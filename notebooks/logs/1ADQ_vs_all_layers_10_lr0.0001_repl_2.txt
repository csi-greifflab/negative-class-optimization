Epoch: 1/200 - Train loss: 0.6819306015968323, Validation loss: 0.672537624835968
Epoch: 2/200 - Train loss: 0.6581509709358215, Validation loss: 0.6433660387992859
Epoch: 3/200 - Train loss: 0.6261926293373108, Validation loss: 0.6129843592643738
Epoch: 4/200 - Train loss: 0.5970557928085327, Validation loss: 0.5874281525611877
Epoch: 5/200 - Train loss: 0.5729595422744751, Validation loss: 0.5670380592346191
Epoch: 6/200 - Train loss: 0.5542618632316589, Validation loss: 0.5517820119857788
Epoch: 7/200 - Train loss: 0.5395469069480896, Validation loss: 0.5385575890541077
Epoch: 8/200 - Train loss: 0.5278925895690918, Validation loss: 0.5291476249694824
Epoch: 9/200 - Train loss: 0.518254816532135, Validation loss: 0.5218732357025146
Epoch: 10/200 - Train loss: 0.5108583569526672, Validation loss: 0.5147486329078674
Epoch: 11/200 - Train loss: 0.5048583149909973, Validation loss: 0.509811520576477
Epoch: 12/200 - Train loss: 0.499433696269989, Validation loss: 0.505550742149353
Epoch: 13/200 - Train loss: 0.4947451651096344, Validation loss: 0.5006134510040283
Epoch: 14/200 - Train loss: 0.49054455757141113, Validation loss: 0.49712079763412476
Epoch: 15/200 - Train loss: 0.48649945855140686, Validation loss: 0.4936957359313965
Epoch: 16/200 - Train loss: 0.4832592308521271, Validation loss: 0.4906711280345917
Epoch: 17/200 - Train loss: 0.47951942682266235, Validation loss: 0.48661914467811584
Epoch: 18/200 - Train loss: 0.47649824619293213, Validation loss: 0.4835033714771271
Epoch: 19/200 - Train loss: 0.4736468493938446, Validation loss: 0.48069214820861816
Epoch: 20/200 - Train loss: 0.4706575572490692, Validation loss: 0.47789520025253296
Epoch: 21/200 - Train loss: 0.46795061230659485, Validation loss: 0.4750743806362152
Epoch: 22/200 - Train loss: 0.46511614322662354, Validation loss: 0.47297441959381104
Epoch: 23/200 - Train loss: 0.4622836112976074, Validation loss: 0.47040265798568726
Epoch: 24/200 - Train loss: 0.45994749665260315, Validation loss: 0.4686369299888611
Epoch: 25/200 - Train loss: 0.4575750231742859, Validation loss: 0.4657081365585327
Epoch: 26/200 - Train loss: 0.4552355408668518, Validation loss: 0.46410197019577026
Epoch: 27/200 - Train loss: 0.4528210461139679, Validation loss: 0.46198347210884094
Epoch: 28/200 - Train loss: 0.45067134499549866, Validation loss: 0.4602634608745575
Epoch: 29/200 - Train loss: 0.44837135076522827, Validation loss: 0.4573691487312317
Epoch: 30/200 - Train loss: 0.44658809900283813, Validation loss: 0.45634472370147705
Epoch: 31/200 - Train loss: 0.4441581070423126, Validation loss: 0.45469966530799866
Epoch: 32/200 - Train loss: 0.4425085186958313, Validation loss: 0.4523898661136627
Epoch: 33/200 - Train loss: 0.44067278504371643, Validation loss: 0.4505560100078583
Epoch: 34/200 - Train loss: 0.43871837854385376, Validation loss: 0.44879311323165894
Epoch: 35/200 - Train loss: 0.4366423487663269, Validation loss: 0.4466964304447174
Epoch: 36/200 - Train loss: 0.43508055806159973, Validation loss: 0.4454047381877899
Epoch: 37/200 - Train loss: 0.43284136056900024, Validation loss: 0.443421870470047
Epoch: 38/200 - Train loss: 0.4313566982746124, Validation loss: 0.4424900412559509
Epoch: 39/200 - Train loss: 0.42916005849838257, Validation loss: 0.4399249255657196
Epoch: 40/200 - Train loss: 0.4276326596736908, Validation loss: 0.4391791522502899
Epoch: 41/200 - Train loss: 0.42565739154815674, Validation loss: 0.4372866153717041
Epoch: 42/200 - Train loss: 0.42345115542411804, Validation loss: 0.4349943697452545
Epoch: 43/200 - Train loss: 0.42171624302864075, Validation loss: 0.43329092860221863
Epoch: 44/200 - Train loss: 0.4198282063007355, Validation loss: 0.4326569437980652
Epoch: 45/200 - Train loss: 0.41805729269981384, Validation loss: 0.4305015206336975
Epoch: 46/200 - Train loss: 0.4164961874485016, Validation loss: 0.4295923113822937
Epoch: 47/200 - Train loss: 0.41432061791419983, Validation loss: 0.4274376630783081
Epoch: 48/200 - Train loss: 0.41280463337898254, Validation loss: 0.42607882618904114
Epoch: 49/200 - Train loss: 0.4106541574001312, Validation loss: 0.4238176643848419
Epoch: 50/200 - Train loss: 0.40866386890411377, Validation loss: 0.422748863697052
Epoch: 51/200 - Train loss: 0.406838059425354, Validation loss: 0.42142581939697266
Epoch: 52/200 - Train loss: 0.4053118824958801, Validation loss: 0.41986486315727234
Epoch: 53/200 - Train loss: 0.40308359265327454, Validation loss: 0.41891908645629883
Epoch: 54/200 - Train loss: 0.40148141980171204, Validation loss: 0.41670018434524536
Epoch: 55/200 - Train loss: 0.3993183672428131, Validation loss: 0.4146937131881714
Epoch: 56/200 - Train loss: 0.39746060967445374, Validation loss: 0.41330838203430176
Epoch: 57/200 - Train loss: 0.3954503834247589, Validation loss: 0.41100841760635376
Epoch: 58/200 - Train loss: 0.3936493992805481, Validation loss: 0.40942302346229553
Epoch: 59/200 - Train loss: 0.39160338044166565, Validation loss: 0.407672643661499
Epoch: 60/200 - Train loss: 0.38960447907447815, Validation loss: 0.40577876567840576
Epoch: 61/200 - Train loss: 0.38806208968162537, Validation loss: 0.4046882688999176
Epoch: 62/200 - Train loss: 0.38590115308761597, Validation loss: 0.4031730890274048
Epoch: 63/200 - Train loss: 0.3838390111923218, Validation loss: 0.40055787563323975
Epoch: 64/200 - Train loss: 0.38175535202026367, Validation loss: 0.3996155858039856
Epoch: 65/200 - Train loss: 0.3799954950809479, Validation loss: 0.3974185287952423
Epoch: 66/200 - Train loss: 0.37837696075439453, Validation loss: 0.39579451084136963
Epoch: 67/200 - Train loss: 0.3761104643344879, Validation loss: 0.3939637541770935
Epoch: 68/200 - Train loss: 0.3748284578323364, Validation loss: 0.3925715982913971
Epoch: 69/200 - Train loss: 0.3730946481227875, Validation loss: 0.39145150780677795
Epoch: 70/200 - Train loss: 0.370481014251709, Validation loss: 0.39011913537979126
Epoch: 71/200 - Train loss: 0.3689517378807068, Validation loss: 0.38732433319091797
Epoch: 72/200 - Train loss: 0.3669532835483551, Validation loss: 0.3863224983215332
Epoch: 73/200 - Train loss: 0.3652077317237854, Validation loss: 0.38411855697631836
Epoch: 74/200 - Train loss: 0.3631681799888611, Validation loss: 0.382215678691864
Epoch: 75/200 - Train loss: 0.36164894700050354, Validation loss: 0.38176098465919495
Epoch: 76/200 - Train loss: 0.35962939262390137, Validation loss: 0.3796851933002472
Epoch: 77/200 - Train loss: 0.357463538646698, Validation loss: 0.37865692377090454
Epoch: 78/200 - Train loss: 0.35551580786705017, Validation loss: 0.3768787384033203
Epoch: 79/200 - Train loss: 0.35385721921920776, Validation loss: 0.3740897476673126
Epoch: 80/200 - Train loss: 0.3519461750984192, Validation loss: 0.3725852966308594
Epoch: 81/200 - Train loss: 0.35060179233551025, Validation loss: 0.3718583285808563
Epoch: 82/200 - Train loss: 0.34883737564086914, Validation loss: 0.3695942461490631
Epoch: 83/200 - Train loss: 0.34653836488723755, Validation loss: 0.3687812089920044
Epoch: 84/200 - Train loss: 0.3450591564178467, Validation loss: 0.3667776584625244
Epoch: 85/200 - Train loss: 0.3431819677352905, Validation loss: 0.36562368273735046
Epoch: 86/200 - Train loss: 0.341744601726532, Validation loss: 0.364082932472229
Epoch: 87/200 - Train loss: 0.339651495218277, Validation loss: 0.3628450334072113
Epoch: 88/200 - Train loss: 0.3385891318321228, Validation loss: 0.36119818687438965
Epoch: 89/200 - Train loss: 0.3366372287273407, Validation loss: 0.3592912554740906
Epoch: 90/200 - Train loss: 0.3347702920436859, Validation loss: 0.35762882232666016
Epoch: 91/200 - Train loss: 0.3330833911895752, Validation loss: 0.35724595189094543
Epoch: 92/200 - Train loss: 0.33156049251556396, Validation loss: 0.3560647666454315
Epoch: 93/200 - Train loss: 0.3296699523925781, Validation loss: 0.3535841107368469
Epoch: 94/200 - Train loss: 0.32815417647361755, Validation loss: 0.3532617390155792
Epoch: 95/200 - Train loss: 0.3262537717819214, Validation loss: 0.35119712352752686
Epoch: 96/200 - Train loss: 0.3249751925468445, Validation loss: 0.3488859236240387
Epoch: 97/200 - Train loss: 0.32340967655181885, Validation loss: 0.34899675846099854
Epoch: 98/200 - Train loss: 0.32183837890625, Validation loss: 0.3466807007789612
Epoch: 99/200 - Train loss: 0.3200176954269409, Validation loss: 0.34685757756233215
Epoch: 100/200 - Train loss: 0.31858476996421814, Validation loss: 0.34428784251213074
Epoch: 101/200 - Train loss: 0.3173832893371582, Validation loss: 0.3432287871837616
Epoch: 102/200 - Train loss: 0.31575751304626465, Validation loss: 0.342122346162796
Epoch: 103/200 - Train loss: 0.31420454382896423, Validation loss: 0.3404577970504761
Epoch: 104/200 - Train loss: 0.31260043382644653, Validation loss: 0.33939191699028015
Epoch: 105/200 - Train loss: 0.31119096279144287, Validation loss: 0.33893832564353943
Epoch: 106/200 - Train loss: 0.3095701336860657, Validation loss: 0.3385591506958008
Epoch: 107/200 - Train loss: 0.3082687258720398, Validation loss: 0.33566635847091675
Epoch: 108/200 - Train loss: 0.30717888474464417, Validation loss: 0.3346808850765228
Epoch: 109/200 - Train loss: 0.30559641122817993, Validation loss: 0.33396413922309875
Epoch: 110/200 - Train loss: 0.30406156182289124, Validation loss: 0.3325822949409485
Epoch: 111/200 - Train loss: 0.3027268946170807, Validation loss: 0.3320819139480591
Epoch: 112/200 - Train loss: 0.30128124356269836, Validation loss: 0.3299933075904846
Epoch: 113/200 - Train loss: 0.30020764470100403, Validation loss: 0.32957184314727783
Epoch: 114/200 - Train loss: 0.2989594340324402, Validation loss: 0.3281599283218384
Epoch: 115/200 - Train loss: 0.29757964611053467, Validation loss: 0.32797402143478394
Epoch: 116/200 - Train loss: 0.2964581251144409, Validation loss: 0.325967401266098
Epoch: 117/200 - Train loss: 0.29495733976364136, Validation loss: 0.3247811794281006
Epoch: 118/200 - Train loss: 0.2938753366470337, Validation loss: 0.3242378830909729
Epoch: 119/200 - Train loss: 0.2923973500728607, Validation loss: 0.3233676552772522
Epoch: 120/200 - Train loss: 0.29132145643234253, Validation loss: 0.3224206268787384
Epoch: 121/200 - Train loss: 0.2903478443622589, Validation loss: 0.32145607471466064
Epoch: 122/200 - Train loss: 0.28930121660232544, Validation loss: 0.32091960310935974
Epoch: 123/200 - Train loss: 0.2877836227416992, Validation loss: 0.31998249888420105
Epoch: 124/200 - Train loss: 0.28729507327079773, Validation loss: 0.3188432455062866
Epoch: 125/200 - Train loss: 0.2857416868209839, Validation loss: 0.3172025680541992
Epoch: 126/200 - Train loss: 0.28469789028167725, Validation loss: 0.31697672605514526
Epoch: 127/200 - Train loss: 0.2836775481700897, Validation loss: 0.3160063326358795
Epoch: 128/200 - Train loss: 0.2827475965023041, Validation loss: 0.3156873285770416
Epoch: 129/200 - Train loss: 0.2816542088985443, Validation loss: 0.3150424659252167
Epoch: 130/200 - Train loss: 0.2806687355041504, Validation loss: 0.3138519525527954
Epoch: 131/200 - Train loss: 0.2799425423145294, Validation loss: 0.3137175440788269
Epoch: 132/200 - Train loss: 0.27861765027046204, Validation loss: 0.31267133355140686
Epoch: 133/200 - Train loss: 0.27748364210128784, Validation loss: 0.31205639243125916
Epoch: 134/200 - Train loss: 0.2769225239753723, Validation loss: 0.31182894110679626
Epoch: 135/200 - Train loss: 0.2762364447116852, Validation loss: 0.3105245530605316
Epoch: 136/200 - Train loss: 0.2748548686504364, Validation loss: 0.3097155690193176
Epoch: 137/200 - Train loss: 0.27409324049949646, Validation loss: 0.3085424304008484
Epoch: 138/200 - Train loss: 0.2730715572834015, Validation loss: 0.308115690946579
Epoch: 139/200 - Train loss: 0.27230513095855713, Validation loss: 0.30736711621284485
Epoch: 140/200 - Train loss: 0.271828293800354, Validation loss: 0.3061557114124298
Epoch: 141/200 - Train loss: 0.27095165848731995, Validation loss: 0.30556219816207886
Epoch: 142/200 - Train loss: 0.2697206139564514, Validation loss: 0.3054635226726532
Epoch: 143/200 - Train loss: 0.26902949810028076, Validation loss: 0.30537116527557373
Epoch: 144/200 - Train loss: 0.26800626516342163, Validation loss: 0.30460867285728455
Epoch: 145/200 - Train loss: 0.26728376746177673, Validation loss: 0.3041384518146515
Epoch: 146/200 - Train loss: 0.2665810286998749, Validation loss: 0.3034370243549347
Epoch: 147/200 - Train loss: 0.26584967970848083, Validation loss: 0.30200305581092834
Epoch: 148/200 - Train loss: 0.2655836045742035, Validation loss: 0.3015579581260681
Epoch: 149/200 - Train loss: 0.26419639587402344, Validation loss: 0.30130746960639954
