Epoch: 1/200 - Train loss: 0.5792209506034851, Validation loss: 0.4816485345363617
Epoch: 2/200 - Train loss: 0.3998851478099823, Validation loss: 0.3648221492767334
Epoch: 3/200 - Train loss: 0.3277274966239929, Validation loss: 0.321289986371994
Epoch: 4/200 - Train loss: 0.28888294100761414, Validation loss: 0.28665897250175476
Epoch: 5/200 - Train loss: 0.25612422823905945, Validation loss: 0.2609750032424927
Epoch: 6/200 - Train loss: 0.23335430026054382, Validation loss: 0.23722580075263977
Epoch: 7/200 - Train loss: 0.2137441635131836, Validation loss: 0.22091202437877655
Epoch: 8/200 - Train loss: 0.19972798228263855, Validation loss: 0.21228015422821045
Epoch: 9/200 - Train loss: 0.1891350895166397, Validation loss: 0.20353400707244873
Epoch: 10/200 - Train loss: 0.1838587075471878, Validation loss: 0.2107066512107849
Epoch: 11/200 - Train loss: 0.1769455373287201, Validation loss: 0.20584459602832794
Epoch: 12/200 - Train loss: 0.17138484120368958, Validation loss: 0.20057059824466705
Epoch: 13/200 - Train loss: 0.1758784055709839, Validation loss: 0.1996510773897171
Epoch: 14/200 - Train loss: 0.16752058267593384, Validation loss: 0.19726316630840302
Epoch: 15/200 - Train loss: 0.1671977937221527, Validation loss: 0.19381669163703918
Epoch: 16/200 - Train loss: 0.1632228046655655, Validation loss: 0.19167131185531616
Epoch: 17/200 - Train loss: 0.16001911461353302, Validation loss: 0.19182482361793518
Epoch: 18/200 - Train loss: 0.16023112833499908, Validation loss: 0.19359596073627472
Epoch: 19/200 - Train loss: 0.15757887065410614, Validation loss: 0.18866278231143951
Epoch: 20/200 - Train loss: 0.15544843673706055, Validation loss: 0.18687614798545837
Epoch: 21/200 - Train loss: 0.1530516892671585, Validation loss: 0.18983463943004608
Epoch: 22/200 - Train loss: 0.15141312777996063, Validation loss: 0.19878213107585907
Epoch: 23/200 - Train loss: 0.15032540261745453, Validation loss: 0.20086993277072906
Epoch: 24/200 - Train loss: 0.15066231787204742, Validation loss: 0.2000059187412262
Epoch: 25/200 - Train loss: 0.14906622469425201, Validation loss: 0.19834350049495697
Epoch: 26/200 - Train loss: 0.14758175611495972, Validation loss: 0.19915713369846344
Epoch: 27/200 - Train loss: 0.14569973945617676, Validation loss: 0.19694478809833527
Epoch: 28/200 - Train loss: 0.14555609226226807, Validation loss: 0.2075100839138031
Epoch: 29/200 - Train loss: 0.14360831677913666, Validation loss: 0.19605883955955505
Epoch: 30/200 - Train loss: 0.14251695573329926, Validation loss: 0.20928192138671875
Epoch: 31/200 - Train loss: 0.14198479056358337, Validation loss: 0.23402360081672668
Epoch: 32/200 - Train loss: 0.1407846063375473, Validation loss: 0.21934862434864044
Epoch: 33/200 - Train loss: 0.1394372284412384, Validation loss: 0.2209741473197937
Epoch: 34/200 - Train loss: 0.14246565103530884, Validation loss: 0.22230418026447296
Epoch: 35/200 - Train loss: 0.13937225937843323, Validation loss: 0.22009789943695068
Epoch: 36/200 - Train loss: 0.14006106555461884, Validation loss: 0.223067045211792
Epoch: 37/200 - Train loss: 0.13888166844844818, Validation loss: 0.2224106341600418
Epoch: 38/200 - Train loss: 0.13852766156196594, Validation loss: 0.22482922673225403
Epoch: 39/200 - Train loss: 0.1383420079946518, Validation loss: 0.22144679725170135
Epoch: 40/200 - Train loss: 0.1368163526058197, Validation loss: 0.2230265736579895
Epoch: 41/200 - Train loss: 0.1375466287136078, Validation loss: 0.20914806425571442
Epoch: 42/200 - Train loss: 0.13576562702655792, Validation loss: 0.211053729057312
Epoch: 43/200 - Train loss: 0.1355130821466446, Validation loss: 0.2228301614522934
Epoch: 44/200 - Train loss: 0.13463112711906433, Validation loss: 0.23924818634986877
Epoch: 45/200 - Train loss: 0.13550317287445068, Validation loss: 0.22283096611499786
Epoch: 46/200 - Train loss: 0.1331547200679779, Validation loss: 0.23680570721626282
Epoch: 47/200 - Train loss: 0.13607080280780792, Validation loss: 0.23485194146633148
Epoch: 48/200 - Train loss: 0.13569805026054382, Validation loss: 0.24653522670269012
Epoch: 49/200 - Train loss: 0.13481207191944122, Validation loss: 0.23720788955688477
Epoch: 50/200 - Train loss: 0.13205912709236145, Validation loss: 0.24933472275733948
Epoch: 51/200 - Train loss: 0.13103275001049042, Validation loss: 0.22375664114952087
Epoch: 52/200 - Train loss: 0.13303571939468384, Validation loss: 0.22292418777942657
Epoch: 53/200 - Train loss: 0.1328984946012497, Validation loss: 0.2404230386018753
Epoch: 54/200 - Train loss: 0.13209964334964752, Validation loss: 0.24900294840335846
Epoch: 55/200 - Train loss: 0.13192731142044067, Validation loss: 0.23993638157844543
Epoch: 56/200 - Train loss: 0.1322137415409088, Validation loss: 0.23755939304828644
Epoch: 57/200 - Train loss: 0.13078241050243378, Validation loss: 0.21651716530323029
Epoch: 58/200 - Train loss: 0.13047240674495697, Validation loss: 0.2655848562717438
Epoch: 59/200 - Train loss: 0.12977470457553864, Validation loss: 0.23840594291687012
Epoch: 60/200 - Train loss: 0.1302109807729721, Validation loss: 0.23770464956760406
Epoch: 61/200 - Train loss: 0.12951363623142242, Validation loss: 0.2490990161895752
Epoch: 62/200 - Train loss: 0.12880587577819824, Validation loss: 0.24351905286312103
Epoch: 63/200 - Train loss: 0.12900933623313904, Validation loss: 0.25072917342185974
Epoch: 64/200 - Train loss: 0.12851369380950928, Validation loss: 0.24110746383666992
Epoch: 65/200 - Train loss: 0.12776605784893036, Validation loss: 0.26721319556236267
Epoch: 66/200 - Train loss: 0.1274067759513855, Validation loss: 0.24009694159030914
Epoch: 67/200 - Train loss: 0.12701374292373657, Validation loss: 0.26506441831588745
Epoch: 68/200 - Train loss: 0.12626010179519653, Validation loss: 0.2654029428958893
Epoch: 69/200 - Train loss: 0.12634819746017456, Validation loss: 0.26781395077705383
Epoch: 70/200 - Train loss: 0.12606236338615417, Validation loss: 0.26578202843666077
Epoch: 71/200 - Train loss: 0.125545471906662, Validation loss: 0.26818370819091797
Epoch: 72/200 - Train loss: 0.1256801038980484, Validation loss: 0.26983919739723206
Epoch: 73/200 - Train loss: 0.12528522312641144, Validation loss: 0.2674349844455719
Epoch: 74/200 - Train loss: 0.12530340254306793, Validation loss: 0.27108898758888245
Epoch: 75/200 - Train loss: 0.12460382282733917, Validation loss: 0.27240756154060364
Epoch: 76/200 - Train loss: 0.12441077828407288, Validation loss: 0.27017131447792053
Epoch: 77/200 - Train loss: 0.12809818983078003, Validation loss: 0.2791912257671356
Epoch: 78/200 - Train loss: 0.12347909063100815, Validation loss: 0.28202009201049805
Epoch: 79/200 - Train loss: 0.12328591197729111, Validation loss: 0.2723315954208374
Epoch: 80/200 - Train loss: 0.12342818081378937, Validation loss: 0.29037678241729736
Epoch: 81/200 - Train loss: 0.12278842180967331, Validation loss: 0.28450265526771545
Epoch: 82/200 - Train loss: 0.12551623582839966, Validation loss: 0.2907088100910187
Epoch: 83/200 - Train loss: 0.1286333054304123, Validation loss: 0.2857634127140045
Epoch: 84/200 - Train loss: 0.12521056830883026, Validation loss: 0.2877918779850006
Epoch: 85/200 - Train loss: 0.12174762785434723, Validation loss: 0.288297176361084
Epoch: 86/200 - Train loss: 0.1212909072637558, Validation loss: 0.28876975178718567
Epoch: 87/200 - Train loss: 0.12697573006153107, Validation loss: 0.2911710739135742
Epoch: 88/200 - Train loss: 0.12414778023958206, Validation loss: 0.2871481478214264
Epoch: 89/200 - Train loss: 0.12357334792613983, Validation loss: 0.2864725887775421
Epoch: 90/200 - Train loss: 0.12047787755727768, Validation loss: 0.28842830657958984
Epoch: 91/200 - Train loss: 0.12351617962121964, Validation loss: 0.28604239225387573
Epoch: 92/200 - Train loss: 0.12670296430587769, Validation loss: 0.28639689087867737
Epoch: 93/200 - Train loss: 0.12555064260959625, Validation loss: 0.2895825505256653
Epoch: 94/200 - Train loss: 0.12312505394220352, Validation loss: 0.29075825214385986
Epoch: 95/200 - Train loss: 0.1253742277622223, Validation loss: 0.2906018793582916
Epoch: 96/200 - Train loss: 0.12228407710790634, Validation loss: 0.2914140820503235
Epoch: 97/200 - Train loss: 0.12183238565921783, Validation loss: 0.29376736283302307
Epoch: 98/200 - Train loss: 0.12521310150623322, Validation loss: 0.29117146134376526
Epoch: 99/200 - Train loss: 0.12475652247667313, Validation loss: 0.29136067628860474
Epoch: 100/200 - Train loss: 0.12491163611412048, Validation loss: 0.29163262248039246
Epoch: 101/200 - Train loss: 0.12511667609214783, Validation loss: 0.2935754656791687
Epoch: 102/200 - Train loss: 0.12404276430606842, Validation loss: 0.3048972189426422
Epoch: 103/200 - Train loss: 0.12371449172496796, Validation loss: 0.2932828664779663
Epoch: 104/200 - Train loss: 0.12047547847032547, Validation loss: 0.2961036264896393
Epoch: 105/200 - Train loss: 0.12285494804382324, Validation loss: 0.29645290970802307
Epoch: 106/200 - Train loss: 0.1265166997909546, Validation loss: 0.29497677087783813
Epoch: 107/200 - Train loss: 0.12588895857334137, Validation loss: 0.2959086000919342
Epoch: 108/200 - Train loss: 0.12544621527194977, Validation loss: 0.29331010580062866
Epoch: 109/200 - Train loss: 0.12315637618303299, Validation loss: 0.2946411669254303
Epoch: 110/200 - Train loss: 0.11954110115766525, Validation loss: 0.29770132899284363
Epoch: 111/200 - Train loss: 0.12538781762123108, Validation loss: 0.2959013879299164
Epoch: 112/200 - Train loss: 0.12511780858039856, Validation loss: 0.2984035611152649
Epoch: 113/200 - Train loss: 0.12541957199573517, Validation loss: 0.2967873513698578
Epoch: 114/200 - Train loss: 0.1243065819144249, Validation loss: 0.29584217071533203
Epoch: 115/200 - Train loss: 0.12473078072071075, Validation loss: 0.2982443869113922
Epoch: 116/200 - Train loss: 0.1271950900554657, Validation loss: 0.2961997091770172
Epoch: 117/200 - Train loss: 0.12149965018033981, Validation loss: 0.29599738121032715
Epoch: 118/200 - Train loss: 0.12090426683425903, Validation loss: 0.29938721656799316
