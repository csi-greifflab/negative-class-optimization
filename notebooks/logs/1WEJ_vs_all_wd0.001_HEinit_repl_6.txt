Epoch: 1/300 - Train loss: 0.6917391419410706, Validation loss: 0.689691424369812
Epoch: 2/300 - Train loss: 0.6901103854179382, Validation loss: 0.6881332397460938
Epoch: 3/300 - Train loss: 0.6884729862213135, Validation loss: 0.6865828037261963
Epoch: 4/300 - Train loss: 0.6868154406547546, Validation loss: 0.6849308609962463
Epoch: 5/300 - Train loss: 0.6851263046264648, Validation loss: 0.6833354830741882
Epoch: 6/300 - Train loss: 0.6833982467651367, Validation loss: 0.681721031665802
Epoch: 7/300 - Train loss: 0.6816251873970032, Validation loss: 0.679989218711853
Epoch: 8/300 - Train loss: 0.6798009276390076, Validation loss: 0.6781591773033142
Epoch: 9/300 - Train loss: 0.6779173612594604, Validation loss: 0.6762703657150269
Epoch: 10/300 - Train loss: 0.6759660840034485, Validation loss: 0.6743114590644836
Epoch: 11/300 - Train loss: 0.6739400625228882, Validation loss: 0.672412633895874
Epoch: 12/300 - Train loss: 0.6718322038650513, Validation loss: 0.6702640652656555
Epoch: 13/300 - Train loss: 0.6696400046348572, Validation loss: 0.6681787371635437
Epoch: 14/300 - Train loss: 0.6673635244369507, Validation loss: 0.6658294796943665
Epoch: 15/300 - Train loss: 0.6649994850158691, Validation loss: 0.6634395122528076
Epoch: 16/300 - Train loss: 0.6625443696975708, Validation loss: 0.6609945893287659
Epoch: 17/300 - Train loss: 0.6599933505058289, Validation loss: 0.6584601402282715
Epoch: 18/300 - Train loss: 0.6573445796966553, Validation loss: 0.6557737588882446
Epoch: 19/300 - Train loss: 0.6545964479446411, Validation loss: 0.6530248522758484
Epoch: 20/300 - Train loss: 0.6517517566680908, Validation loss: 0.6502994298934937
Epoch: 21/300 - Train loss: 0.6488099694252014, Validation loss: 0.647240400314331
Epoch: 22/300 - Train loss: 0.6457715034484863, Validation loss: 0.6441961526870728
Epoch: 23/300 - Train loss: 0.6426390409469604, Validation loss: 0.6410626173019409
Epoch: 24/300 - Train loss: 0.6394146680831909, Validation loss: 0.6377361416816711
Epoch: 25/300 - Train loss: 0.6360971331596375, Validation loss: 0.6344030499458313
Epoch: 26/300 - Train loss: 0.6326932907104492, Validation loss: 0.6310576796531677
Epoch: 27/300 - Train loss: 0.6292068362236023, Validation loss: 0.6275712251663208
Epoch: 28/300 - Train loss: 0.625640869140625, Validation loss: 0.6240367293357849
Epoch: 29/300 - Train loss: 0.6220000982284546, Validation loss: 0.6203540563583374
Epoch: 30/300 - Train loss: 0.6182859539985657, Validation loss: 0.6166301965713501
Epoch: 31/300 - Train loss: 0.6145039796829224, Validation loss: 0.6126367449760437
Epoch: 32/300 - Train loss: 0.6106613278388977, Validation loss: 0.608814537525177
Epoch: 33/300 - Train loss: 0.6067627668380737, Validation loss: 0.604978621006012
Epoch: 34/300 - Train loss: 0.6028171181678772, Validation loss: 0.6011701226234436
Epoch: 35/300 - Train loss: 0.5988287925720215, Validation loss: 0.5969274044036865
Epoch: 36/300 - Train loss: 0.5948024988174438, Validation loss: 0.5930497050285339
Epoch: 37/300 - Train loss: 0.5907430648803711, Validation loss: 0.58896803855896
Epoch: 38/300 - Train loss: 0.5866533517837524, Validation loss: 0.5847082734107971
Epoch: 39/300 - Train loss: 0.5825412273406982, Validation loss: 0.5805255770683289
Epoch: 40/300 - Train loss: 0.5784120559692383, Validation loss: 0.5766973495483398
Epoch: 41/300 - Train loss: 0.5742713212966919, Validation loss: 0.5726746916770935
Epoch: 42/300 - Train loss: 0.5701261758804321, Validation loss: 0.5687155723571777
Epoch: 43/300 - Train loss: 0.5659826397895813, Validation loss: 0.5643894672393799
Epoch: 44/300 - Train loss: 0.5618466138839722, Validation loss: 0.5600937604904175
Epoch: 45/300 - Train loss: 0.5577222108840942, Validation loss: 0.5564724206924438
Epoch: 46/300 - Train loss: 0.5536141395568848, Validation loss: 0.5521594882011414
Epoch: 47/300 - Train loss: 0.5495255589485168, Validation loss: 0.5481082797050476
Epoch: 48/300 - Train loss: 0.54546058177948, Validation loss: 0.5438022613525391
Epoch: 49/300 - Train loss: 0.5414217710494995, Validation loss: 0.5401368737220764
Epoch: 50/300 - Train loss: 0.5374132394790649, Validation loss: 0.5357866287231445
Epoch: 51/300 - Train loss: 0.5334398746490479, Validation loss: 0.5322661399841309
Epoch: 52/300 - Train loss: 0.5295050740242004, Validation loss: 0.5279972553253174
Epoch: 53/300 - Train loss: 0.5256130695343018, Validation loss: 0.5241604447364807
Epoch: 54/300 - Train loss: 0.5217655301094055, Validation loss: 0.5203142166137695
Epoch: 55/300 - Train loss: 0.5179644227027893, Validation loss: 0.5167802572250366
Epoch: 56/300 - Train loss: 0.5142125487327576, Validation loss: 0.5127794146537781
Epoch: 57/300 - Train loss: 0.5105139017105103, Validation loss: 0.5090411305427551
Epoch: 58/300 - Train loss: 0.5068698525428772, Validation loss: 0.5060325860977173
Epoch: 59/300 - Train loss: 0.5032817721366882, Validation loss: 0.5019794702529907
Epoch: 60/300 - Train loss: 0.4997505843639374, Validation loss: 0.49863147735595703
Epoch: 61/300 - Train loss: 0.4962790310382843, Validation loss: 0.49516505002975464
Epoch: 62/300 - Train loss: 0.492867112159729, Validation loss: 0.4919300973415375
Epoch: 63/300 - Train loss: 0.48951682448387146, Validation loss: 0.48818013072013855
Epoch: 64/300 - Train loss: 0.48622944951057434, Validation loss: 0.4849521219730377
Epoch: 65/300 - Train loss: 0.48300498723983765, Validation loss: 0.48191478848457336
Epoch: 66/300 - Train loss: 0.4798441529273987, Validation loss: 0.4785940647125244
Epoch: 67/300 - Train loss: 0.4767475724220276, Validation loss: 0.47558310627937317
Epoch: 68/300 - Train loss: 0.47371596097946167, Validation loss: 0.47242018580436707
Epoch: 69/300 - Train loss: 0.4707498252391815, Validation loss: 0.4698053002357483
Epoch: 70/300 - Train loss: 0.4678492546081543, Validation loss: 0.46648168563842773
Epoch: 71/300 - Train loss: 0.4650144577026367, Validation loss: 0.4636717736721039
Epoch: 72/300 - Train loss: 0.4622451663017273, Validation loss: 0.46113571524620056
Epoch: 73/300 - Train loss: 0.45954063534736633, Validation loss: 0.4586668014526367
Epoch: 74/300 - Train loss: 0.4568999111652374, Validation loss: 0.4556829035282135
Epoch: 75/300 - Train loss: 0.4543229043483734, Validation loss: 0.4536941945552826
Epoch: 76/300 - Train loss: 0.4518090784549713, Validation loss: 0.45065486431121826
Epoch: 77/300 - Train loss: 0.4493577778339386, Validation loss: 0.44833528995513916
Epoch: 78/300 - Train loss: 0.44696763157844543, Validation loss: 0.4460352063179016
Epoch: 79/300 - Train loss: 0.4446375072002411, Validation loss: 0.4435192346572876
Epoch: 80/300 - Train loss: 0.4423666000366211, Validation loss: 0.44175592064857483
Epoch: 81/300 - Train loss: 0.44015371799468994, Validation loss: 0.43868663907051086
Epoch: 82/300 - Train loss: 0.43799731135368347, Validation loss: 0.4372440278530121
Epoch: 83/300 - Train loss: 0.4358953833580017, Validation loss: 0.4346834719181061
Epoch: 84/300 - Train loss: 0.4338468909263611, Validation loss: 0.4330712556838989
Epoch: 85/300 - Train loss: 0.4318503439426422, Validation loss: 0.4306407868862152
Epoch: 86/300 - Train loss: 0.42990437150001526, Validation loss: 0.4291327893733978
Epoch: 87/300 - Train loss: 0.42800840735435486, Validation loss: 0.4267381727695465
Epoch: 88/300 - Train loss: 0.42615920305252075, Validation loss: 0.4253385365009308
Epoch: 89/300 - Train loss: 0.42435553669929504, Validation loss: 0.42312827706336975
Epoch: 90/300 - Train loss: 0.4225950837135315, Validation loss: 0.4210282266139984
Epoch: 91/300 - Train loss: 0.4208759069442749, Validation loss: 0.419635146856308
Epoch: 92/300 - Train loss: 0.4191961884498596, Validation loss: 0.4184704124927521
Epoch: 93/300 - Train loss: 0.4175543785095215, Validation loss: 0.41635608673095703
Epoch: 94/300 - Train loss: 0.41595008969306946, Validation loss: 0.4154722988605499
Epoch: 95/300 - Train loss: 0.4143820106983185, Validation loss: 0.4129519760608673
Epoch: 96/300 - Train loss: 0.4128490388393402, Validation loss: 0.4117170572280884
Epoch: 97/300 - Train loss: 0.41134944558143616, Validation loss: 0.4107714593410492
Epoch: 98/300 - Train loss: 0.40988218784332275, Validation loss: 0.4081316590309143
Epoch: 99/300 - Train loss: 0.4084450304508209, Validation loss: 0.406968355178833
Epoch: 100/300 - Train loss: 0.4070374071598053, Validation loss: 0.40555819869041443
Epoch: 101/300 - Train loss: 0.4056582748889923, Validation loss: 0.4038526713848114
Epoch: 102/300 - Train loss: 0.4043063521385193, Validation loss: 0.4028139114379883
Epoch: 103/300 - Train loss: 0.40297967195510864, Validation loss: 0.4011220633983612
Epoch: 104/300 - Train loss: 0.40167713165283203, Validation loss: 0.40004801750183105
Epoch: 105/300 - Train loss: 0.4004001021385193, Validation loss: 0.3985125720500946
Epoch: 106/300 - Train loss: 0.3991484045982361, Validation loss: 0.39798682928085327
Epoch: 107/300 - Train loss: 0.3979199528694153, Validation loss: 0.3961857557296753
Epoch: 108/300 - Train loss: 0.3967148959636688, Validation loss: 0.3945736289024353
Epoch: 109/300 - Train loss: 0.3955315947532654, Validation loss: 0.39363574981689453
Epoch: 110/300 - Train loss: 0.3943690061569214, Validation loss: 0.3925199806690216
Epoch: 111/300 - Train loss: 0.39322829246520996, Validation loss: 0.3917974531650543
Epoch: 112/300 - Train loss: 0.39210930466651917, Validation loss: 0.3901606500148773
Epoch: 113/300 - Train loss: 0.3910113573074341, Validation loss: 0.3886469006538391
Epoch: 114/300 - Train loss: 0.3899341821670532, Validation loss: 0.38776451349258423
Epoch: 115/300 - Train loss: 0.38887718319892883, Validation loss: 0.38685742020606995
Epoch: 116/300 - Train loss: 0.3878394663333893, Validation loss: 0.3856836259365082
Epoch: 117/300 - Train loss: 0.38682180643081665, Validation loss: 0.3841914236545563
Epoch: 118/300 - Train loss: 0.38582462072372437, Validation loss: 0.38433703780174255
Epoch: 119/300 - Train loss: 0.3848458528518677, Validation loss: 0.3832024037837982
Epoch: 120/300 - Train loss: 0.38388592004776, Validation loss: 0.3817133903503418
Epoch: 121/300 - Train loss: 0.3829437792301178, Validation loss: 0.38097667694091797
Epoch: 122/300 - Train loss: 0.38201966881752014, Validation loss: 0.37907788157463074
Epoch: 123/300 - Train loss: 0.38111424446105957, Validation loss: 0.3790569007396698
Epoch: 124/300 - Train loss: 0.3802267909049988, Validation loss: 0.37817150354385376
Epoch: 125/300 - Train loss: 0.3793572187423706, Validation loss: 0.37642037868499756
Epoch: 126/300 - Train loss: 0.3785040080547333, Validation loss: 0.37648627161979675
Epoch: 127/300 - Train loss: 0.37766578793525696, Validation loss: 0.37522774934768677
Epoch: 128/300 - Train loss: 0.3768428862094879, Validation loss: 0.37382325530052185
Epoch: 129/300 - Train loss: 0.3760344088077545, Validation loss: 0.37383824586868286
Epoch: 130/300 - Train loss: 0.3752402067184448, Validation loss: 0.37189245223999023
Epoch: 131/300 - Train loss: 0.37445956468582153, Validation loss: 0.3716484606266022
Epoch: 132/300 - Train loss: 0.37369176745414734, Validation loss: 0.37052032351493835
Epoch: 133/300 - Train loss: 0.3729364275932312, Validation loss: 0.3696419596672058
Epoch: 134/300 - Train loss: 0.37219247221946716, Validation loss: 0.36898618936538696
Epoch: 135/300 - Train loss: 0.3714607357978821, Validation loss: 0.36853113770484924
Epoch: 136/300 - Train loss: 0.3707405924797058, Validation loss: 0.3675556778907776
Epoch: 137/300 - Train loss: 0.3700321614742279, Validation loss: 0.36646443605422974
Epoch: 138/300 - Train loss: 0.36933472752571106, Validation loss: 0.36639904975891113
Epoch: 139/300 - Train loss: 0.36864739656448364, Validation loss: 0.3651244044303894
Epoch: 140/300 - Train loss: 0.3679698407649994, Validation loss: 0.36459535360336304
Epoch: 141/300 - Train loss: 0.3673020899295807, Validation loss: 0.3640911281108856
Epoch: 142/300 - Train loss: 0.36664333939552307, Validation loss: 0.3634631931781769
Epoch: 143/300 - Train loss: 0.3659936785697937, Validation loss: 0.3622446060180664
Epoch: 144/300 - Train loss: 0.3653517961502075, Validation loss: 0.36223384737968445
Epoch: 145/300 - Train loss: 0.3647167980670929, Validation loss: 0.3614446222782135
Epoch: 146/300 - Train loss: 0.36409059166908264, Validation loss: 0.360323429107666
Epoch: 147/300 - Train loss: 0.36347267031669617, Validation loss: 0.35965603590011597
Epoch: 148/300 - Train loss: 0.3628634512424469, Validation loss: 0.35993972420692444
Epoch: 149/300 - Train loss: 0.3622618317604065, Validation loss: 0.35912129282951355
Epoch: 150/300 - Train loss: 0.36166709661483765, Validation loss: 0.35842886567115784
Epoch: 151/300 - Train loss: 0.36107853055000305, Validation loss: 0.35822415351867676
Epoch: 152/300 - Train loss: 0.36049675941467285, Validation loss: 0.3570146858692169
Epoch: 153/300 - Train loss: 0.35992181301116943, Validation loss: 0.3562561571598053
Epoch: 154/300 - Train loss: 0.35935214161872864, Validation loss: 0.35636791586875916
Epoch: 155/300 - Train loss: 0.35878801345825195, Validation loss: 0.3551925718784332
Epoch: 156/300 - Train loss: 0.35822826623916626, Validation loss: 0.35425466299057007
Epoch: 157/300 - Train loss: 0.35767361521720886, Validation loss: 0.35407575964927673
Epoch: 158/300 - Train loss: 0.35712429881095886, Validation loss: 0.35370150208473206
Epoch: 159/300 - Train loss: 0.35657939314842224, Validation loss: 0.3534944951534271
