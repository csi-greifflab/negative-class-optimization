Epoch: 1/300 - Train loss: 0.6998903751373291, Validation loss: 0.6989496946334839
Epoch: 2/300 - Train loss: 0.6979134678840637, Validation loss: 0.6969472169876099
Epoch: 3/300 - Train loss: 0.6960726380348206, Validation loss: 0.695054292678833
Epoch: 4/300 - Train loss: 0.6943405270576477, Validation loss: 0.6934431195259094
Epoch: 5/300 - Train loss: 0.6926934123039246, Validation loss: 0.6918598413467407
Epoch: 6/300 - Train loss: 0.6910959482192993, Validation loss: 0.6900724768638611
Epoch: 7/300 - Train loss: 0.6895033717155457, Validation loss: 0.688641369342804
Epoch: 8/300 - Train loss: 0.687882125377655, Validation loss: 0.6867738962173462
Epoch: 9/300 - Train loss: 0.6862040162086487, Validation loss: 0.6850128173828125
Epoch: 10/300 - Train loss: 0.6844420433044434, Validation loss: 0.683091938495636
Epoch: 11/300 - Train loss: 0.6825851798057556, Validation loss: 0.6811522245407104
Epoch: 12/300 - Train loss: 0.6806299090385437, Validation loss: 0.678973913192749
Epoch: 13/300 - Train loss: 0.6785823702812195, Validation loss: 0.676785409450531
Epoch: 14/300 - Train loss: 0.6764531135559082, Validation loss: 0.6745995283126831
Epoch: 15/300 - Train loss: 0.6742552518844604, Validation loss: 0.6722346544265747
Epoch: 16/300 - Train loss: 0.6720048785209656, Validation loss: 0.669960618019104
Epoch: 17/300 - Train loss: 0.6697192788124084, Validation loss: 0.6675777435302734
Epoch: 18/300 - Train loss: 0.6674019694328308, Validation loss: 0.6651341319084167
Epoch: 19/300 - Train loss: 0.6650632619857788, Validation loss: 0.6627748608589172
Epoch: 20/300 - Train loss: 0.6627047061920166, Validation loss: 0.660361111164093
Epoch: 21/300 - Train loss: 0.6603280305862427, Validation loss: 0.6580009460449219
Epoch: 22/300 - Train loss: 0.6579250693321228, Validation loss: 0.6554012298583984
Epoch: 23/300 - Train loss: 0.6554923057556152, Validation loss: 0.6529021263122559
Epoch: 24/300 - Train loss: 0.6530309915542603, Validation loss: 0.6504101157188416
Epoch: 25/300 - Train loss: 0.6505491733551025, Validation loss: 0.6478649377822876
Epoch: 26/300 - Train loss: 0.6480485200881958, Validation loss: 0.6451748013496399
Epoch: 27/300 - Train loss: 0.6455276012420654, Validation loss: 0.6428719162940979
Epoch: 28/300 - Train loss: 0.6429897546768188, Validation loss: 0.6403805017471313
Epoch: 29/300 - Train loss: 0.6404384970664978, Validation loss: 0.6376516222953796
Epoch: 30/300 - Train loss: 0.6378781795501709, Validation loss: 0.6350482702255249
Epoch: 31/300 - Train loss: 0.6353123784065247, Validation loss: 0.6323310732841492
Epoch: 32/300 - Train loss: 0.6327413320541382, Validation loss: 0.6298370361328125
Epoch: 33/300 - Train loss: 0.6301681995391846, Validation loss: 0.6273329257965088
Epoch: 34/300 - Train loss: 0.6275942325592041, Validation loss: 0.6246274709701538
Epoch: 35/300 - Train loss: 0.6250211000442505, Validation loss: 0.6222109198570251
Epoch: 36/300 - Train loss: 0.6224489212036133, Validation loss: 0.6195377111434937
Epoch: 37/300 - Train loss: 0.6198804974555969, Validation loss: 0.617031455039978
Epoch: 38/300 - Train loss: 0.6173169016838074, Validation loss: 0.6141716241836548
Epoch: 39/300 - Train loss: 0.6147620677947998, Validation loss: 0.6113563179969788
Epoch: 40/300 - Train loss: 0.6122162342071533, Validation loss: 0.6092166304588318
Epoch: 41/300 - Train loss: 0.609680712223053, Validation loss: 0.6066411733627319
Epoch: 42/300 - Train loss: 0.60715651512146, Validation loss: 0.6039257645606995
Epoch: 43/300 - Train loss: 0.6046441197395325, Validation loss: 0.6013904213905334
Epoch: 44/300 - Train loss: 0.6021455526351929, Validation loss: 0.5990774035453796
Epoch: 45/300 - Train loss: 0.5996612310409546, Validation loss: 0.596555233001709
Epoch: 46/300 - Train loss: 0.5971920490264893, Validation loss: 0.5942502021789551
Epoch: 47/300 - Train loss: 0.5947397351264954, Validation loss: 0.5917026400566101
Epoch: 48/300 - Train loss: 0.5923056602478027, Validation loss: 0.5893675684928894
Epoch: 49/300 - Train loss: 0.5898907780647278, Validation loss: 0.586736261844635
Epoch: 50/300 - Train loss: 0.5874965190887451, Validation loss: 0.5844182968139648
Epoch: 51/300 - Train loss: 0.5851240158081055, Validation loss: 0.5822170376777649
Epoch: 52/300 - Train loss: 0.5827745199203491, Validation loss: 0.5803491473197937
Epoch: 53/300 - Train loss: 0.580450177192688, Validation loss: 0.5774844288825989
Epoch: 54/300 - Train loss: 0.5781506896018982, Validation loss: 0.5753967761993408
Epoch: 55/300 - Train loss: 0.5758768916130066, Validation loss: 0.5730788707733154
Epoch: 56/300 - Train loss: 0.5736292004585266, Validation loss: 0.5707732439041138
Epoch: 57/300 - Train loss: 0.5714075565338135, Validation loss: 0.5687041282653809
Epoch: 58/300 - Train loss: 0.569212794303894, Validation loss: 0.5666345953941345
Epoch: 59/300 - Train loss: 0.5670455098152161, Validation loss: 0.5647765398025513
Epoch: 60/300 - Train loss: 0.5649046301841736, Validation loss: 0.5625036358833313
Epoch: 61/300 - Train loss: 0.5627905130386353, Validation loss: 0.5603463649749756
Epoch: 62/300 - Train loss: 0.5607035160064697, Validation loss: 0.5586794018745422
Epoch: 63/300 - Train loss: 0.5586438179016113, Validation loss: 0.5566930770874023
Epoch: 64/300 - Train loss: 0.5566108226776123, Validation loss: 0.5544412136077881
Epoch: 65/300 - Train loss: 0.554604709148407, Validation loss: 0.5527858734130859
Epoch: 66/300 - Train loss: 0.5526261925697327, Validation loss: 0.5507749915122986
Epoch: 67/300 - Train loss: 0.5506736040115356, Validation loss: 0.5489161014556885
Epoch: 68/300 - Train loss: 0.5487460494041443, Validation loss: 0.5472884774208069
Epoch: 69/300 - Train loss: 0.5468435883522034, Validation loss: 0.5453980565071106
Epoch: 70/300 - Train loss: 0.5449653267860413, Validation loss: 0.5437709093093872
Epoch: 71/300 - Train loss: 0.5431109070777893, Validation loss: 0.5423882603645325
Epoch: 72/300 - Train loss: 0.5412805080413818, Validation loss: 0.5396694540977478
Epoch: 73/300 - Train loss: 0.5394735932350159, Validation loss: 0.5384521484375
Epoch: 74/300 - Train loss: 0.5376895070075989, Validation loss: 0.5366225242614746
Epoch: 75/300 - Train loss: 0.5359267592430115, Validation loss: 0.534961462020874
Epoch: 76/300 - Train loss: 0.5341854691505432, Validation loss: 0.5336146950721741
Epoch: 77/300 - Train loss: 0.5324647426605225, Validation loss: 0.5316135883331299
Epoch: 78/300 - Train loss: 0.5307634472846985, Validation loss: 0.5301310420036316
Epoch: 79/300 - Train loss: 0.5290811657905579, Validation loss: 0.5285034775733948
Epoch: 80/300 - Train loss: 0.5274176001548767, Validation loss: 0.5263647437095642
Epoch: 81/300 - Train loss: 0.5257718563079834, Validation loss: 0.5255257487297058
Epoch: 82/300 - Train loss: 0.5241419672966003, Validation loss: 0.5235792398452759
Epoch: 83/300 - Train loss: 0.5225274562835693, Validation loss: 0.5219951272010803
Epoch: 84/300 - Train loss: 0.5209274888038635, Validation loss: 0.5203101634979248
Epoch: 85/300 - Train loss: 0.5193413496017456, Validation loss: 0.5191696286201477
Epoch: 86/300 - Train loss: 0.5177687406539917, Validation loss: 0.5174833536148071
Epoch: 87/300 - Train loss: 0.5162086486816406, Validation loss: 0.5163269639015198
Epoch: 88/300 - Train loss: 0.5146610140800476, Validation loss: 0.514524519443512
Epoch: 89/300 - Train loss: 0.5131241083145142, Validation loss: 0.5133446455001831
Epoch: 90/300 - Train loss: 0.5115978121757507, Validation loss: 0.5113308429718018
Epoch: 91/300 - Train loss: 0.5100818276405334, Validation loss: 0.5102707743644714
Epoch: 92/300 - Train loss: 0.508575439453125, Validation loss: 0.5088764429092407
Epoch: 93/300 - Train loss: 0.5070781707763672, Validation loss: 0.5072185397148132
Epoch: 94/300 - Train loss: 0.5055893659591675, Validation loss: 0.5059647560119629
Epoch: 95/300 - Train loss: 0.5041089653968811, Validation loss: 0.5043814778327942
Epoch: 96/300 - Train loss: 0.5026355385780334, Validation loss: 0.502925455570221
Epoch: 97/300 - Train loss: 0.5011700987815857, Validation loss: 0.5018504858016968
Epoch: 98/300 - Train loss: 0.49971291422843933, Validation loss: 0.5009043216705322
Epoch: 99/300 - Train loss: 0.49826356768608093, Validation loss: 0.4988456964492798
Epoch: 100/300 - Train loss: 0.49682191014289856, Validation loss: 0.4980181157588959
Epoch: 101/300 - Train loss: 0.4953887462615967, Validation loss: 0.49623560905456543
Epoch: 102/300 - Train loss: 0.493961900472641, Validation loss: 0.494939386844635
Epoch: 103/300 - Train loss: 0.4925406277179718, Validation loss: 0.4931643307209015
Epoch: 104/300 - Train loss: 0.49112579226493835, Validation loss: 0.4923837184906006
Epoch: 105/300 - Train loss: 0.4897174835205078, Validation loss: 0.4908338785171509
Epoch: 106/300 - Train loss: 0.48831671476364136, Validation loss: 0.48947519063949585
Epoch: 107/300 - Train loss: 0.4869236350059509, Validation loss: 0.48800769448280334
Epoch: 108/300 - Train loss: 0.485538512468338, Validation loss: 0.4867578446865082
Epoch: 109/300 - Train loss: 0.48416104912757874, Validation loss: 0.4857127368450165
Epoch: 110/300 - Train loss: 0.4827907383441925, Validation loss: 0.4838818609714508
Epoch: 111/300 - Train loss: 0.4814269542694092, Validation loss: 0.483052134513855
Epoch: 112/300 - Train loss: 0.48006945848464966, Validation loss: 0.48181062936782837
Epoch: 113/300 - Train loss: 0.478718101978302, Validation loss: 0.48065075278282166
Epoch: 114/300 - Train loss: 0.477372407913208, Validation loss: 0.4794222414493561
Epoch: 115/300 - Train loss: 0.47603264451026917, Validation loss: 0.47808825969696045
Epoch: 116/300 - Train loss: 0.4746987521648407, Validation loss: 0.476283460855484
Epoch: 117/300 - Train loss: 0.4733712077140808, Validation loss: 0.4751393496990204
Epoch: 118/300 - Train loss: 0.47204938530921936, Validation loss: 0.47389480471611023
Epoch: 119/300 - Train loss: 0.4707329571247101, Validation loss: 0.47221440076828003
Epoch: 120/300 - Train loss: 0.4694214165210724, Validation loss: 0.4712143540382385
Epoch: 121/300 - Train loss: 0.46811506152153015, Validation loss: 0.46983247995376587
Epoch: 122/300 - Train loss: 0.4668145775794983, Validation loss: 0.4690472185611725
Epoch: 123/300 - Train loss: 0.4655201733112335, Validation loss: 0.4680059254169464
Epoch: 124/300 - Train loss: 0.4642306864261627, Validation loss: 0.46626824140548706
Epoch: 125/300 - Train loss: 0.46294644474983215, Validation loss: 0.4650246500968933
Epoch: 126/300 - Train loss: 0.46166738867759705, Validation loss: 0.46372145414352417
Epoch: 127/300 - Train loss: 0.4603923559188843, Validation loss: 0.46245884895324707
Epoch: 128/300 - Train loss: 0.4591224789619446, Validation loss: 0.46206068992614746
Epoch: 129/300 - Train loss: 0.4578581750392914, Validation loss: 0.4601948857307434
Epoch: 130/300 - Train loss: 0.45659947395324707, Validation loss: 0.45927849411964417
Epoch: 131/300 - Train loss: 0.45534536242485046, Validation loss: 0.4576657712459564
Epoch: 132/300 - Train loss: 0.4540967643260956, Validation loss: 0.457175076007843
Epoch: 133/300 - Train loss: 0.4528529942035675, Validation loss: 0.45549872517585754
Epoch: 134/300 - Train loss: 0.45161446928977966, Validation loss: 0.454411119222641
Epoch: 135/300 - Train loss: 0.45038193464279175, Validation loss: 0.45327484607696533
Epoch: 136/300 - Train loss: 0.44915443658828735, Validation loss: 0.4523848593235016
Epoch: 137/300 - Train loss: 0.44793257117271423, Validation loss: 0.45100128650665283
Epoch: 138/300 - Train loss: 0.4467149078845978, Validation loss: 0.4497973918914795
Epoch: 139/300 - Train loss: 0.4455017149448395, Validation loss: 0.4493725299835205
Epoch: 140/300 - Train loss: 0.44429337978363037, Validation loss: 0.4478205740451813
Epoch: 141/300 - Train loss: 0.4430900812149048, Validation loss: 0.4467974305152893
Epoch: 142/300 - Train loss: 0.44189226627349854, Validation loss: 0.44560232758522034
Epoch: 143/300 - Train loss: 0.4406990110874176, Validation loss: 0.44447869062423706
Epoch: 144/300 - Train loss: 0.43951013684272766, Validation loss: 0.4434499442577362
Epoch: 145/300 - Train loss: 0.43832507729530334, Validation loss: 0.4419898986816406
Epoch: 146/300 - Train loss: 0.4371457099914551, Validation loss: 0.4405445158481598
Epoch: 147/300 - Train loss: 0.43597280979156494, Validation loss: 0.4393981397151947
Epoch: 148/300 - Train loss: 0.4348069727420807, Validation loss: 0.4390004277229309
Epoch: 149/300 - Train loss: 0.43364742398262024, Validation loss: 0.4380754232406616
Epoch: 150/300 - Train loss: 0.4324930012226105, Validation loss: 0.4365621507167816
Epoch: 151/300 - Train loss: 0.43134379386901855, Validation loss: 0.4354628622531891
Epoch: 152/300 - Train loss: 0.4301997721195221, Validation loss: 0.4345559775829315
Epoch: 153/300 - Train loss: 0.4290614724159241, Validation loss: 0.4331655502319336
Epoch: 154/300 - Train loss: 0.4279276430606842, Validation loss: 0.43200039863586426
Epoch: 155/300 - Train loss: 0.42679882049560547, Validation loss: 0.4309101402759552
Epoch: 156/300 - Train loss: 0.4256756901741028, Validation loss: 0.4302505850791931
Epoch: 157/300 - Train loss: 0.4245568513870239, Validation loss: 0.4290525019168854
Epoch: 158/300 - Train loss: 0.42344391345977783, Validation loss: 0.4280218482017517
Epoch: 159/300 - Train loss: 0.4223364591598511, Validation loss: 0.4272500276565552
Epoch: 160/300 - Train loss: 0.42123377323150635, Validation loss: 0.4260065257549286
Epoch: 161/300 - Train loss: 0.4201359152793884, Validation loss: 0.4251613914966583
Epoch: 162/300 - Train loss: 0.4190428555011749, Validation loss: 0.42416834831237793
Epoch: 163/300 - Train loss: 0.4179542362689972, Validation loss: 0.42349720001220703
Epoch: 164/300 - Train loss: 0.4168705940246582, Validation loss: 0.4215410351753235
Epoch: 165/300 - Train loss: 0.41579172015190125, Validation loss: 0.42116665840148926
Epoch: 166/300 - Train loss: 0.4147178530693054, Validation loss: 0.4198414981365204
Epoch: 167/300 - Train loss: 0.4136488139629364, Validation loss: 0.4190104007720947
Epoch: 168/300 - Train loss: 0.41258370876312256, Validation loss: 0.4182089865207672
Epoch: 169/300 - Train loss: 0.41152313351631165, Validation loss: 0.41809001564979553
Epoch: 170/300 - Train loss: 0.4104677140712738, Validation loss: 0.4159637987613678
Epoch: 171/300 - Train loss: 0.40941739082336426, Validation loss: 0.4154447913169861
Epoch: 172/300 - Train loss: 0.40837135910987854, Validation loss: 0.4146638512611389
Epoch: 173/300 - Train loss: 0.407329797744751, Validation loss: 0.41356396675109863
Epoch: 174/300 - Train loss: 0.4062936305999756, Validation loss: 0.41232675313949585
Epoch: 175/300 - Train loss: 0.4052634537220001, Validation loss: 0.41217395663261414
Epoch: 176/300 - Train loss: 0.4042389988899231, Validation loss: 0.41045042872428894
Epoch: 177/300 - Train loss: 0.40321972966194153, Validation loss: 0.40991801023483276
Epoch: 178/300 - Train loss: 0.4022061824798584, Validation loss: 0.40893474221229553
Epoch: 179/300 - Train loss: 0.4011964499950409, Validation loss: 0.4078318774700165
Epoch: 180/300 - Train loss: 0.4001907706260681, Validation loss: 0.40694281458854675
Epoch: 181/300 - Train loss: 0.3991900086402893, Validation loss: 0.405961811542511
Epoch: 182/300 - Train loss: 0.3981935679912567, Validation loss: 0.40493565797805786
Epoch: 183/300 - Train loss: 0.39720067381858826, Validation loss: 0.40405192971229553
Epoch: 184/300 - Train loss: 0.39621102809906006, Validation loss: 0.4032994210720062
Epoch: 185/300 - Train loss: 0.39522647857666016, Validation loss: 0.40245601534843445
Epoch: 186/300 - Train loss: 0.39424699544906616, Validation loss: 0.40177059173583984
Epoch: 187/300 - Train loss: 0.3932729661464691, Validation loss: 0.4006669521331787
Epoch: 188/300 - Train loss: 0.39230477809906006, Validation loss: 0.4006878137588501
Epoch: 189/300 - Train loss: 0.3913414478302002, Validation loss: 0.39872127771377563
Epoch: 190/300 - Train loss: 0.3903828561306, Validation loss: 0.39820095896720886
Epoch: 191/300 - Train loss: 0.38942861557006836, Validation loss: 0.3971812427043915
Epoch: 192/300 - Train loss: 0.3884779214859009, Validation loss: 0.3958296775817871
Epoch: 193/300 - Train loss: 0.3875325918197632, Validation loss: 0.39584505558013916
Epoch: 194/300 - Train loss: 0.3865932524204254, Validation loss: 0.3947871923446655
Epoch: 195/300 - Train loss: 0.38566073775291443, Validation loss: 0.3936482071876526
Epoch: 196/300 - Train loss: 0.3847348690032959, Validation loss: 0.392674058675766
Epoch: 197/300 - Train loss: 0.3838137686252594, Validation loss: 0.3921257257461548
Epoch: 198/300 - Train loss: 0.3828970789909363, Validation loss: 0.3913350999355316
Epoch: 199/300 - Train loss: 0.38198643922805786, Validation loss: 0.39013344049453735
Epoch: 200/300 - Train loss: 0.3810824155807495, Validation loss: 0.3904798626899719
Epoch: 201/300 - Train loss: 0.38018301129341125, Validation loss: 0.38861387968063354
Epoch: 202/300 - Train loss: 0.37928909063339233, Validation loss: 0.38796964287757874
Epoch: 203/300 - Train loss: 0.3784002363681793, Validation loss: 0.3868938088417053
Epoch: 204/300 - Train loss: 0.37751609086990356, Validation loss: 0.3862651288509369
Epoch: 205/300 - Train loss: 0.3766377568244934, Validation loss: 0.38608020544052124
Epoch: 206/300 - Train loss: 0.3757660686969757, Validation loss: 0.3850250244140625
Epoch: 207/300 - Train loss: 0.3749009668827057, Validation loss: 0.383897602558136
Epoch: 208/300 - Train loss: 0.37404194474220276, Validation loss: 0.3833394944667816
Epoch: 209/300 - Train loss: 0.3731888234615326, Validation loss: 0.38264453411102295
Epoch: 210/300 - Train loss: 0.37234097719192505, Validation loss: 0.38169270753860474
Epoch: 211/300 - Train loss: 0.371498167514801, Validation loss: 0.380867063999176
Epoch: 212/300 - Train loss: 0.3706609010696411, Validation loss: 0.3808300197124481
Epoch: 213/300 - Train loss: 0.369829922914505, Validation loss: 0.379578173160553
Epoch: 214/300 - Train loss: 0.36900466680526733, Validation loss: 0.3788919448852539
Epoch: 215/300 - Train loss: 0.3681849539279938, Validation loss: 0.3780757188796997
Epoch: 216/300 - Train loss: 0.3673710227012634, Validation loss: 0.3771691918373108
Epoch: 217/300 - Train loss: 0.3665620982646942, Validation loss: 0.37700867652893066
Epoch: 218/300 - Train loss: 0.3657580316066742, Validation loss: 0.3757407069206238
Epoch: 219/300 - Train loss: 0.36495891213417053, Validation loss: 0.3757352828979492
Epoch: 220/300 - Train loss: 0.36416518688201904, Validation loss: 0.3742445111274719
Epoch: 221/300 - Train loss: 0.36337634921073914, Validation loss: 0.3734649419784546
Epoch: 222/300 - Train loss: 0.36259257793426514, Validation loss: 0.3728802502155304
Epoch: 223/300 - Train loss: 0.36181408166885376, Validation loss: 0.37238484621047974
Epoch: 224/300 - Train loss: 0.36104103922843933, Validation loss: 0.37225818634033203
Epoch: 225/300 - Train loss: 0.36027199029922485, Validation loss: 0.3708905577659607
Epoch: 226/300 - Train loss: 0.35950806736946106, Validation loss: 0.37073200941085815
Epoch: 227/300 - Train loss: 0.3587498664855957, Validation loss: 0.3699469268321991
Epoch: 228/300 - Train loss: 0.35799771547317505, Validation loss: 0.36874353885650635
Epoch: 229/300 - Train loss: 0.35725003480911255, Validation loss: 0.368134081363678
Epoch: 230/300 - Train loss: 0.35650745034217834, Validation loss: 0.3672330975532532
Epoch: 231/300 - Train loss: 0.35577109456062317, Validation loss: 0.3663870096206665
Epoch: 232/300 - Train loss: 0.35503920912742615, Validation loss: 0.3660483658313751
Epoch: 233/300 - Train loss: 0.3543126583099365, Validation loss: 0.3654022812843323
Epoch: 234/300 - Train loss: 0.35359087586402893, Validation loss: 0.36472493410110474
Epoch: 235/300 - Train loss: 0.3528733551502228, Validation loss: 0.36348724365234375
Epoch: 236/300 - Train loss: 0.35216090083122253, Validation loss: 0.3638628125190735
Epoch: 237/300 - Train loss: 0.351453572511673, Validation loss: 0.3624556064605713
Epoch: 238/300 - Train loss: 0.3507518172264099, Validation loss: 0.3618951141834259
Epoch: 239/300 - Train loss: 0.35005488991737366, Validation loss: 0.3615354597568512
Epoch: 240/300 - Train loss: 0.3493621051311493, Validation loss: 0.36070096492767334
Epoch: 241/300 - Train loss: 0.34867405891418457, Validation loss: 0.3598754107952118
Epoch: 242/300 - Train loss: 0.3479918837547302, Validation loss: 0.35944050550460815
Epoch: 243/300 - Train loss: 0.3473142683506012, Validation loss: 0.35906437039375305
Epoch: 244/300 - Train loss: 0.3466411828994751, Validation loss: 0.35791248083114624
Epoch: 245/300 - Train loss: 0.34597301483154297, Validation loss: 0.35759034752845764
Epoch: 246/300 - Train loss: 0.34530937671661377, Validation loss: 0.35660719871520996
Epoch: 247/300 - Train loss: 0.3446505069732666, Validation loss: 0.3566175103187561
Epoch: 248/300 - Train loss: 0.3439961075782776, Validation loss: 0.3563340902328491
Epoch: 249/300 - Train loss: 0.34334686398506165, Validation loss: 0.356484591960907
