Epoch: 1/300 - Train loss: 0.6931130886077881, Validation loss: 0.6910742521286011
Epoch: 2/300 - Train loss: 0.691027045249939, Validation loss: 0.6891464591026306
Epoch: 3/300 - Train loss: 0.689039409160614, Validation loss: 0.687200665473938
Epoch: 4/300 - Train loss: 0.6871095895767212, Validation loss: 0.6854333877563477
Epoch: 5/300 - Train loss: 0.685203492641449, Validation loss: 0.6835696697235107
Epoch: 6/300 - Train loss: 0.6832988262176514, Validation loss: 0.6816822290420532
Epoch: 7/300 - Train loss: 0.6813725829124451, Validation loss: 0.6796208620071411
Epoch: 8/300 - Train loss: 0.6793997883796692, Validation loss: 0.6776806712150574
Epoch: 9/300 - Train loss: 0.6773656010627747, Validation loss: 0.6755754351615906
Epoch: 10/300 - Train loss: 0.6752499341964722, Validation loss: 0.6733857989311218
Epoch: 11/300 - Train loss: 0.6730397939682007, Validation loss: 0.6711245179176331
Epoch: 12/300 - Train loss: 0.6707249283790588, Validation loss: 0.6687442064285278
Epoch: 13/300 - Train loss: 0.6682960987091064, Validation loss: 0.6662170886993408
Epoch: 14/300 - Train loss: 0.6657408475875854, Validation loss: 0.6635454893112183
Epoch: 15/300 - Train loss: 0.663049042224884, Validation loss: 0.6607040166854858
Epoch: 16/300 - Train loss: 0.6602200269699097, Validation loss: 0.6577228903770447
Epoch: 17/300 - Train loss: 0.6572480797767639, Validation loss: 0.6544612646102905
Epoch: 18/300 - Train loss: 0.6541321277618408, Validation loss: 0.6513665914535522
Epoch: 19/300 - Train loss: 0.6508727073669434, Validation loss: 0.647919774055481
Epoch: 20/300 - Train loss: 0.6474713087081909, Validation loss: 0.6444831490516663
Epoch: 21/300 - Train loss: 0.643939733505249, Validation loss: 0.640634298324585
Epoch: 22/300 - Train loss: 0.6402769684791565, Validation loss: 0.6369642019271851
Epoch: 23/300 - Train loss: 0.636488676071167, Validation loss: 0.6330288648605347
Epoch: 24/300 - Train loss: 0.6325821280479431, Validation loss: 0.6290470361709595
Epoch: 25/300 - Train loss: 0.6285680532455444, Validation loss: 0.6250597238540649
Epoch: 26/300 - Train loss: 0.6244527697563171, Validation loss: 0.6208283305168152
Epoch: 27/300 - Train loss: 0.6202427744865417, Validation loss: 0.6166389584541321
Epoch: 28/300 - Train loss: 0.6159443855285645, Validation loss: 0.6122254729270935
Epoch: 29/300 - Train loss: 0.6115631461143494, Validation loss: 0.6077547669410706
Epoch: 30/300 - Train loss: 0.6070990562438965, Validation loss: 0.6032517552375793
Epoch: 31/300 - Train loss: 0.602555513381958, Validation loss: 0.5984197854995728
Epoch: 32/300 - Train loss: 0.5979411602020264, Validation loss: 0.5939812064170837
Epoch: 33/300 - Train loss: 0.5932587385177612, Validation loss: 0.5891664624214172
Epoch: 34/300 - Train loss: 0.5885166525840759, Validation loss: 0.5845794081687927
Epoch: 35/300 - Train loss: 0.5837149620056152, Validation loss: 0.5797062516212463
Epoch: 36/300 - Train loss: 0.5788605809211731, Validation loss: 0.5749215483665466
Epoch: 37/300 - Train loss: 0.5739615559577942, Validation loss: 0.5699570775032043
Epoch: 38/300 - Train loss: 0.5690311193466187, Validation loss: 0.5651998519897461
Epoch: 39/300 - Train loss: 0.5640746355056763, Validation loss: 0.5603089332580566
Epoch: 40/300 - Train loss: 0.5590988993644714, Validation loss: 0.5553002953529358
Epoch: 41/300 - Train loss: 0.5541129112243652, Validation loss: 0.550375759601593
Epoch: 42/300 - Train loss: 0.5491236448287964, Validation loss: 0.54551100730896
Epoch: 43/300 - Train loss: 0.5441400408744812, Validation loss: 0.5404960513114929
Epoch: 44/300 - Train loss: 0.5391719341278076, Validation loss: 0.5358065962791443
Epoch: 45/300 - Train loss: 0.5342260599136353, Validation loss: 0.5309718251228333
Epoch: 46/300 - Train loss: 0.5293099284172058, Validation loss: 0.5260031819343567
Epoch: 47/300 - Train loss: 0.5244297981262207, Validation loss: 0.5210899710655212
Epoch: 48/300 - Train loss: 0.5195903182029724, Validation loss: 0.5163440108299255
Epoch: 49/300 - Train loss: 0.5147960782051086, Validation loss: 0.5117514133453369
Epoch: 50/300 - Train loss: 0.5100517272949219, Validation loss: 0.5071706771850586
Epoch: 51/300 - Train loss: 0.50536048412323, Validation loss: 0.5027117729187012
Epoch: 52/300 - Train loss: 0.500727653503418, Validation loss: 0.49805235862731934
Epoch: 53/300 - Train loss: 0.49615687131881714, Validation loss: 0.49324771761894226
Epoch: 54/300 - Train loss: 0.4916507303714752, Validation loss: 0.48893505334854126
Epoch: 55/300 - Train loss: 0.4872131645679474, Validation loss: 0.48455294966697693
Epoch: 56/300 - Train loss: 0.48284730315208435, Validation loss: 0.4806724190711975
Epoch: 57/300 - Train loss: 0.4785555899143219, Validation loss: 0.4764964282512665
Epoch: 58/300 - Train loss: 0.4743404686450958, Validation loss: 0.4720803499221802
Epoch: 59/300 - Train loss: 0.47020310163497925, Validation loss: 0.4678507149219513
Epoch: 60/300 - Train loss: 0.46614524722099304, Validation loss: 0.46433982253074646
Epoch: 61/300 - Train loss: 0.46216750144958496, Validation loss: 0.46043989062309265
Epoch: 62/300 - Train loss: 0.45827141404151917, Validation loss: 0.4564853608608246
Epoch: 63/300 - Train loss: 0.45445865392684937, Validation loss: 0.4526292681694031
Epoch: 64/300 - Train loss: 0.4507288634777069, Validation loss: 0.44957485795021057
Epoch: 65/300 - Train loss: 0.4470824599266052, Validation loss: 0.445383220911026
Epoch: 66/300 - Train loss: 0.4435194730758667, Validation loss: 0.4419964551925659
Epoch: 67/300 - Train loss: 0.4400390088558197, Validation loss: 0.438742071390152
Epoch: 68/300 - Train loss: 0.43664059042930603, Validation loss: 0.43564391136169434
Epoch: 69/300 - Train loss: 0.43332430720329285, Validation loss: 0.4321356415748596
Epoch: 70/300 - Train loss: 0.4300900101661682, Validation loss: 0.4295267164707184
Epoch: 71/300 - Train loss: 0.4269363582134247, Validation loss: 0.426432341337204
Epoch: 72/300 - Train loss: 0.4238623380661011, Validation loss: 0.42326635122299194
Epoch: 73/300 - Train loss: 0.4208667576313019, Validation loss: 0.42059022188186646
Epoch: 74/300 - Train loss: 0.4179483950138092, Validation loss: 0.41745617985725403
Epoch: 75/300 - Train loss: 0.4151057004928589, Validation loss: 0.4142951965332031
Epoch: 76/300 - Train loss: 0.41233667731285095, Validation loss: 0.4125269055366516
Epoch: 77/300 - Train loss: 0.40963995456695557, Validation loss: 0.40973493456840515
Epoch: 78/300 - Train loss: 0.4070136845111847, Validation loss: 0.40726763010025024
Epoch: 79/300 - Train loss: 0.4044564366340637, Validation loss: 0.4045780301094055
Epoch: 80/300 - Train loss: 0.40196692943573, Validation loss: 0.402092307806015
Epoch: 81/300 - Train loss: 0.3995431065559387, Validation loss: 0.39990711212158203
Epoch: 82/300 - Train loss: 0.39718326926231384, Validation loss: 0.39782196283340454
Epoch: 83/300 - Train loss: 0.3948856592178345, Validation loss: 0.39518293738365173
Epoch: 84/300 - Train loss: 0.392647922039032, Validation loss: 0.39324963092803955
Epoch: 85/300 - Train loss: 0.3904685080051422, Validation loss: 0.39093345403671265
Epoch: 86/300 - Train loss: 0.38834500312805176, Validation loss: 0.388872355222702
Epoch: 87/300 - Train loss: 0.3862754702568054, Validation loss: 0.38696253299713135
Epoch: 88/300 - Train loss: 0.3842584490776062, Validation loss: 0.3850463032722473
Epoch: 89/300 - Train loss: 0.38229236006736755, Validation loss: 0.3835604190826416
Epoch: 90/300 - Train loss: 0.38037559390068054, Validation loss: 0.3811299502849579
Epoch: 91/300 - Train loss: 0.37850674986839294, Validation loss: 0.3800119459629059
Epoch: 92/300 - Train loss: 0.376684308052063, Validation loss: 0.378055214881897
Epoch: 93/300 - Train loss: 0.3749065399169922, Validation loss: 0.37600526213645935
Epoch: 94/300 - Train loss: 0.37317225337028503, Validation loss: 0.3745262026786804
Epoch: 95/300 - Train loss: 0.371479868888855, Validation loss: 0.37281590700149536
Epoch: 96/300 - Train loss: 0.36982810497283936, Validation loss: 0.3710573613643646
Epoch: 97/300 - Train loss: 0.36821484565734863, Validation loss: 0.3695957362651825
Epoch: 98/300 - Train loss: 0.36663955450057983, Validation loss: 0.36829453706741333
Epoch: 99/300 - Train loss: 0.36510077118873596, Validation loss: 0.36707162857055664
Epoch: 100/300 - Train loss: 0.36359700560569763, Validation loss: 0.36595219373703003
Epoch: 101/300 - Train loss: 0.36212795972824097, Validation loss: 0.3644612431526184
Epoch: 102/300 - Train loss: 0.3606921434402466, Validation loss: 0.36267411708831787
Epoch: 103/300 - Train loss: 0.35928887128829956, Validation loss: 0.3610553443431854
Epoch: 104/300 - Train loss: 0.3579169809818268, Validation loss: 0.35994186997413635
Epoch: 105/300 - Train loss: 0.3565749228000641, Validation loss: 0.35946518182754517
Epoch: 106/300 - Train loss: 0.35526183247566223, Validation loss: 0.3574146330356598
Epoch: 107/300 - Train loss: 0.3539770841598511, Validation loss: 0.35599762201309204
Epoch: 108/300 - Train loss: 0.3527200222015381, Validation loss: 0.35433974862098694
Epoch: 109/300 - Train loss: 0.3514898121356964, Validation loss: 0.354228138923645
Epoch: 110/300 - Train loss: 0.3502855896949768, Validation loss: 0.35276341438293457
Epoch: 111/300 - Train loss: 0.34910649061203003, Validation loss: 0.35136041045188904
Epoch: 112/300 - Train loss: 0.3479514718055725, Validation loss: 0.3500920534133911
Epoch: 113/300 - Train loss: 0.34681978821754456, Validation loss: 0.3495510518550873
Epoch: 114/300 - Train loss: 0.345710426568985, Validation loss: 0.3485758900642395
Epoch: 115/300 - Train loss: 0.3446231782436371, Validation loss: 0.3471406102180481
Epoch: 116/300 - Train loss: 0.3435576260089874, Validation loss: 0.3462049067020416
Epoch: 117/300 - Train loss: 0.34251296520233154, Validation loss: 0.3448292016983032
Epoch: 118/300 - Train loss: 0.34148842096328735, Validation loss: 0.34382376074790955
Epoch: 119/300 - Train loss: 0.34048348665237427, Validation loss: 0.3437415063381195
Epoch: 120/300 - Train loss: 0.33949756622314453, Validation loss: 0.34219491481781006
Epoch: 121/300 - Train loss: 0.33852991461753845, Validation loss: 0.34111857414245605
Epoch: 122/300 - Train loss: 0.3375805914402008, Validation loss: 0.340456485748291
Epoch: 123/300 - Train loss: 0.336649090051651, Validation loss: 0.33996647596359253
Epoch: 124/300 - Train loss: 0.33573484420776367, Validation loss: 0.33832234144210815
Epoch: 125/300 - Train loss: 0.33483728766441345, Validation loss: 0.3382057547569275
Epoch: 126/300 - Train loss: 0.3339560329914093, Validation loss: 0.33651411533355713
Epoch: 127/300 - Train loss: 0.3330908715724945, Validation loss: 0.33617058396339417
Epoch: 128/300 - Train loss: 0.3322405219078064, Validation loss: 0.3350118100643158
Epoch: 129/300 - Train loss: 0.3314049243927002, Validation loss: 0.3351248502731323
Epoch: 130/300 - Train loss: 0.3305842876434326, Validation loss: 0.33430618047714233
Epoch: 131/300 - Train loss: 0.3297782838344574, Validation loss: 0.33297985792160034
Epoch: 132/300 - Train loss: 0.3289860188961029, Validation loss: 0.3325894773006439
Epoch: 133/300 - Train loss: 0.3282071650028229, Validation loss: 0.3318370282649994
Epoch: 134/300 - Train loss: 0.3274412453174591, Validation loss: 0.3307128846645355
Epoch: 135/300 - Train loss: 0.32668831944465637, Validation loss: 0.3306436240673065
Epoch: 136/300 - Train loss: 0.32594770193099976, Validation loss: 0.3295007348060608
Epoch: 137/300 - Train loss: 0.3252192437648773, Validation loss: 0.3285868763923645
Epoch: 138/300 - Train loss: 0.3245021104812622, Validation loss: 0.3278547525405884
Epoch: 139/300 - Train loss: 0.3237971365451813, Validation loss: 0.3273894488811493
Epoch: 140/300 - Train loss: 0.3231036365032196, Validation loss: 0.3267398178577423
Epoch: 141/300 - Train loss: 0.3224211633205414, Validation loss: 0.32583320140838623
Epoch: 142/300 - Train loss: 0.3217494487762451, Validation loss: 0.32501110434532166
Epoch: 143/300 - Train loss: 0.32108810544013977, Validation loss: 0.3246312737464905
Epoch: 144/300 - Train loss: 0.320436954498291, Validation loss: 0.32409608364105225
Epoch: 145/300 - Train loss: 0.3197961449623108, Validation loss: 0.32374683022499084
Epoch: 146/300 - Train loss: 0.31916579604148865, Validation loss: 0.3231477737426758
Epoch: 147/300 - Train loss: 0.3185448944568634, Validation loss: 0.32346200942993164
