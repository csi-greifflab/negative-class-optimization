Epoch: 1/100 - Train loss: 0.7045140266418457, Validation loss: 0.7046230435371399
Epoch: 2/100 - Train loss: 0.7025872468948364, Validation loss: 0.7026109099388123
Epoch: 3/100 - Train loss: 0.7007383704185486, Validation loss: 0.7010133266448975
Epoch: 4/100 - Train loss: 0.6989501118659973, Validation loss: 0.6989607810974121
Epoch: 5/100 - Train loss: 0.6972107887268066, Validation loss: 0.6973069310188293
Epoch: 6/100 - Train loss: 0.6955071091651917, Validation loss: 0.6956123113632202
Epoch: 7/100 - Train loss: 0.6938208341598511, Validation loss: 0.69389808177948
Epoch: 8/100 - Train loss: 0.6921358704566956, Validation loss: 0.6920366883277893
Epoch: 9/100 - Train loss: 0.6904416084289551, Validation loss: 0.6904762387275696
Epoch: 10/100 - Train loss: 0.6887279152870178, Validation loss: 0.688556432723999
Epoch: 11/100 - Train loss: 0.6869845986366272, Validation loss: 0.6867801547050476
Epoch: 12/100 - Train loss: 0.6852017641067505, Validation loss: 0.6849246025085449
Epoch: 13/100 - Train loss: 0.6833724975585938, Validation loss: 0.6830183267593384
Epoch: 14/100 - Train loss: 0.6814907789230347, Validation loss: 0.6809488534927368
Epoch: 15/100 - Train loss: 0.6795515418052673, Validation loss: 0.6790171265602112
Epoch: 16/100 - Train loss: 0.6775524020195007, Validation loss: 0.6769808530807495
Epoch: 17/100 - Train loss: 0.6754913926124573, Validation loss: 0.6748368740081787
Epoch: 18/100 - Train loss: 0.6733673810958862, Validation loss: 0.6726661920547485
Epoch: 19/100 - Train loss: 0.6711809039115906, Validation loss: 0.6704943180084229
Epoch: 20/100 - Train loss: 0.6689329147338867, Validation loss: 0.667966365814209
Epoch: 21/100 - Train loss: 0.6666257381439209, Validation loss: 0.6658757328987122
Epoch: 22/100 - Train loss: 0.6642642617225647, Validation loss: 0.6633918881416321
Epoch: 23/100 - Train loss: 0.6618466973304749, Validation loss: 0.6608739495277405
Epoch: 24/100 - Train loss: 0.6593784689903259, Validation loss: 0.658506453037262
Epoch: 25/100 - Train loss: 0.6568572521209717, Validation loss: 0.655755341053009
Epoch: 26/100 - Train loss: 0.6542864441871643, Validation loss: 0.6533372402191162
Epoch: 27/100 - Train loss: 0.6516684889793396, Validation loss: 0.6505890488624573
Epoch: 28/100 - Train loss: 0.6490042805671692, Validation loss: 0.6478947401046753
Epoch: 29/100 - Train loss: 0.6462996006011963, Validation loss: 0.645227313041687
Epoch: 30/100 - Train loss: 0.6435542702674866, Validation loss: 0.642461895942688
Epoch: 31/100 - Train loss: 0.6407697796821594, Validation loss: 0.6397497057914734
Epoch: 32/100 - Train loss: 0.6379479169845581, Validation loss: 0.6369448304176331
Epoch: 33/100 - Train loss: 0.6350895166397095, Validation loss: 0.6340616345405579
Epoch: 34/100 - Train loss: 0.6321970820426941, Validation loss: 0.6311736702919006
Epoch: 35/100 - Train loss: 0.6292728781700134, Validation loss: 0.6283466219902039
Epoch: 36/100 - Train loss: 0.6263197064399719, Validation loss: 0.6255527138710022
Epoch: 37/100 - Train loss: 0.6233380436897278, Validation loss: 0.6224468350410461
Epoch: 38/100 - Train loss: 0.6203311681747437, Validation loss: 0.6197099685668945
Epoch: 39/100 - Train loss: 0.6173012852668762, Validation loss: 0.6165514588356018
Epoch: 40/100 - Train loss: 0.6142534017562866, Validation loss: 0.6137655973434448
Epoch: 41/100 - Train loss: 0.6111940145492554, Validation loss: 0.6107411980628967
Epoch: 42/100 - Train loss: 0.608127772808075, Validation loss: 0.6076589226722717
Epoch: 43/100 - Train loss: 0.6050567030906677, Validation loss: 0.6048417687416077
Epoch: 44/100 - Train loss: 0.601989209651947, Validation loss: 0.6014560461044312
Epoch: 45/100 - Train loss: 0.598930835723877, Validation loss: 0.598882257938385
Epoch: 46/100 - Train loss: 0.59588623046875, Validation loss: 0.5958897471427917
Epoch: 47/100 - Train loss: 0.5928590893745422, Validation loss: 0.5928894877433777
Epoch: 48/100 - Train loss: 0.5898523330688477, Validation loss: 0.5898123979568481
Epoch: 49/100 - Train loss: 0.5868691205978394, Validation loss: 0.5871785879135132
Epoch: 50/100 - Train loss: 0.5839136838912964, Validation loss: 0.5842776894569397
Epoch: 51/100 - Train loss: 0.5809887647628784, Validation loss: 0.5815889835357666
Epoch: 52/100 - Train loss: 0.5780982375144958, Validation loss: 0.5787847638130188
Epoch: 53/100 - Train loss: 0.5752448439598083, Validation loss: 0.5761831998825073
Epoch: 54/100 - Train loss: 0.5724307894706726, Validation loss: 0.5736187696456909
Epoch: 55/100 - Train loss: 0.5696598291397095, Validation loss: 0.5704953670501709
Epoch: 56/100 - Train loss: 0.5669361352920532, Validation loss: 0.5683358311653137
Epoch: 57/100 - Train loss: 0.5642629265785217, Validation loss: 0.5658823847770691
Epoch: 58/100 - Train loss: 0.5616419911384583, Validation loss: 0.5632212162017822
Epoch: 59/100 - Train loss: 0.5590736865997314, Validation loss: 0.5608899593353271
Epoch: 60/100 - Train loss: 0.5565617680549622, Validation loss: 0.5583166480064392
Epoch: 61/100 - Train loss: 0.5541062951087952, Validation loss: 0.5561018586158752
Epoch: 62/100 - Train loss: 0.5517076849937439, Validation loss: 0.5538779497146606
Epoch: 63/100 - Train loss: 0.5493667125701904, Validation loss: 0.5518490076065063
Epoch: 64/100 - Train loss: 0.5470834970474243, Validation loss: 0.5498917102813721
Epoch: 65/100 - Train loss: 0.5448586940765381, Validation loss: 0.5471926927566528
Epoch: 66/100 - Train loss: 0.5426924228668213, Validation loss: 0.5458321571350098
Epoch: 67/100 - Train loss: 0.5405837893486023, Validation loss: 0.5436288714408875
Epoch: 68/100 - Train loss: 0.5385326743125916, Validation loss: 0.5419615507125854
Epoch: 69/100 - Train loss: 0.5365380048751831, Validation loss: 0.5399019122123718
Epoch: 70/100 - Train loss: 0.5345994234085083, Validation loss: 0.5378676652908325
Epoch: 71/100 - Train loss: 0.5327160954475403, Validation loss: 0.5359155535697937
Epoch: 72/100 - Train loss: 0.5308859348297119, Validation loss: 0.5345332622528076
Epoch: 73/100 - Train loss: 0.5291090607643127, Validation loss: 0.5325315594673157
Epoch: 74/100 - Train loss: 0.5273833870887756, Validation loss: 0.532090961933136
Epoch: 75/100 - Train loss: 0.5257067084312439, Validation loss: 0.5301017761230469
Epoch: 76/100 - Train loss: 0.5240788459777832, Validation loss: 0.5282865762710571
Epoch: 77/100 - Train loss: 0.5224972367286682, Validation loss: 0.5265149474143982
Epoch: 78/100 - Train loss: 0.5209610462188721, Validation loss: 0.5259336829185486
Epoch: 79/100 - Train loss: 0.5194693803787231, Validation loss: 0.5238487720489502
Epoch: 80/100 - Train loss: 0.5180198550224304, Validation loss: 0.522682785987854
Epoch: 81/100 - Train loss: 0.5166090130805969, Validation loss: 0.5213924050331116
Epoch: 82/100 - Train loss: 0.515235185623169, Validation loss: 0.5202668309211731
Epoch: 83/100 - Train loss: 0.5138978958129883, Validation loss: 0.5190601348876953
Epoch: 84/100 - Train loss: 0.512595534324646, Validation loss: 0.5178176164627075
Epoch: 85/100 - Train loss: 0.5113254189491272, Validation loss: 0.5163425207138062
Epoch: 86/100 - Train loss: 0.510085940361023, Validation loss: 0.5152584314346313
Epoch: 87/100 - Train loss: 0.5088780522346497, Validation loss: 0.5143091082572937
Epoch: 88/100 - Train loss: 0.5077006816864014, Validation loss: 0.5128681063652039
Epoch: 89/100 - Train loss: 0.506550133228302, Validation loss: 0.5119327306747437
Epoch: 90/100 - Train loss: 0.5054242610931396, Validation loss: 0.5112911462783813
Epoch: 91/100 - Train loss: 0.504321277141571, Validation loss: 0.5092558860778809
Epoch: 92/100 - Train loss: 0.5032416582107544, Validation loss: 0.5088203549385071
Epoch: 93/100 - Train loss: 0.502182126045227, Validation loss: 0.5077033042907715
Epoch: 94/100 - Train loss: 0.5011420249938965, Validation loss: 0.5071279406547546
Epoch: 95/100 - Train loss: 0.5001196265220642, Validation loss: 0.506298303604126
Epoch: 96/100 - Train loss: 0.49911442399024963, Validation loss: 0.5048336982727051
Epoch: 97/100 - Train loss: 0.4981265068054199, Validation loss: 0.5048826932907104
Epoch: 98/100 - Train loss: 0.49715253710746765, Validation loss: 0.5034010410308838
Epoch: 99/100 - Train loss: 0.4961916506290436, Validation loss: 0.5021749138832092
Epoch: 100/100 - Train loss: 0.49524199962615967, Validation loss: 0.5016998648643494
Epoch: 1/300 - Train loss: 0.6933649182319641, Validation loss: 0.6926308870315552
Epoch: 2/300 - Train loss: 0.6925014853477478, Validation loss: 0.6918126344680786
Epoch: 3/300 - Train loss: 0.6916590332984924, Validation loss: 0.6909520030021667
Epoch: 4/300 - Train loss: 0.6907985806465149, Validation loss: 0.6900599598884583
Epoch: 5/300 - Train loss: 0.6898902058601379, Validation loss: 0.6891056299209595
Epoch: 6/300 - Train loss: 0.6889031529426575, Validation loss: 0.6880481839179993
Epoch: 7/300 - Train loss: 0.6878135204315186, Validation loss: 0.6868354678153992
Epoch: 8/300 - Train loss: 0.6866035461425781, Validation loss: 0.6855144500732422
Epoch: 9/300 - Train loss: 0.6852647662162781, Validation loss: 0.6840861439704895
Epoch: 10/300 - Train loss: 0.6837956309318542, Validation loss: 0.6824907660484314
Epoch: 11/300 - Train loss: 0.6821988224983215, Validation loss: 0.6808087229728699
Epoch: 12/300 - Train loss: 0.6804786920547485, Validation loss: 0.6790381669998169
Epoch: 13/300 - Train loss: 0.6786423325538635, Validation loss: 0.677163302898407
Epoch: 14/300 - Train loss: 0.6766921877861023, Validation loss: 0.6750903129577637
Epoch: 15/300 - Train loss: 0.6746379137039185, Validation loss: 0.6729867458343506
Epoch: 16/300 - Train loss: 0.6724916696548462, Validation loss: 0.670842170715332
Epoch: 17/300 - Train loss: 0.6702543497085571, Validation loss: 0.6685993075370789
Epoch: 18/300 - Train loss: 0.6679375767707825, Validation loss: 0.6662227511405945
Epoch: 19/300 - Train loss: 0.6655461192131042, Validation loss: 0.6638903021812439
Epoch: 20/300 - Train loss: 0.6630840301513672, Validation loss: 0.6613937020301819
Epoch: 21/300 - Train loss: 0.6605525612831116, Validation loss: 0.6588559746742249
Epoch: 22/300 - Train loss: 0.6579558253288269, Validation loss: 0.6563390493392944
Epoch: 23/300 - Train loss: 0.6552990674972534, Validation loss: 0.6536720991134644
Epoch: 24/300 - Train loss: 0.652585506439209, Validation loss: 0.6509647369384766
Epoch: 25/300 - Train loss: 0.6498147249221802, Validation loss: 0.6482440829277039
Epoch: 26/300 - Train loss: 0.6469917297363281, Validation loss: 0.6455782651901245
Epoch: 27/300 - Train loss: 0.6441202163696289, Validation loss: 0.6426972150802612
Epoch: 28/300 - Train loss: 0.6412071585655212, Validation loss: 0.6398259401321411
Epoch: 29/300 - Train loss: 0.6382530331611633, Validation loss: 0.6371031403541565
Epoch: 30/300 - Train loss: 0.6352619528770447, Validation loss: 0.6341156959533691
Epoch: 31/300 - Train loss: 0.6322392821311951, Validation loss: 0.6311866641044617
Epoch: 32/300 - Train loss: 0.6291907429695129, Validation loss: 0.6283227205276489
Epoch: 33/300 - Train loss: 0.6261174082756042, Validation loss: 0.6253130435943604
Epoch: 34/300 - Train loss: 0.6230204105377197, Validation loss: 0.6222589612007141
Epoch: 35/300 - Train loss: 0.6199039816856384, Validation loss: 0.6191731691360474
Epoch: 36/300 - Train loss: 0.6167727708816528, Validation loss: 0.6163016557693481
Epoch: 37/300 - Train loss: 0.6136306524276733, Validation loss: 0.6132760047912598
Epoch: 38/300 - Train loss: 0.6104807257652283, Validation loss: 0.6102471351623535
Epoch: 39/300 - Train loss: 0.6073248982429504, Validation loss: 0.6071946620941162
Epoch: 40/300 - Train loss: 0.604166567325592, Validation loss: 0.60419100522995
Epoch: 41/300 - Train loss: 0.6010119915008545, Validation loss: 0.6009151935577393
Epoch: 42/300 - Train loss: 0.5978667140007019, Validation loss: 0.5981649160385132
Epoch: 43/300 - Train loss: 0.5947348475456238, Validation loss: 0.5951976776123047
Epoch: 44/300 - Train loss: 0.5916213393211365, Validation loss: 0.5921704769134521
Epoch: 45/300 - Train loss: 0.5885322690010071, Validation loss: 0.5892013311386108
Epoch: 46/300 - Train loss: 0.5854722857475281, Validation loss: 0.5863189697265625
Epoch: 47/300 - Train loss: 0.5824450254440308, Validation loss: 0.5835695266723633
Epoch: 48/300 - Train loss: 0.5794573426246643, Validation loss: 0.5806682705879211
Epoch: 49/300 - Train loss: 0.5765127539634705, Validation loss: 0.577800452709198
Epoch: 50/300 - Train loss: 0.5736139416694641, Validation loss: 0.574988842010498
Epoch: 51/300 - Train loss: 0.5707646012306213, Validation loss: 0.5725837349891663
Epoch: 52/300 - Train loss: 0.5679687261581421, Validation loss: 0.5698474645614624
Epoch: 53/300 - Train loss: 0.5652284622192383, Validation loss: 0.5672633051872253
Epoch: 54/300 - Train loss: 0.5625462532043457, Validation loss: 0.5648871660232544
Epoch: 55/300 - Train loss: 0.5599251389503479, Validation loss: 0.5625498294830322
Epoch: 56/300 - Train loss: 0.5573663115501404, Validation loss: 0.560145378112793
Epoch: 57/300 - Train loss: 0.5548707246780396, Validation loss: 0.5578223466873169
Epoch: 58/300 - Train loss: 0.5524393916130066, Validation loss: 0.5550569295883179
Epoch: 59/300 - Train loss: 0.5500733852386475, Validation loss: 0.5530897974967957
Epoch: 60/300 - Train loss: 0.5477739572525024, Validation loss: 0.5514211654663086
Epoch: 61/300 - Train loss: 0.5455420017242432, Validation loss: 0.5491843223571777
Epoch: 62/300 - Train loss: 0.5433771014213562, Validation loss: 0.5468053817749023
Epoch: 63/300 - Train loss: 0.5412789583206177, Validation loss: 0.5453676581382751
Epoch: 64/300 - Train loss: 0.5392476916313171, Validation loss: 0.5429994463920593
Epoch: 65/300 - Train loss: 0.5372826457023621, Validation loss: 0.5415278673171997
Epoch: 66/300 - Train loss: 0.535383403301239, Validation loss: 0.539894700050354
Epoch: 67/300 - Train loss: 0.5335484147071838, Validation loss: 0.5379757881164551
Epoch: 68/300 - Train loss: 0.5317762494087219, Validation loss: 0.5364980101585388
Epoch: 69/300 - Train loss: 0.5300657749176025, Validation loss: 0.5351899862289429
Epoch: 70/300 - Train loss: 0.5284153819084167, Validation loss: 0.5338067412376404
Epoch: 71/300 - Train loss: 0.5268239378929138, Validation loss: 0.5318291783332825
Epoch: 72/300 - Train loss: 0.52528977394104, Validation loss: 0.5304164886474609
Epoch: 73/300 - Train loss: 0.523811399936676, Validation loss: 0.5288524031639099
Epoch: 74/300 - Train loss: 0.5223868489265442, Validation loss: 0.5283879637718201
Epoch: 75/300 - Train loss: 0.5210144519805908, Validation loss: 0.5268756747245789
Epoch: 76/300 - Train loss: 0.5196927189826965, Validation loss: 0.5253127813339233
Epoch: 77/300 - Train loss: 0.518418550491333, Validation loss: 0.5248371958732605
Epoch: 78/300 - Train loss: 0.5171900391578674, Validation loss: 0.523674488067627
Epoch: 79/300 - Train loss: 0.5160050392150879, Validation loss: 0.522527277469635
Epoch: 80/300 - Train loss: 0.5148622989654541, Validation loss: 0.5216245055198669
Epoch: 81/300 - Train loss: 0.5137606859207153, Validation loss: 0.5206779837608337
Epoch: 82/300 - Train loss: 0.5126977562904358, Validation loss: 0.5191727876663208
Epoch: 83/300 - Train loss: 0.5116703510284424, Validation loss: 0.5185940861701965
Epoch: 84/300 - Train loss: 0.5106770396232605, Validation loss: 0.517770528793335
Epoch: 85/300 - Train loss: 0.5097154378890991, Validation loss: 0.5173529982566833
Epoch: 86/300 - Train loss: 0.5087839961051941, Validation loss: 0.515912652015686
Epoch: 87/300 - Train loss: 0.5078821778297424, Validation loss: 0.5153781175613403
Epoch: 88/300 - Train loss: 0.5070080757141113, Validation loss: 0.5150501132011414
Epoch: 89/300 - Train loss: 0.5061601996421814, Validation loss: 0.51381915807724
Epoch: 90/300 - Train loss: 0.5053365230560303, Validation loss: 0.5133267045021057
Epoch: 91/300 - Train loss: 0.5045350790023804, Validation loss: 0.5124194622039795
Epoch: 92/300 - Train loss: 0.5037550330162048, Validation loss: 0.5121303796768188
Epoch: 93/300 - Train loss: 0.5029934644699097, Validation loss: 0.5108408331871033
Epoch: 94/300 - Train loss: 0.5022477507591248, Validation loss: 0.5101805329322815
Epoch: 95/300 - Train loss: 0.5015172958374023, Validation loss: 0.5089508891105652
Epoch: 96/300 - Train loss: 0.5008033514022827, Validation loss: 0.5092990398406982
Epoch: 97/300 - Train loss: 0.5001049041748047, Validation loss: 0.509003758430481
Epoch: 98/300 - Train loss: 0.49942007660865784, Validation loss: 0.5078147053718567
Epoch: 99/300 - Train loss: 0.49874669313430786, Validation loss: 0.5066961646080017
Epoch: 100/300 - Train loss: 0.4980841875076294, Validation loss: 0.5067721009254456
Epoch: 101/300 - Train loss: 0.4974324107170105, Validation loss: 0.5055614709854126
Epoch: 102/300 - Train loss: 0.49679020047187805, Validation loss: 0.5052406191825867
Epoch: 103/300 - Train loss: 0.49615588784217834, Validation loss: 0.505198061466217
