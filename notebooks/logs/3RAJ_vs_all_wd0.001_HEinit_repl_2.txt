Epoch: 1/300 - Train loss: 0.6980674862861633, Validation loss: 0.6957354545593262
Epoch: 2/300 - Train loss: 0.6965373158454895, Validation loss: 0.6942417025566101
Epoch: 3/300 - Train loss: 0.6950505375862122, Validation loss: 0.6928986310958862
Epoch: 4/300 - Train loss: 0.6936004757881165, Validation loss: 0.6913043260574341
Epoch: 5/300 - Train loss: 0.6921820640563965, Validation loss: 0.6900855302810669
Epoch: 6/300 - Train loss: 0.6907861828804016, Validation loss: 0.6887149810791016
Epoch: 7/300 - Train loss: 0.6894006133079529, Validation loss: 0.6873287558555603
Epoch: 8/300 - Train loss: 0.688018798828125, Validation loss: 0.6858925223350525
Epoch: 9/300 - Train loss: 0.6866334080696106, Validation loss: 0.6845226287841797
Epoch: 10/300 - Train loss: 0.6852362155914307, Validation loss: 0.683122456073761
Epoch: 11/300 - Train loss: 0.6838212609291077, Validation loss: 0.6817776560783386
Epoch: 12/300 - Train loss: 0.6823874115943909, Validation loss: 0.6802026629447937
Epoch: 13/300 - Train loss: 0.6809279918670654, Validation loss: 0.6787406802177429
Epoch: 14/300 - Train loss: 0.6794406175613403, Validation loss: 0.6771177649497986
Epoch: 15/300 - Train loss: 0.6779182553291321, Validation loss: 0.6756004095077515
Epoch: 16/300 - Train loss: 0.6763584017753601, Validation loss: 0.6740161180496216
Epoch: 17/300 - Train loss: 0.6747573018074036, Validation loss: 0.6722833514213562
Epoch: 18/300 - Train loss: 0.6731115579605103, Validation loss: 0.6705496311187744
Epoch: 19/300 - Train loss: 0.6714190244674683, Validation loss: 0.6687862277030945
Epoch: 20/300 - Train loss: 0.6696757674217224, Validation loss: 0.6669798493385315
Epoch: 21/300 - Train loss: 0.6678786277770996, Validation loss: 0.665073037147522
Epoch: 22/300 - Train loss: 0.6660282015800476, Validation loss: 0.6631683111190796
Epoch: 23/300 - Train loss: 0.6641227602958679, Validation loss: 0.6611597537994385
Epoch: 24/300 - Train loss: 0.6621636152267456, Validation loss: 0.6590238213539124
Epoch: 25/300 - Train loss: 0.6601535677909851, Validation loss: 0.6569079756736755
Epoch: 26/300 - Train loss: 0.6580872535705566, Validation loss: 0.6548153758049011
Epoch: 27/300 - Train loss: 0.6559668779373169, Validation loss: 0.6526763439178467
Epoch: 28/300 - Train loss: 0.6537924408912659, Validation loss: 0.6501438021659851
Epoch: 29/300 - Train loss: 0.651569664478302, Validation loss: 0.6480811834335327
Epoch: 30/300 - Train loss: 0.6493012309074402, Validation loss: 0.6456233263015747
Epoch: 31/300 - Train loss: 0.6469890475273132, Validation loss: 0.6431949734687805
Epoch: 32/300 - Train loss: 0.6446343660354614, Validation loss: 0.6408270597457886
Epoch: 33/300 - Train loss: 0.6422461867332458, Validation loss: 0.6382200121879578
Epoch: 34/300 - Train loss: 0.6398259997367859, Validation loss: 0.635778546333313
Epoch: 35/300 - Train loss: 0.6373802423477173, Validation loss: 0.6332203149795532
Epoch: 36/300 - Train loss: 0.6349098682403564, Validation loss: 0.6306083798408508
Epoch: 37/300 - Train loss: 0.632418692111969, Validation loss: 0.6282598376274109
Epoch: 38/300 - Train loss: 0.62990802526474, Validation loss: 0.6257644295692444
Epoch: 39/300 - Train loss: 0.6273806691169739, Validation loss: 0.6231820583343506
Epoch: 40/300 - Train loss: 0.6248419880867004, Validation loss: 0.6207783222198486
Epoch: 41/300 - Train loss: 0.6222974061965942, Validation loss: 0.6180168986320496
Epoch: 42/300 - Train loss: 0.6197501420974731, Validation loss: 0.6153924465179443
Epoch: 43/300 - Train loss: 0.6172044277191162, Validation loss: 0.6130625605583191
Epoch: 44/300 - Train loss: 0.614663302898407, Validation loss: 0.6105031967163086
Epoch: 45/300 - Train loss: 0.6121281981468201, Validation loss: 0.6080848574638367
Epoch: 46/300 - Train loss: 0.6096034049987793, Validation loss: 0.6053517460823059
Epoch: 47/300 - Train loss: 0.6070922017097473, Validation loss: 0.6028867363929749
Epoch: 48/300 - Train loss: 0.604595959186554, Validation loss: 0.600441575050354
Epoch: 49/300 - Train loss: 0.6021150946617126, Validation loss: 0.5979160070419312
Epoch: 50/300 - Train loss: 0.599653959274292, Validation loss: 0.5951831936836243
Epoch: 51/300 - Train loss: 0.597213625907898, Validation loss: 0.5930016040802002
Epoch: 52/300 - Train loss: 0.594796359539032, Validation loss: 0.5906577706336975
Epoch: 53/300 - Train loss: 0.5924038290977478, Validation loss: 0.5881578326225281
Epoch: 54/300 - Train loss: 0.5900381207466125, Validation loss: 0.5860505104064941
Epoch: 55/300 - Train loss: 0.587701141834259, Validation loss: 0.5835000276565552
Epoch: 56/300 - Train loss: 0.5853939652442932, Validation loss: 0.5812926292419434
Epoch: 57/300 - Train loss: 0.5831173658370972, Validation loss: 0.5790676474571228
Epoch: 58/300 - Train loss: 0.5808723568916321, Validation loss: 0.577553391456604
Epoch: 59/300 - Train loss: 0.5786605477333069, Validation loss: 0.5753352642059326
Epoch: 60/300 - Train loss: 0.5764824151992798, Validation loss: 0.5725525617599487
Epoch: 61/300 - Train loss: 0.5743384957313538, Validation loss: 0.5708344578742981
Epoch: 62/300 - Train loss: 0.57222980260849, Validation loss: 0.5688079595565796
Epoch: 63/300 - Train loss: 0.570155680179596, Validation loss: 0.5671314001083374
Epoch: 64/300 - Train loss: 0.5681162476539612, Validation loss: 0.564864456653595
Epoch: 65/300 - Train loss: 0.5661119818687439, Validation loss: 0.563007652759552
Epoch: 66/300 - Train loss: 0.5641424059867859, Validation loss: 0.5615306496620178
Epoch: 67/300 - Train loss: 0.5622069239616394, Validation loss: 0.5595455169677734
Epoch: 68/300 - Train loss: 0.5603055357933044, Validation loss: 0.5575099587440491
Epoch: 69/300 - Train loss: 0.5584379434585571, Validation loss: 0.5558406114578247
Epoch: 70/300 - Train loss: 0.5566033124923706, Validation loss: 0.5545876026153564
Epoch: 71/300 - Train loss: 0.5548015236854553, Validation loss: 0.5525975227355957
Epoch: 72/300 - Train loss: 0.5530310869216919, Validation loss: 0.5510883927345276
Epoch: 73/300 - Train loss: 0.5512918829917908, Validation loss: 0.5494040250778198
Epoch: 74/300 - Train loss: 0.5495831370353699, Validation loss: 0.5476250648498535
Epoch: 75/300 - Train loss: 0.5479031205177307, Validation loss: 0.5461050271987915
Epoch: 76/300 - Train loss: 0.5462523102760315, Validation loss: 0.5447530746459961
Epoch: 77/300 - Train loss: 0.5446298122406006, Validation loss: 0.5429630279541016
Epoch: 78/300 - Train loss: 0.5430347919464111, Validation loss: 0.5417160391807556
Epoch: 79/300 - Train loss: 0.541465699672699, Validation loss: 0.5400306582450867
Epoch: 80/300 - Train loss: 0.5399215817451477, Validation loss: 0.5387145280838013
Epoch: 81/300 - Train loss: 0.538402259349823, Validation loss: 0.5371323227882385
Epoch: 82/300 - Train loss: 0.5369067192077637, Validation loss: 0.5365667343139648
Epoch: 83/300 - Train loss: 0.535434365272522, Validation loss: 0.534786581993103
Epoch: 84/300 - Train loss: 0.5339846611022949, Validation loss: 0.5333727598190308
Epoch: 85/300 - Train loss: 0.5325564742088318, Validation loss: 0.5319654941558838
Epoch: 86/300 - Train loss: 0.5311497449874878, Validation loss: 0.5306378602981567
Epoch: 87/300 - Train loss: 0.5297630429267883, Validation loss: 0.5291091203689575
Epoch: 88/300 - Train loss: 0.528394877910614, Validation loss: 0.5281916260719299
Epoch: 89/300 - Train loss: 0.5270463824272156, Validation loss: 0.5267488360404968
Epoch: 90/300 - Train loss: 0.5257161855697632, Validation loss: 0.525339663028717
Epoch: 91/300 - Train loss: 0.5244033336639404, Validation loss: 0.5239627361297607
Epoch: 92/300 - Train loss: 0.5231070518493652, Validation loss: 0.5233989953994751
Epoch: 93/300 - Train loss: 0.5218268036842346, Validation loss: 0.5216193199157715
Epoch: 94/300 - Train loss: 0.5205606818199158, Validation loss: 0.5209859013557434
Epoch: 95/300 - Train loss: 0.5193087458610535, Validation loss: 0.5197333693504333
Epoch: 96/300 - Train loss: 0.5180706977844238, Validation loss: 0.5182653665542603
Epoch: 97/300 - Train loss: 0.5168460011482239, Validation loss: 0.5173285603523254
Epoch: 98/300 - Train loss: 0.5156336426734924, Validation loss: 0.5164708495140076
Epoch: 99/300 - Train loss: 0.5144332647323608, Validation loss: 0.5150260925292969
Epoch: 100/300 - Train loss: 0.5132452249526978, Validation loss: 0.5140897035598755
Epoch: 101/300 - Train loss: 0.5120682120323181, Validation loss: 0.5130069255828857
Epoch: 102/300 - Train loss: 0.5109010934829712, Validation loss: 0.5118115544319153
Epoch: 103/300 - Train loss: 0.5097447037696838, Validation loss: 0.5106949210166931
Epoch: 104/300 - Train loss: 0.5085978507995605, Validation loss: 0.5098827481269836
Epoch: 105/300 - Train loss: 0.5074605345726013, Validation loss: 0.508857786655426
Epoch: 106/300 - Train loss: 0.5063323974609375, Validation loss: 0.508441686630249
Epoch: 107/300 - Train loss: 0.5052132606506348, Validation loss: 0.5068257451057434
Epoch: 108/300 - Train loss: 0.5041024684906006, Validation loss: 0.5054724812507629
Epoch: 109/300 - Train loss: 0.5030001401901245, Validation loss: 0.5046474933624268
Epoch: 110/300 - Train loss: 0.5019064545631409, Validation loss: 0.5029609203338623
Epoch: 111/300 - Train loss: 0.5008201003074646, Validation loss: 0.5023542046546936
Epoch: 112/300 - Train loss: 0.49974197149276733, Validation loss: 0.5016138553619385
Epoch: 113/300 - Train loss: 0.49867135286331177, Validation loss: 0.4999367594718933
Epoch: 114/300 - Train loss: 0.49760735034942627, Validation loss: 0.49949976801872253
Epoch: 115/300 - Train loss: 0.4965503513813019, Validation loss: 0.4980314075946808
Epoch: 116/300 - Train loss: 0.49550026655197144, Validation loss: 0.4972379505634308
Epoch: 117/300 - Train loss: 0.4944569170475006, Validation loss: 0.4966782331466675
Epoch: 118/300 - Train loss: 0.49342063069343567, Validation loss: 0.49532943964004517
Epoch: 119/300 - Train loss: 0.49239155650138855, Validation loss: 0.4946761727333069
Epoch: 120/300 - Train loss: 0.49136883020401, Validation loss: 0.49345850944519043
Epoch: 121/300 - Train loss: 0.4903523027896881, Validation loss: 0.49261629581451416
Epoch: 122/300 - Train loss: 0.48934218287467957, Validation loss: 0.49169978499412537
Epoch: 123/300 - Train loss: 0.48833751678466797, Validation loss: 0.4909297525882721
Epoch: 124/300 - Train loss: 0.4873380661010742, Validation loss: 0.490005761384964
Epoch: 125/300 - Train loss: 0.4863446354866028, Validation loss: 0.4891848862171173
Epoch: 126/300 - Train loss: 0.48535677790641785, Validation loss: 0.48803162574768066
Epoch: 127/300 - Train loss: 0.48437464237213135, Validation loss: 0.4871715009212494
Epoch: 128/300 - Train loss: 0.48339810967445374, Validation loss: 0.4862569272518158
Epoch: 129/300 - Train loss: 0.48242664337158203, Validation loss: 0.4847336411476135
Epoch: 130/300 - Train loss: 0.4814603626728058, Validation loss: 0.4842338562011719
Epoch: 131/300 - Train loss: 0.48049986362457275, Validation loss: 0.48383617401123047
Epoch: 132/300 - Train loss: 0.47954443097114563, Validation loss: 0.48261383175849915
Epoch: 133/300 - Train loss: 0.47859442234039307, Validation loss: 0.4813746511936188
Epoch: 134/300 - Train loss: 0.4776494801044464, Validation loss: 0.4803541898727417
Epoch: 135/300 - Train loss: 0.47670844197273254, Validation loss: 0.4800586402416229
Epoch: 136/300 - Train loss: 0.47577202320098877, Validation loss: 0.47911208868026733
Epoch: 137/300 - Train loss: 0.4748398959636688, Validation loss: 0.4783385396003723
Epoch: 138/300 - Train loss: 0.47391214966773987, Validation loss: 0.4768606126308441
Epoch: 139/300 - Train loss: 0.472988098859787, Validation loss: 0.47679221630096436
Epoch: 140/300 - Train loss: 0.4720684289932251, Validation loss: 0.475248247385025
Epoch: 141/300 - Train loss: 0.47115325927734375, Validation loss: 0.4748472273349762
Epoch: 142/300 - Train loss: 0.470242440700531, Validation loss: 0.47421136498451233
Epoch: 143/300 - Train loss: 0.46933645009994507, Validation loss: 0.47292056679725647
Epoch: 144/300 - Train loss: 0.46843472123146057, Validation loss: 0.4725918471813202
Epoch: 145/300 - Train loss: 0.4675365388393402, Validation loss: 0.4711570739746094
Epoch: 146/300 - Train loss: 0.4666425287723541, Validation loss: 0.4709142744541168
Epoch: 147/300 - Train loss: 0.4657534062862396, Validation loss: 0.46949872374534607
Epoch: 148/300 - Train loss: 0.4648672044277191, Validation loss: 0.46911245584487915
Epoch: 149/300 - Train loss: 0.46398454904556274, Validation loss: 0.46794071793556213
Epoch: 150/300 - Train loss: 0.4631059765815735, Validation loss: 0.4672837257385254
Epoch: 151/300 - Train loss: 0.46223166584968567, Validation loss: 0.46664971113204956
Epoch: 152/300 - Train loss: 0.4613610804080963, Validation loss: 0.46509313583374023
Epoch: 153/300 - Train loss: 0.46049368381500244, Validation loss: 0.46508026123046875
Epoch: 154/300 - Train loss: 0.45962953567504883, Validation loss: 0.46381282806396484
Epoch: 155/300 - Train loss: 0.4587689936161041, Validation loss: 0.46338847279548645
Epoch: 156/300 - Train loss: 0.45791131258010864, Validation loss: 0.4628419876098633
Epoch: 157/300 - Train loss: 0.45705699920654297, Validation loss: 0.46118488907814026
Epoch: 158/300 - Train loss: 0.4562056064605713, Validation loss: 0.46142229437828064
Epoch: 159/300 - Train loss: 0.45535793900489807, Validation loss: 0.4603098928928375
Epoch: 160/300 - Train loss: 0.4545133113861084, Validation loss: 0.4596588611602783
Epoch: 161/300 - Train loss: 0.453671932220459, Validation loss: 0.4592079222202301
Epoch: 162/300 - Train loss: 0.45283475518226624, Validation loss: 0.45763900876045227
Epoch: 163/300 - Train loss: 0.4520014226436615, Validation loss: 0.45685669779777527
Epoch: 164/300 - Train loss: 0.4511720836162567, Validation loss: 0.4556921124458313
Epoch: 165/300 - Train loss: 0.4503461420536041, Validation loss: 0.45540064573287964
Epoch: 166/300 - Train loss: 0.44952383637428284, Validation loss: 0.4551531970500946
Epoch: 167/300 - Train loss: 0.4487052261829376, Validation loss: 0.45422011613845825
Epoch: 168/300 - Train loss: 0.4478899836540222, Validation loss: 0.45314571261405945
Epoch: 169/300 - Train loss: 0.4470769166946411, Validation loss: 0.45242053270339966
Epoch: 170/300 - Train loss: 0.44626644253730774, Validation loss: 0.45192936062812805
Epoch: 171/300 - Train loss: 0.44545915722846985, Validation loss: 0.45081034302711487
Epoch: 172/300 - Train loss: 0.4446541666984558, Validation loss: 0.45069319009780884
Epoch: 173/300 - Train loss: 0.44385287165641785, Validation loss: 0.44943755865097046
Epoch: 174/300 - Train loss: 0.44305428862571716, Validation loss: 0.44844070076942444
Epoch: 175/300 - Train loss: 0.44225776195526123, Validation loss: 0.44807884097099304
Epoch: 176/300 - Train loss: 0.4414633512496948, Validation loss: 0.44705909490585327
Epoch: 177/300 - Train loss: 0.44067203998565674, Validation loss: 0.4470892548561096
Epoch: 178/300 - Train loss: 0.43988457322120667, Validation loss: 0.4457772970199585
Epoch: 179/300 - Train loss: 0.43910014629364014, Validation loss: 0.44516581296920776
Epoch: 180/300 - Train loss: 0.4383193552494049, Validation loss: 0.444163978099823
Epoch: 181/300 - Train loss: 0.4375407099723816, Validation loss: 0.4435775578022003
Epoch: 182/300 - Train loss: 0.4367644190788269, Validation loss: 0.4431518614292145
Epoch: 183/300 - Train loss: 0.4359908103942871, Validation loss: 0.4421212673187256
Epoch: 184/300 - Train loss: 0.43521997332572937, Validation loss: 0.44147345423698425
Epoch: 185/300 - Train loss: 0.43445125222206116, Validation loss: 0.4405997097492218
Epoch: 186/300 - Train loss: 0.4336841404438019, Validation loss: 0.4396149218082428
Epoch: 187/300 - Train loss: 0.43292152881622314, Validation loss: 0.4386010766029358
Epoch: 188/300 - Train loss: 0.4321625232696533, Validation loss: 0.438567578792572
Epoch: 189/300 - Train loss: 0.4314066469669342, Validation loss: 0.4373333156108856
Epoch: 190/300 - Train loss: 0.430653840303421, Validation loss: 0.4372672736644745
Epoch: 191/300 - Train loss: 0.42990490794181824, Validation loss: 0.4363635778427124
Epoch: 192/300 - Train loss: 0.4291574954986572, Validation loss: 0.4356250762939453
Epoch: 193/300 - Train loss: 0.4284130930900574, Validation loss: 0.43518882989883423
Epoch: 194/300 - Train loss: 0.427670955657959, Validation loss: 0.4340241253376007
Epoch: 195/300 - Train loss: 0.426931232213974, Validation loss: 0.4334159791469574
Epoch: 196/300 - Train loss: 0.42619484663009644, Validation loss: 0.43256816267967224
Epoch: 197/300 - Train loss: 0.4254617989063263, Validation loss: 0.4318888187408447
Epoch: 198/300 - Train loss: 0.4247319996356964, Validation loss: 0.431997150182724
Epoch: 199/300 - Train loss: 0.4240061640739441, Validation loss: 0.4304921329021454
Epoch: 200/300 - Train loss: 0.42328447103500366, Validation loss: 0.4304637610912323
Epoch: 201/300 - Train loss: 0.4225660264492035, Validation loss: 0.4291173815727234
Epoch: 202/300 - Train loss: 0.42184972763061523, Validation loss: 0.4294302761554718
Epoch: 203/300 - Train loss: 0.42113712430000305, Validation loss: 0.4281916618347168
Epoch: 204/300 - Train loss: 0.4204278886318207, Validation loss: 0.42808443307876587
Epoch: 205/300 - Train loss: 0.4197215437889099, Validation loss: 0.42694514989852905
Epoch: 206/300 - Train loss: 0.419017493724823, Validation loss: 0.4259939193725586
Epoch: 207/300 - Train loss: 0.4183157980442047, Validation loss: 0.4253845512866974
Epoch: 208/300 - Train loss: 0.41761666536331177, Validation loss: 0.4250774383544922
Epoch: 209/300 - Train loss: 0.4169203042984009, Validation loss: 0.42429566383361816
Epoch: 210/300 - Train loss: 0.41622617840766907, Validation loss: 0.4239349067211151
Epoch: 211/300 - Train loss: 0.4155347943305969, Validation loss: 0.4227313995361328
Epoch: 212/300 - Train loss: 0.41484585404396057, Validation loss: 0.4220166802406311
Epoch: 213/300 - Train loss: 0.41415935754776, Validation loss: 0.4211375117301941
Epoch: 214/300 - Train loss: 0.4134749472141266, Validation loss: 0.42140141129493713
Epoch: 215/300 - Train loss: 0.41279128193855286, Validation loss: 0.4201453924179077
Epoch: 216/300 - Train loss: 0.41210874915122986, Validation loss: 0.4195344150066376
Epoch: 217/300 - Train loss: 0.4114280939102173, Validation loss: 0.41906580328941345
Epoch: 218/300 - Train loss: 0.41074812412261963, Validation loss: 0.41832104325294495
Epoch: 219/300 - Train loss: 0.41006866097450256, Validation loss: 0.418055921792984
Epoch: 220/300 - Train loss: 0.40938863158226013, Validation loss: 0.4170253276824951
Epoch: 221/300 - Train loss: 0.4087073504924774, Validation loss: 0.4161873161792755
Epoch: 222/300 - Train loss: 0.4080248773097992, Validation loss: 0.41557934880256653
Epoch: 223/300 - Train loss: 0.40733951330184937, Validation loss: 0.41494637727737427
Epoch: 224/300 - Train loss: 0.40665408968925476, Validation loss: 0.4146949350833893
Epoch: 225/300 - Train loss: 0.4059697091579437, Validation loss: 0.41375449299812317
Epoch: 226/300 - Train loss: 0.4052852690219879, Validation loss: 0.412604957818985
Epoch: 227/300 - Train loss: 0.40460142493247986, Validation loss: 0.41267263889312744
Epoch: 228/300 - Train loss: 0.4039180874824524, Validation loss: 0.41182076930999756
Epoch: 229/300 - Train loss: 0.4032321870326996, Validation loss: 0.4109002947807312
Epoch: 230/300 - Train loss: 0.4025442898273468, Validation loss: 0.4101337492465973
Epoch: 231/300 - Train loss: 0.4018525183200836, Validation loss: 0.4098869562149048
Epoch: 232/300 - Train loss: 0.40115782618522644, Validation loss: 0.4089432656764984
Epoch: 233/300 - Train loss: 0.4004633128643036, Validation loss: 0.40864747762680054
Epoch: 234/300 - Train loss: 0.39976951479911804, Validation loss: 0.40807926654815674
Epoch: 235/300 - Train loss: 0.3990740478038788, Validation loss: 0.40673163533210754
Epoch: 236/300 - Train loss: 0.3983776271343231, Validation loss: 0.40637874603271484
Epoch: 237/300 - Train loss: 0.3976808488368988, Validation loss: 0.406544953584671
Epoch: 238/300 - Train loss: 0.39698326587677, Validation loss: 0.40537765622138977
Epoch: 239/300 - Train loss: 0.3962884545326233, Validation loss: 0.4048693776130676
Epoch: 240/300 - Train loss: 0.39559486508369446, Validation loss: 0.4029901623725891
Epoch: 241/300 - Train loss: 0.3948991894721985, Validation loss: 0.4039229154586792
Epoch: 242/300 - Train loss: 0.39420393109321594, Validation loss: 0.4024128019809723
Epoch: 243/300 - Train loss: 0.3935088515281677, Validation loss: 0.4019632339477539
Epoch: 244/300 - Train loss: 0.3928139805793762, Validation loss: 0.40050292015075684
Epoch: 245/300 - Train loss: 0.3921193778514862, Validation loss: 0.4002309739589691
Epoch: 246/300 - Train loss: 0.3914271593093872, Validation loss: 0.39986753463745117
Epoch: 247/300 - Train loss: 0.39073577523231506, Validation loss: 0.3990345597267151
Epoch: 248/300 - Train loss: 0.39004525542259216, Validation loss: 0.3988685607910156
Epoch: 249/300 - Train loss: 0.38935622572898865, Validation loss: 0.3980080187320709
Epoch: 250/300 - Train loss: 0.38866832852363586, Validation loss: 0.3972161114215851
Epoch: 251/300 - Train loss: 0.38798150420188904, Validation loss: 0.3968460261821747
Epoch: 252/300 - Train loss: 0.38729631900787354, Validation loss: 0.3962472081184387
Epoch: 253/300 - Train loss: 0.3866141140460968, Validation loss: 0.3958410620689392
