Epoch: 1/300 - Train loss: 0.6955118179321289, Validation loss: 0.6913121342658997
Epoch: 2/300 - Train loss: 0.6924443244934082, Validation loss: 0.688370943069458
Epoch: 3/300 - Train loss: 0.6894189715385437, Validation loss: 0.6855296492576599
Epoch: 4/300 - Train loss: 0.6864146590232849, Validation loss: 0.6827199459075928
Epoch: 5/300 - Train loss: 0.6834176778793335, Validation loss: 0.6799076199531555
Epoch: 6/300 - Train loss: 0.6804161071777344, Validation loss: 0.6769588589668274
Epoch: 7/300 - Train loss: 0.6773990392684937, Validation loss: 0.674018919467926
Epoch: 8/300 - Train loss: 0.6743533611297607, Validation loss: 0.6711574792861938
Epoch: 9/300 - Train loss: 0.6712714433670044, Validation loss: 0.6680425405502319
Epoch: 10/300 - Train loss: 0.6681419014930725, Validation loss: 0.6649833917617798
Epoch: 11/300 - Train loss: 0.6649519205093384, Validation loss: 0.6618771553039551
Epoch: 12/300 - Train loss: 0.6616942882537842, Validation loss: 0.6587074398994446
Epoch: 13/300 - Train loss: 0.6583624482154846, Validation loss: 0.655251145362854
Epoch: 14/300 - Train loss: 0.6549573540687561, Validation loss: 0.6519343256950378
Epoch: 15/300 - Train loss: 0.6514686942100525, Validation loss: 0.6484712362289429
Epoch: 16/300 - Train loss: 0.6478954553604126, Validation loss: 0.6447885036468506
Epoch: 17/300 - Train loss: 0.6442365646362305, Validation loss: 0.6411174535751343
Epoch: 18/300 - Train loss: 0.6404919028282166, Validation loss: 0.6374452114105225
Epoch: 19/300 - Train loss: 0.6366575360298157, Validation loss: 0.6335067749023438
Epoch: 20/300 - Train loss: 0.6327317357063293, Validation loss: 0.6296498775482178
Epoch: 21/300 - Train loss: 0.6287149786949158, Validation loss: 0.6256937980651855
Epoch: 22/300 - Train loss: 0.6246130466461182, Validation loss: 0.6215152740478516
Epoch: 23/300 - Train loss: 0.6204290986061096, Validation loss: 0.6172526478767395
Epoch: 24/300 - Train loss: 0.6161591410636902, Validation loss: 0.6129288077354431
Epoch: 25/300 - Train loss: 0.6118103861808777, Validation loss: 0.6086388230323792
Epoch: 26/300 - Train loss: 0.6073867678642273, Validation loss: 0.6040587425231934
Epoch: 27/300 - Train loss: 0.6028925180435181, Validation loss: 0.599666953086853
Epoch: 28/300 - Train loss: 0.5983349084854126, Validation loss: 0.5952242016792297
Epoch: 29/300 - Train loss: 0.5937167406082153, Validation loss: 0.5906292200088501
Epoch: 30/300 - Train loss: 0.589037299156189, Validation loss: 0.5860486030578613
Epoch: 31/300 - Train loss: 0.5843071937561035, Validation loss: 0.5813701748847961
Epoch: 32/300 - Train loss: 0.5795339941978455, Validation loss: 0.5765957832336426
Epoch: 33/300 - Train loss: 0.5747213959693909, Validation loss: 0.5718643665313721
Epoch: 34/300 - Train loss: 0.569877028465271, Validation loss: 0.5672053694725037
Epoch: 35/300 - Train loss: 0.5650054812431335, Validation loss: 0.5621905326843262
Epoch: 36/300 - Train loss: 0.5601228475570679, Validation loss: 0.5575931668281555
Epoch: 37/300 - Train loss: 0.555235743522644, Validation loss: 0.5526561737060547
Epoch: 38/300 - Train loss: 0.5503476858139038, Validation loss: 0.5479261875152588
Epoch: 39/300 - Train loss: 0.5454672574996948, Validation loss: 0.5431532859802246
Epoch: 40/300 - Train loss: 0.5406017303466797, Validation loss: 0.5383130311965942
Epoch: 41/300 - Train loss: 0.5357545614242554, Validation loss: 0.5336627960205078
Epoch: 42/300 - Train loss: 0.5309332609176636, Validation loss: 0.5287646651268005
Epoch: 43/300 - Train loss: 0.5261422991752625, Validation loss: 0.5242120623588562
Epoch: 44/300 - Train loss: 0.5213894248008728, Validation loss: 0.5200102925300598
Epoch: 45/300 - Train loss: 0.5166797041893005, Validation loss: 0.5153796076774597
Epoch: 46/300 - Train loss: 0.5120166540145874, Validation loss: 0.5104084610939026
Epoch: 47/300 - Train loss: 0.5074067115783691, Validation loss: 0.5058835744857788
Epoch: 48/300 - Train loss: 0.5028533339500427, Validation loss: 0.5014000535011292
Epoch: 49/300 - Train loss: 0.49835845828056335, Validation loss: 0.4968738853931427
Epoch: 50/300 - Train loss: 0.4939294755458832, Validation loss: 0.4930555820465088
Epoch: 51/300 - Train loss: 0.4895689785480499, Validation loss: 0.48859909176826477
Epoch: 52/300 - Train loss: 0.4852796792984009, Validation loss: 0.4848010241985321
Epoch: 53/300 - Train loss: 0.4810650050640106, Validation loss: 0.48112431168556213
Epoch: 54/300 - Train loss: 0.47692689299583435, Validation loss: 0.4767281413078308
Epoch: 55/300 - Train loss: 0.47286760807037354, Validation loss: 0.4727408289909363
Epoch: 56/300 - Train loss: 0.4688882827758789, Validation loss: 0.46912938356399536
Epoch: 57/300 - Train loss: 0.46499112248420715, Validation loss: 0.4652588963508606
Epoch: 58/300 - Train loss: 0.46117672324180603, Validation loss: 0.46170487999916077
Epoch: 59/300 - Train loss: 0.4574471414089203, Validation loss: 0.4579918384552002
Epoch: 60/300 - Train loss: 0.4538019299507141, Validation loss: 0.4546600878238678
Epoch: 61/300 - Train loss: 0.4502427577972412, Validation loss: 0.45134100317955017
Epoch: 62/300 - Train loss: 0.446770578622818, Validation loss: 0.44772809743881226
Epoch: 63/300 - Train loss: 0.443385511636734, Validation loss: 0.4444975256919861
Epoch: 64/300 - Train loss: 0.4400876760482788, Validation loss: 0.44158703088760376
Epoch: 65/300 - Train loss: 0.43687593936920166, Validation loss: 0.4381351172924042
Epoch: 66/300 - Train loss: 0.43375080823898315, Validation loss: 0.43547651171684265
Epoch: 67/300 - Train loss: 0.4307117760181427, Validation loss: 0.4323709309101105
Epoch: 68/300 - Train loss: 0.42775779962539673, Validation loss: 0.42945557832717896
Epoch: 69/300 - Train loss: 0.4248881936073303, Validation loss: 0.42691558599472046
Epoch: 70/300 - Train loss: 0.42210203409194946, Validation loss: 0.4240463376045227
Epoch: 71/300 - Train loss: 0.4193974733352661, Validation loss: 0.4216175079345703
Epoch: 72/300 - Train loss: 0.4167729318141937, Validation loss: 0.4189789593219757
Epoch: 73/300 - Train loss: 0.41422709822654724, Validation loss: 0.41674932837486267
Epoch: 74/300 - Train loss: 0.41175881028175354, Validation loss: 0.4140203893184662
Epoch: 75/300 - Train loss: 0.409366637468338, Validation loss: 0.41165295243263245
Epoch: 76/300 - Train loss: 0.4070485830307007, Validation loss: 0.41027647256851196
Epoch: 77/300 - Train loss: 0.4048030972480774, Validation loss: 0.4074324667453766
Epoch: 78/300 - Train loss: 0.4026288688182831, Validation loss: 0.40566393733024597
Epoch: 79/300 - Train loss: 0.4005241096019745, Validation loss: 0.4037605822086334
Epoch: 80/300 - Train loss: 0.3984873592853546, Validation loss: 0.40154600143432617
Epoch: 81/300 - Train loss: 0.39651647210121155, Validation loss: 0.3999634087085724
Epoch: 82/300 - Train loss: 0.39460963010787964, Validation loss: 0.3982475697994232
Epoch: 83/300 - Train loss: 0.3927650451660156, Validation loss: 0.39638203382492065
Epoch: 84/300 - Train loss: 0.39098060131073, Validation loss: 0.39445701241493225
Epoch: 85/300 - Train loss: 0.38925451040267944, Validation loss: 0.39275506138801575
Epoch: 86/300 - Train loss: 0.3875853419303894, Validation loss: 0.3910486400127411
Epoch: 87/300 - Train loss: 0.38597092032432556, Validation loss: 0.3894496560096741
Epoch: 88/300 - Train loss: 0.38440951704978943, Validation loss: 0.3880566358566284
Epoch: 89/300 - Train loss: 0.3828994333744049, Validation loss: 0.38755786418914795
Epoch: 90/300 - Train loss: 0.38143885135650635, Validation loss: 0.3849264085292816
Epoch: 91/300 - Train loss: 0.38002604246139526, Validation loss: 0.384168416261673
Epoch: 92/300 - Train loss: 0.3786596357822418, Validation loss: 0.3822193145751953
Epoch: 93/300 - Train loss: 0.3773377537727356, Validation loss: 0.3810686767101288
Epoch: 94/300 - Train loss: 0.3760588467121124, Validation loss: 0.3804559111595154
Epoch: 95/300 - Train loss: 0.3748215436935425, Validation loss: 0.3790891766548157
Epoch: 96/300 - Train loss: 0.3736240863800049, Validation loss: 0.3782426416873932
Epoch: 97/300 - Train loss: 0.3724648356437683, Validation loss: 0.37657350301742554
Epoch: 98/300 - Train loss: 0.3713424801826477, Validation loss: 0.3752916157245636
Epoch: 99/300 - Train loss: 0.37025579810142517, Validation loss: 0.3745337724685669
Epoch: 100/300 - Train loss: 0.3692033886909485, Validation loss: 0.3730382025241852
Epoch: 101/300 - Train loss: 0.36818385124206543, Validation loss: 0.37235522270202637
Epoch: 102/300 - Train loss: 0.3671959638595581, Validation loss: 0.3716089129447937
Epoch: 103/300 - Train loss: 0.36623841524124146, Validation loss: 0.37052232027053833
Epoch: 104/300 - Train loss: 0.3653096854686737, Validation loss: 0.36958807706832886
Epoch: 105/300 - Train loss: 0.3644092381000519, Validation loss: 0.3690949082374573
Epoch: 106/300 - Train loss: 0.36353588104248047, Validation loss: 0.36812224984169006
Epoch: 107/300 - Train loss: 0.3626883924007416, Validation loss: 0.36706316471099854
Epoch: 108/300 - Train loss: 0.3618656098842621, Validation loss: 0.36638233065605164
Epoch: 109/300 - Train loss: 0.3610667586326599, Validation loss: 0.3655884563922882
Epoch: 110/300 - Train loss: 0.3602907657623291, Validation loss: 0.36473628878593445
Epoch: 111/300 - Train loss: 0.35953694581985474, Validation loss: 0.36446619033813477
Epoch: 112/300 - Train loss: 0.358804315328598, Validation loss: 0.3635496199131012
Epoch: 113/300 - Train loss: 0.35809218883514404, Validation loss: 0.36262401938438416
Epoch: 114/300 - Train loss: 0.3573998808860779, Validation loss: 0.36194780468940735
Epoch: 115/300 - Train loss: 0.35672658681869507, Validation loss: 0.36191892623901367
Epoch: 116/300 - Train loss: 0.35607144236564636, Validation loss: 0.36038461327552795
Epoch: 117/300 - Train loss: 0.3554338812828064, Validation loss: 0.36026906967163086
Epoch: 118/300 - Train loss: 0.35481327772140503, Validation loss: 0.3591211438179016
Epoch: 119/300 - Train loss: 0.3542088568210602, Validation loss: 0.35826656222343445
Epoch: 120/300 - Train loss: 0.3536199927330017, Validation loss: 0.35856539011001587
Epoch: 121/300 - Train loss: 0.35304614901542664, Validation loss: 0.3576103746891022
Epoch: 122/300 - Train loss: 0.3524867296218872, Validation loss: 0.35760733485221863
Epoch: 123/300 - Train loss: 0.35194122791290283, Validation loss: 0.35641565918922424
Epoch: 124/300 - Train loss: 0.35140880942344666, Validation loss: 0.355110228061676
Epoch: 125/300 - Train loss: 0.3508892059326172, Validation loss: 0.3556397259235382
Epoch: 126/300 - Train loss: 0.35038208961486816, Validation loss: 0.35503095388412476
Epoch: 127/300 - Train loss: 0.349886953830719, Validation loss: 0.3545960783958435
