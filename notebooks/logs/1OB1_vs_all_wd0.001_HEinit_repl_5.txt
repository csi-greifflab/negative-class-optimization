Epoch: 1/300 - Train loss: 0.7066318392753601, Validation loss: 0.7020078301429749
Epoch: 2/300 - Train loss: 0.704575777053833, Validation loss: 0.7003345489501953
Epoch: 3/300 - Train loss: 0.7025772333145142, Validation loss: 0.6982676386833191
Epoch: 4/300 - Train loss: 0.7006271481513977, Validation loss: 0.6963933110237122
Epoch: 5/300 - Train loss: 0.6987060308456421, Validation loss: 0.6945731043815613
Epoch: 6/300 - Train loss: 0.6967966556549072, Validation loss: 0.6925727128982544
Epoch: 7/300 - Train loss: 0.6948853135108948, Validation loss: 0.6908478140830994
Epoch: 8/300 - Train loss: 0.692956805229187, Validation loss: 0.6889316439628601
Epoch: 9/300 - Train loss: 0.6909959316253662, Validation loss: 0.68698650598526
Epoch: 10/300 - Train loss: 0.6889925599098206, Validation loss: 0.6846248507499695
Epoch: 11/300 - Train loss: 0.6869369149208069, Validation loss: 0.6828374266624451
Epoch: 12/300 - Train loss: 0.6848183274269104, Validation loss: 0.680718183517456
Epoch: 13/300 - Train loss: 0.6826269626617432, Validation loss: 0.6785233020782471
Epoch: 14/300 - Train loss: 0.6803480386734009, Validation loss: 0.6761499643325806
Epoch: 15/300 - Train loss: 0.6779714226722717, Validation loss: 0.6735363006591797
Epoch: 16/300 - Train loss: 0.6754928231239319, Validation loss: 0.6710139513015747
Epoch: 17/300 - Train loss: 0.6729028224945068, Validation loss: 0.6682857275009155
Epoch: 18/300 - Train loss: 0.6701931953430176, Validation loss: 0.66538405418396
Epoch: 19/300 - Train loss: 0.6673581600189209, Validation loss: 0.6624829769134521
Epoch: 20/300 - Train loss: 0.6643957495689392, Validation loss: 0.65944904088974
Epoch: 21/300 - Train loss: 0.6613053679466248, Validation loss: 0.6561565399169922
Epoch: 22/300 - Train loss: 0.6580938696861267, Validation loss: 0.6528697609901428
Epoch: 23/300 - Train loss: 0.654756486415863, Validation loss: 0.6493353843688965
Epoch: 24/300 - Train loss: 0.6512976288795471, Validation loss: 0.6457781791687012
Epoch: 25/300 - Train loss: 0.6477159857749939, Validation loss: 0.6418895721435547
Epoch: 26/300 - Train loss: 0.644012987613678, Validation loss: 0.637920081615448
Epoch: 27/300 - Train loss: 0.6401951909065247, Validation loss: 0.6338975429534912
Epoch: 28/300 - Train loss: 0.6362631916999817, Validation loss: 0.6297863125801086
Epoch: 29/300 - Train loss: 0.6322237849235535, Validation loss: 0.6257625818252563
Epoch: 30/300 - Train loss: 0.6280816793441772, Validation loss: 0.6215225458145142
Epoch: 31/300 - Train loss: 0.6238483786582947, Validation loss: 0.6172274947166443
Epoch: 32/300 - Train loss: 0.619533121585846, Validation loss: 0.6128805875778198
Epoch: 33/300 - Train loss: 0.615151047706604, Validation loss: 0.6079752445220947
Epoch: 34/300 - Train loss: 0.6107068061828613, Validation loss: 0.6036866903305054
Epoch: 35/300 - Train loss: 0.6062079071998596, Validation loss: 0.5988754630088806
Epoch: 36/300 - Train loss: 0.6016665697097778, Validation loss: 0.5942085385322571
Epoch: 37/300 - Train loss: 0.5970936417579651, Validation loss: 0.5897623896598816
Epoch: 38/300 - Train loss: 0.5924978852272034, Validation loss: 0.5849264860153198
Epoch: 39/300 - Train loss: 0.5878812074661255, Validation loss: 0.5799695253372192
Epoch: 40/300 - Train loss: 0.5832567811012268, Validation loss: 0.5759688019752502
Epoch: 41/300 - Train loss: 0.5786234140396118, Validation loss: 0.5710432529449463
Epoch: 42/300 - Train loss: 0.5739887952804565, Validation loss: 0.5665765404701233
Epoch: 43/300 - Train loss: 0.5693535208702087, Validation loss: 0.5618164539337158
Epoch: 44/300 - Train loss: 0.5647218227386475, Validation loss: 0.5568514466285706
Epoch: 45/300 - Train loss: 0.5600960850715637, Validation loss: 0.5520907044410706
Epoch: 46/300 - Train loss: 0.5554820895195007, Validation loss: 0.5474144816398621
Epoch: 47/300 - Train loss: 0.5508789420127869, Validation loss: 0.5428081154823303
Epoch: 48/300 - Train loss: 0.5462892055511475, Validation loss: 0.5384327173233032
Epoch: 49/300 - Train loss: 0.5417162775993347, Validation loss: 0.5337514877319336
Epoch: 50/300 - Train loss: 0.5371658205986023, Validation loss: 0.528844952583313
Epoch: 51/300 - Train loss: 0.5326426029205322, Validation loss: 0.5243275165557861
Epoch: 52/300 - Train loss: 0.5281484723091125, Validation loss: 0.5198834538459778
Epoch: 53/300 - Train loss: 0.5236859321594238, Validation loss: 0.515432596206665
Epoch: 54/300 - Train loss: 0.5192617774009705, Validation loss: 0.510697066783905
Epoch: 55/300 - Train loss: 0.5148797035217285, Validation loss: 0.506436824798584
Epoch: 56/300 - Train loss: 0.5105418562889099, Validation loss: 0.5022562146186829
Epoch: 57/300 - Train loss: 0.5062530636787415, Validation loss: 0.49786117672920227
Epoch: 58/300 - Train loss: 0.5020170211791992, Validation loss: 0.4934959411621094
Epoch: 59/300 - Train loss: 0.49783438444137573, Validation loss: 0.4894995093345642
Epoch: 60/300 - Train loss: 0.4937089681625366, Validation loss: 0.48537543416023254
Epoch: 61/300 - Train loss: 0.4896408021450043, Validation loss: 0.4812197983264923
Epoch: 62/300 - Train loss: 0.48563340306282043, Validation loss: 0.4776782691478729
Epoch: 63/300 - Train loss: 0.4816879332065582, Validation loss: 0.47302499413490295
Epoch: 64/300 - Train loss: 0.4778057634830475, Validation loss: 0.469439297914505
Epoch: 65/300 - Train loss: 0.4739871919155121, Validation loss: 0.46554630994796753
Epoch: 66/300 - Train loss: 0.47023484110832214, Validation loss: 0.4615306556224823
Epoch: 67/300 - Train loss: 0.466550350189209, Validation loss: 0.45786723494529724
Epoch: 68/300 - Train loss: 0.4629351794719696, Validation loss: 0.4543576240539551
Epoch: 69/300 - Train loss: 0.45939043164253235, Validation loss: 0.45090803503990173
Epoch: 70/300 - Train loss: 0.4559182822704315, Validation loss: 0.4475078880786896
Epoch: 71/300 - Train loss: 0.45251762866973877, Validation loss: 0.44388464093208313
Epoch: 72/300 - Train loss: 0.4491885006427765, Validation loss: 0.4404500424861908
Epoch: 73/300 - Train loss: 0.44593140482902527, Validation loss: 0.4374009072780609
Epoch: 74/300 - Train loss: 0.44274574518203735, Validation loss: 0.43406692147254944
Epoch: 75/300 - Train loss: 0.4396309554576874, Validation loss: 0.43096601963043213
Epoch: 76/300 - Train loss: 0.4365861713886261, Validation loss: 0.42801177501678467
Epoch: 77/300 - Train loss: 0.433612197637558, Validation loss: 0.4248185455799103
Epoch: 78/300 - Train loss: 0.4307091534137726, Validation loss: 0.4218980669975281
Epoch: 79/300 - Train loss: 0.427876353263855, Validation loss: 0.4190516173839569
Epoch: 80/300 - Train loss: 0.4251134991645813, Validation loss: 0.41611236333847046
Epoch: 81/300 - Train loss: 0.4224199652671814, Validation loss: 0.41390085220336914
Epoch: 82/300 - Train loss: 0.4197947382926941, Validation loss: 0.41061556339263916
Epoch: 83/300 - Train loss: 0.4172365665435791, Validation loss: 0.40806901454925537
Epoch: 84/300 - Train loss: 0.41474512219429016, Validation loss: 0.4055219292640686
Epoch: 85/300 - Train loss: 0.4123193919658661, Validation loss: 0.40324342250823975
Epoch: 86/300 - Train loss: 0.4099581241607666, Validation loss: 0.40061113238334656
Epoch: 87/300 - Train loss: 0.40766027569770813, Validation loss: 0.398160845041275
Epoch: 88/300 - Train loss: 0.40542489290237427, Validation loss: 0.39579343795776367
Epoch: 89/300 - Train loss: 0.4032508432865143, Validation loss: 0.3937077522277832
Epoch: 90/300 - Train loss: 0.4011376202106476, Validation loss: 0.39179110527038574
Epoch: 91/300 - Train loss: 0.3990841805934906, Validation loss: 0.38985028862953186
Epoch: 92/300 - Train loss: 0.3970889151096344, Validation loss: 0.3878307044506073
Epoch: 93/300 - Train loss: 0.39514994621276855, Validation loss: 0.38563328981399536
Epoch: 94/300 - Train loss: 0.3932669758796692, Validation loss: 0.38378167152404785
Epoch: 95/300 - Train loss: 0.39143767952919006, Validation loss: 0.3817571699619293
Epoch: 96/300 - Train loss: 0.3896609842777252, Validation loss: 0.37994691729545593
Epoch: 97/300 - Train loss: 0.3879358470439911, Validation loss: 0.3780011534690857
Epoch: 98/300 - Train loss: 0.3862610459327698, Validation loss: 0.3765881061553955
Epoch: 99/300 - Train loss: 0.38463541865348816, Validation loss: 0.37468793988227844
Epoch: 100/300 - Train loss: 0.38305723667144775, Validation loss: 0.37309426069259644
Epoch: 101/300 - Train loss: 0.38152530789375305, Validation loss: 0.3710823059082031
Epoch: 102/300 - Train loss: 0.3800383508205414, Validation loss: 0.37021124362945557
Epoch: 103/300 - Train loss: 0.3785950839519501, Validation loss: 0.36899977922439575
Epoch: 104/300 - Train loss: 0.3771938979625702, Validation loss: 0.36684808135032654
Epoch: 105/300 - Train loss: 0.37583354115486145, Validation loss: 0.3655392825603485
Epoch: 106/300 - Train loss: 0.3745133578777313, Validation loss: 0.36391696333885193
Epoch: 107/300 - Train loss: 0.37323200702667236, Validation loss: 0.3631100058555603
Epoch: 108/300 - Train loss: 0.3719883859157562, Validation loss: 0.36174145340919495
Epoch: 109/300 - Train loss: 0.3707805871963501, Validation loss: 0.3599504232406616
Epoch: 110/300 - Train loss: 0.3696071207523346, Validation loss: 0.35936620831489563
Epoch: 111/300 - Train loss: 0.3684675097465515, Validation loss: 0.35792842507362366
Epoch: 112/300 - Train loss: 0.3673608601093292, Validation loss: 0.357001394033432
Epoch: 113/300 - Train loss: 0.36628568172454834, Validation loss: 0.35585272312164307
Epoch: 114/300 - Train loss: 0.36524108052253723, Validation loss: 0.3547528088092804
Epoch: 115/300 - Train loss: 0.3642261028289795, Validation loss: 0.3531259298324585
Epoch: 116/300 - Train loss: 0.3632394075393677, Validation loss: 0.35229694843292236
Epoch: 117/300 - Train loss: 0.36228033900260925, Validation loss: 0.3514930307865143
Epoch: 118/300 - Train loss: 0.36134788393974304, Validation loss: 0.35044586658477783
Epoch: 119/300 - Train loss: 0.36044132709503174, Validation loss: 0.3497352600097656
Epoch: 120/300 - Train loss: 0.3595598042011261, Validation loss: 0.3485235869884491
Epoch: 121/300 - Train loss: 0.3587021231651306, Validation loss: 0.3474326431751251
Epoch: 122/300 - Train loss: 0.357867956161499, Validation loss: 0.3467513918876648
Epoch: 123/300 - Train loss: 0.35705652832984924, Validation loss: 0.34607601165771484
Epoch: 124/300 - Train loss: 0.3562667667865753, Validation loss: 0.3454117476940155
Epoch: 125/300 - Train loss: 0.35549822449684143, Validation loss: 0.34387829899787903
Epoch: 126/300 - Train loss: 0.3547498881816864, Validation loss: 0.3439883589744568
Epoch: 127/300 - Train loss: 0.3540208041667938, Validation loss: 0.34315890073776245
Epoch: 128/300 - Train loss: 0.3533098101615906, Validation loss: 0.3416179120540619
Epoch: 129/300 - Train loss: 0.3526165187358856, Validation loss: 0.3420673906803131
Epoch: 130/300 - Train loss: 0.3519400954246521, Validation loss: 0.3406064510345459
Epoch: 131/300 - Train loss: 0.35128024220466614, Validation loss: 0.33973249793052673
Epoch: 132/300 - Train loss: 0.3506368100643158, Validation loss: 0.33894023299217224
Epoch: 133/300 - Train loss: 0.3500087559223175, Validation loss: 0.3379583954811096
Epoch: 134/300 - Train loss: 0.3493955731391907, Validation loss: 0.33843210339546204
Epoch: 135/300 - Train loss: 0.3487965762615204, Validation loss: 0.33724692463874817
Epoch: 136/300 - Train loss: 0.3482113778591156, Validation loss: 0.33710911870002747
Epoch: 137/300 - Train loss: 0.34763985872268677, Validation loss: 0.335917204618454
Epoch: 138/300 - Train loss: 0.34708115458488464, Validation loss: 0.33546140789985657
Epoch: 139/300 - Train loss: 0.3465345799922943, Validation loss: 0.3348848223686218
Epoch: 140/300 - Train loss: 0.3459997773170471, Validation loss: 0.33467575907707214
Epoch: 141/300 - Train loss: 0.3454758822917938, Validation loss: 0.3334301710128784
Epoch: 142/300 - Train loss: 0.34496206045150757, Validation loss: 0.3331449031829834
Epoch: 143/300 - Train loss: 0.34445860981941223, Validation loss: 0.3327706456184387
Epoch: 144/300 - Train loss: 0.3439652621746063, Validation loss: 0.3319742679595947
Epoch: 145/300 - Train loss: 0.3434811532497406, Validation loss: 0.3317747116088867
Epoch: 146/300 - Train loss: 0.34300580620765686, Validation loss: 0.3309837579727173
