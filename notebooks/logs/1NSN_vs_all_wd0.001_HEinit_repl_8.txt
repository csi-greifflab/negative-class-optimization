Epoch: 1/300 - Train loss: 0.7034912109375, Validation loss: 0.7034648656845093
Epoch: 2/300 - Train loss: 0.7017905116081238, Validation loss: 0.7018222808837891
Epoch: 3/300 - Train loss: 0.7000895142555237, Validation loss: 0.7000664472579956
Epoch: 4/300 - Train loss: 0.6983741521835327, Validation loss: 0.6982427835464478
Epoch: 5/300 - Train loss: 0.6966276168823242, Validation loss: 0.6963515877723694
Epoch: 6/300 - Train loss: 0.6948330998420715, Validation loss: 0.6945172548294067
Epoch: 7/300 - Train loss: 0.6929666996002197, Validation loss: 0.6925201416015625
Epoch: 8/300 - Train loss: 0.6910160183906555, Validation loss: 0.6904536485671997
Epoch: 9/300 - Train loss: 0.6889633536338806, Validation loss: 0.6882879137992859
Epoch: 10/300 - Train loss: 0.6867926716804504, Validation loss: 0.6860496401786804
Epoch: 11/300 - Train loss: 0.684493362903595, Validation loss: 0.6835579872131348
Epoch: 12/300 - Train loss: 0.6820521950721741, Validation loss: 0.6809879541397095
Epoch: 13/300 - Train loss: 0.6794629693031311, Validation loss: 0.6783434748649597
Epoch: 14/300 - Train loss: 0.6767197251319885, Validation loss: 0.6753911375999451
Epoch: 15/300 - Train loss: 0.6738208532333374, Validation loss: 0.6723774075508118
Epoch: 16/300 - Train loss: 0.6707631349563599, Validation loss: 0.6691538691520691
Epoch: 17/300 - Train loss: 0.6675453186035156, Validation loss: 0.6657861471176147
Epoch: 18/300 - Train loss: 0.6641654372215271, Validation loss: 0.6623326539993286
Epoch: 19/300 - Train loss: 0.6606324911117554, Validation loss: 0.6586990356445312
Epoch: 20/300 - Train loss: 0.656951367855072, Validation loss: 0.65474534034729
Epoch: 21/300 - Train loss: 0.6531245708465576, Validation loss: 0.6509380340576172
Epoch: 22/300 - Train loss: 0.649154782295227, Validation loss: 0.6467320919036865
Epoch: 23/300 - Train loss: 0.6450459361076355, Validation loss: 0.642562210559845
Epoch: 24/300 - Train loss: 0.6408063769340515, Validation loss: 0.6382608413696289
Epoch: 25/300 - Train loss: 0.6364421248435974, Validation loss: 0.6337486505508423
Epoch: 26/300 - Train loss: 0.6319549083709717, Validation loss: 0.6291972398757935
Epoch: 27/300 - Train loss: 0.6273593902587891, Validation loss: 0.6245719194412231
Epoch: 28/300 - Train loss: 0.6226651668548584, Validation loss: 0.6197788119316101
Epoch: 29/300 - Train loss: 0.6178754568099976, Validation loss: 0.6149638891220093
Epoch: 30/300 - Train loss: 0.6129997968673706, Validation loss: 0.6100971698760986
Epoch: 31/300 - Train loss: 0.6080508232116699, Validation loss: 0.6050739288330078
Epoch: 32/300 - Train loss: 0.6030363440513611, Validation loss: 0.6002079248428345
Epoch: 33/300 - Train loss: 0.5979653596878052, Validation loss: 0.5949390530586243
Epoch: 34/300 - Train loss: 0.592847466468811, Validation loss: 0.5899025201797485
Epoch: 35/300 - Train loss: 0.5876901745796204, Validation loss: 0.58477383852005
Epoch: 36/300 - Train loss: 0.5825052857398987, Validation loss: 0.579715371131897
Epoch: 37/300 - Train loss: 0.577297568321228, Validation loss: 0.5746485590934753
Epoch: 38/300 - Train loss: 0.5720798373222351, Validation loss: 0.5693449378013611
Epoch: 39/300 - Train loss: 0.56685471534729, Validation loss: 0.5641770362854004
Epoch: 40/300 - Train loss: 0.5616317987442017, Validation loss: 0.5590071678161621
Epoch: 41/300 - Train loss: 0.5564199686050415, Validation loss: 0.5538333058357239
Epoch: 42/300 - Train loss: 0.5512259602546692, Validation loss: 0.5490330457687378
Epoch: 43/300 - Train loss: 0.5460563898086548, Validation loss: 0.5437126159667969
Epoch: 44/300 - Train loss: 0.5409164428710938, Validation loss: 0.5386659502983093
Epoch: 45/300 - Train loss: 0.5358133316040039, Validation loss: 0.5336296558380127
Epoch: 46/300 - Train loss: 0.5307535529136658, Validation loss: 0.5288506746292114
Epoch: 47/300 - Train loss: 0.5257417559623718, Validation loss: 0.5238060355186462
Epoch: 48/300 - Train loss: 0.5207836627960205, Validation loss: 0.5187779068946838
Epoch: 49/300 - Train loss: 0.51588374376297, Validation loss: 0.5139949321746826
Epoch: 50/300 - Train loss: 0.5110455751419067, Validation loss: 0.5092642307281494
Epoch: 51/300 - Train loss: 0.5062728524208069, Validation loss: 0.5045639872550964
Epoch: 52/300 - Train loss: 0.5015676617622375, Validation loss: 0.5000446438789368
Epoch: 53/300 - Train loss: 0.49693402647972107, Validation loss: 0.4957519769668579
Epoch: 54/300 - Train loss: 0.4923737347126007, Validation loss: 0.49120086431503296
Epoch: 55/300 - Train loss: 0.48788928985595703, Validation loss: 0.48654910922050476
Epoch: 56/300 - Train loss: 0.483482301235199, Validation loss: 0.48246803879737854
Epoch: 57/300 - Train loss: 0.47915446758270264, Validation loss: 0.4781270921230316
Epoch: 58/300 - Train loss: 0.4749073088169098, Validation loss: 0.47426334023475647
Epoch: 59/300 - Train loss: 0.4707426130771637, Validation loss: 0.4697381854057312
Epoch: 60/300 - Train loss: 0.466661274433136, Validation loss: 0.46578481793403625
Epoch: 61/300 - Train loss: 0.46266454458236694, Validation loss: 0.46222710609436035
Epoch: 62/300 - Train loss: 0.4587537348270416, Validation loss: 0.4586271345615387
Epoch: 63/300 - Train loss: 0.45492884516716003, Validation loss: 0.45465514063835144
Epoch: 64/300 - Train loss: 0.45118919014930725, Validation loss: 0.45084360241889954
Epoch: 65/300 - Train loss: 0.44753462076187134, Validation loss: 0.4473881125450134
Epoch: 66/300 - Train loss: 0.44396477937698364, Validation loss: 0.44402432441711426
Epoch: 67/300 - Train loss: 0.4404793679714203, Validation loss: 0.4407002031803131
Epoch: 68/300 - Train loss: 0.4370770752429962, Validation loss: 0.4374040365219116
Epoch: 69/300 - Train loss: 0.43375712633132935, Validation loss: 0.4338424503803253
Epoch: 70/300 - Train loss: 0.43051937222480774, Validation loss: 0.43034419417381287
Epoch: 71/300 - Train loss: 0.4273631274700165, Validation loss: 0.42755046486854553
Epoch: 72/300 - Train loss: 0.42428627610206604, Validation loss: 0.42430272698402405
Epoch: 73/300 - Train loss: 0.4212876558303833, Validation loss: 0.4218628704547882
Epoch: 74/300 - Train loss: 0.41836655139923096, Validation loss: 0.4192304015159607
Epoch: 75/300 - Train loss: 0.41552066802978516, Validation loss: 0.41633015871047974
Epoch: 76/300 - Train loss: 0.41274887323379517, Validation loss: 0.4139832556247711
Epoch: 77/300 - Train loss: 0.4100491404533386, Validation loss: 0.41078072786331177
Epoch: 78/300 - Train loss: 0.407419890165329, Validation loss: 0.40862759947776794
Epoch: 79/300 - Train loss: 0.40485987067222595, Validation loss: 0.40559178590774536
Epoch: 80/300 - Train loss: 0.4023679196834564, Validation loss: 0.40316179394721985
Epoch: 81/300 - Train loss: 0.39994120597839355, Validation loss: 0.40078091621398926
Epoch: 82/300 - Train loss: 0.39757832884788513, Validation loss: 0.3989943265914917
Epoch: 83/300 - Train loss: 0.39527735114097595, Validation loss: 0.39660048484802246
Epoch: 84/300 - Train loss: 0.3930366635322571, Validation loss: 0.39442890882492065
Epoch: 85/300 - Train loss: 0.3908548653125763, Validation loss: 0.39197880029678345
Epoch: 86/300 - Train loss: 0.38873007893562317, Validation loss: 0.39009302854537964
Epoch: 87/300 - Train loss: 0.3866606652736664, Validation loss: 0.388248473405838
Epoch: 88/300 - Train loss: 0.38464489579200745, Validation loss: 0.38662734627723694
Epoch: 89/300 - Train loss: 0.382680743932724, Validation loss: 0.384435772895813
Epoch: 90/300 - Train loss: 0.3807668685913086, Validation loss: 0.3827580213546753
Epoch: 91/300 - Train loss: 0.3789016306400299, Validation loss: 0.38101717829704285
Epoch: 92/300 - Train loss: 0.37708336114883423, Validation loss: 0.3786501884460449
Epoch: 93/300 - Train loss: 0.37531042098999023, Validation loss: 0.37734097242355347
Epoch: 94/300 - Train loss: 0.37358108162879944, Validation loss: 0.3764036297798157
Epoch: 95/300 - Train loss: 0.3718942105770111, Validation loss: 0.3741571009159088
Epoch: 96/300 - Train loss: 0.37024810910224915, Validation loss: 0.3726423382759094
Epoch: 97/300 - Train loss: 0.3686414957046509, Validation loss: 0.37122586369514465
Epoch: 98/300 - Train loss: 0.36707308888435364, Validation loss: 0.3699372410774231
Epoch: 99/300 - Train loss: 0.36554190516471863, Validation loss: 0.36761730909347534
Epoch: 100/300 - Train loss: 0.3640463054180145, Validation loss: 0.36615118384361267
Epoch: 101/300 - Train loss: 0.36258551478385925, Validation loss: 0.36489808559417725
Epoch: 102/300 - Train loss: 0.3611580729484558, Validation loss: 0.3640962243080139
Epoch: 103/300 - Train loss: 0.3597625494003296, Validation loss: 0.3620755672454834
Epoch: 104/300 - Train loss: 0.3583982288837433, Validation loss: 0.3615662157535553
Epoch: 105/300 - Train loss: 0.3570641875267029, Validation loss: 0.35978925228118896
Epoch: 106/300 - Train loss: 0.3557594120502472, Validation loss: 0.35855022072792053
Epoch: 107/300 - Train loss: 0.3544829487800598, Validation loss: 0.3573916256427765
Epoch: 108/300 - Train loss: 0.3532339334487915, Validation loss: 0.35643401741981506
Epoch: 109/300 - Train loss: 0.3520117998123169, Validation loss: 0.35480180382728577
Epoch: 110/300 - Train loss: 0.3508152663707733, Validation loss: 0.35363900661468506
Epoch: 111/300 - Train loss: 0.349643737077713, Validation loss: 0.35329508781433105
Epoch: 112/300 - Train loss: 0.34849631786346436, Validation loss: 0.3512607514858246
Epoch: 113/300 - Train loss: 0.3473721742630005, Validation loss: 0.35130658745765686
Epoch: 114/300 - Train loss: 0.34627068042755127, Validation loss: 0.3492918610572815
Epoch: 115/300 - Train loss: 0.34519103169441223, Validation loss: 0.34785187244415283
Epoch: 116/300 - Train loss: 0.34413206577301025, Validation loss: 0.3481803238391876
Epoch: 117/300 - Train loss: 0.34309351444244385, Validation loss: 0.34614795446395874
Epoch: 118/300 - Train loss: 0.3420749306678772, Validation loss: 0.3457011282444
Epoch: 119/300 - Train loss: 0.3410761058330536, Validation loss: 0.34487321972846985
Epoch: 120/300 - Train loss: 0.34009596705436707, Validation loss: 0.343278169631958
Epoch: 121/300 - Train loss: 0.339134156703949, Validation loss: 0.34289535880088806
Epoch: 122/300 - Train loss: 0.33819010853767395, Validation loss: 0.3407682478427887
Epoch: 123/300 - Train loss: 0.3372631371021271, Validation loss: 0.34080174565315247
Epoch: 124/300 - Train loss: 0.3363528251647949, Validation loss: 0.3394756615161896
Epoch: 125/300 - Train loss: 0.33545830845832825, Validation loss: 0.3386811316013336
Epoch: 126/300 - Train loss: 0.33457934856414795, Validation loss: 0.3379319906234741
Epoch: 127/300 - Train loss: 0.3337151110172272, Validation loss: 0.3367765247821808
Epoch: 128/300 - Train loss: 0.3328656554222107, Validation loss: 0.3363207280635834
Epoch: 129/300 - Train loss: 0.33203038573265076, Validation loss: 0.33546027541160583
Epoch: 130/300 - Train loss: 0.33120837807655334, Validation loss: 0.33573392033576965
Epoch: 131/300 - Train loss: 0.33040013909339905, Validation loss: 0.3341901898384094
Epoch: 132/300 - Train loss: 0.32960498332977295, Validation loss: 0.33343440294265747
Epoch: 133/300 - Train loss: 0.32882222533226013, Validation loss: 0.33286252617836
Epoch: 134/300 - Train loss: 0.3280511200428009, Validation loss: 0.33138027787208557
Epoch: 135/300 - Train loss: 0.3272918462753296, Validation loss: 0.33093497157096863
Epoch: 136/300 - Train loss: 0.3265441954135895, Validation loss: 0.32975518703460693
Epoch: 137/300 - Train loss: 0.32580795884132385, Validation loss: 0.3292688727378845
Epoch: 138/300 - Train loss: 0.32508227229118347, Validation loss: 0.3288789987564087
Epoch: 139/300 - Train loss: 0.3243677020072937, Validation loss: 0.32874253392219543
Epoch: 140/300 - Train loss: 0.32366377115249634, Validation loss: 0.326991468667984
Epoch: 141/300 - Train loss: 0.32296961545944214, Validation loss: 0.32777079939842224
Epoch: 142/300 - Train loss: 0.32228460907936096, Validation loss: 0.32563647627830505
Epoch: 143/300 - Train loss: 0.32160869240760803, Validation loss: 0.3254360556602478
Epoch: 144/300 - Train loss: 0.32094231247901917, Validation loss: 0.3247692286968231
Epoch: 145/300 - Train loss: 0.3202844262123108, Validation loss: 0.32399728894233704
Epoch: 146/300 - Train loss: 0.3196350634098053, Validation loss: 0.32283690571784973
Epoch: 147/300 - Train loss: 0.31899410486221313, Validation loss: 0.3226695656776428
Epoch: 148/300 - Train loss: 0.3183608055114746, Validation loss: 0.32194072008132935
Epoch: 149/300 - Train loss: 0.3177346885204315, Validation loss: 0.32145485281944275
Epoch: 150/300 - Train loss: 0.3171157240867615, Validation loss: 0.32156893610954285
Epoch: 151/300 - Train loss: 0.31650400161743164, Validation loss: 0.3201591670513153
Epoch: 152/300 - Train loss: 0.31589987874031067, Validation loss: 0.31962892413139343
Epoch: 153/300 - Train loss: 0.3153027594089508, Validation loss: 0.31949520111083984
Epoch: 154/300 - Train loss: 0.3147117793560028, Validation loss: 0.3189427852630615
Epoch: 155/300 - Train loss: 0.314127653837204, Validation loss: 0.3182799220085144
