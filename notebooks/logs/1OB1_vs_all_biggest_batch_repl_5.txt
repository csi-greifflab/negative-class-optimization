Epoch: 1/300 - Train loss: 0.699347734451294, Validation loss: 0.6970921754837036
Epoch: 2/300 - Train loss: 0.6961392760276794, Validation loss: 0.6939599514007568
Epoch: 3/300 - Train loss: 0.6929958462715149, Validation loss: 0.6906403303146362
Epoch: 4/300 - Train loss: 0.6898669600486755, Validation loss: 0.6876660585403442
Epoch: 5/300 - Train loss: 0.6867196559906006, Validation loss: 0.6844215989112854
Epoch: 6/300 - Train loss: 0.6835275292396545, Validation loss: 0.6811878085136414
Epoch: 7/300 - Train loss: 0.6802712678909302, Validation loss: 0.677821159362793
Epoch: 8/300 - Train loss: 0.6769223809242249, Validation loss: 0.674355685710907
Epoch: 9/300 - Train loss: 0.6734586358070374, Validation loss: 0.6708241701126099
Epoch: 10/300 - Train loss: 0.6698738932609558, Validation loss: 0.6670709252357483
Epoch: 11/300 - Train loss: 0.6661614179611206, Validation loss: 0.6633648872375488
Epoch: 12/300 - Train loss: 0.662316083908081, Validation loss: 0.6591387987136841
Epoch: 13/300 - Train loss: 0.6583520770072937, Validation loss: 0.6551477313041687
Epoch: 14/300 - Train loss: 0.6542752385139465, Validation loss: 0.6509264707565308
Epoch: 15/300 - Train loss: 0.6500959992408752, Validation loss: 0.6467307209968567
Epoch: 16/300 - Train loss: 0.645827054977417, Validation loss: 0.6422961354255676
Epoch: 17/300 - Train loss: 0.6414823532104492, Validation loss: 0.6378048062324524
Epoch: 18/300 - Train loss: 0.6370763182640076, Validation loss: 0.6331020593643188
Epoch: 19/300 - Train loss: 0.632625162601471, Validation loss: 0.6286237835884094
Epoch: 20/300 - Train loss: 0.6281391382217407, Validation loss: 0.6240127086639404
Epoch: 21/300 - Train loss: 0.6236311793327332, Validation loss: 0.6195715069770813
Epoch: 22/300 - Train loss: 0.6191131472587585, Validation loss: 0.6150321364402771
Epoch: 23/300 - Train loss: 0.6145947575569153, Validation loss: 0.6104354858398438
Epoch: 24/300 - Train loss: 0.6100846529006958, Validation loss: 0.605724036693573
Epoch: 25/300 - Train loss: 0.6055881977081299, Validation loss: 0.6012346148490906
Epoch: 26/300 - Train loss: 0.6011103987693787, Validation loss: 0.5968269109725952
Epoch: 27/300 - Train loss: 0.5966565012931824, Validation loss: 0.591958224773407
Epoch: 28/300 - Train loss: 0.5922300815582275, Validation loss: 0.5877583026885986
Epoch: 29/300 - Train loss: 0.5878338813781738, Validation loss: 0.5832245349884033
Epoch: 30/300 - Train loss: 0.5834686756134033, Validation loss: 0.578460693359375
Epoch: 31/300 - Train loss: 0.5791372060775757, Validation loss: 0.5742319822311401
Epoch: 32/300 - Train loss: 0.5748421549797058, Validation loss: 0.5697469115257263
Epoch: 33/300 - Train loss: 0.5705828666687012, Validation loss: 0.5653051733970642
Epoch: 34/300 - Train loss: 0.5663614869117737, Validation loss: 0.5609833598136902
Epoch: 35/300 - Train loss: 0.5621774196624756, Validation loss: 0.556770920753479
Epoch: 36/300 - Train loss: 0.5580322742462158, Validation loss: 0.5526350736618042
Epoch: 37/300 - Train loss: 0.553928017616272, Validation loss: 0.5486517548561096
Epoch: 38/300 - Train loss: 0.5498653650283813, Validation loss: 0.5442394018173218
Epoch: 39/300 - Train loss: 0.5458437204360962, Validation loss: 0.5404189229011536
Epoch: 40/300 - Train loss: 0.5418632626533508, Validation loss: 0.5361869931221008
Epoch: 41/300 - Train loss: 0.5379242897033691, Validation loss: 0.5321021676063538
Epoch: 42/300 - Train loss: 0.534026563167572, Validation loss: 0.5278286337852478
Epoch: 43/300 - Train loss: 0.5301715135574341, Validation loss: 0.5239636898040771
Epoch: 44/300 - Train loss: 0.5263586640357971, Validation loss: 0.5205244421958923
Epoch: 45/300 - Train loss: 0.5225871801376343, Validation loss: 0.5161197185516357
Epoch: 46/300 - Train loss: 0.5188572406768799, Validation loss: 0.5125438570976257
Epoch: 47/300 - Train loss: 0.5151681303977966, Validation loss: 0.5087014436721802
Epoch: 48/300 - Train loss: 0.51152104139328, Validation loss: 0.5048143863677979
Epoch: 49/300 - Train loss: 0.507915735244751, Validation loss: 0.5012160539627075
Epoch: 50/300 - Train loss: 0.5043513774871826, Validation loss: 0.4980755150318146
Epoch: 51/300 - Train loss: 0.500827968120575, Validation loss: 0.4936875104904175
Epoch: 52/300 - Train loss: 0.4973452389240265, Validation loss: 0.49021807312965393
Epoch: 53/300 - Train loss: 0.4939032196998596, Validation loss: 0.4867788553237915
Epoch: 54/300 - Train loss: 0.4905032515525818, Validation loss: 0.4831390380859375
Epoch: 55/300 - Train loss: 0.48714515566825867, Validation loss: 0.4797506332397461
Epoch: 56/300 - Train loss: 0.48382899165153503, Validation loss: 0.47625622153282166
Epoch: 57/300 - Train loss: 0.4805539548397064, Validation loss: 0.47267410159111023
Epoch: 58/300 - Train loss: 0.4773208796977997, Validation loss: 0.4694371521472931
Epoch: 59/300 - Train loss: 0.47413164377212524, Validation loss: 0.4661697745323181
Epoch: 60/300 - Train loss: 0.47098639607429504, Validation loss: 0.4629926085472107
Epoch: 61/300 - Train loss: 0.4678858518600464, Validation loss: 0.46005284786224365
Epoch: 62/300 - Train loss: 0.4648296535015106, Validation loss: 0.4569208025932312
Epoch: 63/300 - Train loss: 0.46181854605674744, Validation loss: 0.4536116421222687
Epoch: 64/300 - Train loss: 0.4588524401187897, Validation loss: 0.4505459666252136
Epoch: 65/300 - Train loss: 0.45593181252479553, Validation loss: 0.4471425414085388
Epoch: 66/300 - Train loss: 0.45305687189102173, Validation loss: 0.4446996748447418
Epoch: 67/300 - Train loss: 0.4502280652523041, Validation loss: 0.44162315130233765
Epoch: 68/300 - Train loss: 0.44744575023651123, Validation loss: 0.4391806423664093
Epoch: 69/300 - Train loss: 0.44471004605293274, Validation loss: 0.4356756806373596
Epoch: 70/300 - Train loss: 0.44202083349227905, Validation loss: 0.43339183926582336
Epoch: 71/300 - Train loss: 0.43937867879867554, Validation loss: 0.43013012409210205
Epoch: 72/300 - Train loss: 0.4367828667163849, Validation loss: 0.42823266983032227
Epoch: 73/300 - Train loss: 0.43423423171043396, Validation loss: 0.42491626739501953
Epoch: 74/300 - Train loss: 0.4317326843738556, Validation loss: 0.4229692220687866
Epoch: 75/300 - Train loss: 0.42927873134613037, Validation loss: 0.4203075170516968
Epoch: 76/300 - Train loss: 0.4268718659877777, Validation loss: 0.4174354374408722
Epoch: 77/300 - Train loss: 0.4245118796825409, Validation loss: 0.41519299149513245
Epoch: 78/300 - Train loss: 0.4221988320350647, Validation loss: 0.4132084250450134
Epoch: 79/300 - Train loss: 0.4199323058128357, Validation loss: 0.41078299283981323
Epoch: 80/300 - Train loss: 0.41771218180656433, Validation loss: 0.4088556170463562
Epoch: 81/300 - Train loss: 0.4155382513999939, Validation loss: 0.4058919847011566
Epoch: 82/300 - Train loss: 0.4134105145931244, Validation loss: 0.4041745960712433
Epoch: 83/300 - Train loss: 0.4113287329673767, Validation loss: 0.40187281370162964
Epoch: 84/300 - Train loss: 0.40929216146469116, Validation loss: 0.39912742376327515
Epoch: 85/300 - Train loss: 0.407300740480423, Validation loss: 0.39738914370536804
Epoch: 86/300 - Train loss: 0.4053538739681244, Validation loss: 0.3954182267189026
Epoch: 87/300 - Train loss: 0.40345102548599243, Validation loss: 0.3938654065132141
Epoch: 88/300 - Train loss: 0.4015917479991913, Validation loss: 0.39092743396759033
Epoch: 89/300 - Train loss: 0.3997754752635956, Validation loss: 0.3901258409023285
Epoch: 90/300 - Train loss: 0.39800140261650085, Validation loss: 0.3881136476993561
Epoch: 91/300 - Train loss: 0.39626917243003845, Validation loss: 0.3861252963542938
Epoch: 92/300 - Train loss: 0.39457815885543823, Validation loss: 0.3842889666557312
Epoch: 93/300 - Train loss: 0.3929276168346405, Validation loss: 0.3828273415565491
Epoch: 94/300 - Train loss: 0.39131709933280945, Validation loss: 0.38068458437919617
Epoch: 95/300 - Train loss: 0.3897458016872406, Validation loss: 0.3791170120239258
Epoch: 96/300 - Train loss: 0.38821324706077576, Validation loss: 0.3784785866737366
Epoch: 97/300 - Train loss: 0.38671860098838806, Validation loss: 0.37626275420188904
Epoch: 98/300 - Train loss: 0.385261207818985, Validation loss: 0.37445545196533203
Epoch: 99/300 - Train loss: 0.3838404417037964, Validation loss: 0.37306007742881775
Epoch: 100/300 - Train loss: 0.38245540857315063, Validation loss: 0.37183600664138794
Epoch: 101/300 - Train loss: 0.3811056315898895, Validation loss: 0.3703736364841461
Epoch: 102/300 - Train loss: 0.37979018688201904, Validation loss: 0.3692459464073181
Epoch: 103/300 - Train loss: 0.37850865721702576, Validation loss: 0.3679637610912323
Epoch: 104/300 - Train loss: 0.37726032733917236, Validation loss: 0.36621975898742676
Epoch: 105/300 - Train loss: 0.37604448199272156, Validation loss: 0.36469751596450806
Epoch: 106/300 - Train loss: 0.37486061453819275, Validation loss: 0.3641790449619293
Epoch: 107/300 - Train loss: 0.3737078607082367, Validation loss: 0.362666517496109
Epoch: 108/300 - Train loss: 0.372585654258728, Validation loss: 0.3617541193962097
Epoch: 109/300 - Train loss: 0.3714931905269623, Validation loss: 0.36036622524261475
Epoch: 110/300 - Train loss: 0.3704298436641693, Validation loss: 0.35962486267089844
Epoch: 111/300 - Train loss: 0.3693949580192566, Validation loss: 0.3579767048358917
Epoch: 112/300 - Train loss: 0.3683878779411316, Validation loss: 0.3575217127799988
Epoch: 113/300 - Train loss: 0.36740782856941223, Validation loss: 0.3559074401855469
Epoch: 114/300 - Train loss: 0.36645427346229553, Validation loss: 0.3552142083644867
Epoch: 115/300 - Train loss: 0.3655264675617218, Validation loss: 0.3534362316131592
Epoch: 116/300 - Train loss: 0.36462393403053284, Validation loss: 0.3538009524345398
Epoch: 117/300 - Train loss: 0.36374595761299133, Validation loss: 0.35195115208625793
Epoch: 118/300 - Train loss: 0.362892210483551, Validation loss: 0.3511631488800049
Epoch: 119/300 - Train loss: 0.36206185817718506, Validation loss: 0.3511841893196106
Epoch: 120/300 - Train loss: 0.36125436425209045, Validation loss: 0.349650114774704
Epoch: 121/300 - Train loss: 0.3604690730571747, Validation loss: 0.34865137934684753
Epoch: 122/300 - Train loss: 0.35970538854599, Validation loss: 0.34804701805114746
Epoch: 123/300 - Train loss: 0.3589627742767334, Validation loss: 0.34754523634910583
Epoch: 124/300 - Train loss: 0.35824069380760193, Validation loss: 0.34598782658576965
Epoch: 125/300 - Train loss: 0.35753849148750305, Validation loss: 0.3456937074661255
Epoch: 126/300 - Train loss: 0.3568557798862457, Validation loss: 0.3450521230697632
Epoch: 127/300 - Train loss: 0.35619211196899414, Validation loss: 0.3439365327358246
Epoch: 128/300 - Train loss: 0.35554683208465576, Validation loss: 0.3431493639945984
Epoch: 129/300 - Train loss: 0.3549196422100067, Validation loss: 0.3427995443344116
Epoch: 130/300 - Train loss: 0.35430994629859924, Validation loss: 0.3419564962387085
Epoch: 131/300 - Train loss: 0.35371723771095276, Validation loss: 0.341578871011734
Epoch: 132/300 - Train loss: 0.35314109921455383, Validation loss: 0.3413749933242798
Epoch: 133/300 - Train loss: 0.3525809347629547, Validation loss: 0.3405725061893463
Epoch: 134/300 - Train loss: 0.35203632712364197, Validation loss: 0.33941811323165894
Epoch: 135/300 - Train loss: 0.3515069782733917, Validation loss: 0.3390045166015625
Epoch: 136/300 - Train loss: 0.3509923815727234, Validation loss: 0.3384097218513489
Epoch: 137/300 - Train loss: 0.35049208998680115, Validation loss: 0.3377761244773865
Epoch: 138/300 - Train loss: 0.3500056266784668, Validation loss: 0.33724087476730347
Epoch: 139/300 - Train loss: 0.3495326340198517, Validation loss: 0.33718615770339966
