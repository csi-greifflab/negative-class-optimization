Epoch: 1/300 - Train loss: 0.7036554217338562, Validation loss: 0.7019054889678955
Epoch: 2/300 - Train loss: 0.7008429765701294, Validation loss: 0.6990708708763123
Epoch: 3/300 - Train loss: 0.6980617046356201, Validation loss: 0.6963843703269958
Epoch: 4/300 - Train loss: 0.6952990889549255, Validation loss: 0.6936498284339905
Epoch: 5/300 - Train loss: 0.6925380229949951, Validation loss: 0.6908248066902161
Epoch: 6/300 - Train loss: 0.6897676587104797, Validation loss: 0.6881364583969116
Epoch: 7/300 - Train loss: 0.6869745850563049, Validation loss: 0.6853548884391785
Epoch: 8/300 - Train loss: 0.6841478943824768, Validation loss: 0.6824595332145691
Epoch: 9/300 - Train loss: 0.6812804341316223, Validation loss: 0.6795589327812195
Epoch: 10/300 - Train loss: 0.678362250328064, Validation loss: 0.6764808893203735
Epoch: 11/300 - Train loss: 0.6753866672515869, Validation loss: 0.6734519600868225
Epoch: 12/300 - Train loss: 0.6723491549491882, Validation loss: 0.6703671813011169
Epoch: 13/300 - Train loss: 0.6692478656768799, Validation loss: 0.6673166751861572
Epoch: 14/300 - Train loss: 0.6660743355751038, Validation loss: 0.6638393998146057
Epoch: 15/300 - Train loss: 0.66282719373703, Validation loss: 0.6607972979545593
Epoch: 16/300 - Train loss: 0.6595125794410706, Validation loss: 0.6572257280349731
Epoch: 17/300 - Train loss: 0.6561310291290283, Validation loss: 0.6537908315658569
Epoch: 18/300 - Train loss: 0.6526868939399719, Validation loss: 0.64997798204422
Epoch: 19/300 - Train loss: 0.6491782665252686, Validation loss: 0.6467911601066589
Epoch: 20/300 - Train loss: 0.6456130146980286, Validation loss: 0.6430014371871948
Epoch: 21/300 - Train loss: 0.6419990658760071, Validation loss: 0.639310896396637
Epoch: 22/300 - Train loss: 0.6383371949195862, Validation loss: 0.6357981562614441
Epoch: 23/300 - Train loss: 0.6346375942230225, Validation loss: 0.6319343447685242
Epoch: 24/300 - Train loss: 0.6309109926223755, Validation loss: 0.6281647682189941
Epoch: 25/300 - Train loss: 0.627163290977478, Validation loss: 0.6240155696868896
Epoch: 26/300 - Train loss: 0.6234027147293091, Validation loss: 0.6208164691925049
Epoch: 27/300 - Train loss: 0.6196334362030029, Validation loss: 0.6166608333587646
Epoch: 28/300 - Train loss: 0.6158596873283386, Validation loss: 0.6130229830741882
Epoch: 29/300 - Train loss: 0.6120831966400146, Validation loss: 0.6090785264968872
Epoch: 30/300 - Train loss: 0.6083114743232727, Validation loss: 0.6048654317855835
Epoch: 31/300 - Train loss: 0.604550302028656, Validation loss: 0.6014139652252197
Epoch: 32/300 - Train loss: 0.6008030772209167, Validation loss: 0.5973326563835144
Epoch: 33/300 - Train loss: 0.5970737934112549, Validation loss: 0.5940708518028259
Epoch: 34/300 - Train loss: 0.5933651328086853, Validation loss: 0.5900936722755432
Epoch: 35/300 - Train loss: 0.5896757245063782, Validation loss: 0.586364209651947
Epoch: 36/300 - Train loss: 0.5860130190849304, Validation loss: 0.5826781392097473
Epoch: 37/300 - Train loss: 0.5823803544044495, Validation loss: 0.5790048241615295
Epoch: 38/300 - Train loss: 0.5787805318832397, Validation loss: 0.5752642154693604
Epoch: 39/300 - Train loss: 0.5752149224281311, Validation loss: 0.5716356039047241
Epoch: 40/300 - Train loss: 0.5716857314109802, Validation loss: 0.5679336190223694
Epoch: 41/300 - Train loss: 0.5681962966918945, Validation loss: 0.564141571521759
Epoch: 42/300 - Train loss: 0.564747154712677, Validation loss: 0.561420202255249
Epoch: 43/300 - Train loss: 0.5613368153572083, Validation loss: 0.557982861995697
Epoch: 44/300 - Train loss: 0.5579695701599121, Validation loss: 0.5549817085266113
Epoch: 45/300 - Train loss: 0.5546470880508423, Validation loss: 0.5512735843658447
Epoch: 46/300 - Train loss: 0.5513693690299988, Validation loss: 0.5481227040290833
Epoch: 47/300 - Train loss: 0.548136293888092, Validation loss: 0.5446426272392273
Epoch: 48/300 - Train loss: 0.5449479222297668, Validation loss: 0.5415564179420471
Epoch: 49/300 - Train loss: 0.5418063402175903, Validation loss: 0.5380650162696838
Epoch: 50/300 - Train loss: 0.5387120842933655, Validation loss: 0.5347666144371033
Epoch: 51/300 - Train loss: 0.5356653332710266, Validation loss: 0.5327027440071106
Epoch: 52/300 - Train loss: 0.5326657295227051, Validation loss: 0.5295149683952332
Epoch: 53/300 - Train loss: 0.5297130346298218, Validation loss: 0.5262094736099243
Epoch: 54/300 - Train loss: 0.5268068909645081, Validation loss: 0.5228807926177979
Epoch: 55/300 - Train loss: 0.5239475965499878, Validation loss: 0.5213667750358582
Epoch: 56/300 - Train loss: 0.5211353302001953, Validation loss: 0.5179409384727478
Epoch: 57/300 - Train loss: 0.518369734287262, Validation loss: 0.5147555470466614
Epoch: 58/300 - Train loss: 0.5156521797180176, Validation loss: 0.5131471753120422
Epoch: 59/300 - Train loss: 0.5129826068878174, Validation loss: 0.5089596509933472
Epoch: 60/300 - Train loss: 0.5103599429130554, Validation loss: 0.5077947974205017
Epoch: 61/300 - Train loss: 0.5077834129333496, Validation loss: 0.5045057535171509
Epoch: 62/300 - Train loss: 0.5052529573440552, Validation loss: 0.5024423599243164
Epoch: 63/300 - Train loss: 0.5027686953544617, Validation loss: 0.49921298027038574
Epoch: 64/300 - Train loss: 0.5003301501274109, Validation loss: 0.4974146783351898
Epoch: 65/300 - Train loss: 0.49793657660484314, Validation loss: 0.4948250353336334
Epoch: 66/300 - Train loss: 0.4955871105194092, Validation loss: 0.4929157495498657
Epoch: 67/300 - Train loss: 0.4932803809642792, Validation loss: 0.4912652373313904
Epoch: 68/300 - Train loss: 0.491014689207077, Validation loss: 0.4886912405490875
Epoch: 69/300 - Train loss: 0.48879027366638184, Validation loss: 0.4867604374885559
Epoch: 70/300 - Train loss: 0.48660701513290405, Validation loss: 0.4839193820953369
Epoch: 71/300 - Train loss: 0.4844645857810974, Validation loss: 0.4810628592967987
Epoch: 72/300 - Train loss: 0.48236218094825745, Validation loss: 0.47993651032447815
Epoch: 73/300 - Train loss: 0.48029884696006775, Validation loss: 0.47706592082977295
Epoch: 74/300 - Train loss: 0.47827351093292236, Validation loss: 0.4750601351261139
Epoch: 75/300 - Train loss: 0.4762856960296631, Validation loss: 0.4738771617412567
Epoch: 76/300 - Train loss: 0.47433406114578247, Validation loss: 0.4707111120223999
Epoch: 77/300 - Train loss: 0.4724176228046417, Validation loss: 0.4699065387248993
Epoch: 78/300 - Train loss: 0.47053611278533936, Validation loss: 0.4678336977958679
Epoch: 79/300 - Train loss: 0.4686886668205261, Validation loss: 0.4670100212097168
Epoch: 80/300 - Train loss: 0.4668744206428528, Validation loss: 0.4652232825756073
Epoch: 81/300 - Train loss: 0.46509259939193726, Validation loss: 0.4628705084323883
Epoch: 82/300 - Train loss: 0.46334272623062134, Validation loss: 0.46092820167541504
Epoch: 83/300 - Train loss: 0.46162471175193787, Validation loss: 0.45893847942352295
Epoch: 84/300 - Train loss: 0.45993757247924805, Validation loss: 0.45744767785072327
Epoch: 85/300 - Train loss: 0.458281546831131, Validation loss: 0.4564286470413208
Epoch: 86/300 - Train loss: 0.4566551744937897, Validation loss: 0.45448485016822815
Epoch: 87/300 - Train loss: 0.4550582766532898, Validation loss: 0.45253628492355347
Epoch: 88/300 - Train loss: 0.453490674495697, Validation loss: 0.4525099992752075
Epoch: 89/300 - Train loss: 0.45195162296295166, Validation loss: 0.45014265179634094
Epoch: 90/300 - Train loss: 0.45044031739234924, Validation loss: 0.4490557610988617
Epoch: 91/300 - Train loss: 0.4489561915397644, Validation loss: 0.4467483460903168
Epoch: 92/300 - Train loss: 0.4474988877773285, Validation loss: 0.445819228887558
Epoch: 93/300 - Train loss: 0.446067750453949, Validation loss: 0.44319331645965576
Epoch: 94/300 - Train loss: 0.4446620047092438, Validation loss: 0.4431218206882477
Epoch: 95/300 - Train loss: 0.4432808458805084, Validation loss: 0.44082212448120117
Epoch: 96/300 - Train loss: 0.44192376732826233, Validation loss: 0.4397890865802765
Epoch: 97/300 - Train loss: 0.44059035181999207, Validation loss: 0.4383935332298279
Epoch: 98/300 - Train loss: 0.4392804503440857, Validation loss: 0.4374183416366577
Epoch: 99/300 - Train loss: 0.43799325823783875, Validation loss: 0.4360958933830261
Epoch: 100/300 - Train loss: 0.43672817945480347, Validation loss: 0.43449321389198303
Epoch: 101/300 - Train loss: 0.4354851543903351, Validation loss: 0.43352416157722473
Epoch: 102/300 - Train loss: 0.43426334857940674, Validation loss: 0.43228188157081604
Epoch: 103/300 - Train loss: 0.43306249380111694, Validation loss: 0.43215590715408325
Epoch: 104/300 - Train loss: 0.4318819046020508, Validation loss: 0.43014538288116455
Epoch: 105/300 - Train loss: 0.4307211637496948, Validation loss: 0.4283214211463928
Epoch: 106/300 - Train loss: 0.4295800030231476, Validation loss: 0.4270080327987671
Epoch: 107/300 - Train loss: 0.4284578263759613, Validation loss: 0.4267600476741791
Epoch: 108/300 - Train loss: 0.42735427618026733, Validation loss: 0.4248366057872772
Epoch: 109/300 - Train loss: 0.42626917362213135, Validation loss: 0.4242408871650696
Epoch: 110/300 - Train loss: 0.4252018928527832, Validation loss: 0.4226558804512024
Epoch: 111/300 - Train loss: 0.42415210604667664, Validation loss: 0.42183762788772583
Epoch: 112/300 - Train loss: 0.4231192171573639, Validation loss: 0.42045673727989197
Epoch: 113/300 - Train loss: 0.42210307717323303, Validation loss: 0.4196212589740753
Epoch: 114/300 - Train loss: 0.42110365629196167, Validation loss: 0.4188876152038574
Epoch: 115/300 - Train loss: 0.4201200604438782, Validation loss: 0.41822177171707153
Epoch: 116/300 - Train loss: 0.41915246844291687, Validation loss: 0.41763269901275635
Epoch: 117/300 - Train loss: 0.4182003140449524, Validation loss: 0.4154990613460541
Epoch: 118/300 - Train loss: 0.41726329922676086, Validation loss: 0.4156038165092468
Epoch: 119/300 - Train loss: 0.41634097695350647, Validation loss: 0.4131421446800232
Epoch: 120/300 - Train loss: 0.4154329001903534, Validation loss: 0.41377854347229004
Epoch: 121/300 - Train loss: 0.4145386815071106, Validation loss: 0.4126339256763458
Epoch: 122/300 - Train loss: 0.41365864872932434, Validation loss: 0.4119979739189148
Epoch: 123/300 - Train loss: 0.41279199719429016, Validation loss: 0.4104880094528198
Epoch: 124/300 - Train loss: 0.4119386672973633, Validation loss: 0.4099423289299011
Epoch: 125/300 - Train loss: 0.41109833121299744, Validation loss: 0.40976282954216003
Epoch: 126/300 - Train loss: 0.410271018743515, Validation loss: 0.4082304537296295
Epoch: 127/300 - Train loss: 0.4094561040401459, Validation loss: 0.40743395686149597
Epoch: 128/300 - Train loss: 0.40865349769592285, Validation loss: 0.4060065746307373
Epoch: 129/300 - Train loss: 0.40786272287368774, Validation loss: 0.4056224226951599
Epoch: 130/300 - Train loss: 0.40708351135253906, Validation loss: 0.4055659770965576
Epoch: 131/300 - Train loss: 0.4063158631324768, Validation loss: 0.4045943021774292
Epoch: 132/300 - Train loss: 0.40555983781814575, Validation loss: 0.4033950865268707
Epoch: 133/300 - Train loss: 0.40481477975845337, Validation loss: 0.40328502655029297
Epoch: 134/300 - Train loss: 0.40408003330230713, Validation loss: 0.40160083770751953
Epoch: 135/300 - Train loss: 0.4033556580543518, Validation loss: 0.4011951684951782
Epoch: 136/300 - Train loss: 0.40264129638671875, Validation loss: 0.4000779092311859
Epoch: 137/300 - Train loss: 0.40193691849708557, Validation loss: 0.3996566832065582
Epoch: 138/300 - Train loss: 0.4012422561645508, Validation loss: 0.3988439738750458
Epoch: 139/300 - Train loss: 0.40055689215660095, Validation loss: 0.39937475323677063
Epoch: 140/300 - Train loss: 0.3998810350894928, Validation loss: 0.3974173963069916
Epoch: 141/300 - Train loss: 0.39921441674232483, Validation loss: 0.39760446548461914
Epoch: 142/300 - Train loss: 0.39855703711509705, Validation loss: 0.39544275403022766
Epoch: 143/300 - Train loss: 0.397908478975296, Validation loss: 0.3963799774646759
Epoch: 144/300 - Train loss: 0.39726874232292175, Validation loss: 0.39517703652381897
Epoch: 145/300 - Train loss: 0.3966377079486847, Validation loss: 0.3947477638721466
Epoch: 146/300 - Train loss: 0.39601510763168335, Validation loss: 0.395587682723999
