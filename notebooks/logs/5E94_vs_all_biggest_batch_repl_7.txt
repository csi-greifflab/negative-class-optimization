Epoch: 1/300 - Train loss: 0.7126960754394531, Validation loss: 0.7107478976249695
Epoch: 2/300 - Train loss: 0.7094630599021912, Validation loss: 0.7078284621238708
Epoch: 3/300 - Train loss: 0.7064589858055115, Validation loss: 0.7045930624008179
Epoch: 4/300 - Train loss: 0.7036473751068115, Validation loss: 0.7023259997367859
Epoch: 5/300 - Train loss: 0.7009755373001099, Validation loss: 0.6997590065002441
Epoch: 6/300 - Train loss: 0.6983890533447266, Validation loss: 0.6971516609191895
Epoch: 7/300 - Train loss: 0.6958446502685547, Validation loss: 0.694181501865387
Epoch: 8/300 - Train loss: 0.6933048367500305, Validation loss: 0.691864550113678
Epoch: 9/300 - Train loss: 0.6907291412353516, Validation loss: 0.6892213225364685
Epoch: 10/300 - Train loss: 0.6880953311920166, Validation loss: 0.6864116191864014
Epoch: 11/300 - Train loss: 0.6853799223899841, Validation loss: 0.6836592555046082
Epoch: 12/300 - Train loss: 0.6825730204582214, Validation loss: 0.6807411909103394
Epoch: 13/300 - Train loss: 0.6796724200248718, Validation loss: 0.6777148842811584
Epoch: 14/300 - Train loss: 0.6766718626022339, Validation loss: 0.6749495267868042
Epoch: 15/300 - Train loss: 0.6735753417015076, Validation loss: 0.6713210940361023
Epoch: 16/300 - Train loss: 0.6703854203224182, Validation loss: 0.6683359742164612
Epoch: 17/300 - Train loss: 0.6671076416969299, Validation loss: 0.66493821144104
Epoch: 18/300 - Train loss: 0.6637514233589172, Validation loss: 0.6614519357681274
Epoch: 19/300 - Train loss: 0.6603241562843323, Validation loss: 0.6578259468078613
Epoch: 20/300 - Train loss: 0.6568361520767212, Validation loss: 0.6541785001754761
Epoch: 21/300 - Train loss: 0.6532921195030212, Validation loss: 0.6507503390312195
Epoch: 22/300 - Train loss: 0.6496974229812622, Validation loss: 0.6471202373504639
Epoch: 23/300 - Train loss: 0.6460615992546082, Validation loss: 0.6434074640274048
Epoch: 24/300 - Train loss: 0.6423932313919067, Validation loss: 0.639695405960083
Epoch: 25/300 - Train loss: 0.6386980414390564, Validation loss: 0.6358832120895386
Epoch: 26/300 - Train loss: 0.6349775791168213, Validation loss: 0.6321774125099182
Epoch: 27/300 - Train loss: 0.6312379837036133, Validation loss: 0.6282299757003784
Epoch: 28/300 - Train loss: 0.6274845600128174, Validation loss: 0.6247780919075012
Epoch: 29/300 - Train loss: 0.6237193942070007, Validation loss: 0.6208319664001465
Epoch: 30/300 - Train loss: 0.619947075843811, Validation loss: 0.617435872554779
Epoch: 31/300 - Train loss: 0.6161713600158691, Validation loss: 0.6135915517807007
Epoch: 32/300 - Train loss: 0.6123965382575989, Validation loss: 0.6097409129142761
Epoch: 33/300 - Train loss: 0.6086255311965942, Validation loss: 0.6055665016174316
Epoch: 34/300 - Train loss: 0.6048614978790283, Validation loss: 0.6020431518554688
Epoch: 35/300 - Train loss: 0.6011066436767578, Validation loss: 0.5986113548278809
Epoch: 36/300 - Train loss: 0.5973621010780334, Validation loss: 0.5951660871505737
Epoch: 37/300 - Train loss: 0.5936312675476074, Validation loss: 0.5911961197853088
Epoch: 38/300 - Train loss: 0.589917778968811, Validation loss: 0.5875589847564697
Epoch: 39/300 - Train loss: 0.5862255096435547, Validation loss: 0.5838602781295776
Epoch: 40/300 - Train loss: 0.5825572609901428, Validation loss: 0.5798878073692322
Epoch: 41/300 - Train loss: 0.5789160132408142, Validation loss: 0.5764297246932983
Epoch: 42/300 - Train loss: 0.575305163860321, Validation loss: 0.5724639892578125
Epoch: 43/300 - Train loss: 0.5717278718948364, Validation loss: 0.56926029920578
Epoch: 44/300 - Train loss: 0.5681857466697693, Validation loss: 0.5661426186561584
Epoch: 45/300 - Train loss: 0.5646806359291077, Validation loss: 0.5621768236160278
Epoch: 46/300 - Train loss: 0.5612139701843262, Validation loss: 0.5593854188919067
Epoch: 47/300 - Train loss: 0.5577862858772278, Validation loss: 0.5556102395057678
Epoch: 48/300 - Train loss: 0.5543988943099976, Validation loss: 0.5519888401031494
Epoch: 49/300 - Train loss: 0.5510516166687012, Validation loss: 0.5485897660255432
Epoch: 50/300 - Train loss: 0.547745406627655, Validation loss: 0.5452576279640198
Epoch: 51/300 - Train loss: 0.544480562210083, Validation loss: 0.541617751121521
Epoch: 52/300 - Train loss: 0.5412564277648926, Validation loss: 0.5392017960548401
Epoch: 53/300 - Train loss: 0.5380740165710449, Validation loss: 0.5357840061187744
Epoch: 54/300 - Train loss: 0.5349346995353699, Validation loss: 0.5321767330169678
Epoch: 55/300 - Train loss: 0.5318372845649719, Validation loss: 0.5289290547370911
Epoch: 56/300 - Train loss: 0.5287831425666809, Validation loss: 0.5262330174446106
Epoch: 57/300 - Train loss: 0.5257704257965088, Validation loss: 0.5229880213737488
Epoch: 58/300 - Train loss: 0.5227986574172974, Validation loss: 0.5206484794616699
Epoch: 59/300 - Train loss: 0.5198652744293213, Validation loss: 0.5172258615493774
Epoch: 60/300 - Train loss: 0.5169685482978821, Validation loss: 0.5147834420204163
Epoch: 61/300 - Train loss: 0.514107882976532, Validation loss: 0.5112643241882324
Epoch: 62/300 - Train loss: 0.5112833380699158, Validation loss: 0.5093068480491638
Epoch: 63/300 - Train loss: 0.508492648601532, Validation loss: 0.5061196684837341
Epoch: 64/300 - Train loss: 0.5057345628738403, Validation loss: 0.5039746761322021
Epoch: 65/300 - Train loss: 0.5030073523521423, Validation loss: 0.5014467835426331
Epoch: 66/300 - Train loss: 0.5003149509429932, Validation loss: 0.49827292561531067
Epoch: 67/300 - Train loss: 0.4976624846458435, Validation loss: 0.4957546591758728
Epoch: 68/300 - Train loss: 0.49505072832107544, Validation loss: 0.49290770292282104
Epoch: 69/300 - Train loss: 0.49248412251472473, Validation loss: 0.4900687336921692
Epoch: 70/300 - Train loss: 0.4899597764015198, Validation loss: 0.4879794120788574
Epoch: 71/300 - Train loss: 0.4874802827835083, Validation loss: 0.4848087728023529
Epoch: 72/300 - Train loss: 0.4850516617298126, Validation loss: 0.4837595820426941
Epoch: 73/300 - Train loss: 0.48267486691474915, Validation loss: 0.48089632391929626
Epoch: 74/300 - Train loss: 0.48034653067588806, Validation loss: 0.4789853096008301
Epoch: 75/300 - Train loss: 0.4780631959438324, Validation loss: 0.4755319654941559
Epoch: 76/300 - Train loss: 0.47582533955574036, Validation loss: 0.4730337858200073
Epoch: 77/300 - Train loss: 0.47362956404685974, Validation loss: 0.47103604674339294
Epoch: 78/300 - Train loss: 0.47147437930107117, Validation loss: 0.4700857698917389
Epoch: 79/300 - Train loss: 0.4693584144115448, Validation loss: 0.46692144870758057
Epoch: 80/300 - Train loss: 0.46728023886680603, Validation loss: 0.465239018201828
Epoch: 81/300 - Train loss: 0.46523815393447876, Validation loss: 0.46348196268081665
Epoch: 82/300 - Train loss: 0.4632318913936615, Validation loss: 0.461369127035141
Epoch: 83/300 - Train loss: 0.46126046776771545, Validation loss: 0.45963254570961
Epoch: 84/300 - Train loss: 0.4593229591846466, Validation loss: 0.4578525722026825
Epoch: 85/300 - Train loss: 0.45741865038871765, Validation loss: 0.45452430844306946
Epoch: 86/300 - Train loss: 0.4555473029613495, Validation loss: 0.45345020294189453
Epoch: 87/300 - Train loss: 0.4537089169025421, Validation loss: 0.4523283541202545
Epoch: 88/300 - Train loss: 0.4519028067588806, Validation loss: 0.4499187171459198
Epoch: 89/300 - Train loss: 0.4501286447048187, Validation loss: 0.4484640061855316
Epoch: 90/300 - Train loss: 0.4483855366706848, Validation loss: 0.44625842571258545
Epoch: 91/300 - Train loss: 0.4466729462146759, Validation loss: 0.4443066716194153
Epoch: 92/300 - Train loss: 0.4449896216392517, Validation loss: 0.443251371383667
Epoch: 93/300 - Train loss: 0.44333508610725403, Validation loss: 0.44121578335762024
Epoch: 94/300 - Train loss: 0.4417089819908142, Validation loss: 0.44071975350379944
Epoch: 95/300 - Train loss: 0.4401113986968994, Validation loss: 0.4383058547973633
Epoch: 96/300 - Train loss: 0.4385415315628052, Validation loss: 0.4381835460662842
Epoch: 97/300 - Train loss: 0.43699851632118225, Validation loss: 0.43582800030708313
Epoch: 98/300 - Train loss: 0.43548205494880676, Validation loss: 0.4332342743873596
Epoch: 99/300 - Train loss: 0.43399176001548767, Validation loss: 0.43260225653648376
Epoch: 100/300 - Train loss: 0.43252691626548767, Validation loss: 0.4305160641670227
Epoch: 101/300 - Train loss: 0.43108707666397095, Validation loss: 0.4303712844848633
Epoch: 102/300 - Train loss: 0.4296717643737793, Validation loss: 0.42758867144584656
Epoch: 103/300 - Train loss: 0.4282803535461426, Validation loss: 0.4280753433704376
Epoch: 104/300 - Train loss: 0.4269123673439026, Validation loss: 0.42684632539749146
Epoch: 105/300 - Train loss: 0.4255673587322235, Validation loss: 0.42426806688308716
Epoch: 106/300 - Train loss: 0.42424482107162476, Validation loss: 0.4228135645389557
Epoch: 107/300 - Train loss: 0.4229443371295929, Validation loss: 0.42132341861724854
Epoch: 108/300 - Train loss: 0.42166557908058167, Validation loss: 0.42116913199424744
Epoch: 109/300 - Train loss: 0.4204077124595642, Validation loss: 0.4195103943347931
Epoch: 110/300 - Train loss: 0.41917017102241516, Validation loss: 0.41766777634620667
Epoch: 111/300 - Train loss: 0.4179530143737793, Validation loss: 0.41820451617240906
Epoch: 112/300 - Train loss: 0.4167560935020447, Validation loss: 0.4153270125389099
Epoch: 113/300 - Train loss: 0.4155789315700531, Validation loss: 0.4141930937767029
Epoch: 114/300 - Train loss: 0.41442108154296875, Validation loss: 0.4128381311893463
Epoch: 115/300 - Train loss: 0.4132820665836334, Validation loss: 0.41206490993499756
Epoch: 116/300 - Train loss: 0.412161260843277, Validation loss: 0.41108793020248413
Epoch: 117/300 - Train loss: 0.41105854511260986, Validation loss: 0.40953710675239563
Epoch: 118/300 - Train loss: 0.40997380018234253, Validation loss: 0.4090196192264557
Epoch: 119/300 - Train loss: 0.4089065492153168, Validation loss: 0.4070153534412384
Epoch: 120/300 - Train loss: 0.40785670280456543, Validation loss: 0.40756431221961975
Epoch: 121/300 - Train loss: 0.40682363510131836, Validation loss: 0.40651798248291016
Epoch: 122/300 - Train loss: 0.4058067798614502, Validation loss: 0.40546852350234985
Epoch: 123/300 - Train loss: 0.40480586886405945, Validation loss: 0.40222474932670593
Epoch: 124/300 - Train loss: 0.40382078289985657, Validation loss: 0.4024229049682617
Epoch: 125/300 - Train loss: 0.40285125374794006, Validation loss: 0.40170446038246155
Epoch: 126/300 - Train loss: 0.4018966555595398, Validation loss: 0.4000120759010315
Epoch: 127/300 - Train loss: 0.40095657110214233, Validation loss: 0.39910176396369934
Epoch: 128/300 - Train loss: 0.40003088116645813, Validation loss: 0.3998333215713501
Epoch: 129/300 - Train loss: 0.39911893010139465, Validation loss: 0.3978480398654938
Epoch: 130/300 - Train loss: 0.39822059869766235, Validation loss: 0.397003710269928
Epoch: 131/300 - Train loss: 0.3973356783390045, Validation loss: 0.39592647552490234
Epoch: 132/300 - Train loss: 0.39646410942077637, Validation loss: 0.39590588212013245
Epoch: 133/300 - Train loss: 0.3956054151058197, Validation loss: 0.3951560854911804
Epoch: 134/300 - Train loss: 0.3947592079639435, Validation loss: 0.3938194811344147
Epoch: 135/300 - Train loss: 0.39392560720443726, Validation loss: 0.39280378818511963
Epoch: 136/300 - Train loss: 0.3931039571762085, Validation loss: 0.3911455273628235
Epoch: 137/300 - Train loss: 0.39229410886764526, Validation loss: 0.39235466718673706
Epoch: 138/300 - Train loss: 0.39149579405784607, Validation loss: 0.39031437039375305
Epoch: 139/300 - Train loss: 0.3907091021537781, Validation loss: 0.39010319113731384
Epoch: 140/300 - Train loss: 0.38993364572525024, Validation loss: 0.38843077421188354
Epoch: 141/300 - Train loss: 0.3891690671443939, Validation loss: 0.38791319727897644
Epoch: 142/300 - Train loss: 0.38841551542282104, Validation loss: 0.3867824971675873
Epoch: 143/300 - Train loss: 0.38767263293266296, Validation loss: 0.38624075055122375
Epoch: 144/300 - Train loss: 0.3869399428367615, Validation loss: 0.3871316909790039
Epoch: 145/300 - Train loss: 0.3862174153327942, Validation loss: 0.3851422965526581
Epoch: 146/300 - Train loss: 0.3855048418045044, Validation loss: 0.3847869634628296
Epoch: 147/300 - Train loss: 0.3848021328449249, Validation loss: 0.384823203086853
Epoch: 148/300 - Train loss: 0.3841090202331543, Validation loss: 0.383988618850708
Epoch: 149/300 - Train loss: 0.3834247291088104, Validation loss: 0.38285571336746216
Epoch: 150/300 - Train loss: 0.3827495574951172, Validation loss: 0.3825579583644867
Epoch: 151/300 - Train loss: 0.38208311796188354, Validation loss: 0.3814539909362793
Epoch: 152/300 - Train loss: 0.38142526149749756, Validation loss: 0.38173025846481323
Epoch: 153/300 - Train loss: 0.3807760775089264, Validation loss: 0.37988942861557007
Epoch: 154/300 - Train loss: 0.38013529777526855, Validation loss: 0.3792157769203186
Epoch: 155/300 - Train loss: 0.37950265407562256, Validation loss: 0.3784157633781433
Epoch: 156/300 - Train loss: 0.3788781464099884, Validation loss: 0.3787900507450104
Epoch: 157/300 - Train loss: 0.37826162576675415, Validation loss: 0.3776816725730896
Epoch: 158/300 - Train loss: 0.37765276432037354, Validation loss: 0.37717294692993164
Epoch: 159/300 - Train loss: 0.377051442861557, Validation loss: 0.37524187564849854
Epoch: 160/300 - Train loss: 0.3764573931694031, Validation loss: 0.37515437602996826
Epoch: 161/300 - Train loss: 0.3758706748485565, Validation loss: 0.3746633231639862
Epoch: 162/300 - Train loss: 0.37529098987579346, Validation loss: 0.3749275803565979
Epoch: 163/300 - Train loss: 0.3747181296348572, Validation loss: 0.37447401881217957
