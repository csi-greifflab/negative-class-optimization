Epoch: 1/300 - Train loss: 0.7002401947975159, Validation loss: 0.6992107629776001
Epoch: 2/300 - Train loss: 0.6978057622909546, Validation loss: 0.6969560384750366
Epoch: 3/300 - Train loss: 0.6954814195632935, Validation loss: 0.6945925354957581
Epoch: 4/300 - Train loss: 0.6931946277618408, Validation loss: 0.6924781799316406
Epoch: 5/300 - Train loss: 0.6908878684043884, Validation loss: 0.6900174021720886
Epoch: 6/300 - Train loss: 0.6885067820549011, Validation loss: 0.6877399682998657
Epoch: 7/300 - Train loss: 0.6860044598579407, Validation loss: 0.6849814653396606
Epoch: 8/300 - Train loss: 0.6833456158638, Validation loss: 0.6822220087051392
Epoch: 9/300 - Train loss: 0.6805204153060913, Validation loss: 0.679264485836029
Epoch: 10/300 - Train loss: 0.6775186061859131, Validation loss: 0.6761104464530945
Epoch: 11/300 - Train loss: 0.6743360161781311, Validation loss: 0.6728840470314026
Epoch: 12/300 - Train loss: 0.6709681153297424, Validation loss: 0.6694029569625854
Epoch: 13/300 - Train loss: 0.6674163341522217, Validation loss: 0.6657357215881348
Epoch: 14/300 - Train loss: 0.6636825203895569, Validation loss: 0.6618427038192749
Epoch: 15/300 - Train loss: 0.6597802639007568, Validation loss: 0.6579256057739258
Epoch: 16/300 - Train loss: 0.6557263731956482, Validation loss: 0.6537803411483765
Epoch: 17/300 - Train loss: 0.6515302062034607, Validation loss: 0.6494817137718201
Epoch: 18/300 - Train loss: 0.6472027897834778, Validation loss: 0.6450032591819763
Epoch: 19/300 - Train loss: 0.6427532434463501, Validation loss: 0.6406155228614807
Epoch: 20/300 - Train loss: 0.6381955146789551, Validation loss: 0.6361265778541565
Epoch: 21/300 - Train loss: 0.6335329413414001, Validation loss: 0.6315937042236328
Epoch: 22/300 - Train loss: 0.6287786364555359, Validation loss: 0.6267239451408386
Epoch: 23/300 - Train loss: 0.6239416003227234, Validation loss: 0.6217193603515625
Epoch: 24/300 - Train loss: 0.6190298795700073, Validation loss: 0.6170339584350586
Epoch: 25/300 - Train loss: 0.6140540838241577, Validation loss: 0.6122087836265564
Epoch: 26/300 - Train loss: 0.6090177297592163, Validation loss: 0.6072801947593689
Epoch: 27/300 - Train loss: 0.6039228439331055, Validation loss: 0.6021036505699158
Epoch: 28/300 - Train loss: 0.5987756252288818, Validation loss: 0.5968102216720581
Epoch: 29/300 - Train loss: 0.5935797095298767, Validation loss: 0.5919592976570129
Epoch: 30/300 - Train loss: 0.5883386731147766, Validation loss: 0.5865672826766968
Epoch: 31/300 - Train loss: 0.5830549001693726, Validation loss: 0.581240713596344
Epoch: 32/300 - Train loss: 0.577732503414154, Validation loss: 0.5760916471481323
Epoch: 33/300 - Train loss: 0.5723775625228882, Validation loss: 0.5708312392234802
Epoch: 34/300 - Train loss: 0.5669940114021301, Validation loss: 0.5656379461288452
Epoch: 35/300 - Train loss: 0.5615871548652649, Validation loss: 0.560269832611084
Epoch: 36/300 - Train loss: 0.5561627149581909, Validation loss: 0.5548396110534668
Epoch: 37/300 - Train loss: 0.5507268905639648, Validation loss: 0.549606442451477
Epoch: 38/300 - Train loss: 0.545284628868103, Validation loss: 0.5441384315490723
Epoch: 39/300 - Train loss: 0.5398411750793457, Validation loss: 0.5388964414596558
Epoch: 40/300 - Train loss: 0.5344028472900391, Validation loss: 0.5337337851524353
Epoch: 41/300 - Train loss: 0.5289751291275024, Validation loss: 0.5285674929618835
Epoch: 42/300 - Train loss: 0.5235639810562134, Validation loss: 0.5229799151420593
Epoch: 43/300 - Train loss: 0.5181748270988464, Validation loss: 0.5177149176597595
Epoch: 44/300 - Train loss: 0.5128130912780762, Validation loss: 0.5125693678855896
Epoch: 45/300 - Train loss: 0.5074834823608398, Validation loss: 0.5072319507598877
Epoch: 46/300 - Train loss: 0.502191424369812, Validation loss: 0.5022383332252502
Epoch: 47/300 - Train loss: 0.4969411790370941, Validation loss: 0.49701127409935
Epoch: 48/300 - Train loss: 0.491737425327301, Validation loss: 0.49225395917892456
Epoch: 49/300 - Train loss: 0.4865841865539551, Validation loss: 0.48744112253189087
Epoch: 50/300 - Train loss: 0.481485515832901, Validation loss: 0.4826904535293579
Epoch: 51/300 - Train loss: 0.4764450490474701, Validation loss: 0.4777180850505829
Epoch: 52/300 - Train loss: 0.4714660942554474, Validation loss: 0.4731486141681671
Epoch: 53/300 - Train loss: 0.4665514826774597, Validation loss: 0.4678993225097656
Epoch: 54/300 - Train loss: 0.4617041349411011, Validation loss: 0.46363672614097595
Epoch: 55/300 - Train loss: 0.45692628622055054, Validation loss: 0.4588621258735657
Epoch: 56/300 - Train loss: 0.4522199034690857, Validation loss: 0.45410972833633423
Epoch: 57/300 - Train loss: 0.4475870430469513, Validation loss: 0.4497320055961609
Epoch: 58/300 - Train loss: 0.4430292546749115, Validation loss: 0.4451761543750763
Epoch: 59/300 - Train loss: 0.43854790925979614, Validation loss: 0.44142305850982666
Epoch: 60/300 - Train loss: 0.43414369225502014, Validation loss: 0.43706074357032776
Epoch: 61/300 - Train loss: 0.4298177659511566, Validation loss: 0.43295034766197205
Epoch: 62/300 - Train loss: 0.42557090520858765, Validation loss: 0.42877742648124695
Epoch: 63/300 - Train loss: 0.42140281200408936, Validation loss: 0.4250536262989044
Epoch: 64/300 - Train loss: 0.417313814163208, Validation loss: 0.42108505964279175
Epoch: 65/300 - Train loss: 0.4133037328720093, Validation loss: 0.41725635528564453
Epoch: 66/300 - Train loss: 0.40937191247940063, Validation loss: 0.41408979892730713
Epoch: 67/300 - Train loss: 0.4055179953575134, Validation loss: 0.4104062616825104
Epoch: 68/300 - Train loss: 0.40174150466918945, Validation loss: 0.4064202308654785
Epoch: 69/300 - Train loss: 0.39804166555404663, Validation loss: 0.402910053730011
Epoch: 70/300 - Train loss: 0.3944174349308014, Validation loss: 0.3988508880138397
Epoch: 71/300 - Train loss: 0.39086806774139404, Validation loss: 0.3963126242160797
Epoch: 72/300 - Train loss: 0.3873921036720276, Validation loss: 0.3925704061985016
Epoch: 73/300 - Train loss: 0.38398826122283936, Validation loss: 0.3893953859806061
Epoch: 74/300 - Train loss: 0.3806551992893219, Validation loss: 0.38648998737335205
Epoch: 75/300 - Train loss: 0.3773919939994812, Validation loss: 0.38289862871170044
Epoch: 76/300 - Train loss: 0.3741970658302307, Validation loss: 0.37995317578315735
Epoch: 77/300 - Train loss: 0.3710689842700958, Validation loss: 0.37715035676956177
Epoch: 78/300 - Train loss: 0.36800631880760193, Validation loss: 0.37435364723205566
Epoch: 79/300 - Train loss: 0.3650076389312744, Validation loss: 0.3712228834629059
Epoch: 80/300 - Train loss: 0.3620713949203491, Validation loss: 0.3683263063430786
Epoch: 81/300 - Train loss: 0.3591962158679962, Validation loss: 0.3659808337688446
Epoch: 82/300 - Train loss: 0.3563806116580963, Validation loss: 0.3633181154727936
Epoch: 83/300 - Train loss: 0.3536231219768524, Validation loss: 0.3599345088005066
Epoch: 84/300 - Train loss: 0.3509220778942108, Validation loss: 0.35828879475593567
Epoch: 85/300 - Train loss: 0.3482763171195984, Validation loss: 0.35566258430480957
Epoch: 86/300 - Train loss: 0.34568411111831665, Validation loss: 0.353254497051239
Epoch: 87/300 - Train loss: 0.3431442677974701, Validation loss: 0.35016363859176636
Epoch: 88/300 - Train loss: 0.34065526723861694, Validation loss: 0.3478601574897766
Epoch: 89/300 - Train loss: 0.33821582794189453, Validation loss: 0.3457505702972412
Epoch: 90/300 - Train loss: 0.33582472801208496, Validation loss: 0.3431638181209564
Epoch: 91/300 - Train loss: 0.3334806561470032, Validation loss: 0.3410520851612091
Epoch: 92/300 - Train loss: 0.33118218183517456, Validation loss: 0.33873462677001953
Epoch: 93/300 - Train loss: 0.32892775535583496, Validation loss: 0.3366055488586426
Epoch: 94/300 - Train loss: 0.32671621441841125, Validation loss: 0.3345721960067749
Epoch: 95/300 - Train loss: 0.3245467245578766, Validation loss: 0.3327106535434723
Epoch: 96/300 - Train loss: 0.32241788506507874, Validation loss: 0.33000272512435913
Epoch: 97/300 - Train loss: 0.32032865285873413, Validation loss: 0.32801514863967896
Epoch: 98/300 - Train loss: 0.31827792525291443, Validation loss: 0.3265456557273865
Epoch: 99/300 - Train loss: 0.3162645101547241, Validation loss: 0.3246184289455414
Epoch: 100/300 - Train loss: 0.3142874836921692, Validation loss: 0.32269543409347534
Epoch: 101/300 - Train loss: 0.3123457133769989, Validation loss: 0.3204212486743927
Epoch: 102/300 - Train loss: 0.3104383051395416, Validation loss: 0.31858327984809875
Epoch: 103/300 - Train loss: 0.30856412649154663, Validation loss: 0.316787987947464
Epoch: 104/300 - Train loss: 0.30672234296798706, Validation loss: 0.31498822569847107
Epoch: 105/300 - Train loss: 0.3049120306968689, Validation loss: 0.31408289074897766
Epoch: 106/300 - Train loss: 0.30313241481781006, Validation loss: 0.3119624853134155
Epoch: 107/300 - Train loss: 0.30138257145881653, Validation loss: 0.3101138174533844
Epoch: 108/300 - Train loss: 0.2996617555618286, Validation loss: 0.3079577088356018
Epoch: 109/300 - Train loss: 0.29796919226646423, Validation loss: 0.3065187335014343
Epoch: 110/300 - Train loss: 0.29630404710769653, Validation loss: 0.30464908480644226
Epoch: 111/300 - Train loss: 0.2946656048297882, Validation loss: 0.30291569232940674
Epoch: 112/300 - Train loss: 0.29305320978164673, Validation loss: 0.30162379145622253
Epoch: 113/300 - Train loss: 0.29146623611450195, Validation loss: 0.30023807287216187
Epoch: 114/300 - Train loss: 0.28990402817726135, Validation loss: 0.2988411784172058
Epoch: 115/300 - Train loss: 0.28836578130722046, Validation loss: 0.29696205258369446
Epoch: 116/300 - Train loss: 0.2868509590625763, Validation loss: 0.2959703505039215
Epoch: 117/300 - Train loss: 0.2853589951992035, Validation loss: 0.29482823610305786
Epoch: 118/300 - Train loss: 0.28388938307762146, Validation loss: 0.29278114438056946
Epoch: 119/300 - Train loss: 0.28244152665138245, Validation loss: 0.29110419750213623
Epoch: 120/300 - Train loss: 0.2810150384902954, Validation loss: 0.28930509090423584
Epoch: 121/300 - Train loss: 0.279609352350235, Validation loss: 0.2878606915473938
Epoch: 122/300 - Train loss: 0.2782239019870758, Validation loss: 0.28648942708969116
Epoch: 123/300 - Train loss: 0.2768581509590149, Validation loss: 0.28634071350097656
Epoch: 124/300 - Train loss: 0.2755116820335388, Validation loss: 0.28473129868507385
Epoch: 125/300 - Train loss: 0.27418410778045654, Validation loss: 0.2828347384929657
Epoch: 126/300 - Train loss: 0.2728749215602875, Validation loss: 0.28229811787605286
Epoch: 127/300 - Train loss: 0.2715838849544525, Validation loss: 0.2809971868991852
Epoch: 128/300 - Train loss: 0.27031058073043823, Validation loss: 0.27922436594963074
Epoch: 129/300 - Train loss: 0.2690545320510864, Validation loss: 0.27836427092552185
Epoch: 130/300 - Train loss: 0.2678154408931732, Validation loss: 0.2764412462711334
Epoch: 131/300 - Train loss: 0.26659294962882996, Validation loss: 0.27545392513275146
Epoch: 132/300 - Train loss: 0.2653867304325104, Validation loss: 0.27481016516685486
Epoch: 133/300 - Train loss: 0.2641964554786682, Validation loss: 0.2732202410697937
Epoch: 134/300 - Train loss: 0.2630217671394348, Validation loss: 0.27198532223701477
Epoch: 135/300 - Train loss: 0.26186245679855347, Validation loss: 0.27128657698631287
Epoch: 136/300 - Train loss: 0.26071804761886597, Validation loss: 0.270283579826355
Epoch: 137/300 - Train loss: 0.259588360786438, Validation loss: 0.2689363360404968
Epoch: 138/300 - Train loss: 0.2584731876850128, Validation loss: 0.2680482268333435
Epoch: 139/300 - Train loss: 0.25737226009368896, Validation loss: 0.2666822075843811
Epoch: 140/300 - Train loss: 0.25628525018692017, Validation loss: 0.26575037837028503
Epoch: 141/300 - Train loss: 0.25521203875541687, Validation loss: 0.2646114230155945
Epoch: 142/300 - Train loss: 0.25415220856666565, Validation loss: 0.2631149888038635
Epoch: 143/300 - Train loss: 0.2531055808067322, Validation loss: 0.26287558674812317
Epoch: 144/300 - Train loss: 0.25207194685935974, Validation loss: 0.2618348002433777
Epoch: 145/300 - Train loss: 0.25105103850364685, Validation loss: 0.2601882815361023
Epoch: 146/300 - Train loss: 0.25004279613494873, Validation loss: 0.25980862975120544
Epoch: 147/300 - Train loss: 0.2490469366312027, Validation loss: 0.2585062086582184
Epoch: 148/300 - Train loss: 0.24806328117847443, Validation loss: 0.25821951031684875
Epoch: 149/300 - Train loss: 0.24709171056747437, Validation loss: 0.25651830434799194
Epoch: 150/300 - Train loss: 0.24613194167613983, Validation loss: 0.255644828081131
Epoch: 151/300 - Train loss: 0.24518369138240814, Validation loss: 0.2546495199203491
Epoch: 152/300 - Train loss: 0.24424684047698975, Validation loss: 0.2543943226337433
Epoch: 153/300 - Train loss: 0.24332113564014435, Validation loss: 0.25266462564468384
Epoch: 154/300 - Train loss: 0.24240641295909882, Validation loss: 0.2527405321598053
Epoch: 155/300 - Train loss: 0.2415025681257248, Validation loss: 0.25069788098335266
Epoch: 156/300 - Train loss: 0.24060946702957153, Validation loss: 0.25028103590011597
Epoch: 157/300 - Train loss: 0.2397269755601883, Validation loss: 0.24973419308662415
Epoch: 158/300 - Train loss: 0.23885488510131836, Validation loss: 0.2480042725801468
Epoch: 159/300 - Train loss: 0.23799307644367218, Validation loss: 0.24790531396865845
Epoch: 160/300 - Train loss: 0.237141415476799, Validation loss: 0.24654996395111084
Epoch: 161/300 - Train loss: 0.2362997978925705, Validation loss: 0.2456277459859848
Epoch: 162/300 - Train loss: 0.2354680299758911, Validation loss: 0.24459101259708405
Epoch: 163/300 - Train loss: 0.23464597761631012, Validation loss: 0.24429957568645477
Epoch: 164/300 - Train loss: 0.23383349180221558, Validation loss: 0.24384501576423645
Epoch: 165/300 - Train loss: 0.23303043842315674, Validation loss: 0.24233445525169373
Epoch: 166/300 - Train loss: 0.23223663866519928, Validation loss: 0.24144412577152252
Epoch: 167/300 - Train loss: 0.23145201802253723, Validation loss: 0.24138104915618896
Epoch: 168/300 - Train loss: 0.23067648708820343, Validation loss: 0.24060983955860138
Epoch: 169/300 - Train loss: 0.22990985214710236, Validation loss: 0.23917916417121887
Epoch: 170/300 - Train loss: 0.22915194928646088, Validation loss: 0.23862731456756592
Epoch: 171/300 - Train loss: 0.22840261459350586, Validation loss: 0.23827484250068665
Epoch: 172/300 - Train loss: 0.22766175866127014, Validation loss: 0.23693689703941345
Epoch: 173/300 - Train loss: 0.22692933678627014, Validation loss: 0.23682323098182678
Epoch: 174/300 - Train loss: 0.2262052297592163, Validation loss: 0.23620553314685822
Epoch: 175/300 - Train loss: 0.2254893034696579, Validation loss: 0.2349776327610016
Epoch: 176/300 - Train loss: 0.22478146851062775, Validation loss: 0.23448902368545532
Epoch: 177/300 - Train loss: 0.2240815907716751, Validation loss: 0.23418739438056946
Epoch: 178/300 - Train loss: 0.2233896106481552, Validation loss: 0.2331259399652481
Epoch: 179/300 - Train loss: 0.22270537912845612, Validation loss: 0.23260630667209625
Epoch: 180/300 - Train loss: 0.22202883660793304, Validation loss: 0.23266378045082092
Epoch: 181/300 - Train loss: 0.22135980427265167, Validation loss: 0.23106111586093903
Epoch: 182/300 - Train loss: 0.22069823741912842, Validation loss: 0.23101316392421722
Epoch: 183/300 - Train loss: 0.22004398703575134, Validation loss: 0.22983427345752716
Epoch: 184/300 - Train loss: 0.21939705312252045, Validation loss: 0.22933094203472137
Epoch: 185/300 - Train loss: 0.2187572568655014, Validation loss: 0.22785790264606476
Epoch: 186/300 - Train loss: 0.21812458336353302, Validation loss: 0.22764818370342255
Epoch: 187/300 - Train loss: 0.21749885380268097, Validation loss: 0.2266620546579361
Epoch: 188/300 - Train loss: 0.21688002347946167, Validation loss: 0.2265525758266449
Epoch: 189/300 - Train loss: 0.21626798808574677, Validation loss: 0.22559773921966553
Epoch: 190/300 - Train loss: 0.2156626135110855, Validation loss: 0.22632068395614624
Epoch: 191/300 - Train loss: 0.21506386995315552, Validation loss: 0.22444665431976318
Epoch: 192/300 - Train loss: 0.21447157859802246, Validation loss: 0.2241622507572174
Epoch: 193/300 - Train loss: 0.21388575434684753, Validation loss: 0.22354529798030853
Epoch: 194/300 - Train loss: 0.21330626308918, Validation loss: 0.2228110134601593
Epoch: 195/300 - Train loss: 0.21273304522037506, Validation loss: 0.22219336032867432
Epoch: 196/300 - Train loss: 0.21216599643230438, Validation loss: 0.22155219316482544
Epoch: 197/300 - Train loss: 0.2116049975156784, Validation loss: 0.2214159369468689
Epoch: 198/300 - Train loss: 0.21104994416236877, Validation loss: 0.2206541895866394
Epoch: 199/300 - Train loss: 0.2105007767677307, Validation loss: 0.22057271003723145
Epoch: 200/300 - Train loss: 0.20995745062828064, Validation loss: 0.2196672260761261
