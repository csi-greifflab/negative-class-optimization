Epoch: 1/300 - Train loss: 0.6928251385688782, Validation loss: 0.6929263472557068
Epoch: 2/300 - Train loss: 0.690827488899231, Validation loss: 0.6908105611801147
Epoch: 3/300 - Train loss: 0.688848614692688, Validation loss: 0.6888541579246521
Epoch: 4/300 - Train loss: 0.6868876218795776, Validation loss: 0.6868718862533569
Epoch: 5/300 - Train loss: 0.6849362254142761, Validation loss: 0.6848217248916626
Epoch: 6/300 - Train loss: 0.6829912662506104, Validation loss: 0.6829351782798767
Epoch: 7/300 - Train loss: 0.6810523271560669, Validation loss: 0.6809850931167603
Epoch: 8/300 - Train loss: 0.6791102290153503, Validation loss: 0.6789926290512085
Epoch: 9/300 - Train loss: 0.6771566271781921, Validation loss: 0.6769485473632812
Epoch: 10/300 - Train loss: 0.6751841306686401, Validation loss: 0.6749573349952698
Epoch: 11/300 - Train loss: 0.6731811761856079, Validation loss: 0.6729730367660522
Epoch: 12/300 - Train loss: 0.6711422801017761, Validation loss: 0.6708399653434753
Epoch: 13/300 - Train loss: 0.6690651774406433, Validation loss: 0.6687816977500916
Epoch: 14/300 - Train loss: 0.6669419407844543, Validation loss: 0.6666813492774963
Epoch: 15/300 - Train loss: 0.6647697687149048, Validation loss: 0.6644664406776428
Epoch: 16/300 - Train loss: 0.662543773651123, Validation loss: 0.6623660326004028
Epoch: 17/300 - Train loss: 0.6602609753608704, Validation loss: 0.6601046323776245
Epoch: 18/300 - Train loss: 0.6579209566116333, Validation loss: 0.6578236818313599
Epoch: 19/300 - Train loss: 0.6555215120315552, Validation loss: 0.655328094959259
Epoch: 20/300 - Train loss: 0.6530616879463196, Validation loss: 0.6528335213661194
Epoch: 21/300 - Train loss: 0.6505465507507324, Validation loss: 0.6504108309745789
Epoch: 22/300 - Train loss: 0.6479762196540833, Validation loss: 0.6479319930076599
Epoch: 23/300 - Train loss: 0.6453547477722168, Validation loss: 0.6453652381896973
Epoch: 24/300 - Train loss: 0.6426853537559509, Validation loss: 0.642829954624176
Epoch: 25/300 - Train loss: 0.6399713754653931, Validation loss: 0.6402645707130432
Epoch: 26/300 - Train loss: 0.6372181177139282, Validation loss: 0.6375362873077393
Epoch: 27/300 - Train loss: 0.6344324946403503, Validation loss: 0.6348709464073181
Epoch: 28/300 - Train loss: 0.6316205263137817, Validation loss: 0.6322911977767944
Epoch: 29/300 - Train loss: 0.6287819743156433, Validation loss: 0.6293274760246277
Epoch: 30/300 - Train loss: 0.6259231567382812, Validation loss: 0.6265712380409241
Epoch: 31/300 - Train loss: 0.623051106929779, Validation loss: 0.6240121126174927
Epoch: 32/300 - Train loss: 0.6201691031455994, Validation loss: 0.6210297346115112
Epoch: 33/300 - Train loss: 0.6172786355018616, Validation loss: 0.6181804537773132
Epoch: 34/300 - Train loss: 0.6143853664398193, Validation loss: 0.6157392859458923
Epoch: 35/300 - Train loss: 0.6114910840988159, Validation loss: 0.612886369228363
Epoch: 36/300 - Train loss: 0.6085992455482483, Validation loss: 0.6099720001220703
Epoch: 37/300 - Train loss: 0.6057158708572388, Validation loss: 0.6073869466781616
Epoch: 38/300 - Train loss: 0.6028434634208679, Validation loss: 0.6045502424240112
Epoch: 39/300 - Train loss: 0.5999873280525208, Validation loss: 0.6021683812141418
Epoch: 40/300 - Train loss: 0.5971505641937256, Validation loss: 0.5990129709243774
Epoch: 41/300 - Train loss: 0.5943352580070496, Validation loss: 0.5968026518821716
Epoch: 42/300 - Train loss: 0.591546356678009, Validation loss: 0.5939223170280457
Epoch: 43/300 - Train loss: 0.5887851715087891, Validation loss: 0.5913371443748474
Epoch: 44/300 - Train loss: 0.586056649684906, Validation loss: 0.5886849164962769
Epoch: 45/300 - Train loss: 0.5833615660667419, Validation loss: 0.5862131714820862
Epoch: 46/300 - Train loss: 0.5807032585144043, Validation loss: 0.583232581615448
Epoch: 47/300 - Train loss: 0.5780856013298035, Validation loss: 0.5812395811080933
Epoch: 48/300 - Train loss: 0.5755103826522827, Validation loss: 0.5785362720489502
Epoch: 49/300 - Train loss: 0.5729807019233704, Validation loss: 0.5765345692634583
Epoch: 50/300 - Train loss: 0.5704970359802246, Validation loss: 0.5741070508956909
Epoch: 51/300 - Train loss: 0.568059504032135, Validation loss: 0.5716518759727478
Epoch: 52/300 - Train loss: 0.5656691193580627, Validation loss: 0.5694074034690857
Epoch: 53/300 - Train loss: 0.563327968120575, Validation loss: 0.5673307180404663
Epoch: 54/300 - Train loss: 0.5610374808311462, Validation loss: 0.5653340220451355
Epoch: 55/300 - Train loss: 0.5587979555130005, Validation loss: 0.5628963708877563
Epoch: 56/300 - Train loss: 0.5566112399101257, Validation loss: 0.5608808994293213
Epoch: 57/300 - Train loss: 0.5544769763946533, Validation loss: 0.5590795874595642
Epoch: 58/300 - Train loss: 0.5523951053619385, Validation loss: 0.5568922758102417
Epoch: 59/300 - Train loss: 0.5503666400909424, Validation loss: 0.5554837584495544
Epoch: 60/300 - Train loss: 0.5483917593955994, Validation loss: 0.5536003112792969
Epoch: 61/300 - Train loss: 0.5464704036712646, Validation loss: 0.5515078902244568
Epoch: 62/300 - Train loss: 0.5446021556854248, Validation loss: 0.5503530502319336
Epoch: 63/300 - Train loss: 0.5427862405776978, Validation loss: 0.5483783483505249
Epoch: 64/300 - Train loss: 0.5410224199295044, Validation loss: 0.5469239950180054
Epoch: 65/300 - Train loss: 0.5393107533454895, Validation loss: 0.545083224773407
Epoch: 66/300 - Train loss: 0.5376502275466919, Validation loss: 0.5439611077308655
Epoch: 67/300 - Train loss: 0.5360401272773743, Validation loss: 0.5426254272460938
Epoch: 68/300 - Train loss: 0.5344793200492859, Validation loss: 0.5406765341758728
Epoch: 69/300 - Train loss: 0.5329663753509521, Validation loss: 0.5389333367347717
Epoch: 70/300 - Train loss: 0.531499445438385, Validation loss: 0.5375245809555054
Epoch: 71/300 - Train loss: 0.5300776958465576, Validation loss: 0.5367934703826904
Epoch: 72/300 - Train loss: 0.5287001729011536, Validation loss: 0.5354231595993042
Epoch: 73/300 - Train loss: 0.5273656845092773, Validation loss: 0.5343278050422668
Epoch: 74/300 - Train loss: 0.5260721445083618, Validation loss: 0.5330126881599426
Epoch: 75/300 - Train loss: 0.5248174667358398, Validation loss: 0.5317683219909668
Epoch: 76/300 - Train loss: 0.5236009955406189, Validation loss: 0.5305681228637695
Epoch: 77/300 - Train loss: 0.5224207043647766, Validation loss: 0.5295556783676147
Epoch: 78/300 - Train loss: 0.5212745666503906, Validation loss: 0.5281725525856018
Epoch: 79/300 - Train loss: 0.5201624035835266, Validation loss: 0.5279967188835144
Epoch: 80/300 - Train loss: 0.5190828442573547, Validation loss: 0.5268919467926025
Epoch: 81/300 - Train loss: 0.5180349946022034, Validation loss: 0.5256332755088806
Epoch: 82/300 - Train loss: 0.5170169472694397, Validation loss: 0.5247374773025513
Epoch: 83/300 - Train loss: 0.5160272121429443, Validation loss: 0.5235880613327026
Epoch: 84/300 - Train loss: 0.5150634050369263, Validation loss: 0.5227853059768677
Epoch: 85/300 - Train loss: 0.5141237378120422, Validation loss: 0.5221415162086487
Epoch: 86/300 - Train loss: 0.5132089853286743, Validation loss: 0.5207891464233398
Epoch: 87/300 - Train loss: 0.5123157501220703, Validation loss: 0.5201323628425598
Epoch: 88/300 - Train loss: 0.5114440321922302, Validation loss: 0.5189621448516846
Epoch: 89/300 - Train loss: 0.5105924010276794, Validation loss: 0.5182929635047913
Epoch: 90/300 - Train loss: 0.5097591876983643, Validation loss: 0.5176904797554016
Epoch: 91/300 - Train loss: 0.5089424848556519, Validation loss: 0.5167761445045471
Epoch: 92/300 - Train loss: 0.5081408023834229, Validation loss: 0.5157181620597839
Epoch: 93/300 - Train loss: 0.5073539018630981, Validation loss: 0.515483558177948
Epoch: 94/300 - Train loss: 0.5065823793411255, Validation loss: 0.5150859355926514
Epoch: 95/300 - Train loss: 0.50582355260849, Validation loss: 0.5143449902534485
Epoch: 96/300 - Train loss: 0.5050753951072693, Validation loss: 0.5133627653121948
Epoch: 97/300 - Train loss: 0.5043392777442932, Validation loss: 0.5120369791984558
Epoch: 98/300 - Train loss: 0.5036112070083618, Validation loss: 0.511578381061554
Epoch: 99/300 - Train loss: 0.5028915405273438, Validation loss: 0.5111460089683533
Epoch: 100/300 - Train loss: 0.5021799206733704, Validation loss: 0.510566234588623
Epoch: 101/300 - Train loss: 0.5014761090278625, Validation loss: 0.5095929503440857
Epoch: 102/300 - Train loss: 0.5007803440093994, Validation loss: 0.5092375874519348
Epoch: 103/300 - Train loss: 0.500092625617981, Validation loss: 0.5088930726051331
Epoch: 104/300 - Train loss: 0.49940988421440125, Validation loss: 0.5080485343933105
Epoch: 105/300 - Train loss: 0.4987313449382782, Validation loss: 0.5071230530738831
Epoch: 106/300 - Train loss: 0.49805742502212524, Validation loss: 0.5067695379257202
Epoch: 107/300 - Train loss: 0.4973863661289215, Validation loss: 0.5055394172668457
Epoch: 108/300 - Train loss: 0.49671852588653564, Validation loss: 0.5057048797607422
Epoch: 109/300 - Train loss: 0.4960528314113617, Validation loss: 0.504601240158081
Epoch: 110/300 - Train loss: 0.4953894019126892, Validation loss: 0.5038474798202515
Epoch: 111/300 - Train loss: 0.4947240948677063, Validation loss: 0.5027485489845276
Epoch: 112/300 - Train loss: 0.49406003952026367, Validation loss: 0.5024772882461548
Epoch: 113/300 - Train loss: 0.49339649081230164, Validation loss: 0.5017273426055908
Epoch: 114/300 - Train loss: 0.49273231625556946, Validation loss: 0.5014464259147644
Epoch: 115/300 - Train loss: 0.4920681118965149, Validation loss: 0.4999522864818573
Epoch: 116/300 - Train loss: 0.4914051294326782, Validation loss: 0.4997163414955139
Epoch: 117/300 - Train loss: 0.4907410144805908, Validation loss: 0.5000902414321899
Epoch: 118/300 - Train loss: 0.49007782340049744, Validation loss: 0.4983258545398712
Epoch: 119/300 - Train loss: 0.4894163906574249, Validation loss: 0.49827516078948975
Epoch: 120/300 - Train loss: 0.4887535870075226, Validation loss: 0.4978671967983246
