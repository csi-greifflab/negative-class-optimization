Epoch: 1/300 - Train loss: 0.6906801462173462, Validation loss: 0.6891729831695557
Epoch: 2/300 - Train loss: 0.6892425417900085, Validation loss: 0.6876754760742188
Epoch: 3/300 - Train loss: 0.6877736449241638, Validation loss: 0.6861644983291626
Epoch: 4/300 - Train loss: 0.6862592101097107, Validation loss: 0.6845607757568359
Epoch: 5/300 - Train loss: 0.6846927404403687, Validation loss: 0.6829230189323425
Epoch: 6/300 - Train loss: 0.6830736398696899, Validation loss: 0.681170642375946
Epoch: 7/300 - Train loss: 0.681389331817627, Validation loss: 0.6793708801269531
Epoch: 8/300 - Train loss: 0.6796368360519409, Validation loss: 0.6774929165840149
Epoch: 9/300 - Train loss: 0.6778177618980408, Validation loss: 0.6756094694137573
Epoch: 10/300 - Train loss: 0.6759345531463623, Validation loss: 0.6736226677894592
Epoch: 11/300 - Train loss: 0.6739851832389832, Validation loss: 0.6715361475944519
Epoch: 12/300 - Train loss: 0.6719743609428406, Validation loss: 0.6694427728652954
Epoch: 13/300 - Train loss: 0.6699024438858032, Validation loss: 0.6672655344009399
Epoch: 14/300 - Train loss: 0.6677694320678711, Validation loss: 0.6650181412696838
Epoch: 15/300 - Train loss: 0.6655821800231934, Validation loss: 0.6627424359321594
Epoch: 16/300 - Train loss: 0.6633427739143372, Validation loss: 0.6603507995605469
Epoch: 17/300 - Train loss: 0.661051869392395, Validation loss: 0.6579480171203613
Epoch: 18/300 - Train loss: 0.6587156653404236, Validation loss: 0.6554166078567505
Epoch: 19/300 - Train loss: 0.6563409566879272, Validation loss: 0.6529668569564819
Epoch: 20/300 - Train loss: 0.6539351940155029, Validation loss: 0.6505167484283447
Epoch: 21/300 - Train loss: 0.6515032052993774, Validation loss: 0.6479398012161255
Epoch: 22/300 - Train loss: 0.6490433216094971, Validation loss: 0.6454877853393555
Epoch: 23/300 - Train loss: 0.6465572118759155, Validation loss: 0.6430014371871948
Epoch: 24/300 - Train loss: 0.6440554261207581, Validation loss: 0.6404123902320862
Epoch: 25/300 - Train loss: 0.6415380835533142, Validation loss: 0.6378004550933838
Epoch: 26/300 - Train loss: 0.6390094757080078, Validation loss: 0.6353151202201843
Epoch: 27/300 - Train loss: 0.6364737153053284, Validation loss: 0.632867157459259
Epoch: 28/300 - Train loss: 0.6339346766471863, Validation loss: 0.6301292777061462
Epoch: 29/300 - Train loss: 0.6313943862915039, Validation loss: 0.6275266408920288
Epoch: 30/300 - Train loss: 0.6288530230522156, Validation loss: 0.6251293420791626
Epoch: 31/300 - Train loss: 0.6263145804405212, Validation loss: 0.6226000189781189
Epoch: 32/300 - Train loss: 0.6237802505493164, Validation loss: 0.6198336482048035
Epoch: 33/300 - Train loss: 0.6212529540061951, Validation loss: 0.6174458265304565
Epoch: 34/300 - Train loss: 0.6187348365783691, Validation loss: 0.6148358583450317
Epoch: 35/300 - Train loss: 0.6162295341491699, Validation loss: 0.612001359462738
Epoch: 36/300 - Train loss: 0.6137387156486511, Validation loss: 0.6098806858062744
Epoch: 37/300 - Train loss: 0.6112629771232605, Validation loss: 0.6073136329650879
Epoch: 38/300 - Train loss: 0.6088043451309204, Validation loss: 0.6048274636268616
Epoch: 39/300 - Train loss: 0.6063655614852905, Validation loss: 0.6024783849716187
Epoch: 40/300 - Train loss: 0.6039488911628723, Validation loss: 0.5998845100402832
Epoch: 41/300 - Train loss: 0.6015552282333374, Validation loss: 0.5975699424743652
Epoch: 42/300 - Train loss: 0.5991865396499634, Validation loss: 0.5951995849609375
Epoch: 43/300 - Train loss: 0.5968447327613831, Validation loss: 0.5933413505554199
Epoch: 44/300 - Train loss: 0.594531238079071, Validation loss: 0.5907987952232361
Epoch: 45/300 - Train loss: 0.5922470688819885, Validation loss: 0.5888884663581848
Epoch: 46/300 - Train loss: 0.5899935960769653, Validation loss: 0.5864907503128052
Epoch: 47/300 - Train loss: 0.587772011756897, Validation loss: 0.5844511985778809
Epoch: 48/300 - Train loss: 0.585582435131073, Validation loss: 0.5820661783218384
Epoch: 49/300 - Train loss: 0.5834263563156128, Validation loss: 0.5802557468414307
Epoch: 50/300 - Train loss: 0.5813049077987671, Validation loss: 0.5780050158500671
Epoch: 51/300 - Train loss: 0.5792184472084045, Validation loss: 0.5762363076210022
Epoch: 52/300 - Train loss: 0.5771670937538147, Validation loss: 0.5742183923721313
Epoch: 53/300 - Train loss: 0.5751512050628662, Validation loss: 0.5719675421714783
Epoch: 54/300 - Train loss: 0.5731703042984009, Validation loss: 0.5699834227561951
Epoch: 55/300 - Train loss: 0.5712248086929321, Validation loss: 0.5681794285774231
Epoch: 56/300 - Train loss: 0.5693142414093018, Validation loss: 0.5663511157035828
Epoch: 57/300 - Train loss: 0.567438006401062, Validation loss: 0.5647995471954346
Epoch: 58/300 - Train loss: 0.5655956268310547, Validation loss: 0.5631056427955627
Epoch: 59/300 - Train loss: 0.5637869238853455, Validation loss: 0.561301052570343
Epoch: 60/300 - Train loss: 0.56201171875, Validation loss: 0.5598422884941101
Epoch: 61/300 - Train loss: 0.5602692365646362, Validation loss: 0.5579822063446045
Epoch: 62/300 - Train loss: 0.5585587024688721, Validation loss: 0.5565668940544128
Epoch: 63/300 - Train loss: 0.5568804144859314, Validation loss: 0.5549902319908142
Epoch: 64/300 - Train loss: 0.5552324652671814, Validation loss: 0.5534940361976624
Epoch: 65/300 - Train loss: 0.5536144971847534, Validation loss: 0.5524595975875854
Epoch: 66/300 - Train loss: 0.5520252585411072, Validation loss: 0.5505018830299377
Epoch: 67/300 - Train loss: 0.5504641532897949, Validation loss: 0.5497663617134094
Epoch: 68/300 - Train loss: 0.5489309430122375, Validation loss: 0.5482364296913147
Epoch: 69/300 - Train loss: 0.5474250316619873, Validation loss: 0.5465184450149536
Epoch: 70/300 - Train loss: 0.5459455847740173, Validation loss: 0.545265257358551
Epoch: 71/300 - Train loss: 0.5444916486740112, Validation loss: 0.5442188382148743
Epoch: 72/300 - Train loss: 0.5430625677108765, Validation loss: 0.5429118275642395
Epoch: 73/300 - Train loss: 0.5416576266288757, Validation loss: 0.5410311818122864
Epoch: 74/300 - Train loss: 0.5402756929397583, Validation loss: 0.539898693561554
Epoch: 75/300 - Train loss: 0.5389154553413391, Validation loss: 0.53910893201828
Epoch: 76/300 - Train loss: 0.5375765562057495, Validation loss: 0.5378125905990601
Epoch: 77/300 - Train loss: 0.5362580418586731, Validation loss: 0.5364405512809753
Epoch: 78/300 - Train loss: 0.5349591970443726, Validation loss: 0.5353261232376099
Epoch: 79/300 - Train loss: 0.5336792469024658, Validation loss: 0.5338013172149658
Epoch: 80/300 - Train loss: 0.5324177145957947, Validation loss: 0.533004105091095
Epoch: 81/300 - Train loss: 0.5311742424964905, Validation loss: 0.5318135619163513
Epoch: 82/300 - Train loss: 0.5299477577209473, Validation loss: 0.5303331017494202
Epoch: 83/300 - Train loss: 0.5287367105484009, Validation loss: 0.5292930006980896
Epoch: 84/300 - Train loss: 0.5275406837463379, Validation loss: 0.5286887884140015
Epoch: 85/300 - Train loss: 0.5263589024543762, Validation loss: 0.5280793309211731
Epoch: 86/300 - Train loss: 0.5251910090446472, Validation loss: 0.5268082022666931
Epoch: 87/300 - Train loss: 0.5240359902381897, Validation loss: 0.5255110859870911
Epoch: 88/300 - Train loss: 0.5228933691978455, Validation loss: 0.5243754982948303
Epoch: 89/300 - Train loss: 0.5217617154121399, Validation loss: 0.523663341999054
Epoch: 90/300 - Train loss: 0.520641028881073, Validation loss: 0.5229006409645081
Epoch: 91/300 - Train loss: 0.5195302367210388, Validation loss: 0.521385908126831
Epoch: 92/300 - Train loss: 0.5184294581413269, Validation loss: 0.5205291509628296
Epoch: 93/300 - Train loss: 0.5173379778862, Validation loss: 0.5192279815673828
Epoch: 94/300 - Train loss: 0.5162560343742371, Validation loss: 0.5186043977737427
Epoch: 95/300 - Train loss: 0.5151827931404114, Validation loss: 0.5179816484451294
Epoch: 96/300 - Train loss: 0.5141188502311707, Validation loss: 0.5167341232299805
Epoch: 97/300 - Train loss: 0.5130631327629089, Validation loss: 0.5157506465911865
Epoch: 98/300 - Train loss: 0.5120151042938232, Validation loss: 0.5144671201705933
Epoch: 99/300 - Train loss: 0.5109758973121643, Validation loss: 0.513660192489624
Epoch: 100/300 - Train loss: 0.5099458694458008, Validation loss: 0.5128831267356873
Epoch: 101/300 - Train loss: 0.5089215636253357, Validation loss: 0.5120002031326294
Epoch: 102/300 - Train loss: 0.5079034566879272, Validation loss: 0.5115300416946411
Epoch: 103/300 - Train loss: 0.5068913102149963, Validation loss: 0.5100772380828857
Epoch: 104/300 - Train loss: 0.50588458776474, Validation loss: 0.5085954070091248
Epoch: 105/300 - Train loss: 0.5048841834068298, Validation loss: 0.5084583759307861
Epoch: 106/300 - Train loss: 0.503889799118042, Validation loss: 0.5078272819519043
Epoch: 107/300 - Train loss: 0.5029009580612183, Validation loss: 0.5064807534217834
Epoch: 108/300 - Train loss: 0.5019178986549377, Validation loss: 0.5054500699043274
Epoch: 109/300 - Train loss: 0.5009403228759766, Validation loss: 0.5048867464065552
Epoch: 110/300 - Train loss: 0.49996769428253174, Validation loss: 0.5035372376441956
Epoch: 111/300 - Train loss: 0.4989994764328003, Validation loss: 0.5032615065574646
Epoch: 112/300 - Train loss: 0.49803590774536133, Validation loss: 0.50190669298172
Epoch: 113/300 - Train loss: 0.49707725644111633, Validation loss: 0.5012798309326172
Epoch: 114/300 - Train loss: 0.49612322449684143, Validation loss: 0.5001702904701233
Epoch: 115/300 - Train loss: 0.49517425894737244, Validation loss: 0.4993419349193573
Epoch: 116/300 - Train loss: 0.49422961473464966, Validation loss: 0.49808236956596375
Epoch: 117/300 - Train loss: 0.49328821897506714, Validation loss: 0.49793753027915955
Epoch: 118/300 - Train loss: 0.492349773645401, Validation loss: 0.49670669436454773
Epoch: 119/300 - Train loss: 0.49141743779182434, Validation loss: 0.4951286315917969
Epoch: 120/300 - Train loss: 0.49049028754234314, Validation loss: 0.49502497911453247
Epoch: 121/300 - Train loss: 0.489568829536438, Validation loss: 0.49399814009666443
Epoch: 122/300 - Train loss: 0.4886515140533447, Validation loss: 0.4932863414287567
Epoch: 123/300 - Train loss: 0.48773714900016785, Validation loss: 0.49221745133399963
Epoch: 124/300 - Train loss: 0.48682552576065063, Validation loss: 0.49152782559394836
Epoch: 125/300 - Train loss: 0.4859180748462677, Validation loss: 0.4911484122276306
Epoch: 126/300 - Train loss: 0.48501476645469666, Validation loss: 0.4898281395435333
Epoch: 127/300 - Train loss: 0.484115332365036, Validation loss: 0.48944416642189026
Epoch: 128/300 - Train loss: 0.4832199513912201, Validation loss: 0.4878135323524475
Epoch: 129/300 - Train loss: 0.48232775926589966, Validation loss: 0.4869893491268158
Epoch: 130/300 - Train loss: 0.4814397394657135, Validation loss: 0.4866968095302582
Epoch: 131/300 - Train loss: 0.48055487871170044, Validation loss: 0.4852552115917206
Epoch: 132/300 - Train loss: 0.4796760678291321, Validation loss: 0.48494210839271545
Epoch: 133/300 - Train loss: 0.4788018465042114, Validation loss: 0.48413804173469543
Epoch: 134/300 - Train loss: 0.47793251276016235, Validation loss: 0.4831349551677704
Epoch: 135/300 - Train loss: 0.47706738114356995, Validation loss: 0.48325690627098083
Epoch: 136/300 - Train loss: 0.4762067496776581, Validation loss: 0.4814912974834442
Epoch: 137/300 - Train loss: 0.4753516614437103, Validation loss: 0.48060718178749084
Epoch: 138/300 - Train loss: 0.47450095415115356, Validation loss: 0.4801935851573944
Epoch: 139/300 - Train loss: 0.47365373373031616, Validation loss: 0.4793775677680969
Epoch: 140/300 - Train loss: 0.4728110134601593, Validation loss: 0.47859057784080505
Epoch: 141/300 - Train loss: 0.4719725549221039, Validation loss: 0.47788891196250916
Epoch: 142/300 - Train loss: 0.47113776206970215, Validation loss: 0.4767763316631317
Epoch: 143/300 - Train loss: 0.4703060984611511, Validation loss: 0.47697287797927856
Epoch: 144/300 - Train loss: 0.4694787561893463, Validation loss: 0.4756266176700592
Epoch: 145/300 - Train loss: 0.46865561604499817, Validation loss: 0.47468623518943787
Epoch: 146/300 - Train loss: 0.4678356945514679, Validation loss: 0.47400760650634766
Epoch: 147/300 - Train loss: 0.4670197069644928, Validation loss: 0.47328853607177734
Epoch: 148/300 - Train loss: 0.46620675921440125, Validation loss: 0.4720536470413208
Epoch: 149/300 - Train loss: 0.4653968811035156, Validation loss: 0.4717751145362854
Epoch: 150/300 - Train loss: 0.4645906388759613, Validation loss: 0.47053393721580505
Epoch: 151/300 - Train loss: 0.46378836035728455, Validation loss: 0.46997374296188354
Epoch: 152/300 - Train loss: 0.46299004554748535, Validation loss: 0.4692966639995575
Epoch: 153/300 - Train loss: 0.46219635009765625, Validation loss: 0.4693107604980469
Epoch: 154/300 - Train loss: 0.461405873298645, Validation loss: 0.46784985065460205
Epoch: 155/300 - Train loss: 0.46061810851097107, Validation loss: 0.46707645058631897
Epoch: 156/300 - Train loss: 0.4598345160484314, Validation loss: 0.46674656867980957
Epoch: 157/300 - Train loss: 0.45905572175979614, Validation loss: 0.46598008275032043
Epoch: 158/300 - Train loss: 0.4582805335521698, Validation loss: 0.46465981006622314
Epoch: 159/300 - Train loss: 0.45750725269317627, Validation loss: 0.46546289324760437
Epoch: 160/300 - Train loss: 0.45673704147338867, Validation loss: 0.46379223465919495
Epoch: 161/300 - Train loss: 0.4559703767299652, Validation loss: 0.46273812651634216
Epoch: 162/300 - Train loss: 0.45520704984664917, Validation loss: 0.4622153341770172
Epoch: 163/300 - Train loss: 0.4544455409049988, Validation loss: 0.46176305413246155
Epoch: 164/300 - Train loss: 0.4536876082420349, Validation loss: 0.46108323335647583
Epoch: 165/300 - Train loss: 0.4529324173927307, Validation loss: 0.46047452092170715
Epoch: 166/300 - Train loss: 0.4521808326244354, Validation loss: 0.4600655138492584
Epoch: 167/300 - Train loss: 0.4514327049255371, Validation loss: 0.4593238830566406
Epoch: 168/300 - Train loss: 0.450687438249588, Validation loss: 0.4582393169403076
Epoch: 169/300 - Train loss: 0.44994422793388367, Validation loss: 0.4576263427734375
Epoch: 170/300 - Train loss: 0.44920238852500916, Validation loss: 0.4572506546974182
Epoch: 171/300 - Train loss: 0.4484630525112152, Validation loss: 0.4562397301197052
Epoch: 172/300 - Train loss: 0.4477260708808899, Validation loss: 0.4562827944755554
Epoch: 173/300 - Train loss: 0.4469923973083496, Validation loss: 0.4548095762729645
Epoch: 174/300 - Train loss: 0.4462617039680481, Validation loss: 0.45425549149513245
Epoch: 175/300 - Train loss: 0.4455333352088928, Validation loss: 0.4536636769771576
Epoch: 176/300 - Train loss: 0.44480785727500916, Validation loss: 0.4536309838294983
Epoch: 177/300 - Train loss: 0.4440850019454956, Validation loss: 0.45225250720977783
Epoch: 178/300 - Train loss: 0.44336390495300293, Validation loss: 0.4515089690685272
Epoch: 179/300 - Train loss: 0.442644864320755, Validation loss: 0.451266884803772
Epoch: 180/300 - Train loss: 0.44192808866500854, Validation loss: 0.45140066742897034
Epoch: 181/300 - Train loss: 0.44121435284614563, Validation loss: 0.4498816728591919
Epoch: 182/300 - Train loss: 0.44050171971321106, Validation loss: 0.44936391711235046
Epoch: 183/300 - Train loss: 0.439791738986969, Validation loss: 0.448766827583313
Epoch: 184/300 - Train loss: 0.43908587098121643, Validation loss: 0.4483565390110016
Epoch: 185/300 - Train loss: 0.43838217854499817, Validation loss: 0.44782963395118713
Epoch: 186/300 - Train loss: 0.43768012523651123, Validation loss: 0.447433203458786
