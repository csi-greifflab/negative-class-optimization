Epoch: 1/300 - Train loss: 0.7153855562210083, Validation loss: 0.7144712209701538
Epoch: 2/300 - Train loss: 0.711249828338623, Validation loss: 0.710020899772644
Epoch: 3/300 - Train loss: 0.7072970271110535, Validation loss: 0.7065102458000183
Epoch: 4/300 - Train loss: 0.7035135626792908, Validation loss: 0.7030301094055176
Epoch: 5/300 - Train loss: 0.6998732089996338, Validation loss: 0.6994930505752563
Epoch: 6/300 - Train loss: 0.6963678002357483, Validation loss: 0.695931613445282
Epoch: 7/300 - Train loss: 0.6929755210876465, Validation loss: 0.6925137042999268
Epoch: 8/300 - Train loss: 0.6896747946739197, Validation loss: 0.6893024444580078
Epoch: 9/300 - Train loss: 0.6864423155784607, Validation loss: 0.686065673828125
Epoch: 10/300 - Train loss: 0.6832568645477295, Validation loss: 0.6828387975692749
Epoch: 11/300 - Train loss: 0.6800991296768188, Validation loss: 0.6796645522117615
Epoch: 12/300 - Train loss: 0.6769542098045349, Validation loss: 0.67657470703125
Epoch: 13/300 - Train loss: 0.6738084554672241, Validation loss: 0.6734577417373657
Epoch: 14/300 - Train loss: 0.6706427335739136, Validation loss: 0.670218825340271
Epoch: 15/300 - Train loss: 0.6674458980560303, Validation loss: 0.6669193506240845
Epoch: 16/300 - Train loss: 0.664207398891449, Validation loss: 0.6637159585952759
Epoch: 17/300 - Train loss: 0.6609077453613281, Validation loss: 0.6601718664169312
Epoch: 18/300 - Train loss: 0.6575409173965454, Validation loss: 0.6567946672439575
Epoch: 19/300 - Train loss: 0.6541042923927307, Validation loss: 0.6532134413719177
Epoch: 20/300 - Train loss: 0.6505879163742065, Validation loss: 0.6497283577919006
Epoch: 21/300 - Train loss: 0.6469825506210327, Validation loss: 0.6458030343055725
Epoch: 22/300 - Train loss: 0.6432802081108093, Validation loss: 0.6421158313751221
Epoch: 23/300 - Train loss: 0.6394743323326111, Validation loss: 0.6383267045021057
Epoch: 24/300 - Train loss: 0.6355647444725037, Validation loss: 0.6342854499816895
Epoch: 25/300 - Train loss: 0.6315457820892334, Validation loss: 0.6299740672111511
Epoch: 26/300 - Train loss: 0.627418577671051, Validation loss: 0.6260010004043579
Epoch: 27/300 - Train loss: 0.6231776475906372, Validation loss: 0.6214367747306824
Epoch: 28/300 - Train loss: 0.6188258528709412, Validation loss: 0.6171489953994751
Epoch: 29/300 - Train loss: 0.6143633723258972, Validation loss: 0.6125453114509583
Epoch: 30/300 - Train loss: 0.6097886562347412, Validation loss: 0.6079288721084595
Epoch: 31/300 - Train loss: 0.6051099896430969, Validation loss: 0.603187084197998
Epoch: 32/300 - Train loss: 0.6003320813179016, Validation loss: 0.5984702110290527
Epoch: 33/300 - Train loss: 0.5954564809799194, Validation loss: 0.5935699343681335
Epoch: 34/300 - Train loss: 0.5904887318611145, Validation loss: 0.588495135307312
Epoch: 35/300 - Train loss: 0.5854455828666687, Validation loss: 0.5835384130477905
Epoch: 36/300 - Train loss: 0.5803316831588745, Validation loss: 0.5784508585929871
Epoch: 37/300 - Train loss: 0.5751570463180542, Validation loss: 0.5734302997589111
Epoch: 38/300 - Train loss: 0.5699341893196106, Validation loss: 0.5679607391357422
Epoch: 39/300 - Train loss: 0.5646790266036987, Validation loss: 0.5630354285240173
Epoch: 40/300 - Train loss: 0.5594057440757751, Validation loss: 0.5575348138809204
Epoch: 41/300 - Train loss: 0.5541242361068726, Validation loss: 0.5526164770126343
Epoch: 42/300 - Train loss: 0.5488464832305908, Validation loss: 0.5475513339042664
Epoch: 43/300 - Train loss: 0.5435909628868103, Validation loss: 0.5421611666679382
Epoch: 44/300 - Train loss: 0.5383613109588623, Validation loss: 0.5372295379638672
Epoch: 45/300 - Train loss: 0.5331624746322632, Validation loss: 0.5320045351982117
Epoch: 46/300 - Train loss: 0.5280022621154785, Validation loss: 0.526827871799469
Epoch: 47/300 - Train loss: 0.5228887796401978, Validation loss: 0.5214953422546387
Epoch: 48/300 - Train loss: 0.5178223252296448, Validation loss: 0.5166171789169312
Epoch: 49/300 - Train loss: 0.5128096342086792, Validation loss: 0.5119212865829468
Epoch: 50/300 - Train loss: 0.5078566074371338, Validation loss: 0.5066303014755249
Epoch: 51/300 - Train loss: 0.5029639601707458, Validation loss: 0.5020809769630432
Epoch: 52/300 - Train loss: 0.49813300371170044, Validation loss: 0.4972181022167206
Epoch: 53/300 - Train loss: 0.4933680295944214, Validation loss: 0.49226683378219604
Epoch: 54/300 - Train loss: 0.4886738657951355, Validation loss: 0.487675279378891
Epoch: 55/300 - Train loss: 0.48405250906944275, Validation loss: 0.483258455991745
Epoch: 56/300 - Train loss: 0.4795010983943939, Validation loss: 0.47853928804397583
Epoch: 57/300 - Train loss: 0.47502338886260986, Validation loss: 0.47446557879447937
Epoch: 58/300 - Train loss: 0.4706191122531891, Validation loss: 0.4700562357902527
Epoch: 59/300 - Train loss: 0.4662890136241913, Validation loss: 0.4653055965900421
Epoch: 60/300 - Train loss: 0.46203359961509705, Validation loss: 0.46091464161872864
Epoch: 61/300 - Train loss: 0.4578567445278168, Validation loss: 0.45691466331481934
Epoch: 62/300 - Train loss: 0.4537542462348938, Validation loss: 0.45314815640449524
Epoch: 63/300 - Train loss: 0.4497326612472534, Validation loss: 0.449200302362442
Epoch: 64/300 - Train loss: 0.4457906186580658, Validation loss: 0.4458312392234802
Epoch: 65/300 - Train loss: 0.4419248402118683, Validation loss: 0.441381573677063
Epoch: 66/300 - Train loss: 0.43813636898994446, Validation loss: 0.43755391240119934
Epoch: 67/300 - Train loss: 0.43442612886428833, Validation loss: 0.433907151222229
Epoch: 68/300 - Train loss: 0.4307956099510193, Validation loss: 0.43027201294898987
Epoch: 69/300 - Train loss: 0.4272468686103821, Validation loss: 0.4272603988647461
Epoch: 70/300 - Train loss: 0.42378029227256775, Validation loss: 0.42369112372398376
Epoch: 71/300 - Train loss: 0.4203977584838867, Validation loss: 0.4199680685997009
Epoch: 72/300 - Train loss: 0.41710034012794495, Validation loss: 0.4169658422470093
Epoch: 73/300 - Train loss: 0.41389000415802, Validation loss: 0.41369864344596863
Epoch: 74/300 - Train loss: 0.4107690453529358, Validation loss: 0.4106188416481018
Epoch: 75/300 - Train loss: 0.4077373147010803, Validation loss: 0.4081615209579468
Epoch: 76/300 - Train loss: 0.40478813648223877, Validation loss: 0.40504950284957886
Epoch: 77/300 - Train loss: 0.4019184708595276, Validation loss: 0.4023149609565735
Epoch: 78/300 - Train loss: 0.39912524819374084, Validation loss: 0.3991111218929291
Epoch: 79/300 - Train loss: 0.39640572667121887, Validation loss: 0.3966261148452759
Epoch: 80/300 - Train loss: 0.39375704526901245, Validation loss: 0.39441636204719543
Epoch: 81/300 - Train loss: 0.391175240278244, Validation loss: 0.39161986112594604
Epoch: 82/300 - Train loss: 0.38865751028060913, Validation loss: 0.38907334208488464
Epoch: 83/300 - Train loss: 0.3862016499042511, Validation loss: 0.3863791823387146
Epoch: 84/300 - Train loss: 0.3838057816028595, Validation loss: 0.3841332793235779
Epoch: 85/300 - Train loss: 0.3814675807952881, Validation loss: 0.382199764251709
Epoch: 86/300 - Train loss: 0.37918439507484436, Validation loss: 0.37969478964805603
Epoch: 87/300 - Train loss: 0.3769547939300537, Validation loss: 0.3773752450942993
Epoch: 88/300 - Train loss: 0.3747771084308624, Validation loss: 0.3756616711616516
Epoch: 89/300 - Train loss: 0.3726500868797302, Validation loss: 0.3741360902786255
Epoch: 90/300 - Train loss: 0.3705713748931885, Validation loss: 0.3719753921031952
Epoch: 91/300 - Train loss: 0.36854007840156555, Validation loss: 0.36947932839393616
Epoch: 92/300 - Train loss: 0.3665543794631958, Validation loss: 0.3675544559955597
Epoch: 93/300 - Train loss: 0.36461377143859863, Validation loss: 0.3659376800060272
Epoch: 94/300 - Train loss: 0.3627162575721741, Validation loss: 0.3638724386692047
Epoch: 95/300 - Train loss: 0.36086100339889526, Validation loss: 0.3621841073036194
Epoch: 96/300 - Train loss: 0.35904690623283386, Validation loss: 0.36033838987350464
Epoch: 97/300 - Train loss: 0.3572726547718048, Validation loss: 0.3587636351585388
Epoch: 98/300 - Train loss: 0.35553672909736633, Validation loss: 0.3569090962409973
Epoch: 99/300 - Train loss: 0.3538380265235901, Validation loss: 0.35592326521873474
Epoch: 100/300 - Train loss: 0.3521755039691925, Validation loss: 0.35425877571105957
Epoch: 101/300 - Train loss: 0.35054799914360046, Validation loss: 0.35186755657196045
Epoch: 102/300 - Train loss: 0.34895405173301697, Validation loss: 0.3507945239543915
Epoch: 103/300 - Train loss: 0.34739261865615845, Validation loss: 0.3486439883708954
Epoch: 104/300 - Train loss: 0.34586286544799805, Validation loss: 0.3473076820373535
Epoch: 105/300 - Train loss: 0.34436407685279846, Validation loss: 0.34586986899375916
Epoch: 106/300 - Train loss: 0.3428950309753418, Validation loss: 0.3448939323425293
Epoch: 107/300 - Train loss: 0.3414551615715027, Validation loss: 0.3429078161716461
Epoch: 108/300 - Train loss: 0.34004342555999756, Validation loss: 0.3413490653038025
Epoch: 109/300 - Train loss: 0.33865922689437866, Validation loss: 0.3406490981578827
Epoch: 110/300 - Train loss: 0.337302029132843, Validation loss: 0.33924514055252075
Epoch: 111/300 - Train loss: 0.3359711766242981, Validation loss: 0.3379528224468231
Epoch: 112/300 - Train loss: 0.33466529846191406, Validation loss: 0.33598434925079346
Epoch: 113/300 - Train loss: 0.3333832025527954, Validation loss: 0.3349320888519287
Epoch: 114/300 - Train loss: 0.33212438225746155, Validation loss: 0.33398088812828064
Epoch: 115/300 - Train loss: 0.33088812232017517, Validation loss: 0.33309057354927063
Epoch: 116/300 - Train loss: 0.3296741545200348, Validation loss: 0.33147796988487244
Epoch: 117/300 - Train loss: 0.32848209142684937, Validation loss: 0.33065491914749146
Epoch: 118/300 - Train loss: 0.3273109197616577, Validation loss: 0.32921841740608215
Epoch: 119/300 - Train loss: 0.3261599838733673, Validation loss: 0.32837334275245667
Epoch: 120/300 - Train loss: 0.325028657913208, Validation loss: 0.32721832394599915
Epoch: 121/300 - Train loss: 0.3239169120788574, Validation loss: 0.3262609541416168
Epoch: 122/300 - Train loss: 0.32282382249832153, Validation loss: 0.3254891633987427
Epoch: 123/300 - Train loss: 0.3217487931251526, Validation loss: 0.3240944743156433
Epoch: 124/300 - Train loss: 0.3206912875175476, Validation loss: 0.3228352665901184
Epoch: 125/300 - Train loss: 0.3196510076522827, Validation loss: 0.3228585422039032
Epoch: 126/300 - Train loss: 0.3186277449131012, Validation loss: 0.3206102252006531
Epoch: 127/300 - Train loss: 0.3176209330558777, Validation loss: 0.3207371234893799
Epoch: 128/300 - Train loss: 0.31662991642951965, Validation loss: 0.31848493218421936
Epoch: 129/300 - Train loss: 0.31565406918525696, Validation loss: 0.3181036412715912
Epoch: 130/300 - Train loss: 0.31469324231147766, Validation loss: 0.3175010681152344
Epoch: 131/300 - Train loss: 0.31374746561050415, Validation loss: 0.31629306077957153
Epoch: 132/300 - Train loss: 0.31281575560569763, Validation loss: 0.3152710497379303
Epoch: 133/300 - Train loss: 0.3118983209133148, Validation loss: 0.31382766366004944
Epoch: 134/300 - Train loss: 0.31099414825439453, Validation loss: 0.3133476972579956
Epoch: 135/300 - Train loss: 0.3101031482219696, Validation loss: 0.3126581013202667
Epoch: 136/300 - Train loss: 0.3092247545719147, Validation loss: 0.31225576996803284
Epoch: 137/300 - Train loss: 0.308358758687973, Validation loss: 0.31099244952201843
Epoch: 138/300 - Train loss: 0.3075052797794342, Validation loss: 0.3100622594356537
Epoch: 139/300 - Train loss: 0.3066639304161072, Validation loss: 0.3090996742248535
Epoch: 140/300 - Train loss: 0.305834025144577, Validation loss: 0.30859053134918213
Epoch: 141/300 - Train loss: 0.30501589179039, Validation loss: 0.3079908788204193
Epoch: 142/300 - Train loss: 0.30420905351638794, Validation loss: 0.3069884181022644
Epoch: 143/300 - Train loss: 0.30341359972953796, Validation loss: 0.3065454661846161
Epoch: 144/300 - Train loss: 0.3026290833950043, Validation loss: 0.3059564530849457
Epoch: 145/300 - Train loss: 0.30185580253601074, Validation loss: 0.3042789697647095
Epoch: 146/300 - Train loss: 0.301093190908432, Validation loss: 0.30386659502983093
Epoch: 147/300 - Train loss: 0.3003407418727875, Validation loss: 0.3032475709915161
Epoch: 148/300 - Train loss: 0.2995983362197876, Validation loss: 0.301988422870636
Epoch: 149/300 - Train loss: 0.29886606335639954, Validation loss: 0.3019315302371979
Epoch: 150/300 - Train loss: 0.29814353585243225, Validation loss: 0.3013468384742737
Epoch: 151/300 - Train loss: 0.2974305748939514, Validation loss: 0.30018603801727295
Epoch: 152/300 - Train loss: 0.29672691226005554, Validation loss: 0.30049723386764526
Epoch: 153/300 - Train loss: 0.29603227972984314, Validation loss: 0.29890063405036926
Epoch: 154/300 - Train loss: 0.29534614086151123, Validation loss: 0.29820504784584045
Epoch: 155/300 - Train loss: 0.29466843605041504, Validation loss: 0.297964483499527
Epoch: 156/300 - Train loss: 0.29399874806404114, Validation loss: 0.2973719537258148
Epoch: 157/300 - Train loss: 0.29333749413490295, Validation loss: 0.2973673343658447
