Epoch: 1/300 - Train loss: 0.6934266686439514, Validation loss: 0.6906833052635193
Epoch: 2/300 - Train loss: 0.6902973055839539, Validation loss: 0.6876382827758789
Epoch: 3/300 - Train loss: 0.6872050166130066, Validation loss: 0.684559166431427
Epoch: 4/300 - Train loss: 0.684073269367218, Validation loss: 0.6813740730285645
Epoch: 5/300 - Train loss: 0.6808599829673767, Validation loss: 0.6780670881271362
Epoch: 6/300 - Train loss: 0.6775342226028442, Validation loss: 0.6747244596481323
Epoch: 7/300 - Train loss: 0.6740723252296448, Validation loss: 0.671169102191925
Epoch: 8/300 - Train loss: 0.670451819896698, Validation loss: 0.6674343347549438
Epoch: 9/300 - Train loss: 0.6666615009307861, Validation loss: 0.6635609269142151
Epoch: 10/300 - Train loss: 0.6626962423324585, Validation loss: 0.6594837307929993
Epoch: 11/300 - Train loss: 0.6585589051246643, Validation loss: 0.6552834510803223
Epoch: 12/300 - Train loss: 0.654255211353302, Validation loss: 0.6508331298828125
Epoch: 13/300 - Train loss: 0.6497920155525208, Validation loss: 0.6463484168052673
Epoch: 14/300 - Train loss: 0.6451840996742249, Validation loss: 0.6417421102523804
Epoch: 15/300 - Train loss: 0.6404484510421753, Validation loss: 0.636965811252594
Epoch: 16/300 - Train loss: 0.6356028914451599, Validation loss: 0.6321507096290588
Epoch: 17/300 - Train loss: 0.630656898021698, Validation loss: 0.6273278594017029
Epoch: 18/300 - Train loss: 0.6256130337715149, Validation loss: 0.6222211122512817
Epoch: 19/300 - Train loss: 0.6204846501350403, Validation loss: 0.6170532703399658
Epoch: 20/300 - Train loss: 0.6152786612510681, Validation loss: 0.6120118498802185
Epoch: 21/300 - Train loss: 0.6100013852119446, Validation loss: 0.6067734360694885
Epoch: 22/300 - Train loss: 0.6046648025512695, Validation loss: 0.6014134287834167
Epoch: 23/300 - Train loss: 0.5992745161056519, Validation loss: 0.5960907936096191
Epoch: 24/300 - Train loss: 0.5938394665718079, Validation loss: 0.5907053351402283
Epoch: 25/300 - Train loss: 0.5883669853210449, Validation loss: 0.585513710975647
Epoch: 26/300 - Train loss: 0.5828640460968018, Validation loss: 0.5799853205680847
Epoch: 27/300 - Train loss: 0.5773329734802246, Validation loss: 0.574593722820282
Epoch: 28/300 - Train loss: 0.5717816352844238, Validation loss: 0.5691483616828918
Epoch: 29/300 - Train loss: 0.566215455532074, Validation loss: 0.5635786652565002
Epoch: 30/300 - Train loss: 0.5606410503387451, Validation loss: 0.5582792162895203
Epoch: 31/300 - Train loss: 0.55506432056427, Validation loss: 0.5524537563323975
Epoch: 32/300 - Train loss: 0.5494897365570068, Validation loss: 0.5471652150154114
Epoch: 33/300 - Train loss: 0.5439236760139465, Validation loss: 0.5420973300933838
Epoch: 34/300 - Train loss: 0.5383686423301697, Validation loss: 0.536307156085968
Epoch: 35/300 - Train loss: 0.5328286290168762, Validation loss: 0.530788004398346
Epoch: 36/300 - Train loss: 0.5273075699806213, Validation loss: 0.5256479978561401
Epoch: 37/300 - Train loss: 0.5218109488487244, Validation loss: 0.5201238393783569
Epoch: 38/300 - Train loss: 0.5163430571556091, Validation loss: 0.5149660110473633
Epoch: 39/300 - Train loss: 0.5109084844589233, Validation loss: 0.5097817778587341
Epoch: 40/300 - Train loss: 0.5055109858512878, Validation loss: 0.5045095086097717
Epoch: 41/300 - Train loss: 0.5001545548439026, Validation loss: 0.4990934431552887
Epoch: 42/300 - Train loss: 0.49484333395957947, Validation loss: 0.4940207600593567
Epoch: 43/300 - Train loss: 0.48958179354667664, Validation loss: 0.4892166256904602
Epoch: 44/300 - Train loss: 0.484373539686203, Validation loss: 0.48395273089408875
Epoch: 45/300 - Train loss: 0.4792223870754242, Validation loss: 0.4792430102825165
Epoch: 46/300 - Train loss: 0.47413191199302673, Validation loss: 0.4743993878364563
Epoch: 47/300 - Train loss: 0.4691053032875061, Validation loss: 0.4698666036128998
Epoch: 48/300 - Train loss: 0.46414533257484436, Validation loss: 0.4646896719932556
Epoch: 49/300 - Train loss: 0.45925453305244446, Validation loss: 0.4602205753326416
Epoch: 50/300 - Train loss: 0.4544352889060974, Validation loss: 0.4552820324897766
Epoch: 51/300 - Train loss: 0.4496890902519226, Validation loss: 0.4508400559425354
Epoch: 52/300 - Train loss: 0.4450179934501648, Validation loss: 0.44666147232055664
Epoch: 53/300 - Train loss: 0.4404238164424896, Validation loss: 0.44210222363471985
Epoch: 54/300 - Train loss: 0.43590760231018066, Validation loss: 0.43772831559181213
Epoch: 55/300 - Train loss: 0.43147042393684387, Validation loss: 0.43397459387779236
Epoch: 56/300 - Train loss: 0.4271129071712494, Validation loss: 0.42924579977989197
Epoch: 57/300 - Train loss: 0.4228352904319763, Validation loss: 0.4253937304019928
Epoch: 58/300 - Train loss: 0.41863808035850525, Validation loss: 0.42137327790260315
Epoch: 59/300 - Train loss: 0.41452115774154663, Validation loss: 0.4173952341079712
Epoch: 60/300 - Train loss: 0.4104844629764557, Validation loss: 0.4139441251754761
Epoch: 61/300 - Train loss: 0.40652769804000854, Validation loss: 0.4099595546722412
Epoch: 62/300 - Train loss: 0.40265002846717834, Validation loss: 0.4064715504646301
Epoch: 63/300 - Train loss: 0.39885085821151733, Validation loss: 0.4022413492202759
Epoch: 64/300 - Train loss: 0.39512959122657776, Validation loss: 0.39916345477104187
Epoch: 65/300 - Train loss: 0.39148566126823425, Validation loss: 0.3953804075717926
Epoch: 66/300 - Train loss: 0.3879181444644928, Validation loss: 0.39231187105178833
Epoch: 67/300 - Train loss: 0.3844258487224579, Validation loss: 0.3883185386657715
Epoch: 68/300 - Train loss: 0.38100719451904297, Validation loss: 0.3849218487739563
Epoch: 69/300 - Train loss: 0.37766069173812866, Validation loss: 0.3824036419391632
Epoch: 70/300 - Train loss: 0.37438535690307617, Validation loss: 0.379065603017807
Epoch: 71/300 - Train loss: 0.3711797595024109, Validation loss: 0.3760944902896881
Epoch: 72/300 - Train loss: 0.3680422902107239, Validation loss: 0.37375813722610474
Epoch: 73/300 - Train loss: 0.36497190594673157, Validation loss: 0.37060636281967163
Epoch: 74/300 - Train loss: 0.3619670867919922, Validation loss: 0.3673366904258728
Epoch: 75/300 - Train loss: 0.35902631282806396, Validation loss: 0.36437922716140747
Epoch: 76/300 - Train loss: 0.3561480939388275, Validation loss: 0.3618009388446808
Epoch: 77/300 - Train loss: 0.3533307909965515, Validation loss: 0.3590073585510254
Epoch: 78/300 - Train loss: 0.3505726158618927, Validation loss: 0.356489360332489
Epoch: 79/300 - Train loss: 0.3478722870349884, Validation loss: 0.35426318645477295
Epoch: 80/300 - Train loss: 0.34522873163223267, Validation loss: 0.3506738543510437
Epoch: 81/300 - Train loss: 0.3426402509212494, Validation loss: 0.34881260991096497
Epoch: 82/300 - Train loss: 0.34010547399520874, Validation loss: 0.34667861461639404
Epoch: 83/300 - Train loss: 0.33762305974960327, Validation loss: 0.34373095631599426
Epoch: 84/300 - Train loss: 0.3351915776729584, Validation loss: 0.34211260080337524
Epoch: 85/300 - Train loss: 0.3328095078468323, Validation loss: 0.33951374888420105
Epoch: 86/300 - Train loss: 0.3304755985736847, Validation loss: 0.3370601534843445
Epoch: 87/300 - Train loss: 0.32818832993507385, Validation loss: 0.334913045167923
Epoch: 88/300 - Train loss: 0.3259466588497162, Validation loss: 0.33328133821487427
Epoch: 89/300 - Train loss: 0.3237490952014923, Validation loss: 0.33076339960098267
Epoch: 90/300 - Train loss: 0.3215945363044739, Validation loss: 0.32885968685150146
Epoch: 91/300 - Train loss: 0.31948167085647583, Validation loss: 0.32593104243278503
Epoch: 92/300 - Train loss: 0.3174093961715698, Validation loss: 0.324325829744339
Epoch: 93/300 - Train loss: 0.3153764307498932, Validation loss: 0.32269489765167236
Epoch: 94/300 - Train loss: 0.3133818209171295, Validation loss: 0.32038432359695435
Epoch: 95/300 - Train loss: 0.31142452359199524, Validation loss: 0.3186660408973694
Epoch: 96/300 - Train loss: 0.30950304865837097, Validation loss: 0.31634464859962463
Epoch: 97/300 - Train loss: 0.307616263628006, Validation loss: 0.31485405564308167
Epoch: 98/300 - Train loss: 0.3057634234428406, Validation loss: 0.31303760409355164
Epoch: 99/300 - Train loss: 0.30394336581230164, Validation loss: 0.31111401319503784
Epoch: 100/300 - Train loss: 0.30215534567832947, Validation loss: 0.30961164832115173
Epoch: 101/300 - Train loss: 0.30039846897125244, Validation loss: 0.3084559440612793
Epoch: 102/300 - Train loss: 0.29867202043533325, Validation loss: 0.30614370107650757
Epoch: 103/300 - Train loss: 0.29697513580322266, Validation loss: 0.3045358657836914
Epoch: 104/300 - Train loss: 0.29530707001686096, Validation loss: 0.3030450940132141
Epoch: 105/300 - Train loss: 0.293666809797287, Validation loss: 0.3018264174461365
Epoch: 106/300 - Train loss: 0.29205358028411865, Validation loss: 0.2999518811702728
Epoch: 107/300 - Train loss: 0.29046666622161865, Validation loss: 0.29833194613456726
Epoch: 108/300 - Train loss: 0.28890547156333923, Validation loss: 0.2970004379749298
Epoch: 109/300 - Train loss: 0.2873692214488983, Validation loss: 0.29517683386802673
Epoch: 110/300 - Train loss: 0.2858573794364929, Validation loss: 0.2934272587299347
Epoch: 111/300 - Train loss: 0.2843692898750305, Validation loss: 0.29273706674575806
Epoch: 112/300 - Train loss: 0.28290432691574097, Validation loss: 0.29091256856918335
Epoch: 113/300 - Train loss: 0.2814618945121765, Validation loss: 0.2897593677043915
Epoch: 114/300 - Train loss: 0.28004133701324463, Validation loss: 0.28893476724624634
Epoch: 115/300 - Train loss: 0.27864229679107666, Validation loss: 0.28653091192245483
Epoch: 116/300 - Train loss: 0.2772641181945801, Validation loss: 0.2855530083179474
Epoch: 117/300 - Train loss: 0.2759062349796295, Validation loss: 0.2848452925682068
Epoch: 118/300 - Train loss: 0.2745683193206787, Validation loss: 0.28267693519592285
Epoch: 119/300 - Train loss: 0.27324989438056946, Validation loss: 0.28150710463523865
Epoch: 120/300 - Train loss: 0.27195051312446594, Validation loss: 0.2801768183708191
Epoch: 121/300 - Train loss: 0.27066972851753235, Validation loss: 0.2791461646556854
Epoch: 122/300 - Train loss: 0.26940709352493286, Validation loss: 0.27762818336486816
Epoch: 123/300 - Train loss: 0.2681622803211212, Validation loss: 0.2770787477493286
Epoch: 124/300 - Train loss: 0.26693496108055115, Validation loss: 0.27537810802459717
Epoch: 125/300 - Train loss: 0.2657245993614197, Validation loss: 0.2744266986846924
Epoch: 126/300 - Train loss: 0.2645310163497925, Validation loss: 0.2731904089450836
Epoch: 127/300 - Train loss: 0.26335376501083374, Validation loss: 0.2718438506126404
Epoch: 128/300 - Train loss: 0.2621925473213196, Validation loss: 0.27086830139160156
Epoch: 129/300 - Train loss: 0.2610469460487366, Validation loss: 0.2694380283355713
Epoch: 130/300 - Train loss: 0.2599166929721832, Validation loss: 0.2686624526977539
Epoch: 131/300 - Train loss: 0.25880149006843567, Validation loss: 0.2672197222709656
Epoch: 132/300 - Train loss: 0.25770100951194763, Validation loss: 0.26698389649391174
Epoch: 133/300 - Train loss: 0.25661501288414, Validation loss: 0.26535114645957947
Epoch: 134/300 - Train loss: 0.25554320216178894, Validation loss: 0.26455822587013245
Epoch: 135/300 - Train loss: 0.2544853091239929, Validation loss: 0.2634758949279785
Epoch: 136/300 - Train loss: 0.25344109535217285, Validation loss: 0.2621113955974579
Epoch: 137/300 - Train loss: 0.2524104416370392, Validation loss: 0.26130902767181396
Epoch: 138/300 - Train loss: 0.25139299035072327, Validation loss: 0.2601122260093689
Epoch: 139/300 - Train loss: 0.2503884732723236, Validation loss: 0.2591535747051239
Epoch: 140/300 - Train loss: 0.2493966519832611, Validation loss: 0.2585921585559845
Epoch: 141/300 - Train loss: 0.24841728806495667, Validation loss: 0.2572958469390869
Epoch: 142/300 - Train loss: 0.24745021760463715, Validation loss: 0.2567305862903595
Epoch: 143/300 - Train loss: 0.2464951127767563, Validation loss: 0.2559802234172821
Epoch: 144/300 - Train loss: 0.24555177986621857, Validation loss: 0.2541848123073578
Epoch: 145/300 - Train loss: 0.24462008476257324, Validation loss: 0.2538290023803711
Epoch: 146/300 - Train loss: 0.24369993805885315, Validation loss: 0.2529729902744293
Epoch: 147/300 - Train loss: 0.2427911013364792, Validation loss: 0.2515256404876709
Epoch: 148/300 - Train loss: 0.24189338088035583, Validation loss: 0.25085052847862244
Epoch: 149/300 - Train loss: 0.24100659787654877, Validation loss: 0.25000062584877014
Epoch: 150/300 - Train loss: 0.24013058841228485, Validation loss: 0.24918724596500397
Epoch: 151/300 - Train loss: 0.23926515877246857, Validation loss: 0.24803116917610168
Epoch: 152/300 - Train loss: 0.23841020464897156, Validation loss: 0.24793550372123718
Epoch: 153/300 - Train loss: 0.23756547272205353, Validation loss: 0.246411994099617
Epoch: 154/300 - Train loss: 0.23673087358474731, Validation loss: 0.24554592370986938
Epoch: 155/300 - Train loss: 0.2359061986207962, Validation loss: 0.24584142863750458
Epoch: 156/300 - Train loss: 0.23509129881858826, Validation loss: 0.24466337263584137
Epoch: 157/300 - Train loss: 0.23428598046302795, Validation loss: 0.2439965307712555
Epoch: 158/300 - Train loss: 0.23349016904830933, Validation loss: 0.24316011369228363
Epoch: 159/300 - Train loss: 0.23270374536514282, Validation loss: 0.24186845123767853
Epoch: 160/300 - Train loss: 0.2319265604019165, Validation loss: 0.24139468371868134
Epoch: 161/300 - Train loss: 0.23115845024585724, Validation loss: 0.24111440777778625
Epoch: 162/300 - Train loss: 0.2303992211818695, Validation loss: 0.23980765044689178
Epoch: 163/300 - Train loss: 0.22964884340763092, Validation loss: 0.23891019821166992
Epoch: 164/300 - Train loss: 0.22890719771385193, Validation loss: 0.23883573710918427
Epoch: 165/300 - Train loss: 0.2281741350889206, Validation loss: 0.23780684173107147
Epoch: 166/300 - Train loss: 0.22744950652122498, Validation loss: 0.23743389546871185
Epoch: 167/300 - Train loss: 0.22673320770263672, Validation loss: 0.2361062616109848
Epoch: 168/300 - Train loss: 0.2260250598192215, Validation loss: 0.23555952310562134
Epoch: 169/300 - Train loss: 0.22532497346401215, Validation loss: 0.23498179018497467
Epoch: 170/300 - Train loss: 0.22463282942771912, Validation loss: 0.23421552777290344
Epoch: 171/300 - Train loss: 0.22394849359989166, Validation loss: 0.23349273204803467
Epoch: 172/300 - Train loss: 0.22327184677124023, Validation loss: 0.23306743800640106
Epoch: 173/300 - Train loss: 0.22260285913944244, Validation loss: 0.23234494030475616
Epoch: 174/300 - Train loss: 0.22194133698940277, Validation loss: 0.2316843718290329
Epoch: 175/300 - Train loss: 0.22128725051879883, Validation loss: 0.2314283698797226
Epoch: 176/300 - Train loss: 0.2206404060125351, Validation loss: 0.2304401695728302
Epoch: 177/300 - Train loss: 0.22000078856945038, Validation loss: 0.22960548102855682
Epoch: 178/300 - Train loss: 0.21936820447444916, Validation loss: 0.22883519530296326
Epoch: 179/300 - Train loss: 0.21874259412288666, Validation loss: 0.2281980961561203
Epoch: 180/300 - Train loss: 0.21812386810779572, Validation loss: 0.22793999314308167
Epoch: 181/300 - Train loss: 0.21751189231872559, Validation loss: 0.22709524631500244
Epoch: 182/300 - Train loss: 0.2169066071510315, Validation loss: 0.22652283310890198
Epoch: 183/300 - Train loss: 0.21630795300006866, Validation loss: 0.22613757848739624
Epoch: 184/300 - Train loss: 0.21571579575538635, Validation loss: 0.22551000118255615
Epoch: 185/300 - Train loss: 0.21513007581233978, Validation loss: 0.22554020583629608
