Epoch: 1/200 - Train loss: 0.5993711352348328, Validation loss: 0.5378804802894592
Epoch: 2/200 - Train loss: 0.5094817876815796, Validation loss: 0.4839420020580292
Epoch: 3/200 - Train loss: 0.4588918685913086, Validation loss: 0.44309961795806885
Epoch: 4/200 - Train loss: 0.42359963059425354, Validation loss: 0.4161125719547272
Epoch: 5/200 - Train loss: 0.3992067575454712, Validation loss: 0.40237101912498474
Epoch: 6/200 - Train loss: 0.37911614775657654, Validation loss: 0.37739241123199463
Epoch: 7/200 - Train loss: 0.3603370487689972, Validation loss: 0.36251646280288696
Epoch: 8/200 - Train loss: 0.34355008602142334, Validation loss: 0.34684646129608154
Epoch: 9/200 - Train loss: 0.32845932245254517, Validation loss: 0.3343520164489746
Epoch: 10/200 - Train loss: 0.3187006413936615, Validation loss: 0.32224544882774353
Epoch: 11/200 - Train loss: 0.3061070740222931, Validation loss: 0.31183335185050964
Epoch: 12/200 - Train loss: 0.29587048292160034, Validation loss: 0.30352386832237244
Epoch: 13/200 - Train loss: 0.28490516543388367, Validation loss: 0.29891228675842285
Epoch: 14/200 - Train loss: 0.2757517397403717, Validation loss: 0.28696209192276
Epoch: 15/200 - Train loss: 0.2675735056400299, Validation loss: 0.28401076793670654
Epoch: 16/200 - Train loss: 0.2603831887245178, Validation loss: 0.277319997549057
Epoch: 17/200 - Train loss: 0.25356432795524597, Validation loss: 0.2727496027946472
Epoch: 18/200 - Train loss: 0.24825595319271088, Validation loss: 0.2794634699821472
Epoch: 19/200 - Train loss: 0.24313241243362427, Validation loss: 0.2635665833950043
Epoch: 20/200 - Train loss: 0.23859618604183197, Validation loss: 0.26126208901405334
Epoch: 21/200 - Train loss: 0.23426680266857147, Validation loss: 0.2585456073284149
Epoch: 22/200 - Train loss: 0.23041951656341553, Validation loss: 0.25764644145965576
Epoch: 23/200 - Train loss: 0.2234864979982376, Validation loss: 0.2644149363040924
Epoch: 24/200 - Train loss: 0.22011318802833557, Validation loss: 0.2644708752632141
Epoch: 25/200 - Train loss: 0.21760587394237518, Validation loss: 0.2512567341327667
Epoch: 26/200 - Train loss: 0.21466097235679626, Validation loss: 0.2645549178123474
Epoch: 27/200 - Train loss: 0.2125675082206726, Validation loss: 0.26023027300834656
Epoch: 28/200 - Train loss: 0.20833410322666168, Validation loss: 0.26048001646995544
Epoch: 29/200 - Train loss: 0.20644672214984894, Validation loss: 0.25954586267471313
Epoch: 30/200 - Train loss: 0.20503219962120056, Validation loss: 0.260912150144577
Epoch: 31/200 - Train loss: 0.20303010940551758, Validation loss: 0.2590028941631317
Epoch: 32/200 - Train loss: 0.20077529549598694, Validation loss: 0.25965967774391174
Epoch: 33/200 - Train loss: 0.19951818883419037, Validation loss: 0.2599726617336273
Epoch: 34/200 - Train loss: 0.1974753737449646, Validation loss: 0.2703145146369934
Epoch: 35/200 - Train loss: 0.19593341648578644, Validation loss: 0.27218011021614075
Epoch: 36/200 - Train loss: 0.19490060210227966, Validation loss: 0.2696665823459625
Epoch: 37/200 - Train loss: 0.19677872955799103, Validation loss: 0.2632994055747986
Epoch: 38/200 - Train loss: 0.19183585047721863, Validation loss: 0.26964256167411804
Epoch: 39/200 - Train loss: 0.1941026747226715, Validation loss: 0.2683541178703308
Epoch: 40/200 - Train loss: 0.18901216983795166, Validation loss: 0.2594327926635742
Epoch: 41/200 - Train loss: 0.18807120621204376, Validation loss: 0.25848063826560974
Epoch: 42/200 - Train loss: 0.18679356575012207, Validation loss: 0.2688193619251251
Epoch: 43/200 - Train loss: 0.18849751353263855, Validation loss: 0.27292972803115845
Epoch: 44/200 - Train loss: 0.19062107801437378, Validation loss: 0.2631961405277252
Epoch: 45/200 - Train loss: 0.18694961071014404, Validation loss: 0.26948603987693787
Epoch: 46/200 - Train loss: 0.18239432573318481, Validation loss: 0.2578984498977661
Epoch: 47/200 - Train loss: 0.18250858783721924, Validation loss: 0.2576676607131958
Epoch: 48/200 - Train loss: 0.18107949197292328, Validation loss: 0.26999548077583313
Epoch: 49/200 - Train loss: 0.18617680668830872, Validation loss: 0.26922670006752014
Epoch: 50/200 - Train loss: 0.18525932729244232, Validation loss: 0.26952841877937317
Epoch: 51/200 - Train loss: 0.18437987565994263, Validation loss: 0.27179548144340515
Epoch: 52/200 - Train loss: 0.1849060356616974, Validation loss: 0.25798043608665466
Epoch: 53/200 - Train loss: 0.18312886357307434, Validation loss: 0.26921284198760986
Epoch: 54/200 - Train loss: 0.18223269283771515, Validation loss: 0.2682199478149414
Epoch: 55/200 - Train loss: 0.1823907047510147, Validation loss: 0.26920652389526367
Epoch: 56/200 - Train loss: 0.17864365875720978, Validation loss: 0.2576458752155304
Epoch: 57/200 - Train loss: 0.18077664077281952, Validation loss: 0.25581344962120056
Epoch: 58/200 - Train loss: 0.1763882040977478, Validation loss: 0.25829896330833435
Epoch: 59/200 - Train loss: 0.17916245758533478, Validation loss: 0.27489134669303894
Epoch: 60/200 - Train loss: 0.17886103689670563, Validation loss: 0.2697168290615082
Epoch: 61/200 - Train loss: 0.17892134189605713, Validation loss: 0.27278652787208557
Epoch: 62/200 - Train loss: 0.17508989572525024, Validation loss: 0.2609550654888153
Epoch: 63/200 - Train loss: 0.17426557838916779, Validation loss: 0.26951247453689575
Epoch: 64/200 - Train loss: 0.1767907589673996, Validation loss: 0.27474915981292725
Epoch: 65/200 - Train loss: 0.17621168494224548, Validation loss: 0.27010947465896606
Epoch: 66/200 - Train loss: 0.17314447462558746, Validation loss: 0.2727283239364624
Epoch: 67/200 - Train loss: 0.17238017916679382, Validation loss: 0.2719816267490387
Epoch: 68/200 - Train loss: 0.17524577677249908, Validation loss: 0.2716135084629059
Epoch: 69/200 - Train loss: 0.1712101250886917, Validation loss: 0.27211329340934753
Epoch: 70/200 - Train loss: 0.1714785397052765, Validation loss: 0.2734132707118988
Epoch: 71/200 - Train loss: 0.17108815908432007, Validation loss: 0.27505892515182495
Epoch: 72/200 - Train loss: 0.17030343413352966, Validation loss: 0.27353614568710327
Epoch: 73/200 - Train loss: 0.170042023062706, Validation loss: 0.271785169839859
