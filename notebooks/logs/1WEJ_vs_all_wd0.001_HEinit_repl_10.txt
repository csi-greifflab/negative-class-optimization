Epoch: 1/300 - Train loss: 0.7067325711250305, Validation loss: 0.7021148800849915
Epoch: 2/300 - Train loss: 0.7036523818969727, Validation loss: 0.6994023323059082
Epoch: 3/300 - Train loss: 0.7007269263267517, Validation loss: 0.6967746615409851
Epoch: 4/300 - Train loss: 0.6979400515556335, Validation loss: 0.6941314935684204
Epoch: 5/300 - Train loss: 0.6952817440032959, Validation loss: 0.6915274262428284
Epoch: 6/300 - Train loss: 0.6927366256713867, Validation loss: 0.6892140507698059
Epoch: 7/300 - Train loss: 0.6902859807014465, Validation loss: 0.6870258450508118
Epoch: 8/300 - Train loss: 0.6879098415374756, Validation loss: 0.6848971843719482
Epoch: 9/300 - Train loss: 0.6855853199958801, Validation loss: 0.6824792623519897
Epoch: 10/300 - Train loss: 0.6832914352416992, Validation loss: 0.6804060339927673
Epoch: 11/300 - Train loss: 0.6810120344161987, Validation loss: 0.6779894232749939
Epoch: 12/300 - Train loss: 0.6787300109863281, Validation loss: 0.6757743954658508
Epoch: 13/300 - Train loss: 0.6764281392097473, Validation loss: 0.6736453771591187
Epoch: 14/300 - Train loss: 0.6740933060646057, Validation loss: 0.6714492440223694
Epoch: 15/300 - Train loss: 0.6717159152030945, Validation loss: 0.6691631078720093
Epoch: 16/300 - Train loss: 0.6692782044410706, Validation loss: 0.6666286587715149
Epoch: 17/300 - Train loss: 0.6667686104774475, Validation loss: 0.6641445755958557
Epoch: 18/300 - Train loss: 0.66417396068573, Validation loss: 0.6616029143333435
Epoch: 19/300 - Train loss: 0.6614913940429688, Validation loss: 0.6588207483291626
Epoch: 20/300 - Train loss: 0.6587115526199341, Validation loss: 0.655988335609436
Epoch: 21/300 - Train loss: 0.6558237075805664, Validation loss: 0.6532415151596069
Epoch: 22/300 - Train loss: 0.6528258323669434, Validation loss: 0.6500488519668579
Epoch: 23/300 - Train loss: 0.6497166156768799, Validation loss: 0.6471461057662964
Epoch: 24/300 - Train loss: 0.6464954018592834, Validation loss: 0.643761396408081
Epoch: 25/300 - Train loss: 0.6431578397750854, Validation loss: 0.6405465006828308
Epoch: 26/300 - Train loss: 0.6397049427032471, Validation loss: 0.6369605660438538
Epoch: 27/300 - Train loss: 0.636143147945404, Validation loss: 0.6333847641944885
Epoch: 28/300 - Train loss: 0.6324702501296997, Validation loss: 0.6296709775924683
Epoch: 29/300 - Train loss: 0.6286891102790833, Validation loss: 0.6259391903877258
Epoch: 30/300 - Train loss: 0.6248083710670471, Validation loss: 0.6220002174377441
Epoch: 31/300 - Train loss: 0.6208319664001465, Validation loss: 0.6179876923561096
Epoch: 32/300 - Train loss: 0.616766631603241, Validation loss: 0.6139867901802063
Epoch: 33/300 - Train loss: 0.6126174926757812, Validation loss: 0.6096917390823364
Epoch: 34/300 - Train loss: 0.6083888411521912, Validation loss: 0.6053968071937561
Epoch: 35/300 - Train loss: 0.6040779948234558, Validation loss: 0.6014025807380676
Epoch: 36/300 - Train loss: 0.5996966361999512, Validation loss: 0.5970643758773804
Epoch: 37/300 - Train loss: 0.595259964466095, Validation loss: 0.5924349427223206
Epoch: 38/300 - Train loss: 0.5907720327377319, Validation loss: 0.5880417823791504
Epoch: 39/300 - Train loss: 0.5862340331077576, Validation loss: 0.583311915397644
Epoch: 40/300 - Train loss: 0.5816541910171509, Validation loss: 0.578942596912384
Epoch: 41/300 - Train loss: 0.5770441293716431, Validation loss: 0.5743318796157837
Epoch: 42/300 - Train loss: 0.5724107027053833, Validation loss: 0.5695680975914001
Epoch: 43/300 - Train loss: 0.5677574872970581, Validation loss: 0.5654073357582092
Epoch: 44/300 - Train loss: 0.5630938410758972, Validation loss: 0.5602765679359436
Epoch: 45/300 - Train loss: 0.5584219694137573, Validation loss: 0.5557063817977905
Epoch: 46/300 - Train loss: 0.5537468194961548, Validation loss: 0.5512318015098572
Epoch: 47/300 - Train loss: 0.5490763783454895, Validation loss: 0.5463227033615112
Epoch: 48/300 - Train loss: 0.5444155335426331, Validation loss: 0.541722297668457
Epoch: 49/300 - Train loss: 0.5397740602493286, Validation loss: 0.5370833873748779
Epoch: 50/300 - Train loss: 0.5351545810699463, Validation loss: 0.5324130058288574
Epoch: 51/300 - Train loss: 0.5305631756782532, Validation loss: 0.5282159447669983
Epoch: 52/300 - Train loss: 0.5260104537010193, Validation loss: 0.5236707925796509
Epoch: 53/300 - Train loss: 0.5214976668357849, Validation loss: 0.5192792415618896
Epoch: 54/300 - Train loss: 0.5170332789421082, Validation loss: 0.5144813656806946
Epoch: 55/300 - Train loss: 0.5126209855079651, Validation loss: 0.5102792978286743
Epoch: 56/300 - Train loss: 0.5082616209983826, Validation loss: 0.505921483039856
Epoch: 57/300 - Train loss: 0.5039631128311157, Validation loss: 0.5020269155502319
Epoch: 58/300 - Train loss: 0.4997275769710541, Validation loss: 0.4974287152290344
Epoch: 59/300 - Train loss: 0.4955626130104065, Validation loss: 0.49356886744499207
Epoch: 60/300 - Train loss: 0.49147653579711914, Validation loss: 0.4892929792404175
Epoch: 61/300 - Train loss: 0.4874732196331024, Validation loss: 0.48523202538490295
Epoch: 62/300 - Train loss: 0.4835575520992279, Validation loss: 0.4819844663143158
Epoch: 63/300 - Train loss: 0.4797322154045105, Validation loss: 0.4773556888103485
Epoch: 64/300 - Train loss: 0.47600090503692627, Validation loss: 0.47355154156684875
Epoch: 65/300 - Train loss: 0.472362756729126, Validation loss: 0.4703788161277771
Epoch: 66/300 - Train loss: 0.46881887316703796, Validation loss: 0.46678096055984497
Epoch: 67/300 - Train loss: 0.46537116169929504, Validation loss: 0.4634280204772949
Epoch: 68/300 - Train loss: 0.462019145488739, Validation loss: 0.46008002758026123
Epoch: 69/300 - Train loss: 0.4587608873844147, Validation loss: 0.4569776654243469
Epoch: 70/300 - Train loss: 0.45559588074684143, Validation loss: 0.45341405272483826
Epoch: 71/300 - Train loss: 0.4525238871574402, Validation loss: 0.45042628049850464
Epoch: 72/300 - Train loss: 0.449543297290802, Validation loss: 0.4475633203983307
Epoch: 73/300 - Train loss: 0.44665271043777466, Validation loss: 0.44519075751304626
Epoch: 74/300 - Train loss: 0.4438510835170746, Validation loss: 0.44192856550216675
Epoch: 75/300 - Train loss: 0.4411375820636749, Validation loss: 0.4392571747303009
Epoch: 76/300 - Train loss: 0.4385092556476593, Validation loss: 0.437264084815979
Epoch: 77/300 - Train loss: 0.4359651803970337, Validation loss: 0.43459567427635193
Epoch: 78/300 - Train loss: 0.433503121137619, Validation loss: 0.43195557594299316
Epoch: 79/300 - Train loss: 0.4311203062534332, Validation loss: 0.4298678934574127
Epoch: 80/300 - Train loss: 0.42881491780281067, Validation loss: 0.42730021476745605
Epoch: 81/300 - Train loss: 0.42658576369285583, Validation loss: 0.4246702492237091
Epoch: 82/300 - Train loss: 0.42443087697029114, Validation loss: 0.42260265350341797
Epoch: 83/300 - Train loss: 0.4223487377166748, Validation loss: 0.4212948977947235
Epoch: 84/300 - Train loss: 0.4203376770019531, Validation loss: 0.4186718165874481
Epoch: 85/300 - Train loss: 0.4183947443962097, Validation loss: 0.41683799028396606
Epoch: 86/300 - Train loss: 0.4165179431438446, Validation loss: 0.4149104058742523
Epoch: 87/300 - Train loss: 0.4147050976753235, Validation loss: 0.4131479263305664
Epoch: 88/300 - Train loss: 0.41295403242111206, Validation loss: 0.4117134213447571
Epoch: 89/300 - Train loss: 0.4112622141838074, Validation loss: 0.4087725281715393
Epoch: 90/300 - Train loss: 0.409627228975296, Validation loss: 0.4079338610172272
Epoch: 91/300 - Train loss: 0.408047080039978, Validation loss: 0.40663856267929077
Epoch: 92/300 - Train loss: 0.40651994943618774, Validation loss: 0.4044610857963562
Epoch: 93/300 - Train loss: 0.40504351258277893, Validation loss: 0.40357884764671326
Epoch: 94/300 - Train loss: 0.4036155343055725, Validation loss: 0.4018027186393738
Epoch: 95/300 - Train loss: 0.40223318338394165, Validation loss: 0.4007314443588257
Epoch: 96/300 - Train loss: 0.40089336037635803, Validation loss: 0.39891374111175537
Epoch: 97/300 - Train loss: 0.39959561824798584, Validation loss: 0.3971863389015198
Epoch: 98/300 - Train loss: 0.3983383774757385, Validation loss: 0.3963775038719177
Epoch: 99/300 - Train loss: 0.39711982011795044, Validation loss: 0.39525800943374634
Epoch: 100/300 - Train loss: 0.39593803882598877, Validation loss: 0.39372238516807556
Epoch: 101/300 - Train loss: 0.39479124546051025, Validation loss: 0.3928978443145752
Epoch: 102/300 - Train loss: 0.39367806911468506, Validation loss: 0.3916959762573242
Epoch: 103/300 - Train loss: 0.39259737730026245, Validation loss: 0.3906759023666382
Epoch: 104/300 - Train loss: 0.3915480971336365, Validation loss: 0.3894789516925812
Epoch: 105/300 - Train loss: 0.39052772521972656, Validation loss: 0.3886423110961914
Epoch: 106/300 - Train loss: 0.3895358145236969, Validation loss: 0.38742122054100037
Epoch: 107/300 - Train loss: 0.3885708749294281, Validation loss: 0.38653892278671265
Epoch: 108/300 - Train loss: 0.38763144612312317, Validation loss: 0.38598713278770447
Epoch: 109/300 - Train loss: 0.3867165446281433, Validation loss: 0.38438278436660767
Epoch: 110/300 - Train loss: 0.38582491874694824, Validation loss: 0.38384050130844116
Epoch: 111/300 - Train loss: 0.38495495915412903, Validation loss: 0.38324815034866333
Epoch: 112/300 - Train loss: 0.3841060996055603, Validation loss: 0.38239219784736633
Epoch: 113/300 - Train loss: 0.3832769989967346, Validation loss: 0.38121309876441956
Epoch: 114/300 - Train loss: 0.38246747851371765, Validation loss: 0.38087883591651917
Epoch: 115/300 - Train loss: 0.3816770017147064, Validation loss: 0.37957969307899475
Epoch: 116/300 - Train loss: 0.3809051513671875, Validation loss: 0.3787284195423126
Epoch: 117/300 - Train loss: 0.38015061616897583, Validation loss: 0.37781351804733276
Epoch: 118/300 - Train loss: 0.3794117867946625, Validation loss: 0.3767581582069397
Epoch: 119/300 - Train loss: 0.3786872923374176, Validation loss: 0.37672823667526245
Epoch: 120/300 - Train loss: 0.37797680497169495, Validation loss: 0.3756532669067383
Epoch: 121/300 - Train loss: 0.37727972865104675, Validation loss: 0.3745780289173126
Epoch: 122/300 - Train loss: 0.37659525871276855, Validation loss: 0.37405163049697876
Epoch: 123/300 - Train loss: 0.3759223222732544, Validation loss: 0.37335363030433655
Epoch: 124/300 - Train loss: 0.3752608299255371, Validation loss: 0.3727349638938904
Epoch: 125/300 - Train loss: 0.37460991740226746, Validation loss: 0.37229132652282715
Epoch: 126/300 - Train loss: 0.37397000193595886, Validation loss: 0.37145084142684937
Epoch: 127/300 - Train loss: 0.37334153056144714, Validation loss: 0.3712488114833832
Epoch: 128/300 - Train loss: 0.37272417545318604, Validation loss: 0.37008824944496155
Epoch: 129/300 - Train loss: 0.3721177279949188, Validation loss: 0.36954382061958313
Epoch: 130/300 - Train loss: 0.37152132391929626, Validation loss: 0.3695286214351654
Epoch: 131/300 - Train loss: 0.37093499302864075, Validation loss: 0.36815959215164185
Epoch: 132/300 - Train loss: 0.37035760283470154, Validation loss: 0.36767780780792236
Epoch: 133/300 - Train loss: 0.3697890341281891, Validation loss: 0.36678168177604675
Epoch: 134/300 - Train loss: 0.3692284822463989, Validation loss: 0.3665151596069336
Epoch: 135/300 - Train loss: 0.36867600679397583, Validation loss: 0.3659687638282776
Epoch: 136/300 - Train loss: 0.36813095211982727, Validation loss: 0.3652763366699219
Epoch: 137/300 - Train loss: 0.36759302020072937, Validation loss: 0.36525869369506836
