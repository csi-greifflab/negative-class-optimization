Epoch: 1/200 - Train loss: 0.6972998976707458, Validation loss: 0.6954622864723206
Epoch: 2/200 - Train loss: 0.6956025958061218, Validation loss: 0.6929579377174377
Epoch: 3/200 - Train loss: 0.691817581653595, Validation loss: 0.6880621314048767
Epoch: 4/200 - Train loss: 0.682288646697998, Validation loss: 0.668387234210968
Epoch: 5/200 - Train loss: 0.6550253033638, Validation loss: 0.6427801847457886
Epoch: 6/200 - Train loss: 0.628666877746582, Validation loss: 0.618152916431427
Epoch: 7/200 - Train loss: 0.6034662127494812, Validation loss: 0.5948262214660645
Epoch: 8/200 - Train loss: 0.5802222490310669, Validation loss: 0.5739523768424988
Epoch: 9/200 - Train loss: 0.5601390600204468, Validation loss: 0.5565152764320374
Epoch: 10/200 - Train loss: 0.5431514382362366, Validation loss: 0.5426140427589417
Epoch: 11/200 - Train loss: 0.5293675661087036, Validation loss: 0.5299880504608154
Epoch: 12/200 - Train loss: 0.5166895985603333, Validation loss: 0.5202914476394653
Epoch: 13/200 - Train loss: 0.5069627165794373, Validation loss: 0.5123271942138672
Epoch: 14/200 - Train loss: 0.498831182718277, Validation loss: 0.5054836273193359
Epoch: 15/200 - Train loss: 0.4928117096424103, Validation loss: 0.5006087422370911
Epoch: 16/200 - Train loss: 0.4873993992805481, Validation loss: 0.49592462182044983
Epoch: 17/200 - Train loss: 0.48330432176589966, Validation loss: 0.4923529624938965
Epoch: 18/200 - Train loss: 0.4787209928035736, Validation loss: 0.4888572692871094
Epoch: 19/200 - Train loss: 0.4745491147041321, Validation loss: 0.4852154552936554
Epoch: 20/200 - Train loss: 0.471230149269104, Validation loss: 0.4813806712627411
Epoch: 21/200 - Train loss: 0.4674704670906067, Validation loss: 0.4786285161972046
Epoch: 22/200 - Train loss: 0.4642687439918518, Validation loss: 0.4754457473754883
Epoch: 23/200 - Train loss: 0.4609101414680481, Validation loss: 0.47221583127975464
Epoch: 24/200 - Train loss: 0.4571206867694855, Validation loss: 0.469545841217041
Epoch: 25/200 - Train loss: 0.45431050658226013, Validation loss: 0.46672290563583374
Epoch: 26/200 - Train loss: 0.45072638988494873, Validation loss: 0.46473610401153564
Epoch: 27/200 - Train loss: 0.44794854521751404, Validation loss: 0.4607882797718048
Epoch: 28/200 - Train loss: 0.44454634189605713, Validation loss: 0.4588049352169037
Epoch: 29/200 - Train loss: 0.4416515529155731, Validation loss: 0.4559251070022583
Epoch: 30/200 - Train loss: 0.4387156069278717, Validation loss: 0.45301809906959534
Epoch: 31/200 - Train loss: 0.43591436743736267, Validation loss: 0.4500746726989746
Epoch: 32/200 - Train loss: 0.432797908782959, Validation loss: 0.44737428426742554
Epoch: 33/200 - Train loss: 0.43034806847572327, Validation loss: 0.44567736983299255
Epoch: 34/200 - Train loss: 0.4277362525463104, Validation loss: 0.44338440895080566
Epoch: 35/200 - Train loss: 0.42488762736320496, Validation loss: 0.4407704174518585
Epoch: 36/200 - Train loss: 0.42269229888916016, Validation loss: 0.4384118914604187
Epoch: 37/200 - Train loss: 0.41988512873649597, Validation loss: 0.43576517701148987
Epoch: 38/200 - Train loss: 0.41750475764274597, Validation loss: 0.43368396162986755
Epoch: 39/200 - Train loss: 0.41498568654060364, Validation loss: 0.43189528584480286
Epoch: 40/200 - Train loss: 0.41297978162765503, Validation loss: 0.42971181869506836
Epoch: 41/200 - Train loss: 0.41062411665916443, Validation loss: 0.42826709151268005
Epoch: 42/200 - Train loss: 0.4081317186355591, Validation loss: 0.425184428691864
Epoch: 43/200 - Train loss: 0.40635621547698975, Validation loss: 0.42295247316360474
Epoch: 44/200 - Train loss: 0.40357550978660583, Validation loss: 0.42141324281692505
Epoch: 45/200 - Train loss: 0.4014846980571747, Validation loss: 0.42024320363998413
Epoch: 46/200 - Train loss: 0.3997899889945984, Validation loss: 0.41900891065597534
Epoch: 47/200 - Train loss: 0.39742591977119446, Validation loss: 0.4161217212677002
Epoch: 48/200 - Train loss: 0.395600825548172, Validation loss: 0.4145241975784302
Epoch: 49/200 - Train loss: 0.3937914967536926, Validation loss: 0.41282981634140015
Epoch: 50/200 - Train loss: 0.391754686832428, Validation loss: 0.41207098960876465
Epoch: 51/200 - Train loss: 0.3901500999927521, Validation loss: 0.40989580750465393
Epoch: 52/200 - Train loss: 0.3879597783088684, Validation loss: 0.40838029980659485
Epoch: 53/200 - Train loss: 0.38656872510910034, Validation loss: 0.4070092439651489
Epoch: 54/200 - Train loss: 0.38463732600212097, Validation loss: 0.40493881702423096
Epoch: 55/200 - Train loss: 0.3827844262123108, Validation loss: 0.40396496653556824
Epoch: 56/200 - Train loss: 0.3817065954208374, Validation loss: 0.4021192491054535
Epoch: 57/200 - Train loss: 0.3794362246990204, Validation loss: 0.4009900987148285
Epoch: 58/200 - Train loss: 0.37819182872772217, Validation loss: 0.39965686202049255
Epoch: 59/200 - Train loss: 0.3762824237346649, Validation loss: 0.3980916738510132
Epoch: 60/200 - Train loss: 0.374784380197525, Validation loss: 0.39695194363594055
Epoch: 61/200 - Train loss: 0.3733256161212921, Validation loss: 0.39591115713119507
Epoch: 62/200 - Train loss: 0.3716355562210083, Validation loss: 0.39534106850624084
Epoch: 63/200 - Train loss: 0.37032952904701233, Validation loss: 0.3930418789386749
Epoch: 64/200 - Train loss: 0.36880066990852356, Validation loss: 0.3916511535644531
Epoch: 65/200 - Train loss: 0.3675341308116913, Validation loss: 0.3906630575656891
Epoch: 66/200 - Train loss: 0.3658154010772705, Validation loss: 0.38991427421569824
Epoch: 67/200 - Train loss: 0.3645637035369873, Validation loss: 0.38868409395217896
Epoch: 68/200 - Train loss: 0.36276775598526, Validation loss: 0.388529509305954
Epoch: 69/200 - Train loss: 0.3611465096473694, Validation loss: 0.38580405712127686
Epoch: 70/200 - Train loss: 0.3598918318748474, Validation loss: 0.38511621952056885
Epoch: 71/200 - Train loss: 0.3582872152328491, Validation loss: 0.3842289447784424
Epoch: 72/200 - Train loss: 0.35698264837265015, Validation loss: 0.38256123661994934
Epoch: 73/200 - Train loss: 0.35525938868522644, Validation loss: 0.3819802403450012
Epoch: 74/200 - Train loss: 0.3538398742675781, Validation loss: 0.3811018466949463
Epoch: 75/200 - Train loss: 0.3521910607814789, Validation loss: 0.3793676197528839
Epoch: 76/200 - Train loss: 0.3511379659175873, Validation loss: 0.3777466118335724
Epoch: 77/200 - Train loss: 0.3492397367954254, Validation loss: 0.37635117769241333
Epoch: 78/200 - Train loss: 0.34824246168136597, Validation loss: 0.3751735985279083
Epoch: 79/200 - Train loss: 0.3467310070991516, Validation loss: 0.37470489740371704
Epoch: 80/200 - Train loss: 0.34523898363113403, Validation loss: 0.3736242353916168
Epoch: 81/200 - Train loss: 0.34373441338539124, Validation loss: 0.3719426691532135
Epoch: 82/200 - Train loss: 0.34268811345100403, Validation loss: 0.37093502283096313
Epoch: 83/200 - Train loss: 0.34098634123802185, Validation loss: 0.3702123761177063
Epoch: 84/200 - Train loss: 0.34022510051727295, Validation loss: 0.36958834528923035
Epoch: 85/200 - Train loss: 0.3387756943702698, Validation loss: 0.3677399754524231
Epoch: 86/200 - Train loss: 0.33727195858955383, Validation loss: 0.3663007616996765
Epoch: 87/200 - Train loss: 0.3359301686286926, Validation loss: 0.36572399735450745
Epoch: 88/200 - Train loss: 0.3348192274570465, Validation loss: 0.36420226097106934
Epoch: 89/200 - Train loss: 0.3334735631942749, Validation loss: 0.3640305697917938
Epoch: 90/200 - Train loss: 0.3322660028934479, Validation loss: 0.36205199360847473
Epoch: 91/200 - Train loss: 0.330765038728714, Validation loss: 0.3610641360282898
Epoch: 92/200 - Train loss: 0.32941699028015137, Validation loss: 0.36001303791999817
Epoch: 93/200 - Train loss: 0.3285398781299591, Validation loss: 0.35858091711997986
Epoch: 94/200 - Train loss: 0.327364057302475, Validation loss: 0.3582700490951538
Epoch: 95/200 - Train loss: 0.3262117803096771, Validation loss: 0.3571873605251312
Epoch: 96/200 - Train loss: 0.3246428966522217, Validation loss: 0.3560248613357544
Epoch: 97/200 - Train loss: 0.32392436265945435, Validation loss: 0.3550328314304352
Epoch: 98/200 - Train loss: 0.32245051860809326, Validation loss: 0.3538069427013397
Epoch: 99/200 - Train loss: 0.3214852511882782, Validation loss: 0.35307949781417847
Epoch: 100/200 - Train loss: 0.3201606273651123, Validation loss: 0.35232406854629517
Epoch: 101/200 - Train loss: 0.3192594647407532, Validation loss: 0.35089465975761414
Epoch: 102/200 - Train loss: 0.31815966963768005, Validation loss: 0.3508463501930237
Epoch: 103/200 - Train loss: 0.3168865144252777, Validation loss: 0.34897351264953613
Epoch: 104/200 - Train loss: 0.3160395324230194, Validation loss: 0.3484472632408142
Epoch: 105/200 - Train loss: 0.31494414806365967, Validation loss: 0.34733638167381287
Epoch: 106/200 - Train loss: 0.31372684240341187, Validation loss: 0.3466234803199768
Epoch: 107/200 - Train loss: 0.3129538595676422, Validation loss: 0.34492406249046326
Epoch: 108/200 - Train loss: 0.31177330017089844, Validation loss: 0.3455580472946167
Epoch: 109/200 - Train loss: 0.3106575906276703, Validation loss: 0.34395235776901245
Epoch: 110/200 - Train loss: 0.309460312128067, Validation loss: 0.3430326581001282
Epoch: 111/200 - Train loss: 0.30845677852630615, Validation loss: 0.34203293919563293
Epoch: 112/200 - Train loss: 0.3080303370952606, Validation loss: 0.341111421585083
Epoch: 113/200 - Train loss: 0.3074707090854645, Validation loss: 0.341574490070343
Epoch: 114/200 - Train loss: 0.30587729811668396, Validation loss: 0.33973315358161926
Epoch: 115/200 - Train loss: 0.30541491508483887, Validation loss: 0.33937928080558777
Epoch: 116/200 - Train loss: 0.3038409948348999, Validation loss: 0.3388367295265198
Epoch: 117/200 - Train loss: 0.3029935657978058, Validation loss: 0.33846792578697205
Epoch: 118/200 - Train loss: 0.30253034830093384, Validation loss: 0.3378053903579712
Epoch: 119/200 - Train loss: 0.30164429545402527, Validation loss: 0.33678528666496277
Epoch: 120/200 - Train loss: 0.3005225658416748, Validation loss: 0.33497604727745056
Epoch: 121/200 - Train loss: 0.29989174008369446, Validation loss: 0.3352116048336029
Epoch: 122/200 - Train loss: 0.2989044785499573, Validation loss: 0.3341112732887268
Epoch: 123/200 - Train loss: 0.29814285039901733, Validation loss: 0.33408603072166443
Epoch: 124/200 - Train loss: 0.29774653911590576, Validation loss: 0.333260715007782
Epoch: 125/200 - Train loss: 0.29676222801208496, Validation loss: 0.3332678973674774
Epoch: 126/200 - Train loss: 0.2960284650325775, Validation loss: 0.3314186930656433
Epoch: 127/200 - Train loss: 0.29531577229499817, Validation loss: 0.33054307103157043
Epoch: 128/200 - Train loss: 0.29436108469963074, Validation loss: 0.3307132422924042
Epoch: 129/200 - Train loss: 0.29382961988449097, Validation loss: 0.33049264550209045
