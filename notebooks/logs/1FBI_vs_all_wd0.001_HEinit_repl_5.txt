Epoch: 1/300 - Train loss: 0.6986638307571411, Validation loss: 0.6930462121963501
Epoch: 2/300 - Train loss: 0.6949219703674316, Validation loss: 0.6892951130867004
Epoch: 3/300 - Train loss: 0.6913019418716431, Validation loss: 0.6857390403747559
Epoch: 4/300 - Train loss: 0.6877867579460144, Validation loss: 0.6822378635406494
Epoch: 5/300 - Train loss: 0.6843529343605042, Validation loss: 0.6786901950836182
Epoch: 6/300 - Train loss: 0.6809804439544678, Validation loss: 0.6753190755844116
Epoch: 7/300 - Train loss: 0.6776403188705444, Validation loss: 0.6717668771743774
Epoch: 8/300 - Train loss: 0.674312949180603, Validation loss: 0.6683788299560547
Epoch: 9/300 - Train loss: 0.6709776520729065, Validation loss: 0.6649608016014099
Epoch: 10/300 - Train loss: 0.6676151156425476, Validation loss: 0.6614699959754944
Epoch: 11/300 - Train loss: 0.6642137169837952, Validation loss: 0.657828688621521
Epoch: 12/300 - Train loss: 0.6607620716094971, Validation loss: 0.6543028354644775
Epoch: 13/300 - Train loss: 0.6572432518005371, Validation loss: 0.6505313515663147
Epoch: 14/300 - Train loss: 0.653643786907196, Validation loss: 0.6468262672424316
Epoch: 15/300 - Train loss: 0.6499521732330322, Validation loss: 0.6429591178894043
Epoch: 16/300 - Train loss: 0.6461598873138428, Validation loss: 0.6387671828269958
Epoch: 17/300 - Train loss: 0.6422600746154785, Validation loss: 0.6346979737281799
Epoch: 18/300 - Train loss: 0.6382431387901306, Validation loss: 0.6304908394813538
Epoch: 19/300 - Train loss: 0.6341019868850708, Validation loss: 0.6261131167411804
Epoch: 20/300 - Train loss: 0.629835844039917, Validation loss: 0.6215845346450806
Epoch: 21/300 - Train loss: 0.625442385673523, Validation loss: 0.6170608997344971
Epoch: 22/300 - Train loss: 0.6209213137626648, Validation loss: 0.6121967434883118
Epoch: 23/300 - Train loss: 0.616269588470459, Validation loss: 0.6073787808418274
Epoch: 24/300 - Train loss: 0.6114873290061951, Validation loss: 0.6022989153862
Epoch: 25/300 - Train loss: 0.6065794229507446, Validation loss: 0.5970699191093445
Epoch: 26/300 - Train loss: 0.6015499234199524, Validation loss: 0.5919744372367859
Epoch: 27/300 - Train loss: 0.5964038372039795, Validation loss: 0.5864192843437195
Epoch: 28/300 - Train loss: 0.5911491513252258, Validation loss: 0.5809124708175659
Epoch: 29/300 - Train loss: 0.5857918858528137, Validation loss: 0.5753899216651917
Epoch: 30/300 - Train loss: 0.5803348422050476, Validation loss: 0.569813072681427
Epoch: 31/300 - Train loss: 0.5747851729393005, Validation loss: 0.5641310811042786
Epoch: 32/300 - Train loss: 0.5691491365432739, Validation loss: 0.5583828091621399
Epoch: 33/300 - Train loss: 0.5634385943412781, Validation loss: 0.5526596307754517
Epoch: 34/300 - Train loss: 0.5576603412628174, Validation loss: 0.5466897487640381
Epoch: 35/300 - Train loss: 0.5518200993537903, Validation loss: 0.5408400893211365
Epoch: 36/300 - Train loss: 0.545928418636322, Validation loss: 0.5348297357559204
Epoch: 37/300 - Train loss: 0.5399953722953796, Validation loss: 0.5286754369735718
Epoch: 38/300 - Train loss: 0.5340295433998108, Validation loss: 0.5226677060127258
Epoch: 39/300 - Train loss: 0.5280346274375916, Validation loss: 0.516625165939331
Epoch: 40/300 - Train loss: 0.5220178961753845, Validation loss: 0.5105770826339722
Epoch: 41/300 - Train loss: 0.5159872174263, Validation loss: 0.5043208003044128
Epoch: 42/300 - Train loss: 0.5099501609802246, Validation loss: 0.4985292851924896
Epoch: 43/300 - Train loss: 0.503913938999176, Validation loss: 0.49252235889434814
Epoch: 44/300 - Train loss: 0.4978891909122467, Validation loss: 0.48634663224220276
Epoch: 45/300 - Train loss: 0.4918813109397888, Validation loss: 0.4805930256843567
Epoch: 46/300 - Train loss: 0.485899418592453, Validation loss: 0.4742242097854614
Epoch: 47/300 - Train loss: 0.4799500107765198, Validation loss: 0.46823275089263916
Epoch: 48/300 - Train loss: 0.47403717041015625, Validation loss: 0.46264415979385376
Epoch: 49/300 - Train loss: 0.46816468238830566, Validation loss: 0.4567030072212219
Epoch: 50/300 - Train loss: 0.4623381495475769, Validation loss: 0.45090562105178833
Epoch: 51/300 - Train loss: 0.4565631151199341, Validation loss: 0.44522616267204285
Epoch: 52/300 - Train loss: 0.45084476470947266, Validation loss: 0.4397515654563904
Epoch: 53/300 - Train loss: 0.44518792629241943, Validation loss: 0.4338669776916504
Epoch: 54/300 - Train loss: 0.43959712982177734, Validation loss: 0.4282934367656708
Epoch: 55/300 - Train loss: 0.43407556414604187, Validation loss: 0.42301273345947266
Epoch: 56/300 - Train loss: 0.4286280870437622, Validation loss: 0.41745930910110474
Epoch: 57/300 - Train loss: 0.4232574701309204, Validation loss: 0.4125059247016907
Epoch: 58/300 - Train loss: 0.41796594858169556, Validation loss: 0.4072967767715454
Epoch: 59/300 - Train loss: 0.41275787353515625, Validation loss: 0.40197598934173584
Epoch: 60/300 - Train loss: 0.407633900642395, Validation loss: 0.3969701826572418
Epoch: 61/300 - Train loss: 0.4025968909263611, Validation loss: 0.391850084066391
Epoch: 62/300 - Train loss: 0.39764833450317383, Validation loss: 0.3868675231933594
Epoch: 63/300 - Train loss: 0.39279067516326904, Validation loss: 0.3824521601200104
Epoch: 64/300 - Train loss: 0.3880242109298706, Validation loss: 0.37784838676452637
Epoch: 65/300 - Train loss: 0.3833509385585785, Validation loss: 0.37352657318115234
Epoch: 66/300 - Train loss: 0.37876856327056885, Validation loss: 0.3686843514442444
Epoch: 67/300 - Train loss: 0.3742785155773163, Validation loss: 0.36409059166908264
Epoch: 68/300 - Train loss: 0.36988013982772827, Validation loss: 0.36009514331817627
Epoch: 69/300 - Train loss: 0.36557409167289734, Validation loss: 0.3557412624359131
Epoch: 70/300 - Train loss: 0.3613591194152832, Validation loss: 0.35149040818214417
Epoch: 71/300 - Train loss: 0.3572354316711426, Validation loss: 0.347952276468277
Epoch: 72/300 - Train loss: 0.3532029688358307, Validation loss: 0.34384584426879883
Epoch: 73/300 - Train loss: 0.3492600619792938, Validation loss: 0.34024327993392944
Epoch: 74/300 - Train loss: 0.3454059660434723, Validation loss: 0.33597564697265625
Epoch: 75/300 - Train loss: 0.34163975715637207, Validation loss: 0.3325105905532837
Epoch: 76/300 - Train loss: 0.33795860409736633, Validation loss: 0.3291337788105011
Epoch: 77/300 - Train loss: 0.3343607485294342, Validation loss: 0.3259302079677582
Epoch: 78/300 - Train loss: 0.3308449387550354, Validation loss: 0.3222168982028961
Epoch: 79/300 - Train loss: 0.32740941643714905, Validation loss: 0.3187482953071594
Epoch: 80/300 - Train loss: 0.32405295968055725, Validation loss: 0.31541967391967773
Epoch: 81/300 - Train loss: 0.3207728862762451, Validation loss: 0.3125322163105011
Epoch: 82/300 - Train loss: 0.3175690174102783, Validation loss: 0.3094288408756256
Epoch: 83/300 - Train loss: 0.31444016098976135, Validation loss: 0.3066539168357849
Epoch: 84/300 - Train loss: 0.31138405203819275, Validation loss: 0.3036080598831177
Epoch: 85/300 - Train loss: 0.30839869379997253, Validation loss: 0.3004816174507141
Epoch: 86/300 - Train loss: 0.3054819405078888, Validation loss: 0.2979707419872284
Epoch: 87/300 - Train loss: 0.3026328682899475, Validation loss: 0.29522669315338135
Epoch: 88/300 - Train loss: 0.29984983801841736, Validation loss: 0.2924703359603882
Epoch: 89/300 - Train loss: 0.29713138937950134, Validation loss: 0.2897329330444336
Epoch: 90/300 - Train loss: 0.2944771647453308, Validation loss: 0.28724539279937744
Epoch: 91/300 - Train loss: 0.29188716411590576, Validation loss: 0.28523436188697815
Epoch: 92/300 - Train loss: 0.28935813903808594, Validation loss: 0.28263652324676514
Epoch: 93/300 - Train loss: 0.28688886761665344, Validation loss: 0.27948206663131714
Epoch: 94/300 - Train loss: 0.2844783365726471, Validation loss: 0.27781733870506287
Epoch: 95/300 - Train loss: 0.2821257412433624, Validation loss: 0.27500689029693604
Epoch: 96/300 - Train loss: 0.27982965111732483, Validation loss: 0.2731133997440338
Epoch: 97/300 - Train loss: 0.27758848667144775, Validation loss: 0.27117985486984253
Epoch: 98/300 - Train loss: 0.27540117502212524, Validation loss: 0.26912519335746765
Epoch: 99/300 - Train loss: 0.2732662856578827, Validation loss: 0.26660045981407166
Epoch: 100/300 - Train loss: 0.27118200063705444, Validation loss: 0.2647395431995392
Epoch: 101/300 - Train loss: 0.26914727687835693, Validation loss: 0.26297011971473694
Epoch: 102/300 - Train loss: 0.2671602964401245, Validation loss: 0.2608533799648285
Epoch: 103/300 - Train loss: 0.26521971821784973, Validation loss: 0.2593296766281128
Epoch: 104/300 - Train loss: 0.26332470774650574, Validation loss: 0.25762736797332764
Epoch: 105/300 - Train loss: 0.26147377490997314, Validation loss: 0.2554452121257782
Epoch: 106/300 - Train loss: 0.25966575741767883, Validation loss: 0.25366705656051636
Epoch: 107/300 - Train loss: 0.2578997015953064, Validation loss: 0.2523197531700134
Epoch: 108/300 - Train loss: 0.25617411732673645, Validation loss: 0.25046631693840027
Epoch: 109/300 - Train loss: 0.25448864698410034, Validation loss: 0.2490399330854416
Epoch: 110/300 - Train loss: 0.2528423070907593, Validation loss: 0.2478713095188141
Epoch: 111/300 - Train loss: 0.25123417377471924, Validation loss: 0.24560502171516418
Epoch: 112/300 - Train loss: 0.24966324865818024, Validation loss: 0.2439945638179779
Epoch: 113/300 - Train loss: 0.24812857806682587, Validation loss: 0.24234868586063385
Epoch: 114/300 - Train loss: 0.24662932753562927, Validation loss: 0.24121113121509552
Epoch: 115/300 - Train loss: 0.24516454339027405, Validation loss: 0.24027614295482635
Epoch: 116/300 - Train loss: 0.24373354017734528, Validation loss: 0.2387896329164505
Epoch: 117/300 - Train loss: 0.24233560264110565, Validation loss: 0.2373228818178177
Epoch: 118/300 - Train loss: 0.2409699708223343, Validation loss: 0.2360682487487793
Epoch: 119/300 - Train loss: 0.23963572084903717, Validation loss: 0.23467625677585602
Epoch: 120/300 - Train loss: 0.2383321225643158, Validation loss: 0.23380877077579498
Epoch: 121/300 - Train loss: 0.23705843091011047, Validation loss: 0.23198483884334564
Epoch: 122/300 - Train loss: 0.23581399023532867, Validation loss: 0.23097608983516693
Epoch: 123/300 - Train loss: 0.23459798097610474, Validation loss: 0.22983866930007935
Epoch: 124/300 - Train loss: 0.23340971767902374, Validation loss: 0.2289326786994934
Epoch: 125/300 - Train loss: 0.232248455286026, Validation loss: 0.2277388572692871
Epoch: 126/300 - Train loss: 0.23111361265182495, Validation loss: 0.22607755661010742
Epoch: 127/300 - Train loss: 0.2300044596195221, Validation loss: 0.2258131206035614
Epoch: 128/300 - Train loss: 0.2289203405380249, Validation loss: 0.22461344301700592
Epoch: 129/300 - Train loss: 0.227860689163208, Validation loss: 0.22345121204853058
Epoch: 130/300 - Train loss: 0.22682492434978485, Validation loss: 0.22194315493106842
Epoch: 131/300 - Train loss: 0.22581224143505096, Validation loss: 0.2212032675743103
Epoch: 132/300 - Train loss: 0.22482211887836456, Validation loss: 0.2210381180047989
Epoch: 133/300 - Train loss: 0.22385403513908386, Validation loss: 0.21986402571201324
Epoch: 134/300 - Train loss: 0.22290749847888947, Validation loss: 0.21892456710338593
Epoch: 135/300 - Train loss: 0.22198177874088287, Validation loss: 0.21839140355587006
Epoch: 136/300 - Train loss: 0.2210763394832611, Validation loss: 0.21755515038967133
Epoch: 137/300 - Train loss: 0.2201905995607376, Validation loss: 0.21626143157482147
Epoch: 138/300 - Train loss: 0.2193242758512497, Validation loss: 0.21561744809150696
Epoch: 139/300 - Train loss: 0.21847671270370483, Validation loss: 0.2145380973815918
Epoch: 140/300 - Train loss: 0.21764744818210602, Validation loss: 0.21396389603614807
Epoch: 141/300 - Train loss: 0.2168361395597458, Validation loss: 0.21328148245811462
Epoch: 142/300 - Train loss: 0.21604233980178833, Validation loss: 0.212432399392128
Epoch: 143/300 - Train loss: 0.21526557207107544, Validation loss: 0.21204861998558044
Epoch: 144/300 - Train loss: 0.21450549364089966, Validation loss: 0.21066713333129883
Epoch: 145/300 - Train loss: 0.21376170217990875, Validation loss: 0.2110714614391327
Epoch: 146/300 - Train loss: 0.2130337506532669, Validation loss: 0.20973260700702667
Epoch: 147/300 - Train loss: 0.21232129633426666, Validation loss: 0.2090207189321518
Epoch: 148/300 - Train loss: 0.21162383258342743, Validation loss: 0.2085617184638977
Epoch: 149/300 - Train loss: 0.21094104647636414, Validation loss: 0.20747198164463043
Epoch: 150/300 - Train loss: 0.21027253568172455, Validation loss: 0.2067301720380783
Epoch: 151/300 - Train loss: 0.20961785316467285, Validation loss: 0.20653678476810455
Epoch: 152/300 - Train loss: 0.20897674560546875, Validation loss: 0.2060628980398178
Epoch: 153/300 - Train loss: 0.20834891498088837, Validation loss: 0.20555657148361206
Epoch: 154/300 - Train loss: 0.20773401856422424, Validation loss: 0.2045668065547943
Epoch: 155/300 - Train loss: 0.20713169872760773, Validation loss: 0.20394155383110046
Epoch: 156/300 - Train loss: 0.20654168725013733, Validation loss: 0.20375175774097443
Epoch: 157/300 - Train loss: 0.20596368610858917, Validation loss: 0.20273752510547638
Epoch: 158/300 - Train loss: 0.20539741218090057, Validation loss: 0.2021486610174179
Epoch: 159/300 - Train loss: 0.20484255254268646, Validation loss: 0.20220251381397247
