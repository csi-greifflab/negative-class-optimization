Epoch: 1/300 - Train loss: 0.7012948989868164, Validation loss: 0.698482096195221
Epoch: 2/300 - Train loss: 0.6999067664146423, Validation loss: 0.6971566081047058
Epoch: 3/300 - Train loss: 0.6985735297203064, Validation loss: 0.6957642436027527
Epoch: 4/300 - Train loss: 0.6972821354866028, Validation loss: 0.6945630311965942
Epoch: 5/300 - Train loss: 0.696027398109436, Validation loss: 0.6933800578117371
Epoch: 6/300 - Train loss: 0.6947996020317078, Validation loss: 0.6920648217201233
Epoch: 7/300 - Train loss: 0.6935897469520569, Validation loss: 0.6910231113433838
Epoch: 8/300 - Train loss: 0.6923909187316895, Validation loss: 0.6897745132446289
Epoch: 9/300 - Train loss: 0.6911976933479309, Validation loss: 0.6887752413749695
Epoch: 10/300 - Train loss: 0.6900009512901306, Validation loss: 0.6874105930328369
Epoch: 11/300 - Train loss: 0.6887942552566528, Validation loss: 0.6862566471099854
Epoch: 12/300 - Train loss: 0.6875717639923096, Validation loss: 0.6849770545959473
Epoch: 13/300 - Train loss: 0.6863259077072144, Validation loss: 0.6838042140007019
Epoch: 14/300 - Train loss: 0.6850524544715881, Validation loss: 0.6825551390647888
Epoch: 15/300 - Train loss: 0.6837494373321533, Validation loss: 0.6812668442726135
Epoch: 16/300 - Train loss: 0.6824168562889099, Validation loss: 0.6800004839897156
Epoch: 17/300 - Train loss: 0.6810497045516968, Validation loss: 0.6785471439361572
Epoch: 18/300 - Train loss: 0.679648756980896, Validation loss: 0.677132785320282
Epoch: 19/300 - Train loss: 0.6782065033912659, Validation loss: 0.6756780743598938
Epoch: 20/300 - Train loss: 0.6767241358757019, Validation loss: 0.6741416454315186
Epoch: 21/300 - Train loss: 0.6752009391784668, Validation loss: 0.6725050210952759
Epoch: 22/300 - Train loss: 0.6736322045326233, Validation loss: 0.671014666557312
Epoch: 23/300 - Train loss: 0.6720186471939087, Validation loss: 0.6693750023841858
Epoch: 24/300 - Train loss: 0.6703589558601379, Validation loss: 0.6676686406135559
Epoch: 25/300 - Train loss: 0.6686538457870483, Validation loss: 0.6659239530563354
Epoch: 26/300 - Train loss: 0.6669031381607056, Validation loss: 0.664139449596405
Epoch: 27/300 - Train loss: 0.6651081442832947, Validation loss: 0.6623928546905518
Epoch: 28/300 - Train loss: 0.6632683277130127, Validation loss: 0.6604839563369751
Epoch: 29/300 - Train loss: 0.6613848209381104, Validation loss: 0.658502995967865
Epoch: 30/300 - Train loss: 0.6594564914703369, Validation loss: 0.6565513014793396
Epoch: 31/300 - Train loss: 0.6574825644493103, Validation loss: 0.6546323299407959
Epoch: 32/300 - Train loss: 0.6554688811302185, Validation loss: 0.6523855328559875
Epoch: 33/300 - Train loss: 0.6534144878387451, Validation loss: 0.65044766664505
Epoch: 34/300 - Train loss: 0.6513237953186035, Validation loss: 0.648245632648468
Epoch: 35/300 - Train loss: 0.6491948366165161, Validation loss: 0.6461493968963623
Epoch: 36/300 - Train loss: 0.6470293998718262, Validation loss: 0.6438097357749939
Epoch: 37/300 - Train loss: 0.644829273223877, Validation loss: 0.6416801810264587
Epoch: 38/300 - Train loss: 0.6425969004631042, Validation loss: 0.6391391158103943
Epoch: 39/300 - Train loss: 0.640335738658905, Validation loss: 0.637065052986145
Epoch: 40/300 - Train loss: 0.6380482912063599, Validation loss: 0.6346102356910706
Epoch: 41/300 - Train loss: 0.6357348561286926, Validation loss: 0.6325247287750244
Epoch: 42/300 - Train loss: 0.6334013938903809, Validation loss: 0.6301057934761047
Epoch: 43/300 - Train loss: 0.6310505867004395, Validation loss: 0.6276789903640747
Epoch: 44/300 - Train loss: 0.6286888718605042, Validation loss: 0.6253180503845215
Epoch: 45/300 - Train loss: 0.6263183355331421, Validation loss: 0.6228740811347961
Epoch: 46/300 - Train loss: 0.6239413022994995, Validation loss: 0.6205781698226929
Epoch: 47/300 - Train loss: 0.6215575933456421, Validation loss: 0.6182723641395569
Epoch: 48/300 - Train loss: 0.6191672682762146, Validation loss: 0.6155573725700378
Epoch: 49/300 - Train loss: 0.6167730689048767, Validation loss: 0.6131905317306519
Epoch: 50/300 - Train loss: 0.614376425743103, Validation loss: 0.6107248067855835
Epoch: 51/300 - Train loss: 0.6119820475578308, Validation loss: 0.6083433032035828
Epoch: 52/300 - Train loss: 0.6095913052558899, Validation loss: 0.605898380279541
Epoch: 53/300 - Train loss: 0.6072067618370056, Validation loss: 0.6036019325256348
Epoch: 54/300 - Train loss: 0.604831337928772, Validation loss: 0.601026177406311
Epoch: 55/300 - Train loss: 0.6024675965309143, Validation loss: 0.5990822911262512
Epoch: 56/300 - Train loss: 0.6001173853874207, Validation loss: 0.5963675379753113
Epoch: 57/300 - Train loss: 0.5977845788002014, Validation loss: 0.5941172242164612
Epoch: 58/300 - Train loss: 0.5954700708389282, Validation loss: 0.5921226739883423
Epoch: 59/300 - Train loss: 0.5931771397590637, Validation loss: 0.589733898639679
Epoch: 60/300 - Train loss: 0.5909080505371094, Validation loss: 0.5874965786933899
Epoch: 61/300 - Train loss: 0.588664710521698, Validation loss: 0.5855084657669067
Epoch: 62/300 - Train loss: 0.5864471197128296, Validation loss: 0.5833858251571655
Epoch: 63/300 - Train loss: 0.5842580795288086, Validation loss: 0.5810062885284424
Epoch: 64/300 - Train loss: 0.5821005702018738, Validation loss: 0.5786513686180115
Epoch: 65/300 - Train loss: 0.5799750685691833, Validation loss: 0.5771499872207642
Epoch: 66/300 - Train loss: 0.577881395816803, Validation loss: 0.5747096538543701
Epoch: 67/300 - Train loss: 0.5758220553398132, Validation loss: 0.5725178718566895
Epoch: 68/300 - Train loss: 0.5737975835800171, Validation loss: 0.5712295174598694
Epoch: 69/300 - Train loss: 0.5718080401420593, Validation loss: 0.5686980485916138
Epoch: 70/300 - Train loss: 0.5698542594909668, Validation loss: 0.5669965147972107
Epoch: 71/300 - Train loss: 0.5679352283477783, Validation loss: 0.5655676126480103
Epoch: 72/300 - Train loss: 0.5660516619682312, Validation loss: 0.5635334849357605
Epoch: 73/300 - Train loss: 0.5642037391662598, Validation loss: 0.5617846846580505
Epoch: 74/300 - Train loss: 0.5623918175697327, Validation loss: 0.5602968335151672
Epoch: 75/300 - Train loss: 0.5606145262718201, Validation loss: 0.5580864548683167
Epoch: 76/300 - Train loss: 0.558871865272522, Validation loss: 0.5567870736122131
Epoch: 77/300 - Train loss: 0.5571622848510742, Validation loss: 0.5555038452148438
Epoch: 78/300 - Train loss: 0.55548495054245, Validation loss: 0.5537964105606079
Epoch: 79/300 - Train loss: 0.5538402199745178, Validation loss: 0.551837146282196
Epoch: 80/300 - Train loss: 0.5522260069847107, Validation loss: 0.5506868362426758
Epoch: 81/300 - Train loss: 0.5506422519683838, Validation loss: 0.5489778518676758
Epoch: 82/300 - Train loss: 0.5490893721580505, Validation loss: 0.5476345419883728
Epoch: 83/300 - Train loss: 0.5475667715072632, Validation loss: 0.5458326935768127
Epoch: 84/300 - Train loss: 0.5460731387138367, Validation loss: 0.5449193716049194
Epoch: 85/300 - Train loss: 0.5446069240570068, Validation loss: 0.5433927178382874
Epoch: 86/300 - Train loss: 0.5431680679321289, Validation loss: 0.541727602481842
Epoch: 87/300 - Train loss: 0.5417561531066895, Validation loss: 0.540693998336792
Epoch: 88/300 - Train loss: 0.5403696894645691, Validation loss: 0.5390776991844177
Epoch: 89/300 - Train loss: 0.539008378982544, Validation loss: 0.538161039352417
Epoch: 90/300 - Train loss: 0.5376704931259155, Validation loss: 0.5372570157051086
Epoch: 91/300 - Train loss: 0.536355197429657, Validation loss: 0.5354719758033752
Epoch: 92/300 - Train loss: 0.5350618362426758, Validation loss: 0.5348665714263916
Epoch: 93/300 - Train loss: 0.5337888598442078, Validation loss: 0.5331345796585083
Epoch: 94/300 - Train loss: 0.5325354337692261, Validation loss: 0.5323262810707092
Epoch: 95/300 - Train loss: 0.5313021540641785, Validation loss: 0.5313137173652649
Epoch: 96/300 - Train loss: 0.5300880074501038, Validation loss: 0.5303160548210144
Epoch: 97/300 - Train loss: 0.5288912057876587, Validation loss: 0.5283713340759277
Epoch: 98/300 - Train loss: 0.5277108550071716, Validation loss: 0.5277937650680542
Epoch: 99/300 - Train loss: 0.5265473127365112, Validation loss: 0.5263693928718567
Epoch: 100/300 - Train loss: 0.5253987312316895, Validation loss: 0.5258108377456665
Epoch: 101/300 - Train loss: 0.5242636799812317, Validation loss: 0.5241783261299133
Epoch: 102/300 - Train loss: 0.5231417417526245, Validation loss: 0.5228991508483887
Epoch: 103/300 - Train loss: 0.522030770778656, Validation loss: 0.5226525068283081
Epoch: 104/300 - Train loss: 0.5209314823150635, Validation loss: 0.5217128992080688
Epoch: 105/300 - Train loss: 0.5198420882225037, Validation loss: 0.5203798413276672
Epoch: 106/300 - Train loss: 0.5187629461288452, Validation loss: 0.5192176699638367
Epoch: 107/300 - Train loss: 0.517693281173706, Validation loss: 0.518206000328064
Epoch: 108/300 - Train loss: 0.5166321396827698, Validation loss: 0.5174312591552734
Epoch: 109/300 - Train loss: 0.5155778527259827, Validation loss: 0.5161769986152649
Epoch: 110/300 - Train loss: 0.5145317912101746, Validation loss: 0.5159718990325928
Epoch: 111/300 - Train loss: 0.513493001461029, Validation loss: 0.5149676203727722
Epoch: 112/300 - Train loss: 0.5124605298042297, Validation loss: 0.5138161182403564
Epoch: 113/300 - Train loss: 0.5114333033561707, Validation loss: 0.5127414464950562
Epoch: 114/300 - Train loss: 0.5104098320007324, Validation loss: 0.5120750665664673
Epoch: 115/300 - Train loss: 0.5093894004821777, Validation loss: 0.5105421543121338
Epoch: 116/300 - Train loss: 0.5083737969398499, Validation loss: 0.5097936987876892
Epoch: 117/300 - Train loss: 0.5073614120483398, Validation loss: 0.508916974067688
Epoch: 118/300 - Train loss: 0.5063517689704895, Validation loss: 0.5082669258117676
Epoch: 119/300 - Train loss: 0.5053459405899048, Validation loss: 0.5068593621253967
Epoch: 120/300 - Train loss: 0.5043433308601379, Validation loss: 0.5061898231506348
Epoch: 121/300 - Train loss: 0.5033429861068726, Validation loss: 0.5052294731140137
Epoch: 122/300 - Train loss: 0.5023469924926758, Validation loss: 0.5047599077224731
Epoch: 123/300 - Train loss: 0.50135338306427, Validation loss: 0.5038312673568726
Epoch: 124/300 - Train loss: 0.5003625750541687, Validation loss: 0.5024256110191345
Epoch: 125/300 - Train loss: 0.4993736147880554, Validation loss: 0.5016235709190369
Epoch: 126/300 - Train loss: 0.4983862638473511, Validation loss: 0.5003527402877808
Epoch: 127/300 - Train loss: 0.4974014461040497, Validation loss: 0.5000064969062805
Epoch: 128/300 - Train loss: 0.4964180588722229, Validation loss: 0.49908512830734253
Epoch: 129/300 - Train loss: 0.4954351782798767, Validation loss: 0.4977909028530121
Epoch: 130/300 - Train loss: 0.49445340037345886, Validation loss: 0.49701380729675293
Epoch: 131/300 - Train loss: 0.49347272515296936, Validation loss: 0.49725911021232605
Epoch: 132/300 - Train loss: 0.4924919903278351, Validation loss: 0.4955878257751465
Epoch: 133/300 - Train loss: 0.4915117025375366, Validation loss: 0.49403995275497437
Epoch: 134/300 - Train loss: 0.4905313551425934, Validation loss: 0.4935472011566162
Epoch: 135/300 - Train loss: 0.48954904079437256, Validation loss: 0.4931239187717438
Epoch: 136/300 - Train loss: 0.4885670840740204, Validation loss: 0.4919690787792206
Epoch: 137/300 - Train loss: 0.4875853955745697, Validation loss: 0.49112528562545776
Epoch: 138/300 - Train loss: 0.4866022765636444, Validation loss: 0.48933178186416626
Epoch: 139/300 - Train loss: 0.48561805486679077, Validation loss: 0.4882808029651642
Epoch: 140/300 - Train loss: 0.48463335633277893, Validation loss: 0.48811179399490356
Epoch: 141/300 - Train loss: 0.4836469292640686, Validation loss: 0.48692503571510315
Epoch: 142/300 - Train loss: 0.48265987634658813, Validation loss: 0.48575493693351746
Epoch: 143/300 - Train loss: 0.48167070746421814, Validation loss: 0.48546886444091797
Epoch: 144/300 - Train loss: 0.48068171739578247, Validation loss: 0.4847661554813385
Epoch: 145/300 - Train loss: 0.47969144582748413, Validation loss: 0.4836007356643677
Epoch: 146/300 - Train loss: 0.47870180010795593, Validation loss: 0.48278680443763733
Epoch: 147/300 - Train loss: 0.47771161794662476, Validation loss: 0.4806767404079437
Epoch: 148/300 - Train loss: 0.47671976685523987, Validation loss: 0.48017391562461853
Epoch: 149/300 - Train loss: 0.4757256805896759, Validation loss: 0.4795686900615692
Epoch: 150/300 - Train loss: 0.47472769021987915, Validation loss: 0.4784611165523529
Epoch: 151/300 - Train loss: 0.4737281799316406, Validation loss: 0.4771575927734375
Epoch: 152/300 - Train loss: 0.4727247953414917, Validation loss: 0.47655850648880005
Epoch: 153/300 - Train loss: 0.47171688079833984, Validation loss: 0.47530651092529297
Epoch: 154/300 - Train loss: 0.4707028865814209, Validation loss: 0.47474250197410583
Epoch: 155/300 - Train loss: 0.4696824550628662, Validation loss: 0.47372767329216003
Epoch: 156/300 - Train loss: 0.4686545431613922, Validation loss: 0.47286051511764526
Epoch: 157/300 - Train loss: 0.46762096881866455, Validation loss: 0.4711621105670929
Epoch: 158/300 - Train loss: 0.4665796458721161, Validation loss: 0.47059953212738037
Epoch: 159/300 - Train loss: 0.4655274748802185, Validation loss: 0.4701261520385742
Epoch: 160/300 - Train loss: 0.4644675850868225, Validation loss: 0.4684533476829529
Epoch: 161/300 - Train loss: 0.4634004235267639, Validation loss: 0.46734553575515747
Epoch: 162/300 - Train loss: 0.46232032775878906, Validation loss: 0.46586403250694275
Epoch: 163/300 - Train loss: 0.46123257279396057, Validation loss: 0.46550503373146057
Epoch: 164/300 - Train loss: 0.46013492345809937, Validation loss: 0.46450793743133545
Epoch: 165/300 - Train loss: 0.45902982354164124, Validation loss: 0.46328920125961304
Epoch: 166/300 - Train loss: 0.45791953802108765, Validation loss: 0.4620567858219147
Epoch: 167/300 - Train loss: 0.456806480884552, Validation loss: 0.46098917722702026
Epoch: 168/300 - Train loss: 0.4556886851787567, Validation loss: 0.4594918191432953
Epoch: 169/300 - Train loss: 0.4545673429965973, Validation loss: 0.45917728543281555
Epoch: 170/300 - Train loss: 0.45344218611717224, Validation loss: 0.4581449627876282
Epoch: 171/300 - Train loss: 0.45231160521507263, Validation loss: 0.45660167932510376
Epoch: 172/300 - Train loss: 0.45118141174316406, Validation loss: 0.45644068717956543
Epoch: 173/300 - Train loss: 0.45005202293395996, Validation loss: 0.4543798565864563
Epoch: 174/300 - Train loss: 0.44892099499702454, Validation loss: 0.4537094235420227
Epoch: 175/300 - Train loss: 0.44779306650161743, Validation loss: 0.45224013924598694
Epoch: 176/300 - Train loss: 0.4466623365879059, Validation loss: 0.45067518949508667
Epoch: 177/300 - Train loss: 0.44553226232528687, Validation loss: 0.4502602517604828
Epoch: 178/300 - Train loss: 0.444404274225235, Validation loss: 0.44848623871803284
Epoch: 179/300 - Train loss: 0.4432778060436249, Validation loss: 0.44787344336509705
Epoch: 180/300 - Train loss: 0.44215238094329834, Validation loss: 0.44685256481170654
Epoch: 181/300 - Train loss: 0.44102761149406433, Validation loss: 0.445978045463562
Epoch: 182/300 - Train loss: 0.4399048686027527, Validation loss: 0.44401395320892334
Epoch: 183/300 - Train loss: 0.4387824237346649, Validation loss: 0.4432792365550995
Epoch: 184/300 - Train loss: 0.4376610219478607, Validation loss: 0.44248637557029724
Epoch: 185/300 - Train loss: 0.43654003739356995, Validation loss: 0.4409494400024414
Epoch: 186/300 - Train loss: 0.4354206621646881, Validation loss: 0.4403456747531891
Epoch: 187/300 - Train loss: 0.4343035817146301, Validation loss: 0.43916648626327515
Epoch: 188/300 - Train loss: 0.4331919252872467, Validation loss: 0.4378197491168976
Epoch: 189/300 - Train loss: 0.43208470940589905, Validation loss: 0.4370371401309967
Epoch: 190/300 - Train loss: 0.43098294734954834, Validation loss: 0.4354819655418396
Epoch: 191/300 - Train loss: 0.4298875331878662, Validation loss: 0.4346759617328644
Epoch: 192/300 - Train loss: 0.42879530787467957, Validation loss: 0.43356800079345703
Epoch: 193/300 - Train loss: 0.4277085065841675, Validation loss: 0.43299275636672974
Epoch: 194/300 - Train loss: 0.42662760615348816, Validation loss: 0.4312593638896942
Epoch: 195/300 - Train loss: 0.42555296421051025, Validation loss: 0.43057653307914734
Epoch: 196/300 - Train loss: 0.4244849979877472, Validation loss: 0.4294094741344452
Epoch: 197/300 - Train loss: 0.42342376708984375, Validation loss: 0.4290716052055359
Epoch: 198/300 - Train loss: 0.422370046377182, Validation loss: 0.427376389503479
Epoch: 199/300 - Train loss: 0.4213237166404724, Validation loss: 0.42672261595726013
Epoch: 200/300 - Train loss: 0.42028534412384033, Validation loss: 0.4260004162788391
Epoch: 201/300 - Train loss: 0.41925495862960815, Validation loss: 0.42454293370246887
Epoch: 202/300 - Train loss: 0.41823315620422363, Validation loss: 0.42362180352211
Epoch: 203/300 - Train loss: 0.41722020506858826, Validation loss: 0.4226396679878235
Epoch: 204/300 - Train loss: 0.4162138104438782, Validation loss: 0.4216613173484802
Epoch: 205/300 - Train loss: 0.4152141511440277, Validation loss: 0.42063018679618835
Epoch: 206/300 - Train loss: 0.41422075033187866, Validation loss: 0.4200402498245239
Epoch: 207/300 - Train loss: 0.41323575377464294, Validation loss: 0.41868895292282104
Epoch: 208/300 - Train loss: 0.4122594892978668, Validation loss: 0.41825541853904724
Epoch: 209/300 - Train loss: 0.41129156947135925, Validation loss: 0.4173097014427185
Epoch: 210/300 - Train loss: 0.4103308916091919, Validation loss: 0.41596049070358276
Epoch: 211/300 - Train loss: 0.4093785583972931, Validation loss: 0.4150125980377197
Epoch: 212/300 - Train loss: 0.4084342122077942, Validation loss: 0.4143381118774414
Epoch: 213/300 - Train loss: 0.4074983298778534, Validation loss: 0.41417166590690613
Epoch: 214/300 - Train loss: 0.406570702791214, Validation loss: 0.41262856125831604
Epoch: 215/300 - Train loss: 0.4056517481803894, Validation loss: 0.41150203347206116
Epoch: 216/300 - Train loss: 0.4047423303127289, Validation loss: 0.41065317392349243
Epoch: 217/300 - Train loss: 0.40384161472320557, Validation loss: 0.41028890013694763
Epoch: 218/300 - Train loss: 0.4029504954814911, Validation loss: 0.4091566205024719
Epoch: 219/300 - Train loss: 0.4020676612854004, Validation loss: 0.40847623348236084
Epoch: 220/300 - Train loss: 0.4011929929256439, Validation loss: 0.40794163942337036
Epoch: 221/300 - Train loss: 0.4003264307975769, Validation loss: 0.40685170888900757
Epoch: 222/300 - Train loss: 0.3994682729244232, Validation loss: 0.4060102105140686
Epoch: 223/300 - Train loss: 0.3986171782016754, Validation loss: 0.4054848253726959
Epoch: 224/300 - Train loss: 0.3977735936641693, Validation loss: 0.4045007824897766
Epoch: 225/300 - Train loss: 0.3969392776489258, Validation loss: 0.40351107716560364
Epoch: 226/300 - Train loss: 0.3961142301559448, Validation loss: 0.4029984176158905
Epoch: 227/300 - Train loss: 0.39529767632484436, Validation loss: 0.40191709995269775
Epoch: 228/300 - Train loss: 0.3944883644580841, Validation loss: 0.40116074681282043
Epoch: 229/300 - Train loss: 0.39368748664855957, Validation loss: 0.40090376138687134
Epoch: 230/300 - Train loss: 0.39289209246635437, Validation loss: 0.39991337060928345
Epoch: 231/300 - Train loss: 0.3921026587486267, Validation loss: 0.3986858129501343
Epoch: 232/300 - Train loss: 0.3913186490535736, Validation loss: 0.3978613018989563
Epoch: 233/300 - Train loss: 0.3905412554740906, Validation loss: 0.39782753586769104
Epoch: 234/300 - Train loss: 0.3897720277309418, Validation loss: 0.39677509665489197
Epoch: 235/300 - Train loss: 0.3890098035335541, Validation loss: 0.3964967727661133
Epoch: 236/300 - Train loss: 0.3882533609867096, Validation loss: 0.3956489562988281
Epoch: 237/300 - Train loss: 0.3875022530555725, Validation loss: 0.3953523337841034
Epoch: 238/300 - Train loss: 0.3867585361003876, Validation loss: 0.3943903148174286
Epoch: 239/300 - Train loss: 0.38602107763290405, Validation loss: 0.39411893486976624
Epoch: 240/300 - Train loss: 0.3852890729904175, Validation loss: 0.39270728826522827
Epoch: 241/300 - Train loss: 0.3845614492893219, Validation loss: 0.3922773599624634
Epoch: 242/300 - Train loss: 0.38383761048316956, Validation loss: 0.3912545442581177
Epoch: 243/300 - Train loss: 0.3831186890602112, Validation loss: 0.3905518651008606
Epoch: 244/300 - Train loss: 0.38240545988082886, Validation loss: 0.3900420665740967
Epoch: 245/300 - Train loss: 0.3816990554332733, Validation loss: 0.38936376571655273
Epoch: 246/300 - Train loss: 0.3809983730316162, Validation loss: 0.3886406421661377
Epoch: 247/300 - Train loss: 0.38030311465263367, Validation loss: 0.3885820209980011
Epoch: 248/300 - Train loss: 0.3796139359474182, Validation loss: 0.3877958357334137
Epoch: 249/300 - Train loss: 0.37893038988113403, Validation loss: 0.3871370851993561
Epoch: 250/300 - Train loss: 0.3782520294189453, Validation loss: 0.3861299157142639
Epoch: 251/300 - Train loss: 0.3775780200958252, Validation loss: 0.3858502209186554
Epoch: 252/300 - Train loss: 0.37690964341163635, Validation loss: 0.3853684961795807
Epoch: 253/300 - Train loss: 0.37624719738960266, Validation loss: 0.3853868842124939
