Epoch: 1/300 - Train loss: 0.6930863261222839, Validation loss: 0.6892927289009094
Epoch: 2/300 - Train loss: 0.6892568469047546, Validation loss: 0.6855344772338867
Epoch: 3/300 - Train loss: 0.6853423714637756, Validation loss: 0.6816079616546631
Epoch: 4/300 - Train loss: 0.6812983751296997, Validation loss: 0.6775910258293152
Epoch: 5/300 - Train loss: 0.6771050691604614, Validation loss: 0.6733536124229431
Epoch: 6/300 - Train loss: 0.672749936580658, Validation loss: 0.669012188911438
Epoch: 7/300 - Train loss: 0.6682152152061462, Validation loss: 0.6645112633705139
Epoch: 8/300 - Train loss: 0.6634960770606995, Validation loss: 0.6597248315811157
Epoch: 9/300 - Train loss: 0.658593475818634, Validation loss: 0.6547757983207703
Epoch: 10/300 - Train loss: 0.6535176634788513, Validation loss: 0.6497501730918884
Epoch: 11/300 - Train loss: 0.6482780575752258, Validation loss: 0.6445629000663757
Epoch: 12/300 - Train loss: 0.6428910493850708, Validation loss: 0.639320969581604
Epoch: 13/300 - Train loss: 0.6373729109764099, Validation loss: 0.6338615417480469
Epoch: 14/300 - Train loss: 0.6317513585090637, Validation loss: 0.6282656192779541
Epoch: 15/300 - Train loss: 0.626041054725647, Validation loss: 0.6227612495422363
Epoch: 16/300 - Train loss: 0.6202661395072937, Validation loss: 0.6170368194580078
Epoch: 17/300 - Train loss: 0.6144455671310425, Validation loss: 0.6114868521690369
Epoch: 18/300 - Train loss: 0.6086010336875916, Validation loss: 0.6059043407440186
Epoch: 19/300 - Train loss: 0.6027555465698242, Validation loss: 0.6000634431838989
Epoch: 20/300 - Train loss: 0.5969219207763672, Validation loss: 0.59450364112854
Epoch: 21/300 - Train loss: 0.5911053419113159, Validation loss: 0.5889532566070557
Epoch: 22/300 - Train loss: 0.585308849811554, Validation loss: 0.5832014679908752
Epoch: 23/300 - Train loss: 0.5795354843139648, Validation loss: 0.5777199864387512
Epoch: 24/300 - Train loss: 0.5737931132316589, Validation loss: 0.5719864964485168
Epoch: 25/300 - Train loss: 0.5680863857269287, Validation loss: 0.5666576027870178
Epoch: 26/300 - Train loss: 0.5624198317527771, Validation loss: 0.5612544417381287
Epoch: 27/300 - Train loss: 0.5567951202392578, Validation loss: 0.5557191371917725
Epoch: 28/300 - Train loss: 0.5512149930000305, Validation loss: 0.550308883190155
Epoch: 29/300 - Train loss: 0.545680820941925, Validation loss: 0.544987678527832
Epoch: 30/300 - Train loss: 0.5401942133903503, Validation loss: 0.5395641326904297
Epoch: 31/300 - Train loss: 0.5347581505775452, Validation loss: 0.534441351890564
Epoch: 32/300 - Train loss: 0.5293745994567871, Validation loss: 0.5292133092880249
Epoch: 33/300 - Train loss: 0.5240473747253418, Validation loss: 0.5240452885627747
Epoch: 34/300 - Train loss: 0.5187773704528809, Validation loss: 0.5186690092086792
Epoch: 35/300 - Train loss: 0.5135681629180908, Validation loss: 0.5139544010162354
Epoch: 36/300 - Train loss: 0.5084214806556702, Validation loss: 0.5089190602302551
Epoch: 37/300 - Train loss: 0.5033395290374756, Validation loss: 0.5042201280593872
Epoch: 38/300 - Train loss: 0.4983248710632324, Validation loss: 0.49943265318870544
Epoch: 39/300 - Train loss: 0.49337852001190186, Validation loss: 0.4946381449699402
Epoch: 40/300 - Train loss: 0.48850157856941223, Validation loss: 0.4898447096347809
Epoch: 41/300 - Train loss: 0.48369553685188293, Validation loss: 0.4852737784385681
Epoch: 42/300 - Train loss: 0.47896143794059753, Validation loss: 0.48072826862335205
Epoch: 43/300 - Train loss: 0.47429943084716797, Validation loss: 0.47629299759864807
Epoch: 44/300 - Train loss: 0.4697096347808838, Validation loss: 0.47209516167640686
Epoch: 45/300 - Train loss: 0.46519166231155396, Validation loss: 0.4671878516674042
Epoch: 46/300 - Train loss: 0.4607451558113098, Validation loss: 0.4631772041320801
Epoch: 47/300 - Train loss: 0.45637020468711853, Validation loss: 0.4589405953884125
Epoch: 48/300 - Train loss: 0.45206671953201294, Validation loss: 0.45490822196006775
Epoch: 49/300 - Train loss: 0.4478335678577423, Validation loss: 0.4506538510322571
Epoch: 50/300 - Train loss: 0.44367000460624695, Validation loss: 0.4467713236808777
Epoch: 51/300 - Train loss: 0.4395757019519806, Validation loss: 0.44275203347206116
Epoch: 52/300 - Train loss: 0.43555015325546265, Validation loss: 0.4390169084072113
Epoch: 53/300 - Train loss: 0.431591659784317, Validation loss: 0.4355628490447998
Epoch: 54/300 - Train loss: 0.42770010232925415, Validation loss: 0.4313264489173889
Epoch: 55/300 - Train loss: 0.42387455701828003, Validation loss: 0.4278586804866791
Epoch: 56/300 - Train loss: 0.42011401057243347, Validation loss: 0.42418789863586426
Epoch: 57/300 - Train loss: 0.41641783714294434, Validation loss: 0.42071714997291565
Epoch: 58/300 - Train loss: 0.4127846658229828, Validation loss: 0.4170643389225006
Epoch: 59/300 - Train loss: 0.40921369194984436, Validation loss: 0.4137319028377533
Epoch: 60/300 - Train loss: 0.405703604221344, Validation loss: 0.4111100137233734
Epoch: 61/300 - Train loss: 0.4022534489631653, Validation loss: 0.407399982213974
Epoch: 62/300 - Train loss: 0.3988625109195709, Validation loss: 0.4042305052280426
Epoch: 63/300 - Train loss: 0.39553019404411316, Validation loss: 0.40112483501434326
Epoch: 64/300 - Train loss: 0.39225539565086365, Validation loss: 0.397502601146698
Epoch: 65/300 - Train loss: 0.3890371024608612, Validation loss: 0.3946247696876526
Epoch: 66/300 - Train loss: 0.38587409257888794, Validation loss: 0.39182600378990173
Epoch: 67/300 - Train loss: 0.38276582956314087, Validation loss: 0.38836050033569336
Epoch: 68/300 - Train loss: 0.37971121072769165, Validation loss: 0.38540080189704895
Epoch: 69/300 - Train loss: 0.3767094910144806, Validation loss: 0.38254833221435547
Epoch: 70/300 - Train loss: 0.3737594783306122, Validation loss: 0.3799699544906616
Epoch: 71/300 - Train loss: 0.37086018919944763, Validation loss: 0.3770504891872406
Epoch: 72/300 - Train loss: 0.3680103123188019, Validation loss: 0.3742385506629944
Epoch: 73/300 - Train loss: 0.36520904302597046, Validation loss: 0.37168484926223755
Epoch: 74/300 - Train loss: 0.36245569586753845, Validation loss: 0.36878088116645813
Epoch: 75/300 - Train loss: 0.3597491681575775, Validation loss: 0.36633172631263733
Epoch: 76/300 - Train loss: 0.35708874464035034, Validation loss: 0.36330458521842957
Epoch: 77/300 - Train loss: 0.3544732928276062, Validation loss: 0.36123406887054443
Epoch: 78/300 - Train loss: 0.3519018590450287, Validation loss: 0.3584947884082794
Epoch: 79/300 - Train loss: 0.34937381744384766, Validation loss: 0.35642391443252563
Epoch: 80/300 - Train loss: 0.3468882143497467, Validation loss: 0.3535621464252472
Epoch: 81/300 - Train loss: 0.34444376826286316, Validation loss: 0.35154327750205994
Epoch: 82/300 - Train loss: 0.34203997254371643, Validation loss: 0.34911298751831055
Epoch: 83/300 - Train loss: 0.3396759629249573, Validation loss: 0.34667474031448364
Epoch: 84/300 - Train loss: 0.3373509347438812, Validation loss: 0.3440142869949341
Epoch: 85/300 - Train loss: 0.3350644111633301, Validation loss: 0.34222719073295593
Epoch: 86/300 - Train loss: 0.33281537890434265, Validation loss: 0.34043431282043457
Epoch: 87/300 - Train loss: 0.3306029140949249, Validation loss: 0.33770516514778137
Epoch: 88/300 - Train loss: 0.3284262716770172, Validation loss: 0.3357973098754883
Epoch: 89/300 - Train loss: 0.32628482580184937, Validation loss: 0.33365824818611145
Epoch: 90/300 - Train loss: 0.32417795062065125, Validation loss: 0.3315889537334442
Epoch: 91/300 - Train loss: 0.32210487127304077, Validation loss: 0.3299907147884369
Epoch: 92/300 - Train loss: 0.32006463408470154, Validation loss: 0.32764163613319397
Epoch: 93/300 - Train loss: 0.3180568218231201, Validation loss: 0.32570210099220276
Epoch: 94/300 - Train loss: 0.3160804808139801, Validation loss: 0.3235396444797516
Epoch: 95/300 - Train loss: 0.31413501501083374, Validation loss: 0.3221948444843292
Epoch: 96/300 - Train loss: 0.3122200071811676, Validation loss: 0.3198203146457672
Epoch: 97/300 - Train loss: 0.3103347420692444, Validation loss: 0.3179972171783447
Epoch: 98/300 - Train loss: 0.30847856402397156, Validation loss: 0.3163381516933441
Epoch: 99/300 - Train loss: 0.30665069818496704, Validation loss: 0.3151633143424988
Epoch: 100/300 - Train loss: 0.3048504590988159, Validation loss: 0.3125462234020233
Epoch: 101/300 - Train loss: 0.30307736992836, Validation loss: 0.3119146525859833
Epoch: 102/300 - Train loss: 0.30133089423179626, Validation loss: 0.3090601861476898
Epoch: 103/300 - Train loss: 0.29961034655570984, Validation loss: 0.3078911006450653
Epoch: 104/300 - Train loss: 0.2979152500629425, Validation loss: 0.3063298761844635
Epoch: 105/300 - Train loss: 0.2962452471256256, Validation loss: 0.30459877848625183
Epoch: 106/300 - Train loss: 0.2945997714996338, Validation loss: 0.30264776945114136
Epoch: 107/300 - Train loss: 0.29297831654548645, Validation loss: 0.30112215876579285
Epoch: 108/300 - Train loss: 0.2913803160190582, Validation loss: 0.2992715835571289
Epoch: 109/300 - Train loss: 0.2898052930831909, Validation loss: 0.29790210723876953
Epoch: 110/300 - Train loss: 0.28825271129608154, Validation loss: 0.29681241512298584
Epoch: 111/300 - Train loss: 0.28672221302986145, Validation loss: 0.296116441488266
Epoch: 112/300 - Train loss: 0.28521332144737244, Validation loss: 0.2933617830276489
Epoch: 113/300 - Train loss: 0.28372541069984436, Validation loss: 0.2927442491054535
Epoch: 114/300 - Train loss: 0.2822580635547638, Validation loss: 0.2907215356826782
Epoch: 115/300 - Train loss: 0.28081098198890686, Validation loss: 0.28972524404525757
Epoch: 116/300 - Train loss: 0.2793838083744049, Validation loss: 0.2876485586166382
Epoch: 117/300 - Train loss: 0.27797621488571167, Validation loss: 0.28650984168052673
Epoch: 118/300 - Train loss: 0.2765878438949585, Validation loss: 0.2850273549556732
Epoch: 119/300 - Train loss: 0.27521812915802, Validation loss: 0.28395959734916687
Epoch: 120/300 - Train loss: 0.27386683225631714, Validation loss: 0.28261491656303406
Epoch: 121/300 - Train loss: 0.2725336253643036, Validation loss: 0.2817073464393616
Epoch: 122/300 - Train loss: 0.2712181806564331, Validation loss: 0.280121773481369
Epoch: 123/300 - Train loss: 0.2699200510978699, Validation loss: 0.27832451462745667
Epoch: 124/300 - Train loss: 0.26863908767700195, Validation loss: 0.27749937772750854
Epoch: 125/300 - Train loss: 0.26737499237060547, Validation loss: 0.2762269675731659
Epoch: 126/300 - Train loss: 0.26612749695777893, Validation loss: 0.2750842869281769
Epoch: 127/300 - Train loss: 0.2648962438106537, Validation loss: 0.27376022934913635
Epoch: 128/300 - Train loss: 0.26368090510368347, Validation loss: 0.2725980877876282
Epoch: 129/300 - Train loss: 0.2624812722206116, Validation loss: 0.27096158266067505
Epoch: 130/300 - Train loss: 0.2612968981266022, Validation loss: 0.2701228857040405
Epoch: 131/300 - Train loss: 0.2601276636123657, Validation loss: 0.26927047967910767
Epoch: 132/300 - Train loss: 0.2589733302593231, Validation loss: 0.26834407448768616
Epoch: 133/300 - Train loss: 0.2578336000442505, Validation loss: 0.2668074369430542
Epoch: 134/300 - Train loss: 0.2567082345485687, Validation loss: 0.2660888433456421
Epoch: 135/300 - Train loss: 0.2555968761444092, Validation loss: 0.2644604742527008
Epoch: 136/300 - Train loss: 0.2544994056224823, Validation loss: 0.26322242617607117
Epoch: 137/300 - Train loss: 0.2534155249595642, Validation loss: 0.2625366747379303
Epoch: 138/300 - Train loss: 0.25234517455101013, Validation loss: 0.26124027371406555
Epoch: 139/300 - Train loss: 0.25128811597824097, Validation loss: 0.2605559527873993
Epoch: 140/300 - Train loss: 0.2502440810203552, Validation loss: 0.2596793472766876
Epoch: 141/300 - Train loss: 0.24921290576457977, Validation loss: 0.25826573371887207
Epoch: 142/300 - Train loss: 0.24819442629814148, Validation loss: 0.257219135761261
Epoch: 143/300 - Train loss: 0.24718837440013885, Validation loss: 0.2566028833389282
Epoch: 144/300 - Train loss: 0.24619464576244354, Validation loss: 0.2554709017276764
Epoch: 145/300 - Train loss: 0.24521298706531525, Validation loss: 0.2542174160480499
Epoch: 146/300 - Train loss: 0.24424317479133606, Validation loss: 0.25336915254592896
Epoch: 147/300 - Train loss: 0.24328500032424927, Validation loss: 0.2526360750198364
Epoch: 148/300 - Train loss: 0.2423384189605713, Validation loss: 0.2513813078403473
Epoch: 149/300 - Train loss: 0.24140332639217377, Validation loss: 0.25082072615623474
Epoch: 150/300 - Train loss: 0.24047935009002686, Validation loss: 0.24948833882808685
Epoch: 151/300 - Train loss: 0.2395663857460022, Validation loss: 0.2491781860589981
Epoch: 152/300 - Train loss: 0.23866431415081024, Validation loss: 0.24839116632938385
Epoch: 153/300 - Train loss: 0.2377730756998062, Validation loss: 0.24695008993148804
Epoch: 154/300 - Train loss: 0.236892431974411, Validation loss: 0.2456669956445694
Epoch: 155/300 - Train loss: 0.2360221892595291, Validation loss: 0.24546976387500763
Epoch: 156/300 - Train loss: 0.2351623773574829, Validation loss: 0.2442198246717453
Epoch: 157/300 - Train loss: 0.2343127727508545, Validation loss: 0.24343235790729523
Epoch: 158/300 - Train loss: 0.23347315192222595, Validation loss: 0.2425014078617096
Epoch: 159/300 - Train loss: 0.23264345526695251, Validation loss: 0.2421351671218872
Epoch: 160/300 - Train loss: 0.23182348906993866, Validation loss: 0.24126307666301727
Epoch: 161/300 - Train loss: 0.23101314902305603, Validation loss: 0.24023942649364471
Epoch: 162/300 - Train loss: 0.23021230101585388, Validation loss: 0.23992641270160675
Epoch: 163/300 - Train loss: 0.22942078113555908, Validation loss: 0.2390492707490921
Epoch: 164/300 - Train loss: 0.22863857448101044, Validation loss: 0.23813629150390625
Epoch: 165/300 - Train loss: 0.22786545753479004, Validation loss: 0.23788177967071533
Epoch: 166/300 - Train loss: 0.2271014153957367, Validation loss: 0.23682112991809845
Epoch: 167/300 - Train loss: 0.22634628415107727, Validation loss: 0.23614369332790375
Epoch: 168/300 - Train loss: 0.22559988498687744, Validation loss: 0.23502324521541595
Epoch: 169/300 - Train loss: 0.22486217319965363, Validation loss: 0.23431231081485748
Epoch: 170/300 - Train loss: 0.2241329550743103, Validation loss: 0.23351503908634186
Epoch: 171/300 - Train loss: 0.22341212630271912, Validation loss: 0.23294095695018768
Epoch: 172/300 - Train loss: 0.22269956767559052, Validation loss: 0.23231244087219238
Epoch: 173/300 - Train loss: 0.22199518978595734, Validation loss: 0.2314101606607437
Epoch: 174/300 - Train loss: 0.22129887342453003, Validation loss: 0.2304239422082901
Epoch: 175/300 - Train loss: 0.22061051428318024, Validation loss: 0.22986333072185516
Epoch: 176/300 - Train loss: 0.2199300080537796, Validation loss: 0.22895367443561554
Epoch: 177/300 - Train loss: 0.21925725042819977, Validation loss: 0.22886456549167633
Epoch: 178/300 - Train loss: 0.21859210729599, Validation loss: 0.22824037075042725
Epoch: 179/300 - Train loss: 0.2179345339536667, Validation loss: 0.22707636654376984
Epoch: 180/300 - Train loss: 0.2172843962907791, Validation loss: 0.2268657386302948
Epoch: 181/300 - Train loss: 0.21664157509803772, Validation loss: 0.2263578325510025
Epoch: 182/300 - Train loss: 0.21600602567195892, Validation loss: 0.22582682967185974
Epoch: 183/300 - Train loss: 0.21537768840789795, Validation loss: 0.22495393455028534
Epoch: 184/300 - Train loss: 0.21475636959075928, Validation loss: 0.22451996803283691
Epoch: 185/300 - Train loss: 0.21414197981357574, Validation loss: 0.22376348078250885
Epoch: 186/300 - Train loss: 0.21353445947170258, Validation loss: 0.2228834331035614
Epoch: 187/300 - Train loss: 0.21293368935585022, Validation loss: 0.2227797508239746
Epoch: 188/300 - Train loss: 0.2123395949602127, Validation loss: 0.22225065529346466
