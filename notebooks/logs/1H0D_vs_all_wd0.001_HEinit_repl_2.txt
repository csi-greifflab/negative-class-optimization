Epoch: 1/300 - Train loss: 0.7124239206314087, Validation loss: 0.7078955173492432
Epoch: 2/300 - Train loss: 0.7098686099052429, Validation loss: 0.7058238983154297
Epoch: 3/300 - Train loss: 0.7074050903320312, Validation loss: 0.7035264372825623
Epoch: 4/300 - Train loss: 0.705028235912323, Validation loss: 0.7011762261390686
Epoch: 5/300 - Train loss: 0.7027225494384766, Validation loss: 0.6988998055458069
Epoch: 6/300 - Train loss: 0.7004726529121399, Validation loss: 0.696903645992279
Epoch: 7/300 - Train loss: 0.6982614398002625, Validation loss: 0.6947082877159119
Epoch: 8/300 - Train loss: 0.6960700154304504, Validation loss: 0.6925627589225769
Epoch: 9/300 - Train loss: 0.6938872337341309, Validation loss: 0.6904641389846802
Epoch: 10/300 - Train loss: 0.6916924118995667, Validation loss: 0.6885042190551758
Epoch: 11/300 - Train loss: 0.6894709467887878, Validation loss: 0.6861048340797424
Epoch: 12/300 - Train loss: 0.6872059106826782, Validation loss: 0.6840097308158875
Epoch: 13/300 - Train loss: 0.6848838329315186, Validation loss: 0.6817501187324524
Epoch: 14/300 - Train loss: 0.6824960112571716, Validation loss: 0.6791752576828003
Epoch: 15/300 - Train loss: 0.6800336837768555, Validation loss: 0.6767779588699341
Epoch: 16/300 - Train loss: 0.677484393119812, Validation loss: 0.6742768883705139
Epoch: 17/300 - Train loss: 0.6748420000076294, Validation loss: 0.671535849571228
Epoch: 18/300 - Train loss: 0.6721003651618958, Validation loss: 0.6687960624694824
Epoch: 19/300 - Train loss: 0.6692548394203186, Validation loss: 0.6660380959510803
Epoch: 20/300 - Train loss: 0.6662977933883667, Validation loss: 0.6629840135574341
Epoch: 21/300 - Train loss: 0.6632258892059326, Validation loss: 0.6599264740943909
Epoch: 22/300 - Train loss: 0.6600371599197388, Validation loss: 0.6567863821983337
Epoch: 23/300 - Train loss: 0.6567341089248657, Validation loss: 0.6535657048225403
Epoch: 24/300 - Train loss: 0.6533182263374329, Validation loss: 0.6500467658042908
Epoch: 25/300 - Train loss: 0.6497855186462402, Validation loss: 0.6465900540351868
Epoch: 26/300 - Train loss: 0.6461336612701416, Validation loss: 0.6429558992385864
Epoch: 27/300 - Train loss: 0.6423702836036682, Validation loss: 0.63921058177948
Epoch: 28/300 - Train loss: 0.6384916305541992, Validation loss: 0.6352596282958984
Epoch: 29/300 - Train loss: 0.634502649307251, Validation loss: 0.6311838030815125
Epoch: 30/300 - Train loss: 0.6304070353507996, Validation loss: 0.62720787525177
Epoch: 31/300 - Train loss: 0.6262090802192688, Validation loss: 0.6230217218399048
Epoch: 32/300 - Train loss: 0.6219101548194885, Validation loss: 0.6186136603355408
Epoch: 33/300 - Train loss: 0.617509126663208, Validation loss: 0.6140902638435364
Epoch: 34/300 - Train loss: 0.6130166053771973, Validation loss: 0.6096349358558655
Epoch: 35/300 - Train loss: 0.6084429621696472, Validation loss: 0.605232834815979
Epoch: 36/300 - Train loss: 0.6037929654121399, Validation loss: 0.6004784107208252
Epoch: 37/300 - Train loss: 0.5990732312202454, Validation loss: 0.5956628918647766
Epoch: 38/300 - Train loss: 0.594287633895874, Validation loss: 0.5911382436752319
Epoch: 39/300 - Train loss: 0.5894437432289124, Validation loss: 0.5861067771911621
Epoch: 40/300 - Train loss: 0.5845514535903931, Validation loss: 0.5814723968505859
Epoch: 41/300 - Train loss: 0.5796166062355042, Validation loss: 0.5766434073448181
Epoch: 42/300 - Train loss: 0.5746508240699768, Validation loss: 0.5716751217842102
Epoch: 43/300 - Train loss: 0.5696601867675781, Validation loss: 0.5666951537132263
Epoch: 44/300 - Train loss: 0.5646516680717468, Validation loss: 0.5618719458580017
Epoch: 45/300 - Train loss: 0.5596351623535156, Validation loss: 0.5567975640296936
Epoch: 46/300 - Train loss: 0.5546197295188904, Validation loss: 0.5521671175956726
Epoch: 47/300 - Train loss: 0.5496084094047546, Validation loss: 0.5472968816757202
Epoch: 48/300 - Train loss: 0.5446097254753113, Validation loss: 0.542269766330719
Epoch: 49/300 - Train loss: 0.5396283268928528, Validation loss: 0.5374680161476135
Epoch: 50/300 - Train loss: 0.5346708297729492, Validation loss: 0.5325382351875305
Epoch: 51/300 - Train loss: 0.5297454595565796, Validation loss: 0.5278137922286987
Epoch: 52/300 - Train loss: 0.5248580574989319, Validation loss: 0.5233508348464966
Epoch: 53/300 - Train loss: 0.5200145244598389, Validation loss: 0.5185621380805969
Epoch: 54/300 - Train loss: 0.5152214169502258, Validation loss: 0.5140750408172607
Epoch: 55/300 - Train loss: 0.510485827922821, Validation loss: 0.5093105435371399
Epoch: 56/300 - Train loss: 0.505814790725708, Validation loss: 0.5050150156021118
Epoch: 57/300 - Train loss: 0.5012108087539673, Validation loss: 0.5005658268928528
Epoch: 58/300 - Train loss: 0.4966793358325958, Validation loss: 0.4962272047996521
Epoch: 59/300 - Train loss: 0.4922236204147339, Validation loss: 0.4914230704307556
Epoch: 60/300 - Train loss: 0.48784777522087097, Validation loss: 0.48724520206451416
Epoch: 61/300 - Train loss: 0.48355570435523987, Validation loss: 0.4835044741630554
Epoch: 62/300 - Train loss: 0.4793494939804077, Validation loss: 0.4794371724128723
Epoch: 63/300 - Train loss: 0.47523170709609985, Validation loss: 0.4757806062698364
Epoch: 64/300 - Train loss: 0.47120344638824463, Validation loss: 0.47148844599723816
Epoch: 65/300 - Train loss: 0.4672664403915405, Validation loss: 0.4677746593952179
Epoch: 66/300 - Train loss: 0.4634206295013428, Validation loss: 0.46368467807769775
Epoch: 67/300 - Train loss: 0.45966652035713196, Validation loss: 0.4611132740974426
Epoch: 68/300 - Train loss: 0.4560057520866394, Validation loss: 0.4573274552822113
Epoch: 69/300 - Train loss: 0.4524388909339905, Validation loss: 0.45370692014694214
Epoch: 70/300 - Train loss: 0.4489654302597046, Validation loss: 0.4506799578666687
Epoch: 71/300 - Train loss: 0.44558608531951904, Validation loss: 0.4470924735069275
Epoch: 72/300 - Train loss: 0.44230085611343384, Validation loss: 0.44456732273101807
Epoch: 73/300 - Train loss: 0.4391087591648102, Validation loss: 0.4413014352321625
Epoch: 74/300 - Train loss: 0.43600887060165405, Validation loss: 0.437854528427124
Epoch: 75/300 - Train loss: 0.4329999089241028, Validation loss: 0.43521496653556824
Epoch: 76/300 - Train loss: 0.4300805926322937, Validation loss: 0.43244096636772156
Epoch: 77/300 - Train loss: 0.42724987864494324, Validation loss: 0.42979416251182556
Epoch: 78/300 - Train loss: 0.4245055317878723, Validation loss: 0.427353173494339
Epoch: 79/300 - Train loss: 0.42184627056121826, Validation loss: 0.42491549253463745
Epoch: 80/300 - Train loss: 0.41927027702331543, Validation loss: 0.42243295907974243
Epoch: 81/300 - Train loss: 0.41677534580230713, Validation loss: 0.420016348361969
Epoch: 82/300 - Train loss: 0.4143599271774292, Validation loss: 0.41789066791534424
Epoch: 83/300 - Train loss: 0.41202181577682495, Validation loss: 0.415290504693985
Epoch: 84/300 - Train loss: 0.4097587466239929, Validation loss: 0.41308388113975525
Epoch: 85/300 - Train loss: 0.4075687825679779, Validation loss: 0.41131383180618286
Epoch: 86/300 - Train loss: 0.40544986724853516, Validation loss: 0.40894395112991333
Epoch: 87/300 - Train loss: 0.4033997654914856, Validation loss: 0.40701085329055786
Epoch: 88/300 - Train loss: 0.4014165997505188, Validation loss: 0.40581589937210083
Epoch: 89/300 - Train loss: 0.3994981646537781, Validation loss: 0.4036417305469513
Epoch: 90/300 - Train loss: 0.39764204621315, Validation loss: 0.4019568860530853
Epoch: 91/300 - Train loss: 0.3958468437194824, Validation loss: 0.40017998218536377
Epoch: 92/300 - Train loss: 0.39411017298698425, Validation loss: 0.3989744782447815
Epoch: 93/300 - Train loss: 0.39242982864379883, Validation loss: 0.3969069719314575
Epoch: 94/300 - Train loss: 0.3908044695854187, Validation loss: 0.3953128159046173
Epoch: 95/300 - Train loss: 0.38923242688179016, Validation loss: 0.3943628668785095
Epoch: 96/300 - Train loss: 0.3877110779285431, Validation loss: 0.3929239809513092
Epoch: 97/300 - Train loss: 0.386238157749176, Validation loss: 0.390841543674469
Epoch: 98/300 - Train loss: 0.3848121464252472, Validation loss: 0.3901597857475281
Epoch: 99/300 - Train loss: 0.38343170285224915, Validation loss: 0.3882734179496765
Epoch: 100/300 - Train loss: 0.38209500908851624, Validation loss: 0.3873101770877838
Epoch: 101/300 - Train loss: 0.3808002173900604, Validation loss: 0.38559940457344055
Epoch: 102/300 - Train loss: 0.37954604625701904, Validation loss: 0.3847678601741791
Epoch: 103/300 - Train loss: 0.3783305585384369, Validation loss: 0.38356736302375793
Epoch: 104/300 - Train loss: 0.3771522641181946, Validation loss: 0.38190579414367676
Epoch: 105/300 - Train loss: 0.3760093152523041, Validation loss: 0.3811012804508209
Epoch: 106/300 - Train loss: 0.3749007284641266, Validation loss: 0.38030755519866943
Epoch: 107/300 - Train loss: 0.3738248348236084, Validation loss: 0.3791034519672394
Epoch: 108/300 - Train loss: 0.37278035283088684, Validation loss: 0.3779299259185791
Epoch: 109/300 - Train loss: 0.3717661499977112, Validation loss: 0.3771054744720459
Epoch: 110/300 - Train loss: 0.3707810938358307, Validation loss: 0.3768375515937805
Epoch: 111/300 - Train loss: 0.36982354521751404, Validation loss: 0.3757658898830414
Epoch: 112/300 - Train loss: 0.3688926100730896, Validation loss: 0.3752378225326538
Epoch: 113/300 - Train loss: 0.3679872453212738, Validation loss: 0.37312182784080505
Epoch: 114/300 - Train loss: 0.3671065866947174, Validation loss: 0.3727361261844635
Epoch: 115/300 - Train loss: 0.36624959111213684, Validation loss: 0.371376633644104
Epoch: 116/300 - Train loss: 0.36541497707366943, Validation loss: 0.37136492133140564
Epoch: 117/300 - Train loss: 0.3646019697189331, Validation loss: 0.3701651394367218
Epoch: 118/300 - Train loss: 0.3638096749782562, Validation loss: 0.36953046917915344
Epoch: 119/300 - Train loss: 0.3630372881889343, Validation loss: 0.3686244487762451
Epoch: 120/300 - Train loss: 0.3622841238975525, Validation loss: 0.3678833842277527
Epoch: 121/300 - Train loss: 0.36154937744140625, Validation loss: 0.3669207692146301
Epoch: 122/300 - Train loss: 0.3608325123786926, Validation loss: 0.366147518157959
Epoch: 123/300 - Train loss: 0.3601328730583191, Validation loss: 0.3653266131877899
Epoch: 124/300 - Train loss: 0.35944947600364685, Validation loss: 0.36526915431022644
Epoch: 125/300 - Train loss: 0.3587814271450043, Validation loss: 0.3650824725627899
Epoch: 126/300 - Train loss: 0.3581284284591675, Validation loss: 0.36367183923721313
Epoch: 127/300 - Train loss: 0.35748979449272156, Validation loss: 0.3634210228919983
Epoch: 128/300 - Train loss: 0.35686489939689636, Validation loss: 0.36193984746932983
Epoch: 129/300 - Train loss: 0.3562532365322113, Validation loss: 0.3622540235519409
Epoch: 130/300 - Train loss: 0.35565441846847534, Validation loss: 0.36159849166870117
Epoch: 131/300 - Train loss: 0.3550683259963989, Validation loss: 0.3612065315246582
