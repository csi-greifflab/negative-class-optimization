Epoch: 1/200 - Train loss: 0.6402564644813538, Validation loss: 0.5855579376220703
Epoch: 2/200 - Train loss: 0.5349369645118713, Validation loss: 0.4911140203475952
Epoch: 3/200 - Train loss: 0.4605722427368164, Validation loss: 0.4409424066543579
Epoch: 4/200 - Train loss: 0.4174515902996063, Validation loss: 0.4112824499607086
Epoch: 5/200 - Train loss: 0.39353451132774353, Validation loss: 0.40146714448928833
Epoch: 6/200 - Train loss: 0.3781784474849701, Validation loss: 0.3890784680843353
Epoch: 7/200 - Train loss: 0.367348849773407, Validation loss: 0.3809370696544647
Epoch: 8/200 - Train loss: 0.3586939871311188, Validation loss: 0.37462708353996277
Epoch: 9/200 - Train loss: 0.34995222091674805, Validation loss: 0.3708018958568573
Epoch: 10/200 - Train loss: 0.34185004234313965, Validation loss: 0.3685716688632965
Epoch: 11/200 - Train loss: 0.3353027403354645, Validation loss: 0.3630296587944031
Epoch: 12/200 - Train loss: 0.32951784133911133, Validation loss: 0.36167430877685547
Epoch: 13/200 - Train loss: 0.3255799114704132, Validation loss: 0.35536128282546997
Epoch: 14/200 - Train loss: 0.3214840292930603, Validation loss: 0.354977548122406
Epoch: 15/200 - Train loss: 0.31738927960395813, Validation loss: 0.3519430160522461
Epoch: 16/200 - Train loss: 0.3138912320137024, Validation loss: 0.3498254716396332
Epoch: 17/200 - Train loss: 0.3098834753036499, Validation loss: 0.3540137708187103
Epoch: 18/200 - Train loss: 0.30695006251335144, Validation loss: 0.3496794104576111
Epoch: 19/200 - Train loss: 0.3040194511413574, Validation loss: 0.3498276472091675
Epoch: 20/200 - Train loss: 0.3011961281299591, Validation loss: 0.34681910276412964
Epoch: 21/200 - Train loss: 0.2981449067592621, Validation loss: 0.34495943784713745
Epoch: 22/200 - Train loss: 0.2960456311702728, Validation loss: 0.34165289998054504
Epoch: 23/200 - Train loss: 0.29292920231819153, Validation loss: 0.34662479162216187
Epoch: 24/200 - Train loss: 0.2914083003997803, Validation loss: 0.34348446130752563
Epoch: 25/200 - Train loss: 0.28874069452285767, Validation loss: 0.34408244490623474
Epoch: 26/200 - Train loss: 0.2870323956012726, Validation loss: 0.3396123945713043
Epoch: 27/200 - Train loss: 0.28407686948776245, Validation loss: 0.33917245268821716
Epoch: 28/200 - Train loss: 0.28219348192214966, Validation loss: 0.3410704433917999
Epoch: 29/200 - Train loss: 0.28001299500465393, Validation loss: 0.33873334527015686
Epoch: 30/200 - Train loss: 0.2787136137485504, Validation loss: 0.3389751613140106
Epoch: 31/200 - Train loss: 0.2769206762313843, Validation loss: 0.33651596307754517
Epoch: 32/200 - Train loss: 0.27487483620643616, Validation loss: 0.3378280997276306
Epoch: 33/200 - Train loss: 0.27358120679855347, Validation loss: 0.3350045084953308
Epoch: 34/200 - Train loss: 0.27215680480003357, Validation loss: 0.33410122990608215
Epoch: 35/200 - Train loss: 0.2700026035308838, Validation loss: 0.3372550308704376
Epoch: 36/200 - Train loss: 0.2681286036968231, Validation loss: 0.33653268218040466
Epoch: 37/200 - Train loss: 0.26802927255630493, Validation loss: 0.33296695351600647
Epoch: 38/200 - Train loss: 0.26739147305488586, Validation loss: 0.3334886431694031
Epoch: 39/200 - Train loss: 0.2647341787815094, Validation loss: 0.332381933927536
Epoch: 40/200 - Train loss: 0.2638918161392212, Validation loss: 0.3317318260669708
Epoch: 41/200 - Train loss: 0.2629958391189575, Validation loss: 0.332076758146286
Epoch: 42/200 - Train loss: 0.2617984414100647, Validation loss: 0.3358217179775238
Epoch: 43/200 - Train loss: 0.26002684235572815, Validation loss: 0.33442994952201843
Epoch: 44/200 - Train loss: 0.2592582106590271, Validation loss: 0.3312506377696991
Epoch: 45/200 - Train loss: 0.25807034969329834, Validation loss: 0.33016932010650635
Epoch: 46/200 - Train loss: 0.25693342089653015, Validation loss: 0.33270010352134705
Epoch: 47/200 - Train loss: 0.25624746084213257, Validation loss: 0.33395126461982727
Epoch: 48/200 - Train loss: 0.2544289231300354, Validation loss: 0.3324139714241028
Epoch: 49/200 - Train loss: 0.25258129835128784, Validation loss: 0.3274787962436676
Epoch: 50/200 - Train loss: 0.2526281177997589, Validation loss: 0.3265819549560547
Epoch: 51/200 - Train loss: 0.25123053789138794, Validation loss: 0.3322921395301819
Epoch: 52/200 - Train loss: 0.25039178133010864, Validation loss: 0.33470407128334045
Epoch: 53/200 - Train loss: 0.24962130188941956, Validation loss: 0.32736343145370483
Epoch: 54/200 - Train loss: 0.24871836602687836, Validation loss: 0.32843253016471863
Epoch: 55/200 - Train loss: 0.2477889209985733, Validation loss: 0.3271482288837433
Epoch: 56/200 - Train loss: 0.24733950197696686, Validation loss: 0.3311340808868408
Epoch: 57/200 - Train loss: 0.2471679151058197, Validation loss: 0.32804596424102783
Epoch: 58/200 - Train loss: 0.24550692737102509, Validation loss: 0.32922592759132385
Epoch: 59/200 - Train loss: 0.2451903223991394, Validation loss: 0.3292504847049713
Epoch: 60/200 - Train loss: 0.245195671916008, Validation loss: 0.32880932092666626
Epoch: 61/200 - Train loss: 0.2432607263326645, Validation loss: 0.32760319113731384
Epoch: 62/200 - Train loss: 0.24327215552330017, Validation loss: 0.3267536163330078
