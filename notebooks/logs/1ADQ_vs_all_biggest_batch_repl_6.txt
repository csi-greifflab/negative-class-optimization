Epoch: 1/100 - Train loss: 0.7008905410766602, Validation loss: 0.6971927881240845
Epoch: 2/100 - Train loss: 0.6984613537788391, Validation loss: 0.6950409412384033
Epoch: 3/100 - Train loss: 0.6961350440979004, Validation loss: 0.6930420398712158
Epoch: 4/100 - Train loss: 0.6939089298248291, Validation loss: 0.6909511685371399
Epoch: 5/100 - Train loss: 0.6917534470558167, Validation loss: 0.688940167427063
Epoch: 6/100 - Train loss: 0.6896505951881409, Validation loss: 0.6869348287582397
Epoch: 7/100 - Train loss: 0.6875837445259094, Validation loss: 0.6850221753120422
Epoch: 8/100 - Train loss: 0.6855291128158569, Validation loss: 0.6830079555511475
Epoch: 9/100 - Train loss: 0.683461606502533, Validation loss: 0.6809943318367004
Epoch: 10/100 - Train loss: 0.6813666820526123, Validation loss: 0.6789749264717102
Epoch: 11/100 - Train loss: 0.6792258620262146, Validation loss: 0.6768471598625183
Epoch: 12/100 - Train loss: 0.6770300269126892, Validation loss: 0.6747024655342102
Epoch: 13/100 - Train loss: 0.6747669577598572, Validation loss: 0.67249596118927
Epoch: 14/100 - Train loss: 0.6724263429641724, Validation loss: 0.6701245903968811
Epoch: 15/100 - Train loss: 0.6700130105018616, Validation loss: 0.6678065061569214
Epoch: 16/100 - Train loss: 0.6675307750701904, Validation loss: 0.6653138399124146
Epoch: 17/100 - Train loss: 0.6649812459945679, Validation loss: 0.6627837419509888
Epoch: 18/100 - Train loss: 0.662365734577179, Validation loss: 0.6602421998977661
Epoch: 19/100 - Train loss: 0.6596894264221191, Validation loss: 0.6575371623039246
Epoch: 20/100 - Train loss: 0.6569620966911316, Validation loss: 0.6549521088600159
Epoch: 21/100 - Train loss: 0.6541876792907715, Validation loss: 0.6522123217582703
Epoch: 22/100 - Train loss: 0.6513703465461731, Validation loss: 0.6495387554168701
Epoch: 23/100 - Train loss: 0.6485171914100647, Validation loss: 0.6467599272727966
Epoch: 24/100 - Train loss: 0.6456276774406433, Validation loss: 0.6440151929855347
Epoch: 25/100 - Train loss: 0.6427047252655029, Validation loss: 0.6408254504203796
Epoch: 26/100 - Train loss: 0.6397520899772644, Validation loss: 0.6383562684059143
Epoch: 27/100 - Train loss: 0.6367732882499695, Validation loss: 0.6353810429573059
Epoch: 28/100 - Train loss: 0.633776843547821, Validation loss: 0.6325478553771973
Epoch: 29/100 - Train loss: 0.6307647228240967, Validation loss: 0.6296350955963135
Epoch: 30/100 - Train loss: 0.6277357935905457, Validation loss: 0.6266562938690186
Epoch: 31/100 - Train loss: 0.6246948838233948, Validation loss: 0.623752236366272
Epoch: 32/100 - Train loss: 0.6216455101966858, Validation loss: 0.6208399534225464
Epoch: 33/100 - Train loss: 0.6185932159423828, Validation loss: 0.6179883480072021
Epoch: 34/100 - Train loss: 0.6155444979667664, Validation loss: 0.6149556636810303
Epoch: 35/100 - Train loss: 0.6125021576881409, Validation loss: 0.6121788620948792
Epoch: 36/100 - Train loss: 0.6094685196876526, Validation loss: 0.6092625856399536
Epoch: 37/100 - Train loss: 0.6064496040344238, Validation loss: 0.6064028143882751
Epoch: 38/100 - Train loss: 0.6034466028213501, Validation loss: 0.6034155488014221
Epoch: 39/100 - Train loss: 0.6004614233970642, Validation loss: 0.6007267236709595
Epoch: 40/100 - Train loss: 0.5974988341331482, Validation loss: 0.5979998111724854
Epoch: 41/100 - Train loss: 0.5945612788200378, Validation loss: 0.5950294733047485
Epoch: 42/100 - Train loss: 0.5916516780853271, Validation loss: 0.5923340916633606
Epoch: 43/100 - Train loss: 0.5887731313705444, Validation loss: 0.5898507833480835
Epoch: 44/100 - Train loss: 0.5859265923500061, Validation loss: 0.5868610739707947
Epoch: 45/100 - Train loss: 0.5831142663955688, Validation loss: 0.5843296051025391
Epoch: 46/100 - Train loss: 0.5803390145301819, Validation loss: 0.5816561579704285
Epoch: 47/100 - Train loss: 0.5776023268699646, Validation loss: 0.5790933966636658
Epoch: 48/100 - Train loss: 0.5749064087867737, Validation loss: 0.5765836238861084
Epoch: 49/100 - Train loss: 0.572253406047821, Validation loss: 0.5738666653633118
Epoch: 50/100 - Train loss: 0.5696450471878052, Validation loss: 0.5720393061637878
Epoch: 51/100 - Train loss: 0.5670835375785828, Validation loss: 0.5693330764770508
Epoch: 52/100 - Train loss: 0.5645694732666016, Validation loss: 0.5669635534286499
Epoch: 53/100 - Train loss: 0.5621047616004944, Validation loss: 0.5645372867584229
Epoch: 54/100 - Train loss: 0.5596908330917358, Validation loss: 0.5622865557670593
Epoch: 55/100 - Train loss: 0.5573284029960632, Validation loss: 0.5603305101394653
Epoch: 56/100 - Train loss: 0.5550183057785034, Validation loss: 0.5579463839530945
Epoch: 57/100 - Train loss: 0.5527617931365967, Validation loss: 0.5559885501861572
Epoch: 58/100 - Train loss: 0.5505588054656982, Validation loss: 0.5539027452468872
Epoch: 59/100 - Train loss: 0.548409640789032, Validation loss: 0.5517288446426392
Epoch: 60/100 - Train loss: 0.5463140606880188, Validation loss: 0.5498546361923218
Epoch: 61/100 - Train loss: 0.5442725419998169, Validation loss: 0.5476254224777222
Epoch: 62/100 - Train loss: 0.5422849655151367, Validation loss: 0.5458495616912842
Epoch: 63/100 - Train loss: 0.5403497219085693, Validation loss: 0.5442799925804138
Epoch: 64/100 - Train loss: 0.5384666919708252, Validation loss: 0.5425847172737122
Epoch: 65/100 - Train loss: 0.5366350412368774, Validation loss: 0.5407334566116333
Epoch: 66/100 - Train loss: 0.5348538756370544, Validation loss: 0.5390246510505676
Epoch: 67/100 - Train loss: 0.5331218242645264, Validation loss: 0.5379399061203003
Epoch: 68/100 - Train loss: 0.5314379930496216, Validation loss: 0.5360075831413269
Epoch: 69/100 - Train loss: 0.5298012495040894, Validation loss: 0.5340760350227356
Epoch: 70/100 - Train loss: 0.5282101631164551, Validation loss: 0.5332004427909851
Epoch: 71/100 - Train loss: 0.5266637802124023, Validation loss: 0.53181391954422
Epoch: 72/100 - Train loss: 0.5251606106758118, Validation loss: 0.5304115414619446
Epoch: 73/100 - Train loss: 0.5236989259719849, Validation loss: 0.5293073654174805
Epoch: 74/100 - Train loss: 0.5222793221473694, Validation loss: 0.527990460395813
Epoch: 75/100 - Train loss: 0.5209001898765564, Validation loss: 0.5265263915061951
Epoch: 76/100 - Train loss: 0.519559383392334, Validation loss: 0.5259822607040405
Epoch: 77/100 - Train loss: 0.5182551145553589, Validation loss: 0.5242122411727905
Epoch: 78/100 - Train loss: 0.516986608505249, Validation loss: 0.5228461623191833
Epoch: 79/100 - Train loss: 0.5157516598701477, Validation loss: 0.5218703746795654
Epoch: 80/100 - Train loss: 0.5145505666732788, Validation loss: 0.5210980176925659
Epoch: 81/100 - Train loss: 0.5133813619613647, Validation loss: 0.519175112247467
Epoch: 82/100 - Train loss: 0.512241780757904, Validation loss: 0.5190914273262024
Epoch: 83/100 - Train loss: 0.5111303925514221, Validation loss: 0.5176645517349243
Epoch: 84/100 - Train loss: 0.5100468397140503, Validation loss: 0.5170076489448547
Epoch: 85/100 - Train loss: 0.5089893341064453, Validation loss: 0.5157049298286438
Epoch: 86/100 - Train loss: 0.5079563856124878, Validation loss: 0.5146228075027466
Epoch: 87/100 - Train loss: 0.5069456100463867, Validation loss: 0.5137468576431274
Epoch: 88/100 - Train loss: 0.5059555768966675, Validation loss: 0.5125802755355835
Epoch: 89/100 - Train loss: 0.5049874782562256, Validation loss: 0.5120101571083069
Epoch: 90/100 - Train loss: 0.5040395855903625, Validation loss: 0.5113965272903442
Epoch: 91/100 - Train loss: 0.5031098127365112, Validation loss: 0.510611891746521
Epoch: 92/100 - Train loss: 0.5021972060203552, Validation loss: 0.5093907713890076
Epoch: 93/100 - Train loss: 0.5012997388839722, Validation loss: 0.5085697174072266
Epoch: 94/100 - Train loss: 0.5004175305366516, Validation loss: 0.507675051689148
Epoch: 95/100 - Train loss: 0.4995492398738861, Validation loss: 0.5062706470489502
Epoch: 96/100 - Train loss: 0.4986932575702667, Validation loss: 0.5054170489311218
Epoch: 97/100 - Train loss: 0.4978502094745636, Validation loss: 0.5053167939186096
Epoch: 98/100 - Train loss: 0.4970190227031708, Validation loss: 0.5043209791183472
Epoch: 99/100 - Train loss: 0.49619823694229126, Validation loss: 0.5036090612411499
Epoch: 100/100 - Train loss: 0.49538806080818176, Validation loss: 0.5026986598968506
Epoch: 1/300 - Train loss: 0.6998419165611267, Validation loss: 0.696744978427887
Epoch: 2/300 - Train loss: 0.6974255442619324, Validation loss: 0.6945978403091431
Epoch: 3/300 - Train loss: 0.6951444745063782, Validation loss: 0.6925036907196045
Epoch: 4/300 - Train loss: 0.6929575204849243, Validation loss: 0.6905550360679626
Epoch: 5/300 - Train loss: 0.6908243894577026, Validation loss: 0.688472330570221
Epoch: 6/300 - Train loss: 0.6887025237083435, Validation loss: 0.6864476799964905
Epoch: 7/300 - Train loss: 0.6865556836128235, Validation loss: 0.6844379305839539
Epoch: 8/300 - Train loss: 0.6843490600585938, Validation loss: 0.682255208492279
Epoch: 9/300 - Train loss: 0.6820637583732605, Validation loss: 0.6798471212387085
Epoch: 10/300 - Train loss: 0.6796786189079285, Validation loss: 0.6775360703468323
Epoch: 11/300 - Train loss: 0.6771831512451172, Validation loss: 0.6750150918960571
Epoch: 12/300 - Train loss: 0.6745654940605164, Validation loss: 0.6723397374153137
Epoch: 13/300 - Train loss: 0.6718369722366333, Validation loss: 0.6696330308914185
Epoch: 14/300 - Train loss: 0.6690004467964172, Validation loss: 0.6668446660041809
Epoch: 15/300 - Train loss: 0.6660587787628174, Validation loss: 0.6639003753662109
Epoch: 16/300 - Train loss: 0.6630250215530396, Validation loss: 0.6608624458312988
Epoch: 17/300 - Train loss: 0.6599138379096985, Validation loss: 0.6577865481376648
Epoch: 18/300 - Train loss: 0.6567350625991821, Validation loss: 0.6547610759735107
Epoch: 19/300 - Train loss: 0.6534988880157471, Validation loss: 0.6515693068504333
Epoch: 20/300 - Train loss: 0.6502173542976379, Validation loss: 0.6483521461486816
Epoch: 21/300 - Train loss: 0.6469036936759949, Validation loss: 0.6452520489692688
Epoch: 22/300 - Train loss: 0.6435620188713074, Validation loss: 0.6419383883476257
Epoch: 23/300 - Train loss: 0.6401966214179993, Validation loss: 0.6385923624038696
Epoch: 24/300 - Train loss: 0.6368206143379211, Validation loss: 0.635652482509613
Epoch: 25/300 - Train loss: 0.6334375143051147, Validation loss: 0.6322236657142639
Epoch: 26/300 - Train loss: 0.6300569176673889, Validation loss: 0.6290934085845947
Epoch: 27/300 - Train loss: 0.626681387424469, Validation loss: 0.6259616613388062
Epoch: 28/300 - Train loss: 0.6233145594596863, Validation loss: 0.6227055191993713
Epoch: 29/300 - Train loss: 0.6199628710746765, Validation loss: 0.6195037961006165
Epoch: 30/300 - Train loss: 0.6166300177574158, Validation loss: 0.6161907315254211
Epoch: 31/300 - Train loss: 0.613319993019104, Validation loss: 0.6133753657341003
Epoch: 32/300 - Train loss: 0.6100333333015442, Validation loss: 0.6099544763565063
Epoch: 33/300 - Train loss: 0.6067761182785034, Validation loss: 0.6072500944137573
Epoch: 34/300 - Train loss: 0.6035516262054443, Validation loss: 0.6042279005050659
Epoch: 35/300 - Train loss: 0.6003645658493042, Validation loss: 0.6010076999664307
Epoch: 36/300 - Train loss: 0.5972172617912292, Validation loss: 0.5978575348854065
Epoch: 37/300 - Train loss: 0.5941121578216553, Validation loss: 0.5951451659202576
Epoch: 38/300 - Train loss: 0.5910517573356628, Validation loss: 0.5920882225036621
Epoch: 39/300 - Train loss: 0.5880380868911743, Validation loss: 0.5894702672958374
Epoch: 40/300 - Train loss: 0.5850738883018494, Validation loss: 0.5863036513328552
Epoch: 41/300 - Train loss: 0.5821606516838074, Validation loss: 0.5836631655693054
Epoch: 42/300 - Train loss: 0.5792997479438782, Validation loss: 0.5810928344726562
Epoch: 43/300 - Train loss: 0.5764931440353394, Validation loss: 0.5786121487617493
Epoch: 44/300 - Train loss: 0.5737423300743103, Validation loss: 0.5761703848838806
Epoch: 45/300 - Train loss: 0.5710476040840149, Validation loss: 0.5735456347465515
Epoch: 46/300 - Train loss: 0.5684109330177307, Validation loss: 0.5713853240013123
Epoch: 47/300 - Train loss: 0.5658341646194458, Validation loss: 0.5684064030647278
Epoch: 48/300 - Train loss: 0.5633175373077393, Validation loss: 0.5663353204727173
Epoch: 49/300 - Train loss: 0.5608606934547424, Validation loss: 0.5639702081680298
Epoch: 50/300 - Train loss: 0.5584644079208374, Validation loss: 0.5617755651473999
Epoch: 51/300 - Train loss: 0.5561282634735107, Validation loss: 0.5597542524337769
Epoch: 52/300 - Train loss: 0.5538525581359863, Validation loss: 0.5576038360595703
Epoch: 53/300 - Train loss: 0.5516379475593567, Validation loss: 0.5559267401695251
Epoch: 54/300 - Train loss: 0.5494838953018188, Validation loss: 0.5532920956611633
Epoch: 55/300 - Train loss: 0.5473894476890564, Validation loss: 0.5515600442886353
Epoch: 56/300 - Train loss: 0.5453541278839111, Validation loss: 0.5501309633255005
Epoch: 57/300 - Train loss: 0.5433768630027771, Validation loss: 0.5476258397102356
Epoch: 58/300 - Train loss: 0.5414571762084961, Validation loss: 0.546511173248291
Epoch: 59/300 - Train loss: 0.5395942330360413, Validation loss: 0.5445934534072876
Epoch: 60/300 - Train loss: 0.5377876162528992, Validation loss: 0.5427649021148682
Epoch: 61/300 - Train loss: 0.5360357165336609, Validation loss: 0.5412401556968689
Epoch: 62/300 - Train loss: 0.5343371629714966, Validation loss: 0.5399596095085144
Epoch: 63/300 - Train loss: 0.5326908826828003, Validation loss: 0.5382540225982666
Epoch: 64/300 - Train loss: 0.5310958623886108, Validation loss: 0.5369649529457092
Epoch: 65/300 - Train loss: 0.529550313949585, Validation loss: 0.535288393497467
Epoch: 66/300 - Train loss: 0.528052568435669, Validation loss: 0.5342514514923096
Epoch: 67/300 - Train loss: 0.5266014933586121, Validation loss: 0.5325248837471008
Epoch: 68/300 - Train loss: 0.5251949429512024, Validation loss: 0.5312713980674744
Epoch: 69/300 - Train loss: 0.523831307888031, Validation loss: 0.530204176902771
Epoch: 70/300 - Train loss: 0.5225080251693726, Validation loss: 0.5288669466972351
Epoch: 71/300 - Train loss: 0.521224319934845, Validation loss: 0.528383731842041
Epoch: 72/300 - Train loss: 0.519978404045105, Validation loss: 0.5266810059547424
Epoch: 73/300 - Train loss: 0.5187682509422302, Validation loss: 0.5256075859069824
Epoch: 74/300 - Train loss: 0.5175921320915222, Validation loss: 0.5250166654586792
Epoch: 75/300 - Train loss: 0.5164487361907959, Validation loss: 0.522867739200592
Epoch: 76/300 - Train loss: 0.5153375267982483, Validation loss: 0.5225725769996643
Epoch: 77/300 - Train loss: 0.5142556428909302, Validation loss: 0.5211345553398132
Epoch: 78/300 - Train loss: 0.5132017135620117, Validation loss: 0.520996630191803
Epoch: 79/300 - Train loss: 0.5121753215789795, Validation loss: 0.5198129415512085
Epoch: 80/300 - Train loss: 0.5111747980117798, Validation loss: 0.5190096497535706
Epoch: 81/300 - Train loss: 0.5101986527442932, Validation loss: 0.5173832178115845
Epoch: 82/300 - Train loss: 0.5092451572418213, Validation loss: 0.5168688297271729
Epoch: 83/300 - Train loss: 0.5083128809928894, Validation loss: 0.5157428979873657
Epoch: 84/300 - Train loss: 0.5073999166488647, Validation loss: 0.515306830406189
Epoch: 85/300 - Train loss: 0.5065060257911682, Validation loss: 0.5146079063415527
Epoch: 86/300 - Train loss: 0.5056307315826416, Validation loss: 0.5133763551712036
Epoch: 87/300 - Train loss: 0.5047726631164551, Validation loss: 0.5124992728233337
Epoch: 88/300 - Train loss: 0.5039295554161072, Validation loss: 0.5116636753082275
Epoch: 89/300 - Train loss: 0.5031009912490845, Validation loss: 0.510779082775116
Epoch: 90/300 - Train loss: 0.5022837519645691, Validation loss: 0.5100122094154358
Epoch: 91/300 - Train loss: 0.5014767646789551, Validation loss: 0.5097466111183167
Epoch: 92/300 - Train loss: 0.5006791353225708, Validation loss: 0.5090789794921875
Epoch: 93/300 - Train loss: 0.4998925030231476, Validation loss: 0.5076205134391785
Epoch: 94/300 - Train loss: 0.4991171360015869, Validation loss: 0.5081942677497864
Epoch: 95/300 - Train loss: 0.4983488917350769, Validation loss: 0.5066403746604919
Epoch: 96/300 - Train loss: 0.4975852370262146, Validation loss: 0.5061541795730591
Epoch: 97/300 - Train loss: 0.4968268573284149, Validation loss: 0.5046752691268921
Epoch: 98/300 - Train loss: 0.4960721731185913, Validation loss: 0.5042327046394348
Epoch: 99/300 - Train loss: 0.4953198730945587, Validation loss: 0.5037972927093506
Epoch: 100/300 - Train loss: 0.49457406997680664, Validation loss: 0.5031698346138
Epoch: 101/300 - Train loss: 0.49383071064949036, Validation loss: 0.5020320415496826
Epoch: 102/300 - Train loss: 0.4930897355079651, Validation loss: 0.5010805130004883
Epoch: 103/300 - Train loss: 0.492349237203598, Validation loss: 0.5007355809211731
Epoch: 104/300 - Train loss: 0.49161002039909363, Validation loss: 0.5002431869506836
Epoch: 105/300 - Train loss: 0.49087288975715637, Validation loss: 0.4994190037250519
Epoch: 106/300 - Train loss: 0.4901350736618042, Validation loss: 0.4987608790397644
Epoch: 107/300 - Train loss: 0.4893970191478729, Validation loss: 0.4976658523082733
Epoch: 108/300 - Train loss: 0.4886600375175476, Validation loss: 0.4972362220287323
Epoch: 109/300 - Train loss: 0.4879242777824402, Validation loss: 0.49652016162872314
Epoch: 110/300 - Train loss: 0.4871843159198761, Validation loss: 0.496040940284729
Epoch: 111/300 - Train loss: 0.48644110560417175, Validation loss: 0.4954066574573517
Epoch: 112/300 - Train loss: 0.48569634556770325, Validation loss: 0.49432697892189026
Epoch: 113/300 - Train loss: 0.48494818806648254, Validation loss: 0.4939784109592438
Epoch: 114/300 - Train loss: 0.484197199344635, Validation loss: 0.4932873547077179
Epoch: 115/300 - Train loss: 0.4834442734718323, Validation loss: 0.492340087890625
Epoch: 116/300 - Train loss: 0.4826916754245758, Validation loss: 0.4926186203956604
Epoch: 117/300 - Train loss: 0.4819375276565552, Validation loss: 0.49083858728408813
Epoch: 118/300 - Train loss: 0.48118269443511963, Validation loss: 0.4893628656864166
Epoch: 119/300 - Train loss: 0.4804286062717438, Validation loss: 0.48889750242233276
Epoch: 120/300 - Train loss: 0.4796706736087799, Validation loss: 0.4889955520629883
Epoch: 121/300 - Train loss: 0.47891172766685486, Validation loss: 0.4874643385410309
Epoch: 122/300 - Train loss: 0.4781569540500641, Validation loss: 0.48660770058631897
Epoch: 123/300 - Train loss: 0.4774034023284912, Validation loss: 0.48663273453712463
Epoch: 124/300 - Train loss: 0.47664958238601685, Validation loss: 0.48571324348449707
Epoch: 125/300 - Train loss: 0.47589796781539917, Validation loss: 0.48573464155197144
Epoch: 126/300 - Train loss: 0.4751475155353546, Validation loss: 0.48405367136001587
Epoch: 127/300 - Train loss: 0.47439903020858765, Validation loss: 0.4835027754306793
Epoch: 128/300 - Train loss: 0.4736507534980774, Validation loss: 0.4827718436717987
Epoch: 129/300 - Train loss: 0.4729021489620209, Validation loss: 0.4822356700897217
Epoch: 130/300 - Train loss: 0.4721527099609375, Validation loss: 0.4810902178287506
Epoch: 131/300 - Train loss: 0.4714054465293884, Validation loss: 0.4808361232280731
Epoch: 132/300 - Train loss: 0.4706587791442871, Validation loss: 0.4799520969390869
Epoch: 133/300 - Train loss: 0.46991151571273804, Validation loss: 0.4793221950531006
Epoch: 134/300 - Train loss: 0.46916481852531433, Validation loss: 0.47853946685791016
Epoch: 135/300 - Train loss: 0.4684196412563324, Validation loss: 0.4782516360282898
Epoch: 136/300 - Train loss: 0.46767547726631165, Validation loss: 0.4779095947742462
Epoch: 137/300 - Train loss: 0.46693217754364014, Validation loss: 0.47626793384552
Epoch: 138/300 - Train loss: 0.46618974208831787, Validation loss: 0.4760519862174988
Epoch: 139/300 - Train loss: 0.4654451906681061, Validation loss: 0.47526416182518005
Epoch: 140/300 - Train loss: 0.4646983742713928, Validation loss: 0.47460898756980896
Epoch: 141/300 - Train loss: 0.46395212411880493, Validation loss: 0.4738086760044098
Epoch: 142/300 - Train loss: 0.4632059931755066, Validation loss: 0.472761332988739
Epoch: 143/300 - Train loss: 0.46245983242988586, Validation loss: 0.4728008806705475
Epoch: 144/300 - Train loss: 0.4617135226726532, Validation loss: 0.47123563289642334
Epoch: 145/300 - Train loss: 0.46096640825271606, Validation loss: 0.4715391993522644
Epoch: 146/300 - Train loss: 0.460218220949173, Validation loss: 0.4705001711845398
Epoch: 147/300 - Train loss: 0.4594680964946747, Validation loss: 0.469329833984375
Epoch: 148/300 - Train loss: 0.4587187170982361, Validation loss: 0.4687011241912842
Epoch: 149/300 - Train loss: 0.45797041058540344, Validation loss: 0.46870124340057373
Epoch: 150/300 - Train loss: 0.4572238326072693, Validation loss: 0.4677228629589081
Epoch: 151/300 - Train loss: 0.45647773146629333, Validation loss: 0.46731501817703247
Epoch: 152/300 - Train loss: 0.45573243498802185, Validation loss: 0.4675055146217346
Epoch: 153/300 - Train loss: 0.454987496137619, Validation loss: 0.4658980369567871
Epoch: 154/300 - Train loss: 0.4542432725429535, Validation loss: 0.46456119418144226
Epoch: 155/300 - Train loss: 0.45350098609924316, Validation loss: 0.4644390642642975
Epoch: 156/300 - Train loss: 0.45275890827178955, Validation loss: 0.46368810534477234
Epoch: 157/300 - Train loss: 0.4520190358161926, Validation loss: 0.46309274435043335
Epoch: 158/300 - Train loss: 0.45128121972084045, Validation loss: 0.4620231091976166
Epoch: 159/300 - Train loss: 0.45054522156715393, Validation loss: 0.4614398777484894
Epoch: 160/300 - Train loss: 0.44981124997138977, Validation loss: 0.46085238456726074
Epoch: 161/300 - Train loss: 0.4490797817707062, Validation loss: 0.46073687076568604
Epoch: 162/300 - Train loss: 0.44835054874420166, Validation loss: 0.4597701132297516
Epoch: 163/300 - Train loss: 0.44762271642684937, Validation loss: 0.4589228630065918
Epoch: 164/300 - Train loss: 0.44689667224884033, Validation loss: 0.45812320709228516
Epoch: 165/300 - Train loss: 0.4461718797683716, Validation loss: 0.45768898725509644
Epoch: 166/300 - Train loss: 0.44544753432273865, Validation loss: 0.4569002687931061
Epoch: 167/300 - Train loss: 0.4447232782840729, Validation loss: 0.45676830410957336
Epoch: 168/300 - Train loss: 0.44399935007095337, Validation loss: 0.4551270604133606
Epoch: 169/300 - Train loss: 0.4432767331600189, Validation loss: 0.4555768370628357
Epoch: 170/300 - Train loss: 0.44255515933036804, Validation loss: 0.45423856377601624
Epoch: 171/300 - Train loss: 0.44183510541915894, Validation loss: 0.4537629783153534
Epoch: 172/300 - Train loss: 0.4411153793334961, Validation loss: 0.4541057050228119
Epoch: 173/300 - Train loss: 0.4403962194919586, Validation loss: 0.4523233473300934
Epoch: 174/300 - Train loss: 0.4396780729293823, Validation loss: 0.451524019241333
Epoch: 175/300 - Train loss: 0.4389600455760956, Validation loss: 0.4509968161582947
Epoch: 176/300 - Train loss: 0.43824198842048645, Validation loss: 0.4505641758441925
Epoch: 177/300 - Train loss: 0.43752336502075195, Validation loss: 0.45013248920440674
Epoch: 178/300 - Train loss: 0.4368034899234772, Validation loss: 0.4492776095867157
Epoch: 179/300 - Train loss: 0.43608319759368896, Validation loss: 0.4484449326992035
Epoch: 180/300 - Train loss: 0.43536248803138733, Validation loss: 0.448496013879776
Epoch: 181/300 - Train loss: 0.43464192748069763, Validation loss: 0.4469646215438843
Epoch: 182/300 - Train loss: 0.43392208218574524, Validation loss: 0.44723188877105713
Epoch: 183/300 - Train loss: 0.43320128321647644, Validation loss: 0.4462158977985382
Epoch: 184/300 - Train loss: 0.43247830867767334, Validation loss: 0.4462205469608307
