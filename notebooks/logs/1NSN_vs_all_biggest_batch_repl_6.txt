Epoch: 1/300 - Train loss: 0.7004923224449158, Validation loss: 0.699292778968811
Epoch: 2/300 - Train loss: 0.697817325592041, Validation loss: 0.6965264678001404
Epoch: 3/300 - Train loss: 0.6950578093528748, Validation loss: 0.6934345364570618
Epoch: 4/300 - Train loss: 0.6921863555908203, Validation loss: 0.6906818747520447
Epoch: 5/300 - Train loss: 0.689172089099884, Validation loss: 0.6874637603759766
Epoch: 6/300 - Train loss: 0.6859961748123169, Validation loss: 0.683876097202301
Epoch: 7/300 - Train loss: 0.6826391816139221, Validation loss: 0.6804545521736145
Epoch: 8/300 - Train loss: 0.6790862679481506, Validation loss: 0.676777720451355
Epoch: 9/300 - Train loss: 0.6753431558609009, Validation loss: 0.672720730304718
Epoch: 10/300 - Train loss: 0.671421229839325, Validation loss: 0.668566882610321
Epoch: 11/300 - Train loss: 0.6673340201377869, Validation loss: 0.6642667651176453
Epoch: 12/300 - Train loss: 0.6631059050559998, Validation loss: 0.6600948572158813
Epoch: 13/300 - Train loss: 0.6587552428245544, Validation loss: 0.6556356549263
Epoch: 14/300 - Train loss: 0.6543071866035461, Validation loss: 0.6509959697723389
Epoch: 15/300 - Train loss: 0.6497755646705627, Validation loss: 0.6464337706565857
Epoch: 16/300 - Train loss: 0.6451774835586548, Validation loss: 0.6418295502662659
Epoch: 17/300 - Train loss: 0.6405234336853027, Validation loss: 0.6372264623641968
Epoch: 18/300 - Train loss: 0.6358217000961304, Validation loss: 0.6324448585510254
Epoch: 19/300 - Train loss: 0.6310795545578003, Validation loss: 0.6275783777236938
Epoch: 20/300 - Train loss: 0.6263002157211304, Validation loss: 0.6228725910186768
Epoch: 21/300 - Train loss: 0.6214867234230042, Validation loss: 0.6181156039237976
Epoch: 22/300 - Train loss: 0.6166438460350037, Validation loss: 0.613335371017456
Epoch: 23/300 - Train loss: 0.6117749810218811, Validation loss: 0.6084319949150085
Epoch: 24/300 - Train loss: 0.6068822145462036, Validation loss: 0.6036694049835205
Epoch: 25/300 - Train loss: 0.6019685864448547, Validation loss: 0.5986383557319641
Epoch: 26/300 - Train loss: 0.597037136554718, Validation loss: 0.5938535928726196
Epoch: 27/300 - Train loss: 0.5920925140380859, Validation loss: 0.5888867974281311
Epoch: 28/300 - Train loss: 0.587139904499054, Validation loss: 0.5839208364486694
Epoch: 29/300 - Train loss: 0.5821833610534668, Validation loss: 0.5791525840759277
Epoch: 30/300 - Train loss: 0.5772269368171692, Validation loss: 0.574135959148407
Epoch: 31/300 - Train loss: 0.5722741484642029, Validation loss: 0.5694266557693481
Epoch: 32/300 - Train loss: 0.5673295259475708, Validation loss: 0.5641643404960632
Epoch: 33/300 - Train loss: 0.5623968243598938, Validation loss: 0.5595011115074158
Epoch: 34/300 - Train loss: 0.5574790835380554, Validation loss: 0.5546747446060181
Epoch: 35/300 - Train loss: 0.5525799989700317, Validation loss: 0.550012469291687
Epoch: 36/300 - Train loss: 0.5477032661437988, Validation loss: 0.5449156761169434
Epoch: 37/300 - Train loss: 0.5428529977798462, Validation loss: 0.5399156212806702
Epoch: 38/300 - Train loss: 0.5380334258079529, Validation loss: 0.5351981520652771
Epoch: 39/300 - Train loss: 0.5332476496696472, Validation loss: 0.5306977033615112
Epoch: 40/300 - Train loss: 0.5284994840621948, Validation loss: 0.5262355208396912
Epoch: 41/300 - Train loss: 0.5237930417060852, Validation loss: 0.5213814973831177
Epoch: 42/300 - Train loss: 0.5191317200660706, Validation loss: 0.5167813301086426
Epoch: 43/300 - Train loss: 0.5145180225372314, Validation loss: 0.5119965076446533
Epoch: 44/300 - Train loss: 0.5099553465843201, Validation loss: 0.5077441334724426
Epoch: 45/300 - Train loss: 0.5054466128349304, Validation loss: 0.5032464861869812
Epoch: 46/300 - Train loss: 0.5009947419166565, Validation loss: 0.4993509352207184
Epoch: 47/300 - Train loss: 0.4966021776199341, Validation loss: 0.4945780336856842
Epoch: 48/300 - Train loss: 0.49227139353752136, Validation loss: 0.49034208059310913
Epoch: 49/300 - Train loss: 0.4880048334598541, Validation loss: 0.4861062169075012
Epoch: 50/300 - Train loss: 0.48380497097969055, Validation loss: 0.4818026125431061
Epoch: 51/300 - Train loss: 0.47967347502708435, Validation loss: 0.47798261046409607
Epoch: 52/300 - Train loss: 0.47561225295066833, Validation loss: 0.47392919659614563
Epoch: 53/300 - Train loss: 0.4716227352619171, Validation loss: 0.46995511651039124
Epoch: 54/300 - Train loss: 0.4677056074142456, Validation loss: 0.466570645570755
Epoch: 55/300 - Train loss: 0.46386227011680603, Validation loss: 0.4630274176597595
Epoch: 56/300 - Train loss: 0.46009355783462524, Validation loss: 0.45861461758613586
Epoch: 57/300 - Train loss: 0.45640015602111816, Validation loss: 0.4548962712287903
Epoch: 58/300 - Train loss: 0.45278236269950867, Validation loss: 0.4514964818954468
Epoch: 59/300 - Train loss: 0.4492403566837311, Validation loss: 0.44767725467681885
Epoch: 60/300 - Train loss: 0.44577404856681824, Validation loss: 0.44542425870895386
Epoch: 61/300 - Train loss: 0.4423828125, Validation loss: 0.4415070414543152
Epoch: 62/300 - Train loss: 0.4390663206577301, Validation loss: 0.4382762610912323
Epoch: 63/300 - Train loss: 0.4358243942260742, Validation loss: 0.43503159284591675
Epoch: 64/300 - Train loss: 0.4326564371585846, Validation loss: 0.4318400025367737
Epoch: 65/300 - Train loss: 0.42956146597862244, Validation loss: 0.42893916368484497
Epoch: 66/300 - Train loss: 0.4265381395816803, Validation loss: 0.42606979608535767
Epoch: 67/300 - Train loss: 0.42358601093292236, Validation loss: 0.4231233596801758
Epoch: 68/300 - Train loss: 0.42070379853248596, Validation loss: 0.42069005966186523
Epoch: 69/300 - Train loss: 0.41788995265960693, Validation loss: 0.4174931049346924
Epoch: 70/300 - Train loss: 0.41514304280281067, Validation loss: 0.4147249162197113
Epoch: 71/300 - Train loss: 0.41246187686920166, Validation loss: 0.4130864441394806
Epoch: 72/300 - Train loss: 0.4098452925682068, Validation loss: 0.40952059626579285
Epoch: 73/300 - Train loss: 0.40729185938835144, Validation loss: 0.40711697936058044
Epoch: 74/300 - Train loss: 0.40479975938796997, Validation loss: 0.40489646792411804
Epoch: 75/300 - Train loss: 0.40236717462539673, Validation loss: 0.4022693932056427
Epoch: 76/300 - Train loss: 0.39999276399612427, Validation loss: 0.4004184901714325
Epoch: 77/300 - Train loss: 0.3976745307445526, Validation loss: 0.39841511845588684
Epoch: 78/300 - Train loss: 0.3954108655452728, Validation loss: 0.3959335386753082
Epoch: 79/300 - Train loss: 0.393200159072876, Validation loss: 0.39344850182533264
Epoch: 80/300 - Train loss: 0.3910410404205322, Validation loss: 0.3908289670944214
Epoch: 81/300 - Train loss: 0.388931542634964, Validation loss: 0.3895215094089508
Epoch: 82/300 - Train loss: 0.3868701756000519, Validation loss: 0.3873499929904938
Epoch: 83/300 - Train loss: 0.38485538959503174, Validation loss: 0.38519778847694397
Epoch: 84/300 - Train loss: 0.3828859031200409, Validation loss: 0.38404950499534607
Epoch: 85/300 - Train loss: 0.38096046447753906, Validation loss: 0.38185644149780273
Epoch: 86/300 - Train loss: 0.37907716631889343, Validation loss: 0.3801902234554291
Epoch: 87/300 - Train loss: 0.37723490595817566, Validation loss: 0.378932923078537
Epoch: 88/300 - Train loss: 0.37543198466300964, Validation loss: 0.3768552839756012
Epoch: 89/300 - Train loss: 0.3736667037010193, Validation loss: 0.37520328164100647
Epoch: 90/300 - Train loss: 0.37193790078163147, Validation loss: 0.3729820251464844
Epoch: 91/300 - Train loss: 0.3702440559864044, Validation loss: 0.3721558153629303
Epoch: 92/300 - Train loss: 0.3685843050479889, Validation loss: 0.3698576092720032
Epoch: 93/300 - Train loss: 0.36695733666419983, Validation loss: 0.36862698197364807
Epoch: 94/300 - Train loss: 0.36536213755607605, Validation loss: 0.3666086792945862
Epoch: 95/300 - Train loss: 0.3637971878051758, Validation loss: 0.3647069036960602
Epoch: 96/300 - Train loss: 0.36226195096969604, Validation loss: 0.3637097179889679
Epoch: 97/300 - Train loss: 0.3607555031776428, Validation loss: 0.36266326904296875
Epoch: 98/300 - Train loss: 0.3592771887779236, Validation loss: 0.36107468605041504
Epoch: 99/300 - Train loss: 0.3578258752822876, Validation loss: 0.35961461067199707
Epoch: 100/300 - Train loss: 0.3564005494117737, Validation loss: 0.3590187430381775
Epoch: 101/300 - Train loss: 0.35500040650367737, Validation loss: 0.357242614030838
Epoch: 102/300 - Train loss: 0.35362446308135986, Validation loss: 0.3561639189720154
Epoch: 103/300 - Train loss: 0.3522716164588928, Validation loss: 0.35439860820770264
Epoch: 104/300 - Train loss: 0.3509413003921509, Validation loss: 0.3532041609287262
Epoch: 105/300 - Train loss: 0.34963300824165344, Validation loss: 0.3516741096973419
Epoch: 106/300 - Train loss: 0.3483458459377289, Validation loss: 0.3508707582950592
Epoch: 107/300 - Train loss: 0.3470795452594757, Validation loss: 0.34933072328567505
Epoch: 108/300 - Train loss: 0.3458336889743805, Validation loss: 0.34864887595176697
Epoch: 109/300 - Train loss: 0.3446069657802582, Validation loss: 0.34713831543922424
Epoch: 110/300 - Train loss: 0.34339919686317444, Validation loss: 0.3455514907836914
Epoch: 111/300 - Train loss: 0.3422100245952606, Validation loss: 0.34452033042907715
Epoch: 112/300 - Train loss: 0.3410384953022003, Validation loss: 0.3436231315135956
Epoch: 113/300 - Train loss: 0.33988478779792786, Validation loss: 0.3422044515609741
Epoch: 114/300 - Train loss: 0.3387483060359955, Validation loss: 0.3417062759399414
Epoch: 115/300 - Train loss: 0.33762821555137634, Validation loss: 0.33994314074516296
Epoch: 116/300 - Train loss: 0.33652424812316895, Validation loss: 0.33868592977523804
Epoch: 117/300 - Train loss: 0.3354364037513733, Validation loss: 0.33829018473625183
Epoch: 118/300 - Train loss: 0.3343644142150879, Validation loss: 0.33699288964271545
Epoch: 119/300 - Train loss: 0.33330845832824707, Validation loss: 0.3357444107532501
Epoch: 120/300 - Train loss: 0.3322678208351135, Validation loss: 0.3351631164550781
Epoch: 121/300 - Train loss: 0.33124154806137085, Validation loss: 0.33352071046829224
Epoch: 122/300 - Train loss: 0.33022913336753845, Validation loss: 0.3335449695587158
Epoch: 123/300 - Train loss: 0.3292296230792999, Validation loss: 0.33178073167800903
Epoch: 124/300 - Train loss: 0.3282432556152344, Validation loss: 0.3313990533351898
Epoch: 125/300 - Train loss: 0.3272700309753418, Validation loss: 0.3310532569885254
Epoch: 126/300 - Train loss: 0.3263096213340759, Validation loss: 0.3289717733860016
Epoch: 127/300 - Train loss: 0.3253609836101532, Validation loss: 0.3282043933868408
Epoch: 128/300 - Train loss: 0.3244234621524811, Validation loss: 0.3274361193180084
Epoch: 129/300 - Train loss: 0.32349729537963867, Validation loss: 0.32743552327156067
Epoch: 130/300 - Train loss: 0.3225824236869812, Validation loss: 0.325424462556839
Epoch: 131/300 - Train loss: 0.3216789662837982, Validation loss: 0.3251056671142578
Epoch: 132/300 - Train loss: 0.3207865357398987, Validation loss: 0.32431289553642273
Epoch: 133/300 - Train loss: 0.31990453600883484, Validation loss: 0.3230695128440857
Epoch: 134/300 - Train loss: 0.31903332471847534, Validation loss: 0.32297489047050476
Epoch: 135/300 - Train loss: 0.3181729316711426, Validation loss: 0.3215271532535553
Epoch: 136/300 - Train loss: 0.31732240319252014, Validation loss: 0.3213653564453125
Epoch: 137/300 - Train loss: 0.31648099422454834, Validation loss: 0.32016101479530334
Epoch: 138/300 - Train loss: 0.315649151802063, Validation loss: 0.31862887740135193
Epoch: 139/300 - Train loss: 0.3148267865180969, Validation loss: 0.31815651059150696
Epoch: 140/300 - Train loss: 0.31401368975639343, Validation loss: 0.3179604411125183
Epoch: 141/300 - Train loss: 0.3132101893424988, Validation loss: 0.3171934485435486
Epoch: 142/300 - Train loss: 0.31241607666015625, Validation loss: 0.3160894811153412
Epoch: 143/300 - Train loss: 0.31163090467453003, Validation loss: 0.3153327405452728
Epoch: 144/300 - Train loss: 0.3108544945716858, Validation loss: 0.3151976466178894
Epoch: 145/300 - Train loss: 0.3100869655609131, Validation loss: 0.3137446641921997
Epoch: 146/300 - Train loss: 0.3093278408050537, Validation loss: 0.31286266446113586
Epoch: 147/300 - Train loss: 0.30857688188552856, Validation loss: 0.3120741844177246
Epoch: 148/300 - Train loss: 0.307834267616272, Validation loss: 0.31233444809913635
Epoch: 149/300 - Train loss: 0.3070991635322571, Validation loss: 0.31120967864990234
Epoch: 150/300 - Train loss: 0.3063717484474182, Validation loss: 0.3098676800727844
Epoch: 151/300 - Train loss: 0.30565252900123596, Validation loss: 0.30923226475715637
Epoch: 152/300 - Train loss: 0.3049408495426178, Validation loss: 0.3095174729824066
Epoch: 153/300 - Train loss: 0.30423688888549805, Validation loss: 0.3082864284515381
Epoch: 154/300 - Train loss: 0.30354025959968567, Validation loss: 0.3070669174194336
Epoch: 155/300 - Train loss: 0.3028506338596344, Validation loss: 0.3062654137611389
Epoch: 156/300 - Train loss: 0.30216819047927856, Validation loss: 0.3064780533313751
Epoch: 157/300 - Train loss: 0.3014930188655853, Validation loss: 0.305551677942276
Epoch: 158/300 - Train loss: 0.30082541704177856, Validation loss: 0.30497726798057556
Epoch: 159/300 - Train loss: 0.300165057182312, Validation loss: 0.3043796122074127
Epoch: 160/300 - Train loss: 0.2995110750198364, Validation loss: 0.3033459484577179
Epoch: 161/300 - Train loss: 0.2988641560077667, Validation loss: 0.30316945910453796
Epoch: 162/300 - Train loss: 0.2982241213321686, Validation loss: 0.3026334345340729
Epoch: 163/300 - Train loss: 0.2975911498069763, Validation loss: 0.3027738928794861
