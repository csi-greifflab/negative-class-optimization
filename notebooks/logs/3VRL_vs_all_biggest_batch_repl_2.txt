Epoch: 1/300 - Train loss: 0.6902878880500793, Validation loss: 0.687366783618927
Epoch: 2/300 - Train loss: 0.686905026435852, Validation loss: 0.6840721368789673
Epoch: 3/300 - Train loss: 0.6835438013076782, Validation loss: 0.6807697415351868
Epoch: 4/300 - Train loss: 0.6801735758781433, Validation loss: 0.6774523854255676
Epoch: 5/300 - Train loss: 0.6767742037773132, Validation loss: 0.6740724444389343
Epoch: 6/300 - Train loss: 0.6733239889144897, Validation loss: 0.6706412434577942
Epoch: 7/300 - Train loss: 0.6697958707809448, Validation loss: 0.6670873165130615
Epoch: 8/300 - Train loss: 0.6661756038665771, Validation loss: 0.663460910320282
Epoch: 9/300 - Train loss: 0.6624586582183838, Validation loss: 0.6597158312797546
Epoch: 10/300 - Train loss: 0.6586248278617859, Validation loss: 0.6558599472045898
Epoch: 11/300 - Train loss: 0.6546576619148254, Validation loss: 0.6518456339836121
Epoch: 12/300 - Train loss: 0.6505560874938965, Validation loss: 0.6476502418518066
Epoch: 13/300 - Train loss: 0.6463135480880737, Validation loss: 0.6434873938560486
Epoch: 14/300 - Train loss: 0.641930341720581, Validation loss: 0.6391482949256897
Epoch: 15/300 - Train loss: 0.6374128460884094, Validation loss: 0.6345387101173401
Epoch: 16/300 - Train loss: 0.6327633261680603, Validation loss: 0.6299505829811096
Epoch: 17/300 - Train loss: 0.6279937028884888, Validation loss: 0.6251807808876038
Epoch: 18/300 - Train loss: 0.6231197714805603, Validation loss: 0.6203879117965698
Epoch: 19/300 - Train loss: 0.6181602478027344, Validation loss: 0.6153759360313416
Epoch: 20/300 - Train loss: 0.613127589225769, Validation loss: 0.6104562282562256
Epoch: 21/300 - Train loss: 0.6080369353294373, Validation loss: 0.6055623888969421
Epoch: 22/300 - Train loss: 0.602894127368927, Validation loss: 0.6005544066429138
Epoch: 23/300 - Train loss: 0.5977089405059814, Validation loss: 0.5952590107917786
Epoch: 24/300 - Train loss: 0.5924862623214722, Validation loss: 0.5900507569313049
Epoch: 25/300 - Train loss: 0.5872303247451782, Validation loss: 0.585014283657074
Epoch: 26/300 - Train loss: 0.5819448828697205, Validation loss: 0.5799903869628906
Epoch: 27/300 - Train loss: 0.5766348838806152, Validation loss: 0.5747503638267517
Epoch: 28/300 - Train loss: 0.5713006258010864, Validation loss: 0.5693106055259705
Epoch: 29/300 - Train loss: 0.5659454464912415, Validation loss: 0.5642001032829285
Epoch: 30/300 - Train loss: 0.5605725646018982, Validation loss: 0.5591233968734741
Epoch: 31/300 - Train loss: 0.5551850199699402, Validation loss: 0.55377197265625
Epoch: 32/300 - Train loss: 0.5497864484786987, Validation loss: 0.548353910446167
Epoch: 33/300 - Train loss: 0.5443829894065857, Validation loss: 0.5432117581367493
Epoch: 34/300 - Train loss: 0.5389784574508667, Validation loss: 0.5378490686416626
Epoch: 35/300 - Train loss: 0.5335777401924133, Validation loss: 0.5323128700256348
Epoch: 36/300 - Train loss: 0.5281869173049927, Validation loss: 0.5271819829940796
Epoch: 37/300 - Train loss: 0.5228102803230286, Validation loss: 0.5217974781990051
Epoch: 38/300 - Train loss: 0.5174523591995239, Validation loss: 0.5168123841285706
Epoch: 39/300 - Train loss: 0.5121185779571533, Validation loss: 0.5113298296928406
Epoch: 40/300 - Train loss: 0.5068137049674988, Validation loss: 0.5065723657608032
Epoch: 41/300 - Train loss: 0.5015425086021423, Validation loss: 0.5013294219970703
Epoch: 42/300 - Train loss: 0.49630916118621826, Validation loss: 0.4960808753967285
Epoch: 43/300 - Train loss: 0.4911176860332489, Validation loss: 0.491024911403656
Epoch: 44/300 - Train loss: 0.4859715402126312, Validation loss: 0.4861660897731781
Epoch: 45/300 - Train loss: 0.48087459802627563, Validation loss: 0.48125821352005005
Epoch: 46/300 - Train loss: 0.47583040595054626, Validation loss: 0.4760751724243164
Epoch: 47/300 - Train loss: 0.4708423614501953, Validation loss: 0.471597820520401
Epoch: 48/300 - Train loss: 0.4659141004085541, Validation loss: 0.4666864573955536
Epoch: 49/300 - Train loss: 0.4610486328601837, Validation loss: 0.4621371626853943
Epoch: 50/300 - Train loss: 0.4562484622001648, Validation loss: 0.45735085010528564
Epoch: 51/300 - Train loss: 0.4515164792537689, Validation loss: 0.4531366229057312
Epoch: 52/300 - Train loss: 0.4468550980091095, Validation loss: 0.4486369788646698
Epoch: 53/300 - Train loss: 0.4422660171985626, Validation loss: 0.4438877999782562
Epoch: 54/300 - Train loss: 0.4377507269382477, Validation loss: 0.4397604465484619
Epoch: 55/300 - Train loss: 0.4333111047744751, Validation loss: 0.43582379817962646
Epoch: 56/300 - Train loss: 0.42894816398620605, Validation loss: 0.43160754442214966
Epoch: 57/300 - Train loss: 0.4246627390384674, Validation loss: 0.4270617365837097
Epoch: 58/300 - Train loss: 0.4204554259777069, Validation loss: 0.42331811785697937
Epoch: 59/300 - Train loss: 0.416326642036438, Validation loss: 0.41978976130485535
Epoch: 60/300 - Train loss: 0.4122764468193054, Validation loss: 0.4157188832759857
Epoch: 61/300 - Train loss: 0.408304899930954, Validation loss: 0.4117699861526489
Epoch: 62/300 - Train loss: 0.4044114351272583, Validation loss: 0.4081438481807709
Epoch: 63/300 - Train loss: 0.4005957543849945, Validation loss: 0.4047078490257263
Epoch: 64/300 - Train loss: 0.39685744047164917, Validation loss: 0.40103068947792053
Epoch: 65/300 - Train loss: 0.39319562911987305, Validation loss: 0.3975202739238739
Epoch: 66/300 - Train loss: 0.38960951566696167, Validation loss: 0.39449024200439453
Epoch: 67/300 - Train loss: 0.3860982656478882, Validation loss: 0.39075416326522827
Epoch: 68/300 - Train loss: 0.38266071677207947, Validation loss: 0.3871288597583771
Epoch: 69/300 - Train loss: 0.3792954683303833, Validation loss: 0.38432103395462036
Epoch: 70/300 - Train loss: 0.37600141763687134, Validation loss: 0.3808412253856659
Epoch: 71/300 - Train loss: 0.3727770149707794, Validation loss: 0.3776650130748749
Epoch: 72/300 - Train loss: 0.36962100863456726, Validation loss: 0.37494122982025146
Epoch: 73/300 - Train loss: 0.3665320575237274, Validation loss: 0.37195003032684326
Epoch: 74/300 - Train loss: 0.3635089099407196, Validation loss: 0.36942818760871887
Epoch: 75/300 - Train loss: 0.3605498969554901, Validation loss: 0.3664040267467499
Epoch: 76/300 - Train loss: 0.35765358805656433, Validation loss: 0.3638288378715515
Epoch: 77/300 - Train loss: 0.35481855273246765, Validation loss: 0.3614732027053833
Epoch: 78/300 - Train loss: 0.352043479681015, Validation loss: 0.35850074887275696
Epoch: 79/300 - Train loss: 0.3493269383907318, Validation loss: 0.35546281933784485
Epoch: 80/300 - Train loss: 0.34666743874549866, Validation loss: 0.35248419642448425
Epoch: 81/300 - Train loss: 0.34406352043151855, Validation loss: 0.35054734349250793
Epoch: 82/300 - Train loss: 0.3415135443210602, Validation loss: 0.34814393520355225
Epoch: 83/300 - Train loss: 0.33901602029800415, Validation loss: 0.3452599346637726
Epoch: 84/300 - Train loss: 0.3365696668624878, Validation loss: 0.3435856103897095
Epoch: 85/300 - Train loss: 0.33417317271232605, Validation loss: 0.34125474095344543
Epoch: 86/300 - Train loss: 0.3318250775337219, Validation loss: 0.3386607766151428
Epoch: 87/300 - Train loss: 0.3295241892337799, Validation loss: 0.3363696336746216
Epoch: 88/300 - Train loss: 0.32726895809173584, Validation loss: 0.33428728580474854
Epoch: 89/300 - Train loss: 0.325058251619339, Validation loss: 0.3322345018386841
Epoch: 90/300 - Train loss: 0.3228907287120819, Validation loss: 0.3302619457244873
Epoch: 91/300 - Train loss: 0.32076510787010193, Validation loss: 0.3278968632221222
Epoch: 92/300 - Train loss: 0.31868037581443787, Validation loss: 0.32667064666748047
Epoch: 93/300 - Train loss: 0.3166351914405823, Validation loss: 0.32385894656181335
Epoch: 94/300 - Train loss: 0.31462839245796204, Validation loss: 0.3217126131057739
Epoch: 95/300 - Train loss: 0.31265881657600403, Validation loss: 0.3198179304599762
Epoch: 96/300 - Train loss: 0.3107253909111023, Validation loss: 0.3177609145641327
Epoch: 97/300 - Train loss: 0.3088272511959076, Validation loss: 0.31622201204299927
Epoch: 98/300 - Train loss: 0.30696338415145874, Validation loss: 0.3145363926887512
Epoch: 99/300 - Train loss: 0.30513277649879456, Validation loss: 0.31264635920524597
Epoch: 100/300 - Train loss: 0.30333438515663147, Validation loss: 0.31091323494911194
Epoch: 101/300 - Train loss: 0.3015672564506531, Validation loss: 0.30930352210998535
Epoch: 102/300 - Train loss: 0.2998303472995758, Validation loss: 0.3073597252368927
Epoch: 103/300 - Train loss: 0.29812294244766235, Validation loss: 0.3059355318546295
Epoch: 104/300 - Train loss: 0.2964443266391754, Validation loss: 0.30387815833091736
Epoch: 105/300 - Train loss: 0.29479366540908813, Validation loss: 0.3035978376865387
Epoch: 106/300 - Train loss: 0.2931702733039856, Validation loss: 0.3016429543495178
Epoch: 107/300 - Train loss: 0.29157334566116333, Validation loss: 0.2997794449329376
Epoch: 108/300 - Train loss: 0.29000210762023926, Validation loss: 0.29829344153404236
Epoch: 109/300 - Train loss: 0.28845590353012085, Validation loss: 0.29620248079299927
Epoch: 110/300 - Train loss: 0.2869340777397156, Validation loss: 0.29506996273994446
Epoch: 111/300 - Train loss: 0.28543591499328613, Validation loss: 0.29392316937446594
Epoch: 112/300 - Train loss: 0.28396090865135193, Validation loss: 0.2916965186595917
Epoch: 113/300 - Train loss: 0.28250831365585327, Validation loss: 0.2907636761665344
Epoch: 114/300 - Train loss: 0.2810775935649872, Validation loss: 0.28932511806488037
Epoch: 115/300 - Train loss: 0.27966827154159546, Validation loss: 0.2878587543964386
Epoch: 116/300 - Train loss: 0.2782799303531647, Validation loss: 0.28662094473838806
Epoch: 117/300 - Train loss: 0.2769118547439575, Validation loss: 0.2855505347251892
Epoch: 118/300 - Train loss: 0.275563508272171, Validation loss: 0.28441277146339417
Epoch: 119/300 - Train loss: 0.2742345631122589, Validation loss: 0.2829548418521881
Epoch: 120/300 - Train loss: 0.2729245126247406, Validation loss: 0.28175675868988037
Epoch: 121/300 - Train loss: 0.2716330587863922, Validation loss: 0.2799142599105835
Epoch: 122/300 - Train loss: 0.27035969495773315, Validation loss: 0.27924442291259766
Epoch: 123/300 - Train loss: 0.2691040635108948, Validation loss: 0.27745383977890015
Epoch: 124/300 - Train loss: 0.26786577701568604, Validation loss: 0.27604812383651733
Epoch: 125/300 - Train loss: 0.2666444182395935, Validation loss: 0.275259405374527
Epoch: 126/300 - Train loss: 0.2654397785663605, Validation loss: 0.27389055490493774
Epoch: 127/300 - Train loss: 0.26425135135650635, Validation loss: 0.27283206582069397
Epoch: 128/300 - Train loss: 0.2630787193775177, Validation loss: 0.27147865295410156
Epoch: 129/300 - Train loss: 0.2619217038154602, Validation loss: 0.2705489993095398
Epoch: 130/300 - Train loss: 0.26078000664711, Validation loss: 0.269359827041626
Epoch: 131/300 - Train loss: 0.25965332984924316, Validation loss: 0.2685072124004364
Epoch: 132/300 - Train loss: 0.25854140520095825, Validation loss: 0.26750290393829346
Epoch: 133/300 - Train loss: 0.257443904876709, Validation loss: 0.2659204602241516
Epoch: 134/300 - Train loss: 0.25636065006256104, Validation loss: 0.2652527987957001
Epoch: 135/300 - Train loss: 0.25529128313064575, Validation loss: 0.2647640109062195
Epoch: 136/300 - Train loss: 0.25423550605773926, Validation loss: 0.2630034387111664
Epoch: 137/300 - Train loss: 0.25319311022758484, Validation loss: 0.2618735432624817
Epoch: 138/300 - Train loss: 0.2521638572216034, Validation loss: 0.261151522397995
Epoch: 139/300 - Train loss: 0.25114747881889343, Validation loss: 0.25999316573143005
Epoch: 140/300 - Train loss: 0.2501438558101654, Validation loss: 0.25855553150177
Epoch: 141/300 - Train loss: 0.24915271997451782, Validation loss: 0.25811102986335754
Epoch: 142/300 - Train loss: 0.24817384779453278, Validation loss: 0.25725841522216797
Epoch: 143/300 - Train loss: 0.24720703065395355, Validation loss: 0.2563769817352295
Epoch: 144/300 - Train loss: 0.24625208973884583, Validation loss: 0.2554246485233307
Epoch: 145/300 - Train loss: 0.24530883133411407, Validation loss: 0.25410446524620056
Epoch: 146/300 - Train loss: 0.24437712132930756, Validation loss: 0.2534870207309723
Epoch: 147/300 - Train loss: 0.24345673620700836, Validation loss: 0.25250163674354553
Epoch: 148/300 - Train loss: 0.24254749715328217, Validation loss: 0.2519878149032593
Epoch: 149/300 - Train loss: 0.24164924025535583, Validation loss: 0.25069257616996765
Epoch: 150/300 - Train loss: 0.24076177179813385, Validation loss: 0.24960434436798096
Epoch: 151/300 - Train loss: 0.23988492786884308, Validation loss: 0.2493099868297577
Epoch: 152/300 - Train loss: 0.23901858925819397, Validation loss: 0.24839624762535095
Epoch: 153/300 - Train loss: 0.23816250264644623, Validation loss: 0.247393399477005
Epoch: 154/300 - Train loss: 0.2373165488243103, Validation loss: 0.2461116909980774
Epoch: 155/300 - Train loss: 0.23648053407669067, Validation loss: 0.2456589639186859
Epoch: 156/300 - Train loss: 0.23565436899662018, Validation loss: 0.2448708862066269
Epoch: 157/300 - Train loss: 0.2348378747701645, Validation loss: 0.24389642477035522
Epoch: 158/300 - Train loss: 0.23403087258338928, Validation loss: 0.24331225454807281
Epoch: 159/300 - Train loss: 0.2332332581281662, Validation loss: 0.24248772859573364
Epoch: 160/300 - Train loss: 0.2324448674917221, Validation loss: 0.24157537519931793
Epoch: 161/300 - Train loss: 0.23166556656360626, Validation loss: 0.24111178517341614
Epoch: 162/300 - Train loss: 0.2308952808380127, Validation loss: 0.24029399454593658
Epoch: 163/300 - Train loss: 0.23013383150100708, Validation loss: 0.2398485690355301
Epoch: 164/300 - Train loss: 0.2293810099363327, Validation loss: 0.23878979682922363
Epoch: 165/300 - Train loss: 0.22863678634166718, Validation loss: 0.23789319396018982
Epoch: 166/300 - Train loss: 0.22790104150772095, Validation loss: 0.2383720576763153
Epoch: 167/300 - Train loss: 0.22717365622520447, Validation loss: 0.23625577986240387
Epoch: 168/300 - Train loss: 0.22645458579063416, Validation loss: 0.23649166524410248
Epoch: 169/300 - Train loss: 0.2257436364889145, Validation loss: 0.23515543341636658
Epoch: 170/300 - Train loss: 0.22504070401191711, Validation loss: 0.23390592634677887
Epoch: 171/300 - Train loss: 0.22434565424919128, Validation loss: 0.2338717132806778
Epoch: 172/300 - Train loss: 0.22365841269493103, Validation loss: 0.23339338600635529
Epoch: 173/300 - Train loss: 0.22297874093055725, Validation loss: 0.2325650155544281
Epoch: 174/300 - Train loss: 0.22230662405490875, Validation loss: 0.23211278021335602
Epoch: 175/300 - Train loss: 0.22164194285869598, Validation loss: 0.2308199405670166
Epoch: 176/300 - Train loss: 0.22098462283611298, Validation loss: 0.23044854402542114
Epoch: 177/300 - Train loss: 0.22033460438251495, Validation loss: 0.22991658747196198
Epoch: 178/300 - Train loss: 0.21969172358512878, Validation loss: 0.2290543019771576
Epoch: 179/300 - Train loss: 0.2190559059381485, Validation loss: 0.2289436161518097
