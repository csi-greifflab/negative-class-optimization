Epoch: 1/200 - Train loss: 0.5697631239891052, Validation loss: 0.48398494720458984
Epoch: 2/200 - Train loss: 0.45771318674087524, Validation loss: 0.4533518850803375
Epoch: 3/200 - Train loss: 0.42849209904670715, Validation loss: 0.4365434944629669
Epoch: 4/200 - Train loss: 0.40781503915786743, Validation loss: 0.4157164990901947
Epoch: 5/200 - Train loss: 0.3879900872707367, Validation loss: 0.39719367027282715
Epoch: 6/200 - Train loss: 0.3632504642009735, Validation loss: 0.3764606714248657
Epoch: 7/200 - Train loss: 0.3424983024597168, Validation loss: 0.35874536633491516
Epoch: 8/200 - Train loss: 0.32656964659690857, Validation loss: 0.3498851954936981
Epoch: 9/200 - Train loss: 0.31495049595832825, Validation loss: 0.3377634286880493
Epoch: 10/200 - Train loss: 0.3047623634338379, Validation loss: 0.3315325081348419
Epoch: 11/200 - Train loss: 0.2956661880016327, Validation loss: 0.32256075739860535
Epoch: 12/200 - Train loss: 0.2881111800670624, Validation loss: 0.3187353014945984
Epoch: 13/200 - Train loss: 0.28222888708114624, Validation loss: 0.3187773823738098
Epoch: 14/200 - Train loss: 0.27668818831443787, Validation loss: 0.31016477942466736
Epoch: 15/200 - Train loss: 0.2724851667881012, Validation loss: 0.30847981572151184
Epoch: 16/200 - Train loss: 0.2702747881412506, Validation loss: 0.30529311299324036
Epoch: 17/200 - Train loss: 0.2660968005657196, Validation loss: 0.30452272295951843
Epoch: 18/200 - Train loss: 0.2633827328681946, Validation loss: 0.30125707387924194
Epoch: 19/200 - Train loss: 0.260050505399704, Validation loss: 0.3029291033744812
Epoch: 20/200 - Train loss: 0.25826072692871094, Validation loss: 0.30824965238571167
Epoch: 21/200 - Train loss: 0.2567821741104126, Validation loss: 0.30091729760169983
Epoch: 22/200 - Train loss: 0.2542842626571655, Validation loss: 0.2980537712574005
Epoch: 23/200 - Train loss: 0.2534348964691162, Validation loss: 0.3034322261810303
Epoch: 24/200 - Train loss: 0.2522243857383728, Validation loss: 0.2969248294830322
Epoch: 25/200 - Train loss: 0.250634104013443, Validation loss: 0.2945912182331085
Epoch: 26/200 - Train loss: 0.2491520345211029, Validation loss: 0.29662978649139404
Epoch: 27/200 - Train loss: 0.2489638775587082, Validation loss: 0.29411351680755615
Epoch: 28/200 - Train loss: 0.24786344170570374, Validation loss: 0.2918398976325989
Epoch: 29/200 - Train loss: 0.24690194427967072, Validation loss: 0.29478564858436584
Epoch: 30/200 - Train loss: 0.2459433525800705, Validation loss: 0.2930087745189667
Epoch: 31/200 - Train loss: 0.24450156092643738, Validation loss: 0.2906301021575928
Epoch: 32/200 - Train loss: 0.24359363317489624, Validation loss: 0.29269635677337646
Epoch: 33/200 - Train loss: 0.24268510937690735, Validation loss: 0.29563623666763306
Epoch: 34/200 - Train loss: 0.2417798638343811, Validation loss: 0.2920987606048584
Epoch: 35/200 - Train loss: 0.24198946356773376, Validation loss: 0.2913055121898651
Epoch: 36/200 - Train loss: 0.24220553040504456, Validation loss: 0.2877961993217468
Epoch: 37/200 - Train loss: 0.24025793373584747, Validation loss: 0.28671693801879883
Epoch: 38/200 - Train loss: 0.2398924082517624, Validation loss: 0.29022154211997986
Epoch: 39/200 - Train loss: 0.23862263560295105, Validation loss: 0.2871541380882263
Epoch: 40/200 - Train loss: 0.2385140210390091, Validation loss: 0.28831347823143005
Epoch: 41/200 - Train loss: 0.23752513527870178, Validation loss: 0.28961700201034546
Epoch: 42/200 - Train loss: 0.2370351403951645, Validation loss: 0.2865796387195587
Epoch: 43/200 - Train loss: 0.23719176650047302, Validation loss: 0.29135873913764954
Epoch: 44/200 - Train loss: 0.23632323741912842, Validation loss: 0.28540703654289246
Epoch: 45/200 - Train loss: 0.23595567047595978, Validation loss: 0.2868890166282654
Epoch: 46/200 - Train loss: 0.23478737473487854, Validation loss: 0.28669872879981995
Epoch: 47/200 - Train loss: 0.23514370620250702, Validation loss: 0.28578153252601624
Epoch: 48/200 - Train loss: 0.23491854965686798, Validation loss: 0.28872931003570557
Epoch: 49/200 - Train loss: 0.23363858461380005, Validation loss: 0.286539763212204
Epoch: 50/200 - Train loss: 0.23340654373168945, Validation loss: 0.2864289879798889
Epoch: 51/200 - Train loss: 0.2326526790857315, Validation loss: 0.2833448350429535
Epoch: 52/200 - Train loss: 0.23351770639419556, Validation loss: 0.28942641615867615
Epoch: 53/200 - Train loss: 0.23181486129760742, Validation loss: 0.2852349281311035
Epoch: 54/200 - Train loss: 0.23288971185684204, Validation loss: 0.2871604561805725
Epoch: 55/200 - Train loss: 0.23260299861431122, Validation loss: 0.28603190183639526
Epoch: 56/200 - Train loss: 0.2309357225894928, Validation loss: 0.2833496630191803
Epoch: 57/200 - Train loss: 0.2309543341398239, Validation loss: 0.28422942757606506
Epoch: 58/200 - Train loss: 0.23108814656734467, Validation loss: 0.2843627333641052
Epoch: 59/200 - Train loss: 0.23032884299755096, Validation loss: 0.2796526253223419
Epoch: 60/200 - Train loss: 0.23064057528972626, Validation loss: 0.2825278639793396
Epoch: 61/200 - Train loss: 0.22909601032733917, Validation loss: 0.28474554419517517
Epoch: 62/200 - Train loss: 0.22941945493221283, Validation loss: 0.279521107673645
Epoch: 63/200 - Train loss: 0.22913940250873566, Validation loss: 0.27752482891082764
Epoch: 64/200 - Train loss: 0.22929027676582336, Validation loss: 0.28292757272720337
Epoch: 65/200 - Train loss: 0.22942383587360382, Validation loss: 0.28051048517227173
Epoch: 66/200 - Train loss: 0.22816717624664307, Validation loss: 0.2825702130794525
Epoch: 67/200 - Train loss: 0.2280656397342682, Validation loss: 0.27729740738868713
Epoch: 68/200 - Train loss: 0.2267608940601349, Validation loss: 0.28167209029197693
Epoch: 69/200 - Train loss: 0.22706562280654907, Validation loss: 0.27861887216567993
Epoch: 70/200 - Train loss: 0.22642308473587036, Validation loss: 0.28046271204948425
Epoch: 71/200 - Train loss: 0.226490780711174, Validation loss: 0.27903684973716736
Epoch: 72/200 - Train loss: 0.22556030750274658, Validation loss: 0.27637189626693726
Epoch: 73/200 - Train loss: 0.2262040227651596, Validation loss: 0.277152419090271
Epoch: 74/200 - Train loss: 0.2254336178302765, Validation loss: 0.2750042974948883
Epoch: 75/200 - Train loss: 0.22467324137687683, Validation loss: 0.27760764956474304
Epoch: 76/200 - Train loss: 0.2238466590642929, Validation loss: 0.2736779749393463
Epoch: 77/200 - Train loss: 0.22383840382099152, Validation loss: 0.27272602915763855
Epoch: 78/200 - Train loss: 0.2237350195646286, Validation loss: 0.27471670508384705
Epoch: 79/200 - Train loss: 0.22325941920280457, Validation loss: 0.2800377905368805
Epoch: 80/200 - Train loss: 0.22318756580352783, Validation loss: 0.2762197256088257
Epoch: 81/200 - Train loss: 0.2220316231250763, Validation loss: 0.27379584312438965
Epoch: 82/200 - Train loss: 0.2223612517118454, Validation loss: 0.279162734746933
Epoch: 83/200 - Train loss: 0.22244291007518768, Validation loss: 0.27463266253471375
Epoch: 84/200 - Train loss: 0.22127771377563477, Validation loss: 0.2790146470069885
Epoch: 85/200 - Train loss: 0.2207053154706955, Validation loss: 0.27377256751060486
Epoch: 86/200 - Train loss: 0.22015772759914398, Validation loss: 0.27830129861831665
Epoch: 87/200 - Train loss: 0.21915580332279205, Validation loss: 0.27475935220718384
Epoch: 88/200 - Train loss: 0.21942660212516785, Validation loss: 0.28102990984916687
Epoch: 89/200 - Train loss: 0.21879754960536957, Validation loss: 0.2755383551120758
Epoch: 90/200 - Train loss: 0.21790210902690887, Validation loss: 0.27612560987472534
Epoch: 91/200 - Train loss: 0.21764618158340454, Validation loss: 0.27373799681663513
Epoch: 92/200 - Train loss: 0.21754345297813416, Validation loss: 0.2714892327785492
Epoch: 93/200 - Train loss: 0.21675218641757965, Validation loss: 0.2693987786769867
Epoch: 94/200 - Train loss: 0.2162780612707138, Validation loss: 0.27178123593330383
Epoch: 95/200 - Train loss: 0.21582303941249847, Validation loss: 0.26921090483665466
Epoch: 96/200 - Train loss: 0.21526668965816498, Validation loss: 0.2698608636856079
Epoch: 97/200 - Train loss: 0.21427467465400696, Validation loss: 0.26928824186325073
Epoch: 98/200 - Train loss: 0.21475332975387573, Validation loss: 0.27250465750694275
Epoch: 99/200 - Train loss: 0.2138502150774002, Validation loss: 0.26893359422683716
Epoch: 100/200 - Train loss: 0.213446244597435, Validation loss: 0.2701707184314728
