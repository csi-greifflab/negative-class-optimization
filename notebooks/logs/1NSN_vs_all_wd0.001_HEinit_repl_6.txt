Epoch: 1/300 - Train loss: 0.7011211514472961, Validation loss: 0.6988805532455444
Epoch: 2/300 - Train loss: 0.6986076831817627, Validation loss: 0.6965487003326416
Epoch: 3/300 - Train loss: 0.696162223815918, Validation loss: 0.6941483616828918
Epoch: 4/300 - Train loss: 0.69377201795578, Validation loss: 0.6918200254440308
Epoch: 5/300 - Train loss: 0.6914280652999878, Validation loss: 0.6895842552185059
Epoch: 6/300 - Train loss: 0.6891211271286011, Validation loss: 0.6872704029083252
Epoch: 7/300 - Train loss: 0.6868375539779663, Validation loss: 0.6850060820579529
Epoch: 8/300 - Train loss: 0.6845592260360718, Validation loss: 0.682816207408905
Epoch: 9/300 - Train loss: 0.6822700500488281, Validation loss: 0.6805986166000366
Epoch: 10/300 - Train loss: 0.6799558997154236, Validation loss: 0.6782426238059998
Epoch: 11/300 - Train loss: 0.6776050925254822, Validation loss: 0.675832986831665
Epoch: 12/300 - Train loss: 0.6752039194107056, Validation loss: 0.6734621524810791
Epoch: 13/300 - Train loss: 0.6727401614189148, Validation loss: 0.6708984375
Epoch: 14/300 - Train loss: 0.670204222202301, Validation loss: 0.668343722820282
Epoch: 15/300 - Train loss: 0.6675833463668823, Validation loss: 0.6656674742698669
Epoch: 16/300 - Train loss: 0.6648651361465454, Validation loss: 0.6629184484481812
Epoch: 17/300 - Train loss: 0.6620410680770874, Validation loss: 0.6599729657173157
Epoch: 18/300 - Train loss: 0.6590988039970398, Validation loss: 0.6569265723228455
Epoch: 19/300 - Train loss: 0.6560317873954773, Validation loss: 0.6536904573440552
Epoch: 20/300 - Train loss: 0.6528332233428955, Validation loss: 0.6503863334655762
Epoch: 21/300 - Train loss: 0.6494957804679871, Validation loss: 0.6471647620201111
Epoch: 22/300 - Train loss: 0.6460135579109192, Validation loss: 0.643451452255249
Epoch: 23/300 - Train loss: 0.6423869132995605, Validation loss: 0.639738917350769
Epoch: 24/300 - Train loss: 0.6386126279830933, Validation loss: 0.6358022689819336
Epoch: 25/300 - Train loss: 0.634689450263977, Validation loss: 0.6317410469055176
Epoch: 26/300 - Train loss: 0.630617618560791, Validation loss: 0.6278755068778992
Epoch: 27/300 - Train loss: 0.6264007091522217, Validation loss: 0.6233310699462891
Epoch: 28/300 - Train loss: 0.6220450401306152, Validation loss: 0.6189272999763489
Epoch: 29/300 - Train loss: 0.6175564527511597, Validation loss: 0.6144865155220032
Epoch: 30/300 - Train loss: 0.6129472255706787, Validation loss: 0.6098883748054504
Epoch: 31/300 - Train loss: 0.6082247495651245, Validation loss: 0.6051217317581177
Epoch: 32/300 - Train loss: 0.6034039258956909, Validation loss: 0.6003268361091614
Epoch: 33/300 - Train loss: 0.5984940528869629, Validation loss: 0.5952098369598389
Epoch: 34/300 - Train loss: 0.593506932258606, Validation loss: 0.5903030633926392
Epoch: 35/300 - Train loss: 0.5884584188461304, Validation loss: 0.5852406024932861
Epoch: 36/300 - Train loss: 0.5833548903465271, Validation loss: 0.580159068107605
Epoch: 37/300 - Train loss: 0.5782084465026855, Validation loss: 0.5749064087867737
Epoch: 38/300 - Train loss: 0.5730277299880981, Validation loss: 0.5698658227920532
Epoch: 39/300 - Train loss: 0.5678243041038513, Validation loss: 0.5647608041763306
Epoch: 40/300 - Train loss: 0.5626074075698853, Validation loss: 0.5595417022705078
Epoch: 41/300 - Train loss: 0.5573908686637878, Validation loss: 0.5545545816421509
Epoch: 42/300 - Train loss: 0.5521815419197083, Validation loss: 0.5493823885917664
Epoch: 43/300 - Train loss: 0.5469851493835449, Validation loss: 0.5440672039985657
Epoch: 44/300 - Train loss: 0.5418059229850769, Validation loss: 0.5393253564834595
Epoch: 45/300 - Train loss: 0.5366535782814026, Validation loss: 0.5337767004966736
Epoch: 46/300 - Train loss: 0.5315314531326294, Validation loss: 0.5289761424064636
Epoch: 47/300 - Train loss: 0.5264441967010498, Validation loss: 0.5236395597457886
Epoch: 48/300 - Train loss: 0.5213990807533264, Validation loss: 0.5187865495681763
Epoch: 49/300 - Train loss: 0.5164023041725159, Validation loss: 0.5140333771705627
Epoch: 50/300 - Train loss: 0.5114576816558838, Validation loss: 0.5093730688095093
Epoch: 51/300 - Train loss: 0.5065714716911316, Validation loss: 0.5041067600250244
Epoch: 52/300 - Train loss: 0.5017482042312622, Validation loss: 0.4998287856578827
Epoch: 53/300 - Train loss: 0.4969910979270935, Validation loss: 0.49499350786209106
Epoch: 54/300 - Train loss: 0.4923032224178314, Validation loss: 0.4901590645313263
Epoch: 55/300 - Train loss: 0.48768875002861023, Validation loss: 0.4857662618160248
Epoch: 56/300 - Train loss: 0.48315170407295227, Validation loss: 0.48132142424583435
Epoch: 57/300 - Train loss: 0.4786941707134247, Validation loss: 0.47721126675605774
Epoch: 58/300 - Train loss: 0.47431886196136475, Validation loss: 0.4726310968399048
Epoch: 59/300 - Train loss: 0.47002771496772766, Validation loss: 0.46856895089149475
Epoch: 60/300 - Train loss: 0.4658221900463104, Validation loss: 0.46429315209388733
Epoch: 61/300 - Train loss: 0.4617050886154175, Validation loss: 0.4602327048778534
Epoch: 62/300 - Train loss: 0.45767781138420105, Validation loss: 0.4566071927547455
Epoch: 63/300 - Train loss: 0.4537412226200104, Validation loss: 0.45238518714904785
Epoch: 64/300 - Train loss: 0.44989660382270813, Validation loss: 0.44918644428253174
Epoch: 65/300 - Train loss: 0.44614312052726746, Validation loss: 0.4449206292629242
Epoch: 66/300 - Train loss: 0.4424811899662018, Validation loss: 0.4419819414615631
Epoch: 67/300 - Train loss: 0.4389086365699768, Validation loss: 0.4379778504371643
Epoch: 68/300 - Train loss: 0.43542519211769104, Validation loss: 0.43414580821990967
Epoch: 69/300 - Train loss: 0.4320295453071594, Validation loss: 0.4311322569847107
Epoch: 70/300 - Train loss: 0.42872169613838196, Validation loss: 0.4279266595840454
Epoch: 71/300 - Train loss: 0.4255000650882721, Validation loss: 0.4252018928527832
Epoch: 72/300 - Train loss: 0.42236337065696716, Validation loss: 0.4216400384902954
Epoch: 73/300 - Train loss: 0.4193090796470642, Validation loss: 0.418590784072876
Epoch: 74/300 - Train loss: 0.41633546352386475, Validation loss: 0.4159143567085266
Epoch: 75/300 - Train loss: 0.413440465927124, Validation loss: 0.4130449891090393
Epoch: 76/300 - Train loss: 0.41062164306640625, Validation loss: 0.41106343269348145
Epoch: 77/300 - Train loss: 0.40787702798843384, Validation loss: 0.40746769309043884
Epoch: 78/300 - Train loss: 0.4052048921585083, Validation loss: 0.40486180782318115
Epoch: 79/300 - Train loss: 0.40260282158851624, Validation loss: 0.4023810625076294
Epoch: 80/300 - Train loss: 0.40006837248802185, Validation loss: 0.4005144238471985
Epoch: 81/300 - Train loss: 0.3975994288921356, Validation loss: 0.39762812852859497
Epoch: 82/300 - Train loss: 0.3951944410800934, Validation loss: 0.3951739966869354
Epoch: 83/300 - Train loss: 0.3928511142730713, Validation loss: 0.3927588164806366
Epoch: 84/300 - Train loss: 0.3905671238899231, Validation loss: 0.3903738260269165
Epoch: 85/300 - Train loss: 0.3883400559425354, Validation loss: 0.38896119594573975
Epoch: 86/300 - Train loss: 0.386167973279953, Validation loss: 0.38621407747268677
Epoch: 87/300 - Train loss: 0.3840487003326416, Validation loss: 0.3841356337070465
Epoch: 88/300 - Train loss: 0.3819805383682251, Validation loss: 0.3824820816516876
Epoch: 89/300 - Train loss: 0.37996184825897217, Validation loss: 0.3801420032978058
Epoch: 90/300 - Train loss: 0.37799105048179626, Validation loss: 0.3789675235748291
Epoch: 91/300 - Train loss: 0.3760659396648407, Validation loss: 0.3762795925140381
Epoch: 92/300 - Train loss: 0.37418484687805176, Validation loss: 0.37480026483535767
Epoch: 93/300 - Train loss: 0.37234652042388916, Validation loss: 0.37233006954193115
Epoch: 94/300 - Train loss: 0.37054911255836487, Validation loss: 0.3712415099143982
Epoch: 95/300 - Train loss: 0.3687913119792938, Validation loss: 0.3694533109664917
Epoch: 96/300 - Train loss: 0.3670719563961029, Validation loss: 0.3680860698223114
Epoch: 97/300 - Train loss: 0.36538970470428467, Validation loss: 0.36640268564224243
Epoch: 98/300 - Train loss: 0.3637436330318451, Validation loss: 0.36476388573646545
Epoch: 99/300 - Train loss: 0.36213213205337524, Validation loss: 0.3627718687057495
Epoch: 100/300 - Train loss: 0.3605535328388214, Validation loss: 0.36136215925216675
Epoch: 101/300 - Train loss: 0.3590061664581299, Validation loss: 0.3599148094654083
Epoch: 102/300 - Train loss: 0.3574894368648529, Validation loss: 0.35802921652793884
Epoch: 103/300 - Train loss: 0.3560025095939636, Validation loss: 0.35662442445755005
Epoch: 104/300 - Train loss: 0.35454460978507996, Validation loss: 0.35595813393592834
Epoch: 105/300 - Train loss: 0.3531152009963989, Validation loss: 0.3538065552711487
Epoch: 106/300 - Train loss: 0.351712703704834, Validation loss: 0.3524418771266937
Epoch: 107/300 - Train loss: 0.3503362834453583, Validation loss: 0.35095784068107605
Epoch: 108/300 - Train loss: 0.3489847779273987, Validation loss: 0.3496238887310028
Epoch: 109/300 - Train loss: 0.3476574718952179, Validation loss: 0.3486207127571106
Epoch: 110/300 - Train loss: 0.3463538885116577, Validation loss: 0.34780123829841614
Epoch: 111/300 - Train loss: 0.34507355093955994, Validation loss: 0.34601685404777527
Epoch: 112/300 - Train loss: 0.34381556510925293, Validation loss: 0.3450661599636078
Epoch: 113/300 - Train loss: 0.3425794243812561, Validation loss: 0.344007670879364
Epoch: 114/300 - Train loss: 0.34136348962783813, Validation loss: 0.3428637385368347
Epoch: 115/300 - Train loss: 0.34016773104667664, Validation loss: 0.3414987027645111
Epoch: 116/300 - Train loss: 0.3389911949634552, Validation loss: 0.3402966856956482
Epoch: 117/300 - Train loss: 0.33783385157585144, Validation loss: 0.33924809098243713
Epoch: 118/300 - Train loss: 0.33669543266296387, Validation loss: 0.3381538391113281
Epoch: 119/300 - Train loss: 0.33557528257369995, Validation loss: 0.336957722902298
Epoch: 120/300 - Train loss: 0.33447304368019104, Validation loss: 0.3360399901866913
Epoch: 121/300 - Train loss: 0.3333885371685028, Validation loss: 0.33503228425979614
Epoch: 122/300 - Train loss: 0.33232104778289795, Validation loss: 0.3333470821380615
Epoch: 123/300 - Train loss: 0.3312698304653168, Validation loss: 0.33313095569610596
Epoch: 124/300 - Train loss: 0.3302344083786011, Validation loss: 0.33206725120544434
Epoch: 125/300 - Train loss: 0.3292143642902374, Validation loss: 0.33132076263427734
Epoch: 126/300 - Train loss: 0.32820940017700195, Validation loss: 0.3308752775192261
Epoch: 127/300 - Train loss: 0.3272191286087036, Validation loss: 0.3289858102798462
Epoch: 128/300 - Train loss: 0.3262428641319275, Validation loss: 0.3281569182872772
Epoch: 129/300 - Train loss: 0.3252800405025482, Validation loss: 0.32764932513237
Epoch: 130/300 - Train loss: 0.3243311643600464, Validation loss: 0.32638823986053467
Epoch: 131/300 - Train loss: 0.32339560985565186, Validation loss: 0.32559701800346375
Epoch: 132/300 - Train loss: 0.3224733769893646, Validation loss: 0.3247511088848114
Epoch: 133/300 - Train loss: 0.3215639293193817, Validation loss: 0.3240048885345459
Epoch: 134/300 - Train loss: 0.32066717743873596, Validation loss: 0.32248902320861816
Epoch: 135/300 - Train loss: 0.3197824954986572, Validation loss: 0.32169321179389954
Epoch: 136/300 - Train loss: 0.31890973448753357, Validation loss: 0.32117849588394165
Epoch: 137/300 - Train loss: 0.3180478513240814, Validation loss: 0.32016271352767944
Epoch: 138/300 - Train loss: 0.31719711422920227, Validation loss: 0.31923753023147583
Epoch: 139/300 - Train loss: 0.3163577616214752, Validation loss: 0.3185475468635559
Epoch: 140/300 - Train loss: 0.3155299127101898, Validation loss: 0.3176022171974182
Epoch: 141/300 - Train loss: 0.31471261382102966, Validation loss: 0.3166455626487732
Epoch: 142/300 - Train loss: 0.31390610337257385, Validation loss: 0.31642699241638184
Epoch: 143/300 - Train loss: 0.3131102919578552, Validation loss: 0.31588616967201233
Epoch: 144/300 - Train loss: 0.3123241662979126, Validation loss: 0.3149002492427826
Epoch: 145/300 - Train loss: 0.31154748797416687, Validation loss: 0.31375256180763245
Epoch: 146/300 - Train loss: 0.310780793428421, Validation loss: 0.3132674992084503
Epoch: 147/300 - Train loss: 0.3100247085094452, Validation loss: 0.312264621257782
Epoch: 148/300 - Train loss: 0.3092781901359558, Validation loss: 0.3114706873893738
Epoch: 149/300 - Train loss: 0.30854055285453796, Validation loss: 0.31119105219841003
Epoch: 150/300 - Train loss: 0.3078117370605469, Validation loss: 0.31013044714927673
Epoch: 151/300 - Train loss: 0.3070921003818512, Validation loss: 0.3094446063041687
Epoch: 152/300 - Train loss: 0.3063812255859375, Validation loss: 0.3088027536869049
Epoch: 153/300 - Train loss: 0.30567920207977295, Validation loss: 0.30814531445503235
Epoch: 154/300 - Train loss: 0.3049856126308441, Validation loss: 0.3081377148628235
Epoch: 155/300 - Train loss: 0.30430009961128235, Validation loss: 0.3068629503250122
Epoch: 156/300 - Train loss: 0.3036227524280548, Validation loss: 0.3064473271369934
Epoch: 157/300 - Train loss: 0.30295389890670776, Validation loss: 0.3056989014148712
Epoch: 158/300 - Train loss: 0.3022933900356293, Validation loss: 0.3050101697444916
Epoch: 159/300 - Train loss: 0.3016415536403656, Validation loss: 0.3044424057006836
Epoch: 160/300 - Train loss: 0.30099737644195557, Validation loss: 0.3039771020412445
Epoch: 161/300 - Train loss: 0.30036115646362305, Validation loss: 0.303676962852478
Epoch: 162/300 - Train loss: 0.29973283410072327, Validation loss: 0.3022741377353668
Epoch: 163/300 - Train loss: 0.29911166429519653, Validation loss: 0.3020012080669403
Epoch: 164/300 - Train loss: 0.2984983026981354, Validation loss: 0.30202800035476685
