Epoch: 1/300 - Train loss: 0.6997087001800537, Validation loss: 0.6993687748908997
Epoch: 2/300 - Train loss: 0.6979200839996338, Validation loss: 0.697780966758728
Epoch: 3/300 - Train loss: 0.696334183216095, Validation loss: 0.696249783039093
Epoch: 4/300 - Train loss: 0.6949076652526855, Validation loss: 0.6949378252029419
Epoch: 5/300 - Train loss: 0.6936007142066956, Validation loss: 0.693655788898468
Epoch: 6/300 - Train loss: 0.6923795342445374, Validation loss: 0.6922973394393921
Epoch: 7/300 - Train loss: 0.6912024021148682, Validation loss: 0.691207766532898
Epoch: 8/300 - Train loss: 0.690034031867981, Validation loss: 0.6898593902587891
Epoch: 9/300 - Train loss: 0.688852846622467, Validation loss: 0.6885968446731567
Epoch: 10/300 - Train loss: 0.6876417994499207, Validation loss: 0.6873944401741028
Epoch: 11/300 - Train loss: 0.6863881945610046, Validation loss: 0.6859336495399475
Epoch: 12/300 - Train loss: 0.6850788593292236, Validation loss: 0.6846426129341125
Epoch: 13/300 - Train loss: 0.683708667755127, Validation loss: 0.683169960975647
Epoch: 14/300 - Train loss: 0.6822742223739624, Validation loss: 0.6817032694816589
Epoch: 15/300 - Train loss: 0.6807742714881897, Validation loss: 0.680072546005249
Epoch: 16/300 - Train loss: 0.679200291633606, Validation loss: 0.6784236431121826
Epoch: 17/300 - Train loss: 0.6775534152984619, Validation loss: 0.6765248775482178
Epoch: 18/300 - Train loss: 0.6758305430412292, Validation loss: 0.6748386025428772
Epoch: 19/300 - Train loss: 0.6740302443504333, Validation loss: 0.6729575395584106
Epoch: 20/300 - Train loss: 0.6721549034118652, Validation loss: 0.6710529923439026
Epoch: 21/300 - Train loss: 0.6702077984809875, Validation loss: 0.6688642501831055
Epoch: 22/300 - Train loss: 0.6681939363479614, Validation loss: 0.6668143272399902
Epoch: 23/300 - Train loss: 0.6661196351051331, Validation loss: 0.6646830439567566
Epoch: 24/300 - Train loss: 0.6639857888221741, Validation loss: 0.6623899340629578
Epoch: 25/300 - Train loss: 0.6618008017539978, Validation loss: 0.6603154540061951
Epoch: 26/300 - Train loss: 0.6595719456672668, Validation loss: 0.6579545736312866
Epoch: 27/300 - Train loss: 0.6573061347007751, Validation loss: 0.655628502368927
Epoch: 28/300 - Train loss: 0.6550033688545227, Validation loss: 0.6533840298652649
Epoch: 29/300 - Train loss: 0.6526662111282349, Validation loss: 0.6510784029960632
Epoch: 30/300 - Train loss: 0.6502978205680847, Validation loss: 0.6484791040420532
Epoch: 31/300 - Train loss: 0.6478954553604126, Validation loss: 0.6461307406425476
Epoch: 32/300 - Train loss: 0.6454638242721558, Validation loss: 0.6436920166015625
Epoch: 33/300 - Train loss: 0.6430003643035889, Validation loss: 0.6410463452339172
Epoch: 34/300 - Train loss: 0.6405118107795715, Validation loss: 0.6386666893959045
Epoch: 35/300 - Train loss: 0.6379960179328918, Validation loss: 0.6361740231513977
Epoch: 36/300 - Train loss: 0.6354584097862244, Validation loss: 0.6336164474487305
Epoch: 37/300 - Train loss: 0.6329023241996765, Validation loss: 0.6311569809913635
Epoch: 38/300 - Train loss: 0.6303293704986572, Validation loss: 0.6286394000053406
Epoch: 39/300 - Train loss: 0.627743124961853, Validation loss: 0.6257953643798828
Epoch: 40/300 - Train loss: 0.625148355960846, Validation loss: 0.6233348846435547
Epoch: 41/300 - Train loss: 0.6225485801696777, Validation loss: 0.6206706762313843
Epoch: 42/300 - Train loss: 0.6199500560760498, Validation loss: 0.6180486083030701
Epoch: 43/300 - Train loss: 0.6173543930053711, Validation loss: 0.615686297416687
Epoch: 44/300 - Train loss: 0.6147637367248535, Validation loss: 0.6129105091094971
Epoch: 45/300 - Train loss: 0.6121789813041687, Validation loss: 0.6105614304542542
Epoch: 46/300 - Train loss: 0.6096025109291077, Validation loss: 0.6080405116081238
Epoch: 47/300 - Train loss: 0.6070374846458435, Validation loss: 0.6057155728340149
Epoch: 48/300 - Train loss: 0.6044830679893494, Validation loss: 0.6031363010406494
Epoch: 49/300 - Train loss: 0.601941704750061, Validation loss: 0.6004517674446106
Epoch: 50/300 - Train loss: 0.5994156002998352, Validation loss: 0.5982550382614136
Epoch: 51/300 - Train loss: 0.5969058871269226, Validation loss: 0.5955637693405151
Epoch: 52/300 - Train loss: 0.5944151282310486, Validation loss: 0.593099057674408
Epoch: 53/300 - Train loss: 0.5919439792633057, Validation loss: 0.5907672643661499
Epoch: 54/300 - Train loss: 0.5894924402236938, Validation loss: 0.5883897542953491
Epoch: 55/300 - Train loss: 0.5870621204376221, Validation loss: 0.5857672095298767
Epoch: 56/300 - Train loss: 0.5846545696258545, Validation loss: 0.5836705565452576
Epoch: 57/300 - Train loss: 0.5822710990905762, Validation loss: 0.581244707107544
Epoch: 58/300 - Train loss: 0.5799117088317871, Validation loss: 0.578964352607727
Epoch: 59/300 - Train loss: 0.5775775909423828, Validation loss: 0.5767799615859985
Epoch: 60/300 - Train loss: 0.5752685070037842, Validation loss: 0.5745234489440918
Epoch: 61/300 - Train loss: 0.5729847550392151, Validation loss: 0.5721821784973145
Epoch: 62/300 - Train loss: 0.5707277655601501, Validation loss: 0.5701589584350586
Epoch: 63/300 - Train loss: 0.5684974789619446, Validation loss: 0.5680404901504517
Epoch: 64/300 - Train loss: 0.5662940144538879, Validation loss: 0.565680742263794
Epoch: 65/300 - Train loss: 0.5641177892684937, Validation loss: 0.5639545321464539
Epoch: 66/300 - Train loss: 0.5619692206382751, Validation loss: 0.5619167685508728
Epoch: 67/300 - Train loss: 0.5598474144935608, Validation loss: 0.5596887469291687
Epoch: 68/300 - Train loss: 0.5577521920204163, Validation loss: 0.5575870275497437
Epoch: 69/300 - Train loss: 0.5556836724281311, Validation loss: 0.5554893612861633
Epoch: 70/300 - Train loss: 0.5536425113677979, Validation loss: 0.5537257194519043
Epoch: 71/300 - Train loss: 0.551628053188324, Validation loss: 0.5519369840621948
Epoch: 72/300 - Train loss: 0.5496392250061035, Validation loss: 0.5498039722442627
Epoch: 73/300 - Train loss: 0.5476756691932678, Validation loss: 0.5484195947647095
Epoch: 74/300 - Train loss: 0.5457368493080139, Validation loss: 0.5465349555015564
Epoch: 75/300 - Train loss: 0.5438219904899597, Validation loss: 0.5442504286766052
Epoch: 76/300 - Train loss: 0.541930079460144, Validation loss: 0.5425103902816772
Epoch: 77/300 - Train loss: 0.5400609970092773, Validation loss: 0.5407257676124573
Epoch: 78/300 - Train loss: 0.538213312625885, Validation loss: 0.5388025045394897
Epoch: 79/300 - Train loss: 0.5363861918449402, Validation loss: 0.5373609662055969
Epoch: 80/300 - Train loss: 0.5345798134803772, Validation loss: 0.5355228185653687
Epoch: 81/300 - Train loss: 0.5327939391136169, Validation loss: 0.5338361859321594
Epoch: 82/300 - Train loss: 0.531026303768158, Validation loss: 0.5321553349494934
Epoch: 83/300 - Train loss: 0.529276430606842, Validation loss: 0.530581533908844
Epoch: 84/300 - Train loss: 0.5275444388389587, Validation loss: 0.5287796854972839
Epoch: 85/300 - Train loss: 0.5258293151855469, Validation loss: 0.5268882513046265
Epoch: 86/300 - Train loss: 0.5241298675537109, Validation loss: 0.5255574584007263
Epoch: 87/300 - Train loss: 0.5224453806877136, Validation loss: 0.5244249105453491
Epoch: 88/300 - Train loss: 0.5207762718200684, Validation loss: 0.5224862098693848
Epoch: 89/300 - Train loss: 0.5191212892532349, Validation loss: 0.5213904976844788
Epoch: 90/300 - Train loss: 0.5174805521965027, Validation loss: 0.5191457271575928
Epoch: 91/300 - Train loss: 0.5158535838127136, Validation loss: 0.5174892544746399
Epoch: 92/300 - Train loss: 0.5142382979393005, Validation loss: 0.5162873268127441
Epoch: 93/300 - Train loss: 0.5126338601112366, Validation loss: 0.514210045337677
Epoch: 94/300 - Train loss: 0.511039674282074, Validation loss: 0.513113796710968
Epoch: 95/300 - Train loss: 0.5094560384750366, Validation loss: 0.5115155577659607
Epoch: 96/300 - Train loss: 0.507882297039032, Validation loss: 0.5099867582321167
Epoch: 97/300 - Train loss: 0.5063150525093079, Validation loss: 0.5088202953338623
Epoch: 98/300 - Train loss: 0.5047556161880493, Validation loss: 0.5072484016418457
Epoch: 99/300 - Train loss: 0.5032026767730713, Validation loss: 0.5054803490638733
Epoch: 100/300 - Train loss: 0.5016562938690186, Validation loss: 0.503929615020752
Epoch: 101/300 - Train loss: 0.5001178979873657, Validation loss: 0.5022609829902649
Epoch: 102/300 - Train loss: 0.49858811497688293, Validation loss: 0.5011069178581238
Epoch: 103/300 - Train loss: 0.4970649778842926, Validation loss: 0.49981585144996643
Epoch: 104/300 - Train loss: 0.4955483078956604, Validation loss: 0.4983181059360504
Epoch: 105/300 - Train loss: 0.4940379858016968, Validation loss: 0.496409147977829
Epoch: 106/300 - Train loss: 0.4925336539745331, Validation loss: 0.49498462677001953
Epoch: 107/300 - Train loss: 0.4910372197628021, Validation loss: 0.49374473094940186
Epoch: 108/300 - Train loss: 0.48954641819000244, Validation loss: 0.4924786388874054
Epoch: 109/300 - Train loss: 0.4880613386631012, Validation loss: 0.49068495631217957
Epoch: 110/300 - Train loss: 0.4865826964378357, Validation loss: 0.4888715445995331
Epoch: 111/300 - Train loss: 0.48511001467704773, Validation loss: 0.48754844069480896
Epoch: 112/300 - Train loss: 0.48364126682281494, Validation loss: 0.486569344997406
Epoch: 113/300 - Train loss: 0.48217591643333435, Validation loss: 0.4849274158477783
Epoch: 114/300 - Train loss: 0.48071548342704773, Validation loss: 0.48319315910339355
Epoch: 115/300 - Train loss: 0.47925981879234314, Validation loss: 0.482183039188385
Epoch: 116/300 - Train loss: 0.47780850529670715, Validation loss: 0.4808429181575775
Epoch: 117/300 - Train loss: 0.47636210918426514, Validation loss: 0.4794234037399292
Epoch: 118/300 - Train loss: 0.4749208986759186, Validation loss: 0.4775429964065552
Epoch: 119/300 - Train loss: 0.4734853208065033, Validation loss: 0.47613850235939026
Epoch: 120/300 - Train loss: 0.4720532298088074, Validation loss: 0.47454890608787537
Epoch: 121/300 - Train loss: 0.47062528133392334, Validation loss: 0.4737972915172577
Epoch: 122/300 - Train loss: 0.46920260787010193, Validation loss: 0.47175663709640503
Epoch: 123/300 - Train loss: 0.4677847921848297, Validation loss: 0.47117742896080017
Epoch: 124/300 - Train loss: 0.4663715958595276, Validation loss: 0.4694792628288269
Epoch: 125/300 - Train loss: 0.46496182680130005, Validation loss: 0.46818625926971436
Epoch: 126/300 - Train loss: 0.46355703473091125, Validation loss: 0.4670974612236023
Epoch: 127/300 - Train loss: 0.46215763688087463, Validation loss: 0.46552592515945435
Epoch: 128/300 - Train loss: 0.46076351404190063, Validation loss: 0.4644479751586914
Epoch: 129/300 - Train loss: 0.4593731164932251, Validation loss: 0.4623335897922516
Epoch: 130/300 - Train loss: 0.45798856019973755, Validation loss: 0.4615340530872345
Epoch: 131/300 - Train loss: 0.45661094784736633, Validation loss: 0.4595949947834015
Epoch: 132/300 - Train loss: 0.45524194836616516, Validation loss: 0.45892396569252014
Epoch: 133/300 - Train loss: 0.45388033986091614, Validation loss: 0.45717212557792664
Epoch: 134/300 - Train loss: 0.4525262415409088, Validation loss: 0.4558393359184265
Epoch: 135/300 - Train loss: 0.45118218660354614, Validation loss: 0.4550699293613434
Epoch: 136/300 - Train loss: 0.4498472809791565, Validation loss: 0.45331400632858276
Epoch: 137/300 - Train loss: 0.4485205411911011, Validation loss: 0.45233917236328125
Epoch: 138/300 - Train loss: 0.44720160961151123, Validation loss: 0.45100411772727966
Epoch: 139/300 - Train loss: 0.44589143991470337, Validation loss: 0.4500100016593933
Epoch: 140/300 - Train loss: 0.44458937644958496, Validation loss: 0.44853323698043823
Epoch: 141/300 - Train loss: 0.4432956874370575, Validation loss: 0.44730526208877563
Epoch: 142/300 - Train loss: 0.4420119822025299, Validation loss: 0.44612249732017517
Epoch: 143/300 - Train loss: 0.44073840975761414, Validation loss: 0.44461777806282043
Epoch: 144/300 - Train loss: 0.43947431445121765, Validation loss: 0.4435291886329651
Epoch: 145/300 - Train loss: 0.43822014331817627, Validation loss: 0.44297924637794495
Epoch: 146/300 - Train loss: 0.43697547912597656, Validation loss: 0.44117945432662964
Epoch: 147/300 - Train loss: 0.43573975563049316, Validation loss: 0.4396840035915375
Epoch: 148/300 - Train loss: 0.43451207876205444, Validation loss: 0.4386497437953949
Epoch: 149/300 - Train loss: 0.433292955160141, Validation loss: 0.4377058148384094
Epoch: 150/300 - Train loss: 0.43208199739456177, Validation loss: 0.43665289878845215
Epoch: 151/300 - Train loss: 0.4308791160583496, Validation loss: 0.435634046792984
Epoch: 152/300 - Train loss: 0.4296850264072418, Validation loss: 0.4344261884689331
Epoch: 153/300 - Train loss: 0.4285009503364563, Validation loss: 0.4327698051929474
Epoch: 154/300 - Train loss: 0.42732611298561096, Validation loss: 0.4323227107524872
Epoch: 155/300 - Train loss: 0.4261602461338043, Validation loss: 0.4314538836479187
Epoch: 156/300 - Train loss: 0.4250045418739319, Validation loss: 0.4301352798938751
Epoch: 157/300 - Train loss: 0.4238598644733429, Validation loss: 0.4290376603603363
Epoch: 158/300 - Train loss: 0.4227251708507538, Validation loss: 0.4275514483451843
Epoch: 159/300 - Train loss: 0.42160049080848694, Validation loss: 0.4266253411769867
Epoch: 160/300 - Train loss: 0.42048633098602295, Validation loss: 0.4252857565879822
Epoch: 161/300 - Train loss: 0.419383704662323, Validation loss: 0.4244750440120697
Epoch: 162/300 - Train loss: 0.4182930886745453, Validation loss: 0.42303603887557983
Epoch: 163/300 - Train loss: 0.4172137975692749, Validation loss: 0.42219164967536926
Epoch: 164/300 - Train loss: 0.4161446988582611, Validation loss: 0.4213101863861084
Epoch: 165/300 - Train loss: 0.41508641839027405, Validation loss: 0.420430064201355
Epoch: 166/300 - Train loss: 0.41403910517692566, Validation loss: 0.4197526276111603
Epoch: 167/300 - Train loss: 0.41300320625305176, Validation loss: 0.4183969795703888
Epoch: 168/300 - Train loss: 0.41197746992111206, Validation loss: 0.4181075990200043
Epoch: 169/300 - Train loss: 0.4109618663787842, Validation loss: 0.41608288884162903
Epoch: 170/300 - Train loss: 0.4099566638469696, Validation loss: 0.4154435992240906
Epoch: 171/300 - Train loss: 0.40896183252334595, Validation loss: 0.41523149609565735
Epoch: 172/300 - Train loss: 0.40797725319862366, Validation loss: 0.41398146748542786
Epoch: 173/300 - Train loss: 0.4070030748844147, Validation loss: 0.41280397772789
Epoch: 174/300 - Train loss: 0.406038761138916, Validation loss: 0.4117084741592407
Epoch: 175/300 - Train loss: 0.4050844609737396, Validation loss: 0.4115257263183594
Epoch: 176/300 - Train loss: 0.40414026379585266, Validation loss: 0.40996190905570984
Epoch: 177/300 - Train loss: 0.40320587158203125, Validation loss: 0.4091777801513672
Epoch: 178/300 - Train loss: 0.40228161215782166, Validation loss: 0.4081408679485321
Epoch: 179/300 - Train loss: 0.4013678729534149, Validation loss: 0.40743276476860046
Epoch: 180/300 - Train loss: 0.4004633128643036, Validation loss: 0.4064478874206543
Epoch: 181/300 - Train loss: 0.39956727623939514, Validation loss: 0.40607377886772156
Epoch: 182/300 - Train loss: 0.39868032932281494, Validation loss: 0.4047912359237671
Epoch: 183/300 - Train loss: 0.3978029191493988, Validation loss: 0.40419983863830566
Epoch: 184/300 - Train loss: 0.3969346582889557, Validation loss: 0.4035893976688385
Epoch: 185/300 - Train loss: 0.39607569575309753, Validation loss: 0.4025173485279083
Epoch: 186/300 - Train loss: 0.3952260911464691, Validation loss: 0.4017278552055359
Epoch: 187/300 - Train loss: 0.394385427236557, Validation loss: 0.40089935064315796
Epoch: 188/300 - Train loss: 0.3935537338256836, Validation loss: 0.3997710049152374
Epoch: 189/300 - Train loss: 0.3927308917045593, Validation loss: 0.3994777202606201
Epoch: 190/300 - Train loss: 0.3919161260128021, Validation loss: 0.3983710706233978
Epoch: 191/300 - Train loss: 0.3911092281341553, Validation loss: 0.39735937118530273
Epoch: 192/300 - Train loss: 0.3903100788593292, Validation loss: 0.3969678282737732
Epoch: 193/300 - Train loss: 0.38951852917671204, Validation loss: 0.3958762288093567
Epoch: 194/300 - Train loss: 0.38873451948165894, Validation loss: 0.3952520787715912
Epoch: 195/300 - Train loss: 0.38795843720436096, Validation loss: 0.39443209767341614
Epoch: 196/300 - Train loss: 0.38719022274017334, Validation loss: 0.3936600685119629
Epoch: 197/300 - Train loss: 0.38642942905426025, Validation loss: 0.39354416728019714
Epoch: 198/300 - Train loss: 0.3856763541698456, Validation loss: 0.3926560878753662
Epoch: 199/300 - Train loss: 0.3849310278892517, Validation loss: 0.39173880219459534
Epoch: 200/300 - Train loss: 0.3841933012008667, Validation loss: 0.3910887539386749
Epoch: 201/300 - Train loss: 0.38346362113952637, Validation loss: 0.39020660519599915
Epoch: 202/300 - Train loss: 0.3827410340309143, Validation loss: 0.3899318277835846
Epoch: 203/300 - Train loss: 0.3820260167121887, Validation loss: 0.38947659730911255
Epoch: 204/300 - Train loss: 0.38131818175315857, Validation loss: 0.3879905045032501
Epoch: 205/300 - Train loss: 0.38061776757240295, Validation loss: 0.3881548345088959
Epoch: 206/300 - Train loss: 0.37992405891418457, Validation loss: 0.38697510957717896
Epoch: 207/300 - Train loss: 0.379237562417984, Validation loss: 0.3860439658164978
Epoch: 208/300 - Train loss: 0.37855783104896545, Validation loss: 0.38609257340431213
Epoch: 209/300 - Train loss: 0.37788456678390503, Validation loss: 0.3848217725753784
Epoch: 210/300 - Train loss: 0.3772176504135132, Validation loss: 0.3842508792877197
Epoch: 211/300 - Train loss: 0.37655752897262573, Validation loss: 0.38421404361724854
Epoch: 212/300 - Train loss: 0.37590399384498596, Validation loss: 0.3837483525276184
Epoch: 213/300 - Train loss: 0.37525662779808044, Validation loss: 0.38322022557258606
