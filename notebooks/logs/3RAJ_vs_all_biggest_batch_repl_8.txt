Epoch: 1/300 - Train loss: 0.6937484741210938, Validation loss: 0.6932384371757507
Epoch: 2/300 - Train loss: 0.692122220993042, Validation loss: 0.6917593479156494
Epoch: 3/300 - Train loss: 0.6906280517578125, Validation loss: 0.6901909708976746
Epoch: 4/300 - Train loss: 0.6892136335372925, Validation loss: 0.6887668371200562
Epoch: 5/300 - Train loss: 0.6878388524055481, Validation loss: 0.6872701644897461
Epoch: 6/300 - Train loss: 0.6864625215530396, Validation loss: 0.6858176589012146
Epoch: 7/300 - Train loss: 0.6850535273551941, Validation loss: 0.6843669414520264
Epoch: 8/300 - Train loss: 0.6835834383964539, Validation loss: 0.6828393340110779
Epoch: 9/300 - Train loss: 0.6820350885391235, Validation loss: 0.6811784505844116
Epoch: 10/300 - Train loss: 0.6804014444351196, Validation loss: 0.6794765591621399
Epoch: 11/300 - Train loss: 0.6786797642707825, Validation loss: 0.6778022050857544
Epoch: 12/300 - Train loss: 0.6768736839294434, Validation loss: 0.6758416295051575
Epoch: 13/300 - Train loss: 0.674988865852356, Validation loss: 0.6739089488983154
Epoch: 14/300 - Train loss: 0.6730327010154724, Validation loss: 0.6720417141914368
Epoch: 15/300 - Train loss: 0.671014666557312, Validation loss: 0.6700162887573242
Epoch: 16/300 - Train loss: 0.6689409017562866, Validation loss: 0.6678696870803833
Epoch: 17/300 - Train loss: 0.666827917098999, Validation loss: 0.6657276153564453
Epoch: 18/300 - Train loss: 0.6646825671195984, Validation loss: 0.6634948253631592
Epoch: 19/300 - Train loss: 0.6625087261199951, Validation loss: 0.6613398790359497
Epoch: 20/300 - Train loss: 0.6603081226348877, Validation loss: 0.659062385559082
Epoch: 21/300 - Train loss: 0.6580829620361328, Validation loss: 0.6568148136138916
Epoch: 22/300 - Train loss: 0.655838131904602, Validation loss: 0.654635488986969
Epoch: 23/300 - Train loss: 0.6535712480545044, Validation loss: 0.6524145603179932
Epoch: 24/300 - Train loss: 0.6512806415557861, Validation loss: 0.6501973271369934
Epoch: 25/300 - Train loss: 0.6489685773849487, Validation loss: 0.6475562453269958
Epoch: 26/300 - Train loss: 0.6466363072395325, Validation loss: 0.64547199010849
Epoch: 27/300 - Train loss: 0.6442858576774597, Validation loss: 0.6429587602615356
Epoch: 28/300 - Train loss: 0.6419209241867065, Validation loss: 0.6404382586479187
Epoch: 29/300 - Train loss: 0.639543354511261, Validation loss: 0.6380972862243652
Epoch: 30/300 - Train loss: 0.6371558308601379, Validation loss: 0.6356631517410278
Epoch: 31/300 - Train loss: 0.6347623467445374, Validation loss: 0.6333696246147156
Epoch: 32/300 - Train loss: 0.632366418838501, Validation loss: 0.6309176683425903
Epoch: 33/300 - Train loss: 0.6299669742584229, Validation loss: 0.6285663843154907
Epoch: 34/300 - Train loss: 0.6275652050971985, Validation loss: 0.6261953115463257
Epoch: 35/300 - Train loss: 0.6251640915870667, Validation loss: 0.6236282587051392
Epoch: 36/300 - Train loss: 0.6227633953094482, Validation loss: 0.6215752959251404
Epoch: 37/300 - Train loss: 0.6203640699386597, Validation loss: 0.6189970374107361
Epoch: 38/300 - Train loss: 0.6179662942886353, Validation loss: 0.6167901158332825
Epoch: 39/300 - Train loss: 0.6155720353126526, Validation loss: 0.6144461631774902
Epoch: 40/300 - Train loss: 0.6131817102432251, Validation loss: 0.6119816303253174
Epoch: 41/300 - Train loss: 0.6107966303825378, Validation loss: 0.6095408201217651
Epoch: 42/300 - Train loss: 0.6084192991256714, Validation loss: 0.6070917248725891
Epoch: 43/300 - Train loss: 0.6060497760772705, Validation loss: 0.6047985553741455
Epoch: 44/300 - Train loss: 0.6036881804466248, Validation loss: 0.602394163608551
Epoch: 45/300 - Train loss: 0.6013354659080505, Validation loss: 0.6003034710884094
Epoch: 46/300 - Train loss: 0.5989920496940613, Validation loss: 0.5976572036743164
Epoch: 47/300 - Train loss: 0.5966584086418152, Validation loss: 0.5958271026611328
Epoch: 48/300 - Train loss: 0.5943361520767212, Validation loss: 0.5935923457145691
Epoch: 49/300 - Train loss: 0.592024564743042, Validation loss: 0.5914264917373657
Epoch: 50/300 - Train loss: 0.5897252559661865, Validation loss: 0.5890306830406189
Epoch: 51/300 - Train loss: 0.587439239025116, Validation loss: 0.5867605209350586
Epoch: 52/300 - Train loss: 0.5851680040359497, Validation loss: 0.5844601988792419
Epoch: 53/300 - Train loss: 0.5829126238822937, Validation loss: 0.5824848413467407
Epoch: 54/300 - Train loss: 0.5806742906570435, Validation loss: 0.5807409286499023
Epoch: 55/300 - Train loss: 0.5784536004066467, Validation loss: 0.5779498815536499
Epoch: 56/300 - Train loss: 0.5762505531311035, Validation loss: 0.5762332677841187
Epoch: 57/300 - Train loss: 0.5740648508071899, Validation loss: 0.5739801526069641
Epoch: 58/300 - Train loss: 0.5718958973884583, Validation loss: 0.5719212293624878
Epoch: 59/300 - Train loss: 0.5697448253631592, Validation loss: 0.5699054598808289
Epoch: 60/300 - Train loss: 0.5676118731498718, Validation loss: 0.5677534937858582
Epoch: 61/300 - Train loss: 0.5654968023300171, Validation loss: 0.5655076503753662
Epoch: 62/300 - Train loss: 0.5633998513221741, Validation loss: 0.5639917850494385
Epoch: 63/300 - Train loss: 0.561321496963501, Validation loss: 0.5617960691452026
Epoch: 64/300 - Train loss: 0.5592617392539978, Validation loss: 0.5597128868103027
Epoch: 65/300 - Train loss: 0.5572199821472168, Validation loss: 0.5573011040687561
Epoch: 66/300 - Train loss: 0.5551960468292236, Validation loss: 0.5559272170066833
Epoch: 67/300 - Train loss: 0.5531901717185974, Validation loss: 0.5541133880615234
Epoch: 68/300 - Train loss: 0.5512023568153381, Validation loss: 0.5517803430557251
Epoch: 69/300 - Train loss: 0.5492329001426697, Validation loss: 0.5497578978538513
Epoch: 70/300 - Train loss: 0.5472814440727234, Validation loss: 0.5483556389808655
Epoch: 71/300 - Train loss: 0.545347273349762, Validation loss: 0.5465545058250427
Epoch: 72/300 - Train loss: 0.5434297919273376, Validation loss: 0.5451648235321045
Epoch: 73/300 - Train loss: 0.541529655456543, Validation loss: 0.5422676205635071
Epoch: 74/300 - Train loss: 0.5396451950073242, Validation loss: 0.5415077805519104
Epoch: 75/300 - Train loss: 0.5377762913703918, Validation loss: 0.5389794707298279
Epoch: 76/300 - Train loss: 0.535922646522522, Validation loss: 0.5373923778533936
Epoch: 77/300 - Train loss: 0.5340843796730042, Validation loss: 0.5356945395469666
Epoch: 78/300 - Train loss: 0.532260537147522, Validation loss: 0.5340684056282043
Epoch: 79/300 - Train loss: 0.5304511785507202, Validation loss: 0.5323224067687988
Epoch: 80/300 - Train loss: 0.5286561846733093, Validation loss: 0.5306885838508606
Epoch: 81/300 - Train loss: 0.5268753170967102, Validation loss: 0.5286159515380859
Epoch: 82/300 - Train loss: 0.5251078605651855, Validation loss: 0.5272397994995117
Epoch: 83/300 - Train loss: 0.5233531594276428, Validation loss: 0.5251925587654114
Epoch: 84/300 - Train loss: 0.5216116309165955, Validation loss: 0.5232837200164795
Epoch: 85/300 - Train loss: 0.5198822021484375, Validation loss: 0.5220372676849365
Epoch: 86/300 - Train loss: 0.5181626677513123, Validation loss: 0.5205585360527039
Epoch: 87/300 - Train loss: 0.5164543390274048, Validation loss: 0.518892765045166
Epoch: 88/300 - Train loss: 0.5147570967674255, Validation loss: 0.5173764228820801
Epoch: 89/300 - Train loss: 0.51307213306427, Validation loss: 0.5152934193611145
Epoch: 90/300 - Train loss: 0.5113990902900696, Validation loss: 0.5141107439994812
Epoch: 91/300 - Train loss: 0.509736955165863, Validation loss: 0.5121082067489624
Epoch: 92/300 - Train loss: 0.508087694644928, Validation loss: 0.5105923414230347
Epoch: 93/300 - Train loss: 0.5064519047737122, Validation loss: 0.5087876319885254
Epoch: 94/300 - Train loss: 0.5048302412033081, Validation loss: 0.5073140859603882
Epoch: 95/300 - Train loss: 0.503221869468689, Validation loss: 0.5056896805763245
Epoch: 96/300 - Train loss: 0.5016244649887085, Validation loss: 0.5041533708572388
Epoch: 97/300 - Train loss: 0.500039279460907, Validation loss: 0.5029579997062683
Epoch: 98/300 - Train loss: 0.49846476316452026, Validation loss: 0.5014815330505371
Epoch: 99/300 - Train loss: 0.4969009459018707, Validation loss: 0.500332236289978
Epoch: 100/300 - Train loss: 0.49534761905670166, Validation loss: 0.49823644757270813
Epoch: 101/300 - Train loss: 0.49380433559417725, Validation loss: 0.4966498613357544
Epoch: 102/300 - Train loss: 0.49227121472358704, Validation loss: 0.4955887198448181
Epoch: 103/300 - Train loss: 0.4907486140727997, Validation loss: 0.4938898980617523
Epoch: 104/300 - Train loss: 0.4892347455024719, Validation loss: 0.49252262711524963
Epoch: 105/300 - Train loss: 0.48773103952407837, Validation loss: 0.49041101336479187
Epoch: 106/300 - Train loss: 0.48623859882354736, Validation loss: 0.48995324969291687
Epoch: 107/300 - Train loss: 0.4847564995288849, Validation loss: 0.4880739748477936
Epoch: 108/300 - Train loss: 0.48328298330307007, Validation loss: 0.4864107072353363
Epoch: 109/300 - Train loss: 0.48181799054145813, Validation loss: 0.4847821891307831
Epoch: 110/300 - Train loss: 0.4803636074066162, Validation loss: 0.48385101556777954
Epoch: 111/300 - Train loss: 0.478920042514801, Validation loss: 0.4823131859302521
Epoch: 112/300 - Train loss: 0.477487176656723, Validation loss: 0.4807569980621338
Epoch: 113/300 - Train loss: 0.47606390714645386, Validation loss: 0.4794197082519531
Epoch: 114/300 - Train loss: 0.47465118765830994, Validation loss: 0.4781648516654968
Epoch: 115/300 - Train loss: 0.4732487201690674, Validation loss: 0.47661092877388
Epoch: 116/300 - Train loss: 0.47185519337654114, Validation loss: 0.4754577875137329
Epoch: 117/300 - Train loss: 0.47047099471092224, Validation loss: 0.47405436635017395
Epoch: 118/300 - Train loss: 0.46909618377685547, Validation loss: 0.47308188676834106
Epoch: 119/300 - Train loss: 0.4677305817604065, Validation loss: 0.4714841842651367
Epoch: 120/300 - Train loss: 0.46637365221977234, Validation loss: 0.4701245129108429
Epoch: 121/300 - Train loss: 0.4650258421897888, Validation loss: 0.4691403806209564
Epoch: 122/300 - Train loss: 0.4636874496936798, Validation loss: 0.4679945111274719
Epoch: 123/300 - Train loss: 0.4623577892780304, Validation loss: 0.46655577421188354
Epoch: 124/300 - Train loss: 0.461038202047348, Validation loss: 0.46539390087127686
Epoch: 125/300 - Train loss: 0.45972904562950134, Validation loss: 0.4639531672000885
Epoch: 126/300 - Train loss: 0.45843014121055603, Validation loss: 0.46282485127449036
Epoch: 127/300 - Train loss: 0.4571405053138733, Validation loss: 0.46102041006088257
Epoch: 128/300 - Train loss: 0.4558599889278412, Validation loss: 0.4599858820438385
Epoch: 129/300 - Train loss: 0.45458850264549255, Validation loss: 0.4590258300304413
Epoch: 130/300 - Train loss: 0.45332688093185425, Validation loss: 0.4578281044960022
Epoch: 131/300 - Train loss: 0.45207417011260986, Validation loss: 0.4563928544521332
Epoch: 132/300 - Train loss: 0.4508306384086609, Validation loss: 0.4550778567790985
Epoch: 133/300 - Train loss: 0.4495971202850342, Validation loss: 0.45452681183815
Epoch: 134/300 - Train loss: 0.4483731687068939, Validation loss: 0.45342719554901123
Epoch: 135/300 - Train loss: 0.44715747237205505, Validation loss: 0.4515863358974457
Epoch: 136/300 - Train loss: 0.4459509253501892, Validation loss: 0.45031484961509705
Epoch: 137/300 - Train loss: 0.4447534680366516, Validation loss: 0.4493984282016754
Epoch: 138/300 - Train loss: 0.4435647428035736, Validation loss: 0.4478358030319214
Epoch: 139/300 - Train loss: 0.4423833191394806, Validation loss: 0.4468131959438324
Epoch: 140/300 - Train loss: 0.44120949506759644, Validation loss: 0.44585293531417847
Epoch: 141/300 - Train loss: 0.44004425406455994, Validation loss: 0.44468745589256287
Epoch: 142/300 - Train loss: 0.43888822197914124, Validation loss: 0.44387802481651306
Epoch: 143/300 - Train loss: 0.437740683555603, Validation loss: 0.4420586824417114
Epoch: 144/300 - Train loss: 0.4366014003753662, Validation loss: 0.44189441204071045
Epoch: 145/300 - Train loss: 0.4354715049266815, Validation loss: 0.440703809261322
Epoch: 146/300 - Train loss: 0.43435153365135193, Validation loss: 0.43899744749069214
Epoch: 147/300 - Train loss: 0.4332410991191864, Validation loss: 0.4381549060344696
Epoch: 148/300 - Train loss: 0.432140052318573, Validation loss: 0.43722277879714966
Epoch: 149/300 - Train loss: 0.4310494363307953, Validation loss: 0.4360251724720001
Epoch: 150/300 - Train loss: 0.429968923330307, Validation loss: 0.43502599000930786
Epoch: 151/300 - Train loss: 0.42889630794525146, Validation loss: 0.4343571364879608
Epoch: 152/300 - Train loss: 0.4278336763381958, Validation loss: 0.4327529966831207
Epoch: 153/300 - Train loss: 0.426780104637146, Validation loss: 0.43216046690940857
Epoch: 154/300 - Train loss: 0.42573410272598267, Validation loss: 0.43140584230422974
Epoch: 155/300 - Train loss: 0.4246957004070282, Validation loss: 0.42975446581840515
Epoch: 156/300 - Train loss: 0.42366546392440796, Validation loss: 0.42910367250442505
Epoch: 157/300 - Train loss: 0.4226435422897339, Validation loss: 0.4283091723918915
Epoch: 158/300 - Train loss: 0.4216296672821045, Validation loss: 0.4270697832107544
Epoch: 159/300 - Train loss: 0.42062366008758545, Validation loss: 0.42610740661621094
Epoch: 160/300 - Train loss: 0.4196256399154663, Validation loss: 0.42506274580955505
Epoch: 161/300 - Train loss: 0.41863593459129333, Validation loss: 0.42422813177108765
Epoch: 162/300 - Train loss: 0.4176539480686188, Validation loss: 0.4233258366584778
Epoch: 163/300 - Train loss: 0.41667935252189636, Validation loss: 0.42205291986465454
Epoch: 164/300 - Train loss: 0.41571271419525146, Validation loss: 0.4207894504070282
Epoch: 165/300 - Train loss: 0.41475266218185425, Validation loss: 0.42077338695526123
Epoch: 166/300 - Train loss: 0.413799524307251, Validation loss: 0.4198611378669739
Epoch: 167/300 - Train loss: 0.41285353899002075, Validation loss: 0.4185933768749237
Epoch: 168/300 - Train loss: 0.41191497445106506, Validation loss: 0.4176088571548462
Epoch: 169/300 - Train loss: 0.41098418831825256, Validation loss: 0.4172285795211792
Epoch: 170/300 - Train loss: 0.4100598394870758, Validation loss: 0.41593286395072937
Epoch: 171/300 - Train loss: 0.4091421067714691, Validation loss: 0.4155363142490387
Epoch: 172/300 - Train loss: 0.4082300066947937, Validation loss: 0.41457104682922363
Epoch: 173/300 - Train loss: 0.4073236286640167, Validation loss: 0.41316911578178406
Epoch: 174/300 - Train loss: 0.40642234683036804, Validation loss: 0.4129054844379425
Epoch: 175/300 - Train loss: 0.40552666783332825, Validation loss: 0.41196104884147644
Epoch: 176/300 - Train loss: 0.4046371579170227, Validation loss: 0.41046518087387085
Epoch: 177/300 - Train loss: 0.40375247597694397, Validation loss: 0.4097263514995575
Epoch: 178/300 - Train loss: 0.40287381410598755, Validation loss: 0.4089815020561218
Epoch: 179/300 - Train loss: 0.40200141072273254, Validation loss: 0.40811166167259216
Epoch: 180/300 - Train loss: 0.40113380551338196, Validation loss: 0.4069409966468811
Epoch: 181/300 - Train loss: 0.40027105808258057, Validation loss: 0.40640848875045776
Epoch: 182/300 - Train loss: 0.3994137942790985, Validation loss: 0.4058881998062134
Epoch: 183/300 - Train loss: 0.3985627293586731, Validation loss: 0.4045444130897522
Epoch: 184/300 - Train loss: 0.39771825075149536, Validation loss: 0.40442484617233276
Epoch: 185/300 - Train loss: 0.3968796730041504, Validation loss: 0.40338560938835144
Epoch: 186/300 - Train loss: 0.396047979593277, Validation loss: 0.4023100733757019
Epoch: 187/300 - Train loss: 0.39522257447242737, Validation loss: 0.40139350295066833
Epoch: 188/300 - Train loss: 0.3944033682346344, Validation loss: 0.4007910490036011
Epoch: 189/300 - Train loss: 0.3935888707637787, Validation loss: 0.40007251501083374
Epoch: 190/300 - Train loss: 0.39278072118759155, Validation loss: 0.39955541491508484
Epoch: 191/300 - Train loss: 0.3919806182384491, Validation loss: 0.39907410740852356
Epoch: 192/300 - Train loss: 0.3911874294281006, Validation loss: 0.397589772939682
Epoch: 193/300 - Train loss: 0.39039939641952515, Validation loss: 0.3965631127357483
Epoch: 194/300 - Train loss: 0.3896175026893616, Validation loss: 0.3966718018054962
Epoch: 195/300 - Train loss: 0.38884276151657104, Validation loss: 0.39554452896118164
Epoch: 196/300 - Train loss: 0.3880743980407715, Validation loss: 0.3945828974246979
Epoch: 197/300 - Train loss: 0.38731226325035095, Validation loss: 0.39365559816360474
Epoch: 198/300 - Train loss: 0.3865571916103363, Validation loss: 0.3930618166923523
Epoch: 199/300 - Train loss: 0.3858080804347992, Validation loss: 0.3929462134838104
Epoch: 200/300 - Train loss: 0.3850638270378113, Validation loss: 0.3918766975402832
Epoch: 201/300 - Train loss: 0.38432544469833374, Validation loss: 0.3912201523780823
Epoch: 202/300 - Train loss: 0.38359251618385315, Validation loss: 0.3906462490558624
Epoch: 203/300 - Train loss: 0.3828651010990143, Validation loss: 0.3906944990158081
Epoch: 204/300 - Train loss: 0.3821426331996918, Validation loss: 0.389363169670105
Epoch: 205/300 - Train loss: 0.3814249634742737, Validation loss: 0.3886430263519287
Epoch: 206/300 - Train loss: 0.3807121515274048, Validation loss: 0.3887808918952942
Epoch: 207/300 - Train loss: 0.38000527024269104, Validation loss: 0.38735687732696533
Epoch: 208/300 - Train loss: 0.3793037235736847, Validation loss: 0.3864072263240814
Epoch: 209/300 - Train loss: 0.37860652804374695, Validation loss: 0.38574859499931335
Epoch: 210/300 - Train loss: 0.3779142498970032, Validation loss: 0.3857683837413788
Epoch: 211/300 - Train loss: 0.3772260546684265, Validation loss: 0.38455718755722046
Epoch: 212/300 - Train loss: 0.37654152512550354, Validation loss: 0.3835696280002594
Epoch: 213/300 - Train loss: 0.3758607506752014, Validation loss: 0.3838784396648407
Epoch: 214/300 - Train loss: 0.3751832842826843, Validation loss: 0.38283005356788635
Epoch: 215/300 - Train loss: 0.3745102882385254, Validation loss: 0.3825856149196625
Epoch: 216/300 - Train loss: 0.3738410770893097, Validation loss: 0.3812248706817627
Epoch: 217/300 - Train loss: 0.3731769025325775, Validation loss: 0.38173744082450867
Epoch: 218/300 - Train loss: 0.3725173771381378, Validation loss: 0.3806149661540985
Epoch: 219/300 - Train loss: 0.3718627393245697, Validation loss: 0.3794104754924774
Epoch: 220/300 - Train loss: 0.3712127208709717, Validation loss: 0.37917423248291016
Epoch: 221/300 - Train loss: 0.3705670237541199, Validation loss: 0.3778483271598816
Epoch: 222/300 - Train loss: 0.3699249029159546, Validation loss: 0.37761151790618896
Epoch: 223/300 - Train loss: 0.36928626894950867, Validation loss: 0.37848547101020813
Epoch: 224/300 - Train loss: 0.36865171790122986, Validation loss: 0.37695759534835815
Epoch: 225/300 - Train loss: 0.36802124977111816, Validation loss: 0.37585848569869995
Epoch: 226/300 - Train loss: 0.36739423871040344, Validation loss: 0.37579959630966187
Epoch: 227/300 - Train loss: 0.36677247285842896, Validation loss: 0.37485626339912415
Epoch: 228/300 - Train loss: 0.3661556541919708, Validation loss: 0.37356480956077576
Epoch: 229/300 - Train loss: 0.365543931722641, Validation loss: 0.3732930123806
Epoch: 230/300 - Train loss: 0.36493489146232605, Validation loss: 0.37371116876602173
Epoch: 231/300 - Train loss: 0.3643282651901245, Validation loss: 0.37331655621528625
Epoch: 232/300 - Train loss: 0.3637257516384125, Validation loss: 0.3721098303794861
Epoch: 233/300 - Train loss: 0.3631271421909332, Validation loss: 0.37203696370124817
