Epoch: 1/300 - Train loss: 0.7034270167350769, Validation loss: 0.6977888345718384
Epoch: 2/300 - Train loss: 0.7001017928123474, Validation loss: 0.694758415222168
Epoch: 3/300 - Train loss: 0.697041392326355, Validation loss: 0.6921404600143433
Epoch: 4/300 - Train loss: 0.6941889524459839, Validation loss: 0.6893169283866882
Epoch: 5/300 - Train loss: 0.6914754509925842, Validation loss: 0.6870851516723633
Epoch: 6/300 - Train loss: 0.6888379454612732, Validation loss: 0.6842988729476929
Epoch: 7/300 - Train loss: 0.6862146258354187, Validation loss: 0.6815841794013977
Epoch: 8/300 - Train loss: 0.683560848236084, Validation loss: 0.6790446043014526
Epoch: 9/300 - Train loss: 0.6808339357376099, Validation loss: 0.6763057708740234
Epoch: 10/300 - Train loss: 0.6780118942260742, Validation loss: 0.673124372959137
Epoch: 11/300 - Train loss: 0.6750743985176086, Validation loss: 0.6701468825340271
Epoch: 12/300 - Train loss: 0.6720156669616699, Validation loss: 0.6669705510139465
Epoch: 13/300 - Train loss: 0.6688243746757507, Validation loss: 0.6634735465049744
Epoch: 14/300 - Train loss: 0.665503203868866, Validation loss: 0.6601071953773499
Epoch: 15/300 - Train loss: 0.6620584726333618, Validation loss: 0.6567044854164124
Epoch: 16/300 - Train loss: 0.6584947109222412, Validation loss: 0.6528781652450562
Epoch: 17/300 - Train loss: 0.6548229455947876, Validation loss: 0.6493098139762878
Epoch: 18/300 - Train loss: 0.6510482430458069, Validation loss: 0.6453437209129333
Epoch: 19/300 - Train loss: 0.6471854448318481, Validation loss: 0.6413922905921936
Epoch: 20/300 - Train loss: 0.6432441473007202, Validation loss: 0.6372814774513245
Epoch: 21/300 - Train loss: 0.6392323970794678, Validation loss: 0.6333109736442566
Epoch: 22/300 - Train loss: 0.6351506114006042, Validation loss: 0.6290677785873413
Epoch: 23/300 - Train loss: 0.6310083270072937, Validation loss: 0.625271201133728
Epoch: 24/300 - Train loss: 0.6268118023872375, Validation loss: 0.6206146478652954
Epoch: 25/300 - Train loss: 0.622565507888794, Validation loss: 0.6165183782577515
Epoch: 26/300 - Train loss: 0.6182728409767151, Validation loss: 0.6120537519454956
Epoch: 27/300 - Train loss: 0.6139390468597412, Validation loss: 0.6077402234077454
Epoch: 28/300 - Train loss: 0.6095676422119141, Validation loss: 0.6034098863601685
Epoch: 29/300 - Train loss: 0.6051573753356934, Validation loss: 0.5988361835479736
Epoch: 30/300 - Train loss: 0.6007133722305298, Validation loss: 0.5946249961853027
Epoch: 31/300 - Train loss: 0.5962393283843994, Validation loss: 0.590125560760498
Epoch: 32/300 - Train loss: 0.5917368531227112, Validation loss: 0.585586428642273
Epoch: 33/300 - Train loss: 0.5872086882591248, Validation loss: 0.5809960961341858
Epoch: 34/300 - Train loss: 0.5826560854911804, Validation loss: 0.5765478610992432
Epoch: 35/300 - Train loss: 0.5780822038650513, Validation loss: 0.5719054341316223
Epoch: 36/300 - Train loss: 0.5734912157058716, Validation loss: 0.567429780960083
Epoch: 37/300 - Train loss: 0.5688861608505249, Validation loss: 0.5629225373268127
Epoch: 38/300 - Train loss: 0.5642717480659485, Validation loss: 0.5583807826042175
Epoch: 39/300 - Train loss: 0.5596532225608826, Validation loss: 0.553997278213501
Epoch: 40/300 - Train loss: 0.5550340414047241, Validation loss: 0.5493155121803284
Epoch: 41/300 - Train loss: 0.5504186749458313, Validation loss: 0.544820249080658
Epoch: 42/300 - Train loss: 0.5458118319511414, Validation loss: 0.5401459336280823
Epoch: 43/300 - Train loss: 0.5412177443504333, Validation loss: 0.5354135036468506
Epoch: 44/300 - Train loss: 0.5366404056549072, Validation loss: 0.5312811136245728
Epoch: 45/300 - Train loss: 0.5320835709571838, Validation loss: 0.5264968276023865
Epoch: 46/300 - Train loss: 0.5275512933731079, Validation loss: 0.5222278833389282
Epoch: 47/300 - Train loss: 0.5230461955070496, Validation loss: 0.5179078578948975
Epoch: 48/300 - Train loss: 0.5185700058937073, Validation loss: 0.5130585432052612
Epoch: 49/300 - Train loss: 0.5141260027885437, Validation loss: 0.5087617039680481
Epoch: 50/300 - Train loss: 0.5097173452377319, Validation loss: 0.5048161149024963
Epoch: 51/300 - Train loss: 0.505346417427063, Validation loss: 0.5005431771278381
Epoch: 52/300 - Train loss: 0.5010169744491577, Validation loss: 0.4961029291152954
Epoch: 53/300 - Train loss: 0.4967327415943146, Validation loss: 0.49215251207351685
Epoch: 54/300 - Train loss: 0.49249666929244995, Validation loss: 0.48766785860061646
Epoch: 55/300 - Train loss: 0.4883112907409668, Validation loss: 0.4834280014038086
Epoch: 56/300 - Train loss: 0.48417991399765015, Validation loss: 0.4795089364051819
Epoch: 57/300 - Train loss: 0.4801051616668701, Validation loss: 0.4756031930446625
Epoch: 58/300 - Train loss: 0.47608959674835205, Validation loss: 0.4717031717300415
Epoch: 59/300 - Train loss: 0.47213485836982727, Validation loss: 0.4677909016609192
Epoch: 60/300 - Train loss: 0.4682423174381256, Validation loss: 0.46396803855895996
Epoch: 61/300 - Train loss: 0.46441423892974854, Validation loss: 0.45984020829200745
Epoch: 62/300 - Train loss: 0.46065226197242737, Validation loss: 0.45637112855911255
Epoch: 63/300 - Train loss: 0.45695748925209045, Validation loss: 0.45314982533454895
Epoch: 64/300 - Train loss: 0.4533310830593109, Validation loss: 0.44971203804016113
Epoch: 65/300 - Train loss: 0.4497739374637604, Validation loss: 0.4463411569595337
Epoch: 66/300 - Train loss: 0.4462871551513672, Validation loss: 0.44271254539489746
Epoch: 67/300 - Train loss: 0.44287145137786865, Validation loss: 0.4389084577560425
Epoch: 68/300 - Train loss: 0.43952709436416626, Validation loss: 0.43611544370651245
Epoch: 69/300 - Train loss: 0.43625396490097046, Validation loss: 0.4326668381690979
Epoch: 70/300 - Train loss: 0.43305233120918274, Validation loss: 0.4295068681240082
Epoch: 71/300 - Train loss: 0.4299221634864807, Validation loss: 0.4262144863605499
Epoch: 72/300 - Train loss: 0.4268632233142853, Validation loss: 0.4232843518257141
Epoch: 73/300 - Train loss: 0.4238751232624054, Validation loss: 0.4203549027442932
Epoch: 74/300 - Train loss: 0.4209573566913605, Validation loss: 0.41746774315834045
Epoch: 75/300 - Train loss: 0.4181095063686371, Validation loss: 0.4149940013885498
Epoch: 76/300 - Train loss: 0.41533058881759644, Validation loss: 0.41272279620170593
Epoch: 77/300 - Train loss: 0.41262000799179077, Validation loss: 0.40906602144241333
Epoch: 78/300 - Train loss: 0.40997663140296936, Validation loss: 0.40657830238342285
Epoch: 79/300 - Train loss: 0.4073996841907501, Validation loss: 0.4047471880912781
Epoch: 80/300 - Train loss: 0.4048881232738495, Validation loss: 0.40185004472732544
Epoch: 81/300 - Train loss: 0.4024410545825958, Validation loss: 0.3993150591850281
Epoch: 82/300 - Train loss: 0.40005695819854736, Validation loss: 0.3965645730495453
Epoch: 83/300 - Train loss: 0.39773452281951904, Validation loss: 0.394465833902359
Epoch: 84/300 - Train loss: 0.39547258615493774, Validation loss: 0.3930985629558563
Epoch: 85/300 - Train loss: 0.39327001571655273, Validation loss: 0.390720397233963
Epoch: 86/300 - Train loss: 0.39112547039985657, Validation loss: 0.3884762227535248
Epoch: 87/300 - Train loss: 0.38903719186782837, Validation loss: 0.38642260432243347
Epoch: 88/300 - Train loss: 0.3870037794113159, Validation loss: 0.384695827960968
Epoch: 89/300 - Train loss: 0.38502439856529236, Validation loss: 0.3826219141483307
Epoch: 90/300 - Train loss: 0.38309717178344727, Validation loss: 0.38077083230018616
Epoch: 91/300 - Train loss: 0.3812207281589508, Validation loss: 0.37839818000793457
Epoch: 92/300 - Train loss: 0.3793940246105194, Validation loss: 0.37645816802978516
Epoch: 93/300 - Train loss: 0.377615362405777, Validation loss: 0.37569954991340637
Epoch: 94/300 - Train loss: 0.3758835792541504, Validation loss: 0.37373799085617065
Epoch: 95/300 - Train loss: 0.37419721484184265, Validation loss: 0.3710455000400543
Epoch: 96/300 - Train loss: 0.3725547194480896, Validation loss: 0.36989811062812805
Epoch: 97/300 - Train loss: 0.37095460295677185, Validation loss: 0.3686354458332062
Epoch: 98/300 - Train loss: 0.3693959414958954, Validation loss: 0.3671400249004364
Epoch: 99/300 - Train loss: 0.36787763237953186, Validation loss: 0.36513152718544006
Epoch: 100/300 - Train loss: 0.36639881134033203, Validation loss: 0.36432743072509766
Epoch: 101/300 - Train loss: 0.3649578094482422, Validation loss: 0.3622322380542755
Epoch: 102/300 - Train loss: 0.3635531961917877, Validation loss: 0.3608255684375763
Epoch: 103/300 - Train loss: 0.3621836006641388, Validation loss: 0.3595336079597473
Epoch: 104/300 - Train loss: 0.36084896326065063, Validation loss: 0.3586176335811615
Epoch: 105/300 - Train loss: 0.3595485985279083, Validation loss: 0.35732969641685486
Epoch: 106/300 - Train loss: 0.35828086733818054, Validation loss: 0.3559960424900055
Epoch: 107/300 - Train loss: 0.35704514384269714, Validation loss: 0.3557894825935364
Epoch: 108/300 - Train loss: 0.35583963990211487, Validation loss: 0.3537125587463379
Epoch: 109/300 - Train loss: 0.35466334223747253, Validation loss: 0.35291439294815063
Epoch: 110/300 - Train loss: 0.3535152077674866, Validation loss: 0.35153183341026306
Epoch: 111/300 - Train loss: 0.3523947596549988, Validation loss: 0.35018932819366455
Epoch: 112/300 - Train loss: 0.3513014614582062, Validation loss: 0.3494936525821686
Epoch: 113/300 - Train loss: 0.35023415088653564, Validation loss: 0.34782975912094116
Epoch: 114/300 - Train loss: 0.3491920232772827, Validation loss: 0.34727898240089417
Epoch: 115/300 - Train loss: 0.3481745421886444, Validation loss: 0.3462962806224823
Epoch: 116/300 - Train loss: 0.347181111574173, Validation loss: 0.3456766605377197
Epoch: 117/300 - Train loss: 0.3462108373641968, Validation loss: 0.3447023034095764
Epoch: 118/300 - Train loss: 0.34526240825653076, Validation loss: 0.34341660141944885
Epoch: 119/300 - Train loss: 0.34433528780937195, Validation loss: 0.34243661165237427
Epoch: 120/300 - Train loss: 0.3434295058250427, Validation loss: 0.341219961643219
Epoch: 121/300 - Train loss: 0.3425441384315491, Validation loss: 0.3406364321708679
Epoch: 122/300 - Train loss: 0.3416785001754761, Validation loss: 0.3397921323776245
Epoch: 123/300 - Train loss: 0.34083253145217896, Validation loss: 0.3390713334083557
Epoch: 124/300 - Train loss: 0.3400052785873413, Validation loss: 0.33852073550224304
Epoch: 125/300 - Train loss: 0.3391963243484497, Validation loss: 0.3376936912536621
Epoch: 126/300 - Train loss: 0.3384051024913788, Validation loss: 0.336607962846756
Epoch: 127/300 - Train loss: 0.3376306891441345, Validation loss: 0.3363714814186096
Epoch: 128/300 - Train loss: 0.3368729054927826, Validation loss: 0.33599522709846497
Epoch: 129/300 - Train loss: 0.33613118529319763, Validation loss: 0.3340265154838562
Epoch: 130/300 - Train loss: 0.3354054391384125, Validation loss: 0.3334121108055115
Epoch: 131/300 - Train loss: 0.3346951901912689, Validation loss: 0.33313578367233276
Epoch: 132/300 - Train loss: 0.33399954438209534, Validation loss: 0.33181819319725037
Epoch: 133/300 - Train loss: 0.3333178162574768, Validation loss: 0.3316189646720886
Epoch: 134/300 - Train loss: 0.3326497972011566, Validation loss: 0.3305455148220062
Epoch: 135/300 - Train loss: 0.33199459314346313, Validation loss: 0.33002665638923645
Epoch: 136/300 - Train loss: 0.3313526213169098, Validation loss: 0.3289338946342468
Epoch: 137/300 - Train loss: 0.33072274923324585, Validation loss: 0.32898446917533875
Epoch: 138/300 - Train loss: 0.3301055431365967, Validation loss: 0.32976034283638
Epoch: 139/300 - Train loss: 0.3294999301433563, Validation loss: 0.32792893052101135
Epoch: 140/300 - Train loss: 0.3289060890674591, Validation loss: 0.32768678665161133
Epoch: 141/300 - Train loss: 0.32832255959510803, Validation loss: 0.32677286863327026
Epoch: 142/300 - Train loss: 0.32774949073791504, Validation loss: 0.3263166546821594
Epoch: 143/300 - Train loss: 0.32718589901924133, Validation loss: 0.326202929019928
