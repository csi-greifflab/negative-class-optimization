Epoch: 1/100 - Train loss: 0.6955565214157104, Validation loss: 0.6916788220405579
Epoch: 2/100 - Train loss: 0.6926228404045105, Validation loss: 0.688899040222168
Epoch: 3/100 - Train loss: 0.6896882057189941, Validation loss: 0.6861891150474548
Epoch: 4/100 - Train loss: 0.6866881251335144, Validation loss: 0.6831274628639221
Epoch: 5/100 - Train loss: 0.6835749745368958, Validation loss: 0.6799752712249756
Epoch: 6/100 - Train loss: 0.6803149580955505, Validation loss: 0.6766573786735535
Epoch: 7/100 - Train loss: 0.676874577999115, Validation loss: 0.6731510162353516
Epoch: 8/100 - Train loss: 0.673227071762085, Validation loss: 0.669316291809082
Epoch: 9/100 - Train loss: 0.6693713068962097, Validation loss: 0.6653585433959961
Epoch: 10/100 - Train loss: 0.665306031703949, Validation loss: 0.6612564921379089
Epoch: 11/100 - Train loss: 0.6610342860221863, Validation loss: 0.6568402647972107
Epoch: 12/100 - Train loss: 0.6565707921981812, Validation loss: 0.6521375775337219
Epoch: 13/100 - Train loss: 0.6519412994384766, Validation loss: 0.6475502848625183
Epoch: 14/100 - Train loss: 0.6471705436706543, Validation loss: 0.6428272724151611
Epoch: 15/100 - Train loss: 0.642278790473938, Validation loss: 0.6377303004264832
Epoch: 16/100 - Train loss: 0.6372891068458557, Validation loss: 0.6327977180480957
Epoch: 17/100 - Train loss: 0.6322229504585266, Validation loss: 0.6278223991394043
Epoch: 18/100 - Train loss: 0.6271036267280579, Validation loss: 0.6226089596748352
Epoch: 19/100 - Train loss: 0.6219515800476074, Validation loss: 0.6175315976142883
Epoch: 20/100 - Train loss: 0.6167842745780945, Validation loss: 0.6124113202095032
Epoch: 21/100 - Train loss: 0.6116120219230652, Validation loss: 0.6074110865592957
Epoch: 22/100 - Train loss: 0.6064453125, Validation loss: 0.6022254228591919
Epoch: 23/100 - Train loss: 0.6012867093086243, Validation loss: 0.5970768332481384
Epoch: 24/100 - Train loss: 0.5961376428604126, Validation loss: 0.5922750234603882
Epoch: 25/100 - Train loss: 0.5910019278526306, Validation loss: 0.5869632959365845
Epoch: 26/100 - Train loss: 0.585884690284729, Validation loss: 0.5818607211112976
Epoch: 27/100 - Train loss: 0.5807916522026062, Validation loss: 0.5769374966621399
Epoch: 28/100 - Train loss: 0.5757268071174622, Validation loss: 0.572108268737793
Epoch: 29/100 - Train loss: 0.5706986784934998, Validation loss: 0.5672012567520142
Epoch: 30/100 - Train loss: 0.5657114386558533, Validation loss: 0.5622047185897827
Epoch: 31/100 - Train loss: 0.5607694983482361, Validation loss: 0.5573246479034424
Epoch: 32/100 - Train loss: 0.5558772683143616, Validation loss: 0.5525486469268799
Epoch: 33/100 - Train loss: 0.5510373711585999, Validation loss: 0.5477116107940674
Epoch: 34/100 - Train loss: 0.5462515354156494, Validation loss: 0.5431429743766785
Epoch: 35/100 - Train loss: 0.5415226221084595, Validation loss: 0.5385016798973083
Epoch: 36/100 - Train loss: 0.5368536710739136, Validation loss: 0.5341006517410278
Epoch: 37/100 - Train loss: 0.5322471261024475, Validation loss: 0.529090404510498
Epoch: 38/100 - Train loss: 0.5277044177055359, Validation loss: 0.5244461297988892
Epoch: 39/100 - Train loss: 0.5232285261154175, Validation loss: 0.5201570391654968
Epoch: 40/100 - Train loss: 0.518821656703949, Validation loss: 0.5158956050872803
Epoch: 41/100 - Train loss: 0.5144866108894348, Validation loss: 0.5116477012634277
Epoch: 42/100 - Train loss: 0.5102255940437317, Validation loss: 0.5075424909591675
Epoch: 43/100 - Train loss: 0.5060404539108276, Validation loss: 0.5030152201652527
Epoch: 44/100 - Train loss: 0.5019333362579346, Validation loss: 0.4989866614341736
Epoch: 45/100 - Train loss: 0.49790599942207336, Validation loss: 0.49546122550964355
Epoch: 46/100 - Train loss: 0.4939597249031067, Validation loss: 0.4911208748817444
Epoch: 47/100 - Train loss: 0.490095317363739, Validation loss: 0.4872548282146454
Epoch: 48/100 - Train loss: 0.48631352186203003, Validation loss: 0.48373204469680786
Epoch: 49/100 - Train loss: 0.4826146960258484, Validation loss: 0.47995662689208984
Epoch: 50/100 - Train loss: 0.47899913787841797, Validation loss: 0.4760672450065613
Epoch: 51/100 - Train loss: 0.47546690702438354, Validation loss: 0.47265681624412537
Epoch: 52/100 - Train loss: 0.47201794385910034, Validation loss: 0.4696280360221863
Epoch: 53/100 - Train loss: 0.46865183115005493, Validation loss: 0.46590855717658997
Epoch: 54/100 - Train loss: 0.4653688967227936, Validation loss: 0.46323883533477783
Epoch: 55/100 - Train loss: 0.4621690511703491, Validation loss: 0.4593724310398102
Epoch: 56/100 - Train loss: 0.45905157923698425, Validation loss: 0.45666539669036865
Epoch: 57/100 - Train loss: 0.4560156762599945, Validation loss: 0.4538152813911438
Epoch: 58/100 - Train loss: 0.45305994153022766, Validation loss: 0.4507559537887573
Epoch: 59/100 - Train loss: 0.4501834511756897, Validation loss: 0.448419988155365
Epoch: 60/100 - Train loss: 0.44738534092903137, Validation loss: 0.4451378583908081
Epoch: 61/100 - Train loss: 0.44466498494148254, Validation loss: 0.4422852098941803
Epoch: 62/100 - Train loss: 0.4420201778411865, Validation loss: 0.4399547576904297
Epoch: 63/100 - Train loss: 0.43945014476776123, Validation loss: 0.4374825656414032
Epoch: 64/100 - Train loss: 0.43695321679115295, Validation loss: 0.43464821577072144
Epoch: 65/100 - Train loss: 0.4345274865627289, Validation loss: 0.4326828420162201
Epoch: 66/100 - Train loss: 0.432171493768692, Validation loss: 0.43030524253845215
Epoch: 67/100 - Train loss: 0.4298836886882782, Validation loss: 0.4280809760093689
Epoch: 68/100 - Train loss: 0.42766183614730835, Validation loss: 0.4257766902446747
Epoch: 69/100 - Train loss: 0.4255044460296631, Validation loss: 0.423643559217453
Epoch: 70/100 - Train loss: 0.4234088957309723, Validation loss: 0.42151108384132385
Epoch: 71/100 - Train loss: 0.42137426137924194, Validation loss: 0.4191664159297943
Epoch: 72/100 - Train loss: 0.4193982183933258, Validation loss: 0.4179224669933319
Epoch: 73/100 - Train loss: 0.4174789786338806, Validation loss: 0.41579991579055786
Epoch: 74/100 - Train loss: 0.4156148433685303, Validation loss: 0.41341888904571533
Epoch: 75/100 - Train loss: 0.41380423307418823, Validation loss: 0.41193416714668274
Epoch: 76/100 - Train loss: 0.412044882774353, Validation loss: 0.4106355905532837
Epoch: 77/100 - Train loss: 0.41033509373664856, Validation loss: 0.4079245328903198
Epoch: 78/100 - Train loss: 0.4086732566356659, Validation loss: 0.40668755769729614
Epoch: 79/100 - Train loss: 0.40705835819244385, Validation loss: 0.40474218130111694
Epoch: 80/100 - Train loss: 0.40548914670944214, Validation loss: 0.40395480394363403
Epoch: 81/100 - Train loss: 0.4039625823497772, Validation loss: 0.4017723500728607
Epoch: 82/100 - Train loss: 0.40247637033462524, Validation loss: 0.40064162015914917
Epoch: 83/100 - Train loss: 0.40103018283843994, Validation loss: 0.3987281322479248
Epoch: 84/100 - Train loss: 0.3996208608150482, Validation loss: 0.3973352313041687
Epoch: 85/100 - Train loss: 0.398246705532074, Validation loss: 0.39599964022636414
Epoch: 86/100 - Train loss: 0.39690619707107544, Validation loss: 0.3951205611228943
Epoch: 87/100 - Train loss: 0.39559832215309143, Validation loss: 0.39353111386299133
Epoch: 88/100 - Train loss: 0.39432230591773987, Validation loss: 0.39205434918403625
Epoch: 89/100 - Train loss: 0.3930773138999939, Validation loss: 0.3911774456501007
Epoch: 90/100 - Train loss: 0.3918612003326416, Validation loss: 0.39056453108787537
Epoch: 91/100 - Train loss: 0.3906724750995636, Validation loss: 0.3889608383178711
Epoch: 92/100 - Train loss: 0.3895094692707062, Validation loss: 0.387139230966568
Epoch: 93/100 - Train loss: 0.38837113976478577, Validation loss: 0.3863096237182617
Epoch: 94/100 - Train loss: 0.38725602626800537, Validation loss: 0.3851607143878937
Epoch: 95/100 - Train loss: 0.38616448640823364, Validation loss: 0.3843122720718384
Epoch: 96/100 - Train loss: 0.3850966691970825, Validation loss: 0.38332539796829224
Epoch: 97/100 - Train loss: 0.38405099511146545, Validation loss: 0.38194966316223145
Epoch: 98/100 - Train loss: 0.3830261826515198, Validation loss: 0.38034993410110474
Epoch: 99/100 - Train loss: 0.3820207417011261, Validation loss: 0.37988510727882385
Epoch: 100/100 - Train loss: 0.38103240728378296, Validation loss: 0.3786308169364929
Epoch: 1/300 - Train loss: 0.6973962187767029, Validation loss: 0.6935862302780151
Epoch: 2/300 - Train loss: 0.6940516233444214, Validation loss: 0.6901910901069641
Epoch: 3/300 - Train loss: 0.690684974193573, Validation loss: 0.6869741082191467
Epoch: 4/300 - Train loss: 0.6872720718383789, Validation loss: 0.6836650967597961
Epoch: 5/300 - Train loss: 0.6837758421897888, Validation loss: 0.6801733374595642
Epoch: 6/300 - Train loss: 0.6801632046699524, Validation loss: 0.6765215396881104
Epoch: 7/300 - Train loss: 0.6764018535614014, Validation loss: 0.6727667450904846
Epoch: 8/300 - Train loss: 0.6724799871444702, Validation loss: 0.6688411831855774
Epoch: 9/300 - Train loss: 0.668392539024353, Validation loss: 0.6645913124084473
Epoch: 10/300 - Train loss: 0.6641334295272827, Validation loss: 0.6602741479873657
Epoch: 11/300 - Train loss: 0.6597123742103577, Validation loss: 0.6558508276939392
Epoch: 12/300 - Train loss: 0.6551396250724792, Validation loss: 0.651160717010498
Epoch: 13/300 - Train loss: 0.6504342555999756, Validation loss: 0.6464611291885376
Epoch: 14/300 - Train loss: 0.6456080675125122, Validation loss: 0.6415263414382935
Epoch: 15/300 - Train loss: 0.6406817436218262, Validation loss: 0.6365427374839783
Epoch: 16/300 - Train loss: 0.6356673240661621, Validation loss: 0.6315012574195862
Epoch: 17/300 - Train loss: 0.6305854916572571, Validation loss: 0.6265038251876831
Epoch: 18/300 - Train loss: 0.6254546642303467, Validation loss: 0.6213352084159851
Epoch: 19/300 - Train loss: 0.6202878952026367, Validation loss: 0.6163528561592102
Epoch: 20/300 - Train loss: 0.6150996088981628, Validation loss: 0.6110563278198242
Epoch: 21/300 - Train loss: 0.6099032163619995, Validation loss: 0.6060855388641357
Epoch: 22/300 - Train loss: 0.6047126650810242, Validation loss: 0.6010662913322449
Epoch: 23/300 - Train loss: 0.5995402336120605, Validation loss: 0.5957641005516052
Epoch: 24/300 - Train loss: 0.5943992137908936, Validation loss: 0.5907514095306396
Epoch: 25/300 - Train loss: 0.5892897844314575, Validation loss: 0.5857371687889099
Epoch: 26/300 - Train loss: 0.58420729637146, Validation loss: 0.5807129144668579
Epoch: 27/300 - Train loss: 0.5791580080986023, Validation loss: 0.5757125616073608
Epoch: 28/300 - Train loss: 0.5741440653800964, Validation loss: 0.5706927180290222
Epoch: 29/300 - Train loss: 0.569164514541626, Validation loss: 0.5655679702758789
Epoch: 30/300 - Train loss: 0.5642223954200745, Validation loss: 0.5608891844749451
Epoch: 31/300 - Train loss: 0.559320867061615, Validation loss: 0.555814802646637
Epoch: 32/300 - Train loss: 0.5544618368148804, Validation loss: 0.5509878993034363
Epoch: 33/300 - Train loss: 0.5496503710746765, Validation loss: 0.5464022755622864
Epoch: 34/300 - Train loss: 0.5448932647705078, Validation loss: 0.5417007207870483
Epoch: 35/300 - Train loss: 0.5401938557624817, Validation loss: 0.5368415117263794
Epoch: 36/300 - Train loss: 0.5355550050735474, Validation loss: 0.5327186584472656
Epoch: 37/300 - Train loss: 0.5309796929359436, Validation loss: 0.527755081653595
Epoch: 38/300 - Train loss: 0.526473343372345, Validation loss: 0.5236503481864929
Epoch: 39/300 - Train loss: 0.5220391154289246, Validation loss: 0.5190415382385254
Epoch: 40/300 - Train loss: 0.5176803469657898, Validation loss: 0.5146044492721558
Epoch: 41/300 - Train loss: 0.513399064540863, Validation loss: 0.5105424523353577
Epoch: 42/300 - Train loss: 0.5091968774795532, Validation loss: 0.5060789585113525
Epoch: 43/300 - Train loss: 0.5050754547119141, Validation loss: 0.5023970603942871
Epoch: 44/300 - Train loss: 0.5010350942611694, Validation loss: 0.4981567859649658
Epoch: 45/300 - Train loss: 0.4970772862434387, Validation loss: 0.494573175907135
Epoch: 46/300 - Train loss: 0.4932025372982025, Validation loss: 0.49031808972358704
Epoch: 47/300 - Train loss: 0.489410936832428, Validation loss: 0.48694390058517456
Epoch: 48/300 - Train loss: 0.485703706741333, Validation loss: 0.48332104086875916
Epoch: 49/300 - Train loss: 0.48208174109458923, Validation loss: 0.47948694229125977
Epoch: 50/300 - Train loss: 0.47854503989219666, Validation loss: 0.4761439263820648
Epoch: 51/300 - Train loss: 0.475093811750412, Validation loss: 0.4726366698741913
Epoch: 52/300 - Train loss: 0.47172781825065613, Validation loss: 0.4688207507133484
Epoch: 53/300 - Train loss: 0.46844708919525146, Validation loss: 0.46576038002967834
Epoch: 54/300 - Train loss: 0.4652509391307831, Validation loss: 0.4625754654407501
Epoch: 55/300 - Train loss: 0.4621390700340271, Validation loss: 0.4595731794834137
Epoch: 56/300 - Train loss: 0.45911112427711487, Validation loss: 0.45659083127975464
Epoch: 57/300 - Train loss: 0.4561659097671509, Validation loss: 0.45378708839416504
Epoch: 58/300 - Train loss: 0.45330187678337097, Validation loss: 0.45159873366355896
Epoch: 59/300 - Train loss: 0.4505176246166229, Validation loss: 0.44801849126815796
Epoch: 60/300 - Train loss: 0.44781193137168884, Validation loss: 0.445422887802124
Epoch: 61/300 - Train loss: 0.445183664560318, Validation loss: 0.4428148865699768
Epoch: 62/300 - Train loss: 0.4426308274269104, Validation loss: 0.44029170274734497
Epoch: 63/300 - Train loss: 0.440151572227478, Validation loss: 0.43792444467544556
Epoch: 64/300 - Train loss: 0.43774452805519104, Validation loss: 0.4351451098918915
Epoch: 65/300 - Train loss: 0.4354078471660614, Validation loss: 0.43296483159065247
Epoch: 66/300 - Train loss: 0.4331403076648712, Validation loss: 0.4309597611427307
Epoch: 67/300 - Train loss: 0.4309398829936981, Validation loss: 0.4289502799510956
Epoch: 68/300 - Train loss: 0.42880433797836304, Validation loss: 0.42665767669677734
Epoch: 69/300 - Train loss: 0.42673203349113464, Validation loss: 0.4246702790260315
Epoch: 70/300 - Train loss: 0.4247220754623413, Validation loss: 0.4224075376987457
Epoch: 71/300 - Train loss: 0.4227713942527771, Validation loss: 0.4209608733654022
Epoch: 72/300 - Train loss: 0.4208783805370331, Validation loss: 0.41878071427345276
Epoch: 73/300 - Train loss: 0.4190412163734436, Validation loss: 0.4170075058937073
Epoch: 74/300 - Train loss: 0.41725823283195496, Validation loss: 0.4158380329608917
Epoch: 75/300 - Train loss: 0.41552817821502686, Validation loss: 0.4135020673274994
Epoch: 76/300 - Train loss: 0.4138489365577698, Validation loss: 0.4118443727493286
Epoch: 77/300 - Train loss: 0.41221803426742554, Validation loss: 0.40978747606277466
Epoch: 78/300 - Train loss: 0.41063377261161804, Validation loss: 0.408671110868454
Epoch: 79/300 - Train loss: 0.4090940058231354, Validation loss: 0.4073409140110016
Epoch: 80/300 - Train loss: 0.40759745240211487, Validation loss: 0.4054550528526306
Epoch: 81/300 - Train loss: 0.4061424434185028, Validation loss: 0.40419116616249084
Epoch: 82/300 - Train loss: 0.40472838282585144, Validation loss: 0.40335652232170105
Epoch: 83/300 - Train loss: 0.40335360169410706, Validation loss: 0.4013390839099884
Epoch: 84/300 - Train loss: 0.4020167887210846, Validation loss: 0.4003439247608185
Epoch: 85/300 - Train loss: 0.4007153809070587, Validation loss: 0.3986397087574005
Epoch: 86/300 - Train loss: 0.399448961019516, Validation loss: 0.39708060026168823
Epoch: 87/300 - Train loss: 0.3982165455818176, Validation loss: 0.3964528739452362
Epoch: 88/300 - Train loss: 0.39701664447784424, Validation loss: 0.3948245048522949
Epoch: 89/300 - Train loss: 0.39584794640541077, Validation loss: 0.3932033181190491
Epoch: 90/300 - Train loss: 0.3947080075740814, Validation loss: 0.3920421302318573
Epoch: 91/300 - Train loss: 0.3935958445072174, Validation loss: 0.39115196466445923
Epoch: 92/300 - Train loss: 0.3925100862979889, Validation loss: 0.39046698808670044
Epoch: 93/300 - Train loss: 0.39145010709762573, Validation loss: 0.38902732729911804
Epoch: 94/300 - Train loss: 0.3904156982898712, Validation loss: 0.38870054483413696
Epoch: 95/300 - Train loss: 0.38940560817718506, Validation loss: 0.3874671757221222
Epoch: 96/300 - Train loss: 0.3884177505970001, Validation loss: 0.3859182596206665
Epoch: 97/300 - Train loss: 0.387451708316803, Validation loss: 0.3850853741168976
Epoch: 98/300 - Train loss: 0.3865058422088623, Validation loss: 0.3845966160297394
Epoch: 99/300 - Train loss: 0.38558024168014526, Validation loss: 0.38330626487731934
Epoch: 100/300 - Train loss: 0.38467344641685486, Validation loss: 0.382946640253067
Epoch: 101/300 - Train loss: 0.383784681558609, Validation loss: 0.38157740235328674
Epoch: 102/300 - Train loss: 0.38291415572166443, Validation loss: 0.3808390498161316
Epoch: 103/300 - Train loss: 0.38206034898757935, Validation loss: 0.38013729453086853
Epoch: 104/300 - Train loss: 0.38122352957725525, Validation loss: 0.37892580032348633
Epoch: 105/300 - Train loss: 0.38040146231651306, Validation loss: 0.3778231143951416
Epoch: 106/300 - Train loss: 0.3795934021472931, Validation loss: 0.3775871694087982
Epoch: 107/300 - Train loss: 0.37879884243011475, Validation loss: 0.376903772354126
Epoch: 108/300 - Train loss: 0.37801796197891235, Validation loss: 0.37598490715026855
Epoch: 109/300 - Train loss: 0.3772497773170471, Validation loss: 0.37575724720954895
Epoch: 110/300 - Train loss: 0.37649375200271606, Validation loss: 0.3743169903755188
Epoch: 111/300 - Train loss: 0.37575018405914307, Validation loss: 0.3735679090023041
Epoch: 112/300 - Train loss: 0.3750183582305908, Validation loss: 0.3723144829273224
Epoch: 113/300 - Train loss: 0.3742968738079071, Validation loss: 0.37205445766448975
Epoch: 114/300 - Train loss: 0.37358447909355164, Validation loss: 0.3722452223300934
Epoch: 115/300 - Train loss: 0.37287911772727966, Validation loss: 0.37093159556388855
Epoch: 116/300 - Train loss: 0.3721820116043091, Validation loss: 0.3697775602340698
Epoch: 117/300 - Train loss: 0.3714938461780548, Validation loss: 0.3691340982913971
Epoch: 118/300 - Train loss: 0.37081316113471985, Validation loss: 0.3694239556789398
Epoch: 119/300 - Train loss: 0.3701397478580475, Validation loss: 0.36800122261047363
Epoch: 120/300 - Train loss: 0.36947309970855713, Validation loss: 0.36730247735977173
Epoch: 121/300 - Train loss: 0.36881422996520996, Validation loss: 0.36699187755584717
Epoch: 122/300 - Train loss: 0.3681631088256836, Validation loss: 0.3659570813179016
Epoch: 123/300 - Train loss: 0.3675188720226288, Validation loss: 0.36502978205680847
Epoch: 124/300 - Train loss: 0.3668820559978485, Validation loss: 0.36487194895744324
Epoch: 125/300 - Train loss: 0.36625170707702637, Validation loss: 0.364467054605484
Epoch: 126/300 - Train loss: 0.3656277656555176, Validation loss: 0.3637562692165375
Epoch: 127/300 - Train loss: 0.365010142326355, Validation loss: 0.3624267578125
Epoch: 128/300 - Train loss: 0.3643980622291565, Validation loss: 0.3631543517112732
Epoch: 129/300 - Train loss: 0.3637911081314087, Validation loss: 0.36178651452064514
Epoch: 130/300 - Train loss: 0.3631899058818817, Validation loss: 0.3610683083534241
Epoch: 131/300 - Train loss: 0.3625948131084442, Validation loss: 0.36081793904304504
Epoch: 132/300 - Train loss: 0.3620062470436096, Validation loss: 0.3597278594970703
Epoch: 133/300 - Train loss: 0.36142146587371826, Validation loss: 0.35978272557258606
Epoch: 134/300 - Train loss: 0.3608410358428955, Validation loss: 0.3586736023426056
Epoch: 135/300 - Train loss: 0.36026430130004883, Validation loss: 0.3581782877445221
Epoch: 136/300 - Train loss: 0.35969147086143494, Validation loss: 0.35851573944091797
