Epoch: 1/300 - Train loss: 0.6854552030563354, Validation loss: 0.683978796005249
Epoch: 2/300 - Train loss: 0.6824347972869873, Validation loss: 0.6809094548225403
Epoch: 3/300 - Train loss: 0.6793540716171265, Validation loss: 0.6779186129570007
Epoch: 4/300 - Train loss: 0.6761961579322815, Validation loss: 0.6747108101844788
Epoch: 5/300 - Train loss: 0.6729533076286316, Validation loss: 0.6712488532066345
Epoch: 6/300 - Train loss: 0.6696093082427979, Validation loss: 0.6681178212165833
Epoch: 7/300 - Train loss: 0.6661540269851685, Validation loss: 0.6643550395965576
Epoch: 8/300 - Train loss: 0.6625781059265137, Validation loss: 0.6606931090354919
Epoch: 9/300 - Train loss: 0.6588824391365051, Validation loss: 0.6567198634147644
Epoch: 10/300 - Train loss: 0.6550614237785339, Validation loss: 0.6526868939399719
Epoch: 11/300 - Train loss: 0.6511049270629883, Validation loss: 0.6487676501274109
Epoch: 12/300 - Train loss: 0.6470154523849487, Validation loss: 0.6445507407188416
Epoch: 13/300 - Train loss: 0.64278644323349, Validation loss: 0.6401817202568054
Epoch: 14/300 - Train loss: 0.6384202837944031, Validation loss: 0.6356791853904724
Epoch: 15/300 - Train loss: 0.6339276432991028, Validation loss: 0.6310757398605347
Epoch: 16/300 - Train loss: 0.6293090581893921, Validation loss: 0.6262946724891663
Epoch: 17/300 - Train loss: 0.6245684623718262, Validation loss: 0.6213752627372742
Epoch: 18/300 - Train loss: 0.6197123527526855, Validation loss: 0.6163324117660522
Epoch: 19/300 - Train loss: 0.6147467494010925, Validation loss: 0.6113548278808594
Epoch: 20/300 - Train loss: 0.6096715331077576, Validation loss: 0.6060165762901306
Epoch: 21/300 - Train loss: 0.6044990420341492, Validation loss: 0.6008844375610352
Epoch: 22/300 - Train loss: 0.5992335677146912, Validation loss: 0.5955095291137695
Epoch: 23/300 - Train loss: 0.5938854217529297, Validation loss: 0.5901530385017395
Epoch: 24/300 - Train loss: 0.5884638428688049, Validation loss: 0.5848869681358337
Epoch: 25/300 - Train loss: 0.5829747915267944, Validation loss: 0.5793694853782654
Epoch: 26/300 - Train loss: 0.577428936958313, Validation loss: 0.5737473368644714
Epoch: 27/300 - Train loss: 0.5718346238136292, Validation loss: 0.5684446096420288
Epoch: 28/300 - Train loss: 0.5662021040916443, Validation loss: 0.5624743700027466
Epoch: 29/300 - Train loss: 0.5605432987213135, Validation loss: 0.5570117831230164
Epoch: 30/300 - Train loss: 0.5548660159111023, Validation loss: 0.5517169237136841
Epoch: 31/300 - Train loss: 0.549177885055542, Validation loss: 0.5460161566734314
Epoch: 32/300 - Train loss: 0.5434859395027161, Validation loss: 0.5404375791549683
Epoch: 33/300 - Train loss: 0.537799596786499, Validation loss: 0.5348204970359802
Epoch: 34/300 - Train loss: 0.5321282744407654, Validation loss: 0.5291250944137573
Epoch: 35/300 - Train loss: 0.5264798402786255, Validation loss: 0.5237147808074951
Epoch: 36/300 - Train loss: 0.5208609700202942, Validation loss: 0.5184063911437988
Epoch: 37/300 - Train loss: 0.5152773261070251, Validation loss: 0.512901246547699
Epoch: 38/300 - Train loss: 0.5097373723983765, Validation loss: 0.5077053308486938
Epoch: 39/300 - Train loss: 0.5042468309402466, Validation loss: 0.5024355053901672
Epoch: 40/300 - Train loss: 0.4988102316856384, Validation loss: 0.49702775478363037
Epoch: 41/300 - Train loss: 0.49343109130859375, Validation loss: 0.4919538199901581
Epoch: 42/300 - Train loss: 0.48811495304107666, Validation loss: 0.4869227707386017
Epoch: 43/300 - Train loss: 0.48286446928977966, Validation loss: 0.4816848635673523
Epoch: 44/300 - Train loss: 0.4776808023452759, Validation loss: 0.47677934169769287
Epoch: 45/300 - Train loss: 0.4725651741027832, Validation loss: 0.47182056307792664
Epoch: 46/300 - Train loss: 0.467521607875824, Validation loss: 0.4674139618873596
Epoch: 47/300 - Train loss: 0.4625549018383026, Validation loss: 0.46219882369041443
Epoch: 48/300 - Train loss: 0.4576660096645355, Validation loss: 0.4578125476837158
Epoch: 49/300 - Train loss: 0.45285671949386597, Validation loss: 0.4529624879360199
Epoch: 50/300 - Train loss: 0.4481264352798462, Validation loss: 0.4487084448337555
Epoch: 51/300 - Train loss: 0.44347572326660156, Validation loss: 0.4440385699272156
Epoch: 52/300 - Train loss: 0.4389060437679291, Validation loss: 0.43966010212898254
Epoch: 53/300 - Train loss: 0.43442004919052124, Validation loss: 0.4354788661003113
Epoch: 54/300 - Train loss: 0.43001776933670044, Validation loss: 0.43102312088012695
Epoch: 55/300 - Train loss: 0.4257001578807831, Validation loss: 0.42754116654396057
Epoch: 56/300 - Train loss: 0.42146605253219604, Validation loss: 0.4232598543167114
Epoch: 57/300 - Train loss: 0.41731420159339905, Validation loss: 0.4194328486919403
Epoch: 58/300 - Train loss: 0.41324299573898315, Validation loss: 0.4153498709201813
Epoch: 59/300 - Train loss: 0.40925294160842896, Validation loss: 0.4114740788936615
Epoch: 60/300 - Train loss: 0.4053429067134857, Validation loss: 0.4076045751571655
Epoch: 61/300 - Train loss: 0.40151247382164, Validation loss: 0.4037547707557678
Epoch: 62/300 - Train loss: 0.39776018261909485, Validation loss: 0.40016454458236694
Epoch: 63/300 - Train loss: 0.39408475160598755, Validation loss: 0.3966657519340515
Epoch: 64/300 - Train loss: 0.39048486948013306, Validation loss: 0.3935367465019226
Epoch: 65/300 - Train loss: 0.3869595527648926, Validation loss: 0.38988593220710754
Epoch: 66/300 - Train loss: 0.38350850343704224, Validation loss: 0.3869895040988922
Epoch: 67/300 - Train loss: 0.38012969493865967, Validation loss: 0.38442087173461914
Epoch: 68/300 - Train loss: 0.3768214285373688, Validation loss: 0.38068124651908875
Epoch: 69/300 - Train loss: 0.37358221411705017, Validation loss: 0.37752628326416016
Epoch: 70/300 - Train loss: 0.3704107105731964, Validation loss: 0.3741456866264343
Epoch: 71/300 - Train loss: 0.36730554699897766, Validation loss: 0.371452659368515
Epoch: 72/300 - Train loss: 0.3642652928829193, Validation loss: 0.368271142244339
Epoch: 73/300 - Train loss: 0.36128848791122437, Validation loss: 0.3655305802822113
Epoch: 74/300 - Train loss: 0.3583733141422272, Validation loss: 0.36276504397392273
Epoch: 75/300 - Train loss: 0.35551804304122925, Validation loss: 0.3599943220615387
Epoch: 76/300 - Train loss: 0.35272347927093506, Validation loss: 0.35773417353630066
Epoch: 77/300 - Train loss: 0.3499876856803894, Validation loss: 0.35488972067832947
Epoch: 78/300 - Train loss: 0.34730905294418335, Validation loss: 0.352079838514328
Epoch: 79/300 - Train loss: 0.34468644857406616, Validation loss: 0.3497423529624939
Epoch: 80/300 - Train loss: 0.34211814403533936, Validation loss: 0.34700462222099304
Epoch: 81/300 - Train loss: 0.3396036922931671, Validation loss: 0.3443078398704529
Epoch: 82/300 - Train loss: 0.3371424078941345, Validation loss: 0.3419327139854431
Epoch: 83/300 - Train loss: 0.334732323884964, Validation loss: 0.33957386016845703
Epoch: 84/300 - Train loss: 0.3323728144168854, Validation loss: 0.3377078175544739
Epoch: 85/300 - Train loss: 0.330062597990036, Validation loss: 0.3350547254085541
Epoch: 86/300 - Train loss: 0.3278006613254547, Validation loss: 0.3329985439777374
Epoch: 87/300 - Train loss: 0.32558542490005493, Validation loss: 0.33126139640808105
Epoch: 88/300 - Train loss: 0.32341575622558594, Validation loss: 0.32879403233528137
Epoch: 89/300 - Train loss: 0.32129034399986267, Validation loss: 0.3264840841293335
Epoch: 90/300 - Train loss: 0.319208562374115, Validation loss: 0.3247043490409851
Epoch: 91/300 - Train loss: 0.3171687424182892, Validation loss: 0.32299965620040894
Epoch: 92/300 - Train loss: 0.31517013907432556, Validation loss: 0.3206343948841095
Epoch: 93/300 - Train loss: 0.313211590051651, Validation loss: 0.31856805086135864
Epoch: 94/300 - Train loss: 0.31129172444343567, Validation loss: 0.31714197993278503
Epoch: 95/300 - Train loss: 0.30940964818000793, Validation loss: 0.31490325927734375
Epoch: 96/300 - Train loss: 0.3075644373893738, Validation loss: 0.31403371691703796
Epoch: 97/300 - Train loss: 0.30575495958328247, Validation loss: 0.31187793612480164
Epoch: 98/300 - Train loss: 0.3039802312850952, Validation loss: 0.31051427125930786
Epoch: 99/300 - Train loss: 0.30223947763442993, Validation loss: 0.3091099262237549
Epoch: 100/300 - Train loss: 0.30053210258483887, Validation loss: 0.30673331022262573
Epoch: 101/300 - Train loss: 0.2988569736480713, Validation loss: 0.3049372732639313
Epoch: 102/300 - Train loss: 0.29721328616142273, Validation loss: 0.3037866950035095
Epoch: 103/300 - Train loss: 0.29559996724128723, Validation loss: 0.3018604815006256
Epoch: 104/300 - Train loss: 0.29401636123657227, Validation loss: 0.3006511628627777
Epoch: 105/300 - Train loss: 0.29246190190315247, Validation loss: 0.29907405376434326
Epoch: 106/300 - Train loss: 0.2909356951713562, Validation loss: 0.29712995886802673
Epoch: 107/300 - Train loss: 0.2894371747970581, Validation loss: 0.29581478238105774
Epoch: 108/300 - Train loss: 0.2879652976989746, Validation loss: 0.294810950756073
Epoch: 109/300 - Train loss: 0.2865199148654938, Validation loss: 0.2929966449737549
Epoch: 110/300 - Train loss: 0.28510037064552307, Validation loss: 0.2919192612171173
Epoch: 111/300 - Train loss: 0.2837061583995819, Validation loss: 0.29011857509613037
Epoch: 112/300 - Train loss: 0.28233617544174194, Validation loss: 0.28906574845314026
Epoch: 113/300 - Train loss: 0.28098997473716736, Validation loss: 0.2881697118282318
Epoch: 114/300 - Train loss: 0.27966710925102234, Validation loss: 0.28695669770240784
Epoch: 115/300 - Train loss: 0.27836695313453674, Validation loss: 0.28555887937545776
Epoch: 116/300 - Train loss: 0.27708902955055237, Validation loss: 0.2842753529548645
Epoch: 117/300 - Train loss: 0.27583298087120056, Validation loss: 0.2827727794647217
Epoch: 118/300 - Train loss: 0.2745983302593231, Validation loss: 0.2815057933330536
Epoch: 119/300 - Train loss: 0.27338454127311707, Validation loss: 0.28056296706199646
Epoch: 120/300 - Train loss: 0.27219098806381226, Validation loss: 0.2790960371494293
Epoch: 121/300 - Train loss: 0.27101731300354004, Validation loss: 0.27924224734306335
Epoch: 122/300 - Train loss: 0.2698631286621094, Validation loss: 0.2778675854206085
Epoch: 123/300 - Train loss: 0.26872801780700684, Validation loss: 0.27585428953170776
Epoch: 124/300 - Train loss: 0.267611563205719, Validation loss: 0.27460166811943054
Epoch: 125/300 - Train loss: 0.2665136456489563, Validation loss: 0.27410516142845154
Epoch: 126/300 - Train loss: 0.2654336392879486, Validation loss: 0.27334198355674744
Epoch: 127/300 - Train loss: 0.26437142491340637, Validation loss: 0.27180758118629456
Epoch: 128/300 - Train loss: 0.2633265256881714, Validation loss: 0.27059006690979004
Epoch: 129/300 - Train loss: 0.26229846477508545, Validation loss: 0.2705923616886139
Epoch: 130/300 - Train loss: 0.26128700375556946, Validation loss: 0.26893025636672974
Epoch: 131/300 - Train loss: 0.2602916359901428, Validation loss: 0.2683027684688568
Epoch: 132/300 - Train loss: 0.259312242269516, Validation loss: 0.2668685019016266
Epoch: 133/300 - Train loss: 0.25834834575653076, Validation loss: 0.26614928245544434
Epoch: 134/300 - Train loss: 0.25739967823028564, Validation loss: 0.26607978343963623
Epoch: 135/300 - Train loss: 0.2564657926559448, Validation loss: 0.26392439007759094
Epoch: 136/300 - Train loss: 0.2555464208126068, Validation loss: 0.2637513279914856
Epoch: 137/300 - Train loss: 0.2546413838863373, Validation loss: 0.2628433108329773
Epoch: 138/300 - Train loss: 0.25375044345855713, Validation loss: 0.2617757022380829
Epoch: 139/300 - Train loss: 0.2528732419013977, Validation loss: 0.2604520916938782
Epoch: 140/300 - Train loss: 0.2520095705986023, Validation loss: 0.260206401348114
Epoch: 141/300 - Train loss: 0.251159131526947, Validation loss: 0.2591007351875305
Epoch: 142/300 - Train loss: 0.2503216564655304, Validation loss: 0.2588430345058441
Epoch: 143/300 - Train loss: 0.24949687719345093, Validation loss: 0.25756439566612244
Epoch: 144/300 - Train loss: 0.24868448078632355, Validation loss: 0.2569315433502197
Epoch: 145/300 - Train loss: 0.24788425862789154, Validation loss: 0.2559412121772766
Epoch: 146/300 - Train loss: 0.2470959722995758, Validation loss: 0.2557442784309387
Epoch: 147/300 - Train loss: 0.24631935358047485, Validation loss: 0.25459787249565125
Epoch: 148/300 - Train loss: 0.2455540895462036, Validation loss: 0.25339964032173157
Epoch: 149/300 - Train loss: 0.2448001205921173, Validation loss: 0.2535012364387512
Epoch: 150/300 - Train loss: 0.24405710399150848, Validation loss: 0.25252097845077515
Epoch: 151/300 - Train loss: 0.24332484602928162, Validation loss: 0.25140705704689026
Epoch: 152/300 - Train loss: 0.24260321259498596, Validation loss: 0.25094568729400635
Epoch: 153/300 - Train loss: 0.2418919950723648, Validation loss: 0.2504802346229553
Epoch: 154/300 - Train loss: 0.24119099974632263, Validation loss: 0.2499958574771881
Epoch: 155/300 - Train loss: 0.24050015211105347, Validation loss: 0.24907822906970978
Epoch: 156/300 - Train loss: 0.23981927335262299, Validation loss: 0.24860429763793945
Epoch: 157/300 - Train loss: 0.2391481101512909, Validation loss: 0.24734723567962646
Epoch: 158/300 - Train loss: 0.238486647605896, Validation loss: 0.24683848023414612
Epoch: 159/300 - Train loss: 0.2378346174955368, Validation loss: 0.24626460671424866
Epoch: 160/300 - Train loss: 0.23719196021556854, Validation loss: 0.24567507207393646
Epoch: 161/300 - Train loss: 0.2365584522485733, Validation loss: 0.2452784776687622
Epoch: 162/300 - Train loss: 0.23593391478061676, Validation loss: 0.24461668729782104
Epoch: 163/300 - Train loss: 0.23531821370124817, Validation loss: 0.24342332780361176
Epoch: 164/300 - Train loss: 0.234711155295372, Validation loss: 0.24280796945095062
Epoch: 165/300 - Train loss: 0.23411253094673157, Validation loss: 0.24290576577186584
Epoch: 166/300 - Train loss: 0.2335222214460373, Validation loss: 0.242726668715477
