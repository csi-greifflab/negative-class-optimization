Epoch: 1/200 - Train loss: 0.6890975832939148, Validation loss: 0.6815645694732666
Epoch: 2/200 - Train loss: 0.6694256663322449, Validation loss: 0.6561917066574097
Epoch: 3/200 - Train loss: 0.6396504640579224, Validation loss: 0.626140832901001
Epoch: 4/200 - Train loss: 0.6093639135360718, Validation loss: 0.5987933874130249
Epoch: 5/200 - Train loss: 0.5836071968078613, Validation loss: 0.5765030980110168
Epoch: 6/200 - Train loss: 0.563126802444458, Validation loss: 0.5601155161857605
Epoch: 7/200 - Train loss: 0.5470747351646423, Validation loss: 0.5471721887588501
Epoch: 8/200 - Train loss: 0.534882128238678, Validation loss: 0.5367467403411865
Epoch: 9/200 - Train loss: 0.5253747701644897, Validation loss: 0.5290472507476807
Epoch: 10/200 - Train loss: 0.5180988311767578, Validation loss: 0.5229150652885437
Epoch: 11/200 - Train loss: 0.5118734240531921, Validation loss: 0.5181588530540466
Epoch: 12/200 - Train loss: 0.5066379904747009, Validation loss: 0.5133609771728516
Epoch: 13/200 - Train loss: 0.5026912093162537, Validation loss: 0.5095168948173523
Epoch: 14/200 - Train loss: 0.49821776151657104, Validation loss: 0.5051444172859192
Epoch: 15/200 - Train loss: 0.4944203794002533, Validation loss: 0.5022412538528442
Epoch: 16/200 - Train loss: 0.4909577965736389, Validation loss: 0.4989292323589325
Epoch: 17/200 - Train loss: 0.4880664050579071, Validation loss: 0.4960308372974396
Epoch: 18/200 - Train loss: 0.4846974313259125, Validation loss: 0.49274080991744995
Epoch: 19/200 - Train loss: 0.48221689462661743, Validation loss: 0.4893338978290558
Epoch: 20/200 - Train loss: 0.4789977967739105, Validation loss: 0.48700857162475586
Epoch: 21/200 - Train loss: 0.4766225218772888, Validation loss: 0.48466601967811584
Epoch: 22/200 - Train loss: 0.47366198897361755, Validation loss: 0.48193299770355225
Epoch: 23/200 - Train loss: 0.4709453880786896, Validation loss: 0.4798942804336548
Epoch: 24/200 - Train loss: 0.469081312417984, Validation loss: 0.4771669805049896
Epoch: 25/200 - Train loss: 0.46671342849731445, Validation loss: 0.4755507707595825
Epoch: 26/200 - Train loss: 0.46445223689079285, Validation loss: 0.4734165370464325
Epoch: 27/200 - Train loss: 0.46171897649765015, Validation loss: 0.47088107466697693
Epoch: 28/200 - Train loss: 0.45960161089897156, Validation loss: 0.4695388078689575
Epoch: 29/200 - Train loss: 0.45741215348243713, Validation loss: 0.4675990641117096
Epoch: 30/200 - Train loss: 0.4555124044418335, Validation loss: 0.46589407324790955
Epoch: 31/200 - Train loss: 0.4534679055213928, Validation loss: 0.46345022320747375
Epoch: 32/200 - Train loss: 0.45150530338287354, Validation loss: 0.4622003436088562
Epoch: 33/200 - Train loss: 0.4492161273956299, Validation loss: 0.4596773386001587
Epoch: 34/200 - Train loss: 0.4473942518234253, Validation loss: 0.45862409472465515
Epoch: 35/200 - Train loss: 0.4456360936164856, Validation loss: 0.456484854221344
Epoch: 36/200 - Train loss: 0.4432932436466217, Validation loss: 0.45506715774536133
Epoch: 37/200 - Train loss: 0.4415918290615082, Validation loss: 0.4538213014602661
Epoch: 38/200 - Train loss: 0.43947747349739075, Validation loss: 0.4516463875770569
Epoch: 39/200 - Train loss: 0.4384782016277313, Validation loss: 0.4497845470905304
Epoch: 40/200 - Train loss: 0.43637850880622864, Validation loss: 0.44924110174179077
Epoch: 41/200 - Train loss: 0.4345780313014984, Validation loss: 0.44734662771224976
Epoch: 42/200 - Train loss: 0.43282875418663025, Validation loss: 0.44524088501930237
Epoch: 43/200 - Train loss: 0.43076643347740173, Validation loss: 0.44387102127075195
Epoch: 44/200 - Train loss: 0.4288862645626068, Validation loss: 0.44147545099258423
Epoch: 45/200 - Train loss: 0.42736274003982544, Validation loss: 0.4406417906284332
Epoch: 46/200 - Train loss: 0.42545032501220703, Validation loss: 0.4387483298778534
Epoch: 47/200 - Train loss: 0.42409375309944153, Validation loss: 0.43770134449005127
Epoch: 48/200 - Train loss: 0.4217236340045929, Validation loss: 0.43506383895874023
Epoch: 49/200 - Train loss: 0.41990482807159424, Validation loss: 0.4337160885334015
Epoch: 50/200 - Train loss: 0.41838183999061584, Validation loss: 0.4325488209724426
Epoch: 51/200 - Train loss: 0.41685613989830017, Validation loss: 0.43062758445739746
Epoch: 52/200 - Train loss: 0.41446244716644287, Validation loss: 0.42881128191947937
Epoch: 53/200 - Train loss: 0.4130769371986389, Validation loss: 0.4281710684299469
Epoch: 54/200 - Train loss: 0.4107939600944519, Validation loss: 0.42569592595100403
Epoch: 55/200 - Train loss: 0.4089938700199127, Validation loss: 0.4240642786026001
Epoch: 56/200 - Train loss: 0.4070058763027191, Validation loss: 0.4226730465888977
Epoch: 57/200 - Train loss: 0.4054242670536041, Validation loss: 0.42045727372169495
Epoch: 58/200 - Train loss: 0.40319573879241943, Validation loss: 0.4196203351020813
Epoch: 59/200 - Train loss: 0.40130409598350525, Validation loss: 0.4172922372817993
Epoch: 60/200 - Train loss: 0.3994434177875519, Validation loss: 0.41612905263900757
Epoch: 61/200 - Train loss: 0.39745649695396423, Validation loss: 0.413929283618927
Epoch: 62/200 - Train loss: 0.39557039737701416, Validation loss: 0.41260969638824463
Epoch: 63/200 - Train loss: 0.3935341238975525, Validation loss: 0.4102863371372223
Epoch: 64/200 - Train loss: 0.39157113432884216, Validation loss: 0.4095545709133148
Epoch: 65/200 - Train loss: 0.38941895961761475, Validation loss: 0.40698355436325073
Epoch: 66/200 - Train loss: 0.38777172565460205, Validation loss: 0.40575897693634033
Epoch: 67/200 - Train loss: 0.3864492177963257, Validation loss: 0.403897225856781
Epoch: 68/200 - Train loss: 0.3834184408187866, Validation loss: 0.4014432728290558
Epoch: 69/200 - Train loss: 0.3814331591129303, Validation loss: 0.4007832407951355
Epoch: 70/200 - Train loss: 0.379417359828949, Validation loss: 0.39848193526268005
Epoch: 71/200 - Train loss: 0.3770265281200409, Validation loss: 0.3965524137020111
Epoch: 72/200 - Train loss: 0.3751528561115265, Validation loss: 0.39436399936676025
Epoch: 73/200 - Train loss: 0.373149573802948, Validation loss: 0.39310017228126526
Epoch: 74/200 - Train loss: 0.3713255822658539, Validation loss: 0.39109545946121216
Epoch: 75/200 - Train loss: 0.3690500855445862, Validation loss: 0.38917550444602966
Epoch: 76/200 - Train loss: 0.3669509291648865, Validation loss: 0.3871694505214691
Epoch: 77/200 - Train loss: 0.36502423882484436, Validation loss: 0.3854786455631256
Epoch: 78/200 - Train loss: 0.3630329966545105, Validation loss: 0.3840407729148865
Epoch: 79/200 - Train loss: 0.3610208034515381, Validation loss: 0.381881982088089
Epoch: 80/200 - Train loss: 0.3588802218437195, Validation loss: 0.38039878010749817
Epoch: 81/200 - Train loss: 0.3568967580795288, Validation loss: 0.3789559006690979
Epoch: 82/200 - Train loss: 0.3549385070800781, Validation loss: 0.37692469358444214
Epoch: 83/200 - Train loss: 0.35296526551246643, Validation loss: 0.37532928586006165
Epoch: 84/200 - Train loss: 0.3508945107460022, Validation loss: 0.373212993144989
Epoch: 85/200 - Train loss: 0.3495316505432129, Validation loss: 0.3713957369327545
Epoch: 86/200 - Train loss: 0.34710046648979187, Validation loss: 0.3708449900150299
Epoch: 87/200 - Train loss: 0.34547775983810425, Validation loss: 0.36823517084121704
Epoch: 88/200 - Train loss: 0.3433311879634857, Validation loss: 0.3661271035671234
Epoch: 89/200 - Train loss: 0.34190651774406433, Validation loss: 0.36520424485206604
Epoch: 90/200 - Train loss: 0.33982110023498535, Validation loss: 0.3626485764980316
Epoch: 91/200 - Train loss: 0.3377217650413513, Validation loss: 0.36177054047584534
Epoch: 92/200 - Train loss: 0.3362254202365875, Validation loss: 0.3598821759223938
Epoch: 93/200 - Train loss: 0.3342089354991913, Validation loss: 0.3582057058811188
Epoch: 94/200 - Train loss: 0.3324134349822998, Validation loss: 0.35689881443977356
Epoch: 95/200 - Train loss: 0.3310563862323761, Validation loss: 0.35479459166526794
Epoch: 96/200 - Train loss: 0.32898446917533875, Validation loss: 0.35398805141448975
Epoch: 97/200 - Train loss: 0.3272518515586853, Validation loss: 0.35207808017730713
Epoch: 98/200 - Train loss: 0.32542142271995544, Validation loss: 0.3507910966873169
Epoch: 99/200 - Train loss: 0.32379359006881714, Validation loss: 0.34844112396240234
Epoch: 100/200 - Train loss: 0.32213905453681946, Validation loss: 0.34807878732681274
Epoch: 101/200 - Train loss: 0.32042747735977173, Validation loss: 0.3467017710208893
Epoch: 102/200 - Train loss: 0.3190537989139557, Validation loss: 0.34462958574295044
Epoch: 103/200 - Train loss: 0.3171585500240326, Validation loss: 0.34296759963035583
Epoch: 104/200 - Train loss: 0.3155176341533661, Validation loss: 0.34231624007225037
Epoch: 105/200 - Train loss: 0.31434211134910583, Validation loss: 0.3409683108329773
Epoch: 106/200 - Train loss: 0.31241294741630554, Validation loss: 0.3395098149776459
Epoch: 107/200 - Train loss: 0.3110750615596771, Validation loss: 0.33755263686180115
Epoch: 108/200 - Train loss: 0.30957791209220886, Validation loss: 0.336129754781723
Epoch: 109/200 - Train loss: 0.30825334787368774, Validation loss: 0.3351184129714966
Epoch: 110/200 - Train loss: 0.3064877688884735, Validation loss: 0.33420509099960327
Epoch: 111/200 - Train loss: 0.30518513917922974, Validation loss: 0.33228057622909546
Epoch: 112/200 - Train loss: 0.3035408556461334, Validation loss: 0.3320537507534027
Epoch: 113/200 - Train loss: 0.30198314785957336, Validation loss: 0.3301437497138977
Epoch: 114/200 - Train loss: 0.30089908838272095, Validation loss: 0.3291735351085663
Epoch: 115/200 - Train loss: 0.29955077171325684, Validation loss: 0.3277891278266907
Epoch: 116/200 - Train loss: 0.29823681712150574, Validation loss: 0.32657089829444885
Epoch: 117/200 - Train loss: 0.29679855704307556, Validation loss: 0.3256711959838867
Epoch: 118/200 - Train loss: 0.29553380608558655, Validation loss: 0.32471394538879395
Epoch: 119/200 - Train loss: 0.2941769063472748, Validation loss: 0.3234088718891144
Epoch: 120/200 - Train loss: 0.29264217615127563, Validation loss: 0.3223412036895752
Epoch: 121/200 - Train loss: 0.29149529337882996, Validation loss: 0.321235716342926
Epoch: 122/200 - Train loss: 0.2906085252761841, Validation loss: 0.32035601139068604
Epoch: 123/200 - Train loss: 0.28939589858055115, Validation loss: 0.3194386661052704
Epoch: 124/200 - Train loss: 0.2878829538822174, Validation loss: 0.3186458647251129
Epoch: 125/200 - Train loss: 0.28657981753349304, Validation loss: 0.3176290690898895
Epoch: 126/200 - Train loss: 0.28541380167007446, Validation loss: 0.31634390354156494
Epoch: 127/200 - Train loss: 0.2846456468105316, Validation loss: 0.3156055808067322
Epoch: 128/200 - Train loss: 0.2829810678958893, Validation loss: 0.3152015805244446
Epoch: 129/200 - Train loss: 0.2824842035770416, Validation loss: 0.3137062191963196
Epoch: 130/200 - Train loss: 0.28129202127456665, Validation loss: 0.31241029500961304
Epoch: 131/200 - Train loss: 0.2801617383956909, Validation loss: 0.3113556504249573
Epoch: 132/200 - Train loss: 0.27915388345718384, Validation loss: 0.31111493706703186
Epoch: 133/200 - Train loss: 0.2779591977596283, Validation loss: 0.3092626631259918
Epoch: 134/200 - Train loss: 0.2772863805294037, Validation loss: 0.30975058674812317
Epoch: 135/200 - Train loss: 0.2757563591003418, Validation loss: 0.30858245491981506
Epoch: 136/200 - Train loss: 0.27474620938301086, Validation loss: 0.3081178665161133
Epoch: 137/200 - Train loss: 0.27386587858200073, Validation loss: 0.30672818422317505
Epoch: 138/200 - Train loss: 0.2730949819087982, Validation loss: 0.30578747391700745
Epoch: 139/200 - Train loss: 0.272014856338501, Validation loss: 0.30579283833503723
Epoch: 140/200 - Train loss: 0.2711358070373535, Validation loss: 0.3046792447566986
Epoch: 141/200 - Train loss: 0.27001211047172546, Validation loss: 0.3033815324306488
Epoch: 142/200 - Train loss: 0.269317626953125, Validation loss: 0.3034084439277649
Epoch: 143/200 - Train loss: 0.26838624477386475, Validation loss: 0.30214452743530273
Epoch: 144/200 - Train loss: 0.26725995540618896, Validation loss: 0.3016442358493805
Epoch: 145/200 - Train loss: 0.2664102017879486, Validation loss: 0.3005150556564331
Epoch: 146/200 - Train loss: 0.2656974196434021, Validation loss: 0.3000028133392334
Epoch: 147/200 - Train loss: 0.26513978838920593, Validation loss: 0.2993181347846985
Epoch: 148/200 - Train loss: 0.2637872099876404, Validation loss: 0.29801949858665466
Epoch: 149/200 - Train loss: 0.26315751671791077, Validation loss: 0.29765576124191284
Epoch: 150/200 - Train loss: 0.2624930143356323, Validation loss: 0.2973874807357788
Epoch: 151/200 - Train loss: 0.2613356113433838, Validation loss: 0.29740235209465027
Epoch: 152/200 - Train loss: 0.2608623802661896, Validation loss: 0.29617780447006226
Epoch: 153/200 - Train loss: 0.2597363591194153, Validation loss: 0.29597005248069763
Epoch: 154/200 - Train loss: 0.2591401934623718, Validation loss: 0.2946621775627136
Epoch: 155/200 - Train loss: 0.25848421454429626, Validation loss: 0.29437294602394104
Epoch: 156/200 - Train loss: 0.257489413022995, Validation loss: 0.2936631739139557
Epoch: 157/200 - Train loss: 0.2572087347507477, Validation loss: 0.2932034134864807
