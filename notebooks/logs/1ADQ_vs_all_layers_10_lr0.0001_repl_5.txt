Epoch: 1/200 - Train loss: 0.6907713413238525, Validation loss: 0.6824125647544861
Epoch: 2/200 - Train loss: 0.6692479252815247, Validation loss: 0.6536574363708496
Epoch: 3/200 - Train loss: 0.6354712247848511, Validation loss: 0.6200194954872131
Epoch: 4/200 - Train loss: 0.6032574772834778, Validation loss: 0.59200119972229
Epoch: 5/200 - Train loss: 0.5770400762557983, Validation loss: 0.5702650547027588
Epoch: 6/200 - Train loss: 0.5565021634101868, Validation loss: 0.5533633828163147
Epoch: 7/200 - Train loss: 0.540937602519989, Validation loss: 0.5398994088172913
Epoch: 8/200 - Train loss: 0.5281851291656494, Validation loss: 0.529984712600708
Epoch: 9/200 - Train loss: 0.5183354020118713, Validation loss: 0.5218105316162109
Epoch: 10/200 - Train loss: 0.5099433064460754, Validation loss: 0.5142985582351685
Epoch: 11/200 - Train loss: 0.5030588507652283, Validation loss: 0.5081368088722229
Epoch: 12/200 - Train loss: 0.49686557054519653, Validation loss: 0.5035855770111084
Epoch: 13/200 - Train loss: 0.49186602234840393, Validation loss: 0.49826106429100037
Epoch: 14/200 - Train loss: 0.48682039976119995, Validation loss: 0.49425333738327026
Epoch: 15/200 - Train loss: 0.4828161597251892, Validation loss: 0.4904443025588989
Epoch: 16/200 - Train loss: 0.47886109352111816, Validation loss: 0.4875946640968323
Epoch: 17/200 - Train loss: 0.4754229784011841, Validation loss: 0.4838770031929016
Epoch: 18/200 - Train loss: 0.4720732569694519, Validation loss: 0.48104268312454224
Epoch: 19/200 - Train loss: 0.46895506978034973, Validation loss: 0.47770601511001587
Epoch: 20/200 - Train loss: 0.46563249826431274, Validation loss: 0.47606807947158813
Epoch: 21/200 - Train loss: 0.46339842677116394, Validation loss: 0.4723771810531616
Epoch: 22/200 - Train loss: 0.4609135091304779, Validation loss: 0.46985721588134766
Epoch: 23/200 - Train loss: 0.45820677280426025, Validation loss: 0.46797075867652893
Epoch: 24/200 - Train loss: 0.4557642638683319, Validation loss: 0.4665546715259552
Epoch: 25/200 - Train loss: 0.4536915123462677, Validation loss: 0.4641580879688263
Epoch: 26/200 - Train loss: 0.45150983333587646, Validation loss: 0.46261438727378845
Epoch: 27/200 - Train loss: 0.4490283727645874, Validation loss: 0.4604416489601135
Epoch: 28/200 - Train loss: 0.4473888576030731, Validation loss: 0.4581111967563629
Epoch: 29/200 - Train loss: 0.4454467296600342, Validation loss: 0.45640718936920166
Epoch: 30/200 - Train loss: 0.44288739562034607, Validation loss: 0.454861044883728
Epoch: 31/200 - Train loss: 0.4408194124698639, Validation loss: 0.4536588490009308
Epoch: 32/200 - Train loss: 0.4388711154460907, Validation loss: 0.45111915469169617
Epoch: 33/200 - Train loss: 0.43703657388687134, Validation loss: 0.44970250129699707
Epoch: 34/200 - Train loss: 0.4350981116294861, Validation loss: 0.447532594203949
Epoch: 35/200 - Train loss: 0.4326291084289551, Validation loss: 0.4461823105812073
Epoch: 36/200 - Train loss: 0.43075311183929443, Validation loss: 0.4433402717113495
Epoch: 37/200 - Train loss: 0.42879506945610046, Validation loss: 0.4429880678653717
Epoch: 38/200 - Train loss: 0.427114874124527, Validation loss: 0.4408360719680786
Epoch: 39/200 - Train loss: 0.4249153137207031, Validation loss: 0.4386942386627197
Epoch: 40/200 - Train loss: 0.42289844155311584, Validation loss: 0.4371897280216217
Epoch: 41/200 - Train loss: 0.4206748604774475, Validation loss: 0.43596896529197693
Epoch: 42/200 - Train loss: 0.418729692697525, Validation loss: 0.4343395531177521
Epoch: 43/200 - Train loss: 0.4164252281188965, Validation loss: 0.43180549144744873
Epoch: 44/200 - Train loss: 0.414773553609848, Validation loss: 0.4291704297065735
Epoch: 45/200 - Train loss: 0.4125705659389496, Validation loss: 0.42778798937797546
Epoch: 46/200 - Train loss: 0.4102404713630676, Validation loss: 0.4269046485424042
Epoch: 47/200 - Train loss: 0.408048152923584, Validation loss: 0.42428654432296753
Epoch: 48/200 - Train loss: 0.4061272144317627, Validation loss: 0.4227758049964905
Epoch: 49/200 - Train loss: 0.4039812982082367, Validation loss: 0.4213287830352783
Epoch: 50/200 - Train loss: 0.4018959701061249, Validation loss: 0.41914454102516174
Epoch: 51/200 - Train loss: 0.39993980526924133, Validation loss: 0.417209267616272
Epoch: 52/200 - Train loss: 0.3979548215866089, Validation loss: 0.41571882367134094
Epoch: 53/200 - Train loss: 0.3962433934211731, Validation loss: 0.4140726327896118
Epoch: 54/200 - Train loss: 0.39365023374557495, Validation loss: 0.4121090769767761
Epoch: 55/200 - Train loss: 0.3918754458427429, Validation loss: 0.40980473160743713
Epoch: 56/200 - Train loss: 0.38963213562965393, Validation loss: 0.4085861146450043
Epoch: 57/200 - Train loss: 0.38749274611473083, Validation loss: 0.4061308801174164
Epoch: 58/200 - Train loss: 0.3859136998653412, Validation loss: 0.4044351875782013
Epoch: 59/200 - Train loss: 0.3835999369621277, Validation loss: 0.4023413062095642
Epoch: 60/200 - Train loss: 0.38201478123664856, Validation loss: 0.40062499046325684
Epoch: 61/200 - Train loss: 0.3794552981853485, Validation loss: 0.3988505005836487
Epoch: 62/200 - Train loss: 0.3778897225856781, Validation loss: 0.3974410891532898
Epoch: 63/200 - Train loss: 0.37580734491348267, Validation loss: 0.39554041624069214
Epoch: 64/200 - Train loss: 0.37352100014686584, Validation loss: 0.39424872398376465
Epoch: 65/200 - Train loss: 0.37196680903434753, Validation loss: 0.3913077712059021
Epoch: 66/200 - Train loss: 0.3693014681339264, Validation loss: 0.3908692002296448
Epoch: 67/200 - Train loss: 0.3675755560398102, Validation loss: 0.3879089653491974
Epoch: 68/200 - Train loss: 0.36575847864151, Validation loss: 0.38575491309165955
Epoch: 69/200 - Train loss: 0.36367693543434143, Validation loss: 0.3851143419742584
Epoch: 70/200 - Train loss: 0.3620563745498657, Validation loss: 0.38252192735671997
Epoch: 71/200 - Train loss: 0.3601363003253937, Validation loss: 0.38085564970970154
Epoch: 72/200 - Train loss: 0.3579040467739105, Validation loss: 0.3791101574897766
Epoch: 73/200 - Train loss: 0.35632866621017456, Validation loss: 0.37833938002586365
Epoch: 74/200 - Train loss: 0.3543394207954407, Validation loss: 0.37612080574035645
Epoch: 75/200 - Train loss: 0.35277026891708374, Validation loss: 0.3739505708217621
Epoch: 76/200 - Train loss: 0.3505714535713196, Validation loss: 0.3730427622795105
Epoch: 77/200 - Train loss: 0.3489907383918762, Validation loss: 0.3711267411708832
Epoch: 78/200 - Train loss: 0.34721556305885315, Validation loss: 0.3697511851787567
Epoch: 79/200 - Train loss: 0.34538182616233826, Validation loss: 0.368497759103775
Epoch: 80/200 - Train loss: 0.34369027614593506, Validation loss: 0.3660590648651123
Epoch: 81/200 - Train loss: 0.3418881595134735, Validation loss: 0.364912748336792
Epoch: 82/200 - Train loss: 0.34015601873397827, Validation loss: 0.3633326292037964
Epoch: 83/200 - Train loss: 0.338162362575531, Validation loss: 0.3622823655605316
Epoch: 84/200 - Train loss: 0.3368142545223236, Validation loss: 0.3607318103313446
Epoch: 85/200 - Train loss: 0.33497709035873413, Validation loss: 0.3594743311405182
Epoch: 86/200 - Train loss: 0.33350008726119995, Validation loss: 0.35755547881126404
Epoch: 87/200 - Train loss: 0.3316026031970978, Validation loss: 0.3558453619480133
Epoch: 88/200 - Train loss: 0.32993343472480774, Validation loss: 0.3543771803379059
Epoch: 89/200 - Train loss: 0.3285831809043884, Validation loss: 0.35290688276290894
Epoch: 90/200 - Train loss: 0.32703113555908203, Validation loss: 0.3515332043170929
Epoch: 91/200 - Train loss: 0.3250139355659485, Validation loss: 0.3513208031654358
Epoch: 92/200 - Train loss: 0.3234730064868927, Validation loss: 0.34884515404701233
Epoch: 93/200 - Train loss: 0.3219951391220093, Validation loss: 0.34751883149147034
Epoch: 94/200 - Train loss: 0.32068127393722534, Validation loss: 0.3461075723171234
Epoch: 95/200 - Train loss: 0.31919023394584656, Validation loss: 0.3442475497722626
Epoch: 96/200 - Train loss: 0.317428320646286, Validation loss: 0.3438447117805481
Epoch: 97/200 - Train loss: 0.3158988952636719, Validation loss: 0.342527836561203
Epoch: 98/200 - Train loss: 0.3143913745880127, Validation loss: 0.3409830629825592
Epoch: 99/200 - Train loss: 0.3133125305175781, Validation loss: 0.34047549962997437
Epoch: 100/200 - Train loss: 0.31173187494277954, Validation loss: 0.3388402462005615
Epoch: 101/200 - Train loss: 0.3105822205543518, Validation loss: 0.33804088830947876
Epoch: 102/200 - Train loss: 0.3089521527290344, Validation loss: 0.336401104927063
Epoch: 103/200 - Train loss: 0.3081711530685425, Validation loss: 0.33503490686416626
Epoch: 104/200 - Train loss: 0.3064935803413391, Validation loss: 0.3341497480869293
Epoch: 105/200 - Train loss: 0.30544033646583557, Validation loss: 0.3334639072418213
Epoch: 106/200 - Train loss: 0.3039148449897766, Validation loss: 0.3321021795272827
Epoch: 107/200 - Train loss: 0.30284497141838074, Validation loss: 0.3316263258457184
Epoch: 108/200 - Train loss: 0.30150917172431946, Validation loss: 0.33092233538627625
Epoch: 109/200 - Train loss: 0.30053427815437317, Validation loss: 0.3288220167160034
Epoch: 110/200 - Train loss: 0.2997332811355591, Validation loss: 0.32818928360939026
Epoch: 111/200 - Train loss: 0.29789772629737854, Validation loss: 0.328040212392807
Epoch: 112/200 - Train loss: 0.297021746635437, Validation loss: 0.32610002160072327
Epoch: 113/200 - Train loss: 0.2956424057483673, Validation loss: 0.32538726925849915
Epoch: 114/200 - Train loss: 0.2943672835826874, Validation loss: 0.3242941200733185
Epoch: 115/200 - Train loss: 0.29350847005844116, Validation loss: 0.32323768734931946
Epoch: 116/200 - Train loss: 0.29289066791534424, Validation loss: 0.3225800395011902
Epoch: 117/200 - Train loss: 0.2912915050983429, Validation loss: 0.3221227526664734
Epoch: 118/200 - Train loss: 0.29046687483787537, Validation loss: 0.32038167119026184
Epoch: 119/200 - Train loss: 0.289419561624527, Validation loss: 0.320608526468277
Epoch: 120/200 - Train loss: 0.2887625992298126, Validation loss: 0.3191721439361572
Epoch: 121/200 - Train loss: 0.28756454586982727, Validation loss: 0.31842368841171265
Epoch: 122/200 - Train loss: 0.28635114431381226, Validation loss: 0.3175511062145233
Epoch: 123/200 - Train loss: 0.2853531837463379, Validation loss: 0.3177526593208313
Epoch: 124/200 - Train loss: 0.28409701585769653, Validation loss: 0.3159600496292114
Epoch: 125/200 - Train loss: 0.28328096866607666, Validation loss: 0.31545212864875793
Epoch: 126/200 - Train loss: 0.28295964002609253, Validation loss: 0.3145168125629425
Epoch: 127/200 - Train loss: 0.2819340229034424, Validation loss: 0.3135805130004883
Epoch: 128/200 - Train loss: 0.2807462811470032, Validation loss: 0.3128959834575653
Epoch: 129/200 - Train loss: 0.28003793954849243, Validation loss: 0.313287615776062
Epoch: 130/200 - Train loss: 0.2790858745574951, Validation loss: 0.3117513358592987
Epoch: 131/200 - Train loss: 0.27779167890548706, Validation loss: 0.3110954165458679
Epoch: 132/200 - Train loss: 0.27732065320014954, Validation loss: 0.31028318405151367
Epoch: 133/200 - Train loss: 0.2758775055408478, Validation loss: 0.3103410601615906
Epoch: 134/200 - Train loss: 0.2753615081310272, Validation loss: 0.30893078446388245
Epoch: 135/200 - Train loss: 0.27448326349258423, Validation loss: 0.3080178201198578
Epoch: 136/200 - Train loss: 0.2737378478050232, Validation loss: 0.30699482560157776
Epoch: 137/200 - Train loss: 0.2726510465145111, Validation loss: 0.30710580945014954
Epoch: 138/200 - Train loss: 0.27220189571380615, Validation loss: 0.3063508868217468
Epoch: 139/200 - Train loss: 0.2710663676261902, Validation loss: 0.3055301904678345
Epoch: 140/200 - Train loss: 0.2705070376396179, Validation loss: 0.3045410215854645
Epoch: 141/200 - Train loss: 0.26967352628707886, Validation loss: 0.30499452352523804
Epoch: 142/200 - Train loss: 0.26890799403190613, Validation loss: 0.30363255739212036
Epoch: 143/200 - Train loss: 0.26802849769592285, Validation loss: 0.303699791431427
Epoch: 144/200 - Train loss: 0.2676370441913605, Validation loss: 0.3020513653755188
Epoch: 145/200 - Train loss: 0.26656460762023926, Validation loss: 0.30237144231796265
Epoch: 146/200 - Train loss: 0.26598265767097473, Validation loss: 0.30122748017311096
Epoch: 147/200 - Train loss: 0.2654033303260803, Validation loss: 0.30052149295806885
Epoch: 148/200 - Train loss: 0.2644840180873871, Validation loss: 0.30093836784362793
Epoch: 149/200 - Train loss: 0.26394227147102356, Validation loss: 0.29927152395248413
Epoch: 150/200 - Train loss: 0.2630906105041504, Validation loss: 0.2997156083583832
Epoch: 151/200 - Train loss: 0.2625652551651001, Validation loss: 0.29861128330230713
Epoch: 152/200 - Train loss: 0.26179757714271545, Validation loss: 0.29853981733322144
Epoch: 153/200 - Train loss: 0.2609943151473999, Validation loss: 0.2977917790412903
