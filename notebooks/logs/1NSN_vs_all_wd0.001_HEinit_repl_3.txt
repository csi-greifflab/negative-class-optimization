Epoch: 1/300 - Train loss: 0.7137947678565979, Validation loss: 0.7087529897689819
Epoch: 2/300 - Train loss: 0.7110868692398071, Validation loss: 0.7062171697616577
Epoch: 3/300 - Train loss: 0.7084508538246155, Validation loss: 0.7039516568183899
Epoch: 4/300 - Train loss: 0.7058754563331604, Validation loss: 0.701603889465332
Epoch: 5/300 - Train loss: 0.7033465504646301, Validation loss: 0.69883793592453
Epoch: 6/300 - Train loss: 0.7008477449417114, Validation loss: 0.6966114044189453
Epoch: 7/300 - Train loss: 0.6983528137207031, Validation loss: 0.6943151950836182
Epoch: 8/300 - Train loss: 0.69583660364151, Validation loss: 0.6919131278991699
Epoch: 9/300 - Train loss: 0.6932809352874756, Validation loss: 0.6894603967666626
Epoch: 10/300 - Train loss: 0.6906757354736328, Validation loss: 0.6869126558303833
Epoch: 11/300 - Train loss: 0.6880044341087341, Validation loss: 0.6843465566635132
Epoch: 12/300 - Train loss: 0.6852511167526245, Validation loss: 0.6815478205680847
Epoch: 13/300 - Train loss: 0.6824073195457458, Validation loss: 0.6787251234054565
Epoch: 14/300 - Train loss: 0.6794649958610535, Validation loss: 0.6758554577827454
Epoch: 15/300 - Train loss: 0.676410436630249, Validation loss: 0.6726747155189514
Epoch: 16/300 - Train loss: 0.6732439398765564, Validation loss: 0.6697325706481934
Epoch: 17/300 - Train loss: 0.6699658632278442, Validation loss: 0.6663485169410706
Epoch: 18/300 - Train loss: 0.6665728092193604, Validation loss: 0.6628890633583069
Epoch: 19/300 - Train loss: 0.663068413734436, Validation loss: 0.659492015838623
Epoch: 20/300 - Train loss: 0.6594541668891907, Validation loss: 0.6558895111083984
Epoch: 21/300 - Train loss: 0.6557317972183228, Validation loss: 0.652210533618927
Epoch: 22/300 - Train loss: 0.6519085168838501, Validation loss: 0.6483446955680847
Epoch: 23/300 - Train loss: 0.6479880213737488, Validation loss: 0.6444959044456482
Epoch: 24/300 - Train loss: 0.6439692974090576, Validation loss: 0.6404385566711426
Epoch: 25/300 - Train loss: 0.6398600935935974, Validation loss: 0.6364014744758606
Epoch: 26/300 - Train loss: 0.6356663107872009, Validation loss: 0.632295548915863
Epoch: 27/300 - Train loss: 0.6313883662223816, Validation loss: 0.6279773712158203
Epoch: 28/300 - Train loss: 0.6270267367362976, Validation loss: 0.6236674189567566
Epoch: 29/300 - Train loss: 0.6225824356079102, Validation loss: 0.6193763613700867
Epoch: 30/300 - Train loss: 0.618061363697052, Validation loss: 0.6147701740264893
Epoch: 31/300 - Train loss: 0.6134628057479858, Validation loss: 0.6102374792098999
Epoch: 32/300 - Train loss: 0.6087903380393982, Validation loss: 0.6054537892341614
Epoch: 33/300 - Train loss: 0.6040457487106323, Validation loss: 0.6007974147796631
Epoch: 34/300 - Train loss: 0.5992326736450195, Validation loss: 0.5960087180137634
Epoch: 35/300 - Train loss: 0.5943529009819031, Validation loss: 0.5909144282341003
Epoch: 36/300 - Train loss: 0.5894095301628113, Validation loss: 0.5861355066299438
Epoch: 37/300 - Train loss: 0.5844120383262634, Validation loss: 0.5809598565101624
Epoch: 38/300 - Train loss: 0.5793664455413818, Validation loss: 0.5761601328849792
Epoch: 39/300 - Train loss: 0.5742676854133606, Validation loss: 0.5709578394889832
Epoch: 40/300 - Train loss: 0.5691230893135071, Validation loss: 0.565792441368103
Epoch: 41/300 - Train loss: 0.563951849937439, Validation loss: 0.5605260133743286
Epoch: 42/300 - Train loss: 0.5587629675865173, Validation loss: 0.555629312992096
Epoch: 43/300 - Train loss: 0.5535608530044556, Validation loss: 0.5502135753631592
Epoch: 44/300 - Train loss: 0.5483475923538208, Validation loss: 0.5453001260757446
Epoch: 45/300 - Train loss: 0.5431348085403442, Validation loss: 0.5401079058647156
Epoch: 46/300 - Train loss: 0.5379313826560974, Validation loss: 0.5346294641494751
Epoch: 47/300 - Train loss: 0.5327526926994324, Validation loss: 0.5295689702033997
Epoch: 48/300 - Train loss: 0.527606725692749, Validation loss: 0.5246194005012512
Epoch: 49/300 - Train loss: 0.5224916338920593, Validation loss: 0.5193762183189392
Epoch: 50/300 - Train loss: 0.5174181461334229, Validation loss: 0.5147819519042969
Epoch: 51/300 - Train loss: 0.5123911499977112, Validation loss: 0.5094344019889832
Epoch: 52/300 - Train loss: 0.5074228644371033, Validation loss: 0.5046152472496033
Epoch: 53/300 - Train loss: 0.5025165677070618, Validation loss: 0.5003854036331177
Epoch: 54/300 - Train loss: 0.49767425656318665, Validation loss: 0.4948636591434479
Epoch: 55/300 - Train loss: 0.49290066957473755, Validation loss: 0.49083212018013
Epoch: 56/300 - Train loss: 0.48820266127586365, Validation loss: 0.48628970980644226
Epoch: 57/300 - Train loss: 0.48358282446861267, Validation loss: 0.4813602864742279
Epoch: 58/300 - Train loss: 0.4790434241294861, Validation loss: 0.47693732380867004
Epoch: 59/300 - Train loss: 0.47458603978157043, Validation loss: 0.4726015627384186
Epoch: 60/300 - Train loss: 0.47021377086639404, Validation loss: 0.4687962234020233
Epoch: 61/300 - Train loss: 0.46593236923217773, Validation loss: 0.46405041217803955
Epoch: 62/300 - Train loss: 0.4617423117160797, Validation loss: 0.45986899733543396
Epoch: 63/300 - Train loss: 0.4576438367366791, Validation loss: 0.4560600221157074
Epoch: 64/300 - Train loss: 0.4536380469799042, Validation loss: 0.45223382115364075
Epoch: 65/300 - Train loss: 0.4497252106666565, Validation loss: 0.44843846559524536
Epoch: 66/300 - Train loss: 0.4459056854248047, Validation loss: 0.44499728083610535
Epoch: 67/300 - Train loss: 0.44217821955680847, Validation loss: 0.44139233231544495
Epoch: 68/300 - Train loss: 0.4385421574115753, Validation loss: 0.43801969289779663
Epoch: 69/300 - Train loss: 0.43499723076820374, Validation loss: 0.4346325099468231
Epoch: 70/300 - Train loss: 0.43154191970825195, Validation loss: 0.4307771325111389
Epoch: 71/300 - Train loss: 0.4281752109527588, Validation loss: 0.42772436141967773
Epoch: 72/300 - Train loss: 0.42489638924598694, Validation loss: 0.42431655526161194
Epoch: 73/300 - Train loss: 0.421703577041626, Validation loss: 0.4211786091327667
Epoch: 74/300 - Train loss: 0.4185955226421356, Validation loss: 0.41855937242507935
Epoch: 75/300 - Train loss: 0.41557058691978455, Validation loss: 0.41512587666511536
Epoch: 76/300 - Train loss: 0.4126269519329071, Validation loss: 0.41264691948890686
Epoch: 77/300 - Train loss: 0.4097628891468048, Validation loss: 0.40992045402526855
Epoch: 78/300 - Train loss: 0.4069765508174896, Validation loss: 0.4071282744407654
Epoch: 79/300 - Train loss: 0.40426579117774963, Validation loss: 0.40430793166160583
Epoch: 80/300 - Train loss: 0.4016285240650177, Validation loss: 0.40206488966941833
Epoch: 81/300 - Train loss: 0.3990631103515625, Validation loss: 0.3993974030017853
Epoch: 82/300 - Train loss: 0.39656776189804077, Validation loss: 0.3972474932670593
Epoch: 83/300 - Train loss: 0.3941401541233063, Validation loss: 0.3945809006690979
Epoch: 84/300 - Train loss: 0.3917781710624695, Validation loss: 0.39247825741767883
Epoch: 85/300 - Train loss: 0.3894794285297394, Validation loss: 0.3906176686286926
Epoch: 86/300 - Train loss: 0.3872416615486145, Validation loss: 0.38831236958503723
Epoch: 87/300 - Train loss: 0.3850632607936859, Validation loss: 0.38563287258148193
Epoch: 88/300 - Train loss: 0.3829422891139984, Validation loss: 0.384183794260025
Epoch: 89/300 - Train loss: 0.38087669014930725, Validation loss: 0.38206321001052856
Epoch: 90/300 - Train loss: 0.37886443734169006, Validation loss: 0.3801291584968567
Epoch: 91/300 - Train loss: 0.37690404057502747, Validation loss: 0.37790629267692566
Epoch: 92/300 - Train loss: 0.37499338388442993, Validation loss: 0.3760213851928711
Epoch: 93/300 - Train loss: 0.37313053011894226, Validation loss: 0.37469807267189026
Epoch: 94/300 - Train loss: 0.37131381034851074, Validation loss: 0.373212605714798
Epoch: 95/300 - Train loss: 0.3695415258407593, Validation loss: 0.37115707993507385
Epoch: 96/300 - Train loss: 0.36781197786331177, Validation loss: 0.36931291222572327
Epoch: 97/300 - Train loss: 0.3661235272884369, Validation loss: 0.3679795265197754
Epoch: 98/300 - Train loss: 0.36447447538375854, Validation loss: 0.3665296137332916
Epoch: 99/300 - Train loss: 0.3628637194633484, Validation loss: 0.364607572555542
Epoch: 100/300 - Train loss: 0.36129000782966614, Validation loss: 0.362886518239975
Epoch: 101/300 - Train loss: 0.3597516715526581, Validation loss: 0.3616451323032379
Epoch: 102/300 - Train loss: 0.35824742913246155, Validation loss: 0.35987186431884766
Epoch: 103/300 - Train loss: 0.35677605867385864, Validation loss: 0.35851138830184937
Epoch: 104/300 - Train loss: 0.35533663630485535, Validation loss: 0.3564945459365845
Epoch: 105/300 - Train loss: 0.3539280593395233, Validation loss: 0.3557681441307068
Epoch: 106/300 - Train loss: 0.3525489568710327, Validation loss: 0.35454121232032776
Epoch: 107/300 - Train loss: 0.351198673248291, Validation loss: 0.3533644676208496
Epoch: 108/300 - Train loss: 0.34987637400627136, Validation loss: 0.35221198201179504
Epoch: 109/300 - Train loss: 0.348580926656723, Validation loss: 0.3510180115699768
Epoch: 110/300 - Train loss: 0.3473110496997833, Validation loss: 0.3495255410671234
Epoch: 111/300 - Train loss: 0.3460662364959717, Validation loss: 0.3487083315849304
Epoch: 112/300 - Train loss: 0.34484589099884033, Validation loss: 0.3469884991645813
Epoch: 113/300 - Train loss: 0.34364885091781616, Validation loss: 0.34590139985084534
Epoch: 114/300 - Train loss: 0.34247446060180664, Validation loss: 0.3447823226451874
Epoch: 115/300 - Train loss: 0.34132176637649536, Validation loss: 0.3436921238899231
Epoch: 116/300 - Train loss: 0.34018951654434204, Validation loss: 0.34269979596138
Epoch: 117/300 - Train loss: 0.3390781879425049, Validation loss: 0.34164777398109436
Epoch: 118/300 - Train loss: 0.33798664808273315, Validation loss: 0.3404409885406494
Epoch: 119/300 - Train loss: 0.33691471815109253, Validation loss: 0.3398790657520294
Epoch: 120/300 - Train loss: 0.3358614444732666, Validation loss: 0.33860859274864197
Epoch: 121/300 - Train loss: 0.3348264694213867, Validation loss: 0.3377637267112732
Epoch: 122/300 - Train loss: 0.3338092565536499, Validation loss: 0.3366895616054535
Epoch: 123/300 - Train loss: 0.33280912041664124, Validation loss: 0.33621981739997864
Epoch: 124/300 - Train loss: 0.3318253457546234, Validation loss: 0.3343428075313568
Epoch: 125/300 - Train loss: 0.3308568596839905, Validation loss: 0.33423417806625366
Epoch: 126/300 - Train loss: 0.3299034535884857, Validation loss: 0.3336973190307617
Epoch: 127/300 - Train loss: 0.32896506786346436, Validation loss: 0.3321687877178192
Epoch: 128/300 - Train loss: 0.3280409574508667, Validation loss: 0.330735981464386
Epoch: 129/300 - Train loss: 0.3271302282810211, Validation loss: 0.33005639910697937
Epoch: 130/300 - Train loss: 0.3262322247028351, Validation loss: 0.32934197783470154
Epoch: 131/300 - Train loss: 0.32534608244895935, Validation loss: 0.32865476608276367
Epoch: 132/300 - Train loss: 0.3244721591472626, Validation loss: 0.32747888565063477
Epoch: 133/300 - Train loss: 0.3236108124256134, Validation loss: 0.32675597071647644
Epoch: 134/300 - Train loss: 0.3227613866329193, Validation loss: 0.32544562220573425
Epoch: 135/300 - Train loss: 0.32192400097846985, Validation loss: 0.3252929747104645
Epoch: 136/300 - Train loss: 0.3210987150669098, Validation loss: 0.32487690448760986
Epoch: 137/300 - Train loss: 0.3202846646308899, Validation loss: 0.3235671818256378
Epoch: 138/300 - Train loss: 0.3194822371006012, Validation loss: 0.32308900356292725
Epoch: 139/300 - Train loss: 0.31869032979011536, Validation loss: 0.32241585850715637
Epoch: 140/300 - Train loss: 0.3179100453853607, Validation loss: 0.32085612416267395
Epoch: 141/300 - Train loss: 0.3171409070491791, Validation loss: 0.3202438950538635
Epoch: 142/300 - Train loss: 0.3163819909095764, Validation loss: 0.32054591178894043
Epoch: 143/300 - Train loss: 0.31563326716423035, Validation loss: 0.3190487027168274
Epoch: 144/300 - Train loss: 0.3148939311504364, Validation loss: 0.3185727596282959
Epoch: 145/300 - Train loss: 0.31416431069374084, Validation loss: 0.31786927580833435
Epoch: 146/300 - Train loss: 0.31344467401504517, Validation loss: 0.3172298073768616
Epoch: 147/300 - Train loss: 0.31273484230041504, Validation loss: 0.31691044569015503
Epoch: 148/300 - Train loss: 0.31203436851501465, Validation loss: 0.3158259987831116
Epoch: 149/300 - Train loss: 0.31134268641471863, Validation loss: 0.31557217240333557
Epoch: 150/300 - Train loss: 0.31066012382507324, Validation loss: 0.31462734937667847
Epoch: 151/300 - Train loss: 0.3099862039089203, Validation loss: 0.3144429624080658
Epoch: 152/300 - Train loss: 0.30932000279426575, Validation loss: 0.31364312767982483
Epoch: 153/300 - Train loss: 0.3086613714694977, Validation loss: 0.31317397952079773
Epoch: 154/300 - Train loss: 0.30801108479499817, Validation loss: 0.3119696378707886
Epoch: 155/300 - Train loss: 0.30736860632896423, Validation loss: 0.31110066175460815
Epoch: 156/300 - Train loss: 0.3067338764667511, Validation loss: 0.3109826445579529
Epoch: 157/300 - Train loss: 0.30610665678977966, Validation loss: 0.31058329343795776
Epoch: 158/300 - Train loss: 0.3054874539375305, Validation loss: 0.30971041321754456
Epoch: 159/300 - Train loss: 0.3048759996891022, Validation loss: 0.3087998330593109
Epoch: 160/300 - Train loss: 0.3042716979980469, Validation loss: 0.30920034646987915
Epoch: 161/300 - Train loss: 0.30367499589920044, Validation loss: 0.30807697772979736
Epoch: 162/300 - Train loss: 0.303085595369339, Validation loss: 0.30691438913345337
Epoch: 163/300 - Train loss: 0.3025031089782715, Validation loss: 0.3072185218334198
Epoch: 164/300 - Train loss: 0.3019275367259979, Validation loss: 0.3059115409851074
Epoch: 165/300 - Train loss: 0.3013584613800049, Validation loss: 0.3056178390979767
Epoch: 166/300 - Train loss: 0.3007960021495819, Validation loss: 0.3053508996963501
Epoch: 167/300 - Train loss: 0.30024027824401855, Validation loss: 0.30442729592323303
Epoch: 168/300 - Train loss: 0.29969123005867004, Validation loss: 0.3038182854652405
Epoch: 169/300 - Train loss: 0.29914960265159607, Validation loss: 0.303355872631073
Epoch: 170/300 - Train loss: 0.2986147105693817, Validation loss: 0.30298393964767456
Epoch: 171/300 - Train loss: 0.2980872392654419, Validation loss: 0.3026044964790344
