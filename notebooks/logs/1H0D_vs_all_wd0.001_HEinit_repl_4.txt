Epoch: 1/300 - Train loss: 0.7020440697669983, Validation loss: 0.699992835521698
Epoch: 2/300 - Train loss: 0.7001695036888123, Validation loss: 0.6982679963111877
Epoch: 3/300 - Train loss: 0.6983312964439392, Validation loss: 0.6965093016624451
Epoch: 4/300 - Train loss: 0.6965232491493225, Validation loss: 0.6948848962783813
Epoch: 5/300 - Train loss: 0.6947364211082458, Validation loss: 0.693136990070343
Epoch: 6/300 - Train loss: 0.6929605603218079, Validation loss: 0.6914305686950684
Epoch: 7/300 - Train loss: 0.6911844611167908, Validation loss: 0.689737856388092
Epoch: 8/300 - Train loss: 0.6893971562385559, Validation loss: 0.6880163550376892
Epoch: 9/300 - Train loss: 0.6875845789909363, Validation loss: 0.6862019300460815
Epoch: 10/300 - Train loss: 0.6857349872589111, Validation loss: 0.6844196319580078
Epoch: 11/300 - Train loss: 0.6838406324386597, Validation loss: 0.6825547814369202
Epoch: 12/300 - Train loss: 0.6818934679031372, Validation loss: 0.6806153059005737
Epoch: 13/300 - Train loss: 0.679882824420929, Validation loss: 0.6786246299743652
Epoch: 14/300 - Train loss: 0.6778005957603455, Validation loss: 0.6765592098236084
Epoch: 15/300 - Train loss: 0.6756375432014465, Validation loss: 0.6743353009223938
Epoch: 16/300 - Train loss: 0.6733888387680054, Validation loss: 0.6721290946006775
Epoch: 17/300 - Train loss: 0.6710485816001892, Validation loss: 0.6697352528572083
Epoch: 18/300 - Train loss: 0.6686119437217712, Validation loss: 0.667327880859375
Epoch: 19/300 - Train loss: 0.6660759449005127, Validation loss: 0.6647685766220093
Epoch: 20/300 - Train loss: 0.6634398698806763, Validation loss: 0.6621246933937073
Epoch: 21/300 - Train loss: 0.660702109336853, Validation loss: 0.6593286395072937
Epoch: 22/300 - Train loss: 0.6578561067581177, Validation loss: 0.6564982533454895
Epoch: 23/300 - Train loss: 0.6549007296562195, Validation loss: 0.6534197926521301
Epoch: 24/300 - Train loss: 0.651836633682251, Validation loss: 0.6503787040710449
Epoch: 25/300 - Train loss: 0.6486620306968689, Validation loss: 0.6472890377044678
Epoch: 26/300 - Train loss: 0.6453768610954285, Validation loss: 0.6438741087913513
Epoch: 27/300 - Train loss: 0.6419849991798401, Validation loss: 0.6404972076416016
Epoch: 28/300 - Train loss: 0.6384895443916321, Validation loss: 0.6369528770446777
Epoch: 29/300 - Train loss: 0.6348929405212402, Validation loss: 0.6335262656211853
Epoch: 30/300 - Train loss: 0.631198525428772, Validation loss: 0.6297088861465454
Epoch: 31/300 - Train loss: 0.6274043917655945, Validation loss: 0.6258963942527771
Epoch: 32/300 - Train loss: 0.6235182881355286, Validation loss: 0.6219907402992249
Epoch: 33/300 - Train loss: 0.6195427179336548, Validation loss: 0.6179836392402649
Epoch: 34/300 - Train loss: 0.6154776811599731, Validation loss: 0.6139711737632751
Epoch: 35/300 - Train loss: 0.6113296747207642, Validation loss: 0.6096871495246887
Epoch: 36/300 - Train loss: 0.607103168964386, Validation loss: 0.6056079268455505
Epoch: 37/300 - Train loss: 0.6028021574020386, Validation loss: 0.6013805270195007
Epoch: 38/300 - Train loss: 0.5984305739402771, Validation loss: 0.5969157814979553
Epoch: 39/300 - Train loss: 0.5939952731132507, Validation loss: 0.5925769209861755
Epoch: 40/300 - Train loss: 0.5894989371299744, Validation loss: 0.5879688858985901
Epoch: 41/300 - Train loss: 0.5849493741989136, Validation loss: 0.5836403369903564
Epoch: 42/300 - Train loss: 0.5803534388542175, Validation loss: 0.5788314938545227
Epoch: 43/300 - Train loss: 0.5757169127464294, Validation loss: 0.5741848945617676
Epoch: 44/300 - Train loss: 0.5710480809211731, Validation loss: 0.5696983337402344
Epoch: 45/300 - Train loss: 0.5663531422615051, Validation loss: 0.565354585647583
Epoch: 46/300 - Train loss: 0.5616362690925598, Validation loss: 0.5605599284172058
Epoch: 47/300 - Train loss: 0.5569064617156982, Validation loss: 0.555658757686615
Epoch: 48/300 - Train loss: 0.5521690249443054, Validation loss: 0.5511648654937744
Epoch: 49/300 - Train loss: 0.5474305748939514, Validation loss: 0.5462802052497864
Epoch: 50/300 - Train loss: 0.5426981449127197, Validation loss: 0.5417993664741516
Epoch: 51/300 - Train loss: 0.5379785895347595, Validation loss: 0.5370252132415771
Epoch: 52/300 - Train loss: 0.5332795977592468, Validation loss: 0.5325404405593872
Epoch: 53/300 - Train loss: 0.5286072492599487, Validation loss: 0.5276491045951843
Epoch: 54/300 - Train loss: 0.5239657759666443, Validation loss: 0.5233561396598816
Epoch: 55/300 - Train loss: 0.5193608403205872, Validation loss: 0.5187562108039856
Epoch: 56/300 - Train loss: 0.5147995948791504, Validation loss: 0.5143522620201111
Epoch: 57/300 - Train loss: 0.5102890729904175, Validation loss: 0.5100985765457153
Epoch: 58/300 - Train loss: 0.5058336853981018, Validation loss: 0.5056766271591187
Epoch: 59/300 - Train loss: 0.5014361143112183, Validation loss: 0.5012375116348267
Epoch: 60/300 - Train loss: 0.49710172414779663, Validation loss: 0.4973050653934479
Epoch: 61/300 - Train loss: 0.49283352494239807, Validation loss: 0.4928170442581177
Epoch: 62/300 - Train loss: 0.4886348843574524, Validation loss: 0.48903292417526245
Epoch: 63/300 - Train loss: 0.4845088720321655, Validation loss: 0.48488301038742065
Epoch: 64/300 - Train loss: 0.48045864701271057, Validation loss: 0.48095741868019104
Epoch: 65/300 - Train loss: 0.47648584842681885, Validation loss: 0.4770754873752594
Epoch: 66/300 - Train loss: 0.4725915193557739, Validation loss: 0.4737839698791504
Epoch: 67/300 - Train loss: 0.4687783420085907, Validation loss: 0.4696095883846283
Epoch: 68/300 - Train loss: 0.4650487005710602, Validation loss: 0.46608346700668335
Epoch: 69/300 - Train loss: 0.4614037275314331, Validation loss: 0.46297433972358704
Epoch: 70/300 - Train loss: 0.4578440189361572, Validation loss: 0.45906904339790344
Epoch: 71/300 - Train loss: 0.45436960458755493, Validation loss: 0.4556196331977844
Epoch: 72/300 - Train loss: 0.450981080532074, Validation loss: 0.4524346590042114
Epoch: 73/300 - Train loss: 0.4476788640022278, Validation loss: 0.4490728974342346
Epoch: 74/300 - Train loss: 0.44446295499801636, Validation loss: 0.446044921875
Epoch: 75/300 - Train loss: 0.4413333535194397, Validation loss: 0.442913681268692
Epoch: 76/300 - Train loss: 0.43828898668289185, Validation loss: 0.44028347730636597
Epoch: 77/300 - Train loss: 0.43532952666282654, Validation loss: 0.4376268982887268
Epoch: 78/300 - Train loss: 0.43245404958724976, Validation loss: 0.43511152267456055
Epoch: 79/300 - Train loss: 0.42966094613075256, Validation loss: 0.432324081659317
Epoch: 80/300 - Train loss: 0.4269489645957947, Validation loss: 0.4295768141746521
Epoch: 81/300 - Train loss: 0.424316942691803, Validation loss: 0.4272769093513489
Epoch: 82/300 - Train loss: 0.42176368832588196, Validation loss: 0.4245462417602539
Epoch: 83/300 - Train loss: 0.41928744316101074, Validation loss: 0.42235857248306274
Epoch: 84/300 - Train loss: 0.41688671708106995, Validation loss: 0.4198608994483948
Epoch: 85/300 - Train loss: 0.4145599901676178, Validation loss: 0.4176443815231323
Epoch: 86/300 - Train loss: 0.4123053550720215, Validation loss: 0.41529184579849243
Epoch: 87/300 - Train loss: 0.4101204574108124, Validation loss: 0.4136863350868225
Epoch: 88/300 - Train loss: 0.4080038070678711, Validation loss: 0.4112733006477356
Epoch: 89/300 - Train loss: 0.405953586101532, Validation loss: 0.4093363881111145
Epoch: 90/300 - Train loss: 0.4039679169654846, Validation loss: 0.40775352716445923
Epoch: 91/300 - Train loss: 0.40204498171806335, Validation loss: 0.4054652154445648
Epoch: 92/300 - Train loss: 0.4001832902431488, Validation loss: 0.4041445553302765
Epoch: 93/300 - Train loss: 0.39838069677352905, Validation loss: 0.4021921157836914
Epoch: 94/300 - Train loss: 0.396635502576828, Validation loss: 0.4009263217449188
Epoch: 95/300 - Train loss: 0.3949458599090576, Validation loss: 0.3994196653366089
Epoch: 96/300 - Train loss: 0.39330998063087463, Validation loss: 0.39796680212020874
Epoch: 97/300 - Train loss: 0.39172613620758057, Validation loss: 0.39604195952415466
Epoch: 98/300 - Train loss: 0.39019259810447693, Validation loss: 0.39430922269821167
Epoch: 99/300 - Train loss: 0.38870733976364136, Validation loss: 0.3935914933681488
Epoch: 100/300 - Train loss: 0.3872687518596649, Validation loss: 0.39180782437324524
Epoch: 101/300 - Train loss: 0.38587528467178345, Validation loss: 0.3896635174751282
Epoch: 102/300 - Train loss: 0.3845250904560089, Validation loss: 0.3894783556461334
Epoch: 103/300 - Train loss: 0.3832167387008667, Validation loss: 0.3876989483833313
Epoch: 104/300 - Train loss: 0.3819486200809479, Validation loss: 0.3865944743156433
Epoch: 105/300 - Train loss: 0.3807193636894226, Validation loss: 0.38509559631347656
Epoch: 106/300 - Train loss: 0.3795275390148163, Validation loss: 0.38388434052467346
Epoch: 107/300 - Train loss: 0.3783716857433319, Validation loss: 0.3826994001865387
Epoch: 108/300 - Train loss: 0.3772505521774292, Validation loss: 0.38177061080932617
Epoch: 109/300 - Train loss: 0.37616273760795593, Validation loss: 0.3812252879142761
Epoch: 110/300 - Train loss: 0.3751068711280823, Validation loss: 0.37971800565719604
Epoch: 111/300 - Train loss: 0.37408196926116943, Validation loss: 0.37940922379493713
Epoch: 112/300 - Train loss: 0.3730868101119995, Validation loss: 0.37767958641052246
Epoch: 113/300 - Train loss: 0.3721202313899994, Validation loss: 0.37769070267677307
Epoch: 114/300 - Train loss: 0.3711809515953064, Validation loss: 0.3765600323677063
Epoch: 115/300 - Train loss: 0.3702680766582489, Validation loss: 0.37563556432724
Epoch: 116/300 - Train loss: 0.36938053369522095, Validation loss: 0.37452229857444763
Epoch: 117/300 - Train loss: 0.36851751804351807, Validation loss: 0.37383681535720825
Epoch: 118/300 - Train loss: 0.3676779270172119, Validation loss: 0.37234795093536377
Epoch: 119/300 - Train loss: 0.3668609857559204, Validation loss: 0.37221559882164
Epoch: 120/300 - Train loss: 0.36606571078300476, Validation loss: 0.37084537744522095
Epoch: 121/300 - Train loss: 0.3652914762496948, Validation loss: 0.3706125319004059
Epoch: 122/300 - Train loss: 0.3645373582839966, Validation loss: 0.36965835094451904
Epoch: 123/300 - Train loss: 0.36380264163017273, Validation loss: 0.36874327063560486
Epoch: 124/300 - Train loss: 0.3630865514278412, Validation loss: 0.3680606186389923
Epoch: 125/300 - Train loss: 0.3623884916305542, Validation loss: 0.3671802878379822
Epoch: 126/300 - Train loss: 0.3617076277732849, Validation loss: 0.366921067237854
Epoch: 127/300 - Train loss: 0.3610433042049408, Validation loss: 0.3656565845012665
Epoch: 128/300 - Train loss: 0.36039498448371887, Validation loss: 0.365343302488327
Epoch: 129/300 - Train loss: 0.3597621023654938, Validation loss: 0.3650152385234833
Epoch: 130/300 - Train loss: 0.35914406180381775, Validation loss: 0.3644087314605713
Epoch: 131/300 - Train loss: 0.3585406541824341, Validation loss: 0.36389729380607605
Epoch: 132/300 - Train loss: 0.3579511344432831, Validation loss: 0.3627651631832123
Epoch: 133/300 - Train loss: 0.35737499594688416, Validation loss: 0.36202841997146606
Epoch: 134/300 - Train loss: 0.3568118214607239, Validation loss: 0.36163392663002014
Epoch: 135/300 - Train loss: 0.3562612235546112, Validation loss: 0.3613293468952179
Epoch: 136/300 - Train loss: 0.35572269558906555, Validation loss: 0.36049893498420715
Epoch: 137/300 - Train loss: 0.35519587993621826, Validation loss: 0.36041927337646484
