Epoch: 1/300 - Train loss: 0.7113236784934998, Validation loss: 0.711249828338623
Epoch: 2/300 - Train loss: 0.7088527083396912, Validation loss: 0.7088512778282166
Epoch: 3/300 - Train loss: 0.7064558863639832, Validation loss: 0.706365704536438
Epoch: 4/300 - Train loss: 0.7041206359863281, Validation loss: 0.704155683517456
Epoch: 5/300 - Train loss: 0.7018305063247681, Validation loss: 0.702155590057373
Epoch: 6/300 - Train loss: 0.699577808380127, Validation loss: 0.6999602317810059
Epoch: 7/300 - Train loss: 0.6973484754562378, Validation loss: 0.6975204348564148
Epoch: 8/300 - Train loss: 0.6951245069503784, Validation loss: 0.6951304078102112
Epoch: 9/300 - Train loss: 0.6928877830505371, Validation loss: 0.6930763721466064
Epoch: 10/300 - Train loss: 0.69062739610672, Validation loss: 0.6908217668533325
Epoch: 11/300 - Train loss: 0.6883297562599182, Validation loss: 0.6884734034538269
Epoch: 12/300 - Train loss: 0.6859813928604126, Validation loss: 0.6861138939857483
Epoch: 13/300 - Train loss: 0.683571994304657, Validation loss: 0.6835910081863403
Epoch: 14/300 - Train loss: 0.6810947060585022, Validation loss: 0.6809154152870178
Epoch: 15/300 - Train loss: 0.67854243516922, Validation loss: 0.6782181262969971
Epoch: 16/300 - Train loss: 0.6759089827537537, Validation loss: 0.6756078004837036
Epoch: 17/300 - Train loss: 0.6731896996498108, Validation loss: 0.6727168560028076
Epoch: 18/300 - Train loss: 0.670376181602478, Validation loss: 0.6697665452957153
Epoch: 19/300 - Train loss: 0.667465090751648, Validation loss: 0.6668451428413391
Epoch: 20/300 - Train loss: 0.6644517779350281, Validation loss: 0.6637054085731506
Epoch: 21/300 - Train loss: 0.6613330245018005, Validation loss: 0.6602129936218262
Epoch: 22/300 - Train loss: 0.6581079959869385, Validation loss: 0.6570568084716797
Epoch: 23/300 - Train loss: 0.65477454662323, Validation loss: 0.6537750363349915
Epoch: 24/300 - Train loss: 0.6513280272483826, Validation loss: 0.6501203775405884
Epoch: 25/300 - Train loss: 0.6477681994438171, Validation loss: 0.6464026570320129
Epoch: 26/300 - Train loss: 0.6440926194190979, Validation loss: 0.6427733302116394
Epoch: 27/300 - Train loss: 0.640299379825592, Validation loss: 0.6387749910354614
Epoch: 28/300 - Train loss: 0.6363847255706787, Validation loss: 0.6347820162773132
Epoch: 29/300 - Train loss: 0.6323559284210205, Validation loss: 0.6308442950248718
Epoch: 30/300 - Train loss: 0.6282171607017517, Validation loss: 0.6264732480049133
Epoch: 31/300 - Train loss: 0.6239640712738037, Validation loss: 0.6223021149635315
Epoch: 32/300 - Train loss: 0.6195977926254272, Validation loss: 0.6176992654800415
Epoch: 33/300 - Train loss: 0.6151271462440491, Validation loss: 0.6133050322532654
Epoch: 34/300 - Train loss: 0.6105576157569885, Validation loss: 0.60859215259552
Epoch: 35/300 - Train loss: 0.6058903932571411, Validation loss: 0.6041011810302734
Epoch: 36/300 - Train loss: 0.6011328101158142, Validation loss: 0.5990594625473022
Epoch: 37/300 - Train loss: 0.5962867140769958, Validation loss: 0.5944610834121704
Epoch: 38/300 - Train loss: 0.5913679599761963, Validation loss: 0.5895122289657593
Epoch: 39/300 - Train loss: 0.5863815546035767, Validation loss: 0.5846186280250549
Epoch: 40/300 - Train loss: 0.5813342928886414, Validation loss: 0.5794968605041504
Epoch: 41/300 - Train loss: 0.5762383937835693, Validation loss: 0.5744640827178955
Epoch: 42/300 - Train loss: 0.5711037516593933, Validation loss: 0.5691947937011719
Epoch: 43/300 - Train loss: 0.5659357905387878, Validation loss: 0.5639634132385254
Epoch: 44/300 - Train loss: 0.5607407093048096, Validation loss: 0.5589252710342407
Epoch: 45/300 - Train loss: 0.5555290579795837, Validation loss: 0.5535522103309631
Epoch: 46/300 - Train loss: 0.5503106117248535, Validation loss: 0.5486303567886353
Epoch: 47/300 - Train loss: 0.5450925230979919, Validation loss: 0.5435400009155273
Epoch: 48/300 - Train loss: 0.5398769974708557, Validation loss: 0.538031816482544
Epoch: 49/300 - Train loss: 0.5346715450286865, Validation loss: 0.5331315994262695
Epoch: 50/300 - Train loss: 0.5294833779335022, Validation loss: 0.5276941061019897
Epoch: 51/300 - Train loss: 0.5243203639984131, Validation loss: 0.5228105783462524
Epoch: 52/300 - Train loss: 0.5191848278045654, Validation loss: 0.5180067420005798
Epoch: 53/300 - Train loss: 0.5140803456306458, Validation loss: 0.5127021074295044
Epoch: 54/300 - Train loss: 0.5090171098709106, Validation loss: 0.507968008518219
Epoch: 55/300 - Train loss: 0.503996729850769, Validation loss: 0.5028302073478699
Epoch: 56/300 - Train loss: 0.49902045726776123, Validation loss: 0.4977448582649231
Epoch: 57/300 - Train loss: 0.49409669637680054, Validation loss: 0.49282804131507874
Epoch: 58/300 - Train loss: 0.4892289936542511, Validation loss: 0.4882811903953552
Epoch: 59/300 - Train loss: 0.48442530632019043, Validation loss: 0.4833349287509918
Epoch: 60/300 - Train loss: 0.4796893000602722, Validation loss: 0.47852253913879395
Epoch: 61/300 - Train loss: 0.475026398897171, Validation loss: 0.47412431240081787
Epoch: 62/300 - Train loss: 0.47043827176094055, Validation loss: 0.46943509578704834
Epoch: 63/300 - Train loss: 0.4659337103366852, Validation loss: 0.4652568995952606
Epoch: 64/300 - Train loss: 0.4615221619606018, Validation loss: 0.46103963255882263
Epoch: 65/300 - Train loss: 0.45720717310905457, Validation loss: 0.4566707909107208
Epoch: 66/300 - Train loss: 0.45299074053764343, Validation loss: 0.4530627429485321
Epoch: 67/300 - Train loss: 0.4488754868507385, Validation loss: 0.4480423033237457
Epoch: 68/300 - Train loss: 0.44486409425735474, Validation loss: 0.4444425106048584
Epoch: 69/300 - Train loss: 0.4409600794315338, Validation loss: 0.44048500061035156
Epoch: 70/300 - Train loss: 0.437162846326828, Validation loss: 0.43659454584121704
Epoch: 71/300 - Train loss: 0.43347081542015076, Validation loss: 0.43293702602386475
Epoch: 72/300 - Train loss: 0.4298827052116394, Validation loss: 0.42993345856666565
Epoch: 73/300 - Train loss: 0.4263963997364044, Validation loss: 0.4262828528881073
Epoch: 74/300 - Train loss: 0.4230116605758667, Validation loss: 0.4231683313846588
Epoch: 75/300 - Train loss: 0.41972434520721436, Validation loss: 0.4192201793193817
Epoch: 76/300 - Train loss: 0.4165332317352295, Validation loss: 0.41680067777633667
Epoch: 77/300 - Train loss: 0.41343578696250916, Validation loss: 0.4136357009410858
Epoch: 78/300 - Train loss: 0.41042855381965637, Validation loss: 0.41036325693130493
Epoch: 79/300 - Train loss: 0.4075092077255249, Validation loss: 0.4078211188316345
Epoch: 80/300 - Train loss: 0.4046751856803894, Validation loss: 0.40485265851020813
Epoch: 81/300 - Train loss: 0.40192291140556335, Validation loss: 0.4019090235233307
Epoch: 82/300 - Train loss: 0.3992498815059662, Validation loss: 0.3995038568973541
Epoch: 83/300 - Train loss: 0.3966537117958069, Validation loss: 0.39688971638679504
Epoch: 84/300 - Train loss: 0.39413145184516907, Validation loss: 0.39431339502334595
Epoch: 85/300 - Train loss: 0.3916809558868408, Validation loss: 0.39164212346076965
Epoch: 86/300 - Train loss: 0.38930004835128784, Validation loss: 0.3895529806613922
Epoch: 87/300 - Train loss: 0.3869856297969818, Validation loss: 0.38754892349243164
Epoch: 88/300 - Train loss: 0.38473594188690186, Validation loss: 0.38566190004348755
Epoch: 89/300 - Train loss: 0.382548451423645, Validation loss: 0.38304707407951355
Epoch: 90/300 - Train loss: 0.38042107224464417, Validation loss: 0.38109469413757324
Epoch: 91/300 - Train loss: 0.37835168838500977, Validation loss: 0.379216730594635
Epoch: 92/300 - Train loss: 0.37633776664733887, Validation loss: 0.37766700983047485
Epoch: 93/300 - Train loss: 0.3743771016597748, Validation loss: 0.37480875849723816
Epoch: 94/300 - Train loss: 0.37246787548065186, Validation loss: 0.37263035774230957
Epoch: 95/300 - Train loss: 0.3706078827381134, Validation loss: 0.3726167678833008
Epoch: 96/300 - Train loss: 0.3687957227230072, Validation loss: 0.3698165714740753
Epoch: 97/300 - Train loss: 0.36702924966812134, Validation loss: 0.3678000271320343
Epoch: 98/300 - Train loss: 0.36530664563179016, Validation loss: 0.36628246307373047
Epoch: 99/300 - Train loss: 0.3636268377304077, Validation loss: 0.3647094964981079
Epoch: 100/300 - Train loss: 0.3619883358478546, Validation loss: 0.3628608286380768
Epoch: 101/300 - Train loss: 0.3603893518447876, Validation loss: 0.3616679906845093
Epoch: 102/300 - Train loss: 0.358828067779541, Validation loss: 0.35981032252311707
Epoch: 103/300 - Train loss: 0.3573034107685089, Validation loss: 0.3581412136554718
Epoch: 104/300 - Train loss: 0.3558136522769928, Validation loss: 0.35715430974960327
Epoch: 105/300 - Train loss: 0.35435763001441956, Validation loss: 0.3557678759098053
Epoch: 106/300 - Train loss: 0.3529340326786041, Validation loss: 0.3544712960720062
Epoch: 107/300 - Train loss: 0.3515416383743286, Validation loss: 0.353258341550827
Epoch: 108/300 - Train loss: 0.3501798212528229, Validation loss: 0.3518068790435791
Epoch: 109/300 - Train loss: 0.3488474488258362, Validation loss: 0.3506420850753784
Epoch: 110/300 - Train loss: 0.3475433886051178, Validation loss: 0.3489011228084564
Epoch: 111/300 - Train loss: 0.34626686573028564, Validation loss: 0.3484897017478943
Epoch: 112/300 - Train loss: 0.3450168967247009, Validation loss: 0.3466266989707947
Epoch: 113/300 - Train loss: 0.3437924385070801, Validation loss: 0.3450821042060852
Epoch: 114/300 - Train loss: 0.34259268641471863, Validation loss: 0.3445683717727661
Epoch: 115/300 - Train loss: 0.34141743183135986, Validation loss: 0.343456506729126
Epoch: 116/300 - Train loss: 0.3402656018733978, Validation loss: 0.342389851808548
Epoch: 117/300 - Train loss: 0.3391364514827728, Validation loss: 0.34129732847213745
Epoch: 118/300 - Train loss: 0.33802899718284607, Validation loss: 0.3403482139110565
Epoch: 119/300 - Train loss: 0.336942583322525, Validation loss: 0.33867397904396057
Epoch: 120/300 - Train loss: 0.33587655425071716, Validation loss: 0.33742937445640564
Epoch: 121/300 - Train loss: 0.33482980728149414, Validation loss: 0.33720189332962036
Epoch: 122/300 - Train loss: 0.33380189538002014, Validation loss: 0.3352343440055847
Epoch: 123/300 - Train loss: 0.3327922523021698, Validation loss: 0.3352043330669403
Epoch: 124/300 - Train loss: 0.33180010318756104, Validation loss: 0.33463552594184875
Epoch: 125/300 - Train loss: 0.3308251202106476, Validation loss: 0.3332262933254242
Epoch: 126/300 - Train loss: 0.32986608147621155, Validation loss: 0.33121541142463684
Epoch: 127/300 - Train loss: 0.3289225995540619, Validation loss: 0.3308318853378296
Epoch: 128/300 - Train loss: 0.3279942572116852, Validation loss: 0.3305298089981079
Epoch: 129/300 - Train loss: 0.3270799517631531, Validation loss: 0.3297373056411743
Epoch: 130/300 - Train loss: 0.3261803388595581, Validation loss: 0.32878878712654114
Epoch: 131/300 - Train loss: 0.32529547810554504, Validation loss: 0.3278234004974365
Epoch: 132/300 - Train loss: 0.3244244158267975, Validation loss: 0.3274267315864563
Epoch: 133/300 - Train loss: 0.32356685400009155, Validation loss: 0.32618704438209534
Epoch: 134/300 - Train loss: 0.3227223753929138, Validation loss: 0.32533860206604004
Epoch: 135/300 - Train loss: 0.3218908905982971, Validation loss: 0.32365936040878296
Epoch: 136/300 - Train loss: 0.3210708796977997, Validation loss: 0.32364845275878906
Epoch: 137/300 - Train loss: 0.3202623724937439, Validation loss: 0.3230820596218109
Epoch: 138/300 - Train loss: 0.3194652497768402, Validation loss: 0.32221922278404236
Epoch: 139/300 - Train loss: 0.31867945194244385, Validation loss: 0.32110777497291565
Epoch: 140/300 - Train loss: 0.3179056644439697, Validation loss: 0.32067304849624634
Epoch: 141/300 - Train loss: 0.3171425759792328, Validation loss: 0.3194037079811096
Epoch: 142/300 - Train loss: 0.316389799118042, Validation loss: 0.31920573115348816
Epoch: 143/300 - Train loss: 0.31564781069755554, Validation loss: 0.3181256353855133
Epoch: 144/300 - Train loss: 0.3149159252643585, Validation loss: 0.3173955976963043
Epoch: 145/300 - Train loss: 0.31419384479522705, Validation loss: 0.317242830991745
Epoch: 146/300 - Train loss: 0.31348124146461487, Validation loss: 0.3161371648311615
Epoch: 147/300 - Train loss: 0.3127779960632324, Validation loss: 0.3156298100948334
Epoch: 148/300 - Train loss: 0.31208381056785583, Validation loss: 0.3147105574607849
Epoch: 149/300 - Train loss: 0.31139904260635376, Validation loss: 0.31461405754089355
Epoch: 150/300 - Train loss: 0.31072327494621277, Validation loss: 0.3134934604167938
Epoch: 151/300 - Train loss: 0.3100567162036896, Validation loss: 0.313056617975235
Epoch: 152/300 - Train loss: 0.30939844250679016, Validation loss: 0.3129631280899048
Epoch: 153/300 - Train loss: 0.30874812602996826, Validation loss: 0.31205877661705017
Epoch: 154/300 - Train loss: 0.30810675024986267, Validation loss: 0.3117350935935974
Epoch: 155/300 - Train loss: 0.3074742555618286, Validation loss: 0.31054478883743286
Epoch: 156/300 - Train loss: 0.30684974789619446, Validation loss: 0.30964377522468567
Epoch: 157/300 - Train loss: 0.30623331665992737, Validation loss: 0.3088940680027008
Epoch: 158/300 - Train loss: 0.30562466382980347, Validation loss: 0.30918174982070923
Epoch: 159/300 - Train loss: 0.30502378940582275, Validation loss: 0.3080347776412964
Epoch: 160/300 - Train loss: 0.30443015694618225, Validation loss: 0.30727583169937134
Epoch: 161/300 - Train loss: 0.30384376645088196, Validation loss: 0.30687442421913147
Epoch: 162/300 - Train loss: 0.3032643795013428, Validation loss: 0.30720221996307373
Epoch: 163/300 - Train loss: 0.3026922047138214, Validation loss: 0.3068698048591614
