Epoch: 1/300 - Train loss: 0.697249174118042, Validation loss: 0.6966177821159363
Epoch: 2/300 - Train loss: 0.6946911215782166, Validation loss: 0.6940377354621887
Epoch: 3/300 - Train loss: 0.6921758055686951, Validation loss: 0.6914641261100769
Epoch: 4/300 - Train loss: 0.6896926760673523, Validation loss: 0.68910151720047
Epoch: 5/300 - Train loss: 0.6872243881225586, Validation loss: 0.6864248514175415
Epoch: 6/300 - Train loss: 0.6847493648529053, Validation loss: 0.6838830709457397
Epoch: 7/300 - Train loss: 0.6822468042373657, Validation loss: 0.6814016699790955
Epoch: 8/300 - Train loss: 0.6796977519989014, Validation loss: 0.6786381006240845
Epoch: 9/300 - Train loss: 0.6770853996276855, Validation loss: 0.6759778261184692
Epoch: 10/300 - Train loss: 0.6743919253349304, Validation loss: 0.6731730103492737
Epoch: 11/300 - Train loss: 0.6716009378433228, Validation loss: 0.6702673435211182
Epoch: 12/300 - Train loss: 0.6687057018280029, Validation loss: 0.6672999858856201
Epoch: 13/300 - Train loss: 0.6656987071037292, Validation loss: 0.6641358137130737
Epoch: 14/300 - Train loss: 0.6625639796257019, Validation loss: 0.6609396934509277
Epoch: 15/300 - Train loss: 0.6592984199523926, Validation loss: 0.6575477719306946
Epoch: 16/300 - Train loss: 0.6558986902236938, Validation loss: 0.6540659666061401
Epoch: 17/300 - Train loss: 0.6523647308349609, Validation loss: 0.6505690813064575
Epoch: 18/300 - Train loss: 0.6486929059028625, Validation loss: 0.6466675400733948
Epoch: 19/300 - Train loss: 0.6448860168457031, Validation loss: 0.6428208351135254
Epoch: 20/300 - Train loss: 0.6409448981285095, Validation loss: 0.6388255953788757
Epoch: 21/300 - Train loss: 0.6368758082389832, Validation loss: 0.6343850493431091
Epoch: 22/300 - Train loss: 0.6326818466186523, Validation loss: 0.6302661895751953
Epoch: 23/300 - Train loss: 0.6283645033836365, Validation loss: 0.6258576512336731
Epoch: 24/300 - Train loss: 0.6239274740219116, Validation loss: 0.6211989521980286
Epoch: 25/300 - Train loss: 0.6193830966949463, Validation loss: 0.6166929006576538
Epoch: 26/300 - Train loss: 0.614743173122406, Validation loss: 0.6120628118515015
Epoch: 27/300 - Train loss: 0.6100139021873474, Validation loss: 0.6073383092880249
Epoch: 28/300 - Train loss: 0.6052043437957764, Validation loss: 0.6024962663650513
Epoch: 29/300 - Train loss: 0.6003248691558838, Validation loss: 0.5976412296295166
Epoch: 30/300 - Train loss: 0.5953800678253174, Validation loss: 0.5923624038696289
Epoch: 31/300 - Train loss: 0.5903807282447815, Validation loss: 0.5876936316490173
Epoch: 32/300 - Train loss: 0.5853393077850342, Validation loss: 0.5826152563095093
Epoch: 33/300 - Train loss: 0.5802639126777649, Validation loss: 0.5774885416030884
Epoch: 34/300 - Train loss: 0.5751674771308899, Validation loss: 0.5725482702255249
Epoch: 35/300 - Train loss: 0.5700609683990479, Validation loss: 0.5676075220108032
Epoch: 36/300 - Train loss: 0.5649511218070984, Validation loss: 0.5623319149017334
Epoch: 37/300 - Train loss: 0.5598467588424683, Validation loss: 0.5575549006462097
Epoch: 38/300 - Train loss: 0.554753839969635, Validation loss: 0.5524160861968994
Epoch: 39/300 - Train loss: 0.5496789813041687, Validation loss: 0.5471789836883545
Epoch: 40/300 - Train loss: 0.5446308851242065, Validation loss: 0.5423675775527954
Epoch: 41/300 - Train loss: 0.53961580991745, Validation loss: 0.5375550985336304
Epoch: 42/300 - Train loss: 0.5346364378929138, Validation loss: 0.5324466824531555
Epoch: 43/300 - Train loss: 0.5296979546546936, Validation loss: 0.52767014503479
Epoch: 44/300 - Train loss: 0.5248048305511475, Validation loss: 0.5228525400161743
Epoch: 45/300 - Train loss: 0.5199607610702515, Validation loss: 0.5180690884590149
Epoch: 46/300 - Train loss: 0.5151699781417847, Validation loss: 0.5131095051765442
Epoch: 47/300 - Train loss: 0.5104358196258545, Validation loss: 0.5086149573326111
Epoch: 48/300 - Train loss: 0.5057618618011475, Validation loss: 0.5037057995796204
Epoch: 49/300 - Train loss: 0.5011482238769531, Validation loss: 0.4991058111190796
Epoch: 50/300 - Train loss: 0.49659791588783264, Validation loss: 0.4950520098209381
Epoch: 51/300 - Train loss: 0.49211350083351135, Validation loss: 0.4903656244277954
Epoch: 52/300 - Train loss: 0.48769694566726685, Validation loss: 0.48584532737731934
Epoch: 53/300 - Train loss: 0.48334935307502747, Validation loss: 0.48172056674957275
Epoch: 54/300 - Train loss: 0.4790719747543335, Validation loss: 0.4779130220413208
Epoch: 55/300 - Train loss: 0.4748668670654297, Validation loss: 0.4736260175704956
Epoch: 56/300 - Train loss: 0.47073495388031006, Validation loss: 0.4696458876132965
Epoch: 57/300 - Train loss: 0.46667465567588806, Validation loss: 0.46562254428863525
Epoch: 58/300 - Train loss: 0.46268874406814575, Validation loss: 0.46118468046188354
Epoch: 59/300 - Train loss: 0.45877814292907715, Validation loss: 0.45753222703933716
Epoch: 60/300 - Train loss: 0.45494166016578674, Validation loss: 0.4535406231880188
Epoch: 61/300 - Train loss: 0.45117858052253723, Validation loss: 0.4504213333129883
Epoch: 62/300 - Train loss: 0.447487473487854, Validation loss: 0.4467266798019409
Epoch: 63/300 - Train loss: 0.44386664032936096, Validation loss: 0.44332313537597656
Epoch: 64/300 - Train loss: 0.4403154253959656, Validation loss: 0.4394530653953552
Epoch: 65/300 - Train loss: 0.4368349611759186, Validation loss: 0.4359646141529083
Epoch: 66/300 - Train loss: 0.43342432379722595, Validation loss: 0.43280622363090515
Epoch: 67/300 - Train loss: 0.4300839304924011, Validation loss: 0.4296909272670746
Epoch: 68/300 - Train loss: 0.4268125593662262, Validation loss: 0.4261339008808136
Epoch: 69/300 - Train loss: 0.42360684275627136, Validation loss: 0.42287659645080566
Epoch: 70/300 - Train loss: 0.4204687476158142, Validation loss: 0.41991424560546875
Epoch: 71/300 - Train loss: 0.41739803552627563, Validation loss: 0.41695302724838257
Epoch: 72/300 - Train loss: 0.41439688205718994, Validation loss: 0.41366782784461975
Epoch: 73/300 - Train loss: 0.4114668369293213, Validation loss: 0.41153278946876526
Epoch: 74/300 - Train loss: 0.40860846638679504, Validation loss: 0.40826815366744995
Epoch: 75/300 - Train loss: 0.4058201014995575, Validation loss: 0.40510794520378113
Epoch: 76/300 - Train loss: 0.40309977531433105, Validation loss: 0.4034670293331146
Epoch: 77/300 - Train loss: 0.40044665336608887, Validation loss: 0.4002966582775116
Epoch: 78/300 - Train loss: 0.39785823225975037, Validation loss: 0.39773887395858765
Epoch: 79/300 - Train loss: 0.395333856344223, Validation loss: 0.39525511860847473
Epoch: 80/300 - Train loss: 0.3928716480731964, Validation loss: 0.3925800919532776
Epoch: 81/300 - Train loss: 0.39046919345855713, Validation loss: 0.3905092179775238
Epoch: 82/300 - Train loss: 0.38812410831451416, Validation loss: 0.3882271945476532
Epoch: 83/300 - Train loss: 0.38583505153656006, Validation loss: 0.3866272270679474
Epoch: 84/300 - Train loss: 0.3836001753807068, Validation loss: 0.38445907831192017
Epoch: 85/300 - Train loss: 0.381417840719223, Validation loss: 0.38241612911224365
Epoch: 86/300 - Train loss: 0.3792862892150879, Validation loss: 0.37925735116004944
Epoch: 87/300 - Train loss: 0.3772040605545044, Validation loss: 0.37715792655944824
Epoch: 88/300 - Train loss: 0.37516942620277405, Validation loss: 0.3758811950683594
Epoch: 89/300 - Train loss: 0.37318095564842224, Validation loss: 0.3738912045955658
Epoch: 90/300 - Train loss: 0.3712373971939087, Validation loss: 0.37230053544044495
Epoch: 91/300 - Train loss: 0.3693373501300812, Validation loss: 0.3704824447631836
Epoch: 92/300 - Train loss: 0.3674793541431427, Validation loss: 0.3681524395942688
Epoch: 93/300 - Train loss: 0.36566242575645447, Validation loss: 0.36663126945495605
Epoch: 94/300 - Train loss: 0.3638851046562195, Validation loss: 0.3646147847175598
Epoch: 95/300 - Train loss: 0.3621460795402527, Validation loss: 0.3632422089576721
Epoch: 96/300 - Train loss: 0.36044418811798096, Validation loss: 0.3617076277732849
Epoch: 97/300 - Train loss: 0.35877877473831177, Validation loss: 0.3596310317516327
Epoch: 98/300 - Train loss: 0.35714834928512573, Validation loss: 0.3585243225097656
Epoch: 99/300 - Train loss: 0.3555520474910736, Validation loss: 0.35648876428604126
Epoch: 100/300 - Train loss: 0.35398828983306885, Validation loss: 0.3557276725769043
Epoch: 101/300 - Train loss: 0.352456271648407, Validation loss: 0.35380810499191284
Epoch: 102/300 - Train loss: 0.35095492005348206, Validation loss: 0.3521778881549835
Epoch: 103/300 - Train loss: 0.34948331117630005, Validation loss: 0.35195666551589966
Epoch: 104/300 - Train loss: 0.34804052114486694, Validation loss: 0.349281907081604
Epoch: 105/300 - Train loss: 0.34662550687789917, Validation loss: 0.3474253714084625
Epoch: 106/300 - Train loss: 0.34523719549179077, Validation loss: 0.34679049253463745
Epoch: 107/300 - Train loss: 0.3438739478588104, Validation loss: 0.34552568197250366
Epoch: 108/300 - Train loss: 0.34253552556037903, Validation loss: 0.3443145155906677
Epoch: 109/300 - Train loss: 0.3412220776081085, Validation loss: 0.34305915236473083
Epoch: 110/300 - Train loss: 0.33993208408355713, Validation loss: 0.3412427306175232
Epoch: 111/300 - Train loss: 0.3386652171611786, Validation loss: 0.340537428855896
Epoch: 112/300 - Train loss: 0.33742064237594604, Validation loss: 0.3398004472255707
Epoch: 113/300 - Train loss: 0.33619776368141174, Validation loss: 0.33746927976608276
Epoch: 114/300 - Train loss: 0.3349961042404175, Validation loss: 0.33717966079711914
Epoch: 115/300 - Train loss: 0.3338153064250946, Validation loss: 0.3353121876716614
Epoch: 116/300 - Train loss: 0.33265420794487, Validation loss: 0.33457398414611816
Epoch: 117/300 - Train loss: 0.3315128982067108, Validation loss: 0.3335813879966736
Epoch: 118/300 - Train loss: 0.3303902745246887, Validation loss: 0.3330439031124115
Epoch: 119/300 - Train loss: 0.32928621768951416, Validation loss: 0.330980122089386
Epoch: 120/300 - Train loss: 0.32819974422454834, Validation loss: 0.3304673731327057
Epoch: 121/300 - Train loss: 0.32713064551353455, Validation loss: 0.3292059004306793
Epoch: 122/300 - Train loss: 0.3260788917541504, Validation loss: 0.3281572461128235
Epoch: 123/300 - Train loss: 0.32504379749298096, Validation loss: 0.32721227407455444
Epoch: 124/300 - Train loss: 0.32402533292770386, Validation loss: 0.3270190954208374
Epoch: 125/300 - Train loss: 0.3230232894420624, Validation loss: 0.325434148311615
Epoch: 126/300 - Train loss: 0.3220363259315491, Validation loss: 0.3245511054992676
Epoch: 127/300 - Train loss: 0.32106465101242065, Validation loss: 0.32342517375946045
Epoch: 128/300 - Train loss: 0.32010772824287415, Validation loss: 0.322617769241333
Epoch: 129/300 - Train loss: 0.3191654086112976, Validation loss: 0.32139524817466736
Epoch: 130/300 - Train loss: 0.3182372748851776, Validation loss: 0.32050496339797974
Epoch: 131/300 - Train loss: 0.31732314825057983, Validation loss: 0.32013651728630066
Epoch: 132/300 - Train loss: 0.3164231479167938, Validation loss: 0.3187813460826874
Epoch: 133/300 - Train loss: 0.3155360519886017, Validation loss: 0.3181903064250946
Epoch: 134/300 - Train loss: 0.3146612048149109, Validation loss: 0.3174029588699341
Epoch: 135/300 - Train loss: 0.3137986958026886, Validation loss: 0.3162955343723297
Epoch: 136/300 - Train loss: 0.3129483759403229, Validation loss: 0.3156968057155609
Epoch: 137/300 - Train loss: 0.31210988759994507, Validation loss: 0.3151552975177765
Epoch: 138/300 - Train loss: 0.3112829327583313, Validation loss: 0.3138904273509979
Epoch: 139/300 - Train loss: 0.3104671537876129, Validation loss: 0.31306248903274536
Epoch: 140/300 - Train loss: 0.3096630275249481, Validation loss: 0.31298893690109253
Epoch: 141/300 - Train loss: 0.3088701367378235, Validation loss: 0.31198355555534363
Epoch: 142/300 - Train loss: 0.30808764696121216, Validation loss: 0.3112594783306122
Epoch: 143/300 - Train loss: 0.30731460452079773, Validation loss: 0.3106088638305664
Epoch: 144/300 - Train loss: 0.30655157566070557, Validation loss: 0.3094025254249573
Epoch: 145/300 - Train loss: 0.30579841136932373, Validation loss: 0.3090938925743103
Epoch: 146/300 - Train loss: 0.30505409836769104, Validation loss: 0.30855563282966614
Epoch: 147/300 - Train loss: 0.30431920289993286, Validation loss: 0.3076006770133972
Epoch: 148/300 - Train loss: 0.30359339714050293, Validation loss: 0.3067277669906616
Epoch: 149/300 - Train loss: 0.3028762638568878, Validation loss: 0.30630865693092346
Epoch: 150/300 - Train loss: 0.3021683692932129, Validation loss: 0.30498751997947693
Epoch: 151/300 - Train loss: 0.3014693558216095, Validation loss: 0.30475395917892456
Epoch: 152/300 - Train loss: 0.300778865814209, Validation loss: 0.3042137622833252
Epoch: 153/300 - Train loss: 0.3000970482826233, Validation loss: 0.3035070300102234
Epoch: 154/300 - Train loss: 0.2994237542152405, Validation loss: 0.30321642756462097
Epoch: 155/300 - Train loss: 0.29875943064689636, Validation loss: 0.3021109700202942
Epoch: 156/300 - Train loss: 0.2981032729148865, Validation loss: 0.30144011974334717
Epoch: 157/300 - Train loss: 0.2974550724029541, Validation loss: 0.3012174069881439
Epoch: 158/300 - Train loss: 0.29681435227394104, Validation loss: 0.3011084794998169
Epoch: 159/300 - Train loss: 0.29618144035339355, Validation loss: 0.2996523380279541
Epoch: 160/300 - Train loss: 0.29555585980415344, Validation loss: 0.29941409826278687
Epoch: 161/300 - Train loss: 0.2949376702308655, Validation loss: 0.2991001009941101
Epoch: 162/300 - Train loss: 0.2943272292613983, Validation loss: 0.29774338006973267
Epoch: 163/300 - Train loss: 0.2937248945236206, Validation loss: 0.29736587405204773
Epoch: 164/300 - Train loss: 0.2931310534477234, Validation loss: 0.29691755771636963
Epoch: 165/300 - Train loss: 0.29254549741744995, Validation loss: 0.2958894670009613
Epoch: 166/300 - Train loss: 0.2919675409793854, Validation loss: 0.29612410068511963
Epoch: 167/300 - Train loss: 0.29139748215675354, Validation loss: 0.29560771584510803
Epoch: 168/300 - Train loss: 0.29083526134490967, Validation loss: 0.2947082817554474
