Epoch: 1/300 - Train loss: 0.7024832963943481, Validation loss: 0.6983407139778137
Epoch: 2/300 - Train loss: 0.6998036503791809, Validation loss: 0.6956856846809387
Epoch: 3/300 - Train loss: 0.6972439885139465, Validation loss: 0.6933738589286804
Epoch: 4/300 - Train loss: 0.6947892904281616, Validation loss: 0.691048800945282
Epoch: 5/300 - Train loss: 0.6924086809158325, Validation loss: 0.688751757144928
Epoch: 6/300 - Train loss: 0.6900757551193237, Validation loss: 0.6866081953048706
Epoch: 7/300 - Train loss: 0.6877688765525818, Validation loss: 0.6843807101249695
Epoch: 8/300 - Train loss: 0.6854648590087891, Validation loss: 0.682098388671875
Epoch: 9/300 - Train loss: 0.6831462383270264, Validation loss: 0.6798093914985657
Epoch: 10/300 - Train loss: 0.6807937026023865, Validation loss: 0.677499532699585
Epoch: 11/300 - Train loss: 0.6783924698829651, Validation loss: 0.6749748587608337
Epoch: 12/300 - Train loss: 0.6759293079376221, Validation loss: 0.6725451946258545
Epoch: 13/300 - Train loss: 0.6733918786048889, Validation loss: 0.6700049638748169
Epoch: 14/300 - Train loss: 0.6707672476768494, Validation loss: 0.667326033115387
Epoch: 15/300 - Train loss: 0.6680522561073303, Validation loss: 0.6647024154663086
Epoch: 16/300 - Train loss: 0.665239691734314, Validation loss: 0.6616285443305969
Epoch: 17/300 - Train loss: 0.6623236536979675, Validation loss: 0.658695638179779
Epoch: 18/300 - Train loss: 0.6593030691146851, Validation loss: 0.655489444732666
Epoch: 19/300 - Train loss: 0.6561729907989502, Validation loss: 0.6522812247276306
Epoch: 20/300 - Train loss: 0.652935266494751, Validation loss: 0.6490764617919922
Epoch: 21/300 - Train loss: 0.6495909690856934, Validation loss: 0.6455846428871155
Epoch: 22/300 - Train loss: 0.6461378335952759, Validation loss: 0.6418991684913635
Epoch: 23/300 - Train loss: 0.6425817608833313, Validation loss: 0.6384345293045044
Epoch: 24/300 - Train loss: 0.6389269232749939, Validation loss: 0.6346995234489441
Epoch: 25/300 - Train loss: 0.6351807117462158, Validation loss: 0.6308664083480835
Epoch: 26/300 - Train loss: 0.631349503993988, Validation loss: 0.6270497441291809
Epoch: 27/300 - Train loss: 0.6274353861808777, Validation loss: 0.6230707764625549
Epoch: 28/300 - Train loss: 0.6234416961669922, Validation loss: 0.618920624256134
Epoch: 29/300 - Train loss: 0.6193737983703613, Validation loss: 0.614922821521759
Epoch: 30/300 - Train loss: 0.6152402758598328, Validation loss: 0.6105175018310547
Epoch: 31/300 - Train loss: 0.6110490560531616, Validation loss: 0.606343686580658
Epoch: 32/300 - Train loss: 0.6068034768104553, Validation loss: 0.6021009683609009
Epoch: 33/300 - Train loss: 0.6025098562240601, Validation loss: 0.5978590846061707
Epoch: 34/300 - Train loss: 0.5981729626655579, Validation loss: 0.5939258337020874
Epoch: 35/300 - Train loss: 0.5938006043434143, Validation loss: 0.5891174077987671
Epoch: 36/300 - Train loss: 0.5893958210945129, Validation loss: 0.5847763419151306
Epoch: 37/300 - Train loss: 0.5849593877792358, Validation loss: 0.580253005027771
Epoch: 38/300 - Train loss: 0.5804970860481262, Validation loss: 0.5758682489395142
Epoch: 39/300 - Train loss: 0.5760096311569214, Validation loss: 0.571563184261322
Epoch: 40/300 - Train loss: 0.5715058445930481, Validation loss: 0.5672765970230103
Epoch: 41/300 - Train loss: 0.5669904351234436, Validation loss: 0.562592089176178
Epoch: 42/300 - Train loss: 0.562465250492096, Validation loss: 0.5582753419876099
Epoch: 43/300 - Train loss: 0.5579357147216797, Validation loss: 0.5538373589515686
Epoch: 44/300 - Train loss: 0.5534083247184753, Validation loss: 0.5491155385971069
Epoch: 45/300 - Train loss: 0.5488919615745544, Validation loss: 0.5450387597084045
Epoch: 46/300 - Train loss: 0.544391393661499, Validation loss: 0.5404630303382874
Epoch: 47/300 - Train loss: 0.5399132370948792, Validation loss: 0.5363270044326782
Epoch: 48/300 - Train loss: 0.5354615449905396, Validation loss: 0.5318183302879333
Epoch: 49/300 - Train loss: 0.5310394763946533, Validation loss: 0.5275442600250244
Epoch: 50/300 - Train loss: 0.5266538858413696, Validation loss: 0.5234016180038452
Epoch: 51/300 - Train loss: 0.5223056077957153, Validation loss: 0.5189256072044373
Epoch: 52/300 - Train loss: 0.5179980993270874, Validation loss: 0.5152282118797302
Epoch: 53/300 - Train loss: 0.5137338638305664, Validation loss: 0.5104641914367676
Epoch: 54/300 - Train loss: 0.509514331817627, Validation loss: 0.5065302848815918
Epoch: 55/300 - Train loss: 0.5053402781486511, Validation loss: 0.5024918913841248
Epoch: 56/300 - Train loss: 0.5012158155441284, Validation loss: 0.4984282851219177
Epoch: 57/300 - Train loss: 0.49714335799217224, Validation loss: 0.49455443024635315
Epoch: 58/300 - Train loss: 0.4931234121322632, Validation loss: 0.4907141327857971
Epoch: 59/300 - Train loss: 0.48915886878967285, Validation loss: 0.4869440197944641
Epoch: 60/300 - Train loss: 0.4852522015571594, Validation loss: 0.4833979904651642
Epoch: 61/300 - Train loss: 0.48140469193458557, Validation loss: 0.47965413331985474
Epoch: 62/300 - Train loss: 0.47761988639831543, Validation loss: 0.47628292441368103
Epoch: 63/300 - Train loss: 0.47390076518058777, Validation loss: 0.47204893827438354
Epoch: 64/300 - Train loss: 0.4702480435371399, Validation loss: 0.46922528743743896
Epoch: 65/300 - Train loss: 0.46666261553764343, Validation loss: 0.4653155505657196
Epoch: 66/300 - Train loss: 0.46314477920532227, Validation loss: 0.46205660700798035
Epoch: 67/300 - Train loss: 0.459695041179657, Validation loss: 0.45891961455345154
Epoch: 68/300 - Train loss: 0.45631471276283264, Validation loss: 0.45540642738342285
Epoch: 69/300 - Train loss: 0.45300450921058655, Validation loss: 0.4528660476207733
Epoch: 70/300 - Train loss: 0.4497644007205963, Validation loss: 0.4496448040008545
Epoch: 71/300 - Train loss: 0.4465939700603485, Validation loss: 0.44651979207992554
Epoch: 72/300 - Train loss: 0.44349417090415955, Validation loss: 0.44373229146003723
Epoch: 73/300 - Train loss: 0.44046398997306824, Validation loss: 0.4403913915157318
Epoch: 74/300 - Train loss: 0.4375034272670746, Validation loss: 0.4377503991127014
Epoch: 75/300 - Train loss: 0.4346122741699219, Validation loss: 0.4351408779621124
Epoch: 76/300 - Train loss: 0.4317896366119385, Validation loss: 0.43239471316337585
Epoch: 77/300 - Train loss: 0.42903485894203186, Validation loss: 0.42987486720085144
Epoch: 78/300 - Train loss: 0.4263470470905304, Validation loss: 0.4273483157157898
Epoch: 79/300 - Train loss: 0.42372626066207886, Validation loss: 0.42484793066978455
Epoch: 80/300 - Train loss: 0.42117223143577576, Validation loss: 0.42244523763656616
Epoch: 81/300 - Train loss: 0.4186844229698181, Validation loss: 0.4199865460395813
Epoch: 82/300 - Train loss: 0.41626107692718506, Validation loss: 0.4176609516143799
Epoch: 83/300 - Train loss: 0.41390082240104675, Validation loss: 0.4157705008983612
Epoch: 84/300 - Train loss: 0.4116031229496002, Validation loss: 0.4135317802429199
Epoch: 85/300 - Train loss: 0.4093669652938843, Validation loss: 0.4111822247505188
Epoch: 86/300 - Train loss: 0.4071909785270691, Validation loss: 0.4097318947315216
Epoch: 87/300 - Train loss: 0.40507444739341736, Validation loss: 0.407382607460022
Epoch: 88/300 - Train loss: 0.4030162990093231, Validation loss: 0.4063987731933594
Epoch: 89/300 - Train loss: 0.4010152220726013, Validation loss: 0.404033899307251
Epoch: 90/300 - Train loss: 0.3990696668624878, Validation loss: 0.40174025297164917
Epoch: 91/300 - Train loss: 0.39717820286750793, Validation loss: 0.4005095660686493
Epoch: 92/300 - Train loss: 0.39533987641334534, Validation loss: 0.39897021651268005
Epoch: 93/300 - Train loss: 0.3935529589653015, Validation loss: 0.39712750911712646
Epoch: 94/300 - Train loss: 0.3918163478374481, Validation loss: 0.39517921209335327
Epoch: 95/300 - Train loss: 0.3901287019252777, Validation loss: 0.39416611194610596
Epoch: 96/300 - Train loss: 0.38848876953125, Validation loss: 0.39214810729026794
Epoch: 97/300 - Train loss: 0.3868955969810486, Validation loss: 0.39062514901161194
Epoch: 98/300 - Train loss: 0.3853476047515869, Validation loss: 0.38915058970451355
Epoch: 99/300 - Train loss: 0.38384321331977844, Validation loss: 0.3873525857925415
Epoch: 100/300 - Train loss: 0.3823813796043396, Validation loss: 0.3862375319004059
Epoch: 101/300 - Train loss: 0.3809608817100525, Validation loss: 0.3847518563270569
Epoch: 102/300 - Train loss: 0.3795803487300873, Validation loss: 0.3838895857334137
Epoch: 103/300 - Train loss: 0.378238707780838, Validation loss: 0.3825666010379791
Epoch: 104/300 - Train loss: 0.3769349157810211, Validation loss: 0.38096708059310913
Epoch: 105/300 - Train loss: 0.3756680488586426, Validation loss: 0.3803865611553192
Epoch: 106/300 - Train loss: 0.37443673610687256, Validation loss: 0.37890565395355225
Epoch: 107/300 - Train loss: 0.37324008345603943, Validation loss: 0.37820932269096375
Epoch: 108/300 - Train loss: 0.3720771074295044, Validation loss: 0.3764467239379883
Epoch: 109/300 - Train loss: 0.3709464967250824, Validation loss: 0.3757319450378418
Epoch: 110/300 - Train loss: 0.3698473274707794, Validation loss: 0.3747234642505646
Epoch: 111/300 - Train loss: 0.36877813935279846, Validation loss: 0.37366819381713867
Epoch: 112/300 - Train loss: 0.3677380681037903, Validation loss: 0.37246671319007874
Epoch: 113/300 - Train loss: 0.36672648787498474, Validation loss: 0.37167930603027344
Epoch: 114/300 - Train loss: 0.36574238538742065, Validation loss: 0.3707959055900574
Epoch: 115/300 - Train loss: 0.3647845983505249, Validation loss: 0.3695068359375
Epoch: 116/300 - Train loss: 0.363852322101593, Validation loss: 0.3692501187324524
Epoch: 117/300 - Train loss: 0.3629451394081116, Validation loss: 0.3683328628540039
Epoch: 118/300 - Train loss: 0.362062007188797, Validation loss: 0.3673449158668518
Epoch: 119/300 - Train loss: 0.36120176315307617, Validation loss: 0.3662886321544647
Epoch: 120/300 - Train loss: 0.3603638708591461, Validation loss: 0.3654983639717102
Epoch: 121/300 - Train loss: 0.3595477044582367, Validation loss: 0.3647114634513855
Epoch: 122/300 - Train loss: 0.358752578496933, Validation loss: 0.3640226423740387
Epoch: 123/300 - Train loss: 0.35797759890556335, Validation loss: 0.3640899360179901
Epoch: 124/300 - Train loss: 0.3572218418121338, Validation loss: 0.3621402382850647
Epoch: 125/300 - Train loss: 0.3564848005771637, Validation loss: 0.361799418926239
Epoch: 126/300 - Train loss: 0.35576578974723816, Validation loss: 0.3612990975379944
Epoch: 127/300 - Train loss: 0.3550638258457184, Validation loss: 0.360876202583313
Epoch: 128/300 - Train loss: 0.3543785810470581, Validation loss: 0.36000674962997437
Epoch: 129/300 - Train loss: 0.35370954871177673, Validation loss: 0.3596205413341522
Epoch: 130/300 - Train loss: 0.353056401014328, Validation loss: 0.358600378036499
Epoch: 131/300 - Train loss: 0.3524185121059418, Validation loss: 0.3576822578907013
Epoch: 132/300 - Train loss: 0.35179558396339417, Validation loss: 0.3573469817638397
Epoch: 133/300 - Train loss: 0.3511868417263031, Validation loss: 0.35694047808647156
Epoch: 134/300 - Train loss: 0.350591778755188, Validation loss: 0.35695120692253113
