Epoch: 1/200 - Train loss: 0.5672565698623657, Validation loss: 0.46864545345306396
Epoch: 2/200 - Train loss: 0.430009663105011, Validation loss: 0.41880732774734497
Epoch: 3/200 - Train loss: 0.39163437485694885, Validation loss: 0.3952902555465698
Epoch: 4/200 - Train loss: 0.3707985281944275, Validation loss: 0.38241904973983765
Epoch: 5/200 - Train loss: 0.3547114133834839, Validation loss: 0.3669210970401764
Epoch: 6/200 - Train loss: 0.3352700471878052, Validation loss: 0.35139429569244385
Epoch: 7/200 - Train loss: 0.3174517750740051, Validation loss: 0.33503860235214233
Epoch: 8/200 - Train loss: 0.3021693825721741, Validation loss: 0.32251542806625366
Epoch: 9/200 - Train loss: 0.2911416292190552, Validation loss: 0.3142300546169281
Epoch: 10/200 - Train loss: 0.2803908884525299, Validation loss: 0.30459123849868774
Epoch: 11/200 - Train loss: 0.2724528908729553, Validation loss: 0.29856863617897034
Epoch: 12/200 - Train loss: 0.26688459515571594, Validation loss: 0.2989349663257599
Epoch: 13/200 - Train loss: 0.2611899971961975, Validation loss: 0.300508052110672
Epoch: 14/200 - Train loss: 0.25777289271354675, Validation loss: 0.2883026599884033
Epoch: 15/200 - Train loss: 0.25250327587127686, Validation loss: 0.2841685712337494
Epoch: 16/200 - Train loss: 0.24904565513134003, Validation loss: 0.28502920269966125
Epoch: 17/200 - Train loss: 0.24628500640392303, Validation loss: 0.28153106570243835
Epoch: 18/200 - Train loss: 0.24458640813827515, Validation loss: 0.2858160138130188
Epoch: 19/200 - Train loss: 0.2421463280916214, Validation loss: 0.28025949001312256
Epoch: 20/200 - Train loss: 0.23898553848266602, Validation loss: 0.2835221290588379
Epoch: 21/200 - Train loss: 0.2373635619878769, Validation loss: 0.27988365292549133
Epoch: 22/200 - Train loss: 0.23530806601047516, Validation loss: 0.2811215817928314
Epoch: 23/200 - Train loss: 0.234119713306427, Validation loss: 0.277125746011734
Epoch: 24/200 - Train loss: 0.23164492845535278, Validation loss: 0.27849331498146057
Epoch: 25/200 - Train loss: 0.22976794838905334, Validation loss: 0.2779160141944885
Epoch: 26/200 - Train loss: 0.22924832999706268, Validation loss: 0.27807366847991943
Epoch: 27/200 - Train loss: 0.228162482380867, Validation loss: 0.2781065106391907
Epoch: 28/200 - Train loss: 0.22758136689662933, Validation loss: 0.2736448049545288
Epoch: 29/200 - Train loss: 0.22601301968097687, Validation loss: 0.2777409851551056
Epoch: 30/200 - Train loss: 0.22378045320510864, Validation loss: 0.2745167016983032
Epoch: 31/200 - Train loss: 0.22256626188755035, Validation loss: 0.2728239893913269
Epoch: 32/200 - Train loss: 0.22170615196228027, Validation loss: 0.27255088090896606
Epoch: 33/200 - Train loss: 0.2205158919095993, Validation loss: 0.270691841840744
Epoch: 34/200 - Train loss: 0.21993763744831085, Validation loss: 0.2718313932418823
Epoch: 35/200 - Train loss: 0.2190917432308197, Validation loss: 0.2718161642551422
Epoch: 36/200 - Train loss: 0.21746157109737396, Validation loss: 0.26920628547668457
Epoch: 37/200 - Train loss: 0.21750223636627197, Validation loss: 0.2700422704219818
Epoch: 38/200 - Train loss: 0.21721018850803375, Validation loss: 0.2751953601837158
Epoch: 39/200 - Train loss: 0.21599403023719788, Validation loss: 0.2705743908882141
Epoch: 40/200 - Train loss: 0.2140878289937973, Validation loss: 0.2713831961154938
Epoch: 41/200 - Train loss: 0.2137375771999359, Validation loss: 0.27089932560920715
Epoch: 42/200 - Train loss: 0.213672935962677, Validation loss: 0.27089646458625793
Epoch: 43/200 - Train loss: 0.21356089413166046, Validation loss: 0.26974937319755554
Epoch: 44/200 - Train loss: 0.21253372728824615, Validation loss: 0.27264198660850525
Epoch: 45/200 - Train loss: 0.21242418885231018, Validation loss: 0.275451123714447
Epoch: 46/200 - Train loss: 0.21132980287075043, Validation loss: 0.274540513753891
Epoch: 47/200 - Train loss: 0.20987753570079803, Validation loss: 0.26829037070274353
Epoch: 48/200 - Train loss: 0.2096058428287506, Validation loss: 0.2723180651664734
Epoch: 49/200 - Train loss: 0.20938371121883392, Validation loss: 0.2766420245170593
Epoch: 50/200 - Train loss: 0.21024619042873383, Validation loss: 0.278840571641922
Epoch: 51/200 - Train loss: 0.21062886714935303, Validation loss: 0.27521583437919617
Epoch: 52/200 - Train loss: 0.2092210203409195, Validation loss: 0.270012229681015
Epoch: 53/200 - Train loss: 0.20827935636043549, Validation loss: 0.26782000064849854
Epoch: 54/200 - Train loss: 0.20869110524654388, Validation loss: 0.2727122902870178
Epoch: 55/200 - Train loss: 0.20765350759029388, Validation loss: 0.27542054653167725
Epoch: 56/200 - Train loss: 0.20784123241901398, Validation loss: 0.268710196018219
Epoch: 57/200 - Train loss: 0.20726096630096436, Validation loss: 0.2736934721469879
Epoch: 58/200 - Train loss: 0.2061740905046463, Validation loss: 0.2714517116546631
Epoch: 59/200 - Train loss: 0.2063804268836975, Validation loss: 0.2743995487689972
Epoch: 60/200 - Train loss: 0.20738565921783447, Validation loss: 0.27468401193618774
Epoch: 61/200 - Train loss: 0.20607268810272217, Validation loss: 0.27198436856269836
Epoch: 62/200 - Train loss: 0.20725907385349274, Validation loss: 0.2710355818271637
Epoch: 63/200 - Train loss: 0.205730602145195, Validation loss: 0.2720102369785309
Epoch: 64/200 - Train loss: 0.20535287261009216, Validation loss: 0.26969969272613525
Epoch: 65/200 - Train loss: 0.2044583261013031, Validation loss: 0.26788195967674255
Epoch: 66/200 - Train loss: 0.20452652871608734, Validation loss: 0.2730488181114197
Epoch: 67/200 - Train loss: 0.2048182487487793, Validation loss: 0.26990947127342224
Epoch: 68/200 - Train loss: 0.20513929426670074, Validation loss: 0.2734816074371338
Epoch: 69/200 - Train loss: 0.20466060936450958, Validation loss: 0.2694314420223236
Epoch: 70/200 - Train loss: 0.2039104402065277, Validation loss: 0.27390897274017334
Epoch: 71/200 - Train loss: 0.20466744899749756, Validation loss: 0.2678738236427307
Epoch: 72/200 - Train loss: 0.2032424360513687, Validation loss: 0.2736492455005646
Epoch: 73/200 - Train loss: 0.20346984267234802, Validation loss: 0.2676575779914856
Epoch: 74/200 - Train loss: 0.20289768278598785, Validation loss: 0.2686140537261963
Epoch: 75/200 - Train loss: 0.20255734026432037, Validation loss: 0.2731860280036926
Epoch: 76/200 - Train loss: 0.20254692435264587, Validation loss: 0.2685548663139343
Epoch: 77/200 - Train loss: 0.20469020307064056, Validation loss: 0.2673393189907074
Epoch: 78/200 - Train loss: 0.20246602594852448, Validation loss: 0.26736730337142944
Epoch: 79/200 - Train loss: 0.20327061414718628, Validation loss: 0.2746545672416687
Epoch: 80/200 - Train loss: 0.20213629305362701, Validation loss: 0.26966366171836853
Epoch: 81/200 - Train loss: 0.2024502009153366, Validation loss: 0.26798537373542786
Epoch: 82/200 - Train loss: 0.20137113332748413, Validation loss: 0.2696510851383209
Epoch: 83/200 - Train loss: 0.20242290198802948, Validation loss: 0.2651735246181488
Epoch: 84/200 - Train loss: 0.20139333605766296, Validation loss: 0.27184775471687317
Epoch: 85/200 - Train loss: 0.20236921310424805, Validation loss: 0.26685062050819397
Epoch: 86/200 - Train loss: 0.20126359164714813, Validation loss: 0.2695905566215515
Epoch: 87/200 - Train loss: 0.20123976469039917, Validation loss: 0.265859991312027
Epoch: 88/200 - Train loss: 0.20146121084690094, Validation loss: 0.2663939893245697
Epoch: 89/200 - Train loss: 0.2015330046415329, Validation loss: 0.2684241831302643
Epoch: 90/200 - Train loss: 0.2016369104385376, Validation loss: 0.26784324645996094
Epoch: 91/200 - Train loss: 0.200847327709198, Validation loss: 0.2665444612503052
Epoch: 92/200 - Train loss: 0.20142196118831635, Validation loss: 0.2686212658882141
Epoch: 93/200 - Train loss: 0.2009611874818802, Validation loss: 0.26700061559677124
Epoch: 94/200 - Train loss: 0.20119531452655792, Validation loss: 0.27184128761291504
Epoch: 95/200 - Train loss: 0.2008863389492035, Validation loss: 0.26740190386772156
Epoch: 96/200 - Train loss: 0.19972799718379974, Validation loss: 0.270354300737381
Epoch: 97/200 - Train loss: 0.19983981549739838, Validation loss: 0.2693691551685333
Epoch: 98/200 - Train loss: 0.20049907267093658, Validation loss: 0.2696344554424286
Epoch: 99/200 - Train loss: 0.19951148331165314, Validation loss: 0.26919829845428467
Epoch: 100/200 - Train loss: 0.2000342309474945, Validation loss: 0.2709861099720001
Epoch: 101/200 - Train loss: 0.19958294928073883, Validation loss: 0.2763945162296295
Epoch: 102/200 - Train loss: 0.19998346269130707, Validation loss: 0.27022701501846313
Epoch: 103/200 - Train loss: 0.19935882091522217, Validation loss: 0.26843488216400146
Epoch: 104/200 - Train loss: 0.19908566772937775, Validation loss: 0.26929205656051636
Epoch: 105/200 - Train loss: 0.19934529066085815, Validation loss: 0.2665483355522156
Epoch: 106/200 - Train loss: 0.1986733376979828, Validation loss: 0.27004101872444153
Epoch: 107/200 - Train loss: 0.19870787858963013, Validation loss: 0.2712147831916809
Epoch: 108/200 - Train loss: 0.19913804531097412, Validation loss: 0.2721107602119446
Epoch: 109/200 - Train loss: 0.19889216125011444, Validation loss: 0.27388080954551697
Epoch: 110/200 - Train loss: 0.19840531051158905, Validation loss: 0.2698022723197937
Epoch: 111/200 - Train loss: 0.19876274466514587, Validation loss: 0.27400103211402893
Epoch: 112/200 - Train loss: 0.19890402257442474, Validation loss: 0.2666754722595215
Epoch: 113/200 - Train loss: 0.19775661826133728, Validation loss: 0.2697298526763916
Epoch: 114/200 - Train loss: 0.1973612755537033, Validation loss: 0.2684289813041687
Epoch: 115/200 - Train loss: 0.19775065779685974, Validation loss: 0.2765529453754425
Epoch: 116/200 - Train loss: 0.19789309799671173, Validation loss: 0.26927056908607483
Epoch: 117/200 - Train loss: 0.19759957492351532, Validation loss: 0.271840900182724
Epoch: 118/200 - Train loss: 0.19906127452850342, Validation loss: 0.2685698866844177
Epoch: 119/200 - Train loss: 0.19756576418876648, Validation loss: 0.2694835960865021
Epoch: 120/200 - Train loss: 0.19753514230251312, Validation loss: 0.26709702610969543
Epoch: 121/200 - Train loss: 0.19683510065078735, Validation loss: 0.2670438885688782
Epoch: 122/200 - Train loss: 0.19816216826438904, Validation loss: 0.2678714394569397
Epoch: 123/200 - Train loss: 0.19654227793216705, Validation loss: 0.2716810405254364
Epoch: 124/200 - Train loss: 0.19734004139900208, Validation loss: 0.2686886787414551
Epoch: 125/200 - Train loss: 0.1963760107755661, Validation loss: 0.2680702209472656
