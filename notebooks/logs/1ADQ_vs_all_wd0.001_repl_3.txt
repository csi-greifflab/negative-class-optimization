Epoch: 1/300 - Train loss: 0.6946952939033508, Validation loss: 0.6923060417175293
Epoch: 2/300 - Train loss: 0.6929454803466797, Validation loss: 0.6906164884567261
Epoch: 3/300 - Train loss: 0.6911476850509644, Validation loss: 0.688901424407959
Epoch: 4/300 - Train loss: 0.6892822980880737, Validation loss: 0.6870352625846863
Epoch: 5/300 - Train loss: 0.6873362064361572, Validation loss: 0.6852258443832397
Epoch: 6/300 - Train loss: 0.6853101253509521, Validation loss: 0.6832268834114075
Epoch: 7/300 - Train loss: 0.6832113265991211, Validation loss: 0.6812758445739746
Epoch: 8/300 - Train loss: 0.6810463666915894, Validation loss: 0.6791622042655945
Epoch: 9/300 - Train loss: 0.678817868232727, Validation loss: 0.6771108508110046
Epoch: 10/300 - Train loss: 0.6765318512916565, Validation loss: 0.6749241948127747
Epoch: 11/300 - Train loss: 0.6742050051689148, Validation loss: 0.6727064251899719
Epoch: 12/300 - Train loss: 0.671843409538269, Validation loss: 0.6704920530319214
Epoch: 13/300 - Train loss: 0.6694541573524475, Validation loss: 0.6682033538818359
Epoch: 14/300 - Train loss: 0.6670437455177307, Validation loss: 0.6659897565841675
Epoch: 15/300 - Train loss: 0.664614737033844, Validation loss: 0.6636897921562195
Epoch: 16/300 - Train loss: 0.6621710062026978, Validation loss: 0.6614742279052734
Epoch: 17/300 - Train loss: 0.6597098112106323, Validation loss: 0.6591089963912964
Epoch: 18/300 - Train loss: 0.6572354435920715, Validation loss: 0.6567902565002441
Epoch: 19/300 - Train loss: 0.6547451019287109, Validation loss: 0.6543830633163452
Epoch: 20/300 - Train loss: 0.6522346138954163, Validation loss: 0.6519786715507507
Epoch: 21/300 - Train loss: 0.6497025489807129, Validation loss: 0.649601936340332
Epoch: 22/300 - Train loss: 0.6471508741378784, Validation loss: 0.6471899151802063
Epoch: 23/300 - Train loss: 0.6445828080177307, Validation loss: 0.6447302103042603
Epoch: 24/300 - Train loss: 0.6419978737831116, Validation loss: 0.6423904895782471
Epoch: 25/300 - Train loss: 0.6393955945968628, Validation loss: 0.6398078799247742
Epoch: 26/300 - Train loss: 0.6367800235748291, Validation loss: 0.6373013854026794
Epoch: 27/300 - Train loss: 0.6341537237167358, Validation loss: 0.6349442005157471
Epoch: 28/300 - Train loss: 0.6315168738365173, Validation loss: 0.6324329376220703
Epoch: 29/300 - Train loss: 0.6288719177246094, Validation loss: 0.6298734545707703
Epoch: 30/300 - Train loss: 0.6262205839157104, Validation loss: 0.627378523349762
Epoch: 31/300 - Train loss: 0.6235650181770325, Validation loss: 0.6247333884239197
Epoch: 32/300 - Train loss: 0.6209075450897217, Validation loss: 0.6222448348999023
Epoch: 33/300 - Train loss: 0.6182503700256348, Validation loss: 0.6197978854179382
Epoch: 34/300 - Train loss: 0.6155949234962463, Validation loss: 0.6172363758087158
Epoch: 35/300 - Train loss: 0.6129428744316101, Validation loss: 0.6146935820579529
Epoch: 36/300 - Train loss: 0.6102950572967529, Validation loss: 0.6122007369995117
Epoch: 37/300 - Train loss: 0.6076543927192688, Validation loss: 0.6097762584686279
Epoch: 38/300 - Train loss: 0.6050224900245667, Validation loss: 0.6072237491607666
Epoch: 39/300 - Train loss: 0.6024008393287659, Validation loss: 0.604606032371521
Epoch: 40/300 - Train loss: 0.5997902154922485, Validation loss: 0.6021099090576172
Epoch: 41/300 - Train loss: 0.5971936583518982, Validation loss: 0.5998342037200928
Epoch: 42/300 - Train loss: 0.5946130156517029, Validation loss: 0.5971043109893799
Epoch: 43/300 - Train loss: 0.5920487642288208, Validation loss: 0.5947937965393066
Epoch: 44/300 - Train loss: 0.5895026922225952, Validation loss: 0.5925129652023315
Epoch: 45/300 - Train loss: 0.5869765281677246, Validation loss: 0.5901081562042236
Epoch: 46/300 - Train loss: 0.5844721794128418, Validation loss: 0.5878953337669373
Epoch: 47/300 - Train loss: 0.5819915533065796, Validation loss: 0.5850890278816223
Epoch: 48/300 - Train loss: 0.5795361399650574, Validation loss: 0.5828804969787598
Epoch: 49/300 - Train loss: 0.577106773853302, Validation loss: 0.5805678963661194
Epoch: 50/300 - Train loss: 0.5747054815292358, Validation loss: 0.5777531266212463
Epoch: 51/300 - Train loss: 0.5723338723182678, Validation loss: 0.5758788585662842
Epoch: 52/300 - Train loss: 0.5699931383132935, Validation loss: 0.5737114548683167
Epoch: 53/300 - Train loss: 0.5676841735839844, Validation loss: 0.5715966820716858
Epoch: 54/300 - Train loss: 0.5654088854789734, Validation loss: 0.5694947838783264
Epoch: 55/300 - Train loss: 0.5631681680679321, Validation loss: 0.5673249959945679
Epoch: 56/300 - Train loss: 0.5609631538391113, Validation loss: 0.5653023719787598
Epoch: 57/300 - Train loss: 0.5587947368621826, Validation loss: 0.5627692341804504
Epoch: 58/300 - Train loss: 0.5566644072532654, Validation loss: 0.5614299774169922
Epoch: 59/300 - Train loss: 0.5545719861984253, Validation loss: 0.5593256950378418
Epoch: 60/300 - Train loss: 0.5525190830230713, Validation loss: 0.5571079254150391
Epoch: 61/300 - Train loss: 0.5505065321922302, Validation loss: 0.5554760694503784
Epoch: 62/300 - Train loss: 0.5485338568687439, Validation loss: 0.553653359413147
Epoch: 63/300 - Train loss: 0.546602725982666, Validation loss: 0.551766037940979
Epoch: 64/300 - Train loss: 0.5447131395339966, Validation loss: 0.5499093532562256
Epoch: 65/300 - Train loss: 0.5428645610809326, Validation loss: 0.5482301712036133
Epoch: 66/300 - Train loss: 0.5410577058792114, Validation loss: 0.5465061664581299
Epoch: 67/300 - Train loss: 0.5392933487892151, Validation loss: 0.5446116328239441
Epoch: 68/300 - Train loss: 0.537570595741272, Validation loss: 0.543117344379425
Epoch: 69/300 - Train loss: 0.5358896255493164, Validation loss: 0.5414330959320068
Epoch: 70/300 - Train loss: 0.534250020980835, Validation loss: 0.5398395657539368
Epoch: 71/300 - Train loss: 0.5326514840126038, Validation loss: 0.5382779836654663
Epoch: 72/300 - Train loss: 0.5310940146446228, Validation loss: 0.5366681218147278
Epoch: 73/300 - Train loss: 0.5295767188072205, Validation loss: 0.5358951687812805
Epoch: 74/300 - Train loss: 0.5280994772911072, Validation loss: 0.5344127416610718
Epoch: 75/300 - Train loss: 0.5266611576080322, Validation loss: 0.533168613910675
Epoch: 76/300 - Train loss: 0.5252612233161926, Validation loss: 0.5319288372993469
Epoch: 77/300 - Train loss: 0.5238989591598511, Validation loss: 0.5300410389900208
Epoch: 78/300 - Train loss: 0.5225738286972046, Validation loss: 0.529386579990387
Epoch: 79/300 - Train loss: 0.5212845802307129, Validation loss: 0.5286257863044739
Epoch: 80/300 - Train loss: 0.5200307965278625, Validation loss: 0.527095377445221
Epoch: 81/300 - Train loss: 0.5188117027282715, Validation loss: 0.5255407094955444
Epoch: 82/300 - Train loss: 0.5176261067390442, Validation loss: 0.5246596932411194
Epoch: 83/300 - Train loss: 0.5164729356765747, Validation loss: 0.5233645439147949
Epoch: 84/300 - Train loss: 0.5153515338897705, Validation loss: 0.5222049951553345
Epoch: 85/300 - Train loss: 0.5142609477043152, Validation loss: 0.5213659405708313
Epoch: 86/300 - Train loss: 0.5132004618644714, Validation loss: 0.520416259765625
Epoch: 87/300 - Train loss: 0.512167751789093, Validation loss: 0.5194624662399292
Epoch: 88/300 - Train loss: 0.5111633539199829, Validation loss: 0.5184523463249207
Epoch: 89/300 - Train loss: 0.5101858377456665, Validation loss: 0.5178432464599609
Epoch: 90/300 - Train loss: 0.5092344284057617, Validation loss: 0.5171906352043152
Epoch: 91/300 - Train loss: 0.508307695388794, Validation loss: 0.5153599977493286
Epoch: 92/300 - Train loss: 0.5074039697647095, Validation loss: 0.515548050403595
Epoch: 93/300 - Train loss: 0.5065233111381531, Validation loss: 0.5141445398330688
Epoch: 94/300 - Train loss: 0.5056642293930054, Validation loss: 0.5132001638412476
Epoch: 95/300 - Train loss: 0.5048260688781738, Validation loss: 0.5129560232162476
Epoch: 96/300 - Train loss: 0.5040081143379211, Validation loss: 0.5117549300193787
Epoch: 97/300 - Train loss: 0.5032099485397339, Validation loss: 0.5111222267150879
Epoch: 98/300 - Train loss: 0.5024299025535583, Validation loss: 0.510860800743103
Epoch: 99/300 - Train loss: 0.5016671419143677, Validation loss: 0.5097410678863525
Epoch: 100/300 - Train loss: 0.5009205937385559, Validation loss: 0.5095531940460205
Epoch: 101/300 - Train loss: 0.5001893639564514, Validation loss: 0.5088015794754028
Epoch: 102/300 - Train loss: 0.4994725286960602, Validation loss: 0.508512020111084
Epoch: 103/300 - Train loss: 0.4987695813179016, Validation loss: 0.5074319243431091
Epoch: 104/300 - Train loss: 0.4980802536010742, Validation loss: 0.5061986446380615
Epoch: 105/300 - Train loss: 0.49740323424339294, Validation loss: 0.5058308243751526
Epoch: 106/300 - Train loss: 0.4967377483844757, Validation loss: 0.5053867101669312
Epoch: 107/300 - Train loss: 0.49608340859413147, Validation loss: 0.5043106079101562
Epoch: 108/300 - Train loss: 0.49543917179107666, Validation loss: 0.5041773319244385
Epoch: 109/300 - Train loss: 0.494804322719574, Validation loss: 0.5035484433174133
Epoch: 110/300 - Train loss: 0.4941776394844055, Validation loss: 0.5028144717216492
Epoch: 111/300 - Train loss: 0.49355822801589966, Validation loss: 0.5025035738945007
Epoch: 112/300 - Train loss: 0.49294722080230713, Validation loss: 0.501623272895813
Epoch: 113/300 - Train loss: 0.4923431873321533, Validation loss: 0.50159752368927
