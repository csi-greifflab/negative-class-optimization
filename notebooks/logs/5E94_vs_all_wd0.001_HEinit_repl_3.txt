Epoch: 1/300 - Train loss: 0.6860565543174744, Validation loss: 0.6835097074508667
Epoch: 2/300 - Train loss: 0.6837818622589111, Validation loss: 0.6811395883560181
Epoch: 3/300 - Train loss: 0.68146151304245, Validation loss: 0.6786946654319763
Epoch: 4/300 - Train loss: 0.6790809035301208, Validation loss: 0.6763409376144409
Epoch: 5/300 - Train loss: 0.6766380071640015, Validation loss: 0.6738499402999878
Epoch: 6/300 - Train loss: 0.6741321086883545, Validation loss: 0.6711953282356262
Epoch: 7/300 - Train loss: 0.6715571880340576, Validation loss: 0.6687588691711426
Epoch: 8/300 - Train loss: 0.6689233779907227, Validation loss: 0.6660062074661255
Epoch: 9/300 - Train loss: 0.6662209033966064, Validation loss: 0.663205623626709
Epoch: 10/300 - Train loss: 0.6634384989738464, Validation loss: 0.6601770520210266
Epoch: 11/300 - Train loss: 0.6605821251869202, Validation loss: 0.657274067401886
Epoch: 12/300 - Train loss: 0.6576489806175232, Validation loss: 0.6541985273361206
Epoch: 13/300 - Train loss: 0.6546435356140137, Validation loss: 0.6513742804527283
Epoch: 14/300 - Train loss: 0.6515662670135498, Validation loss: 0.6480215787887573
Epoch: 15/300 - Train loss: 0.6484168171882629, Validation loss: 0.6447718143463135
Epoch: 16/300 - Train loss: 0.6451966166496277, Validation loss: 0.6419052481651306
Epoch: 17/300 - Train loss: 0.6419104337692261, Validation loss: 0.6382787823677063
Epoch: 18/300 - Train loss: 0.6385664939880371, Validation loss: 0.6349356770515442
Epoch: 19/300 - Train loss: 0.6351673007011414, Validation loss: 0.631557047367096
Epoch: 20/300 - Train loss: 0.6317262053489685, Validation loss: 0.6280397772789001
Epoch: 21/300 - Train loss: 0.6282436847686768, Validation loss: 0.6242644786834717
Epoch: 22/300 - Train loss: 0.6247225403785706, Validation loss: 0.6213210821151733
Epoch: 23/300 - Train loss: 0.6211668848991394, Validation loss: 0.6171695590019226
Epoch: 24/300 - Train loss: 0.6175744533538818, Validation loss: 0.6136427521705627
Epoch: 25/300 - Train loss: 0.6139494776725769, Validation loss: 0.6104608774185181
Epoch: 26/300 - Train loss: 0.6103017330169678, Validation loss: 0.6065177321434021
Epoch: 27/300 - Train loss: 0.6066362261772156, Validation loss: 0.6029103994369507
Epoch: 28/300 - Train loss: 0.6029554605484009, Validation loss: 0.5991049408912659
Epoch: 29/300 - Train loss: 0.599265456199646, Validation loss: 0.595029890537262
Epoch: 30/300 - Train loss: 0.5955649018287659, Validation loss: 0.5917928218841553
Epoch: 31/300 - Train loss: 0.5918564796447754, Validation loss: 0.5880216360092163
Epoch: 32/300 - Train loss: 0.5881390571594238, Validation loss: 0.5838722586631775
Epoch: 33/300 - Train loss: 0.5844209790229797, Validation loss: 0.580621600151062
Epoch: 34/300 - Train loss: 0.5807011723518372, Validation loss: 0.5771823525428772
Epoch: 35/300 - Train loss: 0.5769838690757751, Validation loss: 0.5728112459182739
Epoch: 36/300 - Train loss: 0.5732742547988892, Validation loss: 0.5694719552993774
Epoch: 37/300 - Train loss: 0.5695791244506836, Validation loss: 0.56587815284729
Epoch: 38/300 - Train loss: 0.5658998489379883, Validation loss: 0.5620967745780945
Epoch: 39/300 - Train loss: 0.5622398853302002, Validation loss: 0.5587185025215149
Epoch: 40/300 - Train loss: 0.5586012601852417, Validation loss: 0.5548140406608582
Epoch: 41/300 - Train loss: 0.5549876093864441, Validation loss: 0.551246166229248
Epoch: 42/300 - Train loss: 0.5514062643051147, Validation loss: 0.5475063323974609
Epoch: 43/300 - Train loss: 0.5478598475456238, Validation loss: 0.5440018177032471
Epoch: 44/300 - Train loss: 0.5443564653396606, Validation loss: 0.5404744744300842
Epoch: 45/300 - Train loss: 0.5408955216407776, Validation loss: 0.537158727645874
Epoch: 46/300 - Train loss: 0.5374794602394104, Validation loss: 0.5338345766067505
Epoch: 47/300 - Train loss: 0.5341122150421143, Validation loss: 0.5309603214263916
Epoch: 48/300 - Train loss: 0.5307953953742981, Validation loss: 0.5274444222450256
Epoch: 49/300 - Train loss: 0.5275291800498962, Validation loss: 0.5244929194450378
Epoch: 50/300 - Train loss: 0.5243188142776489, Validation loss: 0.5200718641281128
Epoch: 51/300 - Train loss: 0.5211668610572815, Validation loss: 0.5178511738777161
Epoch: 52/300 - Train loss: 0.5180737376213074, Validation loss: 0.5147485136985779
Epoch: 53/300 - Train loss: 0.5150404572486877, Validation loss: 0.511357307434082
Epoch: 54/300 - Train loss: 0.5120686292648315, Validation loss: 0.509477972984314
Epoch: 55/300 - Train loss: 0.5091586112976074, Validation loss: 0.5063580870628357
Epoch: 56/300 - Train loss: 0.5063111782073975, Validation loss: 0.5028974413871765
Epoch: 57/300 - Train loss: 0.5035254955291748, Validation loss: 0.5003878474235535
Epoch: 58/300 - Train loss: 0.5008021593093872, Validation loss: 0.4975539445877075
Epoch: 59/300 - Train loss: 0.49814099073410034, Validation loss: 0.49505797028541565
Epoch: 60/300 - Train loss: 0.49554136395454407, Validation loss: 0.4921824336051941
Epoch: 61/300 - Train loss: 0.49300068616867065, Validation loss: 0.4897836744785309
Epoch: 62/300 - Train loss: 0.4905179440975189, Validation loss: 0.48785796761512756
Epoch: 63/300 - Train loss: 0.4880932569503784, Validation loss: 0.4854670464992523
Epoch: 64/300 - Train loss: 0.48572441935539246, Validation loss: 0.4836054742336273
Epoch: 65/300 - Train loss: 0.4834100008010864, Validation loss: 0.4805987775325775
Epoch: 66/300 - Train loss: 0.48114970326423645, Validation loss: 0.47940027713775635
Epoch: 67/300 - Train loss: 0.4789413511753082, Validation loss: 0.4770928919315338
Epoch: 68/300 - Train loss: 0.47678348422050476, Validation loss: 0.4743976891040802
Epoch: 69/300 - Train loss: 0.4746744632720947, Validation loss: 0.4725683629512787
Epoch: 70/300 - Train loss: 0.4726124703884125, Validation loss: 0.4703648090362549
Epoch: 71/300 - Train loss: 0.4705962836742401, Validation loss: 0.46807923913002014
Epoch: 72/300 - Train loss: 0.4686245322227478, Validation loss: 0.46708375215530396
Epoch: 73/300 - Train loss: 0.4666963517665863, Validation loss: 0.4653624892234802
Epoch: 74/300 - Train loss: 0.4648103415966034, Validation loss: 0.46185392141342163
Epoch: 75/300 - Train loss: 0.46296465396881104, Validation loss: 0.4602443277835846
Epoch: 76/300 - Train loss: 0.4611579179763794, Validation loss: 0.45863306522369385
Epoch: 77/300 - Train loss: 0.45938852429389954, Validation loss: 0.45869287848472595
Epoch: 78/300 - Train loss: 0.4576556086540222, Validation loss: 0.4553297758102417
Epoch: 79/300 - Train loss: 0.45595815777778625, Validation loss: 0.45591917634010315
Epoch: 80/300 - Train loss: 0.45429542660713196, Validation loss: 0.45231539011001587
Epoch: 81/300 - Train loss: 0.4526660442352295, Validation loss: 0.4505976438522339
Epoch: 82/300 - Train loss: 0.45106807351112366, Validation loss: 0.44852060079574585
Epoch: 83/300 - Train loss: 0.4495011866092682, Validation loss: 0.44802170991897583
Epoch: 84/300 - Train loss: 0.4479641914367676, Validation loss: 0.4450446367263794
Epoch: 85/300 - Train loss: 0.4464569687843323, Validation loss: 0.44403111934661865
Epoch: 86/300 - Train loss: 0.4449787139892578, Validation loss: 0.4440003037452698
Epoch: 87/300 - Train loss: 0.4435287117958069, Validation loss: 0.4415750801563263
Epoch: 88/300 - Train loss: 0.4421062171459198, Validation loss: 0.44064977765083313
Epoch: 89/300 - Train loss: 0.4407102167606354, Validation loss: 0.43928131461143494
Epoch: 90/300 - Train loss: 0.4393404424190521, Validation loss: 0.4370645582675934
Epoch: 91/300 - Train loss: 0.4379962086677551, Validation loss: 0.43534213304519653
Epoch: 92/300 - Train loss: 0.43667659163475037, Validation loss: 0.4337087571620941
Epoch: 93/300 - Train loss: 0.43538057804107666, Validation loss: 0.43352600932121277
Epoch: 94/300 - Train loss: 0.4341082274913788, Validation loss: 0.4313909411430359
Epoch: 95/300 - Train loss: 0.43285855650901794, Validation loss: 0.4310486614704132
Epoch: 96/300 - Train loss: 0.43163061141967773, Validation loss: 0.4302617311477661
Epoch: 97/300 - Train loss: 0.43042388558387756, Validation loss: 0.42861291766166687
Epoch: 98/300 - Train loss: 0.4292377829551697, Validation loss: 0.42591530084609985
Epoch: 99/300 - Train loss: 0.4280717074871063, Validation loss: 0.42511287331581116
Epoch: 100/300 - Train loss: 0.426925390958786, Validation loss: 0.42514461278915405
Epoch: 101/300 - Train loss: 0.425798624753952, Validation loss: 0.4244939088821411
Epoch: 102/300 - Train loss: 0.42469021677970886, Validation loss: 0.4214651584625244
Epoch: 103/300 - Train loss: 0.42360034584999084, Validation loss: 0.4212363660335541
Epoch: 104/300 - Train loss: 0.42252829670906067, Validation loss: 0.42103755474090576
Epoch: 105/300 - Train loss: 0.421473890542984, Validation loss: 0.42041391134262085
Epoch: 106/300 - Train loss: 0.420436829328537, Validation loss: 0.4186098575592041
Epoch: 107/300 - Train loss: 0.4194161295890808, Validation loss: 0.41715654730796814
Epoch: 108/300 - Train loss: 0.4184117913246155, Validation loss: 0.4154340922832489
Epoch: 109/300 - Train loss: 0.41742339730262756, Validation loss: 0.41579142212867737
Epoch: 110/300 - Train loss: 0.41645047068595886, Validation loss: 0.41382524371147156
Epoch: 111/300 - Train loss: 0.4154927134513855, Validation loss: 0.4127996563911438
Epoch: 112/300 - Train loss: 0.41454946994781494, Validation loss: 0.4121626615524292
Epoch: 113/300 - Train loss: 0.4136205315589905, Validation loss: 0.41203001141548157
Epoch: 114/300 - Train loss: 0.4127059578895569, Validation loss: 0.41055765748023987
Epoch: 115/300 - Train loss: 0.4118053913116455, Validation loss: 0.4102028012275696
Epoch: 116/300 - Train loss: 0.4109184741973877, Validation loss: 0.4097955524921417
Epoch: 117/300 - Train loss: 0.4100446105003357, Validation loss: 0.40706637501716614
Epoch: 118/300 - Train loss: 0.40918397903442383, Validation loss: 0.40652456879615784
Epoch: 119/300 - Train loss: 0.40833529829978943, Validation loss: 0.40580832958221436
Epoch: 120/300 - Train loss: 0.40749895572662354, Validation loss: 0.4047698974609375
Epoch: 121/300 - Train loss: 0.4066745638847351, Validation loss: 0.4045657813549042
Epoch: 122/300 - Train loss: 0.40586236119270325, Validation loss: 0.4045845568180084
Epoch: 123/300 - Train loss: 0.4050619304180145, Validation loss: 0.4032468795776367
Epoch: 124/300 - Train loss: 0.4042726159095764, Validation loss: 0.4026898443698883
Epoch: 125/300 - Train loss: 0.4034945070743561, Validation loss: 0.4014170467853546
Epoch: 126/300 - Train loss: 0.40272676944732666, Validation loss: 0.40056225657463074
Epoch: 127/300 - Train loss: 0.4019697606563568, Validation loss: 0.40074533224105835
Epoch: 128/300 - Train loss: 0.40122348070144653, Validation loss: 0.39936766028404236
Epoch: 129/300 - Train loss: 0.4004877805709839, Validation loss: 0.3983483910560608
Epoch: 130/300 - Train loss: 0.39976221323013306, Validation loss: 0.3984872102737427
Epoch: 131/300 - Train loss: 0.399046927690506, Validation loss: 0.3960728049278259
Epoch: 132/300 - Train loss: 0.3983416259288788, Validation loss: 0.3967081606388092
Epoch: 133/300 - Train loss: 0.3976452946662903, Validation loss: 0.3961624205112457
Epoch: 134/300 - Train loss: 0.39695799350738525, Validation loss: 0.3948296308517456
Epoch: 135/300 - Train loss: 0.3962799310684204, Validation loss: 0.3943331837654114
Epoch: 136/300 - Train loss: 0.39561113715171814, Validation loss: 0.39319944381713867
Epoch: 137/300 - Train loss: 0.3949519395828247, Validation loss: 0.3924853801727295
Epoch: 138/300 - Train loss: 0.3943021297454834, Validation loss: 0.3920004665851593
Epoch: 139/300 - Train loss: 0.393661230802536, Validation loss: 0.39226818084716797
Epoch: 140/300 - Train loss: 0.39302921295166016, Validation loss: 0.3913784623146057
Epoch: 141/300 - Train loss: 0.3924057185649872, Validation loss: 0.3904300034046173
Epoch: 142/300 - Train loss: 0.3917900025844574, Validation loss: 0.3891258239746094
Epoch: 143/300 - Train loss: 0.39118146896362305, Validation loss: 0.3897961378097534
Epoch: 144/300 - Train loss: 0.3905808627605438, Validation loss: 0.388400137424469
Epoch: 145/300 - Train loss: 0.3899885416030884, Validation loss: 0.38825082778930664
