Epoch: 1/300 - Train loss: 0.6954054832458496, Validation loss: 0.6932768821716309
Epoch: 2/300 - Train loss: 0.6934164762496948, Validation loss: 0.6914118528366089
Epoch: 3/300 - Train loss: 0.6915009617805481, Validation loss: 0.6895374059677124
Epoch: 4/300 - Train loss: 0.6895983815193176, Validation loss: 0.6875988841056824
Epoch: 5/300 - Train loss: 0.6876604557037354, Validation loss: 0.6856269836425781
Epoch: 6/300 - Train loss: 0.6856448650360107, Validation loss: 0.6835147738456726
Epoch: 7/300 - Train loss: 0.6835209131240845, Validation loss: 0.6812929511070251
Epoch: 8/300 - Train loss: 0.6812708973884583, Validation loss: 0.6789147853851318
Epoch: 9/300 - Train loss: 0.6788723468780518, Validation loss: 0.6764177083969116
Epoch: 10/300 - Train loss: 0.6763083338737488, Validation loss: 0.673721194267273
Epoch: 11/300 - Train loss: 0.6735680103302002, Validation loss: 0.6707967519760132
Epoch: 12/300 - Train loss: 0.670644223690033, Validation loss: 0.6677366495132446
Epoch: 13/300 - Train loss: 0.6675309538841248, Validation loss: 0.66449373960495
Epoch: 14/300 - Train loss: 0.6642266511917114, Validation loss: 0.6610313653945923
Epoch: 15/300 - Train loss: 0.6607306003570557, Validation loss: 0.6574445366859436
Epoch: 16/300 - Train loss: 0.6570485830307007, Validation loss: 0.6536067128181458
Epoch: 17/300 - Train loss: 0.6531855463981628, Validation loss: 0.6496971845626831
Epoch: 18/300 - Train loss: 0.6491478681564331, Validation loss: 0.6454641222953796
Epoch: 19/300 - Train loss: 0.6449413299560547, Validation loss: 0.6412268877029419
Epoch: 20/300 - Train loss: 0.6405805945396423, Validation loss: 0.6367354393005371
Epoch: 21/300 - Train loss: 0.6360658407211304, Validation loss: 0.6322017908096313
Epoch: 22/300 - Train loss: 0.6314053535461426, Validation loss: 0.627540111541748
Epoch: 23/300 - Train loss: 0.6266123056411743, Validation loss: 0.6226993203163147
Epoch: 24/300 - Train loss: 0.6216914653778076, Validation loss: 0.6178264617919922
Epoch: 25/300 - Train loss: 0.6166578531265259, Validation loss: 0.6128435730934143
Epoch: 26/300 - Train loss: 0.6115262508392334, Validation loss: 0.6076527237892151
Epoch: 27/300 - Train loss: 0.6063065528869629, Validation loss: 0.6024192571640015
Epoch: 28/300 - Train loss: 0.6010066866874695, Validation loss: 0.5971693396568298
Epoch: 29/300 - Train loss: 0.5956416130065918, Validation loss: 0.5917443037033081
Epoch: 30/300 - Train loss: 0.590215265750885, Validation loss: 0.5866050124168396
Epoch: 31/300 - Train loss: 0.5847326517105103, Validation loss: 0.58128821849823
Epoch: 32/300 - Train loss: 0.5792063474655151, Validation loss: 0.5756915807723999
Epoch: 33/300 - Train loss: 0.5736460089683533, Validation loss: 0.5702600479125977
Epoch: 34/300 - Train loss: 0.5680572390556335, Validation loss: 0.56472247838974
Epoch: 35/300 - Train loss: 0.5624460577964783, Validation loss: 0.559249997138977
Epoch: 36/300 - Train loss: 0.5568192601203918, Validation loss: 0.5537952184677124
Epoch: 37/300 - Train loss: 0.5511809587478638, Validation loss: 0.5480806231498718
Epoch: 38/300 - Train loss: 0.5455376505851746, Validation loss: 0.5426079034805298
Epoch: 39/300 - Train loss: 0.5398935079574585, Validation loss: 0.5371488928794861
Epoch: 40/300 - Train loss: 0.5342538952827454, Validation loss: 0.5317006707191467
Epoch: 41/300 - Train loss: 0.5286247134208679, Validation loss: 0.5261119604110718
Epoch: 42/300 - Train loss: 0.5230104923248291, Validation loss: 0.5208451747894287
Epoch: 43/300 - Train loss: 0.517418384552002, Validation loss: 0.5154708623886108
Epoch: 44/300 - Train loss: 0.5118539333343506, Validation loss: 0.509789764881134
Epoch: 45/300 - Train loss: 0.5063222050666809, Validation loss: 0.5044944882392883
Epoch: 46/300 - Train loss: 0.5008282661437988, Validation loss: 0.49922776222229004
Epoch: 47/300 - Train loss: 0.49537724256515503, Validation loss: 0.49404507875442505
Epoch: 48/300 - Train loss: 0.48997411131858826, Validation loss: 0.48880845308303833
Epoch: 49/300 - Train loss: 0.4846231937408447, Validation loss: 0.4834449887275696
Epoch: 50/300 - Train loss: 0.47932854294776917, Validation loss: 0.47879597544670105
Epoch: 51/300 - Train loss: 0.4740944504737854, Validation loss: 0.47330552339553833
Epoch: 52/300 - Train loss: 0.46892470121383667, Validation loss: 0.4682958722114563
Epoch: 53/300 - Train loss: 0.4638226628303528, Validation loss: 0.4636264145374298
Epoch: 54/300 - Train loss: 0.4587912857532501, Validation loss: 0.4588865339756012
Epoch: 55/300 - Train loss: 0.4538336992263794, Validation loss: 0.45420682430267334
Epoch: 56/300 - Train loss: 0.44895249605178833, Validation loss: 0.44926950335502625
Epoch: 57/300 - Train loss: 0.444149911403656, Validation loss: 0.4448934495449066
Epoch: 58/300 - Train loss: 0.4394280016422272, Validation loss: 0.44028759002685547
Epoch: 59/300 - Train loss: 0.4347885549068451, Validation loss: 0.4357306659221649
Epoch: 60/300 - Train loss: 0.4302327632904053, Validation loss: 0.4320414066314697
Epoch: 61/300 - Train loss: 0.42576146125793457, Validation loss: 0.42723146080970764
Epoch: 62/300 - Train loss: 0.4213756024837494, Validation loss: 0.4236913025379181
Epoch: 63/300 - Train loss: 0.41707557439804077, Validation loss: 0.41892409324645996
Epoch: 64/300 - Train loss: 0.4128614068031311, Validation loss: 0.4150357246398926
Epoch: 65/300 - Train loss: 0.4087332785129547, Validation loss: 0.4113888442516327
Epoch: 66/300 - Train loss: 0.40469104051589966, Validation loss: 0.40711092948913574
Epoch: 67/300 - Train loss: 0.4007341265678406, Validation loss: 0.40341174602508545
Epoch: 68/300 - Train loss: 0.3968621492385864, Validation loss: 0.400461882352829
Epoch: 69/300 - Train loss: 0.39307424426078796, Validation loss: 0.3963317275047302
Epoch: 70/300 - Train loss: 0.3893694579601288, Validation loss: 0.3923960030078888
Epoch: 71/300 - Train loss: 0.3857465088367462, Validation loss: 0.38941094279289246
Epoch: 72/300 - Train loss: 0.38220423460006714, Validation loss: 0.38623690605163574
Epoch: 73/300 - Train loss: 0.37874138355255127, Validation loss: 0.3825976252555847
Epoch: 74/300 - Train loss: 0.37535664439201355, Validation loss: 0.3796006143093109
Epoch: 75/300 - Train loss: 0.37204837799072266, Validation loss: 0.3767991364002228
Epoch: 76/300 - Train loss: 0.36881476640701294, Validation loss: 0.37334591150283813
Epoch: 77/300 - Train loss: 0.3656543791294098, Validation loss: 0.3703130781650543
Epoch: 78/300 - Train loss: 0.3625657260417938, Validation loss: 0.36751681566238403
Epoch: 79/300 - Train loss: 0.35954713821411133, Validation loss: 0.3648431599140167
Epoch: 80/300 - Train loss: 0.356596976518631, Validation loss: 0.36227455735206604
Epoch: 81/300 - Train loss: 0.35371336340904236, Validation loss: 0.3592435419559479
Epoch: 82/300 - Train loss: 0.350894570350647, Validation loss: 0.3559172749519348
Epoch: 83/300 - Train loss: 0.34813904762268066, Validation loss: 0.3533710241317749
Epoch: 84/300 - Train loss: 0.34544500708580017, Validation loss: 0.35146841406822205
Epoch: 85/300 - Train loss: 0.34281039237976074, Validation loss: 0.3490239083766937
Epoch: 86/300 - Train loss: 0.3402336537837982, Validation loss: 0.34618568420410156
Epoch: 87/300 - Train loss: 0.33771345019340515, Validation loss: 0.3440338373184204
Epoch: 88/300 - Train loss: 0.3352479040622711, Validation loss: 0.34138280153274536
Epoch: 89/300 - Train loss: 0.33283570408821106, Validation loss: 0.33872190117836
Epoch: 90/300 - Train loss: 0.33047550916671753, Validation loss: 0.33696436882019043
Epoch: 91/300 - Train loss: 0.32816532254219055, Validation loss: 0.3345537781715393
Epoch: 92/300 - Train loss: 0.325903981924057, Validation loss: 0.33224794268608093
Epoch: 93/300 - Train loss: 0.3236897885799408, Validation loss: 0.33043399453163147
Epoch: 94/300 - Train loss: 0.3215213418006897, Validation loss: 0.3275138735771179
Epoch: 95/300 - Train loss: 0.3193974494934082, Validation loss: 0.3261188864707947
Epoch: 96/300 - Train loss: 0.317316472530365, Validation loss: 0.32499006390571594
Epoch: 97/300 - Train loss: 0.3152773380279541, Validation loss: 0.32254526019096375
Epoch: 98/300 - Train loss: 0.3132787346839905, Validation loss: 0.3201189637184143
Epoch: 99/300 - Train loss: 0.3113195598125458, Validation loss: 0.31839805841445923
Epoch: 100/300 - Train loss: 0.3093986511230469, Validation loss: 0.3171132504940033
Epoch: 101/300 - Train loss: 0.3075147271156311, Validation loss: 0.31462228298187256
Epoch: 102/300 - Train loss: 0.30566635727882385, Validation loss: 0.3132520914077759
Epoch: 103/300 - Train loss: 0.3038521409034729, Validation loss: 0.31069934368133545
Epoch: 104/300 - Train loss: 0.30207139253616333, Validation loss: 0.30950668454170227
Epoch: 105/300 - Train loss: 0.30032333731651306, Validation loss: 0.3081580102443695
Epoch: 106/300 - Train loss: 0.2986067235469818, Validation loss: 0.30662041902542114
Epoch: 107/300 - Train loss: 0.2969208359718323, Validation loss: 0.30484628677368164
Epoch: 108/300 - Train loss: 0.29526495933532715, Validation loss: 0.3030160069465637
Epoch: 109/300 - Train loss: 0.2936381697654724, Validation loss: 0.30107319355010986
Epoch: 110/300 - Train loss: 0.2920393943786621, Validation loss: 0.299934059381485
Epoch: 111/300 - Train loss: 0.29046788811683655, Validation loss: 0.29844436049461365
Epoch: 112/300 - Train loss: 0.2889227867126465, Validation loss: 0.29717332124710083
Epoch: 113/300 - Train loss: 0.2874033749103546, Validation loss: 0.29544776678085327
Epoch: 114/300 - Train loss: 0.28590890765190125, Validation loss: 0.2937910556793213
Epoch: 115/300 - Train loss: 0.2844386398792267, Validation loss: 0.2926008403301239
Epoch: 116/300 - Train loss: 0.2829919159412384, Validation loss: 0.29093465209007263
Epoch: 117/300 - Train loss: 0.28156810998916626, Validation loss: 0.28978291153907776
Epoch: 118/300 - Train loss: 0.2801664173603058, Validation loss: 0.2886517643928528
Epoch: 119/300 - Train loss: 0.27878639101982117, Validation loss: 0.2870902419090271
Epoch: 120/300 - Train loss: 0.2774275839328766, Validation loss: 0.2857287526130676
Epoch: 121/300 - Train loss: 0.2760893404483795, Validation loss: 0.2851361334323883
Epoch: 122/300 - Train loss: 0.2747713029384613, Validation loss: 0.28329306840896606
Epoch: 123/300 - Train loss: 0.2734729051589966, Validation loss: 0.28161385655403137
Epoch: 124/300 - Train loss: 0.2721937298774719, Validation loss: 0.2804877758026123
Epoch: 125/300 - Train loss: 0.27093327045440674, Validation loss: 0.27936625480651855
Epoch: 126/300 - Train loss: 0.2696910798549652, Validation loss: 0.27821874618530273
Epoch: 127/300 - Train loss: 0.26846662163734436, Validation loss: 0.2774992883205414
Epoch: 128/300 - Train loss: 0.2672596275806427, Validation loss: 0.2756791114807129
Epoch: 129/300 - Train loss: 0.266069620847702, Validation loss: 0.27503880858421326
Epoch: 130/300 - Train loss: 0.2648961842060089, Validation loss: 0.2740292549133301
Epoch: 131/300 - Train loss: 0.26373884081840515, Validation loss: 0.27235648036003113
Epoch: 132/300 - Train loss: 0.26259735226631165, Validation loss: 0.27130061388015747
Epoch: 133/300 - Train loss: 0.26147136092185974, Validation loss: 0.2703595757484436
Epoch: 134/300 - Train loss: 0.26036062836647034, Validation loss: 0.2691538631916046
Epoch: 135/300 - Train loss: 0.25926473736763, Validation loss: 0.26810315251350403
Epoch: 136/300 - Train loss: 0.25818347930908203, Validation loss: 0.2665465772151947
Epoch: 137/300 - Train loss: 0.2571163773536682, Validation loss: 0.26592305302619934
Epoch: 138/300 - Train loss: 0.256063312292099, Validation loss: 0.2649540305137634
Epoch: 139/300 - Train loss: 0.2550239562988281, Validation loss: 0.2638104259967804
Epoch: 140/300 - Train loss: 0.2539980411529541, Validation loss: 0.2630634009838104
Epoch: 141/300 - Train loss: 0.2529853284358978, Validation loss: 0.26194387674331665
Epoch: 142/300 - Train loss: 0.2519855201244354, Validation loss: 0.26119908690452576
Epoch: 143/300 - Train loss: 0.2509984076023102, Validation loss: 0.260152131319046
Epoch: 144/300 - Train loss: 0.2500237822532654, Validation loss: 0.25912174582481384
Epoch: 145/300 - Train loss: 0.24906131625175476, Validation loss: 0.258010596036911
Epoch: 146/300 - Train loss: 0.2481108456850052, Validation loss: 0.25736165046691895
Epoch: 147/300 - Train loss: 0.24717211723327637, Validation loss: 0.2561149597167969
Epoch: 148/300 - Train loss: 0.24624499678611755, Validation loss: 0.25611451268196106
Epoch: 149/300 - Train loss: 0.24532923102378845, Validation loss: 0.25429609417915344
Epoch: 150/300 - Train loss: 0.24442467093467712, Validation loss: 0.2533981204032898
Epoch: 151/300 - Train loss: 0.24353115260601044, Validation loss: 0.25290319323539734
Epoch: 152/300 - Train loss: 0.2426484227180481, Validation loss: 0.252438485622406
Epoch: 153/300 - Train loss: 0.24177634716033936, Validation loss: 0.25116369128227234
Epoch: 154/300 - Train loss: 0.24091465771198273, Validation loss: 0.24981379508972168
Epoch: 155/300 - Train loss: 0.24006327986717224, Validation loss: 0.24956612288951874
Epoch: 156/300 - Train loss: 0.23922191560268402, Validation loss: 0.2489478886127472
Epoch: 157/300 - Train loss: 0.23839056491851807, Validation loss: 0.24768897891044617
Epoch: 158/300 - Train loss: 0.23756907880306244, Validation loss: 0.24694456160068512
Epoch: 159/300 - Train loss: 0.236757293343544, Validation loss: 0.24606497585773468
Epoch: 160/300 - Train loss: 0.23595494031906128, Validation loss: 0.24534021317958832
Epoch: 161/300 - Train loss: 0.2351619154214859, Validation loss: 0.24451366066932678
Epoch: 162/300 - Train loss: 0.2343781292438507, Validation loss: 0.2438749223947525
Epoch: 163/300 - Train loss: 0.23360340297222137, Validation loss: 0.2432928830385208
Epoch: 164/300 - Train loss: 0.23283761739730835, Validation loss: 0.24279500544071198
Epoch: 165/300 - Train loss: 0.2320805937051773, Validation loss: 0.24159389734268188
Epoch: 166/300 - Train loss: 0.23133227229118347, Validation loss: 0.24122868478298187
Epoch: 167/300 - Train loss: 0.23059244453907013, Validation loss: 0.24066895246505737
Epoch: 168/300 - Train loss: 0.22986094653606415, Validation loss: 0.23984980583190918
Epoch: 169/300 - Train loss: 0.22913777828216553, Validation loss: 0.23861435055732727
Epoch: 170/300 - Train loss: 0.22842276096343994, Validation loss: 0.2376992106437683
Epoch: 171/300 - Train loss: 0.22771576046943665, Validation loss: 0.2379997968673706
Epoch: 172/300 - Train loss: 0.22701668739318848, Validation loss: 0.2370564341545105
Epoch: 173/300 - Train loss: 0.2263254076242447, Validation loss: 0.2367931306362152
Epoch: 174/300 - Train loss: 0.22564178705215454, Validation loss: 0.23548084497451782
Epoch: 175/300 - Train loss: 0.2249656766653061, Validation loss: 0.23461312055587769
Epoch: 176/300 - Train loss: 0.22429676353931427, Validation loss: 0.23415258526802063
Epoch: 177/300 - Train loss: 0.22363510727882385, Validation loss: 0.23313799500465393
Epoch: 178/300 - Train loss: 0.2229805886745453, Validation loss: 0.2329106330871582
Epoch: 179/300 - Train loss: 0.22233323752880096, Validation loss: 0.2319716066122055
Epoch: 180/300 - Train loss: 0.2216927856206894, Validation loss: 0.23151333630084991
Epoch: 181/300 - Train loss: 0.22105923295021057, Validation loss: 0.2307056039571762
Epoch: 182/300 - Train loss: 0.22043247520923615, Validation loss: 0.23059459030628204
Epoch: 183/300 - Train loss: 0.21981248259544373, Validation loss: 0.229351207613945
Epoch: 184/300 - Train loss: 0.21919922530651093, Validation loss: 0.22905127704143524
Epoch: 185/300 - Train loss: 0.2185925394296646, Validation loss: 0.22865428030490875
Epoch: 186/300 - Train loss: 0.21799229085445404, Validation loss: 0.22883126139640808
