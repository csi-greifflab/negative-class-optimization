Epoch: 1/300 - Train loss: 0.7003690004348755, Validation loss: 0.6949483752250671
Epoch: 2/300 - Train loss: 0.6969715356826782, Validation loss: 0.6920295357704163
Epoch: 3/300 - Train loss: 0.6937497854232788, Validation loss: 0.688929557800293
Epoch: 4/300 - Train loss: 0.6906112432479858, Validation loss: 0.6856817603111267
Epoch: 5/300 - Train loss: 0.6874859929084778, Validation loss: 0.682827353477478
Epoch: 6/300 - Train loss: 0.684310793876648, Validation loss: 0.6794422268867493
Epoch: 7/300 - Train loss: 0.6810230612754822, Validation loss: 0.6761464476585388
Epoch: 8/300 - Train loss: 0.6775783896446228, Validation loss: 0.6726746559143066
Epoch: 9/300 - Train loss: 0.673949658870697, Validation loss: 0.6689105033874512
Epoch: 10/300 - Train loss: 0.6701277494430542, Validation loss: 0.6651546359062195
Epoch: 11/300 - Train loss: 0.6661015748977661, Validation loss: 0.6608107089996338
Epoch: 12/300 - Train loss: 0.661880373954773, Validation loss: 0.6566956043243408
Epoch: 13/300 - Train loss: 0.6574758887290955, Validation loss: 0.6522849798202515
Epoch: 14/300 - Train loss: 0.6529074907302856, Validation loss: 0.6472713351249695
Epoch: 15/300 - Train loss: 0.6481950283050537, Validation loss: 0.6426952481269836
Epoch: 16/300 - Train loss: 0.6433678269386292, Validation loss: 0.6379204988479614
Epoch: 17/300 - Train loss: 0.6384422183036804, Validation loss: 0.6330943703651428
Epoch: 18/300 - Train loss: 0.6334377527236938, Validation loss: 0.6281542181968689
Epoch: 19/300 - Train loss: 0.6283643841743469, Validation loss: 0.6232162714004517
Epoch: 20/300 - Train loss: 0.6232377290725708, Validation loss: 0.6180148720741272
Epoch: 21/300 - Train loss: 0.6180627942085266, Validation loss: 0.6128157377243042
Epoch: 22/300 - Train loss: 0.6128451824188232, Validation loss: 0.6077536344528198
Epoch: 23/300 - Train loss: 0.6075873374938965, Validation loss: 0.6028364896774292
Epoch: 24/300 - Train loss: 0.6022934913635254, Validation loss: 0.5972630381584167
Epoch: 25/300 - Train loss: 0.5969687700271606, Validation loss: 0.5923570990562439
Epoch: 26/300 - Train loss: 0.5916168689727783, Validation loss: 0.5870561003684998
Epoch: 27/300 - Train loss: 0.586239755153656, Validation loss: 0.5816823840141296
Epoch: 28/300 - Train loss: 0.5808443427085876, Validation loss: 0.5764811038970947
Epoch: 29/300 - Train loss: 0.5754351019859314, Validation loss: 0.5711694359779358
Epoch: 30/300 - Train loss: 0.5700165629386902, Validation loss: 0.566141664981842
Epoch: 31/300 - Train loss: 0.564593493938446, Validation loss: 0.5606982707977295
Epoch: 32/300 - Train loss: 0.559168815612793, Validation loss: 0.5555155873298645
Epoch: 33/300 - Train loss: 0.5537464022636414, Validation loss: 0.5499976277351379
Epoch: 34/300 - Train loss: 0.5483281016349792, Validation loss: 0.5449036359786987
Epoch: 35/300 - Train loss: 0.5429167747497559, Validation loss: 0.5398081541061401
Epoch: 36/300 - Train loss: 0.5375156998634338, Validation loss: 0.5344794988632202
Epoch: 37/300 - Train loss: 0.532129168510437, Validation loss: 0.529283881187439
Epoch: 38/300 - Train loss: 0.5267608165740967, Validation loss: 0.5242555737495422
Epoch: 39/300 - Train loss: 0.5214141011238098, Validation loss: 0.5192728638648987
Epoch: 40/300 - Train loss: 0.5160926580429077, Validation loss: 0.5138959288597107
Epoch: 41/300 - Train loss: 0.5107985734939575, Validation loss: 0.5087825655937195
Epoch: 42/300 - Train loss: 0.5055356621742249, Validation loss: 0.5036787390708923
Epoch: 43/300 - Train loss: 0.5003072619438171, Validation loss: 0.49871113896369934
Epoch: 44/300 - Train loss: 0.4951169490814209, Validation loss: 0.4936821460723877
Epoch: 45/300 - Train loss: 0.48996827006340027, Validation loss: 0.48855656385421753
Epoch: 46/300 - Train loss: 0.4848634600639343, Validation loss: 0.48408225178718567
Epoch: 47/300 - Train loss: 0.4798049330711365, Validation loss: 0.47874191403388977
Epoch: 48/300 - Train loss: 0.47479453682899475, Validation loss: 0.4742422103881836
Epoch: 49/300 - Train loss: 0.4698357582092285, Validation loss: 0.4692225754261017
Epoch: 50/300 - Train loss: 0.46493056416511536, Validation loss: 0.4646179676055908
Epoch: 51/300 - Train loss: 0.46008139848709106, Validation loss: 0.45979800820350647
Epoch: 52/300 - Train loss: 0.45529094338417053, Validation loss: 0.4554072916507721
Epoch: 53/300 - Train loss: 0.45056024193763733, Validation loss: 0.4508896768093109
Epoch: 54/300 - Train loss: 0.4458915591239929, Validation loss: 0.4465121328830719
Epoch: 55/300 - Train loss: 0.4412862956523895, Validation loss: 0.44196900725364685
Epoch: 56/300 - Train loss: 0.4367457926273346, Validation loss: 0.43790948390960693
Epoch: 57/300 - Train loss: 0.4322713613510132, Validation loss: 0.43305841088294983
Epoch: 58/300 - Train loss: 0.4278644323348999, Validation loss: 0.42879706621170044
Epoch: 59/300 - Train loss: 0.4235258996486664, Validation loss: 0.4248867332935333
Epoch: 60/300 - Train loss: 0.4192562699317932, Validation loss: 0.4208677411079407
Epoch: 61/300 - Train loss: 0.4150567650794983, Validation loss: 0.4171313941478729
Epoch: 62/300 - Train loss: 0.4109276831150055, Validation loss: 0.41280531883239746
Epoch: 63/300 - Train loss: 0.4068700671195984, Validation loss: 0.40943172574043274
Epoch: 64/300 - Train loss: 0.40288400650024414, Validation loss: 0.40532636642456055
Epoch: 65/300 - Train loss: 0.3989699184894562, Validation loss: 0.40190455317497253
Epoch: 66/300 - Train loss: 0.3951275646686554, Validation loss: 0.39834538102149963
Epoch: 67/300 - Train loss: 0.39135581254959106, Validation loss: 0.3943764865398407
Epoch: 68/300 - Train loss: 0.38765525817871094, Validation loss: 0.39091166853904724
Epoch: 69/300 - Train loss: 0.38402530550956726, Validation loss: 0.38754281401634216
Epoch: 70/300 - Train loss: 0.38046523928642273, Validation loss: 0.3837851583957672
Epoch: 71/300 - Train loss: 0.376974493265152, Validation loss: 0.38110458850860596
Epoch: 72/300 - Train loss: 0.3735528290271759, Validation loss: 0.3775186538696289
Epoch: 73/300 - Train loss: 0.370199590921402, Validation loss: 0.37390586733818054
Epoch: 74/300 - Train loss: 0.36691364645957947, Validation loss: 0.37108179926872253
Epoch: 75/300 - Train loss: 0.36369431018829346, Validation loss: 0.367997944355011
Epoch: 76/300 - Train loss: 0.36054104566574097, Validation loss: 0.3648230731487274
Epoch: 77/300 - Train loss: 0.35745248198509216, Validation loss: 0.36219051480293274
Epoch: 78/300 - Train loss: 0.3544272184371948, Validation loss: 0.3591958284378052
Epoch: 79/300 - Train loss: 0.35146453976631165, Validation loss: 0.35632747411727905
Epoch: 80/300 - Train loss: 0.3485628664493561, Validation loss: 0.35339561104774475
Epoch: 81/300 - Train loss: 0.34572121500968933, Validation loss: 0.3507785201072693
Epoch: 82/300 - Train loss: 0.34293830394744873, Validation loss: 0.34837159514427185
Epoch: 83/300 - Train loss: 0.34021350741386414, Validation loss: 0.34578123688697815
Epoch: 84/300 - Train loss: 0.33754512667655945, Validation loss: 0.34308046102523804
Epoch: 85/300 - Train loss: 0.33493196964263916, Validation loss: 0.34043169021606445
Epoch: 86/300 - Train loss: 0.33237266540527344, Validation loss: 0.3379068076610565
Epoch: 87/300 - Train loss: 0.32986584305763245, Validation loss: 0.33603543043136597
Epoch: 88/300 - Train loss: 0.327410489320755, Validation loss: 0.33329343795776367
Epoch: 89/300 - Train loss: 0.32500484585762024, Validation loss: 0.3310309052467346
Epoch: 90/300 - Train loss: 0.3226480484008789, Validation loss: 0.32904544472694397
Epoch: 91/300 - Train loss: 0.32033854722976685, Validation loss: 0.3264418840408325
Epoch: 92/300 - Train loss: 0.3180745542049408, Validation loss: 0.32411861419677734
Epoch: 93/300 - Train loss: 0.3158549666404724, Validation loss: 0.3224998414516449
Epoch: 94/300 - Train loss: 0.3136790692806244, Validation loss: 0.3201185464859009
Epoch: 95/300 - Train loss: 0.31154537200927734, Validation loss: 0.3184205889701843
Epoch: 96/300 - Train loss: 0.30945268273353577, Validation loss: 0.316176176071167
Epoch: 97/300 - Train loss: 0.30740007758140564, Validation loss: 0.3144817352294922
Epoch: 98/300 - Train loss: 0.30538687109947205, Validation loss: 0.31226274371147156
Epoch: 99/300 - Train loss: 0.30341142416000366, Validation loss: 0.31037765741348267
Epoch: 100/300 - Train loss: 0.3014722764492035, Validation loss: 0.3089376389980316
Epoch: 101/300 - Train loss: 0.2995690703392029, Validation loss: 0.3066014349460602
Epoch: 102/300 - Train loss: 0.2977008521556854, Validation loss: 0.3046736717224121
Epoch: 103/300 - Train loss: 0.2958665192127228, Validation loss: 0.3028431236743927
Epoch: 104/300 - Train loss: 0.29406508803367615, Validation loss: 0.30133965611457825
Epoch: 105/300 - Train loss: 0.2922953963279724, Validation loss: 0.2996515929698944
Epoch: 106/300 - Train loss: 0.29055699706077576, Validation loss: 0.2980302572250366
Epoch: 107/300 - Train loss: 0.28884920477867126, Validation loss: 0.29660433530807495
Epoch: 108/300 - Train loss: 0.28717127442359924, Validation loss: 0.2948738932609558
Epoch: 109/300 - Train loss: 0.28552255034446716, Validation loss: 0.29258015751838684
Epoch: 110/300 - Train loss: 0.28390225768089294, Validation loss: 0.29213008284568787
Epoch: 111/300 - Train loss: 0.28230977058410645, Validation loss: 0.28964748978614807
Epoch: 112/300 - Train loss: 0.2807442843914032, Validation loss: 0.28861159086227417
Epoch: 113/300 - Train loss: 0.27920520305633545, Validation loss: 0.2867370545864105
Epoch: 114/300 - Train loss: 0.2776918411254883, Validation loss: 0.28539514541625977
Epoch: 115/300 - Train loss: 0.27620363235473633, Validation loss: 0.283954381942749
Epoch: 116/300 - Train loss: 0.27473968267440796, Validation loss: 0.2831481695175171
Epoch: 117/300 - Train loss: 0.27329933643341064, Validation loss: 0.2814420461654663
Epoch: 118/300 - Train loss: 0.27188199758529663, Validation loss: 0.2803545296192169
Epoch: 119/300 - Train loss: 0.27048730850219727, Validation loss: 0.27891385555267334
Epoch: 120/300 - Train loss: 0.26911479234695435, Validation loss: 0.2773735523223877
Epoch: 121/300 - Train loss: 0.26776373386383057, Validation loss: 0.2761688828468323
Epoch: 122/300 - Train loss: 0.2664340138435364, Validation loss: 0.27442479133605957
Epoch: 123/300 - Train loss: 0.2651250958442688, Validation loss: 0.2730465233325958
Epoch: 124/300 - Train loss: 0.263836145401001, Validation loss: 0.27198493480682373
Epoch: 125/300 - Train loss: 0.26256701350212097, Validation loss: 0.27141380310058594
Epoch: 126/300 - Train loss: 0.2613172233104706, Validation loss: 0.26998171210289
Epoch: 127/300 - Train loss: 0.26008638739585876, Validation loss: 0.26812270283699036
Epoch: 128/300 - Train loss: 0.2588740587234497, Validation loss: 0.2672588527202606
Epoch: 129/300 - Train loss: 0.2576795816421509, Validation loss: 0.2662341892719269
Epoch: 130/300 - Train loss: 0.25650256872177124, Validation loss: 0.2650436460971832
Epoch: 131/300 - Train loss: 0.25534290075302124, Validation loss: 0.26369795203208923
Epoch: 132/300 - Train loss: 0.25420019030570984, Validation loss: 0.26261386275291443
Epoch: 133/300 - Train loss: 0.2530740201473236, Validation loss: 0.2613709270954132
Epoch: 134/300 - Train loss: 0.25196412205696106, Validation loss: 0.2607266306877136
Epoch: 135/300 - Train loss: 0.25087010860443115, Validation loss: 0.25981661677360535
Epoch: 136/300 - Train loss: 0.24979163706302643, Validation loss: 0.2587696611881256
Epoch: 137/300 - Train loss: 0.24872849881649017, Validation loss: 0.2572733163833618
Epoch: 138/300 - Train loss: 0.2476803958415985, Validation loss: 0.25677603483200073
Epoch: 139/300 - Train loss: 0.246646910905838, Validation loss: 0.2552507519721985
Epoch: 140/300 - Train loss: 0.24562783539295197, Validation loss: 0.2546904683113098
Epoch: 141/300 - Train loss: 0.24462296068668365, Validation loss: 0.25337648391723633
Epoch: 142/300 - Train loss: 0.243631973862648, Validation loss: 0.2525522708892822
Epoch: 143/300 - Train loss: 0.24265460669994354, Validation loss: 0.2516281008720398
Epoch: 144/300 - Train loss: 0.241690531373024, Validation loss: 0.250569224357605
Epoch: 145/300 - Train loss: 0.24073956906795502, Validation loss: 0.24974551796913147
Epoch: 146/300 - Train loss: 0.23980136215686798, Validation loss: 0.24845382571220398
Epoch: 147/300 - Train loss: 0.23887541890144348, Validation loss: 0.2485213279724121
Epoch: 148/300 - Train loss: 0.23796188831329346, Validation loss: 0.24778321385383606
Epoch: 149/300 - Train loss: 0.23706044256687164, Validation loss: 0.24563249945640564
Epoch: 150/300 - Train loss: 0.23617084324359894, Validation loss: 0.24527403712272644
Epoch: 151/300 - Train loss: 0.23529279232025146, Validation loss: 0.24413739144802094
Epoch: 152/300 - Train loss: 0.23442628979682922, Validation loss: 0.24330741167068481
Epoch: 153/300 - Train loss: 0.23357106745243073, Validation loss: 0.24292442202568054
Epoch: 154/300 - Train loss: 0.23272705078125, Validation loss: 0.2419232428073883
Epoch: 155/300 - Train loss: 0.23189395666122437, Validation loss: 0.24108770489692688
Epoch: 156/300 - Train loss: 0.23107145726680756, Validation loss: 0.24079936742782593
Epoch: 157/300 - Train loss: 0.23025937378406525, Validation loss: 0.23916105926036835
Epoch: 158/300 - Train loss: 0.22945761680603027, Validation loss: 0.2389444261789322
Epoch: 159/300 - Train loss: 0.22866594791412354, Validation loss: 0.23757559061050415
Epoch: 160/300 - Train loss: 0.2278842329978943, Validation loss: 0.23687636852264404
Epoch: 161/300 - Train loss: 0.2271122932434082, Validation loss: 0.23648229241371155
Epoch: 162/300 - Train loss: 0.22634997963905334, Validation loss: 0.236857071518898
Epoch: 163/300 - Train loss: 0.22559721767902374, Validation loss: 0.23454223573207855
Epoch: 164/300 - Train loss: 0.22485384345054626, Validation loss: 0.2345564216375351
Epoch: 165/300 - Train loss: 0.224119633436203, Validation loss: 0.23394620418548584
Epoch: 166/300 - Train loss: 0.2233944535255432, Validation loss: 0.23280596733093262
Epoch: 167/300 - Train loss: 0.22267793118953705, Validation loss: 0.23233623802661896
Epoch: 168/300 - Train loss: 0.22197003662586212, Validation loss: 0.23134812712669373
Epoch: 169/300 - Train loss: 0.2212706357240677, Validation loss: 0.23081234097480774
Epoch: 170/300 - Train loss: 0.22057968378067017, Validation loss: 0.23025795817375183
Epoch: 171/300 - Train loss: 0.21989688277244568, Validation loss: 0.2301989197731018
Epoch: 172/300 - Train loss: 0.2192220538854599, Validation loss: 0.22873921692371368
Epoch: 173/300 - Train loss: 0.21855512261390686, Validation loss: 0.22777491807937622
Epoch: 174/300 - Train loss: 0.21789610385894775, Validation loss: 0.22698473930358887
Epoch: 175/300 - Train loss: 0.21724483370780945, Validation loss: 0.2269269824028015
Epoch: 176/300 - Train loss: 0.21660125255584717, Validation loss: 0.2263791263103485
Epoch: 177/300 - Train loss: 0.2159651517868042, Validation loss: 0.22560568153858185
Epoch: 178/300 - Train loss: 0.21533644199371338, Validation loss: 0.22474008798599243
Epoch: 179/300 - Train loss: 0.2147151529788971, Validation loss: 0.22458897531032562
Epoch: 180/300 - Train loss: 0.21410109102725983, Validation loss: 0.22392965853214264
Epoch: 181/300 - Train loss: 0.21349412202835083, Validation loss: 0.2232089787721634
Epoch: 182/300 - Train loss: 0.21289421617984772, Validation loss: 0.22266517579555511
Epoch: 183/300 - Train loss: 0.21230114996433258, Validation loss: 0.2220819741487503
