Epoch: 1/100 - Train loss: 0.6934531927108765, Validation loss: 0.6905904412269592
Epoch: 2/100 - Train loss: 0.690502405166626, Validation loss: 0.6878883838653564
Epoch: 3/100 - Train loss: 0.6876778602600098, Validation loss: 0.6852341294288635
Epoch: 4/100 - Train loss: 0.6849390268325806, Validation loss: 0.6825805306434631
Epoch: 5/100 - Train loss: 0.6822186708450317, Validation loss: 0.6799032092094421
Epoch: 6/100 - Train loss: 0.6794687509536743, Validation loss: 0.6771458983421326
Epoch: 7/100 - Train loss: 0.6766533255577087, Validation loss: 0.6743268370628357
Epoch: 8/100 - Train loss: 0.6737368702888489, Validation loss: 0.6712300181388855
Epoch: 9/100 - Train loss: 0.6706981062889099, Validation loss: 0.6680991053581238
Epoch: 10/100 - Train loss: 0.6675281524658203, Validation loss: 0.6649048328399658
Epoch: 11/100 - Train loss: 0.664228081703186, Validation loss: 0.6614794731140137
Epoch: 12/100 - Train loss: 0.660801887512207, Validation loss: 0.6579256057739258
Epoch: 13/100 - Train loss: 0.6572628021240234, Validation loss: 0.654209315776825
Epoch: 14/100 - Train loss: 0.6536169052124023, Validation loss: 0.6504729390144348
Epoch: 15/100 - Train loss: 0.6498826742172241, Validation loss: 0.6465837955474854
Epoch: 16/100 - Train loss: 0.6460749506950378, Validation loss: 0.6428366303443909
Epoch: 17/100 - Train loss: 0.6421952247619629, Validation loss: 0.6388382315635681
Epoch: 18/100 - Train loss: 0.6382632851600647, Validation loss: 0.6347100138664246
Epoch: 19/100 - Train loss: 0.6342973113059998, Validation loss: 0.6306179761886597
Epoch: 20/100 - Train loss: 0.6303090453147888, Validation loss: 0.6269735097885132
Epoch: 21/100 - Train loss: 0.6263013482093811, Validation loss: 0.6227789521217346
Epoch: 22/100 - Train loss: 0.6222760677337646, Validation loss: 0.6186239719390869
Epoch: 23/100 - Train loss: 0.6182371973991394, Validation loss: 0.6142598390579224
Epoch: 24/100 - Train loss: 0.6141790747642517, Validation loss: 0.610429048538208
Epoch: 25/100 - Train loss: 0.6100969314575195, Validation loss: 0.6062195301055908
Epoch: 26/100 - Train loss: 0.6059991121292114, Validation loss: 0.60191410779953
Epoch: 27/100 - Train loss: 0.6018906831741333, Validation loss: 0.5981506109237671
Epoch: 28/100 - Train loss: 0.597782552242279, Validation loss: 0.5942419767379761
Epoch: 29/100 - Train loss: 0.5936856865882874, Validation loss: 0.5899034738540649
Epoch: 30/100 - Train loss: 0.5896084904670715, Validation loss: 0.5858204960823059
Epoch: 31/100 - Train loss: 0.5855628848075867, Validation loss: 0.5817329287528992
Epoch: 32/100 - Train loss: 0.5815562605857849, Validation loss: 0.5774248242378235
Epoch: 33/100 - Train loss: 0.5775907635688782, Validation loss: 0.5739705562591553
Epoch: 34/100 - Train loss: 0.5736698508262634, Validation loss: 0.5699573755264282
Epoch: 35/100 - Train loss: 0.5697952508926392, Validation loss: 0.5658829212188721
Epoch: 36/100 - Train loss: 0.5659664273262024, Validation loss: 0.5621086359024048
Epoch: 37/100 - Train loss: 0.5621810555458069, Validation loss: 0.5583060383796692
Epoch: 38/100 - Train loss: 0.5584381222724915, Validation loss: 0.5546686053276062
Epoch: 39/100 - Train loss: 0.55473792552948, Validation loss: 0.5508022904396057
Epoch: 40/100 - Train loss: 0.5510824918746948, Validation loss: 0.547293484210968
Epoch: 41/100 - Train loss: 0.5474754571914673, Validation loss: 0.5439024567604065
Epoch: 42/100 - Train loss: 0.543917179107666, Validation loss: 0.5399570465087891
Epoch: 43/100 - Train loss: 0.5404094457626343, Validation loss: 0.5366111993789673
Epoch: 44/100 - Train loss: 0.5369497537612915, Validation loss: 0.5330145359039307
Epoch: 45/100 - Train loss: 0.5335390567779541, Validation loss: 0.5300796627998352
Epoch: 46/100 - Train loss: 0.530176043510437, Validation loss: 0.5261178612709045
Epoch: 47/100 - Train loss: 0.5268598794937134, Validation loss: 0.5231568813323975
Epoch: 48/100 - Train loss: 0.5235905647277832, Validation loss: 0.5197628736495972
Epoch: 49/100 - Train loss: 0.5203675627708435, Validation loss: 0.516562283039093
Epoch: 50/100 - Train loss: 0.5171904563903809, Validation loss: 0.513469398021698
Epoch: 51/100 - Train loss: 0.5140601396560669, Validation loss: 0.5104297399520874
Epoch: 52/100 - Train loss: 0.5109763741493225, Validation loss: 0.5071253776550293
Epoch: 53/100 - Train loss: 0.5079389810562134, Validation loss: 0.5045769810676575
Epoch: 54/100 - Train loss: 0.5049483776092529, Validation loss: 0.5011409521102905
Epoch: 55/100 - Train loss: 0.5020034313201904, Validation loss: 0.49806562066078186
Epoch: 56/100 - Train loss: 0.4991038143634796, Validation loss: 0.4954383969306946
Epoch: 57/100 - Train loss: 0.49624907970428467, Validation loss: 0.4928258955478668
Epoch: 58/100 - Train loss: 0.4934384226799011, Validation loss: 0.48982828855514526
Epoch: 59/100 - Train loss: 0.49067068099975586, Validation loss: 0.4868054687976837
Epoch: 60/100 - Train loss: 0.4879458546638489, Validation loss: 0.4838918149471283
Epoch: 61/100 - Train loss: 0.48526331782341003, Validation loss: 0.48182541131973267
Epoch: 62/100 - Train loss: 0.482623428106308, Validation loss: 0.4787044823169708
Epoch: 63/100 - Train loss: 0.4800255298614502, Validation loss: 0.4760294258594513
Epoch: 64/100 - Train loss: 0.4774695038795471, Validation loss: 0.4739227890968323
Epoch: 65/100 - Train loss: 0.4749543368816376, Validation loss: 0.47134438157081604
Epoch: 66/100 - Train loss: 0.4724791944026947, Validation loss: 0.4688118100166321
Epoch: 67/100 - Train loss: 0.4700436294078827, Validation loss: 0.4665204584598541
Epoch: 68/100 - Train loss: 0.4676477611064911, Validation loss: 0.4639253616333008
Epoch: 69/100 - Train loss: 0.4652911126613617, Validation loss: 0.46231821179389954
Epoch: 70/100 - Train loss: 0.4629739224910736, Validation loss: 0.45918160676956177
Epoch: 71/100 - Train loss: 0.4606958329677582, Validation loss: 0.45711392164230347
Epoch: 72/100 - Train loss: 0.4584563672542572, Validation loss: 0.4551381766796112
Epoch: 73/100 - Train loss: 0.4562552869319916, Validation loss: 0.45274001359939575
Epoch: 74/100 - Train loss: 0.45409196615219116, Validation loss: 0.45058155059814453
Epoch: 75/100 - Train loss: 0.45196640491485596, Validation loss: 0.4480234980583191
Epoch: 76/100 - Train loss: 0.4498785138130188, Validation loss: 0.4461032748222351
Epoch: 77/100 - Train loss: 0.4478278160095215, Validation loss: 0.4443228542804718
Epoch: 78/100 - Train loss: 0.4458143711090088, Validation loss: 0.44229641556739807
Epoch: 79/100 - Train loss: 0.44383755326271057, Validation loss: 0.4412088394165039
Epoch: 80/100 - Train loss: 0.4418967366218567, Validation loss: 0.438472718000412
Epoch: 81/100 - Train loss: 0.4399920105934143, Validation loss: 0.4364743232727051
Epoch: 82/100 - Train loss: 0.43812310695648193, Validation loss: 0.43530672788619995
Epoch: 83/100 - Train loss: 0.4362897574901581, Validation loss: 0.4328659772872925
Epoch: 84/100 - Train loss: 0.43449172377586365, Validation loss: 0.43094566464424133
Epoch: 85/100 - Train loss: 0.4327288866043091, Validation loss: 0.429681658744812
Epoch: 86/100 - Train loss: 0.4310001730918884, Validation loss: 0.4278798997402191
Epoch: 87/100 - Train loss: 0.4293054938316345, Validation loss: 0.4261036515235901
Epoch: 88/100 - Train loss: 0.4276450276374817, Validation loss: 0.42425745725631714
Epoch: 89/100 - Train loss: 0.4260183870792389, Validation loss: 0.4231395125389099
Epoch: 90/100 - Train loss: 0.42442503571510315, Validation loss: 0.4216201901435852
Epoch: 91/100 - Train loss: 0.4228650629520416, Validation loss: 0.4200044572353363
Epoch: 92/100 - Train loss: 0.4213380217552185, Validation loss: 0.4184177815914154
Epoch: 93/100 - Train loss: 0.4198433458805084, Validation loss: 0.4172206223011017
Epoch: 94/100 - Train loss: 0.41838008165359497, Validation loss: 0.41565391421318054
Epoch: 95/100 - Train loss: 0.4169478714466095, Validation loss: 0.41426411271095276
Epoch: 96/100 - Train loss: 0.4155465066432953, Validation loss: 0.41284796595573425
Epoch: 97/100 - Train loss: 0.4141755998134613, Validation loss: 0.4115164875984192
Epoch: 98/100 - Train loss: 0.41283515095710754, Validation loss: 0.4102570414543152
Epoch: 99/100 - Train loss: 0.4115239977836609, Validation loss: 0.409300833940506
Epoch: 100/100 - Train loss: 0.41024157404899597, Validation loss: 0.4076496362686157
Epoch: 1/300 - Train loss: 0.6946502923965454, Validation loss: 0.6924238801002502
Epoch: 2/300 - Train loss: 0.6922651529312134, Validation loss: 0.6902745366096497
Epoch: 3/300 - Train loss: 0.6900027990341187, Validation loss: 0.6881486773490906
Epoch: 4/300 - Train loss: 0.6878048777580261, Validation loss: 0.6860411167144775
Epoch: 5/300 - Train loss: 0.6856032013893127, Validation loss: 0.6838302612304688
Epoch: 6/300 - Train loss: 0.6833413243293762, Validation loss: 0.6815366148948669
Epoch: 7/300 - Train loss: 0.680971086025238, Validation loss: 0.6790343523025513
Epoch: 8/300 - Train loss: 0.6784505248069763, Validation loss: 0.6764049530029297
Epoch: 9/300 - Train loss: 0.6757532358169556, Validation loss: 0.6735897064208984
Epoch: 10/300 - Train loss: 0.6728611588478088, Validation loss: 0.6705288290977478
Epoch: 11/300 - Train loss: 0.6697632670402527, Validation loss: 0.6672306060791016
Epoch: 12/300 - Train loss: 0.6664568781852722, Validation loss: 0.6637871861457825
Epoch: 13/300 - Train loss: 0.6629400253295898, Validation loss: 0.6600351929664612
Epoch: 14/300 - Train loss: 0.6592196226119995, Validation loss: 0.6561877727508545
Epoch: 15/300 - Train loss: 0.6553075909614563, Validation loss: 0.6522462964057922
Epoch: 16/300 - Train loss: 0.6512264013290405, Validation loss: 0.6480552554130554
Epoch: 17/300 - Train loss: 0.6469910740852356, Validation loss: 0.64369136095047
Epoch: 18/300 - Train loss: 0.6426172852516174, Validation loss: 0.6393198370933533
Epoch: 19/300 - Train loss: 0.6381157636642456, Validation loss: 0.6346867680549622
Epoch: 20/300 - Train loss: 0.63350510597229, Validation loss: 0.6299657821655273
Epoch: 21/300 - Train loss: 0.6288055777549744, Validation loss: 0.6254352927207947
Epoch: 22/300 - Train loss: 0.6240296959877014, Validation loss: 0.6205065846443176
Epoch: 23/300 - Train loss: 0.6192000508308411, Validation loss: 0.6157793402671814
Epoch: 24/300 - Train loss: 0.614334762096405, Validation loss: 0.61092609167099
Epoch: 25/300 - Train loss: 0.609443724155426, Validation loss: 0.6061511039733887
Epoch: 26/300 - Train loss: 0.6045392751693726, Validation loss: 0.6013258099555969
Epoch: 27/300 - Train loss: 0.5996334552764893, Validation loss: 0.5964641571044922
Epoch: 28/300 - Train loss: 0.5947331190109253, Validation loss: 0.5916244983673096
Epoch: 29/300 - Train loss: 0.5898444056510925, Validation loss: 0.5867528915405273
Epoch: 30/300 - Train loss: 0.5849711298942566, Validation loss: 0.58204185962677
Epoch: 31/300 - Train loss: 0.5801157355308533, Validation loss: 0.5770254731178284
Epoch: 32/300 - Train loss: 0.5752804279327393, Validation loss: 0.5722156763076782
Epoch: 33/300 - Train loss: 0.5704693794250488, Validation loss: 0.5676651000976562
Epoch: 34/300 - Train loss: 0.5656861066818237, Validation loss: 0.5630505681037903
Epoch: 35/300 - Train loss: 0.5609352588653564, Validation loss: 0.5582459568977356
Epoch: 36/300 - Train loss: 0.5562211275100708, Validation loss: 0.5537189245223999
Epoch: 37/300 - Train loss: 0.5515491366386414, Validation loss: 0.5488051176071167
Epoch: 38/300 - Train loss: 0.5469227433204651, Validation loss: 0.5443505644798279
Epoch: 39/300 - Train loss: 0.5423455834388733, Validation loss: 0.5400856733322144
Epoch: 40/300 - Train loss: 0.5378217101097107, Validation loss: 0.5353843569755554
Epoch: 41/300 - Train loss: 0.5333524942398071, Validation loss: 0.5308796763420105
Epoch: 42/300 - Train loss: 0.5289416313171387, Validation loss: 0.5265340805053711
Epoch: 43/300 - Train loss: 0.524591326713562, Validation loss: 0.5223115086555481
Epoch: 44/300 - Train loss: 0.5203039050102234, Validation loss: 0.5175265669822693
Epoch: 45/300 - Train loss: 0.5160816311836243, Validation loss: 0.5137920379638672
Epoch: 46/300 - Train loss: 0.5119253396987915, Validation loss: 0.5097835063934326
Epoch: 47/300 - Train loss: 0.5078370571136475, Validation loss: 0.5054165720939636
Epoch: 48/300 - Train loss: 0.5038186311721802, Validation loss: 0.5017236471176147
Epoch: 49/300 - Train loss: 0.49987122416496277, Validation loss: 0.4974853992462158
Epoch: 50/300 - Train loss: 0.4959958493709564, Validation loss: 0.4938177466392517
Epoch: 51/300 - Train loss: 0.49219390749931335, Validation loss: 0.49004364013671875
Epoch: 52/300 - Train loss: 0.48846426606178284, Validation loss: 0.4865442216396332
Epoch: 53/300 - Train loss: 0.4848068356513977, Validation loss: 0.4828615188598633
Epoch: 54/300 - Train loss: 0.48122191429138184, Validation loss: 0.4789825677871704
Epoch: 55/300 - Train loss: 0.47771015763282776, Validation loss: 0.47599583864212036
Epoch: 56/300 - Train loss: 0.4742704927921295, Validation loss: 0.4723939299583435
Epoch: 57/300 - Train loss: 0.4709029495716095, Validation loss: 0.4690842628479004
Epoch: 58/300 - Train loss: 0.4676085114479065, Validation loss: 0.466201514005661
Epoch: 59/300 - Train loss: 0.46438974142074585, Validation loss: 0.4624897539615631
Epoch: 60/300 - Train loss: 0.461243599653244, Validation loss: 0.4594176411628723
Epoch: 61/300 - Train loss: 0.45816919207572937, Validation loss: 0.4563104510307312
Epoch: 62/300 - Train loss: 0.45516663789749146, Validation loss: 0.45314711332321167
Epoch: 63/300 - Train loss: 0.4522361755371094, Validation loss: 0.4504935145378113
Epoch: 64/300 - Train loss: 0.44937679171562195, Validation loss: 0.4472172260284424
Epoch: 65/300 - Train loss: 0.4465932250022888, Validation loss: 0.44451671838760376
Epoch: 66/300 - Train loss: 0.44388440251350403, Validation loss: 0.44168514013290405
Epoch: 67/300 - Train loss: 0.4412474036216736, Validation loss: 0.439967542886734
Epoch: 68/300 - Train loss: 0.4386821687221527, Validation loss: 0.4371126592159271
Epoch: 69/300 - Train loss: 0.4361867904663086, Validation loss: 0.4343986511230469
Epoch: 70/300 - Train loss: 0.43376055359840393, Validation loss: 0.4316542446613312
Epoch: 71/300 - Train loss: 0.4314008951187134, Validation loss: 0.429811954498291
Epoch: 72/300 - Train loss: 0.4291067123413086, Validation loss: 0.4275740683078766
Epoch: 73/300 - Train loss: 0.4268755614757538, Validation loss: 0.42508232593536377
Epoch: 74/300 - Train loss: 0.4247058033943176, Validation loss: 0.42285245656967163
Epoch: 75/300 - Train loss: 0.42259564995765686, Validation loss: 0.4208517074584961
Epoch: 76/300 - Train loss: 0.42054328322410583, Validation loss: 0.41934165358543396
Epoch: 77/300 - Train loss: 0.4185470938682556, Validation loss: 0.41772380471229553
Epoch: 78/300 - Train loss: 0.41660478711128235, Validation loss: 0.41484907269477844
Epoch: 79/300 - Train loss: 0.41471487283706665, Validation loss: 0.41296684741973877
Epoch: 80/300 - Train loss: 0.4128754734992981, Validation loss: 0.4115925431251526
Epoch: 81/300 - Train loss: 0.41108423471450806, Validation loss: 0.4096900522708893
Epoch: 82/300 - Train loss: 0.4093400835990906, Validation loss: 0.4079393446445465
Epoch: 83/300 - Train loss: 0.40764132142066956, Validation loss: 0.4066109359264374
Epoch: 84/300 - Train loss: 0.4059860408306122, Validation loss: 0.4047369062900543
Epoch: 85/300 - Train loss: 0.4043724238872528, Validation loss: 0.40265628695487976
Epoch: 86/300 - Train loss: 0.402798056602478, Validation loss: 0.40169113874435425
Epoch: 87/300 - Train loss: 0.4012603461742401, Validation loss: 0.39962661266326904
Epoch: 88/300 - Train loss: 0.39975738525390625, Validation loss: 0.39781633019447327
Epoch: 89/300 - Train loss: 0.3982878625392914, Validation loss: 0.3964986205101013
Epoch: 90/300 - Train loss: 0.3968500792980194, Validation loss: 0.3950277268886566
Epoch: 91/300 - Train loss: 0.3954426646232605, Validation loss: 0.3941749930381775
Epoch: 92/300 - Train loss: 0.3940615653991699, Validation loss: 0.39176100492477417
Epoch: 93/300 - Train loss: 0.3927059769630432, Validation loss: 0.39097753167152405
Epoch: 94/300 - Train loss: 0.39137497544288635, Validation loss: 0.38994547724723816
Epoch: 95/300 - Train loss: 0.39006710052490234, Validation loss: 0.38819992542266846
Epoch: 96/300 - Train loss: 0.3887810707092285, Validation loss: 0.38776376843452454
Epoch: 97/300 - Train loss: 0.3875158429145813, Validation loss: 0.3855178952217102
Epoch: 98/300 - Train loss: 0.3862707018852234, Validation loss: 0.3844328820705414
Epoch: 99/300 - Train loss: 0.3850446939468384, Validation loss: 0.38361722230911255
Epoch: 100/300 - Train loss: 0.38383591175079346, Validation loss: 0.38206368684768677
Epoch: 101/300 - Train loss: 0.38264337182044983, Validation loss: 0.3810226619243622
Epoch: 102/300 - Train loss: 0.3814661204814911, Validation loss: 0.38004761934280396
Epoch: 103/300 - Train loss: 0.3803039789199829, Validation loss: 0.37844640016555786
Epoch: 104/300 - Train loss: 0.37915492057800293, Validation loss: 0.3772386908531189
Epoch: 105/300 - Train loss: 0.37802088260650635, Validation loss: 0.376068651676178
Epoch: 106/300 - Train loss: 0.37690022587776184, Validation loss: 0.37533485889434814
Epoch: 107/300 - Train loss: 0.37579306960105896, Validation loss: 0.37374842166900635
Epoch: 108/300 - Train loss: 0.3746964931488037, Validation loss: 0.3724234402179718
Epoch: 109/300 - Train loss: 0.3736092746257782, Validation loss: 0.37142911553382874
Epoch: 110/300 - Train loss: 0.372531533241272, Validation loss: 0.3708568811416626
Epoch: 111/300 - Train loss: 0.3714616894721985, Validation loss: 0.3690083920955658
Epoch: 112/300 - Train loss: 0.37039995193481445, Validation loss: 0.3680783808231354
Epoch: 113/300 - Train loss: 0.36934611201286316, Validation loss: 0.36707112193107605
Epoch: 114/300 - Train loss: 0.3682991862297058, Validation loss: 0.36608991026878357
Epoch: 115/300 - Train loss: 0.3672589063644409, Validation loss: 0.3656245768070221
Epoch: 116/300 - Train loss: 0.3662252724170685, Validation loss: 0.36406585574150085
Epoch: 117/300 - Train loss: 0.36519789695739746, Validation loss: 0.3636787533760071
Epoch: 118/300 - Train loss: 0.3641747534275055, Validation loss: 0.3623772859573364
Epoch: 119/300 - Train loss: 0.3631595969200134, Validation loss: 0.36059409379959106
Epoch: 120/300 - Train loss: 0.362152099609375, Validation loss: 0.360110878944397
Epoch: 121/300 - Train loss: 0.3611501157283783, Validation loss: 0.358845055103302
Epoch: 122/300 - Train loss: 0.3601544201374054, Validation loss: 0.3577781915664673
Epoch: 123/300 - Train loss: 0.35916441679000854, Validation loss: 0.35616907477378845
Epoch: 124/300 - Train loss: 0.3581795394420624, Validation loss: 0.3562752902507782
Epoch: 125/300 - Train loss: 0.3572019338607788, Validation loss: 0.3550335466861725
Epoch: 126/300 - Train loss: 0.3562341034412384, Validation loss: 0.3540600538253784
Epoch: 127/300 - Train loss: 0.3552758991718292, Validation loss: 0.35309943556785583
Epoch: 128/300 - Train loss: 0.3543260991573334, Validation loss: 0.3519420027732849
Epoch: 129/300 - Train loss: 0.35338500142097473, Validation loss: 0.35057926177978516
Epoch: 130/300 - Train loss: 0.352451354265213, Validation loss: 0.34947913885116577
Epoch: 131/300 - Train loss: 0.3515266180038452, Validation loss: 0.3483322560787201
Epoch: 132/300 - Train loss: 0.35061115026474, Validation loss: 0.34748324751853943
Epoch: 133/300 - Train loss: 0.3497050404548645, Validation loss: 0.34688159823417664
Epoch: 134/300 - Train loss: 0.3488069176673889, Validation loss: 0.34616556763648987
Epoch: 135/300 - Train loss: 0.3479183316230774, Validation loss: 0.3454017639160156
Epoch: 136/300 - Train loss: 0.34703969955444336, Validation loss: 0.3441542387008667
Epoch: 137/300 - Train loss: 0.34617090225219727, Validation loss: 0.3431837856769562
Epoch: 138/300 - Train loss: 0.34530994296073914, Validation loss: 0.3422470986843109
Epoch: 139/300 - Train loss: 0.34445634484291077, Validation loss: 0.3410676121711731
Epoch: 140/300 - Train loss: 0.343610942363739, Validation loss: 0.3404673635959625
Epoch: 141/300 - Train loss: 0.3427748382091522, Validation loss: 0.3407558798789978
Epoch: 142/300 - Train loss: 0.34194687008857727, Validation loss: 0.3391510844230652
Epoch: 143/300 - Train loss: 0.3411265015602112, Validation loss: 0.33848363161087036
Epoch: 144/300 - Train loss: 0.3403138816356659, Validation loss: 0.3374812602996826
Epoch: 145/300 - Train loss: 0.33951064944267273, Validation loss: 0.33666881918907166
Epoch: 146/300 - Train loss: 0.33871591091156006, Validation loss: 0.33575162291526794
Epoch: 147/300 - Train loss: 0.337928831577301, Validation loss: 0.3348916471004486
Epoch: 148/300 - Train loss: 0.33715006709098816, Validation loss: 0.33343157172203064
Epoch: 149/300 - Train loss: 0.3363783657550812, Validation loss: 0.3332188129425049
Epoch: 150/300 - Train loss: 0.3356156349182129, Validation loss: 0.3326053023338318
Epoch: 151/300 - Train loss: 0.3348608613014221, Validation loss: 0.33137375116348267
Epoch: 152/300 - Train loss: 0.3341137766838074, Validation loss: 0.33143147826194763
Epoch: 153/300 - Train loss: 0.3333750069141388, Validation loss: 0.3300160765647888
Epoch: 154/300 - Train loss: 0.33264467120170593, Validation loss: 0.32920873165130615
Epoch: 155/300 - Train loss: 0.3319214880466461, Validation loss: 0.32844746112823486
Epoch: 156/300 - Train loss: 0.33120813965797424, Validation loss: 0.32803142070770264
Epoch: 157/300 - Train loss: 0.3305037021636963, Validation loss: 0.3272411823272705
Epoch: 158/300 - Train loss: 0.32980847358703613, Validation loss: 0.3262743055820465
Epoch: 159/300 - Train loss: 0.329120934009552, Validation loss: 0.3259018063545227
Epoch: 160/300 - Train loss: 0.32844170928001404, Validation loss: 0.32473239302635193
Epoch: 161/300 - Train loss: 0.32777106761932373, Validation loss: 0.32385098934173584
Epoch: 162/300 - Train loss: 0.3271082639694214, Validation loss: 0.32408368587493896
Epoch: 163/300 - Train loss: 0.32645243406295776, Validation loss: 0.3227815628051758
Epoch: 164/300 - Train loss: 0.32580313086509705, Validation loss: 0.322470486164093
Epoch: 165/300 - Train loss: 0.3251604437828064, Validation loss: 0.3216654062271118
Epoch: 166/300 - Train loss: 0.3245249092578888, Validation loss: 0.32084938883781433
Epoch: 167/300 - Train loss: 0.3238952159881592, Validation loss: 0.32018208503723145
Epoch: 168/300 - Train loss: 0.32327160239219666, Validation loss: 0.3198321759700775
Epoch: 169/300 - Train loss: 0.32265445590019226, Validation loss: 0.31913435459136963
Epoch: 170/300 - Train loss: 0.32204437255859375, Validation loss: 0.3193712532520294
