Epoch: 1/200 - Train loss: 0.5551661252975464, Validation loss: 0.4673902094364166
Epoch: 2/200 - Train loss: 0.43003445863723755, Validation loss: 0.4173642098903656
Epoch: 3/200 - Train loss: 0.3860757648944855, Validation loss: 0.38788384199142456
Epoch: 4/200 - Train loss: 0.35963037610054016, Validation loss: 0.37154555320739746
Epoch: 5/200 - Train loss: 0.34215304255485535, Validation loss: 0.3585997223854065
Epoch: 6/200 - Train loss: 0.32722508907318115, Validation loss: 0.35321587324142456
Epoch: 7/200 - Train loss: 0.3153068423271179, Validation loss: 0.3461467921733856
Epoch: 8/200 - Train loss: 0.30553361773490906, Validation loss: 0.3385668098926544
Epoch: 9/200 - Train loss: 0.29688572883605957, Validation loss: 0.3310575485229492
Epoch: 10/200 - Train loss: 0.28986161947250366, Validation loss: 0.32536011934280396
Epoch: 11/200 - Train loss: 0.28175413608551025, Validation loss: 0.31719112396240234
Epoch: 12/200 - Train loss: 0.2759086787700653, Validation loss: 0.3102274537086487
Epoch: 13/200 - Train loss: 0.2684791386127472, Validation loss: 0.3042585253715515
Epoch: 14/200 - Train loss: 0.2628543972969055, Validation loss: 0.29909226298332214
Epoch: 15/200 - Train loss: 0.25823742151260376, Validation loss: 0.30056050419807434
Epoch: 16/200 - Train loss: 0.25342413783073425, Validation loss: 0.3034939765930176
Epoch: 17/200 - Train loss: 0.25174349546432495, Validation loss: 0.29906418919563293
Epoch: 18/200 - Train loss: 0.2492356151342392, Validation loss: 0.2919705808162689
Epoch: 19/200 - Train loss: 0.24599523842334747, Validation loss: 0.29269644618034363
Epoch: 20/200 - Train loss: 0.2445056140422821, Validation loss: 0.2946181893348694
Epoch: 21/200 - Train loss: 0.24132885038852692, Validation loss: 0.29648342728614807
Epoch: 22/200 - Train loss: 0.23989568650722504, Validation loss: 0.28985729813575745
Epoch: 23/200 - Train loss: 0.23784740269184113, Validation loss: 0.28803715109825134
Epoch: 24/200 - Train loss: 0.23685050010681152, Validation loss: 0.28985220193862915
Epoch: 25/200 - Train loss: 0.23561450839042664, Validation loss: 0.2880963385105133
Epoch: 26/200 - Train loss: 0.23466822504997253, Validation loss: 0.29110491275787354
Epoch: 27/200 - Train loss: 0.23303744196891785, Validation loss: 0.28925764560699463
Epoch: 28/200 - Train loss: 0.23189151287078857, Validation loss: 0.2888973653316498
Epoch: 29/200 - Train loss: 0.23206323385238647, Validation loss: 0.28801074624061584
Epoch: 30/200 - Train loss: 0.23148542642593384, Validation loss: 0.29368945956230164
Epoch: 31/200 - Train loss: 0.22868375480175018, Validation loss: 0.2906762957572937
Epoch: 32/200 - Train loss: 0.22811703383922577, Validation loss: 0.2883400022983551
Epoch: 33/200 - Train loss: 0.2280181348323822, Validation loss: 0.2853758633136749
Epoch: 34/200 - Train loss: 0.22720710933208466, Validation loss: 0.2880520224571228
Epoch: 35/200 - Train loss: 0.22734053432941437, Validation loss: 0.28483545780181885
Epoch: 36/200 - Train loss: 0.22553977370262146, Validation loss: 0.2957848310470581
Epoch: 37/200 - Train loss: 0.22506484389305115, Validation loss: 0.2866232693195343
Epoch: 38/200 - Train loss: 0.2234238237142563, Validation loss: 0.28535816073417664
Epoch: 39/200 - Train loss: 0.2227351814508438, Validation loss: 0.2843236029148102
Epoch: 40/200 - Train loss: 0.22282671928405762, Validation loss: 0.2875053584575653
Epoch: 41/200 - Train loss: 0.2219095230102539, Validation loss: 0.2904546558856964
Epoch: 42/200 - Train loss: 0.2209787219762802, Validation loss: 0.2876397669315338
Epoch: 43/200 - Train loss: 0.22012533247470856, Validation loss: 0.2853790521621704
Epoch: 44/200 - Train loss: 0.22009868919849396, Validation loss: 0.2831185758113861
Epoch: 45/200 - Train loss: 0.2194618284702301, Validation loss: 0.2865411043167114
Epoch: 46/200 - Train loss: 0.21793432533740997, Validation loss: 0.28578484058380127
Epoch: 47/200 - Train loss: 0.21815809607505798, Validation loss: 0.28384459018707275
Epoch: 48/200 - Train loss: 0.21701116859912872, Validation loss: 0.2886880934238434
Epoch: 49/200 - Train loss: 0.21860206127166748, Validation loss: 0.2840425968170166
Epoch: 50/200 - Train loss: 0.21638838946819305, Validation loss: 0.2865157127380371
Epoch: 51/200 - Train loss: 0.21683497726917267, Validation loss: 0.28413859009742737
Epoch: 52/200 - Train loss: 0.21565957367420197, Validation loss: 0.28629931807518005
Epoch: 53/200 - Train loss: 0.21593083441257477, Validation loss: 0.2845558524131775
Epoch: 54/200 - Train loss: 0.21555538475513458, Validation loss: 0.2811140716075897
Epoch: 55/200 - Train loss: 0.21408233046531677, Validation loss: 0.28472986817359924
Epoch: 56/200 - Train loss: 0.213727667927742, Validation loss: 0.2811044752597809
Epoch: 57/200 - Train loss: 0.2139715850353241, Validation loss: 0.28287971019744873
Epoch: 58/200 - Train loss: 0.21358622610569, Validation loss: 0.2850421071052551
Epoch: 59/200 - Train loss: 0.21276149153709412, Validation loss: 0.28630971908569336
Epoch: 60/200 - Train loss: 0.21353788673877716, Validation loss: 0.2823677957057953
Epoch: 61/200 - Train loss: 0.21279652416706085, Validation loss: 0.28264084458351135
Epoch: 62/200 - Train loss: 0.21280251443386078, Validation loss: 0.28480178117752075
Epoch: 63/200 - Train loss: 0.21212588250637054, Validation loss: 0.28160110116004944
Epoch: 64/200 - Train loss: 0.2111601084470749, Validation loss: 0.2907438576221466
Epoch: 65/200 - Train loss: 0.21260204911231995, Validation loss: 0.2855603098869324
Epoch: 66/200 - Train loss: 0.211251899600029, Validation loss: 0.284742534160614
Epoch: 67/200 - Train loss: 0.21061669290065765, Validation loss: 0.28502002358436584
Epoch: 68/200 - Train loss: 0.21181778609752655, Validation loss: 0.2844884991645813
Epoch: 69/200 - Train loss: 0.21085882186889648, Validation loss: 0.2837257385253906
Epoch: 70/200 - Train loss: 0.21060903370380402, Validation loss: 0.2846258282661438
Epoch: 71/200 - Train loss: 0.2111765295267105, Validation loss: 0.2843377888202667
Epoch: 72/200 - Train loss: 0.21022410690784454, Validation loss: 0.2871859073638916
Epoch: 73/200 - Train loss: 0.21046698093414307, Validation loss: 0.28378385305404663
Epoch: 74/200 - Train loss: 0.21003390848636627, Validation loss: 0.282045841217041
Epoch: 75/200 - Train loss: 0.20890147984027863, Validation loss: 0.28594762086868286
Epoch: 76/200 - Train loss: 0.2090449035167694, Validation loss: 0.2848052382469177
Epoch: 77/200 - Train loss: 0.20924407243728638, Validation loss: 0.28428807854652405
Epoch: 78/200 - Train loss: 0.20956842601299286, Validation loss: 0.28107890486717224
Epoch: 79/200 - Train loss: 0.2090078890323639, Validation loss: 0.281973659992218
Epoch: 80/200 - Train loss: 0.20888666808605194, Validation loss: 0.2849733233451843
Epoch: 81/200 - Train loss: 0.20767343044281006, Validation loss: 0.2798124849796295
Epoch: 82/200 - Train loss: 0.20926442742347717, Validation loss: 0.2845360040664673
Epoch: 83/200 - Train loss: 0.20946264266967773, Validation loss: 0.28179803490638733
Epoch: 84/200 - Train loss: 0.207903653383255, Validation loss: 0.2830638289451599
Epoch: 85/200 - Train loss: 0.20852680504322052, Validation loss: 0.28555938601493835
Epoch: 86/200 - Train loss: 0.20879869163036346, Validation loss: 0.2837297022342682
Epoch: 87/200 - Train loss: 0.2081613391637802, Validation loss: 0.2830928564071655
Epoch: 88/200 - Train loss: 0.20835429430007935, Validation loss: 0.28237098455429077
Epoch: 89/200 - Train loss: 0.20909053087234497, Validation loss: 0.2821893095970154
Epoch: 90/200 - Train loss: 0.20707644522190094, Validation loss: 0.2847399115562439
Epoch: 91/200 - Train loss: 0.20735695958137512, Validation loss: 0.2812277674674988
Epoch: 1/200 - Train loss: 0.5727679133415222, Validation loss: 0.4785880446434021
Epoch: 2/200 - Train loss: 0.4451797604560852, Validation loss: 0.4328457713127136
Epoch: 3/200 - Train loss: 0.407547265291214, Validation loss: 0.40686461329460144
Epoch: 4/200 - Train loss: 0.38043099641799927, Validation loss: 0.3879980742931366
Epoch: 5/200 - Train loss: 0.35729414224624634, Validation loss: 0.3702118694782257
Epoch: 6/200 - Train loss: 0.33815547823905945, Validation loss: 0.35672125220298767
Epoch: 7/200 - Train loss: 0.32487326860427856, Validation loss: 0.34846097230911255
Epoch: 8/200 - Train loss: 0.3151782155036926, Validation loss: 0.34641018509864807
Epoch: 9/200 - Train loss: 0.30822843313217163, Validation loss: 0.3437053859233856
Epoch: 10/200 - Train loss: 0.301119863986969, Validation loss: 0.3516155183315277
Epoch: 11/200 - Train loss: 0.2969343662261963, Validation loss: 0.33620893955230713
Epoch: 12/200 - Train loss: 0.2899349331855774, Validation loss: 0.33363449573516846
Epoch: 13/200 - Train loss: 0.28617027401924133, Validation loss: 0.32733118534088135
Epoch: 14/200 - Train loss: 0.2812765836715698, Validation loss: 0.3295542895793915
Epoch: 15/200 - Train loss: 0.2769956886768341, Validation loss: 0.32325342297554016
Epoch: 16/200 - Train loss: 0.272749125957489, Validation loss: 0.32211628556251526
Epoch: 17/200 - Train loss: 0.26918673515319824, Validation loss: 0.3177892565727234
Epoch: 18/200 - Train loss: 0.2653178870677948, Validation loss: 0.31350794434547424
Epoch: 19/200 - Train loss: 0.2618754804134369, Validation loss: 0.3165038228034973
Epoch: 20/200 - Train loss: 0.2587534487247467, Validation loss: 0.31138065457344055
Epoch: 21/200 - Train loss: 0.25676825642585754, Validation loss: 0.31166502833366394
Epoch: 22/200 - Train loss: 0.2540428638458252, Validation loss: 0.3095090985298157
Epoch: 23/200 - Train loss: 0.25115257501602173, Validation loss: 0.3078683912754059
Epoch: 24/200 - Train loss: 0.2489868700504303, Validation loss: 0.3012002408504486
Epoch: 25/200 - Train loss: 0.24755804240703583, Validation loss: 0.3019411265850067
Epoch: 26/200 - Train loss: 0.24481423199176788, Validation loss: 0.301249623298645
Epoch: 27/200 - Train loss: 0.24377313256263733, Validation loss: 0.2992912828922272
Epoch: 28/200 - Train loss: 0.24077051877975464, Validation loss: 0.2976539134979248
Epoch: 29/200 - Train loss: 0.23922690749168396, Validation loss: 0.29962924122810364
Epoch: 30/200 - Train loss: 0.23849822580814362, Validation loss: 0.2960386872291565
Epoch: 31/200 - Train loss: 0.2373734414577484, Validation loss: 0.29623016715049744
Epoch: 32/200 - Train loss: 0.23527826368808746, Validation loss: 0.29187220335006714
Epoch: 33/200 - Train loss: 0.23491621017456055, Validation loss: 0.29249635338783264
Epoch: 34/200 - Train loss: 0.23335115611553192, Validation loss: 0.2884417772293091
Epoch: 35/200 - Train loss: 0.2320844531059265, Validation loss: 0.29075244069099426
Epoch: 36/200 - Train loss: 0.23014229536056519, Validation loss: 0.28535062074661255
Epoch: 37/200 - Train loss: 0.2293422669172287, Validation loss: 0.2866212725639343
Epoch: 38/200 - Train loss: 0.2286762297153473, Validation loss: 0.2869121730327606
Epoch: 39/200 - Train loss: 0.22652198374271393, Validation loss: 0.2834841310977936
Epoch: 40/200 - Train loss: 0.22620514035224915, Validation loss: 0.2841712534427643
Epoch: 41/200 - Train loss: 0.22553764283657074, Validation loss: 0.28253743052482605
Epoch: 42/200 - Train loss: 0.22558043897151947, Validation loss: 0.2835651636123657
Epoch: 43/200 - Train loss: 0.22381356358528137, Validation loss: 0.28121471405029297
Epoch: 44/200 - Train loss: 0.22197310626506805, Validation loss: 0.28345566987991333
Epoch: 45/200 - Train loss: 0.2221682369709015, Validation loss: 0.2778746783733368
Epoch: 46/200 - Train loss: 0.22053799033164978, Validation loss: 0.2802872061729431
Epoch: 47/200 - Train loss: 0.22038108110427856, Validation loss: 0.2822529971599579
Epoch: 48/200 - Train loss: 0.2198382019996643, Validation loss: 0.28280124068260193
Epoch: 49/200 - Train loss: 0.21862058341503143, Validation loss: 0.27943599224090576
Epoch: 50/200 - Train loss: 0.21856875717639923, Validation loss: 0.27983325719833374
Epoch: 51/200 - Train loss: 0.21890586614608765, Validation loss: 0.2809019982814789
Epoch: 52/200 - Train loss: 0.21797753870487213, Validation loss: 0.27951058745384216
Epoch: 53/200 - Train loss: 0.21767863631248474, Validation loss: 0.29013824462890625
Epoch: 54/200 - Train loss: 0.2174653261899948, Validation loss: 0.2771259546279907
Epoch: 55/200 - Train loss: 0.21616442501544952, Validation loss: 0.2815675437450409
Epoch: 56/200 - Train loss: 0.21585868299007416, Validation loss: 0.27833956480026245
Epoch: 57/200 - Train loss: 0.21582745015621185, Validation loss: 0.28045010566711426
Epoch: 58/200 - Train loss: 0.215958833694458, Validation loss: 0.2783505916595459
Epoch: 59/200 - Train loss: 0.21551088988780975, Validation loss: 0.27937737107276917
Epoch: 60/200 - Train loss: 0.21400320529937744, Validation loss: 0.2828296422958374
Epoch: 61/200 - Train loss: 0.21518443524837494, Validation loss: 0.2813664972782135
Epoch: 62/200 - Train loss: 0.21433940529823303, Validation loss: 0.277080237865448
Epoch: 63/200 - Train loss: 0.21411673724651337, Validation loss: 0.2827874720096588
Epoch: 64/200 - Train loss: 0.2130746692419052, Validation loss: 0.2805114686489105
Epoch: 65/200 - Train loss: 0.2122473567724228, Validation loss: 0.28141918778419495
Epoch: 66/200 - Train loss: 0.2137073278427124, Validation loss: 0.27916592359542847
Epoch: 67/200 - Train loss: 0.21288812160491943, Validation loss: 0.27954328060150146
Epoch: 68/200 - Train loss: 0.21213650703430176, Validation loss: 0.280303955078125
Epoch: 69/200 - Train loss: 0.21189667284488678, Validation loss: 0.282473087310791
Epoch: 70/200 - Train loss: 0.21162578463554382, Validation loss: 0.27995559573173523
Epoch: 71/200 - Train loss: 0.21209371089935303, Validation loss: 0.2801240086555481
Epoch: 72/200 - Train loss: 0.21143986284732819, Validation loss: 0.27712029218673706
Epoch: 73/200 - Train loss: 0.21106162667274475, Validation loss: 0.2777595520019531
Epoch: 74/200 - Train loss: 0.21080496907234192, Validation loss: 0.28138643503189087
Epoch: 75/200 - Train loss: 0.2112145572900772, Validation loss: 0.27923136949539185
Epoch: 76/200 - Train loss: 0.21062034368515015, Validation loss: 0.2773769497871399
Epoch: 77/200 - Train loss: 0.20969967544078827, Validation loss: 0.2803582549095154
Epoch: 78/200 - Train loss: 0.20977753400802612, Validation loss: 0.2779068052768707
Epoch: 79/200 - Train loss: 0.21023549139499664, Validation loss: 0.27953311800956726
