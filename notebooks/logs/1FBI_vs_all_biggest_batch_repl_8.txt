Epoch: 1/300 - Train loss: 0.6999037265777588, Validation loss: 0.698682427406311
Epoch: 2/300 - Train loss: 0.6969543695449829, Validation loss: 0.6954339146614075
Epoch: 3/300 - Train loss: 0.6939711570739746, Validation loss: 0.6921473741531372
Epoch: 4/300 - Train loss: 0.6909106373786926, Validation loss: 0.6890817284584045
Epoch: 5/300 - Train loss: 0.6877373456954956, Validation loss: 0.6854886412620544
Epoch: 6/300 - Train loss: 0.6844198703765869, Validation loss: 0.6820564270019531
Epoch: 7/300 - Train loss: 0.6809414625167847, Validation loss: 0.6782165169715881
Epoch: 8/300 - Train loss: 0.6772833466529846, Validation loss: 0.674235999584198
Epoch: 9/300 - Train loss: 0.6734337210655212, Validation loss: 0.6699668765068054
Epoch: 10/300 - Train loss: 0.6693999171257019, Validation loss: 0.6657012701034546
Epoch: 11/300 - Train loss: 0.6651864051818848, Validation loss: 0.661152184009552
Epoch: 12/300 - Train loss: 0.6608055233955383, Validation loss: 0.6565520763397217
Epoch: 13/300 - Train loss: 0.6562657952308655, Validation loss: 0.6516650319099426
Epoch: 14/300 - Train loss: 0.651581883430481, Validation loss: 0.6466875672340393
Epoch: 15/300 - Train loss: 0.6467732191085815, Validation loss: 0.6416617631912231
Epoch: 16/300 - Train loss: 0.6418497562408447, Validation loss: 0.6364080309867859
Epoch: 17/300 - Train loss: 0.6368207931518555, Validation loss: 0.6312867999076843
Epoch: 18/300 - Train loss: 0.6316985487937927, Validation loss: 0.6259154677391052
Epoch: 19/300 - Train loss: 0.6264958381652832, Validation loss: 0.6205280423164368
Epoch: 20/300 - Train loss: 0.6212165355682373, Validation loss: 0.6149851679801941
Epoch: 21/300 - Train loss: 0.61586594581604, Validation loss: 0.6094274520874023
Epoch: 22/300 - Train loss: 0.610450804233551, Validation loss: 0.6037772297859192
Epoch: 23/300 - Train loss: 0.6049733757972717, Validation loss: 0.5981531143188477
Epoch: 24/300 - Train loss: 0.5994360446929932, Validation loss: 0.592498779296875
Epoch: 25/300 - Train loss: 0.5938407778739929, Validation loss: 0.5866950750350952
Epoch: 26/300 - Train loss: 0.5881903171539307, Validation loss: 0.5809022784233093
Epoch: 27/300 - Train loss: 0.5824884176254272, Validation loss: 0.5749889612197876
Epoch: 28/300 - Train loss: 0.5767371654510498, Validation loss: 0.5691167712211609
Epoch: 29/300 - Train loss: 0.5709397196769714, Validation loss: 0.56313157081604
Epoch: 30/300 - Train loss: 0.5651000738143921, Validation loss: 0.5572463274002075
Epoch: 31/300 - Train loss: 0.5592226982116699, Validation loss: 0.5512344837188721
Epoch: 32/300 - Train loss: 0.5533111095428467, Validation loss: 0.5451378226280212
Epoch: 33/300 - Train loss: 0.5473695993423462, Validation loss: 0.539219856262207
Epoch: 34/300 - Train loss: 0.5414025187492371, Validation loss: 0.5331012606620789
Epoch: 35/300 - Train loss: 0.5354148745536804, Validation loss: 0.5271086096763611
Epoch: 36/300 - Train loss: 0.5294111371040344, Validation loss: 0.5209199786186218
Epoch: 37/300 - Train loss: 0.5233972668647766, Validation loss: 0.5149161219596863
Epoch: 38/300 - Train loss: 0.5173787474632263, Validation loss: 0.5086921453475952
Epoch: 39/300 - Train loss: 0.5113601088523865, Validation loss: 0.5026211738586426
Epoch: 40/300 - Train loss: 0.5053467750549316, Validation loss: 0.4964393377304077
Epoch: 41/300 - Train loss: 0.49934491515159607, Validation loss: 0.4906296730041504
Epoch: 42/300 - Train loss: 0.49335968494415283, Validation loss: 0.4845750331878662
Epoch: 43/300 - Train loss: 0.4873965382575989, Validation loss: 0.4784613847732544
Epoch: 44/300 - Train loss: 0.48146024346351624, Validation loss: 0.47252073884010315
Epoch: 45/300 - Train loss: 0.47555553913116455, Validation loss: 0.46666207909584045
Epoch: 46/300 - Train loss: 0.46968722343444824, Validation loss: 0.46052929759025574
Epoch: 47/300 - Train loss: 0.46385958790779114, Validation loss: 0.4551827609539032
Epoch: 48/300 - Train loss: 0.45807725191116333, Validation loss: 0.4493591785430908
Epoch: 49/300 - Train loss: 0.45234498381614685, Validation loss: 0.4433881938457489
Epoch: 50/300 - Train loss: 0.4466671347618103, Validation loss: 0.43771597743034363
Epoch: 51/300 - Train loss: 0.44104766845703125, Validation loss: 0.4322107136249542
Epoch: 52/300 - Train loss: 0.43548986315727234, Validation loss: 0.42649659514427185
Epoch: 53/300 - Train loss: 0.4299969971179962, Validation loss: 0.4210018515586853
Epoch: 54/300 - Train loss: 0.42457276582717896, Validation loss: 0.41555333137512207
Epoch: 55/300 - Train loss: 0.4192202389240265, Validation loss: 0.41089534759521484
Epoch: 56/300 - Train loss: 0.41394245624542236, Validation loss: 0.4049711525440216
Epoch: 57/300 - Train loss: 0.40874195098876953, Validation loss: 0.40019094944000244
Epoch: 58/300 - Train loss: 0.4036213457584381, Validation loss: 0.3949238955974579
Epoch: 59/300 - Train loss: 0.3985821604728699, Validation loss: 0.3898557424545288
Epoch: 60/300 - Train loss: 0.39362630248069763, Validation loss: 0.3850448727607727
Epoch: 61/300 - Train loss: 0.3887557089328766, Validation loss: 0.3805544674396515
Epoch: 62/300 - Train loss: 0.3839713931083679, Validation loss: 0.37573951482772827
Epoch: 63/300 - Train loss: 0.3792743384838104, Validation loss: 0.3708776533603668
Epoch: 64/300 - Train loss: 0.374665230512619, Validation loss: 0.3663608133792877
Epoch: 65/300 - Train loss: 0.37014445662498474, Validation loss: 0.36185115575790405
Epoch: 66/300 - Train loss: 0.3657122254371643, Validation loss: 0.3576611578464508
Epoch: 67/300 - Train loss: 0.36136892437934875, Validation loss: 0.35317957401275635
Epoch: 68/300 - Train loss: 0.35711440443992615, Validation loss: 0.34920865297317505
Epoch: 69/300 - Train loss: 0.3529488146305084, Validation loss: 0.3451523184776306
Epoch: 70/300 - Train loss: 0.34887105226516724, Validation loss: 0.3408714532852173
Epoch: 71/300 - Train loss: 0.34488046169281006, Validation loss: 0.3372536599636078
Epoch: 72/300 - Train loss: 0.3409767746925354, Validation loss: 0.33354029059410095
Epoch: 73/300 - Train loss: 0.337159126996994, Validation loss: 0.3295244872570038
Epoch: 74/300 - Train loss: 0.33342665433883667, Validation loss: 0.3261139988899231
Epoch: 75/300 - Train loss: 0.32977816462516785, Validation loss: 0.32257992029190063
Epoch: 76/300 - Train loss: 0.3262125551700592, Validation loss: 0.3188624978065491
Epoch: 77/300 - Train loss: 0.3227287232875824, Validation loss: 0.3157234191894531
Epoch: 78/300 - Train loss: 0.31932511925697327, Validation loss: 0.312328577041626
Epoch: 79/300 - Train loss: 0.31600069999694824, Validation loss: 0.3092368245124817
Epoch: 80/300 - Train loss: 0.312753826379776, Validation loss: 0.30614224076271057
Epoch: 81/300 - Train loss: 0.30958327651023865, Validation loss: 0.3025333285331726
Epoch: 82/300 - Train loss: 0.3064877986907959, Validation loss: 0.29986003041267395
Epoch: 83/300 - Train loss: 0.3034656345844269, Validation loss: 0.2970121502876282
Epoch: 84/300 - Train loss: 0.300515353679657, Validation loss: 0.2937391400337219
Epoch: 85/300 - Train loss: 0.297635018825531, Validation loss: 0.2914316654205322
Epoch: 86/300 - Train loss: 0.2948230803012848, Validation loss: 0.2885400652885437
Epoch: 87/300 - Train loss: 0.29207843542099, Validation loss: 0.2853938043117523
Epoch: 88/300 - Train loss: 0.2893994450569153, Validation loss: 0.2835659384727478
Epoch: 89/300 - Train loss: 0.28678464889526367, Validation loss: 0.28050005435943604
Epoch: 90/300 - Train loss: 0.284232497215271, Validation loss: 0.2779616117477417
Epoch: 91/300 - Train loss: 0.28174132108688354, Validation loss: 0.27556371688842773
Epoch: 92/300 - Train loss: 0.2793096601963043, Validation loss: 0.2735232710838318
Epoch: 93/300 - Train loss: 0.2769359052181244, Validation loss: 0.27119991183280945
Epoch: 94/300 - Train loss: 0.2746184766292572, Validation loss: 0.2689858078956604
Epoch: 95/300 - Train loss: 0.2723560929298401, Validation loss: 0.26633220911026
Epoch: 96/300 - Train loss: 0.2701473534107208, Validation loss: 0.26459816098213196
Epoch: 97/300 - Train loss: 0.2679908871650696, Validation loss: 0.26226234436035156
Epoch: 98/300 - Train loss: 0.26588547229766846, Validation loss: 0.26022833585739136
Epoch: 99/300 - Train loss: 0.2638297975063324, Validation loss: 0.2582888901233673
Epoch: 100/300 - Train loss: 0.26182255148887634, Validation loss: 0.2564396858215332
Epoch: 101/300 - Train loss: 0.2598622739315033, Validation loss: 0.25467103719711304
Epoch: 102/300 - Train loss: 0.2579479515552521, Validation loss: 0.2527870535850525
Epoch: 103/300 - Train loss: 0.25607824325561523, Validation loss: 0.2514858841896057
Epoch: 104/300 - Train loss: 0.25425195693969727, Validation loss: 0.2493269294500351
Epoch: 105/300 - Train loss: 0.2524678111076355, Validation loss: 0.24760796129703522
Epoch: 106/300 - Train loss: 0.2507247030735016, Validation loss: 0.2455490231513977
Epoch: 107/300 - Train loss: 0.24902141094207764, Validation loss: 0.24436065554618835
Epoch: 108/300 - Train loss: 0.24735695123672485, Validation loss: 0.2426043003797531
Epoch: 109/300 - Train loss: 0.24573040008544922, Validation loss: 0.24105773866176605
Epoch: 110/300 - Train loss: 0.24414077401161194, Validation loss: 0.2394210398197174
Epoch: 111/300 - Train loss: 0.2425871044397354, Validation loss: 0.23830784857273102
Epoch: 112/300 - Train loss: 0.24106831848621368, Validation loss: 0.23646056652069092
Epoch: 113/300 - Train loss: 0.2395835667848587, Validation loss: 0.23580752313137054
Epoch: 114/300 - Train loss: 0.23813197016716003, Validation loss: 0.23407098650932312
Epoch: 115/300 - Train loss: 0.23671264946460724, Validation loss: 0.23247502744197845
Epoch: 116/300 - Train loss: 0.23532459139823914, Validation loss: 0.23146852850914001
Epoch: 117/300 - Train loss: 0.23396702110767365, Validation loss: 0.229587584733963
Epoch: 118/300 - Train loss: 0.2326391488313675, Validation loss: 0.2289561629295349
Epoch: 119/300 - Train loss: 0.2313401848077774, Validation loss: 0.22747109830379486
Epoch: 120/300 - Train loss: 0.23006945848464966, Validation loss: 0.22611935436725616
Epoch: 121/300 - Train loss: 0.2288261204957962, Validation loss: 0.22502967715263367
Epoch: 122/300 - Train loss: 0.2276095449924469, Validation loss: 0.22410066425800323
Epoch: 123/300 - Train loss: 0.22641897201538086, Validation loss: 0.22305364906787872
Epoch: 124/300 - Train loss: 0.22525371611118317, Validation loss: 0.221653014421463
Epoch: 125/300 - Train loss: 0.22411313652992249, Validation loss: 0.22063878178596497
Epoch: 126/300 - Train loss: 0.22299660742282867, Validation loss: 0.21939289569854736
Epoch: 127/300 - Train loss: 0.2219035029411316, Validation loss: 0.21878792345523834
Epoch: 128/300 - Train loss: 0.22083325684070587, Validation loss: 0.2174617052078247
Epoch: 129/300 - Train loss: 0.21978534758090973, Validation loss: 0.21673664450645447
Epoch: 130/300 - Train loss: 0.2187591791152954, Validation loss: 0.21570754051208496
Epoch: 131/300 - Train loss: 0.21775418519973755, Validation loss: 0.21503785252571106
Epoch: 132/300 - Train loss: 0.21676982939243317, Validation loss: 0.21357594430446625
Epoch: 133/300 - Train loss: 0.21580559015274048, Validation loss: 0.21294048428535461
Epoch: 134/300 - Train loss: 0.2148609757423401, Validation loss: 0.21196608245372772
Epoch: 135/300 - Train loss: 0.21393552422523499, Validation loss: 0.21118082106113434
Epoch: 136/300 - Train loss: 0.21302877366542816, Validation loss: 0.2106075882911682
Epoch: 137/300 - Train loss: 0.21214023232460022, Validation loss: 0.20920921862125397
Epoch: 138/300 - Train loss: 0.21126948297023773, Validation loss: 0.20899659395217896
Epoch: 139/300 - Train loss: 0.2104160487651825, Validation loss: 0.20815858244895935
Epoch: 140/300 - Train loss: 0.20957951247692108, Validation loss: 0.20765872299671173
Epoch: 141/300 - Train loss: 0.20875947177410126, Validation loss: 0.20572003722190857
Epoch: 142/300 - Train loss: 0.20795556902885437, Validation loss: 0.20578326284885406
Epoch: 143/300 - Train loss: 0.20716732740402222, Validation loss: 0.20469801127910614
Epoch: 144/300 - Train loss: 0.20639443397521973, Validation loss: 0.20391379296779633
Epoch: 145/300 - Train loss: 0.20563654601573944, Validation loss: 0.2032873034477234
Epoch: 146/300 - Train loss: 0.2048932909965515, Validation loss: 0.2027122676372528
Epoch: 147/300 - Train loss: 0.2041642665863037, Validation loss: 0.2018325924873352
Epoch: 148/300 - Train loss: 0.20344915986061096, Validation loss: 0.20178671181201935
Epoch: 149/300 - Train loss: 0.20274776220321655, Validation loss: 0.20106901228427887
Epoch: 150/300 - Train loss: 0.20205959677696228, Validation loss: 0.19984741508960724
Epoch: 151/300 - Train loss: 0.20138446986675262, Validation loss: 0.19979792833328247
Epoch: 152/300 - Train loss: 0.20072196424007416, Validation loss: 0.19922560453414917
Epoch: 153/300 - Train loss: 0.20007187128067017, Validation loss: 0.19863568246364594
Epoch: 154/300 - Train loss: 0.19943390786647797, Validation loss: 0.19776952266693115
Epoch: 155/300 - Train loss: 0.1988077461719513, Validation loss: 0.19742657244205475
Epoch: 156/300 - Train loss: 0.19819320738315582, Validation loss: 0.1967332512140274
Epoch: 157/300 - Train loss: 0.19758999347686768, Validation loss: 0.19639946520328522
Epoch: 158/300 - Train loss: 0.19699785113334656, Validation loss: 0.19617445766925812
