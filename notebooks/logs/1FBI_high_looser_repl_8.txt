Epoch: 1/200 - Train loss: 0.6008533239364624, Validation loss: 0.4935644268989563
Epoch: 2/200 - Train loss: 0.42623913288116455, Validation loss: 0.3689700663089752
Epoch: 3/200 - Train loss: 0.3427996337413788, Validation loss: 0.3116608262062073
Epoch: 4/200 - Train loss: 0.2909667193889618, Validation loss: 0.27192726731300354
Epoch: 5/200 - Train loss: 0.255450963973999, Validation loss: 0.24323628842830658
Epoch: 6/200 - Train loss: 0.2309134155511856, Validation loss: 0.22231857478618622
Epoch: 7/200 - Train loss: 0.2181950807571411, Validation loss: 0.20893017947673798
Epoch: 8/200 - Train loss: 0.21072709560394287, Validation loss: 0.20226243138313293
Epoch: 9/200 - Train loss: 0.2012770175933838, Validation loss: 0.1978052407503128
Epoch: 10/200 - Train loss: 0.1954001486301422, Validation loss: 0.2069171667098999
Epoch: 11/200 - Train loss: 0.18480640649795532, Validation loss: 0.20724229514598846
Epoch: 12/200 - Train loss: 0.18090413510799408, Validation loss: 0.18835625052452087
Epoch: 13/200 - Train loss: 0.1828576922416687, Validation loss: 0.20788852870464325
Epoch: 14/200 - Train loss: 0.1716044545173645, Validation loss: 0.20396161079406738
Epoch: 15/200 - Train loss: 0.1757826954126358, Validation loss: 0.20414601266384125
Epoch: 16/200 - Train loss: 0.17523112893104553, Validation loss: 0.21036778390407562
Epoch: 17/200 - Train loss: 0.17599572241306305, Validation loss: 0.19595587253570557
Epoch: 18/200 - Train loss: 0.17223012447357178, Validation loss: 0.19709676504135132
Epoch: 19/200 - Train loss: 0.17555303871631622, Validation loss: 0.19414566457271576
Epoch: 20/200 - Train loss: 0.16951271891593933, Validation loss: 0.1890239119529724
Epoch: 21/200 - Train loss: 0.17005765438079834, Validation loss: 0.20248296856880188
Epoch: 22/200 - Train loss: 0.17995603382587433, Validation loss: 0.18396614491939545
Epoch: 23/200 - Train loss: 0.1775592565536499, Validation loss: 0.18272927403450012
Epoch: 24/200 - Train loss: 0.17579500377178192, Validation loss: 0.19305302202701569
Epoch: 25/200 - Train loss: 0.17659489810466766, Validation loss: 0.2064451426267624
Epoch: 26/200 - Train loss: 0.17492029070854187, Validation loss: 0.20548319816589355
Epoch: 27/200 - Train loss: 0.1762532740831375, Validation loss: 0.2030726671218872
Epoch: 28/200 - Train loss: 0.1770942211151123, Validation loss: 0.19885188341140747
Epoch: 29/200 - Train loss: 0.17876745760440826, Validation loss: 0.19812652468681335
Epoch: 30/200 - Train loss: 0.17353540658950806, Validation loss: 0.19792671501636505
Epoch: 31/200 - Train loss: 0.17824773490428925, Validation loss: 0.1977645605802536
Epoch: 32/200 - Train loss: 0.17636241018772125, Validation loss: 0.1948476880788803
Epoch: 33/200 - Train loss: 0.1751207560300827, Validation loss: 0.20608371496200562
Epoch: 34/200 - Train loss: 0.1743767261505127, Validation loss: 0.2077748328447342
Epoch: 35/200 - Train loss: 0.17914487421512604, Validation loss: 0.20561546087265015
Epoch: 36/200 - Train loss: 0.1743057519197464, Validation loss: 0.20601624250411987
Epoch: 37/200 - Train loss: 0.17704099416732788, Validation loss: 0.20276722311973572
Epoch: 38/200 - Train loss: 0.17528414726257324, Validation loss: 0.20276036858558655
Epoch: 39/200 - Train loss: 0.17445756494998932, Validation loss: 0.21362952888011932
Epoch: 40/200 - Train loss: 0.17367348074913025, Validation loss: 0.20290496945381165
Epoch: 41/200 - Train loss: 0.17756041884422302, Validation loss: 0.2036655992269516
Epoch: 42/200 - Train loss: 0.1723496913909912, Validation loss: 0.20332753658294678
Epoch: 43/200 - Train loss: 0.17087306082248688, Validation loss: 0.2169710248708725
Epoch: 44/200 - Train loss: 0.169793963432312, Validation loss: 0.2034442275762558
Epoch: 45/200 - Train loss: 0.16910047829151154, Validation loss: 0.2025107443332672
Epoch: 46/200 - Train loss: 0.171395406126976, Validation loss: 0.20067597925662994
Epoch: 47/200 - Train loss: 0.17116694152355194, Validation loss: 0.19955196976661682
Epoch: 48/200 - Train loss: 0.16972129046916962, Validation loss: 0.20192039012908936
Epoch: 49/200 - Train loss: 0.1692398637533188, Validation loss: 0.20045873522758484
Epoch: 50/200 - Train loss: 0.1690008044242859, Validation loss: 0.20131412148475647
Epoch: 51/200 - Train loss: 0.16779732704162598, Validation loss: 0.2253257930278778
Epoch: 52/200 - Train loss: 0.1730053573846817, Validation loss: 0.19980525970458984
Epoch: 53/200 - Train loss: 0.16936837136745453, Validation loss: 0.21758051216602325
Epoch: 54/200 - Train loss: 0.1713864505290985, Validation loss: 0.19859027862548828
Epoch: 55/200 - Train loss: 0.17089499533176422, Validation loss: 0.22464992105960846
Epoch: 56/200 - Train loss: 0.17038366198539734, Validation loss: 0.21308128535747528
Epoch: 57/200 - Train loss: 0.16973139345645905, Validation loss: 0.1993643343448639
Epoch: 58/200 - Train loss: 0.16862432658672333, Validation loss: 0.20988819003105164
Epoch: 59/200 - Train loss: 0.17128664255142212, Validation loss: 0.21589376032352448
Epoch: 60/200 - Train loss: 0.17086142301559448, Validation loss: 0.22253605723381042
Epoch: 61/200 - Train loss: 0.17031250894069672, Validation loss: 0.21099095046520233
Epoch: 62/200 - Train loss: 0.17865204811096191, Validation loss: 0.23467302322387695
Epoch: 63/200 - Train loss: 0.17637363076210022, Validation loss: 0.24767768383026123
Epoch: 64/200 - Train loss: 0.18416178226470947, Validation loss: 0.2470080554485321
Epoch: 65/200 - Train loss: 0.1771860122680664, Validation loss: 0.24714210629463196
Epoch: 66/200 - Train loss: 0.1770632416009903, Validation loss: 0.245335653424263
Epoch: 67/200 - Train loss: 0.17605175077915192, Validation loss: 0.24658940732479095
Epoch: 68/200 - Train loss: 0.178938090801239, Validation loss: 0.2580485939979553
Epoch: 69/200 - Train loss: 0.1787152886390686, Validation loss: 0.24897530674934387
Epoch: 70/200 - Train loss: 0.17700819671154022, Validation loss: 0.24971263110637665
Epoch: 71/200 - Train loss: 0.17763738334178925, Validation loss: 0.24718980491161346
Epoch: 72/200 - Train loss: 0.1803203970193863, Validation loss: 0.24667006731033325
Epoch: 73/200 - Train loss: 0.17369835078716278, Validation loss: 0.2459915578365326
Epoch: 74/200 - Train loss: 0.17716588079929352, Validation loss: 0.2470165193080902
Epoch: 75/200 - Train loss: 0.1780901849269867, Validation loss: 0.2481401413679123
Epoch: 76/200 - Train loss: 0.1755760759115219, Validation loss: 0.248933345079422
Epoch: 77/200 - Train loss: 0.17852303385734558, Validation loss: 0.256935715675354
Epoch: 78/200 - Train loss: 0.1771382987499237, Validation loss: 0.24600139260292053
Epoch: 79/200 - Train loss: 0.17707328498363495, Validation loss: 0.25981149077415466
Epoch: 80/200 - Train loss: 0.1768549382686615, Validation loss: 0.24837280809879303
Epoch: 81/200 - Train loss: 0.17688290774822235, Validation loss: 0.2473437786102295
Epoch: 82/200 - Train loss: 0.17922429740428925, Validation loss: 0.24733877182006836
Epoch: 83/200 - Train loss: 0.1787499189376831, Validation loss: 0.25550130009651184
Epoch: 84/200 - Train loss: 0.18163366615772247, Validation loss: 0.2514135241508484
Epoch: 85/200 - Train loss: 0.1779365986585617, Validation loss: 0.24594296514987946
Epoch: 86/200 - Train loss: 0.17706696689128876, Validation loss: 0.2483728677034378
Epoch: 87/200 - Train loss: 0.1834268718957901, Validation loss: 0.24800574779510498
Epoch: 88/200 - Train loss: 0.17680449783802032, Validation loss: 0.2557695209980011
Epoch: 89/200 - Train loss: 0.17733098566532135, Validation loss: 0.24769628047943115
Epoch: 90/200 - Train loss: 0.1766493022441864, Validation loss: 0.24882175028324127
Epoch: 91/200 - Train loss: 0.1842566430568695, Validation loss: 0.2471098154783249
Epoch: 92/200 - Train loss: 0.1755913496017456, Validation loss: 0.2496010810136795
Epoch: 93/200 - Train loss: 0.17828761041164398, Validation loss: 0.2487284392118454
Epoch: 94/200 - Train loss: 0.1814722865819931, Validation loss: 0.24984633922576904
Epoch: 95/200 - Train loss: 0.1796993762254715, Validation loss: 0.24974894523620605
Epoch: 96/200 - Train loss: 0.18009184300899506, Validation loss: 0.24941302835941315
Epoch: 97/200 - Train loss: 0.18279948830604553, Validation loss: 0.25727665424346924
Epoch: 98/200 - Train loss: 0.17608819901943207, Validation loss: 0.24929705262184143
Epoch: 99/200 - Train loss: 0.176493838429451, Validation loss: 0.25913289189338684
Epoch: 100/200 - Train loss: 0.18223272264003754, Validation loss: 0.24977852404117584
Epoch: 101/200 - Train loss: 0.17919813096523285, Validation loss: 0.2481127232313156
Epoch: 102/200 - Train loss: 0.17914263904094696, Validation loss: 0.24968023598194122
Epoch: 103/200 - Train loss: 0.17584861814975739, Validation loss: 0.24991559982299805
Epoch: 104/200 - Train loss: 0.17819197475910187, Validation loss: 0.2600169777870178
Epoch: 105/200 - Train loss: 0.17789874970912933, Validation loss: 0.25159478187561035
Epoch: 106/200 - Train loss: 0.17769747972488403, Validation loss: 0.2510201036930084
Epoch: 107/200 - Train loss: 0.17754106223583221, Validation loss: 0.25429046154022217
Epoch: 108/200 - Train loss: 0.17979539930820465, Validation loss: 0.252046138048172
Epoch: 109/200 - Train loss: 0.17736724019050598, Validation loss: 0.25350818037986755
Epoch: 110/200 - Train loss: 0.17665772140026093, Validation loss: 0.25074303150177
Epoch: 111/200 - Train loss: 0.17948095500469208, Validation loss: 0.2530863583087921
Epoch: 112/200 - Train loss: 0.17642663419246674, Validation loss: 0.2524862289428711
Epoch: 113/200 - Train loss: 0.17897410690784454, Validation loss: 0.26053792238235474
Epoch: 114/200 - Train loss: 0.17852535843849182, Validation loss: 0.2529546618461609
Epoch: 115/200 - Train loss: 0.17875394225120544, Validation loss: 0.2518739700317383
Epoch: 116/200 - Train loss: 0.1746060699224472, Validation loss: 0.25257059931755066
Epoch: 117/200 - Train loss: 0.1744917780160904, Validation loss: 0.25628530979156494
Epoch: 118/200 - Train loss: 0.17463518679141998, Validation loss: 0.25164374709129333
Epoch: 119/200 - Train loss: 0.1771358847618103, Validation loss: 0.25502854585647583
Epoch: 120/200 - Train loss: 0.17696025967597961, Validation loss: 0.2532061040401459
Epoch: 121/200 - Train loss: 0.17738939821720123, Validation loss: 0.25297683477401733
Epoch: 122/200 - Train loss: 0.17361950874328613, Validation loss: 0.26315370202064514
Epoch: 123/200 - Train loss: 0.17980004847049713, Validation loss: 0.25478535890579224
Epoch: 124/200 - Train loss: 0.1763853281736374, Validation loss: 0.2534765303134918
Epoch: 125/200 - Train loss: 0.17655310034751892, Validation loss: 0.25285035371780396
Epoch: 126/200 - Train loss: 0.17845246195793152, Validation loss: 0.2569110691547394
Epoch: 127/200 - Train loss: 0.17844268679618835, Validation loss: 0.25567418336868286
Epoch: 128/200 - Train loss: 0.1784697026014328, Validation loss: 0.2575090527534485
Epoch: 129/200 - Train loss: 0.17515982687473297, Validation loss: 0.25872018933296204
Epoch: 130/200 - Train loss: 0.1748361587524414, Validation loss: 0.2550082504749298
Epoch: 131/200 - Train loss: 0.17479044198989868, Validation loss: 0.25622642040252686
Epoch: 132/200 - Train loss: 0.17799966037273407, Validation loss: 0.25690409541130066
Epoch: 133/200 - Train loss: 0.17706263065338135, Validation loss: 0.2536312937736511
Epoch: 134/200 - Train loss: 0.17754916846752167, Validation loss: 0.2586502134799957
Epoch: 135/200 - Train loss: 0.17678508162498474, Validation loss: 0.26866528391838074
Epoch: 136/200 - Train loss: 0.17701010406017303, Validation loss: 0.25825852155685425
Epoch: 137/200 - Train loss: 0.17670762538909912, Validation loss: 0.2573171555995941
Epoch: 138/200 - Train loss: 0.17596936225891113, Validation loss: 0.25511234998703003
Epoch: 139/200 - Train loss: 0.17594771087169647, Validation loss: 0.25602543354034424
Epoch: 140/200 - Train loss: 0.1761113852262497, Validation loss: 0.2565075755119324
Epoch: 141/200 - Train loss: 0.17670492827892303, Validation loss: 0.25896596908569336
Epoch: 142/200 - Train loss: 0.17615525424480438, Validation loss: 0.2589268684387207
Epoch: 143/200 - Train loss: 0.17535674571990967, Validation loss: 0.2606188654899597
Epoch: 144/200 - Train loss: 0.1754884272813797, Validation loss: 0.25899237394332886
Epoch: 145/200 - Train loss: 0.17486369609832764, Validation loss: 0.2581849992275238
Epoch: 146/200 - Train loss: 0.17494210600852966, Validation loss: 0.2606301009654999
Epoch: 147/200 - Train loss: 0.1748659461736679, Validation loss: 0.2602787911891937
Epoch: 148/200 - Train loss: 0.17430917918682098, Validation loss: 0.2715115547180176
Epoch: 149/200 - Train loss: 0.1803823560476303, Validation loss: 0.27401554584503174
Epoch: 150/200 - Train loss: 0.17440319061279297, Validation loss: 0.2704545855522156
Epoch: 151/200 - Train loss: 0.17413751780986786, Validation loss: 0.26182594895362854
Epoch: 152/200 - Train loss: 0.17479151487350464, Validation loss: 0.25824519991874695
Epoch: 153/200 - Train loss: 0.1742064654827118, Validation loss: 0.2744769752025604
Epoch: 154/200 - Train loss: 0.17351612448692322, Validation loss: 0.27419987320899963
Epoch: 155/200 - Train loss: 0.17365825176239014, Validation loss: 0.26183319091796875
Epoch: 156/200 - Train loss: 0.17279674112796783, Validation loss: 0.2646438479423523
Epoch: 157/200 - Train loss: 0.1733100563287735, Validation loss: 0.26282408833503723
Epoch: 158/200 - Train loss: 0.17285969853401184, Validation loss: 0.26414477825164795
Epoch: 159/200 - Train loss: 0.17275592684745789, Validation loss: 0.274245947599411
Epoch: 160/200 - Train loss: 0.17273849248886108, Validation loss: 0.2614681124687195
Epoch: 161/200 - Train loss: 0.17303553223609924, Validation loss: 0.2636597156524658
Epoch: 162/200 - Train loss: 0.17254985868930817, Validation loss: 0.26594191789627075
Epoch: 163/200 - Train loss: 0.1721673309803009, Validation loss: 0.2619704604148865
Epoch: 164/200 - Train loss: 0.17218630015850067, Validation loss: 0.26420992612838745
Epoch: 165/200 - Train loss: 0.17186221480369568, Validation loss: 0.2665645182132721
Epoch: 166/200 - Train loss: 0.1714780181646347, Validation loss: 0.272255539894104
Epoch: 167/200 - Train loss: 0.171456441283226, Validation loss: 0.2645406723022461
Epoch: 168/200 - Train loss: 0.1717664897441864, Validation loss: 0.28086647391319275
Epoch: 169/200 - Train loss: 0.17224131524562836, Validation loss: 0.27719777822494507
Epoch: 170/200 - Train loss: 0.17383204400539398, Validation loss: 0.2677335739135742
Epoch: 171/200 - Train loss: 0.17143428325653076, Validation loss: 0.2888719439506531
Epoch: 172/200 - Train loss: 0.1680309921503067, Validation loss: 0.2794545292854309
Epoch: 173/200 - Train loss: 0.1671840101480484, Validation loss: 0.27843835949897766
Epoch: 174/200 - Train loss: 0.1674410104751587, Validation loss: 0.279826819896698
Epoch: 175/200 - Train loss: 0.1678665429353714, Validation loss: 0.2809821665287018
Epoch: 176/200 - Train loss: 0.16735616326332092, Validation loss: 0.2808965742588043
Epoch: 177/200 - Train loss: 0.1726914495229721, Validation loss: 0.2795580327510834
Epoch: 178/200 - Train loss: 0.16730041801929474, Validation loss: 0.27945271134376526
Epoch: 179/200 - Train loss: 0.1668231189250946, Validation loss: 0.26990145444869995
Epoch: 180/200 - Train loss: 0.16707409918308258, Validation loss: 0.2678079605102539
Epoch: 181/200 - Train loss: 0.1673714965581894, Validation loss: 0.28577184677124023
Epoch: 182/200 - Train loss: 0.16612878441810608, Validation loss: 0.28475940227508545
Epoch: 183/200 - Train loss: 0.16663497686386108, Validation loss: 0.29195505380630493
Epoch: 184/200 - Train loss: 0.16639554500579834, Validation loss: 0.28309211134910583
Epoch: 185/200 - Train loss: 0.16600370407104492, Validation loss: 0.28304463624954224
Epoch: 186/200 - Train loss: 0.16574673354625702, Validation loss: 0.28039851784706116
Epoch: 187/200 - Train loss: 0.1661471426486969, Validation loss: 0.28034472465515137
Epoch: 188/200 - Train loss: 0.16510634124279022, Validation loss: 0.28413835167884827
Epoch: 189/200 - Train loss: 0.1657259613275528, Validation loss: 0.2835630774497986
Epoch: 190/200 - Train loss: 0.16523659229278564, Validation loss: 0.288239985704422
Epoch: 191/200 - Train loss: 0.16540002822875977, Validation loss: 0.29541492462158203
Epoch: 192/200 - Train loss: 0.16614046692848206, Validation loss: 0.28287047147750854
Epoch: 193/200 - Train loss: 0.16537097096443176, Validation loss: 0.2851451635360718
Epoch: 194/200 - Train loss: 0.16495339572429657, Validation loss: 0.2875790297985077
Epoch: 195/200 - Train loss: 0.16997258365154266, Validation loss: 0.28832095861434937
Epoch: 196/200 - Train loss: 0.1654711365699768, Validation loss: 0.2857171297073364
Epoch: 197/200 - Train loss: 0.16426195204257965, Validation loss: 0.2957475483417511
Epoch: 198/200 - Train loss: 0.1646176129579544, Validation loss: 0.28461456298828125
Epoch: 199/200 - Train loss: 0.16439254581928253, Validation loss: 0.29856565594673157
Epoch: 200/200 - Train loss: 0.16939899325370789, Validation loss: 0.31366783380508423
