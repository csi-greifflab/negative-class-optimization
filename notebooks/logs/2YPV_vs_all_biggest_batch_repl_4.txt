Epoch: 1/300 - Train loss: 0.6918948888778687, Validation loss: 0.6899070739746094
Epoch: 2/300 - Train loss: 0.6900125741958618, Validation loss: 0.6879804134368896
Epoch: 3/300 - Train loss: 0.6880751848220825, Validation loss: 0.6860280632972717
Epoch: 4/300 - Train loss: 0.6860611438751221, Validation loss: 0.6838868856430054
Epoch: 5/300 - Train loss: 0.683933675289154, Validation loss: 0.6816691756248474
Epoch: 6/300 - Train loss: 0.6816567182540894, Validation loss: 0.679207980632782
Epoch: 7/300 - Train loss: 0.6791990995407104, Validation loss: 0.6766660213470459
Epoch: 8/300 - Train loss: 0.6765438318252563, Validation loss: 0.6738072633743286
Epoch: 9/300 - Train loss: 0.6736851930618286, Validation loss: 0.6707503199577332
Epoch: 10/300 - Train loss: 0.6706228256225586, Validation loss: 0.6675096750259399
Epoch: 11/300 - Train loss: 0.6673653721809387, Validation loss: 0.6641284823417664
Epoch: 12/300 - Train loss: 0.6639232039451599, Validation loss: 0.6605032682418823
Epoch: 13/300 - Train loss: 0.6603155732154846, Validation loss: 0.6567750573158264
Epoch: 14/300 - Train loss: 0.6565590500831604, Validation loss: 0.6528984904289246
Epoch: 15/300 - Train loss: 0.6526630520820618, Validation loss: 0.6488910913467407
Epoch: 16/300 - Train loss: 0.6486437916755676, Validation loss: 0.6448209881782532
Epoch: 17/300 - Train loss: 0.6445133686065674, Validation loss: 0.6405798196792603
Epoch: 18/300 - Train loss: 0.6402839422225952, Validation loss: 0.6363028883934021
Epoch: 19/300 - Train loss: 0.6359684467315674, Validation loss: 0.6319202184677124
Epoch: 20/300 - Train loss: 0.6315796375274658, Validation loss: 0.6274863481521606
Epoch: 21/300 - Train loss: 0.627124011516571, Validation loss: 0.6229318380355835
Epoch: 22/300 - Train loss: 0.622614324092865, Validation loss: 0.6185979843139648
Epoch: 23/300 - Train loss: 0.6180590391159058, Validation loss: 0.613684892654419
Epoch: 24/300 - Train loss: 0.613464891910553, Validation loss: 0.609414279460907
Epoch: 25/300 - Train loss: 0.6088361144065857, Validation loss: 0.6046816110610962
Epoch: 26/300 - Train loss: 0.6041765213012695, Validation loss: 0.6001461148262024
Epoch: 27/300 - Train loss: 0.5994889140129089, Validation loss: 0.5952887535095215
Epoch: 28/300 - Train loss: 0.59477698802948, Validation loss: 0.5905489325523376
Epoch: 29/300 - Train loss: 0.5900421142578125, Validation loss: 0.5857847929000854
Epoch: 30/300 - Train loss: 0.5852890610694885, Validation loss: 0.5811380743980408
Epoch: 31/300 - Train loss: 0.5805215835571289, Validation loss: 0.5762351155281067
Epoch: 32/300 - Train loss: 0.5757441520690918, Validation loss: 0.5716534852981567
Epoch: 33/300 - Train loss: 0.570961594581604, Validation loss: 0.5666901469230652
Epoch: 34/300 - Train loss: 0.5661775469779968, Validation loss: 0.5620198249816895
Epoch: 35/300 - Train loss: 0.5613982081413269, Validation loss: 0.5574295520782471
Epoch: 36/300 - Train loss: 0.5566284656524658, Validation loss: 0.5526424646377563
Epoch: 37/300 - Train loss: 0.5518732070922852, Validation loss: 0.5478352904319763
Epoch: 38/300 - Train loss: 0.5471362471580505, Validation loss: 0.543120801448822
Epoch: 39/300 - Train loss: 0.5424214005470276, Validation loss: 0.5382831692695618
Epoch: 40/300 - Train loss: 0.5377331972122192, Validation loss: 0.5340747833251953
Epoch: 41/300 - Train loss: 0.533075749874115, Validation loss: 0.5290203094482422
Epoch: 42/300 - Train loss: 0.5284528136253357, Validation loss: 0.5244521498680115
Epoch: 43/300 - Train loss: 0.5238681435585022, Validation loss: 0.5202550888061523
Epoch: 44/300 - Train loss: 0.5193250179290771, Validation loss: 0.5159234404563904
Epoch: 45/300 - Train loss: 0.5148264765739441, Validation loss: 0.5114096999168396
Epoch: 46/300 - Train loss: 0.5103757381439209, Validation loss: 0.5065119862556458
Epoch: 47/300 - Train loss: 0.505975604057312, Validation loss: 0.502241313457489
Epoch: 48/300 - Train loss: 0.5016289949417114, Validation loss: 0.4982842803001404
Epoch: 49/300 - Train loss: 0.4973383843898773, Validation loss: 0.4939291477203369
Epoch: 50/300 - Train loss: 0.49310627579689026, Validation loss: 0.48964154720306396
Epoch: 51/300 - Train loss: 0.48893487453460693, Validation loss: 0.4859427213668823
Epoch: 52/300 - Train loss: 0.48482632637023926, Validation loss: 0.4814360737800598
Epoch: 53/300 - Train loss: 0.48078247904777527, Validation loss: 0.47739624977111816
Epoch: 54/300 - Train loss: 0.4768049716949463, Validation loss: 0.4732797145843506
Epoch: 55/300 - Train loss: 0.47289523482322693, Validation loss: 0.4693141281604767
Epoch: 56/300 - Train loss: 0.46905478835105896, Validation loss: 0.46593326330184937
Epoch: 57/300 - Train loss: 0.46528422832489014, Validation loss: 0.46216875314712524
Epoch: 58/300 - Train loss: 0.46158432960510254, Validation loss: 0.45823630690574646
Epoch: 59/300 - Train loss: 0.45795559883117676, Validation loss: 0.45512473583221436
Epoch: 60/300 - Train loss: 0.45439857244491577, Validation loss: 0.45155397057533264
Epoch: 61/300 - Train loss: 0.45091304183006287, Validation loss: 0.4483266770839691
Epoch: 62/300 - Train loss: 0.44749900698661804, Validation loss: 0.4448554515838623
Epoch: 63/300 - Train loss: 0.4441562592983246, Validation loss: 0.4412902891635895
Epoch: 64/300 - Train loss: 0.4408845901489258, Validation loss: 0.4380059838294983
Epoch: 65/300 - Train loss: 0.43768367171287537, Validation loss: 0.4351140260696411
Epoch: 66/300 - Train loss: 0.43455252051353455, Validation loss: 0.43211284279823303
Epoch: 67/300 - Train loss: 0.43149083852767944, Validation loss: 0.4287557005882263
Epoch: 68/300 - Train loss: 0.42849794030189514, Validation loss: 0.42544060945510864
Epoch: 69/300 - Train loss: 0.42557260394096375, Validation loss: 0.42273399233818054
Epoch: 70/300 - Train loss: 0.42271432280540466, Validation loss: 0.4198029935359955
Epoch: 71/300 - Train loss: 0.41992196440696716, Validation loss: 0.41765809059143066
Epoch: 72/300 - Train loss: 0.4171939790248871, Validation loss: 0.41437843441963196
Epoch: 73/300 - Train loss: 0.4145289957523346, Validation loss: 0.4123309254646301
Epoch: 74/300 - Train loss: 0.4119262099266052, Validation loss: 0.4093138575553894
Epoch: 75/300 - Train loss: 0.40938422083854675, Validation loss: 0.406628280878067
Epoch: 76/300 - Train loss: 0.4069017469882965, Validation loss: 0.40472865104675293
Epoch: 77/300 - Train loss: 0.40447697043418884, Validation loss: 0.40221962332725525
Epoch: 78/300 - Train loss: 0.40210843086242676, Validation loss: 0.3993755578994751
Epoch: 79/300 - Train loss: 0.3997949957847595, Validation loss: 0.3974931836128235
Epoch: 80/300 - Train loss: 0.39753520488739014, Validation loss: 0.3952920436859131
Epoch: 81/300 - Train loss: 0.39532706141471863, Validation loss: 0.39284610748291016
Epoch: 82/300 - Train loss: 0.39317020773887634, Validation loss: 0.3913842439651489
Epoch: 83/300 - Train loss: 0.39106273651123047, Validation loss: 0.3888804316520691
Epoch: 84/300 - Train loss: 0.389003187417984, Validation loss: 0.3872774839401245
Epoch: 85/300 - Train loss: 0.38698968291282654, Validation loss: 0.3844964802265167
Epoch: 86/300 - Train loss: 0.38502025604248047, Validation loss: 0.38225802779197693
Epoch: 87/300 - Train loss: 0.38309404253959656, Validation loss: 0.3809158205986023
Epoch: 88/300 - Train loss: 0.38120993971824646, Validation loss: 0.3787404000759125
Epoch: 89/300 - Train loss: 0.3793673813343048, Validation loss: 0.3778301179409027
Epoch: 90/300 - Train loss: 0.3775639832019806, Validation loss: 0.374756395816803
Epoch: 91/300 - Train loss: 0.3757994472980499, Validation loss: 0.3729381263256073
Epoch: 92/300 - Train loss: 0.37407156825065613, Validation loss: 0.37216347455978394
Epoch: 93/300 - Train loss: 0.37237903475761414, Validation loss: 0.3700314164161682
Epoch: 94/300 - Train loss: 0.37072163820266724, Validation loss: 0.36839351058006287
Epoch: 95/300 - Train loss: 0.36909809708595276, Validation loss: 0.3668536841869354
Epoch: 96/300 - Train loss: 0.3675078749656677, Validation loss: 0.3655591309070587
Epoch: 97/300 - Train loss: 0.36594870686531067, Validation loss: 0.36323949694633484
Epoch: 98/300 - Train loss: 0.3644202649593353, Validation loss: 0.36268702149391174
Epoch: 99/300 - Train loss: 0.3629210889339447, Validation loss: 0.3609512746334076
Epoch: 100/300 - Train loss: 0.3614504933357239, Validation loss: 0.35887280106544495
Epoch: 101/300 - Train loss: 0.3600073754787445, Validation loss: 0.3577038049697876
Epoch: 102/300 - Train loss: 0.3585917055606842, Validation loss: 0.3559708595275879
Epoch: 103/300 - Train loss: 0.3572019636631012, Validation loss: 0.3551570773124695
Epoch: 104/300 - Train loss: 0.3558368682861328, Validation loss: 0.35431525111198425
Epoch: 105/300 - Train loss: 0.3544951379299164, Validation loss: 0.35204440355300903
Epoch: 106/300 - Train loss: 0.35317662358283997, Validation loss: 0.3512950539588928
Epoch: 107/300 - Train loss: 0.3518814742565155, Validation loss: 0.34980300068855286
Epoch: 108/300 - Train loss: 0.3506090044975281, Validation loss: 0.3482731878757477
Epoch: 109/300 - Train loss: 0.34935879707336426, Validation loss: 0.3469672203063965
Epoch: 110/300 - Train loss: 0.34812992811203003, Validation loss: 0.3467881381511688
Epoch: 111/300 - Train loss: 0.34692245721817017, Validation loss: 0.34502753615379333
Epoch: 112/300 - Train loss: 0.3457370102405548, Validation loss: 0.34371674060821533
Epoch: 113/300 - Train loss: 0.34457099437713623, Validation loss: 0.34244346618652344
Epoch: 114/300 - Train loss: 0.34342318773269653, Validation loss: 0.341217964887619
Epoch: 115/300 - Train loss: 0.3422929644584656, Validation loss: 0.3404909372329712
Epoch: 116/300 - Train loss: 0.3411818742752075, Validation loss: 0.3390730023384094
Epoch: 117/300 - Train loss: 0.34008893370628357, Validation loss: 0.33851158618927
Epoch: 118/300 - Train loss: 0.3390143811702728, Validation loss: 0.33686983585357666
Epoch: 119/300 - Train loss: 0.3379575312137604, Validation loss: 0.3361607491970062
Epoch: 120/300 - Train loss: 0.33691805601119995, Validation loss: 0.33467215299606323
Epoch: 121/300 - Train loss: 0.33589524030685425, Validation loss: 0.3343193233013153
Epoch: 122/300 - Train loss: 0.33488917350769043, Validation loss: 0.3339237570762634
Epoch: 123/300 - Train loss: 0.33389922976493835, Validation loss: 0.3318105638027191
Epoch: 124/300 - Train loss: 0.3329244554042816, Validation loss: 0.33100804686546326
Epoch: 125/300 - Train loss: 0.3319641947746277, Validation loss: 0.3305215835571289
Epoch: 126/300 - Train loss: 0.3310182988643646, Validation loss: 0.32983827590942383
Epoch: 127/300 - Train loss: 0.33008646965026855, Validation loss: 0.3284127116203308
Epoch: 128/300 - Train loss: 0.3291694223880768, Validation loss: 0.32740461826324463
Epoch: 129/300 - Train loss: 0.3282668888568878, Validation loss: 0.3261308968067169
Epoch: 130/300 - Train loss: 0.3273780941963196, Validation loss: 0.32555076479911804
Epoch: 131/300 - Train loss: 0.32650232315063477, Validation loss: 0.3247779309749603
Epoch: 132/300 - Train loss: 0.3256390392780304, Validation loss: 0.32474982738494873
Epoch: 133/300 - Train loss: 0.32478755712509155, Validation loss: 0.32283592224121094
Epoch: 134/300 - Train loss: 0.32394689321517944, Validation loss: 0.3225766122341156
Epoch: 135/300 - Train loss: 0.3231172263622284, Validation loss: 0.3220115602016449
Epoch: 136/300 - Train loss: 0.3222990930080414, Validation loss: 0.3204266130924225
Epoch: 137/300 - Train loss: 0.3214930593967438, Validation loss: 0.32026270031929016
Epoch: 138/300 - Train loss: 0.3206973075866699, Validation loss: 0.31950274109840393
Epoch: 139/300 - Train loss: 0.3199131488800049, Validation loss: 0.3182567059993744
Epoch: 140/300 - Train loss: 0.31914010643959045, Validation loss: 0.3179289698600769
Epoch: 141/300 - Train loss: 0.3183777928352356, Validation loss: 0.31712424755096436
Epoch: 142/300 - Train loss: 0.3176249861717224, Validation loss: 0.3167382478713989
Epoch: 143/300 - Train loss: 0.3168826401233673, Validation loss: 0.3155648112297058
Epoch: 144/300 - Train loss: 0.3161502480506897, Validation loss: 0.3149690330028534
Epoch: 145/300 - Train loss: 0.315428763628006, Validation loss: 0.3147171437740326
Epoch: 146/300 - Train loss: 0.3147185146808624, Validation loss: 0.31454163789749146
Epoch: 147/300 - Train loss: 0.3140183687210083, Validation loss: 0.31276455521583557
Epoch: 148/300 - Train loss: 0.3133280575275421, Validation loss: 0.31205546855926514
Epoch: 149/300 - Train loss: 0.31264716386795044, Validation loss: 0.31172579526901245
Epoch: 150/300 - Train loss: 0.31197547912597656, Validation loss: 0.31220412254333496
Epoch: 151/300 - Train loss: 0.311312735080719, Validation loss: 0.31094926595687866
Epoch: 152/300 - Train loss: 0.31065821647644043, Validation loss: 0.3103767931461334
Epoch: 153/300 - Train loss: 0.3100121021270752, Validation loss: 0.3093681335449219
Epoch: 154/300 - Train loss: 0.3093735873699188, Validation loss: 0.3087621331214905
Epoch: 155/300 - Train loss: 0.30874302983283997, Validation loss: 0.30808234214782715
Epoch: 156/300 - Train loss: 0.30812034010887146, Validation loss: 0.30748850107192993
Epoch: 157/300 - Train loss: 0.30750495195388794, Validation loss: 0.3067699372768402
Epoch: 158/300 - Train loss: 0.3068966865539551, Validation loss: 0.3066664934158325
Epoch: 159/300 - Train loss: 0.3062952160835266, Validation loss: 0.30603569746017456
Epoch: 160/300 - Train loss: 0.30570000410079956, Validation loss: 0.30528467893600464
Epoch: 161/300 - Train loss: 0.3051116168498993, Validation loss: 0.30555692315101624
Epoch: 162/300 - Train loss: 0.30452990531921387, Validation loss: 0.30501309037208557
