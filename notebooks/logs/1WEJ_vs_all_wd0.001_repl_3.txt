Epoch: 1/300 - Train loss: 0.6946277022361755, Validation loss: 0.692274808883667
Epoch: 2/300 - Train loss: 0.6930056214332581, Validation loss: 0.6906551122665405
Epoch: 3/300 - Train loss: 0.6913578510284424, Validation loss: 0.6890175938606262
Epoch: 4/300 - Train loss: 0.6896023154258728, Validation loss: 0.6871909499168396
Epoch: 5/300 - Train loss: 0.6876941919326782, Validation loss: 0.6851912140846252
Epoch: 6/300 - Train loss: 0.6855982542037964, Validation loss: 0.6830019354820251
Epoch: 7/300 - Train loss: 0.6832988262176514, Validation loss: 0.6805874109268188
Epoch: 8/300 - Train loss: 0.6807918548583984, Validation loss: 0.6780878305435181
Epoch: 9/300 - Train loss: 0.678083062171936, Validation loss: 0.6753163933753967
Epoch: 10/300 - Train loss: 0.6751770377159119, Validation loss: 0.6723434925079346
Epoch: 11/300 - Train loss: 0.6720874309539795, Validation loss: 0.66926509141922
Epoch: 12/300 - Train loss: 0.6688318252563477, Validation loss: 0.6660535931587219
Epoch: 13/300 - Train loss: 0.6654203534126282, Validation loss: 0.6626488566398621
Epoch: 14/300 - Train loss: 0.6618731617927551, Validation loss: 0.6591091752052307
Epoch: 15/300 - Train loss: 0.6582071781158447, Validation loss: 0.6555377840995789
Epoch: 16/300 - Train loss: 0.6544402837753296, Validation loss: 0.6518192887306213
Epoch: 17/300 - Train loss: 0.6505829691886902, Validation loss: 0.6480205059051514
Epoch: 18/300 - Train loss: 0.646659791469574, Validation loss: 0.6441870927810669
Epoch: 19/300 - Train loss: 0.6426856517791748, Validation loss: 0.64023756980896
Epoch: 20/300 - Train loss: 0.6386731863021851, Validation loss: 0.6364544630050659
Epoch: 21/300 - Train loss: 0.6346339583396912, Validation loss: 0.6324798464775085
Epoch: 22/300 - Train loss: 0.6305800080299377, Validation loss: 0.6283918619155884
Epoch: 23/300 - Train loss: 0.6265131831169128, Validation loss: 0.6245632171630859
Epoch: 24/300 - Train loss: 0.6224375367164612, Validation loss: 0.6205284595489502
Epoch: 25/300 - Train loss: 0.6183565855026245, Validation loss: 0.6164113879203796
Epoch: 26/300 - Train loss: 0.6142703294754028, Validation loss: 0.6125428080558777
Epoch: 27/300 - Train loss: 0.6101822853088379, Validation loss: 0.6084317564964294
Epoch: 28/300 - Train loss: 0.6060971617698669, Validation loss: 0.6045947074890137
Epoch: 29/300 - Train loss: 0.6020169258117676, Validation loss: 0.6004383563995361
Epoch: 30/300 - Train loss: 0.5979454517364502, Validation loss: 0.5965934991836548
Epoch: 31/300 - Train loss: 0.5938884019851685, Validation loss: 0.5925611257553101
Epoch: 32/300 - Train loss: 0.5898489356040955, Validation loss: 0.588611900806427
Epoch: 33/300 - Train loss: 0.5858291387557983, Validation loss: 0.5847153663635254
Epoch: 34/300 - Train loss: 0.5818321704864502, Validation loss: 0.5808491110801697
Epoch: 35/300 - Train loss: 0.5778599977493286, Validation loss: 0.576811671257019
Epoch: 36/300 - Train loss: 0.573914647102356, Validation loss: 0.5728529691696167
Epoch: 37/300 - Train loss: 0.5699974298477173, Validation loss: 0.5688640475273132
Epoch: 38/300 - Train loss: 0.5661095976829529, Validation loss: 0.5652379989624023
Epoch: 39/300 - Train loss: 0.5622532367706299, Validation loss: 0.5614089965820312
Epoch: 40/300 - Train loss: 0.5584283471107483, Validation loss: 0.5574368238449097
Epoch: 41/300 - Train loss: 0.5546363592147827, Validation loss: 0.5537322759628296
Epoch: 42/300 - Train loss: 0.5508784055709839, Validation loss: 0.5499635338783264
Epoch: 43/300 - Train loss: 0.5471542477607727, Validation loss: 0.5463051795959473
Epoch: 44/300 - Train loss: 0.5434653759002686, Validation loss: 0.5428237318992615
Epoch: 45/300 - Train loss: 0.539812445640564, Validation loss: 0.5392162203788757
Epoch: 46/300 - Train loss: 0.5361960530281067, Validation loss: 0.5356733798980713
Epoch: 47/300 - Train loss: 0.532615602016449, Validation loss: 0.5318514108657837
Epoch: 48/300 - Train loss: 0.5290716886520386, Validation loss: 0.5285517573356628
Epoch: 49/300 - Train loss: 0.5255654454231262, Validation loss: 0.5248943567276001
Epoch: 50/300 - Train loss: 0.5220970511436462, Validation loss: 0.5219852328300476
Epoch: 51/300 - Train loss: 0.5186666250228882, Validation loss: 0.5179460644721985
Epoch: 52/300 - Train loss: 0.5152738094329834, Validation loss: 0.5145657658576965
Epoch: 53/300 - Train loss: 0.5119192004203796, Validation loss: 0.5117021799087524
Epoch: 54/300 - Train loss: 0.5086036324501038, Validation loss: 0.5082307457923889
Epoch: 55/300 - Train loss: 0.5053287148475647, Validation loss: 0.5050747394561768
Epoch: 56/300 - Train loss: 0.5020942091941833, Validation loss: 0.5020470023155212
Epoch: 57/300 - Train loss: 0.4989004135131836, Validation loss: 0.4986943304538727
Epoch: 58/300 - Train loss: 0.49574756622314453, Validation loss: 0.4955042004585266
Epoch: 59/300 - Train loss: 0.4926358759403229, Validation loss: 0.492593914270401
Epoch: 60/300 - Train loss: 0.48956596851348877, Validation loss: 0.4892214834690094
Epoch: 61/300 - Train loss: 0.4865379333496094, Validation loss: 0.4862913489341736
Epoch: 62/300 - Train loss: 0.48355135321617126, Validation loss: 0.4831257164478302
Epoch: 63/300 - Train loss: 0.4806064963340759, Validation loss: 0.4804673194885254
Epoch: 64/300 - Train loss: 0.47770336270332336, Validation loss: 0.4778563976287842
Epoch: 65/300 - Train loss: 0.47484225034713745, Validation loss: 0.47470152378082275
Epoch: 66/300 - Train loss: 0.4720233082771301, Validation loss: 0.47163137793540955
Epoch: 67/300 - Train loss: 0.46924683451652527, Validation loss: 0.46868541836738586
Epoch: 68/300 - Train loss: 0.4665136933326721, Validation loss: 0.46618497371673584
Epoch: 69/300 - Train loss: 0.463823139667511, Validation loss: 0.4638616442680359
Epoch: 70/300 - Train loss: 0.46117591857910156, Validation loss: 0.46082180738449097
Epoch: 71/300 - Train loss: 0.45857176184654236, Validation loss: 0.4585365951061249
Epoch: 72/300 - Train loss: 0.45601069927215576, Validation loss: 0.4559415876865387
Epoch: 73/300 - Train loss: 0.4534929692745209, Validation loss: 0.45331618189811707
Epoch: 74/300 - Train loss: 0.45101797580718994, Validation loss: 0.4506981372833252
Epoch: 75/300 - Train loss: 0.44858595728874207, Validation loss: 0.44859203696250916
Epoch: 76/300 - Train loss: 0.4461958408355713, Validation loss: 0.4460027813911438
Epoch: 77/300 - Train loss: 0.4438476264476776, Validation loss: 0.4429624378681183
Epoch: 78/300 - Train loss: 0.4415416419506073, Validation loss: 0.4412752091884613
Epoch: 79/300 - Train loss: 0.43927764892578125, Validation loss: 0.4390150010585785
Epoch: 80/300 - Train loss: 0.43705543875694275, Validation loss: 0.4369871914386749
Epoch: 81/300 - Train loss: 0.43487444519996643, Validation loss: 0.43496280908584595
Epoch: 82/300 - Train loss: 0.43273407220840454, Validation loss: 0.4324198365211487
Epoch: 83/300 - Train loss: 0.4306345283985138, Validation loss: 0.4304492175579071
Epoch: 84/300 - Train loss: 0.42857518792152405, Validation loss: 0.4284004271030426
Epoch: 85/300 - Train loss: 0.42655566334724426, Validation loss: 0.42656657099723816
Epoch: 86/300 - Train loss: 0.424575537443161, Validation loss: 0.42481380701065063
Epoch: 87/300 - Train loss: 0.42263346910476685, Validation loss: 0.422268807888031
Epoch: 88/300 - Train loss: 0.4207295775413513, Validation loss: 0.41996830701828003
Epoch: 89/300 - Train loss: 0.4188634753227234, Validation loss: 0.41799288988113403
Epoch: 90/300 - Train loss: 0.41703468561172485, Validation loss: 0.4164535701274872
Epoch: 91/300 - Train loss: 0.4152432680130005, Validation loss: 0.41529732942581177
Epoch: 92/300 - Train loss: 0.4134877324104309, Validation loss: 0.41257622838020325
Epoch: 93/300 - Train loss: 0.4117673933506012, Validation loss: 0.4113548994064331
Epoch: 94/300 - Train loss: 0.41008222103118896, Validation loss: 0.40963834524154663
Epoch: 95/300 - Train loss: 0.4084309935569763, Validation loss: 0.4080262780189514
Epoch: 96/300 - Train loss: 0.4068138897418976, Validation loss: 0.40581339597702026
Epoch: 97/300 - Train loss: 0.40523001551628113, Validation loss: 0.4045995771884918
Epoch: 98/300 - Train loss: 0.40367865562438965, Validation loss: 0.4029136598110199
Epoch: 99/300 - Train loss: 0.4021584987640381, Validation loss: 0.4020187556743622
Epoch: 100/300 - Train loss: 0.40066951513290405, Validation loss: 0.4005151093006134
Epoch: 101/300 - Train loss: 0.39921143651008606, Validation loss: 0.39847332239151
Epoch: 102/300 - Train loss: 0.3977833390235901, Validation loss: 0.3975934386253357
Epoch: 103/300 - Train loss: 0.39638420939445496, Validation loss: 0.3950578570365906
Epoch: 104/300 - Train loss: 0.39501360058784485, Validation loss: 0.39413967728614807
Epoch: 105/300 - Train loss: 0.39367052912712097, Validation loss: 0.39272046089172363
Epoch: 106/300 - Train loss: 0.3923543691635132, Validation loss: 0.3915928304195404
Epoch: 107/300 - Train loss: 0.3910648822784424, Validation loss: 0.3900854289531708
Epoch: 108/300 - Train loss: 0.38980093598365784, Validation loss: 0.389323353767395
Epoch: 109/300 - Train loss: 0.3885619044303894, Validation loss: 0.3875712752342224
Epoch: 110/300 - Train loss: 0.387347549200058, Validation loss: 0.38638100028038025
Epoch: 111/300 - Train loss: 0.38615721464157104, Validation loss: 0.38486042618751526
Epoch: 112/300 - Train loss: 0.38498929142951965, Validation loss: 0.38456395268440247
Epoch: 113/300 - Train loss: 0.38384386897087097, Validation loss: 0.3829057216644287
Epoch: 114/300 - Train loss: 0.382720410823822, Validation loss: 0.3814575970172882
Epoch: 115/300 - Train loss: 0.38161763548851013, Validation loss: 0.3804078698158264
Epoch: 116/300 - Train loss: 0.3805346190929413, Validation loss: 0.3791121244430542
Epoch: 117/300 - Train loss: 0.3794730305671692, Validation loss: 0.37834909558296204
Epoch: 118/300 - Train loss: 0.3784305155277252, Validation loss: 0.3766353130340576
Epoch: 119/300 - Train loss: 0.3774060308933258, Validation loss: 0.376568466424942
Epoch: 120/300 - Train loss: 0.37639912962913513, Validation loss: 0.3748786449432373
Epoch: 121/300 - Train loss: 0.3754088878631592, Validation loss: 0.37440723180770874
Epoch: 122/300 - Train loss: 0.37443625926971436, Validation loss: 0.3729228973388672
Epoch: 123/300 - Train loss: 0.373479962348938, Validation loss: 0.37171781063079834
Epoch: 124/300 - Train loss: 0.3725396692752838, Validation loss: 0.3710728585720062
Epoch: 125/300 - Train loss: 0.37161529064178467, Validation loss: 0.37021657824516296
Epoch: 126/300 - Train loss: 0.37070563435554504, Validation loss: 0.36922207474708557
Epoch: 127/300 - Train loss: 0.36980924010276794, Validation loss: 0.3680456280708313
Epoch: 128/300 - Train loss: 0.3689254820346832, Validation loss: 0.3672035038471222
Epoch: 129/300 - Train loss: 0.3680543303489685, Validation loss: 0.36628368496894836
Epoch: 130/300 - Train loss: 0.36719539761543274, Validation loss: 0.36569738388061523
Epoch: 131/300 - Train loss: 0.36634761095046997, Validation loss: 0.3653010129928589
Epoch: 132/300 - Train loss: 0.3655112385749817, Validation loss: 0.36356472969055176
Epoch: 133/300 - Train loss: 0.3646852374076843, Validation loss: 0.363338828086853
Epoch: 134/300 - Train loss: 0.3638700544834137, Validation loss: 0.3617658317089081
Epoch: 135/300 - Train loss: 0.36306601762771606, Validation loss: 0.36129721999168396
Epoch: 136/300 - Train loss: 0.36227166652679443, Validation loss: 0.3604658246040344
Epoch: 137/300 - Train loss: 0.36148855090141296, Validation loss: 0.360332727432251
Epoch: 138/300 - Train loss: 0.3607156276702881, Validation loss: 0.3587493598461151
Epoch: 139/300 - Train loss: 0.3599522113800049, Validation loss: 0.3586646616458893
Epoch: 140/300 - Train loss: 0.3591982126235962, Validation loss: 0.3571891784667969
Epoch: 141/300 - Train loss: 0.3584546744823456, Validation loss: 0.3567466139793396
Epoch: 142/300 - Train loss: 0.35771989822387695, Validation loss: 0.35659730434417725
Epoch: 143/300 - Train loss: 0.3569938838481903, Validation loss: 0.35510364174842834
Epoch: 144/300 - Train loss: 0.3562771677970886, Validation loss: 0.3552497327327728
Epoch: 145/300 - Train loss: 0.3555692732334137, Validation loss: 0.3538966774940491
Epoch: 146/300 - Train loss: 0.3548700511455536, Validation loss: 0.35312405228614807
Epoch: 147/300 - Train loss: 0.3541792333126068, Validation loss: 0.35169699788093567
Epoch: 148/300 - Train loss: 0.3534964919090271, Validation loss: 0.3514712452888489
Epoch: 149/300 - Train loss: 0.3528236150741577, Validation loss: 0.35093945264816284
Epoch: 150/300 - Train loss: 0.35215991735458374, Validation loss: 0.34999218583106995
Epoch: 151/300 - Train loss: 0.35150498151779175, Validation loss: 0.3489021062850952
Epoch: 152/300 - Train loss: 0.35085803270339966, Validation loss: 0.3487875163555145
Epoch: 153/300 - Train loss: 0.3502179682254791, Validation loss: 0.3483988046646118
Epoch: 154/300 - Train loss: 0.3495853543281555, Validation loss: 0.34732699394226074
Epoch: 155/300 - Train loss: 0.34895986318588257, Validation loss: 0.34676581621170044
Epoch: 156/300 - Train loss: 0.348341166973114, Validation loss: 0.3461454510688782
Epoch: 157/300 - Train loss: 0.34772932529449463, Validation loss: 0.345747172832489
Epoch: 158/300 - Train loss: 0.34712523221969604, Validation loss: 0.34499627351760864
Epoch: 159/300 - Train loss: 0.3465286195278168, Validation loss: 0.34450048208236694
Epoch: 160/300 - Train loss: 0.34594017267227173, Validation loss: 0.343949556350708
