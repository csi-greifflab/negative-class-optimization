Epoch: 1/200 - Train loss: 0.6132429838180542, Validation loss: 0.5610083341598511
Epoch: 2/200 - Train loss: 0.5201417803764343, Validation loss: 0.5085544586181641
Epoch: 3/200 - Train loss: 0.4677683413028717, Validation loss: 0.4580003619194031
Epoch: 4/200 - Train loss: 0.42339882254600525, Validation loss: 0.4231891334056854
Epoch: 5/200 - Train loss: 0.39145588874816895, Validation loss: 0.3995436728000641
Epoch: 6/200 - Train loss: 0.36640840768814087, Validation loss: 0.38289472460746765
Epoch: 7/200 - Train loss: 0.35120317339897156, Validation loss: 0.3726184368133545
Epoch: 8/200 - Train loss: 0.3394651412963867, Validation loss: 0.36665353178977966
Epoch: 9/200 - Train loss: 0.331470251083374, Validation loss: 0.3621232509613037
Epoch: 10/200 - Train loss: 0.32399046421051025, Validation loss: 0.35993635654449463
Epoch: 11/200 - Train loss: 0.3180607557296753, Validation loss: 0.35415130853652954
Epoch: 12/200 - Train loss: 0.31298837065696716, Validation loss: 0.352975070476532
Epoch: 13/200 - Train loss: 0.30771294236183167, Validation loss: 0.35214143991470337
Epoch: 14/200 - Train loss: 0.3026313781738281, Validation loss: 0.3474216163158417
Epoch: 15/200 - Train loss: 0.29852795600891113, Validation loss: 0.3454478681087494
Epoch: 16/200 - Train loss: 0.29407501220703125, Validation loss: 0.3434818685054779
Epoch: 17/200 - Train loss: 0.2896038293838501, Validation loss: 0.34136879444122314
Epoch: 18/200 - Train loss: 0.28478220105171204, Validation loss: 0.3377791941165924
Epoch: 19/200 - Train loss: 0.2799186706542969, Validation loss: 0.3374378979206085
Epoch: 20/200 - Train loss: 0.27607694268226624, Validation loss: 0.3277570605278015
Epoch: 21/200 - Train loss: 0.2719433605670929, Validation loss: 0.3273160755634308
Epoch: 22/200 - Train loss: 0.26781678199768066, Validation loss: 0.32170993089675903
Epoch: 23/200 - Train loss: 0.2654476463794708, Validation loss: 0.3209836781024933
Epoch: 24/200 - Train loss: 0.2604285478591919, Validation loss: 0.31538307666778564
Epoch: 25/200 - Train loss: 0.25779229402542114, Validation loss: 0.3159157931804657
Epoch: 26/200 - Train loss: 0.2548956871032715, Validation loss: 0.3128989338874817
Epoch: 27/200 - Train loss: 0.251752644777298, Validation loss: 0.31037500500679016
Epoch: 28/200 - Train loss: 0.2484203279018402, Validation loss: 0.30847683548927307
Epoch: 29/200 - Train loss: 0.2469998449087143, Validation loss: 0.3095529079437256
Epoch: 30/200 - Train loss: 0.24407801032066345, Validation loss: 0.30810147523880005
Epoch: 31/200 - Train loss: 0.24224460124969482, Validation loss: 0.30381831526756287
Epoch: 32/200 - Train loss: 0.24067215621471405, Validation loss: 0.3075975775718689
Epoch: 33/200 - Train loss: 0.23970897495746613, Validation loss: 0.30307134985923767
Epoch: 34/200 - Train loss: 0.237483412027359, Validation loss: 0.30386853218078613
Epoch: 35/200 - Train loss: 0.2363925725221634, Validation loss: 0.3045212924480438
Epoch: 36/200 - Train loss: 0.23564095795154572, Validation loss: 0.30102208256721497
Epoch: 37/200 - Train loss: 0.23379649221897125, Validation loss: 0.3019859194755554
Epoch: 38/200 - Train loss: 0.2330041229724884, Validation loss: 0.3014816641807556
Epoch: 39/200 - Train loss: 0.2315841168165207, Validation loss: 0.3002183437347412
Epoch: 40/200 - Train loss: 0.23085175454616547, Validation loss: 0.30109667778015137
Epoch: 41/200 - Train loss: 0.2305458039045334, Validation loss: 0.2984347641468048
Epoch: 42/200 - Train loss: 0.22974012792110443, Validation loss: 0.3034268915653229
Epoch: 43/200 - Train loss: 0.22866302728652954, Validation loss: 0.2988447844982147
Epoch: 44/200 - Train loss: 0.22847457230091095, Validation loss: 0.300335168838501
Epoch: 45/200 - Train loss: 0.22774435579776764, Validation loss: 0.3005913197994232
Epoch: 1/200 - Train loss: 0.579203724861145, Validation loss: 0.493484228849411
Epoch: 2/200 - Train loss: 0.46957963705062866, Validation loss: 0.4574439823627472
Epoch: 3/200 - Train loss: 0.4308668076992035, Validation loss: 0.42481333017349243
Epoch: 4/200 - Train loss: 0.3977607786655426, Validation loss: 0.395588219165802
Epoch: 5/200 - Train loss: 0.3663804531097412, Validation loss: 0.3700367212295532
Epoch: 6/200 - Train loss: 0.3405309021472931, Validation loss: 0.3530701696872711
Epoch: 7/200 - Train loss: 0.3214109241962433, Validation loss: 0.342786967754364
Epoch: 8/200 - Train loss: 0.30806705355644226, Validation loss: 0.3325735032558441
Epoch: 9/200 - Train loss: 0.29725751280784607, Validation loss: 0.32732492685317993
Epoch: 10/200 - Train loss: 0.28766611218452454, Validation loss: 0.32187730073928833
Epoch: 11/200 - Train loss: 0.2816588580608368, Validation loss: 0.3142360746860504
Epoch: 12/200 - Train loss: 0.27689555287361145, Validation loss: 0.3145434558391571
Epoch: 13/200 - Train loss: 0.27267542481422424, Validation loss: 0.30917155742645264
Epoch: 14/200 - Train loss: 0.2682008743286133, Validation loss: 0.3013620674610138
Epoch: 15/200 - Train loss: 0.26396444439888, Validation loss: 0.30716755986213684
Epoch: 16/200 - Train loss: 0.26234379410743713, Validation loss: 0.2997237741947174
Epoch: 17/200 - Train loss: 0.25981953740119934, Validation loss: 0.29984065890312195
Epoch: 18/200 - Train loss: 0.2586022615432739, Validation loss: 0.2947642207145691
Epoch: 19/200 - Train loss: 0.2548464834690094, Validation loss: 0.29627782106399536
Epoch: 20/200 - Train loss: 0.2534831166267395, Validation loss: 0.29778164625167847
Epoch: 21/200 - Train loss: 0.25287508964538574, Validation loss: 0.2927173972129822
Epoch: 22/200 - Train loss: 0.2508015036582947, Validation loss: 0.29371318221092224
Epoch: 23/200 - Train loss: 0.24913710355758667, Validation loss: 0.2882295548915863
Epoch: 24/200 - Train loss: 0.2490721046924591, Validation loss: 0.3102882206439972
Epoch: 25/200 - Train loss: 0.24824418127536774, Validation loss: 0.28962117433547974
Epoch: 26/200 - Train loss: 0.24659255146980286, Validation loss: 0.28695616126060486
Epoch: 27/200 - Train loss: 0.24650168418884277, Validation loss: 0.28788965940475464
Epoch: 28/200 - Train loss: 0.2455369383096695, Validation loss: 0.2896135449409485
Epoch: 29/200 - Train loss: 0.24483714997768402, Validation loss: 0.2914838194847107
Epoch: 30/200 - Train loss: 0.2437802404165268, Validation loss: 0.2905123233795166
Epoch: 31/200 - Train loss: 0.24276752769947052, Validation loss: 0.28500765562057495
Epoch: 32/200 - Train loss: 0.24208249151706696, Validation loss: 0.2899171710014343
Epoch: 33/200 - Train loss: 0.24146176874637604, Validation loss: 0.2860755920410156
Epoch: 34/200 - Train loss: 0.2398005872964859, Validation loss: 0.28940334916114807
Epoch: 35/200 - Train loss: 0.23910394310951233, Validation loss: 0.2885829210281372
Epoch: 36/200 - Train loss: 0.23862412571907043, Validation loss: 0.28593334555625916
Epoch: 37/200 - Train loss: 0.23762889206409454, Validation loss: 0.2829645574092865
Epoch: 38/200 - Train loss: 0.23853249847888947, Validation loss: 0.284612238407135
Epoch: 39/200 - Train loss: 0.23791110515594482, Validation loss: 0.28578251600265503
Epoch: 40/200 - Train loss: 0.23622891306877136, Validation loss: 0.28432637453079224
Epoch: 41/200 - Train loss: 0.23639731109142303, Validation loss: 0.28132522106170654
Epoch: 42/200 - Train loss: 0.23351570963859558, Validation loss: 0.2823754847049713
Epoch: 43/200 - Train loss: 0.23494967818260193, Validation loss: 0.2824287712574005
Epoch: 44/200 - Train loss: 0.23351462185382843, Validation loss: 0.28266674280166626
Epoch: 45/200 - Train loss: 0.23374883830547333, Validation loss: 0.2838429808616638
