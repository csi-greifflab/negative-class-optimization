Epoch: 1/300 - Train loss: 0.7000231742858887, Validation loss: 0.6982095241546631
Epoch: 2/300 - Train loss: 0.6982717514038086, Validation loss: 0.6964925527572632
Epoch: 3/300 - Train loss: 0.6965777277946472, Validation loss: 0.6948964595794678
Epoch: 4/300 - Train loss: 0.6949323415756226, Validation loss: 0.6932854056358337
Epoch: 5/300 - Train loss: 0.693328320980072, Validation loss: 0.6917218565940857
Epoch: 6/300 - Train loss: 0.6917544603347778, Validation loss: 0.6902503967285156
Epoch: 7/300 - Train loss: 0.6901984810829163, Validation loss: 0.6886354088783264
Epoch: 8/300 - Train loss: 0.6886477470397949, Validation loss: 0.6871258616447449
Epoch: 9/300 - Train loss: 0.6870911121368408, Validation loss: 0.6856132745742798
Epoch: 10/300 - Train loss: 0.685521125793457, Validation loss: 0.6840171813964844
Epoch: 11/300 - Train loss: 0.6839300394058228, Validation loss: 0.6824280023574829
Epoch: 12/300 - Train loss: 0.6823092103004456, Validation loss: 0.6808918118476868
Epoch: 13/300 - Train loss: 0.6806548237800598, Validation loss: 0.6791459918022156
Epoch: 14/300 - Train loss: 0.6789584159851074, Validation loss: 0.6774341464042664
Epoch: 15/300 - Train loss: 0.6772148609161377, Validation loss: 0.6757938861846924
Epoch: 16/300 - Train loss: 0.6754194498062134, Validation loss: 0.6738932728767395
Epoch: 17/300 - Train loss: 0.6735701560974121, Validation loss: 0.6721393465995789
Epoch: 18/300 - Train loss: 0.6716654300689697, Validation loss: 0.6701667308807373
Epoch: 19/300 - Train loss: 0.6697012186050415, Validation loss: 0.6681943535804749
Epoch: 20/300 - Train loss: 0.6676756143569946, Validation loss: 0.6661704182624817
Epoch: 21/300 - Train loss: 0.6655860543251038, Validation loss: 0.6641995310783386
Epoch: 22/300 - Train loss: 0.6634349822998047, Validation loss: 0.6619343757629395
Epoch: 23/300 - Train loss: 0.6612231135368347, Validation loss: 0.6598864793777466
Epoch: 24/300 - Train loss: 0.6589500308036804, Validation loss: 0.6575979590415955
Epoch: 25/300 - Train loss: 0.6566169261932373, Validation loss: 0.6552966833114624
Epoch: 26/300 - Train loss: 0.6542248129844666, Validation loss: 0.6529849767684937
Epoch: 27/300 - Train loss: 0.6517744660377502, Validation loss: 0.6505591869354248
Epoch: 28/300 - Train loss: 0.6492707133293152, Validation loss: 0.6480505466461182
Epoch: 29/300 - Train loss: 0.6467161774635315, Validation loss: 0.6454901099205017
Epoch: 30/300 - Train loss: 0.6441100239753723, Validation loss: 0.643074631690979
Epoch: 31/300 - Train loss: 0.6414573192596436, Validation loss: 0.6403272747993469
Epoch: 32/300 - Train loss: 0.6387588977813721, Validation loss: 0.6377894282341003
Epoch: 33/300 - Train loss: 0.6360194087028503, Validation loss: 0.6350719332695007
Epoch: 34/300 - Train loss: 0.6332433223724365, Validation loss: 0.6325681209564209
Epoch: 35/300 - Train loss: 0.6304340958595276, Validation loss: 0.6295453310012817
Epoch: 36/300 - Train loss: 0.6275966167449951, Validation loss: 0.6269541382789612
Epoch: 37/300 - Train loss: 0.6247355937957764, Validation loss: 0.6242172718048096
Epoch: 38/300 - Train loss: 0.6218527555465698, Validation loss: 0.621250569820404
Epoch: 39/300 - Train loss: 0.6189526915550232, Validation loss: 0.6183918118476868
Epoch: 40/300 - Train loss: 0.6160406470298767, Validation loss: 0.6155425310134888
Epoch: 41/300 - Train loss: 0.6131197214126587, Validation loss: 0.6127397418022156
Epoch: 42/300 - Train loss: 0.6101933717727661, Validation loss: 0.610123336315155
Epoch: 43/300 - Train loss: 0.6072651147842407, Validation loss: 0.6073747873306274
Epoch: 44/300 - Train loss: 0.6043397188186646, Validation loss: 0.6043071150779724
Epoch: 45/300 - Train loss: 0.6014220714569092, Validation loss: 0.6016070246696472
Epoch: 46/300 - Train loss: 0.5985150933265686, Validation loss: 0.5987359285354614
Epoch: 47/300 - Train loss: 0.5956229567527771, Validation loss: 0.5961719155311584
Epoch: 48/300 - Train loss: 0.5927498936653137, Validation loss: 0.5934634804725647
Epoch: 49/300 - Train loss: 0.5898987054824829, Validation loss: 0.5903759598731995
Epoch: 50/300 - Train loss: 0.5870735049247742, Validation loss: 0.5881769061088562
Epoch: 51/300 - Train loss: 0.5842759609222412, Validation loss: 0.5855121612548828
Epoch: 52/300 - Train loss: 0.5815098285675049, Validation loss: 0.5828630328178406
Epoch: 53/300 - Train loss: 0.5787758231163025, Validation loss: 0.5803311467170715
Epoch: 54/300 - Train loss: 0.5760775208473206, Validation loss: 0.5776985287666321
Epoch: 55/300 - Train loss: 0.5734166502952576, Validation loss: 0.5751137137413025
Epoch: 56/300 - Train loss: 0.5707966089248657, Validation loss: 0.5729246735572815
Epoch: 57/300 - Train loss: 0.5682190656661987, Validation loss: 0.5705989599227905
Epoch: 58/300 - Train loss: 0.5656854510307312, Validation loss: 0.5680466294288635
Epoch: 59/300 - Train loss: 0.563197135925293, Validation loss: 0.5655381083488464
Epoch: 60/300 - Train loss: 0.5607543587684631, Validation loss: 0.5631603598594666
Epoch: 61/300 - Train loss: 0.5583584308624268, Validation loss: 0.5610333681106567
Epoch: 62/300 - Train loss: 0.5560089945793152, Validation loss: 0.558971643447876
Epoch: 63/300 - Train loss: 0.5537064671516418, Validation loss: 0.5565971732139587
Epoch: 64/300 - Train loss: 0.551452100276947, Validation loss: 0.5549785494804382
Epoch: 65/300 - Train loss: 0.5492457151412964, Validation loss: 0.5526446104049683
Epoch: 66/300 - Train loss: 0.5470864176750183, Validation loss: 0.551074206829071
Epoch: 67/300 - Train loss: 0.5449749231338501, Validation loss: 0.5486794710159302
Epoch: 68/300 - Train loss: 0.5429113507270813, Validation loss: 0.5468177199363708
Epoch: 69/300 - Train loss: 0.5408955216407776, Validation loss: 0.5448068976402283
Epoch: 70/300 - Train loss: 0.5389271378517151, Validation loss: 0.5431503057479858
Epoch: 71/300 - Train loss: 0.5370047092437744, Validation loss: 0.5412291288375854
Epoch: 72/300 - Train loss: 0.5351276993751526, Validation loss: 0.5397035479545593
Epoch: 73/300 - Train loss: 0.5332947969436646, Validation loss: 0.5384290814399719
Epoch: 74/300 - Train loss: 0.5315044522285461, Validation loss: 0.5361359715461731
Epoch: 75/300 - Train loss: 0.5297574996948242, Validation loss: 0.534585177898407
Epoch: 76/300 - Train loss: 0.5280511975288391, Validation loss: 0.5325350165367126
Epoch: 77/300 - Train loss: 0.526383101940155, Validation loss: 0.5315234661102295
Epoch: 78/300 - Train loss: 0.5247541666030884, Validation loss: 0.5296469330787659
Epoch: 79/300 - Train loss: 0.5231624245643616, Validation loss: 0.5279870629310608
Epoch: 80/300 - Train loss: 0.5216053128242493, Validation loss: 0.5267933011054993
Epoch: 81/300 - Train loss: 0.5200818181037903, Validation loss: 0.5254731178283691
Epoch: 82/300 - Train loss: 0.5185905694961548, Validation loss: 0.5239737629890442
Epoch: 83/300 - Train loss: 0.517131507396698, Validation loss: 0.522480845451355
Epoch: 84/300 - Train loss: 0.5157032012939453, Validation loss: 0.5206466913223267
Epoch: 85/300 - Train loss: 0.5143032073974609, Validation loss: 0.5202352404594421
Epoch: 86/300 - Train loss: 0.5129307508468628, Validation loss: 0.5189884305000305
Epoch: 87/300 - Train loss: 0.5115863680839539, Validation loss: 0.5174224972724915
Epoch: 88/300 - Train loss: 0.5102678537368774, Validation loss: 0.5161231756210327
Epoch: 89/300 - Train loss: 0.5089743137359619, Validation loss: 0.5152885317802429
Epoch: 90/300 - Train loss: 0.5077036619186401, Validation loss: 0.5136618614196777
Epoch: 91/300 - Train loss: 0.5064539313316345, Validation loss: 0.5126644372940063
Epoch: 92/300 - Train loss: 0.5052247047424316, Validation loss: 0.5116927623748779
Epoch: 93/300 - Train loss: 0.5040132403373718, Validation loss: 0.5101518034934998
Epoch: 94/300 - Train loss: 0.5028207898139954, Validation loss: 0.5094810724258423
Epoch: 95/300 - Train loss: 0.5016475915908813, Validation loss: 0.5076397061347961
Epoch: 96/300 - Train loss: 0.5004923939704895, Validation loss: 0.5070333480834961
Epoch: 97/300 - Train loss: 0.4993540346622467, Validation loss: 0.5062395930290222
Epoch: 98/300 - Train loss: 0.49823233485221863, Validation loss: 0.5053228735923767
Epoch: 99/300 - Train loss: 0.4971245527267456, Validation loss: 0.503299355506897
Epoch: 100/300 - Train loss: 0.4960322380065918, Validation loss: 0.5026692748069763
Epoch: 101/300 - Train loss: 0.4949542284011841, Validation loss: 0.5020712614059448
Epoch: 102/300 - Train loss: 0.4938909709453583, Validation loss: 0.5005883574485779
Epoch: 103/300 - Train loss: 0.4928417503833771, Validation loss: 0.4999564290046692
Epoch: 104/300 - Train loss: 0.49180731177330017, Validation loss: 0.4988495707511902
Epoch: 105/300 - Train loss: 0.49078723788261414, Validation loss: 0.4978811740875244
Epoch: 106/300 - Train loss: 0.4897777736186981, Validation loss: 0.4969823956489563
Epoch: 107/300 - Train loss: 0.48878079652786255, Validation loss: 0.49581411480903625
Epoch: 108/300 - Train loss: 0.4877963960170746, Validation loss: 0.49479085206985474
Epoch: 109/300 - Train loss: 0.4868226647377014, Validation loss: 0.49380868673324585
Epoch: 110/300 - Train loss: 0.48586156964302063, Validation loss: 0.4933274984359741
Epoch: 111/300 - Train loss: 0.48491063714027405, Validation loss: 0.4923694431781769
Epoch: 112/300 - Train loss: 0.48396968841552734, Validation loss: 0.4909849166870117
Epoch: 113/300 - Train loss: 0.4830375909805298, Validation loss: 0.49025920033454895
Epoch: 114/300 - Train loss: 0.4821140468120575, Validation loss: 0.49000516533851624
Epoch: 115/300 - Train loss: 0.48119935393333435, Validation loss: 0.4890584945678711
Epoch: 116/300 - Train loss: 0.48029276728630066, Validation loss: 0.48790740966796875
Epoch: 117/300 - Train loss: 0.4793935716152191, Validation loss: 0.4873061776161194
Epoch: 118/300 - Train loss: 0.4785015285015106, Validation loss: 0.48591697216033936
Epoch: 119/300 - Train loss: 0.4776161015033722, Validation loss: 0.4852967858314514
Epoch: 120/300 - Train loss: 0.47673743963241577, Validation loss: 0.4850318431854248
Epoch: 121/300 - Train loss: 0.4758674204349518, Validation loss: 0.483731210231781
Epoch: 122/300 - Train loss: 0.47500333189964294, Validation loss: 0.48307812213897705
Epoch: 123/300 - Train loss: 0.47414538264274597, Validation loss: 0.4818117320537567
Epoch: 124/300 - Train loss: 0.4732941687107086, Validation loss: 0.48201823234558105
Epoch: 125/300 - Train loss: 0.4724496006965637, Validation loss: 0.4805980622768402
Epoch: 126/300 - Train loss: 0.47161027789115906, Validation loss: 0.4800756573677063
Epoch: 127/300 - Train loss: 0.47077545523643494, Validation loss: 0.4787478744983673
Epoch: 128/300 - Train loss: 0.4699479043483734, Validation loss: 0.4779244661331177
Epoch: 129/300 - Train loss: 0.4691271185874939, Validation loss: 0.47760137915611267
Epoch: 130/300 - Train loss: 0.4683130383491516, Validation loss: 0.4767593741416931
Epoch: 131/300 - Train loss: 0.46750539541244507, Validation loss: 0.476462721824646
Epoch: 132/300 - Train loss: 0.46670418977737427, Validation loss: 0.47523802518844604
Epoch: 133/300 - Train loss: 0.46590864658355713, Validation loss: 0.4742075502872467
Epoch: 134/300 - Train loss: 0.4651188850402832, Validation loss: 0.47315502166748047
Epoch: 135/300 - Train loss: 0.4643363654613495, Validation loss: 0.4733179211616516
Epoch: 136/300 - Train loss: 0.4635584056377411, Validation loss: 0.4721027910709381
Epoch: 137/300 - Train loss: 0.4627854526042938, Validation loss: 0.47144362330436707
Epoch: 138/300 - Train loss: 0.4620180130004883, Validation loss: 0.47061687707901
Epoch: 139/300 - Train loss: 0.46125638484954834, Validation loss: 0.47031402587890625
Epoch: 140/300 - Train loss: 0.46050122380256653, Validation loss: 0.46921825408935547
Epoch: 141/300 - Train loss: 0.4597524404525757, Validation loss: 0.46855759620666504
Epoch: 142/300 - Train loss: 0.45901015400886536, Validation loss: 0.4681790769100189
Epoch: 143/300 - Train loss: 0.4582735002040863, Validation loss: 0.4672005772590637
Epoch: 144/300 - Train loss: 0.4575433135032654, Validation loss: 0.4671674072742462
Epoch: 145/300 - Train loss: 0.45681971311569214, Validation loss: 0.46650442481040955
Epoch: 146/300 - Train loss: 0.4561024606227875, Validation loss: 0.4657955467700958
Epoch: 147/300 - Train loss: 0.45539072155952454, Validation loss: 0.4643784761428833
Epoch: 148/300 - Train loss: 0.45468443632125854, Validation loss: 0.46380874514579773
Epoch: 149/300 - Train loss: 0.45398324728012085, Validation loss: 0.463932603597641
Epoch: 150/300 - Train loss: 0.4532870948314667, Validation loss: 0.46290287375450134
Epoch: 151/300 - Train loss: 0.45259636640548706, Validation loss: 0.4623098075389862
Epoch: 152/300 - Train loss: 0.45191118121147156, Validation loss: 0.46184423565864563
Epoch: 153/300 - Train loss: 0.45123112201690674, Validation loss: 0.46193405985832214
Epoch: 154/300 - Train loss: 0.45055606961250305, Validation loss: 0.46041885018348694
Epoch: 155/300 - Train loss: 0.44988489151000977, Validation loss: 0.45973658561706543
Epoch: 156/300 - Train loss: 0.449219673871994, Validation loss: 0.45866402983665466
Epoch: 157/300 - Train loss: 0.4485592246055603, Validation loss: 0.4588797390460968
Epoch: 158/300 - Train loss: 0.4479047656059265, Validation loss: 0.4575713574886322
Epoch: 159/300 - Train loss: 0.44725409150123596, Validation loss: 0.4572294354438782
Epoch: 160/300 - Train loss: 0.4466075003147125, Validation loss: 0.4567455053329468
Epoch: 161/300 - Train loss: 0.4459647238254547, Validation loss: 0.45644262433052063
Epoch: 162/300 - Train loss: 0.4453262388706207, Validation loss: 0.4558402895927429
Epoch: 163/300 - Train loss: 0.44469180703163147, Validation loss: 0.4551261365413666
Epoch: 164/300 - Train loss: 0.4440612494945526, Validation loss: 0.45482170581817627
