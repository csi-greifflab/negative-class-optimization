Epoch: 1/300 - Train loss: 0.7119865417480469, Validation loss: 0.7115882039070129
Epoch: 2/300 - Train loss: 0.7088824510574341, Validation loss: 0.708547055721283
Epoch: 3/300 - Train loss: 0.705901026725769, Validation loss: 0.705549955368042
Epoch: 4/300 - Train loss: 0.7030347585678101, Validation loss: 0.7030321359634399
Epoch: 5/300 - Train loss: 0.7002810835838318, Validation loss: 0.7002049088478088
Epoch: 6/300 - Train loss: 0.6976372599601746, Validation loss: 0.6976227164268494
Epoch: 7/300 - Train loss: 0.6950871348381042, Validation loss: 0.6952470541000366
Epoch: 8/300 - Train loss: 0.6926378011703491, Validation loss: 0.6927773952484131
Epoch: 9/300 - Train loss: 0.6902683973312378, Validation loss: 0.6905166506767273
Epoch: 10/300 - Train loss: 0.6879698634147644, Validation loss: 0.6882369518280029
Epoch: 11/300 - Train loss: 0.6857368350028992, Validation loss: 0.6860172152519226
Epoch: 12/300 - Train loss: 0.6835581660270691, Validation loss: 0.6838924288749695
Epoch: 13/300 - Train loss: 0.6814220547676086, Validation loss: 0.6817498803138733
Epoch: 14/300 - Train loss: 0.6793215274810791, Validation loss: 0.6796603798866272
Epoch: 15/300 - Train loss: 0.6772514581680298, Validation loss: 0.6775845885276794
Epoch: 16/300 - Train loss: 0.6751963496208191, Validation loss: 0.6754773855209351
Epoch: 17/300 - Train loss: 0.6731480956077576, Validation loss: 0.6733483672142029
Epoch: 18/300 - Train loss: 0.6710947155952454, Validation loss: 0.6714980006217957
Epoch: 19/300 - Train loss: 0.6690261363983154, Validation loss: 0.6693925261497498
Epoch: 20/300 - Train loss: 0.6669414639472961, Validation loss: 0.6673197150230408
Epoch: 21/300 - Train loss: 0.6648275852203369, Validation loss: 0.6650866866111755
Epoch: 22/300 - Train loss: 0.6626806855201721, Validation loss: 0.6629416942596436
Epoch: 23/300 - Train loss: 0.6604958176612854, Validation loss: 0.6607652306556702
Epoch: 24/300 - Train loss: 0.6582714915275574, Validation loss: 0.6585750579833984
Epoch: 25/300 - Train loss: 0.6559988260269165, Validation loss: 0.6563053131103516
Epoch: 26/300 - Train loss: 0.6536737680435181, Validation loss: 0.6538537740707397
Epoch: 27/300 - Train loss: 0.6512923240661621, Validation loss: 0.6516863107681274
Epoch: 28/300 - Train loss: 0.6488527059555054, Validation loss: 0.6491276025772095
Epoch: 29/300 - Train loss: 0.6463510990142822, Validation loss: 0.6466064453125
Epoch: 30/300 - Train loss: 0.6437869668006897, Validation loss: 0.644240140914917
Epoch: 31/300 - Train loss: 0.6411606073379517, Validation loss: 0.6415762305259705
Epoch: 32/300 - Train loss: 0.6384768486022949, Validation loss: 0.6389381289482117
Epoch: 33/300 - Train loss: 0.6357365250587463, Validation loss: 0.6361660957336426
Epoch: 34/300 - Train loss: 0.6329417824745178, Validation loss: 0.633777379989624
Epoch: 35/300 - Train loss: 0.6300999522209167, Validation loss: 0.6307451128959656
Epoch: 36/300 - Train loss: 0.6272140145301819, Validation loss: 0.6282280683517456
Epoch: 37/300 - Train loss: 0.6242882013320923, Validation loss: 0.6252703070640564
Epoch: 38/300 - Train loss: 0.6213277578353882, Validation loss: 0.6223320364952087
Epoch: 39/300 - Train loss: 0.6183373928070068, Validation loss: 0.6193244457244873
Epoch: 40/300 - Train loss: 0.6153226494789124, Validation loss: 0.6164767146110535
Epoch: 41/300 - Train loss: 0.6122896671295166, Validation loss: 0.6137508153915405
Epoch: 42/300 - Train loss: 0.6092481017112732, Validation loss: 0.6109912991523743
Epoch: 43/300 - Train loss: 0.6062014102935791, Validation loss: 0.6079949140548706
Epoch: 44/300 - Train loss: 0.6031574010848999, Validation loss: 0.6049801111221313
Epoch: 45/300 - Train loss: 0.6001185178756714, Validation loss: 0.6020143628120422
Epoch: 46/300 - Train loss: 0.5970910787582397, Validation loss: 0.5989062190055847
Epoch: 47/300 - Train loss: 0.5940794944763184, Validation loss: 0.5961712598800659
Epoch: 48/300 - Train loss: 0.5910860896110535, Validation loss: 0.5934096574783325
Epoch: 49/300 - Train loss: 0.5881150960922241, Validation loss: 0.5906277894973755
Epoch: 50/300 - Train loss: 0.5851731300354004, Validation loss: 0.5877904295921326
Epoch: 51/300 - Train loss: 0.5822617411613464, Validation loss: 0.5849120616912842
Epoch: 52/300 - Train loss: 0.579384446144104, Validation loss: 0.5822279453277588
Epoch: 53/300 - Train loss: 0.5765429735183716, Validation loss: 0.5789110064506531
Epoch: 54/300 - Train loss: 0.5737388134002686, Validation loss: 0.5763095617294312
Epoch: 55/300 - Train loss: 0.5709722638130188, Validation loss: 0.5741825103759766
Epoch: 56/300 - Train loss: 0.5682454109191895, Validation loss: 0.5713695287704468
Epoch: 57/300 - Train loss: 0.5655630230903625, Validation loss: 0.5692936182022095
Epoch: 58/300 - Train loss: 0.5629252195358276, Validation loss: 0.5663774609565735
Epoch: 59/300 - Train loss: 0.5603334307670593, Validation loss: 0.5639954805374146
Epoch: 60/300 - Train loss: 0.5577892065048218, Validation loss: 0.5616382956504822
Epoch: 61/300 - Train loss: 0.5552918314933777, Validation loss: 0.5589868426322937
Epoch: 62/300 - Train loss: 0.5528417825698853, Validation loss: 0.5568315982818604
Epoch: 63/300 - Train loss: 0.5504384636878967, Validation loss: 0.5546349883079529
Epoch: 64/300 - Train loss: 0.548081636428833, Validation loss: 0.5521518588066101
Epoch: 65/300 - Train loss: 0.5457702875137329, Validation loss: 0.5498570799827576
Epoch: 66/300 - Train loss: 0.543505847454071, Validation loss: 0.5480786561965942
Epoch: 67/300 - Train loss: 0.5412878394126892, Validation loss: 0.5461896657943726
Epoch: 68/300 - Train loss: 0.5391165018081665, Validation loss: 0.5436866879463196
Epoch: 69/300 - Train loss: 0.5369914770126343, Validation loss: 0.5412395000457764
Epoch: 70/300 - Train loss: 0.5349125266075134, Validation loss: 0.5397486686706543
Epoch: 71/300 - Train loss: 0.5328778624534607, Validation loss: 0.5380324721336365
Epoch: 72/300 - Train loss: 0.5308886766433716, Validation loss: 0.5358599424362183
Epoch: 73/300 - Train loss: 0.5289454460144043, Validation loss: 0.5341951251029968
Epoch: 74/300 - Train loss: 0.527047336101532, Validation loss: 0.532150149345398
Epoch: 75/300 - Train loss: 0.525194525718689, Validation loss: 0.5307546854019165
Epoch: 76/300 - Train loss: 0.5233859419822693, Validation loss: 0.5292783379554749
Epoch: 77/300 - Train loss: 0.5216196775436401, Validation loss: 0.5271364450454712
Epoch: 78/300 - Train loss: 0.519895613193512, Validation loss: 0.5256838798522949
Epoch: 79/300 - Train loss: 0.5182129144668579, Validation loss: 0.524056613445282
Epoch: 80/300 - Train loss: 0.5165684223175049, Validation loss: 0.5219832062721252
Epoch: 81/300 - Train loss: 0.5149627923965454, Validation loss: 0.5206961035728455
Epoch: 82/300 - Train loss: 0.5133962631225586, Validation loss: 0.520529568195343
Epoch: 83/300 - Train loss: 0.51186603307724, Validation loss: 0.5178181529045105
Epoch: 84/300 - Train loss: 0.510369598865509, Validation loss: 0.5171589255332947
Epoch: 85/300 - Train loss: 0.5089062452316284, Validation loss: 0.5152469277381897
Epoch: 86/300 - Train loss: 0.5074747800827026, Validation loss: 0.5143325328826904
Epoch: 87/300 - Train loss: 0.5060737729072571, Validation loss: 0.5125598311424255
Epoch: 88/300 - Train loss: 0.5047001242637634, Validation loss: 0.51131272315979
Epoch: 89/300 - Train loss: 0.5033555626869202, Validation loss: 0.5103013515472412
Epoch: 90/300 - Train loss: 0.5020385384559631, Validation loss: 0.5090674161911011
Epoch: 91/300 - Train loss: 0.500749945640564, Validation loss: 0.5078698396682739
Epoch: 92/300 - Train loss: 0.4994893968105316, Validation loss: 0.5069043040275574
Epoch: 93/300 - Train loss: 0.49825626611709595, Validation loss: 0.5054588913917542
Epoch: 94/300 - Train loss: 0.49705037474632263, Validation loss: 0.5045027732849121
Epoch: 95/300 - Train loss: 0.4958694279193878, Validation loss: 0.5029706358909607
Epoch: 96/300 - Train loss: 0.49471142888069153, Validation loss: 0.502617359161377
Epoch: 97/300 - Train loss: 0.49357569217681885, Validation loss: 0.5013918280601501
Epoch: 98/300 - Train loss: 0.4924609363079071, Validation loss: 0.5011374950408936
Epoch: 99/300 - Train loss: 0.49136677384376526, Validation loss: 0.4993586242198944
Epoch: 100/300 - Train loss: 0.49029240012168884, Validation loss: 0.4987371265888214
Epoch: 101/300 - Train loss: 0.48923853039741516, Validation loss: 0.497214674949646
Epoch: 102/300 - Train loss: 0.488202840089798, Validation loss: 0.49647340178489685
Epoch: 103/300 - Train loss: 0.48718467354774475, Validation loss: 0.49569642543792725
Epoch: 104/300 - Train loss: 0.48618319630622864, Validation loss: 0.4941401183605194
Epoch: 105/300 - Train loss: 0.48519647121429443, Validation loss: 0.49367573857307434
Epoch: 106/300 - Train loss: 0.48422402143478394, Validation loss: 0.4927416741847992
Epoch: 107/300 - Train loss: 0.4832642376422882, Validation loss: 0.49187636375427246
Epoch: 108/300 - Train loss: 0.4823175072669983, Validation loss: 0.4907741844654083
Epoch: 109/300 - Train loss: 0.48138341307640076, Validation loss: 0.48987114429473877
Epoch: 110/300 - Train loss: 0.4804624319076538, Validation loss: 0.48872408270835876
Epoch: 111/300 - Train loss: 0.47955334186553955, Validation loss: 0.4884089529514313
Epoch: 112/300 - Train loss: 0.47865456342697144, Validation loss: 0.48774614930152893
Epoch: 113/300 - Train loss: 0.47776681184768677, Validation loss: 0.486782968044281
Epoch: 114/300 - Train loss: 0.4768899977207184, Validation loss: 0.4859398603439331
Epoch: 115/300 - Train loss: 0.47602176666259766, Validation loss: 0.48562413454055786
Epoch: 116/300 - Train loss: 0.47516271471977234, Validation loss: 0.4842878580093384
Epoch: 117/300 - Train loss: 0.4743122458457947, Validation loss: 0.48354649543762207
Epoch: 118/300 - Train loss: 0.47346922755241394, Validation loss: 0.4824148118495941
Epoch: 119/300 - Train loss: 0.47263389825820923, Validation loss: 0.4823305904865265
Epoch: 120/300 - Train loss: 0.47180789709091187, Validation loss: 0.4820672273635864
Epoch: 121/300 - Train loss: 0.4709901213645935, Validation loss: 0.4807858169078827
Epoch: 122/300 - Train loss: 0.47018060088157654, Validation loss: 0.4799877107143402
Epoch: 123/300 - Train loss: 0.4693778157234192, Validation loss: 0.4788866341114044
Epoch: 124/300 - Train loss: 0.46858134865760803, Validation loss: 0.4783630967140198
Epoch: 125/300 - Train loss: 0.46779152750968933, Validation loss: 0.4778572916984558
Epoch: 126/300 - Train loss: 0.46700745820999146, Validation loss: 0.47693806886672974
Epoch: 127/300 - Train loss: 0.46622976660728455, Validation loss: 0.4761081039905548
Epoch: 128/300 - Train loss: 0.46545878052711487, Validation loss: 0.47483283281326294
Epoch: 129/300 - Train loss: 0.46469321846961975, Validation loss: 0.474270761013031
Epoch: 130/300 - Train loss: 0.4639327824115753, Validation loss: 0.47368693351745605
Epoch: 131/300 - Train loss: 0.4631768465042114, Validation loss: 0.4729810059070587
Epoch: 132/300 - Train loss: 0.46242600679397583, Validation loss: 0.47301074862480164
Epoch: 133/300 - Train loss: 0.4616800844669342, Validation loss: 0.47163960337638855
Epoch: 134/300 - Train loss: 0.46093815565109253, Validation loss: 0.47128114104270935
Epoch: 135/300 - Train loss: 0.46019992232322693, Validation loss: 0.47038212418556213
Epoch: 136/300 - Train loss: 0.4594653844833374, Validation loss: 0.46953678131103516
Epoch: 137/300 - Train loss: 0.45873478055000305, Validation loss: 0.4687822759151459
Epoch: 138/300 - Train loss: 0.45800918340682983, Validation loss: 0.46795395016670227
Epoch: 139/300 - Train loss: 0.4572888910770416, Validation loss: 0.46726861596107483
Epoch: 140/300 - Train loss: 0.45657458901405334, Validation loss: 0.46792104840278625
Epoch: 141/300 - Train loss: 0.45586544275283813, Validation loss: 0.4665051996707916
Epoch: 142/300 - Train loss: 0.45516112446784973, Validation loss: 0.46603527665138245
Epoch: 143/300 - Train loss: 0.45445993542671204, Validation loss: 0.46500203013420105
Epoch: 144/300 - Train loss: 0.4537621736526489, Validation loss: 0.4640111029148102
Epoch: 145/300 - Train loss: 0.4530702233314514, Validation loss: 0.46405360102653503
Epoch: 146/300 - Train loss: 0.4523826837539673, Validation loss: 0.4634038805961609
Epoch: 147/300 - Train loss: 0.45169883966445923, Validation loss: 0.4622035324573517
Epoch: 148/300 - Train loss: 0.45101848244667053, Validation loss: 0.4617759585380554
Epoch: 149/300 - Train loss: 0.4503418207168579, Validation loss: 0.4617898762226105
Epoch: 150/300 - Train loss: 0.4496682584285736, Validation loss: 0.4601012170314789
Epoch: 151/300 - Train loss: 0.4489980638027191, Validation loss: 0.4595755338668823
Epoch: 152/300 - Train loss: 0.44833168387413025, Validation loss: 0.45918816328048706
Epoch: 153/300 - Train loss: 0.44766804575920105, Validation loss: 0.4582608640193939
Epoch: 154/300 - Train loss: 0.44700759649276733, Validation loss: 0.4582749903202057
Epoch: 155/300 - Train loss: 0.4463503360748291, Validation loss: 0.45756444334983826
Epoch: 156/300 - Train loss: 0.4456954300403595, Validation loss: 0.4565366208553314
Epoch: 157/300 - Train loss: 0.4450426995754242, Validation loss: 0.4564462900161743
Epoch: 158/300 - Train loss: 0.4443911612033844, Validation loss: 0.45603224635124207
Epoch: 159/300 - Train loss: 0.4437415897846222, Validation loss: 0.4549005627632141
Epoch: 160/300 - Train loss: 0.4430946409702301, Validation loss: 0.4540528655052185
Epoch: 161/300 - Train loss: 0.4424480199813843, Validation loss: 0.45415031909942627
Epoch: 162/300 - Train loss: 0.441802054643631, Validation loss: 0.45316845178604126
Epoch: 163/300 - Train loss: 0.4411573112010956, Validation loss: 0.4526631236076355
Epoch: 164/300 - Train loss: 0.4405132234096527, Validation loss: 0.45179086923599243
Epoch: 165/300 - Train loss: 0.4398704469203949, Validation loss: 0.4513790011405945
Epoch: 166/300 - Train loss: 0.43922972679138184, Validation loss: 0.4511037766933441
Epoch: 167/300 - Train loss: 0.43859004974365234, Validation loss: 0.4500463902950287
Epoch: 168/300 - Train loss: 0.4379504919052124, Validation loss: 0.44960734248161316
Epoch: 169/300 - Train loss: 0.4373113512992859, Validation loss: 0.44897007942199707
Epoch: 170/300 - Train loss: 0.4366717040538788, Validation loss: 0.4488021731376648
Epoch: 171/300 - Train loss: 0.43603208661079407, Validation loss: 0.44814109802246094
Epoch: 172/300 - Train loss: 0.4353915750980377, Validation loss: 0.4470958411693573
Epoch: 173/300 - Train loss: 0.4347502589225769, Validation loss: 0.4465085566043854
Epoch: 174/300 - Train loss: 0.43410801887512207, Validation loss: 0.44596272706985474
Epoch: 175/300 - Train loss: 0.433464914560318, Validation loss: 0.4456011652946472
Epoch: 176/300 - Train loss: 0.4328201115131378, Validation loss: 0.44516295194625854
