Epoch: 1/200 - Train loss: 0.46136075258255005, Validation loss: 0.383287250995636
Epoch: 2/200 - Train loss: 0.33021023869514465, Validation loss: 0.3160538375377655
Epoch: 3/200 - Train loss: 0.2760998010635376, Validation loss: 0.29213255643844604
Epoch: 4/200 - Train loss: 0.24838478863239288, Validation loss: 0.2721894085407257
Epoch: 5/200 - Train loss: 0.23411090672016144, Validation loss: 0.2628175914287567
Epoch: 6/200 - Train loss: 0.22142279148101807, Validation loss: 0.2601648271083832
Epoch: 7/200 - Train loss: 0.2125295102596283, Validation loss: 0.2577137053012848
Epoch: 8/200 - Train loss: 0.20714840292930603, Validation loss: 0.2574993073940277
Epoch: 9/200 - Train loss: 0.20192022621631622, Validation loss: 0.25455912947654724
Epoch: 10/200 - Train loss: 0.19656650722026825, Validation loss: 0.25417789816856384
Epoch: 11/200 - Train loss: 0.1937510371208191, Validation loss: 0.2503794729709625
Epoch: 12/200 - Train loss: 0.18999116122722626, Validation loss: 0.260983943939209
Epoch: 13/200 - Train loss: 0.1871216744184494, Validation loss: 0.25023308396339417
Epoch: 14/200 - Train loss: 0.18421195447444916, Validation loss: 0.2540416121482849
Epoch: 15/200 - Train loss: 0.18225805461406708, Validation loss: 0.24814443290233612
Epoch: 16/200 - Train loss: 0.1809840202331543, Validation loss: 0.24551837146282196
Epoch: 17/200 - Train loss: 0.17944763600826263, Validation loss: 0.25410768389701843
Epoch: 18/200 - Train loss: 0.17539465427398682, Validation loss: 0.24936285614967346
Epoch: 19/200 - Train loss: 0.17460401356220245, Validation loss: 0.24728555977344513
Epoch: 20/200 - Train loss: 0.17301777005195618, Validation loss: 0.2504606246948242
Epoch: 21/200 - Train loss: 0.17272260785102844, Validation loss: 0.25264036655426025
Epoch: 22/200 - Train loss: 0.17175237834453583, Validation loss: 0.24919697642326355
Epoch: 23/200 - Train loss: 0.17194508016109467, Validation loss: 0.25262752175331116
Epoch: 24/200 - Train loss: 0.1693546324968338, Validation loss: 0.25188660621643066
Epoch: 25/200 - Train loss: 0.16871851682662964, Validation loss: 0.24499541521072388
Epoch: 26/200 - Train loss: 0.16713884472846985, Validation loss: 0.2543523907661438
Epoch: 27/200 - Train loss: 0.16538329422473907, Validation loss: 0.2543422281742096
Epoch: 28/200 - Train loss: 0.16621384024620056, Validation loss: 0.251614511013031
Epoch: 29/200 - Train loss: 0.1652727723121643, Validation loss: 0.25277918577194214
Epoch: 30/200 - Train loss: 0.16432589292526245, Validation loss: 0.24911777675151825
Epoch: 31/200 - Train loss: 0.1661287099123001, Validation loss: 0.25720953941345215
Epoch: 32/200 - Train loss: 0.16249892115592957, Validation loss: 0.25497695803642273
Epoch: 33/200 - Train loss: 0.16256071627140045, Validation loss: 0.24881431460380554
Epoch: 34/200 - Train loss: 0.16156511008739471, Validation loss: 0.25773733854293823
Epoch: 35/200 - Train loss: 0.16088874638080597, Validation loss: 0.25848251581192017
Epoch: 36/200 - Train loss: 0.16149230301380157, Validation loss: 0.26014870405197144
Epoch: 37/200 - Train loss: 0.1592773050069809, Validation loss: 0.26216793060302734
Epoch: 38/200 - Train loss: 0.15983368456363678, Validation loss: 0.2585860788822174
Epoch: 39/200 - Train loss: 0.15893618762493134, Validation loss: 0.2597847282886505
Epoch: 40/200 - Train loss: 0.15809383988380432, Validation loss: 0.2563282549381256
Epoch: 41/200 - Train loss: 0.15680362284183502, Validation loss: 0.2577088177204132
Epoch: 42/200 - Train loss: 0.1573973149061203, Validation loss: 0.26041877269744873
Epoch: 43/200 - Train loss: 0.15713101625442505, Validation loss: 0.25771263241767883
Epoch: 44/200 - Train loss: 0.15666063129901886, Validation loss: 0.2654189169406891
Epoch: 45/200 - Train loss: 0.15660086274147034, Validation loss: 0.2589830160140991
Epoch: 46/200 - Train loss: 0.15590156614780426, Validation loss: 0.2621653079986572
Epoch: 47/200 - Train loss: 0.15601438283920288, Validation loss: 0.26652324199676514
Epoch: 48/200 - Train loss: 0.15583457052707672, Validation loss: 0.2613515853881836
Epoch: 49/200 - Train loss: 0.1545540988445282, Validation loss: 0.25763246417045593
Epoch: 50/200 - Train loss: 0.15375041961669922, Validation loss: 0.2696652114391327
Epoch: 51/200 - Train loss: 0.15306997299194336, Validation loss: 0.27471357583999634
Epoch: 52/200 - Train loss: 0.1540745198726654, Validation loss: 0.26842057704925537
Epoch: 53/200 - Train loss: 0.15280279517173767, Validation loss: 0.2625182569026947
Epoch: 54/200 - Train loss: 0.15412572026252747, Validation loss: 0.26636675000190735
Epoch: 55/200 - Train loss: 0.15343666076660156, Validation loss: 0.2713487446308136
Epoch: 56/200 - Train loss: 0.15192972123622894, Validation loss: 0.26730623841285706
Epoch: 57/200 - Train loss: 0.1513971984386444, Validation loss: 0.26644811034202576
Epoch: 58/200 - Train loss: 0.15219727158546448, Validation loss: 0.26245445013046265
Epoch: 59/200 - Train loss: 0.1511339545249939, Validation loss: 0.2647738754749298
Epoch: 60/200 - Train loss: 0.1519252061843872, Validation loss: 0.2696092128753662
Epoch: 61/200 - Train loss: 0.15135398507118225, Validation loss: 0.27380409836769104
Epoch: 62/200 - Train loss: 0.15029460191726685, Validation loss: 0.26816272735595703
Epoch: 63/200 - Train loss: 0.14968346059322357, Validation loss: 0.26923301815986633
Epoch: 64/200 - Train loss: 0.15004311501979828, Validation loss: 0.27322933077812195
Epoch: 65/200 - Train loss: 0.14911684393882751, Validation loss: 0.26903361082077026
Epoch: 66/200 - Train loss: 0.15004318952560425, Validation loss: 0.2731917202472687
Epoch: 67/200 - Train loss: 0.15001872181892395, Validation loss: 0.2743276059627533
Epoch: 68/200 - Train loss: 0.15006721019744873, Validation loss: 0.2721223831176758
Epoch: 69/200 - Train loss: 0.14920005202293396, Validation loss: 0.27184879779815674
Epoch: 70/200 - Train loss: 0.14795781672000885, Validation loss: 0.26772475242614746
Epoch: 71/200 - Train loss: 0.1481122225522995, Validation loss: 0.27464231848716736
Epoch: 72/200 - Train loss: 0.14806057512760162, Validation loss: 0.2755410373210907
Epoch: 73/200 - Train loss: 0.1483980417251587, Validation loss: 0.271418958902359
Epoch: 74/200 - Train loss: 0.1479223370552063, Validation loss: 0.26949483156204224
Epoch: 75/200 - Train loss: 0.14862556755542755, Validation loss: 0.2703050374984741
Epoch: 76/200 - Train loss: 0.1481609046459198, Validation loss: 0.27362337708473206
Epoch: 77/200 - Train loss: 0.14679406583309174, Validation loss: 0.2717515230178833
Epoch: 78/200 - Train loss: 0.14797455072402954, Validation loss: 0.27467089891433716
Epoch: 79/200 - Train loss: 0.14709651470184326, Validation loss: 0.2718997895717621
Epoch: 80/200 - Train loss: 0.14603079855442047, Validation loss: 0.27684393525123596
Epoch: 81/200 - Train loss: 0.1466408371925354, Validation loss: 0.274509072303772
Epoch: 82/200 - Train loss: 0.14687205851078033, Validation loss: 0.2764183282852173
Epoch: 83/200 - Train loss: 0.1475425511598587, Validation loss: 0.2722860276699066
Epoch: 84/200 - Train loss: 0.14668582379817963, Validation loss: 0.27100810408592224
Epoch: 85/200 - Train loss: 0.14557062089443207, Validation loss: 0.27457234263420105
Epoch: 86/200 - Train loss: 0.14483563601970673, Validation loss: 0.2777174711227417
Epoch: 87/200 - Train loss: 0.14617179334163666, Validation loss: 0.276359498500824
Epoch: 88/200 - Train loss: 0.14553041756153107, Validation loss: 0.27371641993522644
Epoch: 89/200 - Train loss: 0.1455906480550766, Validation loss: 0.2755420207977295
Epoch: 90/200 - Train loss: 0.14526773989200592, Validation loss: 0.2782426178455353
Epoch: 91/200 - Train loss: 0.14433099329471588, Validation loss: 0.2782590985298157
Epoch: 92/200 - Train loss: 0.14482222497463226, Validation loss: 0.2782416045665741
Epoch: 93/200 - Train loss: 0.1444048285484314, Validation loss: 0.27660149335861206
Epoch: 94/200 - Train loss: 0.14543503522872925, Validation loss: 0.2797510623931885
Epoch: 95/200 - Train loss: 0.144738107919693, Validation loss: 0.27905184030532837
Epoch: 96/200 - Train loss: 0.14473332464694977, Validation loss: 0.2763952612876892
Epoch: 97/200 - Train loss: 0.14406606554985046, Validation loss: 0.2788805663585663
Epoch: 98/200 - Train loss: 0.14371079206466675, Validation loss: 0.2764294445514679
