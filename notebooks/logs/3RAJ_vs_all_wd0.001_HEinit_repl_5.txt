Epoch: 1/300 - Train loss: 0.6963809728622437, Validation loss: 0.6942174434661865
Epoch: 2/300 - Train loss: 0.6945076584815979, Validation loss: 0.6925263404846191
Epoch: 3/300 - Train loss: 0.6927339434623718, Validation loss: 0.6908813714981079
Epoch: 4/300 - Train loss: 0.6910385489463806, Validation loss: 0.689246654510498
Epoch: 5/300 - Train loss: 0.6893969178199768, Validation loss: 0.6878379583358765
Epoch: 6/300 - Train loss: 0.6877968907356262, Validation loss: 0.6863232851028442
Epoch: 7/300 - Train loss: 0.6862267255783081, Validation loss: 0.6848192811012268
Epoch: 8/300 - Train loss: 0.6846787929534912, Validation loss: 0.6832061409950256
Epoch: 9/300 - Train loss: 0.6831377744674683, Validation loss: 0.681684136390686
Epoch: 10/300 - Train loss: 0.6815939545631409, Validation loss: 0.6801495552062988
Epoch: 11/300 - Train loss: 0.6800373792648315, Validation loss: 0.678544282913208
Epoch: 12/300 - Train loss: 0.6784617900848389, Validation loss: 0.6768803000450134
Epoch: 13/300 - Train loss: 0.6768637299537659, Validation loss: 0.6751843094825745
Epoch: 14/300 - Train loss: 0.6752366423606873, Validation loss: 0.6734372973442078
Epoch: 15/300 - Train loss: 0.6735751032829285, Validation loss: 0.6716557145118713
Epoch: 16/300 - Train loss: 0.6718730330467224, Validation loss: 0.6698817014694214
Epoch: 17/300 - Train loss: 0.670127272605896, Validation loss: 0.6680030226707458
Epoch: 18/300 - Train loss: 0.6683376431465149, Validation loss: 0.6662240028381348
Epoch: 19/300 - Train loss: 0.6665070652961731, Validation loss: 0.6641900539398193
Epoch: 20/300 - Train loss: 0.664630651473999, Validation loss: 0.662197470664978
Epoch: 21/300 - Train loss: 0.6627136468887329, Validation loss: 0.6601493954658508
Epoch: 22/300 - Train loss: 0.6607567071914673, Validation loss: 0.6581949591636658
Epoch: 23/300 - Train loss: 0.658760130405426, Validation loss: 0.6559684872627258
Epoch: 24/300 - Train loss: 0.6567254066467285, Validation loss: 0.6539002060890198
Epoch: 25/300 - Train loss: 0.6546527743339539, Validation loss: 0.6517150402069092
Epoch: 26/300 - Train loss: 0.6525426506996155, Validation loss: 0.6495881676673889
Epoch: 27/300 - Train loss: 0.6503963470458984, Validation loss: 0.6471880674362183
Epoch: 28/300 - Train loss: 0.6482176780700684, Validation loss: 0.6449413299560547
Epoch: 29/300 - Train loss: 0.6460095643997192, Validation loss: 0.6425831317901611
Epoch: 30/300 - Train loss: 0.6437726616859436, Validation loss: 0.6404179334640503
Epoch: 31/300 - Train loss: 0.641510546207428, Validation loss: 0.6380831003189087
Epoch: 32/300 - Train loss: 0.6392232179641724, Validation loss: 0.6357669830322266
Epoch: 33/300 - Train loss: 0.6369138956069946, Validation loss: 0.6332589983940125
Epoch: 34/300 - Train loss: 0.634584367275238, Validation loss: 0.6307704448699951
Epoch: 35/300 - Train loss: 0.6322377324104309, Validation loss: 0.6281847953796387
Epoch: 36/300 - Train loss: 0.6298733353614807, Validation loss: 0.6259396076202393
Epoch: 37/300 - Train loss: 0.6274937987327576, Validation loss: 0.6234781742095947
Epoch: 38/300 - Train loss: 0.6250995397567749, Validation loss: 0.6209789514541626
Epoch: 39/300 - Train loss: 0.6226963400840759, Validation loss: 0.6187677979469299
Epoch: 40/300 - Train loss: 0.6202896237373352, Validation loss: 0.6162464618682861
Epoch: 41/300 - Train loss: 0.617882490158081, Validation loss: 0.614012598991394
Epoch: 42/300 - Train loss: 0.6154752969741821, Validation loss: 0.6114410758018494
Epoch: 43/300 - Train loss: 0.6130735278129578, Validation loss: 0.609210729598999
Epoch: 44/300 - Train loss: 0.6106774210929871, Validation loss: 0.6068025231361389
Epoch: 45/300 - Train loss: 0.608289361000061, Validation loss: 0.6043177843093872
Epoch: 46/300 - Train loss: 0.6059104204177856, Validation loss: 0.6020790338516235
Epoch: 47/300 - Train loss: 0.6035434007644653, Validation loss: 0.5995076894760132
Epoch: 48/300 - Train loss: 0.6011900305747986, Validation loss: 0.597505509853363
Epoch: 49/300 - Train loss: 0.5988515615463257, Validation loss: 0.5950440764427185
Epoch: 50/300 - Train loss: 0.5965307950973511, Validation loss: 0.5929275155067444
Epoch: 51/300 - Train loss: 0.5942294001579285, Validation loss: 0.5902503728866577
Epoch: 52/300 - Train loss: 0.5919487476348877, Validation loss: 0.5879325270652771
Epoch: 53/300 - Train loss: 0.5896891951560974, Validation loss: 0.5859988331794739
Epoch: 54/300 - Train loss: 0.5874519944190979, Validation loss: 0.5835727453231812
Epoch: 55/300 - Train loss: 0.5852392315864563, Validation loss: 0.5814779996871948
Epoch: 56/300 - Train loss: 0.5830515027046204, Validation loss: 0.5793890357017517
Epoch: 57/300 - Train loss: 0.5808907747268677, Validation loss: 0.5773299932479858
Epoch: 58/300 - Train loss: 0.5787560343742371, Validation loss: 0.5752474069595337
Epoch: 59/300 - Train loss: 0.5766497254371643, Validation loss: 0.5733239650726318
Epoch: 60/300 - Train loss: 0.5745720863342285, Validation loss: 0.5711911916732788
Epoch: 61/300 - Train loss: 0.5725224018096924, Validation loss: 0.5690035820007324
Epoch: 62/300 - Train loss: 0.5705022215843201, Validation loss: 0.5671627521514893
Epoch: 63/300 - Train loss: 0.5685116052627563, Validation loss: 0.5652971863746643
Epoch: 64/300 - Train loss: 0.5665509700775146, Validation loss: 0.5636840462684631
Epoch: 65/300 - Train loss: 0.5646203756332397, Validation loss: 0.5618278980255127
Epoch: 66/300 - Train loss: 0.562719464302063, Validation loss: 0.5596656799316406
Epoch: 67/300 - Train loss: 0.560847282409668, Validation loss: 0.5577253103256226
Epoch: 68/300 - Train loss: 0.5590047240257263, Validation loss: 0.5562232136726379
Epoch: 69/300 - Train loss: 0.5571911931037903, Validation loss: 0.5546942353248596
Epoch: 70/300 - Train loss: 0.555405855178833, Validation loss: 0.5534057021141052
Epoch: 71/300 - Train loss: 0.5536481142044067, Validation loss: 0.5510702729225159
Epoch: 72/300 - Train loss: 0.5519186854362488, Validation loss: 0.5494984984397888
Epoch: 73/300 - Train loss: 0.5502166152000427, Validation loss: 0.5480507612228394
Epoch: 74/300 - Train loss: 0.5485393404960632, Validation loss: 0.5463907718658447
Epoch: 75/300 - Train loss: 0.5468878149986267, Validation loss: 0.5449170470237732
Epoch: 76/300 - Train loss: 0.545261800289154, Validation loss: 0.5430492162704468
Epoch: 77/300 - Train loss: 0.5436602234840393, Validation loss: 0.5418579578399658
Epoch: 78/300 - Train loss: 0.5420833230018616, Validation loss: 0.5399380326271057
Epoch: 79/300 - Train loss: 0.5405291318893433, Validation loss: 0.5393228530883789
Epoch: 80/300 - Train loss: 0.5389974117279053, Validation loss: 0.5375089049339294
Epoch: 81/300 - Train loss: 0.5374876260757446, Validation loss: 0.5361132621765137
Epoch: 82/300 - Train loss: 0.5359981656074524, Validation loss: 0.5344483852386475
Epoch: 83/300 - Train loss: 0.5345290303230286, Validation loss: 0.5328113436698914
Epoch: 84/300 - Train loss: 0.5330795049667358, Validation loss: 0.5323215126991272
Epoch: 85/300 - Train loss: 0.5316500067710876, Validation loss: 0.5309625267982483
Epoch: 86/300 - Train loss: 0.5302389860153198, Validation loss: 0.528984010219574
Epoch: 87/300 - Train loss: 0.5288459658622742, Validation loss: 0.5283305644989014
Epoch: 88/300 - Train loss: 0.5274702310562134, Validation loss: 0.526672899723053
Epoch: 89/300 - Train loss: 0.5261122584342957, Validation loss: 0.5250836610794067
Epoch: 90/300 - Train loss: 0.5247710347175598, Validation loss: 0.5244501829147339
Epoch: 91/300 - Train loss: 0.5234457850456238, Validation loss: 0.5228421092033386
Epoch: 92/300 - Train loss: 0.5221359133720398, Validation loss: 0.5219547152519226
Epoch: 93/300 - Train loss: 0.5208415389060974, Validation loss: 0.5204124450683594
Epoch: 94/300 - Train loss: 0.5195615887641907, Validation loss: 0.5190894603729248
Epoch: 95/300 - Train loss: 0.518295168876648, Validation loss: 0.518642783164978
Epoch: 96/300 - Train loss: 0.5170424580574036, Validation loss: 0.5171695947647095
Epoch: 97/300 - Train loss: 0.5158035159111023, Validation loss: 0.516128659248352
Epoch: 98/300 - Train loss: 0.5145772695541382, Validation loss: 0.5144085884094238
Epoch: 99/300 - Train loss: 0.5133631229400635, Validation loss: 0.51371830701828
Epoch: 100/300 - Train loss: 0.5121615529060364, Validation loss: 0.5122094750404358
Epoch: 101/300 - Train loss: 0.5109718441963196, Validation loss: 0.5113059282302856
Epoch: 102/300 - Train loss: 0.5097925662994385, Validation loss: 0.5101970434188843
Epoch: 103/300 - Train loss: 0.5086237788200378, Validation loss: 0.5092016458511353
Epoch: 104/300 - Train loss: 0.507465660572052, Validation loss: 0.5080270171165466
Epoch: 105/300 - Train loss: 0.5063178539276123, Validation loss: 0.5072457194328308
Epoch: 106/300 - Train loss: 0.5051808953285217, Validation loss: 0.505923330783844
Epoch: 107/300 - Train loss: 0.50405353307724, Validation loss: 0.5051344633102417
Epoch: 108/300 - Train loss: 0.5029368996620178, Validation loss: 0.5039867758750916
Epoch: 109/300 - Train loss: 0.5018299221992493, Validation loss: 0.5032169222831726
Epoch: 110/300 - Train loss: 0.5007319450378418, Validation loss: 0.5019630193710327
Epoch: 111/300 - Train loss: 0.4996429681777954, Validation loss: 0.5005956888198853
Epoch: 112/300 - Train loss: 0.4985620677471161, Validation loss: 0.49982962012290955
Epoch: 113/300 - Train loss: 0.4974888563156128, Validation loss: 0.49865955114364624
Epoch: 114/300 - Train loss: 0.4964238405227661, Validation loss: 0.49757397174835205
Epoch: 115/300 - Train loss: 0.4953669309616089, Validation loss: 0.49711284041404724
Epoch: 116/300 - Train loss: 0.4943172037601471, Validation loss: 0.49660375714302063
Epoch: 117/300 - Train loss: 0.4932751953601837, Validation loss: 0.4950968325138092
Epoch: 118/300 - Train loss: 0.4922402799129486, Validation loss: 0.4940432608127594
Epoch: 119/300 - Train loss: 0.49121254682540894, Validation loss: 0.49298134446144104
Epoch: 120/300 - Train loss: 0.4901920258998871, Validation loss: 0.49245816469192505
Epoch: 121/300 - Train loss: 0.48917901515960693, Validation loss: 0.49128058552742004
Epoch: 122/300 - Train loss: 0.48817309737205505, Validation loss: 0.4903007745742798
Epoch: 123/300 - Train loss: 0.4871731996536255, Validation loss: 0.4897046983242035
Epoch: 124/300 - Train loss: 0.4861793518066406, Validation loss: 0.48837947845458984
Epoch: 125/300 - Train loss: 0.48519250750541687, Validation loss: 0.48768937587738037
Epoch: 126/300 - Train loss: 0.4842120409011841, Validation loss: 0.4872690737247467
Epoch: 127/300 - Train loss: 0.48323720693588257, Validation loss: 0.48628130555152893
Epoch: 128/300 - Train loss: 0.4822692275047302, Validation loss: 0.4853959083557129
Epoch: 129/300 - Train loss: 0.48130741715431213, Validation loss: 0.4841572344303131
Epoch: 130/300 - Train loss: 0.4803517162799835, Validation loss: 0.48285648226737976
Epoch: 131/300 - Train loss: 0.47940099239349365, Validation loss: 0.48218250274658203
Epoch: 132/300 - Train loss: 0.47845566272735596, Validation loss: 0.4813912510871887
Epoch: 133/300 - Train loss: 0.4775157868862152, Validation loss: 0.4801121652126312
Epoch: 134/300 - Train loss: 0.47658205032348633, Validation loss: 0.47972798347473145
Epoch: 135/300 - Train loss: 0.475655198097229, Validation loss: 0.47873732447624207
Epoch: 136/300 - Train loss: 0.47473451495170593, Validation loss: 0.47780531644821167
Epoch: 137/300 - Train loss: 0.47382044792175293, Validation loss: 0.4771176278591156
Epoch: 138/300 - Train loss: 0.4729119539260864, Validation loss: 0.47554856538772583
Epoch: 139/300 - Train loss: 0.4720095694065094, Validation loss: 0.47558730840682983
Epoch: 140/300 - Train loss: 0.47111329436302185, Validation loss: 0.4745664596557617
Epoch: 141/300 - Train loss: 0.4702223837375641, Validation loss: 0.4744095206260681
Epoch: 142/300 - Train loss: 0.46933773159980774, Validation loss: 0.47249817848205566
Epoch: 143/300 - Train loss: 0.46845826506614685, Validation loss: 0.47212690114974976
Epoch: 144/300 - Train loss: 0.46758323907852173, Validation loss: 0.4711766541004181
Epoch: 145/300 - Train loss: 0.46671345829963684, Validation loss: 0.47017747163772583
Epoch: 146/300 - Train loss: 0.46584928035736084, Validation loss: 0.4695437252521515
Epoch: 147/300 - Train loss: 0.4649907946586609, Validation loss: 0.4686729907989502
Epoch: 148/300 - Train loss: 0.46413806080818176, Validation loss: 0.4679722487926483
Epoch: 149/300 - Train loss: 0.4632905423641205, Validation loss: 0.46755683422088623
Epoch: 150/300 - Train loss: 0.4624480605125427, Validation loss: 0.4666978716850281
Epoch: 151/300 - Train loss: 0.46161070466041565, Validation loss: 0.4655749499797821
Epoch: 152/300 - Train loss: 0.46077844500541687, Validation loss: 0.4647178649902344
Epoch: 153/300 - Train loss: 0.4599510431289673, Validation loss: 0.46404221653938293
Epoch: 154/300 - Train loss: 0.45912814140319824, Validation loss: 0.46314316987991333
Epoch: 155/300 - Train loss: 0.458310067653656, Validation loss: 0.46282216906547546
Epoch: 156/300 - Train loss: 0.45749667286872864, Validation loss: 0.4616027772426605
Epoch: 157/300 - Train loss: 0.4566876292228699, Validation loss: 0.46076738834381104
Epoch: 158/300 - Train loss: 0.4558815658092499, Validation loss: 0.45990559458732605
Epoch: 159/300 - Train loss: 0.4550800621509552, Validation loss: 0.459753155708313
Epoch: 160/300 - Train loss: 0.4542829990386963, Validation loss: 0.4588758051395416
Epoch: 161/300 - Train loss: 0.4534901976585388, Validation loss: 0.45797160267829895
Epoch: 162/300 - Train loss: 0.45270153880119324, Validation loss: 0.4575389623641968
Epoch: 163/300 - Train loss: 0.45191678404808044, Validation loss: 0.4564207196235657
Epoch: 164/300 - Train loss: 0.4511365294456482, Validation loss: 0.45577943325042725
Epoch: 165/300 - Train loss: 0.4503602683544159, Validation loss: 0.45472708344459534
Epoch: 166/300 - Train loss: 0.44958797097206116, Validation loss: 0.4544699192047119
Epoch: 167/300 - Train loss: 0.44882017374038696, Validation loss: 0.4534735381603241
Epoch: 168/300 - Train loss: 0.448056161403656, Validation loss: 0.4535481631755829
Epoch: 169/300 - Train loss: 0.44729623198509216, Validation loss: 0.4521905779838562
Epoch: 170/300 - Train loss: 0.4465406835079193, Validation loss: 0.4516570270061493
Epoch: 171/300 - Train loss: 0.44578903913497925, Validation loss: 0.4512489140033722
Epoch: 172/300 - Train loss: 0.44504162669181824, Validation loss: 0.4501851499080658
Epoch: 173/300 - Train loss: 0.44429811835289, Validation loss: 0.44889023900032043
Epoch: 174/300 - Train loss: 0.4435580372810364, Validation loss: 0.448934942483902
Epoch: 175/300 - Train loss: 0.44282254576683044, Validation loss: 0.44788870215415955
Epoch: 176/300 - Train loss: 0.44209054112434387, Validation loss: 0.4478309154510498
Epoch: 177/300 - Train loss: 0.44136202335357666, Validation loss: 0.4466328024864197
Epoch: 178/300 - Train loss: 0.4406365752220154, Validation loss: 0.4463687241077423
Epoch: 179/300 - Train loss: 0.4399150013923645, Validation loss: 0.4450894296169281
Epoch: 180/300 - Train loss: 0.43919631838798523, Validation loss: 0.4447915852069855
Epoch: 181/300 - Train loss: 0.4384799897670746, Validation loss: 0.4443013668060303
Epoch: 182/300 - Train loss: 0.43776631355285645, Validation loss: 0.4435510039329529
Epoch: 183/300 - Train loss: 0.4370560348033905, Validation loss: 0.44227251410484314
Epoch: 184/300 - Train loss: 0.43634888529777527, Validation loss: 0.4422352910041809
Epoch: 185/300 - Train loss: 0.4356440603733063, Validation loss: 0.44168224930763245
Epoch: 186/300 - Train loss: 0.43494248390197754, Validation loss: 0.44036659598350525
Epoch: 187/300 - Train loss: 0.4342430531978607, Validation loss: 0.4400262236595154
Epoch: 188/300 - Train loss: 0.4335459768772125, Validation loss: 0.43884527683258057
Epoch: 189/300 - Train loss: 0.43285104632377625, Validation loss: 0.438551664352417
Epoch: 190/300 - Train loss: 0.43215858936309814, Validation loss: 0.43759068846702576
Epoch: 191/300 - Train loss: 0.43146923184394836, Validation loss: 0.4372529983520508
Epoch: 192/300 - Train loss: 0.43078166246414185, Validation loss: 0.43655893206596375
Epoch: 193/300 - Train loss: 0.4300951659679413, Validation loss: 0.43602532148361206
Epoch: 194/300 - Train loss: 0.42941126227378845, Validation loss: 0.4350740909576416
Epoch: 195/300 - Train loss: 0.42873015999794006, Validation loss: 0.4344674050807953
Epoch: 196/300 - Train loss: 0.4280508756637573, Validation loss: 0.4338211119174957
Epoch: 197/300 - Train loss: 0.42737263441085815, Validation loss: 0.4334568679332733
Epoch: 198/300 - Train loss: 0.4266955256462097, Validation loss: 0.433171808719635
Epoch: 199/300 - Train loss: 0.42601972818374634, Validation loss: 0.4321911633014679
Epoch: 200/300 - Train loss: 0.4253450930118561, Validation loss: 0.43078771233558655
Epoch: 201/300 - Train loss: 0.4246736466884613, Validation loss: 0.43081173300743103
Epoch: 202/300 - Train loss: 0.4240042567253113, Validation loss: 0.4302372336387634
Epoch: 203/300 - Train loss: 0.4233352541923523, Validation loss: 0.42922648787498474
Epoch: 204/300 - Train loss: 0.4226667582988739, Validation loss: 0.4286380708217621
Epoch: 205/300 - Train loss: 0.4219985902309418, Validation loss: 0.4283227026462555
Epoch: 206/300 - Train loss: 0.42133066058158875, Validation loss: 0.4270375669002533
Epoch: 207/300 - Train loss: 0.4206627309322357, Validation loss: 0.4269562065601349
Epoch: 208/300 - Train loss: 0.4199933409690857, Validation loss: 0.42663294076919556
Epoch: 209/300 - Train loss: 0.4193243682384491, Validation loss: 0.4254019558429718
Epoch: 210/300 - Train loss: 0.41865479946136475, Validation loss: 0.42466509342193604
Epoch: 211/300 - Train loss: 0.4179857075214386, Validation loss: 0.42414307594299316
Epoch: 212/300 - Train loss: 0.4173143208026886, Validation loss: 0.42385268211364746
Epoch: 213/300 - Train loss: 0.41664111614227295, Validation loss: 0.4229598641395569
Epoch: 214/300 - Train loss: 0.41596677899360657, Validation loss: 0.42218711972236633
Epoch: 215/300 - Train loss: 0.415291965007782, Validation loss: 0.4211471378803253
Epoch: 216/300 - Train loss: 0.41461536288261414, Validation loss: 0.4207867383956909
Epoch: 217/300 - Train loss: 0.41393667459487915, Validation loss: 0.4202100336551666
Epoch: 218/300 - Train loss: 0.4132542908191681, Validation loss: 0.42011117935180664
Epoch: 219/300 - Train loss: 0.4125703275203705, Validation loss: 0.4192420542240143
Epoch: 220/300 - Train loss: 0.41188478469848633, Validation loss: 0.41820067167282104
Epoch: 221/300 - Train loss: 0.41119539737701416, Validation loss: 0.4175071120262146
Epoch: 222/300 - Train loss: 0.41050344705581665, Validation loss: 0.41690632700920105
Epoch: 223/300 - Train loss: 0.4098089337348938, Validation loss: 0.41594260931015015
Epoch: 224/300 - Train loss: 0.40911105275154114, Validation loss: 0.415737509727478
Epoch: 225/300 - Train loss: 0.40840864181518555, Validation loss: 0.4150877594947815
Epoch: 226/300 - Train loss: 0.4076991081237793, Validation loss: 0.4143034517765045
Epoch: 227/300 - Train loss: 0.40698641538619995, Validation loss: 0.41354769468307495
Epoch: 228/300 - Train loss: 0.4062712788581848, Validation loss: 0.4127606153488159
Epoch: 229/300 - Train loss: 0.4055531322956085, Validation loss: 0.4121645390987396
Epoch: 230/300 - Train loss: 0.40482980012893677, Validation loss: 0.4116121232509613
Epoch: 231/300 - Train loss: 0.4041045308113098, Validation loss: 0.4104347825050354
Epoch: 232/300 - Train loss: 0.4033789336681366, Validation loss: 0.40928637981414795
Epoch: 233/300 - Train loss: 0.4026505649089813, Validation loss: 0.40940698981285095
Epoch: 234/300 - Train loss: 0.4019204080104828, Validation loss: 0.40862950682640076
Epoch: 235/300 - Train loss: 0.40119048953056335, Validation loss: 0.4076719880104065
Epoch: 236/300 - Train loss: 0.4004601538181305, Validation loss: 0.40699049830436707
Epoch: 237/300 - Train loss: 0.3997279703617096, Validation loss: 0.4062802493572235
Epoch: 238/300 - Train loss: 0.3989966809749603, Validation loss: 0.40525341033935547
Epoch: 239/300 - Train loss: 0.398267537355423, Validation loss: 0.4051741659641266
Epoch: 240/300 - Train loss: 0.39753708243370056, Validation loss: 0.4036710858345032
Epoch: 241/300 - Train loss: 0.3968054950237274, Validation loss: 0.4037492573261261
Epoch: 242/300 - Train loss: 0.39607396721839905, Validation loss: 0.40301379561424255
Epoch: 243/300 - Train loss: 0.3953438103199005, Validation loss: 0.40203648805618286
Epoch: 244/300 - Train loss: 0.3946149945259094, Validation loss: 0.40169793367385864
Epoch: 245/300 - Train loss: 0.39388778805732727, Validation loss: 0.40093594789505005
Epoch: 246/300 - Train loss: 0.3931639492511749, Validation loss: 0.3998686969280243
Epoch: 247/300 - Train loss: 0.39244306087493896, Validation loss: 0.39908286929130554
Epoch: 248/300 - Train loss: 0.39172664284706116, Validation loss: 0.3982706069946289
Epoch: 249/300 - Train loss: 0.3910132050514221, Validation loss: 0.39790913462638855
Epoch: 250/300 - Train loss: 0.3903030753135681, Validation loss: 0.3968328535556793
Epoch: 251/300 - Train loss: 0.3895954191684723, Validation loss: 0.3965510427951813
Epoch: 252/300 - Train loss: 0.3888922333717346, Validation loss: 0.3963173031806946
Epoch: 253/300 - Train loss: 0.38819384574890137, Validation loss: 0.3950168490409851
Epoch: 254/300 - Train loss: 0.38749662041664124, Validation loss: 0.39387086033821106
Epoch: 255/300 - Train loss: 0.3868004083633423, Validation loss: 0.39320600032806396
Epoch: 256/300 - Train loss: 0.38610610365867615, Validation loss: 0.3932313621044159
Epoch: 257/300 - Train loss: 0.38541385531425476, Validation loss: 0.3925684988498688
Epoch: 258/300 - Train loss: 0.3847239017486572, Validation loss: 0.3918707072734833
Epoch: 259/300 - Train loss: 0.38403698801994324, Validation loss: 0.39125752449035645
Epoch: 260/300 - Train loss: 0.38335347175598145, Validation loss: 0.39044058322906494
Epoch: 261/300 - Train loss: 0.38267162442207336, Validation loss: 0.3896870017051697
Epoch: 262/300 - Train loss: 0.38199102878570557, Validation loss: 0.38867151737213135
Epoch: 263/300 - Train loss: 0.3813117444515228, Validation loss: 0.3879489600658417
Epoch: 264/300 - Train loss: 0.38063371181488037, Validation loss: 0.38788461685180664
Epoch: 265/300 - Train loss: 0.379956990480423, Validation loss: 0.387111097574234
Epoch: 266/300 - Train loss: 0.37928149104118347, Validation loss: 0.3860425651073456
Epoch: 267/300 - Train loss: 0.3786076605319977, Validation loss: 0.385636568069458
Epoch: 268/300 - Train loss: 0.37793731689453125, Validation loss: 0.38493606448173523
Epoch: 269/300 - Train loss: 0.3772691786289215, Validation loss: 0.3839108645915985
Epoch: 270/300 - Train loss: 0.376603364944458, Validation loss: 0.3841215968132019
Epoch: 271/300 - Train loss: 0.37593862414360046, Validation loss: 0.38310477137565613
Epoch: 272/300 - Train loss: 0.3752749562263489, Validation loss: 0.3824523985385895
Epoch: 273/300 - Train loss: 0.3746130168437958, Validation loss: 0.3817478120326996
Epoch: 274/300 - Train loss: 0.3739543557167053, Validation loss: 0.3807580769062042
Epoch: 275/300 - Train loss: 0.3732979893684387, Validation loss: 0.3804679214954376
Epoch: 276/300 - Train loss: 0.3726448714733124, Validation loss: 0.3804822564125061
Epoch: 277/300 - Train loss: 0.3719935119152069, Validation loss: 0.3795996904373169
Epoch: 278/300 - Train loss: 0.37134405970573425, Validation loss: 0.37882861495018005
Epoch: 279/300 - Train loss: 0.37069907784461975, Validation loss: 0.378061980009079
Epoch: 280/300 - Train loss: 0.3700580894947052, Validation loss: 0.37761998176574707
Epoch: 281/300 - Train loss: 0.36942046880722046, Validation loss: 0.37686365842819214
Epoch: 282/300 - Train loss: 0.36878710985183716, Validation loss: 0.3759142756462097
Epoch: 283/300 - Train loss: 0.3681579828262329, Validation loss: 0.3755567967891693
Epoch: 284/300 - Train loss: 0.3675326704978943, Validation loss: 0.3745884299278259
Epoch: 285/300 - Train loss: 0.36691203713417053, Validation loss: 0.37464553117752075
Epoch: 286/300 - Train loss: 0.3662950098514557, Validation loss: 0.3738214373588562
Epoch: 287/300 - Train loss: 0.365680456161499, Validation loss: 0.37390559911727905
Epoch: 288/300 - Train loss: 0.3650708496570587, Validation loss: 0.3723806142807007
Epoch: 289/300 - Train loss: 0.3644658327102661, Validation loss: 0.3716076910495758
Epoch: 290/300 - Train loss: 0.3638649880886078, Validation loss: 0.37167832255363464
Epoch: 291/300 - Train loss: 0.3632676601409912, Validation loss: 0.3706929087638855
Epoch: 292/300 - Train loss: 0.3626714050769806, Validation loss: 0.3697863221168518
Epoch: 293/300 - Train loss: 0.36207786202430725, Validation loss: 0.3693235516548157
Epoch: 294/300 - Train loss: 0.36148715019226074, Validation loss: 0.36934658885002136
Epoch: 295/300 - Train loss: 0.3608979284763336, Validation loss: 0.36835744976997375
Epoch: 296/300 - Train loss: 0.3603094816207886, Validation loss: 0.3680301904678345
Epoch: 297/300 - Train loss: 0.35972556471824646, Validation loss: 0.36708489060401917
Epoch: 298/300 - Train loss: 0.35914692282676697, Validation loss: 0.36674264073371887
