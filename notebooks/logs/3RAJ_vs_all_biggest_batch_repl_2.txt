Epoch: 1/300 - Train loss: 0.695400059223175, Validation loss: 0.6949252486228943
Epoch: 2/300 - Train loss: 0.6938775777816772, Validation loss: 0.6932517886161804
Epoch: 3/300 - Train loss: 0.692330002784729, Validation loss: 0.6915655136108398
Epoch: 4/300 - Train loss: 0.6907359957695007, Validation loss: 0.6899373531341553
Epoch: 5/300 - Train loss: 0.6890829801559448, Validation loss: 0.6880313754081726
Epoch: 6/300 - Train loss: 0.6873539090156555, Validation loss: 0.6862542033195496
Epoch: 7/300 - Train loss: 0.6855418682098389, Validation loss: 0.6842654347419739
Epoch: 8/300 - Train loss: 0.6836480498313904, Validation loss: 0.6822410225868225
Epoch: 9/300 - Train loss: 0.6816772222518921, Validation loss: 0.6801478266716003
Epoch: 10/300 - Train loss: 0.679635226726532, Validation loss: 0.6778652667999268
Epoch: 11/300 - Train loss: 0.6775250434875488, Validation loss: 0.6756991744041443
Epoch: 12/300 - Train loss: 0.675348162651062, Validation loss: 0.6732970476150513
Epoch: 13/300 - Train loss: 0.6731137037277222, Validation loss: 0.6709770560264587
Epoch: 14/300 - Train loss: 0.6708282232284546, Validation loss: 0.6685668230056763
Epoch: 15/300 - Train loss: 0.6684983968734741, Validation loss: 0.6661293506622314
Epoch: 16/300 - Train loss: 0.6661322116851807, Validation loss: 0.6637215614318848
Epoch: 17/300 - Train loss: 0.6637352108955383, Validation loss: 0.6612612009048462
Epoch: 18/300 - Train loss: 0.6613079309463501, Validation loss: 0.6587628722190857
Epoch: 19/300 - Train loss: 0.6588499546051025, Validation loss: 0.6561970114707947
Epoch: 20/300 - Train loss: 0.6563584804534912, Validation loss: 0.6536612510681152
Epoch: 21/300 - Train loss: 0.6538362503051758, Validation loss: 0.6510318517684937
Epoch: 22/300 - Train loss: 0.651283323764801, Validation loss: 0.6484436392784119
Epoch: 23/300 - Train loss: 0.6487029194831848, Validation loss: 0.6455352902412415
Epoch: 24/300 - Train loss: 0.6460987329483032, Validation loss: 0.6431999206542969
Epoch: 25/300 - Train loss: 0.6434730887413025, Validation loss: 0.6403859853744507
Epoch: 26/300 - Train loss: 0.6408292651176453, Validation loss: 0.6375843286514282
Epoch: 27/300 - Train loss: 0.6381717920303345, Validation loss: 0.6348982453346252
Epoch: 28/300 - Train loss: 0.6355029940605164, Validation loss: 0.6322134733200073
Epoch: 29/300 - Train loss: 0.632830023765564, Validation loss: 0.629634439945221
Epoch: 30/300 - Train loss: 0.6301550269126892, Validation loss: 0.6269723773002625
Epoch: 31/300 - Train loss: 0.6274821758270264, Validation loss: 0.6243281960487366
Epoch: 32/300 - Train loss: 0.6248165369033813, Validation loss: 0.6216068267822266
Epoch: 33/300 - Train loss: 0.6221591830253601, Validation loss: 0.6188859343528748
Epoch: 34/300 - Train loss: 0.6195096969604492, Validation loss: 0.6164106726646423
Epoch: 35/300 - Train loss: 0.6168678402900696, Validation loss: 0.6135357618331909
Epoch: 36/300 - Train loss: 0.6142358779907227, Validation loss: 0.6108012795448303
Epoch: 37/300 - Train loss: 0.6116154193878174, Validation loss: 0.6083944439888
Epoch: 38/300 - Train loss: 0.6090086698532104, Validation loss: 0.6055598258972168
Epoch: 39/300 - Train loss: 0.6064192056655884, Validation loss: 0.6030997633934021
Epoch: 40/300 - Train loss: 0.6038488149642944, Validation loss: 0.6006627678871155
Epoch: 41/300 - Train loss: 0.6012992262840271, Validation loss: 0.5981305241584778
Epoch: 42/300 - Train loss: 0.5987733602523804, Validation loss: 0.5953807830810547
Epoch: 43/300 - Train loss: 0.5962727665901184, Validation loss: 0.5931448936462402
Epoch: 44/300 - Train loss: 0.5937982797622681, Validation loss: 0.5904949903488159
Epoch: 45/300 - Train loss: 0.5913511514663696, Validation loss: 0.588256299495697
Epoch: 46/300 - Train loss: 0.5889325141906738, Validation loss: 0.5858029127120972
Epoch: 47/300 - Train loss: 0.5865428447723389, Validation loss: 0.5839465856552124
Epoch: 48/300 - Train loss: 0.584183931350708, Validation loss: 0.5814122557640076
Epoch: 49/300 - Train loss: 0.5818564891815186, Validation loss: 0.5788326859474182
Epoch: 50/300 - Train loss: 0.5795612931251526, Validation loss: 0.576678991317749
Epoch: 51/300 - Train loss: 0.5772983431816101, Validation loss: 0.5744410753250122
Epoch: 52/300 - Train loss: 0.5750684142112732, Validation loss: 0.5724077224731445
Epoch: 53/300 - Train loss: 0.5728719234466553, Validation loss: 0.5704059600830078
Epoch: 54/300 - Train loss: 0.5707083940505981, Validation loss: 0.568005383014679
Epoch: 55/300 - Train loss: 0.5685781240463257, Validation loss: 0.5663269758224487
Epoch: 56/300 - Train loss: 0.5664804577827454, Validation loss: 0.5645929574966431
Epoch: 57/300 - Train loss: 0.5644151568412781, Validation loss: 0.5624353289604187
Epoch: 58/300 - Train loss: 0.5623820424079895, Validation loss: 0.5606422424316406
Epoch: 59/300 - Train loss: 0.5603808164596558, Validation loss: 0.5586814880371094
Epoch: 60/300 - Train loss: 0.5584103465080261, Validation loss: 0.5564633011817932
Epoch: 61/300 - Train loss: 0.5564704537391663, Validation loss: 0.5547134280204773
Epoch: 62/300 - Train loss: 0.5545602440834045, Validation loss: 0.5530505776405334
Epoch: 63/300 - Train loss: 0.5526785850524902, Validation loss: 0.5507845878601074
Epoch: 64/300 - Train loss: 0.550824761390686, Validation loss: 0.5498843789100647
Epoch: 65/300 - Train loss: 0.5489979386329651, Validation loss: 0.5477779507637024
Epoch: 66/300 - Train loss: 0.5471966862678528, Validation loss: 0.5462052822113037
Epoch: 67/300 - Train loss: 0.5454202890396118, Validation loss: 0.5445665717124939
Epoch: 68/300 - Train loss: 0.5436663627624512, Validation loss: 0.5431256294250488
Epoch: 69/300 - Train loss: 0.541934072971344, Validation loss: 0.5409224629402161
Epoch: 70/300 - Train loss: 0.5402222275733948, Validation loss: 0.5394440293312073
Epoch: 71/300 - Train loss: 0.5385301113128662, Validation loss: 0.5380883812904358
Epoch: 72/300 - Train loss: 0.5368566513061523, Validation loss: 0.5368861556053162
Epoch: 73/300 - Train loss: 0.5352002382278442, Validation loss: 0.5350310206413269
Epoch: 74/300 - Train loss: 0.5335614085197449, Validation loss: 0.5340197682380676
Epoch: 75/300 - Train loss: 0.5319371819496155, Validation loss: 0.5319966673851013
Epoch: 76/300 - Train loss: 0.5303250551223755, Validation loss: 0.5305421948432922
Epoch: 77/300 - Train loss: 0.5287259221076965, Validation loss: 0.5287567973136902
Epoch: 78/300 - Train loss: 0.5271390080451965, Validation loss: 0.527259886264801
Epoch: 79/300 - Train loss: 0.5255609154701233, Validation loss: 0.5257003903388977
Epoch: 80/300 - Train loss: 0.523991584777832, Validation loss: 0.5245251059532166
Epoch: 81/300 - Train loss: 0.522428035736084, Validation loss: 0.5225483775138855
Epoch: 82/300 - Train loss: 0.5208710432052612, Validation loss: 0.5218347907066345
Epoch: 83/300 - Train loss: 0.5193213224411011, Validation loss: 0.5197823643684387
Epoch: 84/300 - Train loss: 0.5177781581878662, Validation loss: 0.5185961723327637
Epoch: 85/300 - Train loss: 0.5162400603294373, Validation loss: 0.5173901915550232
Epoch: 86/300 - Train loss: 0.51470547914505, Validation loss: 0.5158435106277466
Epoch: 87/300 - Train loss: 0.5131748914718628, Validation loss: 0.514305591583252
Epoch: 88/300 - Train loss: 0.5116487741470337, Validation loss: 0.5134152173995972
Epoch: 89/300 - Train loss: 0.5101261138916016, Validation loss: 0.5117447972297668
Epoch: 90/300 - Train loss: 0.5086100101470947, Validation loss: 0.5101804137229919
Epoch: 91/300 - Train loss: 0.5070992112159729, Validation loss: 0.5088008046150208
Epoch: 92/300 - Train loss: 0.5055921673774719, Validation loss: 0.5074371099472046
Epoch: 93/300 - Train loss: 0.5040873289108276, Validation loss: 0.5053967237472534
Epoch: 94/300 - Train loss: 0.5025871396064758, Validation loss: 0.5041891932487488
Epoch: 95/300 - Train loss: 0.5010927319526672, Validation loss: 0.5028871297836304
Epoch: 96/300 - Train loss: 0.4996035695075989, Validation loss: 0.5013483166694641
Epoch: 97/300 - Train loss: 0.4981183409690857, Validation loss: 0.5001492500305176
Epoch: 98/300 - Train loss: 0.496637761592865, Validation loss: 0.4990690052509308
Epoch: 99/300 - Train loss: 0.4951638877391815, Validation loss: 0.49750038981437683
Epoch: 100/300 - Train loss: 0.49369606375694275, Validation loss: 0.4958829879760742
Epoch: 101/300 - Train loss: 0.49223265051841736, Validation loss: 0.4943424165248871
Epoch: 102/300 - Train loss: 0.49077361822128296, Validation loss: 0.4926726818084717
Epoch: 103/300 - Train loss: 0.48932012915611267, Validation loss: 0.49165576696395874
Epoch: 104/300 - Train loss: 0.48787248134613037, Validation loss: 0.490043044090271
Epoch: 105/300 - Train loss: 0.48642978072166443, Validation loss: 0.4884132146835327
Epoch: 106/300 - Train loss: 0.4849931299686432, Validation loss: 0.4872812330722809
Epoch: 107/300 - Train loss: 0.48356324434280396, Validation loss: 0.4855889081954956
Epoch: 108/300 - Train loss: 0.4821386933326721, Validation loss: 0.48507171869277954
Epoch: 109/300 - Train loss: 0.4807201325893402, Validation loss: 0.4829961657524109
Epoch: 110/300 - Train loss: 0.47930896282196045, Validation loss: 0.4816902279853821
Epoch: 111/300 - Train loss: 0.47790393233299255, Validation loss: 0.480631023645401
Epoch: 112/300 - Train loss: 0.47650477290153503, Validation loss: 0.4797433912754059
Epoch: 113/300 - Train loss: 0.4751119613647461, Validation loss: 0.4780564308166504
Epoch: 114/300 - Train loss: 0.4737245440483093, Validation loss: 0.4766700267791748
Epoch: 115/300 - Train loss: 0.4723426103591919, Validation loss: 0.4751841127872467
Epoch: 116/300 - Train loss: 0.4709666073322296, Validation loss: 0.4741078317165375
Epoch: 117/300 - Train loss: 0.4695972800254822, Validation loss: 0.47247689962387085
Epoch: 118/300 - Train loss: 0.4682328999042511, Validation loss: 0.47093790769577026
Epoch: 119/300 - Train loss: 0.4668756425380707, Validation loss: 0.4699365794658661
Epoch: 120/300 - Train loss: 0.46552467346191406, Validation loss: 0.46884608268737793
Epoch: 121/300 - Train loss: 0.4641799330711365, Validation loss: 0.46744459867477417
Epoch: 122/300 - Train loss: 0.46284136176109314, Validation loss: 0.4662283658981323
Epoch: 123/300 - Train loss: 0.4615097939968109, Validation loss: 0.46514904499053955
Epoch: 124/300 - Train loss: 0.460184782743454, Validation loss: 0.4634547233581543
Epoch: 125/300 - Train loss: 0.45886537432670593, Validation loss: 0.4621451497077942
Epoch: 126/300 - Train loss: 0.45755213499069214, Validation loss: 0.4610605537891388
Epoch: 127/300 - Train loss: 0.4562447667121887, Validation loss: 0.460489958524704
Epoch: 128/300 - Train loss: 0.45494306087493896, Validation loss: 0.45849451422691345
Epoch: 129/300 - Train loss: 0.45364677906036377, Validation loss: 0.45714718103408813
Epoch: 130/300 - Train loss: 0.4523574113845825, Validation loss: 0.45660656690597534
Epoch: 131/300 - Train loss: 0.45107513666152954, Validation loss: 0.4553750455379486
Epoch: 132/300 - Train loss: 0.4497995674610138, Validation loss: 0.4547131359577179
Epoch: 133/300 - Train loss: 0.4485298693180084, Validation loss: 0.4520280957221985
Epoch: 134/300 - Train loss: 0.4472678601741791, Validation loss: 0.4509618878364563
Epoch: 135/300 - Train loss: 0.4460114538669586, Validation loss: 0.44999611377716064
Epoch: 136/300 - Train loss: 0.44476231932640076, Validation loss: 0.4489063322544098
Epoch: 137/300 - Train loss: 0.4435197710990906, Validation loss: 0.44864916801452637
Epoch: 138/300 - Train loss: 0.44228464365005493, Validation loss: 0.4471380114555359
Epoch: 139/300 - Train loss: 0.4410569965839386, Validation loss: 0.445125013589859
Epoch: 140/300 - Train loss: 0.43983691930770874, Validation loss: 0.44395631551742554
Epoch: 141/300 - Train loss: 0.4386245608329773, Validation loss: 0.44306766986846924
Epoch: 142/300 - Train loss: 0.4374198913574219, Validation loss: 0.4420470893383026
Epoch: 143/300 - Train loss: 0.4362228214740753, Validation loss: 0.44063225388526917
Epoch: 144/300 - Train loss: 0.43503275513648987, Validation loss: 0.43924957513809204
Epoch: 145/300 - Train loss: 0.43385037779808044, Validation loss: 0.4389684796333313
Epoch: 146/300 - Train loss: 0.43267521262168884, Validation loss: 0.43720149993896484
Epoch: 147/300 - Train loss: 0.43150821328163147, Validation loss: 0.43661198019981384
Epoch: 148/300 - Train loss: 0.43034955859184265, Validation loss: 0.43506869673728943
Epoch: 149/300 - Train loss: 0.4291999042034149, Validation loss: 0.43394482135772705
Epoch: 150/300 - Train loss: 0.4280594289302826, Validation loss: 0.4338538944721222
Epoch: 151/300 - Train loss: 0.4269271790981293, Validation loss: 0.4322364628314972
Epoch: 152/300 - Train loss: 0.4258030951023102, Validation loss: 0.43090686202049255
Epoch: 153/300 - Train loss: 0.4246863126754761, Validation loss: 0.42992082238197327
Epoch: 154/300 - Train loss: 0.4235767722129822, Validation loss: 0.42949455976486206
Epoch: 155/300 - Train loss: 0.4224751889705658, Validation loss: 0.4281734228134155
Epoch: 156/300 - Train loss: 0.42138123512268066, Validation loss: 0.4268598258495331
Epoch: 157/300 - Train loss: 0.42029598355293274, Validation loss: 0.4261334240436554
Epoch: 158/300 - Train loss: 0.4192187786102295, Validation loss: 0.42512601613998413
Epoch: 159/300 - Train loss: 0.4181494414806366, Validation loss: 0.4240667521953583
Epoch: 160/300 - Train loss: 0.4170883297920227, Validation loss: 0.4224567115306854
Epoch: 161/300 - Train loss: 0.4160356819629669, Validation loss: 0.4221467673778534
Epoch: 162/300 - Train loss: 0.4149913489818573, Validation loss: 0.4208855926990509
Epoch: 163/300 - Train loss: 0.41395390033721924, Validation loss: 0.4196477234363556
Epoch: 164/300 - Train loss: 0.4129240810871124, Validation loss: 0.4184384047985077
Epoch: 165/300 - Train loss: 0.41190305352211, Validation loss: 0.4178331196308136
Epoch: 166/300 - Train loss: 0.41089069843292236, Validation loss: 0.41668084263801575
Epoch: 167/300 - Train loss: 0.40988680720329285, Validation loss: 0.4158366024494171
Epoch: 168/300 - Train loss: 0.40889087319374084, Validation loss: 0.41519680619239807
Epoch: 169/300 - Train loss: 0.4079025089740753, Validation loss: 0.4141104221343994
Epoch: 170/300 - Train loss: 0.4069218039512634, Validation loss: 0.41334909200668335
Epoch: 171/300 - Train loss: 0.40594857931137085, Validation loss: 0.41323450207710266
Epoch: 172/300 - Train loss: 0.4049833118915558, Validation loss: 0.4113336205482483
Epoch: 173/300 - Train loss: 0.4040256142616272, Validation loss: 0.4104250371456146
Epoch: 174/300 - Train loss: 0.40307608246803284, Validation loss: 0.4096682667732239
Epoch: 175/300 - Train loss: 0.40213367342948914, Validation loss: 0.408552885055542
Epoch: 176/300 - Train loss: 0.4011984169483185, Validation loss: 0.40769851207733154
Epoch: 177/300 - Train loss: 0.40027105808258057, Validation loss: 0.4065967798233032
Epoch: 178/300 - Train loss: 0.3993508517742157, Validation loss: 0.40633994340896606
Epoch: 179/300 - Train loss: 0.3984384536743164, Validation loss: 0.4051598906517029
Epoch: 180/300 - Train loss: 0.3975334167480469, Validation loss: 0.40394526720046997
Epoch: 181/300 - Train loss: 0.39663466811180115, Validation loss: 0.40407368540763855
Epoch: 182/300 - Train loss: 0.39574316143989563, Validation loss: 0.4021928906440735
Epoch: 183/300 - Train loss: 0.3948591351509094, Validation loss: 0.4022759199142456
Epoch: 184/300 - Train loss: 0.3939823806285858, Validation loss: 0.4009336233139038
Epoch: 185/300 - Train loss: 0.3931121826171875, Validation loss: 0.4000808894634247
Epoch: 186/300 - Train loss: 0.39224880933761597, Validation loss: 0.39898738265037537
Epoch: 187/300 - Train loss: 0.3913923501968384, Validation loss: 0.398353636264801
Epoch: 188/300 - Train loss: 0.39054256677627563, Validation loss: 0.3973489999771118
Epoch: 189/300 - Train loss: 0.38969990611076355, Validation loss: 0.39678362011909485
Epoch: 190/300 - Train loss: 0.38886433839797974, Validation loss: 0.3963831067085266
Epoch: 191/300 - Train loss: 0.38803544640541077, Validation loss: 0.39554598927497864
Epoch: 192/300 - Train loss: 0.3872140049934387, Validation loss: 0.3942979872226715
Epoch: 193/300 - Train loss: 0.3864002823829651, Validation loss: 0.3939261734485626
Epoch: 194/300 - Train loss: 0.38559383153915405, Validation loss: 0.3923124372959137
Epoch: 195/300 - Train loss: 0.3847939670085907, Validation loss: 0.39174604415893555
Epoch: 196/300 - Train loss: 0.3840009868144989, Validation loss: 0.39154839515686035
Epoch: 197/300 - Train loss: 0.3832137882709503, Validation loss: 0.39118632674217224
Epoch: 198/300 - Train loss: 0.3824337124824524, Validation loss: 0.39054468274116516
Epoch: 199/300 - Train loss: 0.3816603124141693, Validation loss: 0.38907185196876526
Epoch: 200/300 - Train loss: 0.3808925151824951, Validation loss: 0.38837581872940063
Epoch: 201/300 - Train loss: 0.3801301121711731, Validation loss: 0.38776758313179016
Epoch: 202/300 - Train loss: 0.3793731927871704, Validation loss: 0.38665103912353516
Epoch: 203/300 - Train loss: 0.3786222040653229, Validation loss: 0.38652852177619934
Epoch: 204/300 - Train loss: 0.37787821888923645, Validation loss: 0.38533860445022583
Epoch: 205/300 - Train loss: 0.37714114785194397, Validation loss: 0.3853006958961487
Epoch: 206/300 - Train loss: 0.3764098286628723, Validation loss: 0.38437899947166443
Epoch: 207/300 - Train loss: 0.3756847381591797, Validation loss: 0.3843114972114563
Epoch: 208/300 - Train loss: 0.37496647238731384, Validation loss: 0.3835063576698303
Epoch: 209/300 - Train loss: 0.374254435300827, Validation loss: 0.38279828429222107
Epoch: 210/300 - Train loss: 0.3735480308532715, Validation loss: 0.3823637068271637
Epoch: 211/300 - Train loss: 0.37284746766090393, Validation loss: 0.3808245360851288
Epoch: 212/300 - Train loss: 0.3721524775028229, Validation loss: 0.38027670979499817
Epoch: 213/300 - Train loss: 0.37146368622779846, Validation loss: 0.3794843256473541
Epoch: 214/300 - Train loss: 0.37078046798706055, Validation loss: 0.37964415550231934
Epoch: 215/300 - Train loss: 0.3701022267341614, Validation loss: 0.37863683700561523
Epoch: 216/300 - Train loss: 0.3694301247596741, Validation loss: 0.3780001401901245
Epoch: 217/300 - Train loss: 0.36876383423805237, Validation loss: 0.3769654631614685
Epoch: 218/300 - Train loss: 0.36810335516929626, Validation loss: 0.3765583336353302
Epoch: 219/300 - Train loss: 0.36744704842567444, Validation loss: 0.376368910074234
Epoch: 220/300 - Train loss: 0.3667953908443451, Validation loss: 0.3753682076931
Epoch: 221/300 - Train loss: 0.36614862084388733, Validation loss: 0.3751959800720215
Epoch: 222/300 - Train loss: 0.36550602316856384, Validation loss: 0.3743932247161865
Epoch: 223/300 - Train loss: 0.3648681938648224, Validation loss: 0.3738326132297516
Epoch: 224/300 - Train loss: 0.36423459649086, Validation loss: 0.3728622496128082
Epoch: 225/300 - Train loss: 0.36360636353492737, Validation loss: 0.3725224733352661
Epoch: 226/300 - Train loss: 0.3629821240901947, Validation loss: 0.37236568331718445
