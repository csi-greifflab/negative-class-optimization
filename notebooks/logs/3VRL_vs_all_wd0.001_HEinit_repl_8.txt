Epoch: 1/300 - Train loss: 0.711231529712677, Validation loss: 0.7075398564338684
Epoch: 2/300 - Train loss: 0.7075127959251404, Validation loss: 0.7039810419082642
Epoch: 3/300 - Train loss: 0.7038583755493164, Validation loss: 0.7004084587097168
Epoch: 4/300 - Train loss: 0.700270414352417, Validation loss: 0.6969206929206848
Epoch: 5/300 - Train loss: 0.6967453956604004, Validation loss: 0.6935603022575378
Epoch: 6/300 - Train loss: 0.6932744979858398, Validation loss: 0.690056562423706
Epoch: 7/300 - Train loss: 0.6898483037948608, Validation loss: 0.6868333220481873
Epoch: 8/300 - Train loss: 0.6864624619483948, Validation loss: 0.6834842562675476
Epoch: 9/300 - Train loss: 0.6831018924713135, Validation loss: 0.6800498962402344
Epoch: 10/300 - Train loss: 0.6797581315040588, Validation loss: 0.6769297122955322
Epoch: 11/300 - Train loss: 0.6764200329780579, Validation loss: 0.6736281514167786
Epoch: 12/300 - Train loss: 0.6730815172195435, Validation loss: 0.6704704165458679
Epoch: 13/300 - Train loss: 0.6697366237640381, Validation loss: 0.6670970916748047
Epoch: 14/300 - Train loss: 0.6663711667060852, Validation loss: 0.6637066006660461
Epoch: 15/300 - Train loss: 0.6629737615585327, Validation loss: 0.6602779626846313
Epoch: 16/300 - Train loss: 0.6595389246940613, Validation loss: 0.6569158434867859
Epoch: 17/300 - Train loss: 0.656061589717865, Validation loss: 0.653469443321228
Epoch: 18/300 - Train loss: 0.6525335311889648, Validation loss: 0.64990234375
Epoch: 19/300 - Train loss: 0.6489463448524475, Validation loss: 0.6464149951934814
Epoch: 20/300 - Train loss: 0.6452953815460205, Validation loss: 0.6426391005516052
Epoch: 21/300 - Train loss: 0.641568660736084, Validation loss: 0.6389498710632324
Epoch: 22/300 - Train loss: 0.6377671957015991, Validation loss: 0.6351904273033142
Epoch: 23/300 - Train loss: 0.6338830590248108, Validation loss: 0.6312174797058105
Epoch: 24/300 - Train loss: 0.6299135088920593, Validation loss: 0.6272150874137878
Epoch: 25/300 - Train loss: 0.6258577108383179, Validation loss: 0.6231715083122253
Epoch: 26/300 - Train loss: 0.6217164397239685, Validation loss: 0.6191640496253967
Epoch: 27/300 - Train loss: 0.6174889802932739, Validation loss: 0.614838719367981
Epoch: 28/300 - Train loss: 0.6131713390350342, Validation loss: 0.6105663180351257
Epoch: 29/300 - Train loss: 0.6087644100189209, Validation loss: 0.6060274243354797
Epoch: 30/300 - Train loss: 0.6042698621749878, Validation loss: 0.6016835570335388
Epoch: 31/300 - Train loss: 0.5996851325035095, Validation loss: 0.5971934795379639
Epoch: 32/300 - Train loss: 0.5950141549110413, Validation loss: 0.5925359725952148
Epoch: 33/300 - Train loss: 0.5902652740478516, Validation loss: 0.5877583026885986
Epoch: 34/300 - Train loss: 0.5854361057281494, Validation loss: 0.5829460024833679
Epoch: 35/300 - Train loss: 0.5805311799049377, Validation loss: 0.5782811641693115
Epoch: 36/300 - Train loss: 0.5755519866943359, Validation loss: 0.5730388164520264
Epoch: 37/300 - Train loss: 0.570507287979126, Validation loss: 0.5680305361747742
Epoch: 38/300 - Train loss: 0.5654079914093018, Validation loss: 0.5628694295883179
Epoch: 39/300 - Train loss: 0.5602574348449707, Validation loss: 0.5578581094741821
Epoch: 40/300 - Train loss: 0.5550626516342163, Validation loss: 0.5530017614364624
Epoch: 41/300 - Train loss: 0.54982990026474, Validation loss: 0.5477145910263062
Epoch: 42/300 - Train loss: 0.5445660352706909, Validation loss: 0.5427572727203369
Epoch: 43/300 - Train loss: 0.5392782688140869, Validation loss: 0.5373853445053101
Epoch: 44/300 - Train loss: 0.5339765548706055, Validation loss: 0.5321583151817322
Epoch: 45/300 - Train loss: 0.5286695957183838, Validation loss: 0.5271117687225342
Epoch: 46/300 - Train loss: 0.5233676433563232, Validation loss: 0.5219324231147766
Epoch: 47/300 - Train loss: 0.5180761218070984, Validation loss: 0.5168371200561523
Epoch: 48/300 - Train loss: 0.5128005146980286, Validation loss: 0.5115216970443726
Epoch: 49/300 - Train loss: 0.5075502991676331, Validation loss: 0.5067072510719299
Epoch: 50/300 - Train loss: 0.5023322701454163, Validation loss: 0.501367449760437
Epoch: 51/300 - Train loss: 0.49715331196784973, Validation loss: 0.4965147376060486
Epoch: 52/300 - Train loss: 0.49201709032058716, Validation loss: 0.49161088466644287
Epoch: 53/300 - Train loss: 0.486930251121521, Validation loss: 0.4865378141403198
Epoch: 54/300 - Train loss: 0.4818953573703766, Validation loss: 0.48193708062171936
Epoch: 55/300 - Train loss: 0.47691646218299866, Validation loss: 0.47708001732826233
Epoch: 56/300 - Train loss: 0.47199979424476624, Validation loss: 0.4723420739173889
Epoch: 57/300 - Train loss: 0.46714869141578674, Validation loss: 0.46758967638015747
Epoch: 58/300 - Train loss: 0.46236202120780945, Validation loss: 0.46287623047828674
Epoch: 59/300 - Train loss: 0.4576433300971985, Validation loss: 0.4586906433105469
Epoch: 60/300 - Train loss: 0.45299434661865234, Validation loss: 0.45379677414894104
Epoch: 61/300 - Train loss: 0.44841501116752625, Validation loss: 0.44958075881004333
Epoch: 62/300 - Train loss: 0.44390782713890076, Validation loss: 0.4456820487976074
Epoch: 63/300 - Train loss: 0.4394741952419281, Validation loss: 0.44108375906944275
Epoch: 64/300 - Train loss: 0.4351162612438202, Validation loss: 0.4369044005870819
Epoch: 65/300 - Train loss: 0.43083396553993225, Validation loss: 0.433726042509079
Epoch: 66/300 - Train loss: 0.42662715911865234, Validation loss: 0.42994165420532227
Epoch: 67/300 - Train loss: 0.42249536514282227, Validation loss: 0.42538806796073914
Epoch: 68/300 - Train loss: 0.4184386432170868, Validation loss: 0.42143702507019043
Epoch: 69/300 - Train loss: 0.41445717215538025, Validation loss: 0.4177503287792206
Epoch: 70/300 - Train loss: 0.4105522334575653, Validation loss: 0.4143013060092926
Epoch: 71/300 - Train loss: 0.406722754240036, Validation loss: 0.4106748700141907
Epoch: 72/300 - Train loss: 0.40296807885169983, Validation loss: 0.4067886769771576
Epoch: 73/300 - Train loss: 0.3992866277694702, Validation loss: 0.4033774435520172
Epoch: 74/300 - Train loss: 0.3956778049468994, Validation loss: 0.40000972151756287
Epoch: 75/300 - Train loss: 0.3921402096748352, Validation loss: 0.3963207006454468
Epoch: 76/300 - Train loss: 0.38867464661598206, Validation loss: 0.39310580492019653
Epoch: 77/300 - Train loss: 0.3852792978286743, Validation loss: 0.38983404636383057
Epoch: 78/300 - Train loss: 0.381953626871109, Validation loss: 0.38711580634117126
Epoch: 79/300 - Train loss: 0.37869566679000854, Validation loss: 0.3836591839790344
Epoch: 80/300 - Train loss: 0.3755051791667938, Validation loss: 0.38069775700569153
Epoch: 81/300 - Train loss: 0.37238240242004395, Validation loss: 0.3780093193054199
Epoch: 82/300 - Train loss: 0.3693249225616455, Validation loss: 0.3748946487903595
Epoch: 83/300 - Train loss: 0.3663325011730194, Validation loss: 0.3724019527435303
Epoch: 84/300 - Train loss: 0.36340391635894775, Validation loss: 0.36912667751312256
Epoch: 85/300 - Train loss: 0.3605371415615082, Validation loss: 0.3667536973953247
Epoch: 86/300 - Train loss: 0.35773083567619324, Validation loss: 0.3634388744831085
Epoch: 87/300 - Train loss: 0.3549841046333313, Validation loss: 0.3613557815551758
Epoch: 88/300 - Train loss: 0.3522951602935791, Validation loss: 0.3584566116333008
Epoch: 89/300 - Train loss: 0.34966304898262024, Validation loss: 0.35609716176986694
Epoch: 90/300 - Train loss: 0.3470875918865204, Validation loss: 0.3537772595882416
Epoch: 91/300 - Train loss: 0.3445673882961273, Validation loss: 0.35091373324394226
Epoch: 92/300 - Train loss: 0.34210070967674255, Validation loss: 0.3490056097507477
Epoch: 93/300 - Train loss: 0.3396856188774109, Validation loss: 0.34645816683769226
Epoch: 94/300 - Train loss: 0.3373202085494995, Validation loss: 0.34389206767082214
Epoch: 95/300 - Train loss: 0.3350050747394562, Validation loss: 0.3417966067790985
Epoch: 96/300 - Train loss: 0.33273836970329285, Validation loss: 0.3400222063064575
Epoch: 97/300 - Train loss: 0.3305187523365021, Validation loss: 0.33748480677604675
Epoch: 98/300 - Train loss: 0.32834580540657043, Validation loss: 0.3357827961444855
Epoch: 99/300 - Train loss: 0.3262183964252472, Validation loss: 0.3337249457836151
Epoch: 100/300 - Train loss: 0.32413509488105774, Validation loss: 0.3311614692211151
Epoch: 101/300 - Train loss: 0.32209450006484985, Validation loss: 0.32985565066337585
Epoch: 102/300 - Train loss: 0.3200949430465698, Validation loss: 0.32755300402641296
Epoch: 103/300 - Train loss: 0.3181353509426117, Validation loss: 0.3251226544380188
Epoch: 104/300 - Train loss: 0.3162146210670471, Validation loss: 0.32400059700012207
Epoch: 105/300 - Train loss: 0.31433188915252686, Validation loss: 0.322270929813385
Epoch: 106/300 - Train loss: 0.3124859035015106, Validation loss: 0.3201753497123718
Epoch: 107/300 - Train loss: 0.31067585945129395, Validation loss: 0.3179963529109955
Epoch: 108/300 - Train loss: 0.3089004456996918, Validation loss: 0.31640928983688354
Epoch: 109/300 - Train loss: 0.3071587383747101, Validation loss: 0.3153703212738037
Epoch: 110/300 - Train loss: 0.30544987320899963, Validation loss: 0.312989741563797
Epoch: 111/300 - Train loss: 0.30377286672592163, Validation loss: 0.31168457865715027
Epoch: 112/300 - Train loss: 0.3021272122859955, Validation loss: 0.31001001596450806
Epoch: 113/300 - Train loss: 0.3005118668079376, Validation loss: 0.30840855836868286
Epoch: 114/300 - Train loss: 0.29892587661743164, Validation loss: 0.30655327439308167
Epoch: 115/300 - Train loss: 0.2973685562610626, Validation loss: 0.3051508665084839
Epoch: 116/300 - Train loss: 0.2958393394947052, Validation loss: 0.3038145899772644
Epoch: 117/300 - Train loss: 0.29433736205101013, Validation loss: 0.3030374348163605
Epoch: 118/300 - Train loss: 0.29286202788352966, Validation loss: 0.30096641182899475
Epoch: 119/300 - Train loss: 0.2914120852947235, Validation loss: 0.29936712980270386
Epoch: 120/300 - Train loss: 0.2899869382381439, Validation loss: 0.2985024154186249
Epoch: 121/300 - Train loss: 0.2885861098766327, Validation loss: 0.2967039942741394
Epoch: 122/300 - Train loss: 0.287209153175354, Validation loss: 0.29530319571495056
Epoch: 123/300 - Train loss: 0.28585538268089294, Validation loss: 0.29390278458595276
Epoch: 124/300 - Train loss: 0.2845243811607361, Validation loss: 0.2928290069103241
Epoch: 125/300 - Train loss: 0.2832155227661133, Validation loss: 0.29146045446395874
Epoch: 126/300 - Train loss: 0.28192806243896484, Validation loss: 0.289783239364624
Epoch: 127/300 - Train loss: 0.28066179156303406, Validation loss: 0.2892416715621948
Epoch: 128/300 - Train loss: 0.27941587567329407, Validation loss: 0.2883385717868805
Epoch: 129/300 - Train loss: 0.2781901955604553, Validation loss: 0.28675106167793274
Epoch: 130/300 - Train loss: 0.2769843339920044, Validation loss: 0.285293847322464
Epoch: 131/300 - Train loss: 0.2757977545261383, Validation loss: 0.28443455696105957
Epoch: 132/300 - Train loss: 0.27463001012802124, Validation loss: 0.2827017605304718
Epoch: 133/300 - Train loss: 0.27348071336746216, Validation loss: 0.2819178104400635
Epoch: 134/300 - Train loss: 0.27234944701194763, Validation loss: 0.2810744047164917
Epoch: 135/300 - Train loss: 0.27123570442199707, Validation loss: 0.2794620096683502
Epoch: 136/300 - Train loss: 0.2701391577720642, Validation loss: 0.2783581614494324
Epoch: 137/300 - Train loss: 0.2690594494342804, Validation loss: 0.2776329517364502
Epoch: 138/300 - Train loss: 0.2679961919784546, Validation loss: 0.27692925930023193
Epoch: 139/300 - Train loss: 0.2669491171836853, Validation loss: 0.27565598487854004
Epoch: 140/300 - Train loss: 0.2659176290035248, Validation loss: 0.27438583970069885
Epoch: 141/300 - Train loss: 0.2649014890193939, Validation loss: 0.2735988199710846
Epoch: 142/300 - Train loss: 0.26390036940574646, Validation loss: 0.272934228181839
Epoch: 143/300 - Train loss: 0.26291385293006897, Validation loss: 0.27149125933647156
Epoch: 144/300 - Train loss: 0.26194193959236145, Validation loss: 0.2708680331707001
Epoch: 145/300 - Train loss: 0.2609843313694, Validation loss: 0.26962921023368835
Epoch: 146/300 - Train loss: 0.2600407600402832, Validation loss: 0.2684534192085266
Epoch: 147/300 - Train loss: 0.25911077857017517, Validation loss: 0.26767319440841675
Epoch: 148/300 - Train loss: 0.2581941485404968, Validation loss: 0.2676455080509186
Epoch: 149/300 - Train loss: 0.2572905719280243, Validation loss: 0.2664947509765625
Epoch: 150/300 - Train loss: 0.25639984011650085, Validation loss: 0.2656553387641907
Epoch: 151/300 - Train loss: 0.2555217742919922, Validation loss: 0.26396840810775757
Epoch: 152/300 - Train loss: 0.25465601682662964, Validation loss: 0.26371440291404724
Epoch: 153/300 - Train loss: 0.25380241870880127, Validation loss: 0.2625289559364319
Epoch: 154/300 - Train loss: 0.25296083092689514, Validation loss: 0.26175329089164734
Epoch: 155/300 - Train loss: 0.252130925655365, Validation loss: 0.2607553005218506
Epoch: 156/300 - Train loss: 0.2513124942779541, Validation loss: 0.26038727164268494
Epoch: 157/300 - Train loss: 0.25050532817840576, Validation loss: 0.2597079575061798
Epoch: 158/300 - Train loss: 0.24970920383930206, Validation loss: 0.2583692669868469
Epoch: 159/300 - Train loss: 0.24892400205135345, Validation loss: 0.25765153765678406
Epoch: 160/300 - Train loss: 0.24814940989017487, Validation loss: 0.25725921988487244
Epoch: 161/300 - Train loss: 0.24738529324531555, Validation loss: 0.25612714886665344
Epoch: 162/300 - Train loss: 0.24663148820400238, Validation loss: 0.2559750974178314
Epoch: 163/300 - Train loss: 0.24588780105113983, Validation loss: 0.25484052300453186
Epoch: 164/300 - Train loss: 0.24515409767627716, Validation loss: 0.2538914084434509
Epoch: 165/300 - Train loss: 0.24443018436431885, Validation loss: 0.25352251529693604
Epoch: 166/300 - Train loss: 0.24371591210365295, Validation loss: 0.25300392508506775
Epoch: 167/300 - Train loss: 0.24301108717918396, Validation loss: 0.25213009119033813
Epoch: 168/300 - Train loss: 0.24231559038162231, Validation loss: 0.25105997920036316
Epoch: 169/300 - Train loss: 0.24162925779819489, Validation loss: 0.2510705292224884
Epoch: 170/300 - Train loss: 0.24095192551612854, Validation loss: 0.250548392534256
Epoch: 171/300 - Train loss: 0.24028345942497253, Validation loss: 0.24915634095668793
Epoch: 172/300 - Train loss: 0.23962365090847015, Validation loss: 0.2481018602848053
Epoch: 173/300 - Train loss: 0.23897230625152588, Validation loss: 0.24774160981178284
Epoch: 174/300 - Train loss: 0.2383292317390442, Validation loss: 0.24757274985313416
Epoch: 175/300 - Train loss: 0.23769435286521912, Validation loss: 0.2465401589870453
Epoch: 176/300 - Train loss: 0.23706750571727753, Validation loss: 0.24603290855884552
Epoch: 177/300 - Train loss: 0.23644864559173584, Validation loss: 0.24523508548736572
Epoch: 178/300 - Train loss: 0.2358376681804657, Validation loss: 0.2445898950099945
Epoch: 179/300 - Train loss: 0.23523442447185516, Validation loss: 0.24409811198711395
Epoch: 180/300 - Train loss: 0.2346387356519699, Validation loss: 0.24359551072120667
Epoch: 181/300 - Train loss: 0.234050452709198, Validation loss: 0.243365079164505
