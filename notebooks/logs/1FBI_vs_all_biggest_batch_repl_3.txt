Epoch: 1/300 - Train loss: 0.7018492817878723, Validation loss: 0.6989971995353699
Epoch: 2/300 - Train loss: 0.6975750923156738, Validation loss: 0.6946342587471008
Epoch: 3/300 - Train loss: 0.6932991743087769, Validation loss: 0.6901178956031799
Epoch: 4/300 - Train loss: 0.6889751553535461, Validation loss: 0.6855436563491821
Epoch: 5/300 - Train loss: 0.6845701932907104, Validation loss: 0.6810159087181091
Epoch: 6/300 - Train loss: 0.6800501346588135, Validation loss: 0.6760854721069336
Epoch: 7/300 - Train loss: 0.6753901243209839, Validation loss: 0.6711078882217407
Epoch: 8/300 - Train loss: 0.6705676913261414, Validation loss: 0.6659595370292664
Epoch: 9/300 - Train loss: 0.6655697226524353, Validation loss: 0.6605013012886047
Epoch: 10/300 - Train loss: 0.6603814959526062, Validation loss: 0.6549183130264282
Epoch: 11/300 - Train loss: 0.6550150513648987, Validation loss: 0.6491105556488037
Epoch: 12/300 - Train loss: 0.6494823098182678, Validation loss: 0.6434277892112732
Epoch: 13/300 - Train loss: 0.6437904834747314, Validation loss: 0.6372137069702148
Epoch: 14/300 - Train loss: 0.6379525661468506, Validation loss: 0.6310638785362244
Epoch: 15/300 - Train loss: 0.6319876909255981, Validation loss: 0.6249732375144958
Epoch: 16/300 - Train loss: 0.6259183287620544, Validation loss: 0.618428111076355
Epoch: 17/300 - Train loss: 0.6197619438171387, Validation loss: 0.612179160118103
Epoch: 18/300 - Train loss: 0.6135318279266357, Validation loss: 0.6056663393974304
Epoch: 19/300 - Train loss: 0.6072455048561096, Validation loss: 0.5990970134735107
Epoch: 20/300 - Train loss: 0.6009191274642944, Validation loss: 0.5928031802177429
Epoch: 21/300 - Train loss: 0.5945618748664856, Validation loss: 0.5862136483192444
Epoch: 22/300 - Train loss: 0.5881791710853577, Validation loss: 0.5796595215797424
Epoch: 23/300 - Train loss: 0.5817804336547852, Validation loss: 0.5731602311134338
Epoch: 24/300 - Train loss: 0.5753690004348755, Validation loss: 0.5666491985321045
Epoch: 25/300 - Train loss: 0.5689534544944763, Validation loss: 0.560035228729248
Epoch: 26/300 - Train loss: 0.5625366568565369, Validation loss: 0.5535984635353088
Epoch: 27/300 - Train loss: 0.5561234354972839, Validation loss: 0.5471782684326172
Epoch: 28/300 - Train loss: 0.5497181415557861, Validation loss: 0.5406357645988464
Epoch: 29/300 - Train loss: 0.5433251857757568, Validation loss: 0.5341350436210632
Epoch: 30/300 - Train loss: 0.5369482636451721, Validation loss: 0.5278650522232056
Epoch: 31/300 - Train loss: 0.5305904150009155, Validation loss: 0.5213959217071533
Epoch: 32/300 - Train loss: 0.5242555737495422, Validation loss: 0.5146939158439636
Epoch: 33/300 - Train loss: 0.5179483294487, Validation loss: 0.5085121393203735
Epoch: 34/300 - Train loss: 0.5116720795631409, Validation loss: 0.5021745562553406
Epoch: 35/300 - Train loss: 0.5054311156272888, Validation loss: 0.49600136280059814
Epoch: 36/300 - Train loss: 0.4992291033267975, Validation loss: 0.4895472228527069
Epoch: 37/300 - Train loss: 0.49306899309158325, Validation loss: 0.4833783209323883
Epoch: 38/300 - Train loss: 0.48695430159568787, Validation loss: 0.47713327407836914
Epoch: 39/300 - Train loss: 0.48088911175727844, Validation loss: 0.4713674485683441
Epoch: 40/300 - Train loss: 0.4748767614364624, Validation loss: 0.46541446447372437
Epoch: 41/300 - Train loss: 0.4689212441444397, Validation loss: 0.45911526679992676
Epoch: 42/300 - Train loss: 0.46302592754364014, Validation loss: 0.45348870754241943
Epoch: 43/300 - Train loss: 0.45719391107559204, Validation loss: 0.44768381118774414
Epoch: 44/300 - Train loss: 0.4514283835887909, Validation loss: 0.4418759346008301
Epoch: 45/300 - Train loss: 0.4457320272922516, Validation loss: 0.43597573041915894
Epoch: 46/300 - Train loss: 0.4401078224182129, Validation loss: 0.4304625988006592
Epoch: 47/300 - Train loss: 0.43455836176872253, Validation loss: 0.4252084791660309
Epoch: 48/300 - Train loss: 0.4290858209133148, Validation loss: 0.4194178879261017
Epoch: 49/300 - Train loss: 0.4236923158168793, Validation loss: 0.41396668553352356
Epoch: 50/300 - Train loss: 0.4183797538280487, Validation loss: 0.40933704376220703
Epoch: 51/300 - Train loss: 0.4131500720977783, Validation loss: 0.4039107859134674
Epoch: 52/300 - Train loss: 0.4080047309398651, Validation loss: 0.399037629365921
Epoch: 53/300 - Train loss: 0.40294525027275085, Validation loss: 0.39369359612464905
Epoch: 54/300 - Train loss: 0.39797282218933105, Validation loss: 0.38904237747192383
Epoch: 55/300 - Train loss: 0.3930880129337311, Validation loss: 0.38409703969955444
Epoch: 56/300 - Train loss: 0.388291597366333, Validation loss: 0.37922388315200806
Epoch: 57/300 - Train loss: 0.38358405232429504, Validation loss: 0.37530088424682617
Epoch: 58/300 - Train loss: 0.3789654076099396, Validation loss: 0.3700472414493561
Epoch: 59/300 - Train loss: 0.3744359016418457, Validation loss: 0.3658759891986847
Epoch: 60/300 - Train loss: 0.36999544501304626, Validation loss: 0.36179065704345703
Epoch: 61/300 - Train loss: 0.36564382910728455, Validation loss: 0.3572317063808441
Epoch: 62/300 - Train loss: 0.36138060688972473, Validation loss: 0.3529985547065735
Epoch: 63/300 - Train loss: 0.357205331325531, Validation loss: 0.3489386737346649
Epoch: 64/300 - Train loss: 0.35311755537986755, Validation loss: 0.34524238109588623
Epoch: 65/300 - Train loss: 0.3491164743900299, Validation loss: 0.34128323197364807
Epoch: 66/300 - Train loss: 0.3452014625072479, Validation loss: 0.3372343182563782
Epoch: 67/300 - Train loss: 0.3413713872432709, Validation loss: 0.3337899148464203
Epoch: 68/300 - Train loss: 0.3376251757144928, Validation loss: 0.33024221658706665
Epoch: 69/300 - Train loss: 0.3339616060256958, Validation loss: 0.3264835774898529
Epoch: 70/300 - Train loss: 0.3303799033164978, Validation loss: 0.32249441742897034
Epoch: 71/300 - Train loss: 0.32687902450561523, Validation loss: 0.3194435238838196
Epoch: 72/300 - Train loss: 0.3234575092792511, Validation loss: 0.3158175051212311
Epoch: 73/300 - Train loss: 0.3201139569282532, Validation loss: 0.31265655159950256
Epoch: 74/300 - Train loss: 0.3168468475341797, Validation loss: 0.30962076783180237
Epoch: 75/300 - Train loss: 0.3136547803878784, Validation loss: 0.30691319704055786
Epoch: 76/300 - Train loss: 0.31053629517555237, Validation loss: 0.3033513128757477
Epoch: 77/300 - Train loss: 0.3074900209903717, Validation loss: 0.3003571331501007
Epoch: 78/300 - Train loss: 0.30451464653015137, Validation loss: 0.297553688287735
Epoch: 79/300 - Train loss: 0.3016085922718048, Validation loss: 0.2948278486728668
Epoch: 80/300 - Train loss: 0.2987704575061798, Validation loss: 0.29209861159324646
Epoch: 81/300 - Train loss: 0.29599854350090027, Validation loss: 0.2895585596561432
Epoch: 82/300 - Train loss: 0.2932910919189453, Validation loss: 0.28635430335998535
Epoch: 83/300 - Train loss: 0.2906467318534851, Validation loss: 0.2841404378414154
Epoch: 84/300 - Train loss: 0.2880641520023346, Validation loss: 0.28154635429382324
Epoch: 85/300 - Train loss: 0.28554192185401917, Validation loss: 0.279556542634964
Epoch: 86/300 - Train loss: 0.28307831287384033, Validation loss: 0.2769811749458313
Epoch: 87/300 - Train loss: 0.2806721031665802, Validation loss: 0.27431705594062805
Epoch: 88/300 - Train loss: 0.2783220708370209, Validation loss: 0.27237468957901
Epoch: 89/300 - Train loss: 0.27602654695510864, Validation loss: 0.26992934942245483
Epoch: 90/300 - Train loss: 0.273784339427948, Validation loss: 0.2678717374801636
Epoch: 91/300 - Train loss: 0.2715940475463867, Validation loss: 0.26583969593048096
Epoch: 92/300 - Train loss: 0.26945436000823975, Validation loss: 0.2635043263435364
Epoch: 93/300 - Train loss: 0.2673640549182892, Validation loss: 0.2615046501159668
Epoch: 94/300 - Train loss: 0.26532191038131714, Validation loss: 0.2596891522407532
Epoch: 95/300 - Train loss: 0.2633264362812042, Validation loss: 0.2579653859138489
Epoch: 96/300 - Train loss: 0.26137641072273254, Validation loss: 0.25646671652793884
Epoch: 97/300 - Train loss: 0.2594709098339081, Validation loss: 0.25421836972236633
Epoch: 98/300 - Train loss: 0.25760865211486816, Validation loss: 0.25252458453178406
Epoch: 99/300 - Train loss: 0.255788654088974, Validation loss: 0.25045663118362427
Epoch: 100/300 - Train loss: 0.25400981307029724, Validation loss: 0.24872705340385437
Epoch: 101/300 - Train loss: 0.25227099657058716, Validation loss: 0.24692687392234802
Epoch: 102/300 - Train loss: 0.2505711615085602, Validation loss: 0.24547883868217468
Epoch: 103/300 - Train loss: 0.24890920519828796, Validation loss: 0.24389849603176117
Epoch: 104/300 - Train loss: 0.24728423357009888, Validation loss: 0.2423548549413681
Epoch: 105/300 - Train loss: 0.24569520354270935, Validation loss: 0.24087993800640106
Epoch: 106/300 - Train loss: 0.24414139986038208, Validation loss: 0.23877140879631042
Epoch: 107/300 - Train loss: 0.2426217943429947, Validation loss: 0.23754943907260895
Epoch: 108/300 - Train loss: 0.24113553762435913, Validation loss: 0.2370038479566574
Epoch: 109/300 - Train loss: 0.23968178033828735, Validation loss: 0.2349696010351181
Epoch: 110/300 - Train loss: 0.23825982213020325, Validation loss: 0.2338649034500122
Epoch: 111/300 - Train loss: 0.23686867952346802, Validation loss: 0.23247314989566803
Epoch: 112/300 - Train loss: 0.23550765216350555, Validation loss: 0.2312525361776352
Epoch: 113/300 - Train loss: 0.23417584598064423, Validation loss: 0.2297387570142746
Epoch: 114/300 - Train loss: 0.2328726053237915, Validation loss: 0.22842630743980408
Epoch: 115/300 - Train loss: 0.23159705102443695, Validation loss: 0.22718952596187592
Epoch: 116/300 - Train loss: 0.23034857213497162, Validation loss: 0.22609218955039978
Epoch: 117/300 - Train loss: 0.2291264533996582, Validation loss: 0.22546930611133575
Epoch: 118/300 - Train loss: 0.22793002426624298, Validation loss: 0.22378675639629364
Epoch: 119/300 - Train loss: 0.2267586588859558, Validation loss: 0.22251829504966736
Epoch: 120/300 - Train loss: 0.22561165690422058, Validation loss: 0.2220931053161621
Epoch: 121/300 - Train loss: 0.2244884967803955, Validation loss: 0.22042405605316162
Epoch: 122/300 - Train loss: 0.22338853776454926, Validation loss: 0.21973682940006256
Epoch: 123/300 - Train loss: 0.22231121361255646, Validation loss: 0.21868324279785156
Epoch: 124/300 - Train loss: 0.22125598788261414, Validation loss: 0.21760998666286469
Epoch: 125/300 - Train loss: 0.2202223241329193, Validation loss: 0.21687230467796326
Epoch: 126/300 - Train loss: 0.2192096710205078, Validation loss: 0.21549555659294128
Epoch: 127/300 - Train loss: 0.21821750700473785, Validation loss: 0.21496380865573883
Epoch: 128/300 - Train loss: 0.21724537014961243, Validation loss: 0.21400247514247894
Epoch: 129/300 - Train loss: 0.21629279851913452, Validation loss: 0.21304158866405487
Epoch: 130/300 - Train loss: 0.21535925567150116, Validation loss: 0.2120838314294815
Epoch: 131/300 - Train loss: 0.2144443541765213, Validation loss: 0.21165359020233154
Epoch: 132/300 - Train loss: 0.21354760229587555, Validation loss: 0.21014641225337982
Epoch: 133/300 - Train loss: 0.2126685529947281, Validation loss: 0.209509938955307
Epoch: 134/300 - Train loss: 0.2118067890405655, Validation loss: 0.20896479487419128
Epoch: 135/300 - Train loss: 0.21096181869506836, Validation loss: 0.20816577970981598
Epoch: 136/300 - Train loss: 0.21013329923152924, Validation loss: 0.20707449316978455
Epoch: 137/300 - Train loss: 0.2093208134174347, Validation loss: 0.20641286671161652
Epoch: 138/300 - Train loss: 0.2085239440202713, Validation loss: 0.2056017518043518
Epoch: 139/300 - Train loss: 0.20774239301681519, Validation loss: 0.204942986369133
Epoch: 140/300 - Train loss: 0.20697574317455292, Validation loss: 0.20442476868629456
Epoch: 141/300 - Train loss: 0.20622369647026062, Validation loss: 0.20358936488628387
Epoch: 142/300 - Train loss: 0.20548592507839203, Validation loss: 0.20256485044956207
Epoch: 143/300 - Train loss: 0.20476211607456207, Validation loss: 0.2028144896030426
Epoch: 144/300 - Train loss: 0.2040518969297409, Validation loss: 0.20171985030174255
Epoch: 145/300 - Train loss: 0.20335493981838226, Validation loss: 0.2010168582201004
Epoch: 146/300 - Train loss: 0.20267102122306824, Validation loss: 0.20049980282783508
Epoch: 147/300 - Train loss: 0.20199976861476898, Validation loss: 0.2000669538974762
Epoch: 148/300 - Train loss: 0.2013409435749054, Validation loss: 0.19929921627044678
Epoch: 149/300 - Train loss: 0.200694277882576, Validation loss: 0.19850698113441467
Epoch: 150/300 - Train loss: 0.20005948841571808, Validation loss: 0.19800539314746857
Epoch: 151/300 - Train loss: 0.19943633675575256, Validation loss: 0.19741007685661316
Epoch: 152/300 - Train loss: 0.19882450997829437, Validation loss: 0.19708026945590973
Epoch: 153/300 - Train loss: 0.1982237547636032, Validation loss: 0.19622567296028137
Epoch: 154/300 - Train loss: 0.19763383269309998, Validation loss: 0.1965448260307312
