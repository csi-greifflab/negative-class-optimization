Epoch: 1/300 - Train loss: 0.6930920481681824, Validation loss: 0.6893343329429626
Epoch: 2/300 - Train loss: 0.6903952360153198, Validation loss: 0.6865131855010986
Epoch: 3/300 - Train loss: 0.6876726150512695, Validation loss: 0.6836762428283691
Epoch: 4/300 - Train loss: 0.6849005818367004, Validation loss: 0.6806638836860657
Epoch: 5/300 - Train loss: 0.6820558309555054, Validation loss: 0.677606999874115
Epoch: 6/300 - Train loss: 0.6791276931762695, Validation loss: 0.6744817495346069
Epoch: 7/300 - Train loss: 0.676102876663208, Validation loss: 0.6712221503257751
Epoch: 8/300 - Train loss: 0.6729704737663269, Validation loss: 0.6678416728973389
Epoch: 9/300 - Train loss: 0.669723391532898, Validation loss: 0.6642549633979797
Epoch: 10/300 - Train loss: 0.666350781917572, Validation loss: 0.6605727076530457
Epoch: 11/300 - Train loss: 0.6628429889678955, Validation loss: 0.6567749381065369
Epoch: 12/300 - Train loss: 0.6591880321502686, Validation loss: 0.6528171300888062
Epoch: 13/300 - Train loss: 0.6553856134414673, Validation loss: 0.6487599015235901
Epoch: 14/300 - Train loss: 0.6514355540275574, Validation loss: 0.6445266604423523
Epoch: 15/300 - Train loss: 0.6473341584205627, Validation loss: 0.6401631236076355
Epoch: 16/300 - Train loss: 0.6430714726448059, Validation loss: 0.6354416608810425
Epoch: 17/300 - Train loss: 0.6386532783508301, Validation loss: 0.6307193040847778
Epoch: 18/300 - Train loss: 0.6340799331665039, Validation loss: 0.6258354783058167
Epoch: 19/300 - Train loss: 0.6293559074401855, Validation loss: 0.6209768056869507
Epoch: 20/300 - Train loss: 0.6244893074035645, Validation loss: 0.6158947944641113
Epoch: 21/300 - Train loss: 0.6194748878479004, Validation loss: 0.6105524301528931
Epoch: 22/300 - Train loss: 0.614327609539032, Validation loss: 0.6049830913543701
Epoch: 23/300 - Train loss: 0.6090468168258667, Validation loss: 0.5994182825088501
Epoch: 24/300 - Train loss: 0.603644073009491, Validation loss: 0.5938419103622437
Epoch: 25/300 - Train loss: 0.5981296300888062, Validation loss: 0.5879595875740051
Epoch: 26/300 - Train loss: 0.5925137400627136, Validation loss: 0.582141637802124
Epoch: 27/300 - Train loss: 0.5868051052093506, Validation loss: 0.5761657357215881
Epoch: 28/300 - Train loss: 0.5810091495513916, Validation loss: 0.5701161623001099
Epoch: 29/300 - Train loss: 0.5751391053199768, Validation loss: 0.5639120936393738
Epoch: 30/300 - Train loss: 0.5691984295845032, Validation loss: 0.5580596327781677
Epoch: 31/300 - Train loss: 0.563194751739502, Validation loss: 0.5517547130584717
Epoch: 32/300 - Train loss: 0.5571399927139282, Validation loss: 0.5456995964050293
Epoch: 33/300 - Train loss: 0.5510459542274475, Validation loss: 0.5394677519798279
Epoch: 34/300 - Train loss: 0.5449175238609314, Validation loss: 0.5333446264266968
Epoch: 35/300 - Train loss: 0.5387625098228455, Validation loss: 0.5271766781806946
Epoch: 36/300 - Train loss: 0.5325820446014404, Validation loss: 0.5206575989723206
Epoch: 37/300 - Train loss: 0.5263820290565491, Validation loss: 0.514483630657196
Epoch: 38/300 - Train loss: 0.5201740264892578, Validation loss: 0.5082898736000061
Epoch: 39/300 - Train loss: 0.513965368270874, Validation loss: 0.50211501121521
Epoch: 40/300 - Train loss: 0.5077638030052185, Validation loss: 0.4956497550010681
Epoch: 41/300 - Train loss: 0.501578152179718, Validation loss: 0.48968151211738586
Epoch: 42/300 - Train loss: 0.4954150319099426, Validation loss: 0.48352470993995667
Epoch: 43/300 - Train loss: 0.48928049206733704, Validation loss: 0.4771922528743744
Epoch: 44/300 - Train loss: 0.48317989706993103, Validation loss: 0.47119346261024475
Epoch: 45/300 - Train loss: 0.4771175682544708, Validation loss: 0.46517738699913025
Epoch: 46/300 - Train loss: 0.47110050916671753, Validation loss: 0.45942968130111694
Epoch: 47/300 - Train loss: 0.4651336967945099, Validation loss: 0.45317691564559937
Epoch: 48/300 - Train loss: 0.4592198133468628, Validation loss: 0.4476236402988434
Epoch: 49/300 - Train loss: 0.45336204767227173, Validation loss: 0.4419683814048767
Epoch: 50/300 - Train loss: 0.4475666880607605, Validation loss: 0.4360884726047516
Epoch: 51/300 - Train loss: 0.4418375492095947, Validation loss: 0.4307096004486084
Epoch: 52/300 - Train loss: 0.4361790418624878, Validation loss: 0.42509016394615173
Epoch: 53/300 - Train loss: 0.4305935204029083, Validation loss: 0.4193114638328552
Epoch: 54/300 - Train loss: 0.4250829219818115, Validation loss: 0.41403695940971375
Epoch: 55/300 - Train loss: 0.41965022683143616, Validation loss: 0.4088952839374542
Epoch: 56/300 - Train loss: 0.41429898142814636, Validation loss: 0.40325695276260376
Epoch: 57/300 - Train loss: 0.40903040766716003, Validation loss: 0.39840182662010193
Epoch: 58/300 - Train loss: 0.40384790301322937, Validation loss: 0.39290687441825867
Epoch: 59/300 - Train loss: 0.3987526297569275, Validation loss: 0.388212651014328
Epoch: 60/300 - Train loss: 0.3937451243400574, Validation loss: 0.38332855701446533
Epoch: 61/300 - Train loss: 0.3888271749019623, Validation loss: 0.37869688868522644
Epoch: 62/300 - Train loss: 0.38399943709373474, Validation loss: 0.37374886870384216
Epoch: 63/300 - Train loss: 0.3792623281478882, Validation loss: 0.3692200481891632
Epoch: 64/300 - Train loss: 0.3746158480644226, Validation loss: 0.3641051650047302
Epoch: 65/300 - Train loss: 0.3700593113899231, Validation loss: 0.3601404130458832
Epoch: 66/300 - Train loss: 0.36559391021728516, Validation loss: 0.35589599609375
Epoch: 67/300 - Train loss: 0.3612196147441864, Validation loss: 0.351631760597229
Epoch: 68/300 - Train loss: 0.3569367527961731, Validation loss: 0.34708642959594727
Epoch: 69/300 - Train loss: 0.3527446985244751, Validation loss: 0.34329456090927124
Epoch: 70/300 - Train loss: 0.3486442267894745, Validation loss: 0.33939412236213684
Epoch: 71/300 - Train loss: 0.3446342945098877, Validation loss: 0.33565446734428406
Epoch: 72/300 - Train loss: 0.3407142460346222, Validation loss: 0.33195436000823975
Epoch: 73/300 - Train loss: 0.3368832468986511, Validation loss: 0.3278055489063263
Epoch: 74/300 - Train loss: 0.3331403434276581, Validation loss: 0.3246084153652191
Epoch: 75/300 - Train loss: 0.3294849097728729, Validation loss: 0.32102444767951965
Epoch: 76/300 - Train loss: 0.3259142339229584, Validation loss: 0.31727465987205505
Epoch: 77/300 - Train loss: 0.3224273920059204, Validation loss: 0.3143537640571594
Epoch: 78/300 - Train loss: 0.3190232217311859, Validation loss: 0.3104746639728546
Epoch: 79/300 - Train loss: 0.3157007694244385, Validation loss: 0.3073805868625641
Epoch: 80/300 - Train loss: 0.3124582767486572, Validation loss: 0.3042684495449066
Epoch: 81/300 - Train loss: 0.30929481983184814, Validation loss: 0.3015271723270416
Epoch: 82/300 - Train loss: 0.30620887875556946, Validation loss: 0.298514723777771
Epoch: 83/300 - Train loss: 0.3031987249851227, Validation loss: 0.2952924370765686
Epoch: 84/300 - Train loss: 0.30026331543922424, Validation loss: 0.2930842936038971
Epoch: 85/300 - Train loss: 0.2974013388156891, Validation loss: 0.28988245129585266
Epoch: 86/300 - Train loss: 0.29461121559143066, Validation loss: 0.28753674030303955
Epoch: 87/300 - Train loss: 0.291891485452652, Validation loss: 0.2845107614994049
Epoch: 88/300 - Train loss: 0.28924092650413513, Validation loss: 0.28257399797439575
Epoch: 89/300 - Train loss: 0.28665757179260254, Validation loss: 0.27961239218711853
Epoch: 90/300 - Train loss: 0.2841401696205139, Validation loss: 0.2769835293292999
Epoch: 91/300 - Train loss: 0.28168749809265137, Validation loss: 0.2752092182636261
Epoch: 92/300 - Train loss: 0.2792978286743164, Validation loss: 0.27231624722480774
Epoch: 93/300 - Train loss: 0.2769695520401001, Validation loss: 0.2700777053833008
Epoch: 94/300 - Train loss: 0.27470123767852783, Validation loss: 0.26793035864830017
Epoch: 95/300 - Train loss: 0.2724907398223877, Validation loss: 0.26601845026016235
Epoch: 96/300 - Train loss: 0.27033674716949463, Validation loss: 0.2637280523777008
Epoch: 97/300 - Train loss: 0.268238365650177, Validation loss: 0.26150134205818176
Epoch: 98/300 - Train loss: 0.26619380712509155, Validation loss: 0.2598544955253601
Epoch: 99/300 - Train loss: 0.2642021179199219, Validation loss: 0.2577074468135834
Epoch: 100/300 - Train loss: 0.26226159930229187, Validation loss: 0.25580865144729614
Epoch: 101/300 - Train loss: 0.26037055253982544, Validation loss: 0.25452545285224915
Epoch: 102/300 - Train loss: 0.2585277259349823, Validation loss: 0.25281286239624023
Epoch: 103/300 - Train loss: 0.2567320466041565, Validation loss: 0.25105419754981995
Epoch: 104/300 - Train loss: 0.2549818456172943, Validation loss: 0.24892953038215637
Epoch: 105/300 - Train loss: 0.25327596068382263, Validation loss: 0.24742873013019562
Epoch: 106/300 - Train loss: 0.2516133487224579, Validation loss: 0.2463182955980301
Epoch: 107/300 - Train loss: 0.24999283254146576, Validation loss: 0.24434098601341248
Epoch: 108/300 - Train loss: 0.24841324985027313, Validation loss: 0.2427946776151657
Epoch: 109/300 - Train loss: 0.246873676776886, Validation loss: 0.2413139045238495
Epoch: 110/300 - Train loss: 0.2453729659318924, Validation loss: 0.2404450923204422
Epoch: 111/300 - Train loss: 0.2439098060131073, Validation loss: 0.23829816281795502
Epoch: 112/300 - Train loss: 0.24248290061950684, Validation loss: 0.23695898056030273
Epoch: 113/300 - Train loss: 0.24109141528606415, Validation loss: 0.2359614372253418
Epoch: 114/300 - Train loss: 0.23973442614078522, Validation loss: 0.23458978533744812
Epoch: 115/300 - Train loss: 0.2384110689163208, Validation loss: 0.2336926907300949
Epoch: 116/300 - Train loss: 0.2371203601360321, Validation loss: 0.2322743982076645
Epoch: 117/300 - Train loss: 0.23586133122444153, Validation loss: 0.23164372146129608
Epoch: 118/300 - Train loss: 0.2346329241991043, Validation loss: 0.22948257625102997
Epoch: 119/300 - Train loss: 0.23343414068222046, Validation loss: 0.22868770360946655
Epoch: 120/300 - Train loss: 0.23226423561573029, Validation loss: 0.22738228738307953
Epoch: 121/300 - Train loss: 0.2311224639415741, Validation loss: 0.22587193548679352
Epoch: 122/300 - Train loss: 0.23000791668891907, Validation loss: 0.22589696943759918
Epoch: 123/300 - Train loss: 0.22891980409622192, Validation loss: 0.22413308918476105
Epoch: 124/300 - Train loss: 0.2278575897216797, Validation loss: 0.22347447276115417
Epoch: 125/300 - Train loss: 0.2268204540014267, Validation loss: 0.22287285327911377
Epoch: 126/300 - Train loss: 0.22580762207508087, Validation loss: 0.220979705452919
Epoch: 127/300 - Train loss: 0.2248183786869049, Validation loss: 0.2202320545911789
Epoch: 128/300 - Train loss: 0.22385196387767792, Validation loss: 0.21949328482151031
Epoch: 129/300 - Train loss: 0.2229078710079193, Validation loss: 0.2185032069683075
Epoch: 130/300 - Train loss: 0.2219853550195694, Validation loss: 0.21755768358707428
Epoch: 131/300 - Train loss: 0.22108398377895355, Validation loss: 0.2167557179927826
Epoch: 132/300 - Train loss: 0.22020310163497925, Validation loss: 0.2162599414587021
Epoch: 133/300 - Train loss: 0.21934208273887634, Validation loss: 0.2149951010942459
Epoch: 134/300 - Train loss: 0.21850045025348663, Validation loss: 0.21437184512615204
Epoch: 135/300 - Train loss: 0.2176775336265564, Validation loss: 0.2136078029870987
Epoch: 136/300 - Train loss: 0.21687279641628265, Validation loss: 0.2130727916955948
Epoch: 137/300 - Train loss: 0.2160857766866684, Validation loss: 0.21285638213157654
Epoch: 138/300 - Train loss: 0.2153160721063614, Validation loss: 0.21221451461315155
Epoch: 139/300 - Train loss: 0.2145633101463318, Validation loss: 0.21067927777767181
Epoch: 140/300 - Train loss: 0.2138269543647766, Validation loss: 0.21029812097549438
Epoch: 141/300 - Train loss: 0.21310652792453766, Validation loss: 0.20946964621543884
Epoch: 142/300 - Train loss: 0.21240165829658508, Validation loss: 0.20898188650608063
Epoch: 143/300 - Train loss: 0.21171191334724426, Validation loss: 0.20859867334365845
Epoch: 144/300 - Train loss: 0.21103687584400177, Validation loss: 0.20759645104408264
Epoch: 145/300 - Train loss: 0.21037614345550537, Validation loss: 0.20690588653087616
Epoch: 146/300 - Train loss: 0.2097294181585312, Validation loss: 0.20644648373126984
Epoch: 147/300 - Train loss: 0.20909632742404938, Validation loss: 0.20573660731315613
Epoch: 148/300 - Train loss: 0.20847639441490173, Validation loss: 0.2055613398551941
Epoch: 149/300 - Train loss: 0.2078692764043808, Validation loss: 0.20437000691890717
Epoch: 150/300 - Train loss: 0.2072746753692627, Validation loss: 0.20401938259601593
Epoch: 151/300 - Train loss: 0.20669235289096832, Validation loss: 0.2033948451280594
Epoch: 152/300 - Train loss: 0.20612186193466187, Validation loss: 0.203453928232193
Epoch: 153/300 - Train loss: 0.20556281507015228, Validation loss: 0.20299115777015686
