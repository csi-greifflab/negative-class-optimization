Epoch: 1/300 - Train loss: 0.6924276351928711, Validation loss: 0.6890825033187866
Epoch: 2/300 - Train loss: 0.6905393004417419, Validation loss: 0.6873251795768738
Epoch: 3/300 - Train loss: 0.6886164546012878, Validation loss: 0.6853340268135071
Epoch: 4/300 - Train loss: 0.6866522431373596, Validation loss: 0.6834231615066528
Epoch: 5/300 - Train loss: 0.6846420168876648, Validation loss: 0.6816648244857788
Epoch: 6/300 - Train loss: 0.6825836896896362, Validation loss: 0.6795045137405396
Epoch: 7/300 - Train loss: 0.680467426776886, Validation loss: 0.6773028373718262
Epoch: 8/300 - Train loss: 0.6782872080802917, Validation loss: 0.6748923659324646
Epoch: 9/300 - Train loss: 0.6760367751121521, Validation loss: 0.6729481816291809
Epoch: 10/300 - Train loss: 0.6737115383148193, Validation loss: 0.6703978180885315
Epoch: 11/300 - Train loss: 0.6713099479675293, Validation loss: 0.6680734753608704
Epoch: 12/300 - Train loss: 0.6688345670700073, Validation loss: 0.6657405495643616
Epoch: 13/300 - Train loss: 0.6662850975990295, Validation loss: 0.6629688143730164
Epoch: 14/300 - Train loss: 0.6636610627174377, Validation loss: 0.6601166129112244
Epoch: 15/300 - Train loss: 0.6609663367271423, Validation loss: 0.6578977704048157
Epoch: 16/300 - Train loss: 0.6582022905349731, Validation loss: 0.6549040675163269
Epoch: 17/300 - Train loss: 0.6553716063499451, Validation loss: 0.6521561741828918
Epoch: 18/300 - Train loss: 0.6524721384048462, Validation loss: 0.6490306854248047
Epoch: 19/300 - Train loss: 0.6495065689086914, Validation loss: 0.6462516784667969
Epoch: 20/300 - Train loss: 0.6464828848838806, Validation loss: 0.6432732343673706
Epoch: 21/300 - Train loss: 0.643401026725769, Validation loss: 0.6401036977767944
Epoch: 22/300 - Train loss: 0.640263020992279, Validation loss: 0.6369998455047607
Epoch: 23/300 - Train loss: 0.6370734572410583, Validation loss: 0.6338619589805603
Epoch: 24/300 - Train loss: 0.6338374614715576, Validation loss: 0.6307762265205383
Epoch: 25/300 - Train loss: 0.6305561065673828, Validation loss: 0.6271757483482361
Epoch: 26/300 - Train loss: 0.6272345781326294, Validation loss: 0.6240777969360352
Epoch: 27/300 - Train loss: 0.6238723397254944, Validation loss: 0.6206845045089722
Epoch: 28/300 - Train loss: 0.6204706430435181, Validation loss: 0.617311418056488
Epoch: 29/300 - Train loss: 0.6170340180397034, Validation loss: 0.6139254570007324
Epoch: 30/300 - Train loss: 0.6135662198066711, Validation loss: 0.6101767420768738
Epoch: 31/300 - Train loss: 0.6100690960884094, Validation loss: 0.6064506769180298
Epoch: 32/300 - Train loss: 0.6065463423728943, Validation loss: 0.60323166847229
Epoch: 33/300 - Train loss: 0.6030030250549316, Validation loss: 0.6000469923019409
Epoch: 34/300 - Train loss: 0.5994433164596558, Validation loss: 0.5961194634437561
Epoch: 35/300 - Train loss: 0.5958730578422546, Validation loss: 0.5925561189651489
Epoch: 36/300 - Train loss: 0.5922970175743103, Validation loss: 0.5893537998199463
Epoch: 37/300 - Train loss: 0.588718056678772, Validation loss: 0.5853304862976074
Epoch: 38/300 - Train loss: 0.5851402878761292, Validation loss: 0.5821747183799744
Epoch: 39/300 - Train loss: 0.5815702676773071, Validation loss: 0.5782469511032104
Epoch: 40/300 - Train loss: 0.5780081152915955, Validation loss: 0.5746669769287109
Epoch: 41/300 - Train loss: 0.5744603872299194, Validation loss: 0.5713837742805481
Epoch: 42/300 - Train loss: 0.5709312558174133, Validation loss: 0.5681819319725037
Epoch: 43/300 - Train loss: 0.5674217939376831, Validation loss: 0.5646599531173706
Epoch: 44/300 - Train loss: 0.563936173915863, Validation loss: 0.5611955523490906
Epoch: 45/300 - Train loss: 0.5604792237281799, Validation loss: 0.5570206642150879
Epoch: 46/300 - Train loss: 0.5570523142814636, Validation loss: 0.5540867447853088
Epoch: 47/300 - Train loss: 0.5536573529243469, Validation loss: 0.5511205792427063
Epoch: 48/300 - Train loss: 0.5502973198890686, Validation loss: 0.5475003719329834
Epoch: 49/300 - Train loss: 0.5469750761985779, Validation loss: 0.5445693731307983
Epoch: 50/300 - Train loss: 0.5436931252479553, Validation loss: 0.5404978394508362
Epoch: 51/300 - Train loss: 0.5404530763626099, Validation loss: 0.5371471643447876
Epoch: 52/300 - Train loss: 0.5372578501701355, Validation loss: 0.5345109105110168
Epoch: 53/300 - Train loss: 0.5341085195541382, Validation loss: 0.5306516885757446
Epoch: 54/300 - Train loss: 0.5310056209564209, Validation loss: 0.5276336669921875
Epoch: 55/300 - Train loss: 0.5279508233070374, Validation loss: 0.5255512595176697
Epoch: 56/300 - Train loss: 0.5249451994895935, Validation loss: 0.5220029354095459
Epoch: 57/300 - Train loss: 0.521989643573761, Validation loss: 0.5196724534034729
Epoch: 58/300 - Train loss: 0.5190853476524353, Validation loss: 0.5166611075401306
Epoch: 59/300 - Train loss: 0.516231894493103, Validation loss: 0.5133224129676819
Epoch: 60/300 - Train loss: 0.5134301781654358, Validation loss: 0.5109655261039734
Epoch: 61/300 - Train loss: 0.5106794834136963, Validation loss: 0.5085963606834412
Epoch: 62/300 - Train loss: 0.5079797506332397, Validation loss: 0.5051153302192688
Epoch: 63/300 - Train loss: 0.5053316354751587, Validation loss: 0.5030800104141235
Epoch: 64/300 - Train loss: 0.5027339458465576, Validation loss: 0.5001922249794006
Epoch: 65/300 - Train loss: 0.5001861453056335, Validation loss: 0.4974791705608368
Epoch: 66/300 - Train loss: 0.4976882040500641, Validation loss: 0.4945239722728729
Epoch: 67/300 - Train loss: 0.49523913860321045, Validation loss: 0.4926268756389618
Epoch: 68/300 - Train loss: 0.49283793568611145, Validation loss: 0.49081748723983765
Epoch: 69/300 - Train loss: 0.4904838800430298, Validation loss: 0.48782259225845337
Epoch: 70/300 - Train loss: 0.48817646503448486, Validation loss: 0.4855823814868927
Epoch: 71/300 - Train loss: 0.48591548204421997, Validation loss: 0.483247309923172
Epoch: 72/300 - Train loss: 0.48369887471199036, Validation loss: 0.48246437311172485
Epoch: 73/300 - Train loss: 0.4815261662006378, Validation loss: 0.47912508249282837
Epoch: 74/300 - Train loss: 0.4793972969055176, Validation loss: 0.47750478982925415
Epoch: 75/300 - Train loss: 0.4773111343383789, Validation loss: 0.4755806624889374
Epoch: 76/300 - Train loss: 0.47526583075523376, Validation loss: 0.4728778302669525
Epoch: 77/300 - Train loss: 0.4732605218887329, Validation loss: 0.4709571301937103
Epoch: 78/300 - Train loss: 0.4712947607040405, Validation loss: 0.46911588311195374
Epoch: 79/300 - Train loss: 0.4693669378757477, Validation loss: 0.4679616093635559
Epoch: 80/300 - Train loss: 0.46747666597366333, Validation loss: 0.46507492661476135
Epoch: 81/300 - Train loss: 0.4656229615211487, Validation loss: 0.46324804425239563
Epoch: 82/300 - Train loss: 0.4638049304485321, Validation loss: 0.46088823676109314
Epoch: 83/300 - Train loss: 0.4620218873023987, Validation loss: 0.4600965976715088
Epoch: 84/300 - Train loss: 0.46027329564094543, Validation loss: 0.45795926451683044
Epoch: 85/300 - Train loss: 0.458558052778244, Validation loss: 0.45574867725372314
Epoch: 86/300 - Train loss: 0.4568750560283661, Validation loss: 0.4545634984970093
Epoch: 87/300 - Train loss: 0.45522403717041016, Validation loss: 0.4525342881679535
Epoch: 88/300 - Train loss: 0.4536043703556061, Validation loss: 0.4518633186817169
Epoch: 89/300 - Train loss: 0.4520149528980255, Validation loss: 0.4499622583389282
Epoch: 90/300 - Train loss: 0.4504549503326416, Validation loss: 0.4482084810733795
Epoch: 91/300 - Train loss: 0.44892433285713196, Validation loss: 0.4471208155155182
Epoch: 92/300 - Train loss: 0.44742274284362793, Validation loss: 0.4452134370803833
Epoch: 93/300 - Train loss: 0.4459487199783325, Validation loss: 0.44435402750968933
Epoch: 94/300 - Train loss: 0.44450148940086365, Validation loss: 0.44252723455429077
Epoch: 95/300 - Train loss: 0.443080872297287, Validation loss: 0.4409444034099579
Epoch: 96/300 - Train loss: 0.4416864514350891, Validation loss: 0.44016459584236145
Epoch: 97/300 - Train loss: 0.44031766057014465, Validation loss: 0.4375137686729431
Epoch: 98/300 - Train loss: 0.4389735162258148, Validation loss: 0.43658509850502014
Epoch: 99/300 - Train loss: 0.4376540780067444, Validation loss: 0.4357980191707611
Epoch: 100/300 - Train loss: 0.43635818362236023, Validation loss: 0.43534666299819946
Epoch: 101/300 - Train loss: 0.43508481979370117, Validation loss: 0.4325936734676361
Epoch: 102/300 - Train loss: 0.43383336067199707, Validation loss: 0.4310894012451172
Epoch: 103/300 - Train loss: 0.43260326981544495, Validation loss: 0.43100211024284363
Epoch: 104/300 - Train loss: 0.4313938319683075, Validation loss: 0.4289359748363495
Epoch: 105/300 - Train loss: 0.4302046597003937, Validation loss: 0.4286764860153198
Epoch: 106/300 - Train loss: 0.42903605103492737, Validation loss: 0.4266705811023712
Epoch: 107/300 - Train loss: 0.4278869330883026, Validation loss: 0.4258970022201538
Epoch: 108/300 - Train loss: 0.42675724625587463, Validation loss: 0.42533352971076965
Epoch: 109/300 - Train loss: 0.4256467819213867, Validation loss: 0.42494919896125793
Epoch: 110/300 - Train loss: 0.4245554208755493, Validation loss: 0.4220898151397705
Epoch: 111/300 - Train loss: 0.4234825372695923, Validation loss: 0.4216997027397156
Epoch: 112/300 - Train loss: 0.42242738604545593, Validation loss: 0.4205724596977234
Epoch: 113/300 - Train loss: 0.42138972878456116, Validation loss: 0.4199528098106384
Epoch: 114/300 - Train loss: 0.4203689694404602, Validation loss: 0.4187212884426117
Epoch: 115/300 - Train loss: 0.41936466097831726, Validation loss: 0.41765883564949036
Epoch: 116/300 - Train loss: 0.4183766841888428, Validation loss: 0.4167301058769226
Epoch: 117/300 - Train loss: 0.41740450263023376, Validation loss: 0.4155721366405487
Epoch: 118/300 - Train loss: 0.41644778847694397, Validation loss: 0.4142194092273712
Epoch: 119/300 - Train loss: 0.41550591588020325, Validation loss: 0.4137582778930664
Epoch: 120/300 - Train loss: 0.4145788848400116, Validation loss: 0.4125080704689026
Epoch: 121/300 - Train loss: 0.41366639733314514, Validation loss: 0.4117206037044525
Epoch: 122/300 - Train loss: 0.41276833415031433, Validation loss: 0.41146713495254517
Epoch: 123/300 - Train loss: 0.4118843078613281, Validation loss: 0.41044923663139343
Epoch: 124/300 - Train loss: 0.4110144078731537, Validation loss: 0.4081800878047943
Epoch: 125/300 - Train loss: 0.4101581871509552, Validation loss: 0.4076993763446808
Epoch: 126/300 - Train loss: 0.4093153178691864, Validation loss: 0.40695518255233765
Epoch: 127/300 - Train loss: 0.40848568081855774, Validation loss: 0.40780988335609436
Epoch: 128/300 - Train loss: 0.4076683521270752, Validation loss: 0.4057943820953369
Epoch: 129/300 - Train loss: 0.40686342120170593, Validation loss: 0.4044104218482971
Epoch: 130/300 - Train loss: 0.4060702621936798, Validation loss: 0.4066222310066223
Epoch: 131/300 - Train loss: 0.4052887260913849, Validation loss: 0.40414997935295105
Epoch: 132/300 - Train loss: 0.4045189321041107, Validation loss: 0.4026806652545929
Epoch: 133/300 - Train loss: 0.4037605822086334, Validation loss: 0.40225455164909363
Epoch: 134/300 - Train loss: 0.403013676404953, Validation loss: 0.4019288122653961
Epoch: 135/300 - Train loss: 0.40227749943733215, Validation loss: 0.3997003734111786
Epoch: 136/300 - Train loss: 0.40155237913131714, Validation loss: 0.39918041229248047
Epoch: 137/300 - Train loss: 0.40083786845207214, Validation loss: 0.3995561897754669
Epoch: 138/300 - Train loss: 0.40013378858566284, Validation loss: 0.3985224962234497
Epoch: 139/300 - Train loss: 0.3994394838809967, Validation loss: 0.398388534784317
Epoch: 140/300 - Train loss: 0.3987540900707245, Validation loss: 0.39675766229629517
Epoch: 141/300 - Train loss: 0.39807793498039246, Validation loss: 0.39648160338401794
Epoch: 142/300 - Train loss: 0.3974107503890991, Validation loss: 0.39511775970458984
Epoch: 143/300 - Train loss: 0.39675265550613403, Validation loss: 0.39564740657806396
Epoch: 144/300 - Train loss: 0.39610350131988525, Validation loss: 0.3947814106941223
