Epoch: 1/200 - Train loss: 0.6868121027946472, Validation loss: 0.6783808469772339
Epoch: 2/200 - Train loss: 0.6658951640129089, Validation loss: 0.6530959606170654
Epoch: 3/200 - Train loss: 0.6352311372756958, Validation loss: 0.6200113296508789
Epoch: 4/200 - Train loss: 0.6030277609825134, Validation loss: 0.5920928120613098
Epoch: 5/200 - Train loss: 0.5769526362419128, Validation loss: 0.570336103439331
Epoch: 6/200 - Train loss: 0.5570029616355896, Validation loss: 0.5537111759185791
Epoch: 7/200 - Train loss: 0.541703462600708, Validation loss: 0.5413274765014648
Epoch: 8/200 - Train loss: 0.5301750302314758, Validation loss: 0.5324996709823608
Epoch: 9/200 - Train loss: 0.521367609500885, Validation loss: 0.5241506695747375
Epoch: 10/200 - Train loss: 0.5141181945800781, Validation loss: 0.5188729763031006
Epoch: 11/200 - Train loss: 0.508724570274353, Validation loss: 0.5137859582901001
Epoch: 12/200 - Train loss: 0.5032495260238647, Validation loss: 0.5091462135314941
Epoch: 13/200 - Train loss: 0.4992196261882782, Validation loss: 0.5054313540458679
Epoch: 14/200 - Train loss: 0.4949445128440857, Validation loss: 0.5018954277038574
Epoch: 15/200 - Train loss: 0.49172234535217285, Validation loss: 0.49816668033599854
Epoch: 16/200 - Train loss: 0.4880646765232086, Validation loss: 0.49568474292755127
Epoch: 17/200 - Train loss: 0.48484086990356445, Validation loss: 0.49220210313796997
Epoch: 18/200 - Train loss: 0.48216724395751953, Validation loss: 0.4893929958343506
Epoch: 19/200 - Train loss: 0.47930487990379333, Validation loss: 0.48779749870300293
Epoch: 20/200 - Train loss: 0.47653308510780334, Validation loss: 0.48438164591789246
Epoch: 21/200 - Train loss: 0.4739803671836853, Validation loss: 0.4815126955509186
Epoch: 22/200 - Train loss: 0.47180208563804626, Validation loss: 0.4794568717479706
Epoch: 23/200 - Train loss: 0.4690795838832855, Validation loss: 0.4774283766746521
Epoch: 24/200 - Train loss: 0.4669633209705353, Validation loss: 0.47533243894577026
Epoch: 25/200 - Train loss: 0.46454617381095886, Validation loss: 0.47273388504981995
Epoch: 26/200 - Train loss: 0.46246960759162903, Validation loss: 0.47109776735305786
Epoch: 27/200 - Train loss: 0.4599202573299408, Validation loss: 0.4696429669857025
Epoch: 28/200 - Train loss: 0.4578217566013336, Validation loss: 0.4675911068916321
Epoch: 29/200 - Train loss: 0.4559759497642517, Validation loss: 0.4649257957935333
Epoch: 30/200 - Train loss: 0.45349952578544617, Validation loss: 0.4631843566894531
Epoch: 31/200 - Train loss: 0.4515467882156372, Validation loss: 0.46142488718032837
Epoch: 32/200 - Train loss: 0.44940924644470215, Validation loss: 0.45975664258003235
Epoch: 33/200 - Train loss: 0.44766533374786377, Validation loss: 0.45826274156570435
Epoch: 34/200 - Train loss: 0.4458128809928894, Validation loss: 0.4557570219039917
Epoch: 35/200 - Train loss: 0.4440404772758484, Validation loss: 0.4538799226284027
Epoch: 36/200 - Train loss: 0.4417067766189575, Validation loss: 0.45267581939697266
Epoch: 37/200 - Train loss: 0.44002124667167664, Validation loss: 0.4513325095176697
Epoch: 38/200 - Train loss: 0.4380549490451813, Validation loss: 0.4483368396759033
Epoch: 39/200 - Train loss: 0.43628549575805664, Validation loss: 0.4468696713447571
Epoch: 40/200 - Train loss: 0.4342561364173889, Validation loss: 0.44577425718307495
Epoch: 41/200 - Train loss: 0.432038277387619, Validation loss: 0.44330301880836487
Epoch: 42/200 - Train loss: 0.43027254939079285, Validation loss: 0.4410463273525238
Epoch: 43/200 - Train loss: 0.4281819760799408, Validation loss: 0.4402827322483063
Epoch: 44/200 - Train loss: 0.4262522757053375, Validation loss: 0.4378754794597626
Epoch: 45/200 - Train loss: 0.42484015226364136, Validation loss: 0.4365732967853546
Epoch: 46/200 - Train loss: 0.4228757321834564, Validation loss: 0.43474602699279785
Epoch: 47/200 - Train loss: 0.42037898302078247, Validation loss: 0.4331555664539337
Epoch: 48/200 - Train loss: 0.41867929697036743, Validation loss: 0.43244075775146484
Epoch: 49/200 - Train loss: 0.4166964888572693, Validation loss: 0.4299755394458771
Epoch: 50/200 - Train loss: 0.4145370423793793, Validation loss: 0.42861971259117126
Epoch: 51/200 - Train loss: 0.4127544164657593, Validation loss: 0.4266946315765381
Epoch: 52/200 - Train loss: 0.4108814001083374, Validation loss: 0.4248018264770508
Epoch: 53/200 - Train loss: 0.4086921811103821, Validation loss: 0.42325612902641296
Epoch: 54/200 - Train loss: 0.40694481134414673, Validation loss: 0.4214724898338318
Epoch: 55/200 - Train loss: 0.4044334888458252, Validation loss: 0.419897198677063
Epoch: 56/200 - Train loss: 0.40343406796455383, Validation loss: 0.41795530915260315
Epoch: 57/200 - Train loss: 0.40093496441841125, Validation loss: 0.41575416922569275
Epoch: 58/200 - Train loss: 0.3995126783847809, Validation loss: 0.4156949520111084
Epoch: 59/200 - Train loss: 0.39731279015541077, Validation loss: 0.41298648715019226
Epoch: 60/200 - Train loss: 0.3954242467880249, Validation loss: 0.41131824254989624
Epoch: 61/200 - Train loss: 0.3936651945114136, Validation loss: 0.4093509316444397
Epoch: 62/200 - Train loss: 0.3916558027267456, Validation loss: 0.40850502252578735
Epoch: 63/200 - Train loss: 0.38954511284828186, Validation loss: 0.40633371472358704
Epoch: 64/200 - Train loss: 0.38726189732551575, Validation loss: 0.4047156572341919
Epoch: 65/200 - Train loss: 0.38582563400268555, Validation loss: 0.4021683633327484
Epoch: 66/200 - Train loss: 0.38377854228019714, Validation loss: 0.4010489583015442
Epoch: 67/200 - Train loss: 0.3816971182823181, Validation loss: 0.3998403251171112
Epoch: 68/200 - Train loss: 0.3797597289085388, Validation loss: 0.39791467785835266
Epoch: 69/200 - Train loss: 0.3778020441532135, Validation loss: 0.39651668071746826
Epoch: 70/200 - Train loss: 0.37598660588264465, Validation loss: 0.3941814601421356
Epoch: 71/200 - Train loss: 0.37460455298423767, Validation loss: 0.39346179366111755
Epoch: 72/200 - Train loss: 0.3721066415309906, Validation loss: 0.39103102684020996
Epoch: 73/200 - Train loss: 0.3699936866760254, Validation loss: 0.3898523449897766
Epoch: 74/200 - Train loss: 0.36835095286369324, Validation loss: 0.38748034834861755
Epoch: 75/200 - Train loss: 0.3662325143814087, Validation loss: 0.38616427779197693
Epoch: 76/200 - Train loss: 0.3642798662185669, Validation loss: 0.38430458307266235
Epoch: 77/200 - Train loss: 0.36287668347358704, Validation loss: 0.3825169503688812
Epoch: 78/200 - Train loss: 0.3606630563735962, Validation loss: 0.38171663880348206
Epoch: 79/200 - Train loss: 0.35897311568260193, Validation loss: 0.3796111047267914
Epoch: 80/200 - Train loss: 0.3573404848575592, Validation loss: 0.378206342458725
Epoch: 81/200 - Train loss: 0.3554084300994873, Validation loss: 0.37665805220603943
Epoch: 82/200 - Train loss: 0.3535715639591217, Validation loss: 0.3757866621017456
Epoch: 83/200 - Train loss: 0.35171425342559814, Validation loss: 0.37324070930480957
Epoch: 84/200 - Train loss: 0.349785715341568, Validation loss: 0.3722168505191803
Epoch: 85/200 - Train loss: 0.3479497730731964, Validation loss: 0.36980006098747253
Epoch: 86/200 - Train loss: 0.3463611900806427, Validation loss: 0.3689877688884735
Epoch: 87/200 - Train loss: 0.3446841835975647, Validation loss: 0.36732277274131775
Epoch: 88/200 - Train loss: 0.34301814436912537, Validation loss: 0.3656618297100067
Epoch: 89/200 - Train loss: 0.34114474058151245, Validation loss: 0.3643438518047333
Epoch: 90/200 - Train loss: 0.33914288878440857, Validation loss: 0.3620893359184265
Epoch: 91/200 - Train loss: 0.33765679597854614, Validation loss: 0.36094391345977783
Epoch: 92/200 - Train loss: 0.3362200856208801, Validation loss: 0.3602539300918579
Epoch: 93/200 - Train loss: 0.33430978655815125, Validation loss: 0.35838860273361206
Epoch: 94/200 - Train loss: 0.332442969083786, Validation loss: 0.3560863435268402
Epoch: 95/200 - Train loss: 0.33090639114379883, Validation loss: 0.35524982213974
Epoch: 96/200 - Train loss: 0.3293236792087555, Validation loss: 0.35404443740844727
Epoch: 97/200 - Train loss: 0.3278558850288391, Validation loss: 0.35201704502105713
Epoch: 98/200 - Train loss: 0.3262065052986145, Validation loss: 0.3509576916694641
Epoch: 99/200 - Train loss: 0.32524988055229187, Validation loss: 0.3495429754257202
Epoch: 100/200 - Train loss: 0.3232647776603699, Validation loss: 0.3477185070514679
Epoch: 101/200 - Train loss: 0.32156163454055786, Validation loss: 0.34662315249443054
Epoch: 102/200 - Train loss: 0.32008683681488037, Validation loss: 0.3460444211959839
Epoch: 103/200 - Train loss: 0.3187524080276489, Validation loss: 0.3445199429988861
Epoch: 104/200 - Train loss: 0.3169059455394745, Validation loss: 0.3432256281375885
Epoch: 105/200 - Train loss: 0.3157063126564026, Validation loss: 0.3419559597969055
Epoch: 106/200 - Train loss: 0.3144243359565735, Validation loss: 0.34064996242523193
Epoch: 107/200 - Train loss: 0.31281778216362, Validation loss: 0.3386673927307129
Epoch: 108/200 - Train loss: 0.310967355966568, Validation loss: 0.33776649832725525
Epoch: 109/200 - Train loss: 0.3094482719898224, Validation loss: 0.33737310767173767
Epoch: 110/200 - Train loss: 0.308512806892395, Validation loss: 0.33576545119285583
Epoch: 111/200 - Train loss: 0.30747082829475403, Validation loss: 0.33483457565307617
Epoch: 112/200 - Train loss: 0.3054603040218353, Validation loss: 0.3340131938457489
Epoch: 113/200 - Train loss: 0.304280161857605, Validation loss: 0.3325182795524597
Epoch: 114/200 - Train loss: 0.3027498722076416, Validation loss: 0.33147740364074707
Epoch: 115/200 - Train loss: 0.30117857456207275, Validation loss: 0.33014482259750366
Epoch: 116/200 - Train loss: 0.30009615421295166, Validation loss: 0.32897090911865234
Epoch: 117/200 - Train loss: 0.2988032102584839, Validation loss: 0.32798975706100464
Epoch: 118/200 - Train loss: 0.29780566692352295, Validation loss: 0.32661953568458557
Epoch: 119/200 - Train loss: 0.2959843873977661, Validation loss: 0.3255078196525574
Epoch: 120/200 - Train loss: 0.29509487748146057, Validation loss: 0.32492777705192566
Epoch: 121/200 - Train loss: 0.2939299941062927, Validation loss: 0.3242657780647278
Epoch: 122/200 - Train loss: 0.2928740978240967, Validation loss: 0.3232223093509674
Epoch: 123/200 - Train loss: 0.29132509231567383, Validation loss: 0.32220953702926636
Epoch: 124/200 - Train loss: 0.2899809181690216, Validation loss: 0.32077381014823914
Epoch: 125/200 - Train loss: 0.28915122151374817, Validation loss: 0.319973349571228
Epoch: 126/200 - Train loss: 0.28781720995903015, Validation loss: 0.31936749815940857
Epoch: 127/200 - Train loss: 0.28663575649261475, Validation loss: 0.317910760641098
Epoch: 128/200 - Train loss: 0.2856234610080719, Validation loss: 0.3172897696495056
Epoch: 129/200 - Train loss: 0.28424614667892456, Validation loss: 0.3172707259654999
Epoch: 130/200 - Train loss: 0.2834082245826721, Validation loss: 0.3156307637691498
Epoch: 131/200 - Train loss: 0.28197652101516724, Validation loss: 0.31475088000297546
Epoch: 132/200 - Train loss: 0.28083983063697815, Validation loss: 0.31383439898490906
Epoch: 133/200 - Train loss: 0.2798977792263031, Validation loss: 0.31257206201553345
Epoch: 134/200 - Train loss: 0.27872025966644287, Validation loss: 0.3122989535331726
Epoch: 135/200 - Train loss: 0.27800068259239197, Validation loss: 0.31198740005493164
Epoch: 136/200 - Train loss: 0.27651548385620117, Validation loss: 0.3098684251308441
Epoch: 137/200 - Train loss: 0.2753763794898987, Validation loss: 0.30944985151290894
Epoch: 138/200 - Train loss: 0.2749931812286377, Validation loss: 0.3091290593147278
Epoch: 139/200 - Train loss: 0.2736875116825104, Validation loss: 0.3076939582824707
Epoch: 140/200 - Train loss: 0.27267366647720337, Validation loss: 0.30686214566230774
Epoch: 141/200 - Train loss: 0.27183595299720764, Validation loss: 0.3069698214530945
Epoch: 142/200 - Train loss: 0.27059394121170044, Validation loss: 0.3061196208000183
Epoch: 143/200 - Train loss: 0.26980629563331604, Validation loss: 0.3054516017436981
Epoch: 144/200 - Train loss: 0.269036203622818, Validation loss: 0.3060416877269745
Epoch: 145/200 - Train loss: 0.26789799332618713, Validation loss: 0.30469000339508057
Epoch: 146/200 - Train loss: 0.2668989598751068, Validation loss: 0.30362069606781006
Epoch: 147/200 - Train loss: 0.2663623094558716, Validation loss: 0.30251821875572205
Epoch: 148/200 - Train loss: 0.2652320861816406, Validation loss: 0.3020922839641571
Epoch: 149/200 - Train loss: 0.26457563042640686, Validation loss: 0.3020881712436676
