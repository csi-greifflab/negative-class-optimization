Epoch: 1/100 - Train loss: 0.6964268684387207, Validation loss: 0.6952506899833679
Epoch: 2/100 - Train loss: 0.6938036680221558, Validation loss: 0.6926964521408081
Epoch: 3/100 - Train loss: 0.6910732388496399, Validation loss: 0.6899122595787048
Epoch: 4/100 - Train loss: 0.6882139444351196, Validation loss: 0.6869806051254272
Epoch: 5/100 - Train loss: 0.6852070093154907, Validation loss: 0.6837815642356873
Epoch: 6/100 - Train loss: 0.682036280632019, Validation loss: 0.6805316805839539
Epoch: 7/100 - Train loss: 0.6786998510360718, Validation loss: 0.6771172285079956
Epoch: 8/100 - Train loss: 0.6752021908760071, Validation loss: 0.6735286712646484
Epoch: 9/100 - Train loss: 0.6715431213378906, Validation loss: 0.6696669459342957
Epoch: 10/100 - Train loss: 0.6677277684211731, Validation loss: 0.6659227609634399
Epoch: 11/100 - Train loss: 0.6637597680091858, Validation loss: 0.6618707776069641
Epoch: 12/100 - Train loss: 0.6596534252166748, Validation loss: 0.6576860547065735
Epoch: 13/100 - Train loss: 0.655421793460846, Validation loss: 0.6532575488090515
Epoch: 14/100 - Train loss: 0.6510741710662842, Validation loss: 0.6490135192871094
Epoch: 15/100 - Train loss: 0.6466304659843445, Validation loss: 0.6445465683937073
Epoch: 16/100 - Train loss: 0.6421027183532715, Validation loss: 0.6399189829826355
Epoch: 17/100 - Train loss: 0.6375028491020203, Validation loss: 0.6354499459266663
Epoch: 18/100 - Train loss: 0.6328475475311279, Validation loss: 0.6306775212287903
Epoch: 19/100 - Train loss: 0.6281526684761047, Validation loss: 0.6260417699813843
Epoch: 20/100 - Train loss: 0.6234303712844849, Validation loss: 0.621515691280365
Epoch: 21/100 - Train loss: 0.618691086769104, Validation loss: 0.6167978644371033
Epoch: 22/100 - Train loss: 0.6139442920684814, Validation loss: 0.6120038032531738
Epoch: 23/100 - Train loss: 0.6091947555541992, Validation loss: 0.6074328422546387
Epoch: 24/100 - Train loss: 0.6044490337371826, Validation loss: 0.6027621030807495
Epoch: 25/100 - Train loss: 0.599709689617157, Validation loss: 0.59831303358078
Epoch: 26/100 - Train loss: 0.5949796438217163, Validation loss: 0.5935752391815186
Epoch: 27/100 - Train loss: 0.5902617573738098, Validation loss: 0.5888357162475586
Epoch: 28/100 - Train loss: 0.5855578780174255, Validation loss: 0.5842493772506714
Epoch: 29/100 - Train loss: 0.5808709263801575, Validation loss: 0.5793724656105042
Epoch: 30/100 - Train loss: 0.5762036442756653, Validation loss: 0.5749852061271667
Epoch: 31/100 - Train loss: 0.5715582966804504, Validation loss: 0.5701436996459961
Epoch: 32/100 - Train loss: 0.5669375658035278, Validation loss: 0.5658057332038879
Epoch: 33/100 - Train loss: 0.5623447895050049, Validation loss: 0.5614511966705322
Epoch: 34/100 - Train loss: 0.5577839016914368, Validation loss: 0.5564903020858765
Epoch: 35/100 - Train loss: 0.553257167339325, Validation loss: 0.5517804622650146
Epoch: 36/100 - Train loss: 0.5487679243087769, Validation loss: 0.5478152632713318
Epoch: 37/100 - Train loss: 0.5443198084831238, Validation loss: 0.5431894659996033
Epoch: 38/100 - Train loss: 0.539914608001709, Validation loss: 0.5390108227729797
Epoch: 39/100 - Train loss: 0.535554826259613, Validation loss: 0.5344843864440918
Epoch: 40/100 - Train loss: 0.531243085861206, Validation loss: 0.5303346514701843
Epoch: 41/100 - Train loss: 0.5269808173179626, Validation loss: 0.5263320803642273
Epoch: 42/100 - Train loss: 0.5227702260017395, Validation loss: 0.5219427347183228
Epoch: 43/100 - Train loss: 0.5186140537261963, Validation loss: 0.5177302360534668
Epoch: 44/100 - Train loss: 0.5145135521888733, Validation loss: 0.5139201879501343
Epoch: 45/100 - Train loss: 0.5104702711105347, Validation loss: 0.5096487402915955
Epoch: 46/100 - Train loss: 0.5064854621887207, Validation loss: 0.5057418346405029
Epoch: 47/100 - Train loss: 0.502560019493103, Validation loss: 0.5021831393241882
Epoch: 48/100 - Train loss: 0.4986950755119324, Validation loss: 0.49802547693252563
Epoch: 49/100 - Train loss: 0.4948922097682953, Validation loss: 0.49403706192970276
Epoch: 50/100 - Train loss: 0.49115243554115295, Validation loss: 0.4903339445590973
Epoch: 51/100 - Train loss: 0.4874761700630188, Validation loss: 0.48694831132888794
Epoch: 52/100 - Train loss: 0.4838640093803406, Validation loss: 0.4831477105617523
Epoch: 53/100 - Train loss: 0.48031628131866455, Validation loss: 0.47981172800064087
Epoch: 54/100 - Train loss: 0.47683343291282654, Validation loss: 0.476280152797699
Epoch: 55/100 - Train loss: 0.47341588139533997, Validation loss: 0.47302964329719543
Epoch: 56/100 - Train loss: 0.470063716173172, Validation loss: 0.4693308174610138
Epoch: 57/100 - Train loss: 0.4667770266532898, Validation loss: 0.46633395552635193
Epoch: 58/100 - Train loss: 0.4635555148124695, Validation loss: 0.46300044655799866
Epoch: 59/100 - Train loss: 0.46039924025535583, Validation loss: 0.46016189455986023
Epoch: 60/100 - Train loss: 0.4573083221912384, Validation loss: 0.4570454955101013
Epoch: 61/100 - Train loss: 0.4542820155620575, Validation loss: 0.4540272057056427
Epoch: 62/100 - Train loss: 0.45132049918174744, Validation loss: 0.4512330889701843
Epoch: 63/100 - Train loss: 0.44842401146888733, Validation loss: 0.4482542872428894
Epoch: 64/100 - Train loss: 0.44559234380722046, Validation loss: 0.4456157684326172
Epoch: 65/100 - Train loss: 0.4428243339061737, Validation loss: 0.44214263558387756
Epoch: 66/100 - Train loss: 0.4401192367076874, Validation loss: 0.43971148133277893
Epoch: 67/100 - Train loss: 0.43747636675834656, Validation loss: 0.4371660351753235
Epoch: 68/100 - Train loss: 0.4348944425582886, Validation loss: 0.43416348099708557
Epoch: 69/100 - Train loss: 0.43237316608428955, Validation loss: 0.4321668744087219
Epoch: 70/100 - Train loss: 0.4299120008945465, Validation loss: 0.4298768937587738
Epoch: 71/100 - Train loss: 0.42750999331474304, Validation loss: 0.4268745183944702
Epoch: 72/100 - Train loss: 0.42516615986824036, Validation loss: 0.42402219772338867
Epoch: 73/100 - Train loss: 0.42287924885749817, Validation loss: 0.422085702419281
Epoch: 74/100 - Train loss: 0.4206479787826538, Validation loss: 0.42005404829978943
Epoch: 75/100 - Train loss: 0.41847237944602966, Validation loss: 0.4182114005088806
Epoch: 76/100 - Train loss: 0.4163512885570526, Validation loss: 0.41553181409835815
Epoch: 77/100 - Train loss: 0.41428178548812866, Validation loss: 0.4146094024181366
Epoch: 78/100 - Train loss: 0.412263423204422, Validation loss: 0.41163766384124756
Epoch: 79/100 - Train loss: 0.41029536724090576, Validation loss: 0.40997782349586487
Epoch: 80/100 - Train loss: 0.4083757698535919, Validation loss: 0.407632052898407
Epoch: 81/100 - Train loss: 0.40650296211242676, Validation loss: 0.40568408370018005
Epoch: 82/100 - Train loss: 0.4046763777732849, Validation loss: 0.40407365560531616
Epoch: 83/100 - Train loss: 0.40289413928985596, Validation loss: 0.4023423492908478
Epoch: 84/100 - Train loss: 0.40115469694137573, Validation loss: 0.39971596002578735
Epoch: 85/100 - Train loss: 0.39945682883262634, Validation loss: 0.3987486660480499
Epoch: 86/100 - Train loss: 0.39779943227767944, Validation loss: 0.39699357748031616
Epoch: 87/100 - Train loss: 0.3961813151836395, Validation loss: 0.3955773115158081
Epoch: 88/100 - Train loss: 0.3946012258529663, Validation loss: 0.3937554657459259
Epoch: 89/100 - Train loss: 0.3930577337741852, Validation loss: 0.3922518789768219
Epoch: 90/100 - Train loss: 0.3915500342845917, Validation loss: 0.3907882571220398
Epoch: 91/100 - Train loss: 0.39007577300071716, Validation loss: 0.389175146818161
Epoch: 92/100 - Train loss: 0.38863450288772583, Validation loss: 0.3879183828830719
Epoch: 93/100 - Train loss: 0.3872251808643341, Validation loss: 0.3858913481235504
Epoch: 94/100 - Train loss: 0.3858473300933838, Validation loss: 0.38488447666168213
Epoch: 95/100 - Train loss: 0.38450029492378235, Validation loss: 0.38321563601493835
Epoch: 96/100 - Train loss: 0.38318267464637756, Validation loss: 0.3824068307876587
Epoch: 97/100 - Train loss: 0.38189348578453064, Validation loss: 0.3808046281337738
Epoch: 98/100 - Train loss: 0.3806306719779968, Validation loss: 0.3791646957397461
Epoch: 99/100 - Train loss: 0.3793943226337433, Validation loss: 0.37864163517951965
Epoch: 100/100 - Train loss: 0.37818339467048645, Validation loss: 0.3769051432609558
Epoch: 1/300 - Train loss: 0.6977602243423462, Validation loss: 0.6963735818862915
Epoch: 2/300 - Train loss: 0.694530189037323, Validation loss: 0.6932398080825806
Epoch: 3/300 - Train loss: 0.6913318634033203, Validation loss: 0.6900814175605774
Epoch: 4/300 - Train loss: 0.6881080865859985, Validation loss: 0.6868296265602112
Epoch: 5/300 - Train loss: 0.684813380241394, Validation loss: 0.6834936141967773
Epoch: 6/300 - Train loss: 0.6814075708389282, Validation loss: 0.6800585389137268
Epoch: 7/300 - Train loss: 0.677858829498291, Validation loss: 0.6764077544212341
Epoch: 8/300 - Train loss: 0.674151599407196, Validation loss: 0.6725754141807556
Epoch: 9/300 - Train loss: 0.670274555683136, Validation loss: 0.6686283349990845
Epoch: 10/300 - Train loss: 0.6662280559539795, Validation loss: 0.6643977761268616
Epoch: 11/300 - Train loss: 0.6620310544967651, Validation loss: 0.6603474617004395
Epoch: 12/300 - Train loss: 0.657700777053833, Validation loss: 0.6558085680007935
Epoch: 13/300 - Train loss: 0.6532485485076904, Validation loss: 0.6514127850532532
Epoch: 14/300 - Train loss: 0.6487008929252625, Validation loss: 0.6468360424041748
Epoch: 15/300 - Train loss: 0.6440796256065369, Validation loss: 0.6424103379249573
Epoch: 16/300 - Train loss: 0.6394076943397522, Validation loss: 0.6376264691352844
Epoch: 17/300 - Train loss: 0.6347118020057678, Validation loss: 0.6330661773681641
Epoch: 18/300 - Train loss: 0.6300061345100403, Validation loss: 0.6283624768257141
Epoch: 19/300 - Train loss: 0.6253021359443665, Validation loss: 0.6237542033195496
Epoch: 20/300 - Train loss: 0.6206094622612, Validation loss: 0.6192300915718079
Epoch: 21/300 - Train loss: 0.6159318685531616, Validation loss: 0.6147739291191101
Epoch: 22/300 - Train loss: 0.6112767457962036, Validation loss: 0.6099830269813538
Epoch: 23/300 - Train loss: 0.6066463589668274, Validation loss: 0.6054401397705078
Epoch: 24/300 - Train loss: 0.6020409464836121, Validation loss: 0.6007375717163086
Epoch: 25/300 - Train loss: 0.5974618196487427, Validation loss: 0.596510648727417
Epoch: 26/300 - Train loss: 0.5929116010665894, Validation loss: 0.5920327305793762
Epoch: 27/300 - Train loss: 0.5883867740631104, Validation loss: 0.5873104929924011
Epoch: 28/300 - Train loss: 0.583886981010437, Validation loss: 0.5833426117897034
Epoch: 29/300 - Train loss: 0.5794118046760559, Validation loss: 0.5787630677223206
Epoch: 30/300 - Train loss: 0.5749622583389282, Validation loss: 0.5744758248329163
Epoch: 31/300 - Train loss: 0.5705419182777405, Validation loss: 0.5699925422668457
Epoch: 32/300 - Train loss: 0.5661526322364807, Validation loss: 0.5653964281082153
Epoch: 33/300 - Train loss: 0.5617966651916504, Validation loss: 0.5612930059432983
Epoch: 34/300 - Train loss: 0.5574764609336853, Validation loss: 0.5569221377372742
Epoch: 35/300 - Train loss: 0.5531951785087585, Validation loss: 0.5527050495147705
Epoch: 36/300 - Train loss: 0.5489553213119507, Validation loss: 0.548823356628418
Epoch: 37/300 - Train loss: 0.544758141040802, Validation loss: 0.5444173216819763
Epoch: 38/300 - Train loss: 0.540605366230011, Validation loss: 0.5402638912200928
Epoch: 39/300 - Train loss: 0.5364985466003418, Validation loss: 0.5362656116485596
Epoch: 40/300 - Train loss: 0.5324389934539795, Validation loss: 0.5322442054748535
Epoch: 41/300 - Train loss: 0.5284277200698853, Validation loss: 0.5280995965003967
Epoch: 42/300 - Train loss: 0.5244660377502441, Validation loss: 0.5239670872688293
Epoch: 43/300 - Train loss: 0.5205550193786621, Validation loss: 0.5199505090713501
Epoch: 44/300 - Train loss: 0.5166946649551392, Validation loss: 0.5163237452507019
Epoch: 45/300 - Train loss: 0.5128861665725708, Validation loss: 0.5128061771392822
Epoch: 46/300 - Train loss: 0.5091302990913391, Validation loss: 0.5091050863265991
Epoch: 47/300 - Train loss: 0.5054274797439575, Validation loss: 0.50498366355896
Epoch: 48/300 - Train loss: 0.501777708530426, Validation loss: 0.5019600987434387
Epoch: 49/300 - Train loss: 0.49818113446235657, Validation loss: 0.49798494577407837
Epoch: 50/300 - Train loss: 0.49463823437690735, Validation loss: 0.4940919876098633
Epoch: 51/300 - Train loss: 0.49114957451820374, Validation loss: 0.4909488260746002
Epoch: 52/300 - Train loss: 0.48771587014198303, Validation loss: 0.48721611499786377
Epoch: 53/300 - Train loss: 0.48433762788772583, Validation loss: 0.4839082360267639
Epoch: 54/300 - Train loss: 0.4810154139995575, Validation loss: 0.4811796247959137
Epoch: 55/300 - Train loss: 0.4777492880821228, Validation loss: 0.4772516191005707
Epoch: 56/300 - Train loss: 0.4745388925075531, Validation loss: 0.4739247262477875
Epoch: 57/300 - Train loss: 0.471384197473526, Validation loss: 0.4710816740989685
Epoch: 58/300 - Train loss: 0.46828481554985046, Validation loss: 0.46773242950439453
Epoch: 59/300 - Train loss: 0.4652407467365265, Validation loss: 0.4649351239204407
Epoch: 60/300 - Train loss: 0.46225202083587646, Validation loss: 0.461768239736557
Epoch: 61/300 - Train loss: 0.4593183994293213, Validation loss: 0.45910078287124634
Epoch: 62/300 - Train loss: 0.4564405381679535, Validation loss: 0.45618486404418945
Epoch: 63/300 - Train loss: 0.453617662191391, Validation loss: 0.4531104266643524
Epoch: 64/300 - Train loss: 0.45084908604621887, Validation loss: 0.4507562816143036
Epoch: 65/300 - Train loss: 0.44813406467437744, Validation loss: 0.44748932123184204
Epoch: 66/300 - Train loss: 0.4454716742038727, Validation loss: 0.44539663195610046
Epoch: 67/300 - Train loss: 0.44286227226257324, Validation loss: 0.44296708703041077
Epoch: 68/300 - Train loss: 0.4403051733970642, Validation loss: 0.4403325915336609
Epoch: 69/300 - Train loss: 0.4377997815608978, Validation loss: 0.43738922476768494
Epoch: 70/300 - Train loss: 0.4353451430797577, Validation loss: 0.4352557361125946
Epoch: 71/300 - Train loss: 0.4329409599304199, Validation loss: 0.4326937198638916
Epoch: 72/300 - Train loss: 0.43058550357818604, Validation loss: 0.43020331859588623
Epoch: 73/300 - Train loss: 0.42827776074409485, Validation loss: 0.42808079719543457
Epoch: 74/300 - Train loss: 0.42601752281188965, Validation loss: 0.4250340163707733
Epoch: 75/300 - Train loss: 0.4238041639328003, Validation loss: 0.4236370623111725
Epoch: 76/300 - Train loss: 0.42163705825805664, Validation loss: 0.4207195043563843
Epoch: 77/300 - Train loss: 0.41951459646224976, Validation loss: 0.419014573097229
Epoch: 78/300 - Train loss: 0.41743555665016174, Validation loss: 0.416942298412323
Epoch: 79/300 - Train loss: 0.41539886593818665, Validation loss: 0.41458746790885925
Epoch: 80/300 - Train loss: 0.4134039282798767, Validation loss: 0.4132626950740814
Epoch: 81/300 - Train loss: 0.411449670791626, Validation loss: 0.41063934564590454
Epoch: 82/300 - Train loss: 0.4095347225666046, Validation loss: 0.4090139865875244
Epoch: 83/300 - Train loss: 0.4076564610004425, Validation loss: 0.40713760256767273
Epoch: 84/300 - Train loss: 0.4058137536048889, Validation loss: 0.4050429165363312
Epoch: 85/300 - Train loss: 0.40400561690330505, Validation loss: 0.40269073843955994
Epoch: 86/300 - Train loss: 0.4022315740585327, Validation loss: 0.40147536993026733
Epoch: 87/300 - Train loss: 0.40049028396606445, Validation loss: 0.39973384141921997
Epoch: 88/300 - Train loss: 0.3987806737422943, Validation loss: 0.3976820409297943
Epoch: 89/300 - Train loss: 0.3971012234687805, Validation loss: 0.39607301354408264
Epoch: 90/300 - Train loss: 0.3954526484012604, Validation loss: 0.39449506998062134
Epoch: 91/300 - Train loss: 0.39383330941200256, Validation loss: 0.39243441820144653
Epoch: 92/300 - Train loss: 0.39224299788475037, Validation loss: 0.39099693298339844
Epoch: 93/300 - Train loss: 0.39068177342414856, Validation loss: 0.3890994191169739
Epoch: 94/300 - Train loss: 0.38914889097213745, Validation loss: 0.388628751039505
Epoch: 95/300 - Train loss: 0.3876429796218872, Validation loss: 0.38672345876693726
Epoch: 96/300 - Train loss: 0.38616397976875305, Validation loss: 0.3847137689590454
Epoch: 97/300 - Train loss: 0.3847111761569977, Validation loss: 0.3837154507637024
Epoch: 98/300 - Train loss: 0.38328465819358826, Validation loss: 0.38217222690582275
Epoch: 99/300 - Train loss: 0.3818846344947815, Validation loss: 0.38130274415016174
Epoch: 100/300 - Train loss: 0.38051044940948486, Validation loss: 0.3790362477302551
Epoch: 101/300 - Train loss: 0.3791610300540924, Validation loss: 0.37801095843315125
Epoch: 102/300 - Train loss: 0.37783512473106384, Validation loss: 0.3765089213848114
Epoch: 103/300 - Train loss: 0.3765324652194977, Validation loss: 0.3749769926071167
Epoch: 104/300 - Train loss: 0.37525036931037903, Validation loss: 0.37401461601257324
Epoch: 105/300 - Train loss: 0.37398913502693176, Validation loss: 0.37275445461273193
Epoch: 106/300 - Train loss: 0.37274765968322754, Validation loss: 0.3714037835597992
Epoch: 107/300 - Train loss: 0.37152525782585144, Validation loss: 0.3698914051055908
Epoch: 108/300 - Train loss: 0.37032172083854675, Validation loss: 0.3690401613712311
Epoch: 109/300 - Train loss: 0.3691369295120239, Validation loss: 0.36760827898979187
Epoch: 110/300 - Train loss: 0.3679710030555725, Validation loss: 0.3661578595638275
Epoch: 111/300 - Train loss: 0.36682239174842834, Validation loss: 0.36506274342536926
Epoch: 112/300 - Train loss: 0.36569133400917053, Validation loss: 0.36426323652267456
Epoch: 113/300 - Train loss: 0.3645761013031006, Validation loss: 0.3630564212799072
Epoch: 114/300 - Train loss: 0.3634771704673767, Validation loss: 0.3619667887687683
Epoch: 115/300 - Train loss: 0.3623935282230377, Validation loss: 0.3615668714046478
Epoch: 116/300 - Train loss: 0.361326664686203, Validation loss: 0.3591945171356201
Epoch: 117/300 - Train loss: 0.36027634143829346, Validation loss: 0.35890987515449524
Epoch: 118/300 - Train loss: 0.35924091935157776, Validation loss: 0.3576548099517822
Epoch: 119/300 - Train loss: 0.3582204580307007, Validation loss: 0.3566649258136749
Epoch: 120/300 - Train loss: 0.35721492767333984, Validation loss: 0.3553231954574585
Epoch: 121/300 - Train loss: 0.356225848197937, Validation loss: 0.35428524017333984
Epoch: 122/300 - Train loss: 0.35525181889533997, Validation loss: 0.35357654094696045
Epoch: 123/300 - Train loss: 0.3542913794517517, Validation loss: 0.35206153988838196
Epoch: 124/300 - Train loss: 0.3533460199832916, Validation loss: 0.3517288565635681
Epoch: 125/300 - Train loss: 0.35241377353668213, Validation loss: 0.3504733145236969
Epoch: 126/300 - Train loss: 0.35149475932121277, Validation loss: 0.34911105036735535
Epoch: 127/300 - Train loss: 0.3505879044532776, Validation loss: 0.34887632727622986
Epoch: 128/300 - Train loss: 0.34969303011894226, Validation loss: 0.34732189774513245
Epoch: 129/300 - Train loss: 0.34881049394607544, Validation loss: 0.3465510308742523
Epoch: 130/300 - Train loss: 0.34793975949287415, Validation loss: 0.34520402550697327
Epoch: 131/300 - Train loss: 0.34708043932914734, Validation loss: 0.34560897946357727
Epoch: 132/300 - Train loss: 0.34623199701309204, Validation loss: 0.344028502702713
Epoch: 133/300 - Train loss: 0.3453943133354187, Validation loss: 0.34297019243240356
Epoch: 134/300 - Train loss: 0.3445681929588318, Validation loss: 0.34246763586997986
Epoch: 135/300 - Train loss: 0.3437526226043701, Validation loss: 0.34181270003318787
Epoch: 136/300 - Train loss: 0.3429465591907501, Validation loss: 0.34090492129325867
Epoch: 137/300 - Train loss: 0.34215056896209717, Validation loss: 0.3397499620914459
Epoch: 138/300 - Train loss: 0.34136438369750977, Validation loss: 0.3395393192768097
Epoch: 139/300 - Train loss: 0.34058788418769836, Validation loss: 0.33826905488967896
Epoch: 140/300 - Train loss: 0.33981966972351074, Validation loss: 0.33710777759552
Epoch: 141/300 - Train loss: 0.33905965089797974, Validation loss: 0.3371178209781647
Epoch: 142/300 - Train loss: 0.3383074104785919, Validation loss: 0.335655152797699
Epoch: 143/300 - Train loss: 0.3375631868839264, Validation loss: 0.3357347548007965
Epoch: 144/300 - Train loss: 0.33682680130004883, Validation loss: 0.33434203267097473
Epoch: 145/300 - Train loss: 0.3360975980758667, Validation loss: 0.33354926109313965
Epoch: 146/300 - Train loss: 0.3353758156299591, Validation loss: 0.33326455950737
Epoch: 147/300 - Train loss: 0.3346610367298126, Validation loss: 0.3320457935333252
Epoch: 148/300 - Train loss: 0.33395320177078247, Validation loss: 0.3315805494785309
Epoch: 149/300 - Train loss: 0.33325228095054626, Validation loss: 0.3309572637081146
Epoch: 150/300 - Train loss: 0.3325583338737488, Validation loss: 0.3303734362125397
Epoch: 151/300 - Train loss: 0.33187058568000793, Validation loss: 0.32974758744239807
Epoch: 152/300 - Train loss: 0.33118852972984314, Validation loss: 0.32825416326522827
Epoch: 153/300 - Train loss: 0.3305124342441559, Validation loss: 0.3279809057712555
Epoch: 154/300 - Train loss: 0.3298414349555969, Validation loss: 0.3278830647468567
Epoch: 155/300 - Train loss: 0.3291759788990021, Validation loss: 0.3268020451068878
Epoch: 156/300 - Train loss: 0.3285156190395355, Validation loss: 0.326657235622406
Epoch: 157/300 - Train loss: 0.3278612494468689, Validation loss: 0.3256269693374634
Epoch: 158/300 - Train loss: 0.32721272110939026, Validation loss: 0.3244294226169586
Epoch: 159/300 - Train loss: 0.3265688717365265, Validation loss: 0.32416412234306335
Epoch: 160/300 - Train loss: 0.3259297311306, Validation loss: 0.32396671175956726
Epoch: 161/300 - Train loss: 0.3252958059310913, Validation loss: 0.32256510853767395
Epoch: 162/300 - Train loss: 0.32466673851013184, Validation loss: 0.3222172260284424
Epoch: 163/300 - Train loss: 0.3240419924259186, Validation loss: 0.3216297924518585
Epoch: 164/300 - Train loss: 0.3234217166900635, Validation loss: 0.32049912214279175
Epoch: 165/300 - Train loss: 0.32280588150024414, Validation loss: 0.32060572504997253
Epoch: 166/300 - Train loss: 0.3221948742866516, Validation loss: 0.319626122713089
Epoch: 167/300 - Train loss: 0.32158833742141724, Validation loss: 0.3189866542816162
Epoch: 168/300 - Train loss: 0.32098618149757385, Validation loss: 0.3189389407634735
Epoch: 169/300 - Train loss: 0.3203878104686737, Validation loss: 0.31819280982017517
Epoch: 170/300 - Train loss: 0.31979331374168396, Validation loss: 0.31731611490249634
Epoch: 171/300 - Train loss: 0.3192036747932434, Validation loss: 0.31700193881988525
Epoch: 172/300 - Train loss: 0.31861844658851624, Validation loss: 0.317018061876297
