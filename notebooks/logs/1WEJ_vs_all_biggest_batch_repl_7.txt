Epoch: 1/100 - Train loss: 0.6939659714698792, Validation loss: 0.6935421228408813
Epoch: 2/100 - Train loss: 0.6919252872467041, Validation loss: 0.6917176842689514
Epoch: 3/100 - Train loss: 0.6898674964904785, Validation loss: 0.6895765066146851
Epoch: 4/100 - Train loss: 0.687748372554779, Validation loss: 0.6872878670692444
Epoch: 5/100 - Train loss: 0.6855220794677734, Validation loss: 0.6850210428237915
Epoch: 6/100 - Train loss: 0.6831588745117188, Validation loss: 0.6826333999633789
Epoch: 7/100 - Train loss: 0.6806387305259705, Validation loss: 0.6800945401191711
Epoch: 8/100 - Train loss: 0.6779358386993408, Validation loss: 0.6772010326385498
Epoch: 9/100 - Train loss: 0.67503821849823, Validation loss: 0.6741820573806763
Epoch: 10/100 - Train loss: 0.6719365119934082, Validation loss: 0.6710681319236755
Epoch: 11/100 - Train loss: 0.6686303615570068, Validation loss: 0.6676346063613892
Epoch: 12/100 - Train loss: 0.6651257872581482, Validation loss: 0.6641233563423157
Epoch: 13/100 - Train loss: 0.6614297032356262, Validation loss: 0.660376787185669
Epoch: 14/100 - Train loss: 0.6575473546981812, Validation loss: 0.6564098000526428
Epoch: 15/100 - Train loss: 0.6535011529922485, Validation loss: 0.6524254083633423
Epoch: 16/100 - Train loss: 0.6493059396743774, Validation loss: 0.6480180025100708
Epoch: 17/100 - Train loss: 0.6449792981147766, Validation loss: 0.6437143087387085
Epoch: 18/100 - Train loss: 0.6405391693115234, Validation loss: 0.6392204761505127
Epoch: 19/100 - Train loss: 0.6360000967979431, Validation loss: 0.6347232460975647
Epoch: 20/100 - Train loss: 0.6313737034797668, Validation loss: 0.6300881505012512
Epoch: 21/100 - Train loss: 0.6266753673553467, Validation loss: 0.625354528427124
Epoch: 22/100 - Train loss: 0.6219177842140198, Validation loss: 0.6207904815673828
Epoch: 23/100 - Train loss: 0.6171182990074158, Validation loss: 0.6158260107040405
Epoch: 24/100 - Train loss: 0.6122904419898987, Validation loss: 0.6109530329704285
Epoch: 25/100 - Train loss: 0.6074360013008118, Validation loss: 0.6061453223228455
Epoch: 26/100 - Train loss: 0.6025629043579102, Validation loss: 0.6013473272323608
Epoch: 27/100 - Train loss: 0.597675621509552, Validation loss: 0.5967833399772644
Epoch: 28/100 - Train loss: 0.592779815196991, Validation loss: 0.5916568636894226
Epoch: 29/100 - Train loss: 0.587881326675415, Validation loss: 0.5867145657539368
Epoch: 30/100 - Train loss: 0.5829892158508301, Validation loss: 0.5820271372795105
Epoch: 31/100 - Train loss: 0.5781089067459106, Validation loss: 0.5768211483955383
Epoch: 32/100 - Train loss: 0.5732430219650269, Validation loss: 0.5722389817237854
Epoch: 33/100 - Train loss: 0.5683957934379578, Validation loss: 0.5671069622039795
Epoch: 34/100 - Train loss: 0.563571572303772, Validation loss: 0.56218421459198
Epoch: 35/100 - Train loss: 0.5587747097015381, Validation loss: 0.5576565861701965
Epoch: 36/100 - Train loss: 0.5540122389793396, Validation loss: 0.5531923174858093
Epoch: 37/100 - Train loss: 0.5492849946022034, Validation loss: 0.5481058359146118
Epoch: 38/100 - Train loss: 0.544598400592804, Validation loss: 0.5433894991874695
Epoch: 39/100 - Train loss: 0.5399551391601562, Validation loss: 0.539165735244751
Epoch: 40/100 - Train loss: 0.535359799861908, Validation loss: 0.5342326760292053
Epoch: 41/100 - Train loss: 0.5308133363723755, Validation loss: 0.5303882360458374
Epoch: 42/100 - Train loss: 0.5263193249702454, Validation loss: 0.525298535823822
Epoch: 43/100 - Train loss: 0.5218812823295593, Validation loss: 0.5210285782814026
Epoch: 44/100 - Train loss: 0.5175024271011353, Validation loss: 0.5161304473876953
Epoch: 45/100 - Train loss: 0.5131849646568298, Validation loss: 0.5121661424636841
Epoch: 46/100 - Train loss: 0.5089316964149475, Validation loss: 0.5076374411582947
Epoch: 47/100 - Train loss: 0.5047464370727539, Validation loss: 0.503574013710022
Epoch: 48/100 - Train loss: 0.5006315112113953, Validation loss: 0.49963703751564026
Epoch: 49/100 - Train loss: 0.49658745527267456, Validation loss: 0.49530360102653503
Epoch: 50/100 - Train loss: 0.4926164746284485, Validation loss: 0.4912734031677246
Epoch: 51/100 - Train loss: 0.4887206256389618, Validation loss: 0.4873673915863037
Epoch: 52/100 - Train loss: 0.48490098118782043, Validation loss: 0.4833904802799225
Epoch: 53/100 - Train loss: 0.48115795850753784, Validation loss: 0.48006168007850647
Epoch: 54/100 - Train loss: 0.47749271988868713, Validation loss: 0.47591328620910645
Epoch: 55/100 - Train loss: 0.4739062488079071, Validation loss: 0.47298187017440796
Epoch: 56/100 - Train loss: 0.4703989326953888, Validation loss: 0.46903371810913086
Epoch: 57/100 - Train loss: 0.4669703543186188, Validation loss: 0.46598687767982483
Epoch: 58/100 - Train loss: 0.46362021565437317, Validation loss: 0.4625774919986725
Epoch: 59/100 - Train loss: 0.46034857630729675, Validation loss: 0.45907723903656006
Epoch: 60/100 - Train loss: 0.457155704498291, Validation loss: 0.45598849654197693
Epoch: 61/100 - Train loss: 0.45404061675071716, Validation loss: 0.453156054019928
Epoch: 62/100 - Train loss: 0.45100274682044983, Validation loss: 0.45015594363212585
Epoch: 63/100 - Train loss: 0.4480413794517517, Validation loss: 0.4472827613353729
Epoch: 64/100 - Train loss: 0.44515568017959595, Validation loss: 0.4442872703075409
Epoch: 65/100 - Train loss: 0.4423445165157318, Validation loss: 0.4411163330078125
Epoch: 66/100 - Train loss: 0.4396069645881653, Validation loss: 0.43854010105133057
Epoch: 67/100 - Train loss: 0.43694180250167847, Validation loss: 0.4356486201286316
Epoch: 68/100 - Train loss: 0.4343477189540863, Validation loss: 0.4331122934818268
Epoch: 69/100 - Train loss: 0.4318237900733948, Validation loss: 0.43093934655189514
Epoch: 70/100 - Train loss: 0.42936843633651733, Validation loss: 0.42842215299606323
Epoch: 71/100 - Train loss: 0.42697978019714355, Validation loss: 0.4261839985847473
Epoch: 72/100 - Train loss: 0.42465725541114807, Validation loss: 0.42385372519493103
Epoch: 73/100 - Train loss: 0.4223993718624115, Validation loss: 0.4210358262062073
Epoch: 74/100 - Train loss: 0.42020443081855774, Validation loss: 0.41877052187919617
Epoch: 75/100 - Train loss: 0.41807201504707336, Validation loss: 0.4172753095626831
Epoch: 76/100 - Train loss: 0.41599953174591064, Validation loss: 0.41456103324890137
Epoch: 77/100 - Train loss: 0.4139857590198517, Validation loss: 0.4128361940383911
Epoch: 78/100 - Train loss: 0.4120285212993622, Validation loss: 0.4104878306388855
Epoch: 79/100 - Train loss: 0.41012611985206604, Validation loss: 0.4086924195289612
Epoch: 80/100 - Train loss: 0.40827834606170654, Validation loss: 0.4067663252353668
Epoch: 81/100 - Train loss: 0.4064825475215912, Validation loss: 0.4053844213485718
Epoch: 82/100 - Train loss: 0.40473636984825134, Validation loss: 0.4039002060890198
Epoch: 83/100 - Train loss: 0.40303876996040344, Validation loss: 0.40207698941230774
Epoch: 84/100 - Train loss: 0.40138864517211914, Validation loss: 0.400507390499115
Epoch: 85/100 - Train loss: 0.3997851014137268, Validation loss: 0.3986448347568512
Epoch: 86/100 - Train loss: 0.39822542667388916, Validation loss: 0.3962448239326477
Epoch: 87/100 - Train loss: 0.39670926332473755, Validation loss: 0.3954615890979767
Epoch: 88/100 - Train loss: 0.39523348212242126, Validation loss: 0.3945561647415161
Epoch: 89/100 - Train loss: 0.39379656314849854, Validation loss: 0.3927333652973175
Epoch: 90/100 - Train loss: 0.3923971951007843, Validation loss: 0.3914279639720917
Epoch: 91/100 - Train loss: 0.39103418588638306, Validation loss: 0.3904479146003723
Epoch: 92/100 - Train loss: 0.3897054195404053, Validation loss: 0.3886049687862396
Epoch: 93/100 - Train loss: 0.38840946555137634, Validation loss: 0.3871074914932251
Epoch: 94/100 - Train loss: 0.38714534044265747, Validation loss: 0.3854435980319977
Epoch: 95/100 - Train loss: 0.3859122693538666, Validation loss: 0.3845427334308624
Epoch: 96/100 - Train loss: 0.3847093880176544, Validation loss: 0.38341546058654785
Epoch: 97/100 - Train loss: 0.38353532552719116, Validation loss: 0.38220080733299255
Epoch: 98/100 - Train loss: 0.3823888599872589, Validation loss: 0.3812255859375
Epoch: 99/100 - Train loss: 0.38126757740974426, Validation loss: 0.37936192750930786
Epoch: 100/100 - Train loss: 0.38017138838768005, Validation loss: 0.37861743569374084
Epoch: 1/300 - Train loss: 0.6942988038063049, Validation loss: 0.691908597946167
Epoch: 2/300 - Train loss: 0.6921442151069641, Validation loss: 0.689770519733429
Epoch: 3/300 - Train loss: 0.6898768544197083, Validation loss: 0.6874940395355225
Epoch: 4/300 - Train loss: 0.6874682307243347, Validation loss: 0.6850364208221436
Epoch: 5/300 - Train loss: 0.684898853302002, Validation loss: 0.6824382543563843
Epoch: 6/300 - Train loss: 0.6821556091308594, Validation loss: 0.6797114014625549
Epoch: 7/300 - Train loss: 0.679240882396698, Validation loss: 0.6768026947975159
Epoch: 8/300 - Train loss: 0.6761572957038879, Validation loss: 0.6736372113227844
Epoch: 9/300 - Train loss: 0.672914981842041, Validation loss: 0.6704332232475281
Epoch: 10/300 - Train loss: 0.6695290803909302, Validation loss: 0.6670888662338257
Epoch: 11/300 - Train loss: 0.6660224795341492, Validation loss: 0.6636276245117188
Epoch: 12/300 - Train loss: 0.6624132990837097, Validation loss: 0.6600747108459473
Epoch: 13/300 - Train loss: 0.6587173938751221, Validation loss: 0.6564252376556396
Epoch: 14/300 - Train loss: 0.6549440622329712, Validation loss: 0.652719259262085
Epoch: 15/300 - Train loss: 0.6511102914810181, Validation loss: 0.6489299535751343
Epoch: 16/300 - Train loss: 0.6472218036651611, Validation loss: 0.6451472043991089
Epoch: 17/300 - Train loss: 0.6432867646217346, Validation loss: 0.6412942409515381
Epoch: 18/300 - Train loss: 0.6393080353736877, Validation loss: 0.637428343296051
Epoch: 19/300 - Train loss: 0.6352900266647339, Validation loss: 0.633396565914154
Epoch: 20/300 - Train loss: 0.6312366127967834, Validation loss: 0.629429042339325
Epoch: 21/300 - Train loss: 0.6271504163742065, Validation loss: 0.6255038976669312
Epoch: 22/300 - Train loss: 0.6230341792106628, Validation loss: 0.6215564608573914
Epoch: 23/300 - Train loss: 0.618891179561615, Validation loss: 0.6174792647361755
Epoch: 24/300 - Train loss: 0.6147223711013794, Validation loss: 0.6132152676582336
Epoch: 25/300 - Train loss: 0.6105299592018127, Validation loss: 0.6090616583824158
Epoch: 26/300 - Train loss: 0.606316864490509, Validation loss: 0.6049333810806274
Epoch: 27/300 - Train loss: 0.6020860075950623, Validation loss: 0.6007040739059448
Epoch: 28/300 - Train loss: 0.5978405475616455, Validation loss: 0.5965412259101868
Epoch: 29/300 - Train loss: 0.5935850143432617, Validation loss: 0.5923325419425964
Epoch: 30/300 - Train loss: 0.5893234610557556, Validation loss: 0.5881869792938232
Epoch: 31/300 - Train loss: 0.5850585699081421, Validation loss: 0.5839208364486694
Epoch: 32/300 - Train loss: 0.5807939171791077, Validation loss: 0.5795186758041382
Epoch: 33/300 - Train loss: 0.5765323042869568, Validation loss: 0.5755029916763306
Epoch: 34/300 - Train loss: 0.5722770094871521, Validation loss: 0.5713915228843689
Epoch: 35/300 - Train loss: 0.5680313110351562, Validation loss: 0.5667780041694641
Epoch: 36/300 - Train loss: 0.5637993812561035, Validation loss: 0.562713623046875
Epoch: 37/300 - Train loss: 0.5595837831497192, Validation loss: 0.5584378838539124
Epoch: 38/300 - Train loss: 0.5553874373435974, Validation loss: 0.5544965267181396
Epoch: 39/300 - Train loss: 0.5512130260467529, Validation loss: 0.5500640273094177
Epoch: 40/300 - Train loss: 0.5470624566078186, Validation loss: 0.5461223721504211
Epoch: 41/300 - Train loss: 0.5429381132125854, Validation loss: 0.5420582294464111
Epoch: 42/300 - Train loss: 0.5388425588607788, Validation loss: 0.5378056168556213
Epoch: 43/300 - Train loss: 0.5347777605056763, Validation loss: 0.5335661768913269
Epoch: 44/300 - Train loss: 0.5307456851005554, Validation loss: 0.5298151969909668
Epoch: 45/300 - Train loss: 0.5267483592033386, Validation loss: 0.5257412195205688
Epoch: 46/300 - Train loss: 0.5227877497673035, Validation loss: 0.5219489336013794
Epoch: 47/300 - Train loss: 0.5188664197921753, Validation loss: 0.5182419419288635
Epoch: 48/300 - Train loss: 0.5149862170219421, Validation loss: 0.514124870300293
Epoch: 49/300 - Train loss: 0.5111486911773682, Validation loss: 0.5104867815971375
Epoch: 50/300 - Train loss: 0.5073554515838623, Validation loss: 0.5069743394851685
Epoch: 51/300 - Train loss: 0.5036088228225708, Validation loss: 0.5027381181716919
Epoch: 52/300 - Train loss: 0.4999100863933563, Validation loss: 0.49944958090782166
Epoch: 53/300 - Train loss: 0.49626046419143677, Validation loss: 0.4958036541938782
Epoch: 54/300 - Train loss: 0.4926620125770569, Validation loss: 0.49213194847106934
Epoch: 55/300 - Train loss: 0.48911571502685547, Validation loss: 0.4885800778865814
Epoch: 56/300 - Train loss: 0.4856226146221161, Validation loss: 0.48471489548683167
Epoch: 57/300 - Train loss: 0.48218390345573425, Validation loss: 0.4811532497406006
Epoch: 58/300 - Train loss: 0.47880059480667114, Validation loss: 0.47782400250434875
Epoch: 59/300 - Train loss: 0.47547343373298645, Validation loss: 0.4748591482639313
Epoch: 60/300 - Train loss: 0.47220221161842346, Validation loss: 0.47129306197166443
Epoch: 61/300 - Train loss: 0.4689875841140747, Validation loss: 0.4678996503353119
Epoch: 62/300 - Train loss: 0.4658300578594208, Validation loss: 0.4658777415752411
Epoch: 63/300 - Train loss: 0.4627308249473572, Validation loss: 0.4621506631374359
Epoch: 64/300 - Train loss: 0.4596906304359436, Validation loss: 0.45908814668655396
Epoch: 65/300 - Train loss: 0.45670902729034424, Validation loss: 0.4562877118587494
Epoch: 66/300 - Train loss: 0.4537865221500397, Validation loss: 0.45289936661720276
Epoch: 67/300 - Train loss: 0.4509229362010956, Validation loss: 0.45009785890579224
Epoch: 68/300 - Train loss: 0.44811776280403137, Validation loss: 0.44823580980300903
Epoch: 69/300 - Train loss: 0.445370614528656, Validation loss: 0.4446071684360504
Epoch: 70/300 - Train loss: 0.44268128275871277, Validation loss: 0.4420279264450073
Epoch: 71/300 - Train loss: 0.44005003571510315, Validation loss: 0.43897733092308044
Epoch: 72/300 - Train loss: 0.4374769330024719, Validation loss: 0.43659523129463196
Epoch: 73/300 - Train loss: 0.43496042490005493, Validation loss: 0.4342533349990845
Epoch: 74/300 - Train loss: 0.43249887228012085, Validation loss: 0.4316263198852539
Epoch: 75/300 - Train loss: 0.43009212613105774, Validation loss: 0.4293901324272156
Epoch: 76/300 - Train loss: 0.4277404248714447, Validation loss: 0.4267576038837433
Epoch: 77/300 - Train loss: 0.42544370889663696, Validation loss: 0.4244706630706787
Epoch: 78/300 - Train loss: 0.42320001125335693, Validation loss: 0.4223859906196594
Epoch: 79/300 - Train loss: 0.4210074245929718, Validation loss: 0.420179158449173
Epoch: 80/300 - Train loss: 0.4188655912876129, Validation loss: 0.41843488812446594
Epoch: 81/300 - Train loss: 0.41677409410476685, Validation loss: 0.4161227345466614
Epoch: 82/300 - Train loss: 0.4147312045097351, Validation loss: 0.41485172510147095
Epoch: 83/300 - Train loss: 0.4127364158630371, Validation loss: 0.4121188819408417
Epoch: 84/300 - Train loss: 0.41078805923461914, Validation loss: 0.4104766547679901
Epoch: 85/300 - Train loss: 0.40888547897338867, Validation loss: 0.4076772630214691
Epoch: 86/300 - Train loss: 0.40702781081199646, Validation loss: 0.40598535537719727
Epoch: 87/300 - Train loss: 0.40521496534347534, Validation loss: 0.40421605110168457
Epoch: 88/300 - Train loss: 0.4034459590911865, Validation loss: 0.40248140692710876
Epoch: 89/300 - Train loss: 0.4017185866832733, Validation loss: 0.4012833833694458
Epoch: 90/300 - Train loss: 0.4000316262245178, Validation loss: 0.39925944805145264
Epoch: 91/300 - Train loss: 0.39838433265686035, Validation loss: 0.3976561427116394
Epoch: 92/300 - Train loss: 0.39677560329437256, Validation loss: 0.39563044905662537
Epoch: 93/300 - Train loss: 0.39520469307899475, Validation loss: 0.3939042091369629
Epoch: 94/300 - Train loss: 0.3936704397201538, Validation loss: 0.3926731050014496
Epoch: 95/300 - Train loss: 0.3921719193458557, Validation loss: 0.39152634143829346
Epoch: 96/300 - Train loss: 0.3907085061073303, Validation loss: 0.3897644281387329
Epoch: 97/300 - Train loss: 0.38927778601646423, Validation loss: 0.3883243501186371
Epoch: 98/300 - Train loss: 0.3878794014453888, Validation loss: 0.3872711956501007
Epoch: 99/300 - Train loss: 0.3865116238594055, Validation loss: 0.38549450039863586
Epoch: 100/300 - Train loss: 0.38517317175865173, Validation loss: 0.38368770480155945
Epoch: 101/300 - Train loss: 0.38386374711990356, Validation loss: 0.38248294591903687
Epoch: 102/300 - Train loss: 0.38258349895477295, Validation loss: 0.38228243589401245
Epoch: 103/300 - Train loss: 0.38133203983306885, Validation loss: 0.3802567720413208
Epoch: 104/300 - Train loss: 0.38010841608047485, Validation loss: 0.37840086221694946
Epoch: 105/300 - Train loss: 0.3789106011390686, Validation loss: 0.3776829242706299
Epoch: 106/300 - Train loss: 0.377737432718277, Validation loss: 0.37675347924232483
Epoch: 107/300 - Train loss: 0.3765893876552582, Validation loss: 0.3756242096424103
Epoch: 108/300 - Train loss: 0.37546536326408386, Validation loss: 0.374176025390625
Epoch: 109/300 - Train loss: 0.37436458468437195, Validation loss: 0.37271764874458313
Epoch: 110/300 - Train loss: 0.37328678369522095, Validation loss: 0.3720155656337738
Epoch: 111/300 - Train loss: 0.3722309172153473, Validation loss: 0.3707815110683441
Epoch: 112/300 - Train loss: 0.3711957335472107, Validation loss: 0.36981070041656494
Epoch: 113/300 - Train loss: 0.37018024921417236, Validation loss: 0.36838340759277344
Epoch: 114/300 - Train loss: 0.3691849708557129, Validation loss: 0.36781516671180725
Epoch: 115/300 - Train loss: 0.36820897459983826, Validation loss: 0.3661741316318512
Epoch: 116/300 - Train loss: 0.36725106835365295, Validation loss: 0.3662853538990021
Epoch: 117/300 - Train loss: 0.3663114905357361, Validation loss: 0.3648878037929535
Epoch: 118/300 - Train loss: 0.3653891384601593, Validation loss: 0.3637801706790924
Epoch: 119/300 - Train loss: 0.3644839823246002, Validation loss: 0.36242038011550903
Epoch: 120/300 - Train loss: 0.3635946810245514, Validation loss: 0.3618083894252777
Epoch: 121/300 - Train loss: 0.36272045969963074, Validation loss: 0.3612874448299408
Epoch: 122/300 - Train loss: 0.3618616759777069, Validation loss: 0.35991132259368896
Epoch: 123/300 - Train loss: 0.3610183298587799, Validation loss: 0.35945644974708557
Epoch: 124/300 - Train loss: 0.3601890206336975, Validation loss: 0.35819533467292786
Epoch: 125/300 - Train loss: 0.3593735098838806, Validation loss: 0.3576340973377228
Epoch: 126/300 - Train loss: 0.35857152938842773, Validation loss: 0.3559265434741974
Epoch: 127/300 - Train loss: 0.3577817380428314, Validation loss: 0.3556949496269226
Epoch: 128/300 - Train loss: 0.3570041358470917, Validation loss: 0.3550472557544708
Epoch: 129/300 - Train loss: 0.3562389016151428, Validation loss: 0.35388779640197754
Epoch: 130/300 - Train loss: 0.35548484325408936, Validation loss: 0.35366344451904297
Epoch: 131/300 - Train loss: 0.3547411859035492, Validation loss: 0.35241612792015076
Epoch: 132/300 - Train loss: 0.3540072441101074, Validation loss: 0.35123246908187866
Epoch: 133/300 - Train loss: 0.3532835841178894, Validation loss: 0.351785808801651
Epoch: 134/300 - Train loss: 0.352569580078125, Validation loss: 0.3506665527820587
Epoch: 135/300 - Train loss: 0.35186541080474854, Validation loss: 0.34935855865478516
Epoch: 136/300 - Train loss: 0.3511699438095093, Validation loss: 0.34911102056503296
Epoch: 137/300 - Train loss: 0.3504832088947296, Validation loss: 0.3495277166366577
Epoch: 138/300 - Train loss: 0.34980425238609314, Validation loss: 0.34784042835235596
Epoch: 139/300 - Train loss: 0.3491331934928894, Validation loss: 0.34719935059547424
Epoch: 140/300 - Train loss: 0.3484691083431244, Validation loss: 0.34595850110054016
Epoch: 141/300 - Train loss: 0.34781262278556824, Validation loss: 0.34582310914993286
Epoch: 142/300 - Train loss: 0.34716349840164185, Validation loss: 0.3454264998435974
Epoch: 143/300 - Train loss: 0.34652087092399597, Validation loss: 0.34447866678237915
Epoch: 144/300 - Train loss: 0.34588661789894104, Validation loss: 0.34389740228652954
Epoch: 145/300 - Train loss: 0.3452599346637726, Validation loss: 0.3435314893722534
Epoch: 146/300 - Train loss: 0.3446400463581085, Validation loss: 0.3424023985862732
Epoch: 147/300 - Train loss: 0.3440263271331787, Validation loss: 0.3419428765773773
Epoch: 148/300 - Train loss: 0.34341859817504883, Validation loss: 0.34125199913978577
Epoch: 149/300 - Train loss: 0.34281614422798157, Validation loss: 0.34075021743774414
Epoch: 150/300 - Train loss: 0.34221944212913513, Validation loss: 0.33981582522392273
Epoch: 151/300 - Train loss: 0.34162822365760803, Validation loss: 0.3398652672767639
Epoch: 152/300 - Train loss: 0.34104326367378235, Validation loss: 0.3386509120464325
Epoch: 153/300 - Train loss: 0.3404633104801178, Validation loss: 0.3384385108947754
Epoch: 154/300 - Train loss: 0.33988773822784424, Validation loss: 0.3381277322769165
Epoch: 155/300 - Train loss: 0.33931776881217957, Validation loss: 0.3371974527835846
Epoch: 156/300 - Train loss: 0.33875229954719543, Validation loss: 0.336587131023407
Epoch: 157/300 - Train loss: 0.33819159865379333, Validation loss: 0.33661261200904846
