Epoch: 1/300 - Train loss: 0.693548321723938, Validation loss: 0.6912329196929932
Epoch: 2/300 - Train loss: 0.6921598315238953, Validation loss: 0.6898610591888428
Epoch: 3/300 - Train loss: 0.6907810568809509, Validation loss: 0.6884362101554871
Epoch: 4/300 - Train loss: 0.6893971562385559, Validation loss: 0.6870288848876953
Epoch: 5/300 - Train loss: 0.6879978179931641, Validation loss: 0.6855733394622803
Epoch: 6/300 - Train loss: 0.6865746378898621, Validation loss: 0.6840701103210449
Epoch: 7/300 - Train loss: 0.6851194500923157, Validation loss: 0.682559072971344
Epoch: 8/300 - Train loss: 0.6836295127868652, Validation loss: 0.6809329986572266
Epoch: 9/300 - Train loss: 0.6820982098579407, Validation loss: 0.6794185638427734
Epoch: 10/300 - Train loss: 0.6805191040039062, Validation loss: 0.6777019500732422
Epoch: 11/300 - Train loss: 0.6788820624351501, Validation loss: 0.6759891510009766
Epoch: 12/300 - Train loss: 0.677182674407959, Validation loss: 0.6740630865097046
Epoch: 13/300 - Train loss: 0.675417959690094, Validation loss: 0.6724209785461426
Epoch: 14/300 - Train loss: 0.6735829710960388, Validation loss: 0.6704196929931641
Epoch: 15/300 - Train loss: 0.6716834902763367, Validation loss: 0.668529212474823
Epoch: 16/300 - Train loss: 0.6697185635566711, Validation loss: 0.6662973165512085
Epoch: 17/300 - Train loss: 0.6676880717277527, Validation loss: 0.6642897129058838
Epoch: 18/300 - Train loss: 0.6655941009521484, Validation loss: 0.6620692014694214
Epoch: 19/300 - Train loss: 0.6634427309036255, Validation loss: 0.6599662899971008
Epoch: 20/300 - Train loss: 0.6612305045127869, Validation loss: 0.657679557800293
Epoch: 21/300 - Train loss: 0.6589610576629639, Validation loss: 0.6551909446716309
Epoch: 22/300 - Train loss: 0.6566378474235535, Validation loss: 0.6528204679489136
Epoch: 23/300 - Train loss: 0.6542606353759766, Validation loss: 0.6502804160118103
Epoch: 24/300 - Train loss: 0.651835024356842, Validation loss: 0.6478553414344788
Epoch: 25/300 - Train loss: 0.6493650674819946, Validation loss: 0.6451723575592041
Epoch: 26/300 - Train loss: 0.6468557715415955, Validation loss: 0.6425750255584717
Epoch: 27/300 - Train loss: 0.6443094611167908, Validation loss: 0.6399325132369995
Epoch: 28/300 - Train loss: 0.6417275667190552, Validation loss: 0.6373699307441711
Epoch: 29/300 - Train loss: 0.6391109824180603, Validation loss: 0.6346380114555359
Epoch: 30/300 - Train loss: 0.6364645957946777, Validation loss: 0.6321246027946472
Epoch: 31/300 - Train loss: 0.6337941884994507, Validation loss: 0.6292168498039246
Epoch: 32/300 - Train loss: 0.6311076879501343, Validation loss: 0.6266009211540222
Epoch: 33/300 - Train loss: 0.6284124851226807, Validation loss: 0.6237446665763855
Epoch: 34/300 - Train loss: 0.625708818435669, Validation loss: 0.6209658980369568
Epoch: 35/300 - Train loss: 0.6230025291442871, Validation loss: 0.6184333562850952
Epoch: 36/300 - Train loss: 0.6203001737594604, Validation loss: 0.6157025098800659
Epoch: 37/300 - Train loss: 0.6176047921180725, Validation loss: 0.6130795478820801
Epoch: 38/300 - Train loss: 0.6149172782897949, Validation loss: 0.6102246642112732
Epoch: 39/300 - Train loss: 0.6122419238090515, Validation loss: 0.6079155802726746
Epoch: 40/300 - Train loss: 0.6095818877220154, Validation loss: 0.6051210761070251
Epoch: 41/300 - Train loss: 0.6069449186325073, Validation loss: 0.6023264527320862
Epoch: 42/300 - Train loss: 0.6043323874473572, Validation loss: 0.6000581383705139
Epoch: 43/300 - Train loss: 0.6017456650733948, Validation loss: 0.5972394943237305
Epoch: 44/300 - Train loss: 0.5991901755332947, Validation loss: 0.5950820446014404
Epoch: 45/300 - Train loss: 0.5966678857803345, Validation loss: 0.5924966931343079
Epoch: 46/300 - Train loss: 0.5941823720932007, Validation loss: 0.589901864528656
Epoch: 47/300 - Train loss: 0.5917347073554993, Validation loss: 0.5875322222709656
Epoch: 48/300 - Train loss: 0.5893245935440063, Validation loss: 0.5854467749595642
Epoch: 49/300 - Train loss: 0.5869558453559875, Validation loss: 0.5832216143608093
Epoch: 50/300 - Train loss: 0.5846293568611145, Validation loss: 0.5808886885643005
Epoch: 51/300 - Train loss: 0.5823454856872559, Validation loss: 0.5786566734313965
Epoch: 52/300 - Train loss: 0.5801065564155579, Validation loss: 0.5767537951469421
Epoch: 53/300 - Train loss: 0.5779135823249817, Validation loss: 0.5743984580039978
Epoch: 54/300 - Train loss: 0.5757653117179871, Validation loss: 0.5727868676185608
Epoch: 55/300 - Train loss: 0.5736618041992188, Validation loss: 0.5706188082695007
Epoch: 56/300 - Train loss: 0.571604311466217, Validation loss: 0.5685027837753296
Epoch: 57/300 - Train loss: 0.5695917010307312, Validation loss: 0.5665653944015503
Epoch: 58/300 - Train loss: 0.567623496055603, Validation loss: 0.5650490522384644
Epoch: 59/300 - Train loss: 0.5656989812850952, Validation loss: 0.5632823705673218
Epoch: 60/300 - Train loss: 0.5638188123703003, Validation loss: 0.5608784556388855
Epoch: 61/300 - Train loss: 0.5619800686836243, Validation loss: 0.5596475601196289
Epoch: 62/300 - Train loss: 0.5601833462715149, Validation loss: 0.5578638911247253
Epoch: 63/300 - Train loss: 0.5584271550178528, Validation loss: 0.5563642382621765
Epoch: 64/300 - Train loss: 0.556710958480835, Validation loss: 0.5545644760131836
Epoch: 65/300 - Train loss: 0.5550329089164734, Validation loss: 0.5529550909996033
Epoch: 66/300 - Train loss: 0.5533906817436218, Validation loss: 0.5513145923614502
Epoch: 67/300 - Train loss: 0.5517842173576355, Validation loss: 0.5502177476882935
Epoch: 68/300 - Train loss: 0.5502125024795532, Validation loss: 0.5484768748283386
Epoch: 69/300 - Train loss: 0.5486739277839661, Validation loss: 0.5474748015403748
Epoch: 70/300 - Train loss: 0.5471681356430054, Validation loss: 0.5453470349311829
Epoch: 71/300 - Train loss: 0.5456926822662354, Validation loss: 0.5443577170372009
Epoch: 72/300 - Train loss: 0.5442466139793396, Validation loss: 0.5430375337600708
Epoch: 73/300 - Train loss: 0.5428290367126465, Validation loss: 0.541539192199707
Epoch: 74/300 - Train loss: 0.5414384007453918, Validation loss: 0.5404791831970215
Epoch: 75/300 - Train loss: 0.5400749444961548, Validation loss: 0.5391608476638794
Epoch: 76/300 - Train loss: 0.538737416267395, Validation loss: 0.5382538437843323
Epoch: 77/300 - Train loss: 0.5374237895011902, Validation loss: 0.5370440483093262
Epoch: 78/300 - Train loss: 0.5361337065696716, Validation loss: 0.5352367162704468
Epoch: 79/300 - Train loss: 0.5348663926124573, Validation loss: 0.5341271758079529
Epoch: 80/300 - Train loss: 0.5336210131645203, Validation loss: 0.5333647131919861
Epoch: 81/300 - Train loss: 0.5323961973190308, Validation loss: 0.5322238802909851
Epoch: 82/300 - Train loss: 0.5311910510063171, Validation loss: 0.5309522151947021
Epoch: 83/300 - Train loss: 0.5300048589706421, Validation loss: 0.5303780436515808
Epoch: 84/300 - Train loss: 0.5288369059562683, Validation loss: 0.5282829403877258
Epoch: 85/300 - Train loss: 0.5276862978935242, Validation loss: 0.5277023315429688
Epoch: 86/300 - Train loss: 0.5265516042709351, Validation loss: 0.5264639258384705
Epoch: 87/300 - Train loss: 0.5254321098327637, Validation loss: 0.5255616307258606
Epoch: 88/300 - Train loss: 0.5243276953697205, Validation loss: 0.5246998071670532
Epoch: 89/300 - Train loss: 0.523237943649292, Validation loss: 0.5235332250595093
Epoch: 90/300 - Train loss: 0.5221612453460693, Validation loss: 0.5227601528167725
Epoch: 91/300 - Train loss: 0.5210976004600525, Validation loss: 0.5214390754699707
Epoch: 92/300 - Train loss: 0.5200476050376892, Validation loss: 0.5207622647285461
Epoch: 93/300 - Train loss: 0.5190104842185974, Validation loss: 0.5193575024604797
Epoch: 94/300 - Train loss: 0.5179855823516846, Validation loss: 0.5193966031074524
Epoch: 95/300 - Train loss: 0.5169718861579895, Validation loss: 0.5178748965263367
Epoch: 96/300 - Train loss: 0.5159682631492615, Validation loss: 0.5167667865753174
Epoch: 97/300 - Train loss: 0.514975905418396, Validation loss: 0.5159900784492493
Epoch: 98/300 - Train loss: 0.513994574546814, Validation loss: 0.5149128437042236
Epoch: 99/300 - Train loss: 0.5130228400230408, Validation loss: 0.5137635469436646
Epoch: 100/300 - Train loss: 0.5120601654052734, Validation loss: 0.513367235660553
Epoch: 101/300 - Train loss: 0.5111070871353149, Validation loss: 0.5123966336250305
Epoch: 102/300 - Train loss: 0.5101629495620728, Validation loss: 0.5114414095878601
Epoch: 103/300 - Train loss: 0.509227454662323, Validation loss: 0.5103965401649475
Epoch: 104/300 - Train loss: 0.5082995891571045, Validation loss: 0.5098972320556641
Epoch: 105/300 - Train loss: 0.507378876209259, Validation loss: 0.5087969303131104
Epoch: 106/300 - Train loss: 0.5064647793769836, Validation loss: 0.5079467296600342
Epoch: 107/300 - Train loss: 0.505557656288147, Validation loss: 0.5072253942489624
Epoch: 108/300 - Train loss: 0.5046566724777222, Validation loss: 0.5066494345664978
Epoch: 109/300 - Train loss: 0.5037624835968018, Validation loss: 0.5054466128349304
Epoch: 110/300 - Train loss: 0.5028749704360962, Validation loss: 0.5044096112251282
Epoch: 111/300 - Train loss: 0.5019930601119995, Validation loss: 0.5033560991287231
Epoch: 112/300 - Train loss: 0.5011178851127625, Validation loss: 0.5029908418655396
Epoch: 113/300 - Train loss: 0.5002489686012268, Validation loss: 0.5019389986991882
Epoch: 114/300 - Train loss: 0.49938616156578064, Validation loss: 0.5014035701751709
Epoch: 115/300 - Train loss: 0.4985296130180359, Validation loss: 0.5010205507278442
Epoch: 116/300 - Train loss: 0.4976785480976105, Validation loss: 0.4996393322944641
Epoch: 117/300 - Train loss: 0.4968324899673462, Validation loss: 0.498196542263031
Epoch: 118/300 - Train loss: 0.49599185585975647, Validation loss: 0.4980018734931946
Epoch: 119/300 - Train loss: 0.49515601992607117, Validation loss: 0.49764853715896606
Epoch: 120/300 - Train loss: 0.49432626366615295, Validation loss: 0.496332585811615
Epoch: 121/300 - Train loss: 0.49350106716156006, Validation loss: 0.4954622685909271
Epoch: 122/300 - Train loss: 0.49267926812171936, Validation loss: 0.4949858784675598
Epoch: 123/300 - Train loss: 0.49186164140701294, Validation loss: 0.494606614112854
Epoch: 124/300 - Train loss: 0.49104785919189453, Validation loss: 0.4933807849884033
Epoch: 125/300 - Train loss: 0.49023735523223877, Validation loss: 0.49261701107025146
Epoch: 126/300 - Train loss: 0.4894290268421173, Validation loss: 0.4919070899486542
Epoch: 127/300 - Train loss: 0.48862358927726746, Validation loss: 0.4916705787181854
Epoch: 128/300 - Train loss: 0.4878200888633728, Validation loss: 0.4906007945537567
Epoch: 129/300 - Train loss: 0.48701736330986023, Validation loss: 0.48996591567993164
Epoch: 130/300 - Train loss: 0.4862171411514282, Validation loss: 0.4893249273300171
Epoch: 131/300 - Train loss: 0.4854198396205902, Validation loss: 0.48811042308807373
Epoch: 132/300 - Train loss: 0.4846259355545044, Validation loss: 0.48786279559135437
Epoch: 133/300 - Train loss: 0.4838351607322693, Validation loss: 0.4871424734592438
Epoch: 134/300 - Train loss: 0.4830489158630371, Validation loss: 0.4864293038845062
Epoch: 135/300 - Train loss: 0.4822673201560974, Validation loss: 0.485770583152771
Epoch: 136/300 - Train loss: 0.48148858547210693, Validation loss: 0.48501890897750854
Epoch: 137/300 - Train loss: 0.48071548342704773, Validation loss: 0.48379504680633545
Epoch: 138/300 - Train loss: 0.47994786500930786, Validation loss: 0.48308154940605164
Epoch: 139/300 - Train loss: 0.4791850745677948, Validation loss: 0.48272648453712463
Epoch: 140/300 - Train loss: 0.47842714190483093, Validation loss: 0.48227763175964355
Epoch: 141/300 - Train loss: 0.4776718020439148, Validation loss: 0.4818391799926758
Epoch: 142/300 - Train loss: 0.4769183099269867, Validation loss: 0.48050031065940857
Epoch: 143/300 - Train loss: 0.4761676490306854, Validation loss: 0.4797306954860687
Epoch: 144/300 - Train loss: 0.47542017698287964, Validation loss: 0.47965601086616516
Epoch: 145/300 - Train loss: 0.4746755063533783, Validation loss: 0.47842949628829956
Epoch: 146/300 - Train loss: 0.4739336669445038, Validation loss: 0.4775410592556
Epoch: 147/300 - Train loss: 0.47319504618644714, Validation loss: 0.4765612781047821
Epoch: 148/300 - Train loss: 0.4724595844745636, Validation loss: 0.4765462875366211
Epoch: 149/300 - Train loss: 0.47172656655311584, Validation loss: 0.4756409525871277
Epoch: 150/300 - Train loss: 0.4709950089454651, Validation loss: 0.47471535205841064
Epoch: 151/300 - Train loss: 0.47026577591896057, Validation loss: 0.47387683391571045
Epoch: 152/300 - Train loss: 0.46953800320625305, Validation loss: 0.4740475118160248
Epoch: 153/300 - Train loss: 0.46881166100502014, Validation loss: 0.47267454862594604
Epoch: 154/300 - Train loss: 0.4680873155593872, Validation loss: 0.4723522961139679
Epoch: 155/300 - Train loss: 0.46736517548561096, Validation loss: 0.4711674153804779
Epoch: 156/300 - Train loss: 0.46664193272590637, Validation loss: 0.4709054231643677
Epoch: 157/300 - Train loss: 0.46591857075691223, Validation loss: 0.4699527323246002
Epoch: 158/300 - Train loss: 0.46519654989242554, Validation loss: 0.469392865896225
Epoch: 159/300 - Train loss: 0.46447449922561646, Validation loss: 0.46886858344078064
Epoch: 160/300 - Train loss: 0.46375152468681335, Validation loss: 0.46810537576675415
Epoch: 161/300 - Train loss: 0.4630275368690491, Validation loss: 0.46762052178382874
Epoch: 162/300 - Train loss: 0.4623052477836609, Validation loss: 0.46708330512046814
Epoch: 163/300 - Train loss: 0.46158289909362793, Validation loss: 0.46595820784568787
Epoch: 164/300 - Train loss: 0.46086058020591736, Validation loss: 0.4653843939304352
Epoch: 165/300 - Train loss: 0.4601384997367859, Validation loss: 0.4641587734222412
Epoch: 166/300 - Train loss: 0.4594145715236664, Validation loss: 0.46372735500335693
Epoch: 167/300 - Train loss: 0.458690345287323, Validation loss: 0.46371662616729736
Epoch: 168/300 - Train loss: 0.4579657316207886, Validation loss: 0.462708055973053
Epoch: 169/300 - Train loss: 0.4572407603263855, Validation loss: 0.461469829082489
Epoch: 170/300 - Train loss: 0.4565155506134033, Validation loss: 0.4614902436733246
Epoch: 171/300 - Train loss: 0.4557914435863495, Validation loss: 0.4609118700027466
Epoch: 172/300 - Train loss: 0.4550674855709076, Validation loss: 0.4601028263568878
Epoch: 173/300 - Train loss: 0.45434293150901794, Validation loss: 0.4588514566421509
Epoch: 174/300 - Train loss: 0.4536161422729492, Validation loss: 0.459175169467926
Epoch: 175/300 - Train loss: 0.45288780331611633, Validation loss: 0.4575934112071991
Epoch: 176/300 - Train loss: 0.45215705037117004, Validation loss: 0.4576338529586792
Epoch: 177/300 - Train loss: 0.4514225423336029, Validation loss: 0.4563639760017395
Epoch: 178/300 - Train loss: 0.4506850242614746, Validation loss: 0.4549407958984375
Epoch: 179/300 - Train loss: 0.44994333386421204, Validation loss: 0.45512276887893677
Epoch: 180/300 - Train loss: 0.44919654726982117, Validation loss: 0.45381298661231995
Epoch: 181/300 - Train loss: 0.44844430685043335, Validation loss: 0.45334210991859436
Epoch: 182/300 - Train loss: 0.44768670201301575, Validation loss: 0.45266035199165344
Epoch: 183/300 - Train loss: 0.44692718982696533, Validation loss: 0.4518529772758484
Epoch: 184/300 - Train loss: 0.4461665451526642, Validation loss: 0.4508797228336334
Epoch: 185/300 - Train loss: 0.445403128862381, Validation loss: 0.4509773850440979
Epoch: 186/300 - Train loss: 0.4446355700492859, Validation loss: 0.45004957914352417
Epoch: 187/300 - Train loss: 0.4438626766204834, Validation loss: 0.44883403182029724
Epoch: 188/300 - Train loss: 0.44308552145957947, Validation loss: 0.44834017753601074
Epoch: 189/300 - Train loss: 0.442306786775589, Validation loss: 0.44774067401885986
Epoch: 190/300 - Train loss: 0.4415261745452881, Validation loss: 0.4470134973526001
Epoch: 191/300 - Train loss: 0.4407440721988678, Validation loss: 0.44626912474632263
Epoch: 192/300 - Train loss: 0.4399634003639221, Validation loss: 0.4448378384113312
Epoch: 193/300 - Train loss: 0.43918272852897644, Validation loss: 0.4443667531013489
Epoch: 194/300 - Train loss: 0.4384009540081024, Validation loss: 0.4439721703529358
Epoch: 195/300 - Train loss: 0.43761539459228516, Validation loss: 0.44260096549987793
Epoch: 196/300 - Train loss: 0.43682870268821716, Validation loss: 0.44183841347694397
Epoch: 197/300 - Train loss: 0.43604350090026855, Validation loss: 0.44137996435165405
Epoch: 198/300 - Train loss: 0.4352589249610901, Validation loss: 0.4406490623950958
Epoch: 199/300 - Train loss: 0.43447640538215637, Validation loss: 0.44019606709480286
Epoch: 200/300 - Train loss: 0.43369725346565247, Validation loss: 0.43954575061798096
Epoch: 201/300 - Train loss: 0.43291959166526794, Validation loss: 0.4381655752658844
Epoch: 202/300 - Train loss: 0.43214336037635803, Validation loss: 0.43786001205444336
Epoch: 203/300 - Train loss: 0.43136662244796753, Validation loss: 0.43727073073387146
Epoch: 204/300 - Train loss: 0.43059152364730835, Validation loss: 0.4365170896053314
Epoch: 205/300 - Train loss: 0.4298180043697357, Validation loss: 0.4358573257923126
Epoch: 206/300 - Train loss: 0.42904648184776306, Validation loss: 0.435339093208313
Epoch: 207/300 - Train loss: 0.4282773435115814, Validation loss: 0.4339480698108673
Epoch: 208/300 - Train loss: 0.4275089204311371, Validation loss: 0.4339882433414459
Epoch: 209/300 - Train loss: 0.42674243450164795, Validation loss: 0.43265581130981445
Epoch: 210/300 - Train loss: 0.42597758769989014, Validation loss: 0.4327307641506195
Epoch: 211/300 - Train loss: 0.42521435022354126, Validation loss: 0.4319705367088318
Epoch: 212/300 - Train loss: 0.424454003572464, Validation loss: 0.43111541867256165
Epoch: 213/300 - Train loss: 0.42369726300239563, Validation loss: 0.43056562542915344
Epoch: 214/300 - Train loss: 0.42294326424598694, Validation loss: 0.4292658567428589
Epoch: 215/300 - Train loss: 0.4221895933151245, Validation loss: 0.42881110310554504
Epoch: 216/300 - Train loss: 0.42143893241882324, Validation loss: 0.42824652791023254
Epoch: 217/300 - Train loss: 0.4206910729408264, Validation loss: 0.42745864391326904
Epoch: 218/300 - Train loss: 0.4199475347995758, Validation loss: 0.4268265664577484
Epoch: 219/300 - Train loss: 0.41920793056488037, Validation loss: 0.4257153272628784
Epoch: 220/300 - Train loss: 0.41847312450408936, Validation loss: 0.4255234897136688
Epoch: 221/300 - Train loss: 0.4177420139312744, Validation loss: 0.4249708950519562
Epoch: 222/300 - Train loss: 0.4170151948928833, Validation loss: 0.4244772493839264
Epoch: 223/300 - Train loss: 0.4162904918193817, Validation loss: 0.42335015535354614
Epoch: 224/300 - Train loss: 0.4155682921409607, Validation loss: 0.4225319027900696
Epoch: 225/300 - Train loss: 0.41484877467155457, Validation loss: 0.4221612811088562
Epoch: 226/300 - Train loss: 0.414133220911026, Validation loss: 0.4212947189807892
Epoch: 227/300 - Train loss: 0.41342198848724365, Validation loss: 0.4217413067817688
Epoch: 228/300 - Train loss: 0.41271382570266724, Validation loss: 0.4203428626060486
Epoch: 229/300 - Train loss: 0.4120083749294281, Validation loss: 0.4192764163017273
Epoch: 230/300 - Train loss: 0.41130656003952026, Validation loss: 0.4188460409641266
Epoch: 231/300 - Train loss: 0.41060858964920044, Validation loss: 0.41859906911849976
Epoch: 232/300 - Train loss: 0.4099145829677582, Validation loss: 0.41744375228881836
Epoch: 233/300 - Train loss: 0.40922510623931885, Validation loss: 0.41703444719314575
Epoch: 234/300 - Train loss: 0.4085390269756317, Validation loss: 0.41665324568748474
Epoch: 235/300 - Train loss: 0.4078562259674072, Validation loss: 0.4156505763530731
Epoch: 236/300 - Train loss: 0.4071776568889618, Validation loss: 0.4148077070713043
Epoch: 237/300 - Train loss: 0.4065018892288208, Validation loss: 0.4146420657634735
Epoch: 238/300 - Train loss: 0.4058300852775574, Validation loss: 0.41405248641967773
Epoch: 239/300 - Train loss: 0.40516218543052673, Validation loss: 0.4139089584350586
