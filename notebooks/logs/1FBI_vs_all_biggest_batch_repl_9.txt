Epoch: 1/300 - Train loss: 0.6946158409118652, Validation loss: 0.6927738189697266
Epoch: 2/300 - Train loss: 0.6918156147003174, Validation loss: 0.6900011301040649
Epoch: 3/300 - Train loss: 0.689020037651062, Validation loss: 0.6869382858276367
Epoch: 4/300 - Train loss: 0.6861705183982849, Validation loss: 0.683922529220581
Epoch: 5/300 - Train loss: 0.6832184791564941, Validation loss: 0.6807091236114502
Epoch: 6/300 - Train loss: 0.6801229119300842, Validation loss: 0.6772904992103577
Epoch: 7/300 - Train loss: 0.676842987537384, Validation loss: 0.6737308502197266
Epoch: 8/300 - Train loss: 0.6733477711677551, Validation loss: 0.6698604822158813
Epoch: 9/300 - Train loss: 0.6696116328239441, Validation loss: 0.665692925453186
Epoch: 10/300 - Train loss: 0.6656269431114197, Validation loss: 0.6613619923591614
Epoch: 11/300 - Train loss: 0.661389946937561, Validation loss: 0.6567380428314209
Epoch: 12/300 - Train loss: 0.6569028496742249, Validation loss: 0.6518945097923279
Epoch: 13/300 - Train loss: 0.6521771550178528, Validation loss: 0.6467599868774414
Epoch: 14/300 - Train loss: 0.6472257971763611, Validation loss: 0.6414195895195007
Epoch: 15/300 - Train loss: 0.6420628428459167, Validation loss: 0.6360870599746704
Epoch: 16/300 - Train loss: 0.6367177367210388, Validation loss: 0.6304040551185608
Epoch: 17/300 - Train loss: 0.6312100291252136, Validation loss: 0.6246151924133301
Epoch: 18/300 - Train loss: 0.625559389591217, Validation loss: 0.6186724305152893
Epoch: 19/300 - Train loss: 0.6197907328605652, Validation loss: 0.612679660320282
Epoch: 20/300 - Train loss: 0.6139132380485535, Validation loss: 0.6066277623176575
Epoch: 21/300 - Train loss: 0.607946515083313, Validation loss: 0.6003918647766113
Epoch: 22/300 - Train loss: 0.6019020676612854, Validation loss: 0.5943315029144287
Epoch: 23/300 - Train loss: 0.5957849025726318, Validation loss: 0.5879942178726196
Epoch: 24/300 - Train loss: 0.5896009802818298, Validation loss: 0.581767737865448
Epoch: 25/300 - Train loss: 0.5833618640899658, Validation loss: 0.5753920078277588
Epoch: 26/300 - Train loss: 0.5770752429962158, Validation loss: 0.5689635276794434
Epoch: 27/300 - Train loss: 0.5707479119300842, Validation loss: 0.5625357627868652
Epoch: 28/300 - Train loss: 0.5643848776817322, Validation loss: 0.5558187365531921
Epoch: 29/300 - Train loss: 0.5579941272735596, Validation loss: 0.5495293736457825
Epoch: 30/300 - Train loss: 0.551581859588623, Validation loss: 0.5431420207023621
Epoch: 31/300 - Train loss: 0.5451513528823853, Validation loss: 0.5365515351295471
Epoch: 32/300 - Train loss: 0.5387094020843506, Validation loss: 0.5301704406738281
Epoch: 33/300 - Train loss: 0.532261073589325, Validation loss: 0.5235447883605957
Epoch: 34/300 - Train loss: 0.5258106589317322, Validation loss: 0.5168595314025879
Epoch: 35/300 - Train loss: 0.5193657279014587, Validation loss: 0.510610044002533
Epoch: 36/300 - Train loss: 0.5129329562187195, Validation loss: 0.5042732357978821
Epoch: 37/300 - Train loss: 0.5065180659294128, Validation loss: 0.49762144684791565
Epoch: 38/300 - Train loss: 0.5001265406608582, Validation loss: 0.4911438822746277
Epoch: 39/300 - Train loss: 0.4937634766101837, Validation loss: 0.4846734404563904
Epoch: 40/300 - Train loss: 0.48743540048599243, Validation loss: 0.47823086380958557
Epoch: 41/300 - Train loss: 0.4811476171016693, Validation loss: 0.472150057554245
Epoch: 42/300 - Train loss: 0.4749053716659546, Validation loss: 0.46589455008506775
Epoch: 43/300 - Train loss: 0.4687140882015228, Validation loss: 0.4595695436000824
Epoch: 44/300 - Train loss: 0.46257975697517395, Validation loss: 0.45375269651412964
Epoch: 45/300 - Train loss: 0.4565068185329437, Validation loss: 0.4475336968898773
Epoch: 46/300 - Train loss: 0.45049986243247986, Validation loss: 0.4415431320667267
Epoch: 47/300 - Train loss: 0.4445626139640808, Validation loss: 0.43560558557510376
Epoch: 48/300 - Train loss: 0.4386994540691376, Validation loss: 0.42971208691596985
Epoch: 49/300 - Train loss: 0.43291327357292175, Validation loss: 0.42437744140625
Epoch: 50/300 - Train loss: 0.4272071123123169, Validation loss: 0.41815900802612305
Epoch: 51/300 - Train loss: 0.4215838313102722, Validation loss: 0.41311872005462646
Epoch: 52/300 - Train loss: 0.41604581475257874, Validation loss: 0.4075051248073578
Epoch: 53/300 - Train loss: 0.4105956256389618, Validation loss: 0.4019552767276764
Epoch: 54/300 - Train loss: 0.40523526072502136, Validation loss: 0.3969261050224304
Epoch: 55/300 - Train loss: 0.39996638894081116, Validation loss: 0.39137667417526245
Epoch: 56/300 - Train loss: 0.3947905898094177, Validation loss: 0.38656896352767944
Epoch: 57/300 - Train loss: 0.3897091746330261, Validation loss: 0.3816511332988739
Epoch: 58/300 - Train loss: 0.38472312688827515, Validation loss: 0.37637996673583984
Epoch: 59/300 - Train loss: 0.3798331916332245, Validation loss: 0.3718588054180145
Epoch: 60/300 - Train loss: 0.3750400245189667, Validation loss: 0.3669857978820801
Epoch: 61/300 - Train loss: 0.37034374475479126, Validation loss: 0.3620504140853882
Epoch: 62/300 - Train loss: 0.36574432253837585, Validation loss: 0.3578382432460785
Epoch: 63/300 - Train loss: 0.3612418472766876, Validation loss: 0.3534277379512787
Epoch: 64/300 - Train loss: 0.35683614015579224, Validation loss: 0.3488847613334656
Epoch: 65/300 - Train loss: 0.35252660512924194, Validation loss: 0.3447284698486328
Epoch: 66/300 - Train loss: 0.3483128249645233, Validation loss: 0.34104159474372864
Epoch: 67/300 - Train loss: 0.344193696975708, Validation loss: 0.3368062973022461
Epoch: 68/300 - Train loss: 0.3401682674884796, Validation loss: 0.33300429582595825
Epoch: 69/300 - Train loss: 0.33623576164245605, Validation loss: 0.3288953900337219
Epoch: 70/300 - Train loss: 0.33239489793777466, Validation loss: 0.3253821134567261
Epoch: 71/300 - Train loss: 0.3286445140838623, Validation loss: 0.32204222679138184
Epoch: 72/300 - Train loss: 0.3249830901622772, Validation loss: 0.31822285056114197
Epoch: 73/300 - Train loss: 0.3214094042778015, Validation loss: 0.31454312801361084
Epoch: 74/300 - Train loss: 0.31792163848876953, Validation loss: 0.31109848618507385
Epoch: 75/300 - Train loss: 0.3145183324813843, Validation loss: 0.3077614903450012
Epoch: 76/300 - Train loss: 0.311197966337204, Validation loss: 0.3047310411930084
Epoch: 77/300 - Train loss: 0.3079589903354645, Validation loss: 0.30155688524246216
Epoch: 78/300 - Train loss: 0.304799884557724, Validation loss: 0.2984681725502014
Epoch: 79/300 - Train loss: 0.3017190098762512, Validation loss: 0.29554498195648193
Epoch: 80/300 - Train loss: 0.2987144887447357, Validation loss: 0.29246729612350464
Epoch: 81/300 - Train loss: 0.29578471183776855, Validation loss: 0.2892826497554779
Epoch: 82/300 - Train loss: 0.2929280698299408, Validation loss: 0.28706127405166626
Epoch: 83/300 - Train loss: 0.29014256596565247, Validation loss: 0.2838222086429596
Epoch: 84/300 - Train loss: 0.28742650151252747, Validation loss: 0.28124168515205383
Epoch: 85/300 - Train loss: 0.2847779393196106, Validation loss: 0.2786094844341278
Epoch: 86/300 - Train loss: 0.28219544887542725, Validation loss: 0.27650758624076843
Epoch: 87/300 - Train loss: 0.27967721223831177, Validation loss: 0.27417436242103577
Epoch: 88/300 - Train loss: 0.2772217392921448, Validation loss: 0.27149009704589844
Epoch: 89/300 - Train loss: 0.2748272120952606, Validation loss: 0.2688677906990051
Epoch: 90/300 - Train loss: 0.2724921703338623, Validation loss: 0.26688480377197266
Epoch: 91/300 - Train loss: 0.27021491527557373, Validation loss: 0.26463282108306885
Epoch: 92/300 - Train loss: 0.2679939270019531, Validation loss: 0.26263898611068726
Epoch: 93/300 - Train loss: 0.26582780480384827, Validation loss: 0.26064759492874146
Epoch: 94/300 - Train loss: 0.26371511816978455, Validation loss: 0.2586791217327118
Epoch: 95/300 - Train loss: 0.26165395975112915, Validation loss: 0.2570490837097168
Epoch: 96/300 - Train loss: 0.25964322686195374, Validation loss: 0.2550853192806244
Epoch: 97/300 - Train loss: 0.2576814591884613, Validation loss: 0.25276979804039
Epoch: 98/300 - Train loss: 0.255767285823822, Validation loss: 0.2510068416595459
Epoch: 99/300 - Train loss: 0.2538994252681732, Validation loss: 0.24911314249038696
Epoch: 100/300 - Train loss: 0.2520766854286194, Validation loss: 0.2474820464849472
Epoch: 101/300 - Train loss: 0.2502976357936859, Validation loss: 0.24553431570529938
Epoch: 102/300 - Train loss: 0.2485610842704773, Validation loss: 0.24399669468402863
Epoch: 103/300 - Train loss: 0.246865913271904, Validation loss: 0.24253380298614502
Epoch: 104/300 - Train loss: 0.2452109158039093, Validation loss: 0.2408970296382904
Epoch: 105/300 - Train loss: 0.24359485507011414, Validation loss: 0.23965340852737427
Epoch: 106/300 - Train loss: 0.24201658368110657, Validation loss: 0.23798690736293793
Epoch: 107/300 - Train loss: 0.240475133061409, Validation loss: 0.2365773767232895
Epoch: 108/300 - Train loss: 0.23896946012973785, Validation loss: 0.23500165343284607
Epoch: 109/300 - Train loss: 0.23749861121177673, Validation loss: 0.23326624929904938
Epoch: 110/300 - Train loss: 0.23606152832508087, Validation loss: 0.23230436444282532
Epoch: 111/300 - Train loss: 0.23465725779533386, Validation loss: 0.23109504580497742
Epoch: 112/300 - Train loss: 0.23328496515750885, Validation loss: 0.22998051345348358
Epoch: 113/300 - Train loss: 0.23194359242916107, Validation loss: 0.22894495725631714
Epoch: 114/300 - Train loss: 0.23063243925571442, Validation loss: 0.22758358716964722
Epoch: 115/300 - Train loss: 0.22935068607330322, Validation loss: 0.2257842868566513
Epoch: 116/300 - Train loss: 0.2280975729227066, Validation loss: 0.224445641040802
Epoch: 117/300 - Train loss: 0.2268722653388977, Validation loss: 0.22344955801963806
Epoch: 118/300 - Train loss: 0.22567400336265564, Validation loss: 0.22265641391277313
Epoch: 119/300 - Train loss: 0.22450202703475952, Validation loss: 0.2212432324886322
Epoch: 120/300 - Train loss: 0.22335566580295563, Validation loss: 0.22049309313297272
Epoch: 121/300 - Train loss: 0.22223424911499023, Validation loss: 0.21914540231227875
Epoch: 122/300 - Train loss: 0.22113707661628723, Validation loss: 0.21810387074947357
Epoch: 123/300 - Train loss: 0.2200634926557541, Validation loss: 0.21707651019096375
Epoch: 124/300 - Train loss: 0.21901293098926544, Validation loss: 0.2161674052476883
Epoch: 125/300 - Train loss: 0.21798472106456757, Validation loss: 0.2152678221464157
Epoch: 126/300 - Train loss: 0.21697819232940674, Validation loss: 0.21374806761741638
Epoch: 127/300 - Train loss: 0.21599286794662476, Validation loss: 0.21357044577598572
Epoch: 128/300 - Train loss: 0.21502824127674103, Validation loss: 0.21204090118408203
Epoch: 129/300 - Train loss: 0.21408377587795258, Validation loss: 0.211527019739151
Epoch: 130/300 - Train loss: 0.21315895020961761, Validation loss: 0.21048541367053986
Epoch: 131/300 - Train loss: 0.21225324273109436, Validation loss: 0.20994384586811066
Epoch: 132/300 - Train loss: 0.2113661915063858, Validation loss: 0.209125816822052
Epoch: 133/300 - Train loss: 0.21049734950065613, Validation loss: 0.20814870297908783
Epoch: 134/300 - Train loss: 0.20964621007442474, Validation loss: 0.20768842101097107
Epoch: 135/300 - Train loss: 0.20881232619285583, Validation loss: 0.2068203240633011
Epoch: 136/300 - Train loss: 0.20799532532691956, Validation loss: 0.20634181797504425
Epoch: 137/300 - Train loss: 0.20719470083713531, Validation loss: 0.20518799126148224
Epoch: 138/300 - Train loss: 0.20641009509563446, Validation loss: 0.2049189954996109
Epoch: 139/300 - Train loss: 0.20564112067222595, Validation loss: 0.20383867621421814
Epoch: 140/300 - Train loss: 0.20488737523555756, Validation loss: 0.20297332108020782
Epoch: 141/300 - Train loss: 0.20414836704730988, Validation loss: 0.20222808420658112
Epoch: 142/300 - Train loss: 0.20342391729354858, Validation loss: 0.20148561894893646
Epoch: 143/300 - Train loss: 0.20271363854408264, Validation loss: 0.20122680068016052
Epoch: 144/300 - Train loss: 0.20201712846755981, Validation loss: 0.20078791677951813
Epoch: 145/300 - Train loss: 0.20133407413959503, Validation loss: 0.20006176829338074
Epoch: 146/300 - Train loss: 0.20066408812999725, Validation loss: 0.1989016830921173
Epoch: 147/300 - Train loss: 0.20000691711902618, Validation loss: 0.1983128935098648
Epoch: 148/300 - Train loss: 0.19936224818229675, Validation loss: 0.19800156354904175
Epoch: 149/300 - Train loss: 0.1987297534942627, Validation loss: 0.19731499254703522
Epoch: 150/300 - Train loss: 0.19810913503170013, Validation loss: 0.1965389996767044
Epoch: 151/300 - Train loss: 0.19750022888183594, Validation loss: 0.196450874209404
Epoch: 152/300 - Train loss: 0.19690267741680145, Validation loss: 0.19595585763454437
Epoch: 153/300 - Train loss: 0.19631628692150116, Validation loss: 0.1950901746749878
Epoch: 154/300 - Train loss: 0.1957407295703888, Validation loss: 0.19472050666809082
Epoch: 155/300 - Train loss: 0.19517582654953003, Validation loss: 0.1939449906349182
