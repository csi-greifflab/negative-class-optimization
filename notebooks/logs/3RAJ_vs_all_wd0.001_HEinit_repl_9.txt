Epoch: 1/300 - Train loss: 0.6938931941986084, Validation loss: 0.6885011792182922
Epoch: 2/300 - Train loss: 0.6918178796768188, Validation loss: 0.6865424513816833
Epoch: 3/300 - Train loss: 0.6897845268249512, Validation loss: 0.6846557259559631
Epoch: 4/300 - Train loss: 0.6877896785736084, Validation loss: 0.6826923489570618
Epoch: 5/300 - Train loss: 0.6858246326446533, Validation loss: 0.6807546019554138
Epoch: 6/300 - Train loss: 0.6838856339454651, Validation loss: 0.6788787841796875
Epoch: 7/300 - Train loss: 0.6819659471511841, Validation loss: 0.6770836114883423
Epoch: 8/300 - Train loss: 0.6800557374954224, Validation loss: 0.6751859784126282
Epoch: 9/300 - Train loss: 0.678141176700592, Validation loss: 0.6732334494590759
Epoch: 10/300 - Train loss: 0.6762152314186096, Validation loss: 0.6712980270385742
Epoch: 11/300 - Train loss: 0.6742666959762573, Validation loss: 0.6693161129951477
Epoch: 12/300 - Train loss: 0.6722954511642456, Validation loss: 0.6673252582550049
Epoch: 13/300 - Train loss: 0.6702948808670044, Validation loss: 0.6652605533599854
Epoch: 14/300 - Train loss: 0.6682599186897278, Validation loss: 0.6630755066871643
Epoch: 15/300 - Train loss: 0.6661837100982666, Validation loss: 0.6609528660774231
Epoch: 16/300 - Train loss: 0.6640697121620178, Validation loss: 0.6589271426200867
Epoch: 17/300 - Train loss: 0.6619135141372681, Validation loss: 0.6564470529556274
Epoch: 18/300 - Train loss: 0.6597126126289368, Validation loss: 0.6540927886962891
Epoch: 19/300 - Train loss: 0.6574640274047852, Validation loss: 0.6518328189849854
Epoch: 20/300 - Train loss: 0.655166506767273, Validation loss: 0.6493912935256958
Epoch: 21/300 - Train loss: 0.6528213620185852, Validation loss: 0.6469732522964478
Epoch: 22/300 - Train loss: 0.6504355072975159, Validation loss: 0.6444894671440125
Epoch: 23/300 - Train loss: 0.6480111479759216, Validation loss: 0.6422417163848877
Epoch: 24/300 - Train loss: 0.6455494165420532, Validation loss: 0.6394389867782593
Epoch: 25/300 - Train loss: 0.6430513858795166, Validation loss: 0.6367194652557373
Epoch: 26/300 - Train loss: 0.640523374080658, Validation loss: 0.6341533064842224
Epoch: 27/300 - Train loss: 0.6379706859588623, Validation loss: 0.6316820383071899
Epoch: 28/300 - Train loss: 0.6353955864906311, Validation loss: 0.6290763020515442
Epoch: 29/300 - Train loss: 0.6328011155128479, Validation loss: 0.6261716485023499
Epoch: 30/300 - Train loss: 0.6301919221878052, Validation loss: 0.623645544052124
Epoch: 31/300 - Train loss: 0.6275725960731506, Validation loss: 0.6210373044013977
Epoch: 32/300 - Train loss: 0.6249455213546753, Validation loss: 0.6183747053146362
Epoch: 33/300 - Train loss: 0.6223092079162598, Validation loss: 0.6157982349395752
Epoch: 34/300 - Train loss: 0.6196778416633606, Validation loss: 0.6130770444869995
Epoch: 35/300 - Train loss: 0.6170562505722046, Validation loss: 0.6106324195861816
Epoch: 36/300 - Train loss: 0.6144460439682007, Validation loss: 0.6076478362083435
Epoch: 37/300 - Train loss: 0.6118492484092712, Validation loss: 0.6051703691482544
Epoch: 38/300 - Train loss: 0.6092715263366699, Validation loss: 0.6024959087371826
Epoch: 39/300 - Train loss: 0.6067109704017639, Validation loss: 0.5999035835266113
Epoch: 40/300 - Train loss: 0.604173481464386, Validation loss: 0.5977067351341248
Epoch: 41/300 - Train loss: 0.6016600131988525, Validation loss: 0.5950115323066711
Epoch: 42/300 - Train loss: 0.5991764068603516, Validation loss: 0.592563271522522
Epoch: 43/300 - Train loss: 0.5967236161231995, Validation loss: 0.5905783176422119
Epoch: 44/300 - Train loss: 0.5943030118942261, Validation loss: 0.5877271890640259
Epoch: 45/300 - Train loss: 0.5919165015220642, Validation loss: 0.5855214595794678
Epoch: 46/300 - Train loss: 0.5895652174949646, Validation loss: 0.5833059549331665
Epoch: 47/300 - Train loss: 0.5872507095336914, Validation loss: 0.5808032751083374
Epoch: 48/300 - Train loss: 0.5849738717079163, Validation loss: 0.5789938569068909
Epoch: 49/300 - Train loss: 0.5827357172966003, Validation loss: 0.5770984292030334
Epoch: 50/300 - Train loss: 0.5805386304855347, Validation loss: 0.5746506452560425
Epoch: 51/300 - Train loss: 0.5783838033676147, Validation loss: 0.5727031826972961
Epoch: 52/300 - Train loss: 0.5762706398963928, Validation loss: 0.5705931782722473
Epoch: 53/300 - Train loss: 0.5741991996765137, Validation loss: 0.5688724517822266
Epoch: 54/300 - Train loss: 0.5721673965454102, Validation loss: 0.5671351552009583
Epoch: 55/300 - Train loss: 0.570174515247345, Validation loss: 0.5652797222137451
Epoch: 56/300 - Train loss: 0.5682215690612793, Validation loss: 0.5636109113693237
Epoch: 57/300 - Train loss: 0.5663069486618042, Validation loss: 0.5614657998085022
Epoch: 58/300 - Train loss: 0.5644299387931824, Validation loss: 0.5597307085990906
Epoch: 59/300 - Train loss: 0.5625897645950317, Validation loss: 0.5584678053855896
Epoch: 60/300 - Train loss: 0.560785710811615, Validation loss: 0.5562162399291992
Epoch: 61/300 - Train loss: 0.5590175986289978, Validation loss: 0.5549577474594116
Epoch: 62/300 - Train loss: 0.5572834610939026, Validation loss: 0.5534943342208862
Epoch: 63/300 - Train loss: 0.5555812120437622, Validation loss: 0.5519137382507324
Epoch: 64/300 - Train loss: 0.5539103150367737, Validation loss: 0.5501896142959595
Epoch: 65/300 - Train loss: 0.5522713661193848, Validation loss: 0.5488814115524292
Epoch: 66/300 - Train loss: 0.550663411617279, Validation loss: 0.5475791692733765
Epoch: 67/300 - Train loss: 0.5490847229957581, Validation loss: 0.5464351773262024
Epoch: 68/300 - Train loss: 0.5475338101387024, Validation loss: 0.5445255041122437
Epoch: 69/300 - Train loss: 0.5460091829299927, Validation loss: 0.5433271527290344
Epoch: 70/300 - Train loss: 0.5445098876953125, Validation loss: 0.5422796010971069
Epoch: 71/300 - Train loss: 0.5430347919464111, Validation loss: 0.5405415296554565
Epoch: 72/300 - Train loss: 0.5415822863578796, Validation loss: 0.5392175316810608
Epoch: 73/300 - Train loss: 0.5401529669761658, Validation loss: 0.5385010838508606
Epoch: 74/300 - Train loss: 0.5387459397315979, Validation loss: 0.5374289155006409
Epoch: 75/300 - Train loss: 0.5373604893684387, Validation loss: 0.535851001739502
Epoch: 76/300 - Train loss: 0.5359950661659241, Validation loss: 0.5342420935630798
Epoch: 77/300 - Train loss: 0.5346497297286987, Validation loss: 0.5329181551933289
Epoch: 78/300 - Train loss: 0.5333238840103149, Validation loss: 0.5317991375923157
Epoch: 79/300 - Train loss: 0.5320148468017578, Validation loss: 0.5306970477104187
Epoch: 80/300 - Train loss: 0.5307225584983826, Validation loss: 0.5295977592468262
Epoch: 81/300 - Train loss: 0.5294466614723206, Validation loss: 0.5285376310348511
Epoch: 82/300 - Train loss: 0.52818763256073, Validation loss: 0.5275132656097412
Epoch: 83/300 - Train loss: 0.5269442796707153, Validation loss: 0.5266392230987549
Epoch: 84/300 - Train loss: 0.5257161259651184, Validation loss: 0.5251862406730652
Epoch: 85/300 - Train loss: 0.524500846862793, Validation loss: 0.5240539908409119
Epoch: 86/300 - Train loss: 0.523299515247345, Validation loss: 0.5234300494194031
Epoch: 87/300 - Train loss: 0.5221110582351685, Validation loss: 0.5216667056083679
Epoch: 88/300 - Train loss: 0.5209352970123291, Validation loss: 0.5204309821128845
Epoch: 89/300 - Train loss: 0.5197703838348389, Validation loss: 0.519380509853363
Epoch: 90/300 - Train loss: 0.5186164379119873, Validation loss: 0.5185473561286926
Epoch: 91/300 - Train loss: 0.5174720883369446, Validation loss: 0.5171810388565063
Epoch: 92/300 - Train loss: 0.5163356065750122, Validation loss: 0.5159740447998047
Epoch: 93/300 - Train loss: 0.5152075290679932, Validation loss: 0.5157467126846313
Epoch: 94/300 - Train loss: 0.5140885710716248, Validation loss: 0.5145281553268433
Epoch: 95/300 - Train loss: 0.512977659702301, Validation loss: 0.5128418207168579
Epoch: 96/300 - Train loss: 0.5118729472160339, Validation loss: 0.5130040049552917
Epoch: 97/300 - Train loss: 0.5107744336128235, Validation loss: 0.5113668441772461
Epoch: 98/300 - Train loss: 0.5096828937530518, Validation loss: 0.5105170011520386
Epoch: 99/300 - Train loss: 0.5085981488227844, Validation loss: 0.5091803073883057
Epoch: 100/300 - Train loss: 0.507519006729126, Validation loss: 0.5087209343910217
Epoch: 101/300 - Train loss: 0.5064451098442078, Validation loss: 0.5070528984069824
Epoch: 102/300 - Train loss: 0.5053770542144775, Validation loss: 0.506842851638794
Epoch: 103/300 - Train loss: 0.5043144226074219, Validation loss: 0.505252480506897
Epoch: 104/300 - Train loss: 0.5032581090927124, Validation loss: 0.503970742225647
Epoch: 105/300 - Train loss: 0.5022086501121521, Validation loss: 0.5034359693527222
Epoch: 106/300 - Train loss: 0.5011659860610962, Validation loss: 0.5022649168968201
Epoch: 107/300 - Train loss: 0.5001285076141357, Validation loss: 0.501737654209137
Epoch: 108/300 - Train loss: 0.49909812211990356, Validation loss: 0.5008083581924438
Epoch: 109/300 - Train loss: 0.49807223677635193, Validation loss: 0.49959155917167664
Epoch: 110/300 - Train loss: 0.4970497190952301, Validation loss: 0.49828648567199707
Epoch: 111/300 - Train loss: 0.4960304796695709, Validation loss: 0.4971790611743927
Epoch: 112/300 - Train loss: 0.4950138330459595, Validation loss: 0.49675363302230835
Epoch: 113/300 - Train loss: 0.4939999580383301, Validation loss: 0.49530676007270813
Epoch: 114/300 - Train loss: 0.49298909306526184, Validation loss: 0.49441009759902954
Epoch: 115/300 - Train loss: 0.4919814467430115, Validation loss: 0.4932623505592346
Epoch: 116/300 - Train loss: 0.4909762442111969, Validation loss: 0.4925478994846344
Epoch: 117/300 - Train loss: 0.4899751842021942, Validation loss: 0.4915991425514221
Epoch: 118/300 - Train loss: 0.4889780580997467, Validation loss: 0.49111253023147583
Epoch: 119/300 - Train loss: 0.4879843294620514, Validation loss: 0.49030789732933044
Epoch: 120/300 - Train loss: 0.4869939684867859, Validation loss: 0.4885725975036621
Epoch: 121/300 - Train loss: 0.4860079288482666, Validation loss: 0.4880206286907196
Epoch: 122/300 - Train loss: 0.4850253164768219, Validation loss: 0.4870957136154175
Epoch: 123/300 - Train loss: 0.4840463399887085, Validation loss: 0.4856570065021515
Epoch: 124/300 - Train loss: 0.48306983709335327, Validation loss: 0.48473674058914185
Epoch: 125/300 - Train loss: 0.48209476470947266, Validation loss: 0.4843534827232361
Epoch: 126/300 - Train loss: 0.48112061619758606, Validation loss: 0.4830636978149414
Epoch: 127/300 - Train loss: 0.4801490008831024, Validation loss: 0.48212090134620667
Epoch: 128/300 - Train loss: 0.47917893528938293, Validation loss: 0.4821488857269287
Epoch: 129/300 - Train loss: 0.47821006178855896, Validation loss: 0.48066744208335876
Epoch: 130/300 - Train loss: 0.47724106907844543, Validation loss: 0.4789656400680542
Epoch: 131/300 - Train loss: 0.4762730598449707, Validation loss: 0.47875458002090454
Epoch: 132/300 - Train loss: 0.4753071069717407, Validation loss: 0.4780498445034027
Epoch: 133/300 - Train loss: 0.4743421971797943, Validation loss: 0.47697895765304565
Epoch: 134/300 - Train loss: 0.4733780026435852, Validation loss: 0.47570839524269104
Epoch: 135/300 - Train loss: 0.472413569688797, Validation loss: 0.47483307123184204
Epoch: 136/300 - Train loss: 0.47144895792007446, Validation loss: 0.47422125935554504
Epoch: 137/300 - Train loss: 0.47048458456993103, Validation loss: 0.47338277101516724
Epoch: 138/300 - Train loss: 0.46951937675476074, Validation loss: 0.4728303849697113
Epoch: 139/300 - Train loss: 0.46855291724205017, Validation loss: 0.47094157338142395
Epoch: 140/300 - Train loss: 0.4675879180431366, Validation loss: 0.4705439507961273
Epoch: 141/300 - Train loss: 0.46662411093711853, Validation loss: 0.469718873500824
Epoch: 142/300 - Train loss: 0.46566155552864075, Validation loss: 0.4690321087837219
Epoch: 143/300 - Train loss: 0.46469926834106445, Validation loss: 0.4678201973438263
Epoch: 144/300 - Train loss: 0.4637400805950165, Validation loss: 0.4667729437351227
Epoch: 145/300 - Train loss: 0.4627803862094879, Validation loss: 0.46619829535484314
Epoch: 146/300 - Train loss: 0.4618211090564728, Validation loss: 0.465805321931839
Epoch: 147/300 - Train loss: 0.4608648121356964, Validation loss: 0.4648984968662262
Epoch: 148/300 - Train loss: 0.4599106013774872, Validation loss: 0.46367424726486206
Epoch: 149/300 - Train loss: 0.45895904302597046, Validation loss: 0.4624306857585907
Epoch: 150/300 - Train loss: 0.45800966024398804, Validation loss: 0.4616212546825409
Epoch: 151/300 - Train loss: 0.457062691450119, Validation loss: 0.4613601863384247
Epoch: 152/300 - Train loss: 0.45611870288848877, Validation loss: 0.46028783917427063
Epoch: 153/300 - Train loss: 0.45517829060554504, Validation loss: 0.4594336152076721
Epoch: 154/300 - Train loss: 0.45424073934555054, Validation loss: 0.4585253596305847
Epoch: 155/300 - Train loss: 0.453307181596756, Validation loss: 0.4573359489440918
Epoch: 156/300 - Train loss: 0.45237788558006287, Validation loss: 0.4566228687763214
Epoch: 157/300 - Train loss: 0.45145222544670105, Validation loss: 0.45550811290740967
Epoch: 158/300 - Train loss: 0.4505287706851959, Validation loss: 0.45497819781303406
Epoch: 159/300 - Train loss: 0.44960862398147583, Validation loss: 0.45393434166908264
Epoch: 160/300 - Train loss: 0.44869303703308105, Validation loss: 0.4529348313808441
Epoch: 161/300 - Train loss: 0.4477815628051758, Validation loss: 0.45186907052993774
Epoch: 162/300 - Train loss: 0.44687360525131226, Validation loss: 0.45098280906677246
Epoch: 163/300 - Train loss: 0.44596779346466064, Validation loss: 0.45101529359817505
Epoch: 164/300 - Train loss: 0.4450647830963135, Validation loss: 0.45016807317733765
Epoch: 165/300 - Train loss: 0.44416487216949463, Validation loss: 0.448292076587677
Epoch: 166/300 - Train loss: 0.44326910376548767, Validation loss: 0.4477379620075226
Epoch: 167/300 - Train loss: 0.44237828254699707, Validation loss: 0.44712314009666443
Epoch: 168/300 - Train loss: 0.4414926767349243, Validation loss: 0.4462515413761139
Epoch: 169/300 - Train loss: 0.44061094522476196, Validation loss: 0.44524097442626953
Epoch: 170/300 - Train loss: 0.4397338330745697, Validation loss: 0.44481146335601807
Epoch: 171/300 - Train loss: 0.43886080384254456, Validation loss: 0.4434358477592468
Epoch: 172/300 - Train loss: 0.4379911422729492, Validation loss: 0.44285106658935547
Epoch: 173/300 - Train loss: 0.4371238350868225, Validation loss: 0.44235125184059143
Epoch: 174/300 - Train loss: 0.4362601041793823, Validation loss: 0.44176414608955383
Epoch: 175/300 - Train loss: 0.43540093302726746, Validation loss: 0.44031649827957153
Epoch: 176/300 - Train loss: 0.43454569578170776, Validation loss: 0.4395557641983032
Epoch: 177/300 - Train loss: 0.43369460105895996, Validation loss: 0.43915969133377075
Epoch: 178/300 - Train loss: 0.43284714221954346, Validation loss: 0.4380427896976471
Epoch: 179/300 - Train loss: 0.4320034086704254, Validation loss: 0.4374934136867523
Epoch: 180/300 - Train loss: 0.4311628043651581, Validation loss: 0.437090128660202
Epoch: 181/300 - Train loss: 0.43032407760620117, Validation loss: 0.43579021096229553
Epoch: 182/300 - Train loss: 0.42948853969573975, Validation loss: 0.4346679747104645
Epoch: 183/300 - Train loss: 0.4286556541919708, Validation loss: 0.4337407648563385
Epoch: 184/300 - Train loss: 0.42782577872276306, Validation loss: 0.4336533546447754
Epoch: 185/300 - Train loss: 0.4269987940788269, Validation loss: 0.4326726794242859
Epoch: 186/300 - Train loss: 0.4261746406555176, Validation loss: 0.43181437253952026
Epoch: 187/300 - Train loss: 0.4253535568714142, Validation loss: 0.43117615580558777
Epoch: 188/300 - Train loss: 0.4245349168777466, Validation loss: 0.4302060604095459
Epoch: 189/300 - Train loss: 0.42371851205825806, Validation loss: 0.4296637177467346
Epoch: 190/300 - Train loss: 0.42290574312210083, Validation loss: 0.42861729860305786
Epoch: 191/300 - Train loss: 0.4220958948135376, Validation loss: 0.4273815453052521
Epoch: 192/300 - Train loss: 0.4212891161441803, Validation loss: 0.42733967304229736
Epoch: 193/300 - Train loss: 0.4204857349395752, Validation loss: 0.4260615110397339
Epoch: 194/300 - Train loss: 0.41968563199043274, Validation loss: 0.42551130056381226
Epoch: 195/300 - Train loss: 0.4188883900642395, Validation loss: 0.42518913745880127
Epoch: 196/300 - Train loss: 0.4180943965911865, Validation loss: 0.4237118661403656
Epoch: 197/300 - Train loss: 0.4173045754432678, Validation loss: 0.42372819781303406
Epoch: 198/300 - Train loss: 0.416517972946167, Validation loss: 0.42279568314552307
Epoch: 199/300 - Train loss: 0.4157348573207855, Validation loss: 0.4220639765262604
Epoch: 200/300 - Train loss: 0.41495612263679504, Validation loss: 0.4211253225803375
Epoch: 201/300 - Train loss: 0.41417938470840454, Validation loss: 0.42019543051719666
Epoch: 202/300 - Train loss: 0.4134051501750946, Validation loss: 0.4188123047351837
Epoch: 203/300 - Train loss: 0.4126340448856354, Validation loss: 0.41855478286743164
Epoch: 204/300 - Train loss: 0.41186583042144775, Validation loss: 0.4179602563381195
Epoch: 205/300 - Train loss: 0.41110098361968994, Validation loss: 0.4173789322376251
Epoch: 206/300 - Train loss: 0.4103394150733948, Validation loss: 0.4165889620780945
Epoch: 207/300 - Train loss: 0.40958172082901, Validation loss: 0.4155344069004059
Epoch: 208/300 - Train loss: 0.40882807970046997, Validation loss: 0.41475772857666016
Epoch: 209/300 - Train loss: 0.40807825326919556, Validation loss: 0.41439494490623474
Epoch: 210/300 - Train loss: 0.40733128786087036, Validation loss: 0.41333356499671936
Epoch: 211/300 - Train loss: 0.4065881371498108, Validation loss: 0.4130193293094635
Epoch: 212/300 - Train loss: 0.40584829449653625, Validation loss: 0.41203704476356506
Epoch: 213/300 - Train loss: 0.4051118791103363, Validation loss: 0.41190171241760254
Epoch: 214/300 - Train loss: 0.40437865257263184, Validation loss: 0.41097158193588257
Epoch: 215/300 - Train loss: 0.40364813804626465, Validation loss: 0.4095415771007538
Epoch: 216/300 - Train loss: 0.4029211699962616, Validation loss: 0.4093300402164459
Epoch: 217/300 - Train loss: 0.4021969735622406, Validation loss: 0.4086657762527466
Epoch: 218/300 - Train loss: 0.4014761745929718, Validation loss: 0.4081575274467468
Epoch: 219/300 - Train loss: 0.4007583558559418, Validation loss: 0.4072282910346985
Epoch: 220/300 - Train loss: 0.40004393458366394, Validation loss: 0.4064904451370239
Epoch: 221/300 - Train loss: 0.3993324041366577, Validation loss: 0.406183123588562
Epoch: 222/300 - Train loss: 0.3986237049102783, Validation loss: 0.40488240122795105
Epoch: 223/300 - Train loss: 0.39791691303253174, Validation loss: 0.40445345640182495
Epoch: 224/300 - Train loss: 0.3972131907939911, Validation loss: 0.4034506678581238
Epoch: 225/300 - Train loss: 0.39651232957839966, Validation loss: 0.40310874581336975
Epoch: 226/300 - Train loss: 0.39581364393234253, Validation loss: 0.4022912085056305
Epoch: 227/300 - Train loss: 0.39511799812316895, Validation loss: 0.4017188847064972
Epoch: 228/300 - Train loss: 0.3944258689880371, Validation loss: 0.4011995196342468
Epoch: 229/300 - Train loss: 0.3937363028526306, Validation loss: 0.40045666694641113
Epoch: 230/300 - Train loss: 0.39304840564727783, Validation loss: 0.40008655190467834
Epoch: 231/300 - Train loss: 0.3923625349998474, Validation loss: 0.39974328875541687
Epoch: 232/300 - Train loss: 0.39167720079421997, Validation loss: 0.39831849932670593
Epoch: 233/300 - Train loss: 0.3909919857978821, Validation loss: 0.3979816138744354
Epoch: 234/300 - Train loss: 0.39030832052230835, Validation loss: 0.39705219864845276
Epoch: 235/300 - Train loss: 0.38962629437446594, Validation loss: 0.3968905806541443
Epoch: 236/300 - Train loss: 0.38894525170326233, Validation loss: 0.3960351347923279
Epoch: 237/300 - Train loss: 0.3882666826248169, Validation loss: 0.39550143480300903
Epoch: 238/300 - Train loss: 0.38758987188339233, Validation loss: 0.3942294120788574
Epoch: 239/300 - Train loss: 0.38691383600234985, Validation loss: 0.39365139603614807
Epoch: 240/300 - Train loss: 0.38623902201652527, Validation loss: 0.3932434022426605
Epoch: 241/300 - Train loss: 0.38556593656539917, Validation loss: 0.3927517533302307
Epoch: 242/300 - Train loss: 0.3848937749862671, Validation loss: 0.39277711510658264
Epoch: 243/300 - Train loss: 0.38422146439552307, Validation loss: 0.3908853530883789
Epoch: 244/300 - Train loss: 0.3835502564907074, Validation loss: 0.3906550705432892
Epoch: 245/300 - Train loss: 0.3828800618648529, Validation loss: 0.3903351128101349
Epoch: 246/300 - Train loss: 0.3822101056575775, Validation loss: 0.38890179991722107
Epoch: 247/300 - Train loss: 0.3815402388572693, Validation loss: 0.38858523964881897
Epoch: 248/300 - Train loss: 0.3808693587779999, Validation loss: 0.3878127932548523
Epoch: 249/300 - Train loss: 0.380199670791626, Validation loss: 0.38701069355010986
Epoch: 250/300 - Train loss: 0.3795315623283386, Validation loss: 0.3867063522338867
Epoch: 251/300 - Train loss: 0.3788644075393677, Validation loss: 0.3862539827823639
Epoch: 252/300 - Train loss: 0.37819892168045044, Validation loss: 0.384917289018631
Epoch: 253/300 - Train loss: 0.3775366544723511, Validation loss: 0.3843761384487152
Epoch: 254/300 - Train loss: 0.37687739729881287, Validation loss: 0.38410860300064087
Epoch: 255/300 - Train loss: 0.37622180581092834, Validation loss: 0.3839041590690613
