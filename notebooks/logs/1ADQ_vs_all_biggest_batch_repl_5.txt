Epoch: 1/100 - Train loss: 0.6992378234863281, Validation loss: 0.696054220199585
Epoch: 2/100 - Train loss: 0.6970781087875366, Validation loss: 0.6941506266593933
Epoch: 3/100 - Train loss: 0.6949878931045532, Validation loss: 0.692272424697876
Epoch: 4/100 - Train loss: 0.6929430961608887, Validation loss: 0.6903815269470215
Epoch: 5/100 - Train loss: 0.6909149289131165, Validation loss: 0.6884603500366211
Epoch: 6/100 - Train loss: 0.688872218132019, Validation loss: 0.6865598559379578
Epoch: 7/100 - Train loss: 0.6867893934249878, Validation loss: 0.6844913959503174
Epoch: 8/100 - Train loss: 0.684643566608429, Validation loss: 0.6823658347129822
Epoch: 9/100 - Train loss: 0.6824182868003845, Validation loss: 0.6800932884216309
Epoch: 10/100 - Train loss: 0.6801013946533203, Validation loss: 0.6778150200843811
Epoch: 11/100 - Train loss: 0.6776822805404663, Validation loss: 0.6754141449928284
Epoch: 12/100 - Train loss: 0.675157368183136, Validation loss: 0.6729691624641418
Epoch: 13/100 - Train loss: 0.6725363731384277, Validation loss: 0.6703314781188965
Epoch: 14/100 - Train loss: 0.6698141098022461, Validation loss: 0.6676467061042786
Epoch: 15/100 - Train loss: 0.6669910550117493, Validation loss: 0.6648725867271423
Epoch: 16/100 - Train loss: 0.664077639579773, Validation loss: 0.6620303988456726
Epoch: 17/100 - Train loss: 0.6610906720161438, Validation loss: 0.6591366529464722
Epoch: 18/100 - Train loss: 0.6580396294593811, Validation loss: 0.6561084985733032
Epoch: 19/100 - Train loss: 0.6549311876296997, Validation loss: 0.6531285047531128
Epoch: 20/100 - Train loss: 0.6517675518989563, Validation loss: 0.6499508619308472
Epoch: 21/100 - Train loss: 0.6485656499862671, Validation loss: 0.6468607187271118
Epoch: 22/100 - Train loss: 0.6453297138214111, Validation loss: 0.6436561346054077
Epoch: 23/100 - Train loss: 0.6420714259147644, Validation loss: 0.6406165361404419
Epoch: 24/100 - Train loss: 0.638802707195282, Validation loss: 0.6375826597213745
Epoch: 25/100 - Train loss: 0.6355276107788086, Validation loss: 0.6342427134513855
Epoch: 26/100 - Train loss: 0.6322502493858337, Validation loss: 0.631102979183197
Epoch: 27/100 - Train loss: 0.628973662853241, Validation loss: 0.6281554102897644
Epoch: 28/100 - Train loss: 0.6256996393203735, Validation loss: 0.6247878074645996
Epoch: 29/100 - Train loss: 0.6224313974380493, Validation loss: 0.6217417120933533
Epoch: 30/100 - Train loss: 0.6191745400428772, Validation loss: 0.6186565160751343
Epoch: 31/100 - Train loss: 0.6159310936927795, Validation loss: 0.6156337857246399
Epoch: 32/100 - Train loss: 0.6127046942710876, Validation loss: 0.6124732494354248
Epoch: 33/100 - Train loss: 0.6094979643821716, Validation loss: 0.6093354225158691
Epoch: 34/100 - Train loss: 0.6063151359558105, Validation loss: 0.6062377691268921
Epoch: 35/100 - Train loss: 0.6031584739685059, Validation loss: 0.6033350229263306
Epoch: 36/100 - Train loss: 0.6000329256057739, Validation loss: 0.6006817817687988
Epoch: 37/100 - Train loss: 0.5969418883323669, Validation loss: 0.5975757837295532
Epoch: 38/100 - Train loss: 0.5938887596130371, Validation loss: 0.5948247909545898
Epoch: 39/100 - Train loss: 0.5908752679824829, Validation loss: 0.5920111536979675
Epoch: 40/100 - Train loss: 0.5879037976264954, Validation loss: 0.5889918804168701
Epoch: 41/100 - Train loss: 0.5849771499633789, Validation loss: 0.586117148399353
Epoch: 42/100 - Train loss: 0.58209627866745, Validation loss: 0.5834046602249146
Epoch: 43/100 - Train loss: 0.5792632102966309, Validation loss: 0.5813085436820984
Epoch: 44/100 - Train loss: 0.576479971408844, Validation loss: 0.5780730843544006
Epoch: 45/100 - Train loss: 0.5737482905387878, Validation loss: 0.5755602717399597
Epoch: 46/100 - Train loss: 0.571068286895752, Validation loss: 0.5733898282051086
Epoch: 47/100 - Train loss: 0.5684412121772766, Validation loss: 0.5710943341255188
Epoch: 48/100 - Train loss: 0.5658683180809021, Validation loss: 0.5684458017349243
Epoch: 49/100 - Train loss: 0.563349723815918, Validation loss: 0.565685510635376
Epoch: 50/100 - Train loss: 0.5608865022659302, Validation loss: 0.5637332797050476
Epoch: 51/100 - Train loss: 0.5584796667098999, Validation loss: 0.5616627931594849
Epoch: 52/100 - Train loss: 0.5561289191246033, Validation loss: 0.5592174530029297
Epoch: 53/100 - Train loss: 0.5538336038589478, Validation loss: 0.5572734475135803
Epoch: 54/100 - Train loss: 0.5515937209129333, Validation loss: 0.5552995204925537
Epoch: 55/100 - Train loss: 0.5494090914726257, Validation loss: 0.5531254410743713
Epoch: 56/100 - Train loss: 0.547278642654419, Validation loss: 0.5508856773376465
Epoch: 57/100 - Train loss: 0.5452017784118652, Validation loss: 0.5488751530647278
Epoch: 58/100 - Train loss: 0.5431783199310303, Validation loss: 0.5467998385429382
Epoch: 59/100 - Train loss: 0.5412076711654663, Validation loss: 0.5455300211906433
Epoch: 60/100 - Train loss: 0.5392892956733704, Validation loss: 0.5434585213661194
Epoch: 61/100 - Train loss: 0.5374221801757812, Validation loss: 0.5418061017990112
Epoch: 62/100 - Train loss: 0.5356051921844482, Validation loss: 0.5401178002357483
Epoch: 63/100 - Train loss: 0.533838152885437, Validation loss: 0.5385295152664185
Epoch: 64/100 - Train loss: 0.5321203470230103, Validation loss: 0.5368799567222595
Epoch: 65/100 - Train loss: 0.5304501056671143, Validation loss: 0.535561203956604
Epoch: 66/100 - Train loss: 0.5288262963294983, Validation loss: 0.5344955921173096
Epoch: 67/100 - Train loss: 0.5272470712661743, Validation loss: 0.5325336456298828
Epoch: 68/100 - Train loss: 0.5257118344306946, Validation loss: 0.5311937928199768
Epoch: 69/100 - Train loss: 0.5242181420326233, Validation loss: 0.5295387506484985
Epoch: 70/100 - Train loss: 0.5227641463279724, Validation loss: 0.5282816290855408
Epoch: 71/100 - Train loss: 0.521349310874939, Validation loss: 0.5275662541389465
Epoch: 72/100 - Train loss: 0.5199728608131409, Validation loss: 0.5261539220809937
Epoch: 73/100 - Train loss: 0.5186319351196289, Validation loss: 0.5247636437416077
Epoch: 74/100 - Train loss: 0.5173256397247314, Validation loss: 0.5235580801963806
Epoch: 75/100 - Train loss: 0.516053318977356, Validation loss: 0.5222863554954529
Epoch: 76/100 - Train loss: 0.5148134827613831, Validation loss: 0.5211395621299744
Epoch: 77/100 - Train loss: 0.5136049389839172, Validation loss: 0.5198487639427185
Epoch: 78/100 - Train loss: 0.51242595911026, Validation loss: 0.5189449191093445
Epoch: 79/100 - Train loss: 0.5112752914428711, Validation loss: 0.5181524753570557
Epoch: 80/100 - Train loss: 0.5101521015167236, Validation loss: 0.516373336315155
Epoch: 81/100 - Train loss: 0.5090550780296326, Validation loss: 0.516127347946167
Epoch: 82/100 - Train loss: 0.5079826712608337, Validation loss: 0.5153825879096985
Epoch: 83/100 - Train loss: 0.5069329142570496, Validation loss: 0.5139870643615723
Epoch: 84/100 - Train loss: 0.5059043765068054, Validation loss: 0.5131765604019165
Epoch: 85/100 - Train loss: 0.504898190498352, Validation loss: 0.5122193694114685
Epoch: 86/100 - Train loss: 0.5039132833480835, Validation loss: 0.5113560557365417
Epoch: 87/100 - Train loss: 0.5029469132423401, Validation loss: 0.510320782661438
Epoch: 88/100 - Train loss: 0.5019991397857666, Validation loss: 0.5098259449005127
Epoch: 89/100 - Train loss: 0.5010674595832825, Validation loss: 0.5083314180374146
Epoch: 90/100 - Train loss: 0.5001528263092041, Validation loss: 0.5079540610313416
Epoch: 91/100 - Train loss: 0.49925315380096436, Validation loss: 0.5065596103668213
Epoch: 92/100 - Train loss: 0.4983676075935364, Validation loss: 0.5063439011573792
Epoch: 93/100 - Train loss: 0.49749574065208435, Validation loss: 0.5050709247589111
Epoch: 94/100 - Train loss: 0.49663934111595154, Validation loss: 0.5041642785072327
Epoch: 95/100 - Train loss: 0.4957957863807678, Validation loss: 0.5039122104644775
Epoch: 96/100 - Train loss: 0.4949626326560974, Validation loss: 0.5027912259101868
Epoch: 97/100 - Train loss: 0.4941402077674866, Validation loss: 0.5023491382598877
Epoch: 98/100 - Train loss: 0.49332764744758606, Validation loss: 0.501262903213501
Epoch: 99/100 - Train loss: 0.49252450466156006, Validation loss: 0.5008518099784851
Epoch: 100/100 - Train loss: 0.49172884225845337, Validation loss: 0.50014328956604
Epoch: 1/300 - Train loss: 0.7054860591888428, Validation loss: 0.70110023021698
Epoch: 2/300 - Train loss: 0.703284740447998, Validation loss: 0.6989787817001343
Epoch: 3/300 - Train loss: 0.7010639309883118, Validation loss: 0.6967713832855225
Epoch: 4/300 - Train loss: 0.6988182663917542, Validation loss: 0.6945235133171082
Epoch: 5/300 - Train loss: 0.6965293884277344, Validation loss: 0.6923611164093018
Epoch: 6/300 - Train loss: 0.6941747665405273, Validation loss: 0.690136194229126
Epoch: 7/300 - Train loss: 0.6917347311973572, Validation loss: 0.6876108646392822
Epoch: 8/300 - Train loss: 0.6892094016075134, Validation loss: 0.6851963996887207
Epoch: 9/300 - Train loss: 0.6866174340248108, Validation loss: 0.6825361847877502
Epoch: 10/300 - Train loss: 0.6839458346366882, Validation loss: 0.680194079875946
Epoch: 11/300 - Train loss: 0.6812127828598022, Validation loss: 0.6774032115936279
Epoch: 12/300 - Train loss: 0.678426206111908, Validation loss: 0.6748575568199158
Epoch: 13/300 - Train loss: 0.6756094098091125, Validation loss: 0.6721283197402954
Epoch: 14/300 - Train loss: 0.6727840304374695, Validation loss: 0.6694462895393372
Epoch: 15/300 - Train loss: 0.6699575185775757, Validation loss: 0.6667931079864502
Epoch: 16/300 - Train loss: 0.6671429872512817, Validation loss: 0.6641421318054199
Epoch: 17/300 - Train loss: 0.6643458604812622, Validation loss: 0.6615888476371765
Epoch: 18/300 - Train loss: 0.6615591049194336, Validation loss: 0.6589772701263428
Epoch: 19/300 - Train loss: 0.6587833762168884, Validation loss: 0.6564054489135742
Epoch: 20/300 - Train loss: 0.6560103297233582, Validation loss: 0.6537681221961975
Epoch: 21/300 - Train loss: 0.6532304286956787, Validation loss: 0.6512012481689453
Epoch: 22/300 - Train loss: 0.6504340767860413, Validation loss: 0.6484954953193665
Epoch: 23/300 - Train loss: 0.6476119756698608, Validation loss: 0.6457885503768921
Epoch: 24/300 - Train loss: 0.6447573304176331, Validation loss: 0.6430215239524841
Epoch: 25/300 - Train loss: 0.6418653726577759, Validation loss: 0.6403583884239197
Epoch: 26/300 - Train loss: 0.6389337182044983, Validation loss: 0.6374220848083496
Epoch: 27/300 - Train loss: 0.6359714269638062, Validation loss: 0.6347432732582092
Epoch: 28/300 - Train loss: 0.6329894661903381, Validation loss: 0.6318963766098022
Epoch: 29/300 - Train loss: 0.6299958825111389, Validation loss: 0.6289867162704468
Epoch: 30/300 - Train loss: 0.6270087957382202, Validation loss: 0.6263550519943237
Epoch: 31/300 - Train loss: 0.6240317225456238, Validation loss: 0.6233783960342407
Epoch: 32/300 - Train loss: 0.6210706830024719, Validation loss: 0.620530366897583
Epoch: 33/300 - Train loss: 0.6181322932243347, Validation loss: 0.6176856756210327
Epoch: 34/300 - Train loss: 0.6152207851409912, Validation loss: 0.6151202917098999
Epoch: 35/300 - Train loss: 0.6123322248458862, Validation loss: 0.6124690175056458
Epoch: 36/300 - Train loss: 0.6094699501991272, Validation loss: 0.6096930503845215
Epoch: 37/300 - Train loss: 0.6066328883171082, Validation loss: 0.6069906949996948
Epoch: 38/300 - Train loss: 0.6038174033164978, Validation loss: 0.6040882468223572
Epoch: 39/300 - Train loss: 0.6010214686393738, Validation loss: 0.6018885970115662
Epoch: 40/300 - Train loss: 0.5982431769371033, Validation loss: 0.5990024209022522
Epoch: 41/300 - Train loss: 0.595481276512146, Validation loss: 0.5969091057777405
Epoch: 42/300 - Train loss: 0.5927367210388184, Validation loss: 0.5940194725990295
Epoch: 43/300 - Train loss: 0.5900108814239502, Validation loss: 0.591187059879303
Epoch: 44/300 - Train loss: 0.5873059630393982, Validation loss: 0.5888781547546387
Epoch: 45/300 - Train loss: 0.584625244140625, Validation loss: 0.5865174531936646
Epoch: 46/300 - Train loss: 0.5819720029830933, Validation loss: 0.5841156840324402
Epoch: 47/300 - Train loss: 0.5793492197990417, Validation loss: 0.581457793712616
Epoch: 48/300 - Train loss: 0.5767590403556824, Validation loss: 0.5790411829948425
Epoch: 49/300 - Train loss: 0.5742049217224121, Validation loss: 0.576673686504364
Epoch: 50/300 - Train loss: 0.5716887712478638, Validation loss: 0.5741419196128845
Epoch: 51/300 - Train loss: 0.5692123770713806, Validation loss: 0.5723657608032227
Epoch: 52/300 - Train loss: 0.5667757987976074, Validation loss: 0.5698878765106201
Epoch: 53/300 - Train loss: 0.5643803477287292, Validation loss: 0.5677844285964966
Epoch: 54/300 - Train loss: 0.56202632188797, Validation loss: 0.5649853348731995
Epoch: 55/300 - Train loss: 0.5597145557403564, Validation loss: 0.5636830925941467
Epoch: 56/300 - Train loss: 0.5574456453323364, Validation loss: 0.5612189769744873
Epoch: 57/300 - Train loss: 0.5552200675010681, Validation loss: 0.5590337514877319
Epoch: 58/300 - Train loss: 0.5530391335487366, Validation loss: 0.5568420886993408
Epoch: 59/300 - Train loss: 0.5509034991264343, Validation loss: 0.5550631284713745
Epoch: 60/300 - Train loss: 0.5488153100013733, Validation loss: 0.5531861782073975
Epoch: 61/300 - Train loss: 0.546775758266449, Validation loss: 0.5517851114273071
Epoch: 62/300 - Train loss: 0.5447853207588196, Validation loss: 0.5495578646659851
Epoch: 63/300 - Train loss: 0.5428447723388672, Validation loss: 0.5478001832962036
Epoch: 64/300 - Train loss: 0.5409539341926575, Validation loss: 0.5459592938423157
Epoch: 65/300 - Train loss: 0.5391131043434143, Validation loss: 0.5444661974906921
Epoch: 66/300 - Train loss: 0.5373213291168213, Validation loss: 0.5424728989601135
Epoch: 67/300 - Train loss: 0.5355781316757202, Validation loss: 0.5410504341125488
Epoch: 68/300 - Train loss: 0.5338832139968872, Validation loss: 0.5394830107688904
Epoch: 69/300 - Train loss: 0.5322356820106506, Validation loss: 0.5376226902008057
Epoch: 70/300 - Train loss: 0.530635416507721, Validation loss: 0.5364464521408081
Epoch: 71/300 - Train loss: 0.5290820002555847, Validation loss: 0.5349748730659485
Epoch: 72/300 - Train loss: 0.5275747179985046, Validation loss: 0.5334250330924988
Epoch: 73/300 - Train loss: 0.5261126160621643, Validation loss: 0.5325295925140381
Epoch: 74/300 - Train loss: 0.5246954560279846, Validation loss: 0.531003475189209
Epoch: 75/300 - Train loss: 0.5233215689659119, Validation loss: 0.5300230383872986
Epoch: 76/300 - Train loss: 0.5219902396202087, Validation loss: 0.5286756753921509
Epoch: 77/300 - Train loss: 0.5206995010375977, Validation loss: 0.5273282527923584
Epoch: 78/300 - Train loss: 0.5194485187530518, Validation loss: 0.5256194472312927
Epoch: 79/300 - Train loss: 0.5182355642318726, Validation loss: 0.5247454643249512
Epoch: 80/300 - Train loss: 0.517059326171875, Validation loss: 0.5242064595222473
Epoch: 81/300 - Train loss: 0.5159183740615845, Validation loss: 0.5235114097595215
Epoch: 82/300 - Train loss: 0.5148112773895264, Validation loss: 0.5215432047843933
Epoch: 83/300 - Train loss: 0.5137375593185425, Validation loss: 0.5206402540206909
Epoch: 84/300 - Train loss: 0.5126962661743164, Validation loss: 0.520305871963501
Epoch: 85/300 - Train loss: 0.5116857290267944, Validation loss: 0.5195049047470093
Epoch: 86/300 - Train loss: 0.510704517364502, Validation loss: 0.5185710191726685
Epoch: 87/300 - Train loss: 0.5097512602806091, Validation loss: 0.5174678564071655
Epoch: 88/300 - Train loss: 0.5088249444961548, Validation loss: 0.5167091488838196
Epoch: 89/300 - Train loss: 0.5079240798950195, Validation loss: 0.5164424180984497
Epoch: 90/300 - Train loss: 0.507047176361084, Validation loss: 0.5149931907653809
Epoch: 91/300 - Train loss: 0.5061935186386108, Validation loss: 0.5149543881416321
Epoch: 92/300 - Train loss: 0.5053612589836121, Validation loss: 0.5135615468025208
Epoch: 93/300 - Train loss: 0.504549503326416, Validation loss: 0.5126522779464722
Epoch: 94/300 - Train loss: 0.5037567019462585, Validation loss: 0.5118173956871033
Epoch: 95/300 - Train loss: 0.5029807686805725, Validation loss: 0.5113128423690796
Epoch: 96/300 - Train loss: 0.502220869064331, Validation loss: 0.5106697678565979
Epoch: 97/300 - Train loss: 0.5014751553535461, Validation loss: 0.5100643038749695
Epoch: 98/300 - Train loss: 0.5007434487342834, Validation loss: 0.5093850493431091
Epoch: 99/300 - Train loss: 0.5000244379043579, Validation loss: 0.5084930062294006
Epoch: 100/300 - Train loss: 0.49931707978248596, Validation loss: 0.5080640912055969
Epoch: 101/300 - Train loss: 0.4986192286014557, Validation loss: 0.507628858089447
Epoch: 102/300 - Train loss: 0.49792957305908203, Validation loss: 0.5067366361618042
Epoch: 103/300 - Train loss: 0.4972453713417053, Validation loss: 0.506873369216919
Epoch: 104/300 - Train loss: 0.49656713008880615, Validation loss: 0.505049467086792
Epoch: 105/300 - Train loss: 0.49589475989341736, Validation loss: 0.5042393803596497
Epoch: 106/300 - Train loss: 0.4952279329299927, Validation loss: 0.5041948556900024
Epoch: 107/300 - Train loss: 0.49456390738487244, Validation loss: 0.5037060379981995
Epoch: 108/300 - Train loss: 0.493900865316391, Validation loss: 0.5027657151222229
Epoch: 109/300 - Train loss: 0.49323907494544983, Validation loss: 0.5021542906761169
Epoch: 110/300 - Train loss: 0.4925798177719116, Validation loss: 0.5013247728347778
Epoch: 111/300 - Train loss: 0.4919237792491913, Validation loss: 0.5009557008743286
Epoch: 112/300 - Train loss: 0.4912727475166321, Validation loss: 0.5006629228591919
Epoch: 113/300 - Train loss: 0.4906231462955475, Validation loss: 0.4994106590747833
Epoch: 114/300 - Train loss: 0.4899753928184509, Validation loss: 0.4990893304347992
Epoch: 115/300 - Train loss: 0.48932933807373047, Validation loss: 0.4986755847930908
Epoch: 116/300 - Train loss: 0.48868101835250854, Validation loss: 0.49734705686569214
Epoch: 117/300 - Train loss: 0.4880315959453583, Validation loss: 0.4969121813774109
Epoch: 118/300 - Train loss: 0.4873802959918976, Validation loss: 0.4963155686855316
Epoch: 119/300 - Train loss: 0.48673027753829956, Validation loss: 0.49554431438446045
Epoch: 120/300 - Train loss: 0.48608216643333435, Validation loss: 0.49537503719329834
Epoch: 121/300 - Train loss: 0.4854362905025482, Validation loss: 0.4947463274002075
Epoch: 122/300 - Train loss: 0.4847927987575531, Validation loss: 0.4942569434642792
Epoch: 123/300 - Train loss: 0.48415061831474304, Validation loss: 0.4931504726409912
Epoch: 124/300 - Train loss: 0.4835093319416046, Validation loss: 0.49263978004455566
Epoch: 125/300 - Train loss: 0.4828689396381378, Validation loss: 0.49255526065826416
