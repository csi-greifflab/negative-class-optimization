Epoch: 1/300 - Train loss: 0.7025859951972961, Validation loss: 0.7003359794616699
Epoch: 2/300 - Train loss: 0.6992494463920593, Validation loss: 0.6968836188316345
Epoch: 3/300 - Train loss: 0.695812463760376, Validation loss: 0.6928690671920776
Epoch: 4/300 - Train loss: 0.6922363042831421, Validation loss: 0.6890935301780701
Epoch: 5/300 - Train loss: 0.6884775757789612, Validation loss: 0.6850131154060364
Epoch: 6/300 - Train loss: 0.6845149397850037, Validation loss: 0.6806483268737793
Epoch: 7/300 - Train loss: 0.6803368926048279, Validation loss: 0.6758821606636047
Epoch: 8/300 - Train loss: 0.6759375929832458, Validation loss: 0.6711400747299194
Epoch: 9/300 - Train loss: 0.671322226524353, Validation loss: 0.6661192178726196
Epoch: 10/300 - Train loss: 0.666506290435791, Validation loss: 0.66079181432724
Epoch: 11/300 - Train loss: 0.6615071296691895, Validation loss: 0.6554437279701233
Epoch: 12/300 - Train loss: 0.6563565135002136, Validation loss: 0.6498352885246277
Epoch: 13/300 - Train loss: 0.6510838866233826, Validation loss: 0.6442214250564575
Epoch: 14/300 - Train loss: 0.6457027196884155, Validation loss: 0.6385483145713806
Epoch: 15/300 - Train loss: 0.640229344367981, Validation loss: 0.6327933669090271
Epoch: 16/300 - Train loss: 0.6346815824508667, Validation loss: 0.6268692016601562
Epoch: 17/300 - Train loss: 0.629071831703186, Validation loss: 0.6209502816200256
Epoch: 18/300 - Train loss: 0.6234108209609985, Validation loss: 0.6150648593902588
Epoch: 19/300 - Train loss: 0.6177110075950623, Validation loss: 0.6091266870498657
Epoch: 20/300 - Train loss: 0.6119810938835144, Validation loss: 0.6031712293624878
Epoch: 21/300 - Train loss: 0.6062256097793579, Validation loss: 0.5972430109977722
Epoch: 22/300 - Train loss: 0.6004523038864136, Validation loss: 0.5915405750274658
Epoch: 23/300 - Train loss: 0.594663143157959, Validation loss: 0.5853973627090454
Epoch: 24/300 - Train loss: 0.5888583660125732, Validation loss: 0.579384982585907
Epoch: 25/300 - Train loss: 0.5830397009849548, Validation loss: 0.5734490156173706
Epoch: 26/300 - Train loss: 0.5772069692611694, Validation loss: 0.5675686597824097
Epoch: 27/300 - Train loss: 0.5713624358177185, Validation loss: 0.5617249608039856
Epoch: 28/300 - Train loss: 0.5655088424682617, Validation loss: 0.5558509230613708
Epoch: 29/300 - Train loss: 0.5596486330032349, Validation loss: 0.5498546361923218
Epoch: 30/300 - Train loss: 0.5537826418876648, Validation loss: 0.5440505743026733
Epoch: 31/300 - Train loss: 0.547914981842041, Validation loss: 0.5379493236541748
Epoch: 32/300 - Train loss: 0.5420488119125366, Validation loss: 0.5320026278495789
Epoch: 33/300 - Train loss: 0.5361862182617188, Validation loss: 0.5262936353683472
Epoch: 34/300 - Train loss: 0.530331552028656, Validation loss: 0.5203998684883118
Epoch: 35/300 - Train loss: 0.5244870185852051, Validation loss: 0.5146738886833191
Epoch: 36/300 - Train loss: 0.518656849861145, Validation loss: 0.5087703466415405
Epoch: 37/300 - Train loss: 0.5128445029258728, Validation loss: 0.5026656985282898
Epoch: 38/300 - Train loss: 0.5070525407791138, Validation loss: 0.4970262050628662
Epoch: 39/300 - Train loss: 0.5012825131416321, Validation loss: 0.4911383390426636
Epoch: 40/300 - Train loss: 0.49553778767585754, Validation loss: 0.48587119579315186
Epoch: 41/300 - Train loss: 0.48982155323028564, Validation loss: 0.48002204298973083
Epoch: 42/300 - Train loss: 0.48413705825805664, Validation loss: 0.4742935299873352
Epoch: 43/300 - Train loss: 0.47848615050315857, Validation loss: 0.4685780107975006
Epoch: 44/300 - Train loss: 0.472871869802475, Validation loss: 0.4631654918193817
Epoch: 45/300 - Train loss: 0.46729618310928345, Validation loss: 0.45741936564445496
Epoch: 46/300 - Train loss: 0.46176135540008545, Validation loss: 0.45212411880493164
Epoch: 47/300 - Train loss: 0.4562714099884033, Validation loss: 0.44679126143455505
Epoch: 48/300 - Train loss: 0.45082882046699524, Validation loss: 0.44114744663238525
Epoch: 49/300 - Train loss: 0.44543561339378357, Validation loss: 0.4358675479888916
Epoch: 50/300 - Train loss: 0.4400942623615265, Validation loss: 0.43056243658065796
Epoch: 51/300 - Train loss: 0.4348067343235016, Validation loss: 0.42526572942733765
Epoch: 52/300 - Train loss: 0.42957544326782227, Validation loss: 0.42008915543556213
Epoch: 53/300 - Train loss: 0.4244026839733124, Validation loss: 0.415179967880249
Epoch: 54/300 - Train loss: 0.4192902147769928, Validation loss: 0.41036155819892883
Epoch: 55/300 - Train loss: 0.4142396152019501, Validation loss: 0.40513548254966736
Epoch: 56/300 - Train loss: 0.4092535376548767, Validation loss: 0.4002775549888611
Epoch: 57/300 - Train loss: 0.40433329343795776, Validation loss: 0.3953962028026581
Epoch: 58/300 - Train loss: 0.39948076009750366, Validation loss: 0.3906943202018738
Epoch: 59/300 - Train loss: 0.3946971595287323, Validation loss: 0.3856370151042938
Epoch: 60/300 - Train loss: 0.38998401165008545, Validation loss: 0.3809051513671875
Epoch: 61/300 - Train loss: 0.3853427469730377, Validation loss: 0.3765243589878082
Epoch: 62/300 - Train loss: 0.3807743787765503, Validation loss: 0.37225645780563354
Epoch: 63/300 - Train loss: 0.3762798607349396, Validation loss: 0.3675599992275238
Epoch: 64/300 - Train loss: 0.371860146522522, Validation loss: 0.36364394426345825
Epoch: 65/300 - Train loss: 0.36751589179039, Validation loss: 0.3593524396419525
Epoch: 66/300 - Train loss: 0.36324790120124817, Validation loss: 0.3549569547176361
Epoch: 67/300 - Train loss: 0.35905593633651733, Validation loss: 0.35090041160583496
Epoch: 68/300 - Train loss: 0.35494017601013184, Validation loss: 0.3470771610736847
Epoch: 69/300 - Train loss: 0.3509007394313812, Validation loss: 0.34291577339172363
Epoch: 70/300 - Train loss: 0.346937894821167, Validation loss: 0.33935320377349854
Epoch: 71/300 - Train loss: 0.3430512845516205, Validation loss: 0.3351953625679016
Epoch: 72/300 - Train loss: 0.3392411470413208, Validation loss: 0.3319553732872009
Epoch: 73/300 - Train loss: 0.3355071544647217, Validation loss: 0.3279203772544861
Epoch: 74/300 - Train loss: 0.3318486511707306, Validation loss: 0.3242713510990143
Epoch: 75/300 - Train loss: 0.32826510071754456, Validation loss: 0.3210436999797821
Epoch: 76/300 - Train loss: 0.32475608587265015, Validation loss: 0.31734606623649597
Epoch: 77/300 - Train loss: 0.3213213086128235, Validation loss: 0.31442585587501526
Epoch: 78/300 - Train loss: 0.31795987486839294, Validation loss: 0.3110884130001068
Epoch: 79/300 - Train loss: 0.3146710991859436, Validation loss: 0.30764704942703247
Epoch: 80/300 - Train loss: 0.3114541471004486, Validation loss: 0.30469173192977905
Epoch: 81/300 - Train loss: 0.3083079755306244, Validation loss: 0.30133169889450073
Epoch: 82/300 - Train loss: 0.30523160099983215, Validation loss: 0.2985895276069641
Epoch: 83/300 - Train loss: 0.30222412943840027, Validation loss: 0.29572594165802
Epoch: 84/300 - Train loss: 0.2992844581604004, Validation loss: 0.2930271625518799
Epoch: 85/300 - Train loss: 0.29641127586364746, Validation loss: 0.2901766896247864
Epoch: 86/300 - Train loss: 0.29360368847846985, Validation loss: 0.28749629855155945
Epoch: 87/300 - Train loss: 0.29086050391197205, Validation loss: 0.2845442295074463
Epoch: 88/300 - Train loss: 0.28818050026893616, Validation loss: 0.28193992376327515
Epoch: 89/300 - Train loss: 0.2855624258518219, Validation loss: 0.2796408534049988
Epoch: 90/300 - Train loss: 0.2830052375793457, Validation loss: 0.2773251235485077
Epoch: 91/300 - Train loss: 0.28050780296325684, Validation loss: 0.2746966779232025
Epoch: 92/300 - Train loss: 0.2780686616897583, Validation loss: 0.27198082208633423
Epoch: 93/300 - Train loss: 0.2756868898868561, Validation loss: 0.26977062225341797
Epoch: 94/300 - Train loss: 0.2733612656593323, Validation loss: 0.26769834756851196
Epoch: 95/300 - Train loss: 0.27109047770500183, Validation loss: 0.26567888259887695
Epoch: 96/300 - Train loss: 0.268873006105423, Validation loss: 0.26348477602005005
Epoch: 97/300 - Train loss: 0.26670771837234497, Validation loss: 0.2611314356327057
Epoch: 98/300 - Train loss: 0.26459336280822754, Validation loss: 0.25981974601745605
Epoch: 99/300 - Train loss: 0.26252907514572144, Validation loss: 0.2574405074119568
Epoch: 100/300 - Train loss: 0.26051339507102966, Validation loss: 0.255753755569458
Epoch: 101/300 - Train loss: 0.25854524970054626, Validation loss: 0.253547340631485
Epoch: 102/300 - Train loss: 0.2566232681274414, Validation loss: 0.2518165409564972
Epoch: 103/300 - Train loss: 0.25474631786346436, Validation loss: 0.2502164840698242
Epoch: 104/300 - Train loss: 0.2529131770133972, Validation loss: 0.24830065667629242
Epoch: 105/300 - Train loss: 0.25112298130989075, Validation loss: 0.24642759561538696
Epoch: 106/300 - Train loss: 0.24937446415424347, Validation loss: 0.24463224411010742
Epoch: 107/300 - Train loss: 0.2476668357849121, Validation loss: 0.2430291324853897
Epoch: 108/300 - Train loss: 0.24599897861480713, Validation loss: 0.241974875330925
Epoch: 109/300 - Train loss: 0.24436967074871063, Validation loss: 0.24008305370807648
Epoch: 110/300 - Train loss: 0.24277789890766144, Validation loss: 0.2386871576309204
Epoch: 111/300 - Train loss: 0.24122273921966553, Validation loss: 0.23670636117458344
Epoch: 112/300 - Train loss: 0.23970313370227814, Validation loss: 0.23588736355304718
Epoch: 113/300 - Train loss: 0.23821835219860077, Validation loss: 0.23426023125648499
Epoch: 114/300 - Train loss: 0.23676739633083344, Validation loss: 0.23245668411254883
Epoch: 115/300 - Train loss: 0.2353491634130478, Validation loss: 0.23127546906471252
Epoch: 116/300 - Train loss: 0.23396296799182892, Validation loss: 0.23006848990917206
Epoch: 117/300 - Train loss: 0.23260803520679474, Validation loss: 0.22893783450126648
Epoch: 118/300 - Train loss: 0.23128342628479004, Validation loss: 0.22745907306671143
Epoch: 119/300 - Train loss: 0.22998835146427155, Validation loss: 0.22634784877300262
Epoch: 120/300 - Train loss: 0.22872208058834076, Validation loss: 0.22526861727237701
Epoch: 121/300 - Train loss: 0.22748365998268127, Validation loss: 0.22418370842933655
Epoch: 122/300 - Train loss: 0.2262725532054901, Validation loss: 0.22254900634288788
Epoch: 123/300 - Train loss: 0.22508801519870758, Validation loss: 0.22134236991405487
Epoch: 124/300 - Train loss: 0.22392931580543518, Validation loss: 0.22040830552577972
Epoch: 125/300 - Train loss: 0.22279570996761322, Validation loss: 0.22003452479839325
Epoch: 126/300 - Train loss: 0.22168663144111633, Validation loss: 0.2182612419128418
Epoch: 127/300 - Train loss: 0.2206013947725296, Validation loss: 0.21783876419067383
Epoch: 128/300 - Train loss: 0.21953937411308289, Validation loss: 0.21685151755809784
Epoch: 129/300 - Train loss: 0.21849998831748962, Validation loss: 0.2154426872730255
Epoch: 130/300 - Train loss: 0.21748273074626923, Validation loss: 0.21484486758708954
Epoch: 131/300 - Train loss: 0.21648694574832916, Validation loss: 0.21399062871932983
Epoch: 132/300 - Train loss: 0.21551209688186646, Validation loss: 0.21278002858161926
Epoch: 133/300 - Train loss: 0.2145576775074005, Validation loss: 0.2118985801935196
Epoch: 134/300 - Train loss: 0.21362312138080597, Validation loss: 0.2112581431865692
Epoch: 135/300 - Train loss: 0.21270784735679626, Validation loss: 0.2101312279701233
Epoch: 136/300 - Train loss: 0.21181133389472961, Validation loss: 0.2100592404603958
Epoch: 137/300 - Train loss: 0.210933119058609, Validation loss: 0.20877555012702942
Epoch: 138/300 - Train loss: 0.2100725769996643, Validation loss: 0.20761625468730927
Epoch: 139/300 - Train loss: 0.20922940969467163, Validation loss: 0.20702485740184784
Epoch: 140/300 - Train loss: 0.2084031105041504, Validation loss: 0.2059893012046814
Epoch: 141/300 - Train loss: 0.20759332180023193, Validation loss: 0.20500868558883667
Epoch: 142/300 - Train loss: 0.20679964125156403, Validation loss: 0.20486818253993988
Epoch: 143/300 - Train loss: 0.20602169632911682, Validation loss: 0.20427772402763367
Epoch: 144/300 - Train loss: 0.20525901019573212, Validation loss: 0.20305787026882172
Epoch: 145/300 - Train loss: 0.20451132953166962, Validation loss: 0.20260155200958252
Epoch: 146/300 - Train loss: 0.20377832651138306, Validation loss: 0.2025490701198578
Epoch: 147/300 - Train loss: 0.20305956900119781, Validation loss: 0.20123809576034546
Epoch: 148/300 - Train loss: 0.20235472917556763, Validation loss: 0.2007063925266266
Epoch: 149/300 - Train loss: 0.20166346430778503, Validation loss: 0.19999729096889496
Epoch: 150/300 - Train loss: 0.20098547637462616, Validation loss: 0.1988862305879593
Epoch: 151/300 - Train loss: 0.20032040774822235, Validation loss: 0.198542520403862
Epoch: 152/300 - Train loss: 0.19966791570186615, Validation loss: 0.19773103296756744
Epoch: 153/300 - Train loss: 0.19902771711349487, Validation loss: 0.19794945418834686
Epoch: 154/300 - Train loss: 0.19839955866336823, Validation loss: 0.1968453824520111
Epoch: 155/300 - Train loss: 0.19778309762477875, Validation loss: 0.19629329442977905
Epoch: 156/300 - Train loss: 0.1971781700849533, Validation loss: 0.1960393786430359
Epoch: 157/300 - Train loss: 0.19658449292182922, Validation loss: 0.19534674286842346
Epoch: 158/300 - Train loss: 0.1960018128156662, Validation loss: 0.19555386900901794
