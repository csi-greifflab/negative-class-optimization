Epoch: 1/300 - Train loss: 0.6901810765266418, Validation loss: 0.6891818046569824
Epoch: 2/300 - Train loss: 0.6888397932052612, Validation loss: 0.6878922581672668
Epoch: 3/300 - Train loss: 0.6874853372573853, Validation loss: 0.6866347789764404
Epoch: 4/300 - Train loss: 0.686112642288208, Validation loss: 0.6852028965950012
Epoch: 5/300 - Train loss: 0.6847164034843445, Validation loss: 0.6838621497154236
Epoch: 6/300 - Train loss: 0.6832965612411499, Validation loss: 0.6823689341545105
Epoch: 7/300 - Train loss: 0.6818458437919617, Validation loss: 0.680901288986206
Epoch: 8/300 - Train loss: 0.6803607940673828, Validation loss: 0.6794695854187012
Epoch: 9/300 - Train loss: 0.6788347959518433, Validation loss: 0.6778964996337891
Epoch: 10/300 - Train loss: 0.6772646903991699, Validation loss: 0.6763202548027039
Epoch: 11/300 - Train loss: 0.675649106502533, Validation loss: 0.6747662425041199
Epoch: 12/300 - Train loss: 0.6739826202392578, Validation loss: 0.6730333566665649
Epoch: 13/300 - Train loss: 0.6722649931907654, Validation loss: 0.6713374853134155
Epoch: 14/300 - Train loss: 0.6704932451248169, Validation loss: 0.6695912480354309
Epoch: 15/300 - Train loss: 0.6686649918556213, Validation loss: 0.6677318811416626
Epoch: 16/300 - Train loss: 0.6667772531509399, Validation loss: 0.6658388376235962
Epoch: 17/300 - Train loss: 0.6648300886154175, Validation loss: 0.6638805270195007
Epoch: 18/300 - Train loss: 0.6628226041793823, Validation loss: 0.66175377368927
Epoch: 19/300 - Train loss: 0.6607553958892822, Validation loss: 0.6595767140388489
Epoch: 20/300 - Train loss: 0.658626139163971, Validation loss: 0.6575013399124146
Epoch: 21/300 - Train loss: 0.6564342379570007, Validation loss: 0.6552244424819946
Epoch: 22/300 - Train loss: 0.654179573059082, Validation loss: 0.6529041528701782
Epoch: 23/300 - Train loss: 0.6518613696098328, Validation loss: 0.6506173014640808
Epoch: 24/300 - Train loss: 0.6494819521903992, Validation loss: 0.6480478644371033
Epoch: 25/300 - Train loss: 0.6470435857772827, Validation loss: 0.645651638507843
Epoch: 26/300 - Train loss: 0.6445500254631042, Validation loss: 0.6432341933250427
Epoch: 27/300 - Train loss: 0.6420020461082458, Validation loss: 0.6407380700111389
Epoch: 28/300 - Train loss: 0.6394039392471313, Validation loss: 0.638017475605011
Epoch: 29/300 - Train loss: 0.6367633938789368, Validation loss: 0.6354023814201355
Epoch: 30/300 - Train loss: 0.6340844035148621, Validation loss: 0.6326196193695068
Epoch: 31/300 - Train loss: 0.6313673257827759, Validation loss: 0.6301623582839966
Epoch: 32/300 - Train loss: 0.6286187767982483, Validation loss: 0.6273057460784912
Epoch: 33/300 - Train loss: 0.6258452534675598, Validation loss: 0.6246464252471924
Epoch: 34/300 - Train loss: 0.6230471134185791, Validation loss: 0.621834397315979
Epoch: 35/300 - Train loss: 0.6202307343482971, Validation loss: 0.6190710067749023
Epoch: 36/300 - Train loss: 0.6174005270004272, Validation loss: 0.6164026260375977
Epoch: 37/300 - Train loss: 0.6145604848861694, Validation loss: 0.6134740710258484
Epoch: 38/300 - Train loss: 0.6117129921913147, Validation loss: 0.6107803583145142
Epoch: 39/300 - Train loss: 0.6088641285896301, Validation loss: 0.6079103350639343
Epoch: 40/300 - Train loss: 0.6060174703598022, Validation loss: 0.605442464351654
Epoch: 41/300 - Train loss: 0.6031759977340698, Validation loss: 0.6026243567466736
Epoch: 42/300 - Train loss: 0.6003419160842896, Validation loss: 0.5998353362083435
Epoch: 43/300 - Train loss: 0.5975190997123718, Validation loss: 0.597046434879303
Epoch: 44/300 - Train loss: 0.5947117805480957, Validation loss: 0.5943860411643982
Epoch: 45/300 - Train loss: 0.5919250845909119, Validation loss: 0.5919169187545776
Epoch: 46/300 - Train loss: 0.58916175365448, Validation loss: 0.5896006226539612
Epoch: 47/300 - Train loss: 0.5864226818084717, Validation loss: 0.5865286588668823
Epoch: 48/300 - Train loss: 0.5837107300758362, Validation loss: 0.583907961845398
Epoch: 49/300 - Train loss: 0.5810286998748779, Validation loss: 0.5816391110420227
Epoch: 50/300 - Train loss: 0.5783777236938477, Validation loss: 0.5791095495223999
Epoch: 51/300 - Train loss: 0.5757597088813782, Validation loss: 0.5765824913978577
Epoch: 52/300 - Train loss: 0.5731775164604187, Validation loss: 0.5740198493003845
Epoch: 53/300 - Train loss: 0.5706332921981812, Validation loss: 0.5716140866279602
Epoch: 54/300 - Train loss: 0.5681281089782715, Validation loss: 0.5699922442436218
Epoch: 55/300 - Train loss: 0.5656636953353882, Validation loss: 0.5669457316398621
Epoch: 56/300 - Train loss: 0.5632429122924805, Validation loss: 0.5652737021446228
Epoch: 57/300 - Train loss: 0.5608676075935364, Validation loss: 0.5629456639289856
Epoch: 58/300 - Train loss: 0.5585374236106873, Validation loss: 0.5604400038719177
Epoch: 59/300 - Train loss: 0.55625319480896, Validation loss: 0.5585980415344238
Epoch: 60/300 - Train loss: 0.5540145039558411, Validation loss: 0.5565783381462097
Epoch: 61/300 - Train loss: 0.5518224835395813, Validation loss: 0.5543467402458191
Epoch: 62/300 - Train loss: 0.5496765971183777, Validation loss: 0.5522465705871582
Epoch: 63/300 - Train loss: 0.5475775599479675, Validation loss: 0.5504984259605408
Epoch: 64/300 - Train loss: 0.545525848865509, Validation loss: 0.5482545495033264
Epoch: 65/300 - Train loss: 0.543520987033844, Validation loss: 0.5467738509178162
Epoch: 66/300 - Train loss: 0.5415623784065247, Validation loss: 0.5450733304023743
Epoch: 67/300 - Train loss: 0.5396499037742615, Validation loss: 0.5428297519683838
Epoch: 68/300 - Train loss: 0.5377838015556335, Validation loss: 0.5413551926612854
Epoch: 69/300 - Train loss: 0.5359619855880737, Validation loss: 0.5391850471496582
Epoch: 70/300 - Train loss: 0.5341838002204895, Validation loss: 0.5380783081054688
Epoch: 71/300 - Train loss: 0.532448410987854, Validation loss: 0.5360330939292908
Epoch: 72/300 - Train loss: 0.5307562947273254, Validation loss: 0.5349292755126953
Epoch: 73/300 - Train loss: 0.5291070342063904, Validation loss: 0.5331156253814697
Epoch: 74/300 - Train loss: 0.5274987816810608, Validation loss: 0.5319387316703796
Epoch: 75/300 - Train loss: 0.5259299874305725, Validation loss: 0.5301876068115234
Epoch: 76/300 - Train loss: 0.5243990421295166, Validation loss: 0.5294152498245239
Epoch: 77/300 - Train loss: 0.5229049921035767, Validation loss: 0.5275524258613586
Epoch: 78/300 - Train loss: 0.5214470624923706, Validation loss: 0.526030957698822
Epoch: 79/300 - Train loss: 0.5200220346450806, Validation loss: 0.5245762467384338
Epoch: 80/300 - Train loss: 0.5186302065849304, Validation loss: 0.5240083932876587
Epoch: 81/300 - Train loss: 0.517270028591156, Validation loss: 0.5223777890205383
Epoch: 82/300 - Train loss: 0.515940248966217, Validation loss: 0.520673930644989
Epoch: 83/300 - Train loss: 0.5146396160125732, Validation loss: 0.5198960900306702
Epoch: 84/300 - Train loss: 0.5133662223815918, Validation loss: 0.5182555913925171
Epoch: 85/300 - Train loss: 0.5121199488639832, Validation loss: 0.517248809337616
Epoch: 86/300 - Train loss: 0.5108973383903503, Validation loss: 0.5168364644050598
Epoch: 87/300 - Train loss: 0.5096964240074158, Validation loss: 0.5150589346885681
Epoch: 88/300 - Train loss: 0.5085168480873108, Validation loss: 0.5139566659927368
Epoch: 89/300 - Train loss: 0.507358193397522, Validation loss: 0.5132074356079102
Epoch: 90/300 - Train loss: 0.5062192678451538, Validation loss: 0.5122871994972229
Epoch: 91/300 - Train loss: 0.505098283290863, Validation loss: 0.5107322931289673
Epoch: 92/300 - Train loss: 0.5039944648742676, Validation loss: 0.5100012421607971
Epoch: 93/300 - Train loss: 0.5029084086418152, Validation loss: 0.5093969106674194
Epoch: 94/300 - Train loss: 0.5018396377563477, Validation loss: 0.5079517364501953
Epoch: 95/300 - Train loss: 0.5007861852645874, Validation loss: 0.5070656538009644
Epoch: 96/300 - Train loss: 0.49974608421325684, Validation loss: 0.506290853023529
Epoch: 97/300 - Train loss: 0.4987201392650604, Validation loss: 0.5050646066665649
Epoch: 98/300 - Train loss: 0.49770933389663696, Validation loss: 0.503910481929779
Epoch: 99/300 - Train loss: 0.4967108964920044, Validation loss: 0.5026549696922302
Epoch: 100/300 - Train loss: 0.4957254230976105, Validation loss: 0.5024345517158508
Epoch: 101/300 - Train loss: 0.49475207924842834, Validation loss: 0.5010815858840942
Epoch: 102/300 - Train loss: 0.49379056692123413, Validation loss: 0.4999549388885498
Epoch: 103/300 - Train loss: 0.4928392469882965, Validation loss: 0.4992051124572754
Epoch: 104/300 - Train loss: 0.49189940094947815, Validation loss: 0.49844613671302795
Epoch: 105/300 - Train loss: 0.4909685552120209, Validation loss: 0.49691087007522583
Epoch: 106/300 - Train loss: 0.4900452196598053, Validation loss: 0.49635761976242065
Epoch: 107/300 - Train loss: 0.48912960290908813, Validation loss: 0.4953855872154236
Epoch: 108/300 - Train loss: 0.48822182416915894, Validation loss: 0.4946661591529846
Epoch: 109/300 - Train loss: 0.48732128739356995, Validation loss: 0.49362465739250183
Epoch: 110/300 - Train loss: 0.48642677068710327, Validation loss: 0.4926694333553314
Epoch: 111/300 - Train loss: 0.48554059863090515, Validation loss: 0.4927029311656952
Epoch: 112/300 - Train loss: 0.4846618175506592, Validation loss: 0.49116089940071106
Epoch: 113/300 - Train loss: 0.48378804326057434, Validation loss: 0.49061447381973267
Epoch: 114/300 - Train loss: 0.48292291164398193, Validation loss: 0.4901271164417267
Epoch: 115/300 - Train loss: 0.48206302523612976, Validation loss: 0.48811638355255127
Epoch: 116/300 - Train loss: 0.48120826482772827, Validation loss: 0.487602561712265
Epoch: 117/300 - Train loss: 0.4803597033023834, Validation loss: 0.4865967631340027
Epoch: 118/300 - Train loss: 0.4795161783695221, Validation loss: 0.4862961173057556
Epoch: 119/300 - Train loss: 0.47867903113365173, Validation loss: 0.4858153462409973
Epoch: 120/300 - Train loss: 0.47784852981567383, Validation loss: 0.4844316244125366
Epoch: 121/300 - Train loss: 0.47702500224113464, Validation loss: 0.4840173125267029
Epoch: 122/300 - Train loss: 0.4762074649333954, Validation loss: 0.4836026132106781
Epoch: 123/300 - Train loss: 0.47539621591567993, Validation loss: 0.4823383390903473
Epoch: 124/300 - Train loss: 0.47459110617637634, Validation loss: 0.48143935203552246
Epoch: 125/300 - Train loss: 0.4737928807735443, Validation loss: 0.48094940185546875
Epoch: 126/300 - Train loss: 0.47300031781196594, Validation loss: 0.4800768792629242
Epoch: 127/300 - Train loss: 0.47221264243125916, Validation loss: 0.4797174632549286
Epoch: 128/300 - Train loss: 0.4714295566082001, Validation loss: 0.47842517495155334
Epoch: 129/300 - Train loss: 0.4706507921218872, Validation loss: 0.4783008396625519
Epoch: 130/300 - Train loss: 0.469874769449234, Validation loss: 0.4774387776851654
Epoch: 131/300 - Train loss: 0.4691009521484375, Validation loss: 0.4760877192020416
Epoch: 132/300 - Train loss: 0.4683308005332947, Validation loss: 0.4763354957103729
Epoch: 133/300 - Train loss: 0.46756529808044434, Validation loss: 0.47524183988571167
Epoch: 134/300 - Train loss: 0.46680328249931335, Validation loss: 0.47492268681526184
Epoch: 135/300 - Train loss: 0.4660453498363495, Validation loss: 0.4738524556159973
Epoch: 136/300 - Train loss: 0.465291827917099, Validation loss: 0.4726563096046448
Epoch: 137/300 - Train loss: 0.4645439684391022, Validation loss: 0.47223153710365295
Epoch: 138/300 - Train loss: 0.46380090713500977, Validation loss: 0.47197431325912476
Epoch: 139/300 - Train loss: 0.46306312084198, Validation loss: 0.4707503914833069
Epoch: 140/300 - Train loss: 0.4623304605484009, Validation loss: 0.4697076678276062
Epoch: 141/300 - Train loss: 0.461601585149765, Validation loss: 0.46961942315101624
Epoch: 142/300 - Train loss: 0.4608764946460724, Validation loss: 0.4694339334964752
Epoch: 143/300 - Train loss: 0.4601553678512573, Validation loss: 0.46846771240234375
Epoch: 144/300 - Train loss: 0.45943892002105713, Validation loss: 0.4682450294494629
Epoch: 145/300 - Train loss: 0.45872795581817627, Validation loss: 0.46656250953674316
Epoch: 146/300 - Train loss: 0.45802104473114014, Validation loss: 0.46641385555267334
Epoch: 147/300 - Train loss: 0.45731863379478455, Validation loss: 0.4653938412666321
Epoch: 148/300 - Train loss: 0.4566209316253662, Validation loss: 0.4654315412044525
Epoch: 149/300 - Train loss: 0.4559274911880493, Validation loss: 0.4643230736255646
Epoch: 150/300 - Train loss: 0.45523709058761597, Validation loss: 0.4637034237384796
Epoch: 151/300 - Train loss: 0.45455020666122437, Validation loss: 0.4626374840736389
Epoch: 152/300 - Train loss: 0.4538657069206238, Validation loss: 0.4628022015094757
Epoch: 153/300 - Train loss: 0.45318517088890076, Validation loss: 0.46176695823669434
Epoch: 154/300 - Train loss: 0.4525073170661926, Validation loss: 0.4608893394470215
Epoch: 155/300 - Train loss: 0.4518330693244934, Validation loss: 0.46064719557762146
Epoch: 156/300 - Train loss: 0.4511626958847046, Validation loss: 0.45996275544166565
Epoch: 157/300 - Train loss: 0.4504951238632202, Validation loss: 0.45935294032096863
Epoch: 158/300 - Train loss: 0.44982919096946716, Validation loss: 0.45937010645866394
