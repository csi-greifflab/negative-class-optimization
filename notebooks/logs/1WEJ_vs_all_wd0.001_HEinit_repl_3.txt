Epoch: 1/300 - Train loss: 0.6948980689048767, Validation loss: 0.6935626268386841
Epoch: 2/300 - Train loss: 0.692624032497406, Validation loss: 0.691479504108429
Epoch: 3/300 - Train loss: 0.690390944480896, Validation loss: 0.689211368560791
Epoch: 4/300 - Train loss: 0.6881833672523499, Validation loss: 0.6872059106826782
Epoch: 5/300 - Train loss: 0.6859896779060364, Validation loss: 0.6851117610931396
Epoch: 6/300 - Train loss: 0.6837947368621826, Validation loss: 0.682930052280426
Epoch: 7/300 - Train loss: 0.6815851926803589, Validation loss: 0.6806781888008118
Epoch: 8/300 - Train loss: 0.6793480515480042, Validation loss: 0.6784313321113586
Epoch: 9/300 - Train loss: 0.6770685315132141, Validation loss: 0.6762890219688416
Epoch: 10/300 - Train loss: 0.6747303605079651, Validation loss: 0.6738907098770142
Epoch: 11/300 - Train loss: 0.6723222136497498, Validation loss: 0.6714276075363159
Epoch: 12/300 - Train loss: 0.6698331832885742, Validation loss: 0.6688970923423767
Epoch: 13/300 - Train loss: 0.6672547459602356, Validation loss: 0.6663804054260254
Epoch: 14/300 - Train loss: 0.6645800471305847, Validation loss: 0.6636814475059509
Epoch: 15/300 - Train loss: 0.6617987155914307, Validation loss: 0.6609737873077393
Epoch: 16/300 - Train loss: 0.6589081883430481, Validation loss: 0.6580565571784973
Epoch: 17/300 - Train loss: 0.6559012532234192, Validation loss: 0.6548760533332825
Epoch: 18/300 - Train loss: 0.6527788043022156, Validation loss: 0.6518378257751465
Epoch: 19/300 - Train loss: 0.649535059928894, Validation loss: 0.648556113243103
Epoch: 20/300 - Train loss: 0.6461691856384277, Validation loss: 0.6451575756072998
Epoch: 21/300 - Train loss: 0.642686128616333, Validation loss: 0.6415677070617676
Epoch: 22/300 - Train loss: 0.6390904188156128, Validation loss: 0.6378999948501587
Epoch: 23/300 - Train loss: 0.6353803277015686, Validation loss: 0.6343178153038025
Epoch: 24/300 - Train loss: 0.6315658688545227, Validation loss: 0.6304333806037903
Epoch: 25/300 - Train loss: 0.6276423931121826, Validation loss: 0.6266276240348816
Epoch: 26/300 - Train loss: 0.6236166954040527, Validation loss: 0.6223227381706238
Epoch: 27/300 - Train loss: 0.6194999814033508, Validation loss: 0.6183840036392212
Epoch: 28/300 - Train loss: 0.6153032779693604, Validation loss: 0.6140218377113342
Epoch: 29/300 - Train loss: 0.6110285520553589, Validation loss: 0.6097625494003296
Epoch: 30/300 - Train loss: 0.6066864132881165, Validation loss: 0.6056491732597351
Epoch: 31/300 - Train loss: 0.6022798418998718, Validation loss: 0.6010816097259521
Epoch: 32/300 - Train loss: 0.5978196263313293, Validation loss: 0.5964722037315369
Epoch: 33/300 - Train loss: 0.5933139324188232, Validation loss: 0.5924345850944519
Epoch: 34/300 - Train loss: 0.5887727737426758, Validation loss: 0.5876380801200867
Epoch: 35/300 - Train loss: 0.5842007994651794, Validation loss: 0.5831016898155212
Epoch: 36/300 - Train loss: 0.5796009302139282, Validation loss: 0.5781224370002747
Epoch: 37/300 - Train loss: 0.5749881863594055, Validation loss: 0.5739487409591675
Epoch: 38/300 - Train loss: 0.5703660845756531, Validation loss: 0.5691773891448975
Epoch: 39/300 - Train loss: 0.5657420754432678, Validation loss: 0.5646482110023499
Epoch: 40/300 - Train loss: 0.5611225366592407, Validation loss: 0.5597678422927856
Epoch: 41/300 - Train loss: 0.556512713432312, Validation loss: 0.5551944971084595
Epoch: 42/300 - Train loss: 0.5519168972969055, Validation loss: 0.5506904125213623
Epoch: 43/300 - Train loss: 0.5473417639732361, Validation loss: 0.5463289618492126
Epoch: 44/300 - Train loss: 0.5427900552749634, Validation loss: 0.5416090488433838
Epoch: 45/300 - Train loss: 0.5382700562477112, Validation loss: 0.537111759185791
Epoch: 46/300 - Train loss: 0.5337851643562317, Validation loss: 0.5326236486434937
Epoch: 47/300 - Train loss: 0.5293407440185547, Validation loss: 0.5281756520271301
Epoch: 48/300 - Train loss: 0.5249391794204712, Validation loss: 0.5233778357505798
Epoch: 49/300 - Train loss: 0.5205842852592468, Validation loss: 0.5195414423942566
Epoch: 50/300 - Train loss: 0.5162819027900696, Validation loss: 0.5150846242904663
Epoch: 51/300 - Train loss: 0.5120359063148499, Validation loss: 0.5105581283569336
Epoch: 52/300 - Train loss: 0.5078487992286682, Validation loss: 0.5063958168029785
Epoch: 53/300 - Train loss: 0.5037248134613037, Validation loss: 0.5021548271179199
Epoch: 54/300 - Train loss: 0.49966686964035034, Validation loss: 0.49821963906288147
Epoch: 55/300 - Train loss: 0.4956764578819275, Validation loss: 0.49456003308296204
Epoch: 56/300 - Train loss: 0.4917563796043396, Validation loss: 0.49029573798179626
Epoch: 57/300 - Train loss: 0.4879077672958374, Validation loss: 0.4860297441482544
Epoch: 58/300 - Train loss: 0.4841329753398895, Validation loss: 0.4832508862018585
Epoch: 59/300 - Train loss: 0.4804338812828064, Validation loss: 0.4789336323738098
Epoch: 60/300 - Train loss: 0.47681158781051636, Validation loss: 0.4752412736415863
Epoch: 61/300 - Train loss: 0.4732676148414612, Validation loss: 0.4718938171863556
Epoch: 62/300 - Train loss: 0.46980294585227966, Validation loss: 0.4680950939655304
Epoch: 63/300 - Train loss: 0.4664188325405121, Validation loss: 0.4650230407714844
Epoch: 64/300 - Train loss: 0.4631161093711853, Validation loss: 0.4615359902381897
Epoch: 65/300 - Train loss: 0.45989519357681274, Validation loss: 0.4583290219306946
Epoch: 66/300 - Train loss: 0.45675474405288696, Validation loss: 0.4553464949131012
Epoch: 67/300 - Train loss: 0.45369330048561096, Validation loss: 0.45232611894607544
Epoch: 68/300 - Train loss: 0.45071178674697876, Validation loss: 0.44951850175857544
Epoch: 69/300 - Train loss: 0.4478110671043396, Validation loss: 0.4466378688812256
Epoch: 70/300 - Train loss: 0.4449893832206726, Validation loss: 0.4435725510120392
Epoch: 71/300 - Train loss: 0.4422464072704315, Validation loss: 0.44094517827033997
Epoch: 72/300 - Train loss: 0.43958181142807007, Validation loss: 0.4381454288959503
Epoch: 73/300 - Train loss: 0.4369935095310211, Validation loss: 0.4355278015136719
Epoch: 74/300 - Train loss: 0.4344800114631653, Validation loss: 0.4326232671737671
Epoch: 75/300 - Train loss: 0.43203985691070557, Validation loss: 0.4305334687232971
Epoch: 76/300 - Train loss: 0.4296715259552002, Validation loss: 0.427946537733078
Epoch: 77/300 - Train loss: 0.42737388610839844, Validation loss: 0.4258338212966919
Epoch: 78/300 - Train loss: 0.42514583468437195, Validation loss: 0.42380598187446594
Epoch: 79/300 - Train loss: 0.42298540472984314, Validation loss: 0.42158469557762146
Epoch: 80/300 - Train loss: 0.4208909571170807, Validation loss: 0.4193095564842224
Epoch: 81/300 - Train loss: 0.4188607931137085, Validation loss: 0.41697216033935547
Epoch: 82/300 - Train loss: 0.4168921709060669, Validation loss: 0.4150325655937195
Epoch: 83/300 - Train loss: 0.41498303413391113, Validation loss: 0.4135366380214691
Epoch: 84/300 - Train loss: 0.41313064098358154, Validation loss: 0.4113590717315674
Epoch: 85/300 - Train loss: 0.41133421659469604, Validation loss: 0.409768283367157
Epoch: 86/300 - Train loss: 0.4095920920372009, Validation loss: 0.4078575074672699
Epoch: 87/300 - Train loss: 0.40790241956710815, Validation loss: 0.40610161423683167
Epoch: 88/300 - Train loss: 0.406263530254364, Validation loss: 0.4046393036842346
Epoch: 89/300 - Train loss: 0.40467268228530884, Validation loss: 0.40318629145622253
Epoch: 90/300 - Train loss: 0.4031280279159546, Validation loss: 0.40172675251960754
Epoch: 91/300 - Train loss: 0.40162795782089233, Validation loss: 0.40014949440956116
Epoch: 92/300 - Train loss: 0.40017032623291016, Validation loss: 0.39942675828933716
Epoch: 93/300 - Train loss: 0.39875292778015137, Validation loss: 0.39692890644073486
Epoch: 94/300 - Train loss: 0.3973745107650757, Validation loss: 0.39579376578330994
Epoch: 95/300 - Train loss: 0.3960335850715637, Validation loss: 0.39437350630760193
Epoch: 96/300 - Train loss: 0.39472779631614685, Validation loss: 0.3928985893726349
Epoch: 97/300 - Train loss: 0.3934553861618042, Validation loss: 0.3914380371570587
Epoch: 98/300 - Train loss: 0.39221638441085815, Validation loss: 0.3905421197414398
Epoch: 99/300 - Train loss: 0.3910087049007416, Validation loss: 0.3896554112434387
Epoch: 100/300 - Train loss: 0.3898308575153351, Validation loss: 0.3880358338356018
Epoch: 101/300 - Train loss: 0.38868170976638794, Validation loss: 0.3871387541294098
Epoch: 102/300 - Train loss: 0.3875595033168793, Validation loss: 0.3862871527671814
Epoch: 103/300 - Train loss: 0.3864629864692688, Validation loss: 0.3844947814941406
Epoch: 104/300 - Train loss: 0.3853910565376282, Validation loss: 0.3832447826862335
Epoch: 105/300 - Train loss: 0.38434338569641113, Validation loss: 0.38264894485473633
Epoch: 106/300 - Train loss: 0.3833184540271759, Validation loss: 0.3814214766025543
Epoch: 107/300 - Train loss: 0.38231438398361206, Validation loss: 0.3804018795490265
Epoch: 108/300 - Train loss: 0.3813307583332062, Validation loss: 0.3797348737716675
Epoch: 109/300 - Train loss: 0.3803670406341553, Validation loss: 0.3785373866558075
Epoch: 110/300 - Train loss: 0.37942269444465637, Validation loss: 0.3772940933704376
Epoch: 111/300 - Train loss: 0.3784964978694916, Validation loss: 0.37607258558273315
Epoch: 112/300 - Train loss: 0.37758684158325195, Validation loss: 0.3756003677845001
Epoch: 113/300 - Train loss: 0.37669500708580017, Validation loss: 0.37426963448524475
Epoch: 114/300 - Train loss: 0.3758183717727661, Validation loss: 0.3731793463230133
Epoch: 115/300 - Train loss: 0.3749578595161438, Validation loss: 0.3730798363685608
Epoch: 116/300 - Train loss: 0.3741128444671631, Validation loss: 0.371985524892807
Epoch: 117/300 - Train loss: 0.37328314781188965, Validation loss: 0.3717050850391388
Epoch: 118/300 - Train loss: 0.37246862053871155, Validation loss: 0.370140016078949
Epoch: 119/300 - Train loss: 0.3716675341129303, Validation loss: 0.3689561188220978
Epoch: 120/300 - Train loss: 0.3708796203136444, Validation loss: 0.3688139021396637
Epoch: 121/300 - Train loss: 0.37010398507118225, Validation loss: 0.36754176020622253
Epoch: 122/300 - Train loss: 0.36934101581573486, Validation loss: 0.3671269714832306
Epoch: 123/300 - Train loss: 0.3685908317565918, Validation loss: 0.3657205104827881
Epoch: 124/300 - Train loss: 0.367853045463562, Validation loss: 0.3651728332042694
Epoch: 125/300 - Train loss: 0.3671259582042694, Validation loss: 0.3646496534347534
Epoch: 126/300 - Train loss: 0.3664100766181946, Validation loss: 0.36403849720954895
Epoch: 127/300 - Train loss: 0.3657037913799286, Validation loss: 0.3633972704410553
Epoch: 128/300 - Train loss: 0.3650071322917938, Validation loss: 0.3623690903186798
Epoch: 129/300 - Train loss: 0.3643209636211395, Validation loss: 0.36203479766845703
Epoch: 130/300 - Train loss: 0.36364394426345825, Validation loss: 0.36102494597435
Epoch: 131/300 - Train loss: 0.36297571659088135, Validation loss: 0.35996511578559875
Epoch: 132/300 - Train loss: 0.36231672763824463, Validation loss: 0.3600603938102722
Epoch: 133/300 - Train loss: 0.36166638135910034, Validation loss: 0.35917577147483826
Epoch: 134/300 - Train loss: 0.36102375388145447, Validation loss: 0.35829371213912964
Epoch: 135/300 - Train loss: 0.36038830876350403, Validation loss: 0.35820719599723816
Epoch: 136/300 - Train loss: 0.35975998640060425, Validation loss: 0.3570043444633484
Epoch: 137/300 - Train loss: 0.3591386675834656, Validation loss: 0.3570074439048767
Epoch: 138/300 - Train loss: 0.3585246205329895, Validation loss: 0.3557630777359009
Epoch: 139/300 - Train loss: 0.3579176366329193, Validation loss: 0.3550247550010681
Epoch: 140/300 - Train loss: 0.35731738805770874, Validation loss: 0.3545103073120117
Epoch: 141/300 - Train loss: 0.35672280192375183, Validation loss: 0.35397741198539734
Epoch: 142/300 - Train loss: 0.35613471269607544, Validation loss: 0.3538375794887543
Epoch: 143/300 - Train loss: 0.3555533289909363, Validation loss: 0.352388858795166
Epoch: 144/300 - Train loss: 0.3549778461456299, Validation loss: 0.35224297642707825
Epoch: 145/300 - Train loss: 0.3544081151485443, Validation loss: 0.3514624536037445
Epoch: 146/300 - Train loss: 0.3538445830345154, Validation loss: 0.35166817903518677
Epoch: 147/300 - Train loss: 0.3532877266407013, Validation loss: 0.35064128041267395
Epoch: 148/300 - Train loss: 0.3527372181415558, Validation loss: 0.3500659167766571
