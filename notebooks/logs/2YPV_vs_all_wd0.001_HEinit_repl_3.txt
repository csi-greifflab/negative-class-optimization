Epoch: 1/300 - Train loss: 0.7017782926559448, Validation loss: 0.701107382774353
Epoch: 2/300 - Train loss: 0.6999831795692444, Validation loss: 0.6993292570114136
Epoch: 3/300 - Train loss: 0.6982083320617676, Validation loss: 0.6976119875907898
Epoch: 4/300 - Train loss: 0.6964446902275085, Validation loss: 0.6957366466522217
Epoch: 5/300 - Train loss: 0.6946814656257629, Validation loss: 0.6940779089927673
Epoch: 6/300 - Train loss: 0.6929032206535339, Validation loss: 0.6922629475593567
Epoch: 7/300 - Train loss: 0.6910871863365173, Validation loss: 0.6904821991920471
Epoch: 8/300 - Train loss: 0.6892154812812805, Validation loss: 0.688393771648407
Epoch: 9/300 - Train loss: 0.6872766613960266, Validation loss: 0.6862793564796448
Epoch: 10/300 - Train loss: 0.6852582693099976, Validation loss: 0.6843653321266174
Epoch: 11/300 - Train loss: 0.6831539273262024, Validation loss: 0.6821694374084473
Epoch: 12/300 - Train loss: 0.6809570789337158, Validation loss: 0.679673433303833
Epoch: 13/300 - Train loss: 0.6786627769470215, Validation loss: 0.6773197054862976
Epoch: 14/300 - Train loss: 0.6762691140174866, Validation loss: 0.6748271584510803
Epoch: 15/300 - Train loss: 0.6737695932388306, Validation loss: 0.6722748279571533
Epoch: 16/300 - Train loss: 0.6711599826812744, Validation loss: 0.6692749261856079
Epoch: 17/300 - Train loss: 0.668438196182251, Validation loss: 0.6665688157081604
Epoch: 18/300 - Train loss: 0.6656034588813782, Validation loss: 0.6635608673095703
Epoch: 19/300 - Train loss: 0.6626599431037903, Validation loss: 0.660470187664032
Epoch: 20/300 - Train loss: 0.6596076488494873, Validation loss: 0.6574074029922485
Epoch: 21/300 - Train loss: 0.6564473509788513, Validation loss: 0.6540958285331726
Epoch: 22/300 - Train loss: 0.6531829833984375, Validation loss: 0.650762677192688
Epoch: 23/300 - Train loss: 0.6498132944107056, Validation loss: 0.647314190864563
Epoch: 24/300 - Train loss: 0.6463437080383301, Validation loss: 0.6436488032341003
Epoch: 25/300 - Train loss: 0.6427847146987915, Validation loss: 0.6400078535079956
Epoch: 26/300 - Train loss: 0.6391395926475525, Validation loss: 0.6361969709396362
Epoch: 27/300 - Train loss: 0.6354101896286011, Validation loss: 0.6324295997619629
Epoch: 28/300 - Train loss: 0.6316055655479431, Validation loss: 0.6285483837127686
Epoch: 29/300 - Train loss: 0.6277295351028442, Validation loss: 0.6245355606079102
Epoch: 30/300 - Train loss: 0.6237837076187134, Validation loss: 0.6206075549125671
Epoch: 31/300 - Train loss: 0.6197745203971863, Validation loss: 0.6164639592170715
Epoch: 32/300 - Train loss: 0.61570805311203, Validation loss: 0.6124014854431152
Epoch: 33/300 - Train loss: 0.6115890145301819, Validation loss: 0.6080029606819153
Epoch: 34/300 - Train loss: 0.6074225306510925, Validation loss: 0.6040244698524475
Epoch: 35/300 - Train loss: 0.603217363357544, Validation loss: 0.5998674035072327
Epoch: 36/300 - Train loss: 0.5989748239517212, Validation loss: 0.595646321773529
Epoch: 37/300 - Train loss: 0.5947009325027466, Validation loss: 0.5911648273468018
Epoch: 38/300 - Train loss: 0.5903982520103455, Validation loss: 0.5869090557098389
Epoch: 39/300 - Train loss: 0.5860702991485596, Validation loss: 0.5825981497764587
Epoch: 40/300 - Train loss: 0.5817192792892456, Validation loss: 0.5781177282333374
Epoch: 41/300 - Train loss: 0.5773509740829468, Validation loss: 0.5737801790237427
Epoch: 42/300 - Train loss: 0.5729691386222839, Validation loss: 0.5694229006767273
Epoch: 43/300 - Train loss: 0.5685792565345764, Validation loss: 0.5649933218955994
Epoch: 44/300 - Train loss: 0.5641855597496033, Validation loss: 0.5605753660202026
Epoch: 45/300 - Train loss: 0.5597919225692749, Validation loss: 0.5562573671340942
Epoch: 46/300 - Train loss: 0.5554019808769226, Validation loss: 0.5517151951789856
Epoch: 47/300 - Train loss: 0.5510191917419434, Validation loss: 0.547385573387146
Epoch: 48/300 - Train loss: 0.5466466546058655, Validation loss: 0.5432869791984558
Epoch: 49/300 - Train loss: 0.5422893166542053, Validation loss: 0.5387497544288635
Epoch: 50/300 - Train loss: 0.5379504561424255, Validation loss: 0.534630537033081
Epoch: 51/300 - Train loss: 0.5336337685585022, Validation loss: 0.5304146409034729
Epoch: 52/300 - Train loss: 0.5293432474136353, Validation loss: 0.5261417627334595
Epoch: 53/300 - Train loss: 0.5250819325447083, Validation loss: 0.5216671228408813
Epoch: 54/300 - Train loss: 0.5208534598350525, Validation loss: 0.5176239013671875
Epoch: 55/300 - Train loss: 0.5166605114936829, Validation loss: 0.513303816318512
Epoch: 56/300 - Train loss: 0.5125057697296143, Validation loss: 0.5095095038414001
Epoch: 57/300 - Train loss: 0.5083926916122437, Validation loss: 0.5052099227905273
Epoch: 58/300 - Train loss: 0.5043238997459412, Validation loss: 0.5008601546287537
Epoch: 59/300 - Train loss: 0.5003018975257874, Validation loss: 0.4972241222858429
Epoch: 60/300 - Train loss: 0.49632927775382996, Validation loss: 0.4934700131416321
Epoch: 61/300 - Train loss: 0.49240732192993164, Validation loss: 0.48959827423095703
Epoch: 62/300 - Train loss: 0.48853811621665955, Validation loss: 0.48559901118278503
Epoch: 63/300 - Train loss: 0.48472315073013306, Validation loss: 0.4816267490386963
Epoch: 64/300 - Train loss: 0.48096445202827454, Validation loss: 0.4784059524536133
Epoch: 65/300 - Train loss: 0.47726279497146606, Validation loss: 0.47500893473625183
Epoch: 66/300 - Train loss: 0.473619282245636, Validation loss: 0.47052013874053955
Epoch: 67/300 - Train loss: 0.4700351059436798, Validation loss: 0.46760693192481995
Epoch: 68/300 - Train loss: 0.46651092171669006, Validation loss: 0.46410441398620605
Epoch: 69/300 - Train loss: 0.46304744482040405, Validation loss: 0.4606272876262665
Epoch: 70/300 - Train loss: 0.45964521169662476, Validation loss: 0.4568389058113098
Epoch: 71/300 - Train loss: 0.45630520582199097, Validation loss: 0.45414528250694275
Epoch: 72/300 - Train loss: 0.45302698016166687, Validation loss: 0.4509392976760864
Epoch: 73/300 - Train loss: 0.4498112201690674, Validation loss: 0.4473712146282196
Epoch: 74/300 - Train loss: 0.44665807485580444, Validation loss: 0.44468021392822266
Epoch: 75/300 - Train loss: 0.44356656074523926, Validation loss: 0.4411354959011078
Epoch: 76/300 - Train loss: 0.4405369758605957, Validation loss: 0.4382757842540741
Epoch: 77/300 - Train loss: 0.43756920099258423, Validation loss: 0.4356934130191803
Epoch: 78/300 - Train loss: 0.4346630871295929, Validation loss: 0.4324566423892975
Epoch: 79/300 - Train loss: 0.4318174123764038, Validation loss: 0.42956167459487915
Epoch: 80/300 - Train loss: 0.42903172969818115, Validation loss: 0.4271124005317688
Epoch: 81/300 - Train loss: 0.42630478739738464, Validation loss: 0.42399147152900696
Epoch: 82/300 - Train loss: 0.4236358106136322, Validation loss: 0.42135170102119446
Epoch: 83/300 - Train loss: 0.4210244417190552, Validation loss: 0.4188443124294281
Epoch: 84/300 - Train loss: 0.4184694290161133, Validation loss: 0.41601526737213135
Epoch: 85/300 - Train loss: 0.4159700572490692, Validation loss: 0.4135791063308716
Epoch: 86/300 - Train loss: 0.41352543234825134, Validation loss: 0.41149279475212097
Epoch: 87/300 - Train loss: 0.41113394498825073, Validation loss: 0.4093432128429413
Epoch: 88/300 - Train loss: 0.4087948501110077, Validation loss: 0.4066925048828125
Epoch: 89/300 - Train loss: 0.40650618076324463, Validation loss: 0.4043444097042084
Epoch: 90/300 - Train loss: 0.4042678475379944, Validation loss: 0.40283527970314026
Epoch: 91/300 - Train loss: 0.402078777551651, Validation loss: 0.40032485127449036
Epoch: 92/300 - Train loss: 0.3999379277229309, Validation loss: 0.39762887358665466
Epoch: 93/300 - Train loss: 0.3978436589241028, Validation loss: 0.3959938883781433
Epoch: 94/300 - Train loss: 0.3957955837249756, Validation loss: 0.39348268508911133
Epoch: 95/300 - Train loss: 0.39379218220710754, Validation loss: 0.3918032646179199
Epoch: 96/300 - Train loss: 0.3918322026729584, Validation loss: 0.38954830169677734
Epoch: 97/300 - Train loss: 0.38991475105285645, Validation loss: 0.388054758310318
Epoch: 98/300 - Train loss: 0.3880385756492615, Validation loss: 0.3858887553215027
Epoch: 99/300 - Train loss: 0.3862019181251526, Validation loss: 0.38393962383270264
Epoch: 100/300 - Train loss: 0.38440364599227905, Validation loss: 0.38205042481422424
Epoch: 101/300 - Train loss: 0.3826427757740021, Validation loss: 0.38025742769241333
Epoch: 102/300 - Train loss: 0.38091856241226196, Validation loss: 0.3789949119091034
Epoch: 103/300 - Train loss: 0.37923112511634827, Validation loss: 0.3768572509288788
Epoch: 104/300 - Train loss: 0.3775794506072998, Validation loss: 0.3752566874027252
Epoch: 105/300 - Train loss: 0.3759635388851166, Validation loss: 0.37327080965042114
Epoch: 106/300 - Train loss: 0.37438225746154785, Validation loss: 0.3720152676105499
Epoch: 107/300 - Train loss: 0.37283480167388916, Validation loss: 0.3702727258205414
Epoch: 108/300 - Train loss: 0.37131962180137634, Validation loss: 0.369110643863678
Epoch: 109/300 - Train loss: 0.3698350787162781, Validation loss: 0.36734119057655334
Epoch: 110/300 - Train loss: 0.36838075518608093, Validation loss: 0.3658367395401001
Epoch: 111/300 - Train loss: 0.3669562339782715, Validation loss: 0.36484989523887634
Epoch: 112/300 - Train loss: 0.36556148529052734, Validation loss: 0.36308422684669495
Epoch: 113/300 - Train loss: 0.36419588327407837, Validation loss: 0.36150920391082764
Epoch: 114/300 - Train loss: 0.36285796761512756, Validation loss: 0.3600773513317108
Epoch: 115/300 - Train loss: 0.3615467846393585, Validation loss: 0.35859912633895874
Epoch: 116/300 - Train loss: 0.36026254296302795, Validation loss: 0.35697370767593384
Epoch: 117/300 - Train loss: 0.35900434851646423, Validation loss: 0.35574793815612793
Epoch: 118/300 - Train loss: 0.3577704429626465, Validation loss: 0.35477006435394287
Epoch: 119/300 - Train loss: 0.35655781626701355, Validation loss: 0.3534334897994995
Epoch: 120/300 - Train loss: 0.35536646842956543, Validation loss: 0.35272979736328125
Epoch: 121/300 - Train loss: 0.35419660806655884, Validation loss: 0.35105419158935547
Epoch: 122/300 - Train loss: 0.353047639131546, Validation loss: 0.35047203302383423
Epoch: 123/300 - Train loss: 0.3519207239151001, Validation loss: 0.34925729036331177
Epoch: 124/300 - Train loss: 0.35081374645233154, Validation loss: 0.34761950373649597
Epoch: 125/300 - Train loss: 0.34972718358039856, Validation loss: 0.3466021716594696
Epoch: 126/300 - Train loss: 0.34866002202033997, Validation loss: 0.34550580382347107
Epoch: 127/300 - Train loss: 0.3476119637489319, Validation loss: 0.3450040817260742
Epoch: 128/300 - Train loss: 0.3465837240219116, Validation loss: 0.3435474634170532
Epoch: 129/300 - Train loss: 0.3455747663974762, Validation loss: 0.34297919273376465
Epoch: 130/300 - Train loss: 0.3445841670036316, Validation loss: 0.3414098620414734
Epoch: 131/300 - Train loss: 0.34361040592193604, Validation loss: 0.34105560183525085
Epoch: 132/300 - Train loss: 0.34265342354774475, Validation loss: 0.34040331840515137
Epoch: 133/300 - Train loss: 0.3417127728462219, Validation loss: 0.3396356403827667
Epoch: 134/300 - Train loss: 0.3407890200614929, Validation loss: 0.33800944685935974
Epoch: 135/300 - Train loss: 0.33988305926322937, Validation loss: 0.3376036286354065
Epoch: 136/300 - Train loss: 0.3389926850795746, Validation loss: 0.3367413580417633
Epoch: 137/300 - Train loss: 0.3381195664405823, Validation loss: 0.33575937151908875
Epoch: 138/300 - Train loss: 0.33726099133491516, Validation loss: 0.3353550434112549
Epoch: 139/300 - Train loss: 0.336416095495224, Validation loss: 0.33341267704963684
Epoch: 140/300 - Train loss: 0.3355838358402252, Validation loss: 0.3329826295375824
Epoch: 141/300 - Train loss: 0.33476588129997253, Validation loss: 0.33218249678611755
Epoch: 142/300 - Train loss: 0.33396220207214355, Validation loss: 0.33166050910949707
Epoch: 143/300 - Train loss: 0.3331736922264099, Validation loss: 0.3310668468475342
Epoch: 144/300 - Train loss: 0.33239930868148804, Validation loss: 0.32948002219200134
Epoch: 145/300 - Train loss: 0.33163803815841675, Validation loss: 0.3289128243923187
Epoch: 146/300 - Train loss: 0.3308894634246826, Validation loss: 0.3280790448188782
Epoch: 147/300 - Train loss: 0.33015352487564087, Validation loss: 0.32803404331207275
Epoch: 148/300 - Train loss: 0.32942989468574524, Validation loss: 0.32734864950180054
Epoch: 149/300 - Train loss: 0.32871878147125244, Validation loss: 0.3263346552848816
Epoch: 150/300 - Train loss: 0.328020840883255, Validation loss: 0.3255952000617981
Epoch: 151/300 - Train loss: 0.32733339071273804, Validation loss: 0.3251056373119354
Epoch: 152/300 - Train loss: 0.3266569674015045, Validation loss: 0.32454627752304077
Epoch: 153/300 - Train loss: 0.3259907066822052, Validation loss: 0.3241336941719055
Epoch: 154/300 - Train loss: 0.32533398270606995, Validation loss: 0.3225201964378357
Epoch: 155/300 - Train loss: 0.32468754053115845, Validation loss: 0.3224058151245117
Epoch: 156/300 - Train loss: 0.3240514099597931, Validation loss: 0.32195544242858887
Epoch: 157/300 - Train loss: 0.32342514395713806, Validation loss: 0.3212844431400299
Epoch: 158/300 - Train loss: 0.32280799746513367, Validation loss: 0.3210744857788086
Epoch: 159/300 - Train loss: 0.3222004771232605, Validation loss: 0.3199017345905304
Epoch: 160/300 - Train loss: 0.321603387594223, Validation loss: 0.3193656802177429
Epoch: 161/300 - Train loss: 0.3210158348083496, Validation loss: 0.31956541538238525
Epoch: 162/300 - Train loss: 0.3204374611377716, Validation loss: 0.31854620575904846
Epoch: 163/300 - Train loss: 0.3198678493499756, Validation loss: 0.3175966739654541
