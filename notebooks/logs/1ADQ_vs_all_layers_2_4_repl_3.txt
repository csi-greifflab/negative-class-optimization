Epoch: 1/200 - Train loss: 0.5900728702545166, Validation loss: 0.5082404613494873
Epoch: 2/200 - Train loss: 0.48648959398269653, Validation loss: 0.4835450053215027
Epoch: 3/200 - Train loss: 0.46619096398353577, Validation loss: 0.46919703483581543
Epoch: 4/200 - Train loss: 0.45467108488082886, Validation loss: 0.46061190962791443
Epoch: 5/200 - Train loss: 0.4478502869606018, Validation loss: 0.45582255721092224
Epoch: 6/200 - Train loss: 0.44225409626960754, Validation loss: 0.45297932624816895
Epoch: 7/200 - Train loss: 0.4381847679615021, Validation loss: 0.4510384798049927
Epoch: 8/200 - Train loss: 0.43407031893730164, Validation loss: 0.4462040066719055
Epoch: 9/200 - Train loss: 0.43030408024787903, Validation loss: 0.4460986852645874
Epoch: 10/200 - Train loss: 0.4270261526107788, Validation loss: 0.441732257604599
Epoch: 11/200 - Train loss: 0.4238167405128479, Validation loss: 0.43830606341362
Epoch: 12/200 - Train loss: 0.4203740954399109, Validation loss: 0.4345603883266449
Epoch: 13/200 - Train loss: 0.41777709126472473, Validation loss: 0.4336945414543152
Epoch: 14/200 - Train loss: 0.4148426949977875, Validation loss: 0.4316030740737915
Epoch: 15/200 - Train loss: 0.41297778487205505, Validation loss: 0.43229275941848755
Epoch: 16/200 - Train loss: 0.4113127589225769, Validation loss: 0.4289079010486603
Epoch: 17/200 - Train loss: 0.4098165035247803, Validation loss: 0.42793309688568115
Epoch: 18/200 - Train loss: 0.4085420072078705, Validation loss: 0.4278026819229126
Epoch: 19/200 - Train loss: 0.40724191069602966, Validation loss: 0.42832812666893005
Epoch: 20/200 - Train loss: 0.4062165319919586, Validation loss: 0.4271981120109558
Epoch: 21/200 - Train loss: 0.40574705600738525, Validation loss: 0.4258253574371338
Epoch: 22/200 - Train loss: 0.4050121307373047, Validation loss: 0.42481598258018494
Epoch: 23/200 - Train loss: 0.40378233790397644, Validation loss: 0.4244232475757599
Epoch: 24/200 - Train loss: 0.4035816192626953, Validation loss: 0.4261700510978699
Epoch: 25/200 - Train loss: 0.40239614248275757, Validation loss: 0.4206502139568329
Epoch: 26/200 - Train loss: 0.40228572487831116, Validation loss: 0.4213452935218811
Epoch: 27/200 - Train loss: 0.4016277492046356, Validation loss: 0.4216160774230957
Epoch: 28/200 - Train loss: 0.400936096906662, Validation loss: 0.4196636378765106
Epoch: 29/200 - Train loss: 0.40086108446121216, Validation loss: 0.42488551139831543
Epoch: 30/200 - Train loss: 0.40043479204177856, Validation loss: 0.4210330545902252
Epoch: 31/200 - Train loss: 0.39944514632225037, Validation loss: 0.4200293719768524
Epoch: 32/200 - Train loss: 0.39931634068489075, Validation loss: 0.42056065797805786
Epoch: 33/200 - Train loss: 0.39902371168136597, Validation loss: 0.41996899247169495
Epoch: 34/200 - Train loss: 0.39907780289649963, Validation loss: 0.42296507954597473
Epoch: 35/200 - Train loss: 0.3992525041103363, Validation loss: 0.4198732376098633
Epoch: 36/200 - Train loss: 0.39853981137275696, Validation loss: 0.42078113555908203
Epoch: 37/200 - Train loss: 0.3985745310783386, Validation loss: 0.41907256841659546
Epoch: 38/200 - Train loss: 0.3984907269477844, Validation loss: 0.42130064964294434
Epoch: 39/200 - Train loss: 0.398273766040802, Validation loss: 0.4204652011394501
