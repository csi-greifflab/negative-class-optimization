Epoch: 1/200 - Train loss: 0.5668453574180603, Validation loss: 0.4944148361682892
Epoch: 2/200 - Train loss: 0.4664519727230072, Validation loss: 0.45468348264694214
Epoch: 3/200 - Train loss: 0.4271048605442047, Validation loss: 0.4222668409347534
Epoch: 4/200 - Train loss: 0.39002275466918945, Validation loss: 0.3916502892971039
Epoch: 5/200 - Train loss: 0.35641029477119446, Validation loss: 0.3616034984588623
Epoch: 6/200 - Train loss: 0.32884180545806885, Validation loss: 0.34996169805526733
Epoch: 7/200 - Train loss: 0.3111373782157898, Validation loss: 0.3316677212715149
Epoch: 8/200 - Train loss: 0.29682523012161255, Validation loss: 0.3246215879917145
Epoch: 9/200 - Train loss: 0.28703773021698, Validation loss: 0.3152405619621277
Epoch: 10/200 - Train loss: 0.27833324670791626, Validation loss: 0.3119186758995056
Epoch: 11/200 - Train loss: 0.2695816457271576, Validation loss: 0.3054322600364685
Epoch: 12/200 - Train loss: 0.2640259861946106, Validation loss: 0.3065018057823181
Epoch: 13/200 - Train loss: 0.2573182284832001, Validation loss: 0.30007147789001465
Epoch: 14/200 - Train loss: 0.2525603771209717, Validation loss: 0.298453688621521
Epoch: 15/200 - Train loss: 0.24929016828536987, Validation loss: 0.30015358328819275
Epoch: 16/200 - Train loss: 0.24533696472644806, Validation loss: 0.29138073325157166
Epoch: 17/200 - Train loss: 0.24340775609016418, Validation loss: 0.2894039750099182
Epoch: 18/200 - Train loss: 0.24018457531929016, Validation loss: 0.2897207736968994
Epoch: 19/200 - Train loss: 0.23715271055698395, Validation loss: 0.2845824658870697
Epoch: 20/200 - Train loss: 0.23577375710010529, Validation loss: 0.28701695799827576
Epoch: 21/200 - Train loss: 0.23313753306865692, Validation loss: 0.2846677303314209
Epoch: 22/200 - Train loss: 0.2326662540435791, Validation loss: 0.28667208552360535
Epoch: 23/200 - Train loss: 0.2307281643152237, Validation loss: 0.28736281394958496
Epoch: 24/200 - Train loss: 0.22996582090854645, Validation loss: 0.2832214832305908
Epoch: 25/200 - Train loss: 0.22935794293880463, Validation loss: 0.2788587510585785
Epoch: 26/200 - Train loss: 0.2275400310754776, Validation loss: 0.27650389075279236
Epoch: 27/200 - Train loss: 0.22750940918922424, Validation loss: 0.28143736720085144
Epoch: 28/200 - Train loss: 0.22658655047416687, Validation loss: 0.27876898646354675
Epoch: 29/200 - Train loss: 0.22542449831962585, Validation loss: 0.28039801120758057
Epoch: 30/200 - Train loss: 0.22531236708164215, Validation loss: 0.27292776107788086
Epoch: 31/200 - Train loss: 0.22465939819812775, Validation loss: 0.2735383212566376
Epoch: 32/200 - Train loss: 0.2241344451904297, Validation loss: 0.27800044417381287
Epoch: 33/200 - Train loss: 0.2229016125202179, Validation loss: 0.275205135345459
Epoch: 34/200 - Train loss: 0.22261297702789307, Validation loss: 0.27298852801322937
Epoch: 35/200 - Train loss: 0.22236354649066925, Validation loss: 0.2699280381202698
Epoch: 36/200 - Train loss: 0.22026380896568298, Validation loss: 0.2744007110595703
Epoch: 37/200 - Train loss: 0.2202250063419342, Validation loss: 0.27100828289985657
Epoch: 38/200 - Train loss: 0.21975749731063843, Validation loss: 0.27305081486701965
Epoch: 39/200 - Train loss: 0.22008533775806427, Validation loss: 0.2714199423789978
Epoch: 40/200 - Train loss: 0.21967828273773193, Validation loss: 0.2726204991340637
Epoch: 41/200 - Train loss: 0.21920271217823029, Validation loss: 0.2697882056236267
Epoch: 42/200 - Train loss: 0.21778199076652527, Validation loss: 0.2687130570411682
Epoch: 43/200 - Train loss: 0.21737903356552124, Validation loss: 0.2704257369041443
Epoch: 44/200 - Train loss: 0.21682074666023254, Validation loss: 0.27243858575820923
Epoch: 45/200 - Train loss: 0.21777093410491943, Validation loss: 0.2751297652721405
Epoch: 46/200 - Train loss: 0.21703222393989563, Validation loss: 0.2658441364765167
Epoch: 47/200 - Train loss: 0.21628957986831665, Validation loss: 0.2691057324409485
Epoch: 48/200 - Train loss: 0.21540069580078125, Validation loss: 0.26914626359939575
Epoch: 49/200 - Train loss: 0.21424169838428497, Validation loss: 0.2656733989715576
Epoch: 50/200 - Train loss: 0.2148534655570984, Validation loss: 0.2751365602016449
Epoch: 51/200 - Train loss: 0.21504244208335876, Validation loss: 0.2676548361778259
Epoch: 52/200 - Train loss: 0.2143031805753708, Validation loss: 0.27238714694976807
Epoch: 53/200 - Train loss: 0.21349872648715973, Validation loss: 0.266644150018692
Epoch: 54/200 - Train loss: 0.21434453129768372, Validation loss: 0.2667328119277954
Epoch: 55/200 - Train loss: 0.21386007964611053, Validation loss: 0.26763424277305603
Epoch: 56/200 - Train loss: 0.2136359065771103, Validation loss: 0.26372209191322327
Epoch: 57/200 - Train loss: 0.21350613236427307, Validation loss: 0.26464760303497314
Epoch: 58/200 - Train loss: 0.21282073855400085, Validation loss: 0.2682311236858368
Epoch: 59/200 - Train loss: 0.2121858149766922, Validation loss: 0.26943913102149963
Epoch: 60/200 - Train loss: 0.2123519331216812, Validation loss: 0.2656584680080414
Epoch: 61/200 - Train loss: 0.21180583536624908, Validation loss: 0.26555001735687256
Epoch: 62/200 - Train loss: 0.2115970104932785, Validation loss: 0.2663463354110718
Epoch: 63/200 - Train loss: 0.21183030307292938, Validation loss: 0.2701784372329712
Epoch: 64/200 - Train loss: 0.2110876739025116, Validation loss: 0.2669762969017029
Epoch: 65/200 - Train loss: 0.21150043606758118, Validation loss: 0.26952049136161804
Epoch: 66/200 - Train loss: 0.21101246774196625, Validation loss: 0.26999926567077637
Epoch: 67/200 - Train loss: 0.21016165614128113, Validation loss: 0.2685776650905609
Epoch: 1/200 - Train loss: 0.5607903003692627, Validation loss: 0.47746437788009644
Epoch: 2/200 - Train loss: 0.44815585017204285, Validation loss: 0.43582937121391296
Epoch: 3/200 - Train loss: 0.4078522026538849, Validation loss: 0.40685001015663147
Epoch: 4/200 - Train loss: 0.37053996324539185, Validation loss: 0.37084081768989563
Epoch: 5/200 - Train loss: 0.33764412999153137, Validation loss: 0.3480474352836609
Epoch: 6/200 - Train loss: 0.3150382339954376, Validation loss: 0.3330066502094269
Epoch: 7/200 - Train loss: 0.2981303930282593, Validation loss: 0.32500630617141724
Epoch: 8/200 - Train loss: 0.2876433730125427, Validation loss: 0.3195435702800751
Epoch: 9/200 - Train loss: 0.2790239453315735, Validation loss: 0.3139607608318329
Epoch: 10/200 - Train loss: 0.27369508147239685, Validation loss: 0.3134070932865143
Epoch: 11/200 - Train loss: 0.2682885229587555, Validation loss: 0.3103620409965515
Epoch: 12/200 - Train loss: 0.2643750309944153, Validation loss: 0.30838629603385925
Epoch: 13/200 - Train loss: 0.26102128624916077, Validation loss: 0.3113647997379303
Epoch: 14/200 - Train loss: 0.25852909684181213, Validation loss: 0.30817973613739014
Epoch: 15/200 - Train loss: 0.2548891305923462, Validation loss: 0.30760857462882996
Epoch: 16/200 - Train loss: 0.2528539001941681, Validation loss: 0.3066422939300537
Epoch: 17/200 - Train loss: 0.2512281835079193, Validation loss: 0.30960145592689514
Epoch: 18/200 - Train loss: 0.24920853972434998, Validation loss: 0.3073822259902954
Epoch: 19/200 - Train loss: 0.24749428033828735, Validation loss: 0.3060029149055481
Epoch: 20/200 - Train loss: 0.24584639072418213, Validation loss: 0.3033287525177002
Epoch: 21/200 - Train loss: 0.24482476711273193, Validation loss: 0.30241507291793823
Epoch: 22/200 - Train loss: 0.24351269006729126, Validation loss: 0.30555370450019836
Epoch: 23/200 - Train loss: 0.24180777370929718, Validation loss: 0.3026140034198761
Epoch: 24/200 - Train loss: 0.24127835035324097, Validation loss: 0.30047765374183655
Epoch: 25/200 - Train loss: 0.24033847451210022, Validation loss: 0.3020414412021637
Epoch: 26/200 - Train loss: 0.2398732751607895, Validation loss: 0.3017067611217499
Epoch: 27/200 - Train loss: 0.23913557827472687, Validation loss: 0.3011813461780548
Epoch: 28/200 - Train loss: 0.23824834823608398, Validation loss: 0.30043208599090576
Epoch: 29/200 - Train loss: 0.23681554198265076, Validation loss: 0.3035609722137451
Epoch: 30/200 - Train loss: 0.2365877479314804, Validation loss: 0.2993009388446808
Epoch: 31/200 - Train loss: 0.23613664507865906, Validation loss: 0.30431067943573
Epoch: 32/200 - Train loss: 0.2361851930618286, Validation loss: 0.3015363812446594
Epoch: 33/200 - Train loss: 0.23517338931560516, Validation loss: 0.30331993103027344
Epoch: 34/200 - Train loss: 0.23477017879486084, Validation loss: 0.30567795038223267
Epoch: 35/200 - Train loss: 0.23449356853961945, Validation loss: 0.2991000711917877
Epoch: 36/200 - Train loss: 0.2339179366827011, Validation loss: 0.2982806861400604
Epoch: 37/200 - Train loss: 0.2334708422422409, Validation loss: 0.29634398221969604
Epoch: 38/200 - Train loss: 0.23337291181087494, Validation loss: 0.29618552327156067
Epoch: 39/200 - Train loss: 0.23242007195949554, Validation loss: 0.299284964799881
Epoch: 40/200 - Train loss: 0.23283563554286957, Validation loss: 0.2992710769176483
Epoch: 41/200 - Train loss: 0.23207059502601624, Validation loss: 0.29684093594551086
Epoch: 42/200 - Train loss: 0.23111389577388763, Validation loss: 0.2939327359199524
Epoch: 43/200 - Train loss: 0.23132416605949402, Validation loss: 0.29438135027885437
Epoch: 44/200 - Train loss: 0.2302064597606659, Validation loss: 0.2942717671394348
Epoch: 45/200 - Train loss: 0.22988839447498322, Validation loss: 0.295507550239563
Epoch: 46/200 - Train loss: 0.22971224784851074, Validation loss: 0.2932496964931488
Epoch: 47/200 - Train loss: 0.2289419323205948, Validation loss: 0.295349657535553
Epoch: 48/200 - Train loss: 0.2295701503753662, Validation loss: 0.2919268012046814
Epoch: 49/200 - Train loss: 0.22880154848098755, Validation loss: 0.29374364018440247
Epoch: 50/200 - Train loss: 0.22844724357128143, Validation loss: 0.29530540108680725
