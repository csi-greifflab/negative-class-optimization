Epoch: 1/300 - Train loss: 0.6906970739364624, Validation loss: 0.6875020265579224
Epoch: 2/300 - Train loss: 0.6876125335693359, Validation loss: 0.6845602989196777
Epoch: 3/300 - Train loss: 0.684556782245636, Validation loss: 0.6817331314086914
Epoch: 4/300 - Train loss: 0.6815284490585327, Validation loss: 0.6786353588104248
Epoch: 5/300 - Train loss: 0.6785175800323486, Validation loss: 0.6757625937461853
Epoch: 6/300 - Train loss: 0.675512433052063, Validation loss: 0.6729033589363098
Epoch: 7/300 - Train loss: 0.6725051403045654, Validation loss: 0.6700153946876526
Epoch: 8/300 - Train loss: 0.6694863438606262, Validation loss: 0.6671176552772522
Epoch: 9/300 - Train loss: 0.6664469838142395, Validation loss: 0.6641202569007874
Epoch: 10/300 - Train loss: 0.6633827090263367, Validation loss: 0.6609829068183899
Epoch: 11/300 - Train loss: 0.6602905988693237, Validation loss: 0.6580463647842407
Epoch: 12/300 - Train loss: 0.6571704149246216, Validation loss: 0.6548773050308228
Epoch: 13/300 - Train loss: 0.6540172100067139, Validation loss: 0.651844322681427
Epoch: 14/300 - Train loss: 0.6508265733718872, Validation loss: 0.648686408996582
Epoch: 15/300 - Train loss: 0.6475942134857178, Validation loss: 0.6454808712005615
Epoch: 16/300 - Train loss: 0.644319474697113, Validation loss: 0.6422256827354431
Epoch: 17/300 - Train loss: 0.6409987211227417, Validation loss: 0.6389812231063843
Epoch: 18/300 - Train loss: 0.6376348733901978, Validation loss: 0.6356258988380432
Epoch: 19/300 - Train loss: 0.6342241764068604, Validation loss: 0.6321728229522705
Epoch: 20/300 - Train loss: 0.6307704448699951, Validation loss: 0.6288129687309265
Epoch: 21/300 - Train loss: 0.6272699236869812, Validation loss: 0.6253272294998169
Epoch: 22/300 - Train loss: 0.6237236261367798, Validation loss: 0.6219577789306641
Epoch: 23/300 - Train loss: 0.6201284527778625, Validation loss: 0.6182307600975037
Epoch: 24/300 - Train loss: 0.6164857745170593, Validation loss: 0.6145442128181458
Epoch: 25/300 - Train loss: 0.6127997636795044, Validation loss: 0.6108399629592896
Epoch: 26/300 - Train loss: 0.6090681552886963, Validation loss: 0.6073709726333618
Epoch: 27/300 - Train loss: 0.6052954196929932, Validation loss: 0.6032661199569702
Epoch: 28/300 - Train loss: 0.6014830470085144, Validation loss: 0.5997939109802246
Epoch: 29/300 - Train loss: 0.5976360440254211, Validation loss: 0.595885694026947
Epoch: 30/300 - Train loss: 0.5937567949295044, Validation loss: 0.5918079614639282
Epoch: 31/300 - Train loss: 0.5898481607437134, Validation loss: 0.5879850387573242
Epoch: 32/300 - Train loss: 0.5859145522117615, Validation loss: 0.5843319296836853
Epoch: 33/300 - Train loss: 0.5819599628448486, Validation loss: 0.5800950527191162
Epoch: 34/300 - Train loss: 0.577986478805542, Validation loss: 0.5763715505599976
Epoch: 35/300 - Train loss: 0.5740028023719788, Validation loss: 0.572172999382019
Epoch: 36/300 - Train loss: 0.570014238357544, Validation loss: 0.5681976675987244
Epoch: 37/300 - Train loss: 0.5660234093666077, Validation loss: 0.5642188787460327
Epoch: 38/300 - Train loss: 0.5620319247245789, Validation loss: 0.5601806044578552
Epoch: 39/300 - Train loss: 0.5580416321754456, Validation loss: 0.5559423565864563
Epoch: 40/300 - Train loss: 0.5540559887886047, Validation loss: 0.5526434183120728
Epoch: 41/300 - Train loss: 0.5500810146331787, Validation loss: 0.5485732555389404
Epoch: 42/300 - Train loss: 0.546116828918457, Validation loss: 0.5443549752235413
Epoch: 43/300 - Train loss: 0.5421653985977173, Validation loss: 0.5406554341316223
Epoch: 44/300 - Train loss: 0.5382331013679504, Validation loss: 0.5364672541618347
Epoch: 45/300 - Train loss: 0.5343226790428162, Validation loss: 0.532534658908844
Epoch: 46/300 - Train loss: 0.5304378867149353, Validation loss: 0.5288546085357666
Epoch: 47/300 - Train loss: 0.5265832543373108, Validation loss: 0.5248198509216309
Epoch: 48/300 - Train loss: 0.5227642059326172, Validation loss: 0.5210293531417847
Epoch: 49/300 - Train loss: 0.5189830660820007, Validation loss: 0.5169842839241028
Epoch: 50/300 - Train loss: 0.5152412056922913, Validation loss: 0.5137254595756531
Epoch: 51/300 - Train loss: 0.5115411877632141, Validation loss: 0.5099332928657532
Epoch: 52/300 - Train loss: 0.5078849792480469, Validation loss: 0.5061204433441162
Epoch: 53/300 - Train loss: 0.5042744874954224, Validation loss: 0.502499520778656
Epoch: 54/300 - Train loss: 0.5007121562957764, Validation loss: 0.4988856017589569
Epoch: 55/300 - Train loss: 0.4972030520439148, Validation loss: 0.4955137372016907
Epoch: 56/300 - Train loss: 0.4937487840652466, Validation loss: 0.49242445826530457
Epoch: 57/300 - Train loss: 0.4903509020805359, Validation loss: 0.4887804687023163
Epoch: 58/300 - Train loss: 0.4870125353336334, Validation loss: 0.48541879653930664
Epoch: 59/300 - Train loss: 0.48373517394065857, Validation loss: 0.4820440411567688
Epoch: 60/300 - Train loss: 0.4805188775062561, Validation loss: 0.4785837233066559
Epoch: 61/300 - Train loss: 0.4773642420768738, Validation loss: 0.4756583571434021
Epoch: 62/300 - Train loss: 0.4742727279663086, Validation loss: 0.47228488326072693
Epoch: 63/300 - Train loss: 0.4712448716163635, Validation loss: 0.4698484241962433
Epoch: 64/300 - Train loss: 0.4682822525501251, Validation loss: 0.46637365221977234
Epoch: 65/300 - Train loss: 0.4653860628604889, Validation loss: 0.4636123478412628
Epoch: 66/300 - Train loss: 0.46255648136138916, Validation loss: 0.46090489625930786
Epoch: 67/300 - Train loss: 0.45979413390159607, Validation loss: 0.4577626585960388
Epoch: 68/300 - Train loss: 0.45709773898124695, Validation loss: 0.45532751083374023
Epoch: 69/300 - Train loss: 0.45446667075157166, Validation loss: 0.4524734616279602
Epoch: 70/300 - Train loss: 0.4519023895263672, Validation loss: 0.4498651623725891
Epoch: 71/300 - Train loss: 0.44940510392189026, Validation loss: 0.44714051485061646
Epoch: 72/300 - Train loss: 0.4469738304615021, Validation loss: 0.4453595280647278
Epoch: 73/300 - Train loss: 0.444608211517334, Validation loss: 0.44306501746177673
Epoch: 74/300 - Train loss: 0.4423067271709442, Validation loss: 0.44044187664985657
Epoch: 75/300 - Train loss: 0.44006815552711487, Validation loss: 0.43768519163131714
Epoch: 76/300 - Train loss: 0.4378913342952728, Validation loss: 0.4354255199432373
Epoch: 77/300 - Train loss: 0.43577566742897034, Validation loss: 0.43375247716903687
Epoch: 78/300 - Train loss: 0.4337204694747925, Validation loss: 0.43175867199897766
Epoch: 79/300 - Train loss: 0.43172362446784973, Validation loss: 0.4300045073032379
Epoch: 80/300 - Train loss: 0.4297850430011749, Validation loss: 0.4275144636631012
Epoch: 81/300 - Train loss: 0.4279029667377472, Validation loss: 0.4253886342048645
Epoch: 82/300 - Train loss: 0.42607662081718445, Validation loss: 0.42365437746047974
Epoch: 83/300 - Train loss: 0.42430436611175537, Validation loss: 0.42206326127052307
Epoch: 84/300 - Train loss: 0.4225855767726898, Validation loss: 0.42071667313575745
Epoch: 85/300 - Train loss: 0.4209185838699341, Validation loss: 0.41922029852867126
Epoch: 86/300 - Train loss: 0.41930171847343445, Validation loss: 0.4169236123561859
Epoch: 87/300 - Train loss: 0.417733758687973, Validation loss: 0.41526177525520325
Epoch: 88/300 - Train loss: 0.4162135422229767, Validation loss: 0.41451436281204224
Epoch: 89/300 - Train loss: 0.41473981738090515, Validation loss: 0.41221797466278076
Epoch: 90/300 - Train loss: 0.4133109450340271, Validation loss: 0.41007041931152344
Epoch: 91/300 - Train loss: 0.41192498803138733, Validation loss: 0.4096068739891052
Epoch: 92/300 - Train loss: 0.41058090329170227, Validation loss: 0.40858668088912964
Epoch: 93/300 - Train loss: 0.4092775881290436, Validation loss: 0.406916081905365
Epoch: 94/300 - Train loss: 0.40801334381103516, Validation loss: 0.40582019090652466
Epoch: 95/300 - Train loss: 0.40678703784942627, Validation loss: 0.40388375520706177
Epoch: 96/300 - Train loss: 0.4055975675582886, Validation loss: 0.4026819169521332
Epoch: 97/300 - Train loss: 0.40444353222846985, Validation loss: 0.4021013379096985
Epoch: 98/300 - Train loss: 0.4033236503601074, Validation loss: 0.4006498157978058
Epoch: 99/300 - Train loss: 0.4022361636161804, Validation loss: 0.3988714814186096
Epoch: 100/300 - Train loss: 0.4011800289154053, Validation loss: 0.39802664518356323
Epoch: 101/300 - Train loss: 0.400153785943985, Validation loss: 0.39744648337364197
Epoch: 102/300 - Train loss: 0.3991560935974121, Validation loss: 0.39631035923957825
Epoch: 103/300 - Train loss: 0.3981857895851135, Validation loss: 0.3949905335903168
Epoch: 104/300 - Train loss: 0.3972413241863251, Validation loss: 0.3951082229614258
Epoch: 105/300 - Train loss: 0.3963225781917572, Validation loss: 0.39350950717926025
Epoch: 106/300 - Train loss: 0.39542776346206665, Validation loss: 0.3925890624523163
Epoch: 107/300 - Train loss: 0.3945558965206146, Validation loss: 0.3914611041545868
Epoch: 108/300 - Train loss: 0.39370661973953247, Validation loss: 0.3903651535511017
Epoch: 109/300 - Train loss: 0.3928784132003784, Validation loss: 0.3896152377128601
Epoch: 110/300 - Train loss: 0.39207011461257935, Validation loss: 0.3896652162075043
Epoch: 111/300 - Train loss: 0.3912810683250427, Validation loss: 0.3881179392337799
Epoch: 112/300 - Train loss: 0.3905104696750641, Validation loss: 0.3868621587753296
Epoch: 113/300 - Train loss: 0.38975757360458374, Validation loss: 0.38634738326072693
Epoch: 114/300 - Train loss: 0.3890221118927002, Validation loss: 0.3855607807636261
Epoch: 115/300 - Train loss: 0.3883028030395508, Validation loss: 0.384919673204422
Epoch: 116/300 - Train loss: 0.38759827613830566, Validation loss: 0.3842725455760956
Epoch: 117/300 - Train loss: 0.3869076073169708, Validation loss: 0.3836492598056793
Epoch: 118/300 - Train loss: 0.3862302005290985, Validation loss: 0.38299664855003357
Epoch: 119/300 - Train loss: 0.3855654299259186, Validation loss: 0.38172653317451477
Epoch: 120/300 - Train loss: 0.3849121332168579, Validation loss: 0.3814373016357422
Epoch: 121/300 - Train loss: 0.38427016139030457, Validation loss: 0.3810974061489105
Epoch: 122/300 - Train loss: 0.3836381733417511, Validation loss: 0.3799329698085785
Epoch: 123/300 - Train loss: 0.3830167353153229, Validation loss: 0.3798165023326874
Epoch: 124/300 - Train loss: 0.38240569829940796, Validation loss: 0.378742516040802
Epoch: 125/300 - Train loss: 0.3818032741546631, Validation loss: 0.3789313733577728
Epoch: 126/300 - Train loss: 0.3812088370323181, Validation loss: 0.377419650554657
Epoch: 127/300 - Train loss: 0.3806225657463074, Validation loss: 0.3768000900745392
Epoch: 128/300 - Train loss: 0.38004469871520996, Validation loss: 0.3764669895172119
Epoch: 129/300 - Train loss: 0.3794735074043274, Validation loss: 0.3757752478122711
Epoch: 130/300 - Train loss: 0.37890949845314026, Validation loss: 0.37561142444610596
Epoch: 131/300 - Train loss: 0.37835198640823364, Validation loss: 0.3746318221092224
Epoch: 132/300 - Train loss: 0.3778018653392792, Validation loss: 0.37444007396698
Epoch: 133/300 - Train loss: 0.3772575259208679, Validation loss: 0.37344789505004883
Epoch: 134/300 - Train loss: 0.3767179548740387, Validation loss: 0.3738718628883362
Epoch: 135/300 - Train loss: 0.3761827349662781, Validation loss: 0.37293657660484314
