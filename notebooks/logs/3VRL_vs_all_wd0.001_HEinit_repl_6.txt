Epoch: 1/300 - Train loss: 0.6937499642372131, Validation loss: 0.6923354268074036
Epoch: 2/300 - Train loss: 0.6923849582672119, Validation loss: 0.6909500360488892
Epoch: 3/300 - Train loss: 0.6909992098808289, Validation loss: 0.6896363496780396
Epoch: 4/300 - Train loss: 0.6895827651023865, Validation loss: 0.6880750060081482
Epoch: 5/300 - Train loss: 0.6881284117698669, Validation loss: 0.6867278218269348
Epoch: 6/300 - Train loss: 0.6866232752799988, Validation loss: 0.6850739121437073
Epoch: 7/300 - Train loss: 0.6850544214248657, Validation loss: 0.6834990382194519
Epoch: 8/300 - Train loss: 0.6834095120429993, Validation loss: 0.6818481087684631
Epoch: 9/300 - Train loss: 0.681679368019104, Validation loss: 0.6800386905670166
Epoch: 10/300 - Train loss: 0.6798539161682129, Validation loss: 0.6782728433609009
Epoch: 11/300 - Train loss: 0.6779198050498962, Validation loss: 0.6762166023254395
Epoch: 12/300 - Train loss: 0.6758675575256348, Validation loss: 0.6741271018981934
Epoch: 13/300 - Train loss: 0.6736958622932434, Validation loss: 0.6718230247497559
Epoch: 14/300 - Train loss: 0.6713913083076477, Validation loss: 0.6695814728736877
Epoch: 15/300 - Train loss: 0.6689487099647522, Validation loss: 0.6669145226478577
Epoch: 16/300 - Train loss: 0.6663644313812256, Validation loss: 0.6644715666770935
Epoch: 17/300 - Train loss: 0.6636366844177246, Validation loss: 0.6616042852401733
Epoch: 18/300 - Train loss: 0.6607609391212463, Validation loss: 0.6586515307426453
Epoch: 19/300 - Train loss: 0.6577370762825012, Validation loss: 0.6555542349815369
Epoch: 20/300 - Train loss: 0.6545701622962952, Validation loss: 0.6521786451339722
Epoch: 21/300 - Train loss: 0.6512571573257446, Validation loss: 0.6489584445953369
Epoch: 22/300 - Train loss: 0.6478053331375122, Validation loss: 0.6454631686210632
Epoch: 23/300 - Train loss: 0.6442255973815918, Validation loss: 0.6420442461967468
Epoch: 24/300 - Train loss: 0.6405242085456848, Validation loss: 0.638176679611206
Epoch: 25/300 - Train loss: 0.6367055177688599, Validation loss: 0.6344760656356812
Epoch: 26/300 - Train loss: 0.6327776312828064, Validation loss: 0.6303698420524597
Epoch: 27/300 - Train loss: 0.6287435293197632, Validation loss: 0.6265583038330078
Epoch: 28/300 - Train loss: 0.6246098279953003, Validation loss: 0.6223570108413696
Epoch: 29/300 - Train loss: 0.6203854084014893, Validation loss: 0.6181288361549377
Epoch: 30/300 - Train loss: 0.6160752773284912, Validation loss: 0.6136630773544312
Epoch: 31/300 - Train loss: 0.6116811037063599, Validation loss: 0.6094580888748169
Epoch: 32/300 - Train loss: 0.6072108149528503, Validation loss: 0.6050093770027161
Epoch: 33/300 - Train loss: 0.602671205997467, Validation loss: 0.6006231904029846
Epoch: 34/300 - Train loss: 0.5980665683746338, Validation loss: 0.5959304571151733
Epoch: 35/300 - Train loss: 0.5934061408042908, Validation loss: 0.5912386775016785
Epoch: 36/300 - Train loss: 0.5886909365653992, Validation loss: 0.5869287848472595
Epoch: 37/300 - Train loss: 0.5839291214942932, Validation loss: 0.5818808674812317
Epoch: 38/300 - Train loss: 0.5791235566139221, Validation loss: 0.5773288011550903
Epoch: 39/300 - Train loss: 0.574277400970459, Validation loss: 0.5724624395370483
Epoch: 40/300 - Train loss: 0.5693957209587097, Validation loss: 0.5676189661026001
Epoch: 41/300 - Train loss: 0.5644855499267578, Validation loss: 0.5630874633789062
Epoch: 42/300 - Train loss: 0.5595529675483704, Validation loss: 0.5580653548240662
Epoch: 43/300 - Train loss: 0.5546022057533264, Validation loss: 0.553325355052948
Epoch: 44/300 - Train loss: 0.5496395230293274, Validation loss: 0.5485266447067261
Epoch: 45/300 - Train loss: 0.5446697473526001, Validation loss: 0.5437374711036682
Epoch: 46/300 - Train loss: 0.539696216583252, Validation loss: 0.538888156414032
Epoch: 47/300 - Train loss: 0.534723699092865, Validation loss: 0.5339531898498535
Epoch: 48/300 - Train loss: 0.5297555327415466, Validation loss: 0.529058575630188
Epoch: 49/300 - Train loss: 0.5247952938079834, Validation loss: 0.5242511630058289
Epoch: 50/300 - Train loss: 0.5198459029197693, Validation loss: 0.5194137692451477
Epoch: 51/300 - Train loss: 0.5149099230766296, Validation loss: 0.5147076845169067
Epoch: 52/300 - Train loss: 0.5099915266036987, Validation loss: 0.5098432898521423
Epoch: 53/300 - Train loss: 0.5050958395004272, Validation loss: 0.5051367878913879
Epoch: 54/300 - Train loss: 0.5002255439758301, Validation loss: 0.5002415180206299
Epoch: 55/300 - Train loss: 0.4953838884830475, Validation loss: 0.49566391110420227
Epoch: 56/300 - Train loss: 0.49057337641716003, Validation loss: 0.4911826252937317
Epoch: 57/300 - Train loss: 0.48579636216163635, Validation loss: 0.4863680899143219
Epoch: 58/300 - Train loss: 0.48105546832084656, Validation loss: 0.48175331950187683
Epoch: 59/300 - Train loss: 0.47635290026664734, Validation loss: 0.47725430130958557
Epoch: 60/300 - Train loss: 0.4716908633708954, Validation loss: 0.47307005524635315
Epoch: 61/300 - Train loss: 0.467070609331131, Validation loss: 0.46849745512008667
Epoch: 62/300 - Train loss: 0.46249476075172424, Validation loss: 0.4634614884853363
Epoch: 63/300 - Train loss: 0.45796486735343933, Validation loss: 0.4595717489719391
Epoch: 64/300 - Train loss: 0.453482985496521, Validation loss: 0.45503348112106323
Epoch: 65/300 - Train loss: 0.44905054569244385, Validation loss: 0.45099467039108276
Epoch: 66/300 - Train loss: 0.4446682631969452, Validation loss: 0.4465191066265106
Epoch: 67/300 - Train loss: 0.4403379261493683, Validation loss: 0.44200414419174194
Epoch: 68/300 - Train loss: 0.4360607862472534, Validation loss: 0.4383363425731659
Epoch: 69/300 - Train loss: 0.43183720111846924, Validation loss: 0.434116393327713
Epoch: 70/300 - Train loss: 0.42766812443733215, Validation loss: 0.4302431643009186
Epoch: 71/300 - Train loss: 0.42355501651763916, Validation loss: 0.42604973912239075
Epoch: 72/300 - Train loss: 0.41950005292892456, Validation loss: 0.4217998683452606
Epoch: 73/300 - Train loss: 0.4155024290084839, Validation loss: 0.41869601607322693
Epoch: 74/300 - Train loss: 0.41156262159347534, Validation loss: 0.4144672751426697
Epoch: 75/300 - Train loss: 0.4076806902885437, Validation loss: 0.4106306731700897
Epoch: 76/300 - Train loss: 0.4038580060005188, Validation loss: 0.40718135237693787
Epoch: 77/300 - Train loss: 0.40009447932243347, Validation loss: 0.40351471304893494
Epoch: 78/300 - Train loss: 0.39639052748680115, Validation loss: 0.3997131884098053
Epoch: 79/300 - Train loss: 0.3927479088306427, Validation loss: 0.3963666260242462
Epoch: 80/300 - Train loss: 0.38916629552841187, Validation loss: 0.39311808347702026
Epoch: 81/300 - Train loss: 0.3856455087661743, Validation loss: 0.3895563781261444
Epoch: 82/300 - Train loss: 0.3821859657764435, Validation loss: 0.3860878646373749
Epoch: 83/300 - Train loss: 0.37878650426864624, Validation loss: 0.3828987181186676
Epoch: 84/300 - Train loss: 0.3754485845565796, Validation loss: 0.38011667132377625
Epoch: 85/300 - Train loss: 0.3721713423728943, Validation loss: 0.3763714134693146
Epoch: 86/300 - Train loss: 0.36895477771759033, Validation loss: 0.37342530488967896
Epoch: 87/300 - Train loss: 0.36579933762550354, Validation loss: 0.37072259187698364
Epoch: 88/300 - Train loss: 0.362703412771225, Validation loss: 0.3677346408367157
Epoch: 89/300 - Train loss: 0.3596667945384979, Validation loss: 0.36450666189193726
Epoch: 90/300 - Train loss: 0.35668864846229553, Validation loss: 0.36147788166999817
Epoch: 91/300 - Train loss: 0.3537675738334656, Validation loss: 0.35878434777259827
Epoch: 92/300 - Train loss: 0.3509032726287842, Validation loss: 0.3561180830001831
Epoch: 93/300 - Train loss: 0.3480953574180603, Validation loss: 0.3532424569129944
Epoch: 94/300 - Train loss: 0.3453421890735626, Validation loss: 0.3505042791366577
Epoch: 95/300 - Train loss: 0.34264278411865234, Validation loss: 0.34766367077827454
Epoch: 96/300 - Train loss: 0.3399955630302429, Validation loss: 0.345505028963089
Epoch: 97/300 - Train loss: 0.3374010920524597, Validation loss: 0.3429258465766907
Epoch: 98/300 - Train loss: 0.33485838770866394, Validation loss: 0.34040403366088867
Epoch: 99/300 - Train loss: 0.33236682415008545, Validation loss: 0.33787640929222107
Epoch: 100/300 - Train loss: 0.3299255967140198, Validation loss: 0.3359174430370331
Epoch: 101/300 - Train loss: 0.3275335729122162, Validation loss: 0.3329588770866394
Epoch: 102/300 - Train loss: 0.3251895606517792, Validation loss: 0.3312014937400818
Epoch: 103/300 - Train loss: 0.32289302349090576, Validation loss: 0.32840150594711304
Epoch: 104/300 - Train loss: 0.3206426501274109, Validation loss: 0.3266820013523102
Epoch: 105/300 - Train loss: 0.3184373378753662, Validation loss: 0.32437005639076233
Epoch: 106/300 - Train loss: 0.31627634167671204, Validation loss: 0.322372168302536
Epoch: 107/300 - Train loss: 0.31415846943855286, Validation loss: 0.3203049600124359
Epoch: 108/300 - Train loss: 0.31208333373069763, Validation loss: 0.3183704912662506
Epoch: 109/300 - Train loss: 0.31005027890205383, Validation loss: 0.316078782081604
Epoch: 110/300 - Train loss: 0.30805790424346924, Validation loss: 0.31481918692588806
Epoch: 111/300 - Train loss: 0.3061055839061737, Validation loss: 0.3126711845397949
Epoch: 112/300 - Train loss: 0.30419185757637024, Validation loss: 0.3104027807712555
Epoch: 113/300 - Train loss: 0.30231544375419617, Validation loss: 0.3091050684452057
Epoch: 114/300 - Train loss: 0.30047622323036194, Validation loss: 0.3073887825012207
Epoch: 115/300 - Train loss: 0.29867303371429443, Validation loss: 0.30547645688056946
Epoch: 116/300 - Train loss: 0.29690518975257874, Validation loss: 0.30366942286491394
Epoch: 117/300 - Train loss: 0.2951723039150238, Validation loss: 0.3021618723869324
Epoch: 118/300 - Train loss: 0.2934735417366028, Validation loss: 0.3008333742618561
Epoch: 119/300 - Train loss: 0.29180824756622314, Validation loss: 0.29909688234329224
Epoch: 120/300 - Train loss: 0.29017573595046997, Validation loss: 0.29708388447761536
Epoch: 121/300 - Train loss: 0.2885749042034149, Validation loss: 0.295888215303421
Epoch: 122/300 - Train loss: 0.28700461983680725, Validation loss: 0.29433077573776245
Epoch: 123/300 - Train loss: 0.28546449542045593, Validation loss: 0.2928343117237091
Epoch: 124/300 - Train loss: 0.28395360708236694, Validation loss: 0.29169920086860657
Epoch: 125/300 - Train loss: 0.28247129917144775, Validation loss: 0.28983935713768005
Epoch: 126/300 - Train loss: 0.28101739287376404, Validation loss: 0.28823065757751465
Epoch: 127/300 - Train loss: 0.27959132194519043, Validation loss: 0.28725939989089966
Epoch: 128/300 - Train loss: 0.27819207310676575, Validation loss: 0.2856576144695282
Epoch: 129/300 - Train loss: 0.27681878209114075, Validation loss: 0.2846214771270752
Epoch: 130/300 - Train loss: 0.2754708528518677, Validation loss: 0.2829321026802063
Epoch: 131/300 - Train loss: 0.27414795756340027, Validation loss: 0.2823869585990906
Epoch: 132/300 - Train loss: 0.2728498578071594, Validation loss: 0.28076085448265076
Epoch: 133/300 - Train loss: 0.27157577872276306, Validation loss: 0.2791827619075775
Epoch: 134/300 - Train loss: 0.27032530307769775, Validation loss: 0.27842289209365845
Epoch: 135/300 - Train loss: 0.2690977156162262, Validation loss: 0.27702775597572327
Epoch: 136/300 - Train loss: 0.2678926885128021, Validation loss: 0.2756006121635437
Epoch: 137/300 - Train loss: 0.26670950651168823, Validation loss: 0.2743728756904602
Epoch: 138/300 - Train loss: 0.26554757356643677, Validation loss: 0.27343806624412537
Epoch: 139/300 - Train loss: 0.2644062340259552, Validation loss: 0.2721654772758484
Epoch: 140/300 - Train loss: 0.26328492164611816, Validation loss: 0.27100664377212524
Epoch: 141/300 - Train loss: 0.2621830999851227, Validation loss: 0.2703647017478943
Epoch: 142/300 - Train loss: 0.2611003518104553, Validation loss: 0.26981422305107117
Epoch: 143/300 - Train loss: 0.26003631949424744, Validation loss: 0.2680324614048004
Epoch: 144/300 - Train loss: 0.25899070501327515, Validation loss: 0.2672496438026428
Epoch: 145/300 - Train loss: 0.2579632103443146, Validation loss: 0.26616114377975464
Epoch: 146/300 - Train loss: 0.2569535970687866, Validation loss: 0.26492029428482056
Epoch: 147/300 - Train loss: 0.2559613585472107, Validation loss: 0.263897180557251
Epoch: 148/300 - Train loss: 0.2549860179424286, Validation loss: 0.26322686672210693
Epoch: 149/300 - Train loss: 0.25402724742889404, Validation loss: 0.26187944412231445
Epoch: 150/300 - Train loss: 0.25308504700660706, Validation loss: 0.26109954714775085
Epoch: 151/300 - Train loss: 0.252159059047699, Validation loss: 0.26034870743751526
Epoch: 152/300 - Train loss: 0.251248836517334, Validation loss: 0.25949689745903015
Epoch: 153/300 - Train loss: 0.25035402178764343, Validation loss: 0.2589845359325409
Epoch: 154/300 - Train loss: 0.2494741529226303, Validation loss: 0.25751399993896484
Epoch: 155/300 - Train loss: 0.24860897660255432, Validation loss: 0.256815642118454
Epoch: 156/300 - Train loss: 0.24775823950767517, Validation loss: 0.25616511702537537
Epoch: 157/300 - Train loss: 0.246921569108963, Validation loss: 0.2550974488258362
Epoch: 158/300 - Train loss: 0.24609869718551636, Validation loss: 0.25470170378685
Epoch: 159/300 - Train loss: 0.24528928101062775, Validation loss: 0.2535528242588043
Epoch: 160/300 - Train loss: 0.24449318647384644, Validation loss: 0.2530186176300049
Epoch: 161/300 - Train loss: 0.24371019005775452, Validation loss: 0.2525213360786438
Epoch: 162/300 - Train loss: 0.2429400384426117, Validation loss: 0.2514761984348297
Epoch: 163/300 - Train loss: 0.24218225479125977, Validation loss: 0.25114232301712036
Epoch: 164/300 - Train loss: 0.24143654108047485, Validation loss: 0.25052255392074585
Epoch: 165/300 - Train loss: 0.2407025545835495, Validation loss: 0.24971890449523926
Epoch: 166/300 - Train loss: 0.23997998237609863, Validation loss: 0.2485361546278
Epoch: 167/300 - Train loss: 0.23926877975463867, Validation loss: 0.24769772589206696
Epoch: 168/300 - Train loss: 0.23856881260871887, Validation loss: 0.2477692812681198
Epoch: 169/300 - Train loss: 0.2378798872232437, Validation loss: 0.24660556018352509
Epoch: 170/300 - Train loss: 0.23720189929008484, Validation loss: 0.24580544233322144
Epoch: 171/300 - Train loss: 0.23653440177440643, Validation loss: 0.24502599239349365
Epoch: 172/300 - Train loss: 0.23587709665298462, Validation loss: 0.24478158354759216
Epoch: 173/300 - Train loss: 0.23522979021072388, Validation loss: 0.24429230391979218
Epoch: 174/300 - Train loss: 0.23459216952323914, Validation loss: 0.2434123009443283
Epoch: 175/300 - Train loss: 0.233964204788208, Validation loss: 0.243108332157135
Epoch: 176/300 - Train loss: 0.2333456575870514, Validation loss: 0.24280832707881927
