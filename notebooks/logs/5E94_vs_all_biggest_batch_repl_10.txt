Epoch: 1/300 - Train loss: 0.6928673982620239, Validation loss: 0.6890766024589539
Epoch: 2/300 - Train loss: 0.6909053921699524, Validation loss: 0.6870781779289246
Epoch: 3/300 - Train loss: 0.6889010071754456, Validation loss: 0.6849714517593384
Epoch: 4/300 - Train loss: 0.6868270039558411, Validation loss: 0.6830004453659058
Epoch: 5/300 - Train loss: 0.6846619844436646, Validation loss: 0.6806861758232117
Epoch: 6/300 - Train loss: 0.6823891997337341, Validation loss: 0.6783105731010437
Epoch: 7/300 - Train loss: 0.6799923181533813, Validation loss: 0.6758882999420166
Epoch: 8/300 - Train loss: 0.677462637424469, Validation loss: 0.6731785535812378
Epoch: 9/300 - Train loss: 0.6747978925704956, Validation loss: 0.6704798340797424
Epoch: 10/300 - Train loss: 0.6720007061958313, Validation loss: 0.6673564314842224
Epoch: 11/300 - Train loss: 0.6690768003463745, Validation loss: 0.6645481586456299
Epoch: 12/300 - Train loss: 0.6660352349281311, Validation loss: 0.6614680290222168
Epoch: 13/300 - Train loss: 0.6628815531730652, Validation loss: 0.6580604314804077
Epoch: 14/300 - Train loss: 0.6596250534057617, Validation loss: 0.6549464464187622
Epoch: 15/300 - Train loss: 0.6562788486480713, Validation loss: 0.6512030363082886
Epoch: 16/300 - Train loss: 0.6528522372245789, Validation loss: 0.6475738883018494
Epoch: 17/300 - Train loss: 0.6493548154830933, Validation loss: 0.6441974639892578
Epoch: 18/300 - Train loss: 0.6457962393760681, Validation loss: 0.6404919624328613
Epoch: 19/300 - Train loss: 0.6421849727630615, Validation loss: 0.6369401216506958
Epoch: 20/300 - Train loss: 0.6385347843170166, Validation loss: 0.6332066655158997
Epoch: 21/300 - Train loss: 0.6348520517349243, Validation loss: 0.6293652057647705
Epoch: 22/300 - Train loss: 0.6311468482017517, Validation loss: 0.6259444952011108
Epoch: 23/300 - Train loss: 0.6274227499961853, Validation loss: 0.6216875314712524
Epoch: 24/300 - Train loss: 0.6236859560012817, Validation loss: 0.6181453466415405
Epoch: 25/300 - Train loss: 0.6199411153793335, Validation loss: 0.6145099401473999
Epoch: 26/300 - Train loss: 0.6161903142929077, Validation loss: 0.6105780601501465
Epoch: 27/300 - Train loss: 0.6124362945556641, Validation loss: 0.6071407198905945
Epoch: 28/300 - Train loss: 0.6086792349815369, Validation loss: 0.602996826171875
Epoch: 29/300 - Train loss: 0.6049220561981201, Validation loss: 0.5991091728210449
Epoch: 30/300 - Train loss: 0.6011659502983093, Validation loss: 0.5958703756332397
Epoch: 31/300 - Train loss: 0.5974132418632507, Validation loss: 0.5919504761695862
Epoch: 32/300 - Train loss: 0.5936671495437622, Validation loss: 0.5882441401481628
Epoch: 33/300 - Train loss: 0.589930534362793, Validation loss: 0.5850200653076172
Epoch: 34/300 - Train loss: 0.5862047076225281, Validation loss: 0.5811256170272827
Epoch: 35/300 - Train loss: 0.5824933648109436, Validation loss: 0.5772395133972168
Epoch: 36/300 - Train loss: 0.5787995457649231, Validation loss: 0.5733193159103394
Epoch: 37/300 - Train loss: 0.5751253366470337, Validation loss: 0.56991046667099
Epoch: 38/300 - Train loss: 0.5714734196662903, Validation loss: 0.5657699704170227
Epoch: 39/300 - Train loss: 0.5678470730781555, Validation loss: 0.562658965587616
Epoch: 40/300 - Train loss: 0.56424880027771, Validation loss: 0.5597298741340637
Epoch: 41/300 - Train loss: 0.5606815218925476, Validation loss: 0.5555477738380432
Epoch: 42/300 - Train loss: 0.5571482181549072, Validation loss: 0.5522083044052124
Epoch: 43/300 - Train loss: 0.5536502599716187, Validation loss: 0.548525333404541
Epoch: 44/300 - Train loss: 0.5501902103424072, Validation loss: 0.5454781651496887
Epoch: 45/300 - Train loss: 0.546769380569458, Validation loss: 0.5422989726066589
Epoch: 46/300 - Train loss: 0.5433898568153381, Validation loss: 0.5389357209205627
Epoch: 47/300 - Train loss: 0.5400537252426147, Validation loss: 0.5360267758369446
Epoch: 48/300 - Train loss: 0.5367627739906311, Validation loss: 0.5325983762741089
Epoch: 49/300 - Train loss: 0.5335181355476379, Validation loss: 0.5288266539573669
Epoch: 50/300 - Train loss: 0.5303208231925964, Validation loss: 0.5261831283569336
Epoch: 51/300 - Train loss: 0.5271721482276917, Validation loss: 0.5228716135025024
Epoch: 52/300 - Train loss: 0.5240729451179504, Validation loss: 0.5198516845703125
Epoch: 53/300 - Train loss: 0.5210243463516235, Validation loss: 0.5168846845626831
Epoch: 54/300 - Train loss: 0.5180274844169617, Validation loss: 0.5139691829681396
Epoch: 55/300 - Train loss: 0.5150826573371887, Validation loss: 0.511459469795227
Epoch: 56/300 - Train loss: 0.512190580368042, Validation loss: 0.508313775062561
Epoch: 57/300 - Train loss: 0.5093514919281006, Validation loss: 0.5055323243141174
Epoch: 58/300 - Train loss: 0.5065653920173645, Validation loss: 0.5035781860351562
Epoch: 59/300 - Train loss: 0.503832221031189, Validation loss: 0.5003420114517212
Epoch: 60/300 - Train loss: 0.5011520385742188, Validation loss: 0.49862489104270935
Epoch: 61/300 - Train loss: 0.4985249638557434, Validation loss: 0.4951423704624176
Epoch: 62/300 - Train loss: 0.4959505498409271, Validation loss: 0.49285611510276794
Epoch: 63/300 - Train loss: 0.49342814087867737, Validation loss: 0.49118679761886597
Epoch: 64/300 - Train loss: 0.490957647562027, Validation loss: 0.48773276805877686
Epoch: 65/300 - Train loss: 0.48853880167007446, Validation loss: 0.4852146506309509
Epoch: 66/300 - Train loss: 0.48617029190063477, Validation loss: 0.48338583111763
Epoch: 67/300 - Train loss: 0.48385149240493774, Validation loss: 0.4825535714626312
Epoch: 68/300 - Train loss: 0.4815821647644043, Validation loss: 0.47817230224609375
Epoch: 69/300 - Train loss: 0.47936102747917175, Validation loss: 0.4765274226665497
Epoch: 70/300 - Train loss: 0.4771868884563446, Validation loss: 0.4744592308998108
Epoch: 71/300 - Train loss: 0.4750586748123169, Validation loss: 0.47337499260902405
Epoch: 72/300 - Train loss: 0.4729759097099304, Validation loss: 0.4702720046043396
Epoch: 73/300 - Train loss: 0.4709378778934479, Validation loss: 0.4684271514415741
Epoch: 74/300 - Train loss: 0.46894344687461853, Validation loss: 0.46673548221588135
Epoch: 75/300 - Train loss: 0.4669913947582245, Validation loss: 0.46543896198272705
Epoch: 76/300 - Train loss: 0.4650808572769165, Validation loss: 0.4633185565471649
Epoch: 77/300 - Train loss: 0.4632105529308319, Validation loss: 0.46118655800819397
Epoch: 78/300 - Train loss: 0.4613795578479767, Validation loss: 0.4599743187427521
Epoch: 79/300 - Train loss: 0.4595867395401001, Validation loss: 0.4571806490421295
Epoch: 80/300 - Train loss: 0.457831472158432, Validation loss: 0.4549686908721924
Epoch: 81/300 - Train loss: 0.45611274242401123, Validation loss: 0.45379096269607544
Epoch: 82/300 - Train loss: 0.454429566860199, Validation loss: 0.4525063931941986
Epoch: 83/300 - Train loss: 0.45278075337409973, Validation loss: 0.4515925347805023
Epoch: 84/300 - Train loss: 0.4511656165122986, Validation loss: 0.4494040608406067
Epoch: 85/300 - Train loss: 0.44958314299583435, Validation loss: 0.44846948981285095
Epoch: 86/300 - Train loss: 0.4480322301387787, Validation loss: 0.447061151266098
Epoch: 87/300 - Train loss: 0.44651201367378235, Validation loss: 0.4448685944080353
Epoch: 88/300 - Train loss: 0.4450216591358185, Validation loss: 0.4432823061943054
Epoch: 89/300 - Train loss: 0.44356027245521545, Validation loss: 0.4414117932319641
Epoch: 90/300 - Train loss: 0.44212719798088074, Validation loss: 0.4409451484680176
Epoch: 91/300 - Train loss: 0.4407217502593994, Validation loss: 0.43930783867836
Epoch: 92/300 - Train loss: 0.43934306502342224, Validation loss: 0.43831366300582886
Epoch: 93/300 - Train loss: 0.4379906952381134, Validation loss: 0.4376528859138489
Epoch: 94/300 - Train loss: 0.4366638958454132, Validation loss: 0.43594321608543396
Epoch: 95/300 - Train loss: 0.43536192178726196, Validation loss: 0.4337500333786011
Epoch: 96/300 - Train loss: 0.4340844452381134, Validation loss: 0.4322703778743744
Epoch: 97/300 - Train loss: 0.4328305423259735, Validation loss: 0.43162238597869873
Epoch: 98/300 - Train loss: 0.43159958720207214, Validation loss: 0.4295957088470459
Epoch: 99/300 - Train loss: 0.43039077520370483, Validation loss: 0.42866504192352295
Epoch: 100/300 - Train loss: 0.4292035698890686, Validation loss: 0.42733868956565857
Epoch: 101/300 - Train loss: 0.4280376434326172, Validation loss: 0.42682743072509766
Epoch: 102/300 - Train loss: 0.42689216136932373, Validation loss: 0.42611780762672424
Epoch: 103/300 - Train loss: 0.42576661705970764, Validation loss: 0.42389944195747375
Epoch: 104/300 - Train loss: 0.42466074228286743, Validation loss: 0.4228437840938568
Epoch: 105/300 - Train loss: 0.4235742390155792, Validation loss: 0.42240646481513977
Epoch: 106/300 - Train loss: 0.42250606417655945, Validation loss: 0.4205164909362793
Epoch: 107/300 - Train loss: 0.4214560389518738, Validation loss: 0.419612318277359
Epoch: 108/300 - Train loss: 0.42042383551597595, Validation loss: 0.4192850887775421
Epoch: 109/300 - Train loss: 0.41940903663635254, Validation loss: 0.41720423102378845
Epoch: 110/300 - Train loss: 0.41841134428977966, Validation loss: 0.4177754819393158
Epoch: 111/300 - Train loss: 0.41742992401123047, Validation loss: 0.41663554310798645
Epoch: 112/300 - Train loss: 0.41646477580070496, Validation loss: 0.41473108530044556
Epoch: 113/300 - Train loss: 0.4155154228210449, Validation loss: 0.4153251349925995
Epoch: 114/300 - Train loss: 0.4145815074443817, Validation loss: 0.4143528938293457
Epoch: 115/300 - Train loss: 0.4136628210544586, Validation loss: 0.41148313879966736
Epoch: 116/300 - Train loss: 0.4127589166164398, Validation loss: 0.4127251207828522
Epoch: 117/300 - Train loss: 0.4118690490722656, Validation loss: 0.41021236777305603
Epoch: 118/300 - Train loss: 0.41099321842193604, Validation loss: 0.41023486852645874
Epoch: 119/300 - Train loss: 0.41013094782829285, Validation loss: 0.40879592299461365
Epoch: 120/300 - Train loss: 0.4092821776866913, Validation loss: 0.4085812568664551
Epoch: 121/300 - Train loss: 0.40844669938087463, Validation loss: 0.4064277708530426
Epoch: 122/300 - Train loss: 0.4076237976551056, Validation loss: 0.40565893054008484
Epoch: 123/300 - Train loss: 0.40681350231170654, Validation loss: 0.4060596525669098
Epoch: 124/300 - Train loss: 0.40601542592048645, Validation loss: 0.4049602448940277
Epoch: 125/300 - Train loss: 0.40522924065589905, Validation loss: 0.4042305648326874
Epoch: 126/300 - Train loss: 0.4044545888900757, Validation loss: 0.40275776386260986
Epoch: 127/300 - Train loss: 0.40369150042533875, Validation loss: 0.40209829807281494
Epoch: 128/300 - Train loss: 0.40293994545936584, Validation loss: 0.40111443400382996
Epoch: 129/300 - Train loss: 0.4021996855735779, Validation loss: 0.40131324529647827
Epoch: 130/300 - Train loss: 0.401470422744751, Validation loss: 0.40039512515068054
Epoch: 131/300 - Train loss: 0.40075191855430603, Validation loss: 0.40048107504844666
Epoch: 132/300 - Train loss: 0.4000437259674072, Validation loss: 0.3989356756210327
Epoch: 133/300 - Train loss: 0.3993457555770874, Validation loss: 0.3994472920894623
Epoch: 134/300 - Train loss: 0.3986576795578003, Validation loss: 0.39680585265159607
Epoch: 135/300 - Train loss: 0.3979792892932892, Validation loss: 0.39580801129341125
Epoch: 136/300 - Train loss: 0.39731037616729736, Validation loss: 0.3969219923019409
Epoch: 137/300 - Train loss: 0.39665088057518005, Validation loss: 0.39602169394493103
Epoch: 138/300 - Train loss: 0.3960002660751343, Validation loss: 0.3956434428691864
Epoch: 139/300 - Train loss: 0.3953585922718048, Validation loss: 0.395010381937027
Epoch: 140/300 - Train loss: 0.3947255313396454, Validation loss: 0.3940141499042511
Epoch: 141/300 - Train loss: 0.39410126209259033, Validation loss: 0.3938831090927124
Epoch: 142/300 - Train loss: 0.3934853971004486, Validation loss: 0.3936786651611328
Epoch: 143/300 - Train loss: 0.3928777575492859, Validation loss: 0.3943822383880615
