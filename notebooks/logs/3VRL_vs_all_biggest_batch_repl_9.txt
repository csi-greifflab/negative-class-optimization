Epoch: 1/300 - Train loss: 0.693284273147583, Validation loss: 0.6912847757339478
Epoch: 2/300 - Train loss: 0.6902626752853394, Validation loss: 0.688443660736084
Epoch: 3/300 - Train loss: 0.6872236728668213, Validation loss: 0.6854280233383179
Epoch: 4/300 - Train loss: 0.6841444969177246, Validation loss: 0.6823465824127197
Epoch: 5/300 - Train loss: 0.680997371673584, Validation loss: 0.679079532623291
Epoch: 6/300 - Train loss: 0.677749514579773, Validation loss: 0.6757871508598328
Epoch: 7/300 - Train loss: 0.6743680238723755, Validation loss: 0.6722086071968079
Epoch: 8/300 - Train loss: 0.6708285212516785, Validation loss: 0.6686004400253296
Epoch: 9/300 - Train loss: 0.6671022772789001, Validation loss: 0.664631724357605
Epoch: 10/300 - Train loss: 0.6631780862808228, Validation loss: 0.6605717539787292
Epoch: 11/300 - Train loss: 0.6590654850006104, Validation loss: 0.6563435792922974
Epoch: 12/300 - Train loss: 0.6547678112983704, Validation loss: 0.6519402861595154
Epoch: 13/300 - Train loss: 0.650292694568634, Validation loss: 0.6473457217216492
Epoch: 14/300 - Train loss: 0.645648181438446, Validation loss: 0.6426236033439636
Epoch: 15/300 - Train loss: 0.6408513784408569, Validation loss: 0.63764488697052
Epoch: 16/300 - Train loss: 0.6359188556671143, Validation loss: 0.6325446367263794
Epoch: 17/300 - Train loss: 0.6308690905570984, Validation loss: 0.6273750066757202
Epoch: 18/300 - Train loss: 0.6257160305976868, Validation loss: 0.6221917867660522
Epoch: 19/300 - Train loss: 0.6204782128334045, Validation loss: 0.6169632077217102
Epoch: 20/300 - Train loss: 0.6151659488677979, Validation loss: 0.611470639705658
Epoch: 21/300 - Train loss: 0.6097961664199829, Validation loss: 0.6062566041946411
Epoch: 22/300 - Train loss: 0.604379415512085, Validation loss: 0.6007983088493347
Epoch: 23/300 - Train loss: 0.5989280939102173, Validation loss: 0.5955948233604431
Epoch: 24/300 - Train loss: 0.5934438109397888, Validation loss: 0.5899315476417542
Epoch: 25/300 - Train loss: 0.5879366993904114, Validation loss: 0.5845029354095459
Epoch: 26/300 - Train loss: 0.5824125409126282, Validation loss: 0.5790432095527649
Epoch: 27/300 - Train loss: 0.5768756866455078, Validation loss: 0.5735980868339539
Epoch: 28/300 - Train loss: 0.5713293552398682, Validation loss: 0.5682641863822937
Epoch: 29/300 - Train loss: 0.5657787919044495, Validation loss: 0.5626645088195801
Epoch: 30/300 - Train loss: 0.5602278113365173, Validation loss: 0.5573664903640747
Epoch: 31/300 - Train loss: 0.5546789169311523, Validation loss: 0.5520181059837341
Epoch: 32/300 - Train loss: 0.549137532711029, Validation loss: 0.5467493534088135
Epoch: 33/300 - Train loss: 0.5436083078384399, Validation loss: 0.5410562753677368
Epoch: 34/300 - Train loss: 0.5380972623825073, Validation loss: 0.5357469320297241
Epoch: 35/300 - Train loss: 0.5326101183891296, Validation loss: 0.5306267738342285
Epoch: 36/300 - Train loss: 0.5271527767181396, Validation loss: 0.5253663063049316
Epoch: 37/300 - Train loss: 0.5217307209968567, Validation loss: 0.5198630690574646
Epoch: 38/300 - Train loss: 0.5163477659225464, Validation loss: 0.5147322416305542
Epoch: 39/300 - Train loss: 0.5110086798667908, Validation loss: 0.5099759697914124
Epoch: 40/300 - Train loss: 0.5057173371315002, Validation loss: 0.5046288967132568
Epoch: 41/300 - Train loss: 0.5004766583442688, Validation loss: 0.4995306730270386
Epoch: 42/300 - Train loss: 0.49528947472572327, Validation loss: 0.4948568344116211
Epoch: 43/300 - Train loss: 0.4901580512523651, Validation loss: 0.4895069897174835
Epoch: 44/300 - Train loss: 0.4850848913192749, Validation loss: 0.48483747243881226
Epoch: 45/300 - Train loss: 0.4800717234611511, Validation loss: 0.48030000925064087
Epoch: 46/300 - Train loss: 0.4751201272010803, Validation loss: 0.47533345222473145
Epoch: 47/300 - Train loss: 0.47023245692253113, Validation loss: 0.4702702462673187
Epoch: 48/300 - Train loss: 0.46541014313697815, Validation loss: 0.4657697379589081
Epoch: 49/300 - Train loss: 0.4606550335884094, Validation loss: 0.4617316722869873
Epoch: 50/300 - Train loss: 0.4559687674045563, Validation loss: 0.45678022503852844
Epoch: 51/300 - Train loss: 0.45135238766670227, Validation loss: 0.45235583186149597
Epoch: 52/300 - Train loss: 0.44680723547935486, Validation loss: 0.44820287823677063
Epoch: 53/300 - Train loss: 0.4423343241214752, Validation loss: 0.4439574182033539
Epoch: 54/300 - Train loss: 0.43793433904647827, Validation loss: 0.4394664168357849
Epoch: 55/300 - Train loss: 0.43360790610313416, Validation loss: 0.43526530265808105
Epoch: 56/300 - Train loss: 0.429355651140213, Validation loss: 0.43144258856773376
Epoch: 57/300 - Train loss: 0.4251778721809387, Validation loss: 0.4274097681045532
Epoch: 58/300 - Train loss: 0.42107418179512024, Validation loss: 0.42320987582206726
Epoch: 59/300 - Train loss: 0.4170442223548889, Validation loss: 0.41942524909973145
Epoch: 60/300 - Train loss: 0.4130876064300537, Validation loss: 0.4159088730812073
Epoch: 61/300 - Train loss: 0.40920403599739075, Validation loss: 0.4118591845035553
Epoch: 62/300 - Train loss: 0.40539345145225525, Validation loss: 0.40883785486221313
Epoch: 63/300 - Train loss: 0.4016551375389099, Validation loss: 0.4051388204097748
Epoch: 64/300 - Train loss: 0.39798852801322937, Validation loss: 0.4014836847782135
Epoch: 65/300 - Train loss: 0.39439278841018677, Validation loss: 0.3982871472835541
Epoch: 66/300 - Train loss: 0.39086711406707764, Validation loss: 0.3944883346557617
Epoch: 67/300 - Train loss: 0.387410432100296, Validation loss: 0.3914010524749756
Epoch: 68/300 - Train loss: 0.38402146100997925, Validation loss: 0.38805535435676575
Epoch: 69/300 - Train loss: 0.3806992173194885, Validation loss: 0.38468605279922485
Epoch: 70/300 - Train loss: 0.37744274735450745, Validation loss: 0.38121816515922546
Epoch: 71/300 - Train loss: 0.3742513954639435, Validation loss: 0.37874019145965576
Epoch: 72/300 - Train loss: 0.37112361192703247, Validation loss: 0.37568116188049316
Epoch: 73/300 - Train loss: 0.3680582344532013, Validation loss: 0.3724234998226166
Epoch: 74/300 - Train loss: 0.3650541305541992, Validation loss: 0.36948487162590027
Epoch: 75/300 - Train loss: 0.3621099889278412, Validation loss: 0.3671143651008606
Epoch: 76/300 - Train loss: 0.3592242896556854, Validation loss: 0.36373254656791687
Epoch: 77/300 - Train loss: 0.35639598965644836, Validation loss: 0.36217254400253296
Epoch: 78/300 - Train loss: 0.3536243438720703, Validation loss: 0.35873743891716003
Epoch: 79/300 - Train loss: 0.35090768337249756, Validation loss: 0.3559466600418091
Epoch: 80/300 - Train loss: 0.34824448823928833, Validation loss: 0.3542407155036926
Epoch: 81/300 - Train loss: 0.3456347584724426, Validation loss: 0.35077229142189026
Epoch: 82/300 - Train loss: 0.3430769443511963, Validation loss: 0.3487531244754791
Epoch: 83/300 - Train loss: 0.3405693769454956, Validation loss: 0.3462319076061249
Epoch: 84/300 - Train loss: 0.3381102383136749, Validation loss: 0.34365367889404297
Epoch: 85/300 - Train loss: 0.3356988728046417, Validation loss: 0.3416862189769745
Epoch: 86/300 - Train loss: 0.3333343267440796, Validation loss: 0.339242547750473
Epoch: 87/300 - Train loss: 0.33101487159729004, Validation loss: 0.3368133008480072
Epoch: 88/300 - Train loss: 0.3287394940853119, Validation loss: 0.33479857444763184
Epoch: 89/300 - Train loss: 0.32650741934776306, Validation loss: 0.33311760425567627
Epoch: 90/300 - Train loss: 0.3243177533149719, Validation loss: 0.33094310760498047
Epoch: 91/300 - Train loss: 0.32216909527778625, Validation loss: 0.3281322419643402
Epoch: 92/300 - Train loss: 0.32006022334098816, Validation loss: 0.3265857994556427
Epoch: 93/300 - Train loss: 0.3179903030395508, Validation loss: 0.32478654384613037
Epoch: 94/300 - Train loss: 0.3159576952457428, Validation loss: 0.32254132628440857
Epoch: 95/300 - Train loss: 0.3139617145061493, Validation loss: 0.32031741738319397
Epoch: 96/300 - Train loss: 0.31200170516967773, Validation loss: 0.3184760510921478
Epoch: 97/300 - Train loss: 0.31007638573646545, Validation loss: 0.3169077932834625
Epoch: 98/300 - Train loss: 0.30818483233451843, Validation loss: 0.314544677734375
Epoch: 99/300 - Train loss: 0.3063261806964874, Validation loss: 0.31290388107299805
Epoch: 100/300 - Train loss: 0.3044995963573456, Validation loss: 0.31123295426368713
Epoch: 101/300 - Train loss: 0.30270421504974365, Validation loss: 0.3094538450241089
Epoch: 102/300 - Train loss: 0.30093932151794434, Validation loss: 0.30828964710235596
Epoch: 103/300 - Train loss: 0.2992039918899536, Validation loss: 0.3064308762550354
Epoch: 104/300 - Train loss: 0.2974976599216461, Validation loss: 0.304019033908844
Epoch: 105/300 - Train loss: 0.2958194315433502, Validation loss: 0.30230236053466797
Epoch: 106/300 - Train loss: 0.2941688001155853, Validation loss: 0.3016209602355957
Epoch: 107/300 - Train loss: 0.29254499077796936, Validation loss: 0.29949870705604553
Epoch: 108/300 - Train loss: 0.2909473478794098, Validation loss: 0.29815566539764404
Epoch: 109/300 - Train loss: 0.2893751561641693, Validation loss: 0.29655781388282776
Epoch: 110/300 - Train loss: 0.28782764077186584, Validation loss: 0.29525256156921387
Epoch: 111/300 - Train loss: 0.28630420565605164, Validation loss: 0.29366856813430786
Epoch: 112/300 - Train loss: 0.2848042845726013, Validation loss: 0.29203855991363525
Epoch: 113/300 - Train loss: 0.28332749009132385, Validation loss: 0.2905813455581665
Epoch: 114/300 - Train loss: 0.28187334537506104, Validation loss: 0.2894560694694519
Epoch: 115/300 - Train loss: 0.28044119477272034, Validation loss: 0.28814905881881714
Epoch: 116/300 - Train loss: 0.2790307104587555, Validation loss: 0.2865600883960724
Epoch: 117/300 - Train loss: 0.2776414155960083, Validation loss: 0.285450279712677
Epoch: 118/300 - Train loss: 0.2762725353240967, Validation loss: 0.2836152911186218
Epoch: 119/300 - Train loss: 0.27492374181747437, Validation loss: 0.28262460231781006
Epoch: 120/300 - Train loss: 0.2735946774482727, Validation loss: 0.2818880081176758
Epoch: 121/300 - Train loss: 0.27228477597236633, Validation loss: 0.28008750081062317
Epoch: 122/300 - Train loss: 0.27099373936653137, Validation loss: 0.2792028486728668
Epoch: 123/300 - Train loss: 0.2697211802005768, Validation loss: 0.277011901140213
Epoch: 124/300 - Train loss: 0.26846665143966675, Validation loss: 0.2767888009548187
Epoch: 125/300 - Train loss: 0.26722970604896545, Validation loss: 0.27510637044906616
Epoch: 126/300 - Train loss: 0.26600998640060425, Validation loss: 0.27421626448631287
Epoch: 127/300 - Train loss: 0.26480725407600403, Validation loss: 0.2736908197402954
Epoch: 128/300 - Train loss: 0.26362118124961853, Validation loss: 0.27160918712615967
Epoch: 129/300 - Train loss: 0.2624514698982239, Validation loss: 0.2708325684070587
Epoch: 130/300 - Train loss: 0.2612977921962738, Validation loss: 0.26980525255203247
Epoch: 131/300 - Train loss: 0.2601598799228668, Validation loss: 0.26826897263526917
Epoch: 132/300 - Train loss: 0.25903743505477905, Validation loss: 0.2672390937805176
Epoch: 133/300 - Train loss: 0.2579302191734314, Validation loss: 0.2664201855659485
Epoch: 134/300 - Train loss: 0.2568379044532776, Validation loss: 0.2653580605983734
Epoch: 135/300 - Train loss: 0.2557600438594818, Validation loss: 0.2641271650791168
Epoch: 136/300 - Train loss: 0.25469642877578735, Validation loss: 0.2639985978603363
Epoch: 137/300 - Train loss: 0.2536468207836151, Validation loss: 0.2617867887020111
Epoch: 138/300 - Train loss: 0.25261086225509644, Validation loss: 0.26201871037483215
Epoch: 139/300 - Train loss: 0.251588374376297, Validation loss: 0.26058173179626465
Epoch: 140/300 - Train loss: 0.2505790889263153, Validation loss: 0.2590617835521698
Epoch: 141/300 - Train loss: 0.24958276748657227, Validation loss: 0.2581551671028137
Epoch: 142/300 - Train loss: 0.24859918653964996, Validation loss: 0.25695091485977173
Epoch: 143/300 - Train loss: 0.24762821197509766, Validation loss: 0.2559122145175934
Epoch: 144/300 - Train loss: 0.2466694414615631, Validation loss: 0.25507891178131104
Epoch: 145/300 - Train loss: 0.2457226812839508, Validation loss: 0.25472813844680786
Epoch: 146/300 - Train loss: 0.24478779733181, Validation loss: 0.25334984064102173
Epoch: 147/300 - Train loss: 0.24386459589004517, Validation loss: 0.2530497908592224
Epoch: 148/300 - Train loss: 0.2429528534412384, Validation loss: 0.25153598189353943
Epoch: 149/300 - Train loss: 0.24205231666564941, Validation loss: 0.2503032982349396
Epoch: 150/300 - Train loss: 0.24116288125514984, Validation loss: 0.25016000866889954
Epoch: 151/300 - Train loss: 0.24028442800045013, Validation loss: 0.24932341277599335
Epoch: 152/300 - Train loss: 0.23941661417484283, Validation loss: 0.24866168200969696
Epoch: 153/300 - Train loss: 0.23855935037136078, Validation loss: 0.24777525663375854
Epoch: 154/300 - Train loss: 0.23771248757839203, Validation loss: 0.24689500033855438
Epoch: 155/300 - Train loss: 0.23687586188316345, Validation loss: 0.2456597536802292
Epoch: 156/300 - Train loss: 0.23604927957057953, Validation loss: 0.2449246495962143
Epoch: 157/300 - Train loss: 0.2352326214313507, Validation loss: 0.24391679465770721
Epoch: 158/300 - Train loss: 0.23442572355270386, Validation loss: 0.2430429905653
Epoch: 159/300 - Train loss: 0.23362837731838226, Validation loss: 0.2424883395433426
Epoch: 160/300 - Train loss: 0.23284047842025757, Validation loss: 0.24184107780456543
Epoch: 161/300 - Train loss: 0.23206189274787903, Validation loss: 0.24067102372646332
Epoch: 162/300 - Train loss: 0.2312924712896347, Validation loss: 0.24047625064849854
Epoch: 163/300 - Train loss: 0.23053207993507385, Validation loss: 0.2393369823694229
Epoch: 164/300 - Train loss: 0.22978056967258453, Validation loss: 0.23911771178245544
Epoch: 165/300 - Train loss: 0.22903774678707123, Validation loss: 0.23820482194423676
Epoch: 166/300 - Train loss: 0.2283034324645996, Validation loss: 0.23744215071201324
Epoch: 167/300 - Train loss: 0.22757761180400848, Validation loss: 0.2364712804555893
Epoch: 168/300 - Train loss: 0.22686012089252472, Validation loss: 0.23649422824382782
Epoch: 169/300 - Train loss: 0.22615079581737518, Validation loss: 0.23511533439159393
Epoch: 170/300 - Train loss: 0.2254495471715927, Validation loss: 0.23471906781196594
Epoch: 171/300 - Train loss: 0.22475628554821014, Validation loss: 0.23437483608722687
Epoch: 172/300 - Train loss: 0.22407083213329315, Validation loss: 0.23315216600894928
Epoch: 173/300 - Train loss: 0.22339318692684174, Validation loss: 0.23228122293949127
Epoch: 174/300 - Train loss: 0.22272320091724396, Validation loss: 0.23192568123340607
Epoch: 175/300 - Train loss: 0.22206079959869385, Validation loss: 0.23157699406147003
Epoch: 176/300 - Train loss: 0.2214057892560959, Validation loss: 0.23093850910663605
Epoch: 177/300 - Train loss: 0.2207580804824829, Validation loss: 0.22976091504096985
Epoch: 178/300 - Train loss: 0.22011755406856537, Validation loss: 0.2295517921447754
Epoch: 179/300 - Train loss: 0.21948403120040894, Validation loss: 0.2285500168800354
Epoch: 180/300 - Train loss: 0.21885743737220764, Validation loss: 0.22806479036808014
Epoch: 181/300 - Train loss: 0.2182377725839615, Validation loss: 0.22775301337242126
Epoch: 182/300 - Train loss: 0.21762481331825256, Validation loss: 0.2271270751953125
Epoch: 183/300 - Train loss: 0.2170185148715973, Validation loss: 0.2260071486234665
Epoch: 184/300 - Train loss: 0.21641890704631805, Validation loss: 0.22579556703567505
Epoch: 185/300 - Train loss: 0.2158256471157074, Validation loss: 0.22558431327342987
Epoch: 186/300 - Train loss: 0.21523885428905487, Validation loss: 0.2244882434606552
Epoch: 187/300 - Train loss: 0.21465829014778137, Validation loss: 0.22406387329101562
Epoch: 188/300 - Train loss: 0.2140839397907257, Validation loss: 0.22308538854122162
Epoch: 189/300 - Train loss: 0.2135157287120819, Validation loss: 0.22264917194843292
Epoch: 190/300 - Train loss: 0.21295353770256042, Validation loss: 0.22215202450752258
Epoch: 191/300 - Train loss: 0.2123972773551941, Validation loss: 0.22209399938583374
Epoch: 192/300 - Train loss: 0.21184663474559784, Validation loss: 0.22124718129634857
