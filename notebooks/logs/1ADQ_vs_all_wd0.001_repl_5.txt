Epoch: 1/300 - Train loss: 0.692030668258667, Validation loss: 0.690872073173523
Epoch: 2/300 - Train loss: 0.6904874444007874, Validation loss: 0.6893869042396545
Epoch: 3/300 - Train loss: 0.6889424324035645, Validation loss: 0.6878913044929504
Epoch: 4/300 - Train loss: 0.6873676776885986, Validation loss: 0.6863234639167786
Epoch: 5/300 - Train loss: 0.6857296824455261, Validation loss: 0.6847044229507446
Epoch: 6/300 - Train loss: 0.6840133666992188, Validation loss: 0.6829471588134766
Epoch: 7/300 - Train loss: 0.6821910738945007, Validation loss: 0.6811190247535706
Epoch: 8/300 - Train loss: 0.680260419845581, Validation loss: 0.6791819930076599
Epoch: 9/300 - Train loss: 0.6782095432281494, Validation loss: 0.6771038770675659
Epoch: 10/300 - Train loss: 0.6760402321815491, Validation loss: 0.674821674823761
Epoch: 11/300 - Train loss: 0.6737570762634277, Validation loss: 0.6725702881813049
Epoch: 12/300 - Train loss: 0.6713669300079346, Validation loss: 0.6700552105903625
Epoch: 13/300 - Train loss: 0.668880045413971, Validation loss: 0.6675569415092468
Epoch: 14/300 - Train loss: 0.6663038730621338, Validation loss: 0.665025532245636
Epoch: 15/300 - Train loss: 0.663648247718811, Validation loss: 0.6623415350914001
Epoch: 16/300 - Train loss: 0.6609206795692444, Validation loss: 0.659523606300354
Epoch: 17/300 - Train loss: 0.6581280827522278, Validation loss: 0.6568058133125305
Epoch: 18/300 - Train loss: 0.6552832126617432, Validation loss: 0.6539900898933411
Epoch: 19/300 - Train loss: 0.6523892283439636, Validation loss: 0.6512553691864014
Epoch: 20/300 - Train loss: 0.6494525074958801, Validation loss: 0.6482356190681458
Epoch: 21/300 - Train loss: 0.6464784145355225, Validation loss: 0.6452703475952148
Epoch: 22/300 - Train loss: 0.6434711217880249, Validation loss: 0.6423244476318359
Epoch: 23/300 - Train loss: 0.6404405832290649, Validation loss: 0.6395310163497925
Epoch: 24/300 - Train loss: 0.6373900771141052, Validation loss: 0.6366798281669617
Epoch: 25/300 - Train loss: 0.634320855140686, Validation loss: 0.6334925889968872
Epoch: 26/300 - Train loss: 0.6312400698661804, Validation loss: 0.630696713924408
Epoch: 27/300 - Train loss: 0.6281549334526062, Validation loss: 0.627481997013092
Epoch: 28/300 - Train loss: 0.6250692009925842, Validation loss: 0.6246775388717651
Epoch: 29/300 - Train loss: 0.6219857335090637, Validation loss: 0.6218385100364685
Epoch: 30/300 - Train loss: 0.6189076900482178, Validation loss: 0.618507444858551
Epoch: 31/300 - Train loss: 0.615838348865509, Validation loss: 0.615859866142273
Epoch: 32/300 - Train loss: 0.6127796769142151, Validation loss: 0.6129010319709778
Epoch: 33/300 - Train loss: 0.6097347736358643, Validation loss: 0.6098480820655823
Epoch: 34/300 - Train loss: 0.6067071557044983, Validation loss: 0.6069706082344055
Epoch: 35/300 - Train loss: 0.6036986708641052, Validation loss: 0.6041316986083984
Epoch: 36/300 - Train loss: 0.6007133722305298, Validation loss: 0.6015365123748779
Epoch: 37/300 - Train loss: 0.5977530479431152, Validation loss: 0.5985734462738037
Epoch: 38/300 - Train loss: 0.5948202013969421, Validation loss: 0.5957632660865784
Epoch: 39/300 - Train loss: 0.5919172763824463, Validation loss: 0.5931109189987183
Epoch: 40/300 - Train loss: 0.5890470147132874, Validation loss: 0.590061366558075
Epoch: 41/300 - Train loss: 0.5862103700637817, Validation loss: 0.5879142880439758
Epoch: 42/300 - Train loss: 0.5834087133407593, Validation loss: 0.585013210773468
Epoch: 43/300 - Train loss: 0.5806443691253662, Validation loss: 0.5825010538101196
Epoch: 44/300 - Train loss: 0.5779187083244324, Validation loss: 0.5797685384750366
Epoch: 45/300 - Train loss: 0.5752338767051697, Validation loss: 0.5769055485725403
Epoch: 46/300 - Train loss: 0.5725908875465393, Validation loss: 0.5749785900115967
Epoch: 47/300 - Train loss: 0.5699905753135681, Validation loss: 0.5723137855529785
Epoch: 48/300 - Train loss: 0.5674342513084412, Validation loss: 0.5697929859161377
Epoch: 49/300 - Train loss: 0.5649235248565674, Validation loss: 0.5677350163459778
Epoch: 50/300 - Train loss: 0.5624585151672363, Validation loss: 0.5651340484619141
Epoch: 51/300 - Train loss: 0.5600402355194092, Validation loss: 0.5629218220710754
Epoch: 52/300 - Train loss: 0.5576692223548889, Validation loss: 0.5607654452323914
Epoch: 53/300 - Train loss: 0.5553455948829651, Validation loss: 0.5585238337516785
Epoch: 54/300 - Train loss: 0.5530701279640198, Validation loss: 0.5566293597221375
Epoch: 55/300 - Train loss: 0.550843358039856, Validation loss: 0.5544658899307251
Epoch: 56/300 - Train loss: 0.5486655235290527, Validation loss: 0.5525573492050171
Epoch: 57/300 - Train loss: 0.5465375781059265, Validation loss: 0.5500322580337524
Epoch: 58/300 - Train loss: 0.5444596409797668, Validation loss: 0.5481919646263123
Epoch: 59/300 - Train loss: 0.5424312353134155, Validation loss: 0.5464965105056763
Epoch: 60/300 - Train loss: 0.5404536724090576, Validation loss: 0.5448643565177917
Epoch: 61/300 - Train loss: 0.5385253429412842, Validation loss: 0.5430126190185547
Epoch: 62/300 - Train loss: 0.5366466045379639, Validation loss: 0.5410297513008118
Epoch: 63/300 - Train loss: 0.5348162055015564, Validation loss: 0.5391929745674133
Epoch: 64/300 - Train loss: 0.5330343246459961, Validation loss: 0.5378327965736389
Epoch: 65/300 - Train loss: 0.5313006639480591, Validation loss: 0.5359833836555481
Epoch: 66/300 - Train loss: 0.5296137928962708, Validation loss: 0.5348308682441711
Epoch: 67/300 - Train loss: 0.5279722213745117, Validation loss: 0.5332551002502441
Epoch: 68/300 - Train loss: 0.5263755321502686, Validation loss: 0.5320942997932434
Epoch: 69/300 - Train loss: 0.5248228311538696, Validation loss: 0.5307996273040771
Epoch: 70/300 - Train loss: 0.5233129262924194, Validation loss: 0.5284133553504944
Epoch: 71/300 - Train loss: 0.5218440890312195, Validation loss: 0.527288556098938
Epoch: 72/300 - Train loss: 0.5204158425331116, Validation loss: 0.5264807939529419
Epoch: 73/300 - Train loss: 0.5190282464027405, Validation loss: 0.5249055027961731
Epoch: 74/300 - Train loss: 0.517680287361145, Validation loss: 0.5236079096794128
Epoch: 75/300 - Train loss: 0.5163707137107849, Validation loss: 0.522432804107666
Epoch: 76/300 - Train loss: 0.5150986313819885, Validation loss: 0.5217437148094177
Epoch: 77/300 - Train loss: 0.5138622522354126, Validation loss: 0.519824743270874
Epoch: 78/300 - Train loss: 0.5126607418060303, Validation loss: 0.5190036296844482
Epoch: 79/300 - Train loss: 0.5114926099777222, Validation loss: 0.5181910395622253
Epoch: 80/300 - Train loss: 0.5103564858436584, Validation loss: 0.5171647071838379
Epoch: 81/300 - Train loss: 0.509250283241272, Validation loss: 0.5162076354026794
Epoch: 82/300 - Train loss: 0.5081733465194702, Validation loss: 0.5148538947105408
Epoch: 83/300 - Train loss: 0.5071249604225159, Validation loss: 0.5138515830039978
Epoch: 84/300 - Train loss: 0.5061039328575134, Validation loss: 0.5124367475509644
Epoch: 85/300 - Train loss: 0.505107581615448, Validation loss: 0.5121533274650574
Epoch: 86/300 - Train loss: 0.5041365623474121, Validation loss: 0.5112723112106323
Epoch: 87/300 - Train loss: 0.5031891465187073, Validation loss: 0.5096744298934937
Epoch: 88/300 - Train loss: 0.5022647380828857, Validation loss: 0.5090798735618591
Epoch: 89/300 - Train loss: 0.501362144947052, Validation loss: 0.5085635185241699
Epoch: 90/300 - Train loss: 0.5004808902740479, Validation loss: 0.5076207518577576
Epoch: 91/300 - Train loss: 0.4996194541454315, Validation loss: 0.5066980719566345
Epoch: 92/300 - Train loss: 0.4987753629684448, Validation loss: 0.5062974691390991
Epoch: 93/300 - Train loss: 0.49794870615005493, Validation loss: 0.5050259828567505
Epoch: 94/300 - Train loss: 0.4971391558647156, Validation loss: 0.5048847794532776
Epoch: 95/300 - Train loss: 0.49634531140327454, Validation loss: 0.5039371848106384
Epoch: 96/300 - Train loss: 0.4955647587776184, Validation loss: 0.5030806064605713
Epoch: 97/300 - Train loss: 0.4947974383831024, Validation loss: 0.5020490884780884
Epoch: 98/300 - Train loss: 0.49404266476631165, Validation loss: 0.5015966296195984
Epoch: 99/300 - Train loss: 0.49330025911331177, Validation loss: 0.5010312795639038
Epoch: 100/300 - Train loss: 0.4925675690174103, Validation loss: 0.5000017881393433
Epoch: 101/300 - Train loss: 0.49184566736221313, Validation loss: 0.49984949827194214
Epoch: 102/300 - Train loss: 0.4911317825317383, Validation loss: 0.49880167841911316
Epoch: 103/300 - Train loss: 0.49042466282844543, Validation loss: 0.4981629252433777
Epoch: 104/300 - Train loss: 0.48972463607788086, Validation loss: 0.4977840483188629
Epoch: 105/300 - Train loss: 0.4890306293964386, Validation loss: 0.49749910831451416
Epoch: 106/300 - Train loss: 0.48834240436553955, Validation loss: 0.4968976676464081
Epoch: 107/300 - Train loss: 0.48765936493873596, Validation loss: 0.49545106291770935
Epoch: 108/300 - Train loss: 0.48698267340660095, Validation loss: 0.49486812949180603
Epoch: 109/300 - Train loss: 0.4863121807575226, Validation loss: 0.49415427446365356
Epoch: 110/300 - Train loss: 0.48564648628234863, Validation loss: 0.4943673610687256
Epoch: 111/300 - Train loss: 0.4849841892719269, Validation loss: 0.49320220947265625
Epoch: 112/300 - Train loss: 0.48432454466819763, Validation loss: 0.49298903346061707
Epoch: 113/300 - Train loss: 0.4836675822734833, Validation loss: 0.4921136498451233
Epoch: 114/300 - Train loss: 0.4830147325992584, Validation loss: 0.4911264181137085
Epoch: 115/300 - Train loss: 0.4823662340641022, Validation loss: 0.49056416749954224
Epoch: 116/300 - Train loss: 0.48172080516815186, Validation loss: 0.49043428897857666
Epoch: 117/300 - Train loss: 0.4810771942138672, Validation loss: 0.49003955721855164
