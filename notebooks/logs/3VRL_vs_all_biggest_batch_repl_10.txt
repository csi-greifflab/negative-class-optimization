Epoch: 1/300 - Train loss: 0.6952824592590332, Validation loss: 0.6887487769126892
Epoch: 2/300 - Train loss: 0.6902679800987244, Validation loss: 0.6838827729225159
Epoch: 3/300 - Train loss: 0.6852763891220093, Validation loss: 0.679095983505249
Epoch: 4/300 - Train loss: 0.6802767515182495, Validation loss: 0.6742473840713501
Epoch: 5/300 - Train loss: 0.6752380728721619, Validation loss: 0.6694415211677551
Epoch: 6/300 - Train loss: 0.6701435446739197, Validation loss: 0.6643649935722351
Epoch: 7/300 - Train loss: 0.6649693250656128, Validation loss: 0.6591468453407288
Epoch: 8/300 - Train loss: 0.659690797328949, Validation loss: 0.6540093421936035
Epoch: 9/300 - Train loss: 0.6543056964874268, Validation loss: 0.6486377716064453
Epoch: 10/300 - Train loss: 0.6488149762153625, Validation loss: 0.6433149576187134
Epoch: 11/300 - Train loss: 0.6432229280471802, Validation loss: 0.6376939415931702
Epoch: 12/300 - Train loss: 0.6375367045402527, Validation loss: 0.6320769190788269
Epoch: 13/300 - Train loss: 0.6317649483680725, Validation loss: 0.6264783143997192
Epoch: 14/300 - Train loss: 0.6259194612503052, Validation loss: 0.620784342288971
Epoch: 15/300 - Train loss: 0.6200101971626282, Validation loss: 0.6148585081100464
Epoch: 16/300 - Train loss: 0.6140508055686951, Validation loss: 0.609003484249115
Epoch: 17/300 - Train loss: 0.60805344581604, Validation loss: 0.6031826138496399
Epoch: 18/300 - Train loss: 0.6020297408103943, Validation loss: 0.597490668296814
Epoch: 19/300 - Train loss: 0.5959898829460144, Validation loss: 0.5914177894592285
Epoch: 20/300 - Train loss: 0.5899398922920227, Validation loss: 0.5855780839920044
Epoch: 21/300 - Train loss: 0.5838855504989624, Validation loss: 0.5795959830284119
Epoch: 22/300 - Train loss: 0.5778376460075378, Validation loss: 0.5735830068588257
Epoch: 23/300 - Train loss: 0.5718042254447937, Validation loss: 0.5678074955940247
Epoch: 24/300 - Train loss: 0.5657867193222046, Validation loss: 0.5620981454849243
Epoch: 25/300 - Train loss: 0.5597915053367615, Validation loss: 0.55616694688797
Epoch: 26/300 - Train loss: 0.5538281798362732, Validation loss: 0.5504581332206726
Epoch: 27/300 - Train loss: 0.5478965044021606, Validation loss: 0.5446224808692932
Epoch: 28/300 - Train loss: 0.5420011878013611, Validation loss: 0.538937509059906
Epoch: 29/300 - Train loss: 0.5361475944519043, Validation loss: 0.5330596566200256
Epoch: 30/300 - Train loss: 0.530340313911438, Validation loss: 0.5276025533676147
Epoch: 31/300 - Train loss: 0.5245792865753174, Validation loss: 0.521904468536377
Epoch: 32/300 - Train loss: 0.5188686847686768, Validation loss: 0.5163713097572327
Epoch: 33/300 - Train loss: 0.5132129192352295, Validation loss: 0.5108175277709961
Epoch: 34/300 - Train loss: 0.50761479139328, Validation loss: 0.5057582259178162
Epoch: 35/300 - Train loss: 0.5020784735679626, Validation loss: 0.5001285672187805
Epoch: 36/300 - Train loss: 0.4966065287590027, Validation loss: 0.4948731064796448
Epoch: 37/300 - Train loss: 0.4912014603614807, Validation loss: 0.48985445499420166
Epoch: 38/300 - Train loss: 0.48586589097976685, Validation loss: 0.4848252534866333
Epoch: 39/300 - Train loss: 0.4806031286716461, Validation loss: 0.4796098470687866
Epoch: 40/300 - Train loss: 0.4754146933555603, Validation loss: 0.4749946594238281
Epoch: 41/300 - Train loss: 0.47030240297317505, Validation loss: 0.4695766270160675
Epoch: 42/300 - Train loss: 0.4652678966522217, Validation loss: 0.46523910760879517
Epoch: 43/300 - Train loss: 0.4603131115436554, Validation loss: 0.4605466425418854
Epoch: 44/300 - Train loss: 0.4554392695426941, Validation loss: 0.45601484179496765
Epoch: 45/300 - Train loss: 0.4506476819515228, Validation loss: 0.45142266154289246
Epoch: 46/300 - Train loss: 0.44593900442123413, Validation loss: 0.4468192756175995
Epoch: 47/300 - Train loss: 0.4413142204284668, Validation loss: 0.442279189825058
Epoch: 48/300 - Train loss: 0.43677398562431335, Validation loss: 0.43803951144218445
Epoch: 49/300 - Train loss: 0.43231815099716187, Validation loss: 0.4342435896396637
Epoch: 50/300 - Train loss: 0.42794710397720337, Validation loss: 0.42993828654289246
Epoch: 51/300 - Train loss: 0.42366108298301697, Validation loss: 0.42584869265556335
Epoch: 52/300 - Train loss: 0.41946011781692505, Validation loss: 0.4215722978115082
Epoch: 53/300 - Train loss: 0.41534367203712463, Validation loss: 0.41767042875289917
Epoch: 54/300 - Train loss: 0.4113113582134247, Validation loss: 0.4142017960548401
Epoch: 55/300 - Train loss: 0.4073624014854431, Validation loss: 0.4100378155708313
Epoch: 56/300 - Train loss: 0.4034959673881531, Validation loss: 0.4065098762512207
Epoch: 57/300 - Train loss: 0.3997110426425934, Validation loss: 0.4027341902256012
Epoch: 58/300 - Train loss: 0.39600634574890137, Validation loss: 0.399969220161438
Epoch: 59/300 - Train loss: 0.3923802673816681, Validation loss: 0.39570340514183044
Epoch: 60/300 - Train loss: 0.3888320028781891, Validation loss: 0.3925824761390686
Epoch: 61/300 - Train loss: 0.38536009192466736, Validation loss: 0.3892781436443329
Epoch: 62/300 - Train loss: 0.3819632828235626, Validation loss: 0.38620486855506897
Epoch: 63/300 - Train loss: 0.37863999605178833, Validation loss: 0.3830000162124634
Epoch: 64/300 - Train loss: 0.375388503074646, Validation loss: 0.37973853945732117
Epoch: 65/300 - Train loss: 0.3722071349620819, Validation loss: 0.376911461353302
Epoch: 66/300 - Train loss: 0.3690943121910095, Validation loss: 0.3743879497051239
Epoch: 67/300 - Train loss: 0.366048663854599, Validation loss: 0.37109628319740295
Epoch: 68/300 - Train loss: 0.36306843161582947, Validation loss: 0.3685791492462158
Epoch: 69/300 - Train loss: 0.36015209555625916, Validation loss: 0.36594149470329285
Epoch: 70/300 - Train loss: 0.35729798674583435, Validation loss: 0.362653911113739
Epoch: 71/300 - Train loss: 0.35450446605682373, Validation loss: 0.3600098788738251
Epoch: 72/300 - Train loss: 0.3517695963382721, Validation loss: 0.3572285771369934
Epoch: 73/300 - Train loss: 0.34909212589263916, Validation loss: 0.3548988997936249
Epoch: 74/300 - Train loss: 0.34647074341773987, Validation loss: 0.3524637222290039
Epoch: 75/300 - Train loss: 0.3439038395881653, Validation loss: 0.3501001000404358
Epoch: 76/300 - Train loss: 0.3413897454738617, Validation loss: 0.34733960032463074
Epoch: 77/300 - Train loss: 0.3389270305633545, Validation loss: 0.3452252745628357
Epoch: 78/300 - Train loss: 0.33651405572891235, Validation loss: 0.3432413637638092
Epoch: 79/300 - Train loss: 0.33414939045906067, Validation loss: 0.34067079424858093
Epoch: 80/300 - Train loss: 0.33183208107948303, Validation loss: 0.3385874032974243
Epoch: 81/300 - Train loss: 0.3295603394508362, Validation loss: 0.33639654517173767
Epoch: 82/300 - Train loss: 0.32733282446861267, Validation loss: 0.33456680178642273
Epoch: 83/300 - Train loss: 0.3251485526561737, Validation loss: 0.33209356665611267
Epoch: 84/300 - Train loss: 0.32300612330436707, Validation loss: 0.329743891954422
Epoch: 85/300 - Train loss: 0.3209041357040405, Validation loss: 0.328195720911026
Epoch: 86/300 - Train loss: 0.3188416361808777, Validation loss: 0.3265218138694763
Epoch: 87/300 - Train loss: 0.31681740283966064, Validation loss: 0.3241111636161804
Epoch: 88/300 - Train loss: 0.31483015418052673, Validation loss: 0.322401225566864
Epoch: 89/300 - Train loss: 0.31287881731987, Validation loss: 0.32039013504981995
Epoch: 90/300 - Train loss: 0.3109624981880188, Validation loss: 0.3184545934200287
Epoch: 91/300 - Train loss: 0.30908018350601196, Validation loss: 0.31639420986175537
Epoch: 92/300 - Train loss: 0.30723121762275696, Validation loss: 0.3143804669380188
Epoch: 93/300 - Train loss: 0.3054143786430359, Validation loss: 0.3132726550102234
Epoch: 94/300 - Train loss: 0.3036288619041443, Validation loss: 0.3112775683403015
Epoch: 95/300 - Train loss: 0.30187392234802246, Validation loss: 0.30991771817207336
Epoch: 96/300 - Train loss: 0.3001483976840973, Validation loss: 0.30769452452659607
Epoch: 97/300 - Train loss: 0.29845142364501953, Validation loss: 0.30643826723098755
Epoch: 98/300 - Train loss: 0.2967824637889862, Validation loss: 0.3044789731502533
Epoch: 99/300 - Train loss: 0.29514068365097046, Validation loss: 0.3034043610095978
Epoch: 100/300 - Train loss: 0.29352545738220215, Validation loss: 0.3018811047077179
Epoch: 101/300 - Train loss: 0.2919359803199768, Validation loss: 0.3000297546386719
Epoch: 102/300 - Train loss: 0.2903715968132019, Validation loss: 0.29870539903640747
Epoch: 103/300 - Train loss: 0.2888316512107849, Validation loss: 0.29696014523506165
Epoch: 104/300 - Train loss: 0.28731533885002136, Validation loss: 0.2956984043121338
Epoch: 105/300 - Train loss: 0.28582218289375305, Validation loss: 0.29475855827331543
Epoch: 106/300 - Train loss: 0.2843515872955322, Validation loss: 0.29281988739967346
Epoch: 107/300 - Train loss: 0.28290295600891113, Validation loss: 0.2914806604385376
Epoch: 108/300 - Train loss: 0.28147587180137634, Validation loss: 0.2902366816997528
Epoch: 109/300 - Train loss: 0.28006982803344727, Validation loss: 0.2881440222263336
Epoch: 110/300 - Train loss: 0.2786843776702881, Validation loss: 0.2870626747608185
Epoch: 111/300 - Train loss: 0.2773189842700958, Validation loss: 0.2861505150794983
Epoch: 112/300 - Train loss: 0.27597305178642273, Validation loss: 0.2850049138069153
Epoch: 113/300 - Train loss: 0.274646133184433, Validation loss: 0.2829996645450592
Epoch: 114/300 - Train loss: 0.27333778142929077, Validation loss: 0.2825718820095062
Epoch: 115/300 - Train loss: 0.272047758102417, Validation loss: 0.2814309597015381
Epoch: 116/300 - Train loss: 0.27077552676200867, Validation loss: 0.2792813181877136
Epoch: 117/300 - Train loss: 0.26952072978019714, Validation loss: 0.27770259976387024
Epoch: 118/300 - Train loss: 0.2682831287384033, Validation loss: 0.2768603265285492
Epoch: 119/300 - Train loss: 0.26706230640411377, Validation loss: 0.276109516620636
Epoch: 120/300 - Train loss: 0.265857994556427, Validation loss: 0.27573609352111816
Epoch: 121/300 - Train loss: 0.26466989517211914, Validation loss: 0.2737898826599121
Epoch: 122/300 - Train loss: 0.26349765062332153, Validation loss: 0.27241259813308716
Epoch: 123/300 - Train loss: 0.2623409628868103, Validation loss: 0.27132660150527954
Epoch: 124/300 - Train loss: 0.2611995041370392, Validation loss: 0.27051132917404175
Epoch: 125/300 - Train loss: 0.2600730061531067, Validation loss: 0.26894572377204895
Epoch: 126/300 - Train loss: 0.2589612305164337, Validation loss: 0.2686668932437897
Epoch: 127/300 - Train loss: 0.2578638195991516, Validation loss: 0.26706257462501526
Epoch: 128/300 - Train loss: 0.25678056478500366, Validation loss: 0.2661783993244171
Epoch: 129/300 - Train loss: 0.25571107864379883, Validation loss: 0.26469922065734863
Epoch: 130/300 - Train loss: 0.2546551525592804, Validation loss: 0.2636543810367584
Epoch: 131/300 - Train loss: 0.25361260771751404, Validation loss: 0.26318833231925964
Epoch: 132/300 - Train loss: 0.25258320569992065, Validation loss: 0.26250186562538147
Epoch: 133/300 - Train loss: 0.25156670808792114, Validation loss: 0.26063185930252075
Epoch: 134/300 - Train loss: 0.2505629062652588, Validation loss: 0.25952357053756714
Epoch: 135/300 - Train loss: 0.24957160651683807, Validation loss: 0.25923529267311096
Epoch: 136/300 - Train loss: 0.24859260022640228, Validation loss: 0.25796419382095337
Epoch: 137/300 - Train loss: 0.2476256936788559, Validation loss: 0.2573000490665436
Epoch: 138/300 - Train loss: 0.246670663356781, Validation loss: 0.25599077343940735
Epoch: 139/300 - Train loss: 0.24572741985321045, Validation loss: 0.25540733337402344
Epoch: 140/300 - Train loss: 0.24479570984840393, Validation loss: 0.2541385293006897
Epoch: 141/300 - Train loss: 0.24387530982494354, Validation loss: 0.2533557415008545
Epoch: 142/300 - Train loss: 0.24296599626541138, Validation loss: 0.2524833679199219
Epoch: 143/300 - Train loss: 0.2420676201581955, Validation loss: 0.25180113315582275
Epoch: 144/300 - Train loss: 0.24118004739284515, Validation loss: 0.25106149911880493
Epoch: 145/300 - Train loss: 0.24030311405658722, Validation loss: 0.24981775879859924
Epoch: 146/300 - Train loss: 0.23943664133548737, Validation loss: 0.2488509714603424
Epoch: 147/300 - Train loss: 0.23858052492141724, Validation loss: 0.2485327273607254
Epoch: 148/300 - Train loss: 0.2377346307039261, Validation loss: 0.2478172481060028
Epoch: 149/300 - Train loss: 0.23689879477024078, Validation loss: 0.24678537249565125
Epoch: 150/300 - Train loss: 0.23607292771339417, Validation loss: 0.2457035481929779
Epoch: 151/300 - Train loss: 0.2352568805217743, Validation loss: 0.24485452473163605
Epoch: 152/300 - Train loss: 0.23445045948028564, Validation loss: 0.24433240294456482
Epoch: 153/300 - Train loss: 0.23365357518196106, Validation loss: 0.24319308996200562
Epoch: 154/300 - Train loss: 0.23286594450473785, Validation loss: 0.24246829748153687
Epoch: 155/300 - Train loss: 0.23208750784397125, Validation loss: 0.24239042401313782
Epoch: 156/300 - Train loss: 0.2313181757926941, Validation loss: 0.24104814231395721
Epoch: 157/300 - Train loss: 0.23055784404277802, Validation loss: 0.24047860503196716
Epoch: 158/300 - Train loss: 0.22980637848377228, Validation loss: 0.24011169373989105
Epoch: 159/300 - Train loss: 0.22906367480754852, Validation loss: 0.23892496526241302
Epoch: 160/300 - Train loss: 0.22832956910133362, Validation loss: 0.23800766468048096
Epoch: 161/300 - Train loss: 0.2276039868593216, Validation loss: 0.2375042736530304
Epoch: 162/300 - Train loss: 0.22688676416873932, Validation loss: 0.23659344017505646
Epoch: 163/300 - Train loss: 0.22617784142494202, Validation loss: 0.23602446913719177
Epoch: 164/300 - Train loss: 0.22547705471515656, Validation loss: 0.23528467118740082
Epoch: 165/300 - Train loss: 0.224784255027771, Validation loss: 0.23453842103481293
Epoch: 166/300 - Train loss: 0.22409920394420624, Validation loss: 0.2336864173412323
Epoch: 167/300 - Train loss: 0.2234218418598175, Validation loss: 0.2334652543067932
Epoch: 168/300 - Train loss: 0.22275196015834808, Validation loss: 0.23329246044158936
Epoch: 169/300 - Train loss: 0.22208964824676514, Validation loss: 0.23192942142486572
Epoch: 170/300 - Train loss: 0.2214347869157791, Validation loss: 0.2315770387649536
Epoch: 171/300 - Train loss: 0.22078721225261688, Validation loss: 0.23089058697223663
Epoch: 172/300 - Train loss: 0.2201467901468277, Validation loss: 0.23065021634101868
Epoch: 173/300 - Train loss: 0.21951353549957275, Validation loss: 0.22918710112571716
Epoch: 174/300 - Train loss: 0.2188873589038849, Validation loss: 0.22892329096794128
Epoch: 175/300 - Train loss: 0.21826818585395813, Validation loss: 0.22816415131092072
Epoch: 176/300 - Train loss: 0.21765580773353577, Validation loss: 0.22704440355300903
Epoch: 177/300 - Train loss: 0.21705017983913422, Validation loss: 0.2264167070388794
Epoch: 178/300 - Train loss: 0.21645118296146393, Validation loss: 0.22641289234161377
Epoch: 179/300 - Train loss: 0.21585877239704132, Validation loss: 0.22554214298725128
Epoch: 180/300 - Train loss: 0.21527287364006042, Validation loss: 0.22480949759483337
Epoch: 181/300 - Train loss: 0.21469342708587646, Validation loss: 0.22485442459583282
Epoch: 182/300 - Train loss: 0.2141202986240387, Validation loss: 0.22415299713611603
Epoch: 183/300 - Train loss: 0.21355342864990234, Validation loss: 0.22345493733882904
Epoch: 184/300 - Train loss: 0.21299266815185547, Validation loss: 0.22318299114704132
