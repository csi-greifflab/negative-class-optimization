Epoch: 1/300 - Train loss: 0.6967090368270874, Validation loss: 0.6958926916122437
Epoch: 2/300 - Train loss: 0.6942658424377441, Validation loss: 0.6932652592658997
Epoch: 3/300 - Train loss: 0.6918595433235168, Validation loss: 0.69084233045578
Epoch: 4/300 - Train loss: 0.6894793510437012, Validation loss: 0.6884661316871643
Epoch: 5/300 - Train loss: 0.6871123313903809, Validation loss: 0.6859492659568787
Epoch: 6/300 - Train loss: 0.6847532987594604, Validation loss: 0.6834713816642761
Epoch: 7/300 - Train loss: 0.6824024319648743, Validation loss: 0.6811599135398865
Epoch: 8/300 - Train loss: 0.6800550222396851, Validation loss: 0.6787229776382446
Epoch: 9/300 - Train loss: 0.6777031421661377, Validation loss: 0.6763213872909546
Epoch: 10/300 - Train loss: 0.675342857837677, Validation loss: 0.6740996241569519
Epoch: 11/300 - Train loss: 0.672967255115509, Validation loss: 0.6714522242546082
Epoch: 12/300 - Train loss: 0.670573890209198, Validation loss: 0.6690447330474854
Epoch: 13/300 - Train loss: 0.6681641936302185, Validation loss: 0.6665311455726624
Epoch: 14/300 - Train loss: 0.6657359600067139, Validation loss: 0.6640719175338745
Epoch: 15/300 - Train loss: 0.6632840633392334, Validation loss: 0.6616249680519104
Epoch: 16/300 - Train loss: 0.6608052849769592, Validation loss: 0.6589050889015198
Epoch: 17/300 - Train loss: 0.6582924127578735, Validation loss: 0.6563515067100525
Epoch: 18/300 - Train loss: 0.65574711561203, Validation loss: 0.6538692712783813
Epoch: 19/300 - Train loss: 0.6531674861907959, Validation loss: 0.6509473323822021
Epoch: 20/300 - Train loss: 0.6505502462387085, Validation loss: 0.6484906673431396
Epoch: 21/300 - Train loss: 0.6478931903839111, Validation loss: 0.645819365978241
Epoch: 22/300 - Train loss: 0.6451936960220337, Validation loss: 0.6429687142372131
Epoch: 23/300 - Train loss: 0.6424535512924194, Validation loss: 0.6401835680007935
Epoch: 24/300 - Train loss: 0.6396682262420654, Validation loss: 0.6371512413024902
Epoch: 25/300 - Train loss: 0.6368363499641418, Validation loss: 0.634272575378418
Epoch: 26/300 - Train loss: 0.6339591145515442, Validation loss: 0.631439208984375
Epoch: 27/300 - Train loss: 0.6310349106788635, Validation loss: 0.62862229347229
Epoch: 28/300 - Train loss: 0.6280615329742432, Validation loss: 0.624998927116394
Epoch: 29/300 - Train loss: 0.6250404119491577, Validation loss: 0.6221911907196045
Epoch: 30/300 - Train loss: 0.6219730377197266, Validation loss: 0.6191132068634033
Epoch: 31/300 - Train loss: 0.6188602447509766, Validation loss: 0.6159836649894714
Epoch: 32/300 - Train loss: 0.6157053709030151, Validation loss: 0.6129285097122192
Epoch: 33/300 - Train loss: 0.6125121712684631, Validation loss: 0.609078586101532
Epoch: 34/300 - Train loss: 0.609278678894043, Validation loss: 0.6060563325881958
Epoch: 35/300 - Train loss: 0.6060081124305725, Validation loss: 0.6025282740592957
Epoch: 36/300 - Train loss: 0.6027012467384338, Validation loss: 0.5995404720306396
Epoch: 37/300 - Train loss: 0.5993612408638, Validation loss: 0.5961100459098816
Epoch: 38/300 - Train loss: 0.5959904193878174, Validation loss: 0.5927074551582336
Epoch: 39/300 - Train loss: 0.5925906300544739, Validation loss: 0.5891254544258118
Epoch: 40/300 - Train loss: 0.5891679525375366, Validation loss: 0.5858278870582581
Epoch: 41/300 - Train loss: 0.585725724697113, Validation loss: 0.5824337005615234
Epoch: 42/300 - Train loss: 0.5822696089744568, Validation loss: 0.5789650082588196
Epoch: 43/300 - Train loss: 0.5788037180900574, Validation loss: 0.5751132965087891
Epoch: 44/300 - Train loss: 0.5753316283226013, Validation loss: 0.571817934513092
Epoch: 45/300 - Train loss: 0.5718586444854736, Validation loss: 0.5683585405349731
Epoch: 46/300 - Train loss: 0.5683886408805847, Validation loss: 0.5647789239883423
Epoch: 47/300 - Train loss: 0.5649241209030151, Validation loss: 0.5614627003669739
Epoch: 48/300 - Train loss: 0.5614703297615051, Validation loss: 0.5583334565162659
Epoch: 49/300 - Train loss: 0.5580297708511353, Validation loss: 0.5546155571937561
Epoch: 50/300 - Train loss: 0.5546057224273682, Validation loss: 0.5511375069618225
Epoch: 51/300 - Train loss: 0.5512032508850098, Validation loss: 0.5480057001113892
Epoch: 52/300 - Train loss: 0.5478299856185913, Validation loss: 0.5442841053009033
Epoch: 53/300 - Train loss: 0.5444859266281128, Validation loss: 0.541867733001709
Epoch: 54/300 - Train loss: 0.5411783456802368, Validation loss: 0.5385607481002808
Epoch: 55/300 - Train loss: 0.5379093289375305, Validation loss: 0.5350631475448608
Epoch: 56/300 - Train loss: 0.5346826910972595, Validation loss: 0.5317234396934509
Epoch: 57/300 - Train loss: 0.5314986109733582, Validation loss: 0.5284009575843811
Epoch: 58/300 - Train loss: 0.5283574461936951, Validation loss: 0.5255001783370972
Epoch: 59/300 - Train loss: 0.5252619981765747, Validation loss: 0.5217767953872681
Epoch: 60/300 - Train loss: 0.5222160816192627, Validation loss: 0.5190991163253784
Epoch: 61/300 - Train loss: 0.5192242860794067, Validation loss: 0.516694188117981
Epoch: 62/300 - Train loss: 0.5162843465805054, Validation loss: 0.5133919715881348
Epoch: 63/300 - Train loss: 0.5133996605873108, Validation loss: 0.51036536693573
Epoch: 64/300 - Train loss: 0.5105711221694946, Validation loss: 0.5077721476554871
Epoch: 65/300 - Train loss: 0.5078007578849792, Validation loss: 0.5054853558540344
Epoch: 66/300 - Train loss: 0.5050857663154602, Validation loss: 0.5028082728385925
Epoch: 67/300 - Train loss: 0.502428412437439, Validation loss: 0.499650239944458
Epoch: 68/300 - Train loss: 0.4998272657394409, Validation loss: 0.4970126748085022
Epoch: 69/300 - Train loss: 0.49728044867515564, Validation loss: 0.4950074553489685
Epoch: 70/300 - Train loss: 0.49479031562805176, Validation loss: 0.49249914288520813
Epoch: 71/300 - Train loss: 0.492355614900589, Validation loss: 0.4894441068172455
Epoch: 72/300 - Train loss: 0.4899750351905823, Validation loss: 0.48813650012016296
Epoch: 73/300 - Train loss: 0.48764604330062866, Validation loss: 0.4854980409145355
Epoch: 74/300 - Train loss: 0.48536771535873413, Validation loss: 0.48400864005088806
Epoch: 75/300 - Train loss: 0.48313841223716736, Validation loss: 0.481796532869339
Epoch: 76/300 - Train loss: 0.48095664381980896, Validation loss: 0.47908490896224976
Epoch: 77/300 - Train loss: 0.47882166504859924, Validation loss: 0.4774089455604553
Epoch: 78/300 - Train loss: 0.47673240303993225, Validation loss: 0.47499480843544006
Epoch: 79/300 - Train loss: 0.47468656301498413, Validation loss: 0.47223344445228577
Epoch: 80/300 - Train loss: 0.47268301248550415, Validation loss: 0.4711074233055115
Epoch: 81/300 - Train loss: 0.47072064876556396, Validation loss: 0.4684640169143677
Epoch: 82/300 - Train loss: 0.4687984585762024, Validation loss: 0.4665560722351074
Epoch: 83/300 - Train loss: 0.46691566705703735, Validation loss: 0.4653230905532837
Epoch: 84/300 - Train loss: 0.46507060527801514, Validation loss: 0.46318602561950684
Epoch: 85/300 - Train loss: 0.46326252818107605, Validation loss: 0.4610539674758911
Epoch: 86/300 - Train loss: 0.46149057149887085, Validation loss: 0.46029025316238403
Epoch: 87/300 - Train loss: 0.4597538113594055, Validation loss: 0.45768266916275024
Epoch: 88/300 - Train loss: 0.4580506980419159, Validation loss: 0.4560995101928711
Epoch: 89/300 - Train loss: 0.4563808739185333, Validation loss: 0.45563626289367676
Epoch: 90/300 - Train loss: 0.4547432065010071, Validation loss: 0.45356422662734985
Epoch: 91/300 - Train loss: 0.45313718914985657, Validation loss: 0.4515920579433441
Epoch: 92/300 - Train loss: 0.4515620172023773, Validation loss: 0.44943034648895264
Epoch: 93/300 - Train loss: 0.4500165283679962, Validation loss: 0.44844597578048706
Epoch: 94/300 - Train loss: 0.44850024580955505, Validation loss: 0.447086900472641
Epoch: 95/300 - Train loss: 0.44701218605041504, Validation loss: 0.44633448123931885
Epoch: 96/300 - Train loss: 0.4455513656139374, Validation loss: 0.444847047328949
Epoch: 97/300 - Train loss: 0.4441172480583191, Validation loss: 0.44296327233314514
Epoch: 98/300 - Train loss: 0.44270989298820496, Validation loss: 0.4417162239551544
Epoch: 99/300 - Train loss: 0.4413284659385681, Validation loss: 0.43884116411209106
Epoch: 100/300 - Train loss: 0.43997228145599365, Validation loss: 0.43920981884002686
Epoch: 101/300 - Train loss: 0.43864062428474426, Validation loss: 0.43707576394081116
Epoch: 102/300 - Train loss: 0.43733271956443787, Validation loss: 0.4367774724960327
Epoch: 103/300 - Train loss: 0.43604782223701477, Validation loss: 0.4341413080692291
Epoch: 104/300 - Train loss: 0.4347849488258362, Validation loss: 0.43353337049484253
Epoch: 105/300 - Train loss: 0.4335433840751648, Validation loss: 0.43334251642227173
Epoch: 106/300 - Train loss: 0.43232372403144836, Validation loss: 0.4310820996761322
Epoch: 107/300 - Train loss: 0.4311250150203705, Validation loss: 0.43022945523262024
Epoch: 108/300 - Train loss: 0.42994698882102966, Validation loss: 0.42851147055625916
Epoch: 109/300 - Train loss: 0.4287896156311035, Validation loss: 0.42742910981178284
Epoch: 110/300 - Train loss: 0.4276520907878876, Validation loss: 0.4269324541091919
Epoch: 111/300 - Train loss: 0.4265343248844147, Validation loss: 0.42577242851257324
Epoch: 112/300 - Train loss: 0.4254353940486908, Validation loss: 0.4233672022819519
Epoch: 113/300 - Train loss: 0.42435428500175476, Validation loss: 0.42206642031669617
Epoch: 114/300 - Train loss: 0.42329141497612, Validation loss: 0.421943724155426
Epoch: 115/300 - Train loss: 0.42224621772766113, Validation loss: 0.42111924290657043
Epoch: 116/300 - Train loss: 0.4212179183959961, Validation loss: 0.4200555682182312
Epoch: 117/300 - Train loss: 0.4202061891555786, Validation loss: 0.41838207840919495
Epoch: 118/300 - Train loss: 0.41921135783195496, Validation loss: 0.41809216141700745
Epoch: 119/300 - Train loss: 0.41823285818099976, Validation loss: 0.4173601269721985
Epoch: 120/300 - Train loss: 0.4172707498073578, Validation loss: 0.4164312779903412
Epoch: 121/300 - Train loss: 0.4163239598274231, Validation loss: 0.41445234417915344
Epoch: 122/300 - Train loss: 0.41539156436920166, Validation loss: 0.41403335332870483
Epoch: 123/300 - Train loss: 0.4144730567932129, Validation loss: 0.4125894606113434
Epoch: 124/300 - Train loss: 0.4135686457157135, Validation loss: 0.4117801785469055
Epoch: 125/300 - Train loss: 0.4126780033111572, Validation loss: 0.41112858057022095
Epoch: 126/300 - Train loss: 0.41180193424224854, Validation loss: 0.4107067584991455
Epoch: 127/300 - Train loss: 0.41093909740448, Validation loss: 0.41021937131881714
Epoch: 128/300 - Train loss: 0.41008931398391724, Validation loss: 0.40843889117240906
Epoch: 129/300 - Train loss: 0.40925195813179016, Validation loss: 0.4086548089981079
Epoch: 130/300 - Train loss: 0.4084271490573883, Validation loss: 0.4069046378135681
Epoch: 131/300 - Train loss: 0.4076154828071594, Validation loss: 0.40614527463912964
Epoch: 132/300 - Train loss: 0.40681612491607666, Validation loss: 0.4054582715034485
Epoch: 133/300 - Train loss: 0.4060288965702057, Validation loss: 0.40346989035606384
Epoch: 134/300 - Train loss: 0.40525326132774353, Validation loss: 0.4030371904373169
Epoch: 135/300 - Train loss: 0.4044894278049469, Validation loss: 0.40333491563796997
Epoch: 136/300 - Train loss: 0.4037368893623352, Validation loss: 0.4022391140460968
Epoch: 137/300 - Train loss: 0.4029952585697174, Validation loss: 0.40100225806236267
Epoch: 138/300 - Train loss: 0.4022645950317383, Validation loss: 0.4018705189228058
Epoch: 139/300 - Train loss: 0.4015444219112396, Validation loss: 0.3997572660446167
Epoch: 140/300 - Train loss: 0.40083470940589905, Validation loss: 0.4003978371620178
Epoch: 141/300 - Train loss: 0.4001350402832031, Validation loss: 0.39905408024787903
Epoch: 142/300 - Train loss: 0.39944592118263245, Validation loss: 0.39806798100471497
Epoch: 143/300 - Train loss: 0.3987671136856079, Validation loss: 0.3972170948982239
Epoch: 144/300 - Train loss: 0.398098349571228, Validation loss: 0.3962036669254303
Epoch: 145/300 - Train loss: 0.3974396288394928, Validation loss: 0.39604777097702026
Epoch: 146/300 - Train loss: 0.39679065346717834, Validation loss: 0.3962525427341461
Epoch: 147/300 - Train loss: 0.3961508274078369, Validation loss: 0.39600545167922974
Epoch: 148/300 - Train loss: 0.39552006125450134, Validation loss: 0.39439284801483154
Epoch: 149/300 - Train loss: 0.39489832520484924, Validation loss: 0.3949504792690277
Epoch: 150/300 - Train loss: 0.39428550004959106, Validation loss: 0.3949204385280609
