Epoch: 1/300 - Train loss: 0.6926271319389343, Validation loss: 0.6887924671173096
Epoch: 2/300 - Train loss: 0.6901959180831909, Validation loss: 0.68644118309021
Epoch: 3/300 - Train loss: 0.6877799034118652, Validation loss: 0.6841680407524109
Epoch: 4/300 - Train loss: 0.685367226600647, Validation loss: 0.6818207502365112
Epoch: 5/300 - Train loss: 0.6829414367675781, Validation loss: 0.6794302463531494
Epoch: 6/300 - Train loss: 0.6804932355880737, Validation loss: 0.6770310401916504
Epoch: 7/300 - Train loss: 0.6780142784118652, Validation loss: 0.6745588779449463
Epoch: 8/300 - Train loss: 0.6754937767982483, Validation loss: 0.6719829440116882
Epoch: 9/300 - Train loss: 0.6729171872138977, Validation loss: 0.6694710850715637
Epoch: 10/300 - Train loss: 0.6702721118927002, Validation loss: 0.6668334007263184
Epoch: 11/300 - Train loss: 0.6675471067428589, Validation loss: 0.6640296578407288
Epoch: 12/300 - Train loss: 0.6647356748580933, Validation loss: 0.661210834980011
Epoch: 13/300 - Train loss: 0.6618272662162781, Validation loss: 0.6582850813865662
Epoch: 14/300 - Train loss: 0.6588139533996582, Validation loss: 0.6551923155784607
Epoch: 15/300 - Train loss: 0.6556923389434814, Validation loss: 0.6519942879676819
Epoch: 16/300 - Train loss: 0.6524652242660522, Validation loss: 0.6487064361572266
Epoch: 17/300 - Train loss: 0.6491297483444214, Validation loss: 0.6453090906143188
Epoch: 18/300 - Train loss: 0.645687997341156, Validation loss: 0.6417911648750305
Epoch: 19/300 - Train loss: 0.642145574092865, Validation loss: 0.6383031606674194
Epoch: 20/300 - Train loss: 0.6385032534599304, Validation loss: 0.6344290375709534
Epoch: 21/300 - Train loss: 0.6347733736038208, Validation loss: 0.630681574344635
Epoch: 22/300 - Train loss: 0.6309603452682495, Validation loss: 0.6269687414169312
Epoch: 23/300 - Train loss: 0.6270720958709717, Validation loss: 0.6230363249778748
Epoch: 24/300 - Train loss: 0.6231136322021484, Validation loss: 0.618983268737793
Epoch: 25/300 - Train loss: 0.6190921068191528, Validation loss: 0.6147869229316711
Epoch: 26/300 - Train loss: 0.6150074601173401, Validation loss: 0.6108624935150146
Epoch: 27/300 - Train loss: 0.6108677983283997, Validation loss: 0.6068281531333923
Epoch: 28/300 - Train loss: 0.6066843867301941, Validation loss: 0.6023142337799072
Epoch: 29/300 - Train loss: 0.6024647355079651, Validation loss: 0.5981488823890686
Epoch: 30/300 - Train loss: 0.5982140898704529, Validation loss: 0.5937219262123108
Epoch: 31/300 - Train loss: 0.5939370393753052, Validation loss: 0.589775025844574
Epoch: 32/300 - Train loss: 0.5896348357200623, Validation loss: 0.5854135751724243
Epoch: 33/300 - Train loss: 0.585308313369751, Validation loss: 0.5811353921890259
Epoch: 34/300 - Train loss: 0.5809663534164429, Validation loss: 0.5768693089485168
Epoch: 35/300 - Train loss: 0.5766102075576782, Validation loss: 0.5724461078643799
Epoch: 36/300 - Train loss: 0.572245180606842, Validation loss: 0.5684492588043213
Epoch: 37/300 - Train loss: 0.5678763389587402, Validation loss: 0.564177393913269
Epoch: 38/300 - Train loss: 0.5635046362876892, Validation loss: 0.5595987439155579
Epoch: 39/300 - Train loss: 0.5591378808021545, Validation loss: 0.5556169748306274
Epoch: 40/300 - Train loss: 0.5547800064086914, Validation loss: 0.5513651371002197
Epoch: 41/300 - Train loss: 0.5504339933395386, Validation loss: 0.5468443632125854
Epoch: 42/300 - Train loss: 0.5461061000823975, Validation loss: 0.542885959148407
Epoch: 43/300 - Train loss: 0.5418025255203247, Validation loss: 0.538424015045166
Epoch: 44/300 - Train loss: 0.5375270247459412, Validation loss: 0.5346983671188354
Epoch: 45/300 - Train loss: 0.5332838296890259, Validation loss: 0.5301637649536133
Epoch: 46/300 - Train loss: 0.5290747284889221, Validation loss: 0.5260829329490662
Epoch: 47/300 - Train loss: 0.5249007344245911, Validation loss: 0.5220283269882202
Epoch: 48/300 - Train loss: 0.5207642912864685, Validation loss: 0.5180007219314575
Epoch: 49/300 - Train loss: 0.5166675448417664, Validation loss: 0.5138906836509705
Epoch: 50/300 - Train loss: 0.5126133561134338, Validation loss: 0.5102200508117676
Epoch: 51/300 - Train loss: 0.5086025595664978, Validation loss: 0.5061267614364624
Epoch: 52/300 - Train loss: 0.5046380162239075, Validation loss: 0.5021242499351501
Epoch: 53/300 - Train loss: 0.5007213354110718, Validation loss: 0.49862536787986755
Epoch: 54/300 - Train loss: 0.49685347080230713, Validation loss: 0.495089590549469
Epoch: 55/300 - Train loss: 0.49303698539733887, Validation loss: 0.4911103844642639
Epoch: 56/300 - Train loss: 0.48927390575408936, Validation loss: 0.4879598319530487
Epoch: 57/300 - Train loss: 0.48556649684906006, Validation loss: 0.484171599149704
Epoch: 58/300 - Train loss: 0.4819161593914032, Validation loss: 0.48059579730033875
Epoch: 59/300 - Train loss: 0.47832512855529785, Validation loss: 0.4770151674747467
Epoch: 60/300 - Train loss: 0.4747943878173828, Validation loss: 0.4740491807460785
Epoch: 61/300 - Train loss: 0.4713251292705536, Validation loss: 0.4703935384750366
Epoch: 62/300 - Train loss: 0.46791744232177734, Validation loss: 0.4670928716659546
Epoch: 63/300 - Train loss: 0.46457144618034363, Validation loss: 0.4639637768268585
Epoch: 64/300 - Train loss: 0.46128731966018677, Validation loss: 0.46049633622169495
Epoch: 65/300 - Train loss: 0.45806562900543213, Validation loss: 0.4577644169330597
Epoch: 66/300 - Train loss: 0.45490652322769165, Validation loss: 0.4545363187789917
Epoch: 67/300 - Train loss: 0.4518103003501892, Validation loss: 0.4522899389266968
Epoch: 68/300 - Train loss: 0.4487774670124054, Validation loss: 0.4494015872478485
Epoch: 69/300 - Train loss: 0.4458085298538208, Validation loss: 0.44612517952919006
Epoch: 70/300 - Train loss: 0.4429027736186981, Validation loss: 0.4436090588569641
Epoch: 71/300 - Train loss: 0.440059632062912, Validation loss: 0.4403552711009979
Epoch: 72/300 - Train loss: 0.4372783899307251, Validation loss: 0.4382306933403015
Epoch: 73/300 - Train loss: 0.4345589578151703, Validation loss: 0.4355550706386566
Epoch: 74/300 - Train loss: 0.4319004714488983, Validation loss: 0.43310973048210144
Epoch: 75/300 - Train loss: 0.42930153012275696, Validation loss: 0.4308546483516693
Epoch: 76/300 - Train loss: 0.42676249146461487, Validation loss: 0.4282490611076355
Epoch: 77/300 - Train loss: 0.4242822825908661, Validation loss: 0.42595043778419495
Epoch: 78/300 - Train loss: 0.4218616783618927, Validation loss: 0.42344924807548523
Epoch: 79/300 - Train loss: 0.41949915885925293, Validation loss: 0.42114824056625366
Epoch: 80/300 - Train loss: 0.4171943664550781, Validation loss: 0.41943681240081787
Epoch: 81/300 - Train loss: 0.4149467945098877, Validation loss: 0.4171774685382843
Epoch: 82/300 - Train loss: 0.41275590658187866, Validation loss: 0.4155237674713135
Epoch: 83/300 - Train loss: 0.41062039136886597, Validation loss: 0.41290855407714844
Epoch: 84/300 - Train loss: 0.4085395634174347, Validation loss: 0.4113202691078186
Epoch: 85/300 - Train loss: 0.40651148557662964, Validation loss: 0.40925389528274536
Epoch: 86/300 - Train loss: 0.40453585982322693, Validation loss: 0.407516747713089
Epoch: 87/300 - Train loss: 0.4026119112968445, Validation loss: 0.4055503308773041
Epoch: 88/300 - Train loss: 0.4007388949394226, Validation loss: 0.4039587676525116
Epoch: 89/300 - Train loss: 0.3989153206348419, Validation loss: 0.40265360474586487
Epoch: 90/300 - Train loss: 0.39714065194129944, Validation loss: 0.40075185894966125
Epoch: 91/300 - Train loss: 0.39541345834732056, Validation loss: 0.3990170955657959
Epoch: 92/300 - Train loss: 0.39373236894607544, Validation loss: 0.3974725008010864
Epoch: 93/300 - Train loss: 0.392095685005188, Validation loss: 0.39595454931259155
Epoch: 94/300 - Train loss: 0.39050284028053284, Validation loss: 0.3944183588027954
Epoch: 95/300 - Train loss: 0.3889525532722473, Validation loss: 0.3930078446865082
Epoch: 96/300 - Train loss: 0.3874437212944031, Validation loss: 0.3916962444782257
Epoch: 97/300 - Train loss: 0.38597598671913147, Validation loss: 0.39053457975387573
Epoch: 98/300 - Train loss: 0.3845475912094116, Validation loss: 0.38848820328712463
Epoch: 99/300 - Train loss: 0.383157342672348, Validation loss: 0.3873524069786072
Epoch: 100/300 - Train loss: 0.3818041980266571, Validation loss: 0.38638249039649963
Epoch: 101/300 - Train loss: 0.3804873526096344, Validation loss: 0.38565608859062195
Epoch: 102/300 - Train loss: 0.3792056739330292, Validation loss: 0.38450050354003906
Epoch: 103/300 - Train loss: 0.3779582381248474, Validation loss: 0.3827168643474579
Epoch: 104/300 - Train loss: 0.37674397230148315, Validation loss: 0.3815631568431854
Epoch: 105/300 - Train loss: 0.3755618929862976, Validation loss: 0.38055771589279175
Epoch: 106/300 - Train loss: 0.3744109272956848, Validation loss: 0.37935134768486023
Epoch: 107/300 - Train loss: 0.3732898533344269, Validation loss: 0.378380686044693
Epoch: 108/300 - Train loss: 0.3721979856491089, Validation loss: 0.37683171033859253
Epoch: 109/300 - Train loss: 0.3711346983909607, Validation loss: 0.375738263130188
Epoch: 110/300 - Train loss: 0.3700989782810211, Validation loss: 0.375483900308609
Epoch: 111/300 - Train loss: 0.36908990144729614, Validation loss: 0.3750591576099396
Epoch: 112/300 - Train loss: 0.3681066632270813, Validation loss: 0.374470978975296
Epoch: 113/300 - Train loss: 0.3671479821205139, Validation loss: 0.37291502952575684
Epoch: 114/300 - Train loss: 0.36621323227882385, Validation loss: 0.3720089793205261
Epoch: 115/300 - Train loss: 0.3653014302253723, Validation loss: 0.37102070450782776
Epoch: 116/300 - Train loss: 0.3644121587276459, Validation loss: 0.37021327018737793
Epoch: 117/300 - Train loss: 0.363544762134552, Validation loss: 0.36967670917510986
Epoch: 118/300 - Train loss: 0.3626987040042877, Validation loss: 0.3679831624031067
Epoch: 119/300 - Train loss: 0.3618730902671814, Validation loss: 0.3675203323364258
Epoch: 120/300 - Train loss: 0.3610669672489166, Validation loss: 0.3671008050441742
Epoch: 121/300 - Train loss: 0.3602796196937561, Validation loss: 0.3662654459476471
Epoch: 122/300 - Train loss: 0.35951054096221924, Validation loss: 0.3656560778617859
Epoch: 123/300 - Train loss: 0.35875922441482544, Validation loss: 0.36455076932907104
Epoch: 124/300 - Train loss: 0.3580252230167389, Validation loss: 0.3641281723976135
Epoch: 125/300 - Train loss: 0.3573078215122223, Validation loss: 0.36312782764434814
Epoch: 126/300 - Train loss: 0.3566064238548279, Validation loss: 0.3627720773220062
Epoch: 127/300 - Train loss: 0.3559207320213318, Validation loss: 0.3618359863758087
Epoch: 128/300 - Train loss: 0.3552504777908325, Validation loss: 0.3613843619823456
Epoch: 129/300 - Train loss: 0.35459476709365845, Validation loss: 0.3604249358177185
Epoch: 130/300 - Train loss: 0.35395315289497375, Validation loss: 0.36020174622535706
Epoch: 131/300 - Train loss: 0.3533251881599426, Validation loss: 0.35926929116249084
Epoch: 132/300 - Train loss: 0.3527103364467621, Validation loss: 0.3587868809700012
Epoch: 133/300 - Train loss: 0.3521082401275635, Validation loss: 0.35854285955429077
Epoch: 134/300 - Train loss: 0.3515182137489319, Validation loss: 0.3579437732696533
Epoch: 135/300 - Train loss: 0.35094016790390015, Validation loss: 0.35724663734436035
Epoch: 136/300 - Train loss: 0.35037362575531006, Validation loss: 0.3569052815437317
