Epoch: 1/100 - Train loss: 0.6984407305717468, Validation loss: 0.6959034204483032
Epoch: 2/100 - Train loss: 0.6966394782066345, Validation loss: 0.6941318511962891
Epoch: 3/100 - Train loss: 0.6947952508926392, Validation loss: 0.6922932863235474
Epoch: 4/100 - Train loss: 0.6928925514221191, Validation loss: 0.6904252767562866
Epoch: 5/100 - Train loss: 0.6909198760986328, Validation loss: 0.6885619163513184
Epoch: 6/100 - Train loss: 0.6888546943664551, Validation loss: 0.6865382194519043
Epoch: 7/100 - Train loss: 0.6866941452026367, Validation loss: 0.6844273805618286
Epoch: 8/100 - Train loss: 0.6844432950019836, Validation loss: 0.682259738445282
Epoch: 9/100 - Train loss: 0.6821053624153137, Validation loss: 0.6799760460853577
Epoch: 10/100 - Train loss: 0.6796844005584717, Validation loss: 0.6775983572006226
Epoch: 11/100 - Train loss: 0.6771953701972961, Validation loss: 0.6752455830574036
Epoch: 12/100 - Train loss: 0.6746442317962646, Validation loss: 0.6727433800697327
Epoch: 13/100 - Train loss: 0.6720371842384338, Validation loss: 0.6701468825340271
Epoch: 14/100 - Train loss: 0.6693825125694275, Validation loss: 0.6677697896957397
Epoch: 15/100 - Train loss: 0.6666858792304993, Validation loss: 0.6651459336280823
Epoch: 16/100 - Train loss: 0.6639580130577087, Validation loss: 0.6626651287078857
Epoch: 17/100 - Train loss: 0.6612051725387573, Validation loss: 0.6598942875862122
Epoch: 18/100 - Train loss: 0.6584281325340271, Validation loss: 0.6572043299674988
Epoch: 19/100 - Train loss: 0.6556293964385986, Validation loss: 0.6547160148620605
Epoch: 20/100 - Train loss: 0.6528053879737854, Validation loss: 0.6518053412437439
Epoch: 21/100 - Train loss: 0.6499590873718262, Validation loss: 0.6491634249687195
Epoch: 22/100 - Train loss: 0.6470910310745239, Validation loss: 0.6465051770210266
Epoch: 23/100 - Train loss: 0.6442070603370667, Validation loss: 0.6435524821281433
Epoch: 24/100 - Train loss: 0.6413071155548096, Validation loss: 0.6408371329307556
Epoch: 25/100 - Train loss: 0.6383949518203735, Validation loss: 0.638272762298584
Epoch: 26/100 - Train loss: 0.6354725956916809, Validation loss: 0.635209858417511
Epoch: 27/100 - Train loss: 0.6325435042381287, Validation loss: 0.6327893733978271
Epoch: 28/100 - Train loss: 0.6296101212501526, Validation loss: 0.6295991539955139
Epoch: 29/100 - Train loss: 0.6266746520996094, Validation loss: 0.6271107792854309
Epoch: 30/100 - Train loss: 0.6237391233444214, Validation loss: 0.6239722371101379
Epoch: 31/100 - Train loss: 0.6208061575889587, Validation loss: 0.6213805675506592
Epoch: 32/100 - Train loss: 0.6178779006004333, Validation loss: 0.6185641884803772
Epoch: 33/100 - Train loss: 0.614955484867096, Validation loss: 0.6156166791915894
Epoch: 34/100 - Train loss: 0.6120412945747375, Validation loss: 0.6131114363670349
Epoch: 35/100 - Train loss: 0.6091378331184387, Validation loss: 0.610132098197937
Epoch: 36/100 - Train loss: 0.6062472462654114, Validation loss: 0.6072766184806824
Epoch: 37/100 - Train loss: 0.6033715605735779, Validation loss: 0.6044802069664001
Epoch: 38/100 - Train loss: 0.6005129218101501, Validation loss: 0.6020572185516357
Epoch: 39/100 - Train loss: 0.5976749062538147, Validation loss: 0.5992509126663208
Epoch: 40/100 - Train loss: 0.5948602557182312, Validation loss: 0.596588671207428
Epoch: 41/100 - Train loss: 0.5920707583427429, Validation loss: 0.5939849019050598
Epoch: 42/100 - Train loss: 0.5893084406852722, Validation loss: 0.5912859439849854
Epoch: 43/100 - Train loss: 0.5865755081176758, Validation loss: 0.5888645052909851
Epoch: 44/100 - Train loss: 0.583873987197876, Validation loss: 0.585943341255188
Epoch: 45/100 - Train loss: 0.5812057256698608, Validation loss: 0.583669126033783
Epoch: 46/100 - Train loss: 0.5785740613937378, Validation loss: 0.5810196399688721
Epoch: 47/100 - Train loss: 0.5759802460670471, Validation loss: 0.5788059234619141
Epoch: 48/100 - Train loss: 0.5734257698059082, Validation loss: 0.5763577818870544
Epoch: 49/100 - Train loss: 0.5709121227264404, Validation loss: 0.574211061000824
Epoch: 50/100 - Train loss: 0.568440854549408, Validation loss: 0.5716080069541931
Epoch: 51/100 - Train loss: 0.5660129189491272, Validation loss: 0.56962651014328
Epoch: 52/100 - Train loss: 0.563630223274231, Validation loss: 0.5668079257011414
Epoch: 53/100 - Train loss: 0.5612940192222595, Validation loss: 0.5650829672813416
Epoch: 54/100 - Train loss: 0.5590050220489502, Validation loss: 0.5630666017532349
Epoch: 55/100 - Train loss: 0.5567648410797119, Validation loss: 0.5605250000953674
Epoch: 56/100 - Train loss: 0.5545740127563477, Validation loss: 0.5589669942855835
Epoch: 57/100 - Train loss: 0.5524331331253052, Validation loss: 0.5564885139465332
Epoch: 58/100 - Train loss: 0.5503427982330322, Validation loss: 0.5548170804977417
Epoch: 59/100 - Train loss: 0.5483037829399109, Validation loss: 0.5531130433082581
Epoch: 60/100 - Train loss: 0.5463162660598755, Validation loss: 0.5509234070777893
Epoch: 61/100 - Train loss: 0.5443800091743469, Validation loss: 0.5494827032089233
Epoch: 62/100 - Train loss: 0.542495608329773, Validation loss: 0.5479764342308044
Epoch: 63/100 - Train loss: 0.5406625270843506, Validation loss: 0.5453847050666809
Epoch: 64/100 - Train loss: 0.5388811230659485, Validation loss: 0.5439873933792114
Epoch: 65/100 - Train loss: 0.5371511578559875, Validation loss: 0.5426701903343201
Epoch: 66/100 - Train loss: 0.5354719758033752, Validation loss: 0.5410127639770508
Epoch: 67/100 - Train loss: 0.5338432192802429, Validation loss: 0.5400233864784241
Epoch: 68/100 - Train loss: 0.5322635769844055, Validation loss: 0.537570595741272
Epoch: 69/100 - Train loss: 0.5307325124740601, Validation loss: 0.5371529459953308
Epoch: 70/100 - Train loss: 0.5292490124702454, Validation loss: 0.5356197953224182
Epoch: 71/100 - Train loss: 0.5278121829032898, Validation loss: 0.5337620973587036
Epoch: 72/100 - Train loss: 0.5264212489128113, Validation loss: 0.5328051447868347
Epoch: 73/100 - Train loss: 0.5250749588012695, Validation loss: 0.5316088795661926
Epoch: 74/100 - Train loss: 0.5237720012664795, Validation loss: 0.5305237770080566
Epoch: 75/100 - Train loss: 0.5225110054016113, Validation loss: 0.5291392207145691
Epoch: 76/100 - Train loss: 0.5212904810905457, Validation loss: 0.5284082889556885
Epoch: 77/100 - Train loss: 0.5201085805892944, Validation loss: 0.5272143483161926
Epoch: 78/100 - Train loss: 0.5189632177352905, Validation loss: 0.5264673829078674
Epoch: 79/100 - Train loss: 0.5178527235984802, Validation loss: 0.5250117182731628
Epoch: 80/100 - Train loss: 0.5167754888534546, Validation loss: 0.5238144993782043
Epoch: 81/100 - Train loss: 0.5157302021980286, Validation loss: 0.5234373807907104
Epoch: 82/100 - Train loss: 0.5147148966789246, Validation loss: 0.5228559374809265
Epoch: 83/100 - Train loss: 0.513727605342865, Validation loss: 0.5220831036567688
Epoch: 84/100 - Train loss: 0.5127663016319275, Validation loss: 0.5207579731941223
Epoch: 85/100 - Train loss: 0.5118287205696106, Validation loss: 0.5196152329444885
Epoch: 86/100 - Train loss: 0.5109142661094666, Validation loss: 0.5182498097419739
Epoch: 87/100 - Train loss: 0.5100197196006775, Validation loss: 0.5179969072341919
Epoch: 88/100 - Train loss: 0.5091436505317688, Validation loss: 0.5167052745819092
Epoch: 89/100 - Train loss: 0.508284866809845, Validation loss: 0.515737771987915
Epoch: 90/100 - Train loss: 0.5074442028999329, Validation loss: 0.5160378217697144
Epoch: 91/100 - Train loss: 0.5066197514533997, Validation loss: 0.5148425102233887
Epoch: 92/100 - Train loss: 0.5058096051216125, Validation loss: 0.5143106579780579
Epoch: 93/100 - Train loss: 0.5050102472305298, Validation loss: 0.5136106610298157
Epoch: 94/100 - Train loss: 0.504223108291626, Validation loss: 0.512136697769165
Epoch: 95/100 - Train loss: 0.5034471154212952, Validation loss: 0.512584388256073
Epoch: 96/100 - Train loss: 0.5026808381080627, Validation loss: 0.5116105675697327
Epoch: 97/100 - Train loss: 0.5019230842590332, Validation loss: 0.5105724930763245
Epoch: 98/100 - Train loss: 0.5011720657348633, Validation loss: 0.5106035470962524
Epoch: 99/100 - Train loss: 0.5004290342330933, Validation loss: 0.5087710022926331
Epoch: 100/100 - Train loss: 0.49969378113746643, Validation loss: 0.5086681842803955
Epoch: 1/300 - Train loss: 0.7025580406188965, Validation loss: 0.6993328332901001
Epoch: 2/300 - Train loss: 0.7008622884750366, Validation loss: 0.6980342864990234
Epoch: 3/300 - Train loss: 0.6991980671882629, Validation loss: 0.6963346600532532
Epoch: 4/300 - Train loss: 0.6975708603858948, Validation loss: 0.6948781609535217
Epoch: 5/300 - Train loss: 0.6959739327430725, Validation loss: 0.6935133337974548
Epoch: 6/300 - Train loss: 0.6944035887718201, Validation loss: 0.6920166015625
Epoch: 7/300 - Train loss: 0.692852258682251, Validation loss: 0.6905668377876282
Epoch: 8/300 - Train loss: 0.6913176774978638, Validation loss: 0.6891101598739624
Epoch: 9/300 - Train loss: 0.689786434173584, Validation loss: 0.6875133514404297
Epoch: 10/300 - Train loss: 0.688252329826355, Validation loss: 0.6860246062278748
Epoch: 11/300 - Train loss: 0.6867043972015381, Validation loss: 0.6845991611480713
Epoch: 12/300 - Train loss: 0.6851321458816528, Validation loss: 0.6829544901847839
Epoch: 13/300 - Train loss: 0.6835245490074158, Validation loss: 0.6814351081848145
Epoch: 14/300 - Train loss: 0.6818714141845703, Validation loss: 0.6798333525657654
Epoch: 15/300 - Train loss: 0.6801663041114807, Validation loss: 0.6781452298164368
Epoch: 16/300 - Train loss: 0.6784055233001709, Validation loss: 0.676438570022583
Epoch: 17/300 - Train loss: 0.6765842437744141, Validation loss: 0.6746089458465576
Epoch: 18/300 - Train loss: 0.6746994853019714, Validation loss: 0.6727551817893982
Epoch: 19/300 - Train loss: 0.6727505326271057, Validation loss: 0.6708101630210876
Epoch: 20/300 - Train loss: 0.6707367897033691, Validation loss: 0.6688266396522522
Epoch: 21/300 - Train loss: 0.668655276298523, Validation loss: 0.6668301820755005
Epoch: 22/300 - Train loss: 0.6665064096450806, Validation loss: 0.6645800471305847
Epoch: 23/300 - Train loss: 0.6642894744873047, Validation loss: 0.6624379754066467
Epoch: 24/300 - Train loss: 0.6620033383369446, Validation loss: 0.6601577997207642
Epoch: 25/300 - Train loss: 0.6596521139144897, Validation loss: 0.6578146815299988
Epoch: 26/300 - Train loss: 0.6572386026382446, Validation loss: 0.6555324792861938
Epoch: 27/300 - Train loss: 0.654765248298645, Validation loss: 0.6530032753944397
Epoch: 28/300 - Train loss: 0.6522321105003357, Validation loss: 0.6505004167556763
Epoch: 29/300 - Train loss: 0.6496425867080688, Validation loss: 0.6480889320373535
Epoch: 30/300 - Train loss: 0.6469942331314087, Validation loss: 0.6452041268348694
Epoch: 31/300 - Train loss: 0.6442947387695312, Validation loss: 0.6427657604217529
Epoch: 32/300 - Train loss: 0.641551673412323, Validation loss: 0.6400079727172852
Epoch: 33/300 - Train loss: 0.6387685537338257, Validation loss: 0.6372733116149902
Epoch: 34/300 - Train loss: 0.6359485387802124, Validation loss: 0.6344947814941406
Epoch: 35/300 - Train loss: 0.6330981254577637, Validation loss: 0.631619393825531
Epoch: 36/300 - Train loss: 0.6302201151847839, Validation loss: 0.6289253234863281
Epoch: 37/300 - Train loss: 0.6273214817047119, Validation loss: 0.6262230277061462
Epoch: 38/300 - Train loss: 0.6244025826454163, Validation loss: 0.6232536435127258
Epoch: 39/300 - Train loss: 0.621465265750885, Validation loss: 0.6204063892364502
Epoch: 40/300 - Train loss: 0.6185104250907898, Validation loss: 0.6176120042800903
Epoch: 41/300 - Train loss: 0.6155402660369873, Validation loss: 0.6145249605178833
Epoch: 42/300 - Train loss: 0.6125580072402954, Validation loss: 0.6117259860038757
Epoch: 43/300 - Train loss: 0.6095676422119141, Validation loss: 0.609133243560791
Epoch: 44/300 - Train loss: 0.6065722703933716, Validation loss: 0.606067419052124
Epoch: 45/300 - Train loss: 0.6035774946212769, Validation loss: 0.6030871272087097
Epoch: 46/300 - Train loss: 0.6005874872207642, Validation loss: 0.600408673286438
Epoch: 47/300 - Train loss: 0.5976070761680603, Validation loss: 0.5975183844566345
Epoch: 48/300 - Train loss: 0.5946407318115234, Validation loss: 0.5944371819496155
Epoch: 49/300 - Train loss: 0.5916933417320251, Validation loss: 0.5920196771621704
Epoch: 50/300 - Train loss: 0.5887693762779236, Validation loss: 0.5889047980308533
Epoch: 51/300 - Train loss: 0.5858730673789978, Validation loss: 0.5866644382476807
Epoch: 52/300 - Train loss: 0.5830086469650269, Validation loss: 0.5837895274162292
Epoch: 53/300 - Train loss: 0.5801795721054077, Validation loss: 0.5810481905937195
Epoch: 54/300 - Train loss: 0.5773882269859314, Validation loss: 0.5783946514129639
Epoch: 55/300 - Train loss: 0.5746377110481262, Validation loss: 0.5760787129402161
Epoch: 56/300 - Train loss: 0.5719307065010071, Validation loss: 0.5731822848320007
Epoch: 57/300 - Train loss: 0.5692700147628784, Validation loss: 0.5706547498703003
Epoch: 58/300 - Train loss: 0.5666577816009521, Validation loss: 0.5683127045631409
Epoch: 59/300 - Train loss: 0.5640958547592163, Validation loss: 0.5656978487968445
Epoch: 60/300 - Train loss: 0.5615856647491455, Validation loss: 0.5636470317840576
Epoch: 61/300 - Train loss: 0.5591294765472412, Validation loss: 0.561294674873352
Epoch: 62/300 - Train loss: 0.5567286610603333, Validation loss: 0.5593253970146179
Epoch: 63/300 - Train loss: 0.5543840527534485, Validation loss: 0.5569178462028503
Epoch: 64/300 - Train loss: 0.5520968437194824, Validation loss: 0.5548784732818604
Epoch: 65/300 - Train loss: 0.5498677492141724, Validation loss: 0.5527516007423401
Epoch: 66/300 - Train loss: 0.5476970672607422, Validation loss: 0.5502626895904541
Epoch: 67/300 - Train loss: 0.5455848574638367, Validation loss: 0.5484572052955627
Epoch: 68/300 - Train loss: 0.5435316562652588, Validation loss: 0.5468075275421143
Epoch: 69/300 - Train loss: 0.5415378212928772, Validation loss: 0.5453396439552307
Epoch: 70/300 - Train loss: 0.5396032333374023, Validation loss: 0.5433174967765808
Epoch: 71/300 - Train loss: 0.5377277731895447, Validation loss: 0.5417976379394531
Epoch: 72/300 - Train loss: 0.5359108448028564, Validation loss: 0.5398699045181274
Epoch: 73/300 - Train loss: 0.5341514945030212, Validation loss: 0.5382271409034729
Epoch: 74/300 - Train loss: 0.5324487686157227, Validation loss: 0.5370098948478699
Epoch: 75/300 - Train loss: 0.5308016538619995, Validation loss: 0.5355550646781921
Epoch: 76/300 - Train loss: 0.5292088985443115, Validation loss: 0.5342018604278564
Epoch: 77/300 - Train loss: 0.5276691317558289, Validation loss: 0.5328524112701416
Epoch: 78/300 - Train loss: 0.526181161403656, Validation loss: 0.531337559223175
Epoch: 79/300 - Train loss: 0.5247434377670288, Validation loss: 0.5296874642372131
Epoch: 80/300 - Train loss: 0.5233545899391174, Validation loss: 0.5286650061607361
Epoch: 81/300 - Train loss: 0.5220122337341309, Validation loss: 0.5271603465080261
Epoch: 82/300 - Train loss: 0.5207154750823975, Validation loss: 0.5266768932342529
Epoch: 83/300 - Train loss: 0.5194624066352844, Validation loss: 0.5249114632606506
Epoch: 84/300 - Train loss: 0.5182515978813171, Validation loss: 0.5244929194450378
Epoch: 85/300 - Train loss: 0.5170813798904419, Validation loss: 0.5234116315841675
Epoch: 86/300 - Train loss: 0.5159493684768677, Validation loss: 0.5227919816970825
Epoch: 87/300 - Train loss: 0.5148539543151855, Validation loss: 0.521109402179718
Epoch: 88/300 - Train loss: 0.5137934684753418, Validation loss: 0.5203108787536621
Epoch: 89/300 - Train loss: 0.5127661228179932, Validation loss: 0.5200826525688171
Epoch: 90/300 - Train loss: 0.5117706060409546, Validation loss: 0.5190967917442322
Epoch: 91/300 - Train loss: 0.5108044147491455, Validation loss: 0.5176486968994141
Epoch: 92/300 - Train loss: 0.509865939617157, Validation loss: 0.5173304677009583
Epoch: 93/300 - Train loss: 0.5089538097381592, Validation loss: 0.5163085460662842
Epoch: 94/300 - Train loss: 0.5080662369728088, Validation loss: 0.515874981880188
Epoch: 95/300 - Train loss: 0.5072011947631836, Validation loss: 0.5143391489982605
Epoch: 96/300 - Train loss: 0.5063577890396118, Validation loss: 0.5140694975852966
Epoch: 97/300 - Train loss: 0.5055363774299622, Validation loss: 0.5127977132797241
Epoch: 98/300 - Train loss: 0.5047340393066406, Validation loss: 0.5122380256652832
Epoch: 99/300 - Train loss: 0.5039499998092651, Validation loss: 0.5116631984710693
Epoch: 100/300 - Train loss: 0.5031827092170715, Validation loss: 0.5116682648658752
Epoch: 101/300 - Train loss: 0.5024312734603882, Validation loss: 0.5108985900878906
Epoch: 102/300 - Train loss: 0.5016965270042419, Validation loss: 0.509956419467926
Epoch: 103/300 - Train loss: 0.5009753704071045, Validation loss: 0.5091860890388489
Epoch: 104/300 - Train loss: 0.5002667307853699, Validation loss: 0.5087886452674866
Epoch: 105/300 - Train loss: 0.4995693266391754, Validation loss: 0.5072605609893799
Epoch: 106/300 - Train loss: 0.4988817274570465, Validation loss: 0.5069278478622437
Epoch: 107/300 - Train loss: 0.4982030987739563, Validation loss: 0.5068199634552002
Epoch: 108/300 - Train loss: 0.49753397703170776, Validation loss: 0.5056338310241699
Epoch: 109/300 - Train loss: 0.49687179923057556, Validation loss: 0.505171000957489
Epoch: 110/300 - Train loss: 0.4962159991264343, Validation loss: 0.5046542286872864
Epoch: 111/300 - Train loss: 0.49556782841682434, Validation loss: 0.5034945011138916
Epoch: 112/300 - Train loss: 0.4949275553226471, Validation loss: 0.5033663511276245
Epoch: 113/300 - Train loss: 0.4942922592163086, Validation loss: 0.5028536319732666
Epoch: 114/300 - Train loss: 0.4936607778072357, Validation loss: 0.5023031234741211
