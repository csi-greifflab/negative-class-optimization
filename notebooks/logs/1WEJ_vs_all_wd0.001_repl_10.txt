Epoch: 1/300 - Train loss: 0.7066861987113953, Validation loss: 0.7060403227806091
Epoch: 2/300 - Train loss: 0.7041935324668884, Validation loss: 0.7039988040924072
Epoch: 3/300 - Train loss: 0.7017655968666077, Validation loss: 0.7015166282653809
Epoch: 4/300 - Train loss: 0.6993924379348755, Validation loss: 0.6991091370582581
Epoch: 5/300 - Train loss: 0.6970590353012085, Validation loss: 0.6970292329788208
Epoch: 6/300 - Train loss: 0.6947453022003174, Validation loss: 0.6946365833282471
Epoch: 7/300 - Train loss: 0.6924253702163696, Validation loss: 0.6922311186790466
Epoch: 8/300 - Train loss: 0.6900832653045654, Validation loss: 0.6900379657745361
Epoch: 9/300 - Train loss: 0.6877003312110901, Validation loss: 0.687484860420227
Epoch: 10/300 - Train loss: 0.6852561235427856, Validation loss: 0.6849807500839233
Epoch: 11/300 - Train loss: 0.6827310919761658, Validation loss: 0.6822295188903809
Epoch: 12/300 - Train loss: 0.6801106929779053, Validation loss: 0.6795287132263184
Epoch: 13/300 - Train loss: 0.6773800253868103, Validation loss: 0.6766228079795837
Epoch: 14/300 - Train loss: 0.6745240688323975, Validation loss: 0.6739054322242737
Epoch: 15/300 - Train loss: 0.6715367436408997, Validation loss: 0.670711100101471
Epoch: 16/300 - Train loss: 0.6684069633483887, Validation loss: 0.6675198674201965
Epoch: 17/300 - Train loss: 0.6651334762573242, Validation loss: 0.6640962958335876
Epoch: 18/300 - Train loss: 0.6617165803909302, Validation loss: 0.6606695652008057
Epoch: 19/300 - Train loss: 0.658162534236908, Validation loss: 0.6570936441421509
Epoch: 20/300 - Train loss: 0.6544780135154724, Validation loss: 0.6533284783363342
Epoch: 21/300 - Train loss: 0.6506715416908264, Validation loss: 0.6493721008300781
Epoch: 22/300 - Train loss: 0.6467600464820862, Validation loss: 0.6454060077667236
Epoch: 23/300 - Train loss: 0.6427582502365112, Validation loss: 0.6415377855300903
Epoch: 24/300 - Train loss: 0.6386775970458984, Validation loss: 0.6375014781951904
Epoch: 25/300 - Train loss: 0.6345275640487671, Validation loss: 0.6331685781478882
Epoch: 26/300 - Train loss: 0.6303207874298096, Validation loss: 0.6289784908294678
Epoch: 27/300 - Train loss: 0.6260665059089661, Validation loss: 0.6248767971992493
Epoch: 28/300 - Train loss: 0.6217688918113708, Validation loss: 0.6203991770744324
Epoch: 29/300 - Train loss: 0.6174329519271851, Validation loss: 0.6161126494407654
Epoch: 30/300 - Train loss: 0.6130621433258057, Validation loss: 0.6119375824928284
Epoch: 31/300 - Train loss: 0.6086598634719849, Validation loss: 0.6074222922325134
Epoch: 32/300 - Train loss: 0.6042304039001465, Validation loss: 0.6028985381126404
Epoch: 33/300 - Train loss: 0.5997765064239502, Validation loss: 0.5984879732131958
Epoch: 34/300 - Train loss: 0.5953032970428467, Validation loss: 0.5939983129501343
Epoch: 35/300 - Train loss: 0.5908141732215881, Validation loss: 0.5897054672241211
Epoch: 36/300 - Train loss: 0.5863136649131775, Validation loss: 0.585045576095581
Epoch: 37/300 - Train loss: 0.5818066596984863, Validation loss: 0.5806046724319458
Epoch: 38/300 - Train loss: 0.5772983431816101, Validation loss: 0.5759117603302002
Epoch: 39/300 - Train loss: 0.5727931261062622, Validation loss: 0.571463406085968
Epoch: 40/300 - Train loss: 0.5682958364486694, Validation loss: 0.5671043395996094
Epoch: 41/300 - Train loss: 0.5638117790222168, Validation loss: 0.5623435974121094
Epoch: 42/300 - Train loss: 0.5593461990356445, Validation loss: 0.5578612089157104
Epoch: 43/300 - Train loss: 0.5549032092094421, Validation loss: 0.5539339780807495
Epoch: 44/300 - Train loss: 0.5504874587059021, Validation loss: 0.5493635535240173
Epoch: 45/300 - Train loss: 0.5461034178733826, Validation loss: 0.5450413227081299
Epoch: 46/300 - Train loss: 0.5417547821998596, Validation loss: 0.5403655767440796
Epoch: 47/300 - Train loss: 0.5374457240104675, Validation loss: 0.5362284779548645
Epoch: 48/300 - Train loss: 0.533179521560669, Validation loss: 0.5318678021430969
Epoch: 49/300 - Train loss: 0.5289595127105713, Validation loss: 0.5275909304618835
Epoch: 50/300 - Train loss: 0.5247886180877686, Validation loss: 0.5234888195991516
Epoch: 51/300 - Train loss: 0.5206699371337891, Validation loss: 0.5193004012107849
Epoch: 52/300 - Train loss: 0.5166066884994507, Validation loss: 0.5153972506523132
Epoch: 53/300 - Train loss: 0.512600839138031, Validation loss: 0.5117200016975403
Epoch: 54/300 - Train loss: 0.5086544156074524, Validation loss: 0.5075985193252563
Epoch: 55/300 - Train loss: 0.5047692060470581, Validation loss: 0.503618061542511
Epoch: 56/300 - Train loss: 0.5009469985961914, Validation loss: 0.4998933672904968
Epoch: 57/300 - Train loss: 0.49718981981277466, Validation loss: 0.4957476556301117
Epoch: 58/300 - Train loss: 0.49349936842918396, Validation loss: 0.49214968085289
Epoch: 59/300 - Train loss: 0.48987722396850586, Validation loss: 0.4890686869621277
Epoch: 60/300 - Train loss: 0.48632463812828064, Validation loss: 0.4848816990852356
Epoch: 61/300 - Train loss: 0.4828428030014038, Validation loss: 0.4815137982368469
Epoch: 62/300 - Train loss: 0.4794323444366455, Validation loss: 0.4783145487308502
Epoch: 63/300 - Train loss: 0.476093590259552, Validation loss: 0.47458669543266296
Epoch: 64/300 - Train loss: 0.4728265702724457, Validation loss: 0.47139033675193787
Epoch: 65/300 - Train loss: 0.4696313142776489, Validation loss: 0.46883657574653625
Epoch: 66/300 - Train loss: 0.4665083587169647, Validation loss: 0.4657529890537262
Epoch: 67/300 - Train loss: 0.46345746517181396, Validation loss: 0.46237823367118835
Epoch: 68/300 - Train loss: 0.4604780673980713, Validation loss: 0.4596930742263794
Epoch: 69/300 - Train loss: 0.4575697183609009, Validation loss: 0.45639845728874207
Epoch: 70/300 - Train loss: 0.45473170280456543, Validation loss: 0.45365506410598755
Epoch: 71/300 - Train loss: 0.45196330547332764, Validation loss: 0.4505208730697632
Epoch: 72/300 - Train loss: 0.44926348328590393, Validation loss: 0.4481703042984009
Epoch: 73/300 - Train loss: 0.4466320276260376, Validation loss: 0.4451368451118469
Epoch: 74/300 - Train loss: 0.4440672993659973, Validation loss: 0.4427175521850586
Epoch: 75/300 - Train loss: 0.4415680766105652, Validation loss: 0.44048282504081726
Epoch: 76/300 - Train loss: 0.43913257122039795, Validation loss: 0.43793272972106934
Epoch: 77/300 - Train loss: 0.43675917387008667, Validation loss: 0.43574225902557373
Epoch: 78/300 - Train loss: 0.43444669246673584, Validation loss: 0.4330897927284241
Epoch: 79/300 - Train loss: 0.43219366669654846, Validation loss: 0.4313448369503021
Epoch: 80/300 - Train loss: 0.4299990236759186, Validation loss: 0.42821675539016724
Epoch: 81/300 - Train loss: 0.4278617203235626, Validation loss: 0.426348477602005
Epoch: 82/300 - Train loss: 0.4257808327674866, Validation loss: 0.42417317628860474
Epoch: 83/300 - Train loss: 0.42375487089157104, Validation loss: 0.42217397689819336
Epoch: 84/300 - Train loss: 0.42178186774253845, Validation loss: 0.4200364649295807
Epoch: 85/300 - Train loss: 0.4198606610298157, Validation loss: 0.41847658157348633
Epoch: 86/300 - Train loss: 0.41798925399780273, Validation loss: 0.4166359603404999
Epoch: 87/300 - Train loss: 0.416165828704834, Validation loss: 0.4142772853374481
Epoch: 88/300 - Train loss: 0.41438978910446167, Validation loss: 0.4127007722854614
Epoch: 89/300 - Train loss: 0.4126596748828888, Validation loss: 0.4110809862613678
Epoch: 90/300 - Train loss: 0.4109741151332855, Validation loss: 0.4088854491710663
Epoch: 91/300 - Train loss: 0.4093319773674011, Validation loss: 0.4073781967163086
Epoch: 92/300 - Train loss: 0.40773043036460876, Validation loss: 0.4057866036891937
Epoch: 93/300 - Train loss: 0.4061679542064667, Validation loss: 0.4044640362262726
Epoch: 94/300 - Train loss: 0.4046441316604614, Validation loss: 0.4028033912181854
Epoch: 95/300 - Train loss: 0.40315794944763184, Validation loss: 0.40144863724708557
Epoch: 96/300 - Train loss: 0.4017076790332794, Validation loss: 0.3996776342391968
Epoch: 97/300 - Train loss: 0.4002915322780609, Validation loss: 0.3988395035266876
Epoch: 98/300 - Train loss: 0.3989095389842987, Validation loss: 0.3974475562572479
Epoch: 99/300 - Train loss: 0.397561252117157, Validation loss: 0.39543500542640686
Epoch: 100/300 - Train loss: 0.39624375104904175, Validation loss: 0.3943765461444855
Epoch: 101/300 - Train loss: 0.3949572741985321, Validation loss: 0.3927103281021118
Epoch: 102/300 - Train loss: 0.3937011957168579, Validation loss: 0.3909222483634949
Epoch: 103/300 - Train loss: 0.3924747407436371, Validation loss: 0.3900407552719116
Epoch: 104/300 - Train loss: 0.39127638936042786, Validation loss: 0.3891373574733734
Epoch: 105/300 - Train loss: 0.3901042938232422, Validation loss: 0.38819998502731323
Epoch: 106/300 - Train loss: 0.3889595866203308, Validation loss: 0.3868463933467865
Epoch: 107/300 - Train loss: 0.38784053921699524, Validation loss: 0.3852316737174988
Epoch: 108/300 - Train loss: 0.3867458999156952, Validation loss: 0.3841336965560913
Epoch: 109/300 - Train loss: 0.38567647337913513, Validation loss: 0.3832356035709381
Epoch: 110/300 - Train loss: 0.3846321403980255, Validation loss: 0.3823104798793793
Epoch: 111/300 - Train loss: 0.3836117386817932, Validation loss: 0.3807758092880249
Epoch: 112/300 - Train loss: 0.38261327147483826, Validation loss: 0.3795783817768097
Epoch: 113/300 - Train loss: 0.3816370368003845, Validation loss: 0.3785715401172638
Epoch: 114/300 - Train loss: 0.38068175315856934, Validation loss: 0.37812167406082153
Epoch: 115/300 - Train loss: 0.379747211933136, Validation loss: 0.37641164660453796
Epoch: 116/300 - Train loss: 0.37883260846138, Validation loss: 0.3762000501155853
Epoch: 117/300 - Train loss: 0.3779365122318268, Validation loss: 0.37460750341415405
Epoch: 118/300 - Train loss: 0.37705883383750916, Validation loss: 0.37456151843070984
Epoch: 119/300 - Train loss: 0.37619906663894653, Validation loss: 0.37392672896385193
Epoch: 120/300 - Train loss: 0.3753562271595001, Validation loss: 0.3728291690349579
Epoch: 121/300 - Train loss: 0.37452971935272217, Validation loss: 0.37158554792404175
Epoch: 122/300 - Train loss: 0.3737187683582306, Validation loss: 0.37015628814697266
Epoch: 123/300 - Train loss: 0.37292352318763733, Validation loss: 0.36957231163978577
Epoch: 124/300 - Train loss: 0.372143417596817, Validation loss: 0.36910706758499146
Epoch: 125/300 - Train loss: 0.371378093957901, Validation loss: 0.36889564990997314
Epoch: 126/300 - Train loss: 0.370627224445343, Validation loss: 0.36772075295448303
Epoch: 127/300 - Train loss: 0.36989009380340576, Validation loss: 0.3663274645805359
Epoch: 128/300 - Train loss: 0.3691658675670624, Validation loss: 0.3657674193382263
Epoch: 129/300 - Train loss: 0.3684553802013397, Validation loss: 0.3651488125324249
Epoch: 130/300 - Train loss: 0.3677576184272766, Validation loss: 0.36419105529785156
Epoch: 131/300 - Train loss: 0.3670726418495178, Validation loss: 0.3634895980358124
Epoch: 132/300 - Train loss: 0.3663995862007141, Validation loss: 0.36276525259017944
Epoch: 133/300 - Train loss: 0.3657383918762207, Validation loss: 0.3630557656288147
Epoch: 134/300 - Train loss: 0.3650885224342346, Validation loss: 0.3613199293613434
Epoch: 135/300 - Train loss: 0.3644494414329529, Validation loss: 0.361176460981369
Epoch: 136/300 - Train loss: 0.3638204336166382, Validation loss: 0.36038047075271606
Epoch: 137/300 - Train loss: 0.363200843334198, Validation loss: 0.3592456579208374
Epoch: 138/300 - Train loss: 0.36259034276008606, Validation loss: 0.35939815640449524
Epoch: 139/300 - Train loss: 0.36198970675468445, Validation loss: 0.3587980270385742
Epoch: 140/300 - Train loss: 0.3613991141319275, Validation loss: 0.35815468430519104
Epoch: 141/300 - Train loss: 0.36081770062446594, Validation loss: 0.3577703535556793
Epoch: 142/300 - Train loss: 0.36024466156959534, Validation loss: 0.35634419322013855
Epoch: 143/300 - Train loss: 0.3596791923046112, Validation loss: 0.35588616132736206
Epoch: 144/300 - Train loss: 0.359121710062027, Validation loss: 0.35567665100097656
Epoch: 145/300 - Train loss: 0.358571857213974, Validation loss: 0.3544074594974518
Epoch: 146/300 - Train loss: 0.3580295443534851, Validation loss: 0.35463204979896545
