Epoch: 1/300 - Train loss: 0.6894934177398682, Validation loss: 0.6856704354286194
Epoch: 2/300 - Train loss: 0.6857567429542542, Validation loss: 0.6819255948066711
Epoch: 3/300 - Train loss: 0.682073712348938, Validation loss: 0.6781662702560425
Epoch: 4/300 - Train loss: 0.6784222722053528, Validation loss: 0.6743690967559814
Epoch: 5/300 - Train loss: 0.6747860312461853, Validation loss: 0.6705614924430847
Epoch: 6/300 - Train loss: 0.6711540222167969, Validation loss: 0.6668956875801086
Epoch: 7/300 - Train loss: 0.6675000786781311, Validation loss: 0.6631128191947937
Epoch: 8/300 - Train loss: 0.6638063192367554, Validation loss: 0.6591783165931702
Epoch: 9/300 - Train loss: 0.6600489020347595, Validation loss: 0.6553249359130859
Epoch: 10/300 - Train loss: 0.6562073826789856, Validation loss: 0.6511478424072266
Epoch: 11/300 - Train loss: 0.6522696614265442, Validation loss: 0.6471514701843262
Epoch: 12/300 - Train loss: 0.648226797580719, Validation loss: 0.6429186463356018
Epoch: 13/300 - Train loss: 0.6440669894218445, Validation loss: 0.6383987069129944
Epoch: 14/300 - Train loss: 0.6397789120674133, Validation loss: 0.633795976638794
Epoch: 15/300 - Train loss: 0.6353576183319092, Validation loss: 0.629082202911377
Epoch: 16/300 - Train loss: 0.6308014392852783, Validation loss: 0.624299943447113
Epoch: 17/300 - Train loss: 0.6261078119277954, Validation loss: 0.6194026470184326
Epoch: 18/300 - Train loss: 0.6212760210037231, Validation loss: 0.6142202615737915
Epoch: 19/300 - Train loss: 0.6162976622581482, Validation loss: 0.6090742945671082
Epoch: 20/300 - Train loss: 0.6111743450164795, Validation loss: 0.6036834120750427
Epoch: 21/300 - Train loss: 0.6059091091156006, Validation loss: 0.598139226436615
Epoch: 22/300 - Train loss: 0.600504457950592, Validation loss: 0.5925966501235962
Epoch: 23/300 - Train loss: 0.5949601531028748, Validation loss: 0.5866454839706421
Epoch: 24/300 - Train loss: 0.5892864465713501, Validation loss: 0.5808975100517273
Epoch: 25/300 - Train loss: 0.5834863185882568, Validation loss: 0.5747582316398621
Epoch: 26/300 - Train loss: 0.5775656700134277, Validation loss: 0.5685967206954956
Epoch: 27/300 - Train loss: 0.5715256929397583, Validation loss: 0.5624608993530273
Epoch: 28/300 - Train loss: 0.5653746724128723, Validation loss: 0.5558889508247375
Epoch: 29/300 - Train loss: 0.5591205358505249, Validation loss: 0.5495638251304626
Epoch: 30/300 - Train loss: 0.5527803897857666, Validation loss: 0.5429162383079529
Epoch: 31/300 - Train loss: 0.5463647842407227, Validation loss: 0.536512553691864
Epoch: 32/300 - Train loss: 0.5398725867271423, Validation loss: 0.5295454263687134
Epoch: 33/300 - Train loss: 0.533314049243927, Validation loss: 0.5231709480285645
Epoch: 34/300 - Train loss: 0.5267001390457153, Validation loss: 0.5163495540618896
Epoch: 35/300 - Train loss: 0.5200374126434326, Validation loss: 0.509516179561615
Epoch: 36/300 - Train loss: 0.5133389234542847, Validation loss: 0.5028768181800842
Epoch: 37/300 - Train loss: 0.5066261887550354, Validation loss: 0.4963611662387848
Epoch: 38/300 - Train loss: 0.49991145730018616, Validation loss: 0.4891866147518158
Epoch: 39/300 - Train loss: 0.4932038486003876, Validation loss: 0.48301735520362854
Epoch: 40/300 - Train loss: 0.4865172505378723, Validation loss: 0.47589725255966187
Epoch: 41/300 - Train loss: 0.47985807061195374, Validation loss: 0.46932679414749146
Epoch: 42/300 - Train loss: 0.4732392728328705, Validation loss: 0.46264755725860596
Epoch: 43/300 - Train loss: 0.46666887402534485, Validation loss: 0.4559233784675598
Epoch: 44/300 - Train loss: 0.46015873551368713, Validation loss: 0.44950518012046814
Epoch: 45/300 - Train loss: 0.4537171423435211, Validation loss: 0.44312724471092224
Epoch: 46/300 - Train loss: 0.44734814763069153, Validation loss: 0.43688005208969116
Epoch: 47/300 - Train loss: 0.44106000661849976, Validation loss: 0.4305884838104248
Epoch: 48/300 - Train loss: 0.4348599910736084, Validation loss: 0.4247743487358093
Epoch: 49/300 - Train loss: 0.4287559688091278, Validation loss: 0.41849765181541443
Epoch: 50/300 - Train loss: 0.4227486252784729, Validation loss: 0.4123394191265106
Epoch: 51/300 - Train loss: 0.4168443977832794, Validation loss: 0.4069069027900696
Epoch: 52/300 - Train loss: 0.41104796528816223, Validation loss: 0.40110981464385986
Epoch: 53/300 - Train loss: 0.40536150336265564, Validation loss: 0.39556294679641724
Epoch: 54/300 - Train loss: 0.3997863829135895, Validation loss: 0.3900856673717499
Epoch: 55/300 - Train loss: 0.39432430267333984, Validation loss: 0.38468512892723083
Epoch: 56/300 - Train loss: 0.3889785706996918, Validation loss: 0.37936413288116455
Epoch: 57/300 - Train loss: 0.3837505578994751, Validation loss: 0.37395530939102173
Epoch: 58/300 - Train loss: 0.3786397874355316, Validation loss: 0.3691282570362091
Epoch: 59/300 - Train loss: 0.3736470639705658, Validation loss: 0.3640369176864624
Epoch: 60/300 - Train loss: 0.36877205967903137, Validation loss: 0.35961422324180603
Epoch: 61/300 - Train loss: 0.36401382088661194, Validation loss: 0.35468849539756775
Epoch: 62/300 - Train loss: 0.35937318205833435, Validation loss: 0.3504025638103485
Epoch: 63/300 - Train loss: 0.3548487722873688, Validation loss: 0.3457043170928955
Epoch: 64/300 - Train loss: 0.35043901205062866, Validation loss: 0.34157437086105347
Epoch: 65/300 - Train loss: 0.34614261984825134, Validation loss: 0.3375757932662964
Epoch: 66/300 - Train loss: 0.3419579565525055, Validation loss: 0.33314523100852966
Epoch: 67/300 - Train loss: 0.33788278698921204, Validation loss: 0.32942861318588257
Epoch: 68/300 - Train loss: 0.3339148163795471, Validation loss: 0.3259254992008209
Epoch: 69/300 - Train loss: 0.33005279302597046, Validation loss: 0.3219882547855377
Epoch: 70/300 - Train loss: 0.3262946903705597, Validation loss: 0.31821998953819275
Epoch: 71/300 - Train loss: 0.32263827323913574, Validation loss: 0.31463712453842163
Epoch: 72/300 - Train loss: 0.31908154487609863, Validation loss: 0.3112386167049408
Epoch: 73/300 - Train loss: 0.3156214952468872, Validation loss: 0.30769604444503784
Epoch: 74/300 - Train loss: 0.31225597858428955, Validation loss: 0.3044282793998718
Epoch: 75/300 - Train loss: 0.30898234248161316, Validation loss: 0.3021869659423828
Epoch: 76/300 - Train loss: 0.30579814314842224, Validation loss: 0.29798880219459534
Epoch: 77/300 - Train loss: 0.30270063877105713, Validation loss: 0.29524192214012146
Epoch: 78/300 - Train loss: 0.29968807101249695, Validation loss: 0.29209062457084656
Epoch: 79/300 - Train loss: 0.2967582941055298, Validation loss: 0.2896415889263153
Epoch: 80/300 - Train loss: 0.2939089238643646, Validation loss: 0.28660961985588074
Epoch: 81/300 - Train loss: 0.29113760590553284, Validation loss: 0.28419631719589233
Epoch: 82/300 - Train loss: 0.28844207525253296, Validation loss: 0.28168240189552307
Epoch: 83/300 - Train loss: 0.28582048416137695, Validation loss: 0.27887240052223206
Epoch: 84/300 - Train loss: 0.28327053785324097, Validation loss: 0.27647891640663147
Epoch: 85/300 - Train loss: 0.2807897925376892, Validation loss: 0.27421343326568604
Epoch: 86/300 - Train loss: 0.27837568521499634, Validation loss: 0.2716917097568512
Epoch: 87/300 - Train loss: 0.2760263681411743, Validation loss: 0.2699176073074341
Epoch: 88/300 - Train loss: 0.2737402319908142, Validation loss: 0.267383337020874
Epoch: 89/300 - Train loss: 0.2715151309967041, Validation loss: 0.265444278717041
Epoch: 90/300 - Train loss: 0.26934945583343506, Validation loss: 0.26336729526519775
Epoch: 91/300 - Train loss: 0.26724135875701904, Validation loss: 0.2613351047039032
Epoch: 92/300 - Train loss: 0.26518893241882324, Validation loss: 0.259037047624588
Epoch: 93/300 - Train loss: 0.26319047808647156, Validation loss: 0.25709766149520874
Epoch: 94/300 - Train loss: 0.26124441623687744, Validation loss: 0.2555736303329468
Epoch: 95/300 - Train loss: 0.25934913754463196, Validation loss: 0.25360360741615295
Epoch: 96/300 - Train loss: 0.2575033903121948, Validation loss: 0.25160694122314453
Epoch: 97/300 - Train loss: 0.2557057738304138, Validation loss: 0.24986425042152405
Epoch: 98/300 - Train loss: 0.25395455956459045, Validation loss: 0.24819830060005188
Epoch: 99/300 - Train loss: 0.25224801898002625, Validation loss: 0.24681773781776428
Epoch: 100/300 - Train loss: 0.25058513879776, Validation loss: 0.24488750100135803
Epoch: 101/300 - Train loss: 0.24896471202373505, Validation loss: 0.24383628368377686
Epoch: 102/300 - Train loss: 0.24738503992557526, Validation loss: 0.24216347932815552
Epoch: 103/300 - Train loss: 0.2458452582359314, Validation loss: 0.24076274037361145
Epoch: 104/300 - Train loss: 0.24434436857700348, Validation loss: 0.23919208347797394
Epoch: 105/300 - Train loss: 0.24288111925125122, Validation loss: 0.23740267753601074
Epoch: 106/300 - Train loss: 0.24145454168319702, Validation loss: 0.23639614880084991
Epoch: 107/300 - Train loss: 0.24006357789039612, Validation loss: 0.23493175208568573
Epoch: 108/300 - Train loss: 0.23870700597763062, Validation loss: 0.2340102195739746
Epoch: 109/300 - Train loss: 0.2373838871717453, Validation loss: 0.2322857677936554
Epoch: 110/300 - Train loss: 0.23609334230422974, Validation loss: 0.23158679902553558
Epoch: 111/300 - Train loss: 0.23483425378799438, Validation loss: 0.23100592195987701
Epoch: 112/300 - Train loss: 0.23360575735569, Validation loss: 0.22906343638896942
Epoch: 113/300 - Train loss: 0.23240704834461212, Validation loss: 0.22784218192100525
Epoch: 114/300 - Train loss: 0.2312372624874115, Validation loss: 0.22627469897270203
Epoch: 115/300 - Train loss: 0.23009559512138367, Validation loss: 0.22563724219799042
Epoch: 116/300 - Train loss: 0.22898118197917938, Validation loss: 0.22440697252750397
Epoch: 117/300 - Train loss: 0.22789323329925537, Validation loss: 0.22360993921756744
Epoch: 118/300 - Train loss: 0.22683091461658478, Validation loss: 0.22266967594623566
Epoch: 119/300 - Train loss: 0.2257935255765915, Validation loss: 0.22174842655658722
Epoch: 120/300 - Train loss: 0.2247803956270218, Validation loss: 0.22089357674121857
Epoch: 121/300 - Train loss: 0.22379085421562195, Validation loss: 0.21993888914585114
Epoch: 122/300 - Train loss: 0.22282415628433228, Validation loss: 0.21867196261882782
Epoch: 123/300 - Train loss: 0.2218797355890274, Validation loss: 0.21839462220668793
Epoch: 124/300 - Train loss: 0.2209569364786148, Validation loss: 0.21689563989639282
Epoch: 125/300 - Train loss: 0.22005513310432434, Validation loss: 0.21616888046264648
Epoch: 126/300 - Train loss: 0.21917374432086945, Validation loss: 0.21518710255622864
Epoch: 127/300 - Train loss: 0.21831217408180237, Validation loss: 0.21502386033535004
Epoch: 128/300 - Train loss: 0.2174699306488037, Validation loss: 0.21398285031318665
Epoch: 129/300 - Train loss: 0.21664650738239288, Validation loss: 0.21343077719211578
Epoch: 130/300 - Train loss: 0.21584120392799377, Validation loss: 0.21207110583782196
Epoch: 131/300 - Train loss: 0.21505354344844818, Validation loss: 0.21131259202957153
Epoch: 132/300 - Train loss: 0.21428310871124268, Validation loss: 0.21121352910995483
Epoch: 133/300 - Train loss: 0.21352943778038025, Validation loss: 0.20965158939361572
Epoch: 134/300 - Train loss: 0.2127920538187027, Validation loss: 0.20927929878234863
Epoch: 135/300 - Train loss: 0.212070494890213, Validation loss: 0.2089298665523529
Epoch: 136/300 - Train loss: 0.21136434376239777, Validation loss: 0.20821651816368103
Epoch: 137/300 - Train loss: 0.21067316830158234, Validation loss: 0.20747891068458557
Epoch: 138/300 - Train loss: 0.20999661087989807, Validation loss: 0.20692241191864014
Epoch: 139/300 - Train loss: 0.20933423936367035, Validation loss: 0.20628534257411957
Epoch: 140/300 - Train loss: 0.2086857110261917, Validation loss: 0.20534773170948029
Epoch: 141/300 - Train loss: 0.20805063843727112, Validation loss: 0.20482604205608368
Epoch: 142/300 - Train loss: 0.20742864906787872, Validation loss: 0.20447713136672974
Epoch: 143/300 - Train loss: 0.2068195343017578, Validation loss: 0.20383939146995544
Epoch: 144/300 - Train loss: 0.20622293651103973, Validation loss: 0.2032473087310791
Epoch: 145/300 - Train loss: 0.20563848316669464, Validation loss: 0.2033822387456894
