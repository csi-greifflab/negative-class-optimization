Epoch: 1/300 - Train loss: 0.6942017078399658, Validation loss: 0.6922659873962402
Epoch: 2/300 - Train loss: 0.6921263933181763, Validation loss: 0.6902154088020325
Epoch: 3/300 - Train loss: 0.6900454759597778, Validation loss: 0.6880754828453064
Epoch: 4/300 - Train loss: 0.6879631280899048, Validation loss: 0.6861781477928162
Epoch: 5/300 - Train loss: 0.685870349407196, Validation loss: 0.6840197443962097
Epoch: 6/300 - Train loss: 0.6837618947029114, Validation loss: 0.6819155812263489
Epoch: 7/300 - Train loss: 0.6816260814666748, Validation loss: 0.6797589659690857
Epoch: 8/300 - Train loss: 0.6794577240943909, Validation loss: 0.6775449514389038
Epoch: 9/300 - Train loss: 0.6772481799125671, Validation loss: 0.6753197312355042
Epoch: 10/300 - Train loss: 0.6749945282936096, Validation loss: 0.6730165481567383
Epoch: 11/300 - Train loss: 0.6726900935173035, Validation loss: 0.6706269979476929
Epoch: 12/300 - Train loss: 0.6703268885612488, Validation loss: 0.6683990359306335
Epoch: 13/300 - Train loss: 0.6679039001464844, Validation loss: 0.6658557653427124
Epoch: 14/300 - Train loss: 0.6654155254364014, Validation loss: 0.6633638143539429
Epoch: 15/300 - Train loss: 0.6628587245941162, Validation loss: 0.6606134176254272
Epoch: 16/300 - Train loss: 0.6602280139923096, Validation loss: 0.6581732034683228
Epoch: 17/300 - Train loss: 0.6575202941894531, Validation loss: 0.6553100943565369
Epoch: 18/300 - Train loss: 0.654736340045929, Validation loss: 0.6524822115898132
Epoch: 19/300 - Train loss: 0.651875913143158, Validation loss: 0.6495717763900757
Epoch: 20/300 - Train loss: 0.6489369869232178, Validation loss: 0.6466094851493835
Epoch: 21/300 - Train loss: 0.6459159851074219, Validation loss: 0.6437103152275085
Epoch: 22/300 - Train loss: 0.6428171992301941, Validation loss: 0.6404797434806824
Epoch: 23/300 - Train loss: 0.6396365761756897, Validation loss: 0.6373576521873474
Epoch: 24/300 - Train loss: 0.6363739371299744, Validation loss: 0.6340917944908142
Epoch: 25/300 - Train loss: 0.6330288052558899, Validation loss: 0.6307209134101868
Epoch: 26/300 - Train loss: 0.6296013593673706, Validation loss: 0.6271134614944458
Epoch: 27/300 - Train loss: 0.6260927319526672, Validation loss: 0.6236893534660339
Epoch: 28/300 - Train loss: 0.62250155210495, Validation loss: 0.6199631690979004
Epoch: 29/300 - Train loss: 0.6188321113586426, Validation loss: 0.6164043545722961
Epoch: 30/300 - Train loss: 0.6150834560394287, Validation loss: 0.6126933097839355
Epoch: 31/300 - Train loss: 0.611257016658783, Validation loss: 0.6088173985481262
Epoch: 32/300 - Train loss: 0.607354462146759, Validation loss: 0.6050443649291992
Epoch: 33/300 - Train loss: 0.6033782958984375, Validation loss: 0.6008723974227905
Epoch: 34/300 - Train loss: 0.5993340015411377, Validation loss: 0.5968314409255981
Epoch: 35/300 - Train loss: 0.5952230095863342, Validation loss: 0.5927488803863525
Epoch: 36/300 - Train loss: 0.5910513401031494, Validation loss: 0.588577151298523
Epoch: 37/300 - Train loss: 0.5868223309516907, Validation loss: 0.5842655301094055
Epoch: 38/300 - Train loss: 0.5825400948524475, Validation loss: 0.5800763368606567
Epoch: 39/300 - Train loss: 0.5782120823860168, Validation loss: 0.575764000415802
Epoch: 40/300 - Train loss: 0.5738472938537598, Validation loss: 0.5712651610374451
Epoch: 41/300 - Train loss: 0.5694484710693359, Validation loss: 0.567073404788971
Epoch: 42/300 - Train loss: 0.5650261044502258, Validation loss: 0.5626087188720703
Epoch: 43/300 - Train loss: 0.5605869293212891, Validation loss: 0.5580481290817261
Epoch: 44/300 - Train loss: 0.5561365485191345, Validation loss: 0.5538995862007141
Epoch: 45/300 - Train loss: 0.5516793131828308, Validation loss: 0.5492398142814636
Epoch: 46/300 - Train loss: 0.5472255945205688, Validation loss: 0.5448379516601562
Epoch: 47/300 - Train loss: 0.5427860021591187, Validation loss: 0.5400331616401672
Epoch: 48/300 - Train loss: 0.5383619070053101, Validation loss: 0.5358904004096985
Epoch: 49/300 - Train loss: 0.5339616537094116, Validation loss: 0.5314731001853943
Epoch: 50/300 - Train loss: 0.529589831829071, Validation loss: 0.5268663763999939
Epoch: 51/300 - Train loss: 0.5252489447593689, Validation loss: 0.5227411985397339
Epoch: 52/300 - Train loss: 0.5209441184997559, Validation loss: 0.5183131694793701
Epoch: 53/300 - Train loss: 0.5166757106781006, Validation loss: 0.5141331553459167
Epoch: 54/300 - Train loss: 0.5124465227127075, Validation loss: 0.5097774863243103
Epoch: 55/300 - Train loss: 0.5082612633705139, Validation loss: 0.5055096745491028
Epoch: 56/300 - Train loss: 0.5041218400001526, Validation loss: 0.5013667345046997
Epoch: 57/300 - Train loss: 0.5000299215316772, Validation loss: 0.4973966181278229
Epoch: 58/300 - Train loss: 0.49598971009254456, Validation loss: 0.4935264587402344
Epoch: 59/300 - Train loss: 0.4920026361942291, Validation loss: 0.48963695764541626
Epoch: 60/300 - Train loss: 0.48807060718536377, Validation loss: 0.4856160581111908
Epoch: 61/300 - Train loss: 0.48419469594955444, Validation loss: 0.4817226231098175
Epoch: 62/300 - Train loss: 0.4803760051727295, Validation loss: 0.4779081344604492
Epoch: 63/300 - Train loss: 0.47661617398262024, Validation loss: 0.4740566909313202
Epoch: 64/300 - Train loss: 0.4729160964488983, Validation loss: 0.47042226791381836
Epoch: 65/300 - Train loss: 0.4692763090133667, Validation loss: 0.46665018796920776
Epoch: 66/300 - Train loss: 0.4656980037689209, Validation loss: 0.46291714906692505
Epoch: 67/300 - Train loss: 0.4621809124946594, Validation loss: 0.45953404903411865
Epoch: 68/300 - Train loss: 0.4587259292602539, Validation loss: 0.4563133418560028
Epoch: 69/300 - Train loss: 0.4553321301937103, Validation loss: 0.4527064561843872
Epoch: 70/300 - Train loss: 0.4519995152950287, Validation loss: 0.44943636655807495
Epoch: 71/300 - Train loss: 0.44872793555259705, Validation loss: 0.44662636518478394
Epoch: 72/300 - Train loss: 0.445517361164093, Validation loss: 0.4430922567844391
Epoch: 73/300 - Train loss: 0.4423676133155823, Validation loss: 0.4398283064365387
Epoch: 74/300 - Train loss: 0.4392787218093872, Validation loss: 0.43658730387687683
Epoch: 75/300 - Train loss: 0.43625009059906006, Validation loss: 0.433649480342865
Epoch: 76/300 - Train loss: 0.433280885219574, Validation loss: 0.4303661286830902
Epoch: 77/300 - Train loss: 0.4303707480430603, Validation loss: 0.4279106855392456
Epoch: 78/300 - Train loss: 0.427519291639328, Validation loss: 0.42557382583618164
Epoch: 79/300 - Train loss: 0.4247263967990875, Validation loss: 0.4223001301288605
Epoch: 80/300 - Train loss: 0.4219909608364105, Validation loss: 0.41957566142082214
Epoch: 81/300 - Train loss: 0.4193118214607239, Validation loss: 0.41684871912002563
Epoch: 82/300 - Train loss: 0.41668814420700073, Validation loss: 0.4136979877948761
Epoch: 83/300 - Train loss: 0.41411927342414856, Validation loss: 0.41146042943000793
Epoch: 84/300 - Train loss: 0.41160401701927185, Validation loss: 0.4093281328678131
Epoch: 85/300 - Train loss: 0.4091417193412781, Validation loss: 0.407064825296402
Epoch: 86/300 - Train loss: 0.4067314565181732, Validation loss: 0.4038959741592407
Epoch: 87/300 - Train loss: 0.40437212586402893, Validation loss: 0.40168777108192444
Epoch: 88/300 - Train loss: 0.4020632803440094, Validation loss: 0.39918121695518494
Epoch: 89/300 - Train loss: 0.39980360865592957, Validation loss: 0.39703577756881714
Epoch: 90/300 - Train loss: 0.3975917100906372, Validation loss: 0.39496180415153503
Epoch: 91/300 - Train loss: 0.3954264223575592, Validation loss: 0.3925141394138336
Epoch: 92/300 - Train loss: 0.393306165933609, Validation loss: 0.39067450165748596
Epoch: 93/300 - Train loss: 0.39123040437698364, Validation loss: 0.38852936029434204
Epoch: 94/300 - Train loss: 0.3891983926296234, Validation loss: 0.38658544421195984
Epoch: 95/300 - Train loss: 0.38720962405204773, Validation loss: 0.3843120336532593
Epoch: 96/300 - Train loss: 0.385262131690979, Validation loss: 0.3826811611652374
Epoch: 97/300 - Train loss: 0.383355051279068, Validation loss: 0.380840539932251
Epoch: 98/300 - Train loss: 0.38148730993270874, Validation loss: 0.3788495659828186
Epoch: 99/300 - Train loss: 0.3796580135822296, Validation loss: 0.37677133083343506
Epoch: 100/300 - Train loss: 0.37786662578582764, Validation loss: 0.37485551834106445
Epoch: 101/300 - Train loss: 0.3761119544506073, Validation loss: 0.3738628625869751
Epoch: 102/300 - Train loss: 0.3743933439254761, Validation loss: 0.3715125322341919
Epoch: 103/300 - Train loss: 0.3727101683616638, Validation loss: 0.37005695700645447
Epoch: 104/300 - Train loss: 0.37106120586395264, Validation loss: 0.36866459250450134
Epoch: 105/300 - Train loss: 0.36944451928138733, Validation loss: 0.36684563755989075
Epoch: 106/300 - Train loss: 0.3678589165210724, Validation loss: 0.36536505818367004
Epoch: 107/300 - Train loss: 0.3663040101528168, Validation loss: 0.3634457588195801
Epoch: 108/300 - Train loss: 0.36477887630462646, Validation loss: 0.3617554008960724
Epoch: 109/300 - Train loss: 0.3632824420928955, Validation loss: 0.3601677715778351
Epoch: 110/300 - Train loss: 0.36181458830833435, Validation loss: 0.3590604364871979
Epoch: 111/300 - Train loss: 0.36037468910217285, Validation loss: 0.3578725755214691
Epoch: 112/300 - Train loss: 0.35896164178848267, Validation loss: 0.35612720251083374
Epoch: 113/300 - Train loss: 0.35757482051849365, Validation loss: 0.3545951545238495
Epoch: 114/300 - Train loss: 0.3562130331993103, Validation loss: 0.35307639837265015
Epoch: 115/300 - Train loss: 0.35487625002861023, Validation loss: 0.3517668843269348
Epoch: 116/300 - Train loss: 0.3535630404949188, Validation loss: 0.3510592579841614
Epoch: 117/300 - Train loss: 0.3522731363773346, Validation loss: 0.34927672147750854
Epoch: 118/300 - Train loss: 0.3510063886642456, Validation loss: 0.34767550230026245
Epoch: 119/300 - Train loss: 0.3497615456581116, Validation loss: 0.3471446633338928
Epoch: 120/300 - Train loss: 0.3485373854637146, Validation loss: 0.34533923864364624
Epoch: 121/300 - Train loss: 0.3473331034183502, Validation loss: 0.3452701270580292
Epoch: 122/300 - Train loss: 0.34614890813827515, Validation loss: 0.3433224558830261
Epoch: 123/300 - Train loss: 0.34498482942581177, Validation loss: 0.34187206625938416
Epoch: 124/300 - Train loss: 0.34383976459503174, Validation loss: 0.34031641483306885
Epoch: 125/300 - Train loss: 0.34271231293678284, Validation loss: 0.3403940796852112
Epoch: 126/300 - Train loss: 0.34160253405570984, Validation loss: 0.3385724127292633
Epoch: 127/300 - Train loss: 0.34050965309143066, Validation loss: 0.33751383423805237
Epoch: 128/300 - Train loss: 0.3394334316253662, Validation loss: 0.33672595024108887
Epoch: 129/300 - Train loss: 0.338375061750412, Validation loss: 0.3353767991065979
Epoch: 130/300 - Train loss: 0.3373328447341919, Validation loss: 0.33432093262672424
Epoch: 131/300 - Train loss: 0.3363070487976074, Validation loss: 0.3331258296966553
Epoch: 132/300 - Train loss: 0.3352958858013153, Validation loss: 0.33274075388908386
Epoch: 133/300 - Train loss: 0.3343002498149872, Validation loss: 0.3314991891384125
Epoch: 134/300 - Train loss: 0.3333193361759186, Validation loss: 0.33090075850486755
Epoch: 135/300 - Train loss: 0.33235278725624084, Validation loss: 0.32971179485321045
Epoch: 136/300 - Train loss: 0.33139997720718384, Validation loss: 0.3286953568458557
Epoch: 137/300 - Train loss: 0.33046120405197144, Validation loss: 0.3279556930065155
Epoch: 138/300 - Train loss: 0.32953688502311707, Validation loss: 0.3271832764148712
Epoch: 139/300 - Train loss: 0.32862651348114014, Validation loss: 0.3261171579360962
Epoch: 140/300 - Train loss: 0.3277287185192108, Validation loss: 0.32511401176452637
Epoch: 141/300 - Train loss: 0.32684382796287537, Validation loss: 0.3240608274936676
Epoch: 142/300 - Train loss: 0.3259718418121338, Validation loss: 0.32387182116508484
Epoch: 143/300 - Train loss: 0.3251134157180786, Validation loss: 0.3227209746837616
Epoch: 144/300 - Train loss: 0.3242673873901367, Validation loss: 0.3217838406562805
Epoch: 145/300 - Train loss: 0.32343387603759766, Validation loss: 0.3211652636528015
Epoch: 146/300 - Train loss: 0.3226129114627838, Validation loss: 0.3195912837982178
Epoch: 147/300 - Train loss: 0.32180362939834595, Validation loss: 0.319295734167099
Epoch: 148/300 - Train loss: 0.32100582122802734, Validation loss: 0.31842556595802307
Epoch: 149/300 - Train loss: 0.32021939754486084, Validation loss: 0.3176054358482361
Epoch: 150/300 - Train loss: 0.31944364309310913, Validation loss: 0.31723877787590027
Epoch: 151/300 - Train loss: 0.3186784088611603, Validation loss: 0.3167332112789154
Epoch: 152/300 - Train loss: 0.31792303919792175, Validation loss: 0.31601229310035706
Epoch: 153/300 - Train loss: 0.3171776533126831, Validation loss: 0.3148898184299469
Epoch: 154/300 - Train loss: 0.31644174456596375, Validation loss: 0.3141748011112213
Epoch: 155/300 - Train loss: 0.3157157599925995, Validation loss: 0.3135506212711334
Epoch: 156/300 - Train loss: 0.3150002360343933, Validation loss: 0.31308284401893616
Epoch: 157/300 - Train loss: 0.3142945468425751, Validation loss: 0.3124232888221741
Epoch: 158/300 - Train loss: 0.3135979473590851, Validation loss: 0.31166866421699524
Epoch: 159/300 - Train loss: 0.31291067600250244, Validation loss: 0.31095242500305176
Epoch: 160/300 - Train loss: 0.3122324049472809, Validation loss: 0.3098762631416321
Epoch: 161/300 - Train loss: 0.3115624487400055, Validation loss: 0.3097960650920868
Epoch: 162/300 - Train loss: 0.31090056896209717, Validation loss: 0.3092800974845886
Epoch: 163/300 - Train loss: 0.31024688482284546, Validation loss: 0.30813679099082947
Epoch: 164/300 - Train loss: 0.3096012771129608, Validation loss: 0.3072799742221832
Epoch: 165/300 - Train loss: 0.3089632987976074, Validation loss: 0.30727890133857727
Epoch: 166/300 - Train loss: 0.30833256244659424, Validation loss: 0.30630016326904297
Epoch: 167/300 - Train loss: 0.3077091872692108, Validation loss: 0.30577269196510315
Epoch: 168/300 - Train loss: 0.3070932924747467, Validation loss: 0.305978387594223
Epoch: 169/300 - Train loss: 0.3064843714237213, Validation loss: 0.305112361907959
