Epoch: 1/200 - Train loss: 0.6257327795028687, Validation loss: 0.5511689782142639
Epoch: 2/200 - Train loss: 0.502532422542572, Validation loss: 0.4659084379673004
Epoch: 3/200 - Train loss: 0.4302690029144287, Validation loss: 0.4094619154930115
Epoch: 4/200 - Train loss: 0.3801005482673645, Validation loss: 0.37158915400505066
Epoch: 5/200 - Train loss: 0.3456028699874878, Validation loss: 0.346858948469162
Epoch: 6/200 - Train loss: 0.3181227445602417, Validation loss: 0.32278069853782654
Epoch: 7/200 - Train loss: 0.29425835609436035, Validation loss: 0.3035835325717926
Epoch: 8/200 - Train loss: 0.2754058241844177, Validation loss: 0.28769636154174805
Epoch: 9/200 - Train loss: 0.25964823365211487, Validation loss: 0.2754400372505188
Epoch: 10/200 - Train loss: 0.24700234830379486, Validation loss: 0.26624295115470886
Epoch: 11/200 - Train loss: 0.236114501953125, Validation loss: 0.25965023040771484
Epoch: 12/200 - Train loss: 0.22737888991832733, Validation loss: 0.25552642345428467
Epoch: 13/200 - Train loss: 0.21922336518764496, Validation loss: 0.24687065184116364
Epoch: 14/200 - Train loss: 0.2135094702243805, Validation loss: 0.2491866946220398
Epoch: 15/200 - Train loss: 0.20791876316070557, Validation loss: 0.23981395363807678
Epoch: 16/200 - Train loss: 0.20149995386600494, Validation loss: 0.23883932828903198
Epoch: 17/200 - Train loss: 0.1977171003818512, Validation loss: 0.23394545912742615
Epoch: 18/200 - Train loss: 0.19359347224235535, Validation loss: 0.23221828043460846
Epoch: 19/200 - Train loss: 0.19021300971508026, Validation loss: 0.2302393913269043
Epoch: 20/200 - Train loss: 0.18618066608905792, Validation loss: 0.22875016927719116
Epoch: 21/200 - Train loss: 0.18396703898906708, Validation loss: 0.22443394362926483
Epoch: 22/200 - Train loss: 0.18009138107299805, Validation loss: 0.22242975234985352
Epoch: 23/200 - Train loss: 0.17778466641902924, Validation loss: 0.22413071990013123
Epoch: 24/200 - Train loss: 0.1756342202425003, Validation loss: 0.21996115148067474
Epoch: 25/200 - Train loss: 0.1729135811328888, Validation loss: 0.2199336290359497
Epoch: 26/200 - Train loss: 0.1709427535533905, Validation loss: 0.22238002717494965
Epoch: 27/200 - Train loss: 0.16844817996025085, Validation loss: 0.2202042192220688
Epoch: 28/200 - Train loss: 0.16671302914619446, Validation loss: 0.21876242756843567
Epoch: 29/200 - Train loss: 0.16495466232299805, Validation loss: 0.22198064625263214
Epoch: 30/200 - Train loss: 0.1630467027425766, Validation loss: 0.21803216636180878
Epoch: 31/200 - Train loss: 0.16184455156326294, Validation loss: 0.21720802783966064
Epoch: 32/200 - Train loss: 0.1612214297056198, Validation loss: 0.21709229052066803
Epoch: 33/200 - Train loss: 0.1588393747806549, Validation loss: 0.2183907926082611
Epoch: 34/200 - Train loss: 0.1573314517736435, Validation loss: 0.2192627191543579
Epoch: 35/200 - Train loss: 0.15582667291164398, Validation loss: 0.2156483232975006
Epoch: 36/200 - Train loss: 0.15488670766353607, Validation loss: 0.21650609374046326
Epoch: 37/200 - Train loss: 0.15367722511291504, Validation loss: 0.21567538380622864
Epoch: 38/200 - Train loss: 0.15303583443164825, Validation loss: 0.22028754651546478
Epoch: 39/200 - Train loss: 0.15218420326709747, Validation loss: 0.22148321568965912
Epoch: 40/200 - Train loss: 0.1509159952402115, Validation loss: 0.21759851276874542
Epoch: 41/200 - Train loss: 0.14959996938705444, Validation loss: 0.21337035298347473
Epoch: 42/200 - Train loss: 0.1491103321313858, Validation loss: 0.21752843260765076
Epoch: 43/200 - Train loss: 0.14829984307289124, Validation loss: 0.2137972116470337
Epoch: 44/200 - Train loss: 0.14643102884292603, Validation loss: 0.21743746101856232
Epoch: 45/200 - Train loss: 0.14614823460578918, Validation loss: 0.21459423005580902
Epoch: 46/200 - Train loss: 0.14478856325149536, Validation loss: 0.21973590552806854
Epoch: 47/200 - Train loss: 0.1443052440881729, Validation loss: 0.21316079795360565
Epoch: 48/200 - Train loss: 0.14350831508636475, Validation loss: 0.21910978853702545
Epoch: 49/200 - Train loss: 0.14281530678272247, Validation loss: 0.2153671383857727
Epoch: 50/200 - Train loss: 0.1416429728269577, Validation loss: 0.21522192656993866
Epoch: 51/200 - Train loss: 0.1421215832233429, Validation loss: 0.2172088772058487
Epoch: 52/200 - Train loss: 0.13967837393283844, Validation loss: 0.21756859123706818
Epoch: 53/200 - Train loss: 0.13920867443084717, Validation loss: 0.2137792408466339
Epoch: 54/200 - Train loss: 0.13867850601673126, Validation loss: 0.21604973077774048
Epoch: 55/200 - Train loss: 0.1385313868522644, Validation loss: 0.21999534964561462
Epoch: 56/200 - Train loss: 0.1376664936542511, Validation loss: 0.222187340259552
Epoch: 57/200 - Train loss: 0.13768133521080017, Validation loss: 0.2152881771326065
Epoch: 58/200 - Train loss: 0.13623923063278198, Validation loss: 0.21779876947402954
Epoch: 59/200 - Train loss: 0.13560134172439575, Validation loss: 0.2182813435792923
Epoch: 60/200 - Train loss: 0.13450390100479126, Validation loss: 0.21584105491638184
Epoch: 61/200 - Train loss: 0.1330605298280716, Validation loss: 0.21807760000228882
Epoch: 62/200 - Train loss: 0.1338975727558136, Validation loss: 0.21732854843139648
Epoch: 63/200 - Train loss: 0.13283976912498474, Validation loss: 0.21953795850276947
Epoch: 64/200 - Train loss: 0.1320706605911255, Validation loss: 0.21947358548641205
Epoch: 65/200 - Train loss: 0.132645845413208, Validation loss: 0.2167550027370453
Epoch: 66/200 - Train loss: 0.13111478090286255, Validation loss: 0.2250204235315323
Epoch: 67/200 - Train loss: 0.13123787939548492, Validation loss: 0.2158852368593216
Epoch: 68/200 - Train loss: 0.13067224621772766, Validation loss: 0.21654370427131653
Epoch: 69/200 - Train loss: 0.1299542486667633, Validation loss: 0.22454094886779785
Epoch: 70/200 - Train loss: 0.12994931638240814, Validation loss: 0.21858638525009155
Epoch: 71/200 - Train loss: 0.12850138545036316, Validation loss: 0.21685250103473663
Epoch: 72/200 - Train loss: 0.12924157083034515, Validation loss: 0.22531461715698242
Epoch: 73/200 - Train loss: 0.12951381504535675, Validation loss: 0.2224775105714798
Epoch: 74/200 - Train loss: 0.12783735990524292, Validation loss: 0.2198958694934845
Epoch: 75/200 - Train loss: 0.12827236950397491, Validation loss: 0.22073180973529816
Epoch: 76/200 - Train loss: 0.12768638134002686, Validation loss: 0.22024625539779663
Epoch: 77/200 - Train loss: 0.12726637721061707, Validation loss: 0.22335712611675262
Epoch: 78/200 - Train loss: 0.12670159339904785, Validation loss: 0.22164808213710785
Epoch: 79/200 - Train loss: 0.12675273418426514, Validation loss: 0.22374339401721954
Epoch: 80/200 - Train loss: 0.12614981830120087, Validation loss: 0.22135233879089355
Epoch: 81/200 - Train loss: 0.12609641253948212, Validation loss: 0.22912153601646423
Epoch: 82/200 - Train loss: 0.12501458823680878, Validation loss: 0.22355078160762787
Epoch: 83/200 - Train loss: 0.12511296570301056, Validation loss: 0.22199295461177826
Epoch: 84/200 - Train loss: 0.12495655566453934, Validation loss: 0.223328098654747
Epoch: 85/200 - Train loss: 0.12479106336832047, Validation loss: 0.22743059694766998
Epoch: 86/200 - Train loss: 0.1242348700761795, Validation loss: 0.22441338002681732
Epoch: 87/200 - Train loss: 0.1238376796245575, Validation loss: 0.22589164972305298
Epoch: 88/200 - Train loss: 0.12392700463533401, Validation loss: 0.2241625040769577
Epoch: 89/200 - Train loss: 0.1231129989027977, Validation loss: 0.22448527812957764
Epoch: 90/200 - Train loss: 0.12268103659152985, Validation loss: 0.22684089839458466
Epoch: 91/200 - Train loss: 0.12250754982233047, Validation loss: 0.22530604898929596
Epoch: 92/200 - Train loss: 0.12193076312541962, Validation loss: 0.22519324719905853
Epoch: 93/200 - Train loss: 0.12328758835792542, Validation loss: 0.22359052300453186
