Epoch: 1/300 - Train loss: 0.6956310868263245, Validation loss: 0.6911213397979736
Epoch: 2/300 - Train loss: 0.6926528215408325, Validation loss: 0.6882500648498535
Epoch: 3/300 - Train loss: 0.6897742748260498, Validation loss: 0.6858868598937988
Epoch: 4/300 - Train loss: 0.6869672536849976, Validation loss: 0.6830107569694519
Epoch: 5/300 - Train loss: 0.6842042207717896, Validation loss: 0.6802586317062378
Epoch: 6/300 - Train loss: 0.6814582347869873, Validation loss: 0.6775648593902588
Epoch: 7/300 - Train loss: 0.6786933541297913, Validation loss: 0.6748256683349609
Epoch: 8/300 - Train loss: 0.6758754253387451, Validation loss: 0.6719746589660645
Epoch: 9/300 - Train loss: 0.6729781031608582, Validation loss: 0.6690778732299805
Epoch: 10/300 - Train loss: 0.6699865460395813, Validation loss: 0.6660743951797485
Epoch: 11/300 - Train loss: 0.6668915748596191, Validation loss: 0.6628567576408386
Epoch: 12/300 - Train loss: 0.6636777520179749, Validation loss: 0.6594047546386719
Epoch: 13/300 - Train loss: 0.6603461503982544, Validation loss: 0.6562400460243225
Epoch: 14/300 - Train loss: 0.6569011211395264, Validation loss: 0.6528358459472656
Epoch: 15/300 - Train loss: 0.6533430814743042, Validation loss: 0.6490228772163391
Epoch: 16/300 - Train loss: 0.6496843695640564, Validation loss: 0.6455679535865784
Epoch: 17/300 - Train loss: 0.6459358334541321, Validation loss: 0.6416452527046204
Epoch: 18/300 - Train loss: 0.6421023607254028, Validation loss: 0.6377832889556885
Epoch: 19/300 - Train loss: 0.6381880044937134, Validation loss: 0.633704423904419
Epoch: 20/300 - Train loss: 0.6342045068740845, Validation loss: 0.6299440860748291
Epoch: 21/300 - Train loss: 0.6301749348640442, Validation loss: 0.6255961656570435
Epoch: 22/300 - Train loss: 0.6261072754859924, Validation loss: 0.62160724401474
Epoch: 23/300 - Train loss: 0.622016191482544, Validation loss: 0.6174735426902771
Epoch: 24/300 - Train loss: 0.6179158091545105, Validation loss: 0.6134893894195557
Epoch: 25/300 - Train loss: 0.6138173937797546, Validation loss: 0.609562337398529
Epoch: 26/300 - Train loss: 0.6097349524497986, Validation loss: 0.605289876461029
Epoch: 27/300 - Train loss: 0.6056761741638184, Validation loss: 0.601309061050415
Epoch: 28/300 - Train loss: 0.601648211479187, Validation loss: 0.5975285172462463
Epoch: 29/300 - Train loss: 0.5976522564888, Validation loss: 0.5934728384017944
Epoch: 30/300 - Train loss: 0.5936919450759888, Validation loss: 0.5893657803535461
Epoch: 31/300 - Train loss: 0.5897670984268188, Validation loss: 0.5856116414070129
Epoch: 32/300 - Train loss: 0.5858782529830933, Validation loss: 0.5814005732536316
Epoch: 33/300 - Train loss: 0.5820265412330627, Validation loss: 0.5781382322311401
Epoch: 34/300 - Train loss: 0.5782144069671631, Validation loss: 0.5743944048881531
Epoch: 35/300 - Train loss: 0.5744444727897644, Validation loss: 0.5699650645256042
Epoch: 36/300 - Train loss: 0.570716381072998, Validation loss: 0.5669584274291992
Epoch: 37/300 - Train loss: 0.5670325756072998, Validation loss: 0.5634527802467346
Epoch: 38/300 - Train loss: 0.5633949041366577, Validation loss: 0.5594702363014221
Epoch: 39/300 - Train loss: 0.5598049759864807, Validation loss: 0.5558165311813354
Epoch: 40/300 - Train loss: 0.5562647581100464, Validation loss: 0.5527102947235107
Epoch: 41/300 - Train loss: 0.5527755618095398, Validation loss: 0.5487173199653625
Epoch: 42/300 - Train loss: 0.5493388175964355, Validation loss: 0.5461071729660034
Epoch: 43/300 - Train loss: 0.5459557771682739, Validation loss: 0.543152928352356
Epoch: 44/300 - Train loss: 0.5426276326179504, Validation loss: 0.5393559336662292
Epoch: 45/300 - Train loss: 0.5393551588058472, Validation loss: 0.5356414914131165
Epoch: 46/300 - Train loss: 0.5361388325691223, Validation loss: 0.532849133014679
Epoch: 47/300 - Train loss: 0.5329790115356445, Validation loss: 0.5303887724876404
Epoch: 48/300 - Train loss: 0.5298758149147034, Validation loss: 0.5269531011581421
Epoch: 49/300 - Train loss: 0.5268293023109436, Validation loss: 0.5240125060081482
Epoch: 50/300 - Train loss: 0.5238394141197205, Validation loss: 0.5213389992713928
Epoch: 51/300 - Train loss: 0.5209056735038757, Validation loss: 0.518254816532135
Epoch: 52/300 - Train loss: 0.5180273652076721, Validation loss: 0.5158761739730835
Epoch: 53/300 - Train loss: 0.5152029991149902, Validation loss: 0.5127391815185547
Epoch: 54/300 - Train loss: 0.5124325156211853, Validation loss: 0.5102287530899048
Epoch: 55/300 - Train loss: 0.5097154378890991, Validation loss: 0.5070878863334656
Epoch: 56/300 - Train loss: 0.5070511102676392, Validation loss: 0.5046945810317993
Epoch: 57/300 - Train loss: 0.5044389367103577, Validation loss: 0.5018188953399658
Epoch: 58/300 - Train loss: 0.5018770694732666, Validation loss: 0.4997246563434601
Epoch: 59/300 - Train loss: 0.499364972114563, Validation loss: 0.497026264667511
Epoch: 60/300 - Train loss: 0.4969019591808319, Validation loss: 0.4939039945602417
Epoch: 61/300 - Train loss: 0.4944875240325928, Validation loss: 0.49293240904808044
Epoch: 62/300 - Train loss: 0.49212080240249634, Validation loss: 0.4899093508720398
Epoch: 63/300 - Train loss: 0.4898003041744232, Validation loss: 0.48773249983787537
Epoch: 64/300 - Train loss: 0.48752498626708984, Validation loss: 0.4862280488014221
Epoch: 65/300 - Train loss: 0.48529374599456787, Validation loss: 0.48287561535835266
Epoch: 66/300 - Train loss: 0.4831051826477051, Validation loss: 0.4811730682849884
Epoch: 67/300 - Train loss: 0.4809582829475403, Validation loss: 0.4798358380794525
Epoch: 68/300 - Train loss: 0.4788524806499481, Validation loss: 0.4776211678981781
Epoch: 69/300 - Train loss: 0.47678637504577637, Validation loss: 0.4758244752883911
Epoch: 70/300 - Train loss: 0.4747592806816101, Validation loss: 0.4738938808441162
Epoch: 71/300 - Train loss: 0.47276976704597473, Validation loss: 0.4712045192718506
Epoch: 72/300 - Train loss: 0.47081688046455383, Validation loss: 0.46902021765708923
Epoch: 73/300 - Train loss: 0.4689001142978668, Validation loss: 0.4679473340511322
Epoch: 74/300 - Train loss: 0.4670192003250122, Validation loss: 0.46594521403312683
Epoch: 75/300 - Train loss: 0.4651731848716736, Validation loss: 0.4636063873767853
Epoch: 76/300 - Train loss: 0.46336084604263306, Validation loss: 0.46233096718788147
Epoch: 77/300 - Train loss: 0.4615805149078369, Validation loss: 0.4600580334663391
Epoch: 78/300 - Train loss: 0.4598320722579956, Validation loss: 0.4582902193069458
Epoch: 79/300 - Train loss: 0.45811474323272705, Validation loss: 0.4569251239299774
Epoch: 80/300 - Train loss: 0.45642754435539246, Validation loss: 0.4552878141403198
Epoch: 81/300 - Train loss: 0.4547698199748993, Validation loss: 0.4531753361225128
Epoch: 82/300 - Train loss: 0.45314034819602966, Validation loss: 0.4514290392398834
Epoch: 83/300 - Train loss: 0.4515388607978821, Validation loss: 0.4499560296535492
Epoch: 84/300 - Train loss: 0.4499647617340088, Validation loss: 0.44876840710639954
Epoch: 85/300 - Train loss: 0.44841673970222473, Validation loss: 0.448106586933136
Epoch: 86/300 - Train loss: 0.446894109249115, Validation loss: 0.4459630250930786
Epoch: 87/300 - Train loss: 0.44539573788642883, Validation loss: 0.44442421197891235
Epoch: 88/300 - Train loss: 0.44392165541648865, Validation loss: 0.4423503577709198
Epoch: 89/300 - Train loss: 0.442471444606781, Validation loss: 0.4416666030883789
Epoch: 90/300 - Train loss: 0.44104427099227905, Validation loss: 0.43985989689826965
Epoch: 91/300 - Train loss: 0.43963944911956787, Validation loss: 0.4388103783130646
Epoch: 92/300 - Train loss: 0.43825671076774597, Validation loss: 0.4369522035121918
Epoch: 93/300 - Train loss: 0.4368954002857208, Validation loss: 0.4364955723285675
Epoch: 94/300 - Train loss: 0.4355548322200775, Validation loss: 0.4338219463825226
Epoch: 95/300 - Train loss: 0.4342350363731384, Validation loss: 0.43221282958984375
Epoch: 96/300 - Train loss: 0.43293559551239014, Validation loss: 0.43227460980415344
Epoch: 97/300 - Train loss: 0.4316559135913849, Validation loss: 0.4310811460018158
Epoch: 98/300 - Train loss: 0.4303954839706421, Validation loss: 0.4297563135623932
Epoch: 99/300 - Train loss: 0.42915377020835876, Validation loss: 0.42799755930900574
Epoch: 100/300 - Train loss: 0.427930623292923, Validation loss: 0.42771971225738525
Epoch: 101/300 - Train loss: 0.4267258048057556, Validation loss: 0.4261462688446045
Epoch: 102/300 - Train loss: 0.4255388379096985, Validation loss: 0.42426013946533203
Epoch: 103/300 - Train loss: 0.4243689775466919, Validation loss: 0.42467549443244934
Epoch: 104/300 - Train loss: 0.42321640253067017, Validation loss: 0.42261895537376404
Epoch: 105/300 - Train loss: 0.4220803380012512, Validation loss: 0.421794056892395
Epoch: 106/300 - Train loss: 0.4209604561328888, Validation loss: 0.4203495383262634
Epoch: 107/300 - Train loss: 0.41985610127449036, Validation loss: 0.4201184809207916
Epoch: 108/300 - Train loss: 0.41876697540283203, Validation loss: 0.4168374240398407
Epoch: 109/300 - Train loss: 0.41769275069236755, Validation loss: 0.41675442457199097
Epoch: 110/300 - Train loss: 0.4166333079338074, Validation loss: 0.4151289463043213
Epoch: 111/300 - Train loss: 0.4155880808830261, Validation loss: 0.41488468647003174
Epoch: 112/300 - Train loss: 0.4145568907260895, Validation loss: 0.4142313003540039
Epoch: 113/300 - Train loss: 0.4135391414165497, Validation loss: 0.41166236996650696
Epoch: 114/300 - Train loss: 0.41253456473350525, Validation loss: 0.41099879145622253
Epoch: 115/300 - Train loss: 0.41154342889785767, Validation loss: 0.41221538186073303
Epoch: 116/300 - Train loss: 0.4105656147003174, Validation loss: 0.41041100025177
Epoch: 117/300 - Train loss: 0.40960049629211426, Validation loss: 0.4088326692581177
Epoch: 118/300 - Train loss: 0.40864819288253784, Validation loss: 0.4077022969722748
Epoch: 119/300 - Train loss: 0.4077083468437195, Validation loss: 0.4068487882614136
Epoch: 120/300 - Train loss: 0.40678074955940247, Validation loss: 0.4063117802143097
Epoch: 121/300 - Train loss: 0.4058648943901062, Validation loss: 0.4048331677913666
Epoch: 122/300 - Train loss: 0.40496063232421875, Validation loss: 0.4044646918773651
Epoch: 123/300 - Train loss: 0.4040676951408386, Validation loss: 0.40295320749282837
Epoch: 124/300 - Train loss: 0.4031859040260315, Validation loss: 0.40359264612197876
Epoch: 125/300 - Train loss: 0.40231508016586304, Validation loss: 0.40175530314445496
Epoch: 126/300 - Train loss: 0.4014548361301422, Validation loss: 0.40121543407440186
Epoch: 127/300 - Train loss: 0.4006049335002899, Validation loss: 0.39887920022010803
Epoch: 128/300 - Train loss: 0.3997654318809509, Validation loss: 0.39975705742836
Epoch: 129/300 - Train loss: 0.3989359140396118, Validation loss: 0.39848169684410095
Epoch: 130/300 - Train loss: 0.39811673760414124, Validation loss: 0.3980608880519867
Epoch: 131/300 - Train loss: 0.39730778336524963, Validation loss: 0.39657062292099
Epoch: 132/300 - Train loss: 0.39650842547416687, Validation loss: 0.3946968913078308
Epoch: 133/300 - Train loss: 0.3957184851169586, Validation loss: 0.3938485085964203
Epoch: 134/300 - Train loss: 0.3949379026889801, Validation loss: 0.39273083209991455
Epoch: 135/300 - Train loss: 0.3941664695739746, Validation loss: 0.39349207282066345
Epoch: 136/300 - Train loss: 0.39340412616729736, Validation loss: 0.3921688497066498
Epoch: 137/300 - Train loss: 0.39265114068984985, Validation loss: 0.39202064275741577
Epoch: 138/300 - Train loss: 0.39190733432769775, Validation loss: 0.39020809531211853
Epoch: 139/300 - Train loss: 0.3911723792552948, Validation loss: 0.38985633850097656
Epoch: 140/300 - Train loss: 0.39044612646102905, Validation loss: 0.3896099627017975
Epoch: 141/300 - Train loss: 0.3897283375263214, Validation loss: 0.3887905478477478
Epoch: 142/300 - Train loss: 0.3890186846256256, Validation loss: 0.3885995149612427
Epoch: 143/300 - Train loss: 0.3883173167705536, Validation loss: 0.3873659670352936
Epoch: 144/300 - Train loss: 0.38762420415878296, Validation loss: 0.3862764537334442
Epoch: 145/300 - Train loss: 0.3869386613368988, Validation loss: 0.38686758279800415
Epoch: 146/300 - Train loss: 0.38626018166542053, Validation loss: 0.38521304726600647
Epoch: 147/300 - Train loss: 0.3855894207954407, Validation loss: 0.3859517276287079
