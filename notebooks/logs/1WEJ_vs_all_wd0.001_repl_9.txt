Epoch: 1/300 - Train loss: 0.7041847109794617, Validation loss: 0.6998887062072754
Epoch: 2/300 - Train loss: 0.7019848823547363, Validation loss: 0.6976931095123291
Epoch: 3/300 - Train loss: 0.6998051404953003, Validation loss: 0.6957617998123169
Epoch: 4/300 - Train loss: 0.6976251602172852, Validation loss: 0.6937827467918396
Epoch: 5/300 - Train loss: 0.6954184174537659, Validation loss: 0.6912697553634644
Epoch: 6/300 - Train loss: 0.6931641101837158, Validation loss: 0.6892182230949402
Epoch: 7/300 - Train loss: 0.6908465027809143, Validation loss: 0.6869164109230042
Epoch: 8/300 - Train loss: 0.6884509921073914, Validation loss: 0.6843425631523132
Epoch: 9/300 - Train loss: 0.6859651803970337, Validation loss: 0.68192058801651
Epoch: 10/300 - Train loss: 0.6833795309066772, Validation loss: 0.6792684197425842
Epoch: 11/300 - Train loss: 0.6806912422180176, Validation loss: 0.6764147877693176
Epoch: 12/300 - Train loss: 0.6778985857963562, Validation loss: 0.6738123297691345
Epoch: 13/300 - Train loss: 0.6749988794326782, Validation loss: 0.6709995269775391
Epoch: 14/300 - Train loss: 0.6719895005226135, Validation loss: 0.6678179502487183
Epoch: 15/300 - Train loss: 0.668870210647583, Validation loss: 0.6644564270973206
Epoch: 16/300 - Train loss: 0.6656367778778076, Validation loss: 0.6613999605178833
Epoch: 17/300 - Train loss: 0.6622878313064575, Validation loss: 0.6578710079193115
Epoch: 18/300 - Train loss: 0.658829391002655, Validation loss: 0.6545130610466003
Epoch: 19/300 - Train loss: 0.6552626490592957, Validation loss: 0.6509476900100708
Epoch: 20/300 - Train loss: 0.6515924334526062, Validation loss: 0.6471945643424988
Epoch: 21/300 - Train loss: 0.6478220820426941, Validation loss: 0.6435646414756775
Epoch: 22/300 - Train loss: 0.6439628005027771, Validation loss: 0.6398261189460754
Epoch: 23/300 - Train loss: 0.6400267481803894, Validation loss: 0.6358737945556641
Epoch: 24/300 - Train loss: 0.6360223889350891, Validation loss: 0.6318639516830444
Epoch: 25/300 - Train loss: 0.6319509148597717, Validation loss: 0.6276646852493286
Epoch: 26/300 - Train loss: 0.6278133988380432, Validation loss: 0.6234318017959595
Epoch: 27/300 - Train loss: 0.623609721660614, Validation loss: 0.619506299495697
Epoch: 28/300 - Train loss: 0.6193451285362244, Validation loss: 0.615116536617279
Epoch: 29/300 - Train loss: 0.61502605676651, Validation loss: 0.6110047101974487
Epoch: 30/300 - Train loss: 0.6106592416763306, Validation loss: 0.6065473556518555
Epoch: 31/300 - Train loss: 0.6062518358230591, Validation loss: 0.6022529602050781
Epoch: 32/300 - Train loss: 0.601810097694397, Validation loss: 0.5978172421455383
Epoch: 33/300 - Train loss: 0.5973400473594666, Validation loss: 0.5933504104614258
Epoch: 34/300 - Train loss: 0.5928475260734558, Validation loss: 0.5890079736709595
Epoch: 35/300 - Train loss: 0.5883376002311707, Validation loss: 0.5845115780830383
Epoch: 36/300 - Train loss: 0.583814799785614, Validation loss: 0.5800513029098511
Epoch: 37/300 - Train loss: 0.5792822241783142, Validation loss: 0.5756340622901917
Epoch: 38/300 - Train loss: 0.5747448801994324, Validation loss: 0.5710536241531372
Epoch: 39/300 - Train loss: 0.5702078938484192, Validation loss: 0.5669023990631104
Epoch: 40/300 - Train loss: 0.5656765103340149, Validation loss: 0.5619596242904663
Epoch: 41/300 - Train loss: 0.5611571669578552, Validation loss: 0.5575809478759766
Epoch: 42/300 - Train loss: 0.5566552877426147, Validation loss: 0.5534640550613403
Epoch: 43/300 - Train loss: 0.5521769523620605, Validation loss: 0.5486819744110107
Epoch: 44/300 - Train loss: 0.5477278828620911, Validation loss: 0.5445168614387512
Epoch: 45/300 - Train loss: 0.5433127880096436, Validation loss: 0.5397694706916809
Epoch: 46/300 - Train loss: 0.5389367341995239, Validation loss: 0.5355535745620728
Epoch: 47/300 - Train loss: 0.5346036553382874, Validation loss: 0.5314624309539795
Epoch: 48/300 - Train loss: 0.5303178429603577, Validation loss: 0.5272229313850403
Epoch: 49/300 - Train loss: 0.5260831713676453, Validation loss: 0.5234450697898865
Epoch: 50/300 - Train loss: 0.5219031572341919, Validation loss: 0.518676221370697
Epoch: 51/300 - Train loss: 0.5177814960479736, Validation loss: 0.5149887800216675
Epoch: 52/300 - Train loss: 0.5137213468551636, Validation loss: 0.5107976794242859
Epoch: 53/300 - Train loss: 0.5097262859344482, Validation loss: 0.5070000886917114
Epoch: 54/300 - Train loss: 0.5057995319366455, Validation loss: 0.5027269721031189
Epoch: 55/300 - Train loss: 0.5019434690475464, Validation loss: 0.4989154040813446
Epoch: 56/300 - Train loss: 0.4981594681739807, Validation loss: 0.49538111686706543
Epoch: 57/300 - Train loss: 0.4944499433040619, Validation loss: 0.4916956126689911
Epoch: 58/300 - Train loss: 0.49081647396087646, Validation loss: 0.4884064197540283
Epoch: 59/300 - Train loss: 0.4872603416442871, Validation loss: 0.48436012864112854
Epoch: 60/300 - Train loss: 0.48378270864486694, Validation loss: 0.4811640679836273
Epoch: 61/300 - Train loss: 0.4803844690322876, Validation loss: 0.4775395095348358
Epoch: 62/300 - Train loss: 0.4770660996437073, Validation loss: 0.47455111145973206
Epoch: 63/300 - Train loss: 0.4738278388977051, Validation loss: 0.4710177481174469
Epoch: 64/300 - Train loss: 0.47066980600357056, Validation loss: 0.46800097823143005
Epoch: 65/300 - Train loss: 0.46759212017059326, Validation loss: 0.4657117426395416
Epoch: 66/300 - Train loss: 0.46459445357322693, Validation loss: 0.4625282287597656
Epoch: 67/300 - Train loss: 0.4616762399673462, Validation loss: 0.45891574025154114
Epoch: 68/300 - Train loss: 0.4588371515274048, Validation loss: 0.45618936419487
Epoch: 69/300 - Train loss: 0.45607641339302063, Validation loss: 0.453514039516449
Epoch: 70/300 - Train loss: 0.4533924162387848, Validation loss: 0.4516977071762085
Epoch: 71/300 - Train loss: 0.45078471302986145, Validation loss: 0.4484339952468872
Epoch: 72/300 - Train loss: 0.4482518434524536, Validation loss: 0.44604283571243286
Epoch: 73/300 - Train loss: 0.44579264521598816, Validation loss: 0.443881094455719
Epoch: 74/300 - Train loss: 0.44340547919273376, Validation loss: 0.4407495856285095
Epoch: 75/300 - Train loss: 0.44108864665031433, Validation loss: 0.4389507472515106
Epoch: 76/300 - Train loss: 0.4388408362865448, Validation loss: 0.4367973506450653
Epoch: 77/300 - Train loss: 0.43666037917137146, Validation loss: 0.43431356549263
Epoch: 78/300 - Train loss: 0.4345456063747406, Validation loss: 0.43219614028930664
Epoch: 79/300 - Train loss: 0.4324948787689209, Validation loss: 0.43041956424713135
Epoch: 80/300 - Train loss: 0.4305061101913452, Validation loss: 0.4280696213245392
Epoch: 81/300 - Train loss: 0.4285772442817688, Validation loss: 0.4257509112358093
Epoch: 82/300 - Train loss: 0.4267067313194275, Validation loss: 0.4243966341018677
Epoch: 83/300 - Train loss: 0.42489269375801086, Validation loss: 0.4225749969482422
Epoch: 84/300 - Train loss: 0.42313361167907715, Validation loss: 0.4209442734718323
Epoch: 85/300 - Train loss: 0.42142748832702637, Validation loss: 0.4194988012313843
Epoch: 86/300 - Train loss: 0.4197724759578705, Validation loss: 0.417420357465744
Epoch: 87/300 - Train loss: 0.41816627979278564, Validation loss: 0.4161352813243866
Epoch: 88/300 - Train loss: 0.4166072607040405, Validation loss: 0.4138042628765106
Epoch: 89/300 - Train loss: 0.41509485244750977, Validation loss: 0.41293349862098694
Epoch: 90/300 - Train loss: 0.4136275351047516, Validation loss: 0.4115830063819885
Epoch: 91/300 - Train loss: 0.4122026264667511, Validation loss: 0.4098796844482422
Epoch: 92/300 - Train loss: 0.4108189344406128, Validation loss: 0.4083541929721832
Epoch: 93/300 - Train loss: 0.40947461128234863, Validation loss: 0.4073623716831207
Epoch: 94/300 - Train loss: 0.40816745162010193, Validation loss: 0.4051215648651123
Epoch: 95/300 - Train loss: 0.40689635276794434, Validation loss: 0.4040079116821289
Epoch: 96/300 - Train loss: 0.4056588411331177, Validation loss: 0.4031590223312378
Epoch: 97/300 - Train loss: 0.40445348620414734, Validation loss: 0.40188634395599365
Epoch: 98/300 - Train loss: 0.4032782316207886, Validation loss: 0.40065866708755493
Epoch: 99/300 - Train loss: 0.402132123708725, Validation loss: 0.3994869589805603
Epoch: 100/300 - Train loss: 0.4010154902935028, Validation loss: 0.3979605734348297
Epoch: 101/300 - Train loss: 0.3999267518520355, Validation loss: 0.39731767773628235
Epoch: 102/300 - Train loss: 0.3988642990589142, Validation loss: 0.39605358242988586
Epoch: 103/300 - Train loss: 0.3978271484375, Validation loss: 0.3950358033180237
Epoch: 104/300 - Train loss: 0.3968139886856079, Validation loss: 0.3940448760986328
Epoch: 105/300 - Train loss: 0.3958248198032379, Validation loss: 0.3925600051879883
Epoch: 106/300 - Train loss: 0.394857794046402, Validation loss: 0.3917059898376465
Epoch: 107/300 - Train loss: 0.39391177892684937, Validation loss: 0.3907604515552521
Epoch: 108/300 - Train loss: 0.39298510551452637, Validation loss: 0.3901371359825134
Epoch: 109/300 - Train loss: 0.3920770287513733, Validation loss: 0.38906916975975037
Epoch: 110/300 - Train loss: 0.3911883533000946, Validation loss: 0.3878984749317169
Epoch: 111/300 - Train loss: 0.3903185725212097, Validation loss: 0.3872207999229431
Epoch: 112/300 - Train loss: 0.38946661353111267, Validation loss: 0.38661110401153564
Epoch: 113/300 - Train loss: 0.38863131403923035, Validation loss: 0.3848828375339508
Epoch: 114/300 - Train loss: 0.3878123462200165, Validation loss: 0.3845714330673218
Epoch: 115/300 - Train loss: 0.3870093524456024, Validation loss: 0.38348713517189026
Epoch: 116/300 - Train loss: 0.3862214982509613, Validation loss: 0.3826391100883484
Epoch: 117/300 - Train loss: 0.38544729351997375, Validation loss: 0.38188767433166504
Epoch: 118/300 - Train loss: 0.38468626141548157, Validation loss: 0.38166341185569763
Epoch: 119/300 - Train loss: 0.3839375972747803, Validation loss: 0.3803902864456177
Epoch: 120/300 - Train loss: 0.3831998407840729, Validation loss: 0.379856675863266
Epoch: 121/300 - Train loss: 0.3824737071990967, Validation loss: 0.37877336144447327
Epoch: 122/300 - Train loss: 0.3817581534385681, Validation loss: 0.3781186044216156
Epoch: 123/300 - Train loss: 0.38105127215385437, Validation loss: 0.37736159563064575
Epoch: 124/300 - Train loss: 0.3803539276123047, Validation loss: 0.3772966265678406
Epoch: 125/300 - Train loss: 0.3796650469303131, Validation loss: 0.37614306807518005
Epoch: 126/300 - Train loss: 0.378984272480011, Validation loss: 0.3752286732196808
Epoch: 127/300 - Train loss: 0.37831154465675354, Validation loss: 0.37527692317962646
Epoch: 128/300 - Train loss: 0.37764590978622437, Validation loss: 0.3741542398929596
Epoch: 129/300 - Train loss: 0.3769868016242981, Validation loss: 0.37287938594818115
Epoch: 130/300 - Train loss: 0.3763332664966583, Validation loss: 0.3722834289073944
Epoch: 131/300 - Train loss: 0.37568697333335876, Validation loss: 0.371934711933136
Epoch: 132/300 - Train loss: 0.3750477135181427, Validation loss: 0.37109702825546265
Epoch: 133/300 - Train loss: 0.37441450357437134, Validation loss: 0.37059491872787476
Epoch: 134/300 - Train loss: 0.37378793954849243, Validation loss: 0.3694918155670166
Epoch: 135/300 - Train loss: 0.37316790223121643, Validation loss: 0.3690200448036194
Epoch: 136/300 - Train loss: 0.3725558817386627, Validation loss: 0.36891958117485046
Epoch: 137/300 - Train loss: 0.37195026874542236, Validation loss: 0.3683382272720337
Epoch: 138/300 - Train loss: 0.3713501989841461, Validation loss: 0.36750930547714233
Epoch: 139/300 - Train loss: 0.37075453996658325, Validation loss: 0.36704570055007935
Epoch: 140/300 - Train loss: 0.3701653778553009, Validation loss: 0.36613038182258606
Epoch: 141/300 - Train loss: 0.36958205699920654, Validation loss: 0.3656291961669922
Epoch: 142/300 - Train loss: 0.369005024433136, Validation loss: 0.3644723892211914
Epoch: 143/300 - Train loss: 0.3684351146221161, Validation loss: 0.36519163846969604
Epoch: 144/300 - Train loss: 0.36787083745002747, Validation loss: 0.36413413286209106
