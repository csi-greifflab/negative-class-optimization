Epoch: 1/300 - Train loss: 0.7005711197853088, Validation loss: 0.6987564563751221
Epoch: 2/300 - Train loss: 0.6972931027412415, Validation loss: 0.6950909495353699
Epoch: 3/300 - Train loss: 0.693915069103241, Validation loss: 0.6915690898895264
Epoch: 4/300 - Train loss: 0.6904178261756897, Validation loss: 0.6877192258834839
Epoch: 5/300 - Train loss: 0.6867731213569641, Validation loss: 0.6838899850845337
Epoch: 6/300 - Train loss: 0.6829767227172852, Validation loss: 0.6797667741775513
Epoch: 7/300 - Train loss: 0.6790271401405334, Validation loss: 0.6754584312438965
Epoch: 8/300 - Train loss: 0.6749314069747925, Validation loss: 0.6711650490760803
Epoch: 9/300 - Train loss: 0.6707096695899963, Validation loss: 0.6666804552078247
Epoch: 10/300 - Train loss: 0.6663822531700134, Validation loss: 0.6620981693267822
Epoch: 11/300 - Train loss: 0.6619665622711182, Validation loss: 0.6575226783752441
Epoch: 12/300 - Train loss: 0.6574799418449402, Validation loss: 0.652849018573761
Epoch: 13/300 - Train loss: 0.6529403328895569, Validation loss: 0.6480679512023926
Epoch: 14/300 - Train loss: 0.6483660340309143, Validation loss: 0.6433531045913696
Epoch: 15/300 - Train loss: 0.6437695622444153, Validation loss: 0.6385995149612427
Epoch: 16/300 - Train loss: 0.6391608119010925, Validation loss: 0.6338792443275452
Epoch: 17/300 - Train loss: 0.6345404386520386, Validation loss: 0.6291322112083435
Epoch: 18/300 - Train loss: 0.6299124360084534, Validation loss: 0.6243482828140259
Epoch: 19/300 - Train loss: 0.6252719163894653, Validation loss: 0.6195054054260254
Epoch: 20/300 - Train loss: 0.6206160187721252, Validation loss: 0.6146659255027771
Epoch: 21/300 - Train loss: 0.6159394979476929, Validation loss: 0.6098967790603638
Epoch: 22/300 - Train loss: 0.6112387180328369, Validation loss: 0.6050970554351807
Epoch: 23/300 - Train loss: 0.6065089702606201, Validation loss: 0.6002247929573059
Epoch: 24/300 - Train loss: 0.6017512083053589, Validation loss: 0.5955486297607422
Epoch: 25/300 - Train loss: 0.596969485282898, Validation loss: 0.5905161499977112
Epoch: 26/300 - Train loss: 0.5921705961227417, Validation loss: 0.5855613946914673
Epoch: 27/300 - Train loss: 0.5873634815216064, Validation loss: 0.5807796716690063
Epoch: 28/300 - Train loss: 0.5825545787811279, Validation loss: 0.5759099721908569
Epoch: 29/300 - Train loss: 0.5777499675750732, Validation loss: 0.571217954158783
Epoch: 30/300 - Train loss: 0.5729581713676453, Validation loss: 0.5662240386009216
Epoch: 31/300 - Train loss: 0.5681915879249573, Validation loss: 0.5613415837287903
Epoch: 32/300 - Train loss: 0.5634608268737793, Validation loss: 0.556444525718689
Epoch: 33/300 - Train loss: 0.5587676167488098, Validation loss: 0.5519405007362366
Epoch: 34/300 - Train loss: 0.5541178584098816, Validation loss: 0.5472103357315063
Epoch: 35/300 - Train loss: 0.5495115518569946, Validation loss: 0.5422950387001038
Epoch: 36/300 - Train loss: 0.5449498295783997, Validation loss: 0.5378304719924927
Epoch: 37/300 - Train loss: 0.5404274463653564, Validation loss: 0.5335021018981934
Epoch: 38/300 - Train loss: 0.535946249961853, Validation loss: 0.5291614532470703
Epoch: 39/300 - Train loss: 0.5315076112747192, Validation loss: 0.5244344472885132
Epoch: 40/300 - Train loss: 0.5271114706993103, Validation loss: 0.5197689533233643
Epoch: 41/300 - Train loss: 0.5227580070495605, Validation loss: 0.5156632661819458
Epoch: 42/300 - Train loss: 0.5184483528137207, Validation loss: 0.5113290548324585
Epoch: 43/300 - Train loss: 0.5141835808753967, Validation loss: 0.5069674253463745
Epoch: 44/300 - Train loss: 0.5099657773971558, Validation loss: 0.5025259256362915
Epoch: 45/300 - Train loss: 0.5057970881462097, Validation loss: 0.4985746741294861
Epoch: 46/300 - Train loss: 0.5016786456108093, Validation loss: 0.4944884181022644
Epoch: 47/300 - Train loss: 0.49761244654655457, Validation loss: 0.49074864387512207
Epoch: 48/300 - Train loss: 0.4936000108718872, Validation loss: 0.48611339926719666
Epoch: 49/300 - Train loss: 0.4896434545516968, Validation loss: 0.48222416639328003
Epoch: 50/300 - Train loss: 0.4857444763183594, Validation loss: 0.4784890413284302
Epoch: 51/300 - Train loss: 0.48190411925315857, Validation loss: 0.4745680093765259
Epoch: 52/300 - Train loss: 0.47812408208847046, Validation loss: 0.47097939252853394
Epoch: 53/300 - Train loss: 0.4744057357311249, Validation loss: 0.46663233637809753
Epoch: 54/300 - Train loss: 0.47074976563453674, Validation loss: 0.4633280634880066
Epoch: 55/300 - Train loss: 0.4671575129032135, Validation loss: 0.4598047137260437
Epoch: 56/300 - Train loss: 0.46363046765327454, Validation loss: 0.45654386281967163
Epoch: 57/300 - Train loss: 0.4601688086986542, Validation loss: 0.4527056813240051
Epoch: 58/300 - Train loss: 0.45677319169044495, Validation loss: 0.44940701127052307
Epoch: 59/300 - Train loss: 0.4534440040588379, Validation loss: 0.44561493396759033
Epoch: 60/300 - Train loss: 0.4501815736293793, Validation loss: 0.442493736743927
Epoch: 61/300 - Train loss: 0.4469861090183258, Validation loss: 0.4390130639076233
Epoch: 62/300 - Train loss: 0.443857342004776, Validation loss: 0.43629512190818787
Epoch: 63/300 - Train loss: 0.4407954514026642, Validation loss: 0.43330708146095276
Epoch: 64/300 - Train loss: 0.43780040740966797, Validation loss: 0.4305505156517029
Epoch: 65/300 - Train loss: 0.4348717927932739, Validation loss: 0.4271611273288727
Epoch: 66/300 - Train loss: 0.4320094585418701, Validation loss: 0.4239373207092285
Epoch: 67/300 - Train loss: 0.42921313643455505, Validation loss: 0.4216591417789459
Epoch: 68/300 - Train loss: 0.4264819622039795, Validation loss: 0.4189569056034088
Epoch: 69/300 - Train loss: 0.4238151013851166, Validation loss: 0.41604211926460266
Epoch: 70/300 - Train loss: 0.4212121069431305, Validation loss: 0.4131971299648285
Epoch: 71/300 - Train loss: 0.4186721742153168, Validation loss: 0.41068941354751587
Epoch: 72/300 - Train loss: 0.4161945581436157, Validation loss: 0.40817034244537354
Epoch: 73/300 - Train loss: 0.4137781858444214, Validation loss: 0.4053366780281067
Epoch: 74/300 - Train loss: 0.41142237186431885, Validation loss: 0.4030367136001587
Epoch: 75/300 - Train loss: 0.4091259837150574, Validation loss: 0.40069130063056946
Epoch: 76/300 - Train loss: 0.40688785910606384, Validation loss: 0.3985145688056946
Epoch: 77/300 - Train loss: 0.40470650792121887, Validation loss: 0.3966371417045593
Epoch: 78/300 - Train loss: 0.4025811553001404, Validation loss: 0.393890380859375
Epoch: 79/300 - Train loss: 0.40051087737083435, Validation loss: 0.39176321029663086
Epoch: 80/300 - Train loss: 0.39849457144737244, Validation loss: 0.389914870262146
Epoch: 81/300 - Train loss: 0.39653125405311584, Validation loss: 0.38792884349823
Epoch: 82/300 - Train loss: 0.39462023973464966, Validation loss: 0.3859170973300934
Epoch: 83/300 - Train loss: 0.39276015758514404, Validation loss: 0.38378316164016724
Epoch: 84/300 - Train loss: 0.3909497559070587, Validation loss: 0.38211408257484436
Epoch: 85/300 - Train loss: 0.38918784260749817, Validation loss: 0.38050583004951477
Epoch: 86/300 - Train loss: 0.3874730169773102, Validation loss: 0.3786958158016205
Epoch: 87/300 - Train loss: 0.38580384850502014, Validation loss: 0.3769543468952179
Epoch: 88/300 - Train loss: 0.38417911529541016, Validation loss: 0.37512776255607605
Epoch: 89/300 - Train loss: 0.382597953081131, Validation loss: 0.3734250068664551
Epoch: 90/300 - Train loss: 0.38105928897857666, Validation loss: 0.37163153290748596
Epoch: 91/300 - Train loss: 0.3795619010925293, Validation loss: 0.370993971824646
Epoch: 92/300 - Train loss: 0.37810462713241577, Validation loss: 0.36908283829689026
Epoch: 93/300 - Train loss: 0.37668687105178833, Validation loss: 0.36675605177879333
Epoch: 94/300 - Train loss: 0.37530726194381714, Validation loss: 0.36605197191238403
Epoch: 95/300 - Train loss: 0.3739646375179291, Validation loss: 0.3650498688220978
Epoch: 96/300 - Train loss: 0.37265798449516296, Validation loss: 0.36322474479675293
Epoch: 97/300 - Train loss: 0.37138599157333374, Validation loss: 0.3618347942829132
Epoch: 98/300 - Train loss: 0.37014809250831604, Validation loss: 0.3605138659477234
Epoch: 99/300 - Train loss: 0.3689431846141815, Validation loss: 0.35944655537605286
Epoch: 100/300 - Train loss: 0.36777034401893616, Validation loss: 0.3578284680843353
Epoch: 101/300 - Train loss: 0.3666286766529083, Validation loss: 0.3569492697715759
Epoch: 102/300 - Train loss: 0.3655177056789398, Validation loss: 0.3557873070240021
Epoch: 103/300 - Train loss: 0.36443594098091125, Validation loss: 0.3542565703392029
Epoch: 104/300 - Train loss: 0.3633820414543152, Validation loss: 0.35311251878738403
Epoch: 105/300 - Train loss: 0.36235544085502625, Validation loss: 0.35247480869293213
Epoch: 106/300 - Train loss: 0.36135536432266235, Validation loss: 0.3512350022792816
Epoch: 107/300 - Train loss: 0.360381156206131, Validation loss: 0.35053426027297974
Epoch: 108/300 - Train loss: 0.35943180322647095, Validation loss: 0.349809855222702
Epoch: 109/300 - Train loss: 0.3585066795349121, Validation loss: 0.3486708104610443
Epoch: 110/300 - Train loss: 0.3576047718524933, Validation loss: 0.34742113947868347
Epoch: 111/300 - Train loss: 0.35672569274902344, Validation loss: 0.3463881313800812
Epoch: 112/300 - Train loss: 0.3558685779571533, Validation loss: 0.34620147943496704
Epoch: 113/300 - Train loss: 0.3550328016281128, Validation loss: 0.34480684995651245
Epoch: 114/300 - Train loss: 0.3542173206806183, Validation loss: 0.34401166439056396
Epoch: 115/300 - Train loss: 0.3534214198589325, Validation loss: 0.34308260679244995
Epoch: 116/300 - Train loss: 0.3526443541049957, Validation loss: 0.34238097071647644
Epoch: 117/300 - Train loss: 0.35188576579093933, Validation loss: 0.3419758677482605
Epoch: 118/300 - Train loss: 0.35114502906799316, Validation loss: 0.34046393632888794
Epoch: 119/300 - Train loss: 0.35042133927345276, Validation loss: 0.3400775194168091
Epoch: 120/300 - Train loss: 0.349714457988739, Validation loss: 0.3391304016113281
Epoch: 121/300 - Train loss: 0.34902456402778625, Validation loss: 0.3384585976600647
Epoch: 122/300 - Train loss: 0.34835097193717957, Validation loss: 0.33751749992370605
Epoch: 123/300 - Train loss: 0.3476923406124115, Validation loss: 0.3371240496635437
Epoch: 124/300 - Train loss: 0.3470485210418701, Validation loss: 0.3361814618110657
Epoch: 125/300 - Train loss: 0.3464197516441345, Validation loss: 0.3354135751724243
Epoch: 126/300 - Train loss: 0.3458055257797241, Validation loss: 0.3349034786224365
Epoch: 127/300 - Train loss: 0.34520530700683594, Validation loss: 0.3347345292568207
Epoch: 128/300 - Train loss: 0.344618558883667, Validation loss: 0.333639532327652
Epoch: 129/300 - Train loss: 0.3440454602241516, Validation loss: 0.3332250118255615
Epoch: 130/300 - Train loss: 0.34348517656326294, Validation loss: 0.3329935073852539
Epoch: 131/300 - Train loss: 0.3429372012615204, Validation loss: 0.33243826031684875
Epoch: 132/300 - Train loss: 0.34240126609802246, Validation loss: 0.33159732818603516
Epoch: 133/300 - Train loss: 0.3418770432472229, Validation loss: 0.3308654725551605
Epoch: 134/300 - Train loss: 0.34136420488357544, Validation loss: 0.33003100752830505
Epoch: 135/300 - Train loss: 0.34086230397224426, Validation loss: 0.3296507000923157
Epoch: 136/300 - Train loss: 0.3403710424900055, Validation loss: 0.329466849565506
Epoch: 137/300 - Train loss: 0.3398900330066681, Validation loss: 0.3293665051460266
