Epoch: 1/300 - Train loss: 0.7019558548927307, Validation loss: 0.7003335356712341
Epoch: 2/300 - Train loss: 0.7003945708274841, Validation loss: 0.6987810134887695
Epoch: 3/300 - Train loss: 0.698860764503479, Validation loss: 0.6972004175186157
Epoch: 4/300 - Train loss: 0.6973429322242737, Validation loss: 0.6957645416259766
Epoch: 5/300 - Train loss: 0.6958281993865967, Validation loss: 0.6941317319869995
Epoch: 6/300 - Train loss: 0.6943114399909973, Validation loss: 0.6927111148834229
Epoch: 7/300 - Train loss: 0.6927863359451294, Validation loss: 0.6910853385925293
Epoch: 8/300 - Train loss: 0.6912394762039185, Validation loss: 0.6895634531974792
Epoch: 9/300 - Train loss: 0.6896623373031616, Validation loss: 0.6878821849822998
Epoch: 10/300 - Train loss: 0.6880443096160889, Validation loss: 0.6862988471984863
Epoch: 11/300 - Train loss: 0.68639075756073, Validation loss: 0.6844441294670105
Epoch: 12/300 - Train loss: 0.6846977472305298, Validation loss: 0.6828886866569519
Epoch: 13/300 - Train loss: 0.6829620003700256, Validation loss: 0.6809905171394348
Epoch: 14/300 - Train loss: 0.6811844110488892, Validation loss: 0.6791828274726868
Epoch: 15/300 - Train loss: 0.6793545484542847, Validation loss: 0.6774471402168274
Epoch: 16/300 - Train loss: 0.677474319934845, Validation loss: 0.6754422783851624
Epoch: 17/300 - Train loss: 0.6755474209785461, Validation loss: 0.6734287738800049
Epoch: 18/300 - Train loss: 0.6735672950744629, Validation loss: 0.6713475584983826
Epoch: 19/300 - Train loss: 0.6715328097343445, Validation loss: 0.6692526936531067
Epoch: 20/300 - Train loss: 0.6694439053535461, Validation loss: 0.6670013070106506
Epoch: 21/300 - Train loss: 0.667303204536438, Validation loss: 0.6648447513580322
Epoch: 22/300 - Train loss: 0.6651064157485962, Validation loss: 0.662500262260437
Epoch: 23/300 - Train loss: 0.6628523468971252, Validation loss: 0.6603090763092041
Epoch: 24/300 - Train loss: 0.660546064376831, Validation loss: 0.6578683257102966
Epoch: 25/300 - Train loss: 0.6581847667694092, Validation loss: 0.6553924679756165
Epoch: 26/300 - Train loss: 0.6557711958885193, Validation loss: 0.6529566049575806
Epoch: 27/300 - Train loss: 0.6533064246177673, Validation loss: 0.6504026651382446
Epoch: 28/300 - Train loss: 0.6507930159568787, Validation loss: 0.6476776599884033
Epoch: 29/300 - Train loss: 0.6482349634170532, Validation loss: 0.6453048586845398
Epoch: 30/300 - Train loss: 0.6456359624862671, Validation loss: 0.6426613926887512
Epoch: 31/300 - Train loss: 0.6430017948150635, Validation loss: 0.6397808194160461
Epoch: 32/300 - Train loss: 0.6403412222862244, Validation loss: 0.6370871663093567
Epoch: 33/300 - Train loss: 0.637657642364502, Validation loss: 0.6344665288925171
Epoch: 34/300 - Train loss: 0.6349560022354126, Validation loss: 0.6316910982131958
Epoch: 35/300 - Train loss: 0.6322364211082458, Validation loss: 0.6290247440338135
Epoch: 36/300 - Train loss: 0.6295021176338196, Validation loss: 0.6262161731719971
Epoch: 37/300 - Train loss: 0.626756489276886, Validation loss: 0.6232633590698242
Epoch: 38/300 - Train loss: 0.6240035891532898, Validation loss: 0.6206734776496887
Epoch: 39/300 - Train loss: 0.6212472915649414, Validation loss: 0.6179326772689819
Epoch: 40/300 - Train loss: 0.6184889078140259, Validation loss: 0.6149417757987976
Epoch: 41/300 - Train loss: 0.6157308220863342, Validation loss: 0.6122058629989624
Epoch: 42/300 - Train loss: 0.6129794120788574, Validation loss: 0.6095089316368103
Epoch: 43/300 - Train loss: 0.6102379560470581, Validation loss: 0.6068280935287476
Epoch: 44/300 - Train loss: 0.6075112819671631, Validation loss: 0.6039647459983826
Epoch: 45/300 - Train loss: 0.6047994494438171, Validation loss: 0.6013951301574707
Epoch: 46/300 - Train loss: 0.6021063923835754, Validation loss: 0.5989290475845337
Epoch: 47/300 - Train loss: 0.5994331240653992, Validation loss: 0.5958729386329651
Epoch: 48/300 - Train loss: 0.5967822670936584, Validation loss: 0.5932556986808777
Epoch: 49/300 - Train loss: 0.5941570401191711, Validation loss: 0.590522825717926
Epoch: 50/300 - Train loss: 0.5915602445602417, Validation loss: 0.5880652070045471
Epoch: 51/300 - Train loss: 0.588992178440094, Validation loss: 0.5852015018463135
Epoch: 52/300 - Train loss: 0.5864531397819519, Validation loss: 0.5828136205673218
Epoch: 53/300 - Train loss: 0.5839458107948303, Validation loss: 0.5803520679473877
Epoch: 54/300 - Train loss: 0.5814713835716248, Validation loss: 0.5781684517860413
Epoch: 55/300 - Train loss: 0.5790308117866516, Validation loss: 0.5754269957542419
Epoch: 56/300 - Train loss: 0.5766245126724243, Validation loss: 0.5731152892112732
Epoch: 57/300 - Train loss: 0.5742520093917847, Validation loss: 0.570582389831543
Epoch: 58/300 - Train loss: 0.5719141960144043, Validation loss: 0.5680182576179504
Epoch: 59/300 - Train loss: 0.5696105360984802, Validation loss: 0.5659483075141907
Epoch: 60/300 - Train loss: 0.5673425197601318, Validation loss: 0.5639070868492126
Epoch: 61/300 - Train loss: 0.5651102066040039, Validation loss: 0.5619792342185974
Epoch: 62/300 - Train loss: 0.5629131197929382, Validation loss: 0.5593860745429993
Epoch: 63/300 - Train loss: 0.5607507824897766, Validation loss: 0.5573250651359558
Epoch: 64/300 - Train loss: 0.5586223006248474, Validation loss: 0.5553378462791443
Epoch: 65/300 - Train loss: 0.5565266013145447, Validation loss: 0.5536256432533264
Epoch: 66/300 - Train loss: 0.554462730884552, Validation loss: 0.5510957837104797
Epoch: 67/300 - Train loss: 0.5524305701255798, Validation loss: 0.5492480397224426
Epoch: 68/300 - Train loss: 0.5504295229911804, Validation loss: 0.5473060607910156
Epoch: 69/300 - Train loss: 0.5484602451324463, Validation loss: 0.5449185371398926
Epoch: 70/300 - Train loss: 0.5465212464332581, Validation loss: 0.5436378121376038
Epoch: 71/300 - Train loss: 0.5446122288703918, Validation loss: 0.5417905449867249
Epoch: 72/300 - Train loss: 0.5427302718162537, Validation loss: 0.5399889349937439
Epoch: 73/300 - Train loss: 0.5408745408058167, Validation loss: 0.5378523468971252
Epoch: 74/300 - Train loss: 0.5390446186065674, Validation loss: 0.5363803505897522
Epoch: 75/300 - Train loss: 0.5372400879859924, Validation loss: 0.5344799160957336
Epoch: 76/300 - Train loss: 0.535459578037262, Validation loss: 0.5329820513725281
Epoch: 77/300 - Train loss: 0.5337022542953491, Validation loss: 0.5310039520263672
Epoch: 78/300 - Train loss: 0.531965970993042, Validation loss: 0.5296055674552917
Epoch: 79/300 - Train loss: 0.5302501916885376, Validation loss: 0.5282389521598816
Epoch: 80/300 - Train loss: 0.5285559296607971, Validation loss: 0.5263637900352478
Epoch: 81/300 - Train loss: 0.5268824696540833, Validation loss: 0.5249541401863098
Epoch: 82/300 - Train loss: 0.5252282023429871, Validation loss: 0.5231112241744995
Epoch: 83/300 - Train loss: 0.5235917568206787, Validation loss: 0.5214418768882751
Epoch: 84/300 - Train loss: 0.5219733119010925, Validation loss: 0.5211251378059387
Epoch: 85/300 - Train loss: 0.5203709006309509, Validation loss: 0.5188092589378357
Epoch: 86/300 - Train loss: 0.518784761428833, Validation loss: 0.51739901304245
Epoch: 87/300 - Train loss: 0.5172157883644104, Validation loss: 0.5155159831047058
Epoch: 88/300 - Train loss: 0.5156621932983398, Validation loss: 0.5141510963439941
Epoch: 89/300 - Train loss: 0.5141229033470154, Validation loss: 0.5130426287651062
Epoch: 90/300 - Train loss: 0.512597382068634, Validation loss: 0.5107566118240356
Epoch: 91/300 - Train loss: 0.5110839009284973, Validation loss: 0.5095917582511902
Epoch: 92/300 - Train loss: 0.5095831155776978, Validation loss: 0.5079028010368347
Epoch: 93/300 - Train loss: 0.5080941915512085, Validation loss: 0.5069916248321533
Epoch: 94/300 - Train loss: 0.5066166520118713, Validation loss: 0.505736768245697
Epoch: 95/300 - Train loss: 0.5051490664482117, Validation loss: 0.5039639472961426
Epoch: 96/300 - Train loss: 0.5036925673484802, Validation loss: 0.5031019449234009
Epoch: 97/300 - Train loss: 0.5022465586662292, Validation loss: 0.5015004277229309
Epoch: 98/300 - Train loss: 0.5008105039596558, Validation loss: 0.4999803304672241
Epoch: 99/300 - Train loss: 0.4993833601474762, Validation loss: 0.49830129742622375
Epoch: 100/300 - Train loss: 0.4979657232761383, Validation loss: 0.49732235074043274
Epoch: 101/300 - Train loss: 0.49655619263648987, Validation loss: 0.4961239993572235
Epoch: 102/300 - Train loss: 0.4951528310775757, Validation loss: 0.49463096261024475
Epoch: 103/300 - Train loss: 0.4937572181224823, Validation loss: 0.4938359558582306
Epoch: 104/300 - Train loss: 0.4923694133758545, Validation loss: 0.4921380877494812
Epoch: 105/300 - Train loss: 0.4909883439540863, Validation loss: 0.49077877402305603
Epoch: 106/300 - Train loss: 0.4896135926246643, Validation loss: 0.48985958099365234
Epoch: 107/300 - Train loss: 0.48824572563171387, Validation loss: 0.4881851077079773
Epoch: 108/300 - Train loss: 0.4868842661380768, Validation loss: 0.48646867275238037
Epoch: 109/300 - Train loss: 0.48552995920181274, Validation loss: 0.48634669184684753
Epoch: 110/300 - Train loss: 0.4841826856136322, Validation loss: 0.48446595668792725
Epoch: 111/300 - Train loss: 0.48283976316452026, Validation loss: 0.48342785239219666
Epoch: 112/300 - Train loss: 0.4815017580986023, Validation loss: 0.48150375485420227
Epoch: 113/300 - Train loss: 0.4801693260669708, Validation loss: 0.4810048043727875
Epoch: 114/300 - Train loss: 0.4788428843021393, Validation loss: 0.47914057970046997
Epoch: 115/300 - Train loss: 0.4775207042694092, Validation loss: 0.47790268063545227
Epoch: 116/300 - Train loss: 0.4762037396430969, Validation loss: 0.4769212603569031
Epoch: 117/300 - Train loss: 0.4748912751674652, Validation loss: 0.4755763113498688
Epoch: 118/300 - Train loss: 0.4735824763774872, Validation loss: 0.47429004311561584
Epoch: 119/300 - Train loss: 0.4722762107849121, Validation loss: 0.4731692969799042
Epoch: 120/300 - Train loss: 0.4709753096103668, Validation loss: 0.4717389941215515
Epoch: 121/300 - Train loss: 0.4696822762489319, Validation loss: 0.47030308842658997
Epoch: 122/300 - Train loss: 0.4683964252471924, Validation loss: 0.46928852796554565
Epoch: 123/300 - Train loss: 0.46711477637290955, Validation loss: 0.4678761065006256
Epoch: 124/300 - Train loss: 0.4658403992652893, Validation loss: 0.46707800030708313
Epoch: 125/300 - Train loss: 0.46457117795944214, Validation loss: 0.4653815031051636
Epoch: 126/300 - Train loss: 0.46330586075782776, Validation loss: 0.4643908441066742
Epoch: 127/300 - Train loss: 0.4620445668697357, Validation loss: 0.463382363319397
Epoch: 128/300 - Train loss: 0.46078765392303467, Validation loss: 0.46189725399017334
Epoch: 129/300 - Train loss: 0.4595361649990082, Validation loss: 0.4607468247413635
Epoch: 130/300 - Train loss: 0.4582919180393219, Validation loss: 0.4598160684108734
Epoch: 131/300 - Train loss: 0.4570533335208893, Validation loss: 0.458079993724823
Epoch: 132/300 - Train loss: 0.4558200538158417, Validation loss: 0.4567442834377289
Epoch: 133/300 - Train loss: 0.45459234714508057, Validation loss: 0.4556118845939636
Epoch: 134/300 - Train loss: 0.4533722996711731, Validation loss: 0.4540974497795105
Epoch: 135/300 - Train loss: 0.4521605670452118, Validation loss: 0.45341333746910095
Epoch: 136/300 - Train loss: 0.4509583115577698, Validation loss: 0.4525062143802643
Epoch: 137/300 - Train loss: 0.4497656226158142, Validation loss: 0.45126256346702576
Epoch: 138/300 - Train loss: 0.4485815763473511, Validation loss: 0.4501075744628906
Epoch: 139/300 - Train loss: 0.44740772247314453, Validation loss: 0.44917240738868713
Epoch: 140/300 - Train loss: 0.4462425708770752, Validation loss: 0.44710633158683777
Epoch: 141/300 - Train loss: 0.44508689641952515, Validation loss: 0.4470387101173401
Epoch: 142/300 - Train loss: 0.44393935799598694, Validation loss: 0.4460037648677826
Epoch: 143/300 - Train loss: 0.4427989721298218, Validation loss: 0.444519966840744
Epoch: 144/300 - Train loss: 0.44166624546051025, Validation loss: 0.44322261214256287
Epoch: 145/300 - Train loss: 0.44054144620895386, Validation loss: 0.4421178698539734
Epoch: 146/300 - Train loss: 0.4394264221191406, Validation loss: 0.4413444697856903
Epoch: 147/300 - Train loss: 0.4383184611797333, Validation loss: 0.4401896297931671
Epoch: 148/300 - Train loss: 0.43721938133239746, Validation loss: 0.4390644431114197
Epoch: 149/300 - Train loss: 0.43612906336784363, Validation loss: 0.4380210041999817
Epoch: 150/300 - Train loss: 0.43504664301872253, Validation loss: 0.4368366301059723
Epoch: 151/300 - Train loss: 0.4339721202850342, Validation loss: 0.43593788146972656
Epoch: 152/300 - Train loss: 0.43290528655052185, Validation loss: 0.43502363562583923
Epoch: 153/300 - Train loss: 0.4318457841873169, Validation loss: 0.4339368939399719
Epoch: 154/300 - Train loss: 0.43079301714897156, Validation loss: 0.4327927827835083
Epoch: 155/300 - Train loss: 0.4297485947608948, Validation loss: 0.4322359263896942
Epoch: 156/300 - Train loss: 0.42871230840682983, Validation loss: 0.4311949610710144
Epoch: 157/300 - Train loss: 0.42768359184265137, Validation loss: 0.4302220642566681
Epoch: 158/300 - Train loss: 0.42666199803352356, Validation loss: 0.4284440875053406
Epoch: 159/300 - Train loss: 0.42564740777015686, Validation loss: 0.42827939987182617
Epoch: 160/300 - Train loss: 0.42463982105255127, Validation loss: 0.42696627974510193
Epoch: 161/300 - Train loss: 0.42363905906677246, Validation loss: 0.425508052110672
Epoch: 162/300 - Train loss: 0.4226457178592682, Validation loss: 0.42473703622817993
Epoch: 163/300 - Train loss: 0.42166030406951904, Validation loss: 0.42413175106048584
Epoch: 164/300 - Train loss: 0.4206826686859131, Validation loss: 0.4229212701320648
Epoch: 165/300 - Train loss: 0.41971343755722046, Validation loss: 0.4223766624927521
Epoch: 166/300 - Train loss: 0.41875195503234863, Validation loss: 0.4217059016227722
Epoch: 167/300 - Train loss: 0.4177969992160797, Validation loss: 0.4207896590232849
Epoch: 168/300 - Train loss: 0.416849821805954, Validation loss: 0.4198140799999237
Epoch: 169/300 - Train loss: 0.41591012477874756, Validation loss: 0.41860243678092957
Epoch: 170/300 - Train loss: 0.41497835516929626, Validation loss: 0.4179246127605438
Epoch: 171/300 - Train loss: 0.4140538275241852, Validation loss: 0.4169634282588959
Epoch: 172/300 - Train loss: 0.41313663125038147, Validation loss: 0.41566577553749084
Epoch: 173/300 - Train loss: 0.41222691535949707, Validation loss: 0.4152179956436157
Epoch: 174/300 - Train loss: 0.411324143409729, Validation loss: 0.4145435094833374
Epoch: 175/300 - Train loss: 0.41042813658714294, Validation loss: 0.4135914742946625
Epoch: 176/300 - Train loss: 0.409539133310318, Validation loss: 0.4125620424747467
Epoch: 177/300 - Train loss: 0.4086570739746094, Validation loss: 0.41200804710388184
Epoch: 178/300 - Train loss: 0.40778204798698425, Validation loss: 0.41082048416137695
Epoch: 179/300 - Train loss: 0.40691378712654114, Validation loss: 0.4103475511074066
Epoch: 180/300 - Train loss: 0.40605202317237854, Validation loss: 0.4095815122127533
Epoch: 181/300 - Train loss: 0.4051973521709442, Validation loss: 0.40830644965171814
Epoch: 182/300 - Train loss: 0.4043499231338501, Validation loss: 0.40804681181907654
Epoch: 183/300 - Train loss: 0.40351009368896484, Validation loss: 0.40729793906211853
Epoch: 184/300 - Train loss: 0.4026780426502228, Validation loss: 0.40661048889160156
Epoch: 185/300 - Train loss: 0.4018532335758209, Validation loss: 0.4056893587112427
Epoch: 186/300 - Train loss: 0.40103524923324585, Validation loss: 0.40534353256225586
Epoch: 187/300 - Train loss: 0.4002244174480438, Validation loss: 0.4042617082595825
Epoch: 188/300 - Train loss: 0.39942049980163574, Validation loss: 0.40332236886024475
Epoch: 189/300 - Train loss: 0.39862295985221863, Validation loss: 0.40269166231155396
Epoch: 190/300 - Train loss: 0.3978314697742462, Validation loss: 0.4019789695739746
Epoch: 191/300 - Train loss: 0.3970463275909424, Validation loss: 0.4009518623352051
Epoch: 192/300 - Train loss: 0.39626872539520264, Validation loss: 0.4004819691181183
Epoch: 193/300 - Train loss: 0.39549723267555237, Validation loss: 0.39951857924461365
Epoch: 194/300 - Train loss: 0.394731342792511, Validation loss: 0.39891648292541504
Epoch: 195/300 - Train loss: 0.39397257566452026, Validation loss: 0.39805975556373596
Epoch: 196/300 - Train loss: 0.3932206630706787, Validation loss: 0.3979032635688782
Epoch: 197/300 - Train loss: 0.39247506856918335, Validation loss: 0.39736005663871765
Epoch: 198/300 - Train loss: 0.3917351961135864, Validation loss: 0.39627960324287415
Epoch: 199/300 - Train loss: 0.39100202918052673, Validation loss: 0.39542850852012634
Epoch: 200/300 - Train loss: 0.3902760446071625, Validation loss: 0.3952333927154541
Epoch: 201/300 - Train loss: 0.38955679535865784, Validation loss: 0.39412763714790344
Epoch: 202/300 - Train loss: 0.3888436555862427, Validation loss: 0.3933606743812561
Epoch: 203/300 - Train loss: 0.3881368935108185, Validation loss: 0.3931150436401367
Epoch: 204/300 - Train loss: 0.3874366283416748, Validation loss: 0.3925322890281677
Epoch: 205/300 - Train loss: 0.3867429494857788, Validation loss: 0.3917054235935211
Epoch: 206/300 - Train loss: 0.38605642318725586, Validation loss: 0.39041003584861755
Epoch: 207/300 - Train loss: 0.38537535071372986, Validation loss: 0.3906444311141968
Epoch: 208/300 - Train loss: 0.38469892740249634, Validation loss: 0.39036521315574646
Epoch: 209/300 - Train loss: 0.38402682542800903, Validation loss: 0.38880258798599243
Epoch: 210/300 - Train loss: 0.3833604156970978, Validation loss: 0.3887672424316406
Epoch: 211/300 - Train loss: 0.3827003836631775, Validation loss: 0.3876481056213379
Epoch: 212/300 - Train loss: 0.38204580545425415, Validation loss: 0.3874650299549103
Epoch: 213/300 - Train loss: 0.3813967704772949, Validation loss: 0.3866179287433624
Epoch: 214/300 - Train loss: 0.3807530105113983, Validation loss: 0.38618794083595276
Epoch: 215/300 - Train loss: 0.380113810300827, Validation loss: 0.3853588402271271
Epoch: 216/300 - Train loss: 0.379480242729187, Validation loss: 0.3852556347846985
Epoch: 217/300 - Train loss: 0.3788524270057678, Validation loss: 0.38458263874053955
Epoch: 218/300 - Train loss: 0.37823015451431274, Validation loss: 0.3840368390083313
