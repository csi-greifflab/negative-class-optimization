Epoch: 1/100 - Train loss: 0.6974552869796753, Validation loss: 0.6944549679756165
Epoch: 2/100 - Train loss: 0.6949151158332825, Validation loss: 0.6920536160469055
Epoch: 3/100 - Train loss: 0.6924875974655151, Validation loss: 0.6898074150085449
Epoch: 4/100 - Train loss: 0.6901502013206482, Validation loss: 0.687545895576477
Epoch: 5/100 - Train loss: 0.6878604888916016, Validation loss: 0.6853548288345337
Epoch: 6/100 - Train loss: 0.6855732798576355, Validation loss: 0.6831212043762207
Epoch: 7/100 - Train loss: 0.6832424402236938, Validation loss: 0.6807811856269836
Epoch: 8/100 - Train loss: 0.6808221340179443, Validation loss: 0.678281843662262
Epoch: 9/100 - Train loss: 0.6782783269882202, Validation loss: 0.6757148504257202
Epoch: 10/100 - Train loss: 0.6755870580673218, Validation loss: 0.6729415059089661
Epoch: 11/100 - Train loss: 0.6727268695831299, Validation loss: 0.669994056224823
Epoch: 12/100 - Train loss: 0.6696900725364685, Validation loss: 0.6668323278427124
Epoch: 13/100 - Train loss: 0.6664665937423706, Validation loss: 0.6635481715202332
Epoch: 14/100 - Train loss: 0.6630547046661377, Validation loss: 0.6600707173347473
Epoch: 15/100 - Train loss: 0.6594533324241638, Validation loss: 0.6563275456428528
Epoch: 16/100 - Train loss: 0.655677080154419, Validation loss: 0.6524210572242737
Epoch: 17/100 - Train loss: 0.6517340540885925, Validation loss: 0.6484023928642273
Epoch: 18/100 - Train loss: 0.6476324796676636, Validation loss: 0.644391655921936
Epoch: 19/100 - Train loss: 0.6433932185173035, Validation loss: 0.6400891542434692
Epoch: 20/100 - Train loss: 0.6390363574028015, Validation loss: 0.63571697473526
Epoch: 21/100 - Train loss: 0.6345741152763367, Validation loss: 0.6312748193740845
Epoch: 22/100 - Train loss: 0.6300239562988281, Validation loss: 0.6267741918563843
Epoch: 23/100 - Train loss: 0.6254053711891174, Validation loss: 0.6222782135009766
Epoch: 24/100 - Train loss: 0.6207396388053894, Validation loss: 0.6176381707191467
Epoch: 25/100 - Train loss: 0.6160386204719543, Validation loss: 0.6129568815231323
Epoch: 26/100 - Train loss: 0.6113131642341614, Validation loss: 0.6083781123161316
Epoch: 27/100 - Train loss: 0.6065723896026611, Validation loss: 0.6036359071731567
Epoch: 28/100 - Train loss: 0.601821780204773, Validation loss: 0.5991076827049255
Epoch: 29/100 - Train loss: 0.5970700979232788, Validation loss: 0.5944545865058899
Epoch: 30/100 - Train loss: 0.5923181772232056, Validation loss: 0.5898410677909851
Epoch: 31/100 - Train loss: 0.5875676870346069, Validation loss: 0.5850096344947815
Epoch: 32/100 - Train loss: 0.5828230381011963, Validation loss: 0.5805160999298096
Epoch: 33/100 - Train loss: 0.5780873894691467, Validation loss: 0.5756072402000427
Epoch: 34/100 - Train loss: 0.5733653903007507, Validation loss: 0.5711798071861267
Epoch: 35/100 - Train loss: 0.5686612725257874, Validation loss: 0.5665042400360107
Epoch: 36/100 - Train loss: 0.5639786720275879, Validation loss: 0.5620134472846985
Epoch: 37/100 - Train loss: 0.5593216419219971, Validation loss: 0.5570456385612488
Epoch: 38/100 - Train loss: 0.5546945333480835, Validation loss: 0.552445113658905
Epoch: 39/100 - Train loss: 0.5501015782356262, Validation loss: 0.5482558012008667
Epoch: 40/100 - Train loss: 0.5455461144447327, Validation loss: 0.5436419248580933
Epoch: 41/100 - Train loss: 0.5410327315330505, Validation loss: 0.5392712950706482
Epoch: 42/100 - Train loss: 0.5365651249885559, Validation loss: 0.5342554450035095
Epoch: 43/100 - Train loss: 0.5321459770202637, Validation loss: 0.5302999019622803
Epoch: 44/100 - Train loss: 0.5277780294418335, Validation loss: 0.5258489847183228
Epoch: 45/100 - Train loss: 0.523464560508728, Validation loss: 0.5215804576873779
Epoch: 46/100 - Train loss: 0.5192078948020935, Validation loss: 0.5171481966972351
Epoch: 47/100 - Train loss: 0.5150098204612732, Validation loss: 0.5132735967636108
Epoch: 48/100 - Train loss: 0.5108721852302551, Validation loss: 0.5086269974708557
Epoch: 49/100 - Train loss: 0.506796658039093, Validation loss: 0.5050561428070068
Epoch: 50/100 - Train loss: 0.5027851462364197, Validation loss: 0.5010937452316284
Epoch: 51/100 - Train loss: 0.4988389313220978, Validation loss: 0.49708518385887146
Epoch: 52/100 - Train loss: 0.4949590563774109, Validation loss: 0.49307575821876526
Epoch: 53/100 - Train loss: 0.49114716053009033, Validation loss: 0.4899587333202362
Epoch: 54/100 - Train loss: 0.4874041676521301, Validation loss: 0.48613423109054565
Epoch: 55/100 - Train loss: 0.48373109102249146, Validation loss: 0.4819507300853729
Epoch: 56/100 - Train loss: 0.48012861609458923, Validation loss: 0.4782305657863617
Epoch: 57/100 - Train loss: 0.47659775614738464, Validation loss: 0.4753263592720032
Epoch: 58/100 - Train loss: 0.4731391370296478, Validation loss: 0.4713909327983856
Epoch: 59/100 - Train loss: 0.4697527587413788, Validation loss: 0.4681878089904785
Epoch: 60/100 - Train loss: 0.4664390981197357, Validation loss: 0.46515101194381714
Epoch: 61/100 - Train loss: 0.4631976783275604, Validation loss: 0.461536169052124
Epoch: 62/100 - Train loss: 0.46002843976020813, Validation loss: 0.4587867558002472
Epoch: 63/100 - Train loss: 0.4569312334060669, Validation loss: 0.45542776584625244
Epoch: 64/100 - Train loss: 0.4539060592651367, Validation loss: 0.45227760076522827
Epoch: 65/100 - Train loss: 0.45095163583755493, Validation loss: 0.44957712292671204
Epoch: 66/100 - Train loss: 0.44806739687919617, Validation loss: 0.4466387927532196
Epoch: 67/100 - Train loss: 0.4452531337738037, Validation loss: 0.44370999932289124
Epoch: 68/100 - Train loss: 0.4425078332424164, Validation loss: 0.441261887550354
Epoch: 69/100 - Train loss: 0.4398302137851715, Validation loss: 0.4386458694934845
Epoch: 70/100 - Train loss: 0.4372193515300751, Validation loss: 0.43572360277175903
Epoch: 71/100 - Train loss: 0.434674471616745, Validation loss: 0.4340956509113312
Epoch: 72/100 - Train loss: 0.4321941137313843, Validation loss: 0.431379109621048
Epoch: 73/100 - Train loss: 0.4297771751880646, Validation loss: 0.42847755551338196
Epoch: 74/100 - Train loss: 0.4274222254753113, Validation loss: 0.4259544909000397
Epoch: 75/100 - Train loss: 0.425128310918808, Validation loss: 0.42403504252433777
Epoch: 76/100 - Train loss: 0.4228939116001129, Validation loss: 0.4211142957210541
Epoch: 77/100 - Train loss: 0.4207181930541992, Validation loss: 0.41960352659225464
Epoch: 78/100 - Train loss: 0.41859859228134155, Validation loss: 0.41701042652130127
Epoch: 79/100 - Train loss: 0.4165346026420593, Validation loss: 0.41522565484046936
Epoch: 80/100 - Train loss: 0.41452404856681824, Validation loss: 0.4134255051612854
Epoch: 81/100 - Train loss: 0.41256555914878845, Validation loss: 0.41112589836120605
Epoch: 82/100 - Train loss: 0.4106578230857849, Validation loss: 0.4090544879436493
Epoch: 83/100 - Train loss: 0.4087996184825897, Validation loss: 0.40786662697792053
Epoch: 84/100 - Train loss: 0.4069891571998596, Validation loss: 0.40561044216156006
Epoch: 85/100 - Train loss: 0.405224472284317, Validation loss: 0.4038804769515991
Epoch: 86/100 - Train loss: 0.40350472927093506, Validation loss: 0.4025944173336029
Epoch: 87/100 - Train loss: 0.40182915329933167, Validation loss: 0.4003946781158447
Epoch: 88/100 - Train loss: 0.4001966714859009, Validation loss: 0.39924871921539307
Epoch: 89/100 - Train loss: 0.3986058533191681, Validation loss: 0.3974913954734802
Epoch: 90/100 - Train loss: 0.39705365896224976, Validation loss: 0.39625856280326843
Epoch: 91/100 - Train loss: 0.39553970098495483, Validation loss: 0.3937930464744568
Epoch: 92/100 - Train loss: 0.3940623998641968, Validation loss: 0.3926111161708832
Epoch: 93/100 - Train loss: 0.39262115955352783, Validation loss: 0.39132341742515564
Epoch: 94/100 - Train loss: 0.3912155032157898, Validation loss: 0.3895621597766876
Epoch: 95/100 - Train loss: 0.38984331488609314, Validation loss: 0.38838446140289307
Epoch: 96/100 - Train loss: 0.38850414752960205, Validation loss: 0.3865460455417633
Epoch: 97/100 - Train loss: 0.387195348739624, Validation loss: 0.3861900568008423
Epoch: 98/100 - Train loss: 0.385916531085968, Validation loss: 0.3840971887111664
Epoch: 99/100 - Train loss: 0.38466793298721313, Validation loss: 0.38344892859458923
Epoch: 100/100 - Train loss: 0.38344821333885193, Validation loss: 0.38151416182518005
Epoch: 1/300 - Train loss: 0.6945858001708984, Validation loss: 0.6935361623764038
Epoch: 2/300 - Train loss: 0.6921850442886353, Validation loss: 0.6914492249488831
Epoch: 3/300 - Train loss: 0.6898209452629089, Validation loss: 0.6889758706092834
Epoch: 4/300 - Train loss: 0.6874340772628784, Validation loss: 0.6866007447242737
Epoch: 5/300 - Train loss: 0.6849608421325684, Validation loss: 0.6840435266494751
Epoch: 6/300 - Train loss: 0.682352602481842, Validation loss: 0.6814810633659363
Epoch: 7/300 - Train loss: 0.6795812845230103, Validation loss: 0.6786105632781982
Epoch: 8/300 - Train loss: 0.6766223907470703, Validation loss: 0.675483226776123
Epoch: 9/300 - Train loss: 0.6734662055969238, Validation loss: 0.6721821427345276
Epoch: 10/300 - Train loss: 0.6701213717460632, Validation loss: 0.6688129305839539
Epoch: 11/300 - Train loss: 0.666592538356781, Validation loss: 0.6652451157569885
Epoch: 12/300 - Train loss: 0.6628983020782471, Validation loss: 0.661429226398468
Epoch: 13/300 - Train loss: 0.659056544303894, Validation loss: 0.6575923562049866
Epoch: 14/300 - Train loss: 0.655084490776062, Validation loss: 0.6536991596221924
Epoch: 15/300 - Train loss: 0.6510012149810791, Validation loss: 0.6496891975402832
Epoch: 16/300 - Train loss: 0.6468336582183838, Validation loss: 0.6452986598014832
Epoch: 17/300 - Train loss: 0.6425992250442505, Validation loss: 0.6411212086677551
Epoch: 18/300 - Train loss: 0.6383156776428223, Validation loss: 0.6369581818580627
Epoch: 19/300 - Train loss: 0.6339904069900513, Validation loss: 0.6326438784599304
Epoch: 20/300 - Train loss: 0.6296335458755493, Validation loss: 0.6283988356590271
Epoch: 21/300 - Train loss: 0.6252535581588745, Validation loss: 0.6239790320396423
Epoch: 22/300 - Train loss: 0.6208602786064148, Validation loss: 0.6201203465461731
Epoch: 23/300 - Train loss: 0.6164652705192566, Validation loss: 0.6155667304992676
Epoch: 24/300 - Train loss: 0.6120741963386536, Validation loss: 0.6112592816352844
Epoch: 25/300 - Train loss: 0.6076914072036743, Validation loss: 0.6068666577339172
Epoch: 26/300 - Train loss: 0.6033221483230591, Validation loss: 0.6025104522705078
Epoch: 27/300 - Train loss: 0.5989685654640198, Validation loss: 0.5981773138046265
Epoch: 28/300 - Train loss: 0.5946330428123474, Validation loss: 0.5942352414131165
Epoch: 29/300 - Train loss: 0.5903180241584778, Validation loss: 0.589625895023346
Epoch: 30/300 - Train loss: 0.5860247611999512, Validation loss: 0.5853880047798157
Epoch: 31/300 - Train loss: 0.5817537903785706, Validation loss: 0.5813775062561035
Epoch: 32/300 - Train loss: 0.577505886554718, Validation loss: 0.5772798657417297
Epoch: 33/300 - Train loss: 0.5732824802398682, Validation loss: 0.573018491268158
Epoch: 34/300 - Train loss: 0.5690844655036926, Validation loss: 0.5689464807510376
Epoch: 35/300 - Train loss: 0.5649147629737854, Validation loss: 0.5647757053375244
Epoch: 36/300 - Train loss: 0.5607753396034241, Validation loss: 0.5607497692108154
Epoch: 37/300 - Train loss: 0.5566675662994385, Validation loss: 0.5565083026885986
Epoch: 38/300 - Train loss: 0.552594006061554, Validation loss: 0.5522510409355164
Epoch: 39/300 - Train loss: 0.5485548377037048, Validation loss: 0.5488008260726929
Epoch: 40/300 - Train loss: 0.5445525050163269, Validation loss: 0.5446634292602539
Epoch: 41/300 - Train loss: 0.5405879020690918, Validation loss: 0.5405016541481018
Epoch: 42/300 - Train loss: 0.5366631150245667, Validation loss: 0.5367354154586792
Epoch: 43/300 - Train loss: 0.5327785611152649, Validation loss: 0.5324622392654419
Epoch: 44/300 - Train loss: 0.5289343595504761, Validation loss: 0.5288958549499512
Epoch: 45/300 - Train loss: 0.5251312851905823, Validation loss: 0.5251224040985107
Epoch: 46/300 - Train loss: 0.5213696360588074, Validation loss: 0.5213779211044312
Epoch: 47/300 - Train loss: 0.5176495909690857, Validation loss: 0.5176377296447754
Epoch: 48/300 - Train loss: 0.5139721632003784, Validation loss: 0.5140808820724487
Epoch: 49/300 - Train loss: 0.5103386044502258, Validation loss: 0.5107471346855164
Epoch: 50/300 - Train loss: 0.5067493319511414, Validation loss: 0.506815493106842
Epoch: 51/300 - Train loss: 0.503206193447113, Validation loss: 0.5031825304031372
Epoch: 52/300 - Train loss: 0.4997086524963379, Validation loss: 0.4998339116573334
Epoch: 53/300 - Train loss: 0.49625805020332336, Validation loss: 0.49659380316734314
Epoch: 54/300 - Train loss: 0.4928557574748993, Validation loss: 0.49314576387405396
Epoch: 55/300 - Train loss: 0.4895016849040985, Validation loss: 0.48976069688796997
Epoch: 56/300 - Train loss: 0.48619675636291504, Validation loss: 0.48629030585289
Epoch: 57/300 - Train loss: 0.4829409122467041, Validation loss: 0.48300275206565857
Epoch: 58/300 - Train loss: 0.4797343611717224, Validation loss: 0.47978270053863525
Epoch: 59/300 - Train loss: 0.4765777289867401, Validation loss: 0.47702252864837646
Epoch: 60/300 - Train loss: 0.473471462726593, Validation loss: 0.47410848736763
Epoch: 61/300 - Train loss: 0.4704151451587677, Validation loss: 0.47053974866867065
Epoch: 62/300 - Train loss: 0.4674094617366791, Validation loss: 0.46780797839164734
Epoch: 63/300 - Train loss: 0.46445420384407043, Validation loss: 0.46449947357177734
Epoch: 64/300 - Train loss: 0.4615492522716522, Validation loss: 0.46177396178245544
Epoch: 65/300 - Train loss: 0.45869407057762146, Validation loss: 0.45870792865753174
Epoch: 66/300 - Train loss: 0.45588886737823486, Validation loss: 0.456031858921051
Epoch: 67/300 - Train loss: 0.45313289761543274, Validation loss: 0.453599214553833
Epoch: 68/300 - Train loss: 0.45042625069618225, Validation loss: 0.45066213607788086
Epoch: 69/300 - Train loss: 0.4477686583995819, Validation loss: 0.4478728473186493
Epoch: 70/300 - Train loss: 0.44515952467918396, Validation loss: 0.4450205862522125
Epoch: 71/300 - Train loss: 0.44259902834892273, Validation loss: 0.44286060333251953
Epoch: 72/300 - Train loss: 0.44008609652519226, Validation loss: 0.44063469767570496
Epoch: 73/300 - Train loss: 0.437620609998703, Validation loss: 0.4376477301120758
Epoch: 74/300 - Train loss: 0.43520230054855347, Validation loss: 0.43536630272865295
Epoch: 75/300 - Train loss: 0.4328303635120392, Validation loss: 0.43300527334213257
Epoch: 76/300 - Train loss: 0.4305044114589691, Validation loss: 0.43067288398742676
Epoch: 77/300 - Train loss: 0.42822349071502686, Validation loss: 0.42839834094047546
Epoch: 78/300 - Train loss: 0.4259866774082184, Validation loss: 0.4259188771247864
Epoch: 79/300 - Train loss: 0.4237934947013855, Validation loss: 0.4240618050098419
Epoch: 80/300 - Train loss: 0.4216427803039551, Validation loss: 0.42170390486717224
Epoch: 81/300 - Train loss: 0.4195336103439331, Validation loss: 0.41896066069602966
Epoch: 82/300 - Train loss: 0.4174656569957733, Validation loss: 0.4174020290374756
Epoch: 83/300 - Train loss: 0.4154384434223175, Validation loss: 0.41532212495803833
Epoch: 84/300 - Train loss: 0.4134501814842224, Validation loss: 0.41367486119270325
Epoch: 85/300 - Train loss: 0.4114994406700134, Validation loss: 0.41129645705223083
Epoch: 86/300 - Train loss: 0.4095860421657562, Validation loss: 0.4093608558177948
Epoch: 87/300 - Train loss: 0.4077097177505493, Validation loss: 0.40783143043518066
Epoch: 88/300 - Train loss: 0.4058695137500763, Validation loss: 0.40588313341140747
Epoch: 89/300 - Train loss: 0.40406474471092224, Validation loss: 0.4036831557750702
Epoch: 90/300 - Train loss: 0.4022946357727051, Validation loss: 0.4022969901561737
Epoch: 91/300 - Train loss: 0.4005587100982666, Validation loss: 0.4006977081298828
Epoch: 92/300 - Train loss: 0.39885708689689636, Validation loss: 0.3990091383457184
Epoch: 93/300 - Train loss: 0.3971891403198242, Validation loss: 0.39697352051734924
Epoch: 94/300 - Train loss: 0.3955535888671875, Validation loss: 0.39590510725975037
Epoch: 95/300 - Train loss: 0.3939487934112549, Validation loss: 0.39371925592422485
Epoch: 96/300 - Train loss: 0.39237353205680847, Validation loss: 0.39166775345802307
Epoch: 97/300 - Train loss: 0.3908267617225647, Validation loss: 0.39065849781036377
Epoch: 98/300 - Train loss: 0.3893076181411743, Validation loss: 0.3888363540172577
Epoch: 99/300 - Train loss: 0.38781630992889404, Validation loss: 0.38743701577186584
Epoch: 100/300 - Train loss: 0.3863521218299866, Validation loss: 0.3861144781112671
Epoch: 101/300 - Train loss: 0.3849142789840698, Validation loss: 0.3851642906665802
Epoch: 102/300 - Train loss: 0.3835010230541229, Validation loss: 0.38305068016052246
Epoch: 103/300 - Train loss: 0.3821110129356384, Validation loss: 0.3817126452922821
Epoch: 104/300 - Train loss: 0.38074547052383423, Validation loss: 0.3801938593387604
Epoch: 105/300 - Train loss: 0.3794032335281372, Validation loss: 0.37912315130233765
Epoch: 106/300 - Train loss: 0.37808290123939514, Validation loss: 0.3775050640106201
Epoch: 107/300 - Train loss: 0.3767847418785095, Validation loss: 0.37626275420188904
Epoch: 108/300 - Train loss: 0.37550729513168335, Validation loss: 0.3752409815788269
Epoch: 109/300 - Train loss: 0.3742506802082062, Validation loss: 0.3738696873188019
Epoch: 110/300 - Train loss: 0.3730146288871765, Validation loss: 0.37231168150901794
Epoch: 111/300 - Train loss: 0.37179794907569885, Validation loss: 0.3710532486438751
Epoch: 112/300 - Train loss: 0.37060075998306274, Validation loss: 0.3696233630180359
Epoch: 113/300 - Train loss: 0.3694210350513458, Validation loss: 0.368712842464447
Epoch: 114/300 - Train loss: 0.3682582974433899, Validation loss: 0.3678206205368042
Epoch: 115/300 - Train loss: 0.36711370944976807, Validation loss: 0.36639851331710815
Epoch: 116/300 - Train loss: 0.36598876118659973, Validation loss: 0.36505502462387085
Epoch: 117/300 - Train loss: 0.36488163471221924, Validation loss: 0.3636787533760071
Epoch: 118/300 - Train loss: 0.363791823387146, Validation loss: 0.36285296082496643
Epoch: 119/300 - Train loss: 0.36271917819976807, Validation loss: 0.3620830476284027
Epoch: 120/300 - Train loss: 0.3616626560688019, Validation loss: 0.3605845272541046
Epoch: 121/300 - Train loss: 0.3606223165988922, Validation loss: 0.359155535697937
Epoch: 122/300 - Train loss: 0.35959696769714355, Validation loss: 0.35876917839050293
Epoch: 123/300 - Train loss: 0.3585861027240753, Validation loss: 0.35807034373283386
Epoch: 124/300 - Train loss: 0.3575885593891144, Validation loss: 0.35652053356170654
Epoch: 125/300 - Train loss: 0.3566056787967682, Validation loss: 0.3551015853881836
Epoch: 126/300 - Train loss: 0.3556366562843323, Validation loss: 0.35453376173973083
Epoch: 127/300 - Train loss: 0.3546796441078186, Validation loss: 0.35406747460365295
Epoch: 128/300 - Train loss: 0.3537350594997406, Validation loss: 0.35270440578460693
Epoch: 129/300 - Train loss: 0.3528023064136505, Validation loss: 0.3512113094329834
Epoch: 130/300 - Train loss: 0.3518814742565155, Validation loss: 0.3506113290786743
Epoch: 131/300 - Train loss: 0.3509727418422699, Validation loss: 0.34977978467941284
Epoch: 132/300 - Train loss: 0.3500749170780182, Validation loss: 0.3493936061859131
Epoch: 133/300 - Train loss: 0.34918835759162903, Validation loss: 0.3484175205230713
Epoch: 134/300 - Train loss: 0.34831225872039795, Validation loss: 0.347225546836853
Epoch: 135/300 - Train loss: 0.3474474549293518, Validation loss: 0.34577006101608276
Epoch: 136/300 - Train loss: 0.3465941846370697, Validation loss: 0.345121294260025
Epoch: 137/300 - Train loss: 0.3457523584365845, Validation loss: 0.344343364238739
Epoch: 138/300 - Train loss: 0.34492164850234985, Validation loss: 0.34394678473472595
Epoch: 139/300 - Train loss: 0.3441023528575897, Validation loss: 0.3425740897655487
Epoch: 140/300 - Train loss: 0.3432926833629608, Validation loss: 0.34216323494911194
Epoch: 141/300 - Train loss: 0.34249210357666016, Validation loss: 0.3411155343055725
Epoch: 142/300 - Train loss: 0.34170201420783997, Validation loss: 0.34062644839286804
Epoch: 143/300 - Train loss: 0.3409223258495331, Validation loss: 0.3397146761417389
Epoch: 144/300 - Train loss: 0.34015247225761414, Validation loss: 0.33918845653533936
Epoch: 145/300 - Train loss: 0.33939263224601746, Validation loss: 0.33857569098472595
Epoch: 146/300 - Train loss: 0.33864206075668335, Validation loss: 0.33686089515686035
Epoch: 147/300 - Train loss: 0.3379005193710327, Validation loss: 0.3366376459598541
Epoch: 148/300 - Train loss: 0.3371679186820984, Validation loss: 0.3361023962497711
Epoch: 149/300 - Train loss: 0.33644357323646545, Validation loss: 0.33535587787628174
Epoch: 150/300 - Train loss: 0.3357279598712921, Validation loss: 0.3341479003429413
Epoch: 151/300 - Train loss: 0.33502086997032166, Validation loss: 0.33389586210250854
Epoch: 152/300 - Train loss: 0.3343225121498108, Validation loss: 0.3330879211425781
Epoch: 153/300 - Train loss: 0.33363205194473267, Validation loss: 0.3320784568786621
Epoch: 154/300 - Train loss: 0.3329489827156067, Validation loss: 0.3321458399295807
Epoch: 155/300 - Train loss: 0.33227407932281494, Validation loss: 0.3313150107860565
Epoch: 156/300 - Train loss: 0.33160683512687683, Validation loss: 0.3298587501049042
Epoch: 157/300 - Train loss: 0.3309471011161804, Validation loss: 0.3294672966003418
Epoch: 158/300 - Train loss: 0.3302944004535675, Validation loss: 0.3290060758590698
Epoch: 159/300 - Train loss: 0.32964929938316345, Validation loss: 0.32820579409599304
Epoch: 160/300 - Train loss: 0.3290112316608429, Validation loss: 0.3272928297519684
Epoch: 161/300 - Train loss: 0.32838013768196106, Validation loss: 0.32696834206581116
Epoch: 162/300 - Train loss: 0.32775580883026123, Validation loss: 0.3263290524482727
Epoch: 163/300 - Train loss: 0.3271385431289673, Validation loss: 0.32682251930236816
Epoch: 164/300 - Train loss: 0.3265278935432434, Validation loss: 0.32550856471061707
Epoch: 165/300 - Train loss: 0.3259236216545105, Validation loss: 0.32471612095832825
Epoch: 166/300 - Train loss: 0.32532498240470886, Validation loss: 0.3239162564277649
Epoch: 167/300 - Train loss: 0.3247320353984833, Validation loss: 0.32325801253318787
Epoch: 168/300 - Train loss: 0.32414495944976807, Validation loss: 0.32296454906463623
Epoch: 169/300 - Train loss: 0.32356390357017517, Validation loss: 0.32189667224884033
Epoch: 170/300 - Train loss: 0.32298868894577026, Validation loss: 0.3217794895172119
Epoch: 171/300 - Train loss: 0.3224189579486847, Validation loss: 0.3213392198085785
Epoch: 172/300 - Train loss: 0.3218547999858856, Validation loss: 0.32026785612106323
Epoch: 173/300 - Train loss: 0.32129600644111633, Validation loss: 0.31968939304351807
Epoch: 174/300 - Train loss: 0.3207421898841858, Validation loss: 0.3194926381111145
Epoch: 175/300 - Train loss: 0.3201932907104492, Validation loss: 0.3194025456905365
