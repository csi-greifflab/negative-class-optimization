Epoch: 1/300 - Train loss: 0.6937780976295471, Validation loss: 0.6922194957733154
Epoch: 2/300 - Train loss: 0.6921032071113586, Validation loss: 0.6905816197395325
Epoch: 3/300 - Train loss: 0.6904429197311401, Validation loss: 0.6888961791992188
Epoch: 4/300 - Train loss: 0.6887447237968445, Validation loss: 0.6871162056922913
Epoch: 5/300 - Train loss: 0.6869454979896545, Validation loss: 0.6851726770401001
Epoch: 6/300 - Train loss: 0.6849879026412964, Validation loss: 0.6830902099609375
Epoch: 7/300 - Train loss: 0.6828429102897644, Validation loss: 0.6807955503463745
Epoch: 8/300 - Train loss: 0.6804994940757751, Validation loss: 0.6782806515693665
Epoch: 9/300 - Train loss: 0.6779576539993286, Validation loss: 0.6756401062011719
Epoch: 10/300 - Train loss: 0.6752145290374756, Validation loss: 0.6727020740509033
Epoch: 11/300 - Train loss: 0.6722719073295593, Validation loss: 0.6695906519889832
Epoch: 12/300 - Train loss: 0.6691468954086304, Validation loss: 0.666371762752533
Epoch: 13/300 - Train loss: 0.6658532619476318, Validation loss: 0.6629530191421509
Epoch: 14/300 - Train loss: 0.6623971462249756, Validation loss: 0.6594031453132629
Epoch: 15/300 - Train loss: 0.6588048338890076, Validation loss: 0.6557087302207947
Epoch: 16/300 - Train loss: 0.6550923585891724, Validation loss: 0.6519116163253784
Epoch: 17/300 - Train loss: 0.6512703895568848, Validation loss: 0.6479870080947876
Epoch: 18/300 - Train loss: 0.6473476886749268, Validation loss: 0.6441359519958496
Epoch: 19/300 - Train loss: 0.6433406472206116, Validation loss: 0.6401183605194092
Epoch: 20/300 - Train loss: 0.639258623123169, Validation loss: 0.6358708143234253
Epoch: 21/300 - Train loss: 0.6351044774055481, Validation loss: 0.6317904591560364
Epoch: 22/300 - Train loss: 0.6308872699737549, Validation loss: 0.6274641156196594
Epoch: 23/300 - Train loss: 0.6266135573387146, Validation loss: 0.6232520937919617
Epoch: 24/300 - Train loss: 0.6222890019416809, Validation loss: 0.618941068649292
Epoch: 25/300 - Train loss: 0.6179178953170776, Validation loss: 0.6146670579910278
Epoch: 26/300 - Train loss: 0.6135067939758301, Validation loss: 0.6102066040039062
Epoch: 27/300 - Train loss: 0.6090606451034546, Validation loss: 0.6058323979377747
Epoch: 28/300 - Train loss: 0.6045838594436646, Validation loss: 0.6012639999389648
Epoch: 29/300 - Train loss: 0.6000827550888062, Validation loss: 0.5970078110694885
Epoch: 30/300 - Train loss: 0.5955619215965271, Validation loss: 0.5923832058906555
Epoch: 31/300 - Train loss: 0.5910264849662781, Validation loss: 0.5877420902252197
Epoch: 32/300 - Train loss: 0.5864819884300232, Validation loss: 0.5834161639213562
Epoch: 33/300 - Train loss: 0.5819333791732788, Validation loss: 0.5789873003959656
Epoch: 34/300 - Train loss: 0.5773851275444031, Validation loss: 0.574286699295044
Epoch: 35/300 - Train loss: 0.5728424191474915, Validation loss: 0.569782018661499
Epoch: 36/300 - Train loss: 0.5683104991912842, Validation loss: 0.5652095675468445
Epoch: 37/300 - Train loss: 0.5637935996055603, Validation loss: 0.5604549646377563
Epoch: 38/300 - Train loss: 0.5592959523200989, Validation loss: 0.5563561320304871
Epoch: 39/300 - Train loss: 0.5548210740089417, Validation loss: 0.5518297553062439
Epoch: 40/300 - Train loss: 0.5503721833229065, Validation loss: 0.5474128127098083
Epoch: 41/300 - Train loss: 0.545953094959259, Validation loss: 0.5430634021759033
Epoch: 42/300 - Train loss: 0.5415680408477783, Validation loss: 0.538789689540863
Epoch: 43/300 - Train loss: 0.5372208952903748, Validation loss: 0.5347049236297607
Epoch: 44/300 - Train loss: 0.5329156517982483, Validation loss: 0.5300984978675842
Epoch: 45/300 - Train loss: 0.5286561250686646, Validation loss: 0.5257789492607117
Epoch: 46/300 - Train loss: 0.5244459509849548, Validation loss: 0.521710216999054
Epoch: 47/300 - Train loss: 0.5202887058258057, Validation loss: 0.5177401304244995
Epoch: 48/300 - Train loss: 0.5161882042884827, Validation loss: 0.5134815573692322
Epoch: 49/300 - Train loss: 0.5121469497680664, Validation loss: 0.5092922449111938
Epoch: 50/300 - Train loss: 0.5081682801246643, Validation loss: 0.505386471748352
Epoch: 51/300 - Train loss: 0.5042546987533569, Validation loss: 0.5017454624176025
Epoch: 52/300 - Train loss: 0.5004090070724487, Validation loss: 0.4977146089076996
Epoch: 53/300 - Train loss: 0.4966333508491516, Validation loss: 0.49391478300094604
Epoch: 54/300 - Train loss: 0.49292922019958496, Validation loss: 0.49044069647789
Epoch: 55/300 - Train loss: 0.48929843306541443, Validation loss: 0.4865858554840088
Epoch: 56/300 - Train loss: 0.48574233055114746, Validation loss: 0.48384010791778564
Epoch: 57/300 - Train loss: 0.48226219415664673, Validation loss: 0.48019900918006897
Epoch: 58/300 - Train loss: 0.4788590371608734, Validation loss: 0.47682759165763855
Epoch: 59/300 - Train loss: 0.47553396224975586, Validation loss: 0.47321197390556335
Epoch: 60/300 - Train loss: 0.4722873568534851, Validation loss: 0.4697430431842804
Epoch: 61/300 - Train loss: 0.4691193401813507, Validation loss: 0.4669910967350006
Epoch: 62/300 - Train loss: 0.4660298824310303, Validation loss: 0.4644240140914917
Epoch: 63/300 - Train loss: 0.4630189836025238, Validation loss: 0.4605684280395508
Epoch: 64/300 - Train loss: 0.46008631587028503, Validation loss: 0.4582032263278961
Epoch: 65/300 - Train loss: 0.4572317898273468, Validation loss: 0.4552881121635437
Epoch: 66/300 - Train loss: 0.4544546604156494, Validation loss: 0.45243039727211
Epoch: 67/300 - Train loss: 0.451753705739975, Validation loss: 0.44988858699798584
Epoch: 68/300 - Train loss: 0.44912728667259216, Validation loss: 0.44707387685775757
Epoch: 69/300 - Train loss: 0.44657403230667114, Validation loss: 0.4446307122707367
Epoch: 70/300 - Train loss: 0.44409340620040894, Validation loss: 0.44168102741241455
Epoch: 71/300 - Train loss: 0.4416845440864563, Validation loss: 0.4392952024936676
Epoch: 72/300 - Train loss: 0.43934592604637146, Validation loss: 0.4379867613315582
Epoch: 73/300 - Train loss: 0.4370754361152649, Validation loss: 0.43469345569610596
Epoch: 74/300 - Train loss: 0.4348711669445038, Validation loss: 0.4327409267425537
Epoch: 75/300 - Train loss: 0.43273159861564636, Validation loss: 0.4303651750087738
Epoch: 76/300 - Train loss: 0.43065518140792847, Validation loss: 0.4282700717449188
Epoch: 77/300 - Train loss: 0.4286401867866516, Validation loss: 0.42632371187210083
Epoch: 78/300 - Train loss: 0.4266849160194397, Validation loss: 0.42451927065849304
Epoch: 79/300 - Train loss: 0.4247877895832062, Validation loss: 0.4225096106529236
Epoch: 80/300 - Train loss: 0.4229467809200287, Validation loss: 0.420350581407547
Epoch: 81/300 - Train loss: 0.4211602509021759, Validation loss: 0.4197804927825928
Epoch: 82/300 - Train loss: 0.41942647099494934, Validation loss: 0.41717255115509033
Epoch: 83/300 - Train loss: 0.41774359345436096, Validation loss: 0.415780633687973
Epoch: 84/300 - Train loss: 0.41610944271087646, Validation loss: 0.41374650597572327
Epoch: 85/300 - Train loss: 0.4145224988460541, Validation loss: 0.41204023361206055
Epoch: 86/300 - Train loss: 0.4129810929298401, Validation loss: 0.4103979468345642
Epoch: 87/300 - Train loss: 0.41148319840431213, Validation loss: 0.409289687871933
Epoch: 88/300 - Train loss: 0.41002723574638367, Validation loss: 0.40796393156051636
Epoch: 89/300 - Train loss: 0.4086111783981323, Validation loss: 0.40594282746315
Epoch: 90/300 - Train loss: 0.4072324335575104, Validation loss: 0.40455472469329834
Epoch: 91/300 - Train loss: 0.4058898687362671, Validation loss: 0.40311455726623535
Epoch: 92/300 - Train loss: 0.4045830965042114, Validation loss: 0.4018127918243408
Epoch: 93/300 - Train loss: 0.40330973267555237, Validation loss: 0.4006570875644684
Epoch: 94/300 - Train loss: 0.4020697772502899, Validation loss: 0.3989657759666443
Epoch: 95/300 - Train loss: 0.4008616805076599, Validation loss: 0.3977946639060974
Epoch: 96/300 - Train loss: 0.3996838629245758, Validation loss: 0.39702555537223816
Epoch: 97/300 - Train loss: 0.39853617548942566, Validation loss: 0.39569902420043945
Epoch: 98/300 - Train loss: 0.39741647243499756, Validation loss: 0.39452430605888367
Epoch: 99/300 - Train loss: 0.39632371068000793, Validation loss: 0.39327752590179443
Epoch: 100/300 - Train loss: 0.39525699615478516, Validation loss: 0.3925488591194153
Epoch: 101/300 - Train loss: 0.3942156136035919, Validation loss: 0.39078330993652344
Epoch: 102/300 - Train loss: 0.3931996822357178, Validation loss: 0.3899138569831848
Epoch: 103/300 - Train loss: 0.3922075927257538, Validation loss: 0.38864144682884216
Epoch: 104/300 - Train loss: 0.3912374973297119, Validation loss: 0.3879212439060211
Epoch: 105/300 - Train loss: 0.3902893364429474, Validation loss: 0.387594610452652
Epoch: 106/300 - Train loss: 0.3893623650074005, Validation loss: 0.386788010597229
Epoch: 107/300 - Train loss: 0.3884565234184265, Validation loss: 0.3853955566883087
Epoch: 108/300 - Train loss: 0.38757044076919556, Validation loss: 0.38411977887153625
Epoch: 109/300 - Train loss: 0.38670358061790466, Validation loss: 0.38386207818984985
Epoch: 110/300 - Train loss: 0.38585516810417175, Validation loss: 0.38299131393432617
Epoch: 111/300 - Train loss: 0.3850249648094177, Validation loss: 0.3827582597732544
Epoch: 112/300 - Train loss: 0.3842117190361023, Validation loss: 0.38042524456977844
Epoch: 113/300 - Train loss: 0.38341525197029114, Validation loss: 0.3803706765174866
Epoch: 114/300 - Train loss: 0.38263431191444397, Validation loss: 0.37935930490493774
Epoch: 115/300 - Train loss: 0.3818676769733429, Validation loss: 0.3783453404903412
Epoch: 116/300 - Train loss: 0.38111573457717896, Validation loss: 0.37772560119628906
Epoch: 117/300 - Train loss: 0.38037779927253723, Validation loss: 0.37661755084991455
Epoch: 118/300 - Train loss: 0.37965381145477295, Validation loss: 0.37635403871536255
Epoch: 119/300 - Train loss: 0.3789423406124115, Validation loss: 0.37488216161727905
Epoch: 120/300 - Train loss: 0.3782435357570648, Validation loss: 0.37421658635139465
Epoch: 121/300 - Train loss: 0.3775567412376404, Validation loss: 0.3735952377319336
Epoch: 122/300 - Train loss: 0.3768804371356964, Validation loss: 0.3732687532901764
Epoch: 123/300 - Train loss: 0.3762146830558777, Validation loss: 0.3723074197769165
Epoch: 124/300 - Train loss: 0.37556082010269165, Validation loss: 0.37180766463279724
Epoch: 125/300 - Train loss: 0.3749177157878876, Validation loss: 0.3712793290615082
Epoch: 126/300 - Train loss: 0.37428489327430725, Validation loss: 0.37132728099823
Epoch: 127/300 - Train loss: 0.37366190552711487, Validation loss: 0.36942920088768005
Epoch: 128/300 - Train loss: 0.3730485737323761, Validation loss: 0.3695955276489258
Epoch: 129/300 - Train loss: 0.3724438548088074, Validation loss: 0.36892107129096985
Epoch: 130/300 - Train loss: 0.3718474209308624, Validation loss: 0.3678998649120331
Epoch: 131/300 - Train loss: 0.3712587058544159, Validation loss: 0.3674745261669159
Epoch: 132/300 - Train loss: 0.3706779181957245, Validation loss: 0.36692047119140625
Epoch: 133/300 - Train loss: 0.37010449171066284, Validation loss: 0.36609119176864624
Epoch: 134/300 - Train loss: 0.36953818798065186, Validation loss: 0.3660314679145813
Epoch: 135/300 - Train loss: 0.3689797818660736, Validation loss: 0.3652597665786743
Epoch: 136/300 - Train loss: 0.36842668056488037, Validation loss: 0.3649219870567322
