Epoch: 1/200 - Train loss: 0.5967705845832825, Validation loss: 0.5345408916473389
Epoch: 2/200 - Train loss: 0.5043980479240417, Validation loss: 0.482499897480011
Epoch: 3/200 - Train loss: 0.45482316613197327, Validation loss: 0.44244250655174255
Epoch: 4/200 - Train loss: 0.418814480304718, Validation loss: 0.4054196774959564
Epoch: 5/200 - Train loss: 0.3865986764431, Validation loss: 0.3789329528808594
Epoch: 6/200 - Train loss: 0.3619498908519745, Validation loss: 0.35792362689971924
Epoch: 7/200 - Train loss: 0.34059154987335205, Validation loss: 0.3380415439605713
Epoch: 8/200 - Train loss: 0.3235139846801758, Validation loss: 0.3275911808013916
Epoch: 9/200 - Train loss: 0.3098559081554413, Validation loss: 0.3140445649623871
Epoch: 10/200 - Train loss: 0.2987947165966034, Validation loss: 0.3055863082408905
Epoch: 11/200 - Train loss: 0.28741389513015747, Validation loss: 0.3004637360572815
Epoch: 12/200 - Train loss: 0.2795970141887665, Validation loss: 0.2925834655761719
Epoch: 13/200 - Train loss: 0.2723272144794464, Validation loss: 0.28718647360801697
Epoch: 14/200 - Train loss: 0.2657091021537781, Validation loss: 0.2829887568950653
Epoch: 15/200 - Train loss: 0.25945955514907837, Validation loss: 0.2792036831378937
Epoch: 16/200 - Train loss: 0.2540789842605591, Validation loss: 0.27518460154533386
Epoch: 17/200 - Train loss: 0.24963900446891785, Validation loss: 0.2738242447376251
Epoch: 18/200 - Train loss: 0.24563348293304443, Validation loss: 0.27185240387916565
Epoch: 19/200 - Train loss: 0.24101224541664124, Validation loss: 0.26607897877693176
Epoch: 20/200 - Train loss: 0.23720881342887878, Validation loss: 0.2623426914215088
Epoch: 21/200 - Train loss: 0.23280183970928192, Validation loss: 0.26019933819770813
Epoch: 22/200 - Train loss: 0.22910176217556, Validation loss: 0.25892603397369385
Epoch: 23/200 - Train loss: 0.22522544860839844, Validation loss: 0.2551727294921875
Epoch: 24/200 - Train loss: 0.22097568213939667, Validation loss: 0.251753032207489
Epoch: 25/200 - Train loss: 0.21754175424575806, Validation loss: 0.2541370391845703
Epoch: 26/200 - Train loss: 0.2133481651544571, Validation loss: 0.25064441561698914
Epoch: 27/200 - Train loss: 0.21021650731563568, Validation loss: 0.2469291388988495
Epoch: 28/200 - Train loss: 0.20754191279411316, Validation loss: 0.2435484677553177
Epoch: 29/200 - Train loss: 0.2042980194091797, Validation loss: 0.24102963507175446
Epoch: 30/200 - Train loss: 0.20242829620838165, Validation loss: 0.24288251996040344
Epoch: 31/200 - Train loss: 0.19905942678451538, Validation loss: 0.23636488616466522
Epoch: 32/200 - Train loss: 0.19623392820358276, Validation loss: 0.23729543387889862
Epoch: 33/200 - Train loss: 0.1941090226173401, Validation loss: 0.2363392412662506
Epoch: 34/200 - Train loss: 0.19147415459156036, Validation loss: 0.23598212003707886
Epoch: 35/200 - Train loss: 0.19025957584381104, Validation loss: 0.2342371940612793
Epoch: 36/200 - Train loss: 0.18748340010643005, Validation loss: 0.23377855122089386
Epoch: 37/200 - Train loss: 0.18652686476707458, Validation loss: 0.2309810370206833
Epoch: 38/200 - Train loss: 0.18472547829151154, Validation loss: 0.23077848553657532
Epoch: 39/200 - Train loss: 0.18282262980937958, Validation loss: 0.2322789877653122
Epoch: 40/200 - Train loss: 0.18189863860607147, Validation loss: 0.23041902482509613
Epoch: 41/200 - Train loss: 0.17962303757667542, Validation loss: 0.22999368607997894
Epoch: 42/200 - Train loss: 0.1782425493001938, Validation loss: 0.23128633201122284
Epoch: 43/200 - Train loss: 0.17658723890781403, Validation loss: 0.24231518805027008
Epoch: 44/200 - Train loss: 0.1757543683052063, Validation loss: 0.24302737414836884
Epoch: 45/200 - Train loss: 0.1748606115579605, Validation loss: 0.2433675080537796
Epoch: 46/200 - Train loss: 0.1739901453256607, Validation loss: 0.22694525122642517
Epoch: 47/200 - Train loss: 0.17290647327899933, Validation loss: 0.24210351705551147
Epoch: 48/200 - Train loss: 0.17174124717712402, Validation loss: 0.23897096514701843
Epoch: 49/200 - Train loss: 0.17012067139148712, Validation loss: 0.23969918489456177
Epoch: 50/200 - Train loss: 0.16960255801677704, Validation loss: 0.24063731729984283
Epoch: 51/200 - Train loss: 0.16885749995708466, Validation loss: 0.24062170088291168
Epoch: 52/200 - Train loss: 0.1679724156856537, Validation loss: 0.24259860813617706
Epoch: 53/200 - Train loss: 0.16693569719791412, Validation loss: 0.23970293998718262
Epoch: 54/200 - Train loss: 0.1668056696653366, Validation loss: 0.23935751616954803
Epoch: 55/200 - Train loss: 0.16517722606658936, Validation loss: 0.24169740080833435
Epoch: 56/200 - Train loss: 0.16463075578212738, Validation loss: 0.24482057988643646
Epoch: 57/200 - Train loss: 0.16363738477230072, Validation loss: 0.24260246753692627
Epoch: 58/200 - Train loss: 0.16327010095119476, Validation loss: 0.24141007661819458
Epoch: 59/200 - Train loss: 0.1630561649799347, Validation loss: 0.2420891523361206
Epoch: 60/200 - Train loss: 0.16228395700454712, Validation loss: 0.24532879889011383
Epoch: 61/200 - Train loss: 0.16096416115760803, Validation loss: 0.24425984919071198
Epoch: 62/200 - Train loss: 0.16091692447662354, Validation loss: 0.2439759075641632
Epoch: 63/200 - Train loss: 0.1598609834909439, Validation loss: 0.24275320768356323
Epoch: 64/200 - Train loss: 0.15927539765834808, Validation loss: 0.2440429925918579
