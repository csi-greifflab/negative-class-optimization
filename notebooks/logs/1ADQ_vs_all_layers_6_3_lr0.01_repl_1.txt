Epoch: 1/200 - Train loss: 0.5171067714691162, Validation loss: 0.42213767766952515
Epoch: 2/200 - Train loss: 0.3754766285419464, Validation loss: 0.3478880822658539
Epoch: 3/200 - Train loss: 0.315556138753891, Validation loss: 0.334103524684906
Epoch: 4/200 - Train loss: 0.2885148525238037, Validation loss: 0.3089093565940857
Epoch: 5/200 - Train loss: 0.2716805636882782, Validation loss: 0.2959006130695343
Epoch: 6/200 - Train loss: 0.26487311720848083, Validation loss: 0.2910827696323395
Epoch: 7/200 - Train loss: 0.25750431418418884, Validation loss: 0.287981778383255
Epoch: 8/200 - Train loss: 0.2527534067630768, Validation loss: 0.2830846309661865
Epoch: 9/200 - Train loss: 0.24850483238697052, Validation loss: 0.2833777368068695
Epoch: 10/200 - Train loss: 0.24753479659557343, Validation loss: 0.28349679708480835
Epoch: 11/200 - Train loss: 0.24337169528007507, Validation loss: 0.27651453018188477
Epoch: 12/200 - Train loss: 0.23936623334884644, Validation loss: 0.2773039638996124
Epoch: 13/200 - Train loss: 0.23758018016815186, Validation loss: 0.2798977792263031
Epoch: 14/200 - Train loss: 0.23694685101509094, Validation loss: 0.27779966592788696
Epoch: 15/200 - Train loss: 0.23481711745262146, Validation loss: 0.27350443601608276
Epoch: 16/200 - Train loss: 0.23441365361213684, Validation loss: 0.2796337306499481
Epoch: 17/200 - Train loss: 0.23390957713127136, Validation loss: 0.27616116404533386
Epoch: 18/200 - Train loss: 0.23317866027355194, Validation loss: 0.2784704267978668
Epoch: 19/200 - Train loss: 0.23193591833114624, Validation loss: 0.2762214243412018
Epoch: 20/200 - Train loss: 0.2309722751379013, Validation loss: 0.2757243514060974
Epoch: 21/200 - Train loss: 0.2301485538482666, Validation loss: 0.27821484208106995
Epoch: 22/200 - Train loss: 0.22860859334468842, Validation loss: 0.2775091528892517
Epoch: 23/200 - Train loss: 0.228737473487854, Validation loss: 0.28012439608573914
Epoch: 24/200 - Train loss: 0.22920538485050201, Validation loss: 0.27584490180015564
Epoch: 25/200 - Train loss: 0.2279455065727234, Validation loss: 0.2749037742614746
Epoch: 26/200 - Train loss: 0.227507084608078, Validation loss: 0.28312358260154724
Epoch: 27/200 - Train loss: 0.22707787156105042, Validation loss: 0.27840521931648254
Epoch: 28/200 - Train loss: 0.2257886826992035, Validation loss: 0.2767881453037262
Epoch: 29/200 - Train loss: 0.225733682513237, Validation loss: 0.27474913001060486
Epoch: 30/200 - Train loss: 0.22532498836517334, Validation loss: 0.27440863847732544
Epoch: 31/200 - Train loss: 0.2255115658044815, Validation loss: 0.2755263149738312
Epoch: 32/200 - Train loss: 0.2242194414138794, Validation loss: 0.275054931640625
Epoch: 33/200 - Train loss: 0.22332434356212616, Validation loss: 0.27471378445625305
Epoch: 34/200 - Train loss: 0.22281698882579803, Validation loss: 0.2826114296913147
Epoch: 35/200 - Train loss: 0.22355839610099792, Validation loss: 0.2782541513442993
Epoch: 36/200 - Train loss: 0.22335577011108398, Validation loss: 0.27939510345458984
Epoch: 37/200 - Train loss: 0.22376424074172974, Validation loss: 0.28172001242637634
Epoch: 38/200 - Train loss: 0.22358110547065735, Validation loss: 0.2767212986946106
Epoch: 39/200 - Train loss: 0.22264964878559113, Validation loss: 0.2793290615081787
Epoch: 40/200 - Train loss: 0.22185896337032318, Validation loss: 0.286678671836853
Epoch: 41/200 - Train loss: 0.2221519649028778, Validation loss: 0.2805503308773041
Epoch: 42/200 - Train loss: 0.2219131737947464, Validation loss: 0.2792457938194275
Epoch: 43/200 - Train loss: 0.22067299485206604, Validation loss: 0.2748854458332062
Epoch: 44/200 - Train loss: 0.22052256762981415, Validation loss: 0.2809602618217468
Epoch: 45/200 - Train loss: 0.22165699303150177, Validation loss: 0.2780989110469818
Epoch: 46/200 - Train loss: 0.22066210210323334, Validation loss: 0.2784727215766907
Epoch: 47/200 - Train loss: 0.2207823395729065, Validation loss: 0.27967244386672974
Epoch: 48/200 - Train loss: 0.2211143523454666, Validation loss: 0.2783729135990143
Epoch: 49/200 - Train loss: 0.21946436166763306, Validation loss: 0.27980712056159973
Epoch: 50/200 - Train loss: 0.2193741649389267, Validation loss: 0.2789788544178009
Epoch: 51/200 - Train loss: 0.21960343420505524, Validation loss: 0.2785767912864685
Epoch: 52/200 - Train loss: 0.21837155520915985, Validation loss: 0.278328001499176
Epoch: 53/200 - Train loss: 0.21953590214252472, Validation loss: 0.27937713265419006
Epoch: 1/200 - Train loss: 0.49540168046951294, Validation loss: 0.4055693447589874
Epoch: 2/200 - Train loss: 0.3642880618572235, Validation loss: 0.3507823050022125
Epoch: 3/200 - Train loss: 0.3119015097618103, Validation loss: 0.31629788875579834
Epoch: 4/200 - Train loss: 0.28324761986732483, Validation loss: 0.3024805188179016
Epoch: 5/200 - Train loss: 0.2704539895057678, Validation loss: 0.2971682548522949
Epoch: 6/200 - Train loss: 0.2573258876800537, Validation loss: 0.29612189531326294
Epoch: 7/200 - Train loss: 0.2515096962451935, Validation loss: 0.28676214814186096
Epoch: 8/200 - Train loss: 0.24584095180034637, Validation loss: 0.28753775358200073
Epoch: 9/200 - Train loss: 0.24129167199134827, Validation loss: 0.284203439950943
Epoch: 10/200 - Train loss: 0.23924610018730164, Validation loss: 0.2816644310951233
Epoch: 11/200 - Train loss: 0.23565863072872162, Validation loss: 0.284678190946579
Epoch: 12/200 - Train loss: 0.2340250164270401, Validation loss: 0.28053581714630127
Epoch: 13/200 - Train loss: 0.23139670491218567, Validation loss: 0.2824888229370117
Epoch: 14/200 - Train loss: 0.2286052703857422, Validation loss: 0.2895205318927765
Epoch: 15/200 - Train loss: 0.22765833139419556, Validation loss: 0.27931809425354004
Epoch: 16/200 - Train loss: 0.2269771695137024, Validation loss: 0.2816278636455536
Epoch: 17/200 - Train loss: 0.2252812385559082, Validation loss: 0.28146785497665405
Epoch: 18/200 - Train loss: 0.22301672399044037, Validation loss: 0.2860192060470581
Epoch: 19/200 - Train loss: 0.22332416474819183, Validation loss: 0.2839618921279907
Epoch: 20/200 - Train loss: 0.22294455766677856, Validation loss: 0.27981215715408325
Epoch: 21/200 - Train loss: 0.22118942439556122, Validation loss: 0.27699336409568787
Epoch: 22/200 - Train loss: 0.22037601470947266, Validation loss: 0.27914828062057495
Epoch: 23/200 - Train loss: 0.22035308182239532, Validation loss: 0.2783016860485077
Epoch: 24/200 - Train loss: 0.21891510486602783, Validation loss: 0.2794437110424042
Epoch: 25/200 - Train loss: 0.21891234815120697, Validation loss: 0.2791268527507782
Epoch: 26/200 - Train loss: 0.21843168139457703, Validation loss: 0.28307947516441345
Epoch: 27/200 - Train loss: 0.21825122833251953, Validation loss: 0.27706313133239746
Epoch: 28/200 - Train loss: 0.21744310855865479, Validation loss: 0.2778037190437317
Epoch: 29/200 - Train loss: 0.21775174140930176, Validation loss: 0.2791283130645752
Epoch: 30/200 - Train loss: 0.2171681523323059, Validation loss: 0.2826283276081085
Epoch: 31/200 - Train loss: 0.2167424112558365, Validation loss: 0.28039124608039856
Epoch: 32/200 - Train loss: 0.21574130654335022, Validation loss: 0.2800552248954773
Epoch: 33/200 - Train loss: 0.21554379165172577, Validation loss: 0.2783288061618805
Epoch: 34/200 - Train loss: 0.2144511342048645, Validation loss: 0.2798214852809906
Epoch: 35/200 - Train loss: 0.21389466524124146, Validation loss: 0.27734431624412537
Epoch: 36/200 - Train loss: 0.2147718071937561, Validation loss: 0.2779117822647095
Epoch: 37/200 - Train loss: 0.2131580263376236, Validation loss: 0.2769991457462311
Epoch: 38/200 - Train loss: 0.2146616131067276, Validation loss: 0.2819276750087738
Epoch: 39/200 - Train loss: 0.21294952929019928, Validation loss: 0.28251996636390686
Epoch: 40/200 - Train loss: 0.21211758255958557, Validation loss: 0.2850366532802582
Epoch: 41/200 - Train loss: 0.21302855014801025, Validation loss: 0.27982693910598755
Epoch: 42/200 - Train loss: 0.21214358508586884, Validation loss: 0.2778136432170868
Epoch: 43/200 - Train loss: 0.21177084743976593, Validation loss: 0.27546271681785583
Epoch: 44/200 - Train loss: 0.21150058507919312, Validation loss: 0.2809965908527374
Epoch: 45/200 - Train loss: 0.21172289550304413, Validation loss: 0.27755486965179443
Epoch: 46/200 - Train loss: 0.21178044378757477, Validation loss: 0.2841333746910095
Epoch: 47/200 - Train loss: 0.2117481231689453, Validation loss: 0.2800513505935669
Epoch: 48/200 - Train loss: 0.2100811004638672, Validation loss: 0.28103938698768616
Epoch: 49/200 - Train loss: 0.2105470597743988, Validation loss: 0.28190264105796814
Epoch: 50/200 - Train loss: 0.20964163541793823, Validation loss: 0.2799615263938904
Epoch: 51/200 - Train loss: 0.2099822759628296, Validation loss: 0.2802414894104004
Epoch: 52/200 - Train loss: 0.21005873382091522, Validation loss: 0.2812178134918213
Epoch: 53/200 - Train loss: 0.2108733355998993, Validation loss: 0.27908724546432495
Epoch: 54/200 - Train loss: 0.20874762535095215, Validation loss: 0.28064659237861633
Epoch: 55/200 - Train loss: 0.20852045714855194, Validation loss: 0.28290531039237976
Epoch: 56/200 - Train loss: 0.2086077332496643, Validation loss: 0.28352031111717224
