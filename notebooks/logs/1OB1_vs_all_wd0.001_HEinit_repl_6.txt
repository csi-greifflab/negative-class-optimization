Epoch: 1/300 - Train loss: 0.7018131017684937, Validation loss: 0.6973720192909241
Epoch: 2/300 - Train loss: 0.6985009908676147, Validation loss: 0.6940154433250427
Epoch: 3/300 - Train loss: 0.6952190399169922, Validation loss: 0.69089275598526
Epoch: 4/300 - Train loss: 0.6919488310813904, Validation loss: 0.6875923275947571
Epoch: 5/300 - Train loss: 0.6886726021766663, Validation loss: 0.6843829154968262
Epoch: 6/300 - Train loss: 0.6853792071342468, Validation loss: 0.681161642074585
Epoch: 7/300 - Train loss: 0.6820695400238037, Validation loss: 0.6778188347816467
Epoch: 8/300 - Train loss: 0.6787354350090027, Validation loss: 0.6745758652687073
Epoch: 9/300 - Train loss: 0.675365686416626, Validation loss: 0.6711772680282593
Epoch: 10/300 - Train loss: 0.6719464659690857, Validation loss: 0.6676395535469055
Epoch: 11/300 - Train loss: 0.6684721112251282, Validation loss: 0.6641427874565125
Epoch: 12/300 - Train loss: 0.6649383306503296, Validation loss: 0.6605893969535828
Epoch: 13/300 - Train loss: 0.66133713722229, Validation loss: 0.6570387482643127
Epoch: 14/300 - Train loss: 0.6576636433601379, Validation loss: 0.6532941460609436
Epoch: 15/300 - Train loss: 0.6539178490638733, Validation loss: 0.6494061946868896
Epoch: 16/300 - Train loss: 0.650094211101532, Validation loss: 0.6455687880516052
Epoch: 17/300 - Train loss: 0.6461905241012573, Validation loss: 0.6415366530418396
Epoch: 18/300 - Train loss: 0.6422011256217957, Validation loss: 0.6376518607139587
Epoch: 19/300 - Train loss: 0.6381301283836365, Validation loss: 0.6333575248718262
Epoch: 20/300 - Train loss: 0.6339752674102783, Validation loss: 0.629299521446228
Epoch: 21/300 - Train loss: 0.6297380328178406, Validation loss: 0.6248421669006348
Epoch: 22/300 - Train loss: 0.6254187822341919, Validation loss: 0.620444118976593
Epoch: 23/300 - Train loss: 0.6210247278213501, Validation loss: 0.616077721118927
Epoch: 24/300 - Train loss: 0.6165582537651062, Validation loss: 0.6113346219062805
Epoch: 25/300 - Train loss: 0.6120244264602661, Validation loss: 0.6068807244300842
Epoch: 26/300 - Train loss: 0.6074281930923462, Validation loss: 0.6018582582473755
Epoch: 27/300 - Train loss: 0.6027756929397583, Validation loss: 0.5972040891647339
Epoch: 28/300 - Train loss: 0.5980756878852844, Validation loss: 0.592563271522522
Epoch: 29/300 - Train loss: 0.5933287143707275, Validation loss: 0.5873249769210815
Epoch: 30/300 - Train loss: 0.5885408520698547, Validation loss: 0.5825325846672058
Epoch: 31/300 - Train loss: 0.5837181806564331, Validation loss: 0.577454686164856
Epoch: 32/300 - Train loss: 0.5788733959197998, Validation loss: 0.5727298855781555
Epoch: 33/300 - Train loss: 0.5740160942077637, Validation loss: 0.5677591562271118
Epoch: 34/300 - Train loss: 0.5691552758216858, Validation loss: 0.5630322098731995
Epoch: 35/300 - Train loss: 0.5642902851104736, Validation loss: 0.5580878853797913
Epoch: 36/300 - Train loss: 0.5594316720962524, Validation loss: 0.5530022382736206
Epoch: 37/300 - Train loss: 0.5545860528945923, Validation loss: 0.5481492280960083
Epoch: 38/300 - Train loss: 0.5497679710388184, Validation loss: 0.5429593920707703
Epoch: 39/300 - Train loss: 0.5449841022491455, Validation loss: 0.5380839705467224
Epoch: 40/300 - Train loss: 0.540241539478302, Validation loss: 0.5336275100708008
Epoch: 41/300 - Train loss: 0.5355396270751953, Validation loss: 0.5283573865890503
Epoch: 42/300 - Train loss: 0.5308852195739746, Validation loss: 0.5237629413604736
Epoch: 43/300 - Train loss: 0.5262835025787354, Validation loss: 0.51924729347229
Epoch: 44/300 - Train loss: 0.5217394232749939, Validation loss: 0.5144620537757874
Epoch: 45/300 - Train loss: 0.517253041267395, Validation loss: 0.5097160935401917
Epoch: 46/300 - Train loss: 0.5128273367881775, Validation loss: 0.5055202841758728
Epoch: 47/300 - Train loss: 0.5084665417671204, Validation loss: 0.5008417963981628
Epoch: 48/300 - Train loss: 0.5041714906692505, Validation loss: 0.49662140011787415
Epoch: 49/300 - Train loss: 0.4999461770057678, Validation loss: 0.49243324995040894
Epoch: 50/300 - Train loss: 0.4957929849624634, Validation loss: 0.4878905415534973
Epoch: 51/300 - Train loss: 0.49170976877212524, Validation loss: 0.4834505021572113
Epoch: 52/300 - Train loss: 0.4876992106437683, Validation loss: 0.47978171706199646
Epoch: 53/300 - Train loss: 0.4837636947631836, Validation loss: 0.4757198393344879
Epoch: 54/300 - Train loss: 0.47990429401397705, Validation loss: 0.47194916009902954
Epoch: 55/300 - Train loss: 0.47612181305885315, Validation loss: 0.4680166244506836
Epoch: 56/300 - Train loss: 0.47241413593292236, Validation loss: 0.4639318287372589
Epoch: 57/300 - Train loss: 0.46878117322921753, Validation loss: 0.46046116948127747
Epoch: 58/300 - Train loss: 0.46522411704063416, Validation loss: 0.4567171633243561
Epoch: 59/300 - Train loss: 0.46174320578575134, Validation loss: 0.453134685754776
Epoch: 60/300 - Train loss: 0.4583384394645691, Validation loss: 0.4495958983898163
Epoch: 61/300 - Train loss: 0.455009788274765, Validation loss: 0.4461521804332733
Epoch: 62/300 - Train loss: 0.4517553448677063, Validation loss: 0.4426024258136749
Epoch: 63/300 - Train loss: 0.44857457280158997, Validation loss: 0.4396057724952698
Epoch: 64/300 - Train loss: 0.4454662799835205, Validation loss: 0.4365735352039337
Epoch: 65/300 - Train loss: 0.44243043661117554, Validation loss: 0.43342217803001404
Epoch: 66/300 - Train loss: 0.43946588039398193, Validation loss: 0.43073412775993347
Epoch: 67/300 - Train loss: 0.43657156825065613, Validation loss: 0.4269716739654541
Epoch: 68/300 - Train loss: 0.4337473511695862, Validation loss: 0.4246010482311249
Epoch: 69/300 - Train loss: 0.430991530418396, Validation loss: 0.4215196669101715
Epoch: 70/300 - Train loss: 0.428302526473999, Validation loss: 0.4188607335090637
Epoch: 71/300 - Train loss: 0.4256788194179535, Validation loss: 0.4161231219768524
Epoch: 72/300 - Train loss: 0.4231201112270355, Validation loss: 0.4139431118965149
Epoch: 73/300 - Train loss: 0.42062509059906006, Validation loss: 0.4107838571071625
Epoch: 74/300 - Train loss: 0.4181923568248749, Validation loss: 0.4084250330924988
Epoch: 75/300 - Train loss: 0.4158211350440979, Validation loss: 0.4060812294483185
Epoch: 76/300 - Train loss: 0.413510799407959, Validation loss: 0.40408000349998474
Epoch: 77/300 - Train loss: 0.4112596809864044, Validation loss: 0.4013129472732544
Epoch: 78/300 - Train loss: 0.40906763076782227, Validation loss: 0.39905110001564026
Epoch: 79/300 - Train loss: 0.4069331884384155, Validation loss: 0.39666634798049927
Epoch: 80/300 - Train loss: 0.4048543870449066, Validation loss: 0.3945440948009491
Epoch: 81/300 - Train loss: 0.40282946825027466, Validation loss: 0.39262887835502625
Epoch: 82/300 - Train loss: 0.40085726976394653, Validation loss: 0.3897275924682617
Epoch: 83/300 - Train loss: 0.39893659949302673, Validation loss: 0.38862064480781555
Epoch: 84/300 - Train loss: 0.39706671237945557, Validation loss: 0.3865987956523895
Epoch: 85/300 - Train loss: 0.395245760679245, Validation loss: 0.3842369019985199
Epoch: 86/300 - Train loss: 0.39347290992736816, Validation loss: 0.3821714520454407
Epoch: 87/300 - Train loss: 0.3917466402053833, Validation loss: 0.380416601896286
Epoch: 88/300 - Train loss: 0.3900662064552307, Validation loss: 0.37909379601478577
Epoch: 89/300 - Train loss: 0.38843005895614624, Validation loss: 0.37712305784225464
Epoch: 90/300 - Train loss: 0.38683727383613586, Validation loss: 0.3758218288421631
Epoch: 91/300 - Train loss: 0.3852858245372772, Validation loss: 0.37433895468711853
Epoch: 92/300 - Train loss: 0.38377395272254944, Validation loss: 0.37248021364212036
Epoch: 93/300 - Train loss: 0.38230109214782715, Validation loss: 0.37102779746055603
Epoch: 94/300 - Train loss: 0.38086608052253723, Validation loss: 0.36923423409461975
Epoch: 95/300 - Train loss: 0.379467636346817, Validation loss: 0.367922842502594
Epoch: 96/300 - Train loss: 0.37810537219047546, Validation loss: 0.3662128150463104
Epoch: 97/300 - Train loss: 0.3767775893211365, Validation loss: 0.36487457156181335
Epoch: 98/300 - Train loss: 0.3754836320877075, Validation loss: 0.36349597573280334
Epoch: 99/300 - Train loss: 0.3742217421531677, Validation loss: 0.36205723881721497
Epoch: 100/300 - Train loss: 0.3729913532733917, Validation loss: 0.360577255487442
Epoch: 101/300 - Train loss: 0.37179097533226013, Validation loss: 0.3595413863658905
Epoch: 102/300 - Train loss: 0.37061962485313416, Validation loss: 0.35886168479919434
Epoch: 103/300 - Train loss: 0.3694770038127899, Validation loss: 0.35854312777519226
Epoch: 104/300 - Train loss: 0.3683614432811737, Validation loss: 0.35606813430786133
Epoch: 105/300 - Train loss: 0.3672720789909363, Validation loss: 0.3542692959308624
Epoch: 106/300 - Train loss: 0.36620885133743286, Validation loss: 0.35388487577438354
Epoch: 107/300 - Train loss: 0.36517059803009033, Validation loss: 0.35343530774116516
Epoch: 108/300 - Train loss: 0.364155113697052, Validation loss: 0.35200271010398865
Epoch: 109/300 - Train loss: 0.3631616532802582, Validation loss: 0.3505621552467346
Epoch: 110/300 - Train loss: 0.3621896207332611, Validation loss: 0.349656879901886
Epoch: 111/300 - Train loss: 0.36123859882354736, Validation loss: 0.3484712243080139
Epoch: 112/300 - Train loss: 0.3603077232837677, Validation loss: 0.34774699807167053
Epoch: 113/300 - Train loss: 0.35939571261405945, Validation loss: 0.34652256965637207
Epoch: 114/300 - Train loss: 0.3585017919540405, Validation loss: 0.3462533950805664
Epoch: 115/300 - Train loss: 0.3576255440711975, Validation loss: 0.34572356939315796
Epoch: 116/300 - Train loss: 0.3567669689655304, Validation loss: 0.3448604345321655
Epoch: 117/300 - Train loss: 0.35592585802078247, Validation loss: 0.34328824281692505
Epoch: 118/300 - Train loss: 0.3551020622253418, Validation loss: 0.3421877920627594
Epoch: 119/300 - Train loss: 0.35429465770721436, Validation loss: 0.3412470817565918
Epoch: 120/300 - Train loss: 0.3535028398036957, Validation loss: 0.3407060503959656
Epoch: 121/300 - Train loss: 0.3527259826660156, Validation loss: 0.3401046693325043
Epoch: 122/300 - Train loss: 0.351963073015213, Validation loss: 0.3389696180820465
Epoch: 123/300 - Train loss: 0.3512146472930908, Validation loss: 0.33824434876441956
Epoch: 124/300 - Train loss: 0.35047999024391174, Validation loss: 0.33759400248527527
Epoch: 125/300 - Train loss: 0.349758505821228, Validation loss: 0.3373405337333679
Epoch: 126/300 - Train loss: 0.3490505516529083, Validation loss: 0.33582010865211487
Epoch: 127/300 - Train loss: 0.34835535287857056, Validation loss: 0.33602678775787354
Epoch: 128/300 - Train loss: 0.34767311811447144, Validation loss: 0.3346662223339081
Epoch: 129/300 - Train loss: 0.34700310230255127, Validation loss: 0.33437177538871765
Epoch: 130/300 - Train loss: 0.346344530582428, Validation loss: 0.3335500955581665
Epoch: 131/300 - Train loss: 0.3456963896751404, Validation loss: 0.33355188369750977
Epoch: 132/300 - Train loss: 0.34505903720855713, Validation loss: 0.3322722911834717
Epoch: 133/300 - Train loss: 0.3444328010082245, Validation loss: 0.33148136734962463
Epoch: 134/300 - Train loss: 0.3438182771205902, Validation loss: 0.3312961459159851
Epoch: 135/300 - Train loss: 0.34321409463882446, Validation loss: 0.33052414655685425
Epoch: 136/300 - Train loss: 0.34261906147003174, Validation loss: 0.3299390375614166
Epoch: 137/300 - Train loss: 0.342033714056015, Validation loss: 0.3292909264564514
Epoch: 138/300 - Train loss: 0.34145817160606384, Validation loss: 0.3286297619342804
Epoch: 139/300 - Train loss: 0.3408922255039215, Validation loss: 0.32842111587524414
Epoch: 140/300 - Train loss: 0.3403348922729492, Validation loss: 0.32750681042671204
Epoch: 141/300 - Train loss: 0.33978500962257385, Validation loss: 0.3268014192581177
Epoch: 142/300 - Train loss: 0.3392435312271118, Validation loss: 0.3262929618358612
Epoch: 143/300 - Train loss: 0.33870965242385864, Validation loss: 0.32568544149398804
Epoch: 144/300 - Train loss: 0.33818307518959045, Validation loss: 0.3247727155685425
Epoch: 145/300 - Train loss: 0.33766308426856995, Validation loss: 0.3247224688529968
Epoch: 146/300 - Train loss: 0.3371497094631195, Validation loss: 0.3243710994720459
