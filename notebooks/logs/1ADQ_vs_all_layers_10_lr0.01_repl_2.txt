Epoch: 1/200 - Train loss: 0.45268669724464417, Validation loss: 0.37394267320632935
Epoch: 2/200 - Train loss: 0.3157915472984314, Validation loss: 0.301871657371521
Epoch: 3/200 - Train loss: 0.25206542015075684, Validation loss: 0.2692505717277527
Epoch: 4/200 - Train loss: 0.22439999878406525, Validation loss: 0.2563806474208832
Epoch: 5/200 - Train loss: 0.20874279737472534, Validation loss: 0.24730026721954346
Epoch: 6/200 - Train loss: 0.19898371398448944, Validation loss: 0.24677373468875885
Epoch: 7/200 - Train loss: 0.19320814311504364, Validation loss: 0.242365762591362
Epoch: 8/200 - Train loss: 0.18732096254825592, Validation loss: 0.2521938979625702
Epoch: 9/200 - Train loss: 0.18319527804851532, Validation loss: 0.24293014407157898
Epoch: 10/200 - Train loss: 0.1757742017507553, Validation loss: 0.24085915088653564
Epoch: 11/200 - Train loss: 0.17298918962478638, Validation loss: 0.23938894271850586
Epoch: 12/200 - Train loss: 0.17090854048728943, Validation loss: 0.25085046887397766
Epoch: 13/200 - Train loss: 0.16931943595409393, Validation loss: 0.24506524205207825
Epoch: 14/200 - Train loss: 0.16852419078350067, Validation loss: 0.24510768055915833
Epoch: 15/200 - Train loss: 0.16505225002765656, Validation loss: 0.25334036350250244
Epoch: 16/200 - Train loss: 0.16427865624427795, Validation loss: 0.24446338415145874
Epoch: 17/200 - Train loss: 0.16167844831943512, Validation loss: 0.24332822859287262
Epoch: 18/200 - Train loss: 0.15891052782535553, Validation loss: 0.24686580896377563
Epoch: 19/200 - Train loss: 0.16091522574424744, Validation loss: 0.24613335728645325
Epoch: 20/200 - Train loss: 0.1576455980539322, Validation loss: 0.24843205511569977
Epoch: 21/200 - Train loss: 0.15561358630657196, Validation loss: 0.24618807435035706
Epoch: 22/200 - Train loss: 0.1540742665529251, Validation loss: 0.2473738044500351
Epoch: 23/200 - Train loss: 0.15371043980121613, Validation loss: 0.257651686668396
Epoch: 24/200 - Train loss: 0.15360890328884125, Validation loss: 0.25102734565734863
Epoch: 25/200 - Train loss: 0.15223002433776855, Validation loss: 0.2507290542125702
Epoch: 26/200 - Train loss: 0.15193592011928558, Validation loss: 0.2524241507053375
Epoch: 27/200 - Train loss: 0.15041913092136383, Validation loss: 0.2464679777622223
Epoch: 28/200 - Train loss: 0.1492881178855896, Validation loss: 0.2500392496585846
Epoch: 29/200 - Train loss: 0.14827650785446167, Validation loss: 0.257100373506546
Epoch: 30/200 - Train loss: 0.14772292971611023, Validation loss: 0.2569100558757782
Epoch: 31/200 - Train loss: 0.14772966504096985, Validation loss: 0.2524089217185974
Epoch: 32/200 - Train loss: 0.14672434329986572, Validation loss: 0.24977974593639374
Epoch: 33/200 - Train loss: 0.1456102430820465, Validation loss: 0.2528034746646881
Epoch: 34/200 - Train loss: 0.14569105207920074, Validation loss: 0.2568068206310272
Epoch: 35/200 - Train loss: 0.1454761028289795, Validation loss: 0.24943047761917114
Epoch: 36/200 - Train loss: 0.14560671150684357, Validation loss: 0.25387653708457947
Epoch: 37/200 - Train loss: 0.14426903426647186, Validation loss: 0.2588023543357849
Epoch: 38/200 - Train loss: 0.14380855858325958, Validation loss: 0.25505533814430237
Epoch: 39/200 - Train loss: 0.14195695519447327, Validation loss: 0.2530432641506195
Epoch: 40/200 - Train loss: 0.1432877629995346, Validation loss: 0.2630237638950348
Epoch: 41/200 - Train loss: 0.14162451028823853, Validation loss: 0.2584775388240814
Epoch: 42/200 - Train loss: 0.14136575162410736, Validation loss: 0.2547124922275543
Epoch: 43/200 - Train loss: 0.14199033379554749, Validation loss: 0.2522754669189453
Epoch: 44/200 - Train loss: 0.14083100855350494, Validation loss: 0.2570665180683136
Epoch: 45/200 - Train loss: 0.1405939757823944, Validation loss: 0.2620265483856201
Epoch: 46/200 - Train loss: 0.14103953540325165, Validation loss: 0.2553175389766693
Epoch: 47/200 - Train loss: 0.14025996625423431, Validation loss: 0.2611584961414337
Epoch: 48/200 - Train loss: 0.13945837318897247, Validation loss: 0.2510843276977539
Epoch: 49/200 - Train loss: 0.1402377188205719, Validation loss: 0.25446364283561707
Epoch: 50/200 - Train loss: 0.13818664848804474, Validation loss: 0.26059481501579285
Epoch: 51/200 - Train loss: 0.13920976221561432, Validation loss: 0.2622353434562683
Epoch: 52/200 - Train loss: 0.13803209364414215, Validation loss: 0.2665170729160309
Epoch: 53/200 - Train loss: 0.13814152777194977, Validation loss: 0.26055628061294556
Epoch: 54/200 - Train loss: 0.13763196766376495, Validation loss: 0.25694170594215393
Epoch: 55/200 - Train loss: 0.1366836577653885, Validation loss: 0.27245840430259705
Epoch: 56/200 - Train loss: 0.13702945411205292, Validation loss: 0.2627911865711212
Epoch: 57/200 - Train loss: 0.13653704524040222, Validation loss: 0.25579404830932617
Epoch: 58/200 - Train loss: 0.13611841201782227, Validation loss: 0.2763660252094269
Epoch: 59/200 - Train loss: 0.13553296029567719, Validation loss: 0.25660422444343567
Epoch: 60/200 - Train loss: 0.1366773247718811, Validation loss: 0.2765970230102539
Epoch: 61/200 - Train loss: 0.1367914378643036, Validation loss: 0.26928985118865967
Epoch: 62/200 - Train loss: 0.1359039545059204, Validation loss: 0.25867798924446106
Epoch: 63/200 - Train loss: 0.13595852255821228, Validation loss: 0.2628837525844574
Epoch: 64/200 - Train loss: 0.13483060896396637, Validation loss: 0.26364070177078247
Epoch: 65/200 - Train loss: 0.13417690992355347, Validation loss: 0.2757534682750702
Epoch: 66/200 - Train loss: 0.134101003408432, Validation loss: 0.2591294050216675
Epoch: 67/200 - Train loss: 0.1352343112230301, Validation loss: 0.27378082275390625
Epoch: 68/200 - Train loss: 0.13405194878578186, Validation loss: 0.2759263217449188
Epoch: 69/200 - Train loss: 0.13546302914619446, Validation loss: 0.26042357087135315
Epoch: 70/200 - Train loss: 0.13508683443069458, Validation loss: 0.276502788066864
Epoch: 71/200 - Train loss: 0.133153036236763, Validation loss: 0.2682531177997589
Epoch: 72/200 - Train loss: 0.13320529460906982, Validation loss: 0.2603398859500885
Epoch: 73/200 - Train loss: 0.1337052434682846, Validation loss: 0.2782415747642517
Epoch: 74/200 - Train loss: 0.13277201354503632, Validation loss: 0.2644244432449341
Epoch: 75/200 - Train loss: 0.1326436698436737, Validation loss: 0.26170632243156433
Epoch: 76/200 - Train loss: 0.13441349565982819, Validation loss: 0.26853862404823303
Epoch: 77/200 - Train loss: 0.13319219648838043, Validation loss: 0.28839603066444397
Epoch: 78/200 - Train loss: 0.1322936713695526, Validation loss: 0.2616145610809326
Epoch: 79/200 - Train loss: 0.1323055773973465, Validation loss: 0.26335084438323975
Epoch: 80/200 - Train loss: 0.13201920688152313, Validation loss: 0.2650648057460785
Epoch: 81/200 - Train loss: 0.13191483914852142, Validation loss: 0.2851981222629547
Epoch: 82/200 - Train loss: 0.13170377910137177, Validation loss: 0.27921098470687866
Epoch: 83/200 - Train loss: 0.13153544068336487, Validation loss: 0.2628285884857178
Epoch: 84/200 - Train loss: 0.13224881887435913, Validation loss: 0.26945897936820984
Epoch: 85/200 - Train loss: 0.1322847157716751, Validation loss: 0.26921388506889343
Epoch: 86/200 - Train loss: 0.1310959756374359, Validation loss: 0.2676183581352234
Epoch: 87/200 - Train loss: 0.13206034898757935, Validation loss: 0.2838101387023926
Epoch: 88/200 - Train loss: 0.1308698207139969, Validation loss: 0.2848908305168152
Epoch: 89/200 - Train loss: 0.1312749683856964, Validation loss: 0.26246362924575806
Epoch: 90/200 - Train loss: 0.1317988783121109, Validation loss: 0.2659514844417572
Epoch: 91/200 - Train loss: 0.13064102828502655, Validation loss: 0.2637729048728943
Epoch: 92/200 - Train loss: 0.13000653684139252, Validation loss: 0.28701406717300415
Epoch: 93/200 - Train loss: 0.1305849850177765, Validation loss: 0.2929348647594452
Epoch: 94/200 - Train loss: 0.13064655661582947, Validation loss: 0.2860003709793091
Epoch: 95/200 - Train loss: 0.1298896223306656, Validation loss: 0.2669971287250519
Epoch: 96/200 - Train loss: 0.1293771117925644, Validation loss: 0.27046456933021545
Epoch: 97/200 - Train loss: 0.13018713891506195, Validation loss: 0.26462817192077637
Epoch: 98/200 - Train loss: 0.12997369468212128, Validation loss: 0.2819980978965759
Epoch: 99/200 - Train loss: 0.12947973608970642, Validation loss: 0.2794768214225769
Epoch: 100/200 - Train loss: 0.12928257882595062, Validation loss: 0.2823083698749542
Epoch: 101/200 - Train loss: 0.13083861768245697, Validation loss: 0.2835835814476013
Epoch: 102/200 - Train loss: 0.12946577370166779, Validation loss: 0.2791685163974762
Epoch: 103/200 - Train loss: 0.12958195805549622, Validation loss: 0.27826252579689026
Epoch: 104/200 - Train loss: 0.12858529388904572, Validation loss: 0.28304600715637207
Epoch: 105/200 - Train loss: 0.12897832691669464, Validation loss: 0.2813586890697479
Epoch: 106/200 - Train loss: 0.12930439412593842, Validation loss: 0.2676752507686615
Epoch: 107/200 - Train loss: 0.12846806645393372, Validation loss: 0.27289021015167236
Epoch: 108/200 - Train loss: 0.12908613681793213, Validation loss: 0.2679999768733978
Epoch: 109/200 - Train loss: 0.12819097936153412, Validation loss: 0.2836167514324188
Epoch: 110/200 - Train loss: 0.12852445244789124, Validation loss: 0.2842378616333008
Epoch: 111/200 - Train loss: 0.1280134916305542, Validation loss: 0.2856377065181732
Epoch: 112/200 - Train loss: 0.12879164516925812, Validation loss: 0.2800583839416504
Epoch: 113/200 - Train loss: 0.12910181283950806, Validation loss: 0.2926381230354309
Epoch: 114/200 - Train loss: 0.127579465508461, Validation loss: 0.2685786187648773
Epoch: 115/200 - Train loss: 0.12821194529533386, Validation loss: 0.2829799950122833
Epoch: 116/200 - Train loss: 0.1282631903886795, Validation loss: 0.2904691696166992
Epoch: 117/200 - Train loss: 0.12768805027008057, Validation loss: 0.27105268836021423
Epoch: 118/200 - Train loss: 0.12711229920387268, Validation loss: 0.27093419432640076
Epoch: 119/200 - Train loss: 0.12692180275917053, Validation loss: 0.28333574533462524
Epoch: 120/200 - Train loss: 0.12755252420902252, Validation loss: 0.2701711654663086
Epoch: 121/200 - Train loss: 0.12808743119239807, Validation loss: 0.26694902777671814
Epoch: 122/200 - Train loss: 0.1275670826435089, Validation loss: 0.2875630259513855
Epoch: 123/200 - Train loss: 0.12810970842838287, Validation loss: 0.2846474349498749
Epoch: 124/200 - Train loss: 0.12600991129875183, Validation loss: 0.28962624073028564
Epoch: 125/200 - Train loss: 0.1271362453699112, Validation loss: 0.28252944350242615
Epoch: 126/200 - Train loss: 0.1268254518508911, Validation loss: 0.324699729681015
Epoch: 127/200 - Train loss: 0.12686730921268463, Validation loss: 0.28483688831329346
Epoch: 128/200 - Train loss: 0.12665389478206635, Validation loss: 0.28657066822052
Epoch: 129/200 - Train loss: 0.12748441100120544, Validation loss: 0.2730538547039032
Epoch: 130/200 - Train loss: 0.1269426792860031, Validation loss: 0.2817194163799286
Epoch: 131/200 - Train loss: 0.1262369304895401, Validation loss: 0.28606075048446655
Epoch: 132/200 - Train loss: 0.12854620814323425, Validation loss: 0.2746446132659912
Epoch: 133/200 - Train loss: 0.1266060471534729, Validation loss: 0.2771880030632019
Epoch: 134/200 - Train loss: 0.12531113624572754, Validation loss: 0.284846693277359
Epoch: 135/200 - Train loss: 0.12671691179275513, Validation loss: 0.2706974446773529
Epoch: 136/200 - Train loss: 0.12621937692165375, Validation loss: 0.2769634425640106
Epoch: 137/200 - Train loss: 0.12672273814678192, Validation loss: 0.2721177041530609
Epoch: 138/200 - Train loss: 0.1256582885980606, Validation loss: 0.2768121361732483
Epoch: 139/200 - Train loss: 0.12600058317184448, Validation loss: 0.2733564078807831
Epoch: 140/200 - Train loss: 0.12587426602840424, Validation loss: 0.27875614166259766
Epoch: 141/200 - Train loss: 0.12557387351989746, Validation loss: 0.278816819190979
Epoch: 142/200 - Train loss: 0.12595276534557343, Validation loss: 0.2912725508213043
Epoch: 143/200 - Train loss: 0.12642288208007812, Validation loss: 0.2763098180294037
Epoch: 144/200 - Train loss: 0.12556326389312744, Validation loss: 0.27619585394859314
Epoch: 145/200 - Train loss: 0.12529242038726807, Validation loss: 0.27714061737060547
Epoch: 146/200 - Train loss: 0.12774547934532166, Validation loss: 0.2812495231628418
Epoch: 147/200 - Train loss: 0.12563617527484894, Validation loss: 0.28799575567245483
Epoch: 148/200 - Train loss: 0.12572745978832245, Validation loss: 0.2911677956581116
Epoch: 149/200 - Train loss: 0.12525661289691925, Validation loss: 0.30199354887008667
Epoch: 150/200 - Train loss: 0.12511807680130005, Validation loss: 0.2866514027118683
Epoch: 151/200 - Train loss: 0.12602366507053375, Validation loss: 0.27491408586502075
Epoch: 152/200 - Train loss: 0.12529729306697845, Validation loss: 0.27763277292251587
Epoch: 153/200 - Train loss: 0.1264224797487259, Validation loss: 0.27351588010787964
Epoch: 154/200 - Train loss: 0.12638165056705475, Validation loss: 0.2773897051811218
Epoch: 155/200 - Train loss: 0.12549066543579102, Validation loss: 0.27281439304351807
Epoch: 156/200 - Train loss: 0.12570451200008392, Validation loss: 0.2806800305843353
Epoch: 157/200 - Train loss: 0.12565934658050537, Validation loss: 0.27664631605148315
Epoch: 158/200 - Train loss: 0.12578381597995758, Validation loss: 0.2779207229614258
Epoch: 159/200 - Train loss: 0.12576869130134583, Validation loss: 0.2735561430454254
Epoch: 160/200 - Train loss: 0.12476187944412231, Validation loss: 0.30630195140838623
Epoch: 161/200 - Train loss: 0.12482238560914993, Validation loss: 0.2908296585083008
Epoch: 162/200 - Train loss: 0.12526659667491913, Validation loss: 0.27770689129829407
Epoch: 163/200 - Train loss: 0.12521734833717346, Validation loss: 0.2873838543891907
Epoch: 164/200 - Train loss: 0.12666742503643036, Validation loss: 0.2961888313293457
Epoch: 165/200 - Train loss: 0.12415138632059097, Validation loss: 0.2877923846244812
Epoch: 166/200 - Train loss: 0.12397444248199463, Validation loss: 0.29292941093444824
Epoch: 167/200 - Train loss: 0.12492481619119644, Validation loss: 0.28936389088630676
Epoch: 168/200 - Train loss: 0.12554733455181122, Validation loss: 0.2892577350139618
Epoch: 169/200 - Train loss: 0.12433893233537674, Validation loss: 0.28087905049324036
Epoch: 170/200 - Train loss: 0.12510208785533905, Validation loss: 0.29354044795036316
Epoch: 171/200 - Train loss: 0.12484253197908401, Validation loss: 0.29360079765319824
Epoch: 172/200 - Train loss: 0.12429141998291016, Validation loss: 0.30498620867729187
Epoch: 173/200 - Train loss: 0.12426520884037018, Validation loss: 0.29189273715019226
Epoch: 174/200 - Train loss: 0.12351304292678833, Validation loss: 0.2888895869255066
Epoch: 175/200 - Train loss: 0.12366973608732224, Validation loss: 0.29348114132881165
Epoch: 176/200 - Train loss: 0.1240381971001625, Validation loss: 0.28401780128479004
Epoch: 177/200 - Train loss: 0.12535516917705536, Validation loss: 0.2915727496147156
Epoch: 178/200 - Train loss: 0.12415077537298203, Validation loss: 0.30401796102523804
Epoch: 179/200 - Train loss: 0.12379463762044907, Validation loss: 0.2983649969100952
Epoch: 180/200 - Train loss: 0.1231309100985527, Validation loss: 0.3045728802680969
Epoch: 181/200 - Train loss: 0.12368760257959366, Validation loss: 0.28676706552505493
Epoch: 182/200 - Train loss: 0.12398193031549454, Validation loss: 0.29169580340385437
Epoch: 183/200 - Train loss: 0.12496379762887955, Validation loss: 0.28905802965164185
Epoch: 184/200 - Train loss: 0.12349989265203476, Validation loss: 0.2748676836490631
Epoch: 185/200 - Train loss: 0.12403697520494461, Validation loss: 0.29623669385910034
Epoch: 186/200 - Train loss: 0.12551087141036987, Validation loss: 0.28989753127098083
Epoch: 187/200 - Train loss: 0.12342805415391922, Validation loss: 0.29221177101135254
Epoch: 188/200 - Train loss: 0.12335915118455887, Validation loss: 0.28121891617774963
Epoch: 189/200 - Train loss: 0.12367206811904907, Validation loss: 0.2932417690753937
Epoch: 190/200 - Train loss: 0.12417370826005936, Validation loss: 0.29263192415237427
Epoch: 191/200 - Train loss: 0.12384388595819473, Validation loss: 0.2898234724998474
Epoch: 192/200 - Train loss: 0.12503045797348022, Validation loss: 0.279302179813385
Epoch: 193/200 - Train loss: 0.12290377169847488, Validation loss: 0.2942136824131012
Epoch: 194/200 - Train loss: 0.12374980747699738, Validation loss: 0.29130464792251587
Epoch: 195/200 - Train loss: 0.12345683574676514, Validation loss: 0.3096904456615448
Epoch: 196/200 - Train loss: 0.12402419745922089, Validation loss: 0.29730746150016785
Epoch: 197/200 - Train loss: 0.1227969229221344, Validation loss: 0.29023808240890503
Epoch: 198/200 - Train loss: 0.12321475148200989, Validation loss: 0.307267963886261
Epoch: 199/200 - Train loss: 0.1234423816204071, Validation loss: 0.29449760913848877
Epoch: 200/200 - Train loss: 0.12321494519710541, Validation loss: 0.29380881786346436
