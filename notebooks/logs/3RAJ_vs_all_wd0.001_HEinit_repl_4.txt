Epoch: 1/300 - Train loss: 0.6945990324020386, Validation loss: 0.6919503211975098
Epoch: 2/300 - Train loss: 0.6933952569961548, Validation loss: 0.6907788515090942
Epoch: 3/300 - Train loss: 0.6921887397766113, Validation loss: 0.689601719379425
Epoch: 4/300 - Train loss: 0.69097501039505, Validation loss: 0.6884772181510925
Epoch: 5/300 - Train loss: 0.6897493004798889, Validation loss: 0.6871575117111206
Epoch: 6/300 - Train loss: 0.6885128617286682, Validation loss: 0.6860163807868958
Epoch: 7/300 - Train loss: 0.6872611045837402, Validation loss: 0.6845880150794983
Epoch: 8/300 - Train loss: 0.6859915852546692, Validation loss: 0.6834153532981873
Epoch: 9/300 - Train loss: 0.6846987009048462, Validation loss: 0.682075560092926
Epoch: 10/300 - Train loss: 0.6833776831626892, Validation loss: 0.6807724237442017
Epoch: 11/300 - Train loss: 0.6820254325866699, Validation loss: 0.6794008016586304
Epoch: 12/300 - Train loss: 0.680640697479248, Validation loss: 0.6780025362968445
Epoch: 13/300 - Train loss: 0.6792232394218445, Validation loss: 0.6765570640563965
Epoch: 14/300 - Train loss: 0.6777709126472473, Validation loss: 0.6750661730766296
Epoch: 15/300 - Train loss: 0.6762825846672058, Validation loss: 0.6734529137611389
Epoch: 16/300 - Train loss: 0.6747564077377319, Validation loss: 0.6720821857452393
Epoch: 17/300 - Train loss: 0.6731939315795898, Validation loss: 0.6703182458877563
Epoch: 18/300 - Train loss: 0.6715929508209229, Validation loss: 0.6687677502632141
Epoch: 19/300 - Train loss: 0.6699513792991638, Validation loss: 0.6672214269638062
Epoch: 20/300 - Train loss: 0.6682693362236023, Validation loss: 0.6654312014579773
Epoch: 21/300 - Train loss: 0.6665481328964233, Validation loss: 0.6636219024658203
Epoch: 22/300 - Train loss: 0.6647872924804688, Validation loss: 0.6618087887763977
Epoch: 23/300 - Train loss: 0.6629854440689087, Validation loss: 0.6599649786949158
Epoch: 24/300 - Train loss: 0.6611430048942566, Validation loss: 0.6582679152488708
Epoch: 25/300 - Train loss: 0.6592627167701721, Validation loss: 0.656248927116394
Epoch: 26/300 - Train loss: 0.6573436260223389, Validation loss: 0.6542686223983765
Epoch: 27/300 - Train loss: 0.6553884744644165, Validation loss: 0.6522830724716187
Epoch: 28/300 - Train loss: 0.6534000635147095, Validation loss: 0.6503807902336121
Epoch: 29/300 - Train loss: 0.6513774394989014, Validation loss: 0.6481130719184875
Epoch: 30/300 - Train loss: 0.6493242979049683, Validation loss: 0.6459740996360779
Epoch: 31/300 - Train loss: 0.6472399830818176, Validation loss: 0.6439147591590881
Epoch: 32/300 - Train loss: 0.6451242566108704, Validation loss: 0.6416934132575989
Epoch: 33/300 - Train loss: 0.642979085445404, Validation loss: 0.6396387815475464
Epoch: 34/300 - Train loss: 0.6408096551895142, Validation loss: 0.6373738050460815
Epoch: 35/300 - Train loss: 0.6386186480522156, Validation loss: 0.6349905729293823
Epoch: 36/300 - Train loss: 0.6364061236381531, Validation loss: 0.6328427791595459
Epoch: 37/300 - Train loss: 0.6341772675514221, Validation loss: 0.6306096911430359
Epoch: 38/300 - Train loss: 0.6319345831871033, Validation loss: 0.628677248954773
Epoch: 39/300 - Train loss: 0.6296792030334473, Validation loss: 0.6260651350021362
Epoch: 40/300 - Train loss: 0.6274139881134033, Validation loss: 0.6238245964050293
Epoch: 41/300 - Train loss: 0.6251410841941833, Validation loss: 0.621449887752533
Epoch: 42/300 - Train loss: 0.6228639483451843, Validation loss: 0.6193763613700867
Epoch: 43/300 - Train loss: 0.6205870509147644, Validation loss: 0.6171540021896362
Epoch: 44/300 - Train loss: 0.6183105111122131, Validation loss: 0.6147319674491882
Epoch: 45/300 - Train loss: 0.6160361170768738, Validation loss: 0.6123983263969421
Epoch: 46/300 - Train loss: 0.6137672066688538, Validation loss: 0.6101598143577576
Epoch: 47/300 - Train loss: 0.6115076541900635, Validation loss: 0.6080582737922668
Epoch: 48/300 - Train loss: 0.609258770942688, Validation loss: 0.6059970259666443
Epoch: 49/300 - Train loss: 0.6070247888565063, Validation loss: 0.6038400530815125
Epoch: 50/300 - Train loss: 0.6048078536987305, Validation loss: 0.6014484167098999
Epoch: 51/300 - Train loss: 0.602608859539032, Validation loss: 0.5992407202720642
Epoch: 52/300 - Train loss: 0.6004297733306885, Validation loss: 0.597195565700531
Epoch: 53/300 - Train loss: 0.5982738137245178, Validation loss: 0.5954079031944275
Epoch: 54/300 - Train loss: 0.5961421132087708, Validation loss: 0.5930342078208923
Epoch: 55/300 - Train loss: 0.594036340713501, Validation loss: 0.5910801291465759
Epoch: 56/300 - Train loss: 0.591959536075592, Validation loss: 0.5893533229827881
Epoch: 57/300 - Train loss: 0.5899104475975037, Validation loss: 0.5868460536003113
Epoch: 58/300 - Train loss: 0.5878903269767761, Validation loss: 0.584632158279419
Epoch: 59/300 - Train loss: 0.5859000086784363, Validation loss: 0.5828270316123962
Epoch: 60/300 - Train loss: 0.5839404463768005, Validation loss: 0.5811419486999512
Epoch: 61/300 - Train loss: 0.582012951374054, Validation loss: 0.5792985558509827
Epoch: 62/300 - Train loss: 0.5801166892051697, Validation loss: 0.5770382881164551
Epoch: 63/300 - Train loss: 0.5782512426376343, Validation loss: 0.5755597352981567
Epoch: 64/300 - Train loss: 0.5764167904853821, Validation loss: 0.5738499164581299
Epoch: 65/300 - Train loss: 0.574613094329834, Validation loss: 0.5720923542976379
Epoch: 66/300 - Train loss: 0.5728409290313721, Validation loss: 0.5706119537353516
Epoch: 67/300 - Train loss: 0.5710989236831665, Validation loss: 0.5686671733856201
Epoch: 68/300 - Train loss: 0.5693877339363098, Validation loss: 0.5672397613525391
Epoch: 69/300 - Train loss: 0.5677073001861572, Validation loss: 0.565882682800293
Epoch: 70/300 - Train loss: 0.566057562828064, Validation loss: 0.5638667345046997
Epoch: 71/300 - Train loss: 0.5644386410713196, Validation loss: 0.5625824928283691
Epoch: 72/300 - Train loss: 0.5628497004508972, Validation loss: 0.5611560344696045
Epoch: 73/300 - Train loss: 0.5612893104553223, Validation loss: 0.5597887635231018
Epoch: 74/300 - Train loss: 0.5597581267356873, Validation loss: 0.5581033229827881
Epoch: 75/300 - Train loss: 0.5582560300827026, Validation loss: 0.5567145347595215
Epoch: 76/300 - Train loss: 0.5567815899848938, Validation loss: 0.5554344654083252
Epoch: 77/300 - Train loss: 0.5553341507911682, Validation loss: 0.5544472336769104
Epoch: 78/300 - Train loss: 0.5539128184318542, Validation loss: 0.5529186129570007
Epoch: 79/300 - Train loss: 0.5525162220001221, Validation loss: 0.5514789819717407
Epoch: 80/300 - Train loss: 0.5511428713798523, Validation loss: 0.5501863956451416
Epoch: 81/300 - Train loss: 0.5497928261756897, Validation loss: 0.5491426587104797
Epoch: 82/300 - Train loss: 0.5484656095504761, Validation loss: 0.5478379726409912
Epoch: 83/300 - Train loss: 0.5471607446670532, Validation loss: 0.5459946393966675
Epoch: 84/300 - Train loss: 0.5458775162696838, Validation loss: 0.5455338358879089
Epoch: 85/300 - Train loss: 0.5446150302886963, Validation loss: 0.5447521209716797
Epoch: 86/300 - Train loss: 0.5433721542358398, Validation loss: 0.5437647104263306
Epoch: 87/300 - Train loss: 0.542148232460022, Validation loss: 0.5422380566596985
Epoch: 88/300 - Train loss: 0.5409424304962158, Validation loss: 0.5409347414970398
Epoch: 89/300 - Train loss: 0.5397529602050781, Validation loss: 0.5397971272468567
Epoch: 90/300 - Train loss: 0.5385788679122925, Validation loss: 0.5393534302711487
Epoch: 91/300 - Train loss: 0.5374205112457275, Validation loss: 0.5379396080970764
Epoch: 92/300 - Train loss: 0.5362779498100281, Validation loss: 0.5368308424949646
Epoch: 93/300 - Train loss: 0.5351502895355225, Validation loss: 0.5354070663452148
Epoch: 94/300 - Train loss: 0.5340347290039062, Validation loss: 0.5341952443122864
Epoch: 95/300 - Train loss: 0.5329312086105347, Validation loss: 0.5338894128799438
Epoch: 96/300 - Train loss: 0.5318381786346436, Validation loss: 0.5324156284332275
Epoch: 97/300 - Train loss: 0.5307544469833374, Validation loss: 0.5320078134536743
Epoch: 98/300 - Train loss: 0.5296785235404968, Validation loss: 0.5306676626205444
Epoch: 99/300 - Train loss: 0.5286097526550293, Validation loss: 0.5299681425094604
Epoch: 100/300 - Train loss: 0.5275483727455139, Validation loss: 0.5285472273826599
Epoch: 101/300 - Train loss: 0.5264918208122253, Validation loss: 0.5279741883277893
Epoch: 102/300 - Train loss: 0.5254400968551636, Validation loss: 0.5267850160598755
Epoch: 103/300 - Train loss: 0.5243930816650391, Validation loss: 0.5258293151855469
Epoch: 104/300 - Train loss: 0.5233480930328369, Validation loss: 0.5246593356132507
Epoch: 105/300 - Train loss: 0.5223060846328735, Validation loss: 0.5239362716674805
Epoch: 106/300 - Train loss: 0.5212661027908325, Validation loss: 0.5227784514427185
Epoch: 107/300 - Train loss: 0.5202286243438721, Validation loss: 0.5220562219619751
Epoch: 108/300 - Train loss: 0.5191909074783325, Validation loss: 0.5208773612976074
Epoch: 109/300 - Train loss: 0.5181519985198975, Validation loss: 0.519956111907959
Epoch: 110/300 - Train loss: 0.5171103477478027, Validation loss: 0.5186535716056824
Epoch: 111/300 - Train loss: 0.5160682201385498, Validation loss: 0.5181339979171753
Epoch: 112/300 - Train loss: 0.5150271058082581, Validation loss: 0.5169829726219177
Epoch: 113/300 - Train loss: 0.513984203338623, Validation loss: 0.5154685378074646
Epoch: 114/300 - Train loss: 0.5129382014274597, Validation loss: 0.5150162577629089
Epoch: 115/300 - Train loss: 0.5118898749351501, Validation loss: 0.513790488243103
Epoch: 116/300 - Train loss: 0.5108386278152466, Validation loss: 0.512645959854126
Epoch: 117/300 - Train loss: 0.5097845792770386, Validation loss: 0.5114454627037048
Epoch: 118/300 - Train loss: 0.5087316632270813, Validation loss: 0.5107130408287048
Epoch: 119/300 - Train loss: 0.5076783299446106, Validation loss: 0.5094534754753113
Epoch: 120/300 - Train loss: 0.5066242218017578, Validation loss: 0.5083793997764587
Epoch: 121/300 - Train loss: 0.505573034286499, Validation loss: 0.5069469809532166
Epoch: 122/300 - Train loss: 0.5045220851898193, Validation loss: 0.5064478516578674
Epoch: 123/300 - Train loss: 0.5034712553024292, Validation loss: 0.5054329633712769
Epoch: 124/300 - Train loss: 0.5024188160896301, Validation loss: 0.504512369632721
Epoch: 125/300 - Train loss: 0.5013653039932251, Validation loss: 0.5039553046226501
Epoch: 126/300 - Train loss: 0.5003131031990051, Validation loss: 0.5031048059463501
Epoch: 127/300 - Train loss: 0.4992613196372986, Validation loss: 0.5013646483421326
Epoch: 128/300 - Train loss: 0.49820825457572937, Validation loss: 0.4999033510684967
Epoch: 129/300 - Train loss: 0.4971575140953064, Validation loss: 0.4994787275791168
Epoch: 130/300 - Train loss: 0.4961073398590088, Validation loss: 0.4991949796676636
Epoch: 131/300 - Train loss: 0.4950585663318634, Validation loss: 0.49753719568252563
Epoch: 132/300 - Train loss: 0.49401143193244934, Validation loss: 0.49624931812286377
Epoch: 133/300 - Train loss: 0.4929659962654114, Validation loss: 0.4950055181980133
Epoch: 134/300 - Train loss: 0.49192148447036743, Validation loss: 0.4948102831840515
Epoch: 135/300 - Train loss: 0.490876168012619, Validation loss: 0.49342966079711914
Epoch: 136/300 - Train loss: 0.4898287355899811, Validation loss: 0.49302729964256287
Epoch: 137/300 - Train loss: 0.48878368735313416, Validation loss: 0.4910888075828552
Epoch: 138/300 - Train loss: 0.48774033784866333, Validation loss: 0.49097752571105957
Epoch: 139/300 - Train loss: 0.48669788241386414, Validation loss: 0.48959001898765564
Epoch: 140/300 - Train loss: 0.48565608263015747, Validation loss: 0.4883483648300171
Epoch: 141/300 - Train loss: 0.4846135973930359, Validation loss: 0.4871279299259186
Epoch: 142/300 - Train loss: 0.48357051610946655, Validation loss: 0.48616641759872437
Epoch: 143/300 - Train loss: 0.48252758383750916, Validation loss: 0.48498788475990295
Epoch: 144/300 - Train loss: 0.4814860224723816, Validation loss: 0.48401737213134766
Epoch: 145/300 - Train loss: 0.4804456830024719, Validation loss: 0.4840090572834015
Epoch: 146/300 - Train loss: 0.4794074296951294, Validation loss: 0.4828529357910156
Epoch: 147/300 - Train loss: 0.4783702492713928, Validation loss: 0.4809914827346802
Epoch: 148/300 - Train loss: 0.47733205556869507, Validation loss: 0.48007312417030334
Epoch: 149/300 - Train loss: 0.4762934744358063, Validation loss: 0.47915810346603394
Epoch: 150/300 - Train loss: 0.47525593638420105, Validation loss: 0.47870194911956787
Epoch: 151/300 - Train loss: 0.47421711683273315, Validation loss: 0.47714763879776
Epoch: 152/300 - Train loss: 0.4731748700141907, Validation loss: 0.4760429263114929
Epoch: 153/300 - Train loss: 0.472131609916687, Validation loss: 0.47477850317955017
Epoch: 154/300 - Train loss: 0.4710882306098938, Validation loss: 0.4748477041721344
Epoch: 155/300 - Train loss: 0.4700431525707245, Validation loss: 0.4728705883026123
Epoch: 156/300 - Train loss: 0.46899744868278503, Validation loss: 0.47261714935302734
Epoch: 157/300 - Train loss: 0.4679501950740814, Validation loss: 0.47120460867881775
Epoch: 158/300 - Train loss: 0.46689939498901367, Validation loss: 0.4702346920967102
Epoch: 159/300 - Train loss: 0.4658462703227997, Validation loss: 0.46893006563186646
Epoch: 160/300 - Train loss: 0.4647897481918335, Validation loss: 0.4685715436935425
Epoch: 161/300 - Train loss: 0.4637312889099121, Validation loss: 0.46720045804977417
Epoch: 162/300 - Train loss: 0.46266838908195496, Validation loss: 0.4664303958415985
Epoch: 163/300 - Train loss: 0.46160340309143066, Validation loss: 0.4654681384563446
Epoch: 164/300 - Train loss: 0.46054041385650635, Validation loss: 0.4641073942184448
Epoch: 165/300 - Train loss: 0.45947960019111633, Validation loss: 0.4632437825202942
Epoch: 166/300 - Train loss: 0.4584164023399353, Validation loss: 0.4628942310810089
Epoch: 167/300 - Train loss: 0.4573548436164856, Validation loss: 0.46135321259498596
Epoch: 168/300 - Train loss: 0.4562942087650299, Validation loss: 0.4600798189640045
Epoch: 169/300 - Train loss: 0.45523232221603394, Validation loss: 0.4593174457550049
Epoch: 170/300 - Train loss: 0.4541727900505066, Validation loss: 0.45822417736053467
Epoch: 171/300 - Train loss: 0.4531134068965912, Validation loss: 0.45756953954696655
Epoch: 172/300 - Train loss: 0.45205461978912354, Validation loss: 0.45630356669425964
Epoch: 173/300 - Train loss: 0.45099854469299316, Validation loss: 0.455890953540802
Epoch: 174/300 - Train loss: 0.4499449133872986, Validation loss: 0.4550245404243469
Epoch: 175/300 - Train loss: 0.4488936960697174, Validation loss: 0.4536096453666687
Epoch: 176/300 - Train loss: 0.4478440284729004, Validation loss: 0.45297667384147644
Epoch: 177/300 - Train loss: 0.4467943012714386, Validation loss: 0.4510681927204132
Epoch: 178/300 - Train loss: 0.44574376940727234, Validation loss: 0.4507441222667694
Epoch: 179/300 - Train loss: 0.4446934163570404, Validation loss: 0.4495633840560913
Epoch: 180/300 - Train loss: 0.4436425268650055, Validation loss: 0.44836482405662537
Epoch: 181/300 - Train loss: 0.44259172677993774, Validation loss: 0.4472919702529907
Epoch: 182/300 - Train loss: 0.44154036045074463, Validation loss: 0.4462229311466217
Epoch: 183/300 - Train loss: 0.44048720598220825, Validation loss: 0.4456632733345032
Epoch: 184/300 - Train loss: 0.4394351541996002, Validation loss: 0.44469979405403137
Epoch: 185/300 - Train loss: 0.4383816719055176, Validation loss: 0.44375842809677124
Epoch: 186/300 - Train loss: 0.4373302459716797, Validation loss: 0.4424707591533661
Epoch: 187/300 - Train loss: 0.436276912689209, Validation loss: 0.44171142578125
Epoch: 188/300 - Train loss: 0.43522170186042786, Validation loss: 0.4402870237827301
Epoch: 189/300 - Train loss: 0.4341666102409363, Validation loss: 0.43899399042129517
Epoch: 190/300 - Train loss: 0.4331095218658447, Validation loss: 0.4381937086582184
Epoch: 191/300 - Train loss: 0.4320515990257263, Validation loss: 0.4369320571422577
Epoch: 192/300 - Train loss: 0.43099305033683777, Validation loss: 0.43630847334861755
Epoch: 193/300 - Train loss: 0.4299377202987671, Validation loss: 0.43510618805885315
Epoch: 194/300 - Train loss: 0.4288853108882904, Validation loss: 0.4339838922023773
Epoch: 195/300 - Train loss: 0.42783746123313904, Validation loss: 0.4331000745296478
Epoch: 196/300 - Train loss: 0.4267922639846802, Validation loss: 0.43196672201156616
Epoch: 197/300 - Train loss: 0.42575162649154663, Validation loss: 0.4315258860588074
Epoch: 198/300 - Train loss: 0.4247130751609802, Validation loss: 0.4306498169898987
Epoch: 199/300 - Train loss: 0.42367905378341675, Validation loss: 0.4299677312374115
Epoch: 200/300 - Train loss: 0.4226507544517517, Validation loss: 0.42808568477630615
Epoch: 201/300 - Train loss: 0.4216262698173523, Validation loss: 0.42733779549598694
Epoch: 202/300 - Train loss: 0.42060723900794983, Validation loss: 0.4268255829811096
Epoch: 203/300 - Train loss: 0.4195954501628876, Validation loss: 0.42531925439834595
Epoch: 204/300 - Train loss: 0.4185922145843506, Validation loss: 0.4247831702232361
Epoch: 205/300 - Train loss: 0.41759395599365234, Validation loss: 0.42349791526794434
Epoch: 206/300 - Train loss: 0.4166007339954376, Validation loss: 0.4223218858242035
Epoch: 207/300 - Train loss: 0.4156143367290497, Validation loss: 0.42141658067703247
Epoch: 208/300 - Train loss: 0.41463321447372437, Validation loss: 0.4205823838710785
Epoch: 209/300 - Train loss: 0.41365736722946167, Validation loss: 0.4193507134914398
Epoch: 210/300 - Train loss: 0.4126891493797302, Validation loss: 0.41869091987609863
Epoch: 211/300 - Train loss: 0.41172879934310913, Validation loss: 0.41799548268318176
Epoch: 212/300 - Train loss: 0.41077566146850586, Validation loss: 0.4168730676174164
Epoch: 213/300 - Train loss: 0.40982934832572937, Validation loss: 0.4162602126598358
Epoch: 214/300 - Train loss: 0.40889137983322144, Validation loss: 0.4150482714176178
Epoch: 215/300 - Train loss: 0.4079589545726776, Validation loss: 0.41470929980278015
Epoch: 216/300 - Train loss: 0.4070342481136322, Validation loss: 0.41370299458503723
Epoch: 217/300 - Train loss: 0.4061172306537628, Validation loss: 0.4118131697177887
Epoch: 218/300 - Train loss: 0.40520766377449036, Validation loss: 0.4110523760318756
Epoch: 219/300 - Train loss: 0.40430396795272827, Validation loss: 0.4106525182723999
Epoch: 220/300 - Train loss: 0.40341001749038696, Validation loss: 0.4096453785896301
Epoch: 221/300 - Train loss: 0.4025235176086426, Validation loss: 0.40917477011680603
Epoch: 222/300 - Train loss: 0.4016440212726593, Validation loss: 0.40808913111686707
Epoch: 223/300 - Train loss: 0.40077123045921326, Validation loss: 0.40756478905677795
Epoch: 224/300 - Train loss: 0.399906188249588, Validation loss: 0.4058733880519867
Epoch: 225/300 - Train loss: 0.3990476727485657, Validation loss: 0.40566909313201904
Epoch: 226/300 - Train loss: 0.39819711446762085, Validation loss: 0.40440163016319275
Epoch: 227/300 - Train loss: 0.39735516905784607, Validation loss: 0.40421003103256226
Epoch: 228/300 - Train loss: 0.39652010798454285, Validation loss: 0.40330421924591064
Epoch: 229/300 - Train loss: 0.3956923484802246, Validation loss: 0.4020169973373413
Epoch: 230/300 - Train loss: 0.39487138390541077, Validation loss: 0.40216299891471863
Epoch: 231/300 - Train loss: 0.39405909180641174, Validation loss: 0.40100088715553284
Epoch: 232/300 - Train loss: 0.39325571060180664, Validation loss: 0.4002460837364197
Epoch: 233/300 - Train loss: 0.39246177673339844, Validation loss: 0.39938831329345703
Epoch: 234/300 - Train loss: 0.39167866110801697, Validation loss: 0.39869630336761475
Epoch: 235/300 - Train loss: 0.39090538024902344, Validation loss: 0.39778777956962585
Epoch: 236/300 - Train loss: 0.3901413381099701, Validation loss: 0.3972530961036682
Epoch: 237/300 - Train loss: 0.38938578963279724, Validation loss: 0.39646223187446594
Epoch: 238/300 - Train loss: 0.38863950967788696, Validation loss: 0.3952094316482544
Epoch: 239/300 - Train loss: 0.3879021406173706, Validation loss: 0.3952997624874115
Epoch: 240/300 - Train loss: 0.38717180490493774, Validation loss: 0.39395418763160706
Epoch: 241/300 - Train loss: 0.386449933052063, Validation loss: 0.3939187526702881
Epoch: 242/300 - Train loss: 0.38573727011680603, Validation loss: 0.39235562086105347
Epoch: 243/300 - Train loss: 0.3850337862968445, Validation loss: 0.3921405076980591
Epoch: 244/300 - Train loss: 0.38433870673179626, Validation loss: 0.3915054202079773
Epoch: 245/300 - Train loss: 0.38365092873573303, Validation loss: 0.39185619354248047
Epoch: 246/300 - Train loss: 0.3829706609249115, Validation loss: 0.3902819752693176
Epoch: 247/300 - Train loss: 0.3822972774505615, Validation loss: 0.3894868791103363
Epoch: 248/300 - Train loss: 0.3816317617893219, Validation loss: 0.38878434896469116
Epoch: 249/300 - Train loss: 0.3809727728366852, Validation loss: 0.38827037811279297
Epoch: 250/300 - Train loss: 0.38032084703445435, Validation loss: 0.38775813579559326
Epoch: 251/300 - Train loss: 0.3796754479408264, Validation loss: 0.3871924877166748
Epoch: 252/300 - Train loss: 0.3790370225906372, Validation loss: 0.38637983798980713
Epoch: 253/300 - Train loss: 0.3784048855304718, Validation loss: 0.38592594861984253
Epoch: 254/300 - Train loss: 0.3777793347835541, Validation loss: 0.38484326004981995
Epoch: 255/300 - Train loss: 0.37715956568717957, Validation loss: 0.3846259117126465
Epoch: 256/300 - Train loss: 0.3765451908111572, Validation loss: 0.383967787027359
Epoch: 257/300 - Train loss: 0.3759375810623169, Validation loss: 0.38285577297210693
Epoch: 258/300 - Train loss: 0.37533602118492126, Validation loss: 0.38277921080589294
Epoch: 259/300 - Train loss: 0.3747406005859375, Validation loss: 0.3823411762714386
Epoch: 260/300 - Train loss: 0.3741515874862671, Validation loss: 0.38170701265335083
Epoch: 261/300 - Train loss: 0.3735686242580414, Validation loss: 0.3814164996147156
