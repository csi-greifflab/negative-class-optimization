Epoch: 1/100 - Train loss: 0.6945648789405823, Validation loss: 0.6926299333572388
Epoch: 2/100 - Train loss: 0.6932968497276306, Validation loss: 0.6914329528808594
Epoch: 3/100 - Train loss: 0.6920409202575684, Validation loss: 0.6902783513069153
Epoch: 4/100 - Train loss: 0.6907756924629211, Validation loss: 0.6890000104904175
Epoch: 5/100 - Train loss: 0.6894795894622803, Validation loss: 0.6877560615539551
Epoch: 6/100 - Train loss: 0.6881424188613892, Validation loss: 0.6864163875579834
Epoch: 7/100 - Train loss: 0.6867544651031494, Validation loss: 0.6850016117095947
Epoch: 8/100 - Train loss: 0.685303270816803, Validation loss: 0.6834644079208374
Epoch: 9/100 - Train loss: 0.6837781071662903, Validation loss: 0.6819183826446533
Epoch: 10/100 - Train loss: 0.6821776032447815, Validation loss: 0.6803576946258545
Epoch: 11/100 - Train loss: 0.6805023550987244, Validation loss: 0.6786079406738281
Epoch: 12/100 - Train loss: 0.6787525415420532, Validation loss: 0.676857590675354
Epoch: 13/100 - Train loss: 0.6769302487373352, Validation loss: 0.6749874353408813
Epoch: 14/100 - Train loss: 0.6750353574752808, Validation loss: 0.6730831265449524
Epoch: 15/100 - Train loss: 0.6730685234069824, Validation loss: 0.6711480617523193
Epoch: 16/100 - Train loss: 0.6710370182991028, Validation loss: 0.6690282821655273
Epoch: 17/100 - Train loss: 0.6689441800117493, Validation loss: 0.6670136451721191
Epoch: 18/100 - Train loss: 0.6667917370796204, Validation loss: 0.6649006009101868
Epoch: 19/100 - Train loss: 0.6645834445953369, Validation loss: 0.662618100643158
Epoch: 20/100 - Train loss: 0.662320077419281, Validation loss: 0.6603710651397705
Epoch: 21/100 - Train loss: 0.6600023508071899, Validation loss: 0.6581641435623169
Epoch: 22/100 - Train loss: 0.657631516456604, Validation loss: 0.6556785106658936
Epoch: 23/100 - Train loss: 0.6552118062973022, Validation loss: 0.6534311771392822
Epoch: 24/100 - Train loss: 0.6527441143989563, Validation loss: 0.6510259509086609
Epoch: 25/100 - Train loss: 0.6502319574356079, Validation loss: 0.6485271453857422
Epoch: 26/100 - Train loss: 0.6476770639419556, Validation loss: 0.6460625529289246
Epoch: 27/100 - Train loss: 0.6450820565223694, Validation loss: 0.6436607837677002
Epoch: 28/100 - Train loss: 0.6424495577812195, Validation loss: 0.6408467888832092
Epoch: 29/100 - Train loss: 0.639780580997467, Validation loss: 0.6383407115936279
Epoch: 30/100 - Train loss: 0.6370787024497986, Validation loss: 0.6358445286750793
Epoch: 31/100 - Train loss: 0.634346604347229, Validation loss: 0.6331798434257507
Epoch: 32/100 - Train loss: 0.6315869092941284, Validation loss: 0.630531370639801
Epoch: 33/100 - Train loss: 0.6288033127784729, Validation loss: 0.627879798412323
Epoch: 34/100 - Train loss: 0.6259981989860535, Validation loss: 0.6252056360244751
Epoch: 35/100 - Train loss: 0.6231754422187805, Validation loss: 0.6222377419471741
Epoch: 36/100 - Train loss: 0.6203387379646301, Validation loss: 0.6196448802947998
Epoch: 37/100 - Train loss: 0.6174911856651306, Validation loss: 0.6168735027313232
Epoch: 38/100 - Train loss: 0.6146373152732849, Validation loss: 0.6142339110374451
Epoch: 39/100 - Train loss: 0.6117802262306213, Validation loss: 0.6115741729736328
Epoch: 40/100 - Train loss: 0.6089234352111816, Validation loss: 0.6088418960571289
Epoch: 41/100 - Train loss: 0.606070339679718, Validation loss: 0.60599684715271
Epoch: 42/100 - Train loss: 0.6032247543334961, Validation loss: 0.6033138036727905
Epoch: 43/100 - Train loss: 0.6003903150558472, Validation loss: 0.6006920337677002
Epoch: 44/100 - Train loss: 0.59757000207901, Validation loss: 0.5981850028038025
Epoch: 45/100 - Train loss: 0.594767153263092, Validation loss: 0.5952121019363403
Epoch: 46/100 - Train loss: 0.5919849872589111, Validation loss: 0.592424213886261
Epoch: 47/100 - Train loss: 0.5892256498336792, Validation loss: 0.5903743505477905
Epoch: 48/100 - Train loss: 0.5864928364753723, Validation loss: 0.5875831842422485
Epoch: 49/100 - Train loss: 0.5837892293930054, Validation loss: 0.5848991274833679
Epoch: 50/100 - Train loss: 0.5811173915863037, Validation loss: 0.5823572874069214
Epoch: 51/100 - Train loss: 0.5784798264503479, Validation loss: 0.5797616839408875
Epoch: 52/100 - Train loss: 0.5758791565895081, Validation loss: 0.5776271820068359
Epoch: 53/100 - Train loss: 0.5733175277709961, Validation loss: 0.5751148462295532
Epoch: 54/100 - Train loss: 0.5707968473434448, Validation loss: 0.5729301571846008
Epoch: 55/100 - Train loss: 0.5683191418647766, Validation loss: 0.5702716112136841
Epoch: 56/100 - Train loss: 0.5658865571022034, Validation loss: 0.5682051181793213
Epoch: 57/100 - Train loss: 0.5635010600090027, Validation loss: 0.5661343932151794
Epoch: 58/100 - Train loss: 0.561163067817688, Validation loss: 0.5638100504875183
Epoch: 59/100 - Train loss: 0.5588740110397339, Validation loss: 0.5615900158882141
Epoch: 60/100 - Train loss: 0.5566351413726807, Validation loss: 0.5597166419029236
Epoch: 61/100 - Train loss: 0.5544472336769104, Validation loss: 0.5576125383377075
Epoch: 62/100 - Train loss: 0.5523105263710022, Validation loss: 0.5553838610649109
Epoch: 63/100 - Train loss: 0.5502263903617859, Validation loss: 0.5536127090454102
Epoch: 64/100 - Train loss: 0.5481953620910645, Validation loss: 0.5522841215133667
Epoch: 65/100 - Train loss: 0.5462173819541931, Validation loss: 0.5501713156700134
Epoch: 66/100 - Train loss: 0.5442920923233032, Validation loss: 0.5483161211013794
Epoch: 67/100 - Train loss: 0.5424196720123291, Validation loss: 0.5464316010475159
Epoch: 68/100 - Train loss: 0.5405994057655334, Validation loss: 0.5447647571563721
Epoch: 69/100 - Train loss: 0.5388311147689819, Validation loss: 0.543644905090332
Epoch: 70/100 - Train loss: 0.5371145606040955, Validation loss: 0.5419977903366089
Epoch: 71/100 - Train loss: 0.5354486703872681, Validation loss: 0.5408483743667603
Epoch: 72/100 - Train loss: 0.5338324904441833, Validation loss: 0.5391713380813599
Epoch: 73/100 - Train loss: 0.5322651267051697, Validation loss: 0.5371549129486084
Epoch: 74/100 - Train loss: 0.5307459235191345, Validation loss: 0.5366066098213196
Epoch: 75/100 - Train loss: 0.5292733311653137, Validation loss: 0.535027265548706
Epoch: 76/100 - Train loss: 0.5278462767601013, Validation loss: 0.5336712002754211
Epoch: 77/100 - Train loss: 0.5264633893966675, Validation loss: 0.5324794054031372
Epoch: 78/100 - Train loss: 0.525123655796051, Validation loss: 0.5313717722892761
Epoch: 79/100 - Train loss: 0.5238256454467773, Validation loss: 0.5295358896255493
Epoch: 80/100 - Train loss: 0.5225675702095032, Validation loss: 0.5291424989700317
Epoch: 81/100 - Train loss: 0.5213483572006226, Validation loss: 0.5280163288116455
Epoch: 82/100 - Train loss: 0.5201661586761475, Validation loss: 0.5267623066902161
Epoch: 83/100 - Train loss: 0.5190184712409973, Validation loss: 0.5261637568473816
Epoch: 84/100 - Train loss: 0.5179039835929871, Validation loss: 0.5244190096855164
Epoch: 85/100 - Train loss: 0.5168216228485107, Validation loss: 0.5236250758171082
Epoch: 86/100 - Train loss: 0.5157687067985535, Validation loss: 0.5224620699882507
Epoch: 87/100 - Train loss: 0.514742910861969, Validation loss: 0.5217428803443909
Epoch: 88/100 - Train loss: 0.5137431621551514, Validation loss: 0.5204924941062927
Epoch: 89/100 - Train loss: 0.5127682685852051, Validation loss: 0.5198983550071716
Epoch: 90/100 - Train loss: 0.5118164420127869, Validation loss: 0.5186115503311157
Epoch: 91/100 - Train loss: 0.5108858942985535, Validation loss: 0.5186173915863037
Epoch: 92/100 - Train loss: 0.5099760890007019, Validation loss: 0.5173013806343079
Epoch: 93/100 - Train loss: 0.5090853571891785, Validation loss: 0.5167827010154724
Epoch: 94/100 - Train loss: 0.5082123279571533, Validation loss: 0.5156086087226868
Epoch: 95/100 - Train loss: 0.5073559880256653, Validation loss: 0.5158672332763672
Epoch: 96/100 - Train loss: 0.5065139532089233, Validation loss: 0.5146637558937073
Epoch: 97/100 - Train loss: 0.5056866407394409, Validation loss: 0.5134559273719788
Epoch: 98/100 - Train loss: 0.5048711895942688, Validation loss: 0.5130645632743835
Epoch: 99/100 - Train loss: 0.5040674805641174, Validation loss: 0.5118321180343628
Epoch: 100/100 - Train loss: 0.5032753348350525, Validation loss: 0.5109198689460754
Epoch: 1/300 - Train loss: 0.6940543055534363, Validation loss: 0.6928964853286743
Epoch: 2/300 - Train loss: 0.6917345523834229, Validation loss: 0.6905845999717712
Epoch: 3/300 - Train loss: 0.6894279718399048, Validation loss: 0.6883108615875244
Epoch: 4/300 - Train loss: 0.6871058940887451, Validation loss: 0.6859452128410339
Epoch: 5/300 - Train loss: 0.6847505569458008, Validation loss: 0.6835996508598328
Epoch: 6/300 - Train loss: 0.6823334097862244, Validation loss: 0.681117594242096
Epoch: 7/300 - Train loss: 0.6798416972160339, Validation loss: 0.6786099076271057
Epoch: 8/300 - Train loss: 0.6772778034210205, Validation loss: 0.6759578585624695
Epoch: 9/300 - Train loss: 0.6746442317962646, Validation loss: 0.6732641458511353
Epoch: 10/300 - Train loss: 0.671931803226471, Validation loss: 0.6704797148704529
Epoch: 11/300 - Train loss: 0.6691449880599976, Validation loss: 0.6675853729248047
Epoch: 12/300 - Train loss: 0.6662914156913757, Validation loss: 0.6648346185684204
Epoch: 13/300 - Train loss: 0.6633665561676025, Validation loss: 0.661817729473114
Epoch: 14/300 - Train loss: 0.660378634929657, Validation loss: 0.6588559746742249
Epoch: 15/300 - Train loss: 0.6573224663734436, Validation loss: 0.6558224558830261
Epoch: 16/300 - Train loss: 0.6541985273361206, Validation loss: 0.6526036858558655
Epoch: 17/300 - Train loss: 0.651006817817688, Validation loss: 0.6492475271224976
Epoch: 18/300 - Train loss: 0.6477506160736084, Validation loss: 0.6460381746292114
Epoch: 19/300 - Train loss: 0.6444392800331116, Validation loss: 0.6427435874938965
Epoch: 20/300 - Train loss: 0.6410861015319824, Validation loss: 0.6394686102867126
Epoch: 21/300 - Train loss: 0.6376984715461731, Validation loss: 0.6363041996955872
Epoch: 22/300 - Train loss: 0.6342893838882446, Validation loss: 0.6328229308128357
Epoch: 23/300 - Train loss: 0.6308629512786865, Validation loss: 0.6293804049491882
Epoch: 24/300 - Train loss: 0.6274389028549194, Validation loss: 0.6260079145431519
Epoch: 25/300 - Train loss: 0.6240236759185791, Validation loss: 0.6226779818534851
Epoch: 26/300 - Train loss: 0.6206244826316833, Validation loss: 0.6193457245826721
Epoch: 27/300 - Train loss: 0.6172470450401306, Validation loss: 0.6162695288658142
Epoch: 28/300 - Train loss: 0.6138929128646851, Validation loss: 0.6130571365356445
Epoch: 29/300 - Train loss: 0.610564649105072, Validation loss: 0.6095773577690125
Epoch: 30/300 - Train loss: 0.6072645783424377, Validation loss: 0.6066655516624451
Epoch: 31/300 - Train loss: 0.6039931178092957, Validation loss: 0.603610098361969
Epoch: 32/300 - Train loss: 0.6007530093193054, Validation loss: 0.6003394722938538
Epoch: 33/300 - Train loss: 0.5975460410118103, Validation loss: 0.597405195236206
Epoch: 34/300 - Train loss: 0.5943738222122192, Validation loss: 0.5942935943603516
Epoch: 35/300 - Train loss: 0.5912377834320068, Validation loss: 0.5909397006034851
Epoch: 36/300 - Train loss: 0.5881425738334656, Validation loss: 0.5883923172950745
Epoch: 37/300 - Train loss: 0.5850925445556641, Validation loss: 0.5854698419570923
Epoch: 38/300 - Train loss: 0.5820915102958679, Validation loss: 0.5825347304344177
Epoch: 39/300 - Train loss: 0.5791404247283936, Validation loss: 0.5797719955444336
Epoch: 40/300 - Train loss: 0.5762399435043335, Validation loss: 0.5770715475082397
Epoch: 41/300 - Train loss: 0.5733922123908997, Validation loss: 0.5742702484130859
Epoch: 42/300 - Train loss: 0.5705981850624084, Validation loss: 0.5712916851043701
Epoch: 43/300 - Train loss: 0.5678582787513733, Validation loss: 0.5692117214202881
Epoch: 44/300 - Train loss: 0.5651742219924927, Validation loss: 0.5666935443878174
Epoch: 45/300 - Train loss: 0.5625486373901367, Validation loss: 0.5643280744552612
Epoch: 46/300 - Train loss: 0.5599825978279114, Validation loss: 0.561784565448761
Epoch: 47/300 - Train loss: 0.5574762225151062, Validation loss: 0.5595152378082275
Epoch: 48/300 - Train loss: 0.5550294518470764, Validation loss: 0.557623565196991
Epoch: 49/300 - Train loss: 0.5526427626609802, Validation loss: 0.5552287697792053
Epoch: 50/300 - Train loss: 0.5503168702125549, Validation loss: 0.5529823303222656
Epoch: 51/300 - Train loss: 0.5480513572692871, Validation loss: 0.5509340763092041
Epoch: 52/300 - Train loss: 0.5458453297615051, Validation loss: 0.5486540794372559
Epoch: 53/300 - Train loss: 0.5436995625495911, Validation loss: 0.5472687482833862
Epoch: 54/300 - Train loss: 0.5416133999824524, Validation loss: 0.5448001623153687
Epoch: 55/300 - Train loss: 0.5395856499671936, Validation loss: 0.5433245897293091
Epoch: 56/300 - Train loss: 0.5376152396202087, Validation loss: 0.5408933758735657
Epoch: 57/300 - Train loss: 0.5357012748718262, Validation loss: 0.5391073822975159
Epoch: 58/300 - Train loss: 0.5338425636291504, Validation loss: 0.5379130244255066
Epoch: 59/300 - Train loss: 0.5320376753807068, Validation loss: 0.5365300178527832
Epoch: 60/300 - Train loss: 0.5302851796150208, Validation loss: 0.5346808433532715
Epoch: 61/300 - Train loss: 0.5285833477973938, Validation loss: 0.5330531597137451
Epoch: 62/300 - Train loss: 0.5269315242767334, Validation loss: 0.5315006375312805
Epoch: 63/300 - Train loss: 0.5253289341926575, Validation loss: 0.5302228927612305
Epoch: 64/300 - Train loss: 0.5237742066383362, Validation loss: 0.5288215279579163
Epoch: 65/300 - Train loss: 0.5222653150558472, Validation loss: 0.5270890593528748
Epoch: 66/300 - Train loss: 0.5208001732826233, Validation loss: 0.5263914465904236
Epoch: 67/300 - Train loss: 0.519378125667572, Validation loss: 0.5248252153396606
Epoch: 68/300 - Train loss: 0.5179967284202576, Validation loss: 0.52344810962677
Epoch: 69/300 - Train loss: 0.5166541337966919, Validation loss: 0.5220264196395874
Epoch: 70/300 - Train loss: 0.5153493881225586, Validation loss: 0.5212846398353577
Epoch: 71/300 - Train loss: 0.5140814781188965, Validation loss: 0.5194438099861145
Epoch: 72/300 - Train loss: 0.512848436832428, Validation loss: 0.5188374519348145
Epoch: 73/300 - Train loss: 0.5116479992866516, Validation loss: 0.5176898837089539
Epoch: 74/300 - Train loss: 0.5104802250862122, Validation loss: 0.5167788863182068
Epoch: 75/300 - Train loss: 0.5093424320220947, Validation loss: 0.5151465535163879
Epoch: 76/300 - Train loss: 0.5082321763038635, Validation loss: 0.5146228075027466
Epoch: 77/300 - Train loss: 0.5071472525596619, Validation loss: 0.5135481357574463
Epoch: 78/300 - Train loss: 0.5060861110687256, Validation loss: 0.5127195119857788
Epoch: 79/300 - Train loss: 0.5050476789474487, Validation loss: 0.5119778513908386
Epoch: 80/300 - Train loss: 0.5040333271026611, Validation loss: 0.5105406045913696
Epoch: 81/300 - Train loss: 0.5030417442321777, Validation loss: 0.5097318887710571
Epoch: 82/300 - Train loss: 0.5020712614059448, Validation loss: 0.5094226598739624
Epoch: 83/300 - Train loss: 0.5011211037635803, Validation loss: 0.50871741771698
Epoch: 84/300 - Train loss: 0.5001897811889648, Validation loss: 0.5072200298309326
Epoch: 85/300 - Train loss: 0.49927595257759094, Validation loss: 0.5062769651412964
Epoch: 86/300 - Train loss: 0.4983804225921631, Validation loss: 0.5059436559677124
Epoch: 87/300 - Train loss: 0.4975022077560425, Validation loss: 0.5051122307777405
Epoch: 88/300 - Train loss: 0.4966384768486023, Validation loss: 0.5047939419746399
Epoch: 89/300 - Train loss: 0.4957882761955261, Validation loss: 0.5038082003593445
Epoch: 90/300 - Train loss: 0.49495238065719604, Validation loss: 0.502408504486084
Epoch: 91/300 - Train loss: 0.49412980675697327, Validation loss: 0.5018091797828674
Epoch: 92/300 - Train loss: 0.49332067370414734, Validation loss: 0.5008819699287415
Epoch: 93/300 - Train loss: 0.49252352118492126, Validation loss: 0.5002267360687256
Epoch: 94/300 - Train loss: 0.4917377233505249, Validation loss: 0.4994423985481262
Epoch: 95/300 - Train loss: 0.49096226692199707, Validation loss: 0.4984777271747589
Epoch: 96/300 - Train loss: 0.4901958703994751, Validation loss: 0.4974439740180969
Epoch: 97/300 - Train loss: 0.4894387125968933, Validation loss: 0.49710536003112793
Epoch: 98/300 - Train loss: 0.48869043588638306, Validation loss: 0.4966129958629608
Epoch: 99/300 - Train loss: 0.4879496097564697, Validation loss: 0.49573251605033875
Epoch: 100/300 - Train loss: 0.48721492290496826, Validation loss: 0.49536436796188354
Epoch: 101/300 - Train loss: 0.48648539185523987, Validation loss: 0.4941224455833435
Epoch: 102/300 - Train loss: 0.4857623279094696, Validation loss: 0.4938753545284271
Epoch: 103/300 - Train loss: 0.48504629731178284, Validation loss: 0.4932820498943329
Epoch: 104/300 - Train loss: 0.4843359589576721, Validation loss: 0.4924749732017517
Epoch: 105/300 - Train loss: 0.4836304485797882, Validation loss: 0.4919317364692688
Epoch: 106/300 - Train loss: 0.482930451631546, Validation loss: 0.4906272888183594
Epoch: 107/300 - Train loss: 0.48223569989204407, Validation loss: 0.49045005440711975
Epoch: 108/300 - Train loss: 0.4815466105937958, Validation loss: 0.48949986696243286
Epoch: 109/300 - Train loss: 0.480861634016037, Validation loss: 0.4885307550430298
Epoch: 110/300 - Train loss: 0.4801788628101349, Validation loss: 0.4884888529777527
Epoch: 111/300 - Train loss: 0.47949740290641785, Validation loss: 0.4876043200492859
Epoch: 112/300 - Train loss: 0.47881877422332764, Validation loss: 0.48655790090560913
Epoch: 113/300 - Train loss: 0.47814270853996277, Validation loss: 0.48726555705070496
Epoch: 114/300 - Train loss: 0.47746938467025757, Validation loss: 0.48559704422950745
Epoch: 115/300 - Train loss: 0.47679728269577026, Validation loss: 0.4849293529987335
Epoch: 116/300 - Train loss: 0.47612646222114563, Validation loss: 0.4841035008430481
Epoch: 117/300 - Train loss: 0.4754556715488434, Validation loss: 0.483907014131546
Epoch: 118/300 - Train loss: 0.4747859537601471, Validation loss: 0.4832533597946167
Epoch: 119/300 - Train loss: 0.47411784529685974, Validation loss: 0.4830266833305359
Epoch: 120/300 - Train loss: 0.47344970703125, Validation loss: 0.48219531774520874
Epoch: 121/300 - Train loss: 0.47278138995170593, Validation loss: 0.48157986998558044
Epoch: 122/300 - Train loss: 0.4721098244190216, Validation loss: 0.4805546700954437
Epoch: 123/300 - Train loss: 0.47143828868865967, Validation loss: 0.4801054000854492
Epoch: 124/300 - Train loss: 0.47076740860939026, Validation loss: 0.47951292991638184
Epoch: 125/300 - Train loss: 0.4700971841812134, Validation loss: 0.47910016775131226
Epoch: 126/300 - Train loss: 0.4694265127182007, Validation loss: 0.4786643385887146
Epoch: 127/300 - Train loss: 0.46875450015068054, Validation loss: 0.4783254861831665
