Epoch: 1/100 - Train loss: 0.7007076144218445, Validation loss: 0.700769305229187
Epoch: 2/100 - Train loss: 0.6990880370140076, Validation loss: 0.6993914246559143
Epoch: 3/100 - Train loss: 0.6975304484367371, Validation loss: 0.6977421641349792
Epoch: 4/100 - Train loss: 0.6959992051124573, Validation loss: 0.6963050961494446
Epoch: 5/100 - Train loss: 0.6944600939750671, Validation loss: 0.6949028372764587
Epoch: 6/100 - Train loss: 0.6928924322128296, Validation loss: 0.6932515501976013
Epoch: 7/100 - Train loss: 0.6912739872932434, Validation loss: 0.6917311549186707
Epoch: 8/100 - Train loss: 0.6895872950553894, Validation loss: 0.6900722980499268
Epoch: 9/100 - Train loss: 0.6878198981285095, Validation loss: 0.6880553960800171
Epoch: 10/100 - Train loss: 0.6859707236289978, Validation loss: 0.6863467693328857
Epoch: 11/100 - Train loss: 0.6840373873710632, Validation loss: 0.6843520402908325
Epoch: 12/100 - Train loss: 0.6820209622383118, Validation loss: 0.6824564337730408
Epoch: 13/100 - Train loss: 0.6799248456954956, Validation loss: 0.6804984211921692
Epoch: 14/100 - Train loss: 0.6777521967887878, Validation loss: 0.6781349182128906
Epoch: 15/100 - Train loss: 0.675502598285675, Validation loss: 0.6759765148162842
Epoch: 16/100 - Train loss: 0.6731805801391602, Validation loss: 0.6736177206039429
Epoch: 17/100 - Train loss: 0.6707898378372192, Validation loss: 0.6712779402732849
Epoch: 18/100 - Train loss: 0.6683325171470642, Validation loss: 0.6687589883804321
Epoch: 19/100 - Train loss: 0.6658110618591309, Validation loss: 0.6661447286605835
Epoch: 20/100 - Train loss: 0.6632240414619446, Validation loss: 0.663443922996521
Epoch: 21/100 - Train loss: 0.6605709791183472, Validation loss: 0.6611577272415161
Epoch: 22/100 - Train loss: 0.657850444316864, Validation loss: 0.6581463813781738
Epoch: 23/100 - Train loss: 0.6550625562667847, Validation loss: 0.6554155945777893
Epoch: 24/100 - Train loss: 0.6522086262702942, Validation loss: 0.6525294780731201
Epoch: 25/100 - Train loss: 0.6492879390716553, Validation loss: 0.6497250199317932
Epoch: 26/100 - Train loss: 0.6463003754615784, Validation loss: 0.6468827128410339
Epoch: 27/100 - Train loss: 0.6432473063468933, Validation loss: 0.6434665322303772
Epoch: 28/100 - Train loss: 0.6401302218437195, Validation loss: 0.6403791904449463
Epoch: 29/100 - Train loss: 0.6369510889053345, Validation loss: 0.6372776031494141
Epoch: 30/100 - Train loss: 0.6337116360664368, Validation loss: 0.6339289546012878
Epoch: 31/100 - Train loss: 0.6304136514663696, Validation loss: 0.6306078433990479
Epoch: 32/100 - Train loss: 0.6270595788955688, Validation loss: 0.6271959543228149
Epoch: 33/100 - Train loss: 0.6236512660980225, Validation loss: 0.6236758828163147
Epoch: 34/100 - Train loss: 0.6201907992362976, Validation loss: 0.6205690503120422
Epoch: 35/100 - Train loss: 0.6166796684265137, Validation loss: 0.6167589426040649
Epoch: 36/100 - Train loss: 0.6131204962730408, Validation loss: 0.6132710576057434
Epoch: 37/100 - Train loss: 0.6095158457756042, Validation loss: 0.6095855236053467
Epoch: 38/100 - Train loss: 0.6058676838874817, Validation loss: 0.6058765649795532
Epoch: 39/100 - Train loss: 0.6021784543991089, Validation loss: 0.6022407412528992
Epoch: 40/100 - Train loss: 0.5984506011009216, Validation loss: 0.5986191034317017
Epoch: 41/100 - Train loss: 0.5946861505508423, Validation loss: 0.5948055386543274
Epoch: 42/100 - Train loss: 0.5908880829811096, Validation loss: 0.5909069776535034
Epoch: 43/100 - Train loss: 0.5870586037635803, Validation loss: 0.5872446298599243
Epoch: 44/100 - Train loss: 0.5832007527351379, Validation loss: 0.5834130644798279
Epoch: 45/100 - Train loss: 0.5793168544769287, Validation loss: 0.5795021653175354
Epoch: 46/100 - Train loss: 0.575410008430481, Validation loss: 0.5757067799568176
Epoch: 47/100 - Train loss: 0.5714830756187439, Validation loss: 0.5715491771697998
Epoch: 48/100 - Train loss: 0.5675394535064697, Validation loss: 0.5674474835395813
Epoch: 49/100 - Train loss: 0.5635823011398315, Validation loss: 0.5635069608688354
Epoch: 50/100 - Train loss: 0.559614360332489, Validation loss: 0.5595703125
Epoch: 51/100 - Train loss: 0.5556395649909973, Validation loss: 0.555473804473877
Epoch: 52/100 - Train loss: 0.5516613721847534, Validation loss: 0.5516364574432373
Epoch: 53/100 - Train loss: 0.5476835370063782, Validation loss: 0.5476803183555603
Epoch: 54/100 - Train loss: 0.5437096953392029, Validation loss: 0.5436882376670837
Epoch: 55/100 - Train loss: 0.5397433042526245, Validation loss: 0.5399839878082275
Epoch: 56/100 - Train loss: 0.5357882380485535, Validation loss: 0.5356683135032654
Epoch: 57/100 - Train loss: 0.5318483710289001, Validation loss: 0.5316714644432068
Epoch: 58/100 - Train loss: 0.5279273390769958, Validation loss: 0.5278512835502625
Epoch: 59/100 - Train loss: 0.5240283608436584, Validation loss: 0.5240504741668701
Epoch: 60/100 - Train loss: 0.5201545357704163, Validation loss: 0.5198308229446411
Epoch: 61/100 - Train loss: 0.5163090825080872, Validation loss: 0.5162993669509888
Epoch: 62/100 - Train loss: 0.5124955177307129, Validation loss: 0.512671947479248
Epoch: 63/100 - Train loss: 0.5087165832519531, Validation loss: 0.5084041953086853
Epoch: 64/100 - Train loss: 0.5049753189086914, Validation loss: 0.5049396753311157
Epoch: 65/100 - Train loss: 0.5012744665145874, Validation loss: 0.5012180805206299
Epoch: 66/100 - Train loss: 0.49761658906936646, Validation loss: 0.49793264269828796
Epoch: 67/100 - Train loss: 0.49400317668914795, Validation loss: 0.49411165714263916
Epoch: 68/100 - Train loss: 0.49043598771095276, Validation loss: 0.49086204171180725
Epoch: 69/100 - Train loss: 0.4869171679019928, Validation loss: 0.48702648282051086
Epoch: 70/100 - Train loss: 0.4834488332271576, Validation loss: 0.48305079340934753
Epoch: 71/100 - Train loss: 0.48003220558166504, Validation loss: 0.48013582825660706
Epoch: 72/100 - Train loss: 0.4766682982444763, Validation loss: 0.476765513420105
Epoch: 73/100 - Train loss: 0.4733584523200989, Validation loss: 0.473228394985199
Epoch: 74/100 - Train loss: 0.4701036512851715, Validation loss: 0.4701593518257141
Epoch: 75/100 - Train loss: 0.46690359711647034, Validation loss: 0.46684667468070984
Epoch: 76/100 - Train loss: 0.46375948190689087, Validation loss: 0.46372079849243164
Epoch: 77/100 - Train loss: 0.460671603679657, Validation loss: 0.46132662892341614
Epoch: 78/100 - Train loss: 0.4576404094696045, Validation loss: 0.4578704535961151
Epoch: 79/100 - Train loss: 0.45466452836990356, Validation loss: 0.45460250973701477
Epoch: 80/100 - Train loss: 0.4517422318458557, Validation loss: 0.4517591595649719
Epoch: 81/100 - Train loss: 0.4488729238510132, Validation loss: 0.4489477574825287
Epoch: 82/100 - Train loss: 0.4460557699203491, Validation loss: 0.4460359513759613
Epoch: 83/100 - Train loss: 0.4432891011238098, Validation loss: 0.4435577690601349
Epoch: 84/100 - Train loss: 0.44057121872901917, Validation loss: 0.44059088826179504
Epoch: 85/100 - Train loss: 0.4379020035266876, Validation loss: 0.438442587852478
Epoch: 86/100 - Train loss: 0.43528035283088684, Validation loss: 0.4353830814361572
Epoch: 87/100 - Train loss: 0.4327048659324646, Validation loss: 0.43282032012939453
Epoch: 88/100 - Train loss: 0.43017157912254333, Validation loss: 0.4307738244533539
Epoch: 89/100 - Train loss: 0.4276825189590454, Validation loss: 0.4280596375465393
Epoch: 90/100 - Train loss: 0.425237238407135, Validation loss: 0.4251863360404968
Epoch: 91/100 - Train loss: 0.4228385388851166, Validation loss: 0.42316895723342896
Epoch: 92/100 - Train loss: 0.4204857647418976, Validation loss: 0.42031413316726685
Epoch: 93/100 - Train loss: 0.41817691922187805, Validation loss: 0.4184236228466034
Epoch: 94/100 - Train loss: 0.4159121811389923, Validation loss: 0.4159945845603943
Epoch: 95/100 - Train loss: 0.41369250416755676, Validation loss: 0.4140055775642395
Epoch: 96/100 - Train loss: 0.4115177094936371, Validation loss: 0.4113231897354126
Epoch: 97/100 - Train loss: 0.40938806533813477, Validation loss: 0.40940630435943604
Epoch: 98/100 - Train loss: 0.4073030650615692, Validation loss: 0.40702807903289795
Epoch: 99/100 - Train loss: 0.40525761246681213, Validation loss: 0.40475019812583923
Epoch: 100/100 - Train loss: 0.40325087308883667, Validation loss: 0.40314969420433044
Epoch: 1/300 - Train loss: 0.7034677267074585, Validation loss: 0.7028259634971619
Epoch: 2/300 - Train loss: 0.7014047503471375, Validation loss: 0.7007102966308594
Epoch: 3/300 - Train loss: 0.6993791460990906, Validation loss: 0.6987649202346802
Epoch: 4/300 - Train loss: 0.6973400712013245, Validation loss: 0.696678876876831
Epoch: 5/300 - Train loss: 0.6952307820320129, Validation loss: 0.6943901181221008
Epoch: 6/300 - Train loss: 0.6930032968521118, Validation loss: 0.6919482946395874
Epoch: 7/300 - Train loss: 0.6906228065490723, Validation loss: 0.6894827485084534
Epoch: 8/300 - Train loss: 0.688057005405426, Validation loss: 0.68677818775177
Epoch: 9/300 - Train loss: 0.6852859258651733, Validation loss: 0.6836746335029602
Epoch: 10/300 - Train loss: 0.6823071837425232, Validation loss: 0.6804999113082886
Epoch: 11/300 - Train loss: 0.679115891456604, Validation loss: 0.6773393154144287
Epoch: 12/300 - Train loss: 0.6757134199142456, Validation loss: 0.6735950112342834
Epoch: 13/300 - Train loss: 0.672100841999054, Validation loss: 0.6697689294815063
Epoch: 14/300 - Train loss: 0.6682894825935364, Validation loss: 0.6657329797744751
Epoch: 15/300 - Train loss: 0.6642900705337524, Validation loss: 0.6616960763931274
Epoch: 16/300 - Train loss: 0.6601212024688721, Validation loss: 0.6572913527488708
Epoch: 17/300 - Train loss: 0.6557931303977966, Validation loss: 0.6528211832046509
Epoch: 18/300 - Train loss: 0.651329755783081, Validation loss: 0.6483331918716431
Epoch: 19/300 - Train loss: 0.6467636823654175, Validation loss: 0.643589437007904
Epoch: 20/300 - Train loss: 0.6421122550964355, Validation loss: 0.6389868259429932
Epoch: 21/300 - Train loss: 0.6373909711837769, Validation loss: 0.6344440579414368
Epoch: 22/300 - Train loss: 0.6326150298118591, Validation loss: 0.6297693252563477
Epoch: 23/300 - Train loss: 0.6277968287467957, Validation loss: 0.624823272228241
Epoch: 24/300 - Train loss: 0.6229445338249207, Validation loss: 0.6199076175689697
Epoch: 25/300 - Train loss: 0.6180644035339355, Validation loss: 0.6151118278503418
Epoch: 26/300 - Train loss: 0.6131669878959656, Validation loss: 0.6102608442306519
Epoch: 27/300 - Train loss: 0.6082606315612793, Validation loss: 0.6053369045257568
Epoch: 28/300 - Train loss: 0.6033499240875244, Validation loss: 0.6005064845085144
Epoch: 29/300 - Train loss: 0.5984367728233337, Validation loss: 0.5955119132995605
Epoch: 30/300 - Train loss: 0.5935249328613281, Validation loss: 0.5906875729560852
Epoch: 31/300 - Train loss: 0.5886231064796448, Validation loss: 0.5857618451118469
Epoch: 32/300 - Train loss: 0.5837337970733643, Validation loss: 0.5812976360321045
Epoch: 33/300 - Train loss: 0.5788607597351074, Validation loss: 0.5762828588485718
Epoch: 34/300 - Train loss: 0.5740063786506653, Validation loss: 0.5714511871337891
Epoch: 35/300 - Train loss: 0.5691744685173035, Validation loss: 0.5665857791900635
Epoch: 36/300 - Train loss: 0.5643694996833801, Validation loss: 0.5618900656700134
Epoch: 37/300 - Train loss: 0.5595955848693848, Validation loss: 0.5574054718017578
Epoch: 38/300 - Train loss: 0.5548564791679382, Validation loss: 0.5525835156440735
Epoch: 39/300 - Train loss: 0.5501549243927002, Validation loss: 0.5482097864151001
Epoch: 40/300 - Train loss: 0.5454938411712646, Validation loss: 0.5433047413825989
Epoch: 41/300 - Train loss: 0.5408765077590942, Validation loss: 0.538651168346405
Epoch: 42/300 - Train loss: 0.5363044738769531, Validation loss: 0.5337462425231934
Epoch: 43/300 - Train loss: 0.531782865524292, Validation loss: 0.5297734141349792
Epoch: 44/300 - Train loss: 0.5273149013519287, Validation loss: 0.5253919959068298
Epoch: 45/300 - Train loss: 0.5229031443595886, Validation loss: 0.5209438800811768
Epoch: 46/300 - Train loss: 0.5185496211051941, Validation loss: 0.5163847804069519
Epoch: 47/300 - Train loss: 0.5142554044723511, Validation loss: 0.5123521685600281
Epoch: 48/300 - Train loss: 0.5100211501121521, Validation loss: 0.5081255435943604
Epoch: 49/300 - Train loss: 0.5058493614196777, Validation loss: 0.503924548625946
Epoch: 50/300 - Train loss: 0.5017434358596802, Validation loss: 0.500115156173706
Epoch: 51/300 - Train loss: 0.49770402908325195, Validation loss: 0.4962366223335266
Epoch: 52/300 - Train loss: 0.49373430013656616, Validation loss: 0.49188730120658875
Epoch: 53/300 - Train loss: 0.489835262298584, Validation loss: 0.48786434531211853
Epoch: 54/300 - Train loss: 0.4860057830810547, Validation loss: 0.48442065715789795
Epoch: 55/300 - Train loss: 0.48224714398384094, Validation loss: 0.48017391562461853
Epoch: 56/300 - Train loss: 0.47856196761131287, Validation loss: 0.47653624415397644
Epoch: 57/300 - Train loss: 0.4749525189399719, Validation loss: 0.47333598136901855
Epoch: 58/300 - Train loss: 0.4714204967021942, Validation loss: 0.47002696990966797
Epoch: 59/300 - Train loss: 0.46796613931655884, Validation loss: 0.46654415130615234
Epoch: 60/300 - Train loss: 0.4645896255970001, Validation loss: 0.4628497064113617
Epoch: 61/300 - Train loss: 0.46129074692726135, Validation loss: 0.4600847363471985
Epoch: 62/300 - Train loss: 0.45807084441185, Validation loss: 0.4567425549030304
Epoch: 63/300 - Train loss: 0.4549295902252197, Validation loss: 0.45306316018104553
Epoch: 64/300 - Train loss: 0.4518667161464691, Validation loss: 0.4504842162132263
Epoch: 65/300 - Train loss: 0.4488815367221832, Validation loss: 0.4472271203994751
Epoch: 66/300 - Train loss: 0.44597333669662476, Validation loss: 0.44402891397476196
Epoch: 67/300 - Train loss: 0.4431415796279907, Validation loss: 0.44117122888565063
Epoch: 68/300 - Train loss: 0.4403855502605438, Validation loss: 0.43895405530929565
Epoch: 69/300 - Train loss: 0.4377039670944214, Validation loss: 0.43618664145469666
Epoch: 70/300 - Train loss: 0.4350959062576294, Validation loss: 0.4336140751838684
Epoch: 71/300 - Train loss: 0.4325600564479828, Validation loss: 0.43111732602119446
Epoch: 72/300 - Train loss: 0.43009504675865173, Validation loss: 0.42846953868865967
Epoch: 73/300 - Train loss: 0.42770007252693176, Validation loss: 0.4259018301963806
Epoch: 74/300 - Train loss: 0.4253736734390259, Validation loss: 0.4239742159843445
Epoch: 75/300 - Train loss: 0.4231138229370117, Validation loss: 0.421832799911499
Epoch: 76/300 - Train loss: 0.42091843485832214, Validation loss: 0.41969922184944153
Epoch: 77/300 - Train loss: 0.41878631711006165, Validation loss: 0.41751334071159363
Epoch: 78/300 - Train loss: 0.41671597957611084, Validation loss: 0.4151950478553772
Epoch: 79/300 - Train loss: 0.4147063195705414, Validation loss: 0.4132818281650543
Epoch: 80/300 - Train loss: 0.41275498270988464, Validation loss: 0.41086897253990173
Epoch: 81/300 - Train loss: 0.410860151052475, Validation loss: 0.4093629717826843
Epoch: 82/300 - Train loss: 0.40902000665664673, Validation loss: 0.40747660398483276
Epoch: 83/300 - Train loss: 0.4072331488132477, Validation loss: 0.40600770711898804
Epoch: 84/300 - Train loss: 0.40549740195274353, Validation loss: 0.4037584960460663
Epoch: 85/300 - Train loss: 0.4038107395172119, Validation loss: 0.4022374451160431
Epoch: 86/300 - Train loss: 0.4021720588207245, Validation loss: 0.40087035298347473
Epoch: 87/300 - Train loss: 0.4005796015262604, Validation loss: 0.3987114727497101
Epoch: 88/300 - Train loss: 0.39903122186660767, Validation loss: 0.3970696032047272
Epoch: 89/300 - Train loss: 0.39752450585365295, Validation loss: 0.39555075764656067
Epoch: 90/300 - Train loss: 0.396058052778244, Validation loss: 0.3952715992927551
Epoch: 91/300 - Train loss: 0.39463043212890625, Validation loss: 0.3928094506263733
Epoch: 92/300 - Train loss: 0.3932393193244934, Validation loss: 0.39147841930389404
Epoch: 93/300 - Train loss: 0.39188334345817566, Validation loss: 0.3900715410709381
Epoch: 94/300 - Train loss: 0.3905608654022217, Validation loss: 0.38867858052253723
Epoch: 95/300 - Train loss: 0.3892707824707031, Validation loss: 0.38717710971832275
Epoch: 96/300 - Train loss: 0.38801008462905884, Validation loss: 0.38683560490608215
Epoch: 97/300 - Train loss: 0.38677820563316345, Validation loss: 0.38495537638664246
Epoch: 98/300 - Train loss: 0.3855744004249573, Validation loss: 0.38370954990386963
Epoch: 99/300 - Train loss: 0.3843976557254791, Validation loss: 0.3826674520969391
Epoch: 100/300 - Train loss: 0.38324597477912903, Validation loss: 0.381070613861084
Epoch: 101/300 - Train loss: 0.3821175694465637, Validation loss: 0.3803230822086334
Epoch: 102/300 - Train loss: 0.3810122311115265, Validation loss: 0.3789380192756653
Epoch: 103/300 - Train loss: 0.37992942333221436, Validation loss: 0.3778711259365082
Epoch: 104/300 - Train loss: 0.3788694739341736, Validation loss: 0.37701207399368286
Epoch: 105/300 - Train loss: 0.3778308928012848, Validation loss: 0.3755595088005066
Epoch: 106/300 - Train loss: 0.3768099546432495, Validation loss: 0.375993013381958
Epoch: 107/300 - Train loss: 0.37580662965774536, Validation loss: 0.3734034299850464
Epoch: 108/300 - Train loss: 0.37482157349586487, Validation loss: 0.372445672750473
Epoch: 109/300 - Train loss: 0.37385451793670654, Validation loss: 0.3715444505214691
Epoch: 110/300 - Train loss: 0.37290388345718384, Validation loss: 0.3706377446651459
Epoch: 111/300 - Train loss: 0.3719688653945923, Validation loss: 0.3696443438529968
Epoch: 112/300 - Train loss: 0.3710492253303528, Validation loss: 0.36880213022232056
Epoch: 113/300 - Train loss: 0.3701421022415161, Validation loss: 0.36815229058265686
Epoch: 114/300 - Train loss: 0.3692469894886017, Validation loss: 0.366884708404541
Epoch: 115/300 - Train loss: 0.3683651089668274, Validation loss: 0.3662395179271698
Epoch: 116/300 - Train loss: 0.3674953281879425, Validation loss: 0.3653406500816345
Epoch: 117/300 - Train loss: 0.36663657426834106, Validation loss: 0.36407819390296936
Epoch: 118/300 - Train loss: 0.36578837037086487, Validation loss: 0.36312857270240784
Epoch: 119/300 - Train loss: 0.36494970321655273, Validation loss: 0.3634493947029114
Epoch: 120/300 - Train loss: 0.3641200363636017, Validation loss: 0.36208102107048035
Epoch: 121/300 - Train loss: 0.36329907178878784, Validation loss: 0.36100879311561584
Epoch: 122/300 - Train loss: 0.3624878525733948, Validation loss: 0.36054787039756775
Epoch: 123/300 - Train loss: 0.36168530583381653, Validation loss: 0.36009612679481506
Epoch: 124/300 - Train loss: 0.3608924448490143, Validation loss: 0.3588520586490631
Epoch: 125/300 - Train loss: 0.360108882188797, Validation loss: 0.3574701249599457
Epoch: 126/300 - Train loss: 0.3593354821205139, Validation loss: 0.3568940758705139
Epoch: 127/300 - Train loss: 0.35857129096984863, Validation loss: 0.35581907629966736
Epoch: 128/300 - Train loss: 0.3578145205974579, Validation loss: 0.35557711124420166
Epoch: 129/300 - Train loss: 0.35706573724746704, Validation loss: 0.3548360764980316
Epoch: 130/300 - Train loss: 0.3563247323036194, Validation loss: 0.3544996976852417
Epoch: 131/300 - Train loss: 0.35559147596359253, Validation loss: 0.35353371500968933
Epoch: 132/300 - Train loss: 0.35486793518066406, Validation loss: 0.3526875674724579
Epoch: 133/300 - Train loss: 0.3541533946990967, Validation loss: 0.3527742028236389
Epoch: 134/300 - Train loss: 0.3534473478794098, Validation loss: 0.3509615957736969
Epoch: 135/300 - Train loss: 0.3527494966983795, Validation loss: 0.35005179047584534
Epoch: 136/300 - Train loss: 0.35205990076065063, Validation loss: 0.35071271657943726
Epoch: 137/300 - Train loss: 0.35137835144996643, Validation loss: 0.3485065996646881
Epoch: 138/300 - Train loss: 0.35070478916168213, Validation loss: 0.34895116090774536
Epoch: 139/300 - Train loss: 0.350038081407547, Validation loss: 0.34756049513816833
Epoch: 140/300 - Train loss: 0.3493778705596924, Validation loss: 0.3466666638851166
Epoch: 141/300 - Train loss: 0.34872379899024963, Validation loss: 0.3467806875705719
Epoch: 142/300 - Train loss: 0.3480769395828247, Validation loss: 0.3450872302055359
Epoch: 143/300 - Train loss: 0.3474361300468445, Validation loss: 0.34503278136253357
Epoch: 144/300 - Train loss: 0.3468021750450134, Validation loss: 0.34404465556144714
Epoch: 145/300 - Train loss: 0.3461741805076599, Validation loss: 0.34345608949661255
Epoch: 146/300 - Train loss: 0.3455503284931183, Validation loss: 0.3431266248226166
Epoch: 147/300 - Train loss: 0.34493187069892883, Validation loss: 0.342355877161026
Epoch: 148/300 - Train loss: 0.34431973099708557, Validation loss: 0.3414040803909302
Epoch: 149/300 - Train loss: 0.3437134027481079, Validation loss: 0.3412332534790039
Epoch: 150/300 - Train loss: 0.343112051486969, Validation loss: 0.34125393629074097
Epoch: 151/300 - Train loss: 0.34251537919044495, Validation loss: 0.33949974179267883
Epoch: 152/300 - Train loss: 0.3419246971607208, Validation loss: 0.33935126662254333
Epoch: 153/300 - Train loss: 0.34133923053741455, Validation loss: 0.3387276530265808
Epoch: 154/300 - Train loss: 0.340758353471756, Validation loss: 0.33799344301223755
Epoch: 155/300 - Train loss: 0.3401823937892914, Validation loss: 0.3371444344520569
Epoch: 156/300 - Train loss: 0.33961087465286255, Validation loss: 0.3368810713291168
Epoch: 157/300 - Train loss: 0.33904367685317993, Validation loss: 0.3366117477416992
