Epoch: 1/300 - Train loss: 0.6916626691818237, Validation loss: 0.6904264688491821
Epoch: 2/300 - Train loss: 0.6900725364685059, Validation loss: 0.6887714266777039
Epoch: 3/300 - Train loss: 0.6885058283805847, Validation loss: 0.6871713399887085
Epoch: 4/300 - Train loss: 0.686933159828186, Validation loss: 0.6855463981628418
Epoch: 5/300 - Train loss: 0.685329020023346, Validation loss: 0.6837864518165588
Epoch: 6/300 - Train loss: 0.6836633682250977, Validation loss: 0.6820297241210938
Epoch: 7/300 - Train loss: 0.6819186806678772, Validation loss: 0.6801183223724365
Epoch: 8/300 - Train loss: 0.6800768971443176, Validation loss: 0.6781935691833496
Epoch: 9/300 - Train loss: 0.6781311631202698, Validation loss: 0.6760668158531189
Epoch: 10/300 - Train loss: 0.6760817170143127, Validation loss: 0.6738454699516296
Epoch: 11/300 - Train loss: 0.6739307641983032, Validation loss: 0.6715012788772583
Epoch: 12/300 - Train loss: 0.6716819405555725, Validation loss: 0.6691125631332397
Epoch: 13/300 - Train loss: 0.6693381071090698, Validation loss: 0.666556179523468
Epoch: 14/300 - Train loss: 0.6669120788574219, Validation loss: 0.6639405488967896
Epoch: 15/300 - Train loss: 0.6644144058227539, Validation loss: 0.6612858772277832
Epoch: 16/300 - Train loss: 0.6618639230728149, Validation loss: 0.6585533022880554
Epoch: 17/300 - Train loss: 0.6592662334442139, Validation loss: 0.6559016108512878
Epoch: 18/300 - Train loss: 0.6566362977027893, Validation loss: 0.653279721736908
Epoch: 19/300 - Train loss: 0.6539837121963501, Validation loss: 0.6503521800041199
Epoch: 20/300 - Train loss: 0.6513150930404663, Validation loss: 0.6478492617607117
Epoch: 21/300 - Train loss: 0.6486371755599976, Validation loss: 0.6450127959251404
Epoch: 22/300 - Train loss: 0.645950198173523, Validation loss: 0.6422961354255676
Epoch: 23/300 - Train loss: 0.6432539224624634, Validation loss: 0.6395931243896484
Epoch: 24/300 - Train loss: 0.6405542492866516, Validation loss: 0.6367321610450745
Epoch: 25/300 - Train loss: 0.6378507018089294, Validation loss: 0.633994996547699
Epoch: 26/300 - Train loss: 0.6351462006568909, Validation loss: 0.63125079870224
Epoch: 27/300 - Train loss: 0.6324396133422852, Validation loss: 0.6285009980201721
Epoch: 28/300 - Train loss: 0.6297340393066406, Validation loss: 0.6257950663566589
Epoch: 29/300 - Train loss: 0.6270343065261841, Validation loss: 0.6231926679611206
Epoch: 30/300 - Train loss: 0.6243417859077454, Validation loss: 0.620296061038971
Epoch: 31/300 - Train loss: 0.6216615438461304, Validation loss: 0.6178056001663208
Epoch: 32/300 - Train loss: 0.6189956068992615, Validation loss: 0.6150583624839783
Epoch: 33/300 - Train loss: 0.61634761095047, Validation loss: 0.6125504374504089
Epoch: 34/300 - Train loss: 0.6137245893478394, Validation loss: 0.6098681688308716
Epoch: 35/300 - Train loss: 0.6111261248588562, Validation loss: 0.6070874929428101
Epoch: 36/300 - Train loss: 0.6085554361343384, Validation loss: 0.6050385236740112
Epoch: 37/300 - Train loss: 0.6060145497322083, Validation loss: 0.602000892162323
Epoch: 38/300 - Train loss: 0.6035062074661255, Validation loss: 0.5998806357383728
Epoch: 39/300 - Train loss: 0.601032555103302, Validation loss: 0.5973654985427856
Epoch: 40/300 - Train loss: 0.5985946655273438, Validation loss: 0.5951576828956604
Epoch: 41/300 - Train loss: 0.5961933135986328, Validation loss: 0.5928336381912231
Epoch: 42/300 - Train loss: 0.5938300490379333, Validation loss: 0.5903252959251404
Epoch: 43/300 - Train loss: 0.5915047526359558, Validation loss: 0.5884273648262024
Epoch: 44/300 - Train loss: 0.5892183780670166, Validation loss: 0.5861901640892029
Epoch: 45/300 - Train loss: 0.5869719982147217, Validation loss: 0.5837806463241577
Epoch: 46/300 - Train loss: 0.584766149520874, Validation loss: 0.5813876986503601
Epoch: 47/300 - Train loss: 0.5826013088226318, Validation loss: 0.5798740386962891
Epoch: 48/300 - Train loss: 0.5804775953292847, Validation loss: 0.5779173374176025
Epoch: 49/300 - Train loss: 0.5783950686454773, Validation loss: 0.5758460760116577
Epoch: 50/300 - Train loss: 0.5763535499572754, Validation loss: 0.5744892358779907
Epoch: 51/300 - Train loss: 0.5743526816368103, Validation loss: 0.5720894932746887
Epoch: 52/300 - Train loss: 0.5723923444747925, Validation loss: 0.5697568655014038
Epoch: 53/300 - Train loss: 0.5704724788665771, Validation loss: 0.5681492686271667
Epoch: 54/300 - Train loss: 0.5685924887657166, Validation loss: 0.5662161707878113
Epoch: 55/300 - Train loss: 0.5667513608932495, Validation loss: 0.564693808555603
Epoch: 56/300 - Train loss: 0.5649487972259521, Validation loss: 0.5629739165306091
Epoch: 57/300 - Train loss: 0.5631842613220215, Validation loss: 0.5617058277130127
Epoch: 58/300 - Train loss: 0.5614562630653381, Validation loss: 0.5595189332962036
Epoch: 59/300 - Train loss: 0.5597634315490723, Validation loss: 0.5583890080451965
Epoch: 60/300 - Train loss: 0.5581048727035522, Validation loss: 0.5568350553512573
Epoch: 61/300 - Train loss: 0.5564797520637512, Validation loss: 0.5557438135147095
Epoch: 62/300 - Train loss: 0.5548862814903259, Validation loss: 0.5536876916885376
Epoch: 63/300 - Train loss: 0.5533238649368286, Validation loss: 0.5525002479553223
Epoch: 64/300 - Train loss: 0.5517913699150085, Validation loss: 0.5506317615509033
Epoch: 65/300 - Train loss: 0.5502880811691284, Validation loss: 0.5495853424072266
Epoch: 66/300 - Train loss: 0.5488120913505554, Validation loss: 0.5481119751930237
Epoch: 67/300 - Train loss: 0.5473615527153015, Validation loss: 0.547139048576355
Epoch: 68/300 - Train loss: 0.5459341406822205, Validation loss: 0.5462607741355896
Epoch: 69/300 - Train loss: 0.5445293188095093, Validation loss: 0.5445417165756226
Epoch: 70/300 - Train loss: 0.5431460738182068, Validation loss: 0.5431256294250488
Epoch: 71/300 - Train loss: 0.5417827367782593, Validation loss: 0.5418379306793213
Epoch: 72/300 - Train loss: 0.5404385924339294, Validation loss: 0.5408588647842407
Epoch: 73/300 - Train loss: 0.5391130447387695, Validation loss: 0.5397624969482422
Epoch: 74/300 - Train loss: 0.53780597448349, Validation loss: 0.5380695462226868
Epoch: 75/300 - Train loss: 0.5365148782730103, Validation loss: 0.5378744602203369
Epoch: 76/300 - Train loss: 0.5352412462234497, Validation loss: 0.5362140536308289
Epoch: 77/300 - Train loss: 0.5339835286140442, Validation loss: 0.5351155400276184
Epoch: 78/300 - Train loss: 0.5327402949333191, Validation loss: 0.5345613360404968
Epoch: 79/300 - Train loss: 0.5315101146697998, Validation loss: 0.5328340530395508
Epoch: 80/300 - Train loss: 0.5302947759628296, Validation loss: 0.5313203930854797
Epoch: 81/300 - Train loss: 0.5290910601615906, Validation loss: 0.5307475328445435
Epoch: 82/300 - Train loss: 0.527898371219635, Validation loss: 0.5292478203773499
Epoch: 83/300 - Train loss: 0.526718020439148, Validation loss: 0.5285910367965698
Epoch: 84/300 - Train loss: 0.5255493521690369, Validation loss: 0.5270746350288391
Epoch: 85/300 - Train loss: 0.5243892669677734, Validation loss: 0.5264330506324768
Epoch: 86/300 - Train loss: 0.5232377052307129, Validation loss: 0.5255706310272217
Epoch: 87/300 - Train loss: 0.5220940709114075, Validation loss: 0.5243297815322876
Epoch: 88/300 - Train loss: 0.5209567546844482, Validation loss: 0.5229938626289368
Epoch: 89/300 - Train loss: 0.5198272466659546, Validation loss: 0.5221225619316101
Epoch: 90/300 - Train loss: 0.5187026858329773, Validation loss: 0.5209376215934753
Epoch: 91/300 - Train loss: 0.5175855159759521, Validation loss: 0.5192310810089111
Epoch: 92/300 - Train loss: 0.5164750814437866, Validation loss: 0.5188947319984436
Epoch: 93/300 - Train loss: 0.5153682827949524, Validation loss: 0.5175995826721191
Epoch: 94/300 - Train loss: 0.5142687559127808, Validation loss: 0.5168383121490479
Epoch: 95/300 - Train loss: 0.5131725668907166, Validation loss: 0.5159039497375488
Epoch: 96/300 - Train loss: 0.5120776295661926, Validation loss: 0.5146918296813965
Epoch: 97/300 - Train loss: 0.5109845995903015, Validation loss: 0.5137184858322144
Epoch: 98/300 - Train loss: 0.509892463684082, Validation loss: 0.5119787454605103
Epoch: 99/300 - Train loss: 0.5088018774986267, Validation loss: 0.5110526084899902
Epoch: 100/300 - Train loss: 0.507713794708252, Validation loss: 0.5110698342323303
Epoch: 101/300 - Train loss: 0.5066263675689697, Validation loss: 0.509333074092865
Epoch: 102/300 - Train loss: 0.5055385828018188, Validation loss: 0.5090485215187073
Epoch: 103/300 - Train loss: 0.5044521689414978, Validation loss: 0.5073962807655334
Epoch: 104/300 - Train loss: 0.5033679008483887, Validation loss: 0.5068431496620178
Epoch: 105/300 - Train loss: 0.5022890567779541, Validation loss: 0.5057141184806824
Epoch: 106/300 - Train loss: 0.5012136101722717, Validation loss: 0.5044143795967102
Epoch: 107/300 - Train loss: 0.5001404285430908, Validation loss: 0.5034497976303101
Epoch: 108/300 - Train loss: 0.49906814098358154, Validation loss: 0.5024195909500122
Epoch: 109/300 - Train loss: 0.4979974031448364, Validation loss: 0.5010570287704468
Epoch: 110/300 - Train loss: 0.4969279170036316, Validation loss: 0.5007144808769226
Epoch: 111/300 - Train loss: 0.4958605468273163, Validation loss: 0.49924972653388977
Epoch: 112/300 - Train loss: 0.4947957992553711, Validation loss: 0.498308926820755
Epoch: 113/300 - Train loss: 0.49373486638069153, Validation loss: 0.4975711405277252
Epoch: 114/300 - Train loss: 0.4926743507385254, Validation loss: 0.496731698513031
Epoch: 115/300 - Train loss: 0.49161654710769653, Validation loss: 0.4953451156616211
Epoch: 116/300 - Train loss: 0.4905606210231781, Validation loss: 0.4940989911556244
Epoch: 117/300 - Train loss: 0.48950743675231934, Validation loss: 0.49435219168663025
Epoch: 118/300 - Train loss: 0.4884582757949829, Validation loss: 0.49284693598747253
Epoch: 119/300 - Train loss: 0.48741260170936584, Validation loss: 0.49152871966362
Epoch: 120/300 - Train loss: 0.4863700568675995, Validation loss: 0.49059024453163147
Epoch: 121/300 - Train loss: 0.48533299565315247, Validation loss: 0.4901787042617798
Epoch: 122/300 - Train loss: 0.4842991232872009, Validation loss: 0.4886998236179352
Epoch: 123/300 - Train loss: 0.4832667410373688, Validation loss: 0.48735710978507996
Epoch: 124/300 - Train loss: 0.4822344481945038, Validation loss: 0.48641863465309143
Epoch: 125/300 - Train loss: 0.4812040627002716, Validation loss: 0.48551392555236816
Epoch: 126/300 - Train loss: 0.4801751673221588, Validation loss: 0.4843979477882385
Epoch: 127/300 - Train loss: 0.47914913296699524, Validation loss: 0.4832012951374054
Epoch: 128/300 - Train loss: 0.47812628746032715, Validation loss: 0.4827668070793152
Epoch: 129/300 - Train loss: 0.47710517048835754, Validation loss: 0.48121777176856995
Epoch: 130/300 - Train loss: 0.47608718276023865, Validation loss: 0.48088786005973816
Epoch: 131/300 - Train loss: 0.4750724136829376, Validation loss: 0.4795960783958435
Epoch: 132/300 - Train loss: 0.47406086325645447, Validation loss: 0.4784888029098511
Epoch: 133/300 - Train loss: 0.47305378317832947, Validation loss: 0.47799140214920044
Epoch: 134/300 - Train loss: 0.4720500111579895, Validation loss: 0.47699013352394104
Epoch: 135/300 - Train loss: 0.4710482954978943, Validation loss: 0.47581541538238525
Epoch: 136/300 - Train loss: 0.4700508415699005, Validation loss: 0.4749697148799896
Epoch: 137/300 - Train loss: 0.46905747056007385, Validation loss: 0.4742582142353058
Epoch: 138/300 - Train loss: 0.4680667519569397, Validation loss: 0.47311705350875854
Epoch: 139/300 - Train loss: 0.4670795798301697, Validation loss: 0.47247591614723206
Epoch: 140/300 - Train loss: 0.466096967458725, Validation loss: 0.47150343656539917
Epoch: 141/300 - Train loss: 0.46511852741241455, Validation loss: 0.47065916657447815
Epoch: 142/300 - Train loss: 0.46414312720298767, Validation loss: 0.4698759913444519
Epoch: 143/300 - Train loss: 0.46317175030708313, Validation loss: 0.46939894556999207
Epoch: 144/300 - Train loss: 0.4622039496898651, Validation loss: 0.4678853452205658
Epoch: 145/300 - Train loss: 0.46123984456062317, Validation loss: 0.4669751822948456
Epoch: 146/300 - Train loss: 0.4602796733379364, Validation loss: 0.4666786193847656
Epoch: 147/300 - Train loss: 0.45932385325431824, Validation loss: 0.46525782346725464
Epoch: 148/300 - Train loss: 0.4583713114261627, Validation loss: 0.46428051590919495
Epoch: 149/300 - Train loss: 0.45742297172546387, Validation loss: 0.4636055529117584
Epoch: 150/300 - Train loss: 0.45647919178009033, Validation loss: 0.4626762866973877
Epoch: 151/300 - Train loss: 0.4555392563343048, Validation loss: 0.4619211256504059
Epoch: 152/300 - Train loss: 0.45460376143455505, Validation loss: 0.4614669382572174
Epoch: 153/300 - Train loss: 0.4536728262901306, Validation loss: 0.4603101909160614
Epoch: 154/300 - Train loss: 0.4527476131916046, Validation loss: 0.45897388458251953
Epoch: 155/300 - Train loss: 0.4518282115459442, Validation loss: 0.45899656414985657
Epoch: 156/300 - Train loss: 0.4509132504463196, Validation loss: 0.4586624801158905
Epoch: 157/300 - Train loss: 0.45000195503234863, Validation loss: 0.4568322002887726
Epoch: 158/300 - Train loss: 0.44909578561782837, Validation loss: 0.45660847425460815
Epoch: 159/300 - Train loss: 0.44819414615631104, Validation loss: 0.45525017380714417
Epoch: 160/300 - Train loss: 0.44729670882225037, Validation loss: 0.45420074462890625
Epoch: 161/300 - Train loss: 0.44640347361564636, Validation loss: 0.45340389013290405
Epoch: 162/300 - Train loss: 0.44551509618759155, Validation loss: 0.4528321623802185
Epoch: 163/300 - Train loss: 0.44463181495666504, Validation loss: 0.4523167908191681
Epoch: 164/300 - Train loss: 0.4437529146671295, Validation loss: 0.4509252905845642
Epoch: 165/300 - Train loss: 0.4428776502609253, Validation loss: 0.4496665298938751
Epoch: 166/300 - Train loss: 0.44200602173805237, Validation loss: 0.4497721791267395
Epoch: 167/300 - Train loss: 0.44113898277282715, Validation loss: 0.44834238290786743
Epoch: 168/300 - Train loss: 0.4402755796909332, Validation loss: 0.44844678044319153
Epoch: 169/300 - Train loss: 0.4394160509109497, Validation loss: 0.4465380012989044
Epoch: 170/300 - Train loss: 0.43855994939804077, Validation loss: 0.4461415410041809
Epoch: 171/300 - Train loss: 0.43770816922187805, Validation loss: 0.4453243911266327
Epoch: 172/300 - Train loss: 0.4368598759174347, Validation loss: 0.4439247250556946
Epoch: 173/300 - Train loss: 0.43601492047309875, Validation loss: 0.4441596567630768
Epoch: 174/300 - Train loss: 0.4351732134819031, Validation loss: 0.4430224895477295
Epoch: 175/300 - Train loss: 0.43433573842048645, Validation loss: 0.4422820508480072
Epoch: 176/300 - Train loss: 0.4335021376609802, Validation loss: 0.44121456146240234
Epoch: 177/300 - Train loss: 0.4326711595058441, Validation loss: 0.4406088888645172
Epoch: 178/300 - Train loss: 0.43184319138526917, Validation loss: 0.4394679367542267
Epoch: 179/300 - Train loss: 0.43101784586906433, Validation loss: 0.43987366557121277
Epoch: 180/300 - Train loss: 0.430195689201355, Validation loss: 0.438317209482193
Epoch: 181/300 - Train loss: 0.4293772280216217, Validation loss: 0.4377841055393219
Epoch: 182/300 - Train loss: 0.4285621643066406, Validation loss: 0.43708667159080505
Epoch: 183/300 - Train loss: 0.42774924635887146, Validation loss: 0.4362390339374542
Epoch: 184/300 - Train loss: 0.4269392788410187, Validation loss: 0.43540453910827637
Epoch: 185/300 - Train loss: 0.4261317253112793, Validation loss: 0.43456992506980896
Epoch: 186/300 - Train loss: 0.4253270626068115, Validation loss: 0.43392249941825867
Epoch: 187/300 - Train loss: 0.42452406883239746, Validation loss: 0.43257686495780945
Epoch: 188/300 - Train loss: 0.4237228333950043, Validation loss: 0.4325864017009735
Epoch: 189/300 - Train loss: 0.42292308807373047, Validation loss: 0.43181362748146057
Epoch: 190/300 - Train loss: 0.422124981880188, Validation loss: 0.4304884672164917
Epoch: 191/300 - Train loss: 0.42132827639579773, Validation loss: 0.4302132725715637
Epoch: 192/300 - Train loss: 0.42053350806236267, Validation loss: 0.4286779463291168
Epoch: 193/300 - Train loss: 0.4197387099266052, Validation loss: 0.42900821566581726
Epoch: 194/300 - Train loss: 0.4189453125, Validation loss: 0.42768973112106323
Epoch: 195/300 - Train loss: 0.4181515574455261, Validation loss: 0.4265953600406647
Epoch: 196/300 - Train loss: 0.4173572361469269, Validation loss: 0.42693066596984863
Epoch: 197/300 - Train loss: 0.41656336188316345, Validation loss: 0.4260218143463135
Epoch: 198/300 - Train loss: 0.415770024061203, Validation loss: 0.42478278279304504
Epoch: 199/300 - Train loss: 0.41497763991355896, Validation loss: 0.42467260360717773
Epoch: 200/300 - Train loss: 0.4141874313354492, Validation loss: 0.4227754771709442
Epoch: 201/300 - Train loss: 0.41339778900146484, Validation loss: 0.4228160083293915
Epoch: 202/300 - Train loss: 0.41260862350463867, Validation loss: 0.4222845137119293
Epoch: 203/300 - Train loss: 0.41182073950767517, Validation loss: 0.42146915197372437
Epoch: 204/300 - Train loss: 0.4110320806503296, Validation loss: 0.4208005964756012
Epoch: 205/300 - Train loss: 0.4102451801300049, Validation loss: 0.42073383927345276
Epoch: 206/300 - Train loss: 0.4094586670398712, Validation loss: 0.4186629056930542
Epoch: 207/300 - Train loss: 0.40867161750793457, Validation loss: 0.4181947410106659
Epoch: 208/300 - Train loss: 0.40788400173187256, Validation loss: 0.41787415742874146
Epoch: 209/300 - Train loss: 0.4070970416069031, Validation loss: 0.41693416237831116
Epoch: 210/300 - Train loss: 0.40630966424942017, Validation loss: 0.4167599081993103
Epoch: 211/300 - Train loss: 0.4055224359035492, Validation loss: 0.4155609905719757
Epoch: 212/300 - Train loss: 0.4047347903251648, Validation loss: 0.4151388108730316
Epoch: 213/300 - Train loss: 0.4039468467235565, Validation loss: 0.4140516221523285
Epoch: 214/300 - Train loss: 0.40315723419189453, Validation loss: 0.41338595747947693
Epoch: 215/300 - Train loss: 0.4023660123348236, Validation loss: 0.41278016567230225
Epoch: 216/300 - Train loss: 0.4015727937221527, Validation loss: 0.41200682520866394
Epoch: 217/300 - Train loss: 0.4007774293422699, Validation loss: 0.4115739166736603
Epoch: 218/300 - Train loss: 0.3999800384044647, Validation loss: 0.4106465280056
Epoch: 219/300 - Train loss: 0.3991835117340088, Validation loss: 0.4099681079387665
Epoch: 220/300 - Train loss: 0.3983878195285797, Validation loss: 0.40892288088798523
Epoch: 221/300 - Train loss: 0.3975882828235626, Validation loss: 0.4083218574523926
Epoch: 222/300 - Train loss: 0.39678964018821716, Validation loss: 0.4075797498226166
Epoch: 223/300 - Train loss: 0.39599061012268066, Validation loss: 0.4074731469154358
Epoch: 224/300 - Train loss: 0.39519202709198, Validation loss: 0.40669047832489014
Epoch: 225/300 - Train loss: 0.3943929970264435, Validation loss: 0.4060530662536621
Epoch: 226/300 - Train loss: 0.3935938775539398, Validation loss: 0.40464794635772705
Epoch: 227/300 - Train loss: 0.3927946388721466, Validation loss: 0.4041881859302521
Epoch: 228/300 - Train loss: 0.3919946551322937, Validation loss: 0.4030379354953766
Epoch: 229/300 - Train loss: 0.3911949396133423, Validation loss: 0.4031669795513153
Epoch: 230/300 - Train loss: 0.3903976380825043, Validation loss: 0.40161779522895813
Epoch: 231/300 - Train loss: 0.38960275053977966, Validation loss: 0.40126973390579224
Epoch: 232/300 - Train loss: 0.38880786299705505, Validation loss: 0.40038779377937317
Epoch: 233/300 - Train loss: 0.38801175355911255, Validation loss: 0.39943960309028625
Epoch: 234/300 - Train loss: 0.3872160315513611, Validation loss: 0.39903947710990906
Epoch: 235/300 - Train loss: 0.38642141222953796, Validation loss: 0.398578941822052
Epoch: 236/300 - Train loss: 0.3856278359889984, Validation loss: 0.39784640073776245
Epoch: 237/300 - Train loss: 0.3848346173763275, Validation loss: 0.3970976769924164
Epoch: 238/300 - Train loss: 0.38404127955436707, Validation loss: 0.3960419297218323
Epoch: 239/300 - Train loss: 0.383249431848526, Validation loss: 0.39544451236724854
Epoch: 240/300 - Train loss: 0.3824608325958252, Validation loss: 0.39533987641334534
Epoch: 241/300 - Train loss: 0.3816729784011841, Validation loss: 0.39370396733283997
Epoch: 242/300 - Train loss: 0.3808844983577728, Validation loss: 0.3934048116207123
Epoch: 243/300 - Train loss: 0.3800981342792511, Validation loss: 0.39284515380859375
Epoch: 244/300 - Train loss: 0.37931352853775024, Validation loss: 0.3917396366596222
Epoch: 245/300 - Train loss: 0.37853094935417175, Validation loss: 0.3909168541431427
Epoch: 246/300 - Train loss: 0.37775129079818726, Validation loss: 0.3898678123950958
Epoch: 247/300 - Train loss: 0.37697380781173706, Validation loss: 0.39001548290252686
Epoch: 248/300 - Train loss: 0.3761994540691376, Validation loss: 0.3891534209251404
Epoch: 249/300 - Train loss: 0.3754260540008545, Validation loss: 0.38877397775650024
Epoch: 250/300 - Train loss: 0.37465307116508484, Validation loss: 0.38754507899284363
Epoch: 251/300 - Train loss: 0.3738803565502167, Validation loss: 0.3872688114643097
Epoch: 252/300 - Train loss: 0.37310710549354553, Validation loss: 0.3868993818759918
Epoch: 253/300 - Train loss: 0.3723374009132385, Validation loss: 0.3858994245529175
Epoch: 254/300 - Train loss: 0.3715677857398987, Validation loss: 0.38461631536483765
Epoch: 255/300 - Train loss: 0.3707984685897827, Validation loss: 0.38429293036460876
Epoch: 256/300 - Train loss: 0.3700319528579712, Validation loss: 0.3841555416584015
Epoch: 257/300 - Train loss: 0.36927011609077454, Validation loss: 0.382874459028244
Epoch: 258/300 - Train loss: 0.3685097098350525, Validation loss: 0.3825169503688812
Epoch: 259/300 - Train loss: 0.3677503764629364, Validation loss: 0.3823207914829254
Epoch: 260/300 - Train loss: 0.36699166893959045, Validation loss: 0.38075384497642517
Epoch: 261/300 - Train loss: 0.3662334382534027, Validation loss: 0.38042962551116943
Epoch: 262/300 - Train loss: 0.3654753565788269, Validation loss: 0.37930184602737427
Epoch: 263/300 - Train loss: 0.3647198975086212, Validation loss: 0.37898850440979004
Epoch: 264/300 - Train loss: 0.36396536231040955, Validation loss: 0.378892719745636
Epoch: 265/300 - Train loss: 0.3632109761238098, Validation loss: 0.3777977526187897
Epoch: 266/300 - Train loss: 0.3624570965766907, Validation loss: 0.37696176767349243
Epoch: 267/300 - Train loss: 0.36170485615730286, Validation loss: 0.37636950612068176
Epoch: 268/300 - Train loss: 0.36095231771469116, Validation loss: 0.3750903904438019
Epoch: 269/300 - Train loss: 0.360199511051178, Validation loss: 0.37476345896720886
Epoch: 270/300 - Train loss: 0.3594481348991394, Validation loss: 0.3755117356777191
Epoch: 271/300 - Train loss: 0.3586973547935486, Validation loss: 0.37339094281196594
Epoch: 272/300 - Train loss: 0.3579489588737488, Validation loss: 0.3729262948036194
Epoch: 273/300 - Train loss: 0.3572036027908325, Validation loss: 0.3721017837524414
Epoch: 274/300 - Train loss: 0.356458842754364, Validation loss: 0.3716001510620117
Epoch: 275/300 - Train loss: 0.3557150065898895, Validation loss: 0.3708101511001587
Epoch: 276/300 - Train loss: 0.3549737334251404, Validation loss: 0.3704061210155487
Epoch: 277/300 - Train loss: 0.3542337119579315, Validation loss: 0.3691597878932953
Epoch: 278/300 - Train loss: 0.3534976840019226, Validation loss: 0.3686058819293976
Epoch: 279/300 - Train loss: 0.35276561975479126, Validation loss: 0.3680928349494934
Epoch: 280/300 - Train loss: 0.35203641653060913, Validation loss: 0.3673146367073059
Epoch: 281/300 - Train loss: 0.3513118624687195, Validation loss: 0.36702901124954224
Epoch: 282/300 - Train loss: 0.35058867931365967, Validation loss: 0.36645451188087463
Epoch: 283/300 - Train loss: 0.34987035393714905, Validation loss: 0.3655981719493866
Epoch: 284/300 - Train loss: 0.3491577208042145, Validation loss: 0.3645670413970947
Epoch: 285/300 - Train loss: 0.34845006465911865, Validation loss: 0.36430197954177856
Epoch: 286/300 - Train loss: 0.34774690866470337, Validation loss: 0.3636893332004547
Epoch: 287/300 - Train loss: 0.3470485210418701, Validation loss: 0.3626821041107178
Epoch: 288/300 - Train loss: 0.3463556468486786, Validation loss: 0.3625088036060333
Epoch: 289/300 - Train loss: 0.34566864371299744, Validation loss: 0.36205464601516724
Epoch: 290/300 - Train loss: 0.344985693693161, Validation loss: 0.3614926040172577
Epoch: 291/300 - Train loss: 0.3443071246147156, Validation loss: 0.36056870222091675
Epoch: 292/300 - Train loss: 0.34363609552383423, Validation loss: 0.3595868945121765
Epoch: 293/300 - Train loss: 0.34296977519989014, Validation loss: 0.3599894046783447
