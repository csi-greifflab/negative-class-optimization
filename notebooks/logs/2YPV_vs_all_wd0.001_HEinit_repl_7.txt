Epoch: 1/300 - Train loss: 0.6950200796127319, Validation loss: 0.6935375332832336
Epoch: 2/300 - Train loss: 0.6927484273910522, Validation loss: 0.6912685036659241
Epoch: 3/300 - Train loss: 0.6904647946357727, Validation loss: 0.6890144348144531
Epoch: 4/300 - Train loss: 0.6881640553474426, Validation loss: 0.6867287755012512
Epoch: 5/300 - Train loss: 0.685836911201477, Validation loss: 0.6844021081924438
Epoch: 6/300 - Train loss: 0.6834692358970642, Validation loss: 0.6820226311683655
Epoch: 7/300 - Train loss: 0.6810476779937744, Validation loss: 0.679660439491272
Epoch: 8/300 - Train loss: 0.6785602569580078, Validation loss: 0.6771541237831116
Epoch: 9/300 - Train loss: 0.6759968996047974, Validation loss: 0.6744490265846252
Epoch: 10/300 - Train loss: 0.673345685005188, Validation loss: 0.6718523502349854
Epoch: 11/300 - Train loss: 0.67059725522995, Validation loss: 0.6690420508384705
Epoch: 12/300 - Train loss: 0.6677421927452087, Validation loss: 0.6662437915802002
Epoch: 13/300 - Train loss: 0.6647745370864868, Validation loss: 0.6632538437843323
Epoch: 14/300 - Train loss: 0.661696195602417, Validation loss: 0.6600885987281799
Epoch: 15/300 - Train loss: 0.658499538898468, Validation loss: 0.6567268967628479
Epoch: 16/300 - Train loss: 0.6551825404167175, Validation loss: 0.6534119844436646
Epoch: 17/300 - Train loss: 0.6517430543899536, Validation loss: 0.6499482989311218
Epoch: 18/300 - Train loss: 0.6481792330741882, Validation loss: 0.6462182998657227
Epoch: 19/300 - Train loss: 0.644492506980896, Validation loss: 0.6424576640129089
Epoch: 20/300 - Train loss: 0.6406832933425903, Validation loss: 0.6386558413505554
Epoch: 21/300 - Train loss: 0.6367552280426025, Validation loss: 0.6345532536506653
Epoch: 22/300 - Train loss: 0.6327058672904968, Validation loss: 0.6304634213447571
Epoch: 23/300 - Train loss: 0.6285369992256165, Validation loss: 0.6262840628623962
Epoch: 24/300 - Train loss: 0.6242561340332031, Validation loss: 0.621867299079895
Epoch: 25/300 - Train loss: 0.6198731064796448, Validation loss: 0.6173791289329529
Epoch: 26/300 - Train loss: 0.6153938174247742, Validation loss: 0.612908661365509
Epoch: 27/300 - Train loss: 0.6108313798904419, Validation loss: 0.6082758903503418
Epoch: 28/300 - Train loss: 0.6061903238296509, Validation loss: 0.6033833026885986
Epoch: 29/300 - Train loss: 0.60147625207901, Validation loss: 0.5986297130584717
Epoch: 30/300 - Train loss: 0.5967034697532654, Validation loss: 0.5939804315567017
Epoch: 31/300 - Train loss: 0.5918797254562378, Validation loss: 0.5890019536018372
Epoch: 32/300 - Train loss: 0.5870153903961182, Validation loss: 0.5841129422187805
Epoch: 33/300 - Train loss: 0.5821219682693481, Validation loss: 0.5791718363761902
Epoch: 34/300 - Train loss: 0.5772103667259216, Validation loss: 0.5743143558502197
Epoch: 35/300 - Train loss: 0.5722867846488953, Validation loss: 0.5694689154624939
Epoch: 36/300 - Train loss: 0.567359209060669, Validation loss: 0.5642894506454468
Epoch: 37/300 - Train loss: 0.5624343156814575, Validation loss: 0.5595135688781738
Epoch: 38/300 - Train loss: 0.5575200915336609, Validation loss: 0.5546934604644775
Epoch: 39/300 - Train loss: 0.552623450756073, Validation loss: 0.5498088598251343
Epoch: 40/300 - Train loss: 0.5477519035339355, Validation loss: 0.544967532157898
Epoch: 41/300 - Train loss: 0.5429086089134216, Validation loss: 0.5400348901748657
Epoch: 42/300 - Train loss: 0.5380999445915222, Validation loss: 0.5351853370666504
Epoch: 43/300 - Train loss: 0.5333312153816223, Validation loss: 0.5305713415145874
Epoch: 44/300 - Train loss: 0.5286045074462891, Validation loss: 0.5259287357330322
Epoch: 45/300 - Train loss: 0.5239213109016418, Validation loss: 0.5210239291191101
Epoch: 46/300 - Train loss: 0.5192886590957642, Validation loss: 0.5164874792098999
Epoch: 47/300 - Train loss: 0.5147114396095276, Validation loss: 0.512008786201477
Epoch: 48/300 - Train loss: 0.5101931095123291, Validation loss: 0.5071636438369751
Epoch: 49/300 - Train loss: 0.5057380199432373, Validation loss: 0.5032361149787903
Epoch: 50/300 - Train loss: 0.5013458728790283, Validation loss: 0.49882668256759644
Epoch: 51/300 - Train loss: 0.49702033400535583, Validation loss: 0.4946790635585785
Epoch: 52/300 - Train loss: 0.49276384711265564, Validation loss: 0.48996907472610474
Epoch: 53/300 - Train loss: 0.4885791838169098, Validation loss: 0.4859755039215088
Epoch: 54/300 - Train loss: 0.4844670593738556, Validation loss: 0.4819214344024658
Epoch: 55/300 - Train loss: 0.4804275929927826, Validation loss: 0.47785845398902893
Epoch: 56/300 - Train loss: 0.4764622449874878, Validation loss: 0.47419947385787964
Epoch: 57/300 - Train loss: 0.47257259488105774, Validation loss: 0.47028854489326477
Epoch: 58/300 - Train loss: 0.4687593877315521, Validation loss: 0.466776579618454
Epoch: 59/300 - Train loss: 0.46502217650413513, Validation loss: 0.4628348648548126
Epoch: 60/300 - Train loss: 0.4613617956638336, Validation loss: 0.4593271315097809
Epoch: 61/300 - Train loss: 0.45777860283851624, Validation loss: 0.45518139004707336
Epoch: 62/300 - Train loss: 0.454271137714386, Validation loss: 0.45199283957481384
Epoch: 63/300 - Train loss: 0.4508392810821533, Validation loss: 0.44880637526512146
Epoch: 64/300 - Train loss: 0.4474826157093048, Validation loss: 0.4454892575740814
Epoch: 65/300 - Train loss: 0.4442005455493927, Validation loss: 0.4420729875564575
Epoch: 66/300 - Train loss: 0.4409908056259155, Validation loss: 0.43902042508125305
Epoch: 67/300 - Train loss: 0.43785345554351807, Validation loss: 0.4358808398246765
Epoch: 68/300 - Train loss: 0.4347875714302063, Validation loss: 0.4330262839794159
Epoch: 69/300 - Train loss: 0.4317913353443146, Validation loss: 0.4299450218677521
Epoch: 70/300 - Train loss: 0.4288634955883026, Validation loss: 0.42693936824798584
Epoch: 71/300 - Train loss: 0.4260020852088928, Validation loss: 0.4242921769618988
Epoch: 72/300 - Train loss: 0.4232054352760315, Validation loss: 0.42125311493873596
Epoch: 73/300 - Train loss: 0.42047300934791565, Validation loss: 0.41877907514572144
Epoch: 74/300 - Train loss: 0.41780373454093933, Validation loss: 0.4162740707397461
Epoch: 75/300 - Train loss: 0.41519618034362793, Validation loss: 0.4135590195655823
Epoch: 76/300 - Train loss: 0.4126485586166382, Validation loss: 0.411074161529541
Epoch: 77/300 - Train loss: 0.4101593792438507, Validation loss: 0.4082464575767517
Epoch: 78/300 - Train loss: 0.407726913690567, Validation loss: 0.40573403239250183
Epoch: 79/300 - Train loss: 0.40535029768943787, Validation loss: 0.403581440448761
Epoch: 80/300 - Train loss: 0.40302836894989014, Validation loss: 0.40154799818992615
Epoch: 81/300 - Train loss: 0.4007597863674164, Validation loss: 0.3998090326786041
Epoch: 82/300 - Train loss: 0.3985428214073181, Validation loss: 0.3976134955883026
Epoch: 83/300 - Train loss: 0.39637652039527893, Validation loss: 0.39478492736816406
Epoch: 84/300 - Train loss: 0.3942594528198242, Validation loss: 0.39296895265579224
Epoch: 85/300 - Train loss: 0.3921903073787689, Validation loss: 0.39088717103004456
Epoch: 86/300 - Train loss: 0.3901667892932892, Validation loss: 0.388415664434433
Epoch: 87/300 - Train loss: 0.3881880044937134, Validation loss: 0.3867056667804718
Epoch: 88/300 - Train loss: 0.3862544000148773, Validation loss: 0.3857276439666748
Epoch: 89/300 - Train loss: 0.3843637704849243, Validation loss: 0.3829323649406433
Epoch: 90/300 - Train loss: 0.3825138807296753, Validation loss: 0.3815041184425354
Epoch: 91/300 - Train loss: 0.3807041049003601, Validation loss: 0.37955716252326965
Epoch: 92/300 - Train loss: 0.3789325952529907, Validation loss: 0.377221018075943
Epoch: 93/300 - Train loss: 0.37719887495040894, Validation loss: 0.3762456476688385
Epoch: 94/300 - Train loss: 0.37550175189971924, Validation loss: 0.3743579387664795
Epoch: 95/300 - Train loss: 0.3738408088684082, Validation loss: 0.37233006954193115
Epoch: 96/300 - Train loss: 0.3722153306007385, Validation loss: 0.3707844913005829
Epoch: 97/300 - Train loss: 0.37062352895736694, Validation loss: 0.368575781583786
Epoch: 98/300 - Train loss: 0.36906352639198303, Validation loss: 0.36806145310401917
Epoch: 99/300 - Train loss: 0.3675357699394226, Validation loss: 0.36574411392211914
Epoch: 100/300 - Train loss: 0.36603882908821106, Validation loss: 0.3643557131290436
Epoch: 101/300 - Train loss: 0.36457252502441406, Validation loss: 0.3633779287338257
Epoch: 102/300 - Train loss: 0.3631349503993988, Validation loss: 0.36193913221359253
Epoch: 103/300 - Train loss: 0.36172568798065186, Validation loss: 0.3607948422431946
Epoch: 104/300 - Train loss: 0.36034366488456726, Validation loss: 0.3586684465408325
Epoch: 105/300 - Train loss: 0.35898831486701965, Validation loss: 0.35795682668685913
Epoch: 106/300 - Train loss: 0.35765957832336426, Validation loss: 0.3568096160888672
Epoch: 107/300 - Train loss: 0.35635703802108765, Validation loss: 0.35491764545440674
Epoch: 108/300 - Train loss: 0.3550802767276764, Validation loss: 0.353428453207016
Epoch: 109/300 - Train loss: 0.3538287878036499, Validation loss: 0.35227468609809875
Epoch: 110/300 - Train loss: 0.35260170698165894, Validation loss: 0.35115569829940796
Epoch: 111/300 - Train loss: 0.3513987064361572, Validation loss: 0.34999942779541016
Epoch: 112/300 - Train loss: 0.3502197861671448, Validation loss: 0.3480533957481384
Epoch: 113/300 - Train loss: 0.34906303882598877, Validation loss: 0.3473515808582306
Epoch: 114/300 - Train loss: 0.3479273319244385, Validation loss: 0.34650710225105286
Epoch: 115/300 - Train loss: 0.3468122184276581, Validation loss: 0.34508219361305237
Epoch: 116/300 - Train loss: 0.3457181751728058, Validation loss: 0.34401512145996094
Epoch: 117/300 - Train loss: 0.34464478492736816, Validation loss: 0.3426814079284668
Epoch: 118/300 - Train loss: 0.34359124302864075, Validation loss: 0.341631144285202
Epoch: 119/300 - Train loss: 0.3425561785697937, Validation loss: 0.3411438465118408
Epoch: 120/300 - Train loss: 0.341538667678833, Validation loss: 0.340064138174057
Epoch: 121/300 - Train loss: 0.3405390977859497, Validation loss: 0.33956775069236755
Epoch: 122/300 - Train loss: 0.3395560383796692, Validation loss: 0.3384439945220947
Epoch: 123/300 - Train loss: 0.3385899066925049, Validation loss: 0.33712124824523926
Epoch: 124/300 - Train loss: 0.3376406729221344, Validation loss: 0.3365398943424225
Epoch: 125/300 - Train loss: 0.3367088735103607, Validation loss: 0.3349224925041199
Epoch: 126/300 - Train loss: 0.3357936441898346, Validation loss: 0.33436426520347595
Epoch: 127/300 - Train loss: 0.33489465713500977, Validation loss: 0.3336256742477417
Epoch: 128/300 - Train loss: 0.3340107202529907, Validation loss: 0.3324558436870575
Epoch: 129/300 - Train loss: 0.33314183354377747, Validation loss: 0.3317580223083496
Epoch: 130/300 - Train loss: 0.3322879672050476, Validation loss: 0.33019107580184937
Epoch: 131/300 - Train loss: 0.33144864439964294, Validation loss: 0.33064034581184387
Epoch: 132/300 - Train loss: 0.33062273263931274, Validation loss: 0.329440712928772
Epoch: 133/300 - Train loss: 0.32981041073799133, Validation loss: 0.32845762372016907
Epoch: 134/300 - Train loss: 0.32901081442832947, Validation loss: 0.3278704285621643
Epoch: 135/300 - Train loss: 0.3282238841056824, Validation loss: 0.32678988575935364
Epoch: 136/300 - Train loss: 0.32744893431663513, Validation loss: 0.32608678936958313
Epoch: 137/300 - Train loss: 0.32668644189834595, Validation loss: 0.3252350091934204
Epoch: 138/300 - Train loss: 0.3259374499320984, Validation loss: 0.32475075125694275
Epoch: 139/300 - Train loss: 0.3252005875110626, Validation loss: 0.3237001895904541
Epoch: 140/300 - Train loss: 0.32447585463523865, Validation loss: 0.32352668046951294
Epoch: 141/300 - Train loss: 0.3237617015838623, Validation loss: 0.3222526013851166
Epoch: 142/300 - Train loss: 0.3230581283569336, Validation loss: 0.322134405374527
Epoch: 143/300 - Train loss: 0.3223656415939331, Validation loss: 0.3207129240036011
Epoch: 144/300 - Train loss: 0.3216840326786041, Validation loss: 0.3198520839214325
Epoch: 145/300 - Train loss: 0.3210132122039795, Validation loss: 0.3198481500148773
Epoch: 146/300 - Train loss: 0.3203526437282562, Validation loss: 0.31969407200813293
Epoch: 147/300 - Train loss: 0.3197023868560791, Validation loss: 0.3192286193370819
Epoch: 148/300 - Train loss: 0.31906235218048096, Validation loss: 0.31748291850090027
Epoch: 149/300 - Train loss: 0.3184318542480469, Validation loss: 0.3167645335197449
Epoch: 150/300 - Train loss: 0.31781187653541565, Validation loss: 0.316816508769989
Epoch: 151/300 - Train loss: 0.3172021508216858, Validation loss: 0.3161031901836395
Epoch: 152/300 - Train loss: 0.31660130620002747, Validation loss: 0.3151678144931793
Epoch: 153/300 - Train loss: 0.3160094618797302, Validation loss: 0.31448274850845337
Epoch: 154/300 - Train loss: 0.31542667746543884, Validation loss: 0.31390082836151123
Epoch: 155/300 - Train loss: 0.31485244631767273, Validation loss: 0.3139004409313202
Epoch: 156/300 - Train loss: 0.3142869174480438, Validation loss: 0.3133258819580078
Epoch: 157/300 - Train loss: 0.3137296438217163, Validation loss: 0.31265950202941895
