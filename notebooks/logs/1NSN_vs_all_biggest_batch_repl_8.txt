Epoch: 1/300 - Train loss: 0.708316445350647, Validation loss: 0.7021315097808838
Epoch: 2/300 - Train loss: 0.703814685344696, Validation loss: 0.6979028582572937
Epoch: 3/300 - Train loss: 0.6994012594223022, Validation loss: 0.6936771273612976
Epoch: 4/300 - Train loss: 0.6950741410255432, Validation loss: 0.6896066069602966
Epoch: 5/300 - Train loss: 0.6908255219459534, Validation loss: 0.6855550408363342
Epoch: 6/300 - Train loss: 0.686648964881897, Validation loss: 0.6815900802612305
Epoch: 7/300 - Train loss: 0.6825240254402161, Validation loss: 0.6777569055557251
Epoch: 8/300 - Train loss: 0.6784271597862244, Validation loss: 0.6737191081047058
Epoch: 9/300 - Train loss: 0.6743483543395996, Validation loss: 0.669838011264801
Epoch: 10/300 - Train loss: 0.6702674031257629, Validation loss: 0.6657451391220093
Epoch: 11/300 - Train loss: 0.6661683917045593, Validation loss: 0.6618130207061768
Epoch: 12/300 - Train loss: 0.6620239019393921, Validation loss: 0.6576494574546814
Epoch: 13/300 - Train loss: 0.6578110456466675, Validation loss: 0.6535711884498596
Epoch: 14/300 - Train loss: 0.6535125374794006, Validation loss: 0.6493217349052429
Epoch: 15/300 - Train loss: 0.6491177678108215, Validation loss: 0.6449140310287476
Epoch: 16/300 - Train loss: 0.6446237564086914, Validation loss: 0.6404173970222473
Epoch: 17/300 - Train loss: 0.6400230526924133, Validation loss: 0.6357265710830688
Epoch: 18/300 - Train loss: 0.6353162527084351, Validation loss: 0.6311777830123901
Epoch: 19/300 - Train loss: 0.6305160522460938, Validation loss: 0.6264687180519104
Epoch: 20/300 - Train loss: 0.6256234645843506, Validation loss: 0.6216074228286743
Epoch: 21/300 - Train loss: 0.6206501126289368, Validation loss: 0.6166649460792542
Epoch: 22/300 - Train loss: 0.6156039834022522, Validation loss: 0.6117110252380371
Epoch: 23/300 - Train loss: 0.6104995608329773, Validation loss: 0.6066130995750427
Epoch: 24/300 - Train loss: 0.605349600315094, Validation loss: 0.6013970971107483
Epoch: 25/300 - Train loss: 0.6001666188240051, Validation loss: 0.5964312553405762
Epoch: 26/300 - Train loss: 0.5949599146842957, Validation loss: 0.5911316871643066
Epoch: 27/300 - Train loss: 0.5897392630577087, Validation loss: 0.5859882235527039
Epoch: 28/300 - Train loss: 0.5845108032226562, Validation loss: 0.580740749835968
Epoch: 29/300 - Train loss: 0.5792803168296814, Validation loss: 0.575639545917511
Epoch: 30/300 - Train loss: 0.5740594267845154, Validation loss: 0.5705278515815735
Epoch: 31/300 - Train loss: 0.5688501596450806, Validation loss: 0.5654658079147339
Epoch: 32/300 - Train loss: 0.5636586546897888, Validation loss: 0.5604206323623657
Epoch: 33/300 - Train loss: 0.55849289894104, Validation loss: 0.5553478002548218
Epoch: 34/300 - Train loss: 0.553356945514679, Validation loss: 0.5502967834472656
Epoch: 35/300 - Train loss: 0.5482611060142517, Validation loss: 0.5451684594154358
Epoch: 36/300 - Train loss: 0.5432100892066956, Validation loss: 0.54030442237854
Epoch: 37/300 - Train loss: 0.5382081866264343, Validation loss: 0.5356999039649963
Epoch: 38/300 - Train loss: 0.5332612991333008, Validation loss: 0.530875027179718
Epoch: 39/300 - Train loss: 0.5283728241920471, Validation loss: 0.5257530212402344
Epoch: 40/300 - Train loss: 0.5235446691513062, Validation loss: 0.5209503769874573
Epoch: 41/300 - Train loss: 0.518779456615448, Validation loss: 0.5166136622428894
Epoch: 42/300 - Train loss: 0.5140790343284607, Validation loss: 0.5117443203926086
Epoch: 43/300 - Train loss: 0.5094457268714905, Validation loss: 0.5074118971824646
Epoch: 44/300 - Train loss: 0.504880964756012, Validation loss: 0.5032877922058105
Epoch: 45/300 - Train loss: 0.5003868937492371, Validation loss: 0.49870339035987854
Epoch: 46/300 - Train loss: 0.49596500396728516, Validation loss: 0.4947514235973358
Epoch: 47/300 - Train loss: 0.49161672592163086, Validation loss: 0.4909263253211975
Epoch: 48/300 - Train loss: 0.4873429834842682, Validation loss: 0.48593807220458984
Epoch: 49/300 - Train loss: 0.4831446409225464, Validation loss: 0.4821447432041168
Epoch: 50/300 - Train loss: 0.4790222644805908, Validation loss: 0.4780607223510742
Epoch: 51/300 - Train loss: 0.47497639060020447, Validation loss: 0.47403761744499207
Epoch: 52/300 - Train loss: 0.4710080921649933, Validation loss: 0.4700409173965454
Epoch: 53/300 - Train loss: 0.4671175181865692, Validation loss: 0.4663363993167877
Epoch: 54/300 - Train loss: 0.46330526471138, Validation loss: 0.4628522992134094
Epoch: 55/300 - Train loss: 0.4595714807510376, Validation loss: 0.45894157886505127
Epoch: 56/300 - Train loss: 0.4559165835380554, Validation loss: 0.45575475692749023
Epoch: 57/300 - Train loss: 0.45234012603759766, Validation loss: 0.45230427384376526
Epoch: 58/300 - Train loss: 0.4488416612148285, Validation loss: 0.4482691287994385
Epoch: 59/300 - Train loss: 0.44542089104652405, Validation loss: 0.4453089237213135
Epoch: 60/300 - Train loss: 0.4420772194862366, Validation loss: 0.4422224462032318
Epoch: 61/300 - Train loss: 0.4388100802898407, Validation loss: 0.43896597623825073
Epoch: 62/300 - Train loss: 0.43561890721321106, Validation loss: 0.43569624423980713
Epoch: 63/300 - Train loss: 0.4325026273727417, Validation loss: 0.43299955129623413
Epoch: 64/300 - Train loss: 0.4294596314430237, Validation loss: 0.42978018522262573
Epoch: 65/300 - Train loss: 0.4264885187149048, Validation loss: 0.4266277849674225
Epoch: 66/300 - Train loss: 0.4235875904560089, Validation loss: 0.42445406317710876
Epoch: 67/300 - Train loss: 0.42075610160827637, Validation loss: 0.42114171385765076
Epoch: 68/300 - Train loss: 0.4179926812648773, Validation loss: 0.41862472891807556
Epoch: 69/300 - Train loss: 0.4152955710887909, Validation loss: 0.4158397614955902
Epoch: 70/300 - Train loss: 0.4126635789871216, Validation loss: 0.4137745797634125
Epoch: 71/300 - Train loss: 0.41009509563446045, Validation loss: 0.41071438789367676
Epoch: 72/300 - Train loss: 0.4075879454612732, Validation loss: 0.407940149307251
Epoch: 73/300 - Train loss: 0.40514081716537476, Validation loss: 0.40594103932380676
Epoch: 74/300 - Train loss: 0.40275245904922485, Validation loss: 0.40392208099365234
Epoch: 75/300 - Train loss: 0.4004209637641907, Validation loss: 0.40119054913520813
Epoch: 76/300 - Train loss: 0.39814427495002747, Validation loss: 0.399554044008255
Epoch: 77/300 - Train loss: 0.3959212005138397, Validation loss: 0.39734235405921936
Epoch: 78/300 - Train loss: 0.39375007152557373, Validation loss: 0.39449387788772583
Epoch: 79/300 - Train loss: 0.3916291296482086, Validation loss: 0.39285174012184143
Epoch: 80/300 - Train loss: 0.3895566761493683, Validation loss: 0.39103782176971436
Epoch: 81/300 - Train loss: 0.3875313699245453, Validation loss: 0.3884420096874237
Epoch: 82/300 - Train loss: 0.3855515718460083, Validation loss: 0.38714858889579773
Epoch: 83/300 - Train loss: 0.3836155831813812, Validation loss: 0.385287880897522
Epoch: 84/300 - Train loss: 0.3817217946052551, Validation loss: 0.38294821977615356
Epoch: 85/300 - Train loss: 0.3798691928386688, Validation loss: 0.3814237117767334
Epoch: 86/300 - Train loss: 0.3780561089515686, Validation loss: 0.37900328636169434
Epoch: 87/300 - Train loss: 0.3762815296649933, Validation loss: 0.3779020309448242
Epoch: 88/300 - Train loss: 0.37454381585121155, Validation loss: 0.3763837218284607
Epoch: 89/300 - Train loss: 0.3728417158126831, Validation loss: 0.37441733479499817
Epoch: 90/300 - Train loss: 0.3711739480495453, Validation loss: 0.3724539577960968
Epoch: 91/300 - Train loss: 0.36953943967819214, Validation loss: 0.37120023369789124
Epoch: 92/300 - Train loss: 0.3679369390010834, Validation loss: 0.3698050081729889
Epoch: 93/300 - Train loss: 0.36636555194854736, Validation loss: 0.3687190115451813
Epoch: 94/300 - Train loss: 0.36482396721839905, Validation loss: 0.3663427233695984
Epoch: 95/300 - Train loss: 0.36331161856651306, Validation loss: 0.3654053211212158
Epoch: 96/300 - Train loss: 0.36182716488838196, Validation loss: 0.3640422523021698
Epoch: 97/300 - Train loss: 0.36036986112594604, Validation loss: 0.3621290624141693
Epoch: 98/300 - Train loss: 0.3589390516281128, Validation loss: 0.36139151453971863
Epoch: 99/300 - Train loss: 0.3575335144996643, Validation loss: 0.3599253296852112
Epoch: 100/300 - Train loss: 0.356152206659317, Validation loss: 0.3579424023628235
Epoch: 101/300 - Train loss: 0.35479459166526794, Validation loss: 0.3567427694797516
Epoch: 102/300 - Train loss: 0.35346028208732605, Validation loss: 0.355947345495224
Epoch: 103/300 - Train loss: 0.3521480858325958, Validation loss: 0.35431867837905884
Epoch: 104/300 - Train loss: 0.35085752606391907, Validation loss: 0.3538070321083069
Epoch: 105/300 - Train loss: 0.3495875895023346, Validation loss: 0.35160592198371887
Epoch: 106/300 - Train loss: 0.3483377993106842, Validation loss: 0.35089436173439026
Epoch: 107/300 - Train loss: 0.34710782766342163, Validation loss: 0.3493613600730896
Epoch: 108/300 - Train loss: 0.3458966314792633, Validation loss: 0.34820041060447693
Epoch: 109/300 - Train loss: 0.34470415115356445, Validation loss: 0.3470970094203949
Epoch: 110/300 - Train loss: 0.34352898597717285, Validation loss: 0.34574729204177856
Epoch: 111/300 - Train loss: 0.34237140417099, Validation loss: 0.34457728266716003
Epoch: 112/300 - Train loss: 0.3412313461303711, Validation loss: 0.3437597155570984
Epoch: 113/300 - Train loss: 0.3401074707508087, Validation loss: 0.34309178590774536
Epoch: 114/300 - Train loss: 0.33899909257888794, Validation loss: 0.34181153774261475
Epoch: 115/300 - Train loss: 0.337906152009964, Validation loss: 0.3398909270763397
Epoch: 116/300 - Train loss: 0.3368276357650757, Validation loss: 0.3400844633579254
Epoch: 117/300 - Train loss: 0.33576348423957825, Validation loss: 0.3384413719177246
Epoch: 118/300 - Train loss: 0.3347133696079254, Validation loss: 0.33753687143325806
Epoch: 119/300 - Train loss: 0.33367669582366943, Validation loss: 0.3371697664260864
Epoch: 120/300 - Train loss: 0.3326532244682312, Validation loss: 0.3355763554573059
Epoch: 121/300 - Train loss: 0.3316437602043152, Validation loss: 0.33483973145484924
Epoch: 122/300 - Train loss: 0.3306475877761841, Validation loss: 0.3332502543926239
Epoch: 123/300 - Train loss: 0.32966339588165283, Validation loss: 0.33297568559646606
Epoch: 124/300 - Train loss: 0.3286912739276886, Validation loss: 0.3319469094276428
Epoch: 125/300 - Train loss: 0.327731192111969, Validation loss: 0.3307287096977234
Epoch: 126/300 - Train loss: 0.3267831802368164, Validation loss: 0.3297561705112457
Epoch: 127/300 - Train loss: 0.3258465826511383, Validation loss: 0.328947514295578
Epoch: 128/300 - Train loss: 0.32492125034332275, Validation loss: 0.32846444845199585
Epoch: 129/300 - Train loss: 0.32400739192962646, Validation loss: 0.3270173966884613
Epoch: 130/300 - Train loss: 0.32310420274734497, Validation loss: 0.3262414336204529
Epoch: 131/300 - Train loss: 0.32221201062202454, Validation loss: 0.3257245123386383
Epoch: 132/300 - Train loss: 0.3213311433792114, Validation loss: 0.3244146406650543
Epoch: 133/300 - Train loss: 0.3204610347747803, Validation loss: 0.32385632395744324
Epoch: 134/300 - Train loss: 0.3196004033088684, Validation loss: 0.32420870661735535
Epoch: 135/300 - Train loss: 0.3187490403652191, Validation loss: 0.3226429522037506
Epoch: 136/300 - Train loss: 0.31790822744369507, Validation loss: 0.3214735984802246
Epoch: 137/300 - Train loss: 0.3170778453350067, Validation loss: 0.32114189863204956
Epoch: 138/300 - Train loss: 0.3162574768066406, Validation loss: 0.32057714462280273
Epoch: 139/300 - Train loss: 0.3154463469982147, Validation loss: 0.3185279369354248
Epoch: 140/300 - Train loss: 0.31464409828186035, Validation loss: 0.318776935338974
Epoch: 141/300 - Train loss: 0.31385108828544617, Validation loss: 0.3181402087211609
Epoch: 142/300 - Train loss: 0.31306737661361694, Validation loss: 0.3168017268180847
Epoch: 143/300 - Train loss: 0.3122926950454712, Validation loss: 0.3163507580757141
Epoch: 144/300 - Train loss: 0.311526894569397, Validation loss: 0.31569620966911316
Epoch: 145/300 - Train loss: 0.3107694983482361, Validation loss: 0.3144770860671997
Epoch: 146/300 - Train loss: 0.3100203275680542, Validation loss: 0.31370097398757935
Epoch: 147/300 - Train loss: 0.30927902460098267, Validation loss: 0.3132151961326599
Epoch: 148/300 - Train loss: 0.3085453510284424, Validation loss: 0.3130747675895691
Epoch: 149/300 - Train loss: 0.3078192472457886, Validation loss: 0.31141072511672974
Epoch: 150/300 - Train loss: 0.3071005046367645, Validation loss: 0.31091585755348206
Epoch: 151/300 - Train loss: 0.3063890337944031, Validation loss: 0.3101727068424225
Epoch: 152/300 - Train loss: 0.3056851327419281, Validation loss: 0.3098169267177582
Epoch: 153/300 - Train loss: 0.3049885332584381, Validation loss: 0.3089645802974701
Epoch: 154/300 - Train loss: 0.30429866909980774, Validation loss: 0.30848661065101624
Epoch: 155/300 - Train loss: 0.30361655354499817, Validation loss: 0.30808186531066895
Epoch: 156/300 - Train loss: 0.3029417395591736, Validation loss: 0.3070829510688782
Epoch: 157/300 - Train loss: 0.3022737503051758, Validation loss: 0.3065621256828308
Epoch: 158/300 - Train loss: 0.30161234736442566, Validation loss: 0.30543673038482666
Epoch: 159/300 - Train loss: 0.3009580075740814, Validation loss: 0.30480021238327026
Epoch: 160/300 - Train loss: 0.3003101348876953, Validation loss: 0.30459827184677124
Epoch: 161/300 - Train loss: 0.2996680736541748, Validation loss: 0.30428704619407654
Epoch: 162/300 - Train loss: 0.2990320026874542, Validation loss: 0.30303874611854553
Epoch: 163/300 - Train loss: 0.2984029948711395, Validation loss: 0.3025984466075897
Epoch: 164/300 - Train loss: 0.2977806329727173, Validation loss: 0.3020150363445282
Epoch: 165/300 - Train loss: 0.2971639335155487, Validation loss: 0.3018576502799988
Epoch: 166/300 - Train loss: 0.2965531647205353, Validation loss: 0.30156245827674866
