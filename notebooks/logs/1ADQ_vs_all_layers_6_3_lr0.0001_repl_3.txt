Epoch: 1/200 - Train loss: 0.6939560770988464, Validation loss: 0.692410409450531
Epoch: 2/200 - Train loss: 0.6906085014343262, Validation loss: 0.6870166659355164
Epoch: 3/200 - Train loss: 0.6813156604766846, Validation loss: 0.6746004819869995
Epoch: 4/200 - Train loss: 0.665378987789154, Validation loss: 0.6565936207771301
Epoch: 5/200 - Train loss: 0.6445183753967285, Validation loss: 0.6350334286689758
Epoch: 6/200 - Train loss: 0.620917022228241, Validation loss: 0.6119888424873352
Epoch: 7/200 - Train loss: 0.5969286561012268, Validation loss: 0.5897243022918701
Epoch: 8/200 - Train loss: 0.5749797821044922, Validation loss: 0.5697660446166992
Epoch: 9/200 - Train loss: 0.5554952621459961, Validation loss: 0.5529392957687378
Epoch: 10/200 - Train loss: 0.5397821664810181, Validation loss: 0.5398395657539368
Epoch: 11/200 - Train loss: 0.5270783305168152, Validation loss: 0.529092013835907
Epoch: 12/200 - Train loss: 0.5177720189094543, Validation loss: 0.5217572450637817
Epoch: 13/200 - Train loss: 0.5098918080329895, Validation loss: 0.5156911015510559
Epoch: 14/200 - Train loss: 0.5042298436164856, Validation loss: 0.5110087990760803
Epoch: 15/200 - Train loss: 0.49975791573524475, Validation loss: 0.5070313215255737
Epoch: 16/200 - Train loss: 0.49591174721717834, Validation loss: 0.5033078193664551
Epoch: 17/200 - Train loss: 0.4926636219024658, Validation loss: 0.500849187374115
Epoch: 18/200 - Train loss: 0.4899575114250183, Validation loss: 0.49810609221458435
Epoch: 19/200 - Train loss: 0.4875181019306183, Validation loss: 0.4963856041431427
Epoch: 20/200 - Train loss: 0.48568668961524963, Validation loss: 0.4948652386665344
Epoch: 21/200 - Train loss: 0.48368287086486816, Validation loss: 0.4931442141532898
Epoch: 22/200 - Train loss: 0.48194706439971924, Validation loss: 0.49130159616470337
Epoch: 23/200 - Train loss: 0.48028865456581116, Validation loss: 0.4895395338535309
Epoch: 24/200 - Train loss: 0.4786348044872284, Validation loss: 0.4882120192050934
Epoch: 25/200 - Train loss: 0.47685423493385315, Validation loss: 0.4863865077495575
Epoch: 26/200 - Train loss: 0.47563809156417847, Validation loss: 0.48516181111335754
Epoch: 27/200 - Train loss: 0.47416016459465027, Validation loss: 0.48388347029685974
Epoch: 28/200 - Train loss: 0.4723230004310608, Validation loss: 0.48227089643478394
Epoch: 29/200 - Train loss: 0.4705340564250946, Validation loss: 0.48112475872039795
Epoch: 30/200 - Train loss: 0.46888771653175354, Validation loss: 0.4785480797290802
Epoch: 31/200 - Train loss: 0.46698519587516785, Validation loss: 0.47753116488456726
Epoch: 32/200 - Train loss: 0.4653186500072479, Validation loss: 0.47549155354499817
Epoch: 33/200 - Train loss: 0.4628724157810211, Validation loss: 0.47400400042533875
Epoch: 34/200 - Train loss: 0.46108752489089966, Validation loss: 0.47181153297424316
Epoch: 35/200 - Train loss: 0.4588821232318878, Validation loss: 0.46898186206817627
Epoch: 36/200 - Train loss: 0.45648548007011414, Validation loss: 0.46758735179901123
Epoch: 37/200 - Train loss: 0.4540647268295288, Validation loss: 0.46517983078956604
Epoch: 38/200 - Train loss: 0.45236754417419434, Validation loss: 0.46358394622802734
Epoch: 39/200 - Train loss: 0.45036375522613525, Validation loss: 0.4611196517944336
Epoch: 40/200 - Train loss: 0.44794923067092896, Validation loss: 0.45909494161605835
Epoch: 41/200 - Train loss: 0.44588008522987366, Validation loss: 0.45741114020347595
Epoch: 42/200 - Train loss: 0.44397711753845215, Validation loss: 0.4554268419742584
Epoch: 43/200 - Train loss: 0.4418880045413971, Validation loss: 0.4531250298023224
Epoch: 44/200 - Train loss: 0.4398908019065857, Validation loss: 0.4513368010520935
Epoch: 45/200 - Train loss: 0.4382147789001465, Validation loss: 0.4498782753944397
Epoch: 46/200 - Train loss: 0.43593060970306396, Validation loss: 0.4479753077030182
Epoch: 47/200 - Train loss: 0.4338112771511078, Validation loss: 0.44607892632484436
Epoch: 48/200 - Train loss: 0.43182477355003357, Validation loss: 0.44360339641571045
Epoch: 49/200 - Train loss: 0.4299599528312683, Validation loss: 0.44159671664237976
Epoch: 50/200 - Train loss: 0.4277265965938568, Validation loss: 0.4405530095100403
Epoch: 51/200 - Train loss: 0.42582598328590393, Validation loss: 0.43834754824638367
Epoch: 52/200 - Train loss: 0.4239029884338379, Validation loss: 0.4366646111011505
Epoch: 53/200 - Train loss: 0.4217558801174164, Validation loss: 0.4352587163448334
Epoch: 54/200 - Train loss: 0.41963696479797363, Validation loss: 0.43281081318855286
Epoch: 55/200 - Train loss: 0.41794633865356445, Validation loss: 0.43091368675231934
Epoch: 56/200 - Train loss: 0.4158688187599182, Validation loss: 0.4287150204181671
Epoch: 57/200 - Train loss: 0.4135720133781433, Validation loss: 0.42738133668899536
Epoch: 58/200 - Train loss: 0.4120284616947174, Validation loss: 0.4250326156616211
Epoch: 59/200 - Train loss: 0.4096015989780426, Validation loss: 0.42412808537483215
Epoch: 60/200 - Train loss: 0.4076400399208069, Validation loss: 0.42132145166397095
Epoch: 61/200 - Train loss: 0.4055407643318176, Validation loss: 0.4195000231266022
Epoch: 62/200 - Train loss: 0.4038633108139038, Validation loss: 0.417320191860199
Epoch: 63/200 - Train loss: 0.40158751606941223, Validation loss: 0.41658827662467957
Epoch: 64/200 - Train loss: 0.3998052477836609, Validation loss: 0.41468334197998047
Epoch: 65/200 - Train loss: 0.39778420329093933, Validation loss: 0.41234201192855835
Epoch: 66/200 - Train loss: 0.3960309624671936, Validation loss: 0.41145560145378113
Epoch: 67/200 - Train loss: 0.393914133310318, Validation loss: 0.4088253080844879
Epoch: 68/200 - Train loss: 0.3916717767715454, Validation loss: 0.40709564089775085
Epoch: 69/200 - Train loss: 0.39019203186035156, Validation loss: 0.4063110649585724
Epoch: 70/200 - Train loss: 0.38816291093826294, Validation loss: 0.4040910601615906
Epoch: 71/200 - Train loss: 0.3858022391796112, Validation loss: 0.40204963088035583
Epoch: 72/200 - Train loss: 0.38417676091194153, Validation loss: 0.40184518694877625
Epoch: 73/200 - Train loss: 0.38203567266464233, Validation loss: 0.39880335330963135
Epoch: 74/200 - Train loss: 0.38002607226371765, Validation loss: 0.3973248600959778
Epoch: 75/200 - Train loss: 0.3781462013721466, Validation loss: 0.3956874907016754
Epoch: 76/200 - Train loss: 0.37606704235076904, Validation loss: 0.39388418197631836
Epoch: 77/200 - Train loss: 0.3741922378540039, Validation loss: 0.3927851617336273
Epoch: 78/200 - Train loss: 0.37194013595581055, Validation loss: 0.3913205862045288
Epoch: 79/200 - Train loss: 0.37044277787208557, Validation loss: 0.3898145258426666
Epoch: 80/200 - Train loss: 0.36822599172592163, Validation loss: 0.38753971457481384
Epoch: 81/200 - Train loss: 0.3663530647754669, Validation loss: 0.3863344192504883
Epoch: 82/200 - Train loss: 0.36423203349113464, Validation loss: 0.38411420583724976
Epoch: 83/200 - Train loss: 0.3625339865684509, Validation loss: 0.3828773498535156
Epoch: 84/200 - Train loss: 0.3605164587497711, Validation loss: 0.3818149268627167
Epoch: 85/200 - Train loss: 0.3584597110748291, Validation loss: 0.37936094403266907
Epoch: 86/200 - Train loss: 0.35695043206214905, Validation loss: 0.3787959814071655
Epoch: 87/200 - Train loss: 0.35526856780052185, Validation loss: 0.37715521454811096
Epoch: 88/200 - Train loss: 0.3534771800041199, Validation loss: 0.3761514723300934
Epoch: 89/200 - Train loss: 0.3516886234283447, Validation loss: 0.37438908219337463
Epoch: 90/200 - Train loss: 0.35006725788116455, Validation loss: 0.3737310469150543
Epoch: 91/200 - Train loss: 0.34810879826545715, Validation loss: 0.37196084856987
Epoch: 92/200 - Train loss: 0.34655332565307617, Validation loss: 0.3702743649482727
Epoch: 93/200 - Train loss: 0.3452697992324829, Validation loss: 0.36860141158103943
Epoch: 94/200 - Train loss: 0.3433905839920044, Validation loss: 0.36727121472358704
Epoch: 95/200 - Train loss: 0.3421124219894409, Validation loss: 0.365825355052948
Epoch: 96/200 - Train loss: 0.3399984836578369, Validation loss: 0.3664887845516205
Epoch: 97/200 - Train loss: 0.33867835998535156, Validation loss: 0.3635686933994293
Epoch: 98/200 - Train loss: 0.33723166584968567, Validation loss: 0.36265525221824646
Epoch: 99/200 - Train loss: 0.3356717824935913, Validation loss: 0.360849529504776
Epoch: 100/200 - Train loss: 0.33396822214126587, Validation loss: 0.3599952459335327
Epoch: 101/200 - Train loss: 0.33235782384872437, Validation loss: 0.3596176207065582
Epoch: 102/200 - Train loss: 0.33109381794929504, Validation loss: 0.3583618104457855
Epoch: 103/200 - Train loss: 0.33000805974006653, Validation loss: 0.35709819197654724
Epoch: 104/200 - Train loss: 0.328169047832489, Validation loss: 0.3566947281360626
Epoch: 105/200 - Train loss: 0.32659590244293213, Validation loss: 0.35569629073143005
Epoch: 106/200 - Train loss: 0.32546401023864746, Validation loss: 0.35358336567878723
Epoch: 107/200 - Train loss: 0.32447677850723267, Validation loss: 0.3540576696395874
Epoch: 108/200 - Train loss: 0.322747141122818, Validation loss: 0.3526107370853424
Epoch: 109/200 - Train loss: 0.3215715289115906, Validation loss: 0.3524852395057678
Epoch: 110/200 - Train loss: 0.3200400769710541, Validation loss: 0.35092127323150635
Epoch: 111/200 - Train loss: 0.318950355052948, Validation loss: 0.3497726321220398
Epoch: 112/200 - Train loss: 0.3175622522830963, Validation loss: 0.3492957055568695
Epoch: 113/200 - Train loss: 0.31643638014793396, Validation loss: 0.34809738397598267
Epoch: 114/200 - Train loss: 0.31536999344825745, Validation loss: 0.34855762124061584
Epoch: 115/200 - Train loss: 0.31438466906547546, Validation loss: 0.34667977690696716
Epoch: 116/200 - Train loss: 0.31309565901756287, Validation loss: 0.34694963693618774
Epoch: 117/200 - Train loss: 0.31190988421440125, Validation loss: 0.34500589966773987
Epoch: 118/200 - Train loss: 0.31078818440437317, Validation loss: 0.34441348910331726
Epoch: 119/200 - Train loss: 0.3095196783542633, Validation loss: 0.34398984909057617
Epoch: 120/200 - Train loss: 0.3086544871330261, Validation loss: 0.3446417450904846
Epoch: 121/200 - Train loss: 0.3076840937137604, Validation loss: 0.3438858389854431
Epoch: 122/200 - Train loss: 0.30675792694091797, Validation loss: 0.3415996730327606
Epoch: 123/200 - Train loss: 0.30562007427215576, Validation loss: 0.34261009097099304
Epoch: 124/200 - Train loss: 0.30494529008865356, Validation loss: 0.3413103222846985
Epoch: 125/200 - Train loss: 0.30353111028671265, Validation loss: 0.3412817120552063
Epoch: 126/200 - Train loss: 0.30293768644332886, Validation loss: 0.33998772501945496
Epoch: 127/200 - Train loss: 0.3017732799053192, Validation loss: 0.3391760587692261
Epoch: 128/200 - Train loss: 0.3007536828517914, Validation loss: 0.3393844962120056
Epoch: 129/200 - Train loss: 0.30067262053489685, Validation loss: 0.33813971281051636
Epoch: 130/200 - Train loss: 0.2995165288448334, Validation loss: 0.3396962583065033
Epoch: 131/200 - Train loss: 0.29835978150367737, Validation loss: 0.3373524248600006
Epoch: 132/200 - Train loss: 0.2977060079574585, Validation loss: 0.33704227209091187
Epoch: 133/200 - Train loss: 0.2966040074825287, Validation loss: 0.336242139339447
Epoch: 134/200 - Train loss: 0.2960231602191925, Validation loss: 0.3364909291267395
Epoch: 135/200 - Train loss: 0.2954811155796051, Validation loss: 0.3351720869541168
