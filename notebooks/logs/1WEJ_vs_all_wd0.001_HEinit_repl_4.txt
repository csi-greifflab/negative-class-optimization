Epoch: 1/300 - Train loss: 0.7075569033622742, Validation loss: 0.7038467526435852
Epoch: 2/300 - Train loss: 0.7048614621162415, Validation loss: 0.7012128829956055
Epoch: 3/300 - Train loss: 0.7021888494491577, Validation loss: 0.6986674666404724
Epoch: 4/300 - Train loss: 0.699508011341095, Validation loss: 0.6960043907165527
Epoch: 5/300 - Train loss: 0.696800708770752, Validation loss: 0.6932385563850403
Epoch: 6/300 - Train loss: 0.6940429210662842, Validation loss: 0.6906126141548157
Epoch: 7/300 - Train loss: 0.6912178993225098, Validation loss: 0.6876294612884521
Epoch: 8/300 - Train loss: 0.688308835029602, Validation loss: 0.6848572492599487
Epoch: 9/300 - Train loss: 0.6853068470954895, Validation loss: 0.681765615940094
Epoch: 10/300 - Train loss: 0.6822040677070618, Validation loss: 0.678867757320404
Epoch: 11/300 - Train loss: 0.6789946556091309, Validation loss: 0.6755953431129456
Epoch: 12/300 - Train loss: 0.6756739616394043, Validation loss: 0.6722555756568909
Epoch: 13/300 - Train loss: 0.6722460389137268, Validation loss: 0.668982207775116
Epoch: 14/300 - Train loss: 0.6687096953392029, Validation loss: 0.6656160950660706
Epoch: 15/300 - Train loss: 0.6650726795196533, Validation loss: 0.6620168685913086
Epoch: 16/300 - Train loss: 0.6613386869430542, Validation loss: 0.658216118812561
Epoch: 17/300 - Train loss: 0.6575127243995667, Validation loss: 0.6545563340187073
Epoch: 18/300 - Train loss: 0.6535969376564026, Validation loss: 0.6506512761116028
Epoch: 19/300 - Train loss: 0.6496012806892395, Validation loss: 0.6467186212539673
Epoch: 20/300 - Train loss: 0.6455305814743042, Validation loss: 0.6427656412124634
Epoch: 21/300 - Train loss: 0.6413896679878235, Validation loss: 0.6387255191802979
Epoch: 22/300 - Train loss: 0.6371779441833496, Validation loss: 0.6344291567802429
Epoch: 23/300 - Train loss: 0.6329030394554138, Validation loss: 0.6304284334182739
Epoch: 24/300 - Train loss: 0.6285629868507385, Validation loss: 0.6262714266777039
Epoch: 25/300 - Train loss: 0.6241693496704102, Validation loss: 0.6220122575759888
Epoch: 26/300 - Train loss: 0.6197208166122437, Validation loss: 0.6176506876945496
Epoch: 27/300 - Train loss: 0.6152234077453613, Validation loss: 0.613183319568634
Epoch: 28/300 - Train loss: 0.6106810569763184, Validation loss: 0.6087145805358887
Epoch: 29/300 - Train loss: 0.6061000823974609, Validation loss: 0.6041843891143799
Epoch: 30/300 - Train loss: 0.6014869809150696, Validation loss: 0.5998052954673767
Epoch: 31/300 - Train loss: 0.5968475341796875, Validation loss: 0.5951975584030151
Epoch: 32/300 - Train loss: 0.5921896696090698, Validation loss: 0.5904676914215088
Epoch: 33/300 - Train loss: 0.5875176787376404, Validation loss: 0.5857366919517517
Epoch: 34/300 - Train loss: 0.5828374028205872, Validation loss: 0.581219494342804
Epoch: 35/300 - Train loss: 0.578159511089325, Validation loss: 0.5766666531562805
Epoch: 36/300 - Train loss: 0.5734934210777283, Validation loss: 0.5718992352485657
Epoch: 37/300 - Train loss: 0.5688415169715881, Validation loss: 0.5676482319831848
Epoch: 38/300 - Train loss: 0.5642092823982239, Validation loss: 0.5627387166023254
Epoch: 39/300 - Train loss: 0.5596020817756653, Validation loss: 0.5582488775253296
Epoch: 40/300 - Train loss: 0.5550267696380615, Validation loss: 0.55385422706604
Epoch: 41/300 - Train loss: 0.5504926443099976, Validation loss: 0.5489627718925476
Epoch: 42/300 - Train loss: 0.546002209186554, Validation loss: 0.5446228384971619
Epoch: 43/300 - Train loss: 0.541560709476471, Validation loss: 0.5401872992515564
Epoch: 44/300 - Train loss: 0.5371687412261963, Validation loss: 0.5360813140869141
Epoch: 45/300 - Train loss: 0.5328280925750732, Validation loss: 0.5313956141471863
Epoch: 46/300 - Train loss: 0.5285388827323914, Validation loss: 0.5274472236633301
Epoch: 47/300 - Train loss: 0.5243048667907715, Validation loss: 0.5225832462310791
Epoch: 48/300 - Train loss: 0.5201317071914673, Validation loss: 0.5192705392837524
Epoch: 49/300 - Train loss: 0.516018807888031, Validation loss: 0.5152337551116943
Epoch: 50/300 - Train loss: 0.5119673609733582, Validation loss: 0.5107409954071045
Epoch: 51/300 - Train loss: 0.5079779624938965, Validation loss: 0.5072378516197205
Epoch: 52/300 - Train loss: 0.504051923751831, Validation loss: 0.5032435059547424
Epoch: 53/300 - Train loss: 0.5001925826072693, Validation loss: 0.4994829297065735
Epoch: 54/300 - Train loss: 0.4963993430137634, Validation loss: 0.49532997608184814
Epoch: 55/300 - Train loss: 0.4926731586456299, Validation loss: 0.49206840991973877
Epoch: 56/300 - Train loss: 0.4890156686306, Validation loss: 0.48790714144706726
Epoch: 57/300 - Train loss: 0.4854280948638916, Validation loss: 0.4843086004257202
Epoch: 58/300 - Train loss: 0.48191091418266296, Validation loss: 0.4808403253555298
Epoch: 59/300 - Train loss: 0.4784642457962036, Validation loss: 0.477308452129364
Epoch: 60/300 - Train loss: 0.4750884771347046, Validation loss: 0.47405269742012024
Epoch: 61/300 - Train loss: 0.47178322076797485, Validation loss: 0.47061246633529663
Epoch: 62/300 - Train loss: 0.4685492217540741, Validation loss: 0.4676626920700073
Epoch: 63/300 - Train loss: 0.46538692712783813, Validation loss: 0.46450573205947876
Epoch: 64/300 - Train loss: 0.46229520440101624, Validation loss: 0.4613334834575653
Epoch: 65/300 - Train loss: 0.45927339792251587, Validation loss: 0.45823171734809875
Epoch: 66/300 - Train loss: 0.45632120966911316, Validation loss: 0.4554615616798401
Epoch: 67/300 - Train loss: 0.45343852043151855, Validation loss: 0.4521269202232361
Epoch: 68/300 - Train loss: 0.4506250321865082, Validation loss: 0.4489959478378296
Epoch: 69/300 - Train loss: 0.44787973165512085, Validation loss: 0.4464958906173706
Epoch: 70/300 - Train loss: 0.4452017843723297, Validation loss: 0.4439088702201843
Epoch: 71/300 - Train loss: 0.4425903260707855, Validation loss: 0.4415198862552643
Epoch: 72/300 - Train loss: 0.4400445222854614, Validation loss: 0.4391257166862488
Epoch: 73/300 - Train loss: 0.43756407499313354, Validation loss: 0.4365701675415039
Epoch: 74/300 - Train loss: 0.4351479411125183, Validation loss: 0.43433594703674316
Epoch: 75/300 - Train loss: 0.4327947497367859, Validation loss: 0.43121179938316345
Epoch: 76/300 - Train loss: 0.43050268292427063, Validation loss: 0.42920929193496704
Epoch: 77/300 - Train loss: 0.42826953530311584, Validation loss: 0.42685917019844055
Epoch: 78/300 - Train loss: 0.4260943531990051, Validation loss: 0.4247128367424011
Epoch: 79/300 - Train loss: 0.4239753186702728, Validation loss: 0.422908216714859
Epoch: 80/300 - Train loss: 0.42191174626350403, Validation loss: 0.42004185914993286
Epoch: 81/300 - Train loss: 0.4199022650718689, Validation loss: 0.4183627963066101
Epoch: 82/300 - Train loss: 0.41794559359550476, Validation loss: 0.416873961687088
Epoch: 83/300 - Train loss: 0.4160411059856415, Validation loss: 0.41441115736961365
Epoch: 84/300 - Train loss: 0.4141864478588104, Validation loss: 0.41216766834259033
Epoch: 85/300 - Train loss: 0.412379652261734, Validation loss: 0.41028892993927
Epoch: 86/300 - Train loss: 0.4106188416481018, Validation loss: 0.4093307554721832
Epoch: 87/300 - Train loss: 0.40890318155288696, Validation loss: 0.40761515498161316
Epoch: 88/300 - Train loss: 0.40723076462745667, Validation loss: 0.4061024487018585
Epoch: 89/300 - Train loss: 0.40560027956962585, Validation loss: 0.40397801995277405
Epoch: 90/300 - Train loss: 0.4040104150772095, Validation loss: 0.40255048871040344
Epoch: 91/300 - Train loss: 0.4024602770805359, Validation loss: 0.40063244104385376
Epoch: 92/300 - Train loss: 0.4009495973587036, Validation loss: 0.39886873960494995
Epoch: 93/300 - Train loss: 0.39947643876075745, Validation loss: 0.39725130796432495
Epoch: 94/300 - Train loss: 0.39803844690322876, Validation loss: 0.3968641757965088
Epoch: 95/300 - Train loss: 0.3966350257396698, Validation loss: 0.39527758955955505
Epoch: 96/300 - Train loss: 0.395263135433197, Validation loss: 0.392720490694046
Epoch: 97/300 - Train loss: 0.3939230144023895, Validation loss: 0.3920340836048126
Epoch: 98/300 - Train loss: 0.39261242747306824, Validation loss: 0.39030882716178894
Epoch: 99/300 - Train loss: 0.3913300931453705, Validation loss: 0.3891606330871582
Epoch: 100/300 - Train loss: 0.3900759220123291, Validation loss: 0.3875455856323242
Epoch: 101/300 - Train loss: 0.3888489007949829, Validation loss: 0.38678714632987976
Epoch: 102/300 - Train loss: 0.3876491189002991, Validation loss: 0.3861013352870941
Epoch: 103/300 - Train loss: 0.3864750266075134, Validation loss: 0.38427358865737915
Epoch: 104/300 - Train loss: 0.3853248059749603, Validation loss: 0.38293686509132385
Epoch: 105/300 - Train loss: 0.3841981589794159, Validation loss: 0.3817279636859894
Epoch: 106/300 - Train loss: 0.38309401273727417, Validation loss: 0.38135749101638794
Epoch: 107/300 - Train loss: 0.38201141357421875, Validation loss: 0.3792532980442047
Epoch: 108/300 - Train loss: 0.3809501826763153, Validation loss: 0.37810561060905457
Epoch: 109/300 - Train loss: 0.3799094259738922, Validation loss: 0.3767516613006592
Epoch: 110/300 - Train loss: 0.3788881003856659, Validation loss: 0.37605729699134827
Epoch: 111/300 - Train loss: 0.37788477540016174, Validation loss: 0.3755059540271759
Epoch: 112/300 - Train loss: 0.37690073251724243, Validation loss: 0.3740672171115875
Epoch: 113/300 - Train loss: 0.37593570351600647, Validation loss: 0.3730647563934326
Epoch: 114/300 - Train loss: 0.37498775124549866, Validation loss: 0.37193191051483154
Epoch: 115/300 - Train loss: 0.3740571141242981, Validation loss: 0.3713262677192688
Epoch: 116/300 - Train loss: 0.37314340472221375, Validation loss: 0.3707387149333954
Epoch: 117/300 - Train loss: 0.37224477529525757, Validation loss: 0.36944666504859924
Epoch: 118/300 - Train loss: 0.37136128544807434, Validation loss: 0.36849164962768555
Epoch: 119/300 - Train loss: 0.37049177289009094, Validation loss: 0.3678300082683563
Epoch: 120/300 - Train loss: 0.3696369528770447, Validation loss: 0.36755606532096863
Epoch: 121/300 - Train loss: 0.3687970042228699, Validation loss: 0.3660404682159424
Epoch: 122/300 - Train loss: 0.36797061562538147, Validation loss: 0.3647850751876831
Epoch: 123/300 - Train loss: 0.36715659499168396, Validation loss: 0.3640401065349579
Epoch: 124/300 - Train loss: 0.366354763507843, Validation loss: 0.36290696263313293
Epoch: 125/300 - Train loss: 0.3655642569065094, Validation loss: 0.36230501532554626
Epoch: 126/300 - Train loss: 0.364785760641098, Validation loss: 0.3610195815563202
Epoch: 127/300 - Train loss: 0.3640178442001343, Validation loss: 0.3607151508331299
Epoch: 128/300 - Train loss: 0.3632611036300659, Validation loss: 0.3602350354194641
Epoch: 129/300 - Train loss: 0.3625144958496094, Validation loss: 0.3598122000694275
Epoch: 130/300 - Train loss: 0.3617774546146393, Validation loss: 0.3587525486946106
Epoch: 131/300 - Train loss: 0.36105066537857056, Validation loss: 0.3573553264141083
Epoch: 132/300 - Train loss: 0.36033371090888977, Validation loss: 0.3568654954433441
Epoch: 133/300 - Train loss: 0.3596242070198059, Validation loss: 0.3561442196369171
Epoch: 134/300 - Train loss: 0.3589226007461548, Validation loss: 0.355885773897171
Epoch: 135/300 - Train loss: 0.35822951793670654, Validation loss: 0.3545916974544525
Epoch: 136/300 - Train loss: 0.3575434684753418, Validation loss: 0.35431575775146484
Epoch: 137/300 - Train loss: 0.35686546564102173, Validation loss: 0.3537532687187195
Epoch: 138/300 - Train loss: 0.35619619488716125, Validation loss: 0.3535741865634918
Epoch: 139/300 - Train loss: 0.3555346131324768, Validation loss: 0.3530617356300354
Epoch: 140/300 - Train loss: 0.3548806607723236, Validation loss: 0.3518577516078949
Epoch: 141/300 - Train loss: 0.3542342782020569, Validation loss: 0.35079020261764526
Epoch: 142/300 - Train loss: 0.3535950481891632, Validation loss: 0.35095643997192383
Epoch: 143/300 - Train loss: 0.35296207666397095, Validation loss: 0.3500005304813385
Epoch: 144/300 - Train loss: 0.3523346483707428, Validation loss: 0.34901753067970276
Epoch: 145/300 - Train loss: 0.351715624332428, Validation loss: 0.34787726402282715
Epoch: 146/300 - Train loss: 0.35110369324684143, Validation loss: 0.34762638807296753
Epoch: 147/300 - Train loss: 0.35049837827682495, Validation loss: 0.346888929605484
Epoch: 148/300 - Train loss: 0.3498998284339905, Validation loss: 0.3461342751979828
Epoch: 149/300 - Train loss: 0.3493073284626007, Validation loss: 0.3451746106147766
Epoch: 150/300 - Train loss: 0.3487206697463989, Validation loss: 0.3448500633239746
Epoch: 151/300 - Train loss: 0.3481404483318329, Validation loss: 0.3444807827472687
Epoch: 152/300 - Train loss: 0.34756606817245483, Validation loss: 0.34368571639060974
Epoch: 153/300 - Train loss: 0.3469984233379364, Validation loss: 0.3428525924682617
Epoch: 154/300 - Train loss: 0.346437007188797, Validation loss: 0.3428550958633423
Epoch: 155/300 - Train loss: 0.3458809554576874, Validation loss: 0.3419190049171448
Epoch: 156/300 - Train loss: 0.34533020853996277, Validation loss: 0.34152525663375854
Epoch: 157/300 - Train loss: 0.3447844386100769, Validation loss: 0.3417661190032959
