Epoch: 1/300 - Train loss: 0.6998481750488281, Validation loss: 0.6999765038490295
Epoch: 2/300 - Train loss: 0.6985125541687012, Validation loss: 0.6986018419265747
Epoch: 3/300 - Train loss: 0.6972399950027466, Validation loss: 0.6972469091415405
Epoch: 4/300 - Train loss: 0.6959992051124573, Validation loss: 0.6960582137107849
Epoch: 5/300 - Train loss: 0.6947673559188843, Validation loss: 0.694692850112915
Epoch: 6/300 - Train loss: 0.6935116052627563, Validation loss: 0.6933037638664246
Epoch: 7/300 - Train loss: 0.6921960711479187, Validation loss: 0.691810131072998
Epoch: 8/300 - Train loss: 0.6908044219017029, Validation loss: 0.6903814673423767
Epoch: 9/300 - Train loss: 0.6893207430839539, Validation loss: 0.688736617565155
Epoch: 10/300 - Train loss: 0.6877216100692749, Validation loss: 0.6868389248847961
Epoch: 11/300 - Train loss: 0.6860044002532959, Validation loss: 0.6849932074546814
Epoch: 12/300 - Train loss: 0.6841775178909302, Validation loss: 0.6831910610198975
Epoch: 13/300 - Train loss: 0.682250440120697, Validation loss: 0.6810375452041626
Epoch: 14/300 - Train loss: 0.680227518081665, Validation loss: 0.6789869666099548
Epoch: 15/300 - Train loss: 0.6781218647956848, Validation loss: 0.6767919659614563
Epoch: 16/300 - Train loss: 0.6759606003761292, Validation loss: 0.6744117736816406
Epoch: 17/300 - Train loss: 0.6737514138221741, Validation loss: 0.672050952911377
Epoch: 18/300 - Train loss: 0.6715012788772583, Validation loss: 0.6697960495948792
Epoch: 19/300 - Train loss: 0.6692140698432922, Validation loss: 0.6673498153686523
Epoch: 20/300 - Train loss: 0.6668932437896729, Validation loss: 0.6649699211120605
Epoch: 21/300 - Train loss: 0.6645417213439941, Validation loss: 0.6624915599822998
Epoch: 22/300 - Train loss: 0.6621633172035217, Validation loss: 0.6599780321121216
Epoch: 23/300 - Train loss: 0.6597522497177124, Validation loss: 0.6574631929397583
Epoch: 24/300 - Train loss: 0.6573074460029602, Validation loss: 0.6548545956611633
Epoch: 25/300 - Train loss: 0.6548312306404114, Validation loss: 0.6525145769119263
Epoch: 26/300 - Train loss: 0.652321994304657, Validation loss: 0.649671196937561
Epoch: 27/300 - Train loss: 0.6497848629951477, Validation loss: 0.6470316648483276
Epoch: 28/300 - Train loss: 0.6472203135490417, Validation loss: 0.6443828344345093
Epoch: 29/300 - Train loss: 0.6446351408958435, Validation loss: 0.6417034268379211
Epoch: 30/300 - Train loss: 0.6420365571975708, Validation loss: 0.6391527056694031
Epoch: 31/300 - Train loss: 0.6394256949424744, Validation loss: 0.6363781094551086
Epoch: 32/300 - Train loss: 0.6368041634559631, Validation loss: 0.6336520314216614
Epoch: 33/300 - Train loss: 0.6341767311096191, Validation loss: 0.6310116052627563
Epoch: 34/300 - Train loss: 0.631545901298523, Validation loss: 0.6284352540969849
Epoch: 35/300 - Train loss: 0.6289140582084656, Validation loss: 0.6257383823394775
Epoch: 36/300 - Train loss: 0.6262813806533813, Validation loss: 0.6230326890945435
Epoch: 37/300 - Train loss: 0.6236509680747986, Validation loss: 0.620261013507843
Epoch: 38/300 - Train loss: 0.6210249066352844, Validation loss: 0.6175001263618469
Epoch: 39/300 - Train loss: 0.6184042096138, Validation loss: 0.6150916814804077
Epoch: 40/300 - Train loss: 0.6157889366149902, Validation loss: 0.612372636795044
Epoch: 41/300 - Train loss: 0.61318039894104, Validation loss: 0.6098768711090088
Epoch: 42/300 - Train loss: 0.6105830669403076, Validation loss: 0.607367992401123
Epoch: 43/300 - Train loss: 0.608000636100769, Validation loss: 0.6046704053878784
Epoch: 44/300 - Train loss: 0.6054372787475586, Validation loss: 0.6020298600196838
Epoch: 45/300 - Train loss: 0.6028953194618225, Validation loss: 0.5993728637695312
Epoch: 46/300 - Train loss: 0.6003784537315369, Validation loss: 0.5969499945640564
Epoch: 47/300 - Train loss: 0.5978880524635315, Validation loss: 0.5943508148193359
Epoch: 48/300 - Train loss: 0.5954269766807556, Validation loss: 0.5925922393798828
Epoch: 49/300 - Train loss: 0.5929971933364868, Validation loss: 0.5900644063949585
Epoch: 50/300 - Train loss: 0.5906001925468445, Validation loss: 0.5875056982040405
Epoch: 51/300 - Train loss: 0.5882374048233032, Validation loss: 0.5853623151779175
Epoch: 52/300 - Train loss: 0.585909366607666, Validation loss: 0.5828728675842285
Epoch: 53/300 - Train loss: 0.5836179256439209, Validation loss: 0.5805434584617615
Epoch: 54/300 - Train loss: 0.5813634991645813, Validation loss: 0.5784916281700134
Epoch: 55/300 - Train loss: 0.5791469812393188, Validation loss: 0.5762255787849426
Epoch: 56/300 - Train loss: 0.5769690275192261, Validation loss: 0.57452791929245
Epoch: 57/300 - Train loss: 0.574830174446106, Validation loss: 0.5719135403633118
Epoch: 58/300 - Train loss: 0.5727308392524719, Validation loss: 0.5704860091209412
Epoch: 59/300 - Train loss: 0.5706712007522583, Validation loss: 0.5681970715522766
Epoch: 60/300 - Train loss: 0.5686513781547546, Validation loss: 0.5660145878791809
Epoch: 61/300 - Train loss: 0.5666707754135132, Validation loss: 0.5648505687713623
Epoch: 62/300 - Train loss: 0.5647293925285339, Validation loss: 0.5624372363090515
Epoch: 63/300 - Train loss: 0.5628265142440796, Validation loss: 0.5605910420417786
Epoch: 64/300 - Train loss: 0.5609617233276367, Validation loss: 0.558816134929657
Epoch: 65/300 - Train loss: 0.5591344833374023, Validation loss: 0.5570979714393616
Epoch: 66/300 - Train loss: 0.5573443174362183, Validation loss: 0.5555869340896606
Epoch: 67/300 - Train loss: 0.5555900931358337, Validation loss: 0.5537852048873901
Epoch: 68/300 - Train loss: 0.5538709163665771, Validation loss: 0.5523800849914551
Epoch: 69/300 - Train loss: 0.5521862506866455, Validation loss: 0.551296591758728
Epoch: 70/300 - Train loss: 0.5505349040031433, Validation loss: 0.5487752556800842
Epoch: 71/300 - Train loss: 0.5489159822463989, Validation loss: 0.5476082563400269
Epoch: 72/300 - Train loss: 0.5473282337188721, Validation loss: 0.546298623085022
Epoch: 73/300 - Train loss: 0.5457708239555359, Validation loss: 0.5446673631668091
Epoch: 74/300 - Train loss: 0.5442424416542053, Validation loss: 0.5431403517723083
Epoch: 75/300 - Train loss: 0.5427425503730774, Validation loss: 0.5422588586807251
Epoch: 76/300 - Train loss: 0.5412698984146118, Validation loss: 0.5407006144523621
Epoch: 77/300 - Train loss: 0.5398234128952026, Validation loss: 0.5392635464668274
Epoch: 78/300 - Train loss: 0.5384021401405334, Validation loss: 0.5379144549369812
Epoch: 79/300 - Train loss: 0.5370050072669983, Validation loss: 0.5368486642837524
Epoch: 80/300 - Train loss: 0.5356311202049255, Validation loss: 0.5352806448936462
Epoch: 81/300 - Train loss: 0.5342794060707092, Validation loss: 0.5343484282493591
Epoch: 82/300 - Train loss: 0.5329489707946777, Validation loss: 0.5333963632583618
Epoch: 83/300 - Train loss: 0.5316383242607117, Validation loss: 0.5318083167076111
Epoch: 84/300 - Train loss: 0.5303463935852051, Validation loss: 0.530633270740509
Epoch: 85/300 - Train loss: 0.5290721654891968, Validation loss: 0.5293083786964417
Epoch: 86/300 - Train loss: 0.5278140902519226, Validation loss: 0.5278123617172241
Epoch: 87/300 - Train loss: 0.5265715718269348, Validation loss: 0.5274031758308411
Epoch: 88/300 - Train loss: 0.525343656539917, Validation loss: 0.5263898968696594
Epoch: 89/300 - Train loss: 0.5241299867630005, Validation loss: 0.5242753028869629
Epoch: 90/300 - Train loss: 0.5229307413101196, Validation loss: 0.5239289999008179
Epoch: 91/300 - Train loss: 0.5217430591583252, Validation loss: 0.5226808786392212
Epoch: 92/300 - Train loss: 0.5205666422843933, Validation loss: 0.5215506553649902
Epoch: 93/300 - Train loss: 0.5194012522697449, Validation loss: 0.5210000872612
Epoch: 94/300 - Train loss: 0.5182464122772217, Validation loss: 0.5191999673843384
Epoch: 95/300 - Train loss: 0.5171003937721252, Validation loss: 0.5183313488960266
Epoch: 96/300 - Train loss: 0.5159626007080078, Validation loss: 0.5171401500701904
Epoch: 97/300 - Train loss: 0.5148320198059082, Validation loss: 0.5173366069793701
Epoch: 98/300 - Train loss: 0.5137099623680115, Validation loss: 0.5147749185562134
Epoch: 99/300 - Train loss: 0.5125945806503296, Validation loss: 0.514844536781311
Epoch: 100/300 - Train loss: 0.5114856362342834, Validation loss: 0.5136238932609558
Epoch: 101/300 - Train loss: 0.5103841423988342, Validation loss: 0.5119317770004272
Epoch: 102/300 - Train loss: 0.5092893838882446, Validation loss: 0.5109938979148865
Epoch: 103/300 - Train loss: 0.5082010626792908, Validation loss: 0.5102055072784424
Epoch: 104/300 - Train loss: 0.5071199536323547, Validation loss: 0.5094247460365295
Epoch: 105/300 - Train loss: 0.5060448050498962, Validation loss: 0.5083945393562317
Epoch: 106/300 - Train loss: 0.5049750208854675, Validation loss: 0.5075708627700806
Epoch: 107/300 - Train loss: 0.5039095282554626, Validation loss: 0.5067698359489441
Epoch: 108/300 - Train loss: 0.5028477311134338, Validation loss: 0.5057116746902466
Epoch: 109/300 - Train loss: 0.5017908811569214, Validation loss: 0.5045374035835266
Epoch: 110/300 - Train loss: 0.5007383823394775, Validation loss: 0.50404292345047
Epoch: 111/300 - Train loss: 0.4996897578239441, Validation loss: 0.5028644800186157
Epoch: 112/300 - Train loss: 0.49864479899406433, Validation loss: 0.5016512870788574
Epoch: 113/300 - Train loss: 0.4976036846637726, Validation loss: 0.5002184510231018
Epoch: 114/300 - Train loss: 0.4965676963329315, Validation loss: 0.4998883306980133
Epoch: 115/300 - Train loss: 0.495536208152771, Validation loss: 0.49907761812210083
Epoch: 116/300 - Train loss: 0.49451038241386414, Validation loss: 0.4981980323791504
Epoch: 117/300 - Train loss: 0.4934893846511841, Validation loss: 0.4968884289264679
Epoch: 118/300 - Train loss: 0.49247297644615173, Validation loss: 0.4958176016807556
Epoch: 119/300 - Train loss: 0.4914598762989044, Validation loss: 0.49512022733688354
Epoch: 120/300 - Train loss: 0.49044957756996155, Validation loss: 0.49413052201271057
Epoch: 121/300 - Train loss: 0.48944294452667236, Validation loss: 0.493031769990921
Epoch: 122/300 - Train loss: 0.4884399473667145, Validation loss: 0.4919999837875366
Epoch: 123/300 - Train loss: 0.48744016885757446, Validation loss: 0.4917820990085602
Epoch: 124/300 - Train loss: 0.4864436089992523, Validation loss: 0.49071863293647766
Epoch: 125/300 - Train loss: 0.48545041680336, Validation loss: 0.4898013770580292
Epoch: 126/300 - Train loss: 0.48446181416511536, Validation loss: 0.4888315200805664
Epoch: 127/300 - Train loss: 0.4834778904914856, Validation loss: 0.48793870210647583
Epoch: 128/300 - Train loss: 0.4824966490268707, Validation loss: 0.48644307255744934
Epoch: 129/300 - Train loss: 0.48151880502700806, Validation loss: 0.48620080947875977
Epoch: 130/300 - Train loss: 0.48054343461990356, Validation loss: 0.48482590913772583
Epoch: 131/300 - Train loss: 0.4795726239681244, Validation loss: 0.48337018489837646
Epoch: 132/300 - Train loss: 0.47860467433929443, Validation loss: 0.48275426030158997
Epoch: 133/300 - Train loss: 0.47764045000076294, Validation loss: 0.48237863183021545
Epoch: 134/300 - Train loss: 0.4766794741153717, Validation loss: 0.4814814031124115
Epoch: 135/300 - Train loss: 0.47572195529937744, Validation loss: 0.48066723346710205
Epoch: 136/300 - Train loss: 0.4747678339481354, Validation loss: 0.4790540933609009
Epoch: 137/300 - Train loss: 0.47381630539894104, Validation loss: 0.478668212890625
Epoch: 138/300 - Train loss: 0.4728673994541168, Validation loss: 0.47796040773391724
Epoch: 139/300 - Train loss: 0.47192129492759705, Validation loss: 0.4769419729709625
Epoch: 140/300 - Train loss: 0.47097817063331604, Validation loss: 0.47651705145835876
Epoch: 141/300 - Train loss: 0.4700385630130768, Validation loss: 0.4749349057674408
Epoch: 142/300 - Train loss: 0.4691006541252136, Validation loss: 0.4751063883304596
Epoch: 143/300 - Train loss: 0.4681653380393982, Validation loss: 0.4736558794975281
Epoch: 144/300 - Train loss: 0.46723178029060364, Validation loss: 0.47289180755615234
Epoch: 145/300 - Train loss: 0.4663003385066986, Validation loss: 0.4720905125141144
Epoch: 146/300 - Train loss: 0.46537116169929504, Validation loss: 0.471262127161026
Epoch: 147/300 - Train loss: 0.46444466710090637, Validation loss: 0.4704526364803314
Epoch: 148/300 - Train loss: 0.46352094411849976, Validation loss: 0.4695032238960266
Epoch: 149/300 - Train loss: 0.4625992476940155, Validation loss: 0.4681639075279236
Epoch: 150/300 - Train loss: 0.46167972683906555, Validation loss: 0.4674619734287262
Epoch: 151/300 - Train loss: 0.46076151728630066, Validation loss: 0.4669111371040344
Epoch: 152/300 - Train loss: 0.4598464369773865, Validation loss: 0.46652770042419434
Epoch: 153/300 - Train loss: 0.4589339792728424, Validation loss: 0.46494221687316895
Epoch: 154/300 - Train loss: 0.458023339509964, Validation loss: 0.4641285836696625
Epoch: 155/300 - Train loss: 0.45711368322372437, Validation loss: 0.46281009912490845
Epoch: 156/300 - Train loss: 0.45620518922805786, Validation loss: 0.46267691254615784
Epoch: 157/300 - Train loss: 0.45529982447624207, Validation loss: 0.46168628334999084
Epoch: 158/300 - Train loss: 0.45439672470092773, Validation loss: 0.46100103855133057
Epoch: 159/300 - Train loss: 0.45349398255348206, Validation loss: 0.4604548513889313
Epoch: 160/300 - Train loss: 0.45259130001068115, Validation loss: 0.4593093693256378
Epoch: 161/300 - Train loss: 0.45168885588645935, Validation loss: 0.4580713212490082
Epoch: 162/300 - Train loss: 0.4507858157157898, Validation loss: 0.4571096897125244
Epoch: 163/300 - Train loss: 0.4498835802078247, Validation loss: 0.45720502734184265
Epoch: 164/300 - Train loss: 0.448982834815979, Validation loss: 0.45555034279823303
Epoch: 165/300 - Train loss: 0.4480827748775482, Validation loss: 0.4546138346195221
Epoch: 166/300 - Train loss: 0.4471839666366577, Validation loss: 0.45371049642562866
Epoch: 167/300 - Train loss: 0.44628503918647766, Validation loss: 0.45345717668533325
Epoch: 168/300 - Train loss: 0.4453873336315155, Validation loss: 0.4522298276424408
Epoch: 169/300 - Train loss: 0.4444884955883026, Validation loss: 0.4510194659233093
Epoch: 170/300 - Train loss: 0.44358980655670166, Validation loss: 0.450607568025589
Epoch: 171/300 - Train loss: 0.4426920711994171, Validation loss: 0.4496290683746338
Epoch: 172/300 - Train loss: 0.44179585576057434, Validation loss: 0.44927778840065
Epoch: 173/300 - Train loss: 0.44090020656585693, Validation loss: 0.44814589619636536
Epoch: 174/300 - Train loss: 0.4400065243244171, Validation loss: 0.4476497769355774
Epoch: 175/300 - Train loss: 0.43911296129226685, Validation loss: 0.44687288999557495
Epoch: 176/300 - Train loss: 0.4382203221321106, Validation loss: 0.44607019424438477
Epoch: 177/300 - Train loss: 0.4373302161693573, Validation loss: 0.4446072578430176
Epoch: 178/300 - Train loss: 0.43644121289253235, Validation loss: 0.44418659806251526
Epoch: 179/300 - Train loss: 0.4355532228946686, Validation loss: 0.4432206451892853
Epoch: 180/300 - Train loss: 0.4346666932106018, Validation loss: 0.4431852102279663
Epoch: 181/300 - Train loss: 0.433781236410141, Validation loss: 0.4420156180858612
Epoch: 182/300 - Train loss: 0.43289780616760254, Validation loss: 0.4411313831806183
Epoch: 183/300 - Train loss: 0.4320148229598999, Validation loss: 0.44090497493743896
Epoch: 184/300 - Train loss: 0.43113112449645996, Validation loss: 0.4393523037433624
Epoch: 185/300 - Train loss: 0.43024757504463196, Validation loss: 0.4387763440608978
Epoch: 186/300 - Train loss: 0.4293654263019562, Validation loss: 0.43793463706970215
Epoch: 187/300 - Train loss: 0.428483247756958, Validation loss: 0.43658962845802307
Epoch: 188/300 - Train loss: 0.42760273814201355, Validation loss: 0.4357893168926239
Epoch: 189/300 - Train loss: 0.4267219305038452, Validation loss: 0.43558093905448914
Epoch: 190/300 - Train loss: 0.4258403778076172, Validation loss: 0.43436315655708313
Epoch: 191/300 - Train loss: 0.4249579608440399, Validation loss: 0.43342941999435425
Epoch: 192/300 - Train loss: 0.4240742623806, Validation loss: 0.4326534569263458
Epoch: 193/300 - Train loss: 0.42318984866142273, Validation loss: 0.4323102831840515
Epoch: 194/300 - Train loss: 0.42230454087257385, Validation loss: 0.4308258295059204
Epoch: 195/300 - Train loss: 0.42142003774642944, Validation loss: 0.4303188621997833
Epoch: 196/300 - Train loss: 0.42053622007369995, Validation loss: 0.429860919713974
Epoch: 197/300 - Train loss: 0.419653058052063, Validation loss: 0.4281967580318451
Epoch: 198/300 - Train loss: 0.4187694787979126, Validation loss: 0.4278157353401184
Epoch: 199/300 - Train loss: 0.4178870916366577, Validation loss: 0.426638126373291
Epoch: 200/300 - Train loss: 0.41700443625450134, Validation loss: 0.42590853571891785
Epoch: 201/300 - Train loss: 0.4161222577095032, Validation loss: 0.4250474274158478
Epoch: 202/300 - Train loss: 0.4152415692806244, Validation loss: 0.42449110746383667
Epoch: 203/300 - Train loss: 0.41435879468917847, Validation loss: 0.42406728863716125
Epoch: 204/300 - Train loss: 0.41347628831863403, Validation loss: 0.42257851362228394
Epoch: 205/300 - Train loss: 0.4125939905643463, Validation loss: 0.4216553568840027
Epoch: 206/300 - Train loss: 0.41171151399612427, Validation loss: 0.4214199185371399
Epoch: 207/300 - Train loss: 0.41082963347435, Validation loss: 0.41972658038139343
Epoch: 208/300 - Train loss: 0.4099480211734772, Validation loss: 0.4190930128097534
Epoch: 209/300 - Train loss: 0.4090654253959656, Validation loss: 0.4190812408924103
Epoch: 210/300 - Train loss: 0.40818119049072266, Validation loss: 0.417205810546875
Epoch: 211/300 - Train loss: 0.40729817748069763, Validation loss: 0.4167816936969757
Epoch: 212/300 - Train loss: 0.40641671419143677, Validation loss: 0.41599535942077637
Epoch: 213/300 - Train loss: 0.4055362939834595, Validation loss: 0.41487058997154236
Epoch: 214/300 - Train loss: 0.404657244682312, Validation loss: 0.4144907593727112
Epoch: 215/300 - Train loss: 0.4037795960903168, Validation loss: 0.41370463371276855
Epoch: 216/300 - Train loss: 0.40290194749832153, Validation loss: 0.41255226731300354
Epoch: 217/300 - Train loss: 0.4020245671272278, Validation loss: 0.4120502471923828
Epoch: 218/300 - Train loss: 0.40114644169807434, Validation loss: 0.4099794030189514
Epoch: 219/300 - Train loss: 0.40027058124542236, Validation loss: 0.4102928042411804
Epoch: 220/300 - Train loss: 0.39939847588539124, Validation loss: 0.40887004137039185
Epoch: 221/300 - Train loss: 0.39852669835090637, Validation loss: 0.4089321494102478
Epoch: 222/300 - Train loss: 0.3976559638977051, Validation loss: 0.4077054262161255
Epoch: 223/300 - Train loss: 0.39678487181663513, Validation loss: 0.4063103497028351
Epoch: 224/300 - Train loss: 0.3959147334098816, Validation loss: 0.40649932622909546
Epoch: 225/300 - Train loss: 0.3950444459915161, Validation loss: 0.4050500690937042
Epoch: 226/300 - Train loss: 0.39417633414268494, Validation loss: 0.40468746423721313
Epoch: 227/300 - Train loss: 0.3933092951774597, Validation loss: 0.4032226502895355
Epoch: 228/300 - Train loss: 0.3924435079097748, Validation loss: 0.40273550152778625
Epoch: 229/300 - Train loss: 0.39157834649086, Validation loss: 0.401665598154068
Epoch: 230/300 - Train loss: 0.3907112777233124, Validation loss: 0.4010748863220215
Epoch: 231/300 - Train loss: 0.38984349370002747, Validation loss: 0.40029090642929077
Epoch: 232/300 - Train loss: 0.3889760673046112, Validation loss: 0.39971861243247986
Epoch: 233/300 - Train loss: 0.38811030983924866, Validation loss: 0.3980660140514374
Epoch: 234/300 - Train loss: 0.3872455358505249, Validation loss: 0.3973315954208374
Epoch: 235/300 - Train loss: 0.38638103008270264, Validation loss: 0.3970015048980713
Epoch: 236/300 - Train loss: 0.38551831245422363, Validation loss: 0.3963387906551361
Epoch: 237/300 - Train loss: 0.3846575617790222, Validation loss: 0.39488479495048523
Epoch: 238/300 - Train loss: 0.3837982416152954, Validation loss: 0.3946234881877899
Epoch: 239/300 - Train loss: 0.38293886184692383, Validation loss: 0.39405179023742676
Epoch: 240/300 - Train loss: 0.382081538438797, Validation loss: 0.39272966980934143
Epoch: 241/300 - Train loss: 0.38122567534446716, Validation loss: 0.3915492594242096
Epoch: 242/300 - Train loss: 0.3803730905056, Validation loss: 0.3909546732902527
Epoch: 243/300 - Train loss: 0.3795222043991089, Validation loss: 0.390963613986969
Epoch: 244/300 - Train loss: 0.3786725401878357, Validation loss: 0.3897448182106018
Epoch: 245/300 - Train loss: 0.3778234124183655, Validation loss: 0.38841885328292847
Epoch: 246/300 - Train loss: 0.3769747316837311, Validation loss: 0.38797426223754883
Epoch: 247/300 - Train loss: 0.3761281371116638, Validation loss: 0.38768354058265686
Epoch: 248/300 - Train loss: 0.3752850294113159, Validation loss: 0.3867979049682617
Epoch: 249/300 - Train loss: 0.3744436800479889, Validation loss: 0.3852398097515106
Epoch: 250/300 - Train loss: 0.3736025094985962, Validation loss: 0.384403795003891
Epoch: 251/300 - Train loss: 0.3727632164955139, Validation loss: 0.383338063955307
Epoch: 252/300 - Train loss: 0.3719249367713928, Validation loss: 0.383102685213089
Epoch: 253/300 - Train loss: 0.37108635902404785, Validation loss: 0.3820628523826599
Epoch: 254/300 - Train loss: 0.3702465295791626, Validation loss: 0.38134557008743286
Epoch: 255/300 - Train loss: 0.36940667033195496, Validation loss: 0.38081830739974976
Epoch: 256/300 - Train loss: 0.3685702681541443, Validation loss: 0.3792131245136261
Epoch: 257/300 - Train loss: 0.3677365779876709, Validation loss: 0.37921082973480225
Epoch: 258/300 - Train loss: 0.3669038414955139, Validation loss: 0.37907564640045166
Epoch: 259/300 - Train loss: 0.3660746216773987, Validation loss: 0.3779122233390808
Epoch: 260/300 - Train loss: 0.3652479648590088, Validation loss: 0.3768981695175171
Epoch: 261/300 - Train loss: 0.36442261934280396, Validation loss: 0.37611016631126404
Epoch: 262/300 - Train loss: 0.36359870433807373, Validation loss: 0.37600982189178467
Epoch: 263/300 - Train loss: 0.3627762794494629, Validation loss: 0.3740072548389435
Epoch: 264/300 - Train loss: 0.36195749044418335, Validation loss: 0.3734264373779297
Epoch: 265/300 - Train loss: 0.3611423969268799, Validation loss: 0.37339648604393005
Epoch: 266/300 - Train loss: 0.36033228039741516, Validation loss: 0.37212085723876953
Epoch: 267/300 - Train loss: 0.359525591135025, Validation loss: 0.3713496923446655
Epoch: 268/300 - Train loss: 0.35872116684913635, Validation loss: 0.3709825575351715
Epoch: 269/300 - Train loss: 0.357918918132782, Validation loss: 0.3703656494617462
Epoch: 270/300 - Train loss: 0.35712045431137085, Validation loss: 0.36960694193840027
Epoch: 271/300 - Train loss: 0.3563270568847656, Validation loss: 0.36869457364082336
Epoch: 272/300 - Train loss: 0.35553744435310364, Validation loss: 0.3680819272994995
Epoch: 273/300 - Train loss: 0.3547528088092804, Validation loss: 0.3667938709259033
Epoch: 274/300 - Train loss: 0.3539726138114929, Validation loss: 0.36610081791877747
Epoch: 275/300 - Train loss: 0.35319769382476807, Validation loss: 0.365572452545166
Epoch: 276/300 - Train loss: 0.35242968797683716, Validation loss: 0.3646549880504608
Epoch: 277/300 - Train loss: 0.3516673743724823, Validation loss: 0.3645571172237396
Epoch: 278/300 - Train loss: 0.35091009736061096, Validation loss: 0.3635534644126892
Epoch: 279/300 - Train loss: 0.3501587510108948, Validation loss: 0.36322978138923645
Epoch: 280/300 - Train loss: 0.3494139015674591, Validation loss: 0.3624311089515686
Epoch: 281/300 - Train loss: 0.34867429733276367, Validation loss: 0.36157578229904175
Epoch: 282/300 - Train loss: 0.3479408025741577, Validation loss: 0.36093032360076904
Epoch: 283/300 - Train loss: 0.3472115397453308, Validation loss: 0.3596998155117035
Epoch: 284/300 - Train loss: 0.3464878797531128, Validation loss: 0.359781414270401
Epoch: 285/300 - Train loss: 0.3457692563533783, Validation loss: 0.3594835102558136
Epoch: 286/300 - Train loss: 0.3450554311275482, Validation loss: 0.3580611050128937
Epoch: 287/300 - Train loss: 0.34434619545936584, Validation loss: 0.3581627309322357
Epoch: 288/300 - Train loss: 0.3436417877674103, Validation loss: 0.356940358877182
Epoch: 289/300 - Train loss: 0.34294408559799194, Validation loss: 0.35574284195899963
Epoch: 290/300 - Train loss: 0.34225234389305115, Validation loss: 0.35563981533050537
Epoch: 291/300 - Train loss: 0.3415655195713043, Validation loss: 0.3553529977798462
Epoch: 292/300 - Train loss: 0.34088343381881714, Validation loss: 0.35441115498542786
Epoch: 293/300 - Train loss: 0.34020644426345825, Validation loss: 0.3535809814929962
Epoch: 294/300 - Train loss: 0.3395339548587799, Validation loss: 0.3528979420661926
Epoch: 295/300 - Train loss: 0.33886754512786865, Validation loss: 0.3526008427143097
Epoch: 296/300 - Train loss: 0.33820635080337524, Validation loss: 0.3520844876766205
Epoch: 297/300 - Train loss: 0.33754971623420715, Validation loss: 0.3511478900909424
Epoch: 298/300 - Train loss: 0.3368987739086151, Validation loss: 0.35113757848739624
