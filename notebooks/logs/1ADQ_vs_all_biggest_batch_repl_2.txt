Epoch: 1/100 - Train loss: 0.6994673609733582, Validation loss: 0.6948925256729126
Epoch: 2/100 - Train loss: 0.6965085864067078, Validation loss: 0.6920169591903687
Epoch: 3/100 - Train loss: 0.6935982704162598, Validation loss: 0.6893027424812317
Epoch: 4/100 - Train loss: 0.690710723400116, Validation loss: 0.6866505146026611
Epoch: 5/100 - Train loss: 0.687831699848175, Validation loss: 0.6838420629501343
Epoch: 6/100 - Train loss: 0.6849544048309326, Validation loss: 0.6812004446983337
Epoch: 7/100 - Train loss: 0.6820545196533203, Validation loss: 0.6783429980278015
Epoch: 8/100 - Train loss: 0.679124116897583, Validation loss: 0.6755860447883606
Epoch: 9/100 - Train loss: 0.6761476397514343, Validation loss: 0.6726600527763367
Epoch: 10/100 - Train loss: 0.6731137633323669, Validation loss: 0.6697762608528137
Epoch: 11/100 - Train loss: 0.6700193881988525, Validation loss: 0.6667138338088989
Epoch: 12/100 - Train loss: 0.6668620705604553, Validation loss: 0.6636965274810791
Epoch: 13/100 - Train loss: 0.6636455655097961, Validation loss: 0.6605071425437927
Epoch: 14/100 - Train loss: 0.6603672504425049, Validation loss: 0.6573143005371094
Epoch: 15/100 - Train loss: 0.6570334434509277, Validation loss: 0.65400230884552
Epoch: 16/100 - Train loss: 0.6536447405815125, Validation loss: 0.6507803201675415
Epoch: 17/100 - Train loss: 0.6502085328102112, Validation loss: 0.64750736951828
Epoch: 18/100 - Train loss: 0.6467412114143372, Validation loss: 0.6441611647605896
Epoch: 19/100 - Train loss: 0.6432492136955261, Validation loss: 0.6407368183135986
Epoch: 20/100 - Train loss: 0.6397364139556885, Validation loss: 0.6373007297515869
Epoch: 21/100 - Train loss: 0.6362162828445435, Validation loss: 0.6337666511535645
Epoch: 22/100 - Train loss: 0.6326886415481567, Validation loss: 0.6306660771369934
Epoch: 23/100 - Train loss: 0.6291701793670654, Validation loss: 0.6274098753929138
Epoch: 24/100 - Train loss: 0.625671923160553, Validation loss: 0.6241167783737183
Epoch: 25/100 - Train loss: 0.6221985220909119, Validation loss: 0.6206310391426086
Epoch: 26/100 - Train loss: 0.6187624335289001, Validation loss: 0.6173902153968811
Epoch: 27/100 - Train loss: 0.6153626441955566, Validation loss: 0.6141162514686584
Epoch: 28/100 - Train loss: 0.6120021343231201, Validation loss: 0.6109865307807922
Epoch: 29/100 - Train loss: 0.6086851358413696, Validation loss: 0.6081412434577942
Epoch: 30/100 - Train loss: 0.6054090261459351, Validation loss: 0.6048718094825745
Epoch: 31/100 - Train loss: 0.6021742820739746, Validation loss: 0.6018246412277222
Epoch: 32/100 - Train loss: 0.5989806652069092, Validation loss: 0.5990884304046631
Epoch: 33/100 - Train loss: 0.5958264470100403, Validation loss: 0.596073567867279
Epoch: 34/100 - Train loss: 0.5927152633666992, Validation loss: 0.5928221940994263
Epoch: 35/100 - Train loss: 0.5896474719047546, Validation loss: 0.5898861885070801
Epoch: 36/100 - Train loss: 0.5866250991821289, Validation loss: 0.5875562429428101
Epoch: 37/100 - Train loss: 0.5836512446403503, Validation loss: 0.5844285488128662
Epoch: 38/100 - Train loss: 0.5807270407676697, Validation loss: 0.581847071647644
Epoch: 39/100 - Train loss: 0.5778548717498779, Validation loss: 0.579285204410553
Epoch: 40/100 - Train loss: 0.5750356316566467, Validation loss: 0.5767717957496643
Epoch: 41/100 - Train loss: 0.572270393371582, Validation loss: 0.5739679336547852
Epoch: 42/100 - Train loss: 0.5695605874061584, Validation loss: 0.5717104077339172
Epoch: 43/100 - Train loss: 0.5669071078300476, Validation loss: 0.5688207745552063
Epoch: 44/100 - Train loss: 0.5643100142478943, Validation loss: 0.5669986605644226
Epoch: 45/100 - Train loss: 0.5617687106132507, Validation loss: 0.5640716552734375
Epoch: 46/100 - Train loss: 0.5592837333679199, Validation loss: 0.5615377426147461
Epoch: 47/100 - Train loss: 0.5568544864654541, Validation loss: 0.5595703125
Epoch: 48/100 - Train loss: 0.5544820427894592, Validation loss: 0.5578063130378723
Epoch: 49/100 - Train loss: 0.5521659255027771, Validation loss: 0.5551640391349792
Epoch: 50/100 - Train loss: 0.549906313419342, Validation loss: 0.5530374050140381
Epoch: 51/100 - Train loss: 0.5477032661437988, Validation loss: 0.5512889623641968
Epoch: 52/100 - Train loss: 0.545556366443634, Validation loss: 0.5491673350334167
Epoch: 53/100 - Train loss: 0.5434653162956238, Validation loss: 0.5469019412994385
Epoch: 54/100 - Train loss: 0.5414294004440308, Validation loss: 0.545596182346344
Epoch: 55/100 - Train loss: 0.5394481420516968, Validation loss: 0.5434932708740234
Epoch: 56/100 - Train loss: 0.5375205874443054, Validation loss: 0.5416303277015686
Epoch: 57/100 - Train loss: 0.5356462597846985, Validation loss: 0.5401490926742554
Epoch: 58/100 - Train loss: 0.53382408618927, Validation loss: 0.5388886332511902
Epoch: 59/100 - Train loss: 0.5320526957511902, Validation loss: 0.5369440913200378
Epoch: 60/100 - Train loss: 0.5303320288658142, Validation loss: 0.535635769367218
Epoch: 61/100 - Train loss: 0.5286608934402466, Validation loss: 0.5334976315498352
Epoch: 62/100 - Train loss: 0.5270373821258545, Validation loss: 0.5321399569511414
Epoch: 63/100 - Train loss: 0.5254605412483215, Validation loss: 0.5306561589241028
Epoch: 64/100 - Train loss: 0.5239300727844238, Validation loss: 0.5289980173110962
Epoch: 65/100 - Train loss: 0.5224436521530151, Validation loss: 0.5279611945152283
Epoch: 66/100 - Train loss: 0.5210003852844238, Validation loss: 0.5269049406051636
Epoch: 67/100 - Train loss: 0.5195985436439514, Validation loss: 0.5254681706428528
Epoch: 68/100 - Train loss: 0.5182359218597412, Validation loss: 0.5239053964614868
Epoch: 69/100 - Train loss: 0.5169107913970947, Validation loss: 0.5232905745506287
Epoch: 70/100 - Train loss: 0.5156233310699463, Validation loss: 0.5219525694847107
Epoch: 71/100 - Train loss: 0.5143710970878601, Validation loss: 0.5204657316207886
Epoch: 72/100 - Train loss: 0.513152539730072, Validation loss: 0.5194129943847656
Epoch: 73/100 - Train loss: 0.5119662880897522, Validation loss: 0.5183667540550232
Epoch: 74/100 - Train loss: 0.5108121633529663, Validation loss: 0.5173521041870117
Epoch: 75/100 - Train loss: 0.5096876621246338, Validation loss: 0.5164248943328857
Epoch: 76/100 - Train loss: 0.508590817451477, Validation loss: 0.5153757333755493
Epoch: 77/100 - Train loss: 0.5075197815895081, Validation loss: 0.5144535303115845
Epoch: 78/100 - Train loss: 0.5064749717712402, Validation loss: 0.5139705538749695
Epoch: 79/100 - Train loss: 0.5054526925086975, Validation loss: 0.5129526257514954
Epoch: 80/100 - Train loss: 0.5044520497322083, Validation loss: 0.5115699768066406
Epoch: 81/100 - Train loss: 0.5034723877906799, Validation loss: 0.5105859637260437
Epoch: 82/100 - Train loss: 0.5025132894515991, Validation loss: 0.5102008581161499
Epoch: 83/100 - Train loss: 0.5015723705291748, Validation loss: 0.5089119672775269
Epoch: 84/100 - Train loss: 0.5006471276283264, Validation loss: 0.508263111114502
Epoch: 85/100 - Train loss: 0.4997364580631256, Validation loss: 0.5072829127311707
Epoch: 86/100 - Train loss: 0.49884143471717834, Validation loss: 0.5066440105438232
Epoch: 87/100 - Train loss: 0.4979593753814697, Validation loss: 0.5058563351631165
Epoch: 88/100 - Train loss: 0.497089147567749, Validation loss: 0.5046215653419495
Epoch: 89/100 - Train loss: 0.496231347322464, Validation loss: 0.503693163394928
Epoch: 90/100 - Train loss: 0.4953850507736206, Validation loss: 0.5032976865768433
Epoch: 91/100 - Train loss: 0.49454909563064575, Validation loss: 0.5028008222579956
Epoch: 92/100 - Train loss: 0.49372345209121704, Validation loss: 0.5019294023513794
Epoch: 93/100 - Train loss: 0.4929077923297882, Validation loss: 0.5009932518005371
Epoch: 94/100 - Train loss: 0.4921020567417145, Validation loss: 0.5000897645950317
Epoch: 95/100 - Train loss: 0.49130505323410034, Validation loss: 0.49903443455696106
Epoch: 96/100 - Train loss: 0.49051493406295776, Validation loss: 0.49884894490242004
Epoch: 97/100 - Train loss: 0.48973342776298523, Validation loss: 0.49786892533302307
Epoch: 98/100 - Train loss: 0.48895832896232605, Validation loss: 0.49733495712280273
Epoch: 99/100 - Train loss: 0.4881889820098877, Validation loss: 0.4963914155960083
Epoch: 100/100 - Train loss: 0.4874248206615448, Validation loss: 0.49532273411750793
Epoch: 1/300 - Train loss: 0.6978952288627625, Validation loss: 0.6944666504859924
Epoch: 2/300 - Train loss: 0.6957466006278992, Validation loss: 0.692340075969696
Epoch: 3/300 - Train loss: 0.6935296058654785, Validation loss: 0.6903524398803711
Epoch: 4/300 - Train loss: 0.6912491321563721, Validation loss: 0.6881092190742493
Epoch: 5/300 - Train loss: 0.6889066100120544, Validation loss: 0.6858255863189697
Epoch: 6/300 - Train loss: 0.6865090727806091, Validation loss: 0.683468222618103
Epoch: 7/300 - Train loss: 0.6840522885322571, Validation loss: 0.6811854243278503
Epoch: 8/300 - Train loss: 0.6815339922904968, Validation loss: 0.6787807941436768
Epoch: 9/300 - Train loss: 0.6789650917053223, Validation loss: 0.6762964129447937
Epoch: 10/300 - Train loss: 0.6763551831245422, Validation loss: 0.6737648248672485
Epoch: 11/300 - Train loss: 0.6737062335014343, Validation loss: 0.6713560819625854
Epoch: 12/300 - Train loss: 0.6710273623466492, Validation loss: 0.668753981590271
Epoch: 13/300 - Train loss: 0.6683272123336792, Validation loss: 0.6661624908447266
Epoch: 14/300 - Train loss: 0.6656129956245422, Validation loss: 0.6636022329330444
Epoch: 15/300 - Train loss: 0.6628960967063904, Validation loss: 0.6610681414604187
Epoch: 16/300 - Train loss: 0.6601741313934326, Validation loss: 0.6584575176239014
Epoch: 17/300 - Train loss: 0.6574517488479614, Validation loss: 0.655867874622345
Epoch: 18/300 - Train loss: 0.6547306776046753, Validation loss: 0.6534361243247986
Epoch: 19/300 - Train loss: 0.6520105004310608, Validation loss: 0.6509212255477905
Epoch: 20/300 - Train loss: 0.6492883563041687, Validation loss: 0.6482325792312622
Epoch: 21/300 - Train loss: 0.6465660929679871, Validation loss: 0.645724892616272
Epoch: 22/300 - Train loss: 0.6438435912132263, Validation loss: 0.6432597637176514
Epoch: 23/300 - Train loss: 0.6411228775978088, Validation loss: 0.64053875207901
Epoch: 24/300 - Train loss: 0.6384034752845764, Validation loss: 0.6381309628486633
Epoch: 25/300 - Train loss: 0.6356845498085022, Validation loss: 0.6352940797805786
Epoch: 26/300 - Train loss: 0.6329674124717712, Validation loss: 0.6327242255210876
Epoch: 27/300 - Train loss: 0.630260169506073, Validation loss: 0.6304275393486023
Epoch: 28/300 - Train loss: 0.6275639533996582, Validation loss: 0.6274879574775696
Epoch: 29/300 - Train loss: 0.6248791813850403, Validation loss: 0.625213623046875
Epoch: 30/300 - Train loss: 0.6222060322761536, Validation loss: 0.6224150061607361
Epoch: 31/300 - Train loss: 0.6195452809333801, Validation loss: 0.620172917842865
Epoch: 32/300 - Train loss: 0.6168997883796692, Validation loss: 0.6176286339759827
Epoch: 33/300 - Train loss: 0.6142709255218506, Validation loss: 0.6150113940238953
Epoch: 34/300 - Train loss: 0.6116578578948975, Validation loss: 0.6124066710472107
Epoch: 35/300 - Train loss: 0.6090614795684814, Validation loss: 0.6103449463844299
Epoch: 36/300 - Train loss: 0.6064807772636414, Validation loss: 0.6077973246574402
Epoch: 37/300 - Train loss: 0.6039174199104309, Validation loss: 0.6051248908042908
Epoch: 38/300 - Train loss: 0.601371705532074, Validation loss: 0.6029377579689026
Epoch: 39/300 - Train loss: 0.5988425612449646, Validation loss: 0.6006755828857422
Epoch: 40/300 - Train loss: 0.5963315963745117, Validation loss: 0.5981565117835999
Epoch: 41/300 - Train loss: 0.5938403010368347, Validation loss: 0.5959188938140869
Epoch: 42/300 - Train loss: 0.5913699865341187, Validation loss: 0.5935541391372681
Epoch: 43/300 - Train loss: 0.588922381401062, Validation loss: 0.591099202632904
Epoch: 44/300 - Train loss: 0.5864979028701782, Validation loss: 0.5889166593551636
Epoch: 45/300 - Train loss: 0.5840977430343628, Validation loss: 0.5863542556762695
Epoch: 46/300 - Train loss: 0.5817217826843262, Validation loss: 0.5842572450637817
Epoch: 47/300 - Train loss: 0.5793706178665161, Validation loss: 0.5820831060409546
Epoch: 48/300 - Train loss: 0.5770447254180908, Validation loss: 0.5795349478721619
Epoch: 49/300 - Train loss: 0.5747446417808533, Validation loss: 0.5777546167373657
Epoch: 50/300 - Train loss: 0.5724703073501587, Validation loss: 0.5756151676177979
Epoch: 51/300 - Train loss: 0.5702213644981384, Validation loss: 0.5731713175773621
Epoch: 52/300 - Train loss: 0.5679982900619507, Validation loss: 0.5708684921264648
Epoch: 53/300 - Train loss: 0.565801203250885, Validation loss: 0.569130003452301
Epoch: 54/300 - Train loss: 0.5636312365531921, Validation loss: 0.5673190355300903
Epoch: 55/300 - Train loss: 0.561488687992096, Validation loss: 0.5651336908340454
Epoch: 56/300 - Train loss: 0.5593742728233337, Validation loss: 0.5629766583442688
Epoch: 57/300 - Train loss: 0.5572883486747742, Validation loss: 0.5614017248153687
Epoch: 58/300 - Train loss: 0.5552321076393127, Validation loss: 0.5596877336502075
Epoch: 59/300 - Train loss: 0.5532057285308838, Validation loss: 0.5570690631866455
Epoch: 60/300 - Train loss: 0.5512092113494873, Validation loss: 0.5555292963981628
Epoch: 61/300 - Train loss: 0.5492428541183472, Validation loss: 0.5535239577293396
Epoch: 62/300 - Train loss: 0.547306478023529, Validation loss: 0.5516335964202881
Epoch: 63/300 - Train loss: 0.5454012751579285, Validation loss: 0.5497137904167175
Epoch: 64/300 - Train loss: 0.5435269474983215, Validation loss: 0.5478867888450623
Epoch: 65/300 - Train loss: 0.5416836738586426, Validation loss: 0.5467379689216614
Epoch: 66/300 - Train loss: 0.5398719310760498, Validation loss: 0.5446204543113708
Epoch: 67/300 - Train loss: 0.5380913019180298, Validation loss: 0.5428549647331238
Epoch: 68/300 - Train loss: 0.5363418459892273, Validation loss: 0.5409733057022095
Epoch: 69/300 - Train loss: 0.5346242189407349, Validation loss: 0.5397506952285767
Epoch: 70/300 - Train loss: 0.5329379439353943, Validation loss: 0.5378327965736389
Epoch: 71/300 - Train loss: 0.5312823057174683, Validation loss: 0.5366115570068359
Epoch: 72/300 - Train loss: 0.5296566486358643, Validation loss: 0.5347855091094971
Epoch: 73/300 - Train loss: 0.5280608534812927, Validation loss: 0.5333592891693115
Epoch: 74/300 - Train loss: 0.526494562625885, Validation loss: 0.5321694016456604
Epoch: 75/300 - Train loss: 0.5249574184417725, Validation loss: 0.5306824445724487
Epoch: 76/300 - Train loss: 0.5234485268592834, Validation loss: 0.5292840003967285
Epoch: 77/300 - Train loss: 0.5219685435295105, Validation loss: 0.5276272296905518
Epoch: 78/300 - Train loss: 0.520517885684967, Validation loss: 0.5267729759216309
Epoch: 79/300 - Train loss: 0.5190956592559814, Validation loss: 0.525407075881958
Epoch: 80/300 - Train loss: 0.517700731754303, Validation loss: 0.523918628692627
Epoch: 81/300 - Train loss: 0.5163335204124451, Validation loss: 0.5223230719566345
Epoch: 82/300 - Train loss: 0.5149925947189331, Validation loss: 0.5213385224342346
Epoch: 83/300 - Train loss: 0.5136777758598328, Validation loss: 0.5200057029724121
Epoch: 84/300 - Train loss: 0.5123894810676575, Validation loss: 0.5186576843261719
Epoch: 85/300 - Train loss: 0.5111269354820251, Validation loss: 0.5176065564155579
Epoch: 86/300 - Train loss: 0.5098890066146851, Validation loss: 0.5166894793510437
Epoch: 87/300 - Train loss: 0.508674681186676, Validation loss: 0.5155221819877625
Epoch: 88/300 - Train loss: 0.5074838399887085, Validation loss: 0.515150249004364
Epoch: 89/300 - Train loss: 0.5063154101371765, Validation loss: 0.5131669640541077
Epoch: 90/300 - Train loss: 0.505169153213501, Validation loss: 0.5124856233596802
Epoch: 91/300 - Train loss: 0.5040446519851685, Validation loss: 0.5111214518547058
Epoch: 92/300 - Train loss: 0.5029415488243103, Validation loss: 0.5103231072425842
Epoch: 93/300 - Train loss: 0.5018593668937683, Validation loss: 0.5089896321296692
Epoch: 94/300 - Train loss: 0.5007970929145813, Validation loss: 0.5084295868873596
Epoch: 95/300 - Train loss: 0.4997536838054657, Validation loss: 0.5069640278816223
Epoch: 96/300 - Train loss: 0.49872854351997375, Validation loss: 0.5062375664710999
Epoch: 97/300 - Train loss: 0.4977210760116577, Validation loss: 0.5055853724479675
Epoch: 98/300 - Train loss: 0.49673089385032654, Validation loss: 0.504681408405304
Epoch: 99/300 - Train loss: 0.4957563877105713, Validation loss: 0.5032599568367004
Epoch: 100/300 - Train loss: 0.4947977066040039, Validation loss: 0.5032860040664673
Epoch: 101/300 - Train loss: 0.4938545525074005, Validation loss: 0.5018524527549744
Epoch: 102/300 - Train loss: 0.49292588233947754, Validation loss: 0.501056432723999
Epoch: 103/300 - Train loss: 0.4920108914375305, Validation loss: 0.500417947769165
Epoch: 104/300 - Train loss: 0.49111002683639526, Validation loss: 0.49944233894348145
Epoch: 105/300 - Train loss: 0.49022215604782104, Validation loss: 0.49896755814552307
Epoch: 106/300 - Train loss: 0.48934704065322876, Validation loss: 0.4979313313961029
Epoch: 107/300 - Train loss: 0.4884829521179199, Validation loss: 0.49674275517463684
Epoch: 108/300 - Train loss: 0.48762989044189453, Validation loss: 0.49638956785202026
Epoch: 109/300 - Train loss: 0.48678821325302124, Validation loss: 0.49536094069480896
Epoch: 110/300 - Train loss: 0.48595720529556274, Validation loss: 0.4958995282649994
Epoch: 111/300 - Train loss: 0.4851360023021698, Validation loss: 0.4936346411705017
Epoch: 112/300 - Train loss: 0.484324187040329, Validation loss: 0.49328529834747314
Epoch: 113/300 - Train loss: 0.4835197329521179, Validation loss: 0.49248233437538147
Epoch: 114/300 - Train loss: 0.4827231466770172, Validation loss: 0.4919363260269165
Epoch: 115/300 - Train loss: 0.4819357097148895, Validation loss: 0.49091365933418274
Epoch: 116/300 - Train loss: 0.4811560809612274, Validation loss: 0.4902631342411041
Epoch: 117/300 - Train loss: 0.4803844094276428, Validation loss: 0.48947957158088684
Epoch: 118/300 - Train loss: 0.4796207547187805, Validation loss: 0.4888955354690552
Epoch: 119/300 - Train loss: 0.4788643717765808, Validation loss: 0.4880122244358063
Epoch: 120/300 - Train loss: 0.4781152009963989, Validation loss: 0.4879775047302246
Epoch: 121/300 - Train loss: 0.4773728549480438, Validation loss: 0.48683154582977295
Epoch: 122/300 - Train loss: 0.4766366183757782, Validation loss: 0.486750990152359
Epoch: 123/300 - Train loss: 0.4759058356285095, Validation loss: 0.48607292771339417
Epoch: 124/300 - Train loss: 0.47518017888069153, Validation loss: 0.48483723402023315
Epoch: 125/300 - Train loss: 0.47445937991142273, Validation loss: 0.48475852608680725
Epoch: 126/300 - Train loss: 0.473742812871933, Validation loss: 0.48365381360054016
Epoch: 127/300 - Train loss: 0.4730301797389984, Validation loss: 0.4827139973640442
Epoch: 128/300 - Train loss: 0.47232216596603394, Validation loss: 0.4824703633785248
Epoch: 129/300 - Train loss: 0.47161826491355896, Validation loss: 0.48217424750328064
Epoch: 130/300 - Train loss: 0.47091832756996155, Validation loss: 0.48117274045944214
Epoch: 131/300 - Train loss: 0.47022175788879395, Validation loss: 0.4804723560810089
Epoch: 132/300 - Train loss: 0.46952763199806213, Validation loss: 0.4801633656024933
Epoch: 133/300 - Train loss: 0.4688367545604706, Validation loss: 0.4792691171169281
Epoch: 134/300 - Train loss: 0.46814942359924316, Validation loss: 0.47942352294921875
Epoch: 135/300 - Train loss: 0.4674657881259918, Validation loss: 0.4780280590057373
Epoch: 136/300 - Train loss: 0.4667845070362091, Validation loss: 0.477671355009079
Epoch: 137/300 - Train loss: 0.4661051630973816, Validation loss: 0.47742578387260437
Epoch: 138/300 - Train loss: 0.46542760729789734, Validation loss: 0.4761466979980469
Epoch: 139/300 - Train loss: 0.46475234627723694, Validation loss: 0.4753257632255554
Epoch: 140/300 - Train loss: 0.4640798270702362, Validation loss: 0.4754858613014221
Epoch: 141/300 - Train loss: 0.46340927481651306, Validation loss: 0.4744287133216858
Epoch: 142/300 - Train loss: 0.4627407193183899, Validation loss: 0.47370097041130066
Epoch: 143/300 - Train loss: 0.4620739817619324, Validation loss: 0.4723932445049286
Epoch: 144/300 - Train loss: 0.46140921115875244, Validation loss: 0.47189614176750183
Epoch: 145/300 - Train loss: 0.46074622869491577, Validation loss: 0.47209057211875916
Epoch: 146/300 - Train loss: 0.4600854218006134, Validation loss: 0.47125574946403503
Epoch: 147/300 - Train loss: 0.4594268798828125, Validation loss: 0.4708307385444641
Epoch: 148/300 - Train loss: 0.4587690830230713, Validation loss: 0.4705495834350586
