Epoch: 1/300 - Train loss: 0.6994901895523071, Validation loss: 0.6956140995025635
Epoch: 2/300 - Train loss: 0.696660578250885, Validation loss: 0.6928910613059998
Epoch: 3/300 - Train loss: 0.6938788294792175, Validation loss: 0.6901960372924805
Epoch: 4/300 - Train loss: 0.6910996437072754, Validation loss: 0.6874174475669861
Epoch: 5/300 - Train loss: 0.6882752180099487, Validation loss: 0.68455570936203
Epoch: 6/300 - Train loss: 0.6853728294372559, Validation loss: 0.6815923452377319
Epoch: 7/300 - Train loss: 0.682350218296051, Validation loss: 0.6784427762031555
Epoch: 8/300 - Train loss: 0.6791736483573914, Validation loss: 0.6751585006713867
Epoch: 9/300 - Train loss: 0.6758142113685608, Validation loss: 0.6715888381004333
Epoch: 10/300 - Train loss: 0.6722583770751953, Validation loss: 0.6678774356842041
Epoch: 11/300 - Train loss: 0.6685050129890442, Validation loss: 0.6640014052391052
Epoch: 12/300 - Train loss: 0.6645621657371521, Validation loss: 0.659934401512146
Epoch: 13/300 - Train loss: 0.6604481339454651, Validation loss: 0.6556230783462524
Epoch: 14/300 - Train loss: 0.6561831831932068, Validation loss: 0.6512510776519775
Epoch: 15/300 - Train loss: 0.6517928242683411, Validation loss: 0.6468099355697632
Epoch: 16/300 - Train loss: 0.6473022103309631, Validation loss: 0.6422168016433716
Epoch: 17/300 - Train loss: 0.6427301168441772, Validation loss: 0.6375591158866882
Epoch: 18/300 - Train loss: 0.6380912065505981, Validation loss: 0.632780909538269
Epoch: 19/300 - Train loss: 0.633399248123169, Validation loss: 0.6280075311660767
Epoch: 20/300 - Train loss: 0.6286629438400269, Validation loss: 0.6231468319892883
Epoch: 21/300 - Train loss: 0.6238964200019836, Validation loss: 0.6184014678001404
Epoch: 22/300 - Train loss: 0.6191073060035706, Validation loss: 0.613656222820282
Epoch: 23/300 - Train loss: 0.6143084764480591, Validation loss: 0.6088763475418091
Epoch: 24/300 - Train loss: 0.6095101237297058, Validation loss: 0.6039516925811768
Epoch: 25/300 - Train loss: 0.60471510887146, Validation loss: 0.5991604924201965
Epoch: 26/300 - Train loss: 0.5999324321746826, Validation loss: 0.594148576259613
Epoch: 27/300 - Train loss: 0.5951687693595886, Validation loss: 0.589244544506073
Epoch: 28/300 - Train loss: 0.5904282331466675, Validation loss: 0.5846105813980103
Epoch: 29/300 - Train loss: 0.5857155919075012, Validation loss: 0.5798238515853882
Epoch: 30/300 - Train loss: 0.581035852432251, Validation loss: 0.5751753449440002
Epoch: 31/300 - Train loss: 0.5763953328132629, Validation loss: 0.5704007148742676
Epoch: 32/300 - Train loss: 0.5717961192131042, Validation loss: 0.5659503936767578
Epoch: 33/300 - Train loss: 0.5672412514686584, Validation loss: 0.5612555742263794
Epoch: 34/300 - Train loss: 0.5627319812774658, Validation loss: 0.5569899082183838
Epoch: 35/300 - Train loss: 0.5582727193832397, Validation loss: 0.5521332025527954
Epoch: 36/300 - Train loss: 0.5538648962974548, Validation loss: 0.5476351976394653
Epoch: 37/300 - Train loss: 0.5495098829269409, Validation loss: 0.5433900356292725
Epoch: 38/300 - Train loss: 0.5452079176902771, Validation loss: 0.5389113426208496
Epoch: 39/300 - Train loss: 0.5409619808197021, Validation loss: 0.5345485210418701
Epoch: 40/300 - Train loss: 0.5367739200592041, Validation loss: 0.5302520394325256
Epoch: 41/300 - Train loss: 0.5326434373855591, Validation loss: 0.5262178182601929
Epoch: 42/300 - Train loss: 0.5285717844963074, Validation loss: 0.5219079256057739
Epoch: 43/300 - Train loss: 0.5245586633682251, Validation loss: 0.5177081227302551
Epoch: 44/300 - Train loss: 0.5206041932106018, Validation loss: 0.5138152241706848
Epoch: 45/300 - Train loss: 0.5167090892791748, Validation loss: 0.5102402567863464
Epoch: 46/300 - Train loss: 0.5128728747367859, Validation loss: 0.5060135722160339
Epoch: 47/300 - Train loss: 0.5090962648391724, Validation loss: 0.5021452307701111
Epoch: 48/300 - Train loss: 0.505378782749176, Validation loss: 0.49822136759757996
Epoch: 49/300 - Train loss: 0.5017193555831909, Validation loss: 0.49451744556427
Epoch: 50/300 - Train loss: 0.49811866879463196, Validation loss: 0.4913087785243988
Epoch: 51/300 - Train loss: 0.4945757985115051, Validation loss: 0.4872596859931946
Epoch: 52/300 - Train loss: 0.4910906255245209, Validation loss: 0.4837615489959717
Epoch: 53/300 - Train loss: 0.4876619875431061, Validation loss: 0.4801536798477173
Epoch: 54/300 - Train loss: 0.4842892289161682, Validation loss: 0.4766063392162323
Epoch: 55/300 - Train loss: 0.4809719920158386, Validation loss: 0.4733571708202362
Epoch: 56/300 - Train loss: 0.47770988941192627, Validation loss: 0.47006380558013916
Epoch: 57/300 - Train loss: 0.47450217604637146, Validation loss: 0.46682751178741455
Epoch: 58/300 - Train loss: 0.47134801745414734, Validation loss: 0.4638362228870392
Epoch: 59/300 - Train loss: 0.46824705600738525, Validation loss: 0.46033233404159546
Epoch: 60/300 - Train loss: 0.4651986360549927, Validation loss: 0.4571987986564636
Epoch: 61/300 - Train loss: 0.4622021019458771, Validation loss: 0.4540887773036957
Epoch: 62/300 - Train loss: 0.45925724506378174, Validation loss: 0.45127829909324646
Epoch: 63/300 - Train loss: 0.4563634395599365, Validation loss: 0.44847461581230164
Epoch: 64/300 - Train loss: 0.4535200297832489, Validation loss: 0.44521957635879517
Epoch: 65/300 - Train loss: 0.45072710514068604, Validation loss: 0.4420825242996216
Epoch: 66/300 - Train loss: 0.4479844868183136, Validation loss: 0.4393399953842163
Epoch: 67/300 - Train loss: 0.4452917277812958, Validation loss: 0.4367072880268097
Epoch: 68/300 - Train loss: 0.4426479935646057, Validation loss: 0.4343809187412262
Epoch: 69/300 - Train loss: 0.4400530457496643, Validation loss: 0.4315609037876129
Epoch: 70/300 - Train loss: 0.4375067949295044, Validation loss: 0.4284193515777588
Epoch: 71/300 - Train loss: 0.43500906229019165, Validation loss: 0.4262444078922272
Epoch: 72/300 - Train loss: 0.4325595498085022, Validation loss: 0.42412808537483215
Epoch: 73/300 - Train loss: 0.43015778064727783, Validation loss: 0.4210888147354126
Epoch: 74/300 - Train loss: 0.42780300974845886, Validation loss: 0.41892364621162415
Epoch: 75/300 - Train loss: 0.4254947304725647, Validation loss: 0.4163152277469635
Epoch: 76/300 - Train loss: 0.4232328534126282, Validation loss: 0.41388896107673645
Epoch: 77/300 - Train loss: 0.42101699113845825, Validation loss: 0.412043958902359
Epoch: 78/300 - Train loss: 0.41884633898735046, Validation loss: 0.40875691175460815
Epoch: 79/300 - Train loss: 0.4167206287384033, Validation loss: 0.40727150440216064
Epoch: 80/300 - Train loss: 0.41463977098464966, Validation loss: 0.40516170859336853
Epoch: 81/300 - Train loss: 0.4126029312610626, Validation loss: 0.4029173254966736
Epoch: 82/300 - Train loss: 0.4106092154979706, Validation loss: 0.4008348286151886
Epoch: 83/300 - Train loss: 0.4086584746837616, Validation loss: 0.39851102232933044
Epoch: 84/300 - Train loss: 0.4067501723766327, Validation loss: 0.3971892297267914
Epoch: 85/300 - Train loss: 0.40488407015800476, Validation loss: 0.39488184452056885
Epoch: 86/300 - Train loss: 0.4030594229698181, Validation loss: 0.3936270773410797
Epoch: 87/300 - Train loss: 0.4012756645679474, Validation loss: 0.39152422547340393
Epoch: 88/300 - Train loss: 0.3995320200920105, Validation loss: 0.38930121064186096
Epoch: 89/300 - Train loss: 0.39782795310020447, Validation loss: 0.38788118958473206
Epoch: 90/300 - Train loss: 0.3961632251739502, Validation loss: 0.3857998251914978
Epoch: 91/300 - Train loss: 0.3945372998714447, Validation loss: 0.3841007947921753
Epoch: 92/300 - Train loss: 0.3929494619369507, Validation loss: 0.38252124190330505
Epoch: 93/300 - Train loss: 0.39139920473098755, Validation loss: 0.3809497356414795
Epoch: 94/300 - Train loss: 0.3898857831954956, Validation loss: 0.3791137635707855
Epoch: 95/300 - Train loss: 0.3884085416793823, Validation loss: 0.37751057744026184
Epoch: 96/300 - Train loss: 0.3869669437408447, Validation loss: 0.37652257084846497
Epoch: 97/300 - Train loss: 0.3855603337287903, Validation loss: 0.3747827112674713
Epoch: 98/300 - Train loss: 0.3841879367828369, Validation loss: 0.37327805161476135
Epoch: 99/300 - Train loss: 0.3828490376472473, Validation loss: 0.37226444482803345
Epoch: 100/300 - Train loss: 0.3815428614616394, Validation loss: 0.3704940974712372
Epoch: 101/300 - Train loss: 0.380268931388855, Validation loss: 0.36918210983276367
Epoch: 102/300 - Train loss: 0.37902677059173584, Validation loss: 0.3680216372013092
Epoch: 103/300 - Train loss: 0.37781569361686707, Validation loss: 0.36701500415802
Epoch: 104/300 - Train loss: 0.37663498520851135, Validation loss: 0.3658265769481659
Epoch: 105/300 - Train loss: 0.37548407912254333, Validation loss: 0.3645356297492981
Epoch: 106/300 - Train loss: 0.3743622601032257, Validation loss: 0.3633192181587219
Epoch: 107/300 - Train loss: 0.37326884269714355, Validation loss: 0.36203670501708984
Epoch: 108/300 - Train loss: 0.37220337986946106, Validation loss: 0.3613481819629669
Epoch: 109/300 - Train loss: 0.37116509675979614, Validation loss: 0.36000266671180725
Epoch: 110/300 - Train loss: 0.37015342712402344, Validation loss: 0.3586662709712982
Epoch: 111/300 - Train loss: 0.369167685508728, Validation loss: 0.3581996262073517
Epoch: 112/300 - Train loss: 0.36820727586746216, Validation loss: 0.3571796119213104
Epoch: 113/300 - Train loss: 0.3672714829444885, Validation loss: 0.35605186223983765
Epoch: 114/300 - Train loss: 0.36635980010032654, Validation loss: 0.35463330149650574
Epoch: 115/300 - Train loss: 0.3654717206954956, Validation loss: 0.35409143567085266
Epoch: 116/300 - Train loss: 0.3646065294742584, Validation loss: 0.3537992537021637
Epoch: 117/300 - Train loss: 0.36376363039016724, Validation loss: 0.3524698317050934
Epoch: 118/300 - Train loss: 0.3629426062107086, Validation loss: 0.35160017013549805
Epoch: 119/300 - Train loss: 0.3621428906917572, Validation loss: 0.3505580723285675
Epoch: 120/300 - Train loss: 0.36136412620544434, Validation loss: 0.3495400547981262
Epoch: 121/300 - Train loss: 0.36060577630996704, Validation loss: 0.3489792048931122
Epoch: 122/300 - Train loss: 0.3598673343658447, Validation loss: 0.34749239683151245
Epoch: 123/300 - Train loss: 0.3591482639312744, Validation loss: 0.3470408618450165
Epoch: 124/300 - Train loss: 0.3584480583667755, Validation loss: 0.3469724953174591
Epoch: 125/300 - Train loss: 0.35776615142822266, Validation loss: 0.34571120142936707
Epoch: 126/300 - Train loss: 0.35710206627845764, Validation loss: 0.3453504145145416
Epoch: 127/300 - Train loss: 0.3564555048942566, Validation loss: 0.34426310658454895
Epoch: 128/300 - Train loss: 0.3558260202407837, Validation loss: 0.3437736928462982
Epoch: 129/300 - Train loss: 0.3552131652832031, Validation loss: 0.3433644473552704
Epoch: 130/300 - Train loss: 0.3546163737773895, Validation loss: 0.34269270300865173
Epoch: 131/300 - Train loss: 0.35403525829315186, Validation loss: 0.342109352350235
Epoch: 132/300 - Train loss: 0.35346949100494385, Validation loss: 0.3413448631763458
Epoch: 133/300 - Train loss: 0.35291874408721924, Validation loss: 0.3412315249443054
Epoch: 134/300 - Train loss: 0.3523826003074646, Validation loss: 0.34030622243881226
Epoch: 135/300 - Train loss: 0.3518606424331665, Validation loss: 0.3401324450969696
Epoch: 136/300 - Train loss: 0.3513524830341339, Validation loss: 0.3392944037914276
