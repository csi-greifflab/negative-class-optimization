Epoch: 1/300 - Train loss: 0.7017201781272888, Validation loss: 0.6958348751068115
Epoch: 2/300 - Train loss: 0.6970560550689697, Validation loss: 0.6915720701217651
Epoch: 3/300 - Train loss: 0.6925376057624817, Validation loss: 0.6873807907104492
Epoch: 4/300 - Train loss: 0.6881343126296997, Validation loss: 0.6833595633506775
Epoch: 5/300 - Train loss: 0.6838221549987793, Validation loss: 0.6790179014205933
Epoch: 6/300 - Train loss: 0.6795763969421387, Validation loss: 0.675121009349823
Epoch: 7/300 - Train loss: 0.6753813028335571, Validation loss: 0.6710918545722961
Epoch: 8/300 - Train loss: 0.6712196469306946, Validation loss: 0.6671080589294434
Epoch: 9/300 - Train loss: 0.6670786142349243, Validation loss: 0.663060188293457
Epoch: 10/300 - Train loss: 0.662947416305542, Validation loss: 0.6591749787330627
Epoch: 11/300 - Train loss: 0.6588181853294373, Validation loss: 0.6551225185394287
Epoch: 12/300 - Train loss: 0.6546736359596252, Validation loss: 0.6510574817657471
Epoch: 13/300 - Train loss: 0.6504992842674255, Validation loss: 0.6469821333885193
Epoch: 14/300 - Train loss: 0.6462792754173279, Validation loss: 0.6428382992744446
Epoch: 15/300 - Train loss: 0.6419999599456787, Validation loss: 0.638716459274292
Epoch: 16/300 - Train loss: 0.6376479864120483, Validation loss: 0.6343123316764832
Epoch: 17/300 - Train loss: 0.6332168579101562, Validation loss: 0.6298597455024719
Epoch: 18/300 - Train loss: 0.628699779510498, Validation loss: 0.6252995133399963
Epoch: 19/300 - Train loss: 0.6240941286087036, Validation loss: 0.6208367347717285
Epoch: 20/300 - Train loss: 0.6194086074829102, Validation loss: 0.6160335540771484
Epoch: 21/300 - Train loss: 0.6146529316902161, Validation loss: 0.6113790273666382
Epoch: 22/300 - Train loss: 0.609839141368866, Validation loss: 0.6066010594367981
Epoch: 23/300 - Train loss: 0.604987382888794, Validation loss: 0.6017895936965942
Epoch: 24/300 - Train loss: 0.6001214981079102, Validation loss: 0.5967366099357605
Epoch: 25/300 - Train loss: 0.5952544808387756, Validation loss: 0.5921179056167603
Epoch: 26/300 - Train loss: 0.5903947353363037, Validation loss: 0.5872831344604492
Epoch: 27/300 - Train loss: 0.5855498313903809, Validation loss: 0.5825648307800293
Epoch: 28/300 - Train loss: 0.5807203650474548, Validation loss: 0.5777976512908936
Epoch: 29/300 - Train loss: 0.5759004354476929, Validation loss: 0.5730708837509155
Epoch: 30/300 - Train loss: 0.5710870623588562, Validation loss: 0.5681966543197632
Epoch: 31/300 - Train loss: 0.5662829279899597, Validation loss: 0.563423216342926
Epoch: 32/300 - Train loss: 0.561484694480896, Validation loss: 0.5586214661598206
Epoch: 33/300 - Train loss: 0.5566913485527039, Validation loss: 0.5539361834526062
Epoch: 34/300 - Train loss: 0.5519047379493713, Validation loss: 0.5493684411048889
Epoch: 35/300 - Train loss: 0.5471274852752686, Validation loss: 0.5444268584251404
Epoch: 36/300 - Train loss: 0.542363166809082, Validation loss: 0.5396405458450317
Epoch: 37/300 - Train loss: 0.5376171469688416, Validation loss: 0.5349003672599792
Epoch: 38/300 - Train loss: 0.5328964591026306, Validation loss: 0.5302540063858032
Epoch: 39/300 - Train loss: 0.5282071828842163, Validation loss: 0.5257143378257751
Epoch: 40/300 - Train loss: 0.5235570073127747, Validation loss: 0.5209161043167114
Epoch: 41/300 - Train loss: 0.5189512968063354, Validation loss: 0.5165702700614929
Epoch: 42/300 - Train loss: 0.5143946409225464, Validation loss: 0.5117766857147217
Epoch: 43/300 - Train loss: 0.5098876953125, Validation loss: 0.5072799324989319
Epoch: 44/300 - Train loss: 0.5054369568824768, Validation loss: 0.502770721912384
Epoch: 45/300 - Train loss: 0.5010469555854797, Validation loss: 0.4986289143562317
Epoch: 46/300 - Train loss: 0.49672186374664307, Validation loss: 0.49412065744400024
Epoch: 47/300 - Train loss: 0.4924631416797638, Validation loss: 0.48979321122169495
Epoch: 48/300 - Train loss: 0.488272488117218, Validation loss: 0.48596036434173584
Epoch: 49/300 - Train loss: 0.4841517508029938, Validation loss: 0.4815419614315033
Epoch: 50/300 - Train loss: 0.48010072112083435, Validation loss: 0.4779580235481262
Epoch: 51/300 - Train loss: 0.4761226177215576, Validation loss: 0.47372913360595703
Epoch: 52/300 - Train loss: 0.47221624851226807, Validation loss: 0.4704073369503021
Epoch: 53/300 - Train loss: 0.46838104724884033, Validation loss: 0.46622565388679504
Epoch: 54/300 - Train loss: 0.46461790800094604, Validation loss: 0.46231579780578613
Epoch: 55/300 - Train loss: 0.460925430059433, Validation loss: 0.45851534605026245
Epoch: 56/300 - Train loss: 0.45730412006378174, Validation loss: 0.45516660809516907
Epoch: 57/300 - Train loss: 0.45375433564186096, Validation loss: 0.451543927192688
Epoch: 58/300 - Train loss: 0.45027512311935425, Validation loss: 0.4481457769870758
Epoch: 59/300 - Train loss: 0.44686633348464966, Validation loss: 0.4452582001686096
Epoch: 60/300 - Train loss: 0.44352835416793823, Validation loss: 0.4412038028240204
Epoch: 61/300 - Train loss: 0.4402602016925812, Validation loss: 0.43832483887672424
Epoch: 62/300 - Train loss: 0.43706175684928894, Validation loss: 0.43534713983535767
Epoch: 63/300 - Train loss: 0.43393269181251526, Validation loss: 0.43152090907096863
Epoch: 64/300 - Train loss: 0.43087199330329895, Validation loss: 0.42921683192253113
Epoch: 65/300 - Train loss: 0.4278789758682251, Validation loss: 0.42617329955101013
Epoch: 66/300 - Train loss: 0.42495277523994446, Validation loss: 0.423038125038147
Epoch: 67/300 - Train loss: 0.4220922589302063, Validation loss: 0.41995278000831604
Epoch: 68/300 - Train loss: 0.4192963242530823, Validation loss: 0.4170908033847809
Epoch: 69/300 - Train loss: 0.416563481092453, Validation loss: 0.41525009274482727
Epoch: 70/300 - Train loss: 0.4138930141925812, Validation loss: 0.4120868146419525
Epoch: 71/300 - Train loss: 0.41128331422805786, Validation loss: 0.4092685282230377
Epoch: 72/300 - Train loss: 0.4087332785129547, Validation loss: 0.40681055188179016
Epoch: 73/300 - Train loss: 0.4062408208847046, Validation loss: 0.40467536449432373
Epoch: 74/300 - Train loss: 0.40380534529685974, Validation loss: 0.40213921666145325
Epoch: 75/300 - Train loss: 0.4014250338077545, Validation loss: 0.39981260895729065
Epoch: 76/300 - Train loss: 0.3990986943244934, Validation loss: 0.39785024523735046
Epoch: 77/300 - Train loss: 0.3968241512775421, Validation loss: 0.39528152346611023
Epoch: 78/300 - Train loss: 0.3946010172367096, Validation loss: 0.39262908697128296
Epoch: 79/300 - Train loss: 0.3924272060394287, Validation loss: 0.39039346575737
Epoch: 80/300 - Train loss: 0.3903001844882965, Validation loss: 0.3883570432662964
Epoch: 81/300 - Train loss: 0.3882198929786682, Validation loss: 0.3867560923099518
Epoch: 82/300 - Train loss: 0.3861849009990692, Validation loss: 0.38456326723098755
Epoch: 83/300 - Train loss: 0.38419365882873535, Validation loss: 0.38230669498443604
Epoch: 84/300 - Train loss: 0.3822455108165741, Validation loss: 0.38001903891563416
Epoch: 85/300 - Train loss: 0.38033923506736755, Validation loss: 0.3781883120536804
Epoch: 86/300 - Train loss: 0.3784736692905426, Validation loss: 0.3764479160308838
Epoch: 87/300 - Train loss: 0.3766474425792694, Validation loss: 0.37463510036468506
Epoch: 88/300 - Train loss: 0.3748587369918823, Validation loss: 0.37402430176734924
Epoch: 89/300 - Train loss: 0.3731071650981903, Validation loss: 0.3708290755748749
Epoch: 90/300 - Train loss: 0.37139105796813965, Validation loss: 0.3692382574081421
Epoch: 91/300 - Train loss: 0.369710773229599, Validation loss: 0.368209570646286
Epoch: 92/300 - Train loss: 0.3680649399757385, Validation loss: 0.366401344537735
Epoch: 93/300 - Train loss: 0.366451621055603, Validation loss: 0.3643108606338501
Epoch: 94/300 - Train loss: 0.3648693263530731, Validation loss: 0.36375394463539124
Epoch: 95/300 - Train loss: 0.36331719160079956, Validation loss: 0.36102816462516785
Epoch: 96/300 - Train loss: 0.36179447174072266, Validation loss: 0.3594612181186676
Epoch: 97/300 - Train loss: 0.36030033230781555, Validation loss: 0.3586443364620209
Epoch: 98/300 - Train loss: 0.35883328318595886, Validation loss: 0.35689133405685425
Epoch: 99/300 - Train loss: 0.35739225149154663, Validation loss: 0.35532739758491516
Epoch: 100/300 - Train loss: 0.35597556829452515, Validation loss: 0.35409632325172424
Epoch: 101/300 - Train loss: 0.35458412766456604, Validation loss: 0.3522508442401886
Epoch: 102/300 - Train loss: 0.35321706533432007, Validation loss: 0.3514111042022705
Epoch: 103/300 - Train loss: 0.3518739938735962, Validation loss: 0.3503688871860504
Epoch: 104/300 - Train loss: 0.3505549132823944, Validation loss: 0.3488061726093292
Epoch: 105/300 - Train loss: 0.34925904870033264, Validation loss: 0.3474293053150177
Epoch: 106/300 - Train loss: 0.34798550605773926, Validation loss: 0.346406489610672
Epoch: 107/300 - Train loss: 0.3467336595058441, Validation loss: 0.34483176469802856
Epoch: 108/300 - Train loss: 0.34550175070762634, Validation loss: 0.3444822430610657
Epoch: 109/300 - Train loss: 0.34429067373275757, Validation loss: 0.34263789653778076
Epoch: 110/300 - Train loss: 0.34309983253479004, Validation loss: 0.34143081307411194
Epoch: 111/300 - Train loss: 0.34192925691604614, Validation loss: 0.3399640917778015
Epoch: 112/300 - Train loss: 0.34077781438827515, Validation loss: 0.33908751606941223
Epoch: 113/300 - Train loss: 0.3396453559398651, Validation loss: 0.33827275037765503
Epoch: 114/300 - Train loss: 0.3385314643383026, Validation loss: 0.3376368582248688
Epoch: 115/300 - Train loss: 0.3374364376068115, Validation loss: 0.3359869122505188
Epoch: 116/300 - Train loss: 0.3363593518733978, Validation loss: 0.33441823720932007
Epoch: 117/300 - Train loss: 0.3352990746498108, Validation loss: 0.33432134985923767
Epoch: 118/300 - Train loss: 0.3342556059360504, Validation loss: 0.33279433846473694
Epoch: 119/300 - Train loss: 0.333229660987854, Validation loss: 0.3311498761177063
Epoch: 120/300 - Train loss: 0.33221980929374695, Validation loss: 0.33051127195358276
Epoch: 121/300 - Train loss: 0.33122575283050537, Validation loss: 0.3298259675502777
Epoch: 122/300 - Train loss: 0.33024585247039795, Validation loss: 0.3290058374404907
Epoch: 123/300 - Train loss: 0.3292812407016754, Validation loss: 0.32743287086486816
Epoch: 124/300 - Train loss: 0.3283317983150482, Validation loss: 0.32672858238220215
Epoch: 125/300 - Train loss: 0.3273967504501343, Validation loss: 0.3265308737754822
Epoch: 126/300 - Train loss: 0.326475590467453, Validation loss: 0.32556504011154175
Epoch: 127/300 - Train loss: 0.32556813955307007, Validation loss: 0.3238716125488281
Epoch: 128/300 - Train loss: 0.3246736526489258, Validation loss: 0.32358816266059875
Epoch: 129/300 - Train loss: 0.3237919211387634, Validation loss: 0.3228120803833008
Epoch: 130/300 - Train loss: 0.32292306423187256, Validation loss: 0.3219471275806427
Epoch: 131/300 - Train loss: 0.32206666469573975, Validation loss: 0.32131141424179077
Epoch: 132/300 - Train loss: 0.32122257351875305, Validation loss: 0.3213012218475342
Epoch: 133/300 - Train loss: 0.3203909993171692, Validation loss: 0.31908875703811646
Epoch: 134/300 - Train loss: 0.31957143545150757, Validation loss: 0.3191721737384796
Epoch: 135/300 - Train loss: 0.31876373291015625, Validation loss: 0.3178965449333191
Epoch: 136/300 - Train loss: 0.3179674744606018, Validation loss: 0.31679943203926086
Epoch: 137/300 - Train loss: 0.31718191504478455, Validation loss: 0.3164915442466736
Epoch: 138/300 - Train loss: 0.31640753149986267, Validation loss: 0.31592199206352234
Epoch: 139/300 - Train loss: 0.3156445622444153, Validation loss: 0.31494802236557007
Epoch: 140/300 - Train loss: 0.3148922324180603, Validation loss: 0.3141825199127197
Epoch: 141/300 - Train loss: 0.3141491413116455, Validation loss: 0.31319984793663025
Epoch: 142/300 - Train loss: 0.31341609358787537, Validation loss: 0.3126826584339142
Epoch: 143/300 - Train loss: 0.31269362568855286, Validation loss: 0.312328964471817
Epoch: 144/300 - Train loss: 0.3119814395904541, Validation loss: 0.31162720918655396
Epoch: 145/300 - Train loss: 0.3112790584564209, Validation loss: 0.31085237860679626
Epoch: 146/300 - Train loss: 0.31058600544929504, Validation loss: 0.31033897399902344
Epoch: 147/300 - Train loss: 0.3099023997783661, Validation loss: 0.3095194101333618
Epoch: 148/300 - Train loss: 0.30922794342041016, Validation loss: 0.3089594542980194
Epoch: 149/300 - Train loss: 0.30856117606163025, Validation loss: 0.30860188603401184
Epoch: 150/300 - Train loss: 0.3079032003879547, Validation loss: 0.3075244128704071
Epoch: 151/300 - Train loss: 0.3072538673877716, Validation loss: 0.3070603311061859
Epoch: 152/300 - Train loss: 0.30661308765411377, Validation loss: 0.3068349361419678
Epoch: 153/300 - Train loss: 0.30598077178001404, Validation loss: 0.3057331144809723
Epoch: 154/300 - Train loss: 0.30535638332366943, Validation loss: 0.305259108543396
Epoch: 155/300 - Train loss: 0.3047401010990143, Validation loss: 0.30448025465011597
Epoch: 156/300 - Train loss: 0.30413204431533813, Validation loss: 0.30415216088294983
Epoch: 157/300 - Train loss: 0.30353212356567383, Validation loss: 0.30322006344795227
Epoch: 158/300 - Train loss: 0.30294010043144226, Validation loss: 0.3024635910987854
Epoch: 159/300 - Train loss: 0.30235499143600464, Validation loss: 0.3028774559497833
Epoch: 160/300 - Train loss: 0.3017767369747162, Validation loss: 0.3016986548900604
Epoch: 161/300 - Train loss: 0.3012051582336426, Validation loss: 0.3020250201225281
Epoch: 162/300 - Train loss: 0.3006405830383301, Validation loss: 0.3010628819465637
