Epoch: 1/100 - Train loss: 0.7021802067756653, Validation loss: 0.6977800726890564
Epoch: 2/100 - Train loss: 0.6997230648994446, Validation loss: 0.695453941822052
Epoch: 3/100 - Train loss: 0.6972706913948059, Validation loss: 0.6932013034820557
Epoch: 4/100 - Train loss: 0.6948113441467285, Validation loss: 0.690651535987854
Epoch: 5/100 - Train loss: 0.6923421621322632, Validation loss: 0.6884677410125732
Epoch: 6/100 - Train loss: 0.6898629069328308, Validation loss: 0.6861252784729004
Epoch: 7/100 - Train loss: 0.6873745918273926, Validation loss: 0.6838300824165344
Epoch: 8/100 - Train loss: 0.6848738789558411, Validation loss: 0.6813983917236328
Epoch: 9/100 - Train loss: 0.6823620796203613, Validation loss: 0.679154634475708
Epoch: 10/100 - Train loss: 0.679844856262207, Validation loss: 0.6768031716346741
Epoch: 11/100 - Train loss: 0.6773295998573303, Validation loss: 0.6744354963302612
Epoch: 12/100 - Train loss: 0.6748223900794983, Validation loss: 0.6720909476280212
Epoch: 13/100 - Train loss: 0.6723291277885437, Validation loss: 0.6697406768798828
Epoch: 14/100 - Train loss: 0.6698502898216248, Validation loss: 0.6674749255180359
Epoch: 15/100 - Train loss: 0.6673908233642578, Validation loss: 0.6651967167854309
Epoch: 16/100 - Train loss: 0.6649497747421265, Validation loss: 0.6630728840827942
Epoch: 17/100 - Train loss: 0.6625245809555054, Validation loss: 0.6607398390769958
Epoch: 18/100 - Train loss: 0.660108208656311, Validation loss: 0.6584171056747437
Epoch: 19/100 - Train loss: 0.6576931476593018, Validation loss: 0.6561861038208008
Epoch: 20/100 - Train loss: 0.655275285243988, Validation loss: 0.6540808081626892
Epoch: 21/100 - Train loss: 0.6528491973876953, Validation loss: 0.6517736315727234
Epoch: 22/100 - Train loss: 0.6504080891609192, Validation loss: 0.6492435336112976
Epoch: 23/100 - Train loss: 0.6479462385177612, Validation loss: 0.6471454501152039
Epoch: 24/100 - Train loss: 0.6454606652259827, Validation loss: 0.6447728872299194
Epoch: 25/100 - Train loss: 0.6429464817047119, Validation loss: 0.6422650814056396
Epoch: 26/100 - Train loss: 0.6403971314430237, Validation loss: 0.6398018002510071
Epoch: 27/100 - Train loss: 0.6378106474876404, Validation loss: 0.6373786330223083
Epoch: 28/100 - Train loss: 0.6351825594902039, Validation loss: 0.6347925662994385
Epoch: 29/100 - Train loss: 0.6325049996376038, Validation loss: 0.6320796608924866
Epoch: 30/100 - Train loss: 0.6297797560691833, Validation loss: 0.6295642852783203
Epoch: 31/100 - Train loss: 0.6270086765289307, Validation loss: 0.6270332336425781
Epoch: 32/100 - Train loss: 0.624194324016571, Validation loss: 0.6241446733474731
Epoch: 33/100 - Train loss: 0.6213436126708984, Validation loss: 0.6215004920959473
Epoch: 34/100 - Train loss: 0.6184614896774292, Validation loss: 0.6186008453369141
Epoch: 35/100 - Train loss: 0.6155563592910767, Validation loss: 0.6159774661064148
Epoch: 36/100 - Train loss: 0.612637996673584, Validation loss: 0.6131473183631897
Epoch: 37/100 - Train loss: 0.6097195744514465, Validation loss: 0.6104918122291565
Epoch: 38/100 - Train loss: 0.6068087816238403, Validation loss: 0.6071892976760864
Epoch: 39/100 - Train loss: 0.6039096117019653, Validation loss: 0.6047691106796265
Epoch: 40/100 - Train loss: 0.6010221838951111, Validation loss: 0.6020700335502625
Epoch: 41/100 - Train loss: 0.5981510281562805, Validation loss: 0.5990954637527466
Epoch: 42/100 - Train loss: 0.5952896475791931, Validation loss: 0.5964762568473816
Epoch: 43/100 - Train loss: 0.5924423336982727, Validation loss: 0.5937400460243225
Epoch: 44/100 - Train loss: 0.5896095633506775, Validation loss: 0.5910813808441162
Epoch: 45/100 - Train loss: 0.5867958664894104, Validation loss: 0.588580310344696
Epoch: 46/100 - Train loss: 0.5840068459510803, Validation loss: 0.5854377746582031
Epoch: 47/100 - Train loss: 0.5812477469444275, Validation loss: 0.5831271409988403
Epoch: 48/100 - Train loss: 0.5785236358642578, Validation loss: 0.5805780291557312
Epoch: 49/100 - Train loss: 0.5758374333381653, Validation loss: 0.5778884887695312
Epoch: 50/100 - Train loss: 0.573194146156311, Validation loss: 0.5757763385772705
Epoch: 51/100 - Train loss: 0.5705977082252502, Validation loss: 0.5733582377433777
Epoch: 52/100 - Train loss: 0.5680506825447083, Validation loss: 0.5707359313964844
Epoch: 53/100 - Train loss: 0.5655544996261597, Validation loss: 0.5684056878089905
Epoch: 54/100 - Train loss: 0.5631095767021179, Validation loss: 0.5660561323165894
Epoch: 55/100 - Train loss: 0.560716450214386, Validation loss: 0.5644887685775757
Epoch: 56/100 - Train loss: 0.5583750009536743, Validation loss: 0.562282919883728
Epoch: 57/100 - Train loss: 0.5560852885246277, Validation loss: 0.5595266222953796
Epoch: 58/100 - Train loss: 0.5538478493690491, Validation loss: 0.5575282573699951
Epoch: 59/100 - Train loss: 0.5516636371612549, Validation loss: 0.5556706190109253
Epoch: 60/100 - Train loss: 0.5495340824127197, Validation loss: 0.5537206530570984
Epoch: 61/100 - Train loss: 0.5474600195884705, Validation loss: 0.5516200661659241
Epoch: 62/100 - Train loss: 0.5454431772232056, Validation loss: 0.5504134893417358
Epoch: 63/100 - Train loss: 0.5434834957122803, Validation loss: 0.54803866147995
Epoch: 64/100 - Train loss: 0.5415810942649841, Validation loss: 0.5466740727424622
Epoch: 65/100 - Train loss: 0.5397344827651978, Validation loss: 0.5443205833435059
Epoch: 66/100 - Train loss: 0.5379430055618286, Validation loss: 0.5432490706443787
Epoch: 67/100 - Train loss: 0.5362061262130737, Validation loss: 0.5412251949310303
Epoch: 68/100 - Train loss: 0.534522533416748, Validation loss: 0.5396778583526611
Epoch: 69/100 - Train loss: 0.5328905582427979, Validation loss: 0.5387470126152039
Epoch: 70/100 - Train loss: 0.5313090682029724, Validation loss: 0.5363659858703613
Epoch: 71/100 - Train loss: 0.5297780632972717, Validation loss: 0.5351126194000244
Epoch: 72/100 - Train loss: 0.5282967686653137, Validation loss: 0.5339139103889465
Epoch: 73/100 - Train loss: 0.5268634557723999, Validation loss: 0.5329030752182007
Epoch: 74/100 - Train loss: 0.5254772305488586, Validation loss: 0.5320450067520142
Epoch: 75/100 - Train loss: 0.5241365432739258, Validation loss: 0.5307933688163757
Epoch: 76/100 - Train loss: 0.5228400826454163, Validation loss: 0.529739499092102
Epoch: 77/100 - Train loss: 0.5215860605239868, Validation loss: 0.5283376574516296
Epoch: 78/100 - Train loss: 0.5203729867935181, Validation loss: 0.5272588133811951
Epoch: 79/100 - Train loss: 0.519199550151825, Validation loss: 0.526462197303772
Epoch: 80/100 - Train loss: 0.5180638432502747, Validation loss: 0.5248525142669678
Epoch: 81/100 - Train loss: 0.5169640779495239, Validation loss: 0.5239704251289368
Epoch: 82/100 - Train loss: 0.5158985257148743, Validation loss: 0.5230276584625244
Epoch: 83/100 - Train loss: 0.5148659348487854, Validation loss: 0.5224758982658386
Epoch: 84/100 - Train loss: 0.5138653516769409, Validation loss: 0.521775484085083
Epoch: 85/100 - Train loss: 0.5128955841064453, Validation loss: 0.520842969417572
Epoch: 86/100 - Train loss: 0.5119542479515076, Validation loss: 0.5198013782501221
Epoch: 87/100 - Train loss: 0.5110403895378113, Validation loss: 0.51891028881073
Epoch: 88/100 - Train loss: 0.5101523995399475, Validation loss: 0.5177937746047974
Epoch: 89/100 - Train loss: 0.5092881321907043, Validation loss: 0.5174703598022461
Epoch: 90/100 - Train loss: 0.5084461569786072, Validation loss: 0.5170860290527344
Epoch: 91/100 - Train loss: 0.5076252818107605, Validation loss: 0.5158576965332031
Epoch: 92/100 - Train loss: 0.5068238973617554, Validation loss: 0.5153977870941162
Epoch: 93/100 - Train loss: 0.5060398578643799, Validation loss: 0.5144185423851013
Epoch: 94/100 - Train loss: 0.5052722096443176, Validation loss: 0.5143970847129822
Epoch: 95/100 - Train loss: 0.5045215487480164, Validation loss: 0.5130378603935242
Epoch: 96/100 - Train loss: 0.5037863254547119, Validation loss: 0.5127964615821838
Epoch: 97/100 - Train loss: 0.5030650496482849, Validation loss: 0.5115153789520264
Epoch: 98/100 - Train loss: 0.5023558139801025, Validation loss: 0.5118648409843445
Epoch: 99/100 - Train loss: 0.5016571283340454, Validation loss: 0.509896993637085
Epoch: 100/100 - Train loss: 0.5009676218032837, Validation loss: 0.5091981887817383
Epoch: 1/300 - Train loss: 0.6971102952957153, Validation loss: 0.6963538527488708
Epoch: 2/300 - Train loss: 0.6951815485954285, Validation loss: 0.6942979097366333
Epoch: 3/300 - Train loss: 0.6932060122489929, Validation loss: 0.6922047138214111
Epoch: 4/300 - Train loss: 0.6911566853523254, Validation loss: 0.6898755431175232
Epoch: 5/300 - Train loss: 0.6890081167221069, Validation loss: 0.6876652836799622
Epoch: 6/300 - Train loss: 0.6867526769638062, Validation loss: 0.6853281259536743
Epoch: 7/300 - Train loss: 0.6843941807746887, Validation loss: 0.6828842759132385
Epoch: 8/300 - Train loss: 0.6819376349449158, Validation loss: 0.6802749633789062
Epoch: 9/300 - Train loss: 0.6793732643127441, Validation loss: 0.6777291297912598
Epoch: 10/300 - Train loss: 0.6767082810401917, Validation loss: 0.6749273538589478
Epoch: 11/300 - Train loss: 0.6739400625228882, Validation loss: 0.6721774339675903
Epoch: 12/300 - Train loss: 0.6710686087608337, Validation loss: 0.6691684722900391
Epoch: 13/300 - Train loss: 0.668100118637085, Validation loss: 0.6663722991943359
Epoch: 14/300 - Train loss: 0.6650463342666626, Validation loss: 0.6631811261177063
Epoch: 15/300 - Train loss: 0.661919891834259, Validation loss: 0.6601256132125854
Epoch: 16/300 - Train loss: 0.6587328314781189, Validation loss: 0.6569080352783203
Epoch: 17/300 - Train loss: 0.6554964184761047, Validation loss: 0.653605580329895
Epoch: 18/300 - Train loss: 0.6522228121757507, Validation loss: 0.650481104850769
Epoch: 19/300 - Train loss: 0.6489260792732239, Validation loss: 0.647235095500946
Epoch: 20/300 - Train loss: 0.6456175446510315, Validation loss: 0.6439433097839355
Epoch: 21/300 - Train loss: 0.6422958970069885, Validation loss: 0.6406429409980774
Epoch: 22/300 - Train loss: 0.6389688849449158, Validation loss: 0.6374069452285767
Epoch: 23/300 - Train loss: 0.635638415813446, Validation loss: 0.6341568827629089
Epoch: 24/300 - Train loss: 0.6323097944259644, Validation loss: 0.6308623552322388
Epoch: 25/300 - Train loss: 0.6289879083633423, Validation loss: 0.6274937987327576
Epoch: 26/300 - Train loss: 0.6256799101829529, Validation loss: 0.6244072914123535
Epoch: 27/300 - Train loss: 0.6223881244659424, Validation loss: 0.6211300492286682
Epoch: 28/300 - Train loss: 0.6191182732582092, Validation loss: 0.6180881857872009
Epoch: 29/300 - Train loss: 0.6158720254898071, Validation loss: 0.6148721575737
Epoch: 30/300 - Train loss: 0.6126498579978943, Validation loss: 0.6117950677871704
Epoch: 31/300 - Train loss: 0.6094554662704468, Validation loss: 0.608470618724823
Epoch: 32/300 - Train loss: 0.6062915325164795, Validation loss: 0.605640172958374
Epoch: 33/300 - Train loss: 0.6031606793403625, Validation loss: 0.6024916768074036
Epoch: 34/300 - Train loss: 0.6000649333000183, Validation loss: 0.5996769070625305
Epoch: 35/300 - Train loss: 0.5970054864883423, Validation loss: 0.5964900255203247
Epoch: 36/300 - Train loss: 0.5939841866493225, Validation loss: 0.5935888886451721
Epoch: 37/300 - Train loss: 0.5910036563873291, Validation loss: 0.5908464789390564
Epoch: 38/300 - Train loss: 0.5880648493766785, Validation loss: 0.5877465009689331
Epoch: 39/300 - Train loss: 0.5851699709892273, Validation loss: 0.5852386951446533
Epoch: 40/300 - Train loss: 0.5823195576667786, Validation loss: 0.582792341709137
Epoch: 41/300 - Train loss: 0.5795148611068726, Validation loss: 0.5799469947814941
Epoch: 42/300 - Train loss: 0.5767574906349182, Validation loss: 0.5775370001792908
Epoch: 43/300 - Train loss: 0.5740483403205872, Validation loss: 0.574365496635437
Epoch: 44/300 - Train loss: 0.5713878870010376, Validation loss: 0.5718402862548828
Epoch: 45/300 - Train loss: 0.5687761902809143, Validation loss: 0.5692832469940186
Epoch: 46/300 - Train loss: 0.5662137269973755, Validation loss: 0.5672407746315002
Epoch: 47/300 - Train loss: 0.5637016892433167, Validation loss: 0.5647481083869934
Epoch: 48/300 - Train loss: 0.5612401366233826, Validation loss: 0.5624507665634155
Epoch: 49/300 - Train loss: 0.5588290691375732, Validation loss: 0.5601112842559814
Epoch: 50/300 - Train loss: 0.556469202041626, Validation loss: 0.5579760074615479
Epoch: 51/300 - Train loss: 0.5541606545448303, Validation loss: 0.5556784272193909
Epoch: 52/300 - Train loss: 0.5519028902053833, Validation loss: 0.5540686249732971
Epoch: 53/300 - Train loss: 0.5496964454650879, Validation loss: 0.5515286922454834
Epoch: 54/300 - Train loss: 0.547541081905365, Validation loss: 0.5494787693023682
Epoch: 55/300 - Train loss: 0.545436680316925, Validation loss: 0.5473522543907166
Epoch: 56/300 - Train loss: 0.5433821678161621, Validation loss: 0.5458301901817322
Epoch: 57/300 - Train loss: 0.541376531124115, Validation loss: 0.5433840751647949
Epoch: 58/300 - Train loss: 0.539418637752533, Validation loss: 0.5420355796813965
Epoch: 59/300 - Train loss: 0.5375085473060608, Validation loss: 0.5405387878417969
Epoch: 60/300 - Train loss: 0.5356446504592896, Validation loss: 0.5383530855178833
Epoch: 61/300 - Train loss: 0.5338258743286133, Validation loss: 0.5365419387817383
Epoch: 62/300 - Train loss: 0.5320528745651245, Validation loss: 0.5351641774177551
Epoch: 63/300 - Train loss: 0.530324399471283, Validation loss: 0.5335802435874939
Epoch: 64/300 - Train loss: 0.528639554977417, Validation loss: 0.5317660570144653
Epoch: 65/300 - Train loss: 0.5269986391067505, Validation loss: 0.530472993850708
Epoch: 66/300 - Train loss: 0.5253994464874268, Validation loss: 0.5287376046180725
Epoch: 67/300 - Train loss: 0.5238403081893921, Validation loss: 0.5274224281311035
Epoch: 68/300 - Train loss: 0.5223216414451599, Validation loss: 0.5260773301124573
Epoch: 69/300 - Train loss: 0.5208433866500854, Validation loss: 0.5244706273078918
Epoch: 70/300 - Train loss: 0.5194041728973389, Validation loss: 0.5233702063560486
Epoch: 71/300 - Train loss: 0.5180035829544067, Validation loss: 0.5225974321365356
Epoch: 72/300 - Train loss: 0.5166404843330383, Validation loss: 0.5209581851959229
Epoch: 73/300 - Train loss: 0.5153136253356934, Validation loss: 0.5197520852088928
Epoch: 74/300 - Train loss: 0.5140225887298584, Validation loss: 0.5185908675193787
Epoch: 75/300 - Train loss: 0.5127659440040588, Validation loss: 0.517092764377594
Epoch: 76/300 - Train loss: 0.511542022228241, Validation loss: 0.5158522129058838
Epoch: 77/300 - Train loss: 0.5103496313095093, Validation loss: 0.5155699253082275
Epoch: 78/300 - Train loss: 0.509187638759613, Validation loss: 0.5145085453987122
Epoch: 79/300 - Train loss: 0.5080547332763672, Validation loss: 0.5132858753204346
Epoch: 80/300 - Train loss: 0.5069490671157837, Validation loss: 0.5122798085212708
Epoch: 81/300 - Train loss: 0.5058689713478088, Validation loss: 0.5111701488494873
Epoch: 82/300 - Train loss: 0.5048156380653381, Validation loss: 0.5101080536842346
Epoch: 83/300 - Train loss: 0.5037874579429626, Validation loss: 0.50934237241745
Epoch: 84/300 - Train loss: 0.5027837753295898, Validation loss: 0.5090500116348267
Epoch: 85/300 - Train loss: 0.5018031001091003, Validation loss: 0.5076248645782471
Epoch: 86/300 - Train loss: 0.5008445382118225, Validation loss: 0.507251501083374
Epoch: 87/300 - Train loss: 0.49990782141685486, Validation loss: 0.5060923099517822
Epoch: 88/300 - Train loss: 0.4989912509918213, Validation loss: 0.5049052834510803
Epoch: 89/300 - Train loss: 0.4980945885181427, Validation loss: 0.5039132833480835
Epoch: 90/300 - Train loss: 0.4972171485424042, Validation loss: 0.5033360719680786
Epoch: 91/300 - Train loss: 0.4963582158088684, Validation loss: 0.502181351184845
Epoch: 92/300 - Train loss: 0.495516836643219, Validation loss: 0.5020475387573242
Epoch: 93/300 - Train loss: 0.4946918785572052, Validation loss: 0.5016981363296509
Epoch: 94/300 - Train loss: 0.4938834309577942, Validation loss: 0.5002504587173462
Epoch: 95/300 - Train loss: 0.49309080839157104, Validation loss: 0.49989545345306396
Epoch: 96/300 - Train loss: 0.4923132359981537, Validation loss: 0.4990895092487335
Epoch: 97/300 - Train loss: 0.4915493428707123, Validation loss: 0.4980166256427765
Epoch: 98/300 - Train loss: 0.49079862236976624, Validation loss: 0.498079776763916
Epoch: 99/300 - Train loss: 0.4900605380535126, Validation loss: 0.49673333764076233
Epoch: 100/300 - Train loss: 0.48933467268943787, Validation loss: 0.4965153634548187
Epoch: 101/300 - Train loss: 0.48862025141716003, Validation loss: 0.49587005376815796
Epoch: 102/300 - Train loss: 0.4879169464111328, Validation loss: 0.49521106481552124
Epoch: 103/300 - Train loss: 0.4872247576713562, Validation loss: 0.4938998520374298
Epoch: 104/300 - Train loss: 0.4865421652793884, Validation loss: 0.49335137009620667
Epoch: 105/300 - Train loss: 0.48586905002593994, Validation loss: 0.49270951747894287
Epoch: 106/300 - Train loss: 0.485204815864563, Validation loss: 0.4924372732639313
Epoch: 107/300 - Train loss: 0.4845481812953949, Validation loss: 0.49181869626045227
Epoch: 108/300 - Train loss: 0.48389890789985657, Validation loss: 0.49135130643844604
Epoch: 109/300 - Train loss: 0.4832545816898346, Validation loss: 0.49053651094436646
Epoch: 110/300 - Train loss: 0.4826165735721588, Validation loss: 0.49023327231407166
Epoch: 111/300 - Train loss: 0.48198455572128296, Validation loss: 0.48929551243782043
Epoch: 112/300 - Train loss: 0.48135825991630554, Validation loss: 0.4892127513885498
