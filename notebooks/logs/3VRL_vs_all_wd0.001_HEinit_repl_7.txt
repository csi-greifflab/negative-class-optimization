Epoch: 1/300 - Train loss: 0.6944187879562378, Validation loss: 0.6925067901611328
Epoch: 2/300 - Train loss: 0.6916308403015137, Validation loss: 0.6897720098495483
Epoch: 3/300 - Train loss: 0.6888747811317444, Validation loss: 0.6869933009147644
Epoch: 4/300 - Train loss: 0.6861292123794556, Validation loss: 0.684187650680542
Epoch: 5/300 - Train loss: 0.6833606958389282, Validation loss: 0.6814667582511902
Epoch: 6/300 - Train loss: 0.6805423498153687, Validation loss: 0.6785051226615906
Epoch: 7/300 - Train loss: 0.6776551008224487, Validation loss: 0.675666332244873
Epoch: 8/300 - Train loss: 0.6746758222579956, Validation loss: 0.6724915504455566
Epoch: 9/300 - Train loss: 0.6715856790542603, Validation loss: 0.6693340539932251
Epoch: 10/300 - Train loss: 0.6683729887008667, Validation loss: 0.6659737825393677
Epoch: 11/300 - Train loss: 0.6650292277336121, Validation loss: 0.6625479459762573
Epoch: 12/300 - Train loss: 0.6615470051765442, Validation loss: 0.6591051816940308
Epoch: 13/300 - Train loss: 0.6579187512397766, Validation loss: 0.655332624912262
Epoch: 14/300 - Train loss: 0.6541401743888855, Validation loss: 0.6514323949813843
Epoch: 15/300 - Train loss: 0.6502090096473694, Validation loss: 0.6474823951721191
Epoch: 16/300 - Train loss: 0.646125316619873, Validation loss: 0.6433320045471191
Epoch: 17/300 - Train loss: 0.6418874859809875, Validation loss: 0.6389599442481995
Epoch: 18/300 - Train loss: 0.6374922394752502, Validation loss: 0.6347129940986633
Epoch: 19/300 - Train loss: 0.6329424977302551, Validation loss: 0.6299911141395569
Epoch: 20/300 - Train loss: 0.6282435059547424, Validation loss: 0.6251924633979797
Epoch: 21/300 - Train loss: 0.6234015226364136, Validation loss: 0.6203805208206177
Epoch: 22/300 - Train loss: 0.6184225678443909, Validation loss: 0.6154400706291199
Epoch: 23/300 - Train loss: 0.6133161187171936, Validation loss: 0.6102340817451477
Epoch: 24/300 - Train loss: 0.6080927848815918, Validation loss: 0.6047962307929993
Epoch: 25/300 - Train loss: 0.6027591228485107, Validation loss: 0.5995426177978516
Epoch: 26/300 - Train loss: 0.5973284244537354, Validation loss: 0.59404057264328
Epoch: 27/300 - Train loss: 0.5918059945106506, Validation loss: 0.5886363983154297
Epoch: 28/300 - Train loss: 0.5862044095993042, Validation loss: 0.582931637763977
Epoch: 29/300 - Train loss: 0.5805392265319824, Validation loss: 0.5774487853050232
Epoch: 30/300 - Train loss: 0.5748231410980225, Validation loss: 0.5716792941093445
Epoch: 31/300 - Train loss: 0.5690596699714661, Validation loss: 0.5660533905029297
Epoch: 32/300 - Train loss: 0.5632655620574951, Validation loss: 0.5603374242782593
Epoch: 33/300 - Train loss: 0.5574472546577454, Validation loss: 0.5547603368759155
Epoch: 34/300 - Train loss: 0.5516173839569092, Validation loss: 0.5488351583480835
Epoch: 35/300 - Train loss: 0.5457854270935059, Validation loss: 0.5431072115898132
Epoch: 36/300 - Train loss: 0.5399612784385681, Validation loss: 0.537376344203949
Epoch: 37/300 - Train loss: 0.5341516733169556, Validation loss: 0.5317354798316956
Epoch: 38/300 - Train loss: 0.528366208076477, Validation loss: 0.5261130332946777
Epoch: 39/300 - Train loss: 0.5226135849952698, Validation loss: 0.5205292701721191
Epoch: 40/300 - Train loss: 0.5168970227241516, Validation loss: 0.515300452709198
Epoch: 41/300 - Train loss: 0.5112243294715881, Validation loss: 0.5095625519752502
Epoch: 42/300 - Train loss: 0.5056048631668091, Validation loss: 0.5042215585708618
Epoch: 43/300 - Train loss: 0.5000460147857666, Validation loss: 0.49870604276657104
Epoch: 44/300 - Train loss: 0.4945506453514099, Validation loss: 0.493751585483551
Epoch: 45/300 - Train loss: 0.4891241192817688, Validation loss: 0.4885145127773285
Epoch: 46/300 - Train loss: 0.4837724566459656, Validation loss: 0.48305562138557434
Epoch: 47/300 - Train loss: 0.47849974036216736, Validation loss: 0.4782849848270416
Epoch: 48/300 - Train loss: 0.4733086824417114, Validation loss: 0.4733361601829529
Epoch: 49/300 - Train loss: 0.4682022035121918, Validation loss: 0.4684002101421356
Epoch: 50/300 - Train loss: 0.4631824195384979, Validation loss: 0.46366095542907715
Epoch: 51/300 - Train loss: 0.4582493305206299, Validation loss: 0.4588845372200012
Epoch: 52/300 - Train loss: 0.45340457558631897, Validation loss: 0.4547533690929413
Epoch: 53/300 - Train loss: 0.448651522397995, Validation loss: 0.45019131898880005
Epoch: 54/300 - Train loss: 0.4439890384674072, Validation loss: 0.4452144503593445
Epoch: 55/300 - Train loss: 0.43941548466682434, Validation loss: 0.44091877341270447
Epoch: 56/300 - Train loss: 0.4349314272403717, Validation loss: 0.4363466203212738
Epoch: 57/300 - Train loss: 0.43053749203681946, Validation loss: 0.43211615085601807
Epoch: 58/300 - Train loss: 0.426233172416687, Validation loss: 0.42838090658187866
Epoch: 59/300 - Train loss: 0.42201879620552063, Validation loss: 0.424328088760376
Epoch: 60/300 - Train loss: 0.417893648147583, Validation loss: 0.42057541012763977
Epoch: 61/300 - Train loss: 0.4138573408126831, Validation loss: 0.4168012738227844
Epoch: 62/300 - Train loss: 0.4099089205265045, Validation loss: 0.41276079416275024
Epoch: 63/300 - Train loss: 0.40604618191719055, Validation loss: 0.4097066819667816
Epoch: 64/300 - Train loss: 0.4022675156593323, Validation loss: 0.40562593936920166
Epoch: 65/300 - Train loss: 0.3985716700553894, Validation loss: 0.4018598794937134
Epoch: 66/300 - Train loss: 0.3949574828147888, Validation loss: 0.39850330352783203
Epoch: 67/300 - Train loss: 0.39142388105392456, Validation loss: 0.3952500820159912
Epoch: 68/300 - Train loss: 0.3879696726799011, Validation loss: 0.3916553556919098
Epoch: 69/300 - Train loss: 0.38459348678588867, Validation loss: 0.38905033469200134
Epoch: 70/300 - Train loss: 0.381293386220932, Validation loss: 0.3856254518032074
Epoch: 71/300 - Train loss: 0.37806737422943115, Validation loss: 0.38254329562187195
Epoch: 72/300 - Train loss: 0.3749135434627533, Validation loss: 0.37891459465026855
Epoch: 73/300 - Train loss: 0.37183037400245667, Validation loss: 0.37703341245651245
Epoch: 74/300 - Train loss: 0.3688161373138428, Validation loss: 0.3737211227416992
Epoch: 75/300 - Train loss: 0.36586830019950867, Validation loss: 0.37083059549331665
Epoch: 76/300 - Train loss: 0.3629854619503021, Validation loss: 0.3688528835773468
Epoch: 77/300 - Train loss: 0.36016660928726196, Validation loss: 0.36597853899002075
Epoch: 78/300 - Train loss: 0.35740992426872253, Validation loss: 0.36291325092315674
Epoch: 79/300 - Train loss: 0.3547133505344391, Validation loss: 0.3600698709487915
Epoch: 80/300 - Train loss: 0.3520755171775818, Validation loss: 0.35724085569381714
Epoch: 81/300 - Train loss: 0.34949493408203125, Validation loss: 0.35550639033317566
Epoch: 82/300 - Train loss: 0.34696972370147705, Validation loss: 0.3530031144618988
Epoch: 83/300 - Train loss: 0.3444991111755371, Validation loss: 0.3508005142211914
Epoch: 84/300 - Train loss: 0.34208133816719055, Validation loss: 0.3480949103832245
Epoch: 85/300 - Train loss: 0.33971476554870605, Validation loss: 0.34580275416374207
Epoch: 86/300 - Train loss: 0.3373982906341553, Validation loss: 0.3433181047439575
Epoch: 87/300 - Train loss: 0.3351306617259979, Validation loss: 0.34145528078079224
Epoch: 88/300 - Train loss: 0.3329106569290161, Validation loss: 0.33996856212615967
Epoch: 89/300 - Train loss: 0.3307371139526367, Validation loss: 0.3374180197715759
Epoch: 90/300 - Train loss: 0.32860928773880005, Validation loss: 0.33496132493019104
Epoch: 91/300 - Train loss: 0.3265259563922882, Validation loss: 0.3328000605106354
Epoch: 92/300 - Train loss: 0.32448598742485046, Validation loss: 0.33112847805023193
Epoch: 93/300 - Train loss: 0.3224872350692749, Validation loss: 0.3297107219696045
Epoch: 94/300 - Train loss: 0.3205282688140869, Validation loss: 0.32731157541275024
Epoch: 95/300 - Train loss: 0.31860825419425964, Validation loss: 0.3251452147960663
Epoch: 96/300 - Train loss: 0.3167263865470886, Validation loss: 0.32367247343063354
Epoch: 97/300 - Train loss: 0.31488168239593506, Validation loss: 0.3217855393886566
Epoch: 98/300 - Train loss: 0.3130727708339691, Validation loss: 0.3198922276496887
Epoch: 99/300 - Train loss: 0.3112986385822296, Validation loss: 0.31803059577941895
Epoch: 100/300 - Train loss: 0.3095583915710449, Validation loss: 0.3173828423023224
Epoch: 101/300 - Train loss: 0.3078511953353882, Validation loss: 0.3149625360965729
Epoch: 102/300 - Train loss: 0.3061763048171997, Validation loss: 0.31338489055633545
Epoch: 103/300 - Train loss: 0.3045327365398407, Validation loss: 0.3126717507839203
Epoch: 104/300 - Train loss: 0.30291953682899475, Validation loss: 0.31043463945388794
Epoch: 105/300 - Train loss: 0.3013361692428589, Validation loss: 0.3087049722671509
Epoch: 106/300 - Train loss: 0.2997818887233734, Validation loss: 0.306980162858963
Epoch: 107/300 - Train loss: 0.29825547337532043, Validation loss: 0.30583447217941284
Epoch: 108/300 - Train loss: 0.29675641655921936, Validation loss: 0.30472734570503235
Epoch: 109/300 - Train loss: 0.29528364539146423, Validation loss: 0.30330997705459595
Epoch: 110/300 - Train loss: 0.2938368618488312, Validation loss: 0.30094113945961
Epoch: 111/300 - Train loss: 0.2924156188964844, Validation loss: 0.30020833015441895
Epoch: 112/300 - Train loss: 0.29101884365081787, Validation loss: 0.29910606145858765
Epoch: 113/300 - Train loss: 0.28964608907699585, Validation loss: 0.2970353960990906
Epoch: 114/300 - Train loss: 0.288296639919281, Validation loss: 0.296072781085968
Epoch: 115/300 - Train loss: 0.286970317363739, Validation loss: 0.29519954323768616
Epoch: 116/300 - Train loss: 0.28566643595695496, Validation loss: 0.29362061619758606
Epoch: 117/300 - Train loss: 0.2843841314315796, Validation loss: 0.2927572429180145
Epoch: 118/300 - Train loss: 0.2831226587295532, Validation loss: 0.2912169098854065
Epoch: 119/300 - Train loss: 0.28188177943229675, Validation loss: 0.2900462746620178
Epoch: 120/300 - Train loss: 0.2806609869003296, Validation loss: 0.28859198093414307
Epoch: 121/300 - Train loss: 0.2794595956802368, Validation loss: 0.2878885567188263
Epoch: 122/300 - Train loss: 0.27827730774879456, Validation loss: 0.2862527370452881
Epoch: 123/300 - Train loss: 0.2771138846874237, Validation loss: 0.285617470741272
Epoch: 124/300 - Train loss: 0.2759687900543213, Validation loss: 0.2839869260787964
Epoch: 125/300 - Train loss: 0.27484166622161865, Validation loss: 0.2831798493862152
Epoch: 126/300 - Train loss: 0.27373218536376953, Validation loss: 0.2817924916744232
Epoch: 127/300 - Train loss: 0.2726399600505829, Validation loss: 0.28119996190071106
Epoch: 128/300 - Train loss: 0.27156466245651245, Validation loss: 0.28014081716537476
Epoch: 129/300 - Train loss: 0.2705058455467224, Validation loss: 0.2789286971092224
Epoch: 130/300 - Train loss: 0.2694629430770874, Validation loss: 0.27800580859184265
Epoch: 131/300 - Train loss: 0.26843592524528503, Validation loss: 0.2770310342311859
Epoch: 132/300 - Train loss: 0.2674242854118347, Validation loss: 0.2754724621772766
Epoch: 133/300 - Train loss: 0.2664277255535126, Validation loss: 0.27463868260383606
Epoch: 134/300 - Train loss: 0.2654459774494171, Validation loss: 0.2743156850337982
Epoch: 135/300 - Train loss: 0.264478862285614, Validation loss: 0.27331987023353577
Epoch: 136/300 - Train loss: 0.2635260820388794, Validation loss: 0.27206480503082275
Epoch: 137/300 - Train loss: 0.26258736848831177, Validation loss: 0.271001398563385
Epoch: 138/300 - Train loss: 0.2616623342037201, Validation loss: 0.2702353894710541
Epoch: 139/300 - Train loss: 0.26075080037117004, Validation loss: 0.2696322798728943
Epoch: 140/300 - Train loss: 0.25985243916511536, Validation loss: 0.26863858103752136
Epoch: 141/300 - Train loss: 0.2589670717716217, Validation loss: 0.2682354152202606
Epoch: 142/300 - Train loss: 0.25809434056282043, Validation loss: 0.26700979471206665
Epoch: 143/300 - Train loss: 0.2572340965270996, Validation loss: 0.2657746970653534
Epoch: 144/300 - Train loss: 0.25638601183891296, Validation loss: 0.26477643847465515
Epoch: 145/300 - Train loss: 0.255549818277359, Validation loss: 0.26405104994773865
Epoch: 146/300 - Train loss: 0.2547249495983124, Validation loss: 0.2639619708061218
Epoch: 147/300 - Train loss: 0.25391140580177307, Validation loss: 0.26282840967178345
Epoch: 148/300 - Train loss: 0.2531091570854187, Validation loss: 0.26183566451072693
Epoch: 149/300 - Train loss: 0.2523179352283478, Validation loss: 0.26081228256225586
Epoch: 150/300 - Train loss: 0.25153765082359314, Validation loss: 0.2608048915863037
Epoch: 151/300 - Train loss: 0.25076815485954285, Validation loss: 0.260008305311203
Epoch: 152/300 - Train loss: 0.25000932812690735, Validation loss: 0.258980929851532
Epoch: 153/300 - Train loss: 0.2492610067129135, Validation loss: 0.25819605588912964
Epoch: 154/300 - Train loss: 0.24852287769317627, Validation loss: 0.2571633458137512
Epoch: 155/300 - Train loss: 0.2477947324514389, Validation loss: 0.25640061497688293
Epoch: 156/300 - Train loss: 0.24707643687725067, Validation loss: 0.25663313269615173
Epoch: 157/300 - Train loss: 0.2463676780462265, Validation loss: 0.25556299090385437
Epoch: 158/300 - Train loss: 0.24566838145256042, Validation loss: 0.25492098927497864
Epoch: 159/300 - Train loss: 0.24497844278812408, Validation loss: 0.2543814778327942
Epoch: 160/300 - Train loss: 0.24429765343666077, Validation loss: 0.2537982761859894
Epoch: 161/300 - Train loss: 0.24362589418888092, Validation loss: 0.25233182311058044
Epoch: 162/300 - Train loss: 0.24296298623085022, Validation loss: 0.25234487652778625
Epoch: 163/300 - Train loss: 0.24230872094631195, Validation loss: 0.2510269582271576
Epoch: 164/300 - Train loss: 0.24166294932365417, Validation loss: 0.25130516290664673
Epoch: 165/300 - Train loss: 0.24102555215358734, Validation loss: 0.2498406618833542
Epoch: 166/300 - Train loss: 0.2403963953256607, Validation loss: 0.2494383603334427
Epoch: 167/300 - Train loss: 0.2397753894329071, Validation loss: 0.24901215732097626
Epoch: 168/300 - Train loss: 0.2391623705625534, Validation loss: 0.24818533658981323
Epoch: 169/300 - Train loss: 0.23855723440647125, Validation loss: 0.24733610451221466
Epoch: 170/300 - Train loss: 0.23795990645885468, Validation loss: 0.24703387916088104
Epoch: 171/300 - Train loss: 0.23737017810344696, Validation loss: 0.24643339216709137
Epoch: 172/300 - Train loss: 0.2367878556251526, Validation loss: 0.24543771147727966
Epoch: 173/300 - Train loss: 0.23621279001235962, Validation loss: 0.24519787728786469
Epoch: 174/300 - Train loss: 0.2356448620557785, Validation loss: 0.24431315064430237
Epoch: 175/300 - Train loss: 0.23508386313915253, Validation loss: 0.24376335740089417
Epoch: 176/300 - Train loss: 0.2345297783613205, Validation loss: 0.24370600283145905
Epoch: 177/300 - Train loss: 0.23398256301879883, Validation loss: 0.2434023767709732
