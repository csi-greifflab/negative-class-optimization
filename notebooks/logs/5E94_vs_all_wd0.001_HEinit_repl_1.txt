Epoch: 1/300 - Train loss: 0.6987565755844116, Validation loss: 0.6959343552589417
Epoch: 2/300 - Train loss: 0.6966710090637207, Validation loss: 0.693975031375885
Epoch: 3/300 - Train loss: 0.6946560144424438, Validation loss: 0.6921132206916809
Epoch: 4/300 - Train loss: 0.6927031874656677, Validation loss: 0.6904765367507935
Epoch: 5/300 - Train loss: 0.6908116340637207, Validation loss: 0.688411295413971
Epoch: 6/300 - Train loss: 0.6889665126800537, Validation loss: 0.6867789030075073
Epoch: 7/300 - Train loss: 0.6871557235717773, Validation loss: 0.6850761771202087
Epoch: 8/300 - Train loss: 0.6853655576705933, Validation loss: 0.6834040284156799
Epoch: 9/300 - Train loss: 0.6835823655128479, Validation loss: 0.6816193461418152
Epoch: 10/300 - Train loss: 0.6817917823791504, Validation loss: 0.6798509359359741
Epoch: 11/300 - Train loss: 0.6799850463867188, Validation loss: 0.6782360076904297
Epoch: 12/300 - Train loss: 0.6781530380249023, Validation loss: 0.6762731075286865
Epoch: 13/300 - Train loss: 0.676281213760376, Validation loss: 0.6745817065238953
Epoch: 14/300 - Train loss: 0.6743584871292114, Validation loss: 0.6726852655410767
Epoch: 15/300 - Train loss: 0.6723785996437073, Validation loss: 0.6709108948707581
Epoch: 16/300 - Train loss: 0.6703334450721741, Validation loss: 0.6687604188919067
Epoch: 17/300 - Train loss: 0.668213427066803, Validation loss: 0.6666820049285889
Epoch: 18/300 - Train loss: 0.6660099029541016, Validation loss: 0.6645020842552185
Epoch: 19/300 - Train loss: 0.6637211441993713, Validation loss: 0.6621381640434265
Epoch: 20/300 - Train loss: 0.6613385081291199, Validation loss: 0.659735381603241
Epoch: 21/300 - Train loss: 0.6588568687438965, Validation loss: 0.6570771336555481
Epoch: 22/300 - Train loss: 0.6562718749046326, Validation loss: 0.6546555757522583
Epoch: 23/300 - Train loss: 0.6535837650299072, Validation loss: 0.6521028876304626
Epoch: 24/300 - Train loss: 0.6507952213287354, Validation loss: 0.6491722464561462
Epoch: 25/300 - Train loss: 0.647905170917511, Validation loss: 0.6461324095726013
Epoch: 26/300 - Train loss: 0.6449142694473267, Validation loss: 0.6434190273284912
Epoch: 27/300 - Train loss: 0.64182049036026, Validation loss: 0.6399877071380615
Epoch: 28/300 - Train loss: 0.6386289000511169, Validation loss: 0.6368259787559509
Epoch: 29/300 - Train loss: 0.6353442668914795, Validation loss: 0.6336278319358826
Epoch: 30/300 - Train loss: 0.6319714784622192, Validation loss: 0.6303080916404724
Epoch: 31/300 - Train loss: 0.6285131573677063, Validation loss: 0.626605212688446
Epoch: 32/300 - Train loss: 0.6249729990959167, Validation loss: 0.6231111884117126
Epoch: 33/300 - Train loss: 0.6213620901107788, Validation loss: 0.6196428537368774
Epoch: 34/300 - Train loss: 0.6176865696907043, Validation loss: 0.6159225702285767
Epoch: 35/300 - Train loss: 0.6139543056488037, Validation loss: 0.6126037836074829
Epoch: 36/300 - Train loss: 0.6101728677749634, Validation loss: 0.6086553931236267
Epoch: 37/300 - Train loss: 0.606348991394043, Validation loss: 0.604636549949646
Epoch: 38/300 - Train loss: 0.6024934649467468, Validation loss: 0.6009857058525085
Epoch: 39/300 - Train loss: 0.5986199975013733, Validation loss: 0.5970609188079834
Epoch: 40/300 - Train loss: 0.594735324382782, Validation loss: 0.593275249004364
Epoch: 41/300 - Train loss: 0.5908496975898743, Validation loss: 0.588923454284668
Epoch: 42/300 - Train loss: 0.586967945098877, Validation loss: 0.5854061841964722
Epoch: 43/300 - Train loss: 0.5830963850021362, Validation loss: 0.5813685655593872
Epoch: 44/300 - Train loss: 0.5792408585548401, Validation loss: 0.5774953365325928
Epoch: 45/300 - Train loss: 0.5754086971282959, Validation loss: 0.5733566284179688
Epoch: 46/300 - Train loss: 0.5716053247451782, Validation loss: 0.5701119899749756
Epoch: 47/300 - Train loss: 0.5678361058235168, Validation loss: 0.5659894347190857
Epoch: 48/300 - Train loss: 0.564104437828064, Validation loss: 0.5629473924636841
Epoch: 49/300 - Train loss: 0.5604162216186523, Validation loss: 0.5584970712661743
Epoch: 50/300 - Train loss: 0.5567750930786133, Validation loss: 0.5548207759857178
Epoch: 51/300 - Train loss: 0.5531878471374512, Validation loss: 0.5516661405563354
Epoch: 52/300 - Train loss: 0.5496534109115601, Validation loss: 0.5481021404266357
Epoch: 53/300 - Train loss: 0.5461730360984802, Validation loss: 0.544951319694519
Epoch: 54/300 - Train loss: 0.5427477955818176, Validation loss: 0.5403991937637329
Epoch: 55/300 - Train loss: 0.5393811464309692, Validation loss: 0.5372903943061829
Epoch: 56/300 - Train loss: 0.5360730886459351, Validation loss: 0.5345782041549683
Epoch: 57/300 - Train loss: 0.5328230857849121, Validation loss: 0.5311453938484192
Epoch: 58/300 - Train loss: 0.5296317338943481, Validation loss: 0.5285336375236511
Epoch: 59/300 - Train loss: 0.5264996290206909, Validation loss: 0.5245144367218018
Epoch: 60/300 - Train loss: 0.5234256982803345, Validation loss: 0.5219833850860596
Epoch: 61/300 - Train loss: 0.5204112529754639, Validation loss: 0.5195807814598083
Epoch: 62/300 - Train loss: 0.5174551606178284, Validation loss: 0.5157641172409058
Epoch: 63/300 - Train loss: 0.5145549774169922, Validation loss: 0.5128990411758423
Epoch: 64/300 - Train loss: 0.5117099285125732, Validation loss: 0.5096136927604675
Epoch: 65/300 - Train loss: 0.5089206099510193, Validation loss: 0.5070131421089172
Epoch: 66/300 - Train loss: 0.5061866044998169, Validation loss: 0.5041429996490479
Epoch: 67/300 - Train loss: 0.5035066604614258, Validation loss: 0.5014871954917908
Epoch: 68/300 - Train loss: 0.500878632068634, Validation loss: 0.49966195225715637
Epoch: 69/300 - Train loss: 0.4983014464378357, Validation loss: 0.49621185660362244
Epoch: 70/300 - Train loss: 0.49577459692955017, Validation loss: 0.4938274025917053
Epoch: 71/300 - Train loss: 0.4932974874973297, Validation loss: 0.4921170473098755
Epoch: 72/300 - Train loss: 0.49086877703666687, Validation loss: 0.48880380392074585
Epoch: 73/300 - Train loss: 0.48848801851272583, Validation loss: 0.4866703450679779
Epoch: 74/300 - Train loss: 0.48615288734436035, Validation loss: 0.48458313941955566
Epoch: 75/300 - Train loss: 0.4838623106479645, Validation loss: 0.48220497369766235
Epoch: 76/300 - Train loss: 0.4816153347492218, Validation loss: 0.4795674979686737
Epoch: 77/300 - Train loss: 0.4794110953807831, Validation loss: 0.47709670662879944
Epoch: 78/300 - Train loss: 0.4772491753101349, Validation loss: 0.4751378297805786
Epoch: 79/300 - Train loss: 0.4751279354095459, Validation loss: 0.47338464856147766
Epoch: 80/300 - Train loss: 0.4730463922023773, Validation loss: 0.47131237387657166
Epoch: 81/300 - Train loss: 0.4710044264793396, Validation loss: 0.4692392647266388
Epoch: 82/300 - Train loss: 0.46900078654289246, Validation loss: 0.4669618010520935
Epoch: 83/300 - Train loss: 0.4670346975326538, Validation loss: 0.4652988612651825
Epoch: 84/300 - Train loss: 0.4651058316230774, Validation loss: 0.46408557891845703
Epoch: 85/300 - Train loss: 0.463213711977005, Validation loss: 0.4613194465637207
Epoch: 86/300 - Train loss: 0.46135738492012024, Validation loss: 0.4597387909889221
Epoch: 87/300 - Train loss: 0.45953652262687683, Validation loss: 0.45811623334884644
Epoch: 88/300 - Train loss: 0.45775043964385986, Validation loss: 0.4566745460033417
Epoch: 89/300 - Train loss: 0.4559980034828186, Validation loss: 0.45432960987091064
Epoch: 90/300 - Train loss: 0.45427870750427246, Validation loss: 0.45249396562576294
Epoch: 91/300 - Train loss: 0.4525924026966095, Validation loss: 0.4514983594417572
Epoch: 92/300 - Train loss: 0.450937956571579, Validation loss: 0.4499788284301758
Epoch: 93/300 - Train loss: 0.4493156373500824, Validation loss: 0.44856691360473633
Epoch: 94/300 - Train loss: 0.44772404432296753, Validation loss: 0.4461418092250824
Epoch: 95/300 - Train loss: 0.44616246223449707, Validation loss: 0.44412779808044434
Epoch: 96/300 - Train loss: 0.44463038444519043, Validation loss: 0.44240453839302063
Epoch: 97/300 - Train loss: 0.44312721490859985, Validation loss: 0.4417318105697632
Epoch: 98/300 - Train loss: 0.44165265560150146, Validation loss: 0.44086116552352905
Epoch: 99/300 - Train loss: 0.4402064383029938, Validation loss: 0.4389359951019287
Epoch: 100/300 - Train loss: 0.4387878477573395, Validation loss: 0.43685391545295715
Epoch: 101/300 - Train loss: 0.43739625811576843, Validation loss: 0.435791939496994
Epoch: 102/300 - Train loss: 0.43603047728538513, Validation loss: 0.43455204367637634
Epoch: 103/300 - Train loss: 0.4346904158592224, Validation loss: 0.4331693947315216
Epoch: 104/300 - Train loss: 0.4333745539188385, Validation loss: 0.4322374761104584
Epoch: 105/300 - Train loss: 0.4320826232433319, Validation loss: 0.43081167340278625
Epoch: 106/300 - Train loss: 0.4308144450187683, Validation loss: 0.4298103451728821
Epoch: 107/300 - Train loss: 0.42956921458244324, Validation loss: 0.4276253879070282
Epoch: 108/300 - Train loss: 0.4283466935157776, Validation loss: 0.42632490396499634
Epoch: 109/300 - Train loss: 0.4271465241909027, Validation loss: 0.4258596897125244
Epoch: 110/300 - Train loss: 0.4259680509567261, Validation loss: 0.4241117835044861
Epoch: 111/300 - Train loss: 0.4248106777667999, Validation loss: 0.42462167143821716
Epoch: 112/300 - Train loss: 0.42367425560951233, Validation loss: 0.4226151704788208
Epoch: 113/300 - Train loss: 0.42255815863609314, Validation loss: 0.42248424887657166
Epoch: 114/300 - Train loss: 0.4214618504047394, Validation loss: 0.41960394382476807
Epoch: 115/300 - Train loss: 0.42038458585739136, Validation loss: 0.419271856546402
Epoch: 116/300 - Train loss: 0.41932618618011475, Validation loss: 0.41768696904182434
Epoch: 117/300 - Train loss: 0.4182860553264618, Validation loss: 0.4168143570423126
Epoch: 118/300 - Train loss: 0.4172637462615967, Validation loss: 0.41537928581237793
Epoch: 119/300 - Train loss: 0.41625887155532837, Validation loss: 0.4151388704776764
Epoch: 120/300 - Train loss: 0.41527119278907776, Validation loss: 0.41394972801208496
Epoch: 121/300 - Train loss: 0.4143000841140747, Validation loss: 0.41289088129997253
Epoch: 122/300 - Train loss: 0.4133453965187073, Validation loss: 0.41272294521331787
Epoch: 123/300 - Train loss: 0.41240671277046204, Validation loss: 0.41133809089660645
Epoch: 124/300 - Train loss: 0.41148361563682556, Validation loss: 0.40938514471054077
Epoch: 125/300 - Train loss: 0.4105755388736725, Validation loss: 0.4084424376487732
Epoch: 126/300 - Train loss: 0.4096817076206207, Validation loss: 0.4079381227493286
Epoch: 127/300 - Train loss: 0.4088021218776703, Validation loss: 0.40846535563468933
Epoch: 128/300 - Train loss: 0.4079367220401764, Validation loss: 0.40540221333503723
Epoch: 129/300 - Train loss: 0.4070851504802704, Validation loss: 0.4049711227416992
Epoch: 130/300 - Train loss: 0.40624773502349854, Validation loss: 0.4043132960796356
Epoch: 131/300 - Train loss: 0.4054237902164459, Validation loss: 0.4035896956920624
Epoch: 132/300 - Train loss: 0.4046129584312439, Validation loss: 0.4032479226589203
Epoch: 133/300 - Train loss: 0.4038149118423462, Validation loss: 0.40240558981895447
Epoch: 134/300 - Train loss: 0.4030293822288513, Validation loss: 0.4015433192253113
Epoch: 135/300 - Train loss: 0.40225645899772644, Validation loss: 0.39964917302131653
Epoch: 136/300 - Train loss: 0.4014959931373596, Validation loss: 0.4011232256889343
Epoch: 137/300 - Train loss: 0.4007476568222046, Validation loss: 0.39913704991340637
Epoch: 138/300 - Train loss: 0.40001145005226135, Validation loss: 0.39935827255249023
Epoch: 139/300 - Train loss: 0.3992871642112732, Validation loss: 0.39824649691581726
Epoch: 140/300 - Train loss: 0.39857426285743713, Validation loss: 0.39689865708351135
Epoch: 141/300 - Train loss: 0.3978724777698517, Validation loss: 0.39744582772254944
Epoch: 142/300 - Train loss: 0.3971814513206482, Validation loss: 0.3951757848262787
Epoch: 143/300 - Train loss: 0.3965011537075043, Validation loss: 0.39519748091697693
Epoch: 144/300 - Train loss: 0.3958313763141632, Validation loss: 0.39417603611946106
Epoch: 145/300 - Train loss: 0.39517122507095337, Validation loss: 0.39419594407081604
Epoch: 146/300 - Train loss: 0.39452069997787476, Validation loss: 0.39353758096694946
Epoch: 147/300 - Train loss: 0.39388009905815125, Validation loss: 0.3920498490333557
Epoch: 148/300 - Train loss: 0.39324888586997986, Validation loss: 0.3916824162006378
Epoch: 149/300 - Train loss: 0.3926267623901367, Validation loss: 0.3908481001853943
Epoch: 150/300 - Train loss: 0.3920137882232666, Validation loss: 0.3906017243862152
Epoch: 151/300 - Train loss: 0.39140939712524414, Validation loss: 0.38975560665130615
Epoch: 152/300 - Train loss: 0.3908137381076813, Validation loss: 0.3892870247364044
Epoch: 153/300 - Train loss: 0.39022666215896606, Validation loss: 0.3888518512248993
Epoch: 154/300 - Train loss: 0.38964760303497314, Validation loss: 0.3890964984893799
Epoch: 155/300 - Train loss: 0.3890765309333801, Validation loss: 0.38821882009506226
Epoch: 156/300 - Train loss: 0.38851335644721985, Validation loss: 0.3879315257072449
