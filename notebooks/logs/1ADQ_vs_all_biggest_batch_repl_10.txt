Epoch: 1/100 - Train loss: 0.7015655636787415, Validation loss: 0.7008928060531616
Epoch: 2/100 - Train loss: 0.6996508836746216, Validation loss: 0.6990774869918823
Epoch: 3/100 - Train loss: 0.6978716850280762, Validation loss: 0.6974299550056458
Epoch: 4/100 - Train loss: 0.6961912512779236, Validation loss: 0.69577956199646
Epoch: 5/100 - Train loss: 0.6945638060569763, Validation loss: 0.6941514611244202
Epoch: 6/100 - Train loss: 0.6929417848587036, Validation loss: 0.6923646330833435
Epoch: 7/100 - Train loss: 0.6912866830825806, Validation loss: 0.6906852126121521
Epoch: 8/100 - Train loss: 0.6895650625228882, Validation loss: 0.6887943148612976
Epoch: 9/100 - Train loss: 0.6877493262290955, Validation loss: 0.6869273781776428
Epoch: 10/100 - Train loss: 0.6858208179473877, Validation loss: 0.6848976612091064
Epoch: 11/100 - Train loss: 0.6837771534919739, Validation loss: 0.6826839447021484
Epoch: 12/100 - Train loss: 0.681621253490448, Validation loss: 0.6805824637413025
Epoch: 13/100 - Train loss: 0.6793491244316101, Validation loss: 0.6782912015914917
Epoch: 14/100 - Train loss: 0.6769686937332153, Validation loss: 0.6757929921150208
Epoch: 15/100 - Train loss: 0.6744924187660217, Validation loss: 0.6732792258262634
Epoch: 16/100 - Train loss: 0.6719232797622681, Validation loss: 0.6707139611244202
Epoch: 17/100 - Train loss: 0.6692781448364258, Validation loss: 0.668017566204071
Epoch: 18/100 - Train loss: 0.6665706038475037, Validation loss: 0.665486752986908
Epoch: 19/100 - Train loss: 0.6638113260269165, Validation loss: 0.6625853180885315
Epoch: 20/100 - Train loss: 0.6610069274902344, Validation loss: 0.6599023342132568
Epoch: 21/100 - Train loss: 0.6581665277481079, Validation loss: 0.6571819186210632
Epoch: 22/100 - Train loss: 0.6552975177764893, Validation loss: 0.6545849442481995
Epoch: 23/100 - Train loss: 0.6524053812026978, Validation loss: 0.6516712307929993
Epoch: 24/100 - Train loss: 0.6494934558868408, Validation loss: 0.648801326751709
Epoch: 25/100 - Train loss: 0.6465631127357483, Validation loss: 0.6459762454032898
Epoch: 26/100 - Train loss: 0.6436122059822083, Validation loss: 0.6432033181190491
Epoch: 27/100 - Train loss: 0.6406422257423401, Validation loss: 0.6402990818023682
Epoch: 28/100 - Train loss: 0.6376571655273438, Validation loss: 0.6374350786209106
Epoch: 29/100 - Train loss: 0.6346554756164551, Validation loss: 0.6346079111099243
Epoch: 30/100 - Train loss: 0.6316388845443726, Validation loss: 0.6315470933914185
Epoch: 31/100 - Train loss: 0.6286100149154663, Validation loss: 0.6284943222999573
Epoch: 32/100 - Train loss: 0.6255706548690796, Validation loss: 0.6257913708686829
Epoch: 33/100 - Train loss: 0.6225255131721497, Validation loss: 0.6227577924728394
Epoch: 34/100 - Train loss: 0.6194794178009033, Validation loss: 0.6197640299797058
Epoch: 35/100 - Train loss: 0.6164353489875793, Validation loss: 0.6166618466377258
Epoch: 36/100 - Train loss: 0.6133967041969299, Validation loss: 0.6136426329612732
Epoch: 37/100 - Train loss: 0.6103670597076416, Validation loss: 0.6108413934707642
Epoch: 38/100 - Train loss: 0.6073499917984009, Validation loss: 0.6078945994377136
Epoch: 39/100 - Train loss: 0.6043462753295898, Validation loss: 0.6054139137268066
Epoch: 40/100 - Train loss: 0.6013591885566711, Validation loss: 0.6024249196052551
Epoch: 41/100 - Train loss: 0.5983913540840149, Validation loss: 0.5993458032608032
Epoch: 42/100 - Train loss: 0.5954451560974121, Validation loss: 0.5966752767562866
Epoch: 43/100 - Train loss: 0.5925220251083374, Validation loss: 0.5937128663063049
Epoch: 44/100 - Train loss: 0.5896238088607788, Validation loss: 0.5906571745872498
Epoch: 45/100 - Train loss: 0.5867524743080139, Validation loss: 0.5883443355560303
Epoch: 46/100 - Train loss: 0.583911120891571, Validation loss: 0.585574746131897
Epoch: 47/100 - Train loss: 0.581100344657898, Validation loss: 0.5829061269760132
Epoch: 48/100 - Train loss: 0.5783216953277588, Validation loss: 0.5802225470542908
Epoch: 49/100 - Train loss: 0.5755783319473267, Validation loss: 0.5775745511054993
Epoch: 50/100 - Train loss: 0.5728711485862732, Validation loss: 0.5746831297874451
Epoch: 51/100 - Train loss: 0.5702017545700073, Validation loss: 0.5722658634185791
Epoch: 52/100 - Train loss: 0.5675722360610962, Validation loss: 0.5701510310173035
Epoch: 53/100 - Train loss: 0.5649821758270264, Validation loss: 0.5674313902854919
Epoch: 54/100 - Train loss: 0.5624330043792725, Validation loss: 0.5648341774940491
Epoch: 55/100 - Train loss: 0.5599263906478882, Validation loss: 0.5627094507217407
Epoch: 56/100 - Train loss: 0.5574623942375183, Validation loss: 0.5601520538330078
Epoch: 57/100 - Train loss: 0.5550414323806763, Validation loss: 0.5579928755760193
Epoch: 58/100 - Train loss: 0.5526653528213501, Validation loss: 0.5559996366500854
Epoch: 59/100 - Train loss: 0.5503333210945129, Validation loss: 0.5535280108451843
Epoch: 60/100 - Train loss: 0.5480471849441528, Validation loss: 0.5513235926628113
Epoch: 61/100 - Train loss: 0.5458071231842041, Validation loss: 0.5496994853019714
Epoch: 62/100 - Train loss: 0.5436130166053772, Validation loss: 0.5473456978797913
Epoch: 63/100 - Train loss: 0.5414646863937378, Validation loss: 0.5455139875411987
Epoch: 64/100 - Train loss: 0.5393628478050232, Validation loss: 0.543062686920166
Epoch: 65/100 - Train loss: 0.5373067855834961, Validation loss: 0.541455090045929
Epoch: 66/100 - Train loss: 0.5352969169616699, Validation loss: 0.5398287773132324
Epoch: 67/100 - Train loss: 0.5333325266838074, Validation loss: 0.5374712347984314
Epoch: 68/100 - Train loss: 0.5314134955406189, Validation loss: 0.5359982848167419
Epoch: 69/100 - Train loss: 0.5295389294624329, Validation loss: 0.5338185429573059
Epoch: 70/100 - Train loss: 0.5277079939842224, Validation loss: 0.5327321887016296
Epoch: 71/100 - Train loss: 0.525920033454895, Validation loss: 0.5304617285728455
Epoch: 72/100 - Train loss: 0.5241748094558716, Validation loss: 0.5296070575714111
Epoch: 73/100 - Train loss: 0.5224712491035461, Validation loss: 0.5274907350540161
Epoch: 74/100 - Train loss: 0.5208081603050232, Validation loss: 0.526287853717804
Epoch: 75/100 - Train loss: 0.5191845297813416, Validation loss: 0.5244544148445129
Epoch: 76/100 - Train loss: 0.5176005363464355, Validation loss: 0.5227465033531189
Epoch: 77/100 - Train loss: 0.5160549879074097, Validation loss: 0.5217169523239136
Epoch: 78/100 - Train loss: 0.5145464539527893, Validation loss: 0.5202058553695679
Epoch: 79/100 - Train loss: 0.5130741596221924, Validation loss: 0.518687903881073
Epoch: 80/100 - Train loss: 0.5116363763809204, Validation loss: 0.5180181860923767
Epoch: 81/100 - Train loss: 0.5102336406707764, Validation loss: 0.5159479975700378
Epoch: 82/100 - Train loss: 0.5088646411895752, Validation loss: 0.5145643353462219
Epoch: 83/100 - Train loss: 0.5075271725654602, Validation loss: 0.5135673880577087
Epoch: 84/100 - Train loss: 0.5062204599380493, Validation loss: 0.5131239295005798
Epoch: 85/100 - Train loss: 0.5049427151679993, Validation loss: 0.5110470652580261
Epoch: 86/100 - Train loss: 0.5036919116973877, Validation loss: 0.5097255110740662
Epoch: 87/100 - Train loss: 0.5024683475494385, Validation loss: 0.5096226930618286
Epoch: 88/100 - Train loss: 0.5012689828872681, Validation loss: 0.5084865689277649
Epoch: 89/100 - Train loss: 0.5000931620597839, Validation loss: 0.506869375705719
Epoch: 90/100 - Train loss: 0.49894070625305176, Validation loss: 0.506030797958374
Epoch: 91/100 - Train loss: 0.49781113862991333, Validation loss: 0.5050491094589233
Epoch: 92/100 - Train loss: 0.49670299887657166, Validation loss: 0.5044513940811157
Epoch: 93/100 - Train loss: 0.4956153333187103, Validation loss: 0.5035275220870972
Epoch: 94/100 - Train loss: 0.4945467710494995, Validation loss: 0.502320408821106
Epoch: 95/100 - Train loss: 0.49349483847618103, Validation loss: 0.5008580684661865
Epoch: 96/100 - Train loss: 0.49245965480804443, Validation loss: 0.4996293783187866
Epoch: 97/100 - Train loss: 0.49143967032432556, Validation loss: 0.4996524751186371
Epoch: 98/100 - Train loss: 0.4904348850250244, Validation loss: 0.4980931580066681
Epoch: 99/100 - Train loss: 0.4894433617591858, Validation loss: 0.49808380007743835
Epoch: 100/100 - Train loss: 0.4884640574455261, Validation loss: 0.49670732021331787
Epoch: 1/300 - Train loss: 0.6976805329322815, Validation loss: 0.6966983079910278
Epoch: 2/300 - Train loss: 0.6957467794418335, Validation loss: 0.6948453783988953
Epoch: 3/300 - Train loss: 0.6938527226448059, Validation loss: 0.6930302381515503
Epoch: 4/300 - Train loss: 0.6919727921485901, Validation loss: 0.6911568641662598
Epoch: 5/300 - Train loss: 0.6900712847709656, Validation loss: 0.6891393661499023
Epoch: 6/300 - Train loss: 0.6881278157234192, Validation loss: 0.6871024966239929
Epoch: 7/300 - Train loss: 0.686112642288208, Validation loss: 0.6850757598876953
Epoch: 8/300 - Train loss: 0.6840192675590515, Validation loss: 0.6828643083572388
Epoch: 9/300 - Train loss: 0.6818403601646423, Validation loss: 0.6805240511894226
Epoch: 10/300 - Train loss: 0.6795696020126343, Validation loss: 0.6781894564628601
Epoch: 11/300 - Train loss: 0.6772060394287109, Validation loss: 0.6758688688278198
Epoch: 12/300 - Train loss: 0.6747501492500305, Validation loss: 0.6733219027519226
Epoch: 13/300 - Train loss: 0.6722051501274109, Validation loss: 0.6707163453102112
Epoch: 14/300 - Train loss: 0.6695830225944519, Validation loss: 0.6679956316947937
Epoch: 15/300 - Train loss: 0.6668878793716431, Validation loss: 0.6653864979743958
Epoch: 16/300 - Train loss: 0.6641330718994141, Validation loss: 0.6625651717185974
Epoch: 17/300 - Train loss: 0.6613287329673767, Validation loss: 0.659882664680481
Epoch: 18/300 - Train loss: 0.6584808826446533, Validation loss: 0.656994640827179
Epoch: 19/300 - Train loss: 0.6555957794189453, Validation loss: 0.6541809439659119
Epoch: 20/300 - Train loss: 0.6526758670806885, Validation loss: 0.6512500643730164
Epoch: 21/300 - Train loss: 0.6497304439544678, Validation loss: 0.6484871506690979
Epoch: 22/300 - Train loss: 0.6467651724815369, Validation loss: 0.6455761194229126
Epoch: 23/300 - Train loss: 0.6437853574752808, Validation loss: 0.6426326632499695
Epoch: 24/300 - Train loss: 0.6407931447029114, Validation loss: 0.6398589611053467
Epoch: 25/300 - Train loss: 0.6377918720245361, Validation loss: 0.6368017792701721
Epoch: 26/300 - Train loss: 0.6347866058349609, Validation loss: 0.634244978427887
Epoch: 27/300 - Train loss: 0.6317804455757141, Validation loss: 0.6313085556030273
Epoch: 28/300 - Train loss: 0.6287766695022583, Validation loss: 0.6284651756286621
Epoch: 29/300 - Train loss: 0.6257789731025696, Validation loss: 0.6255479454994202
Epoch: 30/300 - Train loss: 0.6227879524230957, Validation loss: 0.6227466464042664
Epoch: 31/300 - Train loss: 0.6198043823242188, Validation loss: 0.6199002861976624
Epoch: 32/300 - Train loss: 0.6168308258056641, Validation loss: 0.617046058177948
Epoch: 33/300 - Train loss: 0.6138703227043152, Validation loss: 0.6141689419746399
Epoch: 34/300 - Train loss: 0.610925555229187, Validation loss: 0.6112689971923828
Epoch: 35/300 - Train loss: 0.6079974174499512, Validation loss: 0.6088522672653198
Epoch: 36/300 - Train loss: 0.6050869822502136, Validation loss: 0.6059209704399109
Epoch: 37/300 - Train loss: 0.6021968126296997, Validation loss: 0.6030778288841248
Epoch: 38/300 - Train loss: 0.5993276238441467, Validation loss: 0.6007587909698486
Epoch: 39/300 - Train loss: 0.5964804887771606, Validation loss: 0.5980392098426819
Epoch: 40/300 - Train loss: 0.593657374382019, Validation loss: 0.5950390100479126
Epoch: 41/300 - Train loss: 0.5908594131469727, Validation loss: 0.592551589012146
Epoch: 42/300 - Train loss: 0.5880885124206543, Validation loss: 0.58990478515625
Epoch: 43/300 - Train loss: 0.5853469371795654, Validation loss: 0.5875030159950256
Epoch: 44/300 - Train loss: 0.5826363563537598, Validation loss: 0.5845941305160522
Epoch: 45/300 - Train loss: 0.5799580812454224, Validation loss: 0.5824563503265381
Epoch: 46/300 - Train loss: 0.5773128867149353, Validation loss: 0.5798323750495911
Epoch: 47/300 - Train loss: 0.5747026205062866, Validation loss: 0.5772590637207031
Epoch: 48/300 - Train loss: 0.5721274614334106, Validation loss: 0.5747822523117065
Epoch: 49/300 - Train loss: 0.5695894360542297, Validation loss: 0.5725380182266235
Epoch: 50/300 - Train loss: 0.567089319229126, Validation loss: 0.5697047710418701
Epoch: 51/300 - Train loss: 0.5646275877952576, Validation loss: 0.5677555203437805
Epoch: 52/300 - Train loss: 0.5622062683105469, Validation loss: 0.5653589963912964
Epoch: 53/300 - Train loss: 0.5598248839378357, Validation loss: 0.5635263919830322
Epoch: 54/300 - Train loss: 0.5574846863746643, Validation loss: 0.5615027546882629
Epoch: 55/300 - Train loss: 0.5551864504814148, Validation loss: 0.5590413212776184
Epoch: 56/300 - Train loss: 0.5529317855834961, Validation loss: 0.5571431517601013
Epoch: 57/300 - Train loss: 0.5507209300994873, Validation loss: 0.5552553534507751
Epoch: 58/300 - Train loss: 0.5485530495643616, Validation loss: 0.5531128644943237
Epoch: 59/300 - Train loss: 0.5464298129081726, Validation loss: 0.5510279536247253
Epoch: 60/300 - Train loss: 0.5443504452705383, Validation loss: 0.5492123961448669
Epoch: 61/300 - Train loss: 0.5423157215118408, Validation loss: 0.5471757054328918
Epoch: 62/300 - Train loss: 0.5403255224227905, Validation loss: 0.5461498498916626
Epoch: 63/300 - Train loss: 0.5383796095848083, Validation loss: 0.5438287258148193
Epoch: 64/300 - Train loss: 0.5364781022071838, Validation loss: 0.5418426394462585
Epoch: 65/300 - Train loss: 0.534619927406311, Validation loss: 0.5402259230613708
Epoch: 66/300 - Train loss: 0.5328048467636108, Validation loss: 0.538280189037323
Epoch: 67/300 - Train loss: 0.5310332179069519, Validation loss: 0.5369505286216736
Epoch: 68/300 - Train loss: 0.5293039083480835, Validation loss: 0.5357165932655334
Epoch: 69/300 - Train loss: 0.5276177525520325, Validation loss: 0.533729612827301
Epoch: 70/300 - Train loss: 0.5259730219841003, Validation loss: 0.5319048166275024
Epoch: 71/300 - Train loss: 0.5243688225746155, Validation loss: 0.5308055281639099
Epoch: 72/300 - Train loss: 0.5228034853935242, Validation loss: 0.5290053486824036
Epoch: 73/300 - Train loss: 0.5212761759757996, Validation loss: 0.5276162624359131
Epoch: 74/300 - Train loss: 0.5197867751121521, Validation loss: 0.5263414978981018
Epoch: 75/300 - Train loss: 0.5183342099189758, Validation loss: 0.5253523588180542
Epoch: 76/300 - Train loss: 0.5169166326522827, Validation loss: 0.5238284468650818
Epoch: 77/300 - Train loss: 0.5155331492424011, Validation loss: 0.5226415395736694
Epoch: 78/300 - Train loss: 0.5141829252243042, Validation loss: 0.5219778418540955
Epoch: 79/300 - Train loss: 0.5128640532493591, Validation loss: 0.5202090740203857
Epoch: 80/300 - Train loss: 0.5115756392478943, Validation loss: 0.5190531015396118
Epoch: 81/300 - Train loss: 0.510317325592041, Validation loss: 0.517813503742218
Epoch: 82/300 - Train loss: 0.5090879201889038, Validation loss: 0.5169277787208557
Epoch: 83/300 - Train loss: 0.5078848600387573, Validation loss: 0.5163089632987976
Epoch: 84/300 - Train loss: 0.5067074298858643, Validation loss: 0.5147483348846436
Epoch: 85/300 - Train loss: 0.5055550336837769, Validation loss: 0.5137708783149719
Epoch: 86/300 - Train loss: 0.504425048828125, Validation loss: 0.5122907757759094
Epoch: 87/300 - Train loss: 0.5033157467842102, Validation loss: 0.5114781856536865
Epoch: 88/300 - Train loss: 0.5022266507148743, Validation loss: 0.5104798078536987
Epoch: 89/300 - Train loss: 0.5011569857597351, Validation loss: 0.5092547535896301
Epoch: 90/300 - Train loss: 0.5001039505004883, Validation loss: 0.508012056350708
Epoch: 91/300 - Train loss: 0.4990675747394562, Validation loss: 0.5069669485092163
Epoch: 92/300 - Train loss: 0.49804815649986267, Validation loss: 0.5061827898025513
Epoch: 93/300 - Train loss: 0.4970434308052063, Validation loss: 0.505635142326355
Epoch: 94/300 - Train loss: 0.4960501492023468, Validation loss: 0.5044806003570557
Epoch: 95/300 - Train loss: 0.495067298412323, Validation loss: 0.5037519335746765
Epoch: 96/300 - Train loss: 0.494094580411911, Validation loss: 0.5024073719978333
Epoch: 97/300 - Train loss: 0.4931323528289795, Validation loss: 0.5018088817596436
Epoch: 98/300 - Train loss: 0.49217742681503296, Validation loss: 0.500969409942627
Epoch: 99/300 - Train loss: 0.49123215675354004, Validation loss: 0.5001384615898132
Epoch: 100/300 - Train loss: 0.4902968108654022, Validation loss: 0.49829113483428955
Epoch: 101/300 - Train loss: 0.48936915397644043, Validation loss: 0.4977167546749115
Epoch: 102/300 - Train loss: 0.48844727873802185, Validation loss: 0.4975908696651459
Epoch: 103/300 - Train loss: 0.4875338077545166, Validation loss: 0.49625131487846375
Epoch: 104/300 - Train loss: 0.4866250455379486, Validation loss: 0.49505898356437683
Epoch: 105/300 - Train loss: 0.48572227358818054, Validation loss: 0.49492740631103516
Epoch: 106/300 - Train loss: 0.4848242700099945, Validation loss: 0.49302318692207336
Epoch: 107/300 - Train loss: 0.483929306268692, Validation loss: 0.49282681941986084
Epoch: 108/300 - Train loss: 0.48303863406181335, Validation loss: 0.4923395812511444
Epoch: 109/300 - Train loss: 0.48215606808662415, Validation loss: 0.49070531129837036
Epoch: 110/300 - Train loss: 0.4812775254249573, Validation loss: 0.4898574948310852
Epoch: 111/300 - Train loss: 0.48040083050727844, Validation loss: 0.4881540834903717
Epoch: 112/300 - Train loss: 0.4795275032520294, Validation loss: 0.48847541213035583
Epoch: 113/300 - Train loss: 0.47865885496139526, Validation loss: 0.48713037371635437
Epoch: 114/300 - Train loss: 0.47779276967048645, Validation loss: 0.486581951379776
Epoch: 115/300 - Train loss: 0.47693195939064026, Validation loss: 0.48606574535369873
Epoch: 116/300 - Train loss: 0.4760740101337433, Validation loss: 0.48489633202552795
Epoch: 117/300 - Train loss: 0.47521546483039856, Validation loss: 0.4842323660850525
Epoch: 118/300 - Train loss: 0.47435593605041504, Validation loss: 0.48314180970191956
Epoch: 119/300 - Train loss: 0.47349897027015686, Validation loss: 0.4828875958919525
Epoch: 120/300 - Train loss: 0.47264546155929565, Validation loss: 0.4812546968460083
Epoch: 121/300 - Train loss: 0.4717959463596344, Validation loss: 0.48102718591690063
Epoch: 122/300 - Train loss: 0.47094905376434326, Validation loss: 0.4800146818161011
Epoch: 123/300 - Train loss: 0.4701041579246521, Validation loss: 0.4794456362724304
Epoch: 124/300 - Train loss: 0.4692631661891937, Validation loss: 0.4784359633922577
Epoch: 125/300 - Train loss: 0.4684239625930786, Validation loss: 0.47735080122947693
Epoch: 126/300 - Train loss: 0.46758976578712463, Validation loss: 0.47744202613830566
Epoch: 127/300 - Train loss: 0.4667588770389557, Validation loss: 0.47665145993232727
Epoch: 128/300 - Train loss: 0.46593177318573, Validation loss: 0.47495993971824646
Epoch: 129/300 - Train loss: 0.465108722448349, Validation loss: 0.47436147928237915
Epoch: 130/300 - Train loss: 0.464289128780365, Validation loss: 0.4734247326850891
Epoch: 131/300 - Train loss: 0.4634755253791809, Validation loss: 0.4727303385734558
Epoch: 132/300 - Train loss: 0.46266332268714905, Validation loss: 0.4719317853450775
Epoch: 133/300 - Train loss: 0.46185302734375, Validation loss: 0.47034338116645813
Epoch: 134/300 - Train loss: 0.46104294061660767, Validation loss: 0.4701818823814392
Epoch: 135/300 - Train loss: 0.4602338373661041, Validation loss: 0.46920886635780334
Epoch: 136/300 - Train loss: 0.4594258964061737, Validation loss: 0.46822285652160645
Epoch: 137/300 - Train loss: 0.4586215019226074, Validation loss: 0.46814319491386414
Epoch: 138/300 - Train loss: 0.45782074332237244, Validation loss: 0.46683141589164734
Epoch: 139/300 - Train loss: 0.45702236890792847, Validation loss: 0.46644675731658936
Epoch: 140/300 - Train loss: 0.4562237560749054, Validation loss: 0.4654681980609894
Epoch: 141/300 - Train loss: 0.45542845129966736, Validation loss: 0.4646170139312744
Epoch: 142/300 - Train loss: 0.45463573932647705, Validation loss: 0.4638209640979767
Epoch: 143/300 - Train loss: 0.4538465738296509, Validation loss: 0.46295517683029175
Epoch: 144/300 - Train loss: 0.4530591666698456, Validation loss: 0.4620823562145233
Epoch: 145/300 - Train loss: 0.45227447152137756, Validation loss: 0.46170011162757874
Epoch: 146/300 - Train loss: 0.45149314403533936, Validation loss: 0.46124467253685
Epoch: 147/300 - Train loss: 0.450716108083725, Validation loss: 0.45992258191108704
Epoch: 148/300 - Train loss: 0.4499417543411255, Validation loss: 0.45997944474220276
Epoch: 149/300 - Train loss: 0.4491690695285797, Validation loss: 0.45872732996940613
Epoch: 150/300 - Train loss: 0.44839853048324585, Validation loss: 0.4581175446510315
Epoch: 151/300 - Train loss: 0.44762977957725525, Validation loss: 0.458146333694458
Epoch: 152/300 - Train loss: 0.44686391949653625, Validation loss: 0.45747852325439453
Epoch: 153/300 - Train loss: 0.4461009204387665, Validation loss: 0.4557276964187622
Epoch: 154/300 - Train loss: 0.44533905386924744, Validation loss: 0.45504093170166016
Epoch: 155/300 - Train loss: 0.4445800483226776, Validation loss: 0.45443248748779297
Epoch: 156/300 - Train loss: 0.44382351636886597, Validation loss: 0.45387300848960876
Epoch: 157/300 - Train loss: 0.4430694878101349, Validation loss: 0.4532533884048462
Epoch: 158/300 - Train loss: 0.4423166513442993, Validation loss: 0.45263972878456116
Epoch: 159/300 - Train loss: 0.4415655732154846, Validation loss: 0.4519674479961395
Epoch: 160/300 - Train loss: 0.4408153295516968, Validation loss: 0.45232954621315
Epoch: 161/300 - Train loss: 0.4400676190853119, Validation loss: 0.4513472318649292
Epoch: 162/300 - Train loss: 0.4393218457698822, Validation loss: 0.4499322772026062
Epoch: 163/300 - Train loss: 0.4385780692100525, Validation loss: 0.4495864808559418
Epoch: 164/300 - Train loss: 0.4378356635570526, Validation loss: 0.44894400238990784
Epoch: 165/300 - Train loss: 0.4370962977409363, Validation loss: 0.4476141631603241
Epoch: 166/300 - Train loss: 0.43636009097099304, Validation loss: 0.44713345170021057
Epoch: 167/300 - Train loss: 0.43562573194503784, Validation loss: 0.44707226753234863
Epoch: 168/300 - Train loss: 0.43489453196525574, Validation loss: 0.4468250870704651
Epoch: 169/300 - Train loss: 0.4341653883457184, Validation loss: 0.44547227025032043
Epoch: 170/300 - Train loss: 0.4334392845630646, Validation loss: 0.4450555741786957
Epoch: 171/300 - Train loss: 0.43271663784980774, Validation loss: 0.4438757598400116
Epoch: 172/300 - Train loss: 0.4319964647293091, Validation loss: 0.4434869885444641
Epoch: 173/300 - Train loss: 0.43127885460853577, Validation loss: 0.4425702393054962
Epoch: 174/300 - Train loss: 0.430563747882843, Validation loss: 0.44233980774879456
Epoch: 175/300 - Train loss: 0.42985066771507263, Validation loss: 0.44189101457595825
Epoch: 176/300 - Train loss: 0.4291405975818634, Validation loss: 0.4413726031780243
Epoch: 177/300 - Train loss: 0.42843273282051086, Validation loss: 0.44058072566986084
Epoch: 178/300 - Train loss: 0.42772746086120605, Validation loss: 0.44021549820899963
Epoch: 179/300 - Train loss: 0.42702409625053406, Validation loss: 0.43982064723968506
Epoch: 180/300 - Train loss: 0.4263242185115814, Validation loss: 0.4389874339103699
