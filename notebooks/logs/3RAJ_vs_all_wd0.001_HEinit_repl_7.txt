Epoch: 1/300 - Train loss: 0.7123597264289856, Validation loss: 0.71358722448349
Epoch: 2/300 - Train loss: 0.7107489705085754, Validation loss: 0.711847186088562
Epoch: 3/300 - Train loss: 0.7092238664627075, Validation loss: 0.7104026675224304
Epoch: 4/300 - Train loss: 0.7077817320823669, Validation loss: 0.709023654460907
Epoch: 5/300 - Train loss: 0.7064129710197449, Validation loss: 0.707705557346344
Epoch: 6/300 - Train loss: 0.7051094770431519, Validation loss: 0.705927312374115
Epoch: 7/300 - Train loss: 0.7038630843162537, Validation loss: 0.7049325108528137
Epoch: 8/300 - Train loss: 0.7026615738868713, Validation loss: 0.7037345170974731
Epoch: 9/300 - Train loss: 0.7014966011047363, Validation loss: 0.7023369669914246
Epoch: 10/300 - Train loss: 0.7003596425056458, Validation loss: 0.7012569904327393
Epoch: 11/300 - Train loss: 0.6992427706718445, Validation loss: 0.6999642848968506
Epoch: 12/300 - Train loss: 0.6981346011161804, Validation loss: 0.6987498998641968
Epoch: 13/300 - Train loss: 0.6970308423042297, Validation loss: 0.6977037787437439
Epoch: 14/300 - Train loss: 0.6959261298179626, Validation loss: 0.6966343522071838
Epoch: 15/300 - Train loss: 0.6948151588439941, Validation loss: 0.6953449845314026
Epoch: 16/300 - Train loss: 0.6936878561973572, Validation loss: 0.6939982771873474
Epoch: 17/300 - Train loss: 0.6925408840179443, Validation loss: 0.6929274201393127
Epoch: 18/300 - Train loss: 0.691368818283081, Validation loss: 0.6915806531906128
Epoch: 19/300 - Train loss: 0.6901658773422241, Validation loss: 0.6903234124183655
Epoch: 20/300 - Train loss: 0.6889297366142273, Validation loss: 0.6889507174491882
Epoch: 21/300 - Train loss: 0.6876577734947205, Validation loss: 0.6874688267707825
Epoch: 22/300 - Train loss: 0.6863447427749634, Validation loss: 0.6861638426780701
Epoch: 23/300 - Train loss: 0.6849882006645203, Validation loss: 0.6846318244934082
Epoch: 24/300 - Train loss: 0.6835866570472717, Validation loss: 0.6830486059188843
Epoch: 25/300 - Train loss: 0.6821357607841492, Validation loss: 0.6814642548561096
Epoch: 26/300 - Train loss: 0.6806344985961914, Validation loss: 0.6799067854881287
Epoch: 27/300 - Train loss: 0.6790808439254761, Validation loss: 0.6782723665237427
Epoch: 28/300 - Train loss: 0.6774754524230957, Validation loss: 0.6765749454498291
Epoch: 29/300 - Train loss: 0.6758145689964294, Validation loss: 0.6746939420700073
Epoch: 30/300 - Train loss: 0.6740959882736206, Validation loss: 0.6728891134262085
Epoch: 31/300 - Train loss: 0.6723209023475647, Validation loss: 0.6710055470466614
Epoch: 32/300 - Train loss: 0.6704868078231812, Validation loss: 0.6689296960830688
Epoch: 33/300 - Train loss: 0.6685951948165894, Validation loss: 0.6669374704360962
Epoch: 34/300 - Train loss: 0.6666481494903564, Validation loss: 0.6649251580238342
Epoch: 35/300 - Train loss: 0.6646427512168884, Validation loss: 0.6626556515693665
Epoch: 36/300 - Train loss: 0.6625804901123047, Validation loss: 0.660551130771637
Epoch: 37/300 - Train loss: 0.660463809967041, Validation loss: 0.6583185791969299
Epoch: 38/300 - Train loss: 0.6582928895950317, Validation loss: 0.6561630964279175
Epoch: 39/300 - Train loss: 0.6560711860656738, Validation loss: 0.6537281274795532
Epoch: 40/300 - Train loss: 0.6538034081459045, Validation loss: 0.651370644569397
Epoch: 41/300 - Train loss: 0.6514914631843567, Validation loss: 0.6488687992095947
Epoch: 42/300 - Train loss: 0.6491411328315735, Validation loss: 0.6465016007423401
Epoch: 43/300 - Train loss: 0.6467494368553162, Validation loss: 0.6441067457199097
Epoch: 44/300 - Train loss: 0.6443212628364563, Validation loss: 0.6415663957595825
Epoch: 45/300 - Train loss: 0.6418620347976685, Validation loss: 0.6389804482460022
Epoch: 46/300 - Train loss: 0.6393753886222839, Validation loss: 0.6364083290100098
Epoch: 47/300 - Train loss: 0.6368605494499207, Validation loss: 0.6339977383613586
Epoch: 48/300 - Train loss: 0.6343216896057129, Validation loss: 0.6313549280166626
Epoch: 49/300 - Train loss: 0.6317611932754517, Validation loss: 0.6288691759109497
Epoch: 50/300 - Train loss: 0.6291843056678772, Validation loss: 0.6262117624282837
Epoch: 51/300 - Train loss: 0.626593828201294, Validation loss: 0.6234862804412842
Epoch: 52/300 - Train loss: 0.6239954829216003, Validation loss: 0.620731770992279
Epoch: 53/300 - Train loss: 0.62138831615448, Validation loss: 0.6180080771446228
Epoch: 54/300 - Train loss: 0.6187768578529358, Validation loss: 0.615445077419281
Epoch: 55/300 - Train loss: 0.616165816783905, Validation loss: 0.6130183935165405
Epoch: 56/300 - Train loss: 0.6135563850402832, Validation loss: 0.6102543473243713
Epoch: 57/300 - Train loss: 0.6109522581100464, Validation loss: 0.6076614856719971
Epoch: 58/300 - Train loss: 0.6083569526672363, Validation loss: 0.6051563620567322
Epoch: 59/300 - Train loss: 0.6057747006416321, Validation loss: 0.6022623181343079
Epoch: 60/300 - Train loss: 0.6032090783119202, Validation loss: 0.6001672148704529
Epoch: 61/300 - Train loss: 0.6006643772125244, Validation loss: 0.5973001718521118
Epoch: 62/300 - Train loss: 0.5981430411338806, Validation loss: 0.5950157046318054
Epoch: 63/300 - Train loss: 0.5956475734710693, Validation loss: 0.5923608541488647
Epoch: 64/300 - Train loss: 0.5931793451309204, Validation loss: 0.5901033282279968
Epoch: 65/300 - Train loss: 0.5907416939735413, Validation loss: 0.5876569151878357
Epoch: 66/300 - Train loss: 0.5883357524871826, Validation loss: 0.5853109359741211
Epoch: 67/300 - Train loss: 0.585963249206543, Validation loss: 0.5829848051071167
Epoch: 68/300 - Train loss: 0.5836257934570312, Validation loss: 0.5808162689208984
Epoch: 69/300 - Train loss: 0.5813243985176086, Validation loss: 0.578653872013092
Epoch: 70/300 - Train loss: 0.5790601372718811, Validation loss: 0.5762063264846802
Epoch: 71/300 - Train loss: 0.5768346190452576, Validation loss: 0.5740259289741516
Epoch: 72/300 - Train loss: 0.5746479034423828, Validation loss: 0.571740448474884
Epoch: 73/300 - Train loss: 0.572501003742218, Validation loss: 0.5696171522140503
Epoch: 74/300 - Train loss: 0.5703945755958557, Validation loss: 0.5676944851875305
Epoch: 75/300 - Train loss: 0.5683284997940063, Validation loss: 0.5657994747161865
Epoch: 76/300 - Train loss: 0.566302478313446, Validation loss: 0.5635985732078552
Epoch: 77/300 - Train loss: 0.5643154382705688, Validation loss: 0.5614742040634155
Epoch: 78/300 - Train loss: 0.5623663067817688, Validation loss: 0.5595656037330627
Epoch: 79/300 - Train loss: 0.5604551434516907, Validation loss: 0.5583896636962891
Epoch: 80/300 - Train loss: 0.5585817098617554, Validation loss: 0.5560183525085449
Epoch: 81/300 - Train loss: 0.5567452311515808, Validation loss: 0.5543280243873596
Epoch: 82/300 - Train loss: 0.5549440383911133, Validation loss: 0.5527478456497192
Epoch: 83/300 - Train loss: 0.5531774759292603, Validation loss: 0.5510944128036499
Epoch: 84/300 - Train loss: 0.5514441132545471, Validation loss: 0.548983633518219
Epoch: 85/300 - Train loss: 0.5497434735298157, Validation loss: 0.5476579070091248
Epoch: 86/300 - Train loss: 0.5480741858482361, Validation loss: 0.5462098121643066
Epoch: 87/300 - Train loss: 0.5464349389076233, Validation loss: 0.544247567653656
Epoch: 88/300 - Train loss: 0.5448251962661743, Validation loss: 0.542928159236908
Epoch: 89/300 - Train loss: 0.5432441830635071, Validation loss: 0.5416810512542725
Epoch: 90/300 - Train loss: 0.5416904091835022, Validation loss: 0.5399547815322876
Epoch: 91/300 - Train loss: 0.5401619672775269, Validation loss: 0.5387248396873474
Epoch: 92/300 - Train loss: 0.5386590361595154, Validation loss: 0.5367218255996704
Epoch: 93/300 - Train loss: 0.537180483341217, Validation loss: 0.5358175039291382
Epoch: 94/300 - Train loss: 0.535724401473999, Validation loss: 0.5343877673149109
Epoch: 95/300 - Train loss: 0.5342893600463867, Validation loss: 0.5323418378829956
Epoch: 96/300 - Train loss: 0.5328758955001831, Validation loss: 0.531863808631897
Epoch: 97/300 - Train loss: 0.5314829349517822, Validation loss: 0.5304681658744812
Epoch: 98/300 - Train loss: 0.5301087498664856, Validation loss: 0.5289230942726135
Epoch: 99/300 - Train loss: 0.5287524461746216, Validation loss: 0.5275805592536926
Epoch: 100/300 - Train loss: 0.5274145007133484, Validation loss: 0.5262355804443359
Epoch: 101/300 - Train loss: 0.5260946750640869, Validation loss: 0.525721549987793
Epoch: 102/300 - Train loss: 0.5247910022735596, Validation loss: 0.5246143341064453
Epoch: 103/300 - Train loss: 0.523502767086029, Validation loss: 0.5228267312049866
Epoch: 104/300 - Train loss: 0.5222291350364685, Validation loss: 0.5216379761695862
Epoch: 105/300 - Train loss: 0.5209687352180481, Validation loss: 0.5204875469207764
Epoch: 106/300 - Train loss: 0.5197205543518066, Validation loss: 0.5191895365715027
Epoch: 107/300 - Train loss: 0.5184850096702576, Validation loss: 0.5180469155311584
Epoch: 108/300 - Train loss: 0.517261803150177, Validation loss: 0.5175673365592957
Epoch: 109/300 - Train loss: 0.5160503387451172, Validation loss: 0.5156593322753906
Epoch: 110/300 - Train loss: 0.5148517489433289, Validation loss: 0.5153408050537109
Epoch: 111/300 - Train loss: 0.513664960861206, Validation loss: 0.5134366750717163
Epoch: 112/300 - Train loss: 0.5124893188476562, Validation loss: 0.5131325721740723
Epoch: 113/300 - Train loss: 0.5113242864608765, Validation loss: 0.5115398168563843
Epoch: 114/300 - Train loss: 0.5101679563522339, Validation loss: 0.510430634021759
Epoch: 115/300 - Train loss: 0.5090201497077942, Validation loss: 0.509516716003418
Epoch: 116/300 - Train loss: 0.5078805088996887, Validation loss: 0.5083690881729126
Epoch: 117/300 - Train loss: 0.506748616695404, Validation loss: 0.5081779360771179
Epoch: 118/300 - Train loss: 0.5056244730949402, Validation loss: 0.5067156553268433
Epoch: 119/300 - Train loss: 0.5045079588890076, Validation loss: 0.5049653649330139
Epoch: 120/300 - Train loss: 0.5033988952636719, Validation loss: 0.5041162967681885
Epoch: 121/300 - Train loss: 0.5022965669631958, Validation loss: 0.5034307837486267
Epoch: 122/300 - Train loss: 0.5012000799179077, Validation loss: 0.5020571351051331
Epoch: 123/300 - Train loss: 0.5001099705696106, Validation loss: 0.501133382320404
Epoch: 124/300 - Train loss: 0.49902498722076416, Validation loss: 0.4999101758003235
Epoch: 125/300 - Train loss: 0.49794501066207886, Validation loss: 0.49862346053123474
Epoch: 126/300 - Train loss: 0.4968699514865875, Validation loss: 0.4978516697883606
Epoch: 127/300 - Train loss: 0.49580085277557373, Validation loss: 0.4970904290676117
Epoch: 128/300 - Train loss: 0.49473458528518677, Validation loss: 0.49596577882766724
Epoch: 129/300 - Train loss: 0.4936712086200714, Validation loss: 0.4949001967906952
Epoch: 130/300 - Train loss: 0.492610365152359, Validation loss: 0.49442920088768005
Epoch: 131/300 - Train loss: 0.4915508031845093, Validation loss: 0.49251407384872437
Epoch: 132/300 - Train loss: 0.4904904365539551, Validation loss: 0.49183428287506104
Epoch: 133/300 - Train loss: 0.48942944407463074, Validation loss: 0.49067550897598267
Epoch: 134/300 - Train loss: 0.4883674681186676, Validation loss: 0.48953351378440857
Epoch: 135/300 - Train loss: 0.4873032569885254, Validation loss: 0.4886573553085327
Epoch: 136/300 - Train loss: 0.4862366020679474, Validation loss: 0.487269788980484
Epoch: 137/300 - Train loss: 0.48516589403152466, Validation loss: 0.48702472448349
Epoch: 138/300 - Train loss: 0.4840901792049408, Validation loss: 0.4858030378818512
Epoch: 139/300 - Train loss: 0.4830062687397003, Validation loss: 0.4847440719604492
Epoch: 140/300 - Train loss: 0.48191219568252563, Validation loss: 0.4834184944629669
Epoch: 141/300 - Train loss: 0.48080936074256897, Validation loss: 0.483609139919281
Epoch: 142/300 - Train loss: 0.4796961545944214, Validation loss: 0.4815120995044708
Epoch: 143/300 - Train loss: 0.4785730838775635, Validation loss: 0.48041555285453796
Epoch: 144/300 - Train loss: 0.47743725776672363, Validation loss: 0.47957590222358704
Epoch: 145/300 - Train loss: 0.4762890934944153, Validation loss: 0.4779853820800781
Epoch: 146/300 - Train loss: 0.475130558013916, Validation loss: 0.4767914414405823
Epoch: 147/300 - Train loss: 0.4739637076854706, Validation loss: 0.47553950548171997
Epoch: 148/300 - Train loss: 0.47278815507888794, Validation loss: 0.4746885895729065
Epoch: 149/300 - Train loss: 0.47160524129867554, Validation loss: 0.4741273522377014
Epoch: 150/300 - Train loss: 0.4704127013683319, Validation loss: 0.4725884795188904
Epoch: 151/300 - Train loss: 0.4692074954509735, Validation loss: 0.47117355465888977
Epoch: 152/300 - Train loss: 0.4679953455924988, Validation loss: 0.46949025988578796
Epoch: 153/300 - Train loss: 0.4667748212814331, Validation loss: 0.468282550573349
Epoch: 154/300 - Train loss: 0.4655456244945526, Validation loss: 0.46714693307876587
Epoch: 155/300 - Train loss: 0.46430739760398865, Validation loss: 0.466129869222641
Epoch: 156/300 - Train loss: 0.4630648195743561, Validation loss: 0.4646803140640259
Epoch: 157/300 - Train loss: 0.4618147909641266, Validation loss: 0.46367108821868896
Epoch: 158/300 - Train loss: 0.4605642557144165, Validation loss: 0.46249309182167053
Epoch: 159/300 - Train loss: 0.45931190252304077, Validation loss: 0.46118271350860596
Epoch: 160/300 - Train loss: 0.45805832743644714, Validation loss: 0.4599233567714691
Epoch: 161/300 - Train loss: 0.45680710673332214, Validation loss: 0.45834919810295105
Epoch: 162/300 - Train loss: 0.455556184053421, Validation loss: 0.45749396085739136
Epoch: 163/300 - Train loss: 0.4543059468269348, Validation loss: 0.45683997869491577
Epoch: 164/300 - Train loss: 0.4530562460422516, Validation loss: 0.4550485908985138
Epoch: 165/300 - Train loss: 0.45181265473365784, Validation loss: 0.4540334641933441
Epoch: 166/300 - Train loss: 0.4505760073661804, Validation loss: 0.4530218541622162
Epoch: 167/300 - Train loss: 0.4493454396724701, Validation loss: 0.45177987217903137
Epoch: 168/300 - Train loss: 0.44812652468681335, Validation loss: 0.45108240842819214
Epoch: 169/300 - Train loss: 0.44691693782806396, Validation loss: 0.44903042912483215
Epoch: 170/300 - Train loss: 0.4457166790962219, Validation loss: 0.44877156615257263
Epoch: 171/300 - Train loss: 0.4445234537124634, Validation loss: 0.4468030333518982
Epoch: 172/300 - Train loss: 0.44333896040916443, Validation loss: 0.44606465101242065
Epoch: 173/300 - Train loss: 0.44216397404670715, Validation loss: 0.4449611306190491
Epoch: 174/300 - Train loss: 0.44099897146224976, Validation loss: 0.44372934103012085
Epoch: 175/300 - Train loss: 0.43984487652778625, Validation loss: 0.4424574673175812
Epoch: 176/300 - Train loss: 0.4387027323246002, Validation loss: 0.44197753071784973
Epoch: 177/300 - Train loss: 0.43757110834121704, Validation loss: 0.44018614292144775
Epoch: 178/300 - Train loss: 0.4364495575428009, Validation loss: 0.43964359164237976
Epoch: 179/300 - Train loss: 0.4353382885456085, Validation loss: 0.43830329179763794
Epoch: 180/300 - Train loss: 0.4342358708381653, Validation loss: 0.4371784031391144
Epoch: 181/300 - Train loss: 0.43314242362976074, Validation loss: 0.43640628457069397
Epoch: 182/300 - Train loss: 0.4320596754550934, Validation loss: 0.43483951687812805
Epoch: 183/300 - Train loss: 0.4309863746166229, Validation loss: 0.4339119791984558
Epoch: 184/300 - Train loss: 0.42992326617240906, Validation loss: 0.43363964557647705
Epoch: 185/300 - Train loss: 0.4288707673549652, Validation loss: 0.43221500515937805
Epoch: 186/300 - Train loss: 0.42782899737358093, Validation loss: 0.4305724799633026
Epoch: 187/300 - Train loss: 0.4267975986003876, Validation loss: 0.4304257035255432
Epoch: 188/300 - Train loss: 0.4257757067680359, Validation loss: 0.4295722246170044
Epoch: 189/300 - Train loss: 0.42476439476013184, Validation loss: 0.4283861517906189
Epoch: 190/300 - Train loss: 0.4237652122974396, Validation loss: 0.42768868803977966
Epoch: 191/300 - Train loss: 0.4227767586708069, Validation loss: 0.42590558528900146
Epoch: 192/300 - Train loss: 0.4217976927757263, Validation loss: 0.4254857897758484
Epoch: 193/300 - Train loss: 0.42082738876342773, Validation loss: 0.425201952457428
Epoch: 194/300 - Train loss: 0.41986748576164246, Validation loss: 0.42377862334251404
Epoch: 195/300 - Train loss: 0.4189176559448242, Validation loss: 0.42290613055229187
Epoch: 196/300 - Train loss: 0.41797730326652527, Validation loss: 0.4215201139450073
Epoch: 197/300 - Train loss: 0.4170461595058441, Validation loss: 0.4205794036388397
Epoch: 198/300 - Train loss: 0.4161241054534912, Validation loss: 0.4199204742908478
Epoch: 199/300 - Train loss: 0.41521164774894714, Validation loss: 0.4186014235019684
Epoch: 200/300 - Train loss: 0.4143093228340149, Validation loss: 0.4194512367248535
Epoch: 201/300 - Train loss: 0.41341668367385864, Validation loss: 0.4180259704589844
Epoch: 202/300 - Train loss: 0.412533164024353, Validation loss: 0.41640380024909973
Epoch: 203/300 - Train loss: 0.41165727376937866, Validation loss: 0.41584712266921997
Epoch: 204/300 - Train loss: 0.41078996658325195, Validation loss: 0.41513460874557495
Epoch: 205/300 - Train loss: 0.40993180871009827, Validation loss: 0.4145963191986084
Epoch: 206/300 - Train loss: 0.4090825915336609, Validation loss: 0.413542240858078
Epoch: 207/300 - Train loss: 0.40824228525161743, Validation loss: 0.41286781430244446
Epoch: 208/300 - Train loss: 0.4074101746082306, Validation loss: 0.4119463264942169
Epoch: 209/300 - Train loss: 0.40658658742904663, Validation loss: 0.4108906388282776
Epoch: 210/300 - Train loss: 0.40577128529548645, Validation loss: 0.4103333055973053
Epoch: 211/300 - Train loss: 0.4049631655216217, Validation loss: 0.40981829166412354
Epoch: 212/300 - Train loss: 0.40416374802589417, Validation loss: 0.4088568687438965
Epoch: 213/300 - Train loss: 0.40337270498275757, Validation loss: 0.40816545486450195
Epoch: 214/300 - Train loss: 0.4025889039039612, Validation loss: 0.40770891308784485
Epoch: 215/300 - Train loss: 0.40181246399879456, Validation loss: 0.4064139425754547
Epoch: 216/300 - Train loss: 0.40104374289512634, Validation loss: 0.4060581922531128
Epoch: 217/300 - Train loss: 0.4002821445465088, Validation loss: 0.4053998291492462
Epoch: 218/300 - Train loss: 0.3995286524295807, Validation loss: 0.40435701608657837
Epoch: 219/300 - Train loss: 0.39878231287002563, Validation loss: 0.40343812108039856
Epoch: 220/300 - Train loss: 0.3980432152748108, Validation loss: 0.4034435749053955
Epoch: 221/300 - Train loss: 0.3973119556903839, Validation loss: 0.4023584723472595
Epoch: 222/300 - Train loss: 0.39658817648887634, Validation loss: 0.40147897601127625
Epoch: 223/300 - Train loss: 0.39587074518203735, Validation loss: 0.4007200300693512
Epoch: 224/300 - Train loss: 0.3951592445373535, Validation loss: 0.40092161297798157
Epoch: 225/300 - Train loss: 0.39445364475250244, Validation loss: 0.3997686505317688
Epoch: 226/300 - Train loss: 0.39375442266464233, Validation loss: 0.39922088384628296
Epoch: 227/300 - Train loss: 0.39306211471557617, Validation loss: 0.3978184759616852
Epoch: 228/300 - Train loss: 0.39237552881240845, Validation loss: 0.398471862077713
Epoch: 229/300 - Train loss: 0.39169496297836304, Validation loss: 0.3967337906360626
Epoch: 230/300 - Train loss: 0.391020804643631, Validation loss: 0.39605072140693665
Epoch: 231/300 - Train loss: 0.39035284519195557, Validation loss: 0.3956691026687622
Epoch: 232/300 - Train loss: 0.389691025018692, Validation loss: 0.39521658420562744
Epoch: 233/300 - Train loss: 0.3890363574028015, Validation loss: 0.394605815410614
Epoch: 234/300 - Train loss: 0.38838890194892883, Validation loss: 0.39358794689178467
Epoch: 235/300 - Train loss: 0.3877483606338501, Validation loss: 0.39318791031837463
Epoch: 236/300 - Train loss: 0.3871144950389862, Validation loss: 0.39227238297462463
Epoch: 237/300 - Train loss: 0.3864865303039551, Validation loss: 0.3918426036834717
Epoch: 238/300 - Train loss: 0.38586416840553284, Validation loss: 0.3917331397533417
Epoch: 239/300 - Train loss: 0.3852476477622986, Validation loss: 0.39070308208465576
Epoch: 240/300 - Train loss: 0.38463684916496277, Validation loss: 0.39031022787094116
Epoch: 241/300 - Train loss: 0.3840317130088806, Validation loss: 0.3904239237308502
