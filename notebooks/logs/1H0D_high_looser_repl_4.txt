Epoch: 1/200 - Train loss: 0.6244529485702515, Validation loss: 0.5521765351295471
Epoch: 2/200 - Train loss: 0.5086930990219116, Validation loss: 0.4790317714214325
Epoch: 3/200 - Train loss: 0.4594506025314331, Validation loss: 0.4510967433452606
Epoch: 4/200 - Train loss: 0.43252983689308167, Validation loss: 0.42723146080970764
Epoch: 5/200 - Train loss: 0.4122466444969177, Validation loss: 0.4100797772407532
Epoch: 6/200 - Train loss: 0.39650508761405945, Validation loss: 0.39819926023483276
Epoch: 7/200 - Train loss: 0.380820631980896, Validation loss: 0.38508301973342896
Epoch: 8/200 - Train loss: 0.36295285820961, Validation loss: 0.36975419521331787
Epoch: 9/200 - Train loss: 0.34642255306243896, Validation loss: 0.36182767152786255
Epoch: 10/200 - Train loss: 0.33289238810539246, Validation loss: 0.3503718972206116
Epoch: 11/200 - Train loss: 0.3224157691001892, Validation loss: 0.34202998876571655
Epoch: 12/200 - Train loss: 0.31259259581565857, Validation loss: 0.3390049934387207
Epoch: 13/200 - Train loss: 0.3042106628417969, Validation loss: 0.33190831542015076
Epoch: 14/200 - Train loss: 0.29848331212997437, Validation loss: 0.3289829194545746
Epoch: 15/200 - Train loss: 0.29193416237831116, Validation loss: 0.3261837363243103
Epoch: 16/200 - Train loss: 0.2876838743686676, Validation loss: 0.32344508171081543
Epoch: 17/200 - Train loss: 0.283013254404068, Validation loss: 0.3168497085571289
Epoch: 18/200 - Train loss: 0.27893197536468506, Validation loss: 0.3150409758090973
Epoch: 19/200 - Train loss: 0.27636030316352844, Validation loss: 0.31402909755706787
Epoch: 20/200 - Train loss: 0.27224472165107727, Validation loss: 0.312153697013855
Epoch: 21/200 - Train loss: 0.26905113458633423, Validation loss: 0.3111986815929413
Epoch: 22/200 - Train loss: 0.26667967438697815, Validation loss: 0.3150315284729004
Epoch: 23/200 - Train loss: 0.2637162208557129, Validation loss: 0.3095073997974396
Epoch: 24/200 - Train loss: 0.2601913809776306, Validation loss: 0.3101636469364166
Epoch: 25/200 - Train loss: 0.2581481635570526, Validation loss: 0.30985626578330994
Epoch: 26/200 - Train loss: 0.25659143924713135, Validation loss: 0.3051500618457794
Epoch: 27/200 - Train loss: 0.2554547190666199, Validation loss: 0.30936214327812195
Epoch: 28/200 - Train loss: 0.25276607275009155, Validation loss: 0.30600854754447937
Epoch: 29/200 - Train loss: 0.2511517107486725, Validation loss: 0.30980220437049866
Epoch: 30/200 - Train loss: 0.2501281499862671, Validation loss: 0.3057044446468353
Epoch: 31/200 - Train loss: 0.24853409826755524, Validation loss: 0.3071215748786926
Epoch: 32/200 - Train loss: 0.24622975289821625, Validation loss: 0.31033724546432495
Epoch: 33/200 - Train loss: 0.2446703314781189, Validation loss: 0.30717694759368896
Epoch: 34/200 - Train loss: 0.24354170262813568, Validation loss: 0.3043273091316223
Epoch: 35/200 - Train loss: 0.24132731556892395, Validation loss: 0.3029671311378479
Epoch: 36/200 - Train loss: 0.2400270700454712, Validation loss: 0.30512872338294983
Epoch: 37/200 - Train loss: 0.2391570806503296, Validation loss: 0.30484622716903687
Epoch: 38/200 - Train loss: 0.23811182379722595, Validation loss: 0.30546003580093384
Epoch: 39/200 - Train loss: 0.23599478602409363, Validation loss: 0.30419397354125977
Epoch: 40/200 - Train loss: 0.2347736656665802, Validation loss: 0.3057059049606323
Epoch: 41/200 - Train loss: 0.23356550931930542, Validation loss: 0.30600282549858093
Epoch: 42/200 - Train loss: 0.2333591878414154, Validation loss: 0.30520185828208923
