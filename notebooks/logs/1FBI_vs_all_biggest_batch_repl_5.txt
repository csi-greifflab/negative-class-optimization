Epoch: 1/300 - Train loss: 0.6911999583244324, Validation loss: 0.6887268424034119
Epoch: 2/300 - Train loss: 0.6893917918205261, Validation loss: 0.6867899894714355
Epoch: 3/300 - Train loss: 0.6875091791152954, Validation loss: 0.6847785115242004
Epoch: 4/300 - Train loss: 0.6855131387710571, Validation loss: 0.6825819611549377
Epoch: 5/300 - Train loss: 0.6833767890930176, Validation loss: 0.6802083849906921
Epoch: 6/300 - Train loss: 0.6810675859451294, Validation loss: 0.6776294112205505
Epoch: 7/300 - Train loss: 0.678564727306366, Validation loss: 0.6748695373535156
Epoch: 8/300 - Train loss: 0.6758503317832947, Validation loss: 0.6718232035636902
Epoch: 9/300 - Train loss: 0.6729089617729187, Validation loss: 0.6685826182365417
Epoch: 10/300 - Train loss: 0.6697261929512024, Validation loss: 0.6651049256324768
Epoch: 11/300 - Train loss: 0.6662972569465637, Validation loss: 0.6613180041313171
Epoch: 12/300 - Train loss: 0.6626253724098206, Validation loss: 0.6572147011756897
Epoch: 13/300 - Train loss: 0.6587252020835876, Validation loss: 0.6530802845954895
Epoch: 14/300 - Train loss: 0.6545982360839844, Validation loss: 0.6485812067985535
Epoch: 15/300 - Train loss: 0.6502656936645508, Validation loss: 0.6439567804336548
Epoch: 16/300 - Train loss: 0.6457452774047852, Validation loss: 0.6391781568527222
Epoch: 17/300 - Train loss: 0.6410600543022156, Validation loss: 0.6341804265975952
Epoch: 18/300 - Train loss: 0.6362208127975464, Validation loss: 0.6292024850845337
Epoch: 19/300 - Train loss: 0.6312463879585266, Validation loss: 0.6239498257637024
Epoch: 20/300 - Train loss: 0.626146137714386, Validation loss: 0.618683397769928
Epoch: 21/300 - Train loss: 0.6209330558776855, Validation loss: 0.6132823824882507
Epoch: 22/300 - Train loss: 0.6156193614006042, Validation loss: 0.6078065633773804
Epoch: 23/300 - Train loss: 0.6102086901664734, Validation loss: 0.6022495031356812
Epoch: 24/300 - Train loss: 0.6047099828720093, Validation loss: 0.5964803099632263
Epoch: 25/300 - Train loss: 0.5991250872612, Validation loss: 0.5907389521598816
Epoch: 26/300 - Train loss: 0.5934601426124573, Validation loss: 0.5850130915641785
Epoch: 27/300 - Train loss: 0.58771812915802, Validation loss: 0.5790103077888489
Epoch: 28/300 - Train loss: 0.5819019675254822, Validation loss: 0.5732100009918213
Epoch: 29/300 - Train loss: 0.5760177373886108, Validation loss: 0.5671871900558472
Epoch: 30/300 - Train loss: 0.5700718760490417, Validation loss: 0.5610284805297852
Epoch: 31/300 - Train loss: 0.5640719532966614, Validation loss: 0.5549873113632202
Epoch: 32/300 - Train loss: 0.5580236315727234, Validation loss: 0.5486705899238586
Epoch: 33/300 - Train loss: 0.5519337058067322, Validation loss: 0.5426023602485657
Epoch: 34/300 - Train loss: 0.5458086729049683, Validation loss: 0.5365761518478394
Epoch: 35/300 - Train loss: 0.5396551489830017, Validation loss: 0.5300105214118958
Epoch: 36/300 - Train loss: 0.5334790349006653, Validation loss: 0.5238345861434937
Epoch: 37/300 - Train loss: 0.52728670835495, Validation loss: 0.5177366137504578
Epoch: 38/300 - Train loss: 0.5210844874382019, Validation loss: 0.5114524960517883
Epoch: 39/300 - Train loss: 0.5148782134056091, Validation loss: 0.505416750907898
Epoch: 40/300 - Train loss: 0.5086731910705566, Validation loss: 0.49887460470199585
Epoch: 41/300 - Train loss: 0.5024754405021667, Validation loss: 0.49285364151000977
Epoch: 42/300 - Train loss: 0.4962901771068573, Validation loss: 0.48670494556427
Epoch: 43/300 - Train loss: 0.49012279510498047, Validation loss: 0.48050281405448914
Epoch: 44/300 - Train loss: 0.48397859930992126, Validation loss: 0.4741956293582916
Epoch: 45/300 - Train loss: 0.4778628945350647, Validation loss: 0.4682878255844116
Epoch: 46/300 - Train loss: 0.4717814326286316, Validation loss: 0.462058424949646
Epoch: 47/300 - Train loss: 0.465739369392395, Validation loss: 0.45613956451416016
Epoch: 48/300 - Train loss: 0.45974183082580566, Validation loss: 0.4501492381095886
Epoch: 49/300 - Train loss: 0.45379307866096497, Validation loss: 0.44412344694137573
Epoch: 50/300 - Train loss: 0.4478979706764221, Validation loss: 0.43826520442962646
Epoch: 51/300 - Train loss: 0.44206079840660095, Validation loss: 0.43246379494667053
Epoch: 52/300 - Train loss: 0.4362858235836029, Validation loss: 0.42690643668174744
Epoch: 53/300 - Train loss: 0.4305769205093384, Validation loss: 0.4211302399635315
Epoch: 54/300 - Train loss: 0.4249378740787506, Validation loss: 0.4157509207725525
Epoch: 55/300 - Train loss: 0.4193718731403351, Validation loss: 0.41023513674736023
Epoch: 56/300 - Train loss: 0.41388243436813354, Validation loss: 0.4046628177165985
Epoch: 57/300 - Train loss: 0.4084725081920624, Validation loss: 0.3994273543357849
Epoch: 58/300 - Train loss: 0.4031444787979126, Validation loss: 0.39412742853164673
Epoch: 59/300 - Train loss: 0.39790084958076477, Validation loss: 0.3888399600982666
Epoch: 60/300 - Train loss: 0.3927438259124756, Validation loss: 0.3838708698749542
Epoch: 61/300 - Train loss: 0.3876752555370331, Validation loss: 0.3788761794567108
Epoch: 62/300 - Train loss: 0.38269633054733276, Validation loss: 0.3740731179714203
Epoch: 63/300 - Train loss: 0.37780889868736267, Validation loss: 0.3691326081752777
Epoch: 64/300 - Train loss: 0.3730137050151825, Validation loss: 0.3645916283130646
Epoch: 65/300 - Train loss: 0.36831191182136536, Validation loss: 0.36042267084121704
Epoch: 66/300 - Train loss: 0.3637039065361023, Validation loss: 0.3553861081600189
Epoch: 67/300 - Train loss: 0.3591896891593933, Validation loss: 0.35113438963890076
Epoch: 68/300 - Train loss: 0.35476988554000854, Validation loss: 0.34680745005607605
Epoch: 69/300 - Train loss: 0.3504445552825928, Validation loss: 0.3426935076713562
Epoch: 70/300 - Train loss: 0.34621354937553406, Validation loss: 0.3388519585132599
Epoch: 71/300 - Train loss: 0.34207627177238464, Validation loss: 0.33441898226737976
Epoch: 72/300 - Train loss: 0.3380320072174072, Validation loss: 0.33035698533058167
Epoch: 73/300 - Train loss: 0.33407992124557495, Validation loss: 0.3268420696258545
Epoch: 74/300 - Train loss: 0.3302190899848938, Validation loss: 0.3229656219482422
Epoch: 75/300 - Train loss: 0.32644858956336975, Validation loss: 0.3194340467453003
Epoch: 76/300 - Train loss: 0.322767436504364, Validation loss: 0.3162990212440491
Epoch: 77/300 - Train loss: 0.31917455792427063, Validation loss: 0.3120812773704529
Epoch: 78/300 - Train loss: 0.3156685531139374, Validation loss: 0.3091221749782562
Epoch: 79/300 - Train loss: 0.31224802136421204, Validation loss: 0.30547991394996643
Epoch: 80/300 - Train loss: 0.30891114473342896, Validation loss: 0.3017701506614685
Epoch: 81/300 - Train loss: 0.305656373500824, Validation loss: 0.2990749180316925
Epoch: 82/300 - Train loss: 0.3024822175502777, Validation loss: 0.2960185408592224
Epoch: 83/300 - Train loss: 0.2993871569633484, Validation loss: 0.29306694865226746
Epoch: 84/300 - Train loss: 0.2963694930076599, Validation loss: 0.28990522027015686
Epoch: 85/300 - Train loss: 0.2934277653694153, Validation loss: 0.28752923011779785
Epoch: 86/300 - Train loss: 0.2905599772930145, Validation loss: 0.28461989760398865
Epoch: 87/300 - Train loss: 0.2877644896507263, Validation loss: 0.28178462386131287
Epoch: 88/300 - Train loss: 0.28503984212875366, Validation loss: 0.27899253368377686
Epoch: 89/300 - Train loss: 0.2823845446109772, Validation loss: 0.27630212903022766
Epoch: 90/300 - Train loss: 0.2797965705394745, Validation loss: 0.2739388942718506
Epoch: 91/300 - Train loss: 0.27727416157722473, Validation loss: 0.2715966999530792
Epoch: 92/300 - Train loss: 0.2748158276081085, Validation loss: 0.2695423364639282
Epoch: 93/300 - Train loss: 0.2724197506904602, Validation loss: 0.2666742205619812
Epoch: 94/300 - Train loss: 0.2700845003128052, Validation loss: 0.2648058533668518
Epoch: 95/300 - Train loss: 0.26780831813812256, Validation loss: 0.2624896168708801
Epoch: 96/300 - Train loss: 0.26558971405029297, Validation loss: 0.26081445813179016
Epoch: 97/300 - Train loss: 0.263427197933197, Validation loss: 0.25846582651138306
Epoch: 98/300 - Train loss: 0.2613190710544586, Validation loss: 0.2566438913345337
Epoch: 99/300 - Train loss: 0.2592637836933136, Validation loss: 0.2541685104370117
Epoch: 100/300 - Train loss: 0.25725993514060974, Validation loss: 0.25207293033599854
Epoch: 101/300 - Train loss: 0.2553060054779053, Validation loss: 0.25074559450149536
Epoch: 102/300 - Train loss: 0.2534005641937256, Validation loss: 0.24894051253795624
Epoch: 103/300 - Train loss: 0.25154218077659607, Validation loss: 0.24661575257778168
Epoch: 104/300 - Train loss: 0.24972957372665405, Validation loss: 0.24509723484516144
Epoch: 105/300 - Train loss: 0.24796150624752045, Validation loss: 0.24348805844783783
Epoch: 106/300 - Train loss: 0.246236652135849, Validation loss: 0.241852805018425
Epoch: 107/300 - Train loss: 0.2445538341999054, Validation loss: 0.24011434614658356
Epoch: 108/300 - Train loss: 0.24291178584098816, Validation loss: 0.23859748244285583
Epoch: 109/300 - Train loss: 0.2413092851638794, Validation loss: 0.2369885891675949
Epoch: 110/300 - Train loss: 0.23974519968032837, Validation loss: 0.23602966964244843
Epoch: 111/300 - Train loss: 0.2382183074951172, Validation loss: 0.23401987552642822
Epoch: 112/300 - Train loss: 0.23672768473625183, Validation loss: 0.23272256553173065
Epoch: 113/300 - Train loss: 0.23527215421199799, Validation loss: 0.23128804564476013
Epoch: 114/300 - Train loss: 0.23385083675384521, Validation loss: 0.23018895089626312
Epoch: 115/300 - Train loss: 0.2324628084897995, Validation loss: 0.22844228148460388
Epoch: 116/300 - Train loss: 0.23110710084438324, Validation loss: 0.22744832932949066
Epoch: 117/300 - Train loss: 0.2297828197479248, Validation loss: 0.22654792666435242
Epoch: 118/300 - Train loss: 0.22848911583423615, Validation loss: 0.22475001215934753
Epoch: 119/300 - Train loss: 0.2272251844406128, Validation loss: 0.22357292473316193
Epoch: 120/300 - Train loss: 0.22599011659622192, Validation loss: 0.222559854388237
Epoch: 121/300 - Train loss: 0.22478313744068146, Validation loss: 0.22147955000400543
Epoch: 122/300 - Train loss: 0.22360344231128693, Validation loss: 0.2202681601047516
Epoch: 123/300 - Train loss: 0.2224503457546234, Validation loss: 0.21924428641796112
Epoch: 124/300 - Train loss: 0.22132299840450287, Validation loss: 0.2177310287952423
Epoch: 125/300 - Train loss: 0.2202206701040268, Validation loss: 0.2174985557794571
Epoch: 126/300 - Train loss: 0.21914274990558624, Validation loss: 0.21590596437454224
Epoch: 127/300 - Train loss: 0.2180885672569275, Validation loss: 0.21514122188091278
Epoch: 128/300 - Train loss: 0.2170574814081192, Validation loss: 0.21454600989818573
Epoch: 129/300 - Train loss: 0.21604889631271362, Validation loss: 0.21307729184627533
Epoch: 130/300 - Train loss: 0.21506215631961823, Validation loss: 0.21198903024196625
Epoch: 131/300 - Train loss: 0.21409673988819122, Validation loss: 0.21209558844566345
Epoch: 132/300 - Train loss: 0.2131519913673401, Validation loss: 0.21078738570213318
Epoch: 133/300 - Train loss: 0.21222729980945587, Validation loss: 0.2099844515323639
Epoch: 134/300 - Train loss: 0.21132218837738037, Validation loss: 0.2090398073196411
Epoch: 135/300 - Train loss: 0.2104361206293106, Validation loss: 0.20776312053203583
Epoch: 136/300 - Train loss: 0.20956864953041077, Validation loss: 0.20736455917358398
Epoch: 137/300 - Train loss: 0.2087191641330719, Validation loss: 0.20645126700401306
Epoch: 138/300 - Train loss: 0.2078872174024582, Validation loss: 0.20552648603916168
Epoch: 139/300 - Train loss: 0.20707236230373383, Validation loss: 0.20473894476890564
Epoch: 140/300 - Train loss: 0.20627419650554657, Validation loss: 0.20464973151683807
Epoch: 141/300 - Train loss: 0.205492302775383, Validation loss: 0.20341691374778748
Epoch: 142/300 - Train loss: 0.20472624897956848, Validation loss: 0.20284050703048706
Epoch: 143/300 - Train loss: 0.2039756327867508, Validation loss: 0.20255960524082184
Epoch: 144/300 - Train loss: 0.20324011147022247, Validation loss: 0.2019345462322235
Epoch: 145/300 - Train loss: 0.2025192379951477, Validation loss: 0.2007695436477661
Epoch: 146/300 - Train loss: 0.20181268453598022, Validation loss: 0.20052523910999298
Epoch: 147/300 - Train loss: 0.201120063662529, Validation loss: 0.19987058639526367
Epoch: 148/300 - Train loss: 0.20044100284576416, Validation loss: 0.19908708333969116
Epoch: 149/300 - Train loss: 0.19977512955665588, Validation loss: 0.19863729178905487
Epoch: 150/300 - Train loss: 0.1991221308708191, Validation loss: 0.19792519509792328
Epoch: 151/300 - Train loss: 0.1984817087650299, Validation loss: 0.19690832495689392
Epoch: 152/300 - Train loss: 0.19785359501838684, Validation loss: 0.19710950553417206
Epoch: 153/300 - Train loss: 0.19723735749721527, Validation loss: 0.1964857131242752
Epoch: 154/300 - Train loss: 0.19663283228874207, Validation loss: 0.1953376680612564
Epoch: 155/300 - Train loss: 0.19603967666625977, Validation loss: 0.19488093256950378
Epoch: 156/300 - Train loss: 0.19545765221118927, Validation loss: 0.19462081789970398
Epoch: 157/300 - Train loss: 0.1948864758014679, Validation loss: 0.1939660906791687
Epoch: 158/300 - Train loss: 0.19432587921619415, Validation loss: 0.19316524267196655
Epoch: 159/300 - Train loss: 0.19377568364143372, Validation loss: 0.19286182522773743
Epoch: 160/300 - Train loss: 0.19323568046092987, Validation loss: 0.19225338101387024
