Epoch: 1/300 - Train loss: 0.7033580541610718, Validation loss: 0.7024983763694763
Epoch: 2/300 - Train loss: 0.7005290985107422, Validation loss: 0.699680507183075
Epoch: 3/300 - Train loss: 0.6978023648262024, Validation loss: 0.6971119046211243
Epoch: 4/300 - Train loss: 0.695125162601471, Validation loss: 0.6941364407539368
Epoch: 5/300 - Train loss: 0.692444920539856, Validation loss: 0.6917184591293335
Epoch: 6/300 - Train loss: 0.6897163391113281, Validation loss: 0.6886240243911743
Epoch: 7/300 - Train loss: 0.6868892312049866, Validation loss: 0.6857653856277466
Epoch: 8/300 - Train loss: 0.6839331984519958, Validation loss: 0.682742714881897
Epoch: 9/300 - Train loss: 0.6808209419250488, Validation loss: 0.6792529821395874
Epoch: 10/300 - Train loss: 0.67754065990448, Validation loss: 0.675719141960144
Epoch: 11/300 - Train loss: 0.6740847229957581, Validation loss: 0.6722227931022644
Epoch: 12/300 - Train loss: 0.6704508662223816, Validation loss: 0.6683939099311829
Epoch: 13/300 - Train loss: 0.666641354560852, Validation loss: 0.6644933223724365
Epoch: 14/300 - Train loss: 0.6626656651496887, Validation loss: 0.6602492332458496
Epoch: 15/300 - Train loss: 0.6585303544998169, Validation loss: 0.6560052037239075
Epoch: 16/300 - Train loss: 0.6542451977729797, Validation loss: 0.6517112255096436
Epoch: 17/300 - Train loss: 0.6498274803161621, Validation loss: 0.6471109986305237
Epoch: 18/300 - Train loss: 0.645291268825531, Validation loss: 0.642477810382843
Epoch: 19/300 - Train loss: 0.6406549215316772, Validation loss: 0.6377265453338623
Epoch: 20/300 - Train loss: 0.6359391212463379, Validation loss: 0.6330519318580627
Epoch: 21/300 - Train loss: 0.631157636642456, Validation loss: 0.6284341216087341
Epoch: 22/300 - Train loss: 0.626329779624939, Validation loss: 0.6234995722770691
Epoch: 23/300 - Train loss: 0.6214714646339417, Validation loss: 0.6185329556465149
Epoch: 24/300 - Train loss: 0.6165922284126282, Validation loss: 0.6137571930885315
Epoch: 25/300 - Train loss: 0.6117061972618103, Validation loss: 0.6087964773178101
Epoch: 26/300 - Train loss: 0.6068142056465149, Validation loss: 0.6040599942207336
Epoch: 27/300 - Train loss: 0.6019169092178345, Validation loss: 0.5992113947868347
Epoch: 28/300 - Train loss: 0.5970146059989929, Validation loss: 0.5943233370780945
Epoch: 29/300 - Train loss: 0.5921074151992798, Validation loss: 0.5892638564109802
Epoch: 30/300 - Train loss: 0.5871954560279846, Validation loss: 0.5844623446464539
Epoch: 31/300 - Train loss: 0.5822770595550537, Validation loss: 0.5793631076812744
Epoch: 32/300 - Train loss: 0.5773521065711975, Validation loss: 0.5746515393257141
Epoch: 33/300 - Train loss: 0.5724213719367981, Validation loss: 0.5698911547660828
Epoch: 34/300 - Train loss: 0.5674868226051331, Validation loss: 0.5648298859596252
Epoch: 35/300 - Train loss: 0.5625481009483337, Validation loss: 0.559837818145752
Epoch: 36/300 - Train loss: 0.557608962059021, Validation loss: 0.5546965599060059
Epoch: 37/300 - Train loss: 0.5526682138442993, Validation loss: 0.5497270822525024
Epoch: 38/300 - Train loss: 0.5477294921875, Validation loss: 0.5450429916381836
Epoch: 39/300 - Train loss: 0.5427998900413513, Validation loss: 0.5399714112281799
Epoch: 40/300 - Train loss: 0.5378870368003845, Validation loss: 0.5351850390434265
Epoch: 41/300 - Train loss: 0.532997727394104, Validation loss: 0.5301236510276794
Epoch: 42/300 - Train loss: 0.5281442403793335, Validation loss: 0.5252772569656372
Epoch: 43/300 - Train loss: 0.5233331918716431, Validation loss: 0.5204113125801086
Epoch: 44/300 - Train loss: 0.5185729265213013, Validation loss: 0.5156666040420532
Epoch: 45/300 - Train loss: 0.5138712525367737, Validation loss: 0.5110893249511719
Epoch: 46/300 - Train loss: 0.5092354416847229, Validation loss: 0.506127655506134
Epoch: 47/300 - Train loss: 0.5046678781509399, Validation loss: 0.5020647644996643
Epoch: 48/300 - Train loss: 0.5001726150512695, Validation loss: 0.4971363842487335
Epoch: 49/300 - Train loss: 0.4957493543624878, Validation loss: 0.4927891194820404
Epoch: 50/300 - Train loss: 0.49139904975891113, Validation loss: 0.48894092440605164
Epoch: 51/300 - Train loss: 0.48712092638015747, Validation loss: 0.48456159234046936
Epoch: 52/300 - Train loss: 0.4829130470752716, Validation loss: 0.4801042079925537
Epoch: 53/300 - Train loss: 0.4787760376930237, Validation loss: 0.4758419692516327
Epoch: 54/300 - Train loss: 0.4747098386287689, Validation loss: 0.4722895920276642
Epoch: 55/300 - Train loss: 0.47071439027786255, Validation loss: 0.4681255519390106
Epoch: 56/300 - Train loss: 0.46679025888442993, Validation loss: 0.46463948488235474
Epoch: 57/300 - Train loss: 0.4629381000995636, Validation loss: 0.46032965183258057
Epoch: 58/300 - Train loss: 0.4591582119464874, Validation loss: 0.45657289028167725
Epoch: 59/300 - Train loss: 0.45545095205307007, Validation loss: 0.453070729970932
Epoch: 60/300 - Train loss: 0.45181629061698914, Validation loss: 0.44920825958251953
Epoch: 61/300 - Train loss: 0.44825479388237, Validation loss: 0.4454885423183441
Epoch: 62/300 - Train loss: 0.44476643204689026, Validation loss: 0.4430023431777954
Epoch: 63/300 - Train loss: 0.4413509666919708, Validation loss: 0.4388933777809143
Epoch: 64/300 - Train loss: 0.43800780177116394, Validation loss: 0.4355575442314148
Epoch: 65/300 - Train loss: 0.4347362518310547, Validation loss: 0.4321405291557312
Epoch: 66/300 - Train loss: 0.4315350651741028, Validation loss: 0.42930272221565247
Epoch: 67/300 - Train loss: 0.42840391397476196, Validation loss: 0.4260821044445038
Epoch: 68/300 - Train loss: 0.4253419041633606, Validation loss: 0.42276108264923096
Epoch: 69/300 - Train loss: 0.4223480522632599, Validation loss: 0.42017799615859985
Epoch: 70/300 - Train loss: 0.4194210469722748, Validation loss: 0.4173314869403839
Epoch: 71/300 - Train loss: 0.4165602922439575, Validation loss: 0.414786159992218
Epoch: 72/300 - Train loss: 0.4137646555900574, Validation loss: 0.41158849000930786
Epoch: 73/300 - Train loss: 0.4110325872898102, Validation loss: 0.40880095958709717
Epoch: 74/300 - Train loss: 0.4083622694015503, Validation loss: 0.4067072570323944
Epoch: 75/300 - Train loss: 0.40575236082077026, Validation loss: 0.4038078784942627
Epoch: 76/300 - Train loss: 0.40320146083831787, Validation loss: 0.4010954201221466
Epoch: 77/300 - Train loss: 0.4007083475589752, Validation loss: 0.3981824517250061
Epoch: 78/300 - Train loss: 0.3982713222503662, Validation loss: 0.3963407874107361
Epoch: 79/300 - Train loss: 0.39588868618011475, Validation loss: 0.39405423402786255
Epoch: 80/300 - Train loss: 0.3935592770576477, Validation loss: 0.39114052057266235
Epoch: 81/300 - Train loss: 0.3912821114063263, Validation loss: 0.3893182873725891
Epoch: 82/300 - Train loss: 0.38905593752861023, Validation loss: 0.38721713423728943
Epoch: 83/300 - Train loss: 0.3868787884712219, Validation loss: 0.384801983833313
Epoch: 84/300 - Train loss: 0.38475000858306885, Validation loss: 0.3830244541168213
Epoch: 85/300 - Train loss: 0.38266804814338684, Validation loss: 0.38085052371025085
Epoch: 86/300 - Train loss: 0.38063156604766846, Validation loss: 0.3788190186023712
Epoch: 87/300 - Train loss: 0.37863922119140625, Validation loss: 0.37696656584739685
Epoch: 88/300 - Train loss: 0.37668943405151367, Validation loss: 0.3744410276412964
Epoch: 89/300 - Train loss: 0.37478071451187134, Validation loss: 0.3727312982082367
Epoch: 90/300 - Train loss: 0.37291210889816284, Validation loss: 0.3709508776664734
Epoch: 91/300 - Train loss: 0.37108299136161804, Validation loss: 0.36920222640037537
Epoch: 92/300 - Train loss: 0.3692922592163086, Validation loss: 0.3673393428325653
Epoch: 93/300 - Train loss: 0.3675380349159241, Validation loss: 0.3659813404083252
Epoch: 94/300 - Train loss: 0.36582040786743164, Validation loss: 0.3638014495372772
Epoch: 95/300 - Train loss: 0.3641381561756134, Validation loss: 0.3624279201030731
Epoch: 96/300 - Train loss: 0.36248978972435, Validation loss: 0.3605107367038727
Epoch: 97/300 - Train loss: 0.3608739376068115, Validation loss: 0.3586702048778534
Epoch: 98/300 - Train loss: 0.359289288520813, Validation loss: 0.35740044713020325
Epoch: 99/300 - Train loss: 0.3577343225479126, Validation loss: 0.3562798798084259
Epoch: 100/300 - Train loss: 0.3562094271183014, Validation loss: 0.35447075963020325
Epoch: 101/300 - Train loss: 0.35471343994140625, Validation loss: 0.35298919677734375
Epoch: 102/300 - Train loss: 0.3532453179359436, Validation loss: 0.3513994514942169
Epoch: 103/300 - Train loss: 0.35180458426475525, Validation loss: 0.3500184714794159
Epoch: 104/300 - Train loss: 0.3503901958465576, Validation loss: 0.3485010862350464
Epoch: 105/300 - Train loss: 0.3490014970302582, Validation loss: 0.34725654125213623
Epoch: 106/300 - Train loss: 0.34763771295547485, Validation loss: 0.3456716537475586
Epoch: 107/300 - Train loss: 0.3462976813316345, Validation loss: 0.34480977058410645
Epoch: 108/300 - Train loss: 0.34498006105422974, Validation loss: 0.3438359498977661
Epoch: 109/300 - Train loss: 0.3436841666698456, Validation loss: 0.34195026755332947
Epoch: 110/300 - Train loss: 0.3424100875854492, Validation loss: 0.340658038854599
Epoch: 111/300 - Train loss: 0.34115827083587646, Validation loss: 0.3392624258995056
Epoch: 112/300 - Train loss: 0.33992791175842285, Validation loss: 0.3378470838069916
Epoch: 113/300 - Train loss: 0.33871838450431824, Validation loss: 0.3368869721889496
Epoch: 114/300 - Train loss: 0.3375282287597656, Validation loss: 0.33574262261390686
Epoch: 115/300 - Train loss: 0.33635807037353516, Validation loss: 0.33449122309684753
Epoch: 116/300 - Train loss: 0.33520781993865967, Validation loss: 0.3337934613227844
Epoch: 117/300 - Train loss: 0.33407557010650635, Validation loss: 0.331845223903656
Epoch: 118/300 - Train loss: 0.332960307598114, Validation loss: 0.3313700556755066
Epoch: 119/300 - Train loss: 0.3318629562854767, Validation loss: 0.3298770785331726
Epoch: 120/300 - Train loss: 0.3307828903198242, Validation loss: 0.32913321256637573
Epoch: 121/300 - Train loss: 0.3297201991081238, Validation loss: 0.3281475305557251
Epoch: 122/300 - Train loss: 0.32867431640625, Validation loss: 0.3268454372882843
Epoch: 123/300 - Train loss: 0.32764390110969543, Validation loss: 0.3256208300590515
Epoch: 124/300 - Train loss: 0.32662925124168396, Validation loss: 0.324527382850647
Epoch: 125/300 - Train loss: 0.3256288170814514, Validation loss: 0.32409578561782837
Epoch: 126/300 - Train loss: 0.32464268803596497, Validation loss: 0.3226877748966217
Epoch: 127/300 - Train loss: 0.32367104291915894, Validation loss: 0.32192912697792053
Epoch: 128/300 - Train loss: 0.3227139115333557, Validation loss: 0.3204972743988037
Epoch: 129/300 - Train loss: 0.32177042961120605, Validation loss: 0.32052263617515564
Epoch: 130/300 - Train loss: 0.32083964347839355, Validation loss: 0.319061279296875
Epoch: 131/300 - Train loss: 0.3199211657047272, Validation loss: 0.317978173494339
Epoch: 132/300 - Train loss: 0.31901487708091736, Validation loss: 0.3171350359916687
Epoch: 133/300 - Train loss: 0.3181205987930298, Validation loss: 0.3164339065551758
Epoch: 134/300 - Train loss: 0.317238450050354, Validation loss: 0.31557223200798035
Epoch: 135/300 - Train loss: 0.3163672685623169, Validation loss: 0.31476330757141113
Epoch: 136/300 - Train loss: 0.31550827622413635, Validation loss: 0.31382647156715393
Epoch: 137/300 - Train loss: 0.3146611154079437, Validation loss: 0.3136502504348755
Epoch: 138/300 - Train loss: 0.31382516026496887, Validation loss: 0.31234800815582275
Epoch: 139/300 - Train loss: 0.3129993975162506, Validation loss: 0.31143009662628174
Epoch: 140/300 - Train loss: 0.3121832609176636, Validation loss: 0.31046485900878906
Epoch: 141/300 - Train loss: 0.31137678027153015, Validation loss: 0.3095981478691101
Epoch: 142/300 - Train loss: 0.31057921051979065, Validation loss: 0.30921682715415955
Epoch: 143/300 - Train loss: 0.3097906708717346, Validation loss: 0.3083994388580322
Epoch: 144/300 - Train loss: 0.30901187658309937, Validation loss: 0.30763131380081177
Epoch: 145/300 - Train loss: 0.30824142694473267, Validation loss: 0.3066498339176178
Epoch: 146/300 - Train loss: 0.3074796199798584, Validation loss: 0.3057042956352234
Epoch: 147/300 - Train loss: 0.3067263066768646, Validation loss: 0.3054833710193634
Epoch: 148/300 - Train loss: 0.3059813976287842, Validation loss: 0.3045599162578583
Epoch: 149/300 - Train loss: 0.30524513125419617, Validation loss: 0.30333319306373596
Epoch: 150/300 - Train loss: 0.30451664328575134, Validation loss: 0.30336880683898926
Epoch: 151/300 - Train loss: 0.303795725107193, Validation loss: 0.30249929428100586
Epoch: 152/300 - Train loss: 0.30308160185813904, Validation loss: 0.3013920187950134
Epoch: 153/300 - Train loss: 0.30237430334091187, Validation loss: 0.30114537477493286
Epoch: 154/300 - Train loss: 0.30167484283447266, Validation loss: 0.30031734704971313
Epoch: 155/300 - Train loss: 0.3009827136993408, Validation loss: 0.3000245690345764
Epoch: 156/300 - Train loss: 0.300298810005188, Validation loss: 0.2984282076358795
Epoch: 157/300 - Train loss: 0.2996230125427246, Validation loss: 0.29825419187545776
Epoch: 158/300 - Train loss: 0.29895514249801636, Validation loss: 0.29774367809295654
Epoch: 159/300 - Train loss: 0.2982936203479767, Validation loss: 0.29708003997802734
Epoch: 160/300 - Train loss: 0.29763802886009216, Validation loss: 0.2963622212409973
Epoch: 161/300 - Train loss: 0.29698824882507324, Validation loss: 0.29666608572006226
Epoch: 162/300 - Train loss: 0.2963440716266632, Validation loss: 0.29500699043273926
Epoch: 163/300 - Train loss: 0.2957065999507904, Validation loss: 0.2953503727912903
Epoch: 164/300 - Train loss: 0.29507550597190857, Validation loss: 0.29419100284576416
Epoch: 165/300 - Train loss: 0.29445022344589233, Validation loss: 0.29362544417381287
