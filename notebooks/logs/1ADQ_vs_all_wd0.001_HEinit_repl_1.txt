Epoch: 1/300 - Train loss: 0.6936832070350647, Validation loss: 0.6918303370475769
Epoch: 2/300 - Train loss: 0.6922289729118347, Validation loss: 0.6904786825180054
Epoch: 3/300 - Train loss: 0.690816342830658, Validation loss: 0.6891245245933533
Epoch: 4/300 - Train loss: 0.6894314885139465, Validation loss: 0.687730073928833
Epoch: 5/300 - Train loss: 0.6880595684051514, Validation loss: 0.686381995677948
Epoch: 6/300 - Train loss: 0.6866831183433533, Validation loss: 0.6850045323371887
Epoch: 7/300 - Train loss: 0.6852930188179016, Validation loss: 0.6836615204811096
Epoch: 8/300 - Train loss: 0.6838791966438293, Validation loss: 0.6822315454483032
Epoch: 9/300 - Train loss: 0.6824312210083008, Validation loss: 0.680666446685791
Epoch: 10/300 - Train loss: 0.6809384822845459, Validation loss: 0.6792154908180237
Epoch: 11/300 - Train loss: 0.67939293384552, Validation loss: 0.6775006651878357
Epoch: 12/300 - Train loss: 0.677788496017456, Validation loss: 0.6758496761322021
Epoch: 13/300 - Train loss: 0.6761233806610107, Validation loss: 0.6741268038749695
Epoch: 14/300 - Train loss: 0.6743904948234558, Validation loss: 0.6723732948303223
Epoch: 15/300 - Train loss: 0.6725918650627136, Validation loss: 0.67047119140625
Epoch: 16/300 - Train loss: 0.6707273125648499, Validation loss: 0.6685949563980103
Epoch: 17/300 - Train loss: 0.6687957048416138, Validation loss: 0.6665799617767334
Epoch: 18/300 - Train loss: 0.6668049693107605, Validation loss: 0.6646124720573425
Epoch: 19/300 - Train loss: 0.6647555828094482, Validation loss: 0.6624817848205566
Epoch: 20/300 - Train loss: 0.6626477241516113, Validation loss: 0.6604453325271606
Epoch: 21/300 - Train loss: 0.6604852676391602, Validation loss: 0.6582274436950684
Epoch: 22/300 - Train loss: 0.658273458480835, Validation loss: 0.6559088230133057
Epoch: 23/300 - Train loss: 0.6560149192810059, Validation loss: 0.6536640524864197
Epoch: 24/300 - Train loss: 0.6537110209465027, Validation loss: 0.6515292525291443
Epoch: 25/300 - Train loss: 0.6513658165931702, Validation loss: 0.6490232944488525
Epoch: 26/300 - Train loss: 0.6489810347557068, Validation loss: 0.6468397378921509
Epoch: 27/300 - Train loss: 0.6465571522712708, Validation loss: 0.6442691683769226
Epoch: 28/300 - Train loss: 0.6440953612327576, Validation loss: 0.6418429017066956
Epoch: 29/300 - Train loss: 0.6415991187095642, Validation loss: 0.6393113732337952
Epoch: 30/300 - Train loss: 0.6390674114227295, Validation loss: 0.6367075443267822
Epoch: 31/300 - Train loss: 0.6365051865577698, Validation loss: 0.6342917680740356
Epoch: 32/300 - Train loss: 0.633915901184082, Validation loss: 0.6315403580665588
Epoch: 33/300 - Train loss: 0.6313018798828125, Validation loss: 0.6295250058174133
Epoch: 34/300 - Train loss: 0.6286652088165283, Validation loss: 0.6266013383865356
Epoch: 35/300 - Train loss: 0.6260061264038086, Validation loss: 0.6240915060043335
Epoch: 36/300 - Train loss: 0.6233263611793518, Validation loss: 0.6212301254272461
Epoch: 37/300 - Train loss: 0.6206285357475281, Validation loss: 0.6187076568603516
Epoch: 38/300 - Train loss: 0.6179175972938538, Validation loss: 0.6159900426864624
Epoch: 39/300 - Train loss: 0.6151940822601318, Validation loss: 0.613186240196228
Epoch: 40/300 - Train loss: 0.6124570369720459, Validation loss: 0.6105266809463501
Epoch: 41/300 - Train loss: 0.6097121238708496, Validation loss: 0.6079391837120056
Epoch: 42/300 - Train loss: 0.6069624423980713, Validation loss: 0.6050484776496887
Epoch: 43/300 - Train loss: 0.6042088866233826, Validation loss: 0.6026891469955444
Epoch: 44/300 - Train loss: 0.6014518737792969, Validation loss: 0.5997896194458008
Epoch: 45/300 - Train loss: 0.5986961126327515, Validation loss: 0.5971804261207581
Epoch: 46/300 - Train loss: 0.5959471464157104, Validation loss: 0.59450763463974
Epoch: 47/300 - Train loss: 0.5932067632675171, Validation loss: 0.591621994972229
Epoch: 48/300 - Train loss: 0.5904760360717773, Validation loss: 0.5890737175941467
Epoch: 49/300 - Train loss: 0.5877586603164673, Validation loss: 0.5866823196411133
Epoch: 50/300 - Train loss: 0.5850577354431152, Validation loss: 0.5841569304466248
Epoch: 51/300 - Train loss: 0.5823765993118286, Validation loss: 0.5813538432121277
Epoch: 52/300 - Train loss: 0.5797174572944641, Validation loss: 0.5789171457290649
Epoch: 53/300 - Train loss: 0.5770848989486694, Validation loss: 0.5766886472702026
Epoch: 54/300 - Train loss: 0.5744801163673401, Validation loss: 0.5740534067153931
Epoch: 55/300 - Train loss: 0.5719044804573059, Validation loss: 0.5717178583145142
Epoch: 56/300 - Train loss: 0.5693601965904236, Validation loss: 0.5691599249839783
Epoch: 57/300 - Train loss: 0.5668480396270752, Validation loss: 0.5668491125106812
Epoch: 58/300 - Train loss: 0.5643708109855652, Validation loss: 0.5644742846488953
Epoch: 59/300 - Train loss: 0.5619326829910278, Validation loss: 0.5624188780784607
Epoch: 60/300 - Train loss: 0.5595343112945557, Validation loss: 0.5599236488342285
Epoch: 61/300 - Train loss: 0.5571780800819397, Validation loss: 0.5580637454986572
Epoch: 62/300 - Train loss: 0.5548643469810486, Validation loss: 0.5556702613830566
Epoch: 63/300 - Train loss: 0.5525938272476196, Validation loss: 0.5538884997367859
Epoch: 64/300 - Train loss: 0.5503685474395752, Validation loss: 0.5518578886985779
Epoch: 65/300 - Train loss: 0.5481889843940735, Validation loss: 0.5493379831314087
Epoch: 66/300 - Train loss: 0.5460551381111145, Validation loss: 0.5475436449050903
Epoch: 67/300 - Train loss: 0.5439680218696594, Validation loss: 0.5459513068199158
Epoch: 68/300 - Train loss: 0.5419290065765381, Validation loss: 0.5438672304153442
Epoch: 69/300 - Train loss: 0.5399375557899475, Validation loss: 0.542422890663147
Epoch: 70/300 - Train loss: 0.537994384765625, Validation loss: 0.5401462316513062
Epoch: 71/300 - Train loss: 0.536098837852478, Validation loss: 0.5384839177131653
Epoch: 72/300 - Train loss: 0.5342506766319275, Validation loss: 0.5373080968856812
Epoch: 73/300 - Train loss: 0.5324492454528809, Validation loss: 0.5351157784461975
Epoch: 74/300 - Train loss: 0.5306942462921143, Validation loss: 0.5338609218597412
Epoch: 75/300 - Train loss: 0.5289867520332336, Validation loss: 0.5320608615875244
Epoch: 76/300 - Train loss: 0.527325451374054, Validation loss: 0.5307942032814026
Epoch: 77/300 - Train loss: 0.5257103443145752, Validation loss: 0.5297254323959351
Epoch: 78/300 - Train loss: 0.5241402983665466, Validation loss: 0.5280050039291382
Epoch: 79/300 - Train loss: 0.5226136445999146, Validation loss: 0.5266059041023254
Epoch: 80/300 - Train loss: 0.5211313962936401, Validation loss: 0.5251743197441101
Epoch: 81/300 - Train loss: 0.519692599773407, Validation loss: 0.5236557722091675
Epoch: 82/300 - Train loss: 0.5182957649230957, Validation loss: 0.5226788520812988
Epoch: 83/300 - Train loss: 0.5169404149055481, Validation loss: 0.521680474281311
Epoch: 84/300 - Train loss: 0.5156242847442627, Validation loss: 0.5200121402740479
Epoch: 85/300 - Train loss: 0.5143457651138306, Validation loss: 0.5201555490493774
Epoch: 86/300 - Train loss: 0.5131040215492249, Validation loss: 0.517896831035614
Epoch: 87/300 - Train loss: 0.5118978023529053, Validation loss: 0.5172743797302246
Epoch: 88/300 - Train loss: 0.5107252597808838, Validation loss: 0.515933096408844
Epoch: 89/300 - Train loss: 0.5095852613449097, Validation loss: 0.5153988003730774
Epoch: 90/300 - Train loss: 0.5084765553474426, Validation loss: 0.514141321182251
Epoch: 91/300 - Train loss: 0.5073977708816528, Validation loss: 0.5126080513000488
Epoch: 92/300 - Train loss: 0.5063488483428955, Validation loss: 0.512142539024353
Epoch: 93/300 - Train loss: 0.505328357219696, Validation loss: 0.5113422274589539
Epoch: 94/300 - Train loss: 0.5043337941169739, Validation loss: 0.5101069808006287
Epoch: 95/300 - Train loss: 0.5033642053604126, Validation loss: 0.5094166398048401
Epoch: 96/300 - Train loss: 0.502417802810669, Validation loss: 0.5084560513496399
Epoch: 97/300 - Train loss: 0.5014930963516235, Validation loss: 0.5077798962593079
Epoch: 98/300 - Train loss: 0.5005900263786316, Validation loss: 0.5069774389266968
Epoch: 99/300 - Train loss: 0.49970686435699463, Validation loss: 0.5054935812950134
Epoch: 100/300 - Train loss: 0.49884140491485596, Validation loss: 0.5057650208473206
Epoch: 101/300 - Train loss: 0.4979928731918335, Validation loss: 0.504712700843811
Epoch: 102/300 - Train loss: 0.4971590042114258, Validation loss: 0.504048764705658
Epoch: 103/300 - Train loss: 0.4963395595550537, Validation loss: 0.5025594830513
Epoch: 104/300 - Train loss: 0.4955344498157501, Validation loss: 0.502593994140625
Epoch: 105/300 - Train loss: 0.4947407841682434, Validation loss: 0.5014626383781433
Epoch: 106/300 - Train loss: 0.4939592480659485, Validation loss: 0.5009083151817322
Epoch: 107/300 - Train loss: 0.49318984150886536, Validation loss: 0.4998314380645752
Epoch: 108/300 - Train loss: 0.49243083596229553, Validation loss: 0.49915486574172974
Epoch: 109/300 - Train loss: 0.49168235063552856, Validation loss: 0.4988884925842285
Epoch: 110/300 - Train loss: 0.4909425675868988, Validation loss: 0.4980725944042206
Epoch: 111/300 - Train loss: 0.4902094304561615, Validation loss: 0.496811181306839
Epoch: 112/300 - Train loss: 0.48948341608047485, Validation loss: 0.49651432037353516
Epoch: 113/300 - Train loss: 0.48876458406448364, Validation loss: 0.4959852695465088
Epoch: 114/300 - Train loss: 0.4880511462688446, Validation loss: 0.49539774656295776
Epoch: 115/300 - Train loss: 0.4873422384262085, Validation loss: 0.4948015511035919
Epoch: 116/300 - Train loss: 0.48663726449012756, Validation loss: 0.494083970785141
Epoch: 117/300 - Train loss: 0.4859382212162018, Validation loss: 0.493344247341156
Epoch: 118/300 - Train loss: 0.4852459132671356, Validation loss: 0.49287816882133484
Epoch: 119/300 - Train loss: 0.4845570921897888, Validation loss: 0.49193093180656433
Epoch: 120/300 - Train loss: 0.4838710129261017, Validation loss: 0.49148598313331604
Epoch: 121/300 - Train loss: 0.48318687081336975, Validation loss: 0.4905380606651306
Epoch: 122/300 - Train loss: 0.48250526189804077, Validation loss: 0.48999637365341187
Epoch: 123/300 - Train loss: 0.4818279445171356, Validation loss: 0.48952504992485046
Epoch: 124/300 - Train loss: 0.4811539351940155, Validation loss: 0.4888317883014679
Epoch: 125/300 - Train loss: 0.4804821312427521, Validation loss: 0.48790380358695984
Epoch: 126/300 - Train loss: 0.4798114597797394, Validation loss: 0.4871765971183777
Epoch: 127/300 - Train loss: 0.47914400696754456, Validation loss: 0.4874206781387329
Epoch: 128/300 - Train loss: 0.4784797430038452, Validation loss: 0.48657310009002686
Epoch: 129/300 - Train loss: 0.4778193235397339, Validation loss: 0.48525410890579224
Epoch: 130/300 - Train loss: 0.4771624207496643, Validation loss: 0.48525333404541016
Epoch: 131/300 - Train loss: 0.4765079617500305, Validation loss: 0.48362815380096436
Epoch: 132/300 - Train loss: 0.4758564531803131, Validation loss: 0.48354288935661316
Epoch: 133/300 - Train loss: 0.4752075672149658, Validation loss: 0.4826819896697998
Epoch: 134/300 - Train loss: 0.47456124424934387, Validation loss: 0.48266124725341797
Epoch: 135/300 - Train loss: 0.473919540643692, Validation loss: 0.48193204402923584
Epoch: 136/300 - Train loss: 0.47328075766563416, Validation loss: 0.481178343296051
Epoch: 137/300 - Train loss: 0.47264543175697327, Validation loss: 0.4808124005794525
Epoch: 138/300 - Train loss: 0.4720110595226288, Validation loss: 0.4799838960170746
Epoch: 139/300 - Train loss: 0.4713778495788574, Validation loss: 0.4793136715888977
Epoch: 140/300 - Train loss: 0.47074609994888306, Validation loss: 0.4792574942111969
