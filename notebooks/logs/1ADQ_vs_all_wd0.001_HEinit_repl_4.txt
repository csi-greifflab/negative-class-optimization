Epoch: 1/300 - Train loss: 0.696421205997467, Validation loss: 0.6943203210830688
Epoch: 2/300 - Train loss: 0.6951978802680969, Validation loss: 0.6932675838470459
Epoch: 3/300 - Train loss: 0.693956196308136, Validation loss: 0.6920498013496399
Epoch: 4/300 - Train loss: 0.6926896572113037, Validation loss: 0.6908900737762451
Epoch: 5/300 - Train loss: 0.6913964152336121, Validation loss: 0.6897537112236023
Epoch: 6/300 - Train loss: 0.6900724768638611, Validation loss: 0.6884424090385437
Epoch: 7/300 - Train loss: 0.6887159943580627, Validation loss: 0.6872194409370422
Epoch: 8/300 - Train loss: 0.6873281002044678, Validation loss: 0.685867965221405
Epoch: 9/300 - Train loss: 0.6859070658683777, Validation loss: 0.6845672130584717
Epoch: 10/300 - Train loss: 0.6844505667686462, Validation loss: 0.6832915544509888
Epoch: 11/300 - Train loss: 0.6829622387886047, Validation loss: 0.6818463206291199
Epoch: 12/300 - Train loss: 0.6814369559288025, Validation loss: 0.6804165244102478
Epoch: 13/300 - Train loss: 0.6798775792121887, Validation loss: 0.678942859172821
Epoch: 14/300 - Train loss: 0.678286075592041, Validation loss: 0.6775175929069519
Epoch: 15/300 - Train loss: 0.6766633987426758, Validation loss: 0.676058828830719
Epoch: 16/300 - Train loss: 0.6750133037567139, Validation loss: 0.6744861006736755
Epoch: 17/300 - Train loss: 0.67332923412323, Validation loss: 0.6728782653808594
Epoch: 18/300 - Train loss: 0.671615719795227, Validation loss: 0.6712397336959839
Epoch: 19/300 - Train loss: 0.6698697805404663, Validation loss: 0.6696228981018066
Epoch: 20/300 - Train loss: 0.6680960655212402, Validation loss: 0.6679809093475342
Epoch: 21/300 - Train loss: 0.6662933826446533, Validation loss: 0.666270911693573
Epoch: 22/300 - Train loss: 0.6644608974456787, Validation loss: 0.6645746827125549
Epoch: 23/300 - Train loss: 0.6625975966453552, Validation loss: 0.6627950072288513
Epoch: 24/300 - Train loss: 0.6607031226158142, Validation loss: 0.6611034274101257
Epoch: 25/300 - Train loss: 0.6587780714035034, Validation loss: 0.6591726541519165
Epoch: 26/300 - Train loss: 0.6568195223808289, Validation loss: 0.6573091745376587
Epoch: 27/300 - Train loss: 0.6548289656639099, Validation loss: 0.6556151509284973
Epoch: 28/300 - Train loss: 0.6528070569038391, Validation loss: 0.6536322832107544
Epoch: 29/300 - Train loss: 0.6507545709609985, Validation loss: 0.6516069173812866
Epoch: 30/300 - Train loss: 0.6486675143241882, Validation loss: 0.6495411992073059
Epoch: 31/300 - Train loss: 0.6465466022491455, Validation loss: 0.6475352644920349
Epoch: 32/300 - Train loss: 0.6443902254104614, Validation loss: 0.6456829309463501
Epoch: 33/300 - Train loss: 0.6421971917152405, Validation loss: 0.6436210870742798
Epoch: 34/300 - Train loss: 0.6399662494659424, Validation loss: 0.6414285898208618
Epoch: 35/300 - Train loss: 0.6377010345458984, Validation loss: 0.6392516493797302
Epoch: 36/300 - Train loss: 0.6354060173034668, Validation loss: 0.6372219324111938
Epoch: 37/300 - Train loss: 0.6330865621566772, Validation loss: 0.6349433064460754
Epoch: 38/300 - Train loss: 0.6307429075241089, Validation loss: 0.6326977014541626
Epoch: 39/300 - Train loss: 0.6283776760101318, Validation loss: 0.6306114196777344
Epoch: 40/300 - Train loss: 0.6259923577308655, Validation loss: 0.6280811429023743
Epoch: 41/300 - Train loss: 0.6235867738723755, Validation loss: 0.6257426738739014
Epoch: 42/300 - Train loss: 0.6211622357368469, Validation loss: 0.6236813068389893
Epoch: 43/300 - Train loss: 0.6187195777893066, Validation loss: 0.621313750743866
Epoch: 44/300 - Train loss: 0.6162639260292053, Validation loss: 0.6190740466117859
Epoch: 45/300 - Train loss: 0.6137956380844116, Validation loss: 0.6167010068893433
Epoch: 46/300 - Train loss: 0.611315906047821, Validation loss: 0.614052414894104
Epoch: 47/300 - Train loss: 0.6088262796401978, Validation loss: 0.6117143630981445
Epoch: 48/300 - Train loss: 0.6063312292098999, Validation loss: 0.6093788743019104
Epoch: 49/300 - Train loss: 0.6038301587104797, Validation loss: 0.6068546175956726
Epoch: 50/300 - Train loss: 0.6013267040252686, Validation loss: 0.604546308517456
Epoch: 51/300 - Train loss: 0.5988232493400574, Validation loss: 0.6024508476257324
Epoch: 52/300 - Train loss: 0.5963178277015686, Validation loss: 0.5998800992965698
Epoch: 53/300 - Train loss: 0.5938136577606201, Validation loss: 0.5973652005195618
Epoch: 54/300 - Train loss: 0.5913140773773193, Validation loss: 0.5952125787734985
Epoch: 55/300 - Train loss: 0.5888214111328125, Validation loss: 0.5925570130348206
Epoch: 56/300 - Train loss: 0.5863368511199951, Validation loss: 0.5903629064559937
Epoch: 57/300 - Train loss: 0.5838623642921448, Validation loss: 0.5880072116851807
Epoch: 58/300 - Train loss: 0.5813984870910645, Validation loss: 0.5857347249984741
Epoch: 59/300 - Train loss: 0.5789462924003601, Validation loss: 0.5834611058235168
Epoch: 60/300 - Train loss: 0.5765074491500854, Validation loss: 0.5814288258552551
Epoch: 61/300 - Train loss: 0.5740841627120972, Validation loss: 0.5790650844573975
Epoch: 62/300 - Train loss: 0.5716772079467773, Validation loss: 0.5770313739776611
Epoch: 63/300 - Train loss: 0.5692893862724304, Validation loss: 0.5745311379432678
Epoch: 64/300 - Train loss: 0.566920816898346, Validation loss: 0.5720664858818054
Epoch: 65/300 - Train loss: 0.5645754337310791, Validation loss: 0.5699650049209595
Epoch: 66/300 - Train loss: 0.5622546076774597, Validation loss: 0.5674839019775391
Epoch: 67/300 - Train loss: 0.5599578619003296, Validation loss: 0.5657529234886169
Epoch: 68/300 - Train loss: 0.5576860904693604, Validation loss: 0.5629150867462158
Epoch: 69/300 - Train loss: 0.5554412603378296, Validation loss: 0.5608857870101929
Epoch: 70/300 - Train loss: 0.5532225370407104, Validation loss: 0.559116780757904
Epoch: 71/300 - Train loss: 0.551032543182373, Validation loss: 0.5567049384117126
Epoch: 72/300 - Train loss: 0.5488711595535278, Validation loss: 0.5544998049736023
Epoch: 73/300 - Train loss: 0.5467386841773987, Validation loss: 0.5527260303497314
Epoch: 74/300 - Train loss: 0.5446344017982483, Validation loss: 0.5508559346199036
Epoch: 75/300 - Train loss: 0.5425601601600647, Validation loss: 0.5487075448036194
Epoch: 76/300 - Train loss: 0.5405168533325195, Validation loss: 0.5465796589851379
Epoch: 77/300 - Train loss: 0.5385050177574158, Validation loss: 0.5454055070877075
Epoch: 78/300 - Train loss: 0.5365243554115295, Validation loss: 0.5427640676498413
Epoch: 79/300 - Train loss: 0.5345755815505981, Validation loss: 0.5410728454589844
Epoch: 80/300 - Train loss: 0.5326586961746216, Validation loss: 0.539353609085083
Epoch: 81/300 - Train loss: 0.5307744741439819, Validation loss: 0.5381572246551514
Epoch: 82/300 - Train loss: 0.5289214253425598, Validation loss: 0.5355867743492126
Epoch: 83/300 - Train loss: 0.5271016359329224, Validation loss: 0.5340495705604553
Epoch: 84/300 - Train loss: 0.5253148078918457, Validation loss: 0.5323374271392822
Epoch: 85/300 - Train loss: 0.5235602259635925, Validation loss: 0.5301605463027954
Epoch: 86/300 - Train loss: 0.5218372344970703, Validation loss: 0.5286462306976318
Epoch: 87/300 - Train loss: 0.5201460123062134, Validation loss: 0.52735435962677
Epoch: 88/300 - Train loss: 0.5184860229492188, Validation loss: 0.5257042646408081
Epoch: 89/300 - Train loss: 0.5168565511703491, Validation loss: 0.5238612294197083
Epoch: 90/300 - Train loss: 0.5152568817138672, Validation loss: 0.5232542753219604
Epoch: 91/300 - Train loss: 0.5136868357658386, Validation loss: 0.5215635895729065
Epoch: 92/300 - Train loss: 0.5121456980705261, Validation loss: 0.5199825167655945
Epoch: 93/300 - Train loss: 0.5106323957443237, Validation loss: 0.5179444551467896
Epoch: 94/300 - Train loss: 0.5091466903686523, Validation loss: 0.5169577598571777
Epoch: 95/300 - Train loss: 0.507687509059906, Validation loss: 0.515612006187439
Epoch: 96/300 - Train loss: 0.5062543749809265, Validation loss: 0.5144433379173279
Epoch: 97/300 - Train loss: 0.5048465132713318, Validation loss: 0.5131713151931763
Epoch: 98/300 - Train loss: 0.5034639835357666, Validation loss: 0.5121088624000549
Epoch: 99/300 - Train loss: 0.5021053552627563, Validation loss: 0.5108112096786499
Epoch: 100/300 - Train loss: 0.5007694363594055, Validation loss: 0.5096739530563354
Epoch: 101/300 - Train loss: 0.4994557797908783, Validation loss: 0.5080280303955078
Epoch: 102/300 - Train loss: 0.4981640577316284, Validation loss: 0.5069095492362976
Epoch: 103/300 - Train loss: 0.4968937635421753, Validation loss: 0.5051916837692261
Epoch: 104/300 - Train loss: 0.49564412236213684, Validation loss: 0.5040650367736816
Epoch: 105/300 - Train loss: 0.49441418051719666, Validation loss: 0.503244161605835
Epoch: 106/300 - Train loss: 0.4932030439376831, Validation loss: 0.5016669631004333
Epoch: 107/300 - Train loss: 0.49201130867004395, Validation loss: 0.5010019540786743
Epoch: 108/300 - Train loss: 0.49083882570266724, Validation loss: 0.4992816150188446
Epoch: 109/300 - Train loss: 0.4896851181983948, Validation loss: 0.4985124468803406
Epoch: 110/300 - Train loss: 0.4885488450527191, Validation loss: 0.49826204776763916
Epoch: 111/300 - Train loss: 0.48742908239364624, Validation loss: 0.49667036533355713
Epoch: 112/300 - Train loss: 0.48632529377937317, Validation loss: 0.49548014998435974
Epoch: 113/300 - Train loss: 0.4852364957332611, Validation loss: 0.49421820044517517
Epoch: 114/300 - Train loss: 0.4841634929180145, Validation loss: 0.4940883219242096
Epoch: 115/300 - Train loss: 0.4831051826477051, Validation loss: 0.49267080426216125
Epoch: 116/300 - Train loss: 0.48206159472465515, Validation loss: 0.491879940032959
Epoch: 117/300 - Train loss: 0.4810328185558319, Validation loss: 0.4907824695110321
Epoch: 118/300 - Train loss: 0.48001742362976074, Validation loss: 0.48960062861442566
Epoch: 119/300 - Train loss: 0.4790150225162506, Validation loss: 0.4891833961009979
Epoch: 120/300 - Train loss: 0.4780248999595642, Validation loss: 0.4882850646972656
Epoch: 121/300 - Train loss: 0.47704723477363586, Validation loss: 0.4867096543312073
Epoch: 122/300 - Train loss: 0.47608163952827454, Validation loss: 0.48587849736213684
Epoch: 123/300 - Train loss: 0.4751281142234802, Validation loss: 0.48523518443107605
Epoch: 124/300 - Train loss: 0.4741859436035156, Validation loss: 0.4848158359527588
Epoch: 125/300 - Train loss: 0.47325530648231506, Validation loss: 0.48344478011131287
Epoch: 126/300 - Train loss: 0.4723358452320099, Validation loss: 0.48242148756980896
Epoch: 127/300 - Train loss: 0.47142747044563293, Validation loss: 0.48202261328697205
Epoch: 128/300 - Train loss: 0.4705277681350708, Validation loss: 0.48067569732666016
Epoch: 129/300 - Train loss: 0.46963679790496826, Validation loss: 0.480130672454834
Epoch: 130/300 - Train loss: 0.46875491738319397, Validation loss: 0.4792388677597046
Epoch: 131/300 - Train loss: 0.4678831398487091, Validation loss: 0.47867220640182495
Epoch: 132/300 - Train loss: 0.4670206904411316, Validation loss: 0.4780668318271637
Epoch: 133/300 - Train loss: 0.46616628766059875, Validation loss: 0.4767393469810486
Epoch: 134/300 - Train loss: 0.4653204083442688, Validation loss: 0.47643789649009705
Epoch: 135/300 - Train loss: 0.46448248624801636, Validation loss: 0.4759586751461029
Epoch: 136/300 - Train loss: 0.4636510908603668, Validation loss: 0.4743899405002594
Epoch: 137/300 - Train loss: 0.4628266990184784, Validation loss: 0.4739481508731842
Epoch: 138/300 - Train loss: 0.46200868487358093, Validation loss: 0.4729823172092438
Epoch: 139/300 - Train loss: 0.4611964225769043, Validation loss: 0.4726214110851288
Epoch: 140/300 - Train loss: 0.4603891968727112, Validation loss: 0.4717711806297302
Epoch: 141/300 - Train loss: 0.45958712697029114, Validation loss: 0.4709484875202179
Epoch: 142/300 - Train loss: 0.4587894678115845, Validation loss: 0.4705874025821686
Epoch: 143/300 - Train loss: 0.4579960107803345, Validation loss: 0.46964284777641296
Epoch: 144/300 - Train loss: 0.457206666469574, Validation loss: 0.46892204880714417
Epoch: 145/300 - Train loss: 0.45642074942588806, Validation loss: 0.46809443831443787
Epoch: 146/300 - Train loss: 0.45563939213752747, Validation loss: 0.46758031845092773
Epoch: 147/300 - Train loss: 0.45486021041870117, Validation loss: 0.46652427315711975
Epoch: 148/300 - Train loss: 0.45408377051353455, Validation loss: 0.46572068333625793
Epoch: 149/300 - Train loss: 0.4533105194568634, Validation loss: 0.4651808738708496
Epoch: 150/300 - Train loss: 0.45253974199295044, Validation loss: 0.4643620550632477
Epoch: 151/300 - Train loss: 0.4517725706100464, Validation loss: 0.4637831449508667
Epoch: 152/300 - Train loss: 0.45100870728492737, Validation loss: 0.4636605679988861
Epoch: 153/300 - Train loss: 0.4502471387386322, Validation loss: 0.4628693759441376
Epoch: 154/300 - Train loss: 0.44948771595954895, Validation loss: 0.46209096908569336
Epoch: 155/300 - Train loss: 0.4487312436103821, Validation loss: 0.4612639546394348
Epoch: 156/300 - Train loss: 0.44797730445861816, Validation loss: 0.4601481556892395
Epoch: 157/300 - Train loss: 0.44722697138786316, Validation loss: 0.4602155387401581
Epoch: 158/300 - Train loss: 0.4464804530143738, Validation loss: 0.45900291204452515
Epoch: 159/300 - Train loss: 0.4457376301288605, Validation loss: 0.4582338035106659
Epoch: 160/300 - Train loss: 0.44499707221984863, Validation loss: 0.45778512954711914
Epoch: 161/300 - Train loss: 0.44425827264785767, Validation loss: 0.45693492889404297
Epoch: 162/300 - Train loss: 0.44352102279663086, Validation loss: 0.4559275805950165
Epoch: 163/300 - Train loss: 0.44278550148010254, Validation loss: 0.4565517008304596
Epoch: 164/300 - Train loss: 0.4420529007911682, Validation loss: 0.45511046051979065
Epoch: 165/300 - Train loss: 0.4413222372531891, Validation loss: 0.45444247126579285
Epoch: 166/300 - Train loss: 0.4405937194824219, Validation loss: 0.4532802700996399
Epoch: 167/300 - Train loss: 0.43986666202545166, Validation loss: 0.45302465558052063
Epoch: 168/300 - Train loss: 0.4391411542892456, Validation loss: 0.45270150899887085
Epoch: 169/300 - Train loss: 0.4384174048900604, Validation loss: 0.4519525170326233
Epoch: 170/300 - Train loss: 0.4376967251300812, Validation loss: 0.45062172412872314
Epoch: 171/300 - Train loss: 0.4369794726371765, Validation loss: 0.4505597949028015
Epoch: 172/300 - Train loss: 0.43626368045806885, Validation loss: 0.4498235285282135
Epoch: 173/300 - Train loss: 0.4355488717556, Validation loss: 0.4490842819213867
Epoch: 174/300 - Train loss: 0.4348351061344147, Validation loss: 0.44796353578567505
Epoch: 175/300 - Train loss: 0.4341215193271637, Validation loss: 0.44747141003608704
Epoch: 176/300 - Train loss: 0.4334104061126709, Validation loss: 0.44662585854530334
Epoch: 177/300 - Train loss: 0.4327007532119751, Validation loss: 0.44648030400276184
Epoch: 178/300 - Train loss: 0.4319942891597748, Validation loss: 0.4464891850948334
Epoch: 179/300 - Train loss: 0.4312913119792938, Validation loss: 0.4450453221797943
Epoch: 180/300 - Train loss: 0.43059027194976807, Validation loss: 0.4442392885684967
Epoch: 181/300 - Train loss: 0.4298919141292572, Validation loss: 0.4434407651424408
Epoch: 182/300 - Train loss: 0.4291958808898926, Validation loss: 0.4425355792045593
Epoch: 183/300 - Train loss: 0.4285028576850891, Validation loss: 0.44189849495887756
Epoch: 184/300 - Train loss: 0.4278128147125244, Validation loss: 0.44173336029052734
Epoch: 185/300 - Train loss: 0.42712581157684326, Validation loss: 0.4409104883670807
Epoch: 186/300 - Train loss: 0.4264414608478546, Validation loss: 0.44078943133354187
Epoch: 187/300 - Train loss: 0.4257597327232361, Validation loss: 0.43974941968917847
Epoch: 188/300 - Train loss: 0.4250800907611847, Validation loss: 0.4389243423938751
Epoch: 189/300 - Train loss: 0.42440342903137207, Validation loss: 0.43915417790412903
Epoch: 190/300 - Train loss: 0.4237293303012848, Validation loss: 0.4381648898124695
Epoch: 191/300 - Train loss: 0.42305776476860046, Validation loss: 0.43717893958091736
Epoch: 192/300 - Train loss: 0.4223901331424713, Validation loss: 0.43691715598106384
