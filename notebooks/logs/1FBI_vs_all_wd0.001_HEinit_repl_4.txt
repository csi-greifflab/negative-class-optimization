Epoch: 1/300 - Train loss: 0.6889697909355164, Validation loss: 0.685705840587616
Epoch: 2/300 - Train loss: 0.6855746507644653, Validation loss: 0.682284414768219
Epoch: 3/300 - Train loss: 0.6821824908256531, Validation loss: 0.6787479519844055
Epoch: 4/300 - Train loss: 0.6787787079811096, Validation loss: 0.675358235836029
Epoch: 5/300 - Train loss: 0.6753523945808411, Validation loss: 0.6718024015426636
Epoch: 6/300 - Train loss: 0.6718956232070923, Validation loss: 0.6681475639343262
Epoch: 7/300 - Train loss: 0.6683927774429321, Validation loss: 0.6644432544708252
Epoch: 8/300 - Train loss: 0.6648303270339966, Validation loss: 0.6607090830802917
Epoch: 9/300 - Train loss: 0.6611983180046082, Validation loss: 0.6568654775619507
Epoch: 10/300 - Train loss: 0.657482922077179, Validation loss: 0.6529361605644226
Epoch: 11/300 - Train loss: 0.6536772847175598, Validation loss: 0.6491290926933289
Epoch: 12/300 - Train loss: 0.6497772932052612, Validation loss: 0.6449878215789795
Epoch: 13/300 - Train loss: 0.6457788348197937, Validation loss: 0.6407118439674377
Epoch: 14/300 - Train loss: 0.6416773200035095, Validation loss: 0.6364744305610657
Epoch: 15/300 - Train loss: 0.6374719738960266, Validation loss: 0.6320999264717102
Epoch: 16/300 - Train loss: 0.6331568956375122, Validation loss: 0.6276561617851257
Epoch: 17/300 - Train loss: 0.6287341117858887, Validation loss: 0.6229947209358215
Epoch: 18/300 - Train loss: 0.6242045760154724, Validation loss: 0.618034839630127
Epoch: 19/300 - Train loss: 0.6195690631866455, Validation loss: 0.6132364273071289
Epoch: 20/300 - Train loss: 0.6148273944854736, Validation loss: 0.608361542224884
Epoch: 21/300 - Train loss: 0.6099761128425598, Validation loss: 0.6033377051353455
Epoch: 22/300 - Train loss: 0.6050201058387756, Validation loss: 0.5982195734977722
Epoch: 23/300 - Train loss: 0.5999607443809509, Validation loss: 0.5930287837982178
Epoch: 24/300 - Train loss: 0.5948023200035095, Validation loss: 0.5876396894454956
Epoch: 25/300 - Train loss: 0.5895469188690186, Validation loss: 0.5822294354438782
Epoch: 26/300 - Train loss: 0.5841978192329407, Validation loss: 0.5766950845718384
Epoch: 27/300 - Train loss: 0.578763484954834, Validation loss: 0.5713949203491211
Epoch: 28/300 - Train loss: 0.5732520222663879, Validation loss: 0.5654870867729187
Epoch: 29/300 - Train loss: 0.567672073841095, Validation loss: 0.5598475337028503
Epoch: 30/300 - Train loss: 0.5620281100273132, Validation loss: 0.5540711879730225
Epoch: 31/300 - Train loss: 0.556327760219574, Validation loss: 0.5481546521186829
Epoch: 32/300 - Train loss: 0.5505801439285278, Validation loss: 0.5425732731819153
Epoch: 33/300 - Train loss: 0.5447947382926941, Validation loss: 0.5367333889007568
Epoch: 34/300 - Train loss: 0.5389769077301025, Validation loss: 0.5308258533477783
Epoch: 35/300 - Train loss: 0.5331396460533142, Validation loss: 0.5248383283615112
Epoch: 36/300 - Train loss: 0.5272877812385559, Validation loss: 0.518946647644043
Epoch: 37/300 - Train loss: 0.5214301347732544, Validation loss: 0.5129629969596863
Epoch: 38/300 - Train loss: 0.5155741572380066, Validation loss: 0.506991982460022
Epoch: 39/300 - Train loss: 0.509724497795105, Validation loss: 0.5012118220329285
Epoch: 40/300 - Train loss: 0.5038888454437256, Validation loss: 0.4951641857624054
Epoch: 41/300 - Train loss: 0.49807050824165344, Validation loss: 0.48933887481689453
Epoch: 42/300 - Train loss: 0.4922753572463989, Validation loss: 0.4836483299732208
Epoch: 43/300 - Train loss: 0.4865095615386963, Validation loss: 0.47757643461227417
Epoch: 44/300 - Train loss: 0.480776846408844, Validation loss: 0.47207680344581604
Epoch: 45/300 - Train loss: 0.47508400678634644, Validation loss: 0.46624258160591125
Epoch: 46/300 - Train loss: 0.469434916973114, Validation loss: 0.46074533462524414
Epoch: 47/300 - Train loss: 0.4638327360153198, Validation loss: 0.4548470079898834
Epoch: 48/300 - Train loss: 0.45828211307525635, Validation loss: 0.44939985871315
Epoch: 49/300 - Train loss: 0.45278602838516235, Validation loss: 0.4444617033004761
Epoch: 50/300 - Train loss: 0.4473485052585602, Validation loss: 0.4384117126464844
Epoch: 51/300 - Train loss: 0.4419741630554199, Validation loss: 0.4332493245601654
Epoch: 52/300 - Train loss: 0.4366667568683624, Validation loss: 0.4278603792190552
Epoch: 53/300 - Train loss: 0.4314280152320862, Validation loss: 0.422726035118103
Epoch: 54/300 - Train loss: 0.42626097798347473, Validation loss: 0.4175044000148773
Epoch: 55/300 - Train loss: 0.4211694300174713, Validation loss: 0.41257524490356445
Epoch: 56/300 - Train loss: 0.4161549210548401, Validation loss: 0.4076623320579529
Epoch: 57/300 - Train loss: 0.4112192392349243, Validation loss: 0.40286198258399963
Epoch: 58/300 - Train loss: 0.40636396408081055, Validation loss: 0.39806070923805237
Epoch: 59/300 - Train loss: 0.4015904664993286, Validation loss: 0.39298519492149353
Epoch: 60/300 - Train loss: 0.396899551153183, Validation loss: 0.38828906416893005
Epoch: 61/300 - Train loss: 0.3922916352748871, Validation loss: 0.38407522439956665
Epoch: 62/300 - Train loss: 0.38776764273643494, Validation loss: 0.3799414336681366
Epoch: 63/300 - Train loss: 0.3833281695842743, Validation loss: 0.37549588084220886
Epoch: 64/300 - Train loss: 0.37897393107414246, Validation loss: 0.37075579166412354
Epoch: 65/300 - Train loss: 0.37470507621765137, Validation loss: 0.3671436607837677
Epoch: 66/300 - Train loss: 0.3705211877822876, Validation loss: 0.3626817762851715
Epoch: 67/300 - Train loss: 0.36642149090766907, Validation loss: 0.35831454396247864
Epoch: 68/300 - Train loss: 0.3624057471752167, Validation loss: 0.35449281334877014
Epoch: 69/300 - Train loss: 0.3584733307361603, Validation loss: 0.35121047496795654
Epoch: 70/300 - Train loss: 0.3546239733695984, Validation loss: 0.3472152054309845
Epoch: 71/300 - Train loss: 0.350856214761734, Validation loss: 0.3433321714401245
Epoch: 72/300 - Train loss: 0.3471694588661194, Validation loss: 0.34001919627189636
Epoch: 73/300 - Train loss: 0.34356313943862915, Validation loss: 0.33633044362068176
Epoch: 74/300 - Train loss: 0.3400364816188812, Validation loss: 0.3330952227115631
Epoch: 75/300 - Train loss: 0.3365882635116577, Validation loss: 0.3295730650424957
Epoch: 76/300 - Train loss: 0.33321690559387207, Validation loss: 0.32587262988090515
Epoch: 77/300 - Train loss: 0.3299214839935303, Validation loss: 0.3228338360786438
Epoch: 78/300 - Train loss: 0.32670027017593384, Validation loss: 0.319497287273407
Epoch: 79/300 - Train loss: 0.32355207204818726, Validation loss: 0.31656819581985474
Epoch: 80/300 - Train loss: 0.3204760253429413, Validation loss: 0.31352144479751587
Epoch: 81/300 - Train loss: 0.31747058033943176, Validation loss: 0.3109882175922394
Epoch: 82/300 - Train loss: 0.3145347833633423, Validation loss: 0.3075594902038574
Epoch: 83/300 - Train loss: 0.3116666376590729, Validation loss: 0.30510663986206055
Epoch: 84/300 - Train loss: 0.30886510014533997, Validation loss: 0.3021760880947113
Epoch: 85/300 - Train loss: 0.30612877011299133, Validation loss: 0.2998794615268707
Epoch: 86/300 - Train loss: 0.3034563660621643, Validation loss: 0.29739007353782654
Epoch: 87/300 - Train loss: 0.3008466958999634, Validation loss: 0.29446038603782654
Epoch: 88/300 - Train loss: 0.29829809069633484, Validation loss: 0.2919261157512665
Epoch: 89/300 - Train loss: 0.2958088219165802, Validation loss: 0.28968867659568787
Epoch: 90/300 - Train loss: 0.2933781147003174, Validation loss: 0.2870871424674988
Epoch: 91/300 - Train loss: 0.2910042107105255, Validation loss: 0.2848794162273407
Epoch: 92/300 - Train loss: 0.28868597745895386, Validation loss: 0.28282713890075684
Epoch: 93/300 - Train loss: 0.28642186522483826, Validation loss: 0.28102874755859375
Epoch: 94/300 - Train loss: 0.2842106819152832, Validation loss: 0.27788904309272766
Epoch: 95/300 - Train loss: 0.2820512354373932, Validation loss: 0.27606791257858276
Epoch: 96/300 - Train loss: 0.2799420654773712, Validation loss: 0.2738448977470398
Epoch: 97/300 - Train loss: 0.2778818905353546, Validation loss: 0.27251023054122925
Epoch: 98/300 - Train loss: 0.2758697271347046, Validation loss: 0.2702074944972992
Epoch: 99/300 - Train loss: 0.2739045023918152, Validation loss: 0.26799947023391724
Epoch: 100/300 - Train loss: 0.27198490500450134, Validation loss: 0.26637792587280273
Epoch: 101/300 - Train loss: 0.27010974287986755, Validation loss: 0.2649286687374115
Epoch: 102/300 - Train loss: 0.2682779133319855, Validation loss: 0.2627844214439392
Epoch: 103/300 - Train loss: 0.26648804545402527, Validation loss: 0.2613937258720398
Epoch: 104/300 - Train loss: 0.26473912596702576, Validation loss: 0.2595069110393524
Epoch: 105/300 - Train loss: 0.2630302309989929, Validation loss: 0.2577042281627655
Epoch: 106/300 - Train loss: 0.2613603472709656, Validation loss: 0.25631922483444214
Epoch: 107/300 - Train loss: 0.25972849130630493, Validation loss: 0.2544393837451935
Epoch: 108/300 - Train loss: 0.25813353061676025, Validation loss: 0.2527698874473572
Epoch: 109/300 - Train loss: 0.2565743029117584, Validation loss: 0.2513662278652191
Epoch: 110/300 - Train loss: 0.2550499737262726, Validation loss: 0.24966463446617126
Epoch: 111/300 - Train loss: 0.25355958938598633, Validation loss: 0.24846668541431427
Epoch: 112/300 - Train loss: 0.2521025240421295, Validation loss: 0.24754837155342102
Epoch: 113/300 - Train loss: 0.25067776441574097, Validation loss: 0.24585218727588654
Epoch: 114/300 - Train loss: 0.24928432703018188, Validation loss: 0.2443079799413681
Epoch: 115/300 - Train loss: 0.24792155623435974, Validation loss: 0.2431269884109497
Epoch: 116/300 - Train loss: 0.24658861756324768, Validation loss: 0.24158477783203125
Epoch: 117/300 - Train loss: 0.24528484046459198, Validation loss: 0.24134069681167603
Epoch: 118/300 - Train loss: 0.24400939047336578, Validation loss: 0.23935651779174805
Epoch: 119/300 - Train loss: 0.24276159703731537, Validation loss: 0.23830267786979675
Epoch: 120/300 - Train loss: 0.24154065549373627, Validation loss: 0.23692409694194794
Epoch: 121/300 - Train loss: 0.24034593999385834, Validation loss: 0.23529259860515594
Epoch: 122/300 - Train loss: 0.23917673528194427, Validation loss: 0.23468618094921112
Epoch: 123/300 - Train loss: 0.23803220689296722, Validation loss: 0.2339087277650833
Epoch: 124/300 - Train loss: 0.23691165447235107, Validation loss: 0.2327415645122528
Epoch: 125/300 - Train loss: 0.23581463098526, Validation loss: 0.23126058280467987
Epoch: 126/300 - Train loss: 0.23474039137363434, Validation loss: 0.2305615395307541
Epoch: 127/300 - Train loss: 0.2336883693933487, Validation loss: 0.22916395962238312
Epoch: 128/300 - Train loss: 0.23265793919563293, Validation loss: 0.2288145124912262
Epoch: 129/300 - Train loss: 0.2316484898328781, Validation loss: 0.2273692488670349
Epoch: 130/300 - Train loss: 0.23065955936908722, Validation loss: 0.2267882376909256
Epoch: 131/300 - Train loss: 0.22969065606594086, Validation loss: 0.22532083094120026
Epoch: 132/300 - Train loss: 0.2287413328886032, Validation loss: 0.22451651096343994
Epoch: 133/300 - Train loss: 0.22781094908714294, Validation loss: 0.22387860715389252
Epoch: 134/300 - Train loss: 0.22689908742904663, Validation loss: 0.22298112511634827
Epoch: 135/300 - Train loss: 0.22600528597831726, Validation loss: 0.2223275601863861
Epoch: 136/300 - Train loss: 0.22512926161289215, Validation loss: 0.2210673838853836
Epoch: 137/300 - Train loss: 0.22427046298980713, Validation loss: 0.2211132049560547
Epoch: 138/300 - Train loss: 0.22342842817306519, Validation loss: 0.21988624334335327
Epoch: 139/300 - Train loss: 0.2226027548313141, Validation loss: 0.21885068714618683
Epoch: 140/300 - Train loss: 0.2217930257320404, Validation loss: 0.21788068115711212
Epoch: 141/300 - Train loss: 0.2209988236427307, Validation loss: 0.21731112897396088
Epoch: 142/300 - Train loss: 0.22021979093551636, Validation loss: 0.2167443186044693
Epoch: 143/300 - Train loss: 0.2194555252790451, Validation loss: 0.2158288061618805
Epoch: 144/300 - Train loss: 0.21870574355125427, Validation loss: 0.2152940332889557
Epoch: 145/300 - Train loss: 0.21797002851963043, Validation loss: 0.21440249681472778
Epoch: 146/300 - Train loss: 0.2172480672597885, Validation loss: 0.21343392133712769
Epoch: 147/300 - Train loss: 0.2165394276380539, Validation loss: 0.21324381232261658
Epoch: 148/300 - Train loss: 0.21584375202655792, Validation loss: 0.21266089379787445
Epoch: 149/300 - Train loss: 0.21516065299510956, Validation loss: 0.21161910891532898
Epoch: 150/300 - Train loss: 0.2144898623228073, Validation loss: 0.21118341386318207
Epoch: 151/300 - Train loss: 0.21383103728294373, Validation loss: 0.2106543630361557
Epoch: 152/300 - Train loss: 0.21318386495113373, Validation loss: 0.20963154733181
Epoch: 153/300 - Train loss: 0.21254821121692657, Validation loss: 0.20908653736114502
Epoch: 154/300 - Train loss: 0.21192392706871033, Validation loss: 0.20875616371631622
Epoch: 155/300 - Train loss: 0.21131066977977753, Validation loss: 0.20832166075706482
Epoch: 156/300 - Train loss: 0.21070817112922668, Validation loss: 0.20734871923923492
Epoch: 157/300 - Train loss: 0.21011608839035034, Validation loss: 0.20712065696716309
Epoch: 158/300 - Train loss: 0.20953427255153656, Validation loss: 0.20632383227348328
Epoch: 159/300 - Train loss: 0.20896245539188385, Validation loss: 0.20610976219177246
Epoch: 160/300 - Train loss: 0.20840038359165192, Validation loss: 0.20571109652519226
