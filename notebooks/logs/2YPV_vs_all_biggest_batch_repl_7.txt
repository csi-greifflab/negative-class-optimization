Epoch: 1/300 - Train loss: 0.7061960101127625, Validation loss: 0.7022054195404053
Epoch: 2/300 - Train loss: 0.7044510841369629, Validation loss: 0.7010082602500916
Epoch: 3/300 - Train loss: 0.7028490900993347, Validation loss: 0.6994298100471497
Epoch: 4/300 - Train loss: 0.7013466358184814, Validation loss: 0.6981011033058167
Epoch: 5/300 - Train loss: 0.6998695731163025, Validation loss: 0.6966702938079834
Epoch: 6/300 - Train loss: 0.69835364818573, Validation loss: 0.6950046420097351
Epoch: 7/300 - Train loss: 0.696750819683075, Validation loss: 0.6934956312179565
Epoch: 8/300 - Train loss: 0.6950222849845886, Validation loss: 0.6914058923721313
Epoch: 9/300 - Train loss: 0.6931330561637878, Validation loss: 0.6895891427993774
Epoch: 10/300 - Train loss: 0.6910625696182251, Validation loss: 0.6873909831047058
Epoch: 11/300 - Train loss: 0.6887919306755066, Validation loss: 0.6850362420082092
Epoch: 12/300 - Train loss: 0.6863075494766235, Validation loss: 0.682285487651825
Epoch: 13/300 - Train loss: 0.6836011409759521, Validation loss: 0.679508626461029
Epoch: 14/300 - Train loss: 0.6806738972663879, Validation loss: 0.676478922367096
Epoch: 15/300 - Train loss: 0.6775266528129578, Validation loss: 0.6733065843582153
Epoch: 16/300 - Train loss: 0.6741694808006287, Validation loss: 0.6698403358459473
Epoch: 17/300 - Train loss: 0.6706085801124573, Validation loss: 0.666105329990387
Epoch: 18/300 - Train loss: 0.6668586730957031, Validation loss: 0.6621786952018738
Epoch: 19/300 - Train loss: 0.662941575050354, Validation loss: 0.6582414507865906
Epoch: 20/300 - Train loss: 0.6588758826255798, Validation loss: 0.654054582118988
Epoch: 21/300 - Train loss: 0.6546750068664551, Validation loss: 0.6500145792961121
Epoch: 22/300 - Train loss: 0.6503676176071167, Validation loss: 0.6455749273300171
Epoch: 23/300 - Train loss: 0.6459736824035645, Validation loss: 0.6412913799285889
Epoch: 24/300 - Train loss: 0.6415063738822937, Validation loss: 0.6368931531906128
Epoch: 25/300 - Train loss: 0.6369748711585999, Validation loss: 0.632294774055481
Epoch: 26/300 - Train loss: 0.6323926448822021, Validation loss: 0.6277405619621277
Epoch: 27/300 - Train loss: 0.6277636885643005, Validation loss: 0.6230846643447876
Epoch: 28/300 - Train loss: 0.6230915784835815, Validation loss: 0.6186343431472778
Epoch: 29/300 - Train loss: 0.6183743476867676, Validation loss: 0.6138307452201843
Epoch: 30/300 - Train loss: 0.6136133074760437, Validation loss: 0.6092243194580078
Epoch: 31/300 - Train loss: 0.6088087558746338, Validation loss: 0.6044095754623413
Epoch: 32/300 - Train loss: 0.6039656400680542, Validation loss: 0.5996123552322388
Epoch: 33/300 - Train loss: 0.5990869998931885, Validation loss: 0.5947648286819458
Epoch: 34/300 - Train loss: 0.5941769480705261, Validation loss: 0.5899957418441772
Epoch: 35/300 - Train loss: 0.5892418622970581, Validation loss: 0.585054337978363
Epoch: 36/300 - Train loss: 0.5842870473861694, Validation loss: 0.5800786018371582
Epoch: 37/300 - Train loss: 0.579318642616272, Validation loss: 0.575185239315033
Epoch: 38/300 - Train loss: 0.5743420124053955, Validation loss: 0.5701491832733154
Epoch: 39/300 - Train loss: 0.5693625211715698, Validation loss: 0.5654333829879761
Epoch: 40/300 - Train loss: 0.5643846988677979, Validation loss: 0.5604494214057922
Epoch: 41/300 - Train loss: 0.5594143867492676, Validation loss: 0.5555242300033569
Epoch: 42/300 - Train loss: 0.5544566512107849, Validation loss: 0.5507166981697083
Epoch: 43/300 - Train loss: 0.5495166182518005, Validation loss: 0.5459007620811462
Epoch: 44/300 - Train loss: 0.5445989966392517, Validation loss: 0.5413827896118164
Epoch: 45/300 - Train loss: 0.5397078990936279, Validation loss: 0.5361196994781494
Epoch: 46/300 - Train loss: 0.5348482728004456, Validation loss: 0.5314518213272095
Epoch: 47/300 - Train loss: 0.5300245881080627, Validation loss: 0.5266513228416443
Epoch: 48/300 - Train loss: 0.5252415537834167, Validation loss: 0.5216464996337891
Epoch: 49/300 - Train loss: 0.5205028057098389, Validation loss: 0.5170685648918152
Epoch: 50/300 - Train loss: 0.5158123970031738, Validation loss: 0.5126489400863647
Epoch: 51/300 - Train loss: 0.5111737847328186, Validation loss: 0.5081420540809631
Epoch: 52/300 - Train loss: 0.5065904855728149, Validation loss: 0.5035139918327332
Epoch: 53/300 - Train loss: 0.5020655393600464, Validation loss: 0.4989563226699829
Epoch: 54/300 - Train loss: 0.49760210514068604, Validation loss: 0.4946165680885315
Epoch: 55/300 - Train loss: 0.4932030737400055, Validation loss: 0.49037036299705505
Epoch: 56/300 - Train loss: 0.488870769739151, Validation loss: 0.48591822385787964
Epoch: 57/300 - Train loss: 0.4846075773239136, Validation loss: 0.48209819197654724
Epoch: 58/300 - Train loss: 0.48041537404060364, Validation loss: 0.47787779569625854
Epoch: 59/300 - Train loss: 0.47629567980766296, Validation loss: 0.4733935296535492
Epoch: 60/300 - Train loss: 0.4722505509853363, Validation loss: 0.46970322728157043
Epoch: 61/300 - Train loss: 0.4682812988758087, Validation loss: 0.46576935052871704
Epoch: 62/300 - Train loss: 0.4643891155719757, Validation loss: 0.46209415793418884
Epoch: 63/300 - Train loss: 0.460575133562088, Validation loss: 0.45816344022750854
Epoch: 64/300 - Train loss: 0.4568396806716919, Validation loss: 0.4543103575706482
Epoch: 65/300 - Train loss: 0.4531829059123993, Validation loss: 0.4507666528224945
Epoch: 66/300 - Train loss: 0.44960543513298035, Validation loss: 0.4473631680011749
Epoch: 67/300 - Train loss: 0.44610753655433655, Validation loss: 0.44378402829170227
Epoch: 68/300 - Train loss: 0.44268879294395447, Validation loss: 0.44025880098342896
Epoch: 69/300 - Train loss: 0.4393486976623535, Validation loss: 0.43718382716178894
Epoch: 70/300 - Train loss: 0.4360865652561188, Validation loss: 0.43408316373825073
Epoch: 71/300 - Train loss: 0.43290141224861145, Validation loss: 0.4307914078235626
Epoch: 72/300 - Train loss: 0.429792582988739, Validation loss: 0.42767801880836487
Epoch: 73/300 - Train loss: 0.42675939202308655, Validation loss: 0.4245477616786957
Epoch: 74/300 - Train loss: 0.42380064725875854, Validation loss: 0.42181462049484253
Epoch: 75/300 - Train loss: 0.42091524600982666, Validation loss: 0.4190579652786255
Epoch: 76/300 - Train loss: 0.41810157895088196, Validation loss: 0.41610753536224365
Epoch: 77/300 - Train loss: 0.41535869240760803, Validation loss: 0.4135591387748718
Epoch: 78/300 - Train loss: 0.41268521547317505, Validation loss: 0.41140061616897583
Epoch: 79/300 - Train loss: 0.41007909178733826, Validation loss: 0.40837767720222473
Epoch: 80/300 - Train loss: 0.4075390696525574, Validation loss: 0.4058813452720642
Epoch: 81/300 - Train loss: 0.4050631821155548, Validation loss: 0.40368929505348206
Epoch: 82/300 - Train loss: 0.40264979004859924, Validation loss: 0.40081697702407837
Epoch: 83/300 - Train loss: 0.4002974331378937, Validation loss: 0.39851799607276917
Epoch: 84/300 - Train loss: 0.3980051875114441, Validation loss: 0.3962976336479187
Epoch: 85/300 - Train loss: 0.3957710564136505, Validation loss: 0.3938131332397461
Epoch: 86/300 - Train loss: 0.3935931324958801, Validation loss: 0.3920557200908661
Epoch: 87/300 - Train loss: 0.39146971702575684, Validation loss: 0.3894794285297394
Epoch: 88/300 - Train loss: 0.38939934968948364, Validation loss: 0.3875316083431244
Epoch: 89/300 - Train loss: 0.38738059997558594, Validation loss: 0.3853270411491394
Epoch: 90/300 - Train loss: 0.3854113817214966, Validation loss: 0.3835441470146179
Epoch: 91/300 - Train loss: 0.383489191532135, Validation loss: 0.3816555440425873
Epoch: 92/300 - Train loss: 0.38161277770996094, Validation loss: 0.37953776121139526
Epoch: 93/300 - Train loss: 0.37978023290634155, Validation loss: 0.3782605826854706
Epoch: 94/300 - Train loss: 0.37799033522605896, Validation loss: 0.37645986676216125
Epoch: 95/300 - Train loss: 0.3762412667274475, Validation loss: 0.3747974932193756
Epoch: 96/300 - Train loss: 0.37453150749206543, Validation loss: 0.37342533469200134
Epoch: 97/300 - Train loss: 0.37286099791526794, Validation loss: 0.3705712556838989
Epoch: 98/300 - Train loss: 0.3712274432182312, Validation loss: 0.3699833154678345
Epoch: 99/300 - Train loss: 0.36962947249412537, Validation loss: 0.36784762144088745
Epoch: 100/300 - Train loss: 0.3680654764175415, Validation loss: 0.36599981784820557
Epoch: 101/300 - Train loss: 0.36653393507003784, Validation loss: 0.36458563804626465
Epoch: 102/300 - Train loss: 0.3650330603122711, Validation loss: 0.3630092442035675
Epoch: 103/300 - Train loss: 0.36356121301651, Validation loss: 0.3617224097251892
Epoch: 104/300 - Train loss: 0.36211732029914856, Validation loss: 0.3601335883140564
Epoch: 105/300 - Train loss: 0.36070066690444946, Validation loss: 0.3582078516483307
Epoch: 106/300 - Train loss: 0.35931044816970825, Validation loss: 0.35773026943206787
Epoch: 107/300 - Train loss: 0.35794565081596375, Validation loss: 0.35555073618888855
Epoch: 108/300 - Train loss: 0.356605589389801, Validation loss: 0.35512369871139526
Epoch: 109/300 - Train loss: 0.3552895784378052, Validation loss: 0.3533382713794708
Epoch: 110/300 - Train loss: 0.35399630665779114, Validation loss: 0.351963609457016
Epoch: 111/300 - Train loss: 0.35272538661956787, Validation loss: 0.35072246193885803
Epoch: 112/300 - Train loss: 0.3514763414859772, Validation loss: 0.34943655133247375
Epoch: 113/300 - Train loss: 0.3502490818500519, Validation loss: 0.34899425506591797
Epoch: 114/300 - Train loss: 0.3490432798862457, Validation loss: 0.3474682569503784
Epoch: 115/300 - Train loss: 0.3478582203388214, Validation loss: 0.34588098526000977
Epoch: 116/300 - Train loss: 0.3466932773590088, Validation loss: 0.344501793384552
Epoch: 117/300 - Train loss: 0.3455471992492676, Validation loss: 0.3436116576194763
Epoch: 118/300 - Train loss: 0.34441953897476196, Validation loss: 0.3432471752166748
Epoch: 119/300 - Train loss: 0.34331122040748596, Validation loss: 0.3413356840610504
Epoch: 120/300 - Train loss: 0.34222087264060974, Validation loss: 0.34063348174095154
Epoch: 121/300 - Train loss: 0.3411487936973572, Validation loss: 0.33960896730422974
Epoch: 122/300 - Train loss: 0.34009385108947754, Validation loss: 0.33816957473754883
Epoch: 123/300 - Train loss: 0.3390556275844574, Validation loss: 0.3372046649456024
Epoch: 124/300 - Train loss: 0.33803293108940125, Validation loss: 0.33613821864128113
Epoch: 125/300 - Train loss: 0.33702558279037476, Validation loss: 0.33538052439689636
Epoch: 126/300 - Train loss: 0.3360334038734436, Validation loss: 0.3346913158893585
Epoch: 127/300 - Train loss: 0.33505433797836304, Validation loss: 0.33320432901382446
Epoch: 128/300 - Train loss: 0.33408936858177185, Validation loss: 0.3324050307273865
Epoch: 129/300 - Train loss: 0.3331393003463745, Validation loss: 0.33182212710380554
Epoch: 130/300 - Train loss: 0.3322029709815979, Validation loss: 0.33072367310523987
Epoch: 131/300 - Train loss: 0.33128008246421814, Validation loss: 0.3295728266239166
Epoch: 132/300 - Train loss: 0.3303714990615845, Validation loss: 0.32827290892601013
Epoch: 133/300 - Train loss: 0.32947707176208496, Validation loss: 0.3284223973751068
Epoch: 134/300 - Train loss: 0.3285950720310211, Validation loss: 0.32701247930526733
Epoch: 135/300 - Train loss: 0.3277268409729004, Validation loss: 0.32630273699760437
Epoch: 136/300 - Train loss: 0.3268735110759735, Validation loss: 0.3252866864204407
Epoch: 137/300 - Train loss: 0.32603535056114197, Validation loss: 0.32471418380737305
Epoch: 138/300 - Train loss: 0.32520925998687744, Validation loss: 0.32365986704826355
Epoch: 139/300 - Train loss: 0.3243970572948456, Validation loss: 0.32324424386024475
Epoch: 140/300 - Train loss: 0.3235967755317688, Validation loss: 0.3219907879829407
Epoch: 141/300 - Train loss: 0.32280775904655457, Validation loss: 0.321289986371994
Epoch: 142/300 - Train loss: 0.32203033566474915, Validation loss: 0.3211756646633148
Epoch: 143/300 - Train loss: 0.32126376032829285, Validation loss: 0.32048627734184265
Epoch: 144/300 - Train loss: 0.32050761580467224, Validation loss: 0.31973132491111755
Epoch: 145/300 - Train loss: 0.3197619616985321, Validation loss: 0.31880494952201843
Epoch: 146/300 - Train loss: 0.3190262019634247, Validation loss: 0.3176422119140625
Epoch: 147/300 - Train loss: 0.3182987868785858, Validation loss: 0.31754109263420105
Epoch: 148/300 - Train loss: 0.31758272647857666, Validation loss: 0.31661373376846313
Epoch: 149/300 - Train loss: 0.31687718629837036, Validation loss: 0.31554099917411804
Epoch: 150/300 - Train loss: 0.31617990136146545, Validation loss: 0.31465986371040344
Epoch: 151/300 - Train loss: 0.3154904842376709, Validation loss: 0.31429728865623474
Epoch: 152/300 - Train loss: 0.3148094117641449, Validation loss: 0.3143802583217621
Epoch: 153/300 - Train loss: 0.31413692235946655, Validation loss: 0.3132593035697937
Epoch: 154/300 - Train loss: 0.31347233057022095, Validation loss: 0.31276896595954895
Epoch: 155/300 - Train loss: 0.31281551718711853, Validation loss: 0.3117121756076813
Epoch: 156/300 - Train loss: 0.31216633319854736, Validation loss: 0.3112392723560333
Epoch: 157/300 - Train loss: 0.3115253746509552, Validation loss: 0.3112089931964874
Epoch: 158/300 - Train loss: 0.31089213490486145, Validation loss: 0.3099449574947357
Epoch: 159/300 - Train loss: 0.3102661371231079, Validation loss: 0.30919381976127625
Epoch: 160/300 - Train loss: 0.3096476197242737, Validation loss: 0.30910012125968933
Epoch: 161/300 - Train loss: 0.309035986661911, Validation loss: 0.30812743306159973
Epoch: 162/300 - Train loss: 0.30843207240104675, Validation loss: 0.30810776352882385
Epoch: 163/300 - Train loss: 0.3078361749649048, Validation loss: 0.3072557747364044
Epoch: 164/300 - Train loss: 0.30724745988845825, Validation loss: 0.30658307671546936
Epoch: 165/300 - Train loss: 0.3066663146018982, Validation loss: 0.30630093812942505
