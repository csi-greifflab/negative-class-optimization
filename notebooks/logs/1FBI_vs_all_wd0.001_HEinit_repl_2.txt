Epoch: 1/300 - Train loss: 0.695763885974884, Validation loss: 0.6894781589508057
Epoch: 2/300 - Train loss: 0.6907948851585388, Validation loss: 0.6847471594810486
Epoch: 3/300 - Train loss: 0.6859541535377502, Validation loss: 0.6801645755767822
Epoch: 4/300 - Train loss: 0.6812413930892944, Validation loss: 0.6756629347801208
Epoch: 5/300 - Train loss: 0.6766399145126343, Validation loss: 0.6712613105773926
Epoch: 6/300 - Train loss: 0.6721401214599609, Validation loss: 0.6670623421669006
Epoch: 7/300 - Train loss: 0.6677284240722656, Validation loss: 0.6627572774887085
Epoch: 8/300 - Train loss: 0.6633833646774292, Validation loss: 0.6586750149726868
Epoch: 9/300 - Train loss: 0.6590808629989624, Validation loss: 0.6544456481933594
Epoch: 10/300 - Train loss: 0.6548051834106445, Validation loss: 0.6501650214195251
Epoch: 11/300 - Train loss: 0.6505352854728699, Validation loss: 0.6459324359893799
Epoch: 12/300 - Train loss: 0.6462527513504028, Validation loss: 0.6418001055717468
Epoch: 13/300 - Train loss: 0.6419429183006287, Validation loss: 0.6374617218971252
Epoch: 14/300 - Train loss: 0.6375999450683594, Validation loss: 0.6331483721733093
Epoch: 15/300 - Train loss: 0.6332105994224548, Validation loss: 0.6286649107933044
Epoch: 16/300 - Train loss: 0.6287618279457092, Validation loss: 0.6241294145584106
Epoch: 17/300 - Train loss: 0.6242427229881287, Validation loss: 0.619711697101593
Epoch: 18/300 - Train loss: 0.6196473240852356, Validation loss: 0.6148977279663086
Epoch: 19/300 - Train loss: 0.6149682998657227, Validation loss: 0.610279381275177
Epoch: 20/300 - Train loss: 0.6102015972137451, Validation loss: 0.6054744720458984
Epoch: 21/300 - Train loss: 0.6053460240364075, Validation loss: 0.6003352999687195
Epoch: 22/300 - Train loss: 0.6004025340080261, Validation loss: 0.59508216381073
Epoch: 23/300 - Train loss: 0.595365047454834, Validation loss: 0.5900293588638306
Epoch: 24/300 - Train loss: 0.5902354121208191, Validation loss: 0.5845957398414612
Epoch: 25/300 - Train loss: 0.5850112438201904, Validation loss: 0.5793167948722839
Epoch: 26/300 - Train loss: 0.5796934366226196, Validation loss: 0.5737826228141785
Epoch: 27/300 - Train loss: 0.5742813944816589, Validation loss: 0.5683304071426392
Epoch: 28/300 - Train loss: 0.5687775611877441, Validation loss: 0.5623674392700195
Epoch: 29/300 - Train loss: 0.5631806254386902, Validation loss: 0.5566527843475342
Epoch: 30/300 - Train loss: 0.5574967265129089, Validation loss: 0.5508391261100769
Epoch: 31/300 - Train loss: 0.5517355799674988, Validation loss: 0.5450199246406555
Epoch: 32/300 - Train loss: 0.5459001660346985, Validation loss: 0.5387978553771973
Epoch: 33/300 - Train loss: 0.5399995446205139, Validation loss: 0.5328256487846375
Epoch: 34/300 - Train loss: 0.5340359210968018, Validation loss: 0.5263979434967041
Epoch: 35/300 - Train loss: 0.528019905090332, Validation loss: 0.5205110311508179
Epoch: 36/300 - Train loss: 0.521960437297821, Validation loss: 0.5144326090812683
Epoch: 37/300 - Train loss: 0.5158649682998657, Validation loss: 0.5080845355987549
Epoch: 38/300 - Train loss: 0.5097389817237854, Validation loss: 0.5016024112701416
Epoch: 39/300 - Train loss: 0.5035937428474426, Validation loss: 0.49537593126296997
Epoch: 40/300 - Train loss: 0.4974433481693268, Validation loss: 0.4890844225883484
Epoch: 41/300 - Train loss: 0.4912927746772766, Validation loss: 0.48280423879623413
Epoch: 42/300 - Train loss: 0.48515287041664124, Validation loss: 0.47671541571617126
Epoch: 43/300 - Train loss: 0.479034960269928, Validation loss: 0.47051316499710083
Epoch: 44/300 - Train loss: 0.47295188903808594, Validation loss: 0.4641355872154236
Epoch: 45/300 - Train loss: 0.4669082760810852, Validation loss: 0.4579155147075653
Epoch: 46/300 - Train loss: 0.46091052889823914, Validation loss: 0.4519338607788086
Epoch: 47/300 - Train loss: 0.4549596309661865, Validation loss: 0.4460694193840027
Epoch: 48/300 - Train loss: 0.4490625560283661, Validation loss: 0.44004344940185547
Epoch: 49/300 - Train loss: 0.4432264268398285, Validation loss: 0.4341505765914917
Epoch: 50/300 - Train loss: 0.4374569058418274, Validation loss: 0.4283095896244049
Epoch: 51/300 - Train loss: 0.43175897002220154, Validation loss: 0.42282453179359436
Epoch: 52/300 - Train loss: 0.42613378167152405, Validation loss: 0.41711628437042236
Epoch: 53/300 - Train loss: 0.42058491706848145, Validation loss: 0.4115523099899292
Epoch: 54/300 - Train loss: 0.4151158928871155, Validation loss: 0.4059334397315979
Epoch: 55/300 - Train loss: 0.40972742438316345, Validation loss: 0.4006921052932739
Epoch: 56/300 - Train loss: 0.4044232666492462, Validation loss: 0.3956565260887146
Epoch: 57/300 - Train loss: 0.3992081582546234, Validation loss: 0.39031049609184265
Epoch: 58/300 - Train loss: 0.3940839469432831, Validation loss: 0.38525524735450745
Epoch: 59/300 - Train loss: 0.38905104994773865, Validation loss: 0.38014087080955505
Epoch: 60/300 - Train loss: 0.3841108977794647, Validation loss: 0.3753048777580261
Epoch: 61/300 - Train loss: 0.37926581501960754, Validation loss: 0.37059497833251953
Epoch: 62/300 - Train loss: 0.3745162785053253, Validation loss: 0.3655945956707001
Epoch: 63/300 - Train loss: 0.36986348032951355, Validation loss: 0.36144861578941345
Epoch: 64/300 - Train loss: 0.3653082251548767, Validation loss: 0.35694921016693115
Epoch: 65/300 - Train loss: 0.3608514368534088, Validation loss: 0.3520893454551697
Epoch: 66/300 - Train loss: 0.3564930558204651, Validation loss: 0.34798920154571533
Epoch: 67/300 - Train loss: 0.3522322475910187, Validation loss: 0.3435783386230469
Epoch: 68/300 - Train loss: 0.3480682969093323, Validation loss: 0.3399282991886139
Epoch: 69/300 - Train loss: 0.34400030970573425, Validation loss: 0.3356205224990845
Epoch: 70/300 - Train loss: 0.3400273621082306, Validation loss: 0.3315262794494629
Epoch: 71/300 - Train loss: 0.33614885807037354, Validation loss: 0.32825198769569397
Epoch: 72/300 - Train loss: 0.33236297965049744, Validation loss: 0.3238607347011566
Epoch: 73/300 - Train loss: 0.3286684453487396, Validation loss: 0.32029101252555847
Epoch: 74/300 - Train loss: 0.3250642716884613, Validation loss: 0.3170308768749237
Epoch: 75/300 - Train loss: 0.32154861092567444, Validation loss: 0.3137904107570648
Epoch: 76/300 - Train loss: 0.3181198239326477, Validation loss: 0.3100348114967346
Epoch: 77/300 - Train loss: 0.31477659940719604, Validation loss: 0.30675622820854187
Epoch: 78/300 - Train loss: 0.31151753664016724, Validation loss: 0.3035092055797577
Epoch: 79/300 - Train loss: 0.3083413541316986, Validation loss: 0.30099138617515564
Epoch: 80/300 - Train loss: 0.30524560809135437, Validation loss: 0.2980539798736572
Epoch: 81/300 - Train loss: 0.30222856998443604, Validation loss: 0.2950565218925476
Epoch: 82/300 - Train loss: 0.2992887496948242, Validation loss: 0.29185694456100464
Epoch: 83/300 - Train loss: 0.29642418026924133, Validation loss: 0.28914308547973633
Epoch: 84/300 - Train loss: 0.29363322257995605, Validation loss: 0.28644150495529175
Epoch: 85/300 - Train loss: 0.2909141480922699, Validation loss: 0.2839972674846649
Epoch: 86/300 - Train loss: 0.2882654666900635, Validation loss: 0.2808009684085846
Epoch: 87/300 - Train loss: 0.2856852114200592, Validation loss: 0.27830901741981506
Epoch: 88/300 - Train loss: 0.283171683549881, Validation loss: 0.2757810652256012
Epoch: 89/300 - Train loss: 0.2807232737541199, Validation loss: 0.27371275424957275
Epoch: 90/300 - Train loss: 0.2783380448818207, Validation loss: 0.2712976634502411
Epoch: 91/300 - Train loss: 0.276014506816864, Validation loss: 0.26919659972190857
Epoch: 92/300 - Train loss: 0.273750901222229, Validation loss: 0.26749739050865173
Epoch: 93/300 - Train loss: 0.2715458273887634, Validation loss: 0.2650425434112549
Epoch: 94/300 - Train loss: 0.2693972885608673, Validation loss: 0.2630143165588379
Epoch: 95/300 - Train loss: 0.26730382442474365, Validation loss: 0.2610240578651428
Epoch: 96/300 - Train loss: 0.2652643322944641, Validation loss: 0.25899580121040344
Epoch: 97/300 - Train loss: 0.263277143239975, Validation loss: 0.25726011395454407
Epoch: 98/300 - Train loss: 0.26134058833122253, Validation loss: 0.25494861602783203
Epoch: 99/300 - Train loss: 0.2594534158706665, Validation loss: 0.2530898451805115
Epoch: 100/300 - Train loss: 0.2576143443584442, Validation loss: 0.2515307664871216
Epoch: 101/300 - Train loss: 0.2558220326900482, Validation loss: 0.2499854862689972
Epoch: 102/300 - Train loss: 0.2540750801563263, Validation loss: 0.2486342042684555
Epoch: 103/300 - Train loss: 0.2523721158504486, Validation loss: 0.246628999710083
Epoch: 104/300 - Train loss: 0.2507120668888092, Validation loss: 0.24484415352344513
Epoch: 105/300 - Train loss: 0.24909357726573944, Validation loss: 0.24358859658241272
Epoch: 106/300 - Train loss: 0.2475157529115677, Validation loss: 0.2416664958000183
Epoch: 107/300 - Train loss: 0.2459772229194641, Validation loss: 0.24061067402362823
Epoch: 108/300 - Train loss: 0.24447667598724365, Validation loss: 0.2389385998249054
Epoch: 109/300 - Train loss: 0.24301348626613617, Validation loss: 0.23767916858196259
Epoch: 110/300 - Train loss: 0.2415865808725357, Validation loss: 0.2368541657924652
Epoch: 111/300 - Train loss: 0.24019500613212585, Validation loss: 0.23468904197216034
Epoch: 112/300 - Train loss: 0.23883774876594543, Validation loss: 0.23390834033489227
Epoch: 113/300 - Train loss: 0.23751340806484222, Validation loss: 0.23251663148403168
Epoch: 114/300 - Train loss: 0.23622141778469086, Validation loss: 0.23096145689487457
Epoch: 115/300 - Train loss: 0.2349606305360794, Validation loss: 0.22949931025505066
Epoch: 116/300 - Train loss: 0.2337302714586258, Validation loss: 0.22906813025474548
Epoch: 117/300 - Train loss: 0.23252956569194794, Validation loss: 0.2274353802204132
Epoch: 118/300 - Train loss: 0.23135776817798615, Validation loss: 0.2266532927751541
Epoch: 119/300 - Train loss: 0.23021414875984192, Validation loss: 0.22522716224193573
Epoch: 120/300 - Train loss: 0.22909793257713318, Validation loss: 0.2242969423532486
Epoch: 121/300 - Train loss: 0.22800827026367188, Validation loss: 0.2235041856765747
Epoch: 122/300 - Train loss: 0.22694458067417145, Validation loss: 0.22209179401397705
Epoch: 123/300 - Train loss: 0.22590599954128265, Validation loss: 0.22144439816474915
Epoch: 124/300 - Train loss: 0.22489188611507416, Validation loss: 0.22070786356925964
Epoch: 125/300 - Train loss: 0.22390158474445343, Validation loss: 0.21913133561611176
Epoch: 126/300 - Train loss: 0.22293435037136078, Validation loss: 0.2186862677335739
Epoch: 127/300 - Train loss: 0.22198954224586487, Validation loss: 0.2177024632692337
Epoch: 128/300 - Train loss: 0.2210666388273239, Validation loss: 0.21669961512088776
Epoch: 129/300 - Train loss: 0.22016486525535583, Validation loss: 0.21634908020496368
Epoch: 130/300 - Train loss: 0.21928377449512482, Validation loss: 0.215172678232193
Epoch: 131/300 - Train loss: 0.21842284500598907, Validation loss: 0.21437275409698486
Epoch: 132/300 - Train loss: 0.21758145093917847, Validation loss: 0.21380239725112915
Epoch: 133/300 - Train loss: 0.21675892174243927, Validation loss: 0.212964728474617
Epoch: 134/300 - Train loss: 0.21595482528209686, Validation loss: 0.21238619089126587
Epoch: 135/300 - Train loss: 0.21516865491867065, Validation loss: 0.21205636858940125
Epoch: 136/300 - Train loss: 0.21439988911151886, Validation loss: 0.21079447865486145
Epoch: 137/300 - Train loss: 0.2136479765176773, Validation loss: 0.21022021770477295
Epoch: 138/300 - Train loss: 0.21291252970695496, Validation loss: 0.20956222712993622
Epoch: 139/300 - Train loss: 0.2121930867433548, Validation loss: 0.20889580249786377
Epoch: 140/300 - Train loss: 0.2114892154932022, Validation loss: 0.20813779532909393
Epoch: 141/300 - Train loss: 0.21080052852630615, Validation loss: 0.20747427642345428
Epoch: 142/300 - Train loss: 0.21012674272060394, Validation loss: 0.20680974423885345
Epoch: 143/300 - Train loss: 0.20946745574474335, Validation loss: 0.20616258680820465
Epoch: 144/300 - Train loss: 0.2088223397731781, Validation loss: 0.20582319796085358
Epoch: 145/300 - Train loss: 0.2081909328699112, Validation loss: 0.2053474336862564
Epoch: 146/300 - Train loss: 0.20757292211055756, Validation loss: 0.20481634140014648
Epoch: 147/300 - Train loss: 0.2069680243730545, Validation loss: 0.20407907664775848
Epoch: 148/300 - Train loss: 0.206375852227211, Validation loss: 0.20350398123264313
Epoch: 149/300 - Train loss: 0.2057960331439972, Validation loss: 0.20263908803462982
Epoch: 150/300 - Train loss: 0.2052283138036728, Validation loss: 0.20247682929039001
