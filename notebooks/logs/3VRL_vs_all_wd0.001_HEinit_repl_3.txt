Epoch: 1/300 - Train loss: 0.6991133689880371, Validation loss: 0.6951048374176025
Epoch: 2/300 - Train loss: 0.6966491937637329, Validation loss: 0.6928185820579529
Epoch: 3/300 - Train loss: 0.6942945718765259, Validation loss: 0.6908776760101318
Epoch: 4/300 - Train loss: 0.6920403242111206, Validation loss: 0.6886724233627319
Epoch: 5/300 - Train loss: 0.6898677945137024, Validation loss: 0.6866002082824707
Epoch: 6/300 - Train loss: 0.6877490878105164, Validation loss: 0.6845773458480835
Epoch: 7/300 - Train loss: 0.6856567859649658, Validation loss: 0.6826688051223755
Epoch: 8/300 - Train loss: 0.6835632920265198, Validation loss: 0.6804719567298889
Epoch: 9/300 - Train loss: 0.6814476847648621, Validation loss: 0.6785549521446228
Epoch: 10/300 - Train loss: 0.6792866587638855, Validation loss: 0.6763004064559937
Epoch: 11/300 - Train loss: 0.6770668029785156, Validation loss: 0.6740744709968567
Epoch: 12/300 - Train loss: 0.6747750043869019, Validation loss: 0.6719433069229126
Epoch: 13/300 - Train loss: 0.6724012494087219, Validation loss: 0.6694428324699402
Epoch: 14/300 - Train loss: 0.6699355244636536, Validation loss: 0.6669878363609314
Epoch: 15/300 - Train loss: 0.6673691868782043, Validation loss: 0.6643866300582886
Epoch: 16/300 - Train loss: 0.6646952033042908, Validation loss: 0.6616576313972473
Epoch: 17/300 - Train loss: 0.6619040966033936, Validation loss: 0.6589421033859253
Epoch: 18/300 - Train loss: 0.6589938402175903, Validation loss: 0.6560123562812805
Epoch: 19/300 - Train loss: 0.655960738658905, Validation loss: 0.65291428565979
Epoch: 20/300 - Train loss: 0.6528066396713257, Validation loss: 0.6497745513916016
Epoch: 21/300 - Train loss: 0.6495276093482971, Validation loss: 0.6465705633163452
Epoch: 22/300 - Train loss: 0.6461241841316223, Validation loss: 0.6429508328437805
Epoch: 23/300 - Train loss: 0.6425986289978027, Validation loss: 0.6395268440246582
Epoch: 24/300 - Train loss: 0.6389532089233398, Validation loss: 0.635917603969574
Epoch: 25/300 - Train loss: 0.6351937651634216, Validation loss: 0.6321231722831726
Epoch: 26/300 - Train loss: 0.6313238143920898, Validation loss: 0.6282277703285217
Epoch: 27/300 - Train loss: 0.627349317073822, Validation loss: 0.6242368221282959
Epoch: 28/300 - Train loss: 0.6232729554176331, Validation loss: 0.6200763583183289
Epoch: 29/300 - Train loss: 0.6191006302833557, Validation loss: 0.6160224080085754
Epoch: 30/300 - Train loss: 0.6148422956466675, Validation loss: 0.6118923425674438
Epoch: 31/300 - Train loss: 0.6104997992515564, Validation loss: 0.6074711084365845
Epoch: 32/300 - Train loss: 0.6060793995857239, Validation loss: 0.6031557321548462
Epoch: 33/300 - Train loss: 0.6015860438346863, Validation loss: 0.5986329913139343
Epoch: 34/300 - Train loss: 0.5970262885093689, Validation loss: 0.5940719246864319
Epoch: 35/300 - Train loss: 0.5924002528190613, Validation loss: 0.5897275805473328
Epoch: 36/300 - Train loss: 0.587712287902832, Validation loss: 0.5850392580032349
Epoch: 37/300 - Train loss: 0.582966148853302, Validation loss: 0.5801964998245239
Epoch: 38/300 - Train loss: 0.5781622529029846, Validation loss: 0.5754019618034363
Epoch: 39/300 - Train loss: 0.5733056664466858, Validation loss: 0.5705702304840088
Epoch: 40/300 - Train loss: 0.5684024691581726, Validation loss: 0.5659274458885193
Epoch: 41/300 - Train loss: 0.5634550452232361, Validation loss: 0.5609638094902039
Epoch: 42/300 - Train loss: 0.558466911315918, Validation loss: 0.5565025806427002
Epoch: 43/300 - Train loss: 0.5534432530403137, Validation loss: 0.551517128944397
Epoch: 44/300 - Train loss: 0.5483900308609009, Validation loss: 0.5464872121810913
Epoch: 45/300 - Train loss: 0.5433130264282227, Validation loss: 0.5414381623268127
Epoch: 46/300 - Train loss: 0.5382201075553894, Validation loss: 0.5367237329483032
Epoch: 47/300 - Train loss: 0.5331146121025085, Validation loss: 0.531527578830719
Epoch: 48/300 - Train loss: 0.5280051827430725, Validation loss: 0.526367723941803
Epoch: 49/300 - Train loss: 0.5228970646858215, Validation loss: 0.5217136144638062
Epoch: 50/300 - Train loss: 0.517794668674469, Validation loss: 0.5169475674629211
Epoch: 51/300 - Train loss: 0.5127031207084656, Validation loss: 0.5121158361434937
Epoch: 52/300 - Train loss: 0.5076287388801575, Validation loss: 0.5068150162696838
Epoch: 53/300 - Train loss: 0.5025784373283386, Validation loss: 0.5023417472839355
Epoch: 54/300 - Train loss: 0.49755674600601196, Validation loss: 0.4974347651004791
Epoch: 55/300 - Train loss: 0.4925687313079834, Validation loss: 0.49235329031944275
Epoch: 56/300 - Train loss: 0.48761749267578125, Validation loss: 0.4878752827644348
Epoch: 57/300 - Train loss: 0.48271098732948303, Validation loss: 0.4831914007663727
Epoch: 58/300 - Train loss: 0.477851003408432, Validation loss: 0.478586882352829
Epoch: 59/300 - Train loss: 0.47304052114486694, Validation loss: 0.47424107789993286
Epoch: 60/300 - Train loss: 0.468283474445343, Validation loss: 0.4693417251110077
Epoch: 61/300 - Train loss: 0.46358415484428406, Validation loss: 0.46487686038017273
Epoch: 62/300 - Train loss: 0.4589475095272064, Validation loss: 0.4605903625488281
Epoch: 63/300 - Train loss: 0.4543755054473877, Validation loss: 0.45594096183776855
Epoch: 64/300 - Train loss: 0.4498707056045532, Validation loss: 0.4516686797142029
Epoch: 65/300 - Train loss: 0.44543594121932983, Validation loss: 0.447501540184021
Epoch: 66/300 - Train loss: 0.44107329845428467, Validation loss: 0.44335246086120605
Epoch: 67/300 - Train loss: 0.43678492307662964, Validation loss: 0.43931204080581665
Epoch: 68/300 - Train loss: 0.43257156014442444, Validation loss: 0.43549442291259766
Epoch: 69/300 - Train loss: 0.4284336566925049, Validation loss: 0.4312620162963867
Epoch: 70/300 - Train loss: 0.4243723750114441, Validation loss: 0.4277188181877136
Epoch: 71/300 - Train loss: 0.4203892648220062, Validation loss: 0.42389723658561707
Epoch: 72/300 - Train loss: 0.41648390889167786, Validation loss: 0.4198507070541382
Epoch: 73/300 - Train loss: 0.4126558303833008, Validation loss: 0.41614338755607605
Epoch: 74/300 - Train loss: 0.40890491008758545, Validation loss: 0.413263738155365
Epoch: 75/300 - Train loss: 0.4052317142486572, Validation loss: 0.4094141125679016
Epoch: 76/300 - Train loss: 0.4016358256340027, Validation loss: 0.4059794545173645
Epoch: 77/300 - Train loss: 0.3981158137321472, Validation loss: 0.40234750509262085
Epoch: 78/300 - Train loss: 0.3946702778339386, Validation loss: 0.39926624298095703
Epoch: 79/300 - Train loss: 0.39129745960235596, Validation loss: 0.3963066339492798
Epoch: 80/300 - Train loss: 0.3879954218864441, Validation loss: 0.3929346203804016
Epoch: 81/300 - Train loss: 0.38476261496543884, Validation loss: 0.389995813369751
Epoch: 82/300 - Train loss: 0.38159677386283875, Validation loss: 0.38703563809394836
Epoch: 83/300 - Train loss: 0.37849631905555725, Validation loss: 0.38435858488082886
Epoch: 84/300 - Train loss: 0.37545838952064514, Validation loss: 0.38093122839927673
Epoch: 85/300 - Train loss: 0.3724786639213562, Validation loss: 0.3775419294834137
Epoch: 86/300 - Train loss: 0.3695538640022278, Validation loss: 0.376134991645813
Epoch: 87/300 - Train loss: 0.36668291687965393, Validation loss: 0.37236449122428894
Epoch: 88/300 - Train loss: 0.3638606667518616, Validation loss: 0.37002238631248474
Epoch: 89/300 - Train loss: 0.36108580231666565, Validation loss: 0.36753612756729126
Epoch: 90/300 - Train loss: 0.35835856199264526, Validation loss: 0.3647361993789673
Epoch: 91/300 - Train loss: 0.35567933320999146, Validation loss: 0.3619842827320099
Epoch: 92/300 - Train loss: 0.3530459403991699, Validation loss: 0.35928067564964294
Epoch: 93/300 - Train loss: 0.3504588007926941, Validation loss: 0.35713672637939453
Epoch: 94/300 - Train loss: 0.3479175567626953, Validation loss: 0.3549751937389374
Epoch: 95/300 - Train loss: 0.3454206585884094, Validation loss: 0.3520074188709259
Epoch: 96/300 - Train loss: 0.34296494722366333, Validation loss: 0.35010793805122375
Epoch: 97/300 - Train loss: 0.34054937958717346, Validation loss: 0.34800586104393005
Epoch: 98/300 - Train loss: 0.3381686806678772, Validation loss: 0.3450307250022888
Epoch: 99/300 - Train loss: 0.3358253240585327, Validation loss: 0.343350350856781
Epoch: 100/300 - Train loss: 0.3335244953632355, Validation loss: 0.3406881093978882
Epoch: 101/300 - Train loss: 0.33126845955848694, Validation loss: 0.3386400043964386
Epoch: 102/300 - Train loss: 0.329055517911911, Validation loss: 0.33655351400375366
Epoch: 103/300 - Train loss: 0.3268873989582062, Validation loss: 0.33422568440437317
Epoch: 104/300 - Train loss: 0.32476121187210083, Validation loss: 0.3322753608226776
Epoch: 105/300 - Train loss: 0.32267501950263977, Validation loss: 0.3306616246700287
Epoch: 106/300 - Train loss: 0.32062828540802, Validation loss: 0.3285461664199829
Epoch: 107/300 - Train loss: 0.31861892342567444, Validation loss: 0.32611051201820374
Epoch: 108/300 - Train loss: 0.316646009683609, Validation loss: 0.32443898916244507
Epoch: 109/300 - Train loss: 0.3147076964378357, Validation loss: 0.3225175440311432
Epoch: 110/300 - Train loss: 0.31280404329299927, Validation loss: 0.3207419216632843
Epoch: 111/300 - Train loss: 0.3109344244003296, Validation loss: 0.31873294711112976
Epoch: 112/300 - Train loss: 0.3090971112251282, Validation loss: 0.3168857991695404
Epoch: 113/300 - Train loss: 0.3072914779186249, Validation loss: 0.314875990152359
Epoch: 114/300 - Train loss: 0.3055171072483063, Validation loss: 0.31347212195396423
Epoch: 115/300 - Train loss: 0.3037737011909485, Validation loss: 0.3122503161430359
Epoch: 116/300 - Train loss: 0.30206093192100525, Validation loss: 0.30965378880500793
Epoch: 117/300 - Train loss: 0.3003784716129303, Validation loss: 0.3087628483772278
Epoch: 118/300 - Train loss: 0.2987254858016968, Validation loss: 0.3069521486759186
Epoch: 119/300 - Train loss: 0.29710155725479126, Validation loss: 0.3052279055118561
Epoch: 120/300 - Train loss: 0.2955056130886078, Validation loss: 0.3040890693664551
Epoch: 121/300 - Train loss: 0.2939367890357971, Validation loss: 0.30233681201934814
Epoch: 122/300 - Train loss: 0.292394757270813, Validation loss: 0.30032023787498474
Epoch: 123/300 - Train loss: 0.29087892174720764, Validation loss: 0.29963168501853943
Epoch: 124/300 - Train loss: 0.28938835859298706, Validation loss: 0.2976319491863251
Epoch: 125/300 - Train loss: 0.2879229187965393, Validation loss: 0.2957875430583954
Epoch: 126/300 - Train loss: 0.28648245334625244, Validation loss: 0.29446661472320557
Epoch: 127/300 - Train loss: 0.28506624698638916, Validation loss: 0.29416200518608093
Epoch: 128/300 - Train loss: 0.2836741507053375, Validation loss: 0.29242143034935
Epoch: 129/300 - Train loss: 0.2823054790496826, Validation loss: 0.290183961391449
Epoch: 130/300 - Train loss: 0.28095993399620056, Validation loss: 0.28921258449554443
Epoch: 131/300 - Train loss: 0.27963683009147644, Validation loss: 0.2882039248943329
Epoch: 132/300 - Train loss: 0.2783358693122864, Validation loss: 0.28665342926979065
Epoch: 133/300 - Train loss: 0.2770567238330841, Validation loss: 0.2853895127773285
Epoch: 134/300 - Train loss: 0.27579888701438904, Validation loss: 0.2835729420185089
Epoch: 135/300 - Train loss: 0.27456188201904297, Validation loss: 0.2833018898963928
Epoch: 136/300 - Train loss: 0.2733451724052429, Validation loss: 0.28201672434806824
Epoch: 137/300 - Train loss: 0.2721484303474426, Validation loss: 0.2808676064014435
Epoch: 138/300 - Train loss: 0.27097123861312866, Validation loss: 0.28029903769493103
Epoch: 139/300 - Train loss: 0.2698131799697876, Validation loss: 0.278190016746521
Epoch: 140/300 - Train loss: 0.268673837184906, Validation loss: 0.27732905745506287
Epoch: 141/300 - Train loss: 0.26755276322364807, Validation loss: 0.2759700417518616
Epoch: 142/300 - Train loss: 0.26644954085350037, Validation loss: 0.27477937936782837
Epoch: 143/300 - Train loss: 0.26536399126052856, Validation loss: 0.2737664580345154
Epoch: 144/300 - Train loss: 0.2642957270145416, Validation loss: 0.2728261947631836
Epoch: 145/300 - Train loss: 0.2632443904876709, Validation loss: 0.2716229259967804
Epoch: 146/300 - Train loss: 0.26220953464508057, Validation loss: 0.27064934372901917
Epoch: 147/300 - Train loss: 0.2611907422542572, Validation loss: 0.2697715759277344
Epoch: 148/300 - Train loss: 0.2601880729198456, Validation loss: 0.2685939371585846
Epoch: 149/300 - Train loss: 0.25920096039772034, Validation loss: 0.2679893970489502
Epoch: 150/300 - Train loss: 0.25822901725769043, Validation loss: 0.26669934391975403
Epoch: 151/300 - Train loss: 0.2572718560695648, Validation loss: 0.2664012312889099
Epoch: 152/300 - Train loss: 0.25632935762405396, Validation loss: 0.26516517996788025
Epoch: 153/300 - Train loss: 0.2554011642932892, Validation loss: 0.2645033895969391
Epoch: 154/300 - Train loss: 0.2544870674610138, Validation loss: 0.26305070519447327
Epoch: 155/300 - Train loss: 0.25358688831329346, Validation loss: 0.26207730174064636
Epoch: 156/300 - Train loss: 0.25270047783851624, Validation loss: 0.26099950075149536
Epoch: 157/300 - Train loss: 0.25182726979255676, Validation loss: 0.26033520698547363
Epoch: 158/300 - Train loss: 0.2509671151638031, Validation loss: 0.25992095470428467
Epoch: 159/300 - Train loss: 0.25011980533599854, Validation loss: 0.25912564992904663
Epoch: 160/300 - Train loss: 0.2492852658033371, Validation loss: 0.258333683013916
Epoch: 161/300 - Train loss: 0.2484632283449173, Validation loss: 0.257474809885025
Epoch: 162/300 - Train loss: 0.2476533055305481, Validation loss: 0.25738298892974854
Epoch: 163/300 - Train loss: 0.24685543775558472, Validation loss: 0.25578466057777405
Epoch: 164/300 - Train loss: 0.24606940150260925, Validation loss: 0.25438404083251953
Epoch: 165/300 - Train loss: 0.24529491364955902, Validation loss: 0.2535979449748993
Epoch: 166/300 - Train loss: 0.24453173577785492, Validation loss: 0.25309258699417114
Epoch: 167/300 - Train loss: 0.24377970397472382, Validation loss: 0.2525290548801422
Epoch: 168/300 - Train loss: 0.2430385947227478, Validation loss: 0.2514917552471161
Epoch: 169/300 - Train loss: 0.24230816960334778, Validation loss: 0.25087422132492065
Epoch: 170/300 - Train loss: 0.24158823490142822, Validation loss: 0.25035229325294495
Epoch: 171/300 - Train loss: 0.24087859690189362, Validation loss: 0.24953040480613708
Epoch: 172/300 - Train loss: 0.24017927050590515, Validation loss: 0.24885238707065582
Epoch: 173/300 - Train loss: 0.23948991298675537, Validation loss: 0.24799805879592896
Epoch: 174/300 - Train loss: 0.23881033062934875, Validation loss: 0.24723489582538605
Epoch: 175/300 - Train loss: 0.23814041912555695, Validation loss: 0.24733200669288635
Epoch: 176/300 - Train loss: 0.2374800145626068, Validation loss: 0.2459791749715805
Epoch: 177/300 - Train loss: 0.2368289679288864, Validation loss: 0.24562376737594604
Epoch: 178/300 - Train loss: 0.23618710041046143, Validation loss: 0.2446509599685669
Epoch: 179/300 - Train loss: 0.23555417358875275, Validation loss: 0.24455878138542175
Epoch: 180/300 - Train loss: 0.23492994904518127, Validation loss: 0.24366746842861176
Epoch: 181/300 - Train loss: 0.23431435227394104, Validation loss: 0.24327610433101654
Epoch: 182/300 - Train loss: 0.2337072491645813, Validation loss: 0.24213649332523346
Epoch: 183/300 - Train loss: 0.2331084907054901, Validation loss: 0.2419154942035675
Epoch: 184/300 - Train loss: 0.23251792788505554, Validation loss: 0.2414541393518448
Epoch: 185/300 - Train loss: 0.23193535208702087, Validation loss: 0.24072769284248352
Epoch: 186/300 - Train loss: 0.23136086761951447, Validation loss: 0.24028567969799042
Epoch: 187/300 - Train loss: 0.230794295668602, Validation loss: 0.23958736658096313
Epoch: 188/300 - Train loss: 0.23023544251918793, Validation loss: 0.2388123720884323
Epoch: 189/300 - Train loss: 0.2296842336654663, Validation loss: 0.23839698731899261
Epoch: 190/300 - Train loss: 0.22914054989814758, Validation loss: 0.2376023679971695
Epoch: 191/300 - Train loss: 0.228604257106781, Validation loss: 0.2377438247203827
