Epoch: 1/300 - Train loss: 0.6911770105361938, Validation loss: 0.6900554895401001
Epoch: 2/300 - Train loss: 0.6882796883583069, Validation loss: 0.687183678150177
Epoch: 3/300 - Train loss: 0.6853771209716797, Validation loss: 0.6843515634536743
Epoch: 4/300 - Train loss: 0.6824541687965393, Validation loss: 0.6813161969184875
Epoch: 5/300 - Train loss: 0.6795047521591187, Validation loss: 0.6784303784370422
Epoch: 6/300 - Train loss: 0.6765221357345581, Validation loss: 0.6754608154296875
Epoch: 7/300 - Train loss: 0.6734975576400757, Validation loss: 0.6722608208656311
Epoch: 8/300 - Train loss: 0.6704264879226685, Validation loss: 0.6692436337471008
Epoch: 9/300 - Train loss: 0.667298436164856, Validation loss: 0.6660356521606445
Epoch: 10/300 - Train loss: 0.6641088724136353, Validation loss: 0.6629405617713928
Epoch: 11/300 - Train loss: 0.6608550548553467, Validation loss: 0.6596330404281616
Epoch: 12/300 - Train loss: 0.6575295925140381, Validation loss: 0.6561841368675232
Epoch: 13/300 - Train loss: 0.6541309952735901, Validation loss: 0.6526607275009155
Epoch: 14/300 - Train loss: 0.6506568789482117, Validation loss: 0.6492545008659363
Epoch: 15/300 - Train loss: 0.6471047401428223, Validation loss: 0.6456637382507324
Epoch: 16/300 - Train loss: 0.6434770822525024, Validation loss: 0.6418682336807251
Epoch: 17/300 - Train loss: 0.6397696137428284, Validation loss: 0.6383002996444702
Epoch: 18/300 - Train loss: 0.635979175567627, Validation loss: 0.6345880627632141
Epoch: 19/300 - Train loss: 0.6321040987968445, Validation loss: 0.6303651332855225
Epoch: 20/300 - Train loss: 0.6281452775001526, Validation loss: 0.6266353726387024
Epoch: 21/300 - Train loss: 0.6241039037704468, Validation loss: 0.6225541830062866
Epoch: 22/300 - Train loss: 0.6199817657470703, Validation loss: 0.6183673143386841
Epoch: 23/300 - Train loss: 0.6157793998718262, Validation loss: 0.6142123341560364
Epoch: 24/300 - Train loss: 0.6114965677261353, Validation loss: 0.6098421812057495
Epoch: 25/300 - Train loss: 0.6071376800537109, Validation loss: 0.6054885983467102
Epoch: 26/300 - Train loss: 0.6027054786682129, Validation loss: 0.601273238658905
Epoch: 27/300 - Train loss: 0.5982098579406738, Validation loss: 0.5967445373535156
Epoch: 28/300 - Train loss: 0.5936554074287415, Validation loss: 0.5922254323959351
Epoch: 29/300 - Train loss: 0.5890410542488098, Validation loss: 0.5875499248504639
Epoch: 30/300 - Train loss: 0.5843768119812012, Validation loss: 0.5829163193702698
Epoch: 31/300 - Train loss: 0.5796735882759094, Validation loss: 0.5782889723777771
Epoch: 32/300 - Train loss: 0.5749363303184509, Validation loss: 0.5735790133476257
Epoch: 33/300 - Train loss: 0.5701722502708435, Validation loss: 0.5688402056694031
Epoch: 34/300 - Train loss: 0.5653860569000244, Validation loss: 0.5642241835594177
Epoch: 35/300 - Train loss: 0.5605872869491577, Validation loss: 0.5594520568847656
Epoch: 36/300 - Train loss: 0.5557810664176941, Validation loss: 0.5549595952033997
Epoch: 37/300 - Train loss: 0.5509768724441528, Validation loss: 0.5502454042434692
Epoch: 38/300 - Train loss: 0.5461804270744324, Validation loss: 0.5454767942428589
Epoch: 39/300 - Train loss: 0.5413997769355774, Validation loss: 0.5409107804298401
Epoch: 40/300 - Train loss: 0.5366424322128296, Validation loss: 0.5362130999565125
Epoch: 41/300 - Train loss: 0.5319129228591919, Validation loss: 0.5315929055213928
Epoch: 42/300 - Train loss: 0.5272155404090881, Validation loss: 0.526959240436554
Epoch: 43/300 - Train loss: 0.5225574970245361, Validation loss: 0.5227017402648926
Epoch: 44/300 - Train loss: 0.5179446935653687, Validation loss: 0.5180279016494751
Epoch: 45/300 - Train loss: 0.5133787989616394, Validation loss: 0.5135136246681213
Epoch: 46/300 - Train loss: 0.508866548538208, Validation loss: 0.5095404386520386
Epoch: 47/300 - Train loss: 0.5044130682945251, Validation loss: 0.5048423409461975
Epoch: 48/300 - Train loss: 0.5000230073928833, Validation loss: 0.5005245804786682
Epoch: 49/300 - Train loss: 0.4957018196582794, Validation loss: 0.4966770112514496
Epoch: 50/300 - Train loss: 0.49145224690437317, Validation loss: 0.49253812432289124
Epoch: 51/300 - Train loss: 0.4872760772705078, Validation loss: 0.4886350631713867
Epoch: 52/300 - Train loss: 0.48317673802375793, Validation loss: 0.48487263917922974
Epoch: 53/300 - Train loss: 0.47915568947792053, Validation loss: 0.48054221272468567
Epoch: 54/300 - Train loss: 0.4752155840396881, Validation loss: 0.4771376848220825
Epoch: 55/300 - Train loss: 0.47135812044143677, Validation loss: 0.47332337498664856
Epoch: 56/300 - Train loss: 0.46758341789245605, Validation loss: 0.4696006178855896
Epoch: 57/300 - Train loss: 0.46389394998550415, Validation loss: 0.466127872467041
Epoch: 58/300 - Train loss: 0.4602900743484497, Validation loss: 0.4629567563533783
Epoch: 59/300 - Train loss: 0.4567714035511017, Validation loss: 0.4590802490711212
Epoch: 60/300 - Train loss: 0.4533381164073944, Validation loss: 0.4563184380531311
Epoch: 61/300 - Train loss: 0.44999054074287415, Validation loss: 0.45261135697364807
Epoch: 62/300 - Train loss: 0.44672828912734985, Validation loss: 0.4494185447692871
Epoch: 63/300 - Train loss: 0.4435528814792633, Validation loss: 0.4471229314804077
Epoch: 64/300 - Train loss: 0.4404626786708832, Validation loss: 0.44349008798599243
Epoch: 65/300 - Train loss: 0.4374576807022095, Validation loss: 0.4406992793083191
Epoch: 66/300 - Train loss: 0.4345359206199646, Validation loss: 0.43853506445884705
Epoch: 67/300 - Train loss: 0.43169665336608887, Validation loss: 0.43525055050849915
Epoch: 68/300 - Train loss: 0.4289383888244629, Validation loss: 0.4322734773159027
Epoch: 69/300 - Train loss: 0.42625993490219116, Validation loss: 0.4304007291793823
Epoch: 70/300 - Train loss: 0.4236604571342468, Validation loss: 0.4277563989162445
Epoch: 71/300 - Train loss: 0.4211377501487732, Validation loss: 0.42509710788726807
Epoch: 72/300 - Train loss: 0.4186899662017822, Validation loss: 0.4229085147380829
Epoch: 73/300 - Train loss: 0.4163159430027008, Validation loss: 0.4211186170578003
Epoch: 74/300 - Train loss: 0.41401341557502747, Validation loss: 0.41834545135498047
Epoch: 75/300 - Train loss: 0.4117814898490906, Validation loss: 0.4166382849216461
Epoch: 76/300 - Train loss: 0.40961921215057373, Validation loss: 0.41441237926483154
Epoch: 77/300 - Train loss: 0.40752387046813965, Validation loss: 0.4124501645565033
Epoch: 78/300 - Train loss: 0.4054945111274719, Validation loss: 0.41011205315589905
Epoch: 79/300 - Train loss: 0.4035288989543915, Validation loss: 0.408326119184494
Epoch: 80/300 - Train loss: 0.4016248881816864, Validation loss: 0.40608587861061096
Epoch: 81/300 - Train loss: 0.3997810482978821, Validation loss: 0.40444236993789673
Epoch: 82/300 - Train loss: 0.3979949951171875, Validation loss: 0.403404176235199
Epoch: 83/300 - Train loss: 0.3962654173374176, Validation loss: 0.40162229537963867
Epoch: 84/300 - Train loss: 0.3945896029472351, Validation loss: 0.40007272362709045
Epoch: 85/300 - Train loss: 0.39296600222587585, Validation loss: 0.39831510186195374
Epoch: 86/300 - Train loss: 0.39139267802238464, Validation loss: 0.3966372013092041
Epoch: 87/300 - Train loss: 0.38986822962760925, Validation loss: 0.39551180601119995
Epoch: 88/300 - Train loss: 0.38839077949523926, Validation loss: 0.39388689398765564
Epoch: 89/300 - Train loss: 0.38695836067199707, Validation loss: 0.39264971017837524
Epoch: 90/300 - Train loss: 0.3855692744255066, Validation loss: 0.3913884460926056
Epoch: 91/300 - Train loss: 0.38422250747680664, Validation loss: 0.3902721107006073
Epoch: 92/300 - Train loss: 0.3829161524772644, Validation loss: 0.3884771764278412
Epoch: 93/300 - Train loss: 0.38164886832237244, Validation loss: 0.387408971786499
Epoch: 94/300 - Train loss: 0.38041943311691284, Validation loss: 0.386572927236557
Epoch: 95/300 - Train loss: 0.37922602891921997, Validation loss: 0.38480496406555176
Epoch: 96/300 - Train loss: 0.3780672252178192, Validation loss: 0.3845260441303253
Epoch: 97/300 - Train loss: 0.3769419491291046, Validation loss: 0.3826446831226349
Epoch: 98/300 - Train loss: 0.37584882974624634, Validation loss: 0.38151121139526367
Epoch: 99/300 - Train loss: 0.3747864365577698, Validation loss: 0.3805367350578308
Epoch: 100/300 - Train loss: 0.37375375628471375, Validation loss: 0.3800497055053711
Epoch: 101/300 - Train loss: 0.37274980545043945, Validation loss: 0.3788694739341736
Epoch: 102/300 - Train loss: 0.3717733323574066, Validation loss: 0.3783756494522095
Epoch: 103/300 - Train loss: 0.37082338333129883, Validation loss: 0.3768186867237091
Epoch: 104/300 - Train loss: 0.36989906430244446, Validation loss: 0.37615516781806946
Epoch: 105/300 - Train loss: 0.3689992129802704, Validation loss: 0.37577855587005615
Epoch: 106/300 - Train loss: 0.3681226372718811, Validation loss: 0.3742692768573761
Epoch: 107/300 - Train loss: 0.36726808547973633, Validation loss: 0.3732595145702362
Epoch: 108/300 - Train loss: 0.36643487215042114, Validation loss: 0.3728906512260437
Epoch: 109/300 - Train loss: 0.3656224310398102, Validation loss: 0.3720865845680237
Epoch: 110/300 - Train loss: 0.36482998728752136, Validation loss: 0.37158694863319397
Epoch: 111/300 - Train loss: 0.36405685544013977, Validation loss: 0.37034541368484497
Epoch: 112/300 - Train loss: 0.3633021116256714, Validation loss: 0.36940768361091614
Epoch: 113/300 - Train loss: 0.3625650703907013, Validation loss: 0.3692362904548645
Epoch: 114/300 - Train loss: 0.3618452548980713, Validation loss: 0.3683031499385834
Epoch: 115/300 - Train loss: 0.36114203929901123, Validation loss: 0.3672926127910614
Epoch: 116/300 - Train loss: 0.3604544997215271, Validation loss: 0.3671889007091522
Epoch: 117/300 - Train loss: 0.3597819209098816, Validation loss: 0.36610811948776245
Epoch: 118/300 - Train loss: 0.35912391543388367, Validation loss: 0.3657562732696533
Epoch: 119/300 - Train loss: 0.3584800660610199, Validation loss: 0.3648183047771454
Epoch: 120/300 - Train loss: 0.35784971714019775, Validation loss: 0.36390554904937744
Epoch: 121/300 - Train loss: 0.3572324812412262, Validation loss: 0.3632996380329132
Epoch: 122/300 - Train loss: 0.35662785172462463, Validation loss: 0.36263924837112427
Epoch: 123/300 - Train loss: 0.35603538155555725, Validation loss: 0.3625696301460266
Epoch: 124/300 - Train loss: 0.3554545044898987, Validation loss: 0.3614886701107025
Epoch: 125/300 - Train loss: 0.3548850119113922, Validation loss: 0.36150267720222473
Epoch: 126/300 - Train loss: 0.354326456785202, Validation loss: 0.36125072836875916
