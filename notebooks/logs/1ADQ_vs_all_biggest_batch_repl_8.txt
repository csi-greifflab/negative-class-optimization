Epoch: 1/100 - Train loss: 0.6925784945487976, Validation loss: 0.6908827424049377
Epoch: 2/100 - Train loss: 0.6905190944671631, Validation loss: 0.6889637112617493
Epoch: 3/100 - Train loss: 0.6884334087371826, Validation loss: 0.6870168447494507
Epoch: 4/100 - Train loss: 0.6862866878509521, Validation loss: 0.6849440336227417
Epoch: 5/100 - Train loss: 0.6840505599975586, Validation loss: 0.6827592849731445
Epoch: 6/100 - Train loss: 0.6817015409469604, Validation loss: 0.6805086731910706
Epoch: 7/100 - Train loss: 0.6792281866073608, Validation loss: 0.6780687570571899
Epoch: 8/100 - Train loss: 0.6766181588172913, Validation loss: 0.6756142377853394
Epoch: 9/100 - Train loss: 0.6738727688789368, Validation loss: 0.6729059815406799
Epoch: 10/100 - Train loss: 0.6710008382797241, Validation loss: 0.6700411438941956
Epoch: 11/100 - Train loss: 0.6680076122283936, Validation loss: 0.667111873626709
Epoch: 12/100 - Train loss: 0.6649066805839539, Validation loss: 0.663952648639679
Epoch: 13/100 - Train loss: 0.6617061495780945, Validation loss: 0.6608478426933289
Epoch: 14/100 - Train loss: 0.6584245562553406, Validation loss: 0.6575828790664673
Epoch: 15/100 - Train loss: 0.6550789475440979, Validation loss: 0.6543831825256348
Epoch: 16/100 - Train loss: 0.6516838669776917, Validation loss: 0.6510759592056274
Epoch: 17/100 - Train loss: 0.6482499241828918, Validation loss: 0.6478026509284973
Epoch: 18/100 - Train loss: 0.6447892189025879, Validation loss: 0.6443807482719421
Epoch: 19/100 - Train loss: 0.6413196325302124, Validation loss: 0.6410271525382996
Epoch: 20/100 - Train loss: 0.6378424763679504, Validation loss: 0.6377596855163574
Epoch: 21/100 - Train loss: 0.6343603134155273, Validation loss: 0.6342464685440063
Epoch: 22/100 - Train loss: 0.6308819055557251, Validation loss: 0.6309499740600586
Epoch: 23/100 - Train loss: 0.6274121403694153, Validation loss: 0.627628743648529
Epoch: 24/100 - Train loss: 0.6239556670188904, Validation loss: 0.6241582632064819
Epoch: 25/100 - Train loss: 0.6205154061317444, Validation loss: 0.6208592653274536
Epoch: 26/100 - Train loss: 0.6170933842658997, Validation loss: 0.6177532076835632
Epoch: 27/100 - Train loss: 0.6136922836303711, Validation loss: 0.6145309209823608
Epoch: 28/100 - Train loss: 0.6103156805038452, Validation loss: 0.6117068529129028
Epoch: 29/100 - Train loss: 0.6069703102111816, Validation loss: 0.608023464679718
Epoch: 30/100 - Train loss: 0.6036592721939087, Validation loss: 0.6048256754875183
Epoch: 31/100 - Train loss: 0.600383460521698, Validation loss: 0.6017208099365234
Epoch: 32/100 - Train loss: 0.5971459746360779, Validation loss: 0.598604679107666
Epoch: 33/100 - Train loss: 0.5939507484436035, Validation loss: 0.595641016960144
Epoch: 34/100 - Train loss: 0.5907990336418152, Validation loss: 0.5928012728691101
Epoch: 35/100 - Train loss: 0.5876956582069397, Validation loss: 0.5899918675422668
Epoch: 36/100 - Train loss: 0.5846422910690308, Validation loss: 0.5868861675262451
Epoch: 37/100 - Train loss: 0.5816397666931152, Validation loss: 0.5840353965759277
Epoch: 38/100 - Train loss: 0.578691303730011, Validation loss: 0.5814089775085449
Epoch: 39/100 - Train loss: 0.5757989287376404, Validation loss: 0.5784117579460144
Epoch: 40/100 - Train loss: 0.5729642510414124, Validation loss: 0.576236367225647
Epoch: 41/100 - Train loss: 0.570187509059906, Validation loss: 0.5733954906463623
Epoch: 42/100 - Train loss: 0.5674700736999512, Validation loss: 0.5706808567047119
Epoch: 43/100 - Train loss: 0.5648111701011658, Validation loss: 0.5682427883148193
Epoch: 44/100 - Train loss: 0.5622117519378662, Validation loss: 0.5657700896263123
Epoch: 45/100 - Train loss: 0.5596725940704346, Validation loss: 0.5632468461990356
Epoch: 46/100 - Train loss: 0.5571936368942261, Validation loss: 0.5609346032142639
Epoch: 47/100 - Train loss: 0.5547746419906616, Validation loss: 0.5588746666908264
Epoch: 48/100 - Train loss: 0.5524147152900696, Validation loss: 0.5565955638885498
Epoch: 49/100 - Train loss: 0.5501142740249634, Validation loss: 0.5544042587280273
Epoch: 50/100 - Train loss: 0.5478723049163818, Validation loss: 0.5525838732719421
Epoch: 51/100 - Train loss: 0.5456879138946533, Validation loss: 0.5502987504005432
Epoch: 52/100 - Train loss: 0.5435607433319092, Validation loss: 0.5486186742782593
Epoch: 53/100 - Train loss: 0.5414900183677673, Validation loss: 0.5464466214179993
Epoch: 54/100 - Train loss: 0.5394752025604248, Validation loss: 0.5448673367500305
Epoch: 55/100 - Train loss: 0.5375151038169861, Validation loss: 0.5432407259941101
Epoch: 56/100 - Train loss: 0.5356093049049377, Validation loss: 0.5408074855804443
Epoch: 57/100 - Train loss: 0.533755898475647, Validation loss: 0.5390400290489197
Epoch: 58/100 - Train loss: 0.5319550633430481, Validation loss: 0.5377084612846375
Epoch: 59/100 - Train loss: 0.5302044153213501, Validation loss: 0.5360187292098999
Epoch: 60/100 - Train loss: 0.5285049676895142, Validation loss: 0.5342334508895874
Epoch: 61/100 - Train loss: 0.5268546938896179, Validation loss: 0.5332694053649902
Epoch: 62/100 - Train loss: 0.5252509713172913, Validation loss: 0.5318194627761841
Epoch: 63/100 - Train loss: 0.523691713809967, Validation loss: 0.529987096786499
Epoch: 64/100 - Train loss: 0.5221766233444214, Validation loss: 0.5287743210792542
Epoch: 65/100 - Train loss: 0.520704984664917, Validation loss: 0.527407705783844
Epoch: 66/100 - Train loss: 0.5192757844924927, Validation loss: 0.5255435705184937
Epoch: 67/100 - Train loss: 0.5178884267807007, Validation loss: 0.5248363018035889
Epoch: 68/100 - Train loss: 0.516539990901947, Validation loss: 0.5229061841964722
Epoch: 69/100 - Train loss: 0.5152292251586914, Validation loss: 0.5220391750335693
Epoch: 70/100 - Train loss: 0.5139545202255249, Validation loss: 0.5206380486488342
Epoch: 71/100 - Train loss: 0.5127132534980774, Validation loss: 0.5203111171722412
Epoch: 72/100 - Train loss: 0.5115054845809937, Validation loss: 0.5182870626449585
Epoch: 73/100 - Train loss: 0.5103304982185364, Validation loss: 0.517842173576355
Epoch: 74/100 - Train loss: 0.5091855525970459, Validation loss: 0.517421543598175
Epoch: 75/100 - Train loss: 0.5080689787864685, Validation loss: 0.516122579574585
Epoch: 76/100 - Train loss: 0.5069798827171326, Validation loss: 0.5142913460731506
Epoch: 77/100 - Train loss: 0.5059160590171814, Validation loss: 0.5142157077789307
Epoch: 78/100 - Train loss: 0.5048772692680359, Validation loss: 0.5132830142974854
Epoch: 79/100 - Train loss: 0.5038625001907349, Validation loss: 0.511981725692749
Epoch: 80/100 - Train loss: 0.5028710961341858, Validation loss: 0.5108705759048462
Epoch: 81/100 - Train loss: 0.5019000172615051, Validation loss: 0.5103269219398499
Epoch: 82/100 - Train loss: 0.5009470582008362, Validation loss: 0.5092820525169373
Epoch: 83/100 - Train loss: 0.5000132322311401, Validation loss: 0.5085060596466064
Epoch: 84/100 - Train loss: 0.49909570813179016, Validation loss: 0.507799506187439
Epoch: 85/100 - Train loss: 0.49819499254226685, Validation loss: 0.5074164271354675
Epoch: 86/100 - Train loss: 0.4973096549510956, Validation loss: 0.5064494609832764
Epoch: 87/100 - Train loss: 0.49643802642822266, Validation loss: 0.505410373210907
Epoch: 88/100 - Train loss: 0.4955783486366272, Validation loss: 0.5046659111976624
Epoch: 89/100 - Train loss: 0.49473056197166443, Validation loss: 0.5032146573066711
Epoch: 90/100 - Train loss: 0.49389418959617615, Validation loss: 0.5031173229217529
Epoch: 91/100 - Train loss: 0.49306735396385193, Validation loss: 0.5022193789482117
Epoch: 92/100 - Train loss: 0.4922489523887634, Validation loss: 0.5010393261909485
Epoch: 93/100 - Train loss: 0.4914391338825226, Validation loss: 0.5011745691299438
Epoch: 94/100 - Train loss: 0.4906345307826996, Validation loss: 0.49968045949935913
Epoch: 95/100 - Train loss: 0.48983606696128845, Validation loss: 0.4986945390701294
Epoch: 96/100 - Train loss: 0.4890437424182892, Validation loss: 0.49758097529411316
Epoch: 97/100 - Train loss: 0.4882594048976898, Validation loss: 0.49776265025138855
Epoch: 98/100 - Train loss: 0.48748135566711426, Validation loss: 0.4966503083705902
Epoch: 99/100 - Train loss: 0.4867076277732849, Validation loss: 0.4955359101295471
Epoch: 100/100 - Train loss: 0.4859364628791809, Validation loss: 0.49496394395828247
Epoch: 1/300 - Train loss: 0.6942799687385559, Validation loss: 0.6938381195068359
Epoch: 2/300 - Train loss: 0.6927191615104675, Validation loss: 0.6923131942749023
Epoch: 3/300 - Train loss: 0.6911643743515015, Validation loss: 0.6906457543373108
Epoch: 4/300 - Train loss: 0.6895832419395447, Validation loss: 0.6890320181846619
Epoch: 5/300 - Train loss: 0.6879581809043884, Validation loss: 0.687397301197052
Epoch: 6/300 - Train loss: 0.6862731575965881, Validation loss: 0.6857098937034607
Epoch: 7/300 - Train loss: 0.6845223307609558, Validation loss: 0.6839819550514221
Epoch: 8/300 - Train loss: 0.6826955080032349, Validation loss: 0.6821108460426331
Epoch: 9/300 - Train loss: 0.6807937026023865, Validation loss: 0.6801032423973083
Epoch: 10/300 - Train loss: 0.6788194179534912, Validation loss: 0.6782675385475159
Epoch: 11/300 - Train loss: 0.6767737865447998, Validation loss: 0.67626953125
Epoch: 12/300 - Train loss: 0.6746567487716675, Validation loss: 0.6740254163742065
Epoch: 13/300 - Train loss: 0.6724764108657837, Validation loss: 0.6719228029251099
Epoch: 14/300 - Train loss: 0.6702366471290588, Validation loss: 0.6697731018066406
Epoch: 15/300 - Train loss: 0.6679405570030212, Validation loss: 0.6673980355262756
Epoch: 16/300 - Train loss: 0.6655887365341187, Validation loss: 0.6651130318641663
Epoch: 17/300 - Train loss: 0.6631869673728943, Validation loss: 0.6626836061477661
Epoch: 18/300 - Train loss: 0.6607379913330078, Validation loss: 0.660401463508606
Epoch: 19/300 - Train loss: 0.658244252204895, Validation loss: 0.6577484607696533
Epoch: 20/300 - Train loss: 0.6557112336158752, Validation loss: 0.6554729342460632
Epoch: 21/300 - Train loss: 0.6531404852867126, Validation loss: 0.652988612651825
Epoch: 22/300 - Train loss: 0.6505319476127625, Validation loss: 0.6504445672035217
Epoch: 23/300 - Train loss: 0.6478884816169739, Validation loss: 0.6478039026260376
Epoch: 24/300 - Train loss: 0.6452157497406006, Validation loss: 0.6451895236968994
Epoch: 25/300 - Train loss: 0.6425143480300903, Validation loss: 0.6427710056304932
Epoch: 26/300 - Train loss: 0.6397843956947327, Validation loss: 0.6400719881057739
Epoch: 27/300 - Train loss: 0.6370286345481873, Validation loss: 0.6369612216949463
Epoch: 28/300 - Train loss: 0.6342505812644958, Validation loss: 0.6346524953842163
Epoch: 29/300 - Train loss: 0.6314534544944763, Validation loss: 0.6317963600158691
Epoch: 30/300 - Train loss: 0.6286385655403137, Validation loss: 0.6292011141777039
Epoch: 31/300 - Train loss: 0.6258082985877991, Validation loss: 0.6263951659202576
Epoch: 32/300 - Train loss: 0.6229664087295532, Validation loss: 0.6239238977432251
Epoch: 33/300 - Train loss: 0.6201157569885254, Validation loss: 0.6210540533065796
Epoch: 34/300 - Train loss: 0.617260217666626, Validation loss: 0.618564248085022
Epoch: 35/300 - Train loss: 0.6144039034843445, Validation loss: 0.6156828999519348
Epoch: 36/300 - Train loss: 0.6115486025810242, Validation loss: 0.6126020550727844
Epoch: 37/300 - Train loss: 0.6086971759796143, Validation loss: 0.6103867888450623
Epoch: 38/300 - Train loss: 0.605852484703064, Validation loss: 0.6075722575187683
Epoch: 39/300 - Train loss: 0.6030175685882568, Validation loss: 0.6049221158027649
Epoch: 40/300 - Train loss: 0.6001935601234436, Validation loss: 0.6020609140396118
Epoch: 41/300 - Train loss: 0.5973833203315735, Validation loss: 0.5994200110435486
Epoch: 42/300 - Train loss: 0.5945896506309509, Validation loss: 0.5965503454208374
Epoch: 43/300 - Train loss: 0.5918145179748535, Validation loss: 0.5943529009819031
Epoch: 44/300 - Train loss: 0.5890604853630066, Validation loss: 0.5916150808334351
Epoch: 45/300 - Train loss: 0.586330235004425, Validation loss: 0.5890262126922607
Epoch: 46/300 - Train loss: 0.5836249589920044, Validation loss: 0.5863893628120422
Epoch: 47/300 - Train loss: 0.5809468626976013, Validation loss: 0.5838620662689209
Epoch: 48/300 - Train loss: 0.5782979130744934, Validation loss: 0.5813484787940979
Epoch: 49/300 - Train loss: 0.5756799578666687, Validation loss: 0.5790920257568359
Epoch: 50/300 - Train loss: 0.5730945467948914, Validation loss: 0.5763230919837952
Epoch: 51/300 - Train loss: 0.5705437064170837, Validation loss: 0.5741459131240845
Epoch: 52/300 - Train loss: 0.5680285096168518, Validation loss: 0.5717967748641968
Epoch: 53/300 - Train loss: 0.5655498504638672, Validation loss: 0.5692701935768127
Epoch: 54/300 - Train loss: 0.5631090402603149, Validation loss: 0.5671566724777222
Epoch: 55/300 - Train loss: 0.5607084631919861, Validation loss: 0.5647768974304199
Epoch: 56/300 - Train loss: 0.5583482384681702, Validation loss: 0.5622103214263916
Epoch: 57/300 - Train loss: 0.5560289621353149, Validation loss: 0.5603283643722534
Epoch: 58/300 - Train loss: 0.5537512898445129, Validation loss: 0.5582609176635742
Epoch: 59/300 - Train loss: 0.5515152215957642, Validation loss: 0.5562212467193604
Epoch: 60/300 - Train loss: 0.5493212342262268, Validation loss: 0.5542786717414856
Epoch: 61/300 - Train loss: 0.547170102596283, Validation loss: 0.5520492792129517
Epoch: 62/300 - Train loss: 0.5450611114501953, Validation loss: 0.5500550866127014
Epoch: 63/300 - Train loss: 0.5429948568344116, Validation loss: 0.5480350852012634
Epoch: 64/300 - Train loss: 0.5409713387489319, Validation loss: 0.5463333129882812
Epoch: 65/300 - Train loss: 0.5389910936355591, Validation loss: 0.5445047616958618
Epoch: 66/300 - Train loss: 0.537053108215332, Validation loss: 0.5426319241523743
Epoch: 67/300 - Train loss: 0.5351558923721313, Validation loss: 0.5409113764762878
Epoch: 68/300 - Train loss: 0.5333002209663391, Validation loss: 0.5390380024909973
Epoch: 69/300 - Train loss: 0.5314849019050598, Validation loss: 0.5372223258018494
Epoch: 70/300 - Train loss: 0.5297106504440308, Validation loss: 0.5355051159858704
Epoch: 71/300 - Train loss: 0.527975857257843, Validation loss: 0.5339633822441101
Epoch: 72/300 - Train loss: 0.526279628276825, Validation loss: 0.5327617526054382
Epoch: 73/300 - Train loss: 0.5246214270591736, Validation loss: 0.532052218914032
Epoch: 74/300 - Train loss: 0.5229994058609009, Validation loss: 0.52986079454422
Epoch: 75/300 - Train loss: 0.5214135646820068, Validation loss: 0.5277310013771057
Epoch: 76/300 - Train loss: 0.5198625922203064, Validation loss: 0.5263126492500305
Epoch: 77/300 - Train loss: 0.518343985080719, Validation loss: 0.5256115794181824
Epoch: 78/300 - Train loss: 0.5168570876121521, Validation loss: 0.5238468647003174
Epoch: 79/300 - Train loss: 0.5154018998146057, Validation loss: 0.5224201083183289
Epoch: 80/300 - Train loss: 0.5139763951301575, Validation loss: 0.5214605331420898
Epoch: 81/300 - Train loss: 0.5125793814659119, Validation loss: 0.5198907256126404
Epoch: 82/300 - Train loss: 0.5112094879150391, Validation loss: 0.5185699462890625
Epoch: 83/300 - Train loss: 0.5098649263381958, Validation loss: 0.517625629901886
Epoch: 84/300 - Train loss: 0.5085440278053284, Validation loss: 0.5160892009735107
Epoch: 85/300 - Train loss: 0.5072457194328308, Validation loss: 0.5145719051361084
Epoch: 86/300 - Train loss: 0.5059689283370972, Validation loss: 0.5133800506591797
Epoch: 87/300 - Train loss: 0.5047134160995483, Validation loss: 0.5130192637443542
Epoch: 88/300 - Train loss: 0.5034795999526978, Validation loss: 0.5120906829833984
Epoch: 89/300 - Train loss: 0.5022661685943604, Validation loss: 0.5100250840187073
Epoch: 90/300 - Train loss: 0.5010719895362854, Validation loss: 0.5097495317459106
Epoch: 91/300 - Train loss: 0.49989569187164307, Validation loss: 0.5081606507301331
Epoch: 92/300 - Train loss: 0.49873507022857666, Validation loss: 0.5072541236877441
Epoch: 93/300 - Train loss: 0.4975908398628235, Validation loss: 0.5059937834739685
Epoch: 94/300 - Train loss: 0.4964617192745209, Validation loss: 0.5049670934677124
Epoch: 95/300 - Train loss: 0.4953468441963196, Validation loss: 0.5040913820266724
Epoch: 96/300 - Train loss: 0.4942450523376465, Validation loss: 0.5029990077018738
Epoch: 97/300 - Train loss: 0.4931570887565613, Validation loss: 0.5023971199989319
Epoch: 98/300 - Train loss: 0.4920809268951416, Validation loss: 0.5016587376594543
Epoch: 99/300 - Train loss: 0.4910148084163666, Validation loss: 0.5001032948493958
Epoch: 100/300 - Train loss: 0.4899580180644989, Validation loss: 0.4993675947189331
Epoch: 101/300 - Train loss: 0.48891130089759827, Validation loss: 0.49852725863456726
Epoch: 102/300 - Train loss: 0.48787444829940796, Validation loss: 0.4982064366340637
Epoch: 103/300 - Train loss: 0.48684731125831604, Validation loss: 0.49696558713912964
Epoch: 104/300 - Train loss: 0.4858277440071106, Validation loss: 0.49540185928344727
Epoch: 105/300 - Train loss: 0.484816312789917, Validation loss: 0.49483025074005127
Epoch: 106/300 - Train loss: 0.48381051421165466, Validation loss: 0.49383944272994995
Epoch: 107/300 - Train loss: 0.4828130900859833, Validation loss: 0.49332118034362793
Epoch: 108/300 - Train loss: 0.4818224012851715, Validation loss: 0.49241533875465393
Epoch: 109/300 - Train loss: 0.48083850741386414, Validation loss: 0.49154603481292725
Epoch: 110/300 - Train loss: 0.47986218333244324, Validation loss: 0.4905657470226288
Epoch: 111/300 - Train loss: 0.4788925349712372, Validation loss: 0.4898305833339691
Epoch: 112/300 - Train loss: 0.4779294729232788, Validation loss: 0.4891994893550873
Epoch: 113/300 - Train loss: 0.4769701659679413, Validation loss: 0.4875020682811737
Epoch: 114/300 - Train loss: 0.47601553797721863, Validation loss: 0.48754966259002686
Epoch: 115/300 - Train loss: 0.47506630420684814, Validation loss: 0.48612937331199646
Epoch: 116/300 - Train loss: 0.474122017621994, Validation loss: 0.4855131208896637
Epoch: 117/300 - Train loss: 0.4731845557689667, Validation loss: 0.4842054843902588
Epoch: 118/300 - Train loss: 0.4722519814968109, Validation loss: 0.4841630458831787
Epoch: 119/300 - Train loss: 0.47132617235183716, Validation loss: 0.48335325717926025
Epoch: 120/300 - Train loss: 0.47040754556655884, Validation loss: 0.481580913066864
Epoch: 121/300 - Train loss: 0.4694952368736267, Validation loss: 0.4806292951107025
Epoch: 122/300 - Train loss: 0.46858924627304077, Validation loss: 0.48025041818618774
Epoch: 123/300 - Train loss: 0.46768832206726074, Validation loss: 0.479448139667511
Epoch: 124/300 - Train loss: 0.46679243445396423, Validation loss: 0.47906002402305603
Epoch: 125/300 - Train loss: 0.46590304374694824, Validation loss: 0.4777924418449402
Epoch: 126/300 - Train loss: 0.46502143144607544, Validation loss: 0.4767473340034485
Epoch: 127/300 - Train loss: 0.46414652466773987, Validation loss: 0.47711771726608276
Epoch: 128/300 - Train loss: 0.4632788300514221, Validation loss: 0.47498685121536255
Epoch: 129/300 - Train loss: 0.4624182879924774, Validation loss: 0.47462934255599976
Epoch: 130/300 - Train loss: 0.4615662097930908, Validation loss: 0.4738200008869171
Epoch: 131/300 - Train loss: 0.46071872115135193, Validation loss: 0.47306010127067566
Epoch: 132/300 - Train loss: 0.45987680554389954, Validation loss: 0.47231751680374146
Epoch: 133/300 - Train loss: 0.4590415358543396, Validation loss: 0.47173038125038147
Epoch: 134/300 - Train loss: 0.45821234583854675, Validation loss: 0.4710630476474762
Epoch: 135/300 - Train loss: 0.45738884806632996, Validation loss: 0.47013112902641296
Epoch: 136/300 - Train loss: 0.4565703570842743, Validation loss: 0.47008785605430603
Epoch: 137/300 - Train loss: 0.4557552635669708, Validation loss: 0.46837660670280457
Epoch: 138/300 - Train loss: 0.45494380593299866, Validation loss: 0.4676544666290283
Epoch: 139/300 - Train loss: 0.4541372060775757, Validation loss: 0.467088520526886
Epoch: 140/300 - Train loss: 0.4533345401287079, Validation loss: 0.46681511402130127
Epoch: 141/300 - Train loss: 0.45253628492355347, Validation loss: 0.4649549424648285
Epoch: 142/300 - Train loss: 0.4517397880554199, Validation loss: 0.4650193452835083
Epoch: 143/300 - Train loss: 0.4509463608264923, Validation loss: 0.4652877449989319
Epoch: 144/300 - Train loss: 0.4501563012599945, Validation loss: 0.4634076654911041
Epoch: 145/300 - Train loss: 0.4493679702281952, Validation loss: 0.4631054997444153
Epoch: 146/300 - Train loss: 0.44858118891716003, Validation loss: 0.46261849999427795
Epoch: 147/300 - Train loss: 0.44779494404792786, Validation loss: 0.46180763840675354
Epoch: 148/300 - Train loss: 0.44700977206230164, Validation loss: 0.4609864354133606
Epoch: 149/300 - Train loss: 0.4462277293205261, Validation loss: 0.4600502550601959
Epoch: 150/300 - Train loss: 0.44544750452041626, Validation loss: 0.4591043293476105
Epoch: 151/300 - Train loss: 0.44466841220855713, Validation loss: 0.45977726578712463
Epoch: 152/300 - Train loss: 0.44389012455940247, Validation loss: 0.45821788907051086
Epoch: 153/300 - Train loss: 0.4431132674217224, Validation loss: 0.45782795548439026
Epoch: 154/300 - Train loss: 0.442339688539505, Validation loss: 0.45651009678840637
Epoch: 155/300 - Train loss: 0.4415668547153473, Validation loss: 0.4556441009044647
Epoch: 156/300 - Train loss: 0.44079601764678955, Validation loss: 0.4559595286846161
Epoch: 157/300 - Train loss: 0.44002577662467957, Validation loss: 0.4548349380493164
Epoch: 158/300 - Train loss: 0.4392537772655487, Validation loss: 0.45427271723747253
Epoch: 159/300 - Train loss: 0.43848055601119995, Validation loss: 0.4539346396923065
Epoch: 160/300 - Train loss: 0.4377078413963318, Validation loss: 0.453163206577301
Epoch: 161/300 - Train loss: 0.4369366466999054, Validation loss: 0.45195257663726807
Epoch: 162/300 - Train loss: 0.4361666142940521, Validation loss: 0.45115652680397034
Epoch: 163/300 - Train loss: 0.43539756536483765, Validation loss: 0.4509498178958893
Epoch: 164/300 - Train loss: 0.4346281588077545, Validation loss: 0.4500197768211365
Epoch: 165/300 - Train loss: 0.4338599145412445, Validation loss: 0.4491070508956909
Epoch: 166/300 - Train loss: 0.4330900311470032, Validation loss: 0.4485897421836853
Epoch: 167/300 - Train loss: 0.43232277035713196, Validation loss: 0.4484415054321289
Epoch: 168/300 - Train loss: 0.43155530095100403, Validation loss: 0.4477650821208954
Epoch: 169/300 - Train loss: 0.43078869581222534, Validation loss: 0.4466243386268616
Epoch: 170/300 - Train loss: 0.4300234019756317, Validation loss: 0.446283221244812
Epoch: 171/300 - Train loss: 0.4292583465576172, Validation loss: 0.4455537796020508
Epoch: 172/300 - Train loss: 0.4284941852092743, Validation loss: 0.4451647698879242
Epoch: 173/300 - Train loss: 0.4277322292327881, Validation loss: 0.44407522678375244
Epoch: 174/300 - Train loss: 0.4269713759422302, Validation loss: 0.4436318278312683
Epoch: 175/300 - Train loss: 0.4262130856513977, Validation loss: 0.44299036264419556
Epoch: 176/300 - Train loss: 0.42545783519744873, Validation loss: 0.4415103495121002
Epoch: 177/300 - Train loss: 0.42470481991767883, Validation loss: 0.44136711955070496
Epoch: 178/300 - Train loss: 0.42395463585853577, Validation loss: 0.4411397874355316
Epoch: 179/300 - Train loss: 0.42320728302001953, Validation loss: 0.440206378698349
Epoch: 180/300 - Train loss: 0.4224611818790436, Validation loss: 0.43965816497802734
Epoch: 181/300 - Train loss: 0.42171570658683777, Validation loss: 0.43909457325935364
Epoch: 182/300 - Train loss: 0.42097073793411255, Validation loss: 0.43889111280441284
Epoch: 183/300 - Train loss: 0.4202252924442291, Validation loss: 0.43737876415252686
Epoch: 184/300 - Train loss: 0.41947951912879944, Validation loss: 0.43627673387527466
Epoch: 185/300 - Train loss: 0.41873490810394287, Validation loss: 0.43641653656959534
Epoch: 186/300 - Train loss: 0.41799241304397583, Validation loss: 0.4353392720222473
Epoch: 187/300 - Train loss: 0.4172509014606476, Validation loss: 0.4349280595779419
Epoch: 188/300 - Train loss: 0.4165111780166626, Validation loss: 0.4342130422592163
Epoch: 189/300 - Train loss: 0.4157721698284149, Validation loss: 0.43302619457244873
Epoch: 190/300 - Train loss: 0.41503313183784485, Validation loss: 0.43338388204574585
Epoch: 191/300 - Train loss: 0.41429537534713745, Validation loss: 0.4328993260860443
Epoch: 192/300 - Train loss: 0.4135591387748718, Validation loss: 0.4314482808113098
Epoch: 193/300 - Train loss: 0.41282328963279724, Validation loss: 0.4306201934814453
Epoch: 194/300 - Train loss: 0.41208723187446594, Validation loss: 0.42968645691871643
Epoch: 195/300 - Train loss: 0.41135257482528687, Validation loss: 0.43011561036109924
Epoch: 196/300 - Train loss: 0.41061797738075256, Validation loss: 0.42912426590919495
Epoch: 197/300 - Train loss: 0.40988457202911377, Validation loss: 0.42829233407974243
Epoch: 198/300 - Train loss: 0.40915122628211975, Validation loss: 0.4276575744152069
Epoch: 199/300 - Train loss: 0.4084179103374481, Validation loss: 0.4269406497478485
Epoch: 200/300 - Train loss: 0.40768492221832275, Validation loss: 0.42718619108200073
Epoch: 201/300 - Train loss: 0.4069528579711914, Validation loss: 0.42583152651786804
Epoch: 202/300 - Train loss: 0.4062223732471466, Validation loss: 0.4247492551803589
Epoch: 203/300 - Train loss: 0.4054924249649048, Validation loss: 0.4240976870059967
Epoch: 204/300 - Train loss: 0.40476393699645996, Validation loss: 0.423832505941391
Epoch: 205/300 - Train loss: 0.40403634309768677, Validation loss: 0.42306622862815857
Epoch: 206/300 - Train loss: 0.4033103883266449, Validation loss: 0.4230397641658783
Epoch: 207/300 - Train loss: 0.40258556604385376, Validation loss: 0.4220336377620697
Epoch: 208/300 - Train loss: 0.40186089277267456, Validation loss: 0.4214226305484772
Epoch: 209/300 - Train loss: 0.40113747119903564, Validation loss: 0.42098045349121094
Epoch: 210/300 - Train loss: 0.4004153907299042, Validation loss: 0.42013847827911377
Epoch: 211/300 - Train loss: 0.3996947407722473, Validation loss: 0.4190937876701355
Epoch: 212/300 - Train loss: 0.3989751935005188, Validation loss: 0.4183824360370636
Epoch: 213/300 - Train loss: 0.3982580304145813, Validation loss: 0.41779908537864685
Epoch: 214/300 - Train loss: 0.3975428640842438, Validation loss: 0.4171275496482849
Epoch: 215/300 - Train loss: 0.3968312740325928, Validation loss: 0.41694673895835876
Epoch: 216/300 - Train loss: 0.39611971378326416, Validation loss: 0.41570353507995605
Epoch: 217/300 - Train loss: 0.3954089283943176, Validation loss: 0.4147647023200989
Epoch: 218/300 - Train loss: 0.39469796419143677, Validation loss: 0.4145520329475403
Epoch: 219/300 - Train loss: 0.3939891755580902, Validation loss: 0.4138292968273163
Epoch: 220/300 - Train loss: 0.3932819664478302, Validation loss: 0.41375088691711426
Epoch: 221/300 - Train loss: 0.3925780653953552, Validation loss: 0.41258999705314636
Epoch: 222/300 - Train loss: 0.3918772041797638, Validation loss: 0.4125467836856842
Epoch: 223/300 - Train loss: 0.39117899537086487, Validation loss: 0.4121953845024109
