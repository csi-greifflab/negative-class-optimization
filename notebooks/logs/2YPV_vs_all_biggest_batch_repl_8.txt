Epoch: 1/300 - Train loss: 0.6927434802055359, Validation loss: 0.690558910369873
Epoch: 2/300 - Train loss: 0.6907329559326172, Validation loss: 0.6886393427848816
Epoch: 3/300 - Train loss: 0.6887415051460266, Validation loss: 0.6867015361785889
Epoch: 4/300 - Train loss: 0.6867190003395081, Validation loss: 0.6846728920936584
Epoch: 5/300 - Train loss: 0.6846205592155457, Validation loss: 0.6824786067008972
Epoch: 6/300 - Train loss: 0.682401180267334, Validation loss: 0.6801982522010803
Epoch: 7/300 - Train loss: 0.6800267100334167, Validation loss: 0.6776488423347473
Epoch: 8/300 - Train loss: 0.6774753928184509, Validation loss: 0.6749923229217529
Epoch: 9/300 - Train loss: 0.6747263669967651, Validation loss: 0.6720324158668518
Epoch: 10/300 - Train loss: 0.6717734932899475, Validation loss: 0.668997585773468
Epoch: 11/300 - Train loss: 0.6686162948608398, Validation loss: 0.6656419634819031
Epoch: 12/300 - Train loss: 0.6652617454528809, Validation loss: 0.662093460559845
Epoch: 13/300 - Train loss: 0.6617121696472168, Validation loss: 0.6584045886993408
Epoch: 14/300 - Train loss: 0.6579731106758118, Validation loss: 0.6544883847236633
Epoch: 15/300 - Train loss: 0.6540601253509521, Validation loss: 0.6504672765731812
Epoch: 16/300 - Train loss: 0.6499830484390259, Validation loss: 0.6463315486907959
Epoch: 17/300 - Train loss: 0.6457502245903015, Validation loss: 0.6419525742530823
Epoch: 18/300 - Train loss: 0.6413729190826416, Validation loss: 0.6374927163124084
Epoch: 19/300 - Train loss: 0.6368657350540161, Validation loss: 0.6328021883964539
Epoch: 20/300 - Train loss: 0.6322429776191711, Validation loss: 0.6282634735107422
Epoch: 21/300 - Train loss: 0.6275168657302856, Validation loss: 0.6235007643699646
Epoch: 22/300 - Train loss: 0.6226873993873596, Validation loss: 0.6186776161193848
Epoch: 23/300 - Train loss: 0.6177668571472168, Validation loss: 0.6135962605476379
Epoch: 24/300 - Train loss: 0.6127659678459167, Validation loss: 0.6085877418518066
Epoch: 25/300 - Train loss: 0.6076952219009399, Validation loss: 0.6034902930259705
Epoch: 26/300 - Train loss: 0.6025574207305908, Validation loss: 0.5985727310180664
Epoch: 27/300 - Train loss: 0.5973700881004333, Validation loss: 0.593214213848114
Epoch: 28/300 - Train loss: 0.5921476483345032, Validation loss: 0.5881531238555908
Epoch: 29/300 - Train loss: 0.5869067907333374, Validation loss: 0.5830087661743164
Epoch: 30/300 - Train loss: 0.5816618800163269, Validation loss: 0.5778818130493164
Epoch: 31/300 - Train loss: 0.5764287710189819, Validation loss: 0.5727123618125916
Epoch: 32/300 - Train loss: 0.5712178349494934, Validation loss: 0.5675380825996399
Epoch: 33/300 - Train loss: 0.5660340785980225, Validation loss: 0.5625359416007996
Epoch: 34/300 - Train loss: 0.5608806610107422, Validation loss: 0.557339072227478
Epoch: 35/300 - Train loss: 0.5557609796524048, Validation loss: 0.5524290800094604
Epoch: 36/300 - Train loss: 0.5506776571273804, Validation loss: 0.5474112629890442
Epoch: 37/300 - Train loss: 0.5456323027610779, Validation loss: 0.5423304438591003
Epoch: 38/300 - Train loss: 0.5406268835067749, Validation loss: 0.5375180244445801
Epoch: 39/300 - Train loss: 0.5356634855270386, Validation loss: 0.5325304269790649
Epoch: 40/300 - Train loss: 0.5307438373565674, Validation loss: 0.5276630520820618
Epoch: 41/300 - Train loss: 0.525872528553009, Validation loss: 0.5228139162063599
Epoch: 42/300 - Train loss: 0.5210531949996948, Validation loss: 0.5178449153900146
Epoch: 43/300 - Train loss: 0.516289234161377, Validation loss: 0.5134993195533752
Epoch: 44/300 - Train loss: 0.5115849375724792, Validation loss: 0.5085374116897583
Epoch: 45/300 - Train loss: 0.5069434642791748, Validation loss: 0.5042054653167725
Epoch: 46/300 - Train loss: 0.502367377281189, Validation loss: 0.4996112883090973
Epoch: 47/300 - Train loss: 0.4978596568107605, Validation loss: 0.49504554271698
Epoch: 48/300 - Train loss: 0.4934227764606476, Validation loss: 0.49124255776405334
Epoch: 49/300 - Train loss: 0.48905912041664124, Validation loss: 0.48662981390953064
Epoch: 50/300 - Train loss: 0.48477038741111755, Validation loss: 0.48195627331733704
Epoch: 51/300 - Train loss: 0.4805578589439392, Validation loss: 0.47769442200660706
Epoch: 52/300 - Train loss: 0.4764227569103241, Validation loss: 0.47407054901123047
Epoch: 53/300 - Train loss: 0.47236567735671997, Validation loss: 0.4700007736682892
Epoch: 54/300 - Train loss: 0.4683873653411865, Validation loss: 0.46597301959991455
Epoch: 55/300 - Train loss: 0.4644882380962372, Validation loss: 0.46260184049606323
Epoch: 56/300 - Train loss: 0.46066826581954956, Validation loss: 0.45822837948799133
Epoch: 57/300 - Train loss: 0.456927627325058, Validation loss: 0.4549500346183777
Epoch: 58/300 - Train loss: 0.45326709747314453, Validation loss: 0.45137736201286316
Epoch: 59/300 - Train loss: 0.449686199426651, Validation loss: 0.4477734863758087
Epoch: 60/300 - Train loss: 0.4461844861507416, Validation loss: 0.4442303776741028
Epoch: 61/300 - Train loss: 0.44276106357574463, Validation loss: 0.4405415654182434
Epoch: 62/300 - Train loss: 0.43941521644592285, Validation loss: 0.43813446164131165
Epoch: 63/300 - Train loss: 0.43614616990089417, Validation loss: 0.43427127599716187
Epoch: 64/300 - Train loss: 0.4329531192779541, Validation loss: 0.4311021864414215
Epoch: 65/300 - Train loss: 0.42983442544937134, Validation loss: 0.42806151509284973
Epoch: 66/300 - Train loss: 0.4267892837524414, Validation loss: 0.4249451458454132
Epoch: 67/300 - Train loss: 0.4238162040710449, Validation loss: 0.42194727063179016
Epoch: 68/300 - Train loss: 0.42091453075408936, Validation loss: 0.41931822896003723
Epoch: 69/300 - Train loss: 0.41808202862739563, Validation loss: 0.4160556495189667
Epoch: 70/300 - Train loss: 0.41531792283058167, Validation loss: 0.41392162442207336
Epoch: 71/300 - Train loss: 0.41262009739875793, Validation loss: 0.4110288619995117
Epoch: 72/300 - Train loss: 0.40998750925064087, Validation loss: 0.4086437225341797
Epoch: 73/300 - Train loss: 0.4074183702468872, Validation loss: 0.40611204504966736
Epoch: 74/300 - Train loss: 0.4049116373062134, Validation loss: 0.40344905853271484
Epoch: 75/300 - Train loss: 0.4024656414985657, Validation loss: 0.40152814984321594
Epoch: 76/300 - Train loss: 0.40007874369621277, Validation loss: 0.3987005054950714
Epoch: 77/300 - Train loss: 0.3977486491203308, Validation loss: 0.3958883285522461
Epoch: 78/300 - Train loss: 0.3954739272594452, Validation loss: 0.39368852972984314
Epoch: 79/300 - Train loss: 0.3932526111602783, Validation loss: 0.3920176923274994
Epoch: 80/300 - Train loss: 0.39108267426490784, Validation loss: 0.389583021402359
Epoch: 81/300 - Train loss: 0.38896262645721436, Validation loss: 0.387688010931015
Epoch: 82/300 - Train loss: 0.3868907690048218, Validation loss: 0.3858301639556885
Epoch: 83/300 - Train loss: 0.38486555218696594, Validation loss: 0.383606880903244
Epoch: 84/300 - Train loss: 0.3828851878643036, Validation loss: 0.3814657926559448
Epoch: 85/300 - Train loss: 0.3809472918510437, Validation loss: 0.3794436752796173
Epoch: 86/300 - Train loss: 0.37905073165893555, Validation loss: 0.3773416578769684
Epoch: 87/300 - Train loss: 0.37719428539276123, Validation loss: 0.3758091628551483
Epoch: 88/300 - Train loss: 0.3753778636455536, Validation loss: 0.3742755949497223
Epoch: 89/300 - Train loss: 0.37360072135925293, Validation loss: 0.3722204566001892
Epoch: 90/300 - Train loss: 0.3718614876270294, Validation loss: 0.3704158067703247
Epoch: 91/300 - Train loss: 0.3701589107513428, Validation loss: 0.36917853355407715
Epoch: 92/300 - Train loss: 0.36849167943000793, Validation loss: 0.3676629960536957
Epoch: 93/300 - Train loss: 0.3668583333492279, Validation loss: 0.36548593640327454
Epoch: 94/300 - Train loss: 0.3652576804161072, Validation loss: 0.36376601457595825
Epoch: 95/300 - Train loss: 0.36368924379348755, Validation loss: 0.36211371421813965
Epoch: 96/300 - Train loss: 0.3621514141559601, Validation loss: 0.36063656210899353
Epoch: 97/300 - Train loss: 0.3606426417827606, Validation loss: 0.35925501585006714
Epoch: 98/300 - Train loss: 0.35916274785995483, Validation loss: 0.3574582636356354
Epoch: 99/300 - Train loss: 0.35771089792251587, Validation loss: 0.35633546113967896
Epoch: 100/300 - Train loss: 0.35628536343574524, Validation loss: 0.35469648241996765
Epoch: 101/300 - Train loss: 0.35488685965538025, Validation loss: 0.35343286395072937
Epoch: 102/300 - Train loss: 0.3535151779651642, Validation loss: 0.3525546193122864
Epoch: 103/300 - Train loss: 0.3521690368652344, Validation loss: 0.350555956363678
Epoch: 104/300 - Train loss: 0.35084807872772217, Validation loss: 0.34992486238479614
Epoch: 105/300 - Train loss: 0.3495524525642395, Validation loss: 0.3487515449523926
Epoch: 106/300 - Train loss: 0.34827929735183716, Validation loss: 0.34765350818634033
Epoch: 107/300 - Train loss: 0.3470280170440674, Validation loss: 0.3452230989933014
Epoch: 108/300 - Train loss: 0.3457990884780884, Validation loss: 0.34399983286857605
Epoch: 109/300 - Train loss: 0.34459230303764343, Validation loss: 0.34352779388427734
Epoch: 110/300 - Train loss: 0.3434068262577057, Validation loss: 0.3423382639884949
Epoch: 111/300 - Train loss: 0.3422413766384125, Validation loss: 0.341090589761734
Epoch: 112/300 - Train loss: 0.3410954177379608, Validation loss: 0.3397148847579956
Epoch: 113/300 - Train loss: 0.33997026085853577, Validation loss: 0.3386427164077759
Epoch: 114/300 - Train loss: 0.33886462450027466, Validation loss: 0.3371894955635071
Epoch: 115/300 - Train loss: 0.33777740597724915, Validation loss: 0.3362995386123657
Epoch: 116/300 - Train loss: 0.33670851588249207, Validation loss: 0.3360223174095154
Epoch: 117/300 - Train loss: 0.33565667271614075, Validation loss: 0.3344120383262634
Epoch: 118/300 - Train loss: 0.33462315797805786, Validation loss: 0.33286184072494507
Epoch: 119/300 - Train loss: 0.333607017993927, Validation loss: 0.3322908580303192
Epoch: 120/300 - Train loss: 0.3326066732406616, Validation loss: 0.3317577838897705
Epoch: 121/300 - Train loss: 0.33162203431129456, Validation loss: 0.33062201738357544
Epoch: 122/300 - Train loss: 0.330654501914978, Validation loss: 0.3299429714679718
Epoch: 123/300 - Train loss: 0.3297032415866852, Validation loss: 0.3284757137298584
Epoch: 124/300 - Train loss: 0.3287668824195862, Validation loss: 0.3277013897895813
Epoch: 125/300 - Train loss: 0.32784417271614075, Validation loss: 0.3267924189567566
Epoch: 126/300 - Train loss: 0.3269345760345459, Validation loss: 0.3262929916381836
Epoch: 127/300 - Train loss: 0.32603883743286133, Validation loss: 0.3251480162143707
Epoch: 128/300 - Train loss: 0.3251565098762512, Validation loss: 0.3243880569934845
Epoch: 129/300 - Train loss: 0.32428672909736633, Validation loss: 0.3234507739543915
Epoch: 130/300 - Train loss: 0.3234284520149231, Validation loss: 0.3231608271598816
Epoch: 131/300 - Train loss: 0.3225817084312439, Validation loss: 0.3216731548309326
Epoch: 132/300 - Train loss: 0.3217475116252899, Validation loss: 0.3206298351287842
Epoch: 133/300 - Train loss: 0.3209260106086731, Validation loss: 0.31972983479499817
Epoch: 134/300 - Train loss: 0.32011473178863525, Validation loss: 0.31926533579826355
Epoch: 135/300 - Train loss: 0.31931355595588684, Validation loss: 0.31899672746658325
Epoch: 136/300 - Train loss: 0.31852272152900696, Validation loss: 0.31835314631462097
Epoch: 137/300 - Train loss: 0.31774261593818665, Validation loss: 0.31753668189048767
Epoch: 138/300 - Train loss: 0.3169725239276886, Validation loss: 0.3166128396987915
Epoch: 139/300 - Train loss: 0.3162115216255188, Validation loss: 0.31621310114860535
Epoch: 140/300 - Train loss: 0.3154594898223877, Validation loss: 0.31462353467941284
Epoch: 141/300 - Train loss: 0.3147159516811371, Validation loss: 0.31409671902656555
Epoch: 142/300 - Train loss: 0.3139810860157013, Validation loss: 0.313893586397171
Epoch: 143/300 - Train loss: 0.31325531005859375, Validation loss: 0.31236526370048523
Epoch: 144/300 - Train loss: 0.31253916025161743, Validation loss: 0.31167590618133545
Epoch: 145/300 - Train loss: 0.3118322789669037, Validation loss: 0.3114795982837677
Epoch: 146/300 - Train loss: 0.3111339807510376, Validation loss: 0.3106837868690491
Epoch: 147/300 - Train loss: 0.3104448914527893, Validation loss: 0.31016165018081665
Epoch: 148/300 - Train loss: 0.309765100479126, Validation loss: 0.3094192445278168
Epoch: 149/300 - Train loss: 0.30909305810928345, Validation loss: 0.3088584244251251
Epoch: 150/300 - Train loss: 0.30842915177345276, Validation loss: 0.30764633417129517
Epoch: 151/300 - Train loss: 0.3077731728553772, Validation loss: 0.3084764778614044
Epoch: 152/300 - Train loss: 0.3071247935295105, Validation loss: 0.3070891797542572
Epoch: 153/300 - Train loss: 0.30648288130760193, Validation loss: 0.3064146637916565
Epoch: 154/300 - Train loss: 0.3058473467826843, Validation loss: 0.30566462874412537
Epoch: 155/300 - Train loss: 0.3052193224430084, Validation loss: 0.30543774366378784
Epoch: 156/300 - Train loss: 0.304597944021225, Validation loss: 0.3043333888053894
Epoch: 157/300 - Train loss: 0.3039836287498474, Validation loss: 0.3038725256919861
Epoch: 158/300 - Train loss: 0.30337655544281006, Validation loss: 0.30360695719718933
Epoch: 159/300 - Train loss: 0.30277636647224426, Validation loss: 0.3032299876213074
Epoch: 160/300 - Train loss: 0.3021828830242157, Validation loss: 0.30252811312675476
Epoch: 161/300 - Train loss: 0.3015962243080139, Validation loss: 0.30204471945762634
Epoch: 162/300 - Train loss: 0.30101653933525085, Validation loss: 0.3012760579586029
Epoch: 163/300 - Train loss: 0.30044353008270264, Validation loss: 0.30092111229896545
