Epoch: 1/300 - Train loss: 0.6857647895812988, Validation loss: 0.6843769550323486
Epoch: 2/300 - Train loss: 0.6827912926673889, Validation loss: 0.6814404129981995
Epoch: 3/300 - Train loss: 0.6798069477081299, Validation loss: 0.6784786581993103
Epoch: 4/300 - Train loss: 0.676788866519928, Validation loss: 0.6755028367042542
Epoch: 5/300 - Train loss: 0.673726499080658, Validation loss: 0.6724518537521362
Epoch: 6/300 - Train loss: 0.6706085205078125, Validation loss: 0.6693684458732605
Epoch: 7/300 - Train loss: 0.667432963848114, Validation loss: 0.666215181350708
Epoch: 8/300 - Train loss: 0.6641988158226013, Validation loss: 0.6629571914672852
Epoch: 9/300 - Train loss: 0.6609024405479431, Validation loss: 0.6597121953964233
Epoch: 10/300 - Train loss: 0.65753573179245, Validation loss: 0.6562975645065308
Epoch: 11/300 - Train loss: 0.6540989279747009, Validation loss: 0.6528449058532715
Epoch: 12/300 - Train loss: 0.6505888104438782, Validation loss: 0.6493678689002991
Epoch: 13/300 - Train loss: 0.6470020413398743, Validation loss: 0.6459493637084961
Epoch: 14/300 - Train loss: 0.6433422565460205, Validation loss: 0.6422483325004578
Epoch: 15/300 - Train loss: 0.6396117210388184, Validation loss: 0.6382483839988708
Epoch: 16/300 - Train loss: 0.6358122229576111, Validation loss: 0.6347026824951172
Epoch: 17/300 - Train loss: 0.6319513916969299, Validation loss: 0.6307454705238342
Epoch: 18/300 - Train loss: 0.6280323266983032, Validation loss: 0.6268711090087891
Epoch: 19/300 - Train loss: 0.6240577101707458, Validation loss: 0.6228313446044922
Epoch: 20/300 - Train loss: 0.6200336217880249, Validation loss: 0.6187344789505005
Epoch: 21/300 - Train loss: 0.6159647107124329, Validation loss: 0.6147997379302979
Epoch: 22/300 - Train loss: 0.6118534803390503, Validation loss: 0.6106445789337158
Epoch: 23/300 - Train loss: 0.6077013611793518, Validation loss: 0.6064899563789368
Epoch: 24/300 - Train loss: 0.6035140752792358, Validation loss: 0.6023548245429993
Epoch: 25/300 - Train loss: 0.5992957353591919, Validation loss: 0.5981655716896057
Epoch: 26/300 - Train loss: 0.5950540900230408, Validation loss: 0.5939304232597351
Epoch: 27/300 - Train loss: 0.5907926559448242, Validation loss: 0.5896444320678711
Epoch: 28/300 - Train loss: 0.5865162014961243, Validation loss: 0.5853786468505859
Epoch: 29/300 - Train loss: 0.5822299122810364, Validation loss: 0.5807751417160034
Epoch: 30/300 - Train loss: 0.57793790102005, Validation loss: 0.5767900943756104
Epoch: 31/300 - Train loss: 0.5736446380615234, Validation loss: 0.5724776387214661
Epoch: 32/300 - Train loss: 0.5693534016609192, Validation loss: 0.5681292414665222
Epoch: 33/300 - Train loss: 0.5650699734687805, Validation loss: 0.5637543201446533
Epoch: 34/300 - Train loss: 0.5607941150665283, Validation loss: 0.5596351027488708
Epoch: 35/300 - Train loss: 0.5565340518951416, Validation loss: 0.5551959276199341
Epoch: 36/300 - Train loss: 0.5522915720939636, Validation loss: 0.5511474013328552
Epoch: 37/300 - Train loss: 0.54807448387146, Validation loss: 0.5467463135719299
Epoch: 38/300 - Train loss: 0.5438843965530396, Validation loss: 0.5425910949707031
Epoch: 39/300 - Train loss: 0.5397244691848755, Validation loss: 0.5386470556259155
Epoch: 40/300 - Train loss: 0.5356028079986572, Validation loss: 0.5341985821723938
Epoch: 41/300 - Train loss: 0.5315209627151489, Validation loss: 0.5302112698554993
Epoch: 42/300 - Train loss: 0.5274782776832581, Validation loss: 0.5260025858879089
Epoch: 43/300 - Train loss: 0.5234789848327637, Validation loss: 0.5223249793052673
Epoch: 44/300 - Train loss: 0.5195284485816956, Validation loss: 0.5181541442871094
Epoch: 45/300 - Train loss: 0.5156282782554626, Validation loss: 0.5142504572868347
Epoch: 46/300 - Train loss: 0.5117805600166321, Validation loss: 0.5106995701789856
Epoch: 47/300 - Train loss: 0.5079882144927979, Validation loss: 0.5068256855010986
Epoch: 48/300 - Train loss: 0.5042541027069092, Validation loss: 0.5031047463417053
Epoch: 49/300 - Train loss: 0.5005792379379272, Validation loss: 0.4992973208427429
Epoch: 50/300 - Train loss: 0.49696382880210876, Validation loss: 0.4956218898296356
Epoch: 51/300 - Train loss: 0.49341335892677307, Validation loss: 0.4921494126319885
Epoch: 52/300 - Train loss: 0.48993027210235596, Validation loss: 0.4885043203830719
Epoch: 53/300 - Train loss: 0.4865137040615082, Validation loss: 0.4855780601501465
Epoch: 54/300 - Train loss: 0.48316508531570435, Validation loss: 0.48204824328422546
Epoch: 55/300 - Train loss: 0.47988516092300415, Validation loss: 0.4786248207092285
Epoch: 56/300 - Train loss: 0.47667407989501953, Validation loss: 0.4755805730819702
Epoch: 57/300 - Train loss: 0.4735334813594818, Validation loss: 0.47251057624816895
Epoch: 58/300 - Train loss: 0.4704647958278656, Validation loss: 0.4698156416416168
Epoch: 59/300 - Train loss: 0.46746817231178284, Validation loss: 0.4669541120529175
Epoch: 60/300 - Train loss: 0.4645440876483917, Validation loss: 0.4636339545249939
Epoch: 61/300 - Train loss: 0.46169260144233704, Validation loss: 0.4608507752418518
Epoch: 62/300 - Train loss: 0.45891380310058594, Validation loss: 0.4578103721141815
Epoch: 63/300 - Train loss: 0.4562062621116638, Validation loss: 0.45523202419281006
Epoch: 64/300 - Train loss: 0.4535703659057617, Validation loss: 0.4525972604751587
Epoch: 65/300 - Train loss: 0.4510057270526886, Validation loss: 0.4503362476825714
Epoch: 66/300 - Train loss: 0.448511004447937, Validation loss: 0.4479777216911316
Epoch: 67/300 - Train loss: 0.44608554244041443, Validation loss: 0.4449765086174011
Epoch: 68/300 - Train loss: 0.4437282085418701, Validation loss: 0.4422658085823059
Epoch: 69/300 - Train loss: 0.4414377808570862, Validation loss: 0.44023481011390686
Epoch: 70/300 - Train loss: 0.43921372294425964, Validation loss: 0.43828055262565613
Epoch: 71/300 - Train loss: 0.4370543658733368, Validation loss: 0.43631288409233093
Epoch: 72/300 - Train loss: 0.43495914340019226, Validation loss: 0.43408364057540894
Epoch: 73/300 - Train loss: 0.432926207780838, Validation loss: 0.43222326040267944
Epoch: 74/300 - Train loss: 0.4309546649456024, Validation loss: 0.43032222986221313
Epoch: 75/300 - Train loss: 0.4290434718132019, Validation loss: 0.428119033575058
Epoch: 76/300 - Train loss: 0.42719119787216187, Validation loss: 0.42616838216781616
Epoch: 77/300 - Train loss: 0.42539605498313904, Validation loss: 0.42409729957580566
Epoch: 78/300 - Train loss: 0.42365607619285583, Validation loss: 0.4226304888725281
Epoch: 79/300 - Train loss: 0.42197033762931824, Validation loss: 0.42046645283699036
Epoch: 80/300 - Train loss: 0.42033690214157104, Validation loss: 0.41956233978271484
Epoch: 81/300 - Train loss: 0.4187544584274292, Validation loss: 0.41814038157463074
Epoch: 82/300 - Train loss: 0.4172219932079315, Validation loss: 0.4167633652687073
Epoch: 83/300 - Train loss: 0.4157385528087616, Validation loss: 0.415266752243042
Epoch: 84/300 - Train loss: 0.41430240869522095, Validation loss: 0.4130226671695709
Epoch: 85/300 - Train loss: 0.4129121005535126, Validation loss: 0.41242632269859314
Epoch: 86/300 - Train loss: 0.41156628727912903, Validation loss: 0.410478413105011
Epoch: 87/300 - Train loss: 0.41026371717453003, Validation loss: 0.4083765745162964
Epoch: 88/300 - Train loss: 0.4090031385421753, Validation loss: 0.4077704846858978
Epoch: 89/300 - Train loss: 0.40778279304504395, Validation loss: 0.40690964460372925
Epoch: 90/300 - Train loss: 0.4066009521484375, Validation loss: 0.4053042232990265
Epoch: 91/300 - Train loss: 0.40545743703842163, Validation loss: 0.4040295481681824
Epoch: 92/300 - Train loss: 0.4043506979942322, Validation loss: 0.40310338139533997
Epoch: 93/300 - Train loss: 0.4032796025276184, Validation loss: 0.40215930342674255
Epoch: 94/300 - Train loss: 0.4022423326969147, Validation loss: 0.4005439281463623
Epoch: 95/300 - Train loss: 0.40123772621154785, Validation loss: 0.39982691407203674
Epoch: 96/300 - Train loss: 0.4002642333507538, Validation loss: 0.399410605430603
Epoch: 97/300 - Train loss: 0.39932137727737427, Validation loss: 0.39793258905410767
Epoch: 98/300 - Train loss: 0.3984076678752899, Validation loss: 0.39650413393974304
Epoch: 99/300 - Train loss: 0.3975217342376709, Validation loss: 0.3964260518550873
Epoch: 100/300 - Train loss: 0.39666271209716797, Validation loss: 0.3947421610355377
Epoch: 101/300 - Train loss: 0.39583009481430054, Validation loss: 0.3939509689807892
Epoch: 102/300 - Train loss: 0.39502203464508057, Validation loss: 0.39362627267837524
Epoch: 103/300 - Train loss: 0.39423760771751404, Validation loss: 0.39322155714035034
Epoch: 104/300 - Train loss: 0.3934754729270935, Validation loss: 0.39262381196022034
Epoch: 105/300 - Train loss: 0.39273494482040405, Validation loss: 0.3913334012031555
Epoch: 106/300 - Train loss: 0.3920154571533203, Validation loss: 0.39081886410713196
Epoch: 107/300 - Train loss: 0.39131656289100647, Validation loss: 0.3897949755191803
Epoch: 108/300 - Train loss: 0.39063721895217896, Validation loss: 0.38958868384361267
Epoch: 109/300 - Train loss: 0.3899767994880676, Validation loss: 0.387721985578537
Epoch: 110/300 - Train loss: 0.38933417201042175, Validation loss: 0.3874730169773102
Epoch: 111/300 - Train loss: 0.38870853185653687, Validation loss: 0.38707324862480164
Epoch: 112/300 - Train loss: 0.3880995213985443, Validation loss: 0.38641178607940674
Epoch: 113/300 - Train loss: 0.3875059485435486, Validation loss: 0.3863391876220703
Epoch: 114/300 - Train loss: 0.38692694902420044, Validation loss: 0.38511553406715393
Epoch: 115/300 - Train loss: 0.38636231422424316, Validation loss: 0.3849729895591736
Epoch: 116/300 - Train loss: 0.3858111798763275, Validation loss: 0.38398852944374084
Epoch: 117/300 - Train loss: 0.3852732479572296, Validation loss: 0.38383644819259644
Epoch: 118/300 - Train loss: 0.3847479820251465, Validation loss: 0.38307690620422363
