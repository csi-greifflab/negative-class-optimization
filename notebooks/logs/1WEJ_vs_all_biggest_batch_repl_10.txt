Epoch: 1/100 - Train loss: 0.6939190030097961, Validation loss: 0.6912965774536133
Epoch: 2/100 - Train loss: 0.6907640695571899, Validation loss: 0.6881891489028931
Epoch: 3/100 - Train loss: 0.6875694990158081, Validation loss: 0.6849370002746582
Epoch: 4/100 - Train loss: 0.6843051314353943, Validation loss: 0.6815239787101746
Epoch: 5/100 - Train loss: 0.6809570789337158, Validation loss: 0.678034782409668
Epoch: 6/100 - Train loss: 0.6775240898132324, Validation loss: 0.6745709776878357
Epoch: 7/100 - Train loss: 0.6740061044692993, Validation loss: 0.6709704399108887
Epoch: 8/100 - Train loss: 0.6704016327857971, Validation loss: 0.6672675013542175
Epoch: 9/100 - Train loss: 0.6667123436927795, Validation loss: 0.6635181307792664
Epoch: 10/100 - Train loss: 0.6629397869110107, Validation loss: 0.6596335768699646
Epoch: 11/100 - Train loss: 0.6590902805328369, Validation loss: 0.6557573080062866
Epoch: 12/100 - Train loss: 0.6551755666732788, Validation loss: 0.651720404624939
Epoch: 13/100 - Train loss: 0.6512040495872498, Validation loss: 0.6476885676383972
Epoch: 14/100 - Train loss: 0.6471803188323975, Validation loss: 0.6436431407928467
Epoch: 15/100 - Train loss: 0.6431047916412354, Validation loss: 0.6395981907844543
Epoch: 16/100 - Train loss: 0.638981282711029, Validation loss: 0.6354851126670837
Epoch: 17/100 - Train loss: 0.634818434715271, Validation loss: 0.6312400102615356
Epoch: 18/100 - Train loss: 0.6306208968162537, Validation loss: 0.6271482110023499
Epoch: 19/100 - Train loss: 0.6263932585716248, Validation loss: 0.6228235960006714
Epoch: 20/100 - Train loss: 0.6221421957015991, Validation loss: 0.6185678839683533
Epoch: 21/100 - Train loss: 0.6178714632987976, Validation loss: 0.6144320964813232
Epoch: 22/100 - Train loss: 0.6135848164558411, Validation loss: 0.6099473834037781
Epoch: 23/100 - Train loss: 0.6092840433120728, Validation loss: 0.6057877540588379
Epoch: 24/100 - Train loss: 0.6049702763557434, Validation loss: 0.601311445236206
Epoch: 25/100 - Train loss: 0.600644588470459, Validation loss: 0.5970166921615601
Epoch: 26/100 - Train loss: 0.5963116884231567, Validation loss: 0.592807412147522
Epoch: 27/100 - Train loss: 0.5919756889343262, Validation loss: 0.5885867476463318
Epoch: 28/100 - Train loss: 0.587637186050415, Validation loss: 0.5841089487075806
Epoch: 29/100 - Train loss: 0.5832973718643188, Validation loss: 0.579460859298706
Epoch: 30/100 - Train loss: 0.5789582133293152, Validation loss: 0.5752093195915222
Epoch: 31/100 - Train loss: 0.5746223330497742, Validation loss: 0.5713360905647278
Epoch: 32/100 - Train loss: 0.570292592048645, Validation loss: 0.5666376352310181
Epoch: 33/100 - Train loss: 0.5659723877906799, Validation loss: 0.5623942017555237
Epoch: 34/100 - Train loss: 0.5616656541824341, Validation loss: 0.5584339499473572
Epoch: 35/100 - Train loss: 0.5573757886886597, Validation loss: 0.5540350079536438
Epoch: 36/100 - Train loss: 0.5531062483787537, Validation loss: 0.5496739745140076
Epoch: 37/100 - Train loss: 0.548861563205719, Validation loss: 0.54561448097229
Epoch: 38/100 - Train loss: 0.5446447730064392, Validation loss: 0.5413889288902283
Epoch: 39/100 - Train loss: 0.5404589176177979, Validation loss: 0.5373051166534424
Epoch: 40/100 - Train loss: 0.5363079905509949, Validation loss: 0.5331224799156189
Epoch: 41/100 - Train loss: 0.5321943759918213, Validation loss: 0.5287602543830872
Epoch: 42/100 - Train loss: 0.5281205773353577, Validation loss: 0.5247687101364136
Epoch: 43/100 - Train loss: 0.5240888595581055, Validation loss: 0.5208507180213928
Epoch: 44/100 - Train loss: 0.5201026797294617, Validation loss: 0.5171535015106201
Epoch: 45/100 - Train loss: 0.5161643624305725, Validation loss: 0.5136410593986511
Epoch: 46/100 - Train loss: 0.5122764706611633, Validation loss: 0.5090481042861938
Epoch: 47/100 - Train loss: 0.5084416270256042, Validation loss: 0.5053719282150269
Epoch: 48/100 - Train loss: 0.5046625137329102, Validation loss: 0.501715898513794
Epoch: 49/100 - Train loss: 0.5009411573410034, Validation loss: 0.4979281723499298
Epoch: 50/100 - Train loss: 0.49728018045425415, Validation loss: 0.4942205250263214
Epoch: 51/100 - Train loss: 0.49368250370025635, Validation loss: 0.4908657371997833
Epoch: 52/100 - Train loss: 0.490148663520813, Validation loss: 0.4873853027820587
Epoch: 53/100 - Train loss: 0.48668044805526733, Validation loss: 0.4839296340942383
Epoch: 54/100 - Train loss: 0.48327916860580444, Validation loss: 0.48042652010917664
Epoch: 55/100 - Train loss: 0.4799460768699646, Validation loss: 0.47704342007637024
Epoch: 56/100 - Train loss: 0.4766824543476105, Validation loss: 0.47411826252937317
Epoch: 57/100 - Train loss: 0.47348880767822266, Validation loss: 0.4712633788585663
Epoch: 58/100 - Train loss: 0.47036629915237427, Validation loss: 0.46814364194869995
Epoch: 59/100 - Train loss: 0.4673149585723877, Validation loss: 0.46463504433631897
Epoch: 60/100 - Train loss: 0.4643349051475525, Validation loss: 0.46155309677124023
Epoch: 61/100 - Train loss: 0.4614261984825134, Validation loss: 0.4588940739631653
Epoch: 62/100 - Train loss: 0.45858922600746155, Validation loss: 0.4556991755962372
Epoch: 63/100 - Train loss: 0.455823689699173, Validation loss: 0.4534914493560791
Epoch: 64/100 - Train loss: 0.4531293511390686, Validation loss: 0.45051124691963196
Epoch: 65/100 - Train loss: 0.4505055248737335, Validation loss: 0.4476773142814636
Epoch: 66/100 - Train loss: 0.44795161485671997, Validation loss: 0.4459046721458435
Epoch: 67/100 - Train loss: 0.44546711444854736, Validation loss: 0.44298669695854187
Epoch: 68/100 - Train loss: 0.44305142760276794, Validation loss: 0.4411649703979492
Epoch: 69/100 - Train loss: 0.4407038390636444, Validation loss: 0.438581645488739
Epoch: 70/100 - Train loss: 0.43842336535453796, Validation loss: 0.43588581681251526
Epoch: 71/100 - Train loss: 0.43620872497558594, Validation loss: 0.43388158082962036
Epoch: 72/100 - Train loss: 0.43405890464782715, Validation loss: 0.4316849708557129
Epoch: 73/100 - Train loss: 0.43197301030158997, Validation loss: 0.4294414520263672
Epoch: 74/100 - Train loss: 0.42994973063468933, Validation loss: 0.42822784185409546
Epoch: 75/100 - Train loss: 0.4279879629611969, Validation loss: 0.42560023069381714
Epoch: 76/100 - Train loss: 0.4260860085487366, Validation loss: 0.4239870309829712
Epoch: 77/100 - Train loss: 0.4242425858974457, Validation loss: 0.4224188029766083
Epoch: 78/100 - Train loss: 0.42245614528656006, Validation loss: 0.4204762578010559
Epoch: 79/100 - Train loss: 0.42072510719299316, Validation loss: 0.4185083508491516
Epoch: 80/100 - Train loss: 0.41904789209365845, Validation loss: 0.4168667197227478
Epoch: 81/100 - Train loss: 0.4174230992794037, Validation loss: 0.415134459733963
Epoch: 82/100 - Train loss: 0.41584882140159607, Validation loss: 0.414060115814209
Epoch: 83/100 - Train loss: 0.4143241345882416, Validation loss: 0.4127093553543091
Epoch: 84/100 - Train loss: 0.4128474295139313, Validation loss: 0.4114169180393219
Epoch: 85/100 - Train loss: 0.4114172160625458, Validation loss: 0.4094281792640686
Epoch: 86/100 - Train loss: 0.41003188490867615, Validation loss: 0.40781545639038086
Epoch: 87/100 - Train loss: 0.4086899757385254, Validation loss: 0.4066644608974457
Epoch: 88/100 - Train loss: 0.4073903560638428, Validation loss: 0.4055173993110657
Epoch: 89/100 - Train loss: 0.4061316251754761, Validation loss: 0.40386763215065
Epoch: 90/100 - Train loss: 0.4049120843410492, Validation loss: 0.4025092124938965
Epoch: 91/100 - Train loss: 0.4037304222583771, Validation loss: 0.4014658033847809
Epoch: 92/100 - Train loss: 0.40258535742759705, Validation loss: 0.3999127745628357
Epoch: 93/100 - Train loss: 0.40147554874420166, Validation loss: 0.40024471282958984
Epoch: 94/100 - Train loss: 0.40039965510368347, Validation loss: 0.39880073070526123
Epoch: 95/100 - Train loss: 0.3993561863899231, Validation loss: 0.397649347782135
Epoch: 96/100 - Train loss: 0.3983437120914459, Validation loss: 0.3967621624469757
Epoch: 97/100 - Train loss: 0.3973613381385803, Validation loss: 0.39540427923202515
Epoch: 98/100 - Train loss: 0.39640817046165466, Validation loss: 0.39422157406806946
Epoch: 99/100 - Train loss: 0.3954828679561615, Validation loss: 0.39358022809028625
Epoch: 100/100 - Train loss: 0.39458414912223816, Validation loss: 0.39329642057418823
Epoch: 1/300 - Train loss: 0.6964846849441528, Validation loss: 0.6934738755226135
Epoch: 2/300 - Train loss: 0.6931769847869873, Validation loss: 0.6904756426811218
Epoch: 3/300 - Train loss: 0.6899973154067993, Validation loss: 0.6874892115592957
Epoch: 4/300 - Train loss: 0.6869112849235535, Validation loss: 0.6845569014549255
Epoch: 5/300 - Train loss: 0.6838620901107788, Validation loss: 0.6816508769989014
Epoch: 6/300 - Train loss: 0.6807841062545776, Validation loss: 0.6784947514533997
Epoch: 7/300 - Train loss: 0.6776207685470581, Validation loss: 0.6753855347633362
Epoch: 8/300 - Train loss: 0.6743243336677551, Validation loss: 0.6718961000442505
Epoch: 9/300 - Train loss: 0.6708665490150452, Validation loss: 0.6683490872383118
Epoch: 10/300 - Train loss: 0.667219877243042, Validation loss: 0.6645998358726501
Epoch: 11/300 - Train loss: 0.663368284702301, Validation loss: 0.6606121063232422
Epoch: 12/300 - Train loss: 0.6593158841133118, Validation loss: 0.6564379930496216
Epoch: 13/300 - Train loss: 0.6550679802894592, Validation loss: 0.6520875096321106
Epoch: 14/300 - Train loss: 0.6506364345550537, Validation loss: 0.6474995613098145
Epoch: 15/300 - Train loss: 0.6460409760475159, Validation loss: 0.6428877115249634
Epoch: 16/300 - Train loss: 0.6412940621376038, Validation loss: 0.6378757357597351
Epoch: 17/300 - Train loss: 0.6364172697067261, Validation loss: 0.633134663105011
Epoch: 18/300 - Train loss: 0.6314231753349304, Validation loss: 0.6279372572898865
Epoch: 19/300 - Train loss: 0.6263416409492493, Validation loss: 0.6230405569076538
Epoch: 20/300 - Train loss: 0.6211933493614197, Validation loss: 0.6178635954856873
Epoch: 21/300 - Train loss: 0.6160010695457458, Validation loss: 0.6126760244369507
Epoch: 22/300 - Train loss: 0.6107827425003052, Validation loss: 0.6076130270957947
Epoch: 23/300 - Train loss: 0.6055548787117004, Validation loss: 0.6023961305618286
Epoch: 24/300 - Train loss: 0.6003319621086121, Validation loss: 0.5972920060157776
Epoch: 25/300 - Train loss: 0.5951279401779175, Validation loss: 0.5920519232749939
Epoch: 26/300 - Train loss: 0.5899484157562256, Validation loss: 0.587002158164978
Epoch: 27/300 - Train loss: 0.5847945213317871, Validation loss: 0.5818577408790588
Epoch: 28/300 - Train loss: 0.579664945602417, Validation loss: 0.576805591583252
Epoch: 29/300 - Train loss: 0.5745648741722107, Validation loss: 0.5718277096748352
Epoch: 30/300 - Train loss: 0.569499671459198, Validation loss: 0.5666084885597229
Epoch: 31/300 - Train loss: 0.5644741058349609, Validation loss: 0.5618190169334412
Epoch: 32/300 - Train loss: 0.5594921708106995, Validation loss: 0.5571319460868835
Epoch: 33/300 - Train loss: 0.5545570850372314, Validation loss: 0.5522222518920898
Epoch: 34/300 - Train loss: 0.5496743321418762, Validation loss: 0.5473108887672424
Epoch: 35/300 - Train loss: 0.5448499917984009, Validation loss: 0.5424100756645203
Epoch: 36/300 - Train loss: 0.5400883555412292, Validation loss: 0.5379711985588074
Epoch: 37/300 - Train loss: 0.5353937745094299, Validation loss: 0.5331938862800598
Epoch: 38/300 - Train loss: 0.5307695269584656, Validation loss: 0.5287318825721741
Epoch: 39/300 - Train loss: 0.5262179970741272, Validation loss: 0.5243447422981262
Epoch: 40/300 - Train loss: 0.5217410326004028, Validation loss: 0.5196371674537659
Epoch: 41/300 - Train loss: 0.5173395872116089, Validation loss: 0.5150771737098694
Epoch: 42/300 - Train loss: 0.5130159258842468, Validation loss: 0.51103675365448
Epoch: 43/300 - Train loss: 0.5087718367576599, Validation loss: 0.5065797567367554
Epoch: 44/300 - Train loss: 0.504608690738678, Validation loss: 0.5023712515830994
Epoch: 45/300 - Train loss: 0.5005279779434204, Validation loss: 0.49850812554359436
Epoch: 46/300 - Train loss: 0.49653106927871704, Validation loss: 0.4944886565208435
Epoch: 47/300 - Train loss: 0.49261876940727234, Validation loss: 0.4908013939857483
Epoch: 48/300 - Train loss: 0.48879244923591614, Validation loss: 0.4874206781387329
Epoch: 49/300 - Train loss: 0.4850533604621887, Validation loss: 0.4834279716014862
Epoch: 50/300 - Train loss: 0.48140132427215576, Validation loss: 0.47933778166770935
Epoch: 51/300 - Train loss: 0.47783687710762024, Validation loss: 0.4762212336063385
Epoch: 52/300 - Train loss: 0.47436001896858215, Validation loss: 0.4726696312427521
Epoch: 53/300 - Train loss: 0.4709708094596863, Validation loss: 0.4694634675979614
Epoch: 54/300 - Train loss: 0.46766871213912964, Validation loss: 0.4665948748588562
Epoch: 55/300 - Train loss: 0.4644528329372406, Validation loss: 0.4628433883190155
Epoch: 56/300 - Train loss: 0.46132251620292664, Validation loss: 0.4594026505947113
Epoch: 57/300 - Train loss: 0.4582774043083191, Validation loss: 0.456790030002594
Epoch: 58/300 - Train loss: 0.45531603693962097, Validation loss: 0.4538726508617401
Epoch: 59/300 - Train loss: 0.45243725180625916, Validation loss: 0.4509811997413635
Epoch: 60/300 - Train loss: 0.44963976740837097, Validation loss: 0.4483156204223633
Epoch: 61/300 - Train loss: 0.4469222128391266, Validation loss: 0.44612762331962585
Epoch: 62/300 - Train loss: 0.4442831575870514, Validation loss: 0.44282954931259155
Epoch: 63/300 - Train loss: 0.4417213201522827, Validation loss: 0.4405742883682251
Epoch: 64/300 - Train loss: 0.4392349123954773, Validation loss: 0.43775948882102966
Epoch: 65/300 - Train loss: 0.43682193756103516, Validation loss: 0.43547680974006653
Epoch: 66/300 - Train loss: 0.43448135256767273, Validation loss: 0.43348029255867004
Epoch: 67/300 - Train loss: 0.4322105050086975, Validation loss: 0.43070727586746216
Epoch: 68/300 - Train loss: 0.4300081729888916, Validation loss: 0.4287250339984894
Epoch: 69/300 - Train loss: 0.4278723895549774, Validation loss: 0.4264122247695923
Epoch: 70/300 - Train loss: 0.42580071091651917, Validation loss: 0.42431914806365967
Epoch: 71/300 - Train loss: 0.42379096150398254, Validation loss: 0.4223063886165619
Epoch: 72/300 - Train loss: 0.4218413233757019, Validation loss: 0.42073073983192444
Epoch: 73/300 - Train loss: 0.4199499189853668, Validation loss: 0.4184117019176483
Epoch: 74/300 - Train loss: 0.4181152582168579, Validation loss: 0.41677337884902954
Epoch: 75/300 - Train loss: 0.41633471846580505, Validation loss: 0.4149782061576843
Epoch: 76/300 - Train loss: 0.41460686922073364, Validation loss: 0.41304874420166016
Epoch: 77/300 - Train loss: 0.41292986273765564, Validation loss: 0.41147953271865845
Epoch: 78/300 - Train loss: 0.41130152344703674, Validation loss: 0.4094872772693634
Epoch: 79/300 - Train loss: 0.4097203314304352, Validation loss: 0.40856632590293884
Epoch: 80/300 - Train loss: 0.4081836938858032, Validation loss: 0.40624263882637024
Epoch: 81/300 - Train loss: 0.40669116377830505, Validation loss: 0.4053618311882019
Epoch: 82/300 - Train loss: 0.4052390456199646, Validation loss: 0.4038192629814148
Epoch: 83/300 - Train loss: 0.4038265645503998, Validation loss: 0.4015306234359741
Epoch: 84/300 - Train loss: 0.4024518132209778, Validation loss: 0.4008871018886566
Epoch: 85/300 - Train loss: 0.40111348032951355, Validation loss: 0.39977511763572693
Epoch: 86/300 - Train loss: 0.3998095989227295, Validation loss: 0.39837682247161865
Epoch: 87/300 - Train loss: 0.3985394239425659, Validation loss: 0.39808911085128784
Epoch: 88/300 - Train loss: 0.39730215072631836, Validation loss: 0.3961271643638611
Epoch: 89/300 - Train loss: 0.3960956335067749, Validation loss: 0.39416879415512085
Epoch: 90/300 - Train loss: 0.3949187397956848, Validation loss: 0.39338114857673645
Epoch: 91/300 - Train loss: 0.3937694728374481, Validation loss: 0.39215967059135437
Epoch: 92/300 - Train loss: 0.3926466703414917, Validation loss: 0.39098408818244934
Epoch: 93/300 - Train loss: 0.39155060052871704, Validation loss: 0.3892963230609894
Epoch: 94/300 - Train loss: 0.39047887921333313, Validation loss: 0.38896530866622925
Epoch: 95/300 - Train loss: 0.3894311487674713, Validation loss: 0.3881247639656067
Epoch: 96/300 - Train loss: 0.3884070813655853, Validation loss: 0.38658690452575684
Epoch: 97/300 - Train loss: 0.38740548491477966, Validation loss: 0.38618358969688416
Epoch: 98/300 - Train loss: 0.3864246606826782, Validation loss: 0.3846628963947296
Epoch: 99/300 - Train loss: 0.38546422123908997, Validation loss: 0.38412928581237793
Epoch: 100/300 - Train loss: 0.3845229744911194, Validation loss: 0.38333603739738464
Epoch: 101/300 - Train loss: 0.3835994303226471, Validation loss: 0.38186970353126526
Epoch: 102/300 - Train loss: 0.3826944828033447, Validation loss: 0.38095852732658386
Epoch: 103/300 - Train loss: 0.3818056285381317, Validation loss: 0.3799966871738434
Epoch: 104/300 - Train loss: 0.3809327781200409, Validation loss: 0.37916311621665955
Epoch: 105/300 - Train loss: 0.38007479906082153, Validation loss: 0.37849366664886475
Epoch: 106/300 - Train loss: 0.3792320191860199, Validation loss: 0.377411425113678
Epoch: 107/300 - Train loss: 0.37840259075164795, Validation loss: 0.37653711438179016
Epoch: 108/300 - Train loss: 0.3775861859321594, Validation loss: 0.37611669301986694
Epoch: 109/300 - Train loss: 0.37678197026252747, Validation loss: 0.3748213052749634
Epoch: 110/300 - Train loss: 0.3759898841381073, Validation loss: 0.375178724527359
Epoch: 111/300 - Train loss: 0.3752095699310303, Validation loss: 0.3731860816478729
Epoch: 112/300 - Train loss: 0.3744410276412964, Validation loss: 0.37254440784454346
Epoch: 113/300 - Train loss: 0.37368452548980713, Validation loss: 0.37250345945358276
Epoch: 114/300 - Train loss: 0.3729381263256073, Validation loss: 0.3709689676761627
Epoch: 115/300 - Train loss: 0.3722013235092163, Validation loss: 0.3703315854072571
Epoch: 116/300 - Train loss: 0.37147483229637146, Validation loss: 0.3691641390323639
Epoch: 117/300 - Train loss: 0.37075692415237427, Validation loss: 0.3698941767215729
Epoch: 118/300 - Train loss: 0.37004899978637695, Validation loss: 0.36878764629364014
Epoch: 119/300 - Train loss: 0.3693494200706482, Validation loss: 0.36794140934944153
Epoch: 120/300 - Train loss: 0.36865904927253723, Validation loss: 0.3661962151527405
Epoch: 121/300 - Train loss: 0.367977112531662, Validation loss: 0.3663528561592102
Epoch: 122/300 - Train loss: 0.3673039674758911, Validation loss: 0.3653944730758667
Epoch: 123/300 - Train loss: 0.36663758754730225, Validation loss: 0.3652994632720947
Epoch: 124/300 - Train loss: 0.36597681045532227, Validation loss: 0.36389482021331787
Epoch: 125/300 - Train loss: 0.3653210401535034, Validation loss: 0.36326852440834045
Epoch: 126/300 - Train loss: 0.36467278003692627, Validation loss: 0.3629223704338074
Epoch: 127/300 - Train loss: 0.3640294373035431, Validation loss: 0.3621176779270172
Epoch: 128/300 - Train loss: 0.3633918762207031, Validation loss: 0.3619590401649475
Epoch: 129/300 - Train loss: 0.3627603054046631, Validation loss: 0.36125868558883667
Epoch: 130/300 - Train loss: 0.36213284730911255, Validation loss: 0.36064615845680237
Epoch: 131/300 - Train loss: 0.3615104556083679, Validation loss: 0.3597937226295471
Epoch: 132/300 - Train loss: 0.3608943819999695, Validation loss: 0.3586905896663666
Epoch: 133/300 - Train loss: 0.3602837324142456, Validation loss: 0.35938775539398193
Epoch: 134/300 - Train loss: 0.3596784174442291, Validation loss: 0.35872143507003784
