Epoch: 1/300 - Train loss: 0.6947816610336304, Validation loss: 0.6911228895187378
Epoch: 2/300 - Train loss: 0.692223072052002, Validation loss: 0.6886928081512451
Epoch: 3/300 - Train loss: 0.6897269487380981, Validation loss: 0.6863707900047302
Epoch: 4/300 - Train loss: 0.6872606873512268, Validation loss: 0.6839907169342041
Epoch: 5/300 - Train loss: 0.684782862663269, Validation loss: 0.6816228032112122
Epoch: 6/300 - Train loss: 0.6822627186775208, Validation loss: 0.6791265606880188
Epoch: 7/300 - Train loss: 0.6796658039093018, Validation loss: 0.6765105724334717
Epoch: 8/300 - Train loss: 0.6769717335700989, Validation loss: 0.673796534538269
Epoch: 9/300 - Train loss: 0.6741547584533691, Validation loss: 0.6709364652633667
Epoch: 10/300 - Train loss: 0.671200156211853, Validation loss: 0.667918860912323
Epoch: 11/300 - Train loss: 0.6681094765663147, Validation loss: 0.6647802591323853
Epoch: 12/300 - Train loss: 0.6648837327957153, Validation loss: 0.6615609526634216
Epoch: 13/300 - Train loss: 0.661524772644043, Validation loss: 0.6580809950828552
Epoch: 14/300 - Train loss: 0.6580358147621155, Validation loss: 0.6545924544334412
Epoch: 15/300 - Train loss: 0.6544315218925476, Validation loss: 0.6510039567947388
Epoch: 16/300 - Train loss: 0.6507186889648438, Validation loss: 0.6473159790039062
Epoch: 17/300 - Train loss: 0.6469106078147888, Validation loss: 0.6434658169746399
Epoch: 18/300 - Train loss: 0.643015444278717, Validation loss: 0.639516294002533
Epoch: 19/300 - Train loss: 0.6390421390533447, Validation loss: 0.6356146931648254
Epoch: 20/300 - Train loss: 0.6349942684173584, Validation loss: 0.6316918730735779
Epoch: 21/300 - Train loss: 0.6308858394622803, Validation loss: 0.6274632811546326
Epoch: 22/300 - Train loss: 0.6267232894897461, Validation loss: 0.6236382126808167
Epoch: 23/300 - Train loss: 0.6225094795227051, Validation loss: 0.6191208362579346
Epoch: 24/300 - Train loss: 0.6182544827461243, Validation loss: 0.6150615811347961
Epoch: 25/300 - Train loss: 0.6139642596244812, Validation loss: 0.6108138561248779
Epoch: 26/300 - Train loss: 0.6096420884132385, Validation loss: 0.6064757108688354
Epoch: 27/300 - Train loss: 0.6052901148796082, Validation loss: 0.6020618677139282
Epoch: 28/300 - Train loss: 0.6009138226509094, Validation loss: 0.5977309346199036
Epoch: 29/300 - Train loss: 0.5965167880058289, Validation loss: 0.5935031175613403
Epoch: 30/300 - Train loss: 0.592101514339447, Validation loss: 0.5890368819236755
Epoch: 31/300 - Train loss: 0.5876714587211609, Validation loss: 0.5846794843673706
Epoch: 32/300 - Train loss: 0.5832291841506958, Validation loss: 0.5801777243614197
Epoch: 33/300 - Train loss: 0.5787806510925293, Validation loss: 0.5758404731750488
Epoch: 34/300 - Train loss: 0.5743304491043091, Validation loss: 0.5713780522346497
Epoch: 35/300 - Train loss: 0.5698839426040649, Validation loss: 0.5667577385902405
Epoch: 36/300 - Train loss: 0.5654460787773132, Validation loss: 0.5625447034835815
Epoch: 37/300 - Train loss: 0.5610220432281494, Validation loss: 0.5582563877105713
Epoch: 38/300 - Train loss: 0.5566161870956421, Validation loss: 0.5537511110305786
Epoch: 39/300 - Train loss: 0.5522329807281494, Validation loss: 0.5494247674942017
Epoch: 40/300 - Train loss: 0.5478765368461609, Validation loss: 0.5452520847320557
Epoch: 41/300 - Train loss: 0.5435509085655212, Validation loss: 0.5409702658653259
Epoch: 42/300 - Train loss: 0.5392596125602722, Validation loss: 0.5368064641952515
Epoch: 43/300 - Train loss: 0.5350064635276794, Validation loss: 0.5323552489280701
Epoch: 44/300 - Train loss: 0.5307939648628235, Validation loss: 0.5280776023864746
Epoch: 45/300 - Train loss: 0.5266256332397461, Validation loss: 0.5243045687675476
Epoch: 46/300 - Train loss: 0.5225046277046204, Validation loss: 0.5200720429420471
Epoch: 47/300 - Train loss: 0.5184344053268433, Validation loss: 0.5161739587783813
Epoch: 48/300 - Train loss: 0.5144182443618774, Validation loss: 0.5119929313659668
Epoch: 49/300 - Train loss: 0.5104590058326721, Validation loss: 0.5082386136054993
Epoch: 50/300 - Train loss: 0.5065594911575317, Validation loss: 0.5041065812110901
Epoch: 51/300 - Train loss: 0.5027220845222473, Validation loss: 0.500602662563324
Epoch: 52/300 - Train loss: 0.4989493489265442, Validation loss: 0.4969351291656494
Epoch: 53/300 - Train loss: 0.49524298310279846, Validation loss: 0.49312785267829895
Epoch: 54/300 - Train loss: 0.491604745388031, Validation loss: 0.4894111752510071
Epoch: 55/300 - Train loss: 0.488036572933197, Validation loss: 0.48602819442749023
Epoch: 56/300 - Train loss: 0.4845399856567383, Validation loss: 0.48263686895370483
Epoch: 57/300 - Train loss: 0.4811161458492279, Validation loss: 0.4792075753211975
Epoch: 58/300 - Train loss: 0.477765828371048, Validation loss: 0.4757261872291565
Epoch: 59/300 - Train loss: 0.47448956966400146, Validation loss: 0.47222474217414856
Epoch: 60/300 - Train loss: 0.4712882339954376, Validation loss: 0.4689798653125763
Epoch: 61/300 - Train loss: 0.46816205978393555, Validation loss: 0.46602585911750793
Epoch: 62/300 - Train loss: 0.46511080861091614, Validation loss: 0.46317198872566223
Epoch: 63/300 - Train loss: 0.4621344804763794, Validation loss: 0.4600628912448883
Epoch: 64/300 - Train loss: 0.45923304557800293, Validation loss: 0.4570596516132355
Epoch: 65/300 - Train loss: 0.45640599727630615, Validation loss: 0.4545224606990814
Epoch: 66/300 - Train loss: 0.45365285873413086, Validation loss: 0.4517017900943756
Epoch: 67/300 - Train loss: 0.4509727656841278, Validation loss: 0.44942793250083923
Epoch: 68/300 - Train loss: 0.44836416840553284, Validation loss: 0.4464954435825348
Epoch: 69/300 - Train loss: 0.44582614302635193, Validation loss: 0.44447943568229675
Epoch: 70/300 - Train loss: 0.4433569610118866, Validation loss: 0.44149336218833923
Epoch: 71/300 - Train loss: 0.44095590710639954, Validation loss: 0.43953537940979004
Epoch: 72/300 - Train loss: 0.43862184882164, Validation loss: 0.43695536255836487
Epoch: 73/300 - Train loss: 0.4363527297973633, Validation loss: 0.43444326519966125
Epoch: 74/300 - Train loss: 0.4341473877429962, Validation loss: 0.4320651590824127
Epoch: 75/300 - Train loss: 0.4320041537284851, Validation loss: 0.430084228515625
Epoch: 76/300 - Train loss: 0.429921954870224, Validation loss: 0.42825204133987427
Epoch: 77/300 - Train loss: 0.427899032831192, Validation loss: 0.425749272108078
Epoch: 78/300 - Train loss: 0.4259335696697235, Validation loss: 0.42368659377098083
Epoch: 79/300 - Train loss: 0.42402419447898865, Validation loss: 0.4218379855155945
Epoch: 80/300 - Train loss: 0.42216944694519043, Validation loss: 0.419892817735672
Epoch: 81/300 - Train loss: 0.42036759853363037, Validation loss: 0.41837602853775024
Epoch: 82/300 - Train loss: 0.41861632466316223, Validation loss: 0.41622409224510193
Epoch: 83/300 - Train loss: 0.4169144034385681, Validation loss: 0.414908766746521
Epoch: 84/300 - Train loss: 0.41526028513908386, Validation loss: 0.41297924518585205
Epoch: 85/300 - Train loss: 0.41365277767181396, Validation loss: 0.41191819310188293
Epoch: 86/300 - Train loss: 0.41208934783935547, Validation loss: 0.4099583327770233
Epoch: 87/300 - Train loss: 0.41056862473487854, Validation loss: 0.40865573287010193
Epoch: 88/300 - Train loss: 0.40908950567245483, Validation loss: 0.4070165753364563
Epoch: 89/300 - Train loss: 0.4076504707336426, Validation loss: 0.4053772985935211
Epoch: 90/300 - Train loss: 0.4062506854534149, Validation loss: 0.4035153388977051
Epoch: 91/300 - Train loss: 0.4048862159252167, Validation loss: 0.4025908410549164
Epoch: 92/300 - Train loss: 0.40355563163757324, Validation loss: 0.4016069173812866
Epoch: 93/300 - Train loss: 0.4022581875324249, Validation loss: 0.4001143276691437
Epoch: 94/300 - Train loss: 0.40099287033081055, Validation loss: 0.39837467670440674
Epoch: 95/300 - Train loss: 0.39975860714912415, Validation loss: 0.3978312313556671
Epoch: 96/300 - Train loss: 0.39855363965034485, Validation loss: 0.39607667922973633
Epoch: 97/300 - Train loss: 0.39737799763679504, Validation loss: 0.3947552740573883
Epoch: 98/300 - Train loss: 0.39623087644577026, Validation loss: 0.39381352066993713
Epoch: 99/300 - Train loss: 0.39511024951934814, Validation loss: 0.3918463885784149
Epoch: 100/300 - Train loss: 0.3940165042877197, Validation loss: 0.39162299036979675
Epoch: 101/300 - Train loss: 0.39294829964637756, Validation loss: 0.3904429078102112
Epoch: 102/300 - Train loss: 0.3919040858745575, Validation loss: 0.38934966921806335
Epoch: 103/300 - Train loss: 0.390884131193161, Validation loss: 0.3887442946434021
Epoch: 104/300 - Train loss: 0.38988783955574036, Validation loss: 0.38734039664268494
Epoch: 105/300 - Train loss: 0.38891345262527466, Validation loss: 0.38591840863227844
Epoch: 106/300 - Train loss: 0.3879610598087311, Validation loss: 0.3848574757575989
Epoch: 107/300 - Train loss: 0.3870299160480499, Validation loss: 0.38406702876091003
Epoch: 108/300 - Train loss: 0.3861188590526581, Validation loss: 0.3832297921180725
Epoch: 109/300 - Train loss: 0.38522785902023315, Validation loss: 0.3823472559452057
Epoch: 110/300 - Train loss: 0.3843556046485901, Validation loss: 0.381112277507782
Epoch: 111/300 - Train loss: 0.38350075483322144, Validation loss: 0.3806982934474945
Epoch: 112/300 - Train loss: 0.38266316056251526, Validation loss: 0.3795815706253052
Epoch: 113/300 - Train loss: 0.3818422853946686, Validation loss: 0.37864407896995544
Epoch: 114/300 - Train loss: 0.3810366988182068, Validation loss: 0.37851354479789734
Epoch: 115/300 - Train loss: 0.38024523854255676, Validation loss: 0.3768017590045929
Epoch: 116/300 - Train loss: 0.37946856021881104, Validation loss: 0.3756648004055023
Epoch: 117/300 - Train loss: 0.3787066638469696, Validation loss: 0.3754522204399109
Epoch: 118/300 - Train loss: 0.3779577314853668, Validation loss: 0.37512239813804626
Epoch: 119/300 - Train loss: 0.3772214353084564, Validation loss: 0.3751733899116516
Epoch: 120/300 - Train loss: 0.3764972984790802, Validation loss: 0.372999370098114
Epoch: 121/300 - Train loss: 0.37578392028808594, Validation loss: 0.37222379446029663
Epoch: 122/300 - Train loss: 0.3750816583633423, Validation loss: 0.371547132730484
Epoch: 123/300 - Train loss: 0.37439045310020447, Validation loss: 0.3708955645561218
Epoch: 124/300 - Train loss: 0.37370970845222473, Validation loss: 0.37010058760643005
Epoch: 125/300 - Train loss: 0.3730393946170807, Validation loss: 0.36985325813293457
Epoch: 126/300 - Train loss: 0.3723782002925873, Validation loss: 0.36896464228630066
Epoch: 127/300 - Train loss: 0.37172603607177734, Validation loss: 0.3677107095718384
Epoch: 128/300 - Train loss: 0.37108221650123596, Validation loss: 0.36667174100875854
Epoch: 129/300 - Train loss: 0.37044650316238403, Validation loss: 0.36642518639564514
Epoch: 130/300 - Train loss: 0.36981961131095886, Validation loss: 0.3664468824863434
Epoch: 131/300 - Train loss: 0.3692014515399933, Validation loss: 0.36562633514404297
Epoch: 132/300 - Train loss: 0.36859211325645447, Validation loss: 0.36462247371673584
Epoch: 133/300 - Train loss: 0.3679904639720917, Validation loss: 0.3644177317619324
Epoch: 134/300 - Train loss: 0.36739540100097656, Validation loss: 0.3643307089805603
Epoch: 135/300 - Train loss: 0.36680784821510315, Validation loss: 0.36297979950904846
Epoch: 136/300 - Train loss: 0.3662268817424774, Validation loss: 0.36191660165786743
Epoch: 137/300 - Train loss: 0.365651935338974, Validation loss: 0.3617311418056488
