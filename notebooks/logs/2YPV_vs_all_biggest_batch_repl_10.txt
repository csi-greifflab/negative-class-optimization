Epoch: 1/300 - Train loss: 0.6931166052818298, Validation loss: 0.6915407776832581
Epoch: 2/300 - Train loss: 0.6910629272460938, Validation loss: 0.6895184516906738
Epoch: 3/300 - Train loss: 0.6889528036117554, Validation loss: 0.6872786283493042
Epoch: 4/300 - Train loss: 0.6867423057556152, Validation loss: 0.6848589777946472
Epoch: 5/300 - Train loss: 0.684382438659668, Validation loss: 0.6822837591171265
Epoch: 6/300 - Train loss: 0.681831955909729, Validation loss: 0.6794593334197998
Epoch: 7/300 - Train loss: 0.6790640354156494, Validation loss: 0.676395058631897
Epoch: 8/300 - Train loss: 0.6760678887367249, Validation loss: 0.673029363155365
Epoch: 9/300 - Train loss: 0.6728351712226868, Validation loss: 0.6695404052734375
Epoch: 10/300 - Train loss: 0.6693708300590515, Validation loss: 0.665790319442749
Epoch: 11/300 - Train loss: 0.6656864285469055, Validation loss: 0.6618592739105225
Epoch: 12/300 - Train loss: 0.6617997288703918, Validation loss: 0.6577603816986084
Epoch: 13/300 - Train loss: 0.6577391028404236, Validation loss: 0.6534205079078674
Epoch: 14/300 - Train loss: 0.6535245776176453, Validation loss: 0.6489819884300232
Epoch: 15/300 - Train loss: 0.6491798758506775, Validation loss: 0.6444534659385681
Epoch: 16/300 - Train loss: 0.6447232961654663, Validation loss: 0.6398757100105286
Epoch: 17/300 - Train loss: 0.6401727199554443, Validation loss: 0.6351942420005798
Epoch: 18/300 - Train loss: 0.6355448365211487, Validation loss: 0.6303228735923767
Epoch: 19/300 - Train loss: 0.6308510303497314, Validation loss: 0.6256923079490662
Epoch: 20/300 - Train loss: 0.6261067986488342, Validation loss: 0.6209781765937805
Epoch: 21/300 - Train loss: 0.6213194727897644, Validation loss: 0.6159626245498657
Epoch: 22/300 - Train loss: 0.616502583026886, Validation loss: 0.6112089157104492
Epoch: 23/300 - Train loss: 0.6116599440574646, Validation loss: 0.60615473985672
Epoch: 24/300 - Train loss: 0.6067982912063599, Validation loss: 0.6013911962509155
Epoch: 25/300 - Train loss: 0.601926863193512, Validation loss: 0.596332848072052
Epoch: 26/300 - Train loss: 0.5970513820648193, Validation loss: 0.5916502475738525
Epoch: 27/300 - Train loss: 0.5921797156333923, Validation loss: 0.5866219997406006
Epoch: 28/300 - Train loss: 0.5873196125030518, Validation loss: 0.5817989706993103
Epoch: 29/300 - Train loss: 0.5824722051620483, Validation loss: 0.5771010518074036
Epoch: 30/300 - Train loss: 0.5776426792144775, Validation loss: 0.57220858335495
Epoch: 31/300 - Train loss: 0.5728371143341064, Validation loss: 0.5673881769180298
Epoch: 32/300 - Train loss: 0.5680550932884216, Validation loss: 0.5625033378601074
Epoch: 33/300 - Train loss: 0.5633013248443604, Validation loss: 0.5579515695571899
Epoch: 34/300 - Train loss: 0.5585786700248718, Validation loss: 0.553388774394989
Epoch: 35/300 - Train loss: 0.5538890361785889, Validation loss: 0.5487022399902344
Epoch: 36/300 - Train loss: 0.549234926700592, Validation loss: 0.5441430807113647
Epoch: 37/300 - Train loss: 0.5446172952651978, Validation loss: 0.5394911170005798
Epoch: 38/300 - Train loss: 0.5400374531745911, Validation loss: 0.5349936485290527
Epoch: 39/300 - Train loss: 0.5354968905448914, Validation loss: 0.5303608179092407
Epoch: 40/300 - Train loss: 0.5309982895851135, Validation loss: 0.5261854529380798
Epoch: 41/300 - Train loss: 0.526542603969574, Validation loss: 0.5217288732528687
Epoch: 42/300 - Train loss: 0.5221320390701294, Validation loss: 0.517517626285553
Epoch: 43/300 - Train loss: 0.5177690982818604, Validation loss: 0.5129352807998657
Epoch: 44/300 - Train loss: 0.513455867767334, Validation loss: 0.5090267062187195
Epoch: 45/300 - Train loss: 0.5091938376426697, Validation loss: 0.5041622519493103
Epoch: 46/300 - Train loss: 0.5049835443496704, Validation loss: 0.5004556775093079
Epoch: 47/300 - Train loss: 0.5008258819580078, Validation loss: 0.4961509108543396
Epoch: 48/300 - Train loss: 0.49672213196754456, Validation loss: 0.49219152331352234
Epoch: 49/300 - Train loss: 0.4926728904247284, Validation loss: 0.4883652925491333
Epoch: 50/300 - Train loss: 0.48867812752723694, Validation loss: 0.48454493284225464
Epoch: 51/300 - Train loss: 0.48473963141441345, Validation loss: 0.48097825050354004
Epoch: 52/300 - Train loss: 0.48085880279541016, Validation loss: 0.4768327474594116
Epoch: 53/300 - Train loss: 0.47703641653060913, Validation loss: 0.4731869399547577
Epoch: 54/300 - Train loss: 0.4732733964920044, Validation loss: 0.46991977095603943
Epoch: 55/300 - Train loss: 0.46957144141197205, Validation loss: 0.46600160002708435
Epoch: 56/300 - Train loss: 0.46593114733695984, Validation loss: 0.46190372109413147
Epoch: 57/300 - Train loss: 0.4623527228832245, Validation loss: 0.45903176069259644
Epoch: 58/300 - Train loss: 0.45883709192276, Validation loss: 0.4551839828491211
Epoch: 59/300 - Train loss: 0.45538437366485596, Validation loss: 0.45177096128463745
Epoch: 60/300 - Train loss: 0.4519941806793213, Validation loss: 0.44872310757637024
Epoch: 61/300 - Train loss: 0.44866612553596497, Validation loss: 0.4458565413951874
Epoch: 62/300 - Train loss: 0.44540101289749146, Validation loss: 0.4420926868915558
Epoch: 63/300 - Train loss: 0.442198783159256, Validation loss: 0.43883413076400757
Epoch: 64/300 - Train loss: 0.4390595257282257, Validation loss: 0.4367486536502838
Epoch: 65/300 - Train loss: 0.4359828233718872, Validation loss: 0.43281248211860657
Epoch: 66/300 - Train loss: 0.43296757340431213, Validation loss: 0.4301321804523468
Epoch: 67/300 - Train loss: 0.4300138056278229, Validation loss: 0.42682120203971863
Epoch: 68/300 - Train loss: 0.4271208345890045, Validation loss: 0.4245118498802185
Epoch: 69/300 - Train loss: 0.4242890775203705, Validation loss: 0.4213619530200958
Epoch: 70/300 - Train loss: 0.42151761054992676, Validation loss: 0.4188450276851654
Epoch: 71/300 - Train loss: 0.4188055992126465, Validation loss: 0.416087806224823
Epoch: 72/300 - Train loss: 0.4161527454853058, Validation loss: 0.41382503509521484
Epoch: 73/300 - Train loss: 0.41355809569358826, Validation loss: 0.41104409098625183
Epoch: 74/300 - Train loss: 0.4110206663608551, Validation loss: 0.40859368443489075
Epoch: 75/300 - Train loss: 0.4085399806499481, Validation loss: 0.4062306582927704
Epoch: 76/300 - Train loss: 0.40611520409584045, Validation loss: 0.40432101488113403
Epoch: 77/300 - Train loss: 0.403745174407959, Validation loss: 0.4016132056713104
Epoch: 78/300 - Train loss: 0.4014286398887634, Validation loss: 0.39903122186660767
Epoch: 79/300 - Train loss: 0.39916494488716125, Validation loss: 0.3968210220336914
Epoch: 80/300 - Train loss: 0.3969537317752838, Validation loss: 0.39480018615722656
Epoch: 81/300 - Train loss: 0.3947935700416565, Validation loss: 0.3926661014556885
Epoch: 82/300 - Train loss: 0.3926832973957062, Validation loss: 0.39067554473876953
Epoch: 83/300 - Train loss: 0.39062216877937317, Validation loss: 0.3883325457572937
Epoch: 84/300 - Train loss: 0.38860905170440674, Validation loss: 0.38645240664482117
Epoch: 85/300 - Train loss: 0.38664332032203674, Validation loss: 0.3841921389102936
Epoch: 86/300 - Train loss: 0.38472333550453186, Validation loss: 0.3825099766254425
Epoch: 87/300 - Train loss: 0.3828476667404175, Validation loss: 0.38058382272720337
Epoch: 88/300 - Train loss: 0.3810156583786011, Validation loss: 0.3786791265010834
Epoch: 89/300 - Train loss: 0.37922602891921997, Validation loss: 0.3776227831840515
Epoch: 90/300 - Train loss: 0.377477765083313, Validation loss: 0.3750283122062683
Epoch: 91/300 - Train loss: 0.3757702708244324, Validation loss: 0.3739545941352844
Epoch: 92/300 - Train loss: 0.37410295009613037, Validation loss: 0.37166863679885864
Epoch: 93/300 - Train loss: 0.3724748194217682, Validation loss: 0.3704259395599365
Epoch: 94/300 - Train loss: 0.3708840310573578, Validation loss: 0.36878085136413574
Epoch: 95/300 - Train loss: 0.3693302869796753, Validation loss: 0.36772406101226807
Epoch: 96/300 - Train loss: 0.3678118586540222, Validation loss: 0.36575084924697876
Epoch: 97/300 - Train loss: 0.3663278818130493, Validation loss: 0.3639543652534485
Epoch: 98/300 - Train loss: 0.36487776041030884, Validation loss: 0.3629419207572937
Epoch: 99/300 - Train loss: 0.36346057057380676, Validation loss: 0.3616878390312195
Epoch: 100/300 - Train loss: 0.3620750606060028, Validation loss: 0.359789103269577
Epoch: 101/300 - Train loss: 0.3607209026813507, Validation loss: 0.35846012830734253
Epoch: 102/300 - Train loss: 0.35939693450927734, Validation loss: 0.35771235823631287
Epoch: 103/300 - Train loss: 0.3581026494503021, Validation loss: 0.35650354623794556
Epoch: 104/300 - Train loss: 0.35683736205101013, Validation loss: 0.354610800743103
Epoch: 105/300 - Train loss: 0.3556002974510193, Validation loss: 0.35479193925857544
Epoch: 106/300 - Train loss: 0.35439059138298035, Validation loss: 0.3527757227420807
Epoch: 107/300 - Train loss: 0.35320770740509033, Validation loss: 0.35196438431739807
Epoch: 108/300 - Train loss: 0.35205063223838806, Validation loss: 0.3506243824958801
Epoch: 109/300 - Train loss: 0.35091930627822876, Validation loss: 0.34922701120376587
Epoch: 110/300 - Train loss: 0.34981241822242737, Validation loss: 0.3481326997280121
Epoch: 111/300 - Train loss: 0.3487294316291809, Validation loss: 0.34693512320518494
Epoch: 112/300 - Train loss: 0.34766966104507446, Validation loss: 0.3460492789745331
Epoch: 113/300 - Train loss: 0.3466331362724304, Validation loss: 0.34458330273628235
Epoch: 114/300 - Train loss: 0.3456191122531891, Validation loss: 0.3443323075771332
Epoch: 115/300 - Train loss: 0.34462642669677734, Validation loss: 0.34297263622283936
Epoch: 116/300 - Train loss: 0.3436543047428131, Validation loss: 0.34196236729621887
Epoch: 117/300 - Train loss: 0.34270188212394714, Validation loss: 0.34086111187934875
Epoch: 118/300 - Train loss: 0.34176915884017944, Validation loss: 0.34020137786865234
Epoch: 119/300 - Train loss: 0.3408556878566742, Validation loss: 0.33936721086502075
Epoch: 120/300 - Train loss: 0.33996063470840454, Validation loss: 0.3383764624595642
Epoch: 121/300 - Train loss: 0.339083731174469, Validation loss: 0.3372005224227905
Epoch: 122/300 - Train loss: 0.3382243514060974, Validation loss: 0.33670902252197266
Epoch: 123/300 - Train loss: 0.3373827636241913, Validation loss: 0.3357546627521515
Epoch: 124/300 - Train loss: 0.3365585505962372, Validation loss: 0.3352603018283844
Epoch: 125/300 - Train loss: 0.3357506990432739, Validation loss: 0.3340478241443634
Epoch: 126/300 - Train loss: 0.3349594175815582, Validation loss: 0.33361536264419556
Epoch: 127/300 - Train loss: 0.33418363332748413, Validation loss: 0.3328823447227478
Epoch: 128/300 - Train loss: 0.3334231674671173, Validation loss: 0.3319244384765625
Epoch: 129/300 - Train loss: 0.33267742395401, Validation loss: 0.3312456011772156
Epoch: 130/300 - Train loss: 0.33194637298583984, Validation loss: 0.33054038882255554
Epoch: 131/300 - Train loss: 0.33122944831848145, Validation loss: 0.32949399948120117
Epoch: 132/300 - Train loss: 0.3305264115333557, Validation loss: 0.32940542697906494
Epoch: 133/300 - Train loss: 0.329837441444397, Validation loss: 0.32844385504722595
Epoch: 134/300 - Train loss: 0.3291614353656769, Validation loss: 0.327814519405365
Epoch: 135/300 - Train loss: 0.32849767804145813, Validation loss: 0.3267856240272522
Epoch: 136/300 - Train loss: 0.3278462290763855, Validation loss: 0.3268965482711792
Epoch: 137/300 - Train loss: 0.3272066116333008, Validation loss: 0.3259354531764984
Epoch: 138/300 - Train loss: 0.32657888531684875, Validation loss: 0.32573261857032776
Epoch: 139/300 - Train loss: 0.32596349716186523, Validation loss: 0.32502618432044983
Epoch: 140/300 - Train loss: 0.3253595232963562, Validation loss: 0.32421037554740906
Epoch: 141/300 - Train loss: 0.3247665464878082, Validation loss: 0.3237420618534088
Epoch: 142/300 - Train loss: 0.3241840898990631, Validation loss: 0.32258060574531555
Epoch: 143/300 - Train loss: 0.3236119747161865, Validation loss: 0.3225835859775543
Epoch: 144/300 - Train loss: 0.3230503499507904, Validation loss: 0.3217763900756836
Epoch: 145/300 - Train loss: 0.3224991261959076, Validation loss: 0.3217082917690277
Epoch: 146/300 - Train loss: 0.3219577968120575, Validation loss: 0.32146191596984863
