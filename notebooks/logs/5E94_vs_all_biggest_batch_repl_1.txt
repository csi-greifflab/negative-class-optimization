Epoch: 1/300 - Train loss: 0.6947175860404968, Validation loss: 0.6914141178131104
Epoch: 2/300 - Train loss: 0.6924867033958435, Validation loss: 0.6892246007919312
Epoch: 3/300 - Train loss: 0.6903339624404907, Validation loss: 0.6871029138565063
Epoch: 4/300 - Train loss: 0.6882065534591675, Validation loss: 0.6847743391990662
Epoch: 5/300 - Train loss: 0.686063289642334, Validation loss: 0.6828852891921997
Epoch: 6/300 - Train loss: 0.6838509440422058, Validation loss: 0.6803684234619141
Epoch: 7/300 - Train loss: 0.6815242171287537, Validation loss: 0.6780793070793152
Epoch: 8/300 - Train loss: 0.6790497303009033, Validation loss: 0.6753071546554565
Epoch: 9/300 - Train loss: 0.6764135360717773, Validation loss: 0.6725817918777466
Epoch: 10/300 - Train loss: 0.673610270023346, Validation loss: 0.6698884963989258
Epoch: 11/300 - Train loss: 0.6706514954566956, Validation loss: 0.6667404174804688
Epoch: 12/300 - Train loss: 0.6675523519515991, Validation loss: 0.6635861396789551
Epoch: 13/300 - Train loss: 0.6643262505531311, Validation loss: 0.6604472398757935
Epoch: 14/300 - Train loss: 0.6609854698181152, Validation loss: 0.657027542591095
Epoch: 15/300 - Train loss: 0.6575294733047485, Validation loss: 0.6536489725112915
Epoch: 16/300 - Train loss: 0.6539708375930786, Validation loss: 0.6502981781959534
Epoch: 17/300 - Train loss: 0.6503267884254456, Validation loss: 0.6466829776763916
Epoch: 18/300 - Train loss: 0.6466084122657776, Validation loss: 0.6428066492080688
Epoch: 19/300 - Train loss: 0.642826497554779, Validation loss: 0.6391724348068237
Epoch: 20/300 - Train loss: 0.6389884352684021, Validation loss: 0.6356031894683838
Epoch: 21/300 - Train loss: 0.6351052522659302, Validation loss: 0.6315358281135559
Epoch: 22/300 - Train loss: 0.631186842918396, Validation loss: 0.627910852432251
Epoch: 23/300 - Train loss: 0.6272401809692383, Validation loss: 0.6238113045692444
Epoch: 24/300 - Train loss: 0.6232721209526062, Validation loss: 0.6201531291007996
Epoch: 25/300 - Train loss: 0.6192925572395325, Validation loss: 0.6162022948265076
Epoch: 26/300 - Train loss: 0.6153090596199036, Validation loss: 0.6123979091644287
Epoch: 27/300 - Train loss: 0.6113263964653015, Validation loss: 0.6083431243896484
Epoch: 28/300 - Train loss: 0.6073514819145203, Validation loss: 0.6043423414230347
Epoch: 29/300 - Train loss: 0.6033896207809448, Validation loss: 0.6003387570381165
Epoch: 30/300 - Train loss: 0.5994434952735901, Validation loss: 0.5964757204055786
Epoch: 31/300 - Train loss: 0.5955156683921814, Validation loss: 0.5929292440414429
Epoch: 32/300 - Train loss: 0.5916082859039307, Validation loss: 0.588971734046936
Epoch: 33/300 - Train loss: 0.5877256393432617, Validation loss: 0.5847308039665222
Epoch: 34/300 - Train loss: 0.5838719606399536, Validation loss: 0.5816065669059753
Epoch: 35/300 - Train loss: 0.5800498127937317, Validation loss: 0.5773616433143616
Epoch: 36/300 - Train loss: 0.5762628316879272, Validation loss: 0.5739253163337708
Epoch: 37/300 - Train loss: 0.5725137591362, Validation loss: 0.5702676773071289
Epoch: 38/300 - Train loss: 0.5688048601150513, Validation loss: 0.5664526224136353
Epoch: 39/300 - Train loss: 0.5651399493217468, Validation loss: 0.563026487827301
Epoch: 40/300 - Train loss: 0.5615214109420776, Validation loss: 0.5592971444129944
Epoch: 41/300 - Train loss: 0.5579519867897034, Validation loss: 0.5560154318809509
Epoch: 42/300 - Train loss: 0.5544338822364807, Validation loss: 0.5529423952102661
Epoch: 43/300 - Train loss: 0.5509685277938843, Validation loss: 0.5496863126754761
Epoch: 44/300 - Train loss: 0.5475574135780334, Validation loss: 0.5458196401596069
Epoch: 45/300 - Train loss: 0.5442014336585999, Validation loss: 0.5423763990402222
Epoch: 46/300 - Train loss: 0.5409013628959656, Validation loss: 0.539574146270752
Epoch: 47/300 - Train loss: 0.5376579761505127, Validation loss: 0.5370901226997375
Epoch: 48/300 - Train loss: 0.5344714522361755, Validation loss: 0.5329974889755249
Epoch: 49/300 - Train loss: 0.5313420295715332, Validation loss: 0.5301530957221985
Epoch: 50/300 - Train loss: 0.5282701849937439, Validation loss: 0.5274024605751038
Epoch: 51/300 - Train loss: 0.5252548456192017, Validation loss: 0.5246918797492981
Epoch: 52/300 - Train loss: 0.5222963690757751, Validation loss: 0.5210770964622498
Epoch: 53/300 - Train loss: 0.51939457654953, Validation loss: 0.5189839601516724
Epoch: 54/300 - Train loss: 0.5165491104125977, Validation loss: 0.5155414342880249
Epoch: 55/300 - Train loss: 0.5137589573860168, Validation loss: 0.5130495429039001
Epoch: 56/300 - Train loss: 0.5110233426094055, Validation loss: 0.5097576379776001
Epoch: 57/300 - Train loss: 0.5083413124084473, Validation loss: 0.5083200335502625
Epoch: 58/300 - Train loss: 0.5057122111320496, Validation loss: 0.5046442747116089
Epoch: 59/300 - Train loss: 0.5031350255012512, Validation loss: 0.502936840057373
Epoch: 60/300 - Train loss: 0.5006093382835388, Validation loss: 0.5000817179679871
Epoch: 61/300 - Train loss: 0.49813446402549744, Validation loss: 0.49758660793304443
Epoch: 62/300 - Train loss: 0.4957088828086853, Validation loss: 0.49436667561531067
Epoch: 63/300 - Train loss: 0.4933314323425293, Validation loss: 0.49295780062675476
Epoch: 64/300 - Train loss: 0.4910009205341339, Validation loss: 0.4915965795516968
Epoch: 65/300 - Train loss: 0.48871636390686035, Validation loss: 0.4884166419506073
Epoch: 66/300 - Train loss: 0.48647695779800415, Validation loss: 0.4866097867488861
Epoch: 67/300 - Train loss: 0.48428213596343994, Validation loss: 0.4840884208679199
Epoch: 68/300 - Train loss: 0.4821304678916931, Validation loss: 0.48183685541152954
Epoch: 69/300 - Train loss: 0.4800207018852234, Validation loss: 0.48013272881507874
Epoch: 70/300 - Train loss: 0.47795191407203674, Validation loss: 0.47826364636421204
Epoch: 71/300 - Train loss: 0.4759230315685272, Validation loss: 0.4758923649787903
Epoch: 72/300 - Train loss: 0.47393301129341125, Validation loss: 0.4736708402633667
Epoch: 73/300 - Train loss: 0.4719806909561157, Validation loss: 0.47176820039749146
Epoch: 74/300 - Train loss: 0.47006452083587646, Validation loss: 0.4691076874732971
Epoch: 75/300 - Train loss: 0.4681837260723114, Validation loss: 0.46876686811447144
Epoch: 76/300 - Train loss: 0.46633756160736084, Validation loss: 0.46670934557914734
Epoch: 77/300 - Train loss: 0.46452540159225464, Validation loss: 0.46443745493888855
Epoch: 78/300 - Train loss: 0.4627464711666107, Validation loss: 0.46232709288597107
Epoch: 79/300 - Train loss: 0.46100014448165894, Validation loss: 0.46050718426704407
Epoch: 80/300 - Train loss: 0.4592849314212799, Validation loss: 0.4596671462059021
Epoch: 81/300 - Train loss: 0.4576003849506378, Validation loss: 0.4581340253353119
Epoch: 82/300 - Train loss: 0.45594555139541626, Validation loss: 0.4569925367832184
Epoch: 83/300 - Train loss: 0.4543195068836212, Validation loss: 0.4558406472206116
Epoch: 84/300 - Train loss: 0.4527219831943512, Validation loss: 0.45387357473373413
Epoch: 85/300 - Train loss: 0.4511519968509674, Validation loss: 0.4511224329471588
Epoch: 86/300 - Train loss: 0.4496086537837982, Validation loss: 0.4492150545120239
Epoch: 87/300 - Train loss: 0.4480917453765869, Validation loss: 0.4480438232421875
Epoch: 88/300 - Train loss: 0.4466008245944977, Validation loss: 0.44675472378730774
Epoch: 89/300 - Train loss: 0.4451354742050171, Validation loss: 0.4448590874671936
Epoch: 90/300 - Train loss: 0.44369393587112427, Validation loss: 0.4433439075946808
Epoch: 91/300 - Train loss: 0.4422754943370819, Validation loss: 0.4435630142688751
Epoch: 92/300 - Train loss: 0.44088014960289, Validation loss: 0.44092872738838196
Epoch: 93/300 - Train loss: 0.4395071268081665, Validation loss: 0.440375953912735
Epoch: 94/300 - Train loss: 0.4381561279296875, Validation loss: 0.4388088583946228
Epoch: 95/300 - Train loss: 0.4368264973163605, Validation loss: 0.43639782071113586
Epoch: 96/300 - Train loss: 0.4355173110961914, Validation loss: 0.435564786195755
Epoch: 97/300 - Train loss: 0.43422794342041016, Validation loss: 0.4344034492969513
Epoch: 98/300 - Train loss: 0.4329581558704376, Validation loss: 0.43403366208076477
Epoch: 99/300 - Train loss: 0.43170735239982605, Validation loss: 0.43226733803749084
Epoch: 100/300 - Train loss: 0.4304754137992859, Validation loss: 0.43240174651145935
Epoch: 101/300 - Train loss: 0.4292617738246918, Validation loss: 0.4295460879802704
Epoch: 102/300 - Train loss: 0.42806586623191833, Validation loss: 0.4274696707725525
Epoch: 103/300 - Train loss: 0.42688727378845215, Validation loss: 0.42706942558288574
Epoch: 104/300 - Train loss: 0.4257252812385559, Validation loss: 0.42580223083496094
Epoch: 105/300 - Train loss: 0.4245794713497162, Validation loss: 0.423928439617157
Epoch: 106/300 - Train loss: 0.4234502911567688, Validation loss: 0.4239598214626312
Epoch: 107/300 - Train loss: 0.42233696579933167, Validation loss: 0.42235347628593445
Epoch: 108/300 - Train loss: 0.4212391674518585, Validation loss: 0.4208936095237732
Epoch: 109/300 - Train loss: 0.42015641927719116, Validation loss: 0.41934525966644287
Epoch: 110/300 - Train loss: 0.41908878087997437, Validation loss: 0.41895028948783875
Epoch: 111/300 - Train loss: 0.4180358350276947, Validation loss: 0.41753020882606506
Epoch: 112/300 - Train loss: 0.4169972836971283, Validation loss: 0.41607150435447693
Epoch: 113/300 - Train loss: 0.4159733057022095, Validation loss: 0.41557788848876953
Epoch: 114/300 - Train loss: 0.41496309638023376, Validation loss: 0.41423553228378296
Epoch: 115/300 - Train loss: 0.4139666259288788, Validation loss: 0.4135095477104187
Epoch: 116/300 - Train loss: 0.41298341751098633, Validation loss: 0.4118722379207611
Epoch: 117/300 - Train loss: 0.41201335191726685, Validation loss: 0.41239622235298157
Epoch: 118/300 - Train loss: 0.41105565428733826, Validation loss: 0.4101511240005493
Epoch: 119/300 - Train loss: 0.41011038422584534, Validation loss: 0.40921759605407715
Epoch: 120/300 - Train loss: 0.4091768264770508, Validation loss: 0.4099690020084381
Epoch: 121/300 - Train loss: 0.4082549810409546, Validation loss: 0.4082903265953064
Epoch: 122/300 - Train loss: 0.40734440088272095, Validation loss: 0.40738382935523987
Epoch: 123/300 - Train loss: 0.40644508600234985, Validation loss: 0.4063182473182678
Epoch: 124/300 - Train loss: 0.40555647015571594, Validation loss: 0.40512576699256897
Epoch: 125/300 - Train loss: 0.40467825531959534, Validation loss: 0.40522903203964233
Epoch: 126/300 - Train loss: 0.40381038188934326, Validation loss: 0.4036223590373993
Epoch: 127/300 - Train loss: 0.4029526710510254, Validation loss: 0.40343931317329407
Epoch: 128/300 - Train loss: 0.4021052420139313, Validation loss: 0.40273699164390564
Epoch: 129/300 - Train loss: 0.40126797556877136, Validation loss: 0.4004647135734558
Epoch: 130/300 - Train loss: 0.4004403352737427, Validation loss: 0.39999186992645264
Epoch: 131/300 - Train loss: 0.3996221423149109, Validation loss: 0.40029022097587585
Epoch: 132/300 - Train loss: 0.39881348609924316, Validation loss: 0.3985849618911743
Epoch: 133/300 - Train loss: 0.3980141282081604, Validation loss: 0.3984222412109375
Epoch: 134/300 - Train loss: 0.3972241282463074, Validation loss: 0.39712077379226685
Epoch: 135/300 - Train loss: 0.39644306898117065, Validation loss: 0.39600440859794617
Epoch: 136/300 - Train loss: 0.39567095041275024, Validation loss: 0.394864946603775
Epoch: 137/300 - Train loss: 0.3949076235294342, Validation loss: 0.39511245489120483
Epoch: 138/300 - Train loss: 0.39415326714515686, Validation loss: 0.3944239020347595
Epoch: 139/300 - Train loss: 0.393407940864563, Validation loss: 0.3938603401184082
Epoch: 140/300 - Train loss: 0.39267218112945557, Validation loss: 0.392122745513916
Epoch: 141/300 - Train loss: 0.3919451832771301, Validation loss: 0.3925617039203644
Epoch: 142/300 - Train loss: 0.39122703671455383, Validation loss: 0.39199575781822205
Epoch: 143/300 - Train loss: 0.39051738381385803, Validation loss: 0.39141181111335754
Epoch: 144/300 - Train loss: 0.38981640338897705, Validation loss: 0.3900628685951233
Epoch: 145/300 - Train loss: 0.38912439346313477, Validation loss: 0.38978126645088196
Epoch: 146/300 - Train loss: 0.3884405791759491, Validation loss: 0.3885350525379181
Epoch: 147/300 - Train loss: 0.3877650201320648, Validation loss: 0.3888739049434662
Epoch: 148/300 - Train loss: 0.38709756731987, Validation loss: 0.3878863453865051
Epoch: 149/300 - Train loss: 0.38643762469291687, Validation loss: 0.385853111743927
Epoch: 150/300 - Train loss: 0.38578540086746216, Validation loss: 0.38576921820640564
Epoch: 151/300 - Train loss: 0.38514044880867004, Validation loss: 0.38513049483299255
Epoch: 152/300 - Train loss: 0.3845028579235077, Validation loss: 0.38628360629081726
Epoch: 153/300 - Train loss: 0.38387271761894226, Validation loss: 0.38373351097106934
Epoch: 154/300 - Train loss: 0.3832494616508484, Validation loss: 0.3846012353897095
Epoch: 155/300 - Train loss: 0.3826332092285156, Validation loss: 0.3819214701652527
Epoch: 156/300 - Train loss: 0.38202354311943054, Validation loss: 0.3811587989330292
Epoch: 157/300 - Train loss: 0.3814206123352051, Validation loss: 0.380449116230011
Epoch: 158/300 - Train loss: 0.38082388043403625, Validation loss: 0.37963342666625977
Epoch: 159/300 - Train loss: 0.38023343682289124, Validation loss: 0.3810845613479614
Epoch: 160/300 - Train loss: 0.3796496093273163, Validation loss: 0.37888017296791077
Epoch: 161/300 - Train loss: 0.37907230854034424, Validation loss: 0.37853068113327026
Epoch: 162/300 - Train loss: 0.378501296043396, Validation loss: 0.3788173496723175
Epoch: 163/300 - Train loss: 0.3779365122318268, Validation loss: 0.3765715956687927
Epoch: 164/300 - Train loss: 0.37737801671028137, Validation loss: 0.37811434268951416
Epoch: 165/300 - Train loss: 0.3768255114555359, Validation loss: 0.3762182891368866
