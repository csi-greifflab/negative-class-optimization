Epoch: 1/300 - Train loss: 0.6973713040351868, Validation loss: 0.6926177740097046
Epoch: 2/300 - Train loss: 0.6946039199829102, Validation loss: 0.6898991465568542
Epoch: 3/300 - Train loss: 0.6918215751647949, Validation loss: 0.6872523427009583
Epoch: 4/300 - Train loss: 0.6889944076538086, Validation loss: 0.6843321919441223
Epoch: 5/300 - Train loss: 0.6861036419868469, Validation loss: 0.6815398335456848
Epoch: 6/300 - Train loss: 0.6831376552581787, Validation loss: 0.6784728765487671
Epoch: 7/300 - Train loss: 0.6800854206085205, Validation loss: 0.6753659844398499
Epoch: 8/300 - Train loss: 0.6769327521324158, Validation loss: 0.6719967126846313
Epoch: 9/300 - Train loss: 0.6736661791801453, Validation loss: 0.6686115264892578
Epoch: 10/300 - Train loss: 0.6702775359153748, Validation loss: 0.6651996374130249
Epoch: 11/300 - Train loss: 0.6667594313621521, Validation loss: 0.6616275310516357
Epoch: 12/300 - Train loss: 0.6631048917770386, Validation loss: 0.6578799486160278
Epoch: 13/300 - Train loss: 0.6593126654624939, Validation loss: 0.6541656851768494
Epoch: 14/300 - Train loss: 0.6553782820701599, Validation loss: 0.6500698328018188
Epoch: 15/300 - Train loss: 0.6512975692749023, Validation loss: 0.6460080146789551
Epoch: 16/300 - Train loss: 0.6470679640769958, Validation loss: 0.6417146921157837
Epoch: 17/300 - Train loss: 0.6426882147789001, Validation loss: 0.637183427810669
Epoch: 18/300 - Train loss: 0.6381654739379883, Validation loss: 0.6327579617500305
Epoch: 19/300 - Train loss: 0.6335055828094482, Validation loss: 0.6281107664108276
Epoch: 20/300 - Train loss: 0.6287151575088501, Validation loss: 0.6234732866287231
Epoch: 21/300 - Train loss: 0.6237944960594177, Validation loss: 0.6183432340621948
Epoch: 22/300 - Train loss: 0.6187487840652466, Validation loss: 0.6135074496269226
Epoch: 23/300 - Train loss: 0.61358243227005, Validation loss: 0.6084274053573608
Epoch: 24/300 - Train loss: 0.6083076000213623, Validation loss: 0.6031532883644104
Epoch: 25/300 - Train loss: 0.6029348969459534, Validation loss: 0.5980014801025391
Epoch: 26/300 - Train loss: 0.5974734425544739, Validation loss: 0.5925785303115845
Epoch: 27/300 - Train loss: 0.5919283032417297, Validation loss: 0.5870826244354248
Epoch: 28/300 - Train loss: 0.5863082408905029, Validation loss: 0.5816208124160767
Epoch: 29/300 - Train loss: 0.5806218981742859, Validation loss: 0.5761280059814453
Epoch: 30/300 - Train loss: 0.5748803615570068, Validation loss: 0.5704427361488342
Epoch: 31/300 - Train loss: 0.5690910816192627, Validation loss: 0.5649898648262024
Epoch: 32/300 - Train loss: 0.5632645487785339, Validation loss: 0.5591362714767456
Epoch: 33/300 - Train loss: 0.5574133992195129, Validation loss: 0.5534681081771851
Epoch: 34/300 - Train loss: 0.5515465140342712, Validation loss: 0.5480919480323792
Epoch: 35/300 - Train loss: 0.5456759333610535, Validation loss: 0.5422785878181458
Epoch: 36/300 - Train loss: 0.5398052930831909, Validation loss: 0.5369246006011963
Epoch: 37/300 - Train loss: 0.5339453220367432, Validation loss: 0.5308019518852234
Epoch: 38/300 - Train loss: 0.5281022191047668, Validation loss: 0.525215744972229
Epoch: 39/300 - Train loss: 0.5222856998443604, Validation loss: 0.5197681784629822
Epoch: 40/300 - Train loss: 0.5165038108825684, Validation loss: 0.5139020681381226
Epoch: 41/300 - Train loss: 0.51076340675354, Validation loss: 0.5082131028175354
Epoch: 42/300 - Train loss: 0.5050666928291321, Validation loss: 0.5028032064437866
Epoch: 43/300 - Train loss: 0.4994165301322937, Validation loss: 0.4974643886089325
Epoch: 44/300 - Train loss: 0.49381986260414124, Validation loss: 0.49196818470954895
Epoch: 45/300 - Train loss: 0.48828622698783875, Validation loss: 0.48656392097473145
Epoch: 46/300 - Train loss: 0.48281946778297424, Validation loss: 0.48174065351486206
Epoch: 47/300 - Train loss: 0.47742408514022827, Validation loss: 0.47635960578918457
Epoch: 48/300 - Train loss: 0.472103476524353, Validation loss: 0.4710806608200073
Epoch: 49/300 - Train loss: 0.4668624699115753, Validation loss: 0.46597588062286377
Epoch: 50/300 - Train loss: 0.4617064893245697, Validation loss: 0.4614220857620239
Epoch: 51/300 - Train loss: 0.456638365983963, Validation loss: 0.4565478265285492
Epoch: 52/300 - Train loss: 0.45165979862213135, Validation loss: 0.4518989622592926
Epoch: 53/300 - Train loss: 0.4467729926109314, Validation loss: 0.4475303590297699
Epoch: 54/300 - Train loss: 0.4419792592525482, Validation loss: 0.44304385781288147
Epoch: 55/300 - Train loss: 0.43728214502334595, Validation loss: 0.4382641315460205
Epoch: 56/300 - Train loss: 0.432683527469635, Validation loss: 0.43434572219848633
Epoch: 57/300 - Train loss: 0.42818257212638855, Validation loss: 0.4300153851509094
Epoch: 58/300 - Train loss: 0.4237813353538513, Validation loss: 0.42588362097740173
Epoch: 59/300 - Train loss: 0.4194771945476532, Validation loss: 0.42159706354141235
Epoch: 60/300 - Train loss: 0.41526997089385986, Validation loss: 0.4174129068851471
Epoch: 61/300 - Train loss: 0.4111582636833191, Validation loss: 0.4133198857307434
Epoch: 62/300 - Train loss: 0.40714213252067566, Validation loss: 0.4100756049156189
Epoch: 63/300 - Train loss: 0.4032219350337982, Validation loss: 0.40616536140441895
Epoch: 64/300 - Train loss: 0.399396687746048, Validation loss: 0.4022637903690338
Epoch: 65/300 - Train loss: 0.39566266536712646, Validation loss: 0.39901942014694214
Epoch: 66/300 - Train loss: 0.3920184373855591, Validation loss: 0.3956490755081177
Epoch: 67/300 - Train loss: 0.3884618580341339, Validation loss: 0.3926226794719696
Epoch: 68/300 - Train loss: 0.3849923610687256, Validation loss: 0.3893370032310486
Epoch: 69/300 - Train loss: 0.3816066384315491, Validation loss: 0.3862581253051758
Epoch: 70/300 - Train loss: 0.37830159068107605, Validation loss: 0.3826979100704193
Epoch: 71/300 - Train loss: 0.3750762343406677, Validation loss: 0.37992265820503235
Epoch: 72/300 - Train loss: 0.37192922830581665, Validation loss: 0.37627527117729187
Epoch: 73/300 - Train loss: 0.3688565194606781, Validation loss: 0.3737664222717285
Epoch: 74/300 - Train loss: 0.3658565580844879, Validation loss: 0.3706058859825134
Epoch: 75/300 - Train loss: 0.3629269003868103, Validation loss: 0.3682849109172821
Epoch: 76/300 - Train loss: 0.3600654602050781, Validation loss: 0.3657376766204834
Epoch: 77/300 - Train loss: 0.35727018117904663, Validation loss: 0.36292311549186707
Epoch: 78/300 - Train loss: 0.35453981161117554, Validation loss: 0.3599473834037781
Epoch: 79/300 - Train loss: 0.35187163949012756, Validation loss: 0.3577919602394104
Epoch: 80/300 - Train loss: 0.34926488995552063, Validation loss: 0.3550199866294861
Epoch: 81/300 - Train loss: 0.3467179834842682, Validation loss: 0.35279974341392517
Epoch: 82/300 - Train loss: 0.34422895312309265, Validation loss: 0.3498822748661041
Epoch: 83/300 - Train loss: 0.3417957127094269, Validation loss: 0.3479849696159363
Epoch: 84/300 - Train loss: 0.3394167423248291, Validation loss: 0.3459356427192688
Epoch: 85/300 - Train loss: 0.3370898962020874, Validation loss: 0.34418773651123047
Epoch: 86/300 - Train loss: 0.3348132371902466, Validation loss: 0.34129276871681213
Epoch: 87/300 - Train loss: 0.33258652687072754, Validation loss: 0.3395620286464691
Epoch: 88/300 - Train loss: 0.3304077684879303, Validation loss: 0.3374761641025543
Epoch: 89/300 - Train loss: 0.3282749354839325, Validation loss: 0.33517372608184814
Epoch: 90/300 - Train loss: 0.3261873126029968, Validation loss: 0.3331078290939331
Epoch: 91/300 - Train loss: 0.32414358854293823, Validation loss: 0.33094531297683716
Epoch: 92/300 - Train loss: 0.3221423923969269, Validation loss: 0.329516738653183
Epoch: 93/300 - Train loss: 0.3201825022697449, Validation loss: 0.32762789726257324
Epoch: 94/300 - Train loss: 0.31826233863830566, Validation loss: 0.3256821632385254
Epoch: 95/300 - Train loss: 0.31638026237487793, Validation loss: 0.3242570161819458
Epoch: 96/300 - Train loss: 0.314535528421402, Validation loss: 0.32178133726119995
Epoch: 97/300 - Train loss: 0.312727153301239, Validation loss: 0.31983354687690735
Epoch: 98/300 - Train loss: 0.31095436215400696, Validation loss: 0.31822603940963745
Epoch: 99/300 - Train loss: 0.30921611189842224, Validation loss: 0.31658467650413513
Epoch: 100/300 - Train loss: 0.3075111508369446, Validation loss: 0.31531384587287903
Epoch: 101/300 - Train loss: 0.3058386445045471, Validation loss: 0.31339266896247864
Epoch: 102/300 - Train loss: 0.304197758436203, Validation loss: 0.312136173248291
Epoch: 103/300 - Train loss: 0.3025871515274048, Validation loss: 0.30996620655059814
Epoch: 104/300 - Train loss: 0.3010059893131256, Validation loss: 0.30905383825302124
Epoch: 105/300 - Train loss: 0.2994537055492401, Validation loss: 0.3075271546840668
Epoch: 106/300 - Train loss: 0.2979295551776886, Validation loss: 0.30569005012512207
Epoch: 107/300 - Train loss: 0.2964327931404114, Validation loss: 0.3039766252040863
Epoch: 108/300 - Train loss: 0.29496273398399353, Validation loss: 0.30265888571739197
Epoch: 109/300 - Train loss: 0.29351842403411865, Validation loss: 0.3014543950557709
Epoch: 110/300 - Train loss: 0.2920995056629181, Validation loss: 0.30011534690856934
Epoch: 111/300 - Train loss: 0.2907051146030426, Validation loss: 0.2988775074481964
Epoch: 112/300 - Train loss: 0.28933480381965637, Validation loss: 0.29734665155410767
Epoch: 113/300 - Train loss: 0.2879878580570221, Validation loss: 0.29589006304740906
Epoch: 114/300 - Train loss: 0.28666365146636963, Validation loss: 0.294604629278183
Epoch: 115/300 - Train loss: 0.28536173701286316, Validation loss: 0.29339590668678284
Epoch: 116/300 - Train loss: 0.2840815484523773, Validation loss: 0.29220256209373474
Epoch: 117/300 - Train loss: 0.2828225791454315, Validation loss: 0.29142192006111145
Epoch: 118/300 - Train loss: 0.28158414363861084, Validation loss: 0.290007084608078
Epoch: 119/300 - Train loss: 0.28036588430404663, Validation loss: 0.2889091968536377
Epoch: 120/300 - Train loss: 0.2791673541069031, Validation loss: 0.2875489294528961
Epoch: 121/300 - Train loss: 0.2779881954193115, Validation loss: 0.2864445745944977
Epoch: 122/300 - Train loss: 0.27682802081108093, Validation loss: 0.2863173186779022
Epoch: 123/300 - Train loss: 0.27568626403808594, Validation loss: 0.28462448716163635
Epoch: 124/300 - Train loss: 0.27456244826316833, Validation loss: 0.28358110785484314
Epoch: 125/300 - Train loss: 0.2734561562538147, Validation loss: 0.2819801867008209
Epoch: 126/300 - Train loss: 0.27236708998680115, Validation loss: 0.28108665347099304
Epoch: 127/300 - Train loss: 0.27129483222961426, Validation loss: 0.2799456715583801
Epoch: 128/300 - Train loss: 0.27023887634277344, Validation loss: 0.2790798544883728
Epoch: 129/300 - Train loss: 0.2691989839076996, Validation loss: 0.27830106019973755
Epoch: 130/300 - Train loss: 0.2681748569011688, Validation loss: 0.27665233612060547
Epoch: 131/300 - Train loss: 0.26716604828834534, Validation loss: 0.27598729729652405
Epoch: 132/300 - Train loss: 0.2661721110343933, Validation loss: 0.27546799182891846
Epoch: 133/300 - Train loss: 0.2651928663253784, Validation loss: 0.27364179491996765
Epoch: 134/300 - Train loss: 0.264227956533432, Validation loss: 0.2732076644897461
Epoch: 135/300 - Train loss: 0.2632772922515869, Validation loss: 0.27203720808029175
Epoch: 136/300 - Train loss: 0.2623404562473297, Validation loss: 0.2714340090751648
Epoch: 137/300 - Train loss: 0.26141712069511414, Validation loss: 0.27033138275146484
Epoch: 138/300 - Train loss: 0.260507196187973, Validation loss: 0.26932355761528015
Epoch: 139/300 - Train loss: 0.2596103250980377, Validation loss: 0.2685457468032837
Epoch: 140/300 - Train loss: 0.2587263584136963, Validation loss: 0.26754888892173767
Epoch: 141/300 - Train loss: 0.2578549087047577, Validation loss: 0.26714664697647095
Epoch: 142/300 - Train loss: 0.2569958567619324, Validation loss: 0.2657488286495209
Epoch: 143/300 - Train loss: 0.25614896416664124, Validation loss: 0.2651601731777191
Epoch: 144/300 - Train loss: 0.2553138732910156, Validation loss: 0.26434534788131714
Epoch: 145/300 - Train loss: 0.254490464925766, Validation loss: 0.26308494806289673
Epoch: 146/300 - Train loss: 0.25367864966392517, Validation loss: 0.2620195150375366
Epoch: 147/300 - Train loss: 0.2528780996799469, Validation loss: 0.2613605260848999
Epoch: 148/300 - Train loss: 0.2520886957645416, Validation loss: 0.26118195056915283
Epoch: 149/300 - Train loss: 0.25131022930145264, Validation loss: 0.25999051332473755
Epoch: 150/300 - Train loss: 0.250542551279068, Validation loss: 0.25968292355537415
Epoch: 151/300 - Train loss: 0.24978558719158173, Validation loss: 0.2592897117137909
Epoch: 152/300 - Train loss: 0.24903897941112518, Validation loss: 0.2582809329032898
Epoch: 153/300 - Train loss: 0.24830257892608643, Validation loss: 0.2573961615562439
Epoch: 154/300 - Train loss: 0.24757608771324158, Validation loss: 0.256152868270874
Epoch: 155/300 - Train loss: 0.24685946106910706, Validation loss: 0.25595277547836304
Epoch: 156/300 - Train loss: 0.24615252017974854, Validation loss: 0.25563591718673706
Epoch: 157/300 - Train loss: 0.24545511603355408, Validation loss: 0.25446420907974243
Epoch: 158/300 - Train loss: 0.24476701021194458, Validation loss: 0.253821462392807
Epoch: 159/300 - Train loss: 0.2440880835056305, Validation loss: 0.25312939286231995
Epoch: 160/300 - Train loss: 0.2434181571006775, Validation loss: 0.25258323550224304
Epoch: 161/300 - Train loss: 0.24275709688663483, Validation loss: 0.2516515552997589
Epoch: 162/300 - Train loss: 0.24210476875305176, Validation loss: 0.25142043828964233
Epoch: 163/300 - Train loss: 0.24146094918251038, Validation loss: 0.2511497735977173
Epoch: 164/300 - Train loss: 0.24082541465759277, Validation loss: 0.2501591444015503
Epoch: 165/300 - Train loss: 0.24019813537597656, Validation loss: 0.24911852180957794
Epoch: 166/300 - Train loss: 0.23957903683185577, Validation loss: 0.24894171953201294
Epoch: 167/300 - Train loss: 0.23896783590316772, Validation loss: 0.24814237654209137
Epoch: 168/300 - Train loss: 0.23836439847946167, Validation loss: 0.2471150904893875
Epoch: 169/300 - Train loss: 0.23776859045028687, Validation loss: 0.2471461147069931
Epoch: 170/300 - Train loss: 0.23718038201332092, Validation loss: 0.2466549575328827
