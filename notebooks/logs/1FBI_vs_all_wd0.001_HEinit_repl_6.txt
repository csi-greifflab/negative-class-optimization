Epoch: 1/300 - Train loss: 0.7166895866394043, Validation loss: 0.7158470153808594
Epoch: 2/300 - Train loss: 0.7124378681182861, Validation loss: 0.711764931678772
Epoch: 3/300 - Train loss: 0.7083220481872559, Validation loss: 0.7073444128036499
Epoch: 4/300 - Train loss: 0.7043024897575378, Validation loss: 0.7034871578216553
Epoch: 5/300 - Train loss: 0.7003595232963562, Validation loss: 0.6993452906608582
Epoch: 6/300 - Train loss: 0.6964649558067322, Validation loss: 0.6956528425216675
Epoch: 7/300 - Train loss: 0.6925931572914124, Validation loss: 0.6912730932235718
Epoch: 8/300 - Train loss: 0.6887240409851074, Validation loss: 0.6873224377632141
Epoch: 9/300 - Train loss: 0.6848366856575012, Validation loss: 0.6832242608070374
Epoch: 10/300 - Train loss: 0.6809161901473999, Validation loss: 0.679174542427063
Epoch: 11/300 - Train loss: 0.6769450902938843, Validation loss: 0.6748161911964417
Epoch: 12/300 - Train loss: 0.6729069352149963, Validation loss: 0.6708260774612427
Epoch: 13/300 - Train loss: 0.6687875390052795, Validation loss: 0.6668679118156433
Epoch: 14/300 - Train loss: 0.664577066898346, Validation loss: 0.6623325347900391
Epoch: 15/300 - Train loss: 0.6602634787559509, Validation loss: 0.6574791669845581
Epoch: 16/300 - Train loss: 0.6558372378349304, Validation loss: 0.6528811454772949
Epoch: 17/300 - Train loss: 0.6512910723686218, Validation loss: 0.647943377494812
Epoch: 18/300 - Train loss: 0.6466180682182312, Validation loss: 0.6428429484367371
Epoch: 19/300 - Train loss: 0.6418176889419556, Validation loss: 0.6380030512809753
Epoch: 20/300 - Train loss: 0.6368948221206665, Validation loss: 0.6328880786895752
Epoch: 21/300 - Train loss: 0.6318467855453491, Validation loss: 0.6275102496147156
Epoch: 22/300 - Train loss: 0.6266776323318481, Validation loss: 0.6220724582672119
Epoch: 23/300 - Train loss: 0.6213911771774292, Validation loss: 0.616826057434082
Epoch: 24/300 - Train loss: 0.6159980297088623, Validation loss: 0.6110798120498657
Epoch: 25/300 - Train loss: 0.6105020642280579, Validation loss: 0.6051710247993469
Epoch: 26/300 - Train loss: 0.6049131155014038, Validation loss: 0.5993431806564331
Epoch: 27/300 - Train loss: 0.5992382168769836, Validation loss: 0.5937913656234741
Epoch: 28/300 - Train loss: 0.5934866070747375, Validation loss: 0.5879942774772644
Epoch: 29/300 - Train loss: 0.5876678228378296, Validation loss: 0.5816899538040161
Epoch: 30/300 - Train loss: 0.5817868113517761, Validation loss: 0.575701117515564
Epoch: 31/300 - Train loss: 0.5758545398712158, Validation loss: 0.569839358329773
Epoch: 32/300 - Train loss: 0.5698751211166382, Validation loss: 0.56346195936203
Epoch: 33/300 - Train loss: 0.5638566017150879, Validation loss: 0.5573533773422241
Epoch: 34/300 - Train loss: 0.5578073859214783, Validation loss: 0.5512769818305969
Epoch: 35/300 - Train loss: 0.5517371296882629, Validation loss: 0.5448290705680847
Epoch: 36/300 - Train loss: 0.5456516742706299, Validation loss: 0.5386368632316589
Epoch: 37/300 - Train loss: 0.5395551919937134, Validation loss: 0.5325977802276611
Epoch: 38/300 - Train loss: 0.533454418182373, Validation loss: 0.5265923142433167
Epoch: 39/300 - Train loss: 0.5273532271385193, Validation loss: 0.5202924609184265
Epoch: 40/300 - Train loss: 0.5212609171867371, Validation loss: 0.5141830444335938
Epoch: 41/300 - Train loss: 0.5151835680007935, Validation loss: 0.5077944993972778
Epoch: 42/300 - Train loss: 0.5091264843940735, Validation loss: 0.502098023891449
Epoch: 43/300 - Train loss: 0.5030930042266846, Validation loss: 0.49564459919929504
Epoch: 44/300 - Train loss: 0.497088760137558, Validation loss: 0.48975658416748047
Epoch: 45/300 - Train loss: 0.4911194145679474, Validation loss: 0.4834418296813965
Epoch: 46/300 - Train loss: 0.48518988490104675, Validation loss: 0.47755172848701477
Epoch: 47/300 - Train loss: 0.47930535674095154, Validation loss: 0.47171157598495483
Epoch: 48/300 - Train loss: 0.4734717905521393, Validation loss: 0.4660419523715973
Epoch: 49/300 - Train loss: 0.4676932692527771, Validation loss: 0.4601975977420807
Epoch: 50/300 - Train loss: 0.4619710445404053, Validation loss: 0.4542088806629181
Epoch: 51/300 - Train loss: 0.45630592107772827, Validation loss: 0.448591947555542
Epoch: 52/300 - Train loss: 0.4507019519805908, Validation loss: 0.4428040385246277
Epoch: 53/300 - Train loss: 0.44516411423683167, Validation loss: 0.43720072507858276
Epoch: 54/300 - Train loss: 0.4396943151950836, Validation loss: 0.4318367838859558
Epoch: 55/300 - Train loss: 0.43429574370384216, Validation loss: 0.42639675736427307
Epoch: 56/300 - Train loss: 0.42897045612335205, Validation loss: 0.4209964871406555
Epoch: 57/300 - Train loss: 0.4237210750579834, Validation loss: 0.41604506969451904
Epoch: 58/300 - Train loss: 0.41854920983314514, Validation loss: 0.4108179807662964
Epoch: 59/300 - Train loss: 0.41345539689064026, Validation loss: 0.40544891357421875
Epoch: 60/300 - Train loss: 0.40844103693962097, Validation loss: 0.40053316950798035
Epoch: 61/300 - Train loss: 0.4035074710845947, Validation loss: 0.39591336250305176
Epoch: 62/300 - Train loss: 0.39865657687187195, Validation loss: 0.3907354474067688
Epoch: 63/300 - Train loss: 0.3938896954059601, Validation loss: 0.38639265298843384
Epoch: 64/300 - Train loss: 0.38920557498931885, Validation loss: 0.38160839676856995
Epoch: 65/300 - Train loss: 0.384605348110199, Validation loss: 0.37761741876602173
Epoch: 66/300 - Train loss: 0.3800887167453766, Validation loss: 0.37245237827301025
Epoch: 67/300 - Train loss: 0.3756563365459442, Validation loss: 0.36826205253601074
Epoch: 68/300 - Train loss: 0.37130823731422424, Validation loss: 0.36407366394996643
Epoch: 69/300 - Train loss: 0.3670452833175659, Validation loss: 0.35943669080734253
Epoch: 70/300 - Train loss: 0.36286723613739014, Validation loss: 0.3553336560726166
Epoch: 71/300 - Train loss: 0.35877394676208496, Validation loss: 0.3516104817390442
Epoch: 72/300 - Train loss: 0.35476499795913696, Validation loss: 0.34729620814323425
Epoch: 73/300 - Train loss: 0.35084009170532227, Validation loss: 0.3432943522930145
Epoch: 74/300 - Train loss: 0.3469986915588379, Validation loss: 0.33957481384277344
Epoch: 75/300 - Train loss: 0.3432389497756958, Validation loss: 0.3362847864627838
Epoch: 76/300 - Train loss: 0.3395604193210602, Validation loss: 0.3327614665031433
Epoch: 77/300 - Train loss: 0.33596184849739075, Validation loss: 0.3288338780403137
Epoch: 78/300 - Train loss: 0.33244240283966064, Validation loss: 0.3255699574947357
Epoch: 79/300 - Train loss: 0.3290020525455475, Validation loss: 0.3217487037181854
Epoch: 80/300 - Train loss: 0.3256387710571289, Validation loss: 0.3187749683856964
Epoch: 81/300 - Train loss: 0.32235172390937805, Validation loss: 0.3155148923397064
Epoch: 82/300 - Train loss: 0.31913989782333374, Validation loss: 0.3124057948589325
Epoch: 83/300 - Train loss: 0.3160019814968109, Validation loss: 0.3092367947101593
Epoch: 84/300 - Train loss: 0.3129371702671051, Validation loss: 0.3066384196281433
Epoch: 85/300 - Train loss: 0.30994340777397156, Validation loss: 0.30330854654312134
Epoch: 86/300 - Train loss: 0.3070200979709625, Validation loss: 0.3002432584762573
Epoch: 87/300 - Train loss: 0.3041660487651825, Validation loss: 0.29829007387161255
Epoch: 88/300 - Train loss: 0.30137965083122253, Validation loss: 0.2954753041267395
Epoch: 89/300 - Train loss: 0.2986597716808319, Validation loss: 0.29224705696105957
Epoch: 90/300 - Train loss: 0.2960047125816345, Validation loss: 0.2895019054412842
Epoch: 91/300 - Train loss: 0.2934134900569916, Validation loss: 0.28762534260749817
Epoch: 92/300 - Train loss: 0.29088470339775085, Validation loss: 0.28462550044059753
Epoch: 93/300 - Train loss: 0.28841671347618103, Validation loss: 0.2823650538921356
Epoch: 94/300 - Train loss: 0.28600814938545227, Validation loss: 0.2802999019622803
Epoch: 95/300 - Train loss: 0.28365761041641235, Validation loss: 0.27801141142845154
Epoch: 96/300 - Train loss: 0.28136366605758667, Validation loss: 0.2753196358680725
Epoch: 97/300 - Train loss: 0.2791251242160797, Validation loss: 0.27361026406288147
Epoch: 98/300 - Train loss: 0.2769409120082855, Validation loss: 0.2714596688747406
Epoch: 99/300 - Train loss: 0.2748095989227295, Validation loss: 0.26926061511039734
Epoch: 100/300 - Train loss: 0.2727299928665161, Validation loss: 0.26696351170539856
Epoch: 101/300 - Train loss: 0.27070069313049316, Validation loss: 0.26538246870040894
Epoch: 102/300 - Train loss: 0.2687206566333771, Validation loss: 0.2630181312561035
Epoch: 103/300 - Train loss: 0.2667885720729828, Validation loss: 0.260971337556839
Epoch: 104/300 - Train loss: 0.26490330696105957, Validation loss: 0.25960981845855713
Epoch: 105/300 - Train loss: 0.26306354999542236, Validation loss: 0.2581504285335541
Epoch: 106/300 - Train loss: 0.26126837730407715, Validation loss: 0.2563587725162506
Epoch: 107/300 - Train loss: 0.2595165967941284, Validation loss: 0.2546699047088623
Epoch: 108/300 - Train loss: 0.25780701637268066, Validation loss: 0.2522556781768799
Epoch: 109/300 - Train loss: 0.25613832473754883, Validation loss: 0.2516898214817047
Epoch: 110/300 - Train loss: 0.25450965762138367, Validation loss: 0.2495804727077484
Epoch: 111/300 - Train loss: 0.25291967391967773, Validation loss: 0.24811899662017822
Epoch: 112/300 - Train loss: 0.2513674795627594, Validation loss: 0.24675828218460083
Epoch: 113/300 - Train loss: 0.2498522698879242, Validation loss: 0.2448035031557083
Epoch: 114/300 - Train loss: 0.2483731210231781, Validation loss: 0.24345505237579346
Epoch: 115/300 - Train loss: 0.24692903459072113, Validation loss: 0.24235011637210846
Epoch: 116/300 - Train loss: 0.2455189973115921, Validation loss: 0.24073171615600586
Epoch: 117/300 - Train loss: 0.24414220452308655, Validation loss: 0.23973813652992249
Epoch: 118/300 - Train loss: 0.24279768764972687, Validation loss: 0.23789890110492706
Epoch: 119/300 - Train loss: 0.24148458242416382, Validation loss: 0.23700584471225739
Epoch: 120/300 - Train loss: 0.24020209908485413, Validation loss: 0.235494002699852
Epoch: 121/300 - Train loss: 0.23894940316677094, Validation loss: 0.2343149334192276
Epoch: 122/300 - Train loss: 0.23772571980953217, Validation loss: 0.23385611176490784
Epoch: 123/300 - Train loss: 0.23653022944927216, Validation loss: 0.23208579421043396
Epoch: 124/300 - Train loss: 0.23536215722560883, Validation loss: 0.2310590296983719
Epoch: 125/300 - Train loss: 0.2342206984758377, Validation loss: 0.2302468717098236
Epoch: 126/300 - Train loss: 0.23310521245002747, Validation loss: 0.22892071306705475
Epoch: 127/300 - Train loss: 0.2320149689912796, Validation loss: 0.22762484848499298
Epoch: 128/300 - Train loss: 0.23094938695430756, Validation loss: 0.22699537873268127
Epoch: 129/300 - Train loss: 0.22990782558918, Validation loss: 0.22639678418636322
Epoch: 130/300 - Train loss: 0.2288895845413208, Validation loss: 0.22488048672676086
Epoch: 131/300 - Train loss: 0.22789408266544342, Validation loss: 0.22379609942436218
Epoch: 132/300 - Train loss: 0.22692067921161652, Validation loss: 0.22346918284893036
Epoch: 133/300 - Train loss: 0.22596882283687592, Validation loss: 0.22202754020690918
Epoch: 134/300 - Train loss: 0.22503791749477386, Validation loss: 0.22134263813495636
Epoch: 135/300 - Train loss: 0.22412742674350739, Validation loss: 0.22047273814678192
Epoch: 136/300 - Train loss: 0.22323690354824066, Validation loss: 0.21972507238388062
Epoch: 137/300 - Train loss: 0.22236578166484833, Validation loss: 0.21902838349342346
Epoch: 138/300 - Train loss: 0.2215135395526886, Validation loss: 0.21802416443824768
Epoch: 139/300 - Train loss: 0.2206796407699585, Validation loss: 0.2168695032596588
Epoch: 140/300 - Train loss: 0.2198636531829834, Validation loss: 0.21656197309494019
Epoch: 141/300 - Train loss: 0.2190650850534439, Validation loss: 0.21575528383255005
Epoch: 142/300 - Train loss: 0.2182835042476654, Validation loss: 0.214800164103508
Epoch: 143/300 - Train loss: 0.21751855313777924, Validation loss: 0.21446536481380463
Epoch: 144/300 - Train loss: 0.21676965057849884, Validation loss: 0.21357765793800354
Epoch: 145/300 - Train loss: 0.21603649854660034, Validation loss: 0.21294860541820526
Epoch: 146/300 - Train loss: 0.2153187096118927, Validation loss: 0.21241310238838196
Epoch: 147/300 - Train loss: 0.21461573243141174, Validation loss: 0.21144796907901764
Epoch: 148/300 - Train loss: 0.2139272689819336, Validation loss: 0.21105970442295074
Epoch: 149/300 - Train loss: 0.21325305104255676, Validation loss: 0.21041181683540344
Epoch: 150/300 - Train loss: 0.21259263157844543, Validation loss: 0.2098151445388794
Epoch: 151/300 - Train loss: 0.21194566786289215, Validation loss: 0.2088451087474823
Epoch: 152/300 - Train loss: 0.21131187677383423, Validation loss: 0.20868468284606934
Epoch: 153/300 - Train loss: 0.21069090068340302, Validation loss: 0.2078467160463333
Epoch: 154/300 - Train loss: 0.21008242666721344, Validation loss: 0.20827500522136688
Epoch: 155/300 - Train loss: 0.20948612689971924, Validation loss: 0.2066488415002823
Epoch: 156/300 - Train loss: 0.2089017927646637, Validation loss: 0.2055162936449051
Epoch: 157/300 - Train loss: 0.20832912623882294, Validation loss: 0.20583516359329224
Epoch: 158/300 - Train loss: 0.2077677696943283, Validation loss: 0.2048887461423874
Epoch: 159/300 - Train loss: 0.2072174847126007, Validation loss: 0.20428460836410522
Epoch: 160/300 - Train loss: 0.20667794346809387, Validation loss: 0.20404304563999176
