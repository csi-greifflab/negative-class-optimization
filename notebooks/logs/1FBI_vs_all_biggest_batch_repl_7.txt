Epoch: 1/300 - Train loss: 0.695129930973053, Validation loss: 0.6911216974258423
Epoch: 2/300 - Train loss: 0.6922832727432251, Validation loss: 0.6882814764976501
Epoch: 3/300 - Train loss: 0.6894354820251465, Validation loss: 0.6855612993240356
Epoch: 4/300 - Train loss: 0.6865460276603699, Validation loss: 0.6825202107429504
Epoch: 5/300 - Train loss: 0.6835780739784241, Validation loss: 0.6791906952857971
Epoch: 6/300 - Train loss: 0.6804841160774231, Validation loss: 0.6759995818138123
Epoch: 7/300 - Train loss: 0.6772369742393494, Validation loss: 0.6724701523780823
Epoch: 8/300 - Train loss: 0.6738108396530151, Validation loss: 0.668667197227478
Epoch: 9/300 - Train loss: 0.6701880097389221, Validation loss: 0.6648949980735779
Epoch: 10/300 - Train loss: 0.6663601398468018, Validation loss: 0.6607227921485901
Epoch: 11/300 - Train loss: 0.6623181104660034, Validation loss: 0.6563529968261719
Epoch: 12/300 - Train loss: 0.6580765843391418, Validation loss: 0.651757538318634
Epoch: 13/300 - Train loss: 0.6536427140235901, Validation loss: 0.6470697522163391
Epoch: 14/300 - Train loss: 0.6490273475646973, Validation loss: 0.6422057151794434
Epoch: 15/300 - Train loss: 0.6442492008209229, Validation loss: 0.6370472311973572
Epoch: 16/300 - Train loss: 0.6393146514892578, Validation loss: 0.6318769454956055
Epoch: 17/300 - Train loss: 0.634233295917511, Validation loss: 0.6265354752540588
Epoch: 18/300 - Train loss: 0.6290162205696106, Validation loss: 0.6210328936576843
Epoch: 19/300 - Train loss: 0.623674213886261, Validation loss: 0.615265429019928
Epoch: 20/300 - Train loss: 0.6182175278663635, Validation loss: 0.609671413898468
Epoch: 21/300 - Train loss: 0.6126580238342285, Validation loss: 0.6040753126144409
Epoch: 22/300 - Train loss: 0.6070002317428589, Validation loss: 0.598243236541748
Epoch: 23/300 - Train loss: 0.6012542843818665, Validation loss: 0.5923197269439697
Epoch: 24/300 - Train loss: 0.5954315662384033, Validation loss: 0.5864141583442688
Epoch: 25/300 - Train loss: 0.5895405411720276, Validation loss: 0.5802666544914246
Epoch: 26/300 - Train loss: 0.5835905075073242, Validation loss: 0.5743489265441895
Epoch: 27/300 - Train loss: 0.5775856375694275, Validation loss: 0.5680704116821289
Epoch: 28/300 - Train loss: 0.5715309977531433, Validation loss: 0.5620740056037903
Epoch: 29/300 - Train loss: 0.565434455871582, Validation loss: 0.555809497833252
Epoch: 30/300 - Train loss: 0.5593010187149048, Validation loss: 0.549598217010498
Epoch: 31/300 - Train loss: 0.5531362295150757, Validation loss: 0.5434226989746094
Epoch: 32/300 - Train loss: 0.5469444990158081, Validation loss: 0.5370965600013733
Epoch: 33/300 - Train loss: 0.5407314300537109, Validation loss: 0.5308260321617126
Epoch: 34/300 - Train loss: 0.5345017313957214, Validation loss: 0.5246723890304565
Epoch: 35/300 - Train loss: 0.5282610058784485, Validation loss: 0.5182058811187744
Epoch: 36/300 - Train loss: 0.5220147967338562, Validation loss: 0.5120381116867065
Epoch: 37/300 - Train loss: 0.515768826007843, Validation loss: 0.5058338046073914
Epoch: 38/300 - Train loss: 0.5095275640487671, Validation loss: 0.49949711561203003
Epoch: 39/300 - Train loss: 0.5032973885536194, Validation loss: 0.49361658096313477
Epoch: 40/300 - Train loss: 0.49708297848701477, Validation loss: 0.4873094856739044
Epoch: 41/300 - Train loss: 0.490890234708786, Validation loss: 0.48113295435905457
Epoch: 42/300 - Train loss: 0.4847240746021271, Validation loss: 0.4747958481311798
Epoch: 43/300 - Train loss: 0.47858935594558716, Validation loss: 0.4685264825820923
Epoch: 44/300 - Train loss: 0.47249096632003784, Validation loss: 0.4626868963241577
Epoch: 45/300 - Train loss: 0.4664342403411865, Validation loss: 0.45662862062454224
Epoch: 46/300 - Train loss: 0.4604239761829376, Validation loss: 0.45084407925605774
Epoch: 47/300 - Train loss: 0.45446455478668213, Validation loss: 0.444920152425766
Epoch: 48/300 - Train loss: 0.44856059551239014, Validation loss: 0.4387010633945465
Epoch: 49/300 - Train loss: 0.44271519780158997, Validation loss: 0.4330255389213562
Epoch: 50/300 - Train loss: 0.4369328022003174, Validation loss: 0.427560955286026
Epoch: 51/300 - Train loss: 0.4312167167663574, Validation loss: 0.42163780331611633
Epoch: 52/300 - Train loss: 0.42557045817375183, Validation loss: 0.4162578582763672
Epoch: 53/300 - Train loss: 0.4199967682361603, Validation loss: 0.4106888473033905
Epoch: 54/300 - Train loss: 0.4144986867904663, Validation loss: 0.40544605255126953
Epoch: 55/300 - Train loss: 0.4090787172317505, Validation loss: 0.4000121057033539
Epoch: 56/300 - Train loss: 0.40373939275741577, Validation loss: 0.39473238587379456
Epoch: 57/300 - Train loss: 0.39848291873931885, Validation loss: 0.38960498571395874
Epoch: 58/300 - Train loss: 0.39331144094467163, Validation loss: 0.3843437433242798
Epoch: 59/300 - Train loss: 0.38822659850120544, Validation loss: 0.37909749150276184
Epoch: 60/300 - Train loss: 0.38323020935058594, Validation loss: 0.3743794858455658
Epoch: 61/300 - Train loss: 0.37832337617874146, Validation loss: 0.3696956932544708
Epoch: 62/300 - Train loss: 0.37350717186927795, Validation loss: 0.3647926449775696
Epoch: 63/300 - Train loss: 0.36878275871276855, Validation loss: 0.36023369431495667
Epoch: 64/300 - Train loss: 0.36415067315101624, Validation loss: 0.35625603795051575
Epoch: 65/300 - Train loss: 0.3596116900444031, Validation loss: 0.35125160217285156
Epoch: 66/300 - Train loss: 0.35516586899757385, Validation loss: 0.34722211956977844
Epoch: 67/300 - Train loss: 0.3508133292198181, Validation loss: 0.34290897846221924
Epoch: 68/300 - Train loss: 0.34655410051345825, Validation loss: 0.33894285559654236
Epoch: 69/300 - Train loss: 0.3423876464366913, Validation loss: 0.33443203568458557
Epoch: 70/300 - Train loss: 0.3383132815361023, Validation loss: 0.3306167721748352
Epoch: 71/300 - Train loss: 0.3343307077884674, Validation loss: 0.32645055651664734
Epoch: 72/300 - Train loss: 0.33043915033340454, Validation loss: 0.32300907373428345
Epoch: 73/300 - Train loss: 0.3266376554965973, Validation loss: 0.31898874044418335
Epoch: 74/300 - Train loss: 0.3229251503944397, Validation loss: 0.31531670689582825
Epoch: 75/300 - Train loss: 0.3193005621433258, Validation loss: 0.3122289776802063
Epoch: 76/300 - Train loss: 0.31576257944107056, Validation loss: 0.3088715076446533
Epoch: 77/300 - Train loss: 0.3123100697994232, Validation loss: 0.3052053451538086
Epoch: 78/300 - Train loss: 0.3089418411254883, Validation loss: 0.3023555278778076
Epoch: 79/300 - Train loss: 0.30565616488456726, Validation loss: 0.29847049713134766
Epoch: 80/300 - Train loss: 0.3024519383907318, Validation loss: 0.29557672142982483
Epoch: 81/300 - Train loss: 0.2993275225162506, Validation loss: 0.2921993136405945
Epoch: 82/300 - Train loss: 0.29628127813339233, Validation loss: 0.2897161543369293
Epoch: 83/300 - Train loss: 0.29331153631210327, Validation loss: 0.2867099642753601
Epoch: 84/300 - Train loss: 0.2904166877269745, Validation loss: 0.2836838364601135
Epoch: 85/300 - Train loss: 0.28759482502937317, Validation loss: 0.28106561303138733
Epoch: 86/300 - Train loss: 0.28484445810317993, Validation loss: 0.2782973647117615
Epoch: 87/300 - Train loss: 0.28216367959976196, Validation loss: 0.2758103609085083
Epoch: 88/300 - Train loss: 0.27955105900764465, Validation loss: 0.2731812298297882
Epoch: 89/300 - Train loss: 0.2770049273967743, Validation loss: 0.2711644768714905
Epoch: 90/300 - Train loss: 0.27452343702316284, Validation loss: 0.26895952224731445
Epoch: 91/300 - Train loss: 0.2721051275730133, Validation loss: 0.26606497168540955
Epoch: 92/300 - Train loss: 0.2697482705116272, Validation loss: 0.26367872953414917
Epoch: 93/300 - Train loss: 0.26745137572288513, Validation loss: 0.26151958107948303
Epoch: 94/300 - Train loss: 0.26521289348602295, Validation loss: 0.25956934690475464
Epoch: 95/300 - Train loss: 0.26303136348724365, Validation loss: 0.2573899030685425
Epoch: 96/300 - Train loss: 0.2609049677848816, Validation loss: 0.2551153600215912
Epoch: 97/300 - Train loss: 0.2588323950767517, Validation loss: 0.25313231348991394
Epoch: 98/300 - Train loss: 0.256812185049057, Validation loss: 0.2514432966709137
Epoch: 99/300 - Train loss: 0.2548426687717438, Validation loss: 0.24999913573265076
Epoch: 100/300 - Train loss: 0.2529224157333374, Validation loss: 0.24756793677806854
Epoch: 101/300 - Train loss: 0.2510499954223633, Validation loss: 0.2463086098432541
Epoch: 102/300 - Train loss: 0.2492239624261856, Validation loss: 0.2442328929901123
Epoch: 103/300 - Train loss: 0.2474430948495865, Validation loss: 0.24277330935001373
Epoch: 104/300 - Train loss: 0.24570617079734802, Validation loss: 0.2409786581993103
Epoch: 105/300 - Train loss: 0.24401187896728516, Validation loss: 0.23924261331558228
Epoch: 106/300 - Train loss: 0.24235892295837402, Validation loss: 0.23766052722930908
Epoch: 107/300 - Train loss: 0.24074618518352509, Validation loss: 0.23606452345848083
Epoch: 108/300 - Train loss: 0.23917239904403687, Validation loss: 0.2341311126947403
Epoch: 109/300 - Train loss: 0.2376364916563034, Validation loss: 0.2331695854663849
Epoch: 110/300 - Train loss: 0.2361372858285904, Validation loss: 0.231403186917305
Epoch: 111/300 - Train loss: 0.23467373847961426, Validation loss: 0.23022209107875824
Epoch: 112/300 - Train loss: 0.23324500024318695, Validation loss: 0.22897204756736755
Epoch: 113/300 - Train loss: 0.23185008764266968, Validation loss: 0.22795948386192322
Epoch: 114/300 - Train loss: 0.2304879128932953, Validation loss: 0.22651632130146027
Epoch: 115/300 - Train loss: 0.22915753722190857, Validation loss: 0.2249973863363266
Epoch: 116/300 - Train loss: 0.22785766422748566, Validation loss: 0.2235000878572464
Epoch: 117/300 - Train loss: 0.22658777236938477, Validation loss: 0.22271853685379028
Epoch: 118/300 - Train loss: 0.22534704208374023, Validation loss: 0.22147658467292786
Epoch: 119/300 - Train loss: 0.22413471341133118, Validation loss: 0.220555379986763
Epoch: 120/300 - Train loss: 0.22294992208480835, Validation loss: 0.2192908227443695
Epoch: 121/300 - Train loss: 0.22179198265075684, Validation loss: 0.21795199811458588
Epoch: 122/300 - Train loss: 0.22066009044647217, Validation loss: 0.21713516116142273
Epoch: 123/300 - Train loss: 0.21955357491970062, Validation loss: 0.21636003255844116
Epoch: 124/300 - Train loss: 0.2184717059135437, Validation loss: 0.21469905972480774
Epoch: 125/300 - Train loss: 0.21741387248039246, Validation loss: 0.21446342766284943
Epoch: 126/300 - Train loss: 0.21637935936450958, Validation loss: 0.21310071647167206
Epoch: 127/300 - Train loss: 0.21536745131015778, Validation loss: 0.21237243711948395
Epoch: 128/300 - Train loss: 0.21437758207321167, Validation loss: 0.21120195090770721
Epoch: 129/300 - Train loss: 0.21340912580490112, Validation loss: 0.2102469503879547
Epoch: 130/300 - Train loss: 0.21246157586574554, Validation loss: 0.20972764492034912
Epoch: 131/300 - Train loss: 0.2115343064069748, Validation loss: 0.20845505595207214
Epoch: 132/300 - Train loss: 0.21062687039375305, Validation loss: 0.20756526291370392
Epoch: 133/300 - Train loss: 0.20973864197731018, Validation loss: 0.20766671001911163
Epoch: 134/300 - Train loss: 0.20886901021003723, Validation loss: 0.20600607991218567
Epoch: 135/300 - Train loss: 0.20801757276058197, Validation loss: 0.20489388704299927
Epoch: 136/300 - Train loss: 0.20718391239643097, Validation loss: 0.2045530527830124
Epoch: 137/300 - Train loss: 0.2063675969839096, Validation loss: 0.2036280632019043
Epoch: 138/300 - Train loss: 0.2055680751800537, Validation loss: 0.2031112015247345
Epoch: 139/300 - Train loss: 0.20478497445583344, Validation loss: 0.20261898636817932
Epoch: 140/300 - Train loss: 0.20401784777641296, Validation loss: 0.20179180800914764
Epoch: 141/300 - Train loss: 0.20326627790927887, Validation loss: 0.20107191801071167
Epoch: 142/300 - Train loss: 0.2025299370288849, Validation loss: 0.20060685276985168
Epoch: 143/300 - Train loss: 0.2018084079027176, Validation loss: 0.19953127205371857
Epoch: 144/300 - Train loss: 0.2011014074087143, Validation loss: 0.1994856745004654
Epoch: 145/300 - Train loss: 0.20040836930274963, Validation loss: 0.1981900930404663
Epoch: 146/300 - Train loss: 0.19972902536392212, Validation loss: 0.1978648453950882
Epoch: 147/300 - Train loss: 0.19906304776668549, Validation loss: 0.1970978081226349
Epoch: 148/300 - Train loss: 0.19841009378433228, Validation loss: 0.1967940330505371
Epoch: 149/300 - Train loss: 0.19776977598667145, Validation loss: 0.19592827558517456
Epoch: 150/300 - Train loss: 0.1971418410539627, Validation loss: 0.19545100629329681
Epoch: 151/300 - Train loss: 0.19652605056762695, Validation loss: 0.1947883516550064
Epoch: 152/300 - Train loss: 0.19592207670211792, Validation loss: 0.19431981444358826
Epoch: 153/300 - Train loss: 0.19532962143421173, Validation loss: 0.19408069550991058
Epoch: 154/300 - Train loss: 0.1947484016418457, Validation loss: 0.19353130459785461
