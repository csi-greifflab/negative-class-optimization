Epoch: 1/300 - Train loss: 0.7002856731414795, Validation loss: 0.6976097226142883
Epoch: 2/300 - Train loss: 0.6967102289199829, Validation loss: 0.6940550208091736
Epoch: 3/300 - Train loss: 0.6932066679000854, Validation loss: 0.6906373500823975
Epoch: 4/300 - Train loss: 0.6897597908973694, Validation loss: 0.6873457431793213
Epoch: 5/300 - Train loss: 0.6863512992858887, Validation loss: 0.6839680671691895
Epoch: 6/300 - Train loss: 0.6829574704170227, Validation loss: 0.6805458068847656
Epoch: 7/300 - Train loss: 0.6795449256896973, Validation loss: 0.6772295236587524
Epoch: 8/300 - Train loss: 0.6760982871055603, Validation loss: 0.6739365458488464
Epoch: 9/300 - Train loss: 0.6726003885269165, Validation loss: 0.6704214811325073
Epoch: 10/300 - Train loss: 0.6690411567687988, Validation loss: 0.6669455766677856
Epoch: 11/300 - Train loss: 0.665411651134491, Validation loss: 0.6634485125541687
Epoch: 12/300 - Train loss: 0.6617001891136169, Validation loss: 0.6596553921699524
Epoch: 13/300 - Train loss: 0.6578983664512634, Validation loss: 0.6559172868728638
Epoch: 14/300 - Train loss: 0.6540042757987976, Validation loss: 0.6519936919212341
Epoch: 15/300 - Train loss: 0.6500077843666077, Validation loss: 0.6480477452278137
Epoch: 16/300 - Train loss: 0.6459065675735474, Validation loss: 0.6440314650535583
Epoch: 17/300 - Train loss: 0.6416962742805481, Validation loss: 0.6399006247520447
Epoch: 18/300 - Train loss: 0.6373748183250427, Validation loss: 0.6356655359268188
Epoch: 19/300 - Train loss: 0.6329485177993774, Validation loss: 0.6311569213867188
Epoch: 20/300 - Train loss: 0.6284163594245911, Validation loss: 0.6266759634017944
Epoch: 21/300 - Train loss: 0.6237791180610657, Validation loss: 0.622251033782959
Epoch: 22/300 - Train loss: 0.6190385222434998, Validation loss: 0.6175612211227417
Epoch: 23/300 - Train loss: 0.6142018437385559, Validation loss: 0.6128283739089966
Epoch: 24/300 - Train loss: 0.6092786192893982, Validation loss: 0.6079545021057129
Epoch: 25/300 - Train loss: 0.6042770743370056, Validation loss: 0.6029512882232666
Epoch: 26/300 - Train loss: 0.5992013216018677, Validation loss: 0.5980412364006042
Epoch: 27/300 - Train loss: 0.5940579771995544, Validation loss: 0.5931563377380371
Epoch: 28/300 - Train loss: 0.5888491868972778, Validation loss: 0.5880163908004761
Epoch: 29/300 - Train loss: 0.5835804343223572, Validation loss: 0.5829479098320007
Epoch: 30/300 - Train loss: 0.5782580375671387, Validation loss: 0.5778307914733887
Epoch: 31/300 - Train loss: 0.5728935599327087, Validation loss: 0.5724050402641296
Epoch: 32/300 - Train loss: 0.5674914717674255, Validation loss: 0.5671076774597168
Epoch: 33/300 - Train loss: 0.5620591640472412, Validation loss: 0.5620085000991821
Epoch: 34/300 - Train loss: 0.556603729724884, Validation loss: 0.5568422675132751
Epoch: 35/300 - Train loss: 0.5511288642883301, Validation loss: 0.5514930486679077
Epoch: 36/300 - Train loss: 0.5456371307373047, Validation loss: 0.5457932353019714
Epoch: 37/300 - Train loss: 0.5401313304901123, Validation loss: 0.5404959917068481
Epoch: 38/300 - Train loss: 0.534625232219696, Validation loss: 0.5352942943572998
Epoch: 39/300 - Train loss: 0.5291273593902588, Validation loss: 0.5302267670631409
Epoch: 40/300 - Train loss: 0.5236464738845825, Validation loss: 0.5246017575263977
Epoch: 41/300 - Train loss: 0.518191933631897, Validation loss: 0.5193586349487305
Epoch: 42/300 - Train loss: 0.5127741098403931, Validation loss: 0.514150857925415
Epoch: 43/300 - Train loss: 0.5073980689048767, Validation loss: 0.5088827610015869
Epoch: 44/300 - Train loss: 0.5020694732666016, Validation loss: 0.503845751285553
Epoch: 45/300 - Train loss: 0.49679142236709595, Validation loss: 0.4986397624015808
Epoch: 46/300 - Train loss: 0.49156826734542847, Validation loss: 0.4935579299926758
Epoch: 47/300 - Train loss: 0.48640450835227966, Validation loss: 0.4888885021209717
Epoch: 48/300 - Train loss: 0.4813055098056793, Validation loss: 0.4840969145298004
Epoch: 49/300 - Train loss: 0.47628000378608704, Validation loss: 0.4793432056903839
Epoch: 50/300 - Train loss: 0.4713316559791565, Validation loss: 0.4740847647190094
Epoch: 51/300 - Train loss: 0.466464102268219, Validation loss: 0.4698371887207031
Epoch: 52/300 - Train loss: 0.46167927980422974, Validation loss: 0.4650115966796875
Epoch: 53/300 - Train loss: 0.4569779932498932, Validation loss: 0.4610024094581604
Epoch: 54/300 - Train loss: 0.4523610770702362, Validation loss: 0.45625150203704834
Epoch: 55/300 - Train loss: 0.44783177971839905, Validation loss: 0.4517766833305359
Epoch: 56/300 - Train loss: 0.443388432264328, Validation loss: 0.4478100836277008
Epoch: 57/300 - Train loss: 0.43902984261512756, Validation loss: 0.44344568252563477
Epoch: 58/300 - Train loss: 0.43475618958473206, Validation loss: 0.43909189105033875
Epoch: 59/300 - Train loss: 0.43056753277778625, Validation loss: 0.43566781282424927
Epoch: 60/300 - Train loss: 0.4264625906944275, Validation loss: 0.4314073622226715
Epoch: 61/300 - Train loss: 0.4224407970905304, Validation loss: 0.42778512835502625
Epoch: 62/300 - Train loss: 0.4185015857219696, Validation loss: 0.4241361916065216
Epoch: 63/300 - Train loss: 0.4146444797515869, Validation loss: 0.4205830991268158
Epoch: 64/300 - Train loss: 0.4108682870864868, Validation loss: 0.4168531000614166
Epoch: 65/300 - Train loss: 0.40717101097106934, Validation loss: 0.4134669899940491
Epoch: 66/300 - Train loss: 0.4035518169403076, Validation loss: 0.409924179315567
Epoch: 67/300 - Train loss: 0.40000948309898376, Validation loss: 0.40667951107025146
Epoch: 68/300 - Train loss: 0.39654189348220825, Validation loss: 0.40302199125289917
Epoch: 69/300 - Train loss: 0.39314717054367065, Validation loss: 0.39968326687812805
Epoch: 70/300 - Train loss: 0.3898235559463501, Validation loss: 0.39663276076316833
Epoch: 71/300 - Train loss: 0.38657015562057495, Validation loss: 0.393612802028656
Epoch: 72/300 - Train loss: 0.3833855390548706, Validation loss: 0.3905925154685974
Epoch: 73/300 - Train loss: 0.3802677392959595, Validation loss: 0.38764676451683044
Epoch: 74/300 - Train loss: 0.3772161304950714, Validation loss: 0.3848496377468109
Epoch: 75/300 - Train loss: 0.37422969937324524, Validation loss: 0.3814581036567688
Epoch: 76/300 - Train loss: 0.3713069558143616, Validation loss: 0.37872838973999023
Epoch: 77/300 - Train loss: 0.36844611167907715, Validation loss: 0.3759092390537262
Epoch: 78/300 - Train loss: 0.36564624309539795, Validation loss: 0.37352076172828674
Epoch: 79/300 - Train loss: 0.3629052937030792, Validation loss: 0.37027931213378906
Epoch: 80/300 - Train loss: 0.36022135615348816, Validation loss: 0.3678027093410492
Epoch: 81/300 - Train loss: 0.3575936257839203, Validation loss: 0.36580389738082886
Epoch: 82/300 - Train loss: 0.35501977801322937, Validation loss: 0.36328282952308655
Epoch: 83/300 - Train loss: 0.3524984121322632, Validation loss: 0.3610140085220337
Epoch: 84/300 - Train loss: 0.3500285744667053, Validation loss: 0.3581103980541229
Epoch: 85/300 - Train loss: 0.34760865569114685, Validation loss: 0.35596752166748047
Epoch: 86/300 - Train loss: 0.34523749351501465, Validation loss: 0.3540656566619873
Epoch: 87/300 - Train loss: 0.34291383624076843, Validation loss: 0.3514416217803955
Epoch: 88/300 - Train loss: 0.34063616394996643, Validation loss: 0.3491590619087219
Epoch: 89/300 - Train loss: 0.3384033143520355, Validation loss: 0.3472236394882202
Epoch: 90/300 - Train loss: 0.33621400594711304, Validation loss: 0.3451857268810272
Epoch: 91/300 - Train loss: 0.33406689763069153, Validation loss: 0.3431943953037262
Epoch: 92/300 - Train loss: 0.3319605588912964, Validation loss: 0.34064459800720215
Epoch: 93/300 - Train loss: 0.3298936188220978, Validation loss: 0.3388131856918335
Epoch: 94/300 - Train loss: 0.3278656005859375, Validation loss: 0.33666887879371643
Epoch: 95/300 - Train loss: 0.3258751630783081, Validation loss: 0.334807425737381
Epoch: 96/300 - Train loss: 0.32392117381095886, Validation loss: 0.3331541121006012
Epoch: 97/300 - Train loss: 0.3220025897026062, Validation loss: 0.331084281206131
Epoch: 98/300 - Train loss: 0.3201185166835785, Validation loss: 0.32921281456947327
Epoch: 99/300 - Train loss: 0.31826794147491455, Validation loss: 0.3274703621864319
Epoch: 100/300 - Train loss: 0.31645023822784424, Validation loss: 0.3255413770675659
Epoch: 101/300 - Train loss: 0.31466445326805115, Validation loss: 0.324321985244751
Epoch: 102/300 - Train loss: 0.31290939450263977, Validation loss: 0.32307225465774536
Epoch: 103/300 - Train loss: 0.31118419766426086, Validation loss: 0.32048261165618896
Epoch: 104/300 - Train loss: 0.3094882369041443, Validation loss: 0.31832942366600037
Epoch: 105/300 - Train loss: 0.3078204393386841, Validation loss: 0.31689536571502686
Epoch: 106/300 - Train loss: 0.3061802089214325, Validation loss: 0.31539854407310486
Epoch: 107/300 - Train loss: 0.3045665919780731, Validation loss: 0.31484630703926086
Epoch: 108/300 - Train loss: 0.3029787242412567, Validation loss: 0.31272798776626587
Epoch: 109/300 - Train loss: 0.30141574144363403, Validation loss: 0.31139081716537476
Epoch: 110/300 - Train loss: 0.29987701773643494, Validation loss: 0.309342622756958
Epoch: 111/300 - Train loss: 0.29836195707321167, Validation loss: 0.30802997946739197
Epoch: 112/300 - Train loss: 0.2968699038028717, Validation loss: 0.30667582154273987
Epoch: 113/300 - Train loss: 0.2954004108905792, Validation loss: 0.3054083287715912
Epoch: 114/300 - Train loss: 0.2939528822898865, Validation loss: 0.30340951681137085
Epoch: 115/300 - Train loss: 0.2925269305706024, Validation loss: 0.30165189504623413
Epoch: 116/300 - Train loss: 0.2911217212677002, Validation loss: 0.30091559886932373
Epoch: 117/300 - Train loss: 0.289736807346344, Validation loss: 0.29967164993286133
Epoch: 118/300 - Train loss: 0.28837162256240845, Validation loss: 0.29802995920181274
Epoch: 119/300 - Train loss: 0.2870258092880249, Validation loss: 0.2967061996459961
Epoch: 120/300 - Train loss: 0.28569886088371277, Validation loss: 0.29573893547058105
Epoch: 121/300 - Train loss: 0.284390389919281, Validation loss: 0.29427626729011536
Epoch: 122/300 - Train loss: 0.28310006856918335, Validation loss: 0.29293060302734375
Epoch: 123/300 - Train loss: 0.28182727098464966, Validation loss: 0.2916163206100464
Epoch: 124/300 - Train loss: 0.2805715799331665, Validation loss: 0.2905850410461426
Epoch: 125/300 - Train loss: 0.27933287620544434, Validation loss: 0.28936904668807983
Epoch: 126/300 - Train loss: 0.2781106233596802, Validation loss: 0.28794172406196594
Epoch: 127/300 - Train loss: 0.27690479159355164, Validation loss: 0.28712472319602966
Epoch: 128/300 - Train loss: 0.27571484446525574, Validation loss: 0.2856464684009552
Epoch: 129/300 - Train loss: 0.27454042434692383, Validation loss: 0.2851495146751404
Epoch: 130/300 - Train loss: 0.27338123321533203, Validation loss: 0.28324589133262634
Epoch: 131/300 - Train loss: 0.27223703265190125, Validation loss: 0.2822886109352112
Epoch: 132/300 - Train loss: 0.27110761404037476, Validation loss: 0.2814682424068451
Epoch: 133/300 - Train loss: 0.26999279856681824, Validation loss: 0.280366450548172
Epoch: 134/300 - Train loss: 0.2688923478126526, Validation loss: 0.2788200080394745
Epoch: 135/300 - Train loss: 0.2678060233592987, Validation loss: 0.27832701802253723
Epoch: 136/300 - Train loss: 0.2667335569858551, Validation loss: 0.2767929434776306
Epoch: 137/300 - Train loss: 0.26567456126213074, Validation loss: 0.2759142816066742
Epoch: 138/300 - Train loss: 0.2646290361881256, Validation loss: 0.27499425411224365
Epoch: 139/300 - Train loss: 0.2635968029499054, Validation loss: 0.27305254340171814
Epoch: 140/300 - Train loss: 0.26257747411727905, Validation loss: 0.2729684114456177
Epoch: 141/300 - Train loss: 0.2615709602832794, Validation loss: 0.27177783846855164
Epoch: 142/300 - Train loss: 0.26057711243629456, Validation loss: 0.2707293927669525
Epoch: 143/300 - Train loss: 0.2595957815647125, Validation loss: 0.26976510882377625
Epoch: 144/300 - Train loss: 0.25862663984298706, Validation loss: 0.26878854632377625
Epoch: 145/300 - Train loss: 0.2576694190502167, Validation loss: 0.2681446969509125
Epoch: 146/300 - Train loss: 0.256724089384079, Validation loss: 0.2669961750507355
Epoch: 147/300 - Train loss: 0.2557905316352844, Validation loss: 0.2661367654800415
Epoch: 148/300 - Train loss: 0.25486844778060913, Validation loss: 0.26540252566337585
Epoch: 149/300 - Train loss: 0.2539577782154083, Validation loss: 0.2638116776943207
Epoch: 150/300 - Train loss: 0.25305837392807007, Validation loss: 0.2633127272129059
Epoch: 151/300 - Train loss: 0.2521698772907257, Validation loss: 0.26225391030311584
Epoch: 152/300 - Train loss: 0.25129225850105286, Validation loss: 0.26149511337280273
Epoch: 153/300 - Train loss: 0.2504253387451172, Validation loss: 0.25991836190223694
Epoch: 154/300 - Train loss: 0.24956901371479034, Validation loss: 0.2598188519477844
Epoch: 155/300 - Train loss: 0.24872320890426636, Validation loss: 0.25914710760116577
Epoch: 156/300 - Train loss: 0.24788770079612732, Validation loss: 0.25815555453300476
Epoch: 157/300 - Train loss: 0.2470623403787613, Validation loss: 0.25742581486701965
Epoch: 158/300 - Train loss: 0.24624711275100708, Validation loss: 0.25669774413108826
Epoch: 159/300 - Train loss: 0.24544192850589752, Validation loss: 0.25549283623695374
Epoch: 160/300 - Train loss: 0.24464663863182068, Validation loss: 0.25484228134155273
Epoch: 161/300 - Train loss: 0.24386106431484222, Validation loss: 0.25380760431289673
Epoch: 162/300 - Train loss: 0.243085116147995, Validation loss: 0.25279560685157776
Epoch: 163/300 - Train loss: 0.24231864511966705, Validation loss: 0.2531091570854187
Epoch: 164/300 - Train loss: 0.2415616512298584, Validation loss: 0.2513822317123413
Epoch: 165/300 - Train loss: 0.2408139407634735, Validation loss: 0.251102477312088
Epoch: 166/300 - Train loss: 0.24007537961006165, Validation loss: 0.2503988444805145
Epoch: 167/300 - Train loss: 0.2393459528684616, Validation loss: 0.24913053214550018
Epoch: 168/300 - Train loss: 0.2386254072189331, Validation loss: 0.24842171370983124
Epoch: 169/300 - Train loss: 0.23791377246379852, Validation loss: 0.24826444685459137
Epoch: 170/300 - Train loss: 0.23721082508563995, Validation loss: 0.2474619299173355
Epoch: 171/300 - Train loss: 0.23651638627052307, Validation loss: 0.24650134146213531
Epoch: 172/300 - Train loss: 0.2358303815126419, Validation loss: 0.24612484872341156
Epoch: 173/300 - Train loss: 0.23515282571315765, Validation loss: 0.24544043838977814
Epoch: 174/300 - Train loss: 0.23448333144187927, Validation loss: 0.24424239993095398
Epoch: 175/300 - Train loss: 0.23382192850112915, Validation loss: 0.24378499388694763
Epoch: 176/300 - Train loss: 0.23316846787929535, Validation loss: 0.24317368865013123
Epoch: 177/300 - Train loss: 0.2325228452682495, Validation loss: 0.2431173473596573
Epoch: 178/300 - Train loss: 0.23188507556915283, Validation loss: 0.241567000746727
Epoch: 179/300 - Train loss: 0.23125524818897247, Validation loss: 0.24132490158081055
Epoch: 180/300 - Train loss: 0.23063315451145172, Validation loss: 0.2407532036304474
Epoch: 181/300 - Train loss: 0.23001857101917267, Validation loss: 0.24021634459495544
Epoch: 182/300 - Train loss: 0.2294112592935562, Validation loss: 0.23937386274337769
Epoch: 183/300 - Train loss: 0.22881129384040833, Validation loss: 0.23856748640537262
Epoch: 184/300 - Train loss: 0.22821860015392303, Validation loss: 0.2383781373500824
Epoch: 185/300 - Train loss: 0.22763311862945557, Validation loss: 0.23724310100078583
Epoch: 186/300 - Train loss: 0.22705473005771637, Validation loss: 0.23690229654312134
Epoch: 187/300 - Train loss: 0.2264833301305771, Validation loss: 0.2368251085281372
