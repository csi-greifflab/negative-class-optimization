Epoch: 1/300 - Train loss: 0.689678966999054, Validation loss: 0.6872240900993347
Epoch: 2/300 - Train loss: 0.686917245388031, Validation loss: 0.68465656042099
Epoch: 3/300 - Train loss: 0.6841464042663574, Validation loss: 0.681823194026947
Epoch: 4/300 - Train loss: 0.6813520789146423, Validation loss: 0.6791884303092957
Epoch: 5/300 - Train loss: 0.6785182952880859, Validation loss: 0.6763280630111694
Epoch: 6/300 - Train loss: 0.6756294965744019, Validation loss: 0.6733980178833008
Epoch: 7/300 - Train loss: 0.672674298286438, Validation loss: 0.6705838441848755
Epoch: 8/300 - Train loss: 0.6696375608444214, Validation loss: 0.6673491597175598
Epoch: 9/300 - Train loss: 0.6665042638778687, Validation loss: 0.6642763614654541
Epoch: 10/300 - Train loss: 0.6632621884346008, Validation loss: 0.6609339714050293
Epoch: 11/300 - Train loss: 0.6599017381668091, Validation loss: 0.6575504541397095
Epoch: 12/300 - Train loss: 0.6564213037490845, Validation loss: 0.6539526581764221
Epoch: 13/300 - Train loss: 0.6528068780899048, Validation loss: 0.6502574682235718
Epoch: 14/300 - Train loss: 0.6490554213523865, Validation loss: 0.6464856863021851
Epoch: 15/300 - Train loss: 0.6451699137687683, Validation loss: 0.6423977017402649
Epoch: 16/300 - Train loss: 0.6411475539207458, Validation loss: 0.6383273601531982
Epoch: 17/300 - Train loss: 0.6369916796684265, Validation loss: 0.6341261267662048
Epoch: 18/300 - Train loss: 0.6327088475227356, Validation loss: 0.6296624541282654
Epoch: 19/300 - Train loss: 0.6283024549484253, Validation loss: 0.6251671314239502
Epoch: 20/300 - Train loss: 0.6237819790840149, Validation loss: 0.6206308603286743
Epoch: 21/300 - Train loss: 0.6191557049751282, Validation loss: 0.615820586681366
Epoch: 22/300 - Train loss: 0.6144345998764038, Validation loss: 0.6111574172973633
Epoch: 23/300 - Train loss: 0.6096264719963074, Validation loss: 0.6062759160995483
Epoch: 24/300 - Train loss: 0.6047376394271851, Validation loss: 0.6014648675918579
Epoch: 25/300 - Train loss: 0.5997816324234009, Validation loss: 0.5963172316551208
Epoch: 26/300 - Train loss: 0.5947668552398682, Validation loss: 0.59134840965271
Epoch: 27/300 - Train loss: 0.5897060632705688, Validation loss: 0.5862426161766052
Epoch: 28/300 - Train loss: 0.5846100449562073, Validation loss: 0.5809635519981384
Epoch: 29/300 - Train loss: 0.57948899269104, Validation loss: 0.5761183500289917
Epoch: 30/300 - Train loss: 0.5743493437767029, Validation loss: 0.570848822593689
Epoch: 31/300 - Train loss: 0.5692001581192017, Validation loss: 0.5657052397727966
Epoch: 32/300 - Train loss: 0.5640527606010437, Validation loss: 0.5605607628822327
Epoch: 33/300 - Train loss: 0.558915376663208, Validation loss: 0.5555248260498047
Epoch: 34/300 - Train loss: 0.5537952184677124, Validation loss: 0.5502864718437195
Epoch: 35/300 - Train loss: 0.5486941933631897, Validation loss: 0.5453839898109436
Epoch: 36/300 - Train loss: 0.5436211824417114, Validation loss: 0.5402162671089172
Epoch: 37/300 - Train loss: 0.5385851263999939, Validation loss: 0.5352259874343872
Epoch: 38/300 - Train loss: 0.5335918068885803, Validation loss: 0.5302419662475586
Epoch: 39/300 - Train loss: 0.5286442637443542, Validation loss: 0.5252581238746643
Epoch: 40/300 - Train loss: 0.5237472653388977, Validation loss: 0.5207571983337402
Epoch: 41/300 - Train loss: 0.5189058780670166, Validation loss: 0.5155312418937683
Epoch: 42/300 - Train loss: 0.51412433385849, Validation loss: 0.5111547708511353
Epoch: 43/300 - Train loss: 0.5094035863876343, Validation loss: 0.5061944723129272
Epoch: 44/300 - Train loss: 0.5047479867935181, Validation loss: 0.5017797350883484
Epoch: 45/300 - Train loss: 0.500159740447998, Validation loss: 0.49726009368896484
Epoch: 46/300 - Train loss: 0.4956406056880951, Validation loss: 0.4930788576602936
Epoch: 47/300 - Train loss: 0.4911942780017853, Validation loss: 0.4883604049682617
Epoch: 48/300 - Train loss: 0.4868229925632477, Validation loss: 0.48444193601608276
Epoch: 49/300 - Train loss: 0.48252812027931213, Validation loss: 0.47965025901794434
Epoch: 50/300 - Train loss: 0.47831061482429504, Validation loss: 0.47572001814842224
Epoch: 51/300 - Train loss: 0.4741731286048889, Validation loss: 0.4715859889984131
Epoch: 52/300 - Train loss: 0.4701169431209564, Validation loss: 0.4676889479160309
Epoch: 53/300 - Train loss: 0.4661409854888916, Validation loss: 0.46350693702697754
Epoch: 54/300 - Train loss: 0.4622455835342407, Validation loss: 0.459617555141449
Epoch: 55/300 - Train loss: 0.4584314525127411, Validation loss: 0.4561029374599457
Epoch: 56/300 - Train loss: 0.4546996057033539, Validation loss: 0.4524398744106293
Epoch: 57/300 - Train loss: 0.45104992389678955, Validation loss: 0.4485436975955963
Epoch: 58/300 - Train loss: 0.447481244802475, Validation loss: 0.4454895257949829
Epoch: 59/300 - Train loss: 0.4439932405948639, Validation loss: 0.4421098828315735
Epoch: 60/300 - Train loss: 0.44058430194854736, Validation loss: 0.4387072026729584
Epoch: 61/300 - Train loss: 0.4372543394565582, Validation loss: 0.43511447310447693
Epoch: 62/300 - Train loss: 0.43400338292121887, Validation loss: 0.43169480562210083
Epoch: 63/300 - Train loss: 0.43082964420318604, Validation loss: 0.42897361516952515
Epoch: 64/300 - Train loss: 0.4277327358722687, Validation loss: 0.4261154234409332
Epoch: 65/300 - Train loss: 0.42471200227737427, Validation loss: 0.42316707968711853
Epoch: 66/300 - Train loss: 0.4217658042907715, Validation loss: 0.42015063762664795
Epoch: 67/300 - Train loss: 0.418893039226532, Validation loss: 0.4176759719848633
Epoch: 68/300 - Train loss: 0.4160919189453125, Validation loss: 0.41436225175857544
Epoch: 69/300 - Train loss: 0.41336122155189514, Validation loss: 0.4117223024368286
Epoch: 70/300 - Train loss: 0.4106995761394501, Validation loss: 0.40931567549705505
Epoch: 71/300 - Train loss: 0.4081052541732788, Validation loss: 0.4067310094833374
Epoch: 72/300 - Train loss: 0.40557706356048584, Validation loss: 0.4041084349155426
Epoch: 73/300 - Train loss: 0.4031132161617279, Validation loss: 0.40181925892829895
Epoch: 74/300 - Train loss: 0.40071219205856323, Validation loss: 0.3995608687400818
Epoch: 75/300 - Train loss: 0.398373007774353, Validation loss: 0.3972501754760742
Epoch: 76/300 - Train loss: 0.39609384536743164, Validation loss: 0.39482396841049194
Epoch: 77/300 - Train loss: 0.3938726484775543, Validation loss: 0.3921467959880829
Epoch: 78/300 - Train loss: 0.3917079269886017, Validation loss: 0.3900988698005676
Epoch: 79/300 - Train loss: 0.38959798216819763, Validation loss: 0.38805365562438965
Epoch: 80/300 - Train loss: 0.3875409662723541, Validation loss: 0.38578999042510986
Epoch: 81/300 - Train loss: 0.38553568720817566, Validation loss: 0.38456210494041443
Epoch: 82/300 - Train loss: 0.38358092308044434, Validation loss: 0.38262954354286194
Epoch: 83/300 - Train loss: 0.38167524337768555, Validation loss: 0.3803249001502991
Epoch: 84/300 - Train loss: 0.37981662154197693, Validation loss: 0.3782684803009033
Epoch: 85/300 - Train loss: 0.37800332903862, Validation loss: 0.37701335549354553
Epoch: 86/300 - Train loss: 0.3762345612049103, Validation loss: 0.37429648637771606
Epoch: 87/300 - Train loss: 0.37450969219207764, Validation loss: 0.37338241934776306
Epoch: 88/300 - Train loss: 0.37282729148864746, Validation loss: 0.37118467688560486
Epoch: 89/300 - Train loss: 0.3711856007575989, Validation loss: 0.3701333999633789
Epoch: 90/300 - Train loss: 0.3695840537548065, Validation loss: 0.36789366602897644
Epoch: 91/300 - Train loss: 0.36802124977111816, Validation loss: 0.36688604950904846
Epoch: 92/300 - Train loss: 0.36649656295776367, Validation loss: 0.364745169878006
Epoch: 93/300 - Train loss: 0.36500832438468933, Validation loss: 0.3635568618774414
Epoch: 94/300 - Train loss: 0.3635546863079071, Validation loss: 0.36196190118789673
Epoch: 95/300 - Train loss: 0.3621348440647125, Validation loss: 0.36087214946746826
Epoch: 96/300 - Train loss: 0.360747367143631, Validation loss: 0.359447181224823
Epoch: 97/300 - Train loss: 0.35939154028892517, Validation loss: 0.35743042826652527
Epoch: 98/300 - Train loss: 0.3580664098262787, Validation loss: 0.3562483489513397
Epoch: 99/300 - Train loss: 0.35677093267440796, Validation loss: 0.3550356924533844
Epoch: 100/300 - Train loss: 0.35550448298454285, Validation loss: 0.35343924164772034
Epoch: 101/300 - Train loss: 0.35426652431488037, Validation loss: 0.35245540738105774
Epoch: 102/300 - Train loss: 0.353055477142334, Validation loss: 0.3512921631336212
Epoch: 103/300 - Train loss: 0.35187065601348877, Validation loss: 0.3495568633079529
Epoch: 104/300 - Train loss: 0.35071122646331787, Validation loss: 0.34903213381767273
Epoch: 105/300 - Train loss: 0.3495759665966034, Validation loss: 0.3479222059249878
Epoch: 106/300 - Train loss: 0.3484642505645752, Validation loss: 0.3465067446231842
Epoch: 107/300 - Train loss: 0.3473759591579437, Validation loss: 0.3453977704048157
Epoch: 108/300 - Train loss: 0.3463103771209717, Validation loss: 0.3442929983139038
Epoch: 109/300 - Train loss: 0.34526702761650085, Validation loss: 0.3439667820930481
Epoch: 110/300 - Train loss: 0.344245046377182, Validation loss: 0.3420310318470001
Epoch: 111/300 - Train loss: 0.3432430326938629, Validation loss: 0.34110918641090393
Epoch: 112/300 - Train loss: 0.3422604501247406, Validation loss: 0.3400862514972687
Epoch: 113/300 - Train loss: 0.3412970304489136, Validation loss: 0.3392675220966339
Epoch: 114/300 - Train loss: 0.34035202860832214, Validation loss: 0.3382016122341156
Epoch: 115/300 - Train loss: 0.3394259214401245, Validation loss: 0.3373005986213684
Epoch: 116/300 - Train loss: 0.338516503572464, Validation loss: 0.33645328879356384
Epoch: 117/300 - Train loss: 0.3376239538192749, Validation loss: 0.3353080153465271
Epoch: 118/300 - Train loss: 0.33674877882003784, Validation loss: 0.33478838205337524
Epoch: 119/300 - Train loss: 0.33588966727256775, Validation loss: 0.33438584208488464
Epoch: 120/300 - Train loss: 0.3350463807582855, Validation loss: 0.3331106901168823
Epoch: 121/300 - Train loss: 0.33421874046325684, Validation loss: 0.3321521282196045
Epoch: 122/300 - Train loss: 0.333406537771225, Validation loss: 0.3312177062034607
Epoch: 123/300 - Train loss: 0.3326092064380646, Validation loss: 0.33043161034584045
Epoch: 124/300 - Train loss: 0.3318268060684204, Validation loss: 0.33020707964897156
Epoch: 125/300 - Train loss: 0.33105894923210144, Validation loss: 0.3285486102104187
Epoch: 126/300 - Train loss: 0.3303050994873047, Validation loss: 0.32890182733535767
Epoch: 127/300 - Train loss: 0.32956385612487793, Validation loss: 0.32718104124069214
Epoch: 128/300 - Train loss: 0.32883530855178833, Validation loss: 0.3271334171295166
Epoch: 129/300 - Train loss: 0.32811906933784485, Validation loss: 0.3259929418563843
Epoch: 130/300 - Train loss: 0.32741519808769226, Validation loss: 0.3250064253807068
Epoch: 131/300 - Train loss: 0.32672327756881714, Validation loss: 0.32459378242492676
Epoch: 132/300 - Train loss: 0.3260432183742523, Validation loss: 0.32374870777130127
Epoch: 133/300 - Train loss: 0.325374573469162, Validation loss: 0.32301825284957886
Epoch: 134/300 - Train loss: 0.3247164189815521, Validation loss: 0.3226441740989685
Epoch: 135/300 - Train loss: 0.32406917214393616, Validation loss: 0.3215046525001526
Epoch: 136/300 - Train loss: 0.32343295216560364, Validation loss: 0.32112470269203186
Epoch: 137/300 - Train loss: 0.3228071331977844, Validation loss: 0.3205592632293701
Epoch: 138/300 - Train loss: 0.32219037413597107, Validation loss: 0.31993719935417175
Epoch: 139/300 - Train loss: 0.32158294320106506, Validation loss: 0.3193972706794739
Epoch: 140/300 - Train loss: 0.32098522782325745, Validation loss: 0.31887510418891907
Epoch: 141/300 - Train loss: 0.32039716839790344, Validation loss: 0.31792643666267395
Epoch: 142/300 - Train loss: 0.3198181092739105, Validation loss: 0.3175881505012512
Epoch: 143/300 - Train loss: 0.3192477524280548, Validation loss: 0.31747886538505554
Epoch: 144/300 - Train loss: 0.31868621706962585, Validation loss: 0.31662049889564514
