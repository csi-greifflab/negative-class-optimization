Epoch: 1/300 - Train loss: 0.6929941177368164, Validation loss: 0.6925022006034851
Epoch: 2/300 - Train loss: 0.6916531920433044, Validation loss: 0.6911970973014832
Epoch: 3/300 - Train loss: 0.6902830600738525, Validation loss: 0.68979811668396
Epoch: 4/300 - Train loss: 0.6888551712036133, Validation loss: 0.6883268356323242
Epoch: 5/300 - Train loss: 0.6873353719711304, Validation loss: 0.6867015957832336
Epoch: 6/300 - Train loss: 0.6857029795646667, Validation loss: 0.6849024295806885
Epoch: 7/300 - Train loss: 0.683932900428772, Validation loss: 0.683027446269989
Epoch: 8/300 - Train loss: 0.6820089817047119, Validation loss: 0.6810421943664551
Epoch: 9/300 - Train loss: 0.6799205541610718, Validation loss: 0.6787852644920349
Epoch: 10/300 - Train loss: 0.6776629090309143, Validation loss: 0.6764513254165649
Epoch: 11/300 - Train loss: 0.6752361059188843, Validation loss: 0.6739450097084045
Epoch: 12/300 - Train loss: 0.6726333498954773, Validation loss: 0.671137273311615
Epoch: 13/300 - Train loss: 0.6698596477508545, Validation loss: 0.6681870222091675
Epoch: 14/300 - Train loss: 0.6669226884841919, Validation loss: 0.6651558876037598
Epoch: 15/300 - Train loss: 0.663831353187561, Validation loss: 0.6620352268218994
Epoch: 16/300 - Train loss: 0.6605856418609619, Validation loss: 0.6586712002754211
Epoch: 17/300 - Train loss: 0.657194197177887, Validation loss: 0.6552636623382568
Epoch: 18/300 - Train loss: 0.6536656618118286, Validation loss: 0.6515745520591736
Epoch: 19/300 - Train loss: 0.6500031352043152, Validation loss: 0.6477706432342529
Epoch: 20/300 - Train loss: 0.6462245583534241, Validation loss: 0.643828272819519
Epoch: 21/300 - Train loss: 0.6423359513282776, Validation loss: 0.6399625539779663
Epoch: 22/300 - Train loss: 0.6383471488952637, Validation loss: 0.635913610458374
Epoch: 23/300 - Train loss: 0.634269118309021, Validation loss: 0.6318551301956177
Epoch: 24/300 - Train loss: 0.6301136016845703, Validation loss: 0.6277169585227966
Epoch: 25/300 - Train loss: 0.6258893609046936, Validation loss: 0.6233549118041992
Epoch: 26/300 - Train loss: 0.621604323387146, Validation loss: 0.6191756129264832
Epoch: 27/300 - Train loss: 0.6172600984573364, Validation loss: 0.6147697567939758
Epoch: 28/300 - Train loss: 0.612860381603241, Validation loss: 0.6103906035423279
Epoch: 29/300 - Train loss: 0.6084077954292297, Validation loss: 0.6058513522148132
Epoch: 30/300 - Train loss: 0.603906512260437, Validation loss: 0.6013777852058411
Epoch: 31/300 - Train loss: 0.5993590950965881, Validation loss: 0.5968577265739441
Epoch: 32/300 - Train loss: 0.5947676301002502, Validation loss: 0.5921746492385864
Epoch: 33/300 - Train loss: 0.5901370048522949, Validation loss: 0.5877345204353333
Epoch: 34/300 - Train loss: 0.5854740738868713, Validation loss: 0.5829460024833679
Epoch: 35/300 - Train loss: 0.5807844400405884, Validation loss: 0.5783553719520569
Epoch: 36/300 - Train loss: 0.5760730504989624, Validation loss: 0.5737143158912659
Epoch: 37/300 - Train loss: 0.5713450312614441, Validation loss: 0.5692732930183411
Epoch: 38/300 - Train loss: 0.5666046738624573, Validation loss: 0.5643953084945679
Epoch: 39/300 - Train loss: 0.5618573427200317, Validation loss: 0.5595304369926453
Epoch: 40/300 - Train loss: 0.55710768699646, Validation loss: 0.5548143982887268
Epoch: 41/300 - Train loss: 0.5523602366447449, Validation loss: 0.5503461360931396
Epoch: 42/300 - Train loss: 0.5476193428039551, Validation loss: 0.5456891655921936
Epoch: 43/300 - Train loss: 0.5428898930549622, Validation loss: 0.5410972237586975
Epoch: 44/300 - Train loss: 0.538176417350769, Validation loss: 0.5364108085632324
Epoch: 45/300 - Train loss: 0.5334835052490234, Validation loss: 0.5316133499145508
Epoch: 46/300 - Train loss: 0.5288146734237671, Validation loss: 0.5267986059188843
Epoch: 47/300 - Train loss: 0.5241737961769104, Validation loss: 0.5225312113761902
Epoch: 48/300 - Train loss: 0.5195633769035339, Validation loss: 0.5183688998222351
Epoch: 49/300 - Train loss: 0.5149859189987183, Validation loss: 0.51338130235672
Epoch: 50/300 - Train loss: 0.5104441046714783, Validation loss: 0.5088810920715332
Epoch: 51/300 - Train loss: 0.5059398412704468, Validation loss: 0.5045393705368042
Epoch: 52/300 - Train loss: 0.5014758706092834, Validation loss: 0.500066339969635
Epoch: 53/300 - Train loss: 0.49705514311790466, Validation loss: 0.4959539771080017
Epoch: 54/300 - Train loss: 0.49268051981925964, Validation loss: 0.4912937581539154
Epoch: 55/300 - Train loss: 0.48835423588752747, Validation loss: 0.4870970845222473
Epoch: 56/300 - Train loss: 0.4840792119503021, Validation loss: 0.48317983746528625
Epoch: 57/300 - Train loss: 0.4798584580421448, Validation loss: 0.478929340839386
Epoch: 58/300 - Train loss: 0.4756946861743927, Validation loss: 0.4747975766658783
Epoch: 59/300 - Train loss: 0.4715906083583832, Validation loss: 0.4708283543586731
Epoch: 60/300 - Train loss: 0.4675494134426117, Validation loss: 0.4666052460670471
Epoch: 61/300 - Train loss: 0.46357375383377075, Validation loss: 0.46315011382102966
Epoch: 62/300 - Train loss: 0.4596661925315857, Validation loss: 0.45898571610450745
Epoch: 63/300 - Train loss: 0.45582833886146545, Validation loss: 0.4553733170032501
Epoch: 64/300 - Train loss: 0.4520614445209503, Validation loss: 0.4521421790122986
Epoch: 65/300 - Train loss: 0.44836732745170593, Validation loss: 0.44783419370651245
Epoch: 66/300 - Train loss: 0.4447477161884308, Validation loss: 0.44456249475479126
Epoch: 67/300 - Train loss: 0.44120344519615173, Validation loss: 0.4410213530063629
Epoch: 68/300 - Train loss: 0.4377354681491852, Validation loss: 0.43787288665771484
Epoch: 69/300 - Train loss: 0.43434375524520874, Validation loss: 0.4346575438976288
Epoch: 70/300 - Train loss: 0.431028813123703, Validation loss: 0.43109869956970215
Epoch: 71/300 - Train loss: 0.42779070138931274, Validation loss: 0.42826858162879944
Epoch: 72/300 - Train loss: 0.4246295690536499, Validation loss: 0.4247964024543762
Epoch: 73/300 - Train loss: 0.42154473066329956, Validation loss: 0.42175397276878357
Epoch: 74/300 - Train loss: 0.4185357093811035, Validation loss: 0.4186961352825165
Epoch: 75/300 - Train loss: 0.4156014919281006, Validation loss: 0.41595181822776794
Epoch: 76/300 - Train loss: 0.4127408266067505, Validation loss: 0.4132404625415802
Epoch: 77/300 - Train loss: 0.409952312707901, Validation loss: 0.4109991192817688
Epoch: 78/300 - Train loss: 0.40723490715026855, Validation loss: 0.4081796407699585
Epoch: 79/300 - Train loss: 0.4045867621898651, Validation loss: 0.40554121136665344
Epoch: 80/300 - Train loss: 0.4020061790943146, Validation loss: 0.40341028571128845
Epoch: 81/300 - Train loss: 0.3994915187358856, Validation loss: 0.40018969774246216
Epoch: 82/300 - Train loss: 0.3970410227775574, Validation loss: 0.3979349136352539
Epoch: 83/300 - Train loss: 0.3946533203125, Validation loss: 0.3964352011680603
Epoch: 84/300 - Train loss: 0.39232632517814636, Validation loss: 0.39361628890037537
Epoch: 85/300 - Train loss: 0.3900584280490875, Validation loss: 0.39099904894828796
Epoch: 86/300 - Train loss: 0.3878478705883026, Validation loss: 0.38905155658721924
Epoch: 87/300 - Train loss: 0.3856927454471588, Validation loss: 0.3873779773712158
Epoch: 88/300 - Train loss: 0.38359108567237854, Validation loss: 0.38474777340888977
Epoch: 89/300 - Train loss: 0.38154125213623047, Validation loss: 0.3833999037742615
Epoch: 90/300 - Train loss: 0.37954118847846985, Validation loss: 0.38110730051994324
Epoch: 91/300 - Train loss: 0.37758955359458923, Validation loss: 0.37996432185173035
Epoch: 92/300 - Train loss: 0.3756844699382782, Validation loss: 0.377736896276474
Epoch: 93/300 - Train loss: 0.37382426857948303, Validation loss: 0.3759300112724304
Epoch: 94/300 - Train loss: 0.3720075190067291, Validation loss: 0.3745143413543701
Epoch: 95/300 - Train loss: 0.37023231387138367, Validation loss: 0.3724106550216675
Epoch: 96/300 - Train loss: 0.368497371673584, Validation loss: 0.3701714277267456
Epoch: 97/300 - Train loss: 0.3668012022972107, Validation loss: 0.3695279657840729
Epoch: 98/300 - Train loss: 0.36514219641685486, Validation loss: 0.3675321340560913
Epoch: 99/300 - Train loss: 0.3635191321372986, Validation loss: 0.36571893095970154
Epoch: 100/300 - Train loss: 0.36193060874938965, Validation loss: 0.3642461895942688
Epoch: 101/300 - Train loss: 0.36037537455558777, Validation loss: 0.3632676601409912
Epoch: 102/300 - Train loss: 0.35885220766067505, Validation loss: 0.3619549572467804
Epoch: 103/300 - Train loss: 0.35736027359962463, Validation loss: 0.35993990302085876
Epoch: 104/300 - Train loss: 0.35589873790740967, Validation loss: 0.3587980568408966
Epoch: 105/300 - Train loss: 0.3544658422470093, Validation loss: 0.3574152886867523
Epoch: 106/300 - Train loss: 0.35306060314178467, Validation loss: 0.35543134808540344
Epoch: 107/300 - Train loss: 0.35168230533599854, Validation loss: 0.3551195561885834
Epoch: 108/300 - Train loss: 0.350329726934433, Validation loss: 0.35281041264533997
Epoch: 109/300 - Train loss: 0.3490019142627716, Validation loss: 0.3522700071334839
Epoch: 110/300 - Train loss: 0.3476978540420532, Validation loss: 0.35078954696655273
Epoch: 111/300 - Train loss: 0.34641674160957336, Validation loss: 0.34995511174201965
Epoch: 112/300 - Train loss: 0.3451579809188843, Validation loss: 0.3480314314365387
Epoch: 113/300 - Train loss: 0.34392106533050537, Validation loss: 0.34699875116348267
Epoch: 114/300 - Train loss: 0.3427046835422516, Validation loss: 0.34613144397735596
Epoch: 115/300 - Train loss: 0.341509073972702, Validation loss: 0.34484976530075073
Epoch: 116/300 - Train loss: 0.3403334617614746, Validation loss: 0.3437182903289795
Epoch: 117/300 - Train loss: 0.3391774892807007, Validation loss: 0.34233784675598145
Epoch: 118/300 - Train loss: 0.3380398452281952, Validation loss: 0.3411962687969208
Epoch: 119/300 - Train loss: 0.336919903755188, Validation loss: 0.34020936489105225
Epoch: 120/300 - Train loss: 0.3358173966407776, Validation loss: 0.3389533460140228
Epoch: 121/300 - Train loss: 0.3347320556640625, Validation loss: 0.33774715662002563
Epoch: 122/300 - Train loss: 0.33366310596466064, Validation loss: 0.3374825119972229
Epoch: 123/300 - Train loss: 0.3326098620891571, Validation loss: 0.3355596661567688
Epoch: 124/300 - Train loss: 0.33157241344451904, Validation loss: 0.33554786443710327
Epoch: 125/300 - Train loss: 0.3305504620075226, Validation loss: 0.33380717039108276
Epoch: 126/300 - Train loss: 0.32954224944114685, Validation loss: 0.33289822936058044
Epoch: 127/300 - Train loss: 0.32854780554771423, Validation loss: 0.33195918798446655
Epoch: 128/300 - Train loss: 0.3275672197341919, Validation loss: 0.3315776586532593
Epoch: 129/300 - Train loss: 0.32660001516342163, Validation loss: 0.3301021158695221
Epoch: 130/300 - Train loss: 0.32564622163772583, Validation loss: 0.32937827706336975
Epoch: 131/300 - Train loss: 0.32470589876174927, Validation loss: 0.3288556933403015
Epoch: 132/300 - Train loss: 0.32377859950065613, Validation loss: 0.3273996412754059
Epoch: 133/300 - Train loss: 0.32286298274993896, Validation loss: 0.3273175060749054
Epoch: 134/300 - Train loss: 0.32195907831192017, Validation loss: 0.32563674449920654
Epoch: 135/300 - Train loss: 0.3210672438144684, Validation loss: 0.32457202672958374
Epoch: 136/300 - Train loss: 0.3201868534088135, Validation loss: 0.3242017328739166
Epoch: 137/300 - Train loss: 0.31931832432746887, Validation loss: 0.3229518234729767
Epoch: 138/300 - Train loss: 0.3184608221054077, Validation loss: 0.3228757977485657
Epoch: 139/300 - Train loss: 0.3176141083240509, Validation loss: 0.3217918574810028
Epoch: 140/300 - Train loss: 0.31677743792533875, Validation loss: 0.3206905424594879
Epoch: 141/300 - Train loss: 0.3159513473510742, Validation loss: 0.32067182660102844
Epoch: 142/300 - Train loss: 0.315136194229126, Validation loss: 0.3186805844306946
Epoch: 143/300 - Train loss: 0.31433162093162537, Validation loss: 0.3184792101383209
Epoch: 144/300 - Train loss: 0.3135373294353485, Validation loss: 0.31743350625038147
Epoch: 145/300 - Train loss: 0.31275299191474915, Validation loss: 0.3166353702545166
Epoch: 146/300 - Train loss: 0.31197836995124817, Validation loss: 0.3161230683326721
Epoch: 147/300 - Train loss: 0.3112126290798187, Validation loss: 0.3151848316192627
Epoch: 148/300 - Train loss: 0.3104555010795593, Validation loss: 0.3150638937950134
Epoch: 149/300 - Train loss: 0.30970749258995056, Validation loss: 0.31367364525794983
Epoch: 150/300 - Train loss: 0.30896806716918945, Validation loss: 0.3131520748138428
Epoch: 151/300 - Train loss: 0.3082371652126312, Validation loss: 0.3126583397388458
Epoch: 152/300 - Train loss: 0.3075142502784729, Validation loss: 0.3118683397769928
Epoch: 153/300 - Train loss: 0.30679959058761597, Validation loss: 0.3107657730579376
Epoch: 154/300 - Train loss: 0.30609339475631714, Validation loss: 0.31062838435173035
Epoch: 155/300 - Train loss: 0.3053954839706421, Validation loss: 0.30951568484306335
Epoch: 156/300 - Train loss: 0.30470573902130127, Validation loss: 0.30907559394836426
Epoch: 157/300 - Train loss: 0.3040247857570648, Validation loss: 0.308518648147583
Epoch: 158/300 - Train loss: 0.3033515214920044, Validation loss: 0.30777406692504883
Epoch: 159/300 - Train loss: 0.3026854991912842, Validation loss: 0.30757761001586914
Epoch: 160/300 - Train loss: 0.30202725529670715, Validation loss: 0.30694782733917236
Epoch: 161/300 - Train loss: 0.3013770580291748, Validation loss: 0.3069295585155487
