Epoch: 1/300 - Train loss: 0.6973665952682495, Validation loss: 0.6952036619186401
Epoch: 2/300 - Train loss: 0.6941425204277039, Validation loss: 0.6922367215156555
Epoch: 3/300 - Train loss: 0.6909984946250916, Validation loss: 0.6891741156578064
Epoch: 4/300 - Train loss: 0.6879185438156128, Validation loss: 0.6863399744033813
Epoch: 5/300 - Train loss: 0.6848776936531067, Validation loss: 0.6832517981529236
Epoch: 6/300 - Train loss: 0.681859016418457, Validation loss: 0.6803737878799438
Epoch: 7/300 - Train loss: 0.6788514852523804, Validation loss: 0.6774270534515381
Epoch: 8/300 - Train loss: 0.6758382320404053, Validation loss: 0.674554169178009
Epoch: 9/300 - Train loss: 0.6728094816207886, Validation loss: 0.671597421169281
Epoch: 10/300 - Train loss: 0.6697573661804199, Validation loss: 0.6684411764144897
Epoch: 11/300 - Train loss: 0.6666732430458069, Validation loss: 0.6655188202857971
Epoch: 12/300 - Train loss: 0.6635501384735107, Validation loss: 0.6624393463134766
Epoch: 13/300 - Train loss: 0.6603797674179077, Validation loss: 0.6594696640968323
Epoch: 14/300 - Train loss: 0.6571641564369202, Validation loss: 0.656308650970459
Epoch: 15/300 - Train loss: 0.6539039015769958, Validation loss: 0.6529909372329712
Epoch: 16/300 - Train loss: 0.6505980491638184, Validation loss: 0.6495640873908997
Epoch: 17/300 - Train loss: 0.647250771522522, Validation loss: 0.6465087532997131
Epoch: 18/300 - Train loss: 0.6438633799552917, Validation loss: 0.642857551574707
Epoch: 19/300 - Train loss: 0.6404420733451843, Validation loss: 0.6396355032920837
Epoch: 20/300 - Train loss: 0.636995792388916, Validation loss: 0.6361482739448547
Epoch: 21/300 - Train loss: 0.6335228085517883, Validation loss: 0.632912814617157
Epoch: 22/300 - Train loss: 0.6300286650657654, Validation loss: 0.629248857498169
Epoch: 23/300 - Train loss: 0.6265174746513367, Validation loss: 0.6260539889335632
Epoch: 24/300 - Train loss: 0.622994065284729, Validation loss: 0.6226154565811157
Epoch: 25/300 - Train loss: 0.6194638013839722, Validation loss: 0.619208037853241
Epoch: 26/300 - Train loss: 0.6159274578094482, Validation loss: 0.6157081127166748
Epoch: 27/300 - Train loss: 0.612387478351593, Validation loss: 0.612261176109314
Epoch: 28/300 - Train loss: 0.608843982219696, Validation loss: 0.6085024476051331
Epoch: 29/300 - Train loss: 0.60529625415802, Validation loss: 0.6052648425102234
Epoch: 30/300 - Train loss: 0.6017473936080933, Validation loss: 0.6015651226043701
Epoch: 31/300 - Train loss: 0.5981979966163635, Validation loss: 0.5980363488197327
Epoch: 32/300 - Train loss: 0.5946495532989502, Validation loss: 0.594666063785553
Epoch: 33/300 - Train loss: 0.591102123260498, Validation loss: 0.5909559726715088
Epoch: 34/300 - Train loss: 0.5875585079193115, Validation loss: 0.5875965356826782
Epoch: 35/300 - Train loss: 0.5840176343917847, Validation loss: 0.5840311646461487
Epoch: 36/300 - Train loss: 0.5804784297943115, Validation loss: 0.5803502202033997
Epoch: 37/300 - Train loss: 0.5769407749176025, Validation loss: 0.5769362449645996
Epoch: 38/300 - Train loss: 0.5734062790870667, Validation loss: 0.5735895037651062
Epoch: 39/300 - Train loss: 0.5698755979537964, Validation loss: 0.5697546005249023
Epoch: 40/300 - Train loss: 0.5663477182388306, Validation loss: 0.5663287043571472
Epoch: 41/300 - Train loss: 0.5628216862678528, Validation loss: 0.5629019141197205
Epoch: 42/300 - Train loss: 0.5592981576919556, Validation loss: 0.5595143437385559
Epoch: 43/300 - Train loss: 0.5557776689529419, Validation loss: 0.5558541417121887
Epoch: 44/300 - Train loss: 0.5522624254226685, Validation loss: 0.5525662899017334
Epoch: 45/300 - Train loss: 0.5487526655197144, Validation loss: 0.5487192869186401
Epoch: 46/300 - Train loss: 0.5452460646629333, Validation loss: 0.5453548431396484
Epoch: 47/300 - Train loss: 0.5417432188987732, Validation loss: 0.5417690277099609
Epoch: 48/300 - Train loss: 0.5382458567619324, Validation loss: 0.5382668375968933
Epoch: 49/300 - Train loss: 0.5347528457641602, Validation loss: 0.5347873568534851
Epoch: 50/300 - Train loss: 0.5312675833702087, Validation loss: 0.530860185623169
Epoch: 51/300 - Train loss: 0.5277932286262512, Validation loss: 0.5278141498565674
Epoch: 52/300 - Train loss: 0.5243313908576965, Validation loss: 0.5244159698486328
Epoch: 53/300 - Train loss: 0.5208795070648193, Validation loss: 0.5208432674407959
Epoch: 54/300 - Train loss: 0.5174378752708435, Validation loss: 0.5172604918479919
Epoch: 55/300 - Train loss: 0.5140071511268616, Validation loss: 0.5137913823127747
Epoch: 56/300 - Train loss: 0.5105903744697571, Validation loss: 0.5103915929794312
Epoch: 57/300 - Train loss: 0.5071871876716614, Validation loss: 0.5068966150283813
Epoch: 58/300 - Train loss: 0.503800094127655, Validation loss: 0.5037034749984741
Epoch: 59/300 - Train loss: 0.5004297494888306, Validation loss: 0.5003669857978821
Epoch: 60/300 - Train loss: 0.4970778524875641, Validation loss: 0.49679669737815857
Epoch: 61/300 - Train loss: 0.4937437176704407, Validation loss: 0.49331343173980713
Epoch: 62/300 - Train loss: 0.49042779207229614, Validation loss: 0.4902944564819336
Epoch: 63/300 - Train loss: 0.4871319830417633, Validation loss: 0.4868338108062744
Epoch: 64/300 - Train loss: 0.48385605216026306, Validation loss: 0.48349761962890625
Epoch: 65/300 - Train loss: 0.4806024432182312, Validation loss: 0.4801429510116577
Epoch: 66/300 - Train loss: 0.4773723781108856, Validation loss: 0.4766870439052582
Epoch: 67/300 - Train loss: 0.4741656184196472, Validation loss: 0.4738215506076813
Epoch: 68/300 - Train loss: 0.4709842801094055, Validation loss: 0.47026580572128296
Epoch: 69/300 - Train loss: 0.4678303599357605, Validation loss: 0.4671451151371002
Epoch: 70/300 - Train loss: 0.4647059738636017, Validation loss: 0.46413344144821167
Epoch: 71/300 - Train loss: 0.4616125226020813, Validation loss: 0.4610742926597595
Epoch: 72/300 - Train loss: 0.4585510492324829, Validation loss: 0.4580659568309784
Epoch: 73/300 - Train loss: 0.45552265644073486, Validation loss: 0.4548017382621765
Epoch: 74/300 - Train loss: 0.45253023505210876, Validation loss: 0.4517742991447449
Epoch: 75/300 - Train loss: 0.4495796859264374, Validation loss: 0.4486527740955353
Epoch: 76/300 - Train loss: 0.44666942954063416, Validation loss: 0.44561767578125
Epoch: 77/300 - Train loss: 0.4438023865222931, Validation loss: 0.44320666790008545
Epoch: 78/300 - Train loss: 0.44098228216171265, Validation loss: 0.4397169053554535
Epoch: 79/300 - Train loss: 0.4382106363773346, Validation loss: 0.43751585483551025
Epoch: 80/300 - Train loss: 0.4354868531227112, Validation loss: 0.43443551659584045
Epoch: 81/300 - Train loss: 0.4328136742115021, Validation loss: 0.4317619502544403
Epoch: 82/300 - Train loss: 0.4301915764808655, Validation loss: 0.42880088090896606
Epoch: 83/300 - Train loss: 0.4276212751865387, Validation loss: 0.42654094099998474
Epoch: 84/300 - Train loss: 0.42510345578193665, Validation loss: 0.4241236448287964
Epoch: 85/300 - Train loss: 0.4226364493370056, Validation loss: 0.42137768864631653
Epoch: 86/300 - Train loss: 0.42021965980529785, Validation loss: 0.4189545810222626
Epoch: 87/300 - Train loss: 0.41785264015197754, Validation loss: 0.4163133502006531
Epoch: 88/300 - Train loss: 0.415535032749176, Validation loss: 0.414241224527359
Epoch: 89/300 - Train loss: 0.4132653474807739, Validation loss: 0.41186192631721497
Epoch: 90/300 - Train loss: 0.411044716835022, Validation loss: 0.4094672203063965
Epoch: 91/300 - Train loss: 0.40887296199798584, Validation loss: 0.4073428809642792
Epoch: 92/300 - Train loss: 0.406749427318573, Validation loss: 0.40585947036743164
Epoch: 93/300 - Train loss: 0.4046729803085327, Validation loss: 0.4037002921104431
Epoch: 94/300 - Train loss: 0.4026437997817993, Validation loss: 0.40153685212135315
Epoch: 95/300 - Train loss: 0.4006613492965698, Validation loss: 0.39959317445755005
Epoch: 96/300 - Train loss: 0.39872440695762634, Validation loss: 0.3975387513637543
Epoch: 97/300 - Train loss: 0.3968321979045868, Validation loss: 0.3953956961631775
Epoch: 98/300 - Train loss: 0.39498430490493774, Validation loss: 0.39417019486427307
Epoch: 99/300 - Train loss: 0.39317938685417175, Validation loss: 0.3917499780654907
Epoch: 100/300 - Train loss: 0.3914166986942291, Validation loss: 0.3896125853061676
Epoch: 101/300 - Train loss: 0.38969534635543823, Validation loss: 0.3881780803203583
Epoch: 102/300 - Train loss: 0.3880143165588379, Validation loss: 0.3866356611251831
Epoch: 103/300 - Train loss: 0.3863722085952759, Validation loss: 0.3845643401145935
Epoch: 104/300 - Train loss: 0.3847687542438507, Validation loss: 0.3835371136665344
Epoch: 105/300 - Train loss: 0.3832026422023773, Validation loss: 0.38157176971435547
Epoch: 106/300 - Train loss: 0.3816729784011841, Validation loss: 0.38028818368911743
Epoch: 107/300 - Train loss: 0.3801800608634949, Validation loss: 0.37861165404319763
Epoch: 108/300 - Train loss: 0.37872180342674255, Validation loss: 0.3770427405834198
Epoch: 109/300 - Train loss: 0.37729763984680176, Validation loss: 0.37579041719436646
Epoch: 110/300 - Train loss: 0.375906765460968, Validation loss: 0.37433716654777527
Epoch: 111/300 - Train loss: 0.3745485842227936, Validation loss: 0.3728667199611664
Epoch: 112/300 - Train loss: 0.3732217252254486, Validation loss: 0.3717274069786072
Epoch: 113/300 - Train loss: 0.37192508578300476, Validation loss: 0.3707437515258789
Epoch: 114/300 - Train loss: 0.3706582188606262, Validation loss: 0.36924976110458374
Epoch: 115/300 - Train loss: 0.36942005157470703, Validation loss: 0.3678589165210724
Epoch: 116/300 - Train loss: 0.3682094216346741, Validation loss: 0.36595943570137024
Epoch: 117/300 - Train loss: 0.3670256435871124, Validation loss: 0.3652935028076172
Epoch: 118/300 - Train loss: 0.3658677339553833, Validation loss: 0.3642500638961792
Epoch: 119/300 - Train loss: 0.3647352159023285, Validation loss: 0.36343082785606384
Epoch: 120/300 - Train loss: 0.3636270761489868, Validation loss: 0.362382709980011
Epoch: 121/300 - Train loss: 0.3625428080558777, Validation loss: 0.36144694685935974
Epoch: 122/300 - Train loss: 0.3614812195301056, Validation loss: 0.35997095704078674
Epoch: 123/300 - Train loss: 0.360441654920578, Validation loss: 0.3591260015964508
Epoch: 124/300 - Train loss: 0.3594233989715576, Validation loss: 0.35769835114479065
Epoch: 125/300 - Train loss: 0.3584257662296295, Validation loss: 0.35758987069129944
Epoch: 126/300 - Train loss: 0.35744884610176086, Validation loss: 0.3559466600418091
Epoch: 127/300 - Train loss: 0.3564923107624054, Validation loss: 0.3548208177089691
Epoch: 128/300 - Train loss: 0.35555499792099, Validation loss: 0.3545010983943939
Epoch: 129/300 - Train loss: 0.3546363413333893, Validation loss: 0.35334932804107666
Epoch: 130/300 - Train loss: 0.3537358045578003, Validation loss: 0.35232141613960266
Epoch: 131/300 - Train loss: 0.3528522551059723, Validation loss: 0.35080352425575256
Epoch: 132/300 - Train loss: 0.351985365152359, Validation loss: 0.34986254572868347
Epoch: 133/300 - Train loss: 0.3511343002319336, Validation loss: 0.34932926297187805
Epoch: 134/300 - Train loss: 0.3502984046936035, Validation loss: 0.34849023818969727
Epoch: 135/300 - Train loss: 0.34947726130485535, Validation loss: 0.3472616970539093
Epoch: 136/300 - Train loss: 0.3486703336238861, Validation loss: 0.346769243478775
Epoch: 137/300 - Train loss: 0.3478770852088928, Validation loss: 0.34674447774887085
Epoch: 138/300 - Train loss: 0.3470972776412964, Validation loss: 0.3455004394054413
Epoch: 139/300 - Train loss: 0.34633100032806396, Validation loss: 0.34484589099884033
Epoch: 140/300 - Train loss: 0.3455772399902344, Validation loss: 0.3438030183315277
Epoch: 141/300 - Train loss: 0.3448359966278076, Validation loss: 0.3431752622127533
Epoch: 142/300 - Train loss: 0.3441069424152374, Validation loss: 0.3427891731262207
Epoch: 143/300 - Train loss: 0.3433893620967865, Validation loss: 0.3420247733592987
Epoch: 144/300 - Train loss: 0.34268298745155334, Validation loss: 0.34090855717658997
Epoch: 145/300 - Train loss: 0.34198716282844543, Validation loss: 0.34016153216362
Epoch: 146/300 - Train loss: 0.34130212664604187, Validation loss: 0.33927008509635925
Epoch: 147/300 - Train loss: 0.34062761068344116, Validation loss: 0.3387269973754883
Epoch: 148/300 - Train loss: 0.33996284008026123, Validation loss: 0.3383823335170746
Epoch: 149/300 - Train loss: 0.33930790424346924, Validation loss: 0.33740460872650146
Epoch: 150/300 - Train loss: 0.3386615216732025, Validation loss: 0.3361663520336151
Epoch: 151/300 - Train loss: 0.3380230963230133, Validation loss: 0.3360635042190552
Epoch: 152/300 - Train loss: 0.33739301562309265, Validation loss: 0.3360725939273834
Epoch: 153/300 - Train loss: 0.3367711901664734, Validation loss: 0.3351048231124878
Epoch: 154/300 - Train loss: 0.3361572027206421, Validation loss: 0.334372878074646
Epoch: 155/300 - Train loss: 0.33555081486701965, Validation loss: 0.3336796462535858
Epoch: 156/300 - Train loss: 0.33495232462882996, Validation loss: 0.3332544267177582
Epoch: 157/300 - Train loss: 0.3343605697154999, Validation loss: 0.33268675208091736
Epoch: 158/300 - Train loss: 0.3337748646736145, Validation loss: 0.3317360579967499
Epoch: 159/300 - Train loss: 0.3331962525844574, Validation loss: 0.3317163288593292
