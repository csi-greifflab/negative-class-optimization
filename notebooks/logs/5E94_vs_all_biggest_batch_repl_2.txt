Epoch: 1/300 - Train loss: 0.6988886594772339, Validation loss: 0.6967197060585022
Epoch: 2/300 - Train loss: 0.6961517333984375, Validation loss: 0.6940163969993591
Epoch: 3/300 - Train loss: 0.6934224963188171, Validation loss: 0.6913599371910095
Epoch: 4/300 - Train loss: 0.690679132938385, Validation loss: 0.6884625554084778
Epoch: 5/300 - Train loss: 0.6878877878189087, Validation loss: 0.6856615543365479
Epoch: 6/300 - Train loss: 0.685019850730896, Validation loss: 0.6827809810638428
Epoch: 7/300 - Train loss: 0.6820454001426697, Validation loss: 0.6796563267707825
Epoch: 8/300 - Train loss: 0.6789408922195435, Validation loss: 0.6762613654136658
Epoch: 9/300 - Train loss: 0.6756946444511414, Validation loss: 0.6728325486183167
Epoch: 10/300 - Train loss: 0.6723023056983948, Validation loss: 0.669337272644043
Epoch: 11/300 - Train loss: 0.6687742471694946, Validation loss: 0.6656343936920166
Epoch: 12/300 - Train loss: 0.665122926235199, Validation loss: 0.6618149876594543
Epoch: 13/300 - Train loss: 0.6613569855690002, Validation loss: 0.6577972769737244
Epoch: 14/300 - Train loss: 0.6574880480766296, Validation loss: 0.6535806059837341
Epoch: 15/300 - Train loss: 0.6535403728485107, Validation loss: 0.6496177911758423
Epoch: 16/300 - Train loss: 0.6495358943939209, Validation loss: 0.6456303000450134
Epoch: 17/300 - Train loss: 0.6454820036888123, Validation loss: 0.6413528323173523
Epoch: 18/300 - Train loss: 0.6413966417312622, Validation loss: 0.6373993754386902
Epoch: 19/300 - Train loss: 0.6372852921485901, Validation loss: 0.6330286860466003
Epoch: 20/300 - Train loss: 0.6331573724746704, Validation loss: 0.6287588477134705
Epoch: 21/300 - Train loss: 0.6290232539176941, Validation loss: 0.6246215105056763
Epoch: 22/300 - Train loss: 0.6248874068260193, Validation loss: 0.6206717491149902
Epoch: 23/300 - Train loss: 0.6207534074783325, Validation loss: 0.616554319858551
Epoch: 24/300 - Train loss: 0.6166243553161621, Validation loss: 0.6123590469360352
Epoch: 25/300 - Train loss: 0.6125065684318542, Validation loss: 0.6082584857940674
Epoch: 26/300 - Train loss: 0.6084046363830566, Validation loss: 0.60398268699646
Epoch: 27/300 - Train loss: 0.6043233275413513, Validation loss: 0.6000427603721619
Epoch: 28/300 - Train loss: 0.6002677083015442, Validation loss: 0.5958538055419922
Epoch: 29/300 - Train loss: 0.5962409973144531, Validation loss: 0.5918700098991394
Epoch: 30/300 - Train loss: 0.5922439098358154, Validation loss: 0.5881823897361755
Epoch: 31/300 - Train loss: 0.5882818698883057, Validation loss: 0.5843159556388855
Epoch: 32/300 - Train loss: 0.5843562483787537, Validation loss: 0.5803262591362
Epoch: 33/300 - Train loss: 0.5804708003997803, Validation loss: 0.5765260457992554
Epoch: 34/300 - Train loss: 0.5766268372535706, Validation loss: 0.5723980069160461
Epoch: 35/300 - Train loss: 0.5728250741958618, Validation loss: 0.5691442489624023
Epoch: 36/300 - Train loss: 0.5690677165985107, Validation loss: 0.5650317072868347
Epoch: 37/300 - Train loss: 0.5653572082519531, Validation loss: 0.5608564019203186
Epoch: 38/300 - Train loss: 0.5616946220397949, Validation loss: 0.5576532483100891
Epoch: 39/300 - Train loss: 0.5580834150314331, Validation loss: 0.5541620254516602
Epoch: 40/300 - Train loss: 0.5545240044593811, Validation loss: 0.550326406955719
Epoch: 41/300 - Train loss: 0.551018238067627, Validation loss: 0.54740971326828
Epoch: 42/300 - Train loss: 0.5475672483444214, Validation loss: 0.5435352325439453
Epoch: 43/300 - Train loss: 0.5441721081733704, Validation loss: 0.5410192012786865
Epoch: 44/300 - Train loss: 0.5408337116241455, Validation loss: 0.537322461605072
Epoch: 45/300 - Train loss: 0.5375524163246155, Validation loss: 0.5344048738479614
Epoch: 46/300 - Train loss: 0.5343281626701355, Validation loss: 0.5302000045776367
Epoch: 47/300 - Train loss: 0.5311609506607056, Validation loss: 0.5285859704017639
Epoch: 48/300 - Train loss: 0.5280508995056152, Validation loss: 0.5253180265426636
Epoch: 49/300 - Train loss: 0.524997353553772, Validation loss: 0.5215578675270081
Epoch: 50/300 - Train loss: 0.5220001935958862, Validation loss: 0.5190195441246033
Epoch: 51/300 - Train loss: 0.5190598368644714, Validation loss: 0.5164492130279541
Epoch: 52/300 - Train loss: 0.5161756873130798, Validation loss: 0.5129776000976562
Epoch: 53/300 - Train loss: 0.5133469104766846, Validation loss: 0.5101863145828247
Epoch: 54/300 - Train loss: 0.5105733871459961, Validation loss: 0.5076060891151428
Epoch: 55/300 - Train loss: 0.5078547596931458, Validation loss: 0.5057081580162048
Epoch: 56/300 - Train loss: 0.5051906704902649, Validation loss: 0.5022619366645813
Epoch: 57/300 - Train loss: 0.5025801062583923, Validation loss: 0.499972939491272
Epoch: 58/300 - Train loss: 0.5000220537185669, Validation loss: 0.4976009130477905
Epoch: 59/300 - Train loss: 0.49751538038253784, Validation loss: 0.49456772208213806
Epoch: 60/300 - Train loss: 0.49505922198295593, Validation loss: 0.4925433099269867
Epoch: 61/300 - Train loss: 0.49265241622924805, Validation loss: 0.49132996797561646
Epoch: 62/300 - Train loss: 0.49029409885406494, Validation loss: 0.48747357726097107
Epoch: 63/300 - Train loss: 0.48798322677612305, Validation loss: 0.48561957478523254
Epoch: 64/300 - Train loss: 0.4857189655303955, Validation loss: 0.4834897220134735
Epoch: 65/300 - Train loss: 0.48350000381469727, Validation loss: 0.481321781873703
Epoch: 66/300 - Train loss: 0.4813252389431, Validation loss: 0.47877535223960876
Epoch: 67/300 - Train loss: 0.47919365763664246, Validation loss: 0.47761598229408264
Epoch: 68/300 - Train loss: 0.4771043062210083, Validation loss: 0.47496137022972107
Epoch: 69/300 - Train loss: 0.4750559329986572, Validation loss: 0.4730859398841858
Epoch: 70/300 - Train loss: 0.4730472266674042, Validation loss: 0.47104617953300476
Epoch: 71/300 - Train loss: 0.4710768759250641, Validation loss: 0.4691537916660309
Epoch: 72/300 - Train loss: 0.4691438376903534, Validation loss: 0.4679040312767029
Epoch: 73/300 - Train loss: 0.4672475755214691, Validation loss: 0.465110719203949
Epoch: 74/300 - Train loss: 0.4653865098953247, Validation loss: 0.4637102484703064
Epoch: 75/300 - Train loss: 0.46355965733528137, Validation loss: 0.46154680848121643
Epoch: 76/300 - Train loss: 0.4617667496204376, Validation loss: 0.4609583914279938
Epoch: 77/300 - Train loss: 0.46000605821609497, Validation loss: 0.45816484093666077
Epoch: 78/300 - Train loss: 0.4582770764827728, Validation loss: 0.45646974444389343
Epoch: 79/300 - Train loss: 0.4565789997577667, Validation loss: 0.45512548089027405
Epoch: 80/300 - Train loss: 0.45491161942481995, Validation loss: 0.45407894253730774
Epoch: 81/300 - Train loss: 0.45327436923980713, Validation loss: 0.4516201913356781
Epoch: 82/300 - Train loss: 0.4516657888889313, Validation loss: 0.45034971833229065
Epoch: 83/300 - Train loss: 0.45008525252342224, Validation loss: 0.4484487473964691
Epoch: 84/300 - Train loss: 0.44853243231773376, Validation loss: 0.4470020830631256
Epoch: 85/300 - Train loss: 0.44700661301612854, Validation loss: 0.4461410343647003
Epoch: 86/300 - Train loss: 0.44550731778144836, Validation loss: 0.444335401058197
Epoch: 87/300 - Train loss: 0.44403356313705444, Validation loss: 0.4430692493915558
Epoch: 88/300 - Train loss: 0.4425853490829468, Validation loss: 0.44138607382774353
Epoch: 89/300 - Train loss: 0.4411616027355194, Validation loss: 0.44075608253479004
Epoch: 90/300 - Train loss: 0.43976178765296936, Validation loss: 0.4378040134906769
Epoch: 91/300 - Train loss: 0.4383857846260071, Validation loss: 0.43751874566078186
Epoch: 92/300 - Train loss: 0.437033474445343, Validation loss: 0.4372207820415497
Epoch: 93/300 - Train loss: 0.43570393323898315, Validation loss: 0.4350534975528717
Epoch: 94/300 - Train loss: 0.43439632654190063, Validation loss: 0.4324710965156555
Epoch: 95/300 - Train loss: 0.43311041593551636, Validation loss: 0.4322704076766968
Epoch: 96/300 - Train loss: 0.43184569478034973, Validation loss: 0.4309937059879303
Epoch: 97/300 - Train loss: 0.43060144782066345, Validation loss: 0.429269939661026
Epoch: 98/300 - Train loss: 0.4293772578239441, Validation loss: 0.42880183458328247
Epoch: 99/300 - Train loss: 0.428172767162323, Validation loss: 0.4276837408542633
Epoch: 100/300 - Train loss: 0.4269873797893524, Validation loss: 0.42649078369140625
Epoch: 101/300 - Train loss: 0.4258207380771637, Validation loss: 0.42443612217903137
Epoch: 102/300 - Train loss: 0.42467233538627625, Validation loss: 0.4248763918876648
Epoch: 103/300 - Train loss: 0.42354172468185425, Validation loss: 0.42385199666023254
Epoch: 104/300 - Train loss: 0.42242807149887085, Validation loss: 0.42114636301994324
Epoch: 105/300 - Train loss: 0.4213310480117798, Validation loss: 0.4203234612941742
Epoch: 106/300 - Train loss: 0.42025071382522583, Validation loss: 0.41949141025543213
Epoch: 107/300 - Train loss: 0.4191868007183075, Validation loss: 0.41831737756729126
Epoch: 108/300 - Train loss: 0.41813838481903076, Validation loss: 0.4179929196834564
Epoch: 109/300 - Train loss: 0.41710546612739563, Validation loss: 0.4158608615398407
Epoch: 110/300 - Train loss: 0.4160877764225006, Validation loss: 0.4150736927986145
Epoch: 111/300 - Train loss: 0.41508445143699646, Validation loss: 0.41393089294433594
Epoch: 112/300 - Train loss: 0.4140956699848175, Validation loss: 0.41367393732070923
Epoch: 113/300 - Train loss: 0.41312170028686523, Validation loss: 0.4118606448173523
Epoch: 114/300 - Train loss: 0.41216161847114563, Validation loss: 0.41120827198028564
Epoch: 115/300 - Train loss: 0.4112149477005005, Validation loss: 0.41064849495887756
Epoch: 116/300 - Train loss: 0.41028136014938354, Validation loss: 0.4101465344429016
Epoch: 117/300 - Train loss: 0.40936043858528137, Validation loss: 0.40871813893318176
Epoch: 118/300 - Train loss: 0.40845194458961487, Validation loss: 0.4079381227493286
Epoch: 119/300 - Train loss: 0.4075556695461273, Validation loss: 0.40729066729545593
Epoch: 120/300 - Train loss: 0.40667155385017395, Validation loss: 0.40483391284942627
Epoch: 121/300 - Train loss: 0.405799001455307, Validation loss: 0.4052879512310028
Epoch: 122/300 - Train loss: 0.40493831038475037, Validation loss: 0.4046971797943115
Epoch: 123/300 - Train loss: 0.40408846735954285, Validation loss: 0.40300092101097107
Epoch: 124/300 - Train loss: 0.4032498896121979, Validation loss: 0.4022868275642395
Epoch: 125/300 - Train loss: 0.40242186188697815, Validation loss: 0.4025307595729828
Epoch: 126/300 - Train loss: 0.4016041159629822, Validation loss: 0.40029633045196533
Epoch: 127/300 - Train loss: 0.4007958769798279, Validation loss: 0.39960116147994995
Epoch: 128/300 - Train loss: 0.3999977707862854, Validation loss: 0.3985622227191925
Epoch: 129/300 - Train loss: 0.3992098867893219, Validation loss: 0.3980832099914551
Epoch: 130/300 - Train loss: 0.3984310030937195, Validation loss: 0.3976130485534668
Epoch: 131/300 - Train loss: 0.3976614475250244, Validation loss: 0.39668506383895874
Epoch: 132/300 - Train loss: 0.39690110087394714, Validation loss: 0.396485298871994
Epoch: 133/300 - Train loss: 0.396150141954422, Validation loss: 0.3960625231266022
Epoch: 134/300 - Train loss: 0.395408034324646, Validation loss: 0.39470183849334717
Epoch: 135/300 - Train loss: 0.39467474818229675, Validation loss: 0.3938600718975067
Epoch: 136/300 - Train loss: 0.3939504325389862, Validation loss: 0.3944645822048187
Epoch: 137/300 - Train loss: 0.39323487877845764, Validation loss: 0.3928993344306946
Epoch: 138/300 - Train loss: 0.3925284743309021, Validation loss: 0.39268335700035095
Epoch: 139/300 - Train loss: 0.3918301463127136, Validation loss: 0.3919808566570282
Epoch: 140/300 - Train loss: 0.3911392092704773, Validation loss: 0.3905600309371948
Epoch: 141/300 - Train loss: 0.39045631885528564, Validation loss: 0.39024168252944946
Epoch: 142/300 - Train loss: 0.38978174328804016, Validation loss: 0.3898794949054718
Epoch: 143/300 - Train loss: 0.38911500573158264, Validation loss: 0.3874633014202118
Epoch: 144/300 - Train loss: 0.388455867767334, Validation loss: 0.38892167806625366
Epoch: 145/300 - Train loss: 0.38780391216278076, Validation loss: 0.3879653215408325
Epoch: 146/300 - Train loss: 0.38715943694114685, Validation loss: 0.3864825367927551
Epoch: 147/300 - Train loss: 0.38652193546295166, Validation loss: 0.385416716337204
Epoch: 148/300 - Train loss: 0.3858915865421295, Validation loss: 0.38731124997138977
Epoch: 149/300 - Train loss: 0.3852682411670685, Validation loss: 0.3849785029888153
Epoch: 150/300 - Train loss: 0.3846513032913208, Validation loss: 0.38480910658836365
Epoch: 151/300 - Train loss: 0.38404080271720886, Validation loss: 0.38472461700439453
Epoch: 152/300 - Train loss: 0.3834365904331207, Validation loss: 0.3825710713863373
Epoch: 153/300 - Train loss: 0.3828384578227997, Validation loss: 0.3832989037036896
Epoch: 154/300 - Train loss: 0.3822467029094696, Validation loss: 0.381775438785553
Epoch: 155/300 - Train loss: 0.38166093826293945, Validation loss: 0.3808605968952179
Epoch: 156/300 - Train loss: 0.38108107447624207, Validation loss: 0.38060706853866577
Epoch: 157/300 - Train loss: 0.3805065453052521, Validation loss: 0.38026121258735657
Epoch: 158/300 - Train loss: 0.3799372911453247, Validation loss: 0.37901952862739563
Epoch: 159/300 - Train loss: 0.37937381863594055, Validation loss: 0.37851059436798096
Epoch: 160/300 - Train loss: 0.3788159191608429, Validation loss: 0.3794078230857849
Epoch: 161/300 - Train loss: 0.37826302647590637, Validation loss: 0.3784496486186981
