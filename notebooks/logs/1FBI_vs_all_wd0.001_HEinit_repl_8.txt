Epoch: 1/300 - Train loss: 0.7025372982025146, Validation loss: 0.7004541158676147
Epoch: 2/300 - Train loss: 0.6992490887641907, Validation loss: 0.6971824765205383
Epoch: 3/300 - Train loss: 0.6960256099700928, Validation loss: 0.6938719749450684
Epoch: 4/300 - Train loss: 0.692858874797821, Validation loss: 0.6905917525291443
Epoch: 5/300 - Train loss: 0.689744234085083, Validation loss: 0.6873365044593811
Epoch: 6/300 - Train loss: 0.6866617202758789, Validation loss: 0.6842036843299866
Epoch: 7/300 - Train loss: 0.6835941672325134, Validation loss: 0.6809818148612976
Epoch: 8/300 - Train loss: 0.6805217862129211, Validation loss: 0.6779178380966187
Epoch: 9/300 - Train loss: 0.6774245500564575, Validation loss: 0.6745851635932922
Epoch: 10/300 - Train loss: 0.6742815971374512, Validation loss: 0.6711629033088684
Epoch: 11/300 - Train loss: 0.6710812449455261, Validation loss: 0.6678736209869385
Epoch: 12/300 - Train loss: 0.6678037643432617, Validation loss: 0.6643492579460144
Epoch: 13/300 - Train loss: 0.6644349694252014, Validation loss: 0.6606770157814026
Epoch: 14/300 - Train loss: 0.6609693765640259, Validation loss: 0.6569746136665344
Epoch: 15/300 - Train loss: 0.6573957800865173, Validation loss: 0.6532909274101257
Epoch: 16/300 - Train loss: 0.6537004709243774, Validation loss: 0.6491590738296509
Epoch: 17/300 - Train loss: 0.6498792767524719, Validation loss: 0.6452798843383789
Epoch: 18/300 - Train loss: 0.6459221839904785, Validation loss: 0.6408923268318176
Epoch: 19/300 - Train loss: 0.641830325126648, Validation loss: 0.6366404891014099
Epoch: 20/300 - Train loss: 0.6376007795333862, Validation loss: 0.6321012377738953
Epoch: 21/300 - Train loss: 0.6332346796989441, Validation loss: 0.6274731159210205
Epoch: 22/300 - Train loss: 0.6287333965301514, Validation loss: 0.6227147579193115
Epoch: 23/300 - Train loss: 0.6240931153297424, Validation loss: 0.6178300976753235
Epoch: 24/300 - Train loss: 0.6193166375160217, Validation loss: 0.6128048896789551
Epoch: 25/300 - Train loss: 0.6144105792045593, Validation loss: 0.6077022552490234
Epoch: 26/300 - Train loss: 0.6093801856040955, Validation loss: 0.6023436784744263
Epoch: 27/300 - Train loss: 0.6042299270629883, Validation loss: 0.5970962047576904
Epoch: 28/300 - Train loss: 0.5989629030227661, Validation loss: 0.5917314887046814
Epoch: 29/300 - Train loss: 0.5935871005058289, Validation loss: 0.5860111117362976
Epoch: 30/300 - Train loss: 0.5881137847900391, Validation loss: 0.5803585648536682
Epoch: 31/300 - Train loss: 0.5825512409210205, Validation loss: 0.5746887922286987
Epoch: 32/300 - Train loss: 0.5769034624099731, Validation loss: 0.5687823295593262
Epoch: 33/300 - Train loss: 0.5711820125579834, Validation loss: 0.5631519556045532
Epoch: 34/300 - Train loss: 0.5653929710388184, Validation loss: 0.5570899248123169
Epoch: 35/300 - Train loss: 0.5595425963401794, Validation loss: 0.5512951016426086
Epoch: 36/300 - Train loss: 0.5536369681358337, Validation loss: 0.5452616810798645
Epoch: 37/300 - Train loss: 0.5476832985877991, Validation loss: 0.5392087697982788
Epoch: 38/300 - Train loss: 0.5416902899742126, Validation loss: 0.5330617427825928
Epoch: 39/300 - Train loss: 0.5356621146202087, Validation loss: 0.526914119720459
Epoch: 40/300 - Train loss: 0.5296075940132141, Validation loss: 0.5207899808883667
Epoch: 41/300 - Train loss: 0.5235341787338257, Validation loss: 0.5145692825317383
Epoch: 42/300 - Train loss: 0.5174479484558105, Validation loss: 0.5085573792457581
Epoch: 43/300 - Train loss: 0.5113545656204224, Validation loss: 0.5023514628410339
Epoch: 44/300 - Train loss: 0.5052617192268372, Validation loss: 0.49628132581710815
Epoch: 45/300 - Train loss: 0.49917489290237427, Validation loss: 0.49027153849601746
Epoch: 46/300 - Train loss: 0.4931016266345978, Validation loss: 0.48416823148727417
Epoch: 47/300 - Train loss: 0.48704877495765686, Validation loss: 0.4780491888523102
Epoch: 48/300 - Train loss: 0.4810227155685425, Validation loss: 0.47227686643600464
Epoch: 49/300 - Train loss: 0.4750269651412964, Validation loss: 0.46635663509368896
Epoch: 50/300 - Train loss: 0.46906810998916626, Validation loss: 0.4601333737373352
Epoch: 51/300 - Train loss: 0.46315208077430725, Validation loss: 0.45427659153938293
Epoch: 52/300 - Train loss: 0.45728346705436707, Validation loss: 0.44835516810417175
Epoch: 53/300 - Train loss: 0.4514662027359009, Validation loss: 0.4426686465740204
Epoch: 54/300 - Train loss: 0.44570502638816833, Validation loss: 0.43698617815971375
Epoch: 55/300 - Train loss: 0.44000422954559326, Validation loss: 0.43095502257347107
Epoch: 56/300 - Train loss: 0.43436798453330994, Validation loss: 0.42569082975387573
Epoch: 57/300 - Train loss: 0.42879971861839294, Validation loss: 0.41999149322509766
Epoch: 58/300 - Train loss: 0.42330315709114075, Validation loss: 0.4144801199436188
Epoch: 59/300 - Train loss: 0.4178820550441742, Validation loss: 0.40961819887161255
Epoch: 60/300 - Train loss: 0.41253915429115295, Validation loss: 0.4039500653743744
Epoch: 61/300 - Train loss: 0.4072768986225128, Validation loss: 0.3990859091281891
Epoch: 62/300 - Train loss: 0.40209782123565674, Validation loss: 0.39392200112342834
Epoch: 63/300 - Train loss: 0.39700406789779663, Validation loss: 0.38904765248298645
Epoch: 64/300 - Train loss: 0.39199700951576233, Validation loss: 0.3834756016731262
Epoch: 65/300 - Train loss: 0.38707831501960754, Validation loss: 0.3785876929759979
Epoch: 66/300 - Train loss: 0.38224899768829346, Validation loss: 0.3739059567451477
Epoch: 67/300 - Train loss: 0.3775101900100708, Validation loss: 0.3696213960647583
Epoch: 68/300 - Train loss: 0.37286272644996643, Validation loss: 0.36478376388549805
Epoch: 69/300 - Train loss: 0.36830711364746094, Validation loss: 0.360622763633728
Epoch: 70/300 - Train loss: 0.3638436794281006, Validation loss: 0.35586103796958923
Epoch: 71/300 - Train loss: 0.35947248339653015, Validation loss: 0.35179463028907776
Epoch: 72/300 - Train loss: 0.35519304871559143, Validation loss: 0.34763211011886597
Epoch: 73/300 - Train loss: 0.351005494594574, Validation loss: 0.3432326316833496
Epoch: 74/300 - Train loss: 0.3469094932079315, Validation loss: 0.33952245116233826
Epoch: 75/300 - Train loss: 0.34290528297424316, Validation loss: 0.33545470237731934
Epoch: 76/300 - Train loss: 0.3389918804168701, Validation loss: 0.3315995931625366
Epoch: 77/300 - Train loss: 0.3351683020591736, Validation loss: 0.32796308398246765
Epoch: 78/300 - Train loss: 0.3314332962036133, Validation loss: 0.32445284724235535
Epoch: 79/300 - Train loss: 0.327785462141037, Validation loss: 0.3210086226463318
Epoch: 80/300 - Train loss: 0.3242238759994507, Validation loss: 0.3173239827156067
Epoch: 81/300 - Train loss: 0.32074791193008423, Validation loss: 0.31386393308639526
Epoch: 82/300 - Train loss: 0.3173561990261078, Validation loss: 0.3108177185058594
Epoch: 83/300 - Train loss: 0.3140473961830139, Validation loss: 0.30744969844818115
Epoch: 84/300 - Train loss: 0.3108198940753937, Validation loss: 0.30417025089263916
Epoch: 85/300 - Train loss: 0.3076723515987396, Validation loss: 0.30101659893989563
Epoch: 86/300 - Train loss: 0.30460330843925476, Validation loss: 0.2978975474834442
Epoch: 87/300 - Train loss: 0.3016113042831421, Validation loss: 0.2951885461807251
Epoch: 88/300 - Train loss: 0.2986949682235718, Validation loss: 0.29231247305870056
Epoch: 89/300 - Train loss: 0.2958522439002991, Validation loss: 0.2896134853363037
Epoch: 90/300 - Train loss: 0.2930814027786255, Validation loss: 0.2869427502155304
Epoch: 91/300 - Train loss: 0.29038116335868835, Validation loss: 0.2840418517589569
Epoch: 92/300 - Train loss: 0.2877500057220459, Validation loss: 0.28190872073173523
Epoch: 93/300 - Train loss: 0.2851865887641907, Validation loss: 0.2790859341621399
Epoch: 94/300 - Train loss: 0.28268900513648987, Validation loss: 0.2766592800617218
Epoch: 95/300 - Train loss: 0.280255526304245, Validation loss: 0.2741199731826782
Epoch: 96/300 - Train loss: 0.27788490056991577, Validation loss: 0.271953284740448
Epoch: 97/300 - Train loss: 0.2755756378173828, Validation loss: 0.2698930501937866
Epoch: 98/300 - Train loss: 0.2733258306980133, Validation loss: 0.26777708530426025
Epoch: 99/300 - Train loss: 0.27113422751426697, Validation loss: 0.2657396197319031
Epoch: 100/300 - Train loss: 0.2689994275569916, Validation loss: 0.26351049542427063
Epoch: 101/300 - Train loss: 0.26691991090774536, Validation loss: 0.2615935504436493
Epoch: 102/300 - Train loss: 0.2648942768573761, Validation loss: 0.25963911414146423
Epoch: 103/300 - Train loss: 0.26292112469673157, Validation loss: 0.2581060528755188
Epoch: 104/300 - Train loss: 0.26099881529808044, Validation loss: 0.2558296322822571
Epoch: 105/300 - Train loss: 0.259126216173172, Validation loss: 0.2539115250110626
Epoch: 106/300 - Train loss: 0.25730204582214355, Validation loss: 0.25242680311203003
Epoch: 107/300 - Train loss: 0.2555249035358429, Validation loss: 0.25020113587379456
Epoch: 108/300 - Train loss: 0.25379347801208496, Validation loss: 0.24875400960445404
Epoch: 109/300 - Train loss: 0.2521064281463623, Validation loss: 0.24730707705020905
Epoch: 110/300 - Train loss: 0.25046247243881226, Validation loss: 0.24576254189014435
Epoch: 111/300 - Train loss: 0.24886023998260498, Validation loss: 0.24425260722637177
Epoch: 112/300 - Train loss: 0.24729858338832855, Validation loss: 0.2426040768623352
Epoch: 113/300 - Train loss: 0.24577657878398895, Validation loss: 0.24079032242298126
Epoch: 114/300 - Train loss: 0.2442929595708847, Validation loss: 0.23990346491336823
Epoch: 115/300 - Train loss: 0.24284657835960388, Validation loss: 0.23807771503925323
Epoch: 116/300 - Train loss: 0.24143636226654053, Validation loss: 0.23690518736839294
Epoch: 117/300 - Train loss: 0.24006131291389465, Validation loss: 0.2357957512140274
Epoch: 118/300 - Train loss: 0.23872055113315582, Validation loss: 0.23488116264343262
Epoch: 119/300 - Train loss: 0.23741307854652405, Validation loss: 0.23324346542358398
Epoch: 120/300 - Train loss: 0.2361379861831665, Validation loss: 0.23182173073291779
Epoch: 121/300 - Train loss: 0.23489448428153992, Validation loss: 0.2308969348669052
Epoch: 122/300 - Train loss: 0.23368169367313385, Validation loss: 0.2297002226114273
Epoch: 123/300 - Train loss: 0.23249857127666473, Validation loss: 0.22874686121940613
Epoch: 124/300 - Train loss: 0.23134426772594452, Validation loss: 0.22731533646583557
Epoch: 125/300 - Train loss: 0.23021791875362396, Validation loss: 0.2259812355041504
Epoch: 126/300 - Train loss: 0.22911866009235382, Validation loss: 0.2251676768064499
Epoch: 127/300 - Train loss: 0.2280457466840744, Validation loss: 0.22382782399654388
Epoch: 128/300 - Train loss: 0.22699841856956482, Validation loss: 0.22334693372249603
Epoch: 129/300 - Train loss: 0.22597602009773254, Validation loss: 0.22206613421440125
Epoch: 130/300 - Train loss: 0.22497770190238953, Validation loss: 0.22181124985218048
Epoch: 131/300 - Train loss: 0.22400273382663727, Validation loss: 0.22062674164772034
Epoch: 132/300 - Train loss: 0.22305049002170563, Validation loss: 0.21964244544506073
Epoch: 133/300 - Train loss: 0.222120463848114, Validation loss: 0.21847504377365112
Epoch: 134/300 - Train loss: 0.2212119847536087, Validation loss: 0.21775636076927185
Epoch: 135/300 - Train loss: 0.22032442688941956, Validation loss: 0.21716853976249695
Epoch: 136/300 - Train loss: 0.21945719420909882, Validation loss: 0.21589823067188263
Epoch: 137/300 - Train loss: 0.2186097651720047, Validation loss: 0.21517835557460785
Epoch: 138/300 - Train loss: 0.2177816927433014, Validation loss: 0.21479788422584534
Epoch: 139/300 - Train loss: 0.21697235107421875, Validation loss: 0.21367688477039337
Epoch: 140/300 - Train loss: 0.21618114411830902, Validation loss: 0.21310438215732574
Epoch: 141/300 - Train loss: 0.21540750563144684, Validation loss: 0.21218299865722656
Epoch: 142/300 - Train loss: 0.21465107798576355, Validation loss: 0.21136242151260376
Epoch: 143/300 - Train loss: 0.21391144394874573, Validation loss: 0.21117360889911652
Epoch: 144/300 - Train loss: 0.2131880223751068, Validation loss: 0.21018539369106293
Epoch: 145/300 - Train loss: 0.2124803513288498, Validation loss: 0.2093617022037506
Epoch: 146/300 - Train loss: 0.21178801357746124, Validation loss: 0.209112748503685
Epoch: 147/300 - Train loss: 0.2111106514930725, Validation loss: 0.20815613865852356
Epoch: 148/300 - Train loss: 0.2104477733373642, Validation loss: 0.2075417935848236
Epoch: 149/300 - Train loss: 0.20979903638362885, Validation loss: 0.2076725959777832
Epoch: 150/300 - Train loss: 0.20916397869586945, Validation loss: 0.2062319815158844
Epoch: 151/300 - Train loss: 0.20854230225086212, Validation loss: 0.2059003859758377
Epoch: 152/300 - Train loss: 0.20793350040912628, Validation loss: 0.20556598901748657
Epoch: 153/300 - Train loss: 0.2073373645544052, Validation loss: 0.20455431938171387
Epoch: 154/300 - Train loss: 0.20675350725650787, Validation loss: 0.20399191975593567
Epoch: 155/300 - Train loss: 0.20618179440498352, Validation loss: 0.203609436750412
Epoch: 156/300 - Train loss: 0.20562170445919037, Validation loss: 0.20288202166557312
Epoch: 157/300 - Train loss: 0.20507286489009857, Validation loss: 0.20255346596240997
Epoch: 158/300 - Train loss: 0.20453505218029022, Validation loss: 0.20212599635124207
Epoch: 159/300 - Train loss: 0.2040080577135086, Validation loss: 0.2017221599817276
