Epoch: 1/200 - Train loss: 0.5810142755508423, Validation loss: 0.482327401638031
Epoch: 2/200 - Train loss: 0.3970247209072113, Validation loss: 0.36181068420410156
Epoch: 3/200 - Train loss: 0.31964564323425293, Validation loss: 0.3080597519874573
Epoch: 4/200 - Train loss: 0.2754860818386078, Validation loss: 0.2752041220664978
Epoch: 5/200 - Train loss: 0.24298611283302307, Validation loss: 0.25099027156829834
Epoch: 6/200 - Train loss: 0.21977005898952484, Validation loss: 0.2298867255449295
Epoch: 7/200 - Train loss: 0.20295464992523193, Validation loss: 0.21495285630226135
Epoch: 8/200 - Train loss: 0.19006599485874176, Validation loss: 0.20645393431186676
Epoch: 9/200 - Train loss: 0.18010622262954712, Validation loss: 0.20090225338935852
Epoch: 10/200 - Train loss: 0.17439517378807068, Validation loss: 0.19342443346977234
Epoch: 11/200 - Train loss: 0.16799668967723846, Validation loss: 0.18891118466854095
Epoch: 12/200 - Train loss: 0.16259276866912842, Validation loss: 0.18708211183547974
Epoch: 13/200 - Train loss: 0.15666857361793518, Validation loss: 0.19072671234607697
Epoch: 14/200 - Train loss: 0.15618610382080078, Validation loss: 0.1826731562614441
Epoch: 15/200 - Train loss: 0.15259870886802673, Validation loss: 0.18154317140579224
Epoch: 16/200 - Train loss: 0.151852548122406, Validation loss: 0.17606022953987122
Epoch: 17/200 - Train loss: 0.14837174117565155, Validation loss: 0.1758371740579605
Epoch: 18/200 - Train loss: 0.14572307467460632, Validation loss: 0.17372284829616547
Epoch: 19/200 - Train loss: 0.14294244349002838, Validation loss: 0.1721004694700241
Epoch: 20/200 - Train loss: 0.14056028425693512, Validation loss: 0.1706467568874359
Epoch: 21/200 - Train loss: 0.13853251934051514, Validation loss: 0.17113840579986572
Epoch: 22/200 - Train loss: 0.1369314193725586, Validation loss: 0.17375555634498596
Epoch: 23/200 - Train loss: 0.13478457927703857, Validation loss: 0.17374825477600098
Epoch: 24/200 - Train loss: 0.13270574808120728, Validation loss: 0.1677793562412262
Epoch: 25/200 - Train loss: 0.13078594207763672, Validation loss: 0.17254583537578583
Epoch: 26/200 - Train loss: 0.12988758087158203, Validation loss: 0.16847075521945953
Epoch: 27/200 - Train loss: 0.13143257796764374, Validation loss: 0.16967715322971344
Epoch: 28/200 - Train loss: 0.1269148290157318, Validation loss: 0.1679331511259079
Epoch: 29/200 - Train loss: 0.12606678903102875, Validation loss: 0.16678449511528015
Epoch: 30/200 - Train loss: 0.1271076500415802, Validation loss: 0.18095479905605316
Epoch: 31/200 - Train loss: 0.12631258368492126, Validation loss: 0.1795446276664734
Epoch: 32/200 - Train loss: 0.1259170025587082, Validation loss: 0.1793169379234314
Epoch: 33/200 - Train loss: 0.12390697002410889, Validation loss: 0.17918513715267181
Epoch: 34/200 - Train loss: 0.12606173753738403, Validation loss: 0.18153731524944305
Epoch: 35/200 - Train loss: 0.12632444500923157, Validation loss: 0.19022637605667114
Epoch: 36/200 - Train loss: 0.12507767975330353, Validation loss: 0.19078180193901062
Epoch: 37/200 - Train loss: 0.12382642924785614, Validation loss: 0.18882238864898682
Epoch: 38/200 - Train loss: 0.12245677411556244, Validation loss: 0.19342093169689178
Epoch: 39/200 - Train loss: 0.12139812111854553, Validation loss: 0.17866967618465424
Epoch: 40/200 - Train loss: 0.121185801923275, Validation loss: 0.2028559446334839
Epoch: 41/200 - Train loss: 0.12003853172063828, Validation loss: 0.18980470299720764
Epoch: 42/200 - Train loss: 0.12029029428958893, Validation loss: 0.19394616782665253
Epoch: 43/200 - Train loss: 0.11916285008192062, Validation loss: 0.20188750326633453
Epoch: 44/200 - Train loss: 0.11814355850219727, Validation loss: 0.20423486828804016
Epoch: 45/200 - Train loss: 0.11779040098190308, Validation loss: 0.19370542466640472
Epoch: 46/200 - Train loss: 0.11676501482725143, Validation loss: 0.20426233112812042
Epoch: 47/200 - Train loss: 0.11591891199350357, Validation loss: 0.2025030553340912
Epoch: 48/200 - Train loss: 0.11650962382555008, Validation loss: 0.20270171761512756
Epoch: 49/200 - Train loss: 0.11491113156080246, Validation loss: 0.20578788220882416
Epoch: 50/200 - Train loss: 0.11478644609451294, Validation loss: 0.20641116797924042
Epoch: 51/200 - Train loss: 0.11394930630922318, Validation loss: 0.20174726843833923
Epoch: 52/200 - Train loss: 0.11341197788715363, Validation loss: 0.20439165830612183
Epoch: 53/200 - Train loss: 0.11304828524589539, Validation loss: 0.20476935803890228
Epoch: 54/200 - Train loss: 0.11230560392141342, Validation loss: 0.21747420728206635
Epoch: 55/200 - Train loss: 0.11217238008975983, Validation loss: 0.20567749440670013
Epoch: 56/200 - Train loss: 0.11131498962640762, Validation loss: 0.2054509073495865
Epoch: 57/200 - Train loss: 0.11172404885292053, Validation loss: 0.20777830481529236
Epoch: 58/200 - Train loss: 0.11028360575437546, Validation loss: 0.2155013084411621
Epoch: 59/200 - Train loss: 0.10963725298643112, Validation loss: 0.20518070459365845
Epoch: 60/200 - Train loss: 0.10973405092954636, Validation loss: 0.20997190475463867
Epoch: 61/200 - Train loss: 0.10948549956083298, Validation loss: 0.2178877890110016
Epoch: 62/200 - Train loss: 0.11149559915065765, Validation loss: 0.208078995347023
Epoch: 63/200 - Train loss: 0.10854380577802658, Validation loss: 0.22115793824195862
Epoch: 64/200 - Train loss: 0.11066845059394836, Validation loss: 0.221906378865242
Epoch: 65/200 - Train loss: 0.11086667329072952, Validation loss: 0.22280758619308472
Epoch: 66/200 - Train loss: 0.10679420083761215, Validation loss: 0.2329733818769455
Epoch: 67/200 - Train loss: 0.1100517138838768, Validation loss: 0.21150629222393036
Epoch: 68/200 - Train loss: 0.1100570410490036, Validation loss: 0.2218969762325287
Epoch: 69/200 - Train loss: 0.10912353545427322, Validation loss: 0.21297600865364075
Epoch: 70/200 - Train loss: 0.11017001420259476, Validation loss: 0.22113561630249023
Epoch: 71/200 - Train loss: 0.10839445143938065, Validation loss: 0.23572556674480438
Epoch: 72/200 - Train loss: 0.10810595750808716, Validation loss: 0.22289885580539703
Epoch: 73/200 - Train loss: 0.1077481210231781, Validation loss: 0.22228291630744934
Epoch: 74/200 - Train loss: 0.10743565112352371, Validation loss: 0.22390146553516388
Epoch: 75/200 - Train loss: 0.10742776840925217, Validation loss: 0.22349826991558075
Epoch: 76/200 - Train loss: 0.1076633408665657, Validation loss: 0.23257924616336823
Epoch: 77/200 - Train loss: 0.10656245797872543, Validation loss: 0.22297750413417816
Epoch: 78/200 - Train loss: 0.1068001314997673, Validation loss: 0.23614588379859924
Epoch: 79/200 - Train loss: 0.10642669349908829, Validation loss: 0.23820334672927856
Epoch: 80/200 - Train loss: 0.10592948645353317, Validation loss: 0.238568514585495
Epoch: 81/200 - Train loss: 0.10536684840917587, Validation loss: 0.2367045134305954
Epoch: 82/200 - Train loss: 0.10501725226640701, Validation loss: 0.24652481079101562
Epoch: 83/200 - Train loss: 0.10516592115163803, Validation loss: 0.23528093099594116
Epoch: 84/200 - Train loss: 0.10444863140583038, Validation loss: 0.2509377598762512
Epoch: 85/200 - Train loss: 0.10535205900669098, Validation loss: 0.24095089733600616
Epoch: 86/200 - Train loss: 0.10369328409433365, Validation loss: 0.23756057024002075
Epoch: 87/200 - Train loss: 0.10366032272577286, Validation loss: 0.22831973433494568
Epoch: 88/200 - Train loss: 0.10379824787378311, Validation loss: 0.23692089319229126
Epoch: 89/200 - Train loss: 0.10387958586215973, Validation loss: 0.24065086245536804
Epoch: 90/200 - Train loss: 0.10287200659513474, Validation loss: 0.23857763409614563
Epoch: 91/200 - Train loss: 0.10610083490610123, Validation loss: 0.2542590796947479
Epoch: 92/200 - Train loss: 0.10289432853460312, Validation loss: 0.2421092689037323
Epoch: 93/200 - Train loss: 0.10205905139446259, Validation loss: 0.23942439258098602
Epoch: 94/200 - Train loss: 0.10273698717355728, Validation loss: 0.24123314023017883
Epoch: 95/200 - Train loss: 0.10198353976011276, Validation loss: 0.22752408683300018
Epoch: 96/200 - Train loss: 0.10423824936151505, Validation loss: 0.2410067468881607
Epoch: 97/200 - Train loss: 0.10210774093866348, Validation loss: 0.2430548518896103
Epoch: 98/200 - Train loss: 0.10509441047906876, Validation loss: 0.2575165331363678
Epoch: 99/200 - Train loss: 0.10080647468566895, Validation loss: 0.25351011753082275
Epoch: 100/200 - Train loss: 0.1033824160695076, Validation loss: 0.255569189786911
Epoch: 101/200 - Train loss: 0.10031720250844955, Validation loss: 0.23131753504276276
Epoch: 102/200 - Train loss: 0.10004441440105438, Validation loss: 0.26000458002090454
Epoch: 103/200 - Train loss: 0.10314534604549408, Validation loss: 0.25356072187423706
Epoch: 104/200 - Train loss: 0.10062727332115173, Validation loss: 0.2563961148262024
Epoch: 105/200 - Train loss: 0.09947691112756729, Validation loss: 0.241703063249588
Epoch: 106/200 - Train loss: 0.10018154978752136, Validation loss: 0.2596322000026703
Epoch: 107/200 - Train loss: 0.10202278196811676, Validation loss: 0.2439737170934677
Epoch: 108/200 - Train loss: 0.10223926603794098, Validation loss: 0.26113519072532654
Epoch: 109/200 - Train loss: 0.09847559034824371, Validation loss: 0.25710928440093994
Epoch: 110/200 - Train loss: 0.101004458963871, Validation loss: 0.2589750289916992
Epoch: 111/200 - Train loss: 0.09825873374938965, Validation loss: 0.2596432864665985
Epoch: 112/200 - Train loss: 0.10128132253885269, Validation loss: 0.25630730390548706
Epoch: 113/200 - Train loss: 0.10139992088079453, Validation loss: 0.2556118369102478
Epoch: 114/200 - Train loss: 0.09839364141225815, Validation loss: 0.2662210762500763
Epoch: 115/200 - Train loss: 0.09924538433551788, Validation loss: 0.25890737771987915
Epoch: 116/200 - Train loss: 0.09791669994592667, Validation loss: 0.25631093978881836
Epoch: 117/200 - Train loss: 0.09674768894910812, Validation loss: 0.26088014245033264
Epoch: 118/200 - Train loss: 0.09669724851846695, Validation loss: 0.2466817945241928
Epoch: 119/200 - Train loss: 0.10070456564426422, Validation loss: 0.2596176564693451
Epoch: 120/200 - Train loss: 0.09950718283653259, Validation loss: 0.27112025022506714
Epoch: 121/200 - Train loss: 0.09675273299217224, Validation loss: 0.2567683756351471
Epoch: 122/200 - Train loss: 0.09661607444286346, Validation loss: 0.26354196667671204
Epoch: 123/200 - Train loss: 0.10003754496574402, Validation loss: 0.2589826285839081
Epoch: 124/200 - Train loss: 0.0962211936712265, Validation loss: 0.26301977038383484
Epoch: 125/200 - Train loss: 0.09889020025730133, Validation loss: 0.2617442309856415
Epoch: 126/200 - Train loss: 0.09937348961830139, Validation loss: 0.26031410694122314
Epoch: 127/200 - Train loss: 0.09860195964574814, Validation loss: 0.26416587829589844
Epoch: 128/200 - Train loss: 0.09863226860761642, Validation loss: 0.26477864384651184
Epoch: 129/200 - Train loss: 0.09844405949115753, Validation loss: 0.2736078202724457
Epoch: 130/200 - Train loss: 0.09791236370801926, Validation loss: 0.26462721824645996
Epoch: 131/200 - Train loss: 0.0979824960231781, Validation loss: 0.28095707297325134
Epoch: 132/200 - Train loss: 0.09830423444509506, Validation loss: 0.26599323749542236
Epoch: 133/200 - Train loss: 0.09755339473485947, Validation loss: 0.2649490237236023
Epoch: 134/200 - Train loss: 0.09712743759155273, Validation loss: 0.25406208634376526
Epoch: 135/200 - Train loss: 0.09761348366737366, Validation loss: 0.26954472064971924
Epoch: 136/200 - Train loss: 0.0970652773976326, Validation loss: 0.2670782506465912
Epoch: 137/200 - Train loss: 0.0967874825000763, Validation loss: 0.2638857662677765
Epoch: 138/200 - Train loss: 0.09703881293535233, Validation loss: 0.2698113024234772
Epoch: 139/200 - Train loss: 0.09700179845094681, Validation loss: 0.265061616897583
Epoch: 140/200 - Train loss: 0.09753037989139557, Validation loss: 0.26870661973953247
Epoch: 141/200 - Train loss: 0.09610501676797867, Validation loss: 0.26980865001678467
Epoch: 142/200 - Train loss: 0.09930677711963654, Validation loss: 0.26842331886291504
Epoch: 143/200 - Train loss: 0.09612687677145004, Validation loss: 0.26445481181144714
Epoch: 144/200 - Train loss: 0.09991049766540527, Validation loss: 0.26873645186424255
Epoch: 145/200 - Train loss: 0.09935274720191956, Validation loss: 0.26684924960136414
Epoch: 146/200 - Train loss: 0.09875377267599106, Validation loss: 0.26949211955070496
Epoch: 147/200 - Train loss: 0.09568459540605545, Validation loss: 0.2695613205432892
Epoch: 148/200 - Train loss: 0.09538037329912186, Validation loss: 0.2801066040992737
Epoch: 149/200 - Train loss: 0.09885938465595245, Validation loss: 0.27217385172843933
Epoch: 150/200 - Train loss: 0.09591531753540039, Validation loss: 0.27880656719207764
Epoch: 151/200 - Train loss: 0.09530699253082275, Validation loss: 0.2710093855857849
Epoch: 152/200 - Train loss: 0.09554989635944366, Validation loss: 0.27151286602020264
Epoch: 153/200 - Train loss: 0.09505382925271988, Validation loss: 0.2727154791355133
Epoch: 154/200 - Train loss: 0.09909418970346451, Validation loss: 0.27054068446159363
Epoch: 155/200 - Train loss: 0.09770228713750839, Validation loss: 0.2733590602874756
Epoch: 156/200 - Train loss: 0.094410739839077, Validation loss: 0.2731437087059021
Epoch: 157/200 - Train loss: 0.09435980767011642, Validation loss: 0.27352240681648254
Epoch: 158/200 - Train loss: 0.09474692493677139, Validation loss: 0.2715646028518677
Epoch: 159/200 - Train loss: 0.09797301143407822, Validation loss: 0.2737957835197449
Epoch: 160/200 - Train loss: 0.0935756266117096, Validation loss: 0.27351588010787964
