Epoch: 1/300 - Train loss: 0.7017372846603394, Validation loss: 0.6978055834770203
Epoch: 2/300 - Train loss: 0.6997352242469788, Validation loss: 0.6959498524665833
Epoch: 3/300 - Train loss: 0.6977802515029907, Validation loss: 0.6943200826644897
Epoch: 4/300 - Train loss: 0.6958725452423096, Validation loss: 0.6924660205841064
Epoch: 5/300 - Train loss: 0.6939972043037415, Validation loss: 0.6906686425209045
Epoch: 6/300 - Train loss: 0.6921499371528625, Validation loss: 0.6890755891799927
Epoch: 7/300 - Train loss: 0.6903266310691833, Validation loss: 0.687341034412384
Epoch: 8/300 - Train loss: 0.6885080933570862, Validation loss: 0.685593843460083
Epoch: 9/300 - Train loss: 0.6866859197616577, Validation loss: 0.6839973330497742
Epoch: 10/300 - Train loss: 0.6848482489585876, Validation loss: 0.6820902228355408
Epoch: 11/300 - Train loss: 0.6829908490180969, Validation loss: 0.6803598999977112
Epoch: 12/300 - Train loss: 0.6811032891273499, Validation loss: 0.6785079836845398
Epoch: 13/300 - Train loss: 0.6791813373565674, Validation loss: 0.676600456237793
Epoch: 14/300 - Train loss: 0.6772186756134033, Validation loss: 0.6746426820755005
Epoch: 15/300 - Train loss: 0.6752181649208069, Validation loss: 0.6726343035697937
Epoch: 16/300 - Train loss: 0.6731731295585632, Validation loss: 0.670554518699646
Epoch: 17/300 - Train loss: 0.6710882782936096, Validation loss: 0.6685428619384766
Epoch: 18/300 - Train loss: 0.668968677520752, Validation loss: 0.6663356423377991
Epoch: 19/300 - Train loss: 0.6668082475662231, Validation loss: 0.6640723943710327
Epoch: 20/300 - Train loss: 0.6646115779876709, Validation loss: 0.6618121862411499
Epoch: 21/300 - Train loss: 0.6623837351799011, Validation loss: 0.6595584750175476
Epoch: 22/300 - Train loss: 0.6601284146308899, Validation loss: 0.6572266817092896
Epoch: 23/300 - Train loss: 0.6578521728515625, Validation loss: 0.6549842953681946
Epoch: 24/300 - Train loss: 0.6555583477020264, Validation loss: 0.652564525604248
Epoch: 25/300 - Train loss: 0.6532506942749023, Validation loss: 0.6501332521438599
Epoch: 26/300 - Train loss: 0.6509297490119934, Validation loss: 0.6477535367012024
Epoch: 27/300 - Train loss: 0.6485976576805115, Validation loss: 0.6454161405563354
Epoch: 28/300 - Train loss: 0.6462553143501282, Validation loss: 0.6431173086166382
Epoch: 29/300 - Train loss: 0.6439031362533569, Validation loss: 0.6406747102737427
Epoch: 30/300 - Train loss: 0.6415398716926575, Validation loss: 0.6383183002471924
Epoch: 31/300 - Train loss: 0.6391656994819641, Validation loss: 0.6357729434967041
Epoch: 32/300 - Train loss: 0.6367796659469604, Validation loss: 0.6334385871887207
Epoch: 33/300 - Train loss: 0.6343827843666077, Validation loss: 0.631123423576355
Epoch: 34/300 - Train loss: 0.6319762468338013, Validation loss: 0.6287723779678345
Epoch: 35/300 - Train loss: 0.6295597553253174, Validation loss: 0.6263800859451294
Epoch: 36/300 - Train loss: 0.6271373629570007, Validation loss: 0.6236072778701782
Epoch: 37/300 - Train loss: 0.624711811542511, Validation loss: 0.6211429834365845
Epoch: 38/300 - Train loss: 0.6222857236862183, Validation loss: 0.6188605427742004
Epoch: 39/300 - Train loss: 0.6198621988296509, Validation loss: 0.6165506839752197
Epoch: 40/300 - Train loss: 0.617442786693573, Validation loss: 0.6141817569732666
Epoch: 41/300 - Train loss: 0.6150309443473816, Validation loss: 0.6117369532585144
Epoch: 42/300 - Train loss: 0.6126298904418945, Validation loss: 0.6095775365829468
Epoch: 43/300 - Train loss: 0.610241174697876, Validation loss: 0.6071186661720276
Epoch: 44/300 - Train loss: 0.6078659296035767, Validation loss: 0.6045063734054565
Epoch: 45/300 - Train loss: 0.6055065989494324, Validation loss: 0.6021658778190613
Epoch: 46/300 - Train loss: 0.603164553642273, Validation loss: 0.6000981330871582
Epoch: 47/300 - Train loss: 0.6008415818214417, Validation loss: 0.5977979302406311
Epoch: 48/300 - Train loss: 0.5985397100448608, Validation loss: 0.5956050753593445
Epoch: 49/300 - Train loss: 0.5962607860565186, Validation loss: 0.593401312828064
Epoch: 50/300 - Train loss: 0.5940066576004028, Validation loss: 0.5914714336395264
Epoch: 51/300 - Train loss: 0.5917781591415405, Validation loss: 0.5892536640167236
Epoch: 52/300 - Train loss: 0.589576780796051, Validation loss: 0.5871877670288086
Epoch: 53/300 - Train loss: 0.5874031782150269, Validation loss: 0.5848712921142578
Epoch: 54/300 - Train loss: 0.585257887840271, Validation loss: 0.5828246474266052
Epoch: 55/300 - Train loss: 0.5831421613693237, Validation loss: 0.5806094408035278
Epoch: 56/300 - Train loss: 0.5810571312904358, Validation loss: 0.5787778496742249
Epoch: 57/300 - Train loss: 0.5790035128593445, Validation loss: 0.5771144032478333
Epoch: 58/300 - Train loss: 0.5769819617271423, Validation loss: 0.5750567317008972
Epoch: 59/300 - Train loss: 0.5749931335449219, Validation loss: 0.5734070539474487
Epoch: 60/300 - Train loss: 0.5730372667312622, Validation loss: 0.5709370970726013
Epoch: 61/300 - Train loss: 0.5711143016815186, Validation loss: 0.5693392753601074
Epoch: 62/300 - Train loss: 0.569225013256073, Validation loss: 0.5676688551902771
Epoch: 63/300 - Train loss: 0.5673699378967285, Validation loss: 0.5656861066818237
Epoch: 64/300 - Train loss: 0.5655486583709717, Validation loss: 0.5641674399375916
Epoch: 65/300 - Train loss: 0.5637614130973816, Validation loss: 0.5624454021453857
Epoch: 66/300 - Train loss: 0.5620074272155762, Validation loss: 0.5609330534934998
Epoch: 67/300 - Train loss: 0.5602868795394897, Validation loss: 0.5592804551124573
Epoch: 68/300 - Train loss: 0.5585991740226746, Validation loss: 0.5579736828804016
Epoch: 69/300 - Train loss: 0.5569440126419067, Validation loss: 0.5564664602279663
Epoch: 70/300 - Train loss: 0.5553207397460938, Validation loss: 0.5551130771636963
Epoch: 71/300 - Train loss: 0.5537284016609192, Validation loss: 0.5537378191947937
Epoch: 72/300 - Train loss: 0.5521666407585144, Validation loss: 0.5522715449333191
Epoch: 73/300 - Train loss: 0.5506348013877869, Validation loss: 0.5506750345230103
Epoch: 74/300 - Train loss: 0.5491318106651306, Validation loss: 0.5494138598442078
Epoch: 75/300 - Train loss: 0.5476567149162292, Validation loss: 0.5482476353645325
Epoch: 76/300 - Train loss: 0.5462090373039246, Validation loss: 0.5467325448989868
Epoch: 77/300 - Train loss: 0.5447874665260315, Validation loss: 0.5454883575439453
Epoch: 78/300 - Train loss: 0.5433906316757202, Validation loss: 0.5444790124893188
Epoch: 79/300 - Train loss: 0.542017936706543, Validation loss: 0.5428140759468079
Epoch: 80/300 - Train loss: 0.5406690835952759, Validation loss: 0.5429500341415405
Epoch: 81/300 - Train loss: 0.5393437147140503, Validation loss: 0.5406178832054138
Epoch: 82/300 - Train loss: 0.5380401015281677, Validation loss: 0.5394248962402344
Epoch: 83/300 - Train loss: 0.53675776720047, Validation loss: 0.5385938882827759
Epoch: 84/300 - Train loss: 0.5354957580566406, Validation loss: 0.5370763540267944
Epoch: 85/300 - Train loss: 0.5342530012130737, Validation loss: 0.5364277362823486
Epoch: 86/300 - Train loss: 0.5330288410186768, Validation loss: 0.5343958735466003
Epoch: 87/300 - Train loss: 0.5318225622177124, Validation loss: 0.534170389175415
Epoch: 88/300 - Train loss: 0.5306335091590881, Validation loss: 0.5331600904464722
Epoch: 89/300 - Train loss: 0.529460608959198, Validation loss: 0.5319528579711914
Epoch: 90/300 - Train loss: 0.5283035039901733, Validation loss: 0.5310277938842773
Epoch: 91/300 - Train loss: 0.5271613597869873, Validation loss: 0.5302378535270691
Epoch: 92/300 - Train loss: 0.5260327458381653, Validation loss: 0.5283893346786499
Epoch: 93/300 - Train loss: 0.5249178409576416, Validation loss: 0.5277723073959351
Epoch: 94/300 - Train loss: 0.5238167643547058, Validation loss: 0.526439905166626
Epoch: 95/300 - Train loss: 0.5227292776107788, Validation loss: 0.5260075330734253
Epoch: 96/300 - Train loss: 0.5216551423072815, Validation loss: 0.524285078048706
Epoch: 97/300 - Train loss: 0.5205927491188049, Validation loss: 0.5240297317504883
Epoch: 98/300 - Train loss: 0.5195411443710327, Validation loss: 0.5229228734970093
Epoch: 99/300 - Train loss: 0.5184997320175171, Validation loss: 0.5226989388465881
Epoch: 100/300 - Train loss: 0.5174688100814819, Validation loss: 0.5216131806373596
Epoch: 101/300 - Train loss: 0.5164476633071899, Validation loss: 0.5202211141586304
Epoch: 102/300 - Train loss: 0.5154366493225098, Validation loss: 0.5193654894828796
Epoch: 103/300 - Train loss: 0.5144351124763489, Validation loss: 0.5186023712158203
Epoch: 104/300 - Train loss: 0.513441801071167, Validation loss: 0.5178476572036743
Epoch: 105/300 - Train loss: 0.5124565362930298, Validation loss: 0.5167948603630066
Epoch: 106/300 - Train loss: 0.5114796161651611, Validation loss: 0.5157407522201538
Epoch: 107/300 - Train loss: 0.5105105638504028, Validation loss: 0.5149868130683899
Epoch: 108/300 - Train loss: 0.5095494985580444, Validation loss: 0.5139964818954468
Epoch: 109/300 - Train loss: 0.5085963606834412, Validation loss: 0.5132833123207092
Epoch: 110/300 - Train loss: 0.5076500773429871, Validation loss: 0.5123624801635742
Epoch: 111/300 - Train loss: 0.5067116618156433, Validation loss: 0.5118998289108276
Epoch: 112/300 - Train loss: 0.5057801604270935, Validation loss: 0.5108917355537415
Epoch: 113/300 - Train loss: 0.5048556327819824, Validation loss: 0.510021984577179
Epoch: 114/300 - Train loss: 0.5039373636245728, Validation loss: 0.5088537931442261
Epoch: 115/300 - Train loss: 0.5030250549316406, Validation loss: 0.5084398984909058
Epoch: 116/300 - Train loss: 0.5021188855171204, Validation loss: 0.5077874064445496
Epoch: 117/300 - Train loss: 0.5012191534042358, Validation loss: 0.5066600441932678
Epoch: 118/300 - Train loss: 0.5003253817558289, Validation loss: 0.5065285563468933
Epoch: 119/300 - Train loss: 0.49943703413009644, Validation loss: 0.5050418376922607
Epoch: 120/300 - Train loss: 0.4985550343990326, Validation loss: 0.504289448261261
Epoch: 121/300 - Train loss: 0.4976781904697418, Validation loss: 0.5033941268920898
Epoch: 122/300 - Train loss: 0.4968063533306122, Validation loss: 0.5020855069160461
Epoch: 123/300 - Train loss: 0.4959392845630646, Validation loss: 0.5015829205513
Epoch: 124/300 - Train loss: 0.4950771927833557, Validation loss: 0.5008667707443237
Epoch: 125/300 - Train loss: 0.4942203164100647, Validation loss: 0.5006592273712158
Epoch: 126/300 - Train loss: 0.4933689534664154, Validation loss: 0.49919912219047546
Epoch: 127/300 - Train loss: 0.4925224483013153, Validation loss: 0.49889910221099854
Epoch: 128/300 - Train loss: 0.4916805624961853, Validation loss: 0.4981447756290436
Epoch: 129/300 - Train loss: 0.490843266248703, Validation loss: 0.4975937604904175
Epoch: 130/300 - Train loss: 0.4900113344192505, Validation loss: 0.4964950680732727
Epoch: 131/300 - Train loss: 0.4891839325428009, Validation loss: 0.4950281083583832
Epoch: 132/300 - Train loss: 0.488360732793808, Validation loss: 0.49544498324394226
Epoch: 133/300 - Train loss: 0.4875420928001404, Validation loss: 0.4940554201602936
Epoch: 134/300 - Train loss: 0.486727774143219, Validation loss: 0.49339476227760315
Epoch: 135/300 - Train loss: 0.4859176278114319, Validation loss: 0.4922965168952942
Epoch: 136/300 - Train loss: 0.4851112365722656, Validation loss: 0.49154236912727356
Epoch: 137/300 - Train loss: 0.48430925607681274, Validation loss: 0.4915963411331177
Epoch: 138/300 - Train loss: 0.48351162672042847, Validation loss: 0.4902910888195038
Epoch: 139/300 - Train loss: 0.48271816968917847, Validation loss: 0.4894464612007141
Epoch: 140/300 - Train loss: 0.4819294214248657, Validation loss: 0.48815232515335083
Epoch: 141/300 - Train loss: 0.48114535212516785, Validation loss: 0.4880122244358063
Epoch: 142/300 - Train loss: 0.48036518692970276, Validation loss: 0.48740342259407043
Epoch: 143/300 - Train loss: 0.4795897901058197, Validation loss: 0.48594367504119873
Epoch: 144/300 - Train loss: 0.4788186848163605, Validation loss: 0.48595473170280457
Epoch: 145/300 - Train loss: 0.4780511260032654, Validation loss: 0.4851508140563965
Epoch: 146/300 - Train loss: 0.47728776931762695, Validation loss: 0.4841421842575073
Epoch: 147/300 - Train loss: 0.47652825713157654, Validation loss: 0.48410776257514954
Epoch: 148/300 - Train loss: 0.4757729470729828, Validation loss: 0.4829925298690796
Epoch: 149/300 - Train loss: 0.47502243518829346, Validation loss: 0.4827212393283844
Epoch: 150/300 - Train loss: 0.4742755889892578, Validation loss: 0.48178353905677795
Epoch: 151/300 - Train loss: 0.4735337495803833, Validation loss: 0.4804849624633789
Epoch: 152/300 - Train loss: 0.4727969467639923, Validation loss: 0.48014041781425476
Epoch: 153/300 - Train loss: 0.47206494212150574, Validation loss: 0.4797143340110779
Epoch: 154/300 - Train loss: 0.4713367819786072, Validation loss: 0.4786480963230133
Epoch: 155/300 - Train loss: 0.47061264514923096, Validation loss: 0.4790046811103821
Epoch: 156/300 - Train loss: 0.46989190578460693, Validation loss: 0.4774359464645386
Epoch: 157/300 - Train loss: 0.4691758155822754, Validation loss: 0.476298063993454
Epoch: 158/300 - Train loss: 0.4684639573097229, Validation loss: 0.47657549381256104
Epoch: 159/300 - Train loss: 0.4677564203739166, Validation loss: 0.4752900004386902
Epoch: 160/300 - Train loss: 0.4670534133911133, Validation loss: 0.4752115309238434
Epoch: 161/300 - Train loss: 0.4663550853729248, Validation loss: 0.4740331768989563
Epoch: 162/300 - Train loss: 0.46566078066825867, Validation loss: 0.47397562861442566
Epoch: 163/300 - Train loss: 0.4649713337421417, Validation loss: 0.4734005630016327
Epoch: 164/300 - Train loss: 0.46428632736206055, Validation loss: 0.4731680750846863
Epoch: 165/300 - Train loss: 0.4636058509349823, Validation loss: 0.47133901715278625
Epoch: 166/300 - Train loss: 0.4629291296005249, Validation loss: 0.47090089321136475
Epoch: 167/300 - Train loss: 0.46225661039352417, Validation loss: 0.47122424840927124
Epoch: 168/300 - Train loss: 0.461588591337204, Validation loss: 0.4701060354709625
Epoch: 169/300 - Train loss: 0.46092426776885986, Validation loss: 0.46983784437179565
Epoch: 170/300 - Train loss: 0.46026313304901123, Validation loss: 0.4686700105667114
Epoch: 171/300 - Train loss: 0.45960599184036255, Validation loss: 0.46795162558555603
Epoch: 172/300 - Train loss: 0.4589524269104004, Validation loss: 0.468350350856781
Epoch: 173/300 - Train loss: 0.4583026170730591, Validation loss: 0.46656954288482666
Epoch: 174/300 - Train loss: 0.45765626430511475, Validation loss: 0.46583497524261475
Epoch: 175/300 - Train loss: 0.4570138156414032, Validation loss: 0.4652964770793915
Epoch: 176/300 - Train loss: 0.4563749432563782, Validation loss: 0.465492844581604
Epoch: 177/300 - Train loss: 0.4557400047779083, Validation loss: 0.4647974669933319
Epoch: 178/300 - Train loss: 0.4551088809967041, Validation loss: 0.4635739028453827
Epoch: 179/300 - Train loss: 0.45448052883148193, Validation loss: 0.462874174118042
Epoch: 180/300 - Train loss: 0.4538556933403015, Validation loss: 0.46283602714538574
Epoch: 181/300 - Train loss: 0.4532344341278076, Validation loss: 0.4624108672142029
Epoch: 182/300 - Train loss: 0.45261603593826294, Validation loss: 0.4620170593261719
