Epoch: 1/100 - Train loss: 0.7056008577346802, Validation loss: 0.7000842690467834
Epoch: 2/100 - Train loss: 0.7021655440330505, Validation loss: 0.6969448328018188
Epoch: 3/100 - Train loss: 0.6988669633865356, Validation loss: 0.6939898133277893
Epoch: 4/100 - Train loss: 0.6956959366798401, Validation loss: 0.6911203265190125
Epoch: 5/100 - Train loss: 0.6926282644271851, Validation loss: 0.6882117390632629
Epoch: 6/100 - Train loss: 0.6896260976791382, Validation loss: 0.685516893863678
Epoch: 7/100 - Train loss: 0.68666011095047, Validation loss: 0.6825871467590332
Epoch: 8/100 - Train loss: 0.6836980581283569, Validation loss: 0.6795867085456848
Epoch: 9/100 - Train loss: 0.6807036995887756, Validation loss: 0.6765952706336975
Epoch: 10/100 - Train loss: 0.6776471138000488, Validation loss: 0.6735641956329346
Epoch: 11/100 - Train loss: 0.6745100021362305, Validation loss: 0.6703991889953613
Epoch: 12/100 - Train loss: 0.6712781190872192, Validation loss: 0.6673731207847595
Epoch: 13/100 - Train loss: 0.6679402589797974, Validation loss: 0.663885235786438
Epoch: 14/100 - Train loss: 0.6644884943962097, Validation loss: 0.6603831648826599
Epoch: 15/100 - Train loss: 0.6609246134757996, Validation loss: 0.6568252444267273
Epoch: 16/100 - Train loss: 0.6572508215904236, Validation loss: 0.6531334519386292
Epoch: 17/100 - Train loss: 0.6534696817398071, Validation loss: 0.6494088768959045
Epoch: 18/100 - Train loss: 0.6495943069458008, Validation loss: 0.6457530856132507
Epoch: 19/100 - Train loss: 0.6456301212310791, Validation loss: 0.6416643857955933
Epoch: 20/100 - Train loss: 0.6415843963623047, Validation loss: 0.6376322507858276
Epoch: 21/100 - Train loss: 0.6374645233154297, Validation loss: 0.633615255355835
Epoch: 22/100 - Train loss: 0.6332776546478271, Validation loss: 0.6292464137077332
Epoch: 23/100 - Train loss: 0.6290284991264343, Validation loss: 0.6251263618469238
Epoch: 24/100 - Train loss: 0.6247215270996094, Validation loss: 0.6209487318992615
Epoch: 25/100 - Train loss: 0.6203643679618835, Validation loss: 0.6166293025016785
Epoch: 26/100 - Train loss: 0.6159568428993225, Validation loss: 0.6122757196426392
Epoch: 27/100 - Train loss: 0.6115018129348755, Validation loss: 0.6076900362968445
Epoch: 28/100 - Train loss: 0.6070030331611633, Validation loss: 0.6032558679580688
Epoch: 29/100 - Train loss: 0.602470874786377, Validation loss: 0.5987016558647156
Epoch: 30/100 - Train loss: 0.5979101061820984, Validation loss: 0.5943825840950012
Epoch: 31/100 - Train loss: 0.5933272242546082, Validation loss: 0.5899491906166077
Epoch: 32/100 - Train loss: 0.5887315273284912, Validation loss: 0.585457444190979
Epoch: 33/100 - Train loss: 0.584132730960846, Validation loss: 0.5809668898582458
Epoch: 34/100 - Train loss: 0.5795345902442932, Validation loss: 0.5762218832969666
Epoch: 35/100 - Train loss: 0.5749479532241821, Validation loss: 0.5720933079719543
Epoch: 36/100 - Train loss: 0.5703777074813843, Validation loss: 0.5673654079437256
Epoch: 37/100 - Train loss: 0.5658248662948608, Validation loss: 0.5628362894058228
Epoch: 38/100 - Train loss: 0.5612913966178894, Validation loss: 0.5585355162620544
Epoch: 39/100 - Train loss: 0.5567788481712341, Validation loss: 0.553867518901825
Epoch: 40/100 - Train loss: 0.5522897243499756, Validation loss: 0.5494942665100098
Epoch: 41/100 - Train loss: 0.5478253364562988, Validation loss: 0.5450226068496704
Epoch: 42/100 - Train loss: 0.5433912873268127, Validation loss: 0.5405164957046509
Epoch: 43/100 - Train loss: 0.5389929413795471, Validation loss: 0.5362114310264587
Epoch: 44/100 - Train loss: 0.5346360206604004, Validation loss: 0.5322055220603943
Epoch: 45/100 - Train loss: 0.5303257703781128, Validation loss: 0.5278284549713135
Epoch: 46/100 - Train loss: 0.526067852973938, Validation loss: 0.5236388444900513
Epoch: 47/100 - Train loss: 0.5218662619590759, Validation loss: 0.5193542838096619
Epoch: 48/100 - Train loss: 0.5177242755889893, Validation loss: 0.5153434872627258
Epoch: 49/100 - Train loss: 0.5136448740959167, Validation loss: 0.5112094879150391
Epoch: 50/100 - Train loss: 0.5096304416656494, Validation loss: 0.5077356696128845
Epoch: 51/100 - Train loss: 0.5056825876235962, Validation loss: 0.5035730600357056
Epoch: 52/100 - Train loss: 0.5018025040626526, Validation loss: 0.4999355971813202
Epoch: 53/100 - Train loss: 0.497991144657135, Validation loss: 0.49632319808006287
Epoch: 54/100 - Train loss: 0.49424925446510315, Validation loss: 0.492301344871521
Epoch: 55/100 - Train loss: 0.49057823419570923, Validation loss: 0.4891790449619293
Epoch: 56/100 - Train loss: 0.4869791567325592, Validation loss: 0.48521333932876587
Epoch: 57/100 - Train loss: 0.48345276713371277, Validation loss: 0.4814651608467102
Epoch: 58/100 - Train loss: 0.47999998927116394, Validation loss: 0.47813868522644043
Epoch: 59/100 - Train loss: 0.4766220152378082, Validation loss: 0.4752008318901062
Epoch: 60/100 - Train loss: 0.4733193814754486, Validation loss: 0.4723835289478302
Epoch: 61/100 - Train loss: 0.47009262442588806, Validation loss: 0.46864810585975647
Epoch: 62/100 - Train loss: 0.4669414758682251, Validation loss: 0.46563056111335754
Epoch: 63/100 - Train loss: 0.46386638283729553, Validation loss: 0.46191543340682983
Epoch: 64/100 - Train loss: 0.4608670175075531, Validation loss: 0.4594612419605255
Epoch: 65/100 - Train loss: 0.45794281363487244, Validation loss: 0.4563738703727722
Epoch: 66/100 - Train loss: 0.4550933539867401, Validation loss: 0.45307767391204834
Epoch: 67/100 - Train loss: 0.45231786370277405, Validation loss: 0.45044222474098206
Epoch: 68/100 - Train loss: 0.449615478515625, Validation loss: 0.4480762183666229
Epoch: 69/100 - Train loss: 0.4469849467277527, Validation loss: 0.44561710953712463
Epoch: 70/100 - Train loss: 0.44442591071128845, Validation loss: 0.44303667545318604
Epoch: 71/100 - Train loss: 0.4419373571872711, Validation loss: 0.44083505868911743
Epoch: 72/100 - Train loss: 0.4395173490047455, Validation loss: 0.4381808340549469
Epoch: 73/100 - Train loss: 0.43716463446617126, Validation loss: 0.43579593300819397
Epoch: 74/100 - Train loss: 0.4348776638507843, Validation loss: 0.433505117893219
Epoch: 75/100 - Train loss: 0.4326554238796234, Validation loss: 0.43087196350097656
Epoch: 76/100 - Train loss: 0.4304955005645752, Validation loss: 0.4290986955165863
Epoch: 77/100 - Train loss: 0.42839664220809937, Validation loss: 0.4273379445075989
Epoch: 78/100 - Train loss: 0.42635688185691833, Validation loss: 0.42477530241012573
Epoch: 79/100 - Train loss: 0.4243745803833008, Validation loss: 0.4232942461967468
Epoch: 80/100 - Train loss: 0.42244842648506165, Validation loss: 0.4210274815559387
Epoch: 81/100 - Train loss: 0.42057666182518005, Validation loss: 0.4190733730792999
Epoch: 82/100 - Train loss: 0.41875743865966797, Validation loss: 0.4176699221134186
Epoch: 83/100 - Train loss: 0.41698959469795227, Validation loss: 0.4154413640499115
Epoch: 84/100 - Train loss: 0.41527122259140015, Validation loss: 0.41397207975387573
Epoch: 85/100 - Train loss: 0.4136010706424713, Validation loss: 0.4123528003692627
Epoch: 86/100 - Train loss: 0.41197705268859863, Validation loss: 0.4105685353279114
Epoch: 87/100 - Train loss: 0.41039764881134033, Validation loss: 0.40901464223861694
Epoch: 88/100 - Train loss: 0.4088619649410248, Validation loss: 0.40708377957344055
Epoch: 89/100 - Train loss: 0.40736833214759827, Validation loss: 0.40638142824172974
Epoch: 90/100 - Train loss: 0.4059135615825653, Validation loss: 0.4048098623752594
Epoch: 91/100 - Train loss: 0.40449753403663635, Validation loss: 0.4032125473022461
Epoch: 92/100 - Train loss: 0.4031185805797577, Validation loss: 0.4016125798225403
Epoch: 93/100 - Train loss: 0.401774525642395, Validation loss: 0.40084195137023926
Epoch: 94/100 - Train loss: 0.4004635214805603, Validation loss: 0.39968934655189514
Epoch: 95/100 - Train loss: 0.39918452501296997, Validation loss: 0.3985188901424408
Epoch: 96/100 - Train loss: 0.3979370594024658, Validation loss: 0.39630797505378723
Epoch: 97/100 - Train loss: 0.3967183828353882, Validation loss: 0.39520183205604553
Epoch: 98/100 - Train loss: 0.39552709460258484, Validation loss: 0.39472800493240356
Epoch: 99/100 - Train loss: 0.3943637013435364, Validation loss: 0.39271804690361023
Epoch: 100/100 - Train loss: 0.3932262361049652, Validation loss: 0.39167913794517517
Epoch: 1/300 - Train loss: 0.6944128274917603, Validation loss: 0.6915443539619446
Epoch: 2/300 - Train loss: 0.6924939155578613, Validation loss: 0.6895949244499207
Epoch: 3/300 - Train loss: 0.6905111074447632, Validation loss: 0.6876832246780396
Epoch: 4/300 - Train loss: 0.6884350180625916, Validation loss: 0.6855165958404541
Epoch: 5/300 - Train loss: 0.6862430572509766, Validation loss: 0.6834094524383545
Epoch: 6/300 - Train loss: 0.6839256286621094, Validation loss: 0.6809980869293213
Epoch: 7/300 - Train loss: 0.6814793944358826, Validation loss: 0.6785652041435242
Epoch: 8/300 - Train loss: 0.6789000630378723, Validation loss: 0.6759374141693115
Epoch: 9/300 - Train loss: 0.6761878728866577, Validation loss: 0.6732608675956726
Epoch: 10/300 - Train loss: 0.6733459234237671, Validation loss: 0.6703392267227173
Epoch: 11/300 - Train loss: 0.6703792214393616, Validation loss: 0.6673986315727234
Epoch: 12/300 - Train loss: 0.6672903299331665, Validation loss: 0.6643745303153992
Epoch: 13/300 - Train loss: 0.6640816330909729, Validation loss: 0.6611339449882507
Epoch: 14/300 - Train loss: 0.6607586741447449, Validation loss: 0.6577981114387512
Epoch: 15/300 - Train loss: 0.6573264002799988, Validation loss: 0.6545082926750183
Epoch: 16/300 - Train loss: 0.6537965536117554, Validation loss: 0.6509327292442322
Epoch: 17/300 - Train loss: 0.6501758098602295, Validation loss: 0.6473763585090637
Epoch: 18/300 - Train loss: 0.6464799642562866, Validation loss: 0.6437901258468628
Epoch: 19/300 - Train loss: 0.6427122950553894, Validation loss: 0.640030026435852
Epoch: 20/300 - Train loss: 0.6388788819313049, Validation loss: 0.636318564414978
Epoch: 21/300 - Train loss: 0.6349862217903137, Validation loss: 0.6324004530906677
Epoch: 22/300 - Train loss: 0.6310409307479858, Validation loss: 0.628372311592102
Epoch: 23/300 - Train loss: 0.6270443201065063, Validation loss: 0.6243756413459778
Epoch: 24/300 - Train loss: 0.6230003833770752, Validation loss: 0.6205527782440186
Epoch: 25/300 - Train loss: 0.6189131140708923, Validation loss: 0.6166415810585022
Epoch: 26/300 - Train loss: 0.6147893667221069, Validation loss: 0.6124506592750549
Epoch: 27/300 - Train loss: 0.6106328964233398, Validation loss: 0.6084029674530029
Epoch: 28/300 - Train loss: 0.6064496636390686, Validation loss: 0.6041710376739502
Epoch: 29/300 - Train loss: 0.6022464632987976, Validation loss: 0.6001806259155273
Epoch: 30/300 - Train loss: 0.5980281233787537, Validation loss: 0.5958940386772156
Epoch: 31/300 - Train loss: 0.5937997102737427, Validation loss: 0.5917386412620544
Epoch: 32/300 - Train loss: 0.5895649194717407, Validation loss: 0.5876718163490295
Epoch: 33/300 - Train loss: 0.5853285789489746, Validation loss: 0.5834333300590515
Epoch: 34/300 - Train loss: 0.581092894077301, Validation loss: 0.5791986584663391
Epoch: 35/300 - Train loss: 0.5768606662750244, Validation loss: 0.5750114321708679
Epoch: 36/300 - Train loss: 0.5726357102394104, Validation loss: 0.5709918737411499
Epoch: 37/300 - Train loss: 0.5684213042259216, Validation loss: 0.5668461918830872
Epoch: 38/300 - Train loss: 0.5642206072807312, Validation loss: 0.5627278685569763
Epoch: 39/300 - Train loss: 0.5600364804267883, Validation loss: 0.5584902167320251
Epoch: 40/300 - Train loss: 0.5558724403381348, Validation loss: 0.5544007420539856
Epoch: 41/300 - Train loss: 0.5517334938049316, Validation loss: 0.5502402186393738
Epoch: 42/300 - Train loss: 0.5476225018501282, Validation loss: 0.5460155010223389
Epoch: 43/300 - Train loss: 0.543542206287384, Validation loss: 0.5421334505081177
Epoch: 44/300 - Train loss: 0.5394947528839111, Validation loss: 0.5381002426147461
Epoch: 45/300 - Train loss: 0.5354834794998169, Validation loss: 0.5341967940330505
Epoch: 46/300 - Train loss: 0.5315106511116028, Validation loss: 0.5303860306739807
Epoch: 47/300 - Train loss: 0.5275785326957703, Validation loss: 0.5261639356613159
Epoch: 48/300 - Train loss: 0.5236883759498596, Validation loss: 0.5224159955978394
Epoch: 49/300 - Train loss: 0.5198419094085693, Validation loss: 0.5190500617027283
Epoch: 50/300 - Train loss: 0.5160408020019531, Validation loss: 0.514790415763855
Epoch: 51/300 - Train loss: 0.5122864246368408, Validation loss: 0.5109649896621704
Epoch: 52/300 - Train loss: 0.5085806250572205, Validation loss: 0.507472038269043
Epoch: 53/300 - Train loss: 0.5049248337745667, Validation loss: 0.5036884546279907
Epoch: 54/300 - Train loss: 0.501320481300354, Validation loss: 0.5009121894836426
Epoch: 55/300 - Train loss: 0.49776867032051086, Validation loss: 0.4972327947616577
Epoch: 56/300 - Train loss: 0.4942709505558014, Validation loss: 0.49332672357559204
Epoch: 57/300 - Train loss: 0.4908283054828644, Validation loss: 0.48994579911231995
Epoch: 58/300 - Train loss: 0.48744067549705505, Validation loss: 0.48672717809677124
Epoch: 59/300 - Train loss: 0.4841090142726898, Validation loss: 0.4835001528263092
Epoch: 60/300 - Train loss: 0.4808346629142761, Validation loss: 0.4800078868865967
Epoch: 61/300 - Train loss: 0.47761887311935425, Validation loss: 0.47696226835250854
Epoch: 62/300 - Train loss: 0.474461168050766, Validation loss: 0.47394683957099915
Epoch: 63/300 - Train loss: 0.47136226296424866, Validation loss: 0.4703413248062134
Epoch: 64/300 - Train loss: 0.4683229923248291, Validation loss: 0.46759194135665894
Epoch: 65/300 - Train loss: 0.46534276008605957, Validation loss: 0.46463072299957275
Epoch: 66/300 - Train loss: 0.46242159605026245, Validation loss: 0.4616830348968506
Epoch: 67/300 - Train loss: 0.4595600366592407, Validation loss: 0.458949476480484
Epoch: 68/300 - Train loss: 0.4567579925060272, Validation loss: 0.45635509490966797
Epoch: 69/300 - Train loss: 0.45401471853256226, Validation loss: 0.4532685875892639
Epoch: 70/300 - Train loss: 0.4513302743434906, Validation loss: 0.450864315032959
Epoch: 71/300 - Train loss: 0.44870463013648987, Validation loss: 0.44863563776016235
Epoch: 72/300 - Train loss: 0.4461359977722168, Validation loss: 0.44559457898139954
Epoch: 73/300 - Train loss: 0.44362425804138184, Validation loss: 0.4428808093070984
Epoch: 74/300 - Train loss: 0.44116899371147156, Validation loss: 0.4405955672264099
Epoch: 75/300 - Train loss: 0.43876951932907104, Validation loss: 0.4382801353931427
Epoch: 76/300 - Train loss: 0.4364256262779236, Validation loss: 0.435613214969635
Epoch: 77/300 - Train loss: 0.4341358542442322, Validation loss: 0.4335722029209137
Epoch: 78/300 - Train loss: 0.43189936876296997, Validation loss: 0.4316805899143219
Epoch: 79/300 - Train loss: 0.4297149181365967, Validation loss: 0.4291037917137146
Epoch: 80/300 - Train loss: 0.42758068442344666, Validation loss: 0.42728710174560547
Epoch: 81/300 - Train loss: 0.4254964292049408, Validation loss: 0.42494720220565796
Epoch: 82/300 - Train loss: 0.4234609305858612, Validation loss: 0.4228321313858032
Epoch: 83/300 - Train loss: 0.4214741885662079, Validation loss: 0.42069634795188904
Epoch: 84/300 - Train loss: 0.4195346236228943, Validation loss: 0.41966721415519714
Epoch: 85/300 - Train loss: 0.41764044761657715, Validation loss: 0.41813480854034424
Epoch: 86/300 - Train loss: 0.41578981280326843, Validation loss: 0.41524767875671387
Epoch: 87/300 - Train loss: 0.41398191452026367, Validation loss: 0.4131513833999634
Epoch: 88/300 - Train loss: 0.4122160077095032, Validation loss: 0.4115283191204071
Epoch: 89/300 - Train loss: 0.41049113869667053, Validation loss: 0.40955138206481934
Epoch: 90/300 - Train loss: 0.40880638360977173, Validation loss: 0.40779778361320496
Epoch: 91/300 - Train loss: 0.4071599245071411, Validation loss: 0.4062754213809967
Epoch: 92/300 - Train loss: 0.40555137395858765, Validation loss: 0.40475451946258545
Epoch: 93/300 - Train loss: 0.4039793908596039, Validation loss: 0.40342870354652405
Epoch: 94/300 - Train loss: 0.40244176983833313, Validation loss: 0.4017585515975952
Epoch: 95/300 - Train loss: 0.40093839168548584, Validation loss: 0.4008221924304962
Epoch: 96/300 - Train loss: 0.3994678854942322, Validation loss: 0.3985849916934967
Epoch: 97/300 - Train loss: 0.3980296552181244, Validation loss: 0.3976270258426666
Epoch: 98/300 - Train loss: 0.39662206172943115, Validation loss: 0.3963163197040558
Epoch: 99/300 - Train loss: 0.3952447772026062, Validation loss: 0.3945809602737427
Epoch: 100/300 - Train loss: 0.39389702677726746, Validation loss: 0.39326995611190796
Epoch: 101/300 - Train loss: 0.3925780653953552, Validation loss: 0.3920591473579407
Epoch: 102/300 - Train loss: 0.3912874162197113, Validation loss: 0.39048123359680176
Epoch: 103/300 - Train loss: 0.39002278447151184, Validation loss: 0.3896971046924591
Epoch: 104/300 - Train loss: 0.38878417015075684, Validation loss: 0.3877861201763153
Epoch: 105/300 - Train loss: 0.3875705897808075, Validation loss: 0.3870616555213928
Epoch: 106/300 - Train loss: 0.3863798677921295, Validation loss: 0.3851107358932495
Epoch: 107/300 - Train loss: 0.38521161675453186, Validation loss: 0.3844667077064514
Epoch: 108/300 - Train loss: 0.3840654194355011, Validation loss: 0.3829061985015869
Epoch: 109/300 - Train loss: 0.38294026255607605, Validation loss: 0.38295260071754456
Epoch: 110/300 - Train loss: 0.3818342387676239, Validation loss: 0.38096436858177185
Epoch: 111/300 - Train loss: 0.3807465732097626, Validation loss: 0.38021448254585266
Epoch: 112/300 - Train loss: 0.37967631220817566, Validation loss: 0.37820538878440857
Epoch: 113/300 - Train loss: 0.3786218464374542, Validation loss: 0.37771090865135193
Epoch: 114/300 - Train loss: 0.3775830864906311, Validation loss: 0.37637123465538025
Epoch: 115/300 - Train loss: 0.37656059861183167, Validation loss: 0.37579020857810974
Epoch: 116/300 - Train loss: 0.37555307149887085, Validation loss: 0.37526312470436096
Epoch: 117/300 - Train loss: 0.37456023693084717, Validation loss: 0.3740188777446747
Epoch: 118/300 - Train loss: 0.37358006834983826, Validation loss: 0.37234699726104736
Epoch: 119/300 - Train loss: 0.37261271476745605, Validation loss: 0.371035635471344
Epoch: 120/300 - Train loss: 0.37165722250938416, Validation loss: 0.3696606755256653
Epoch: 121/300 - Train loss: 0.370711088180542, Validation loss: 0.37005800008773804
Epoch: 122/300 - Train loss: 0.36977601051330566, Validation loss: 0.3680585026741028
Epoch: 123/300 - Train loss: 0.36885014176368713, Validation loss: 0.3670823574066162
Epoch: 124/300 - Train loss: 0.3679334223270416, Validation loss: 0.366377055644989
Epoch: 125/300 - Train loss: 0.3670274317264557, Validation loss: 0.36611127853393555
Epoch: 126/300 - Train loss: 0.3661309480667114, Validation loss: 0.36501672863960266
Epoch: 127/300 - Train loss: 0.3652448356151581, Validation loss: 0.3630571663379669
Epoch: 128/300 - Train loss: 0.3643665909767151, Validation loss: 0.36346009373664856
Epoch: 129/300 - Train loss: 0.36349788308143616, Validation loss: 0.3620099127292633
Epoch: 130/300 - Train loss: 0.36263933777809143, Validation loss: 0.3612574636936188
Epoch: 131/300 - Train loss: 0.3617892265319824, Validation loss: 0.3598487377166748
Epoch: 132/300 - Train loss: 0.36094704270362854, Validation loss: 0.35944727063179016
Epoch: 133/300 - Train loss: 0.36011365056037903, Validation loss: 0.3585149049758911
Epoch: 134/300 - Train loss: 0.35928913950920105, Validation loss: 0.35774287581443787
Epoch: 135/300 - Train loss: 0.3584749698638916, Validation loss: 0.3572441041469574
Epoch: 136/300 - Train loss: 0.357669860124588, Validation loss: 0.3552953600883484
Epoch: 137/300 - Train loss: 0.35687345266342163, Validation loss: 0.3548027575016022
Epoch: 138/300 - Train loss: 0.3560850918292999, Validation loss: 0.35483983159065247
Epoch: 139/300 - Train loss: 0.35530465841293335, Validation loss: 0.3532369136810303
Epoch: 140/300 - Train loss: 0.35453227162361145, Validation loss: 0.35219383239746094
Epoch: 141/300 - Train loss: 0.3537682890892029, Validation loss: 0.35188916325569153
Epoch: 142/300 - Train loss: 0.3530121147632599, Validation loss: 0.35104963183403015
Epoch: 143/300 - Train loss: 0.3522641956806183, Validation loss: 0.3509726822376251
Epoch: 144/300 - Train loss: 0.3515249192714691, Validation loss: 0.3497138023376465
Epoch: 145/300 - Train loss: 0.3507934808731079, Validation loss: 0.3488233685493469
Epoch: 146/300 - Train loss: 0.35006892681121826, Validation loss: 0.34830185770988464
Epoch: 147/300 - Train loss: 0.3493514657020569, Validation loss: 0.347135454416275
Epoch: 148/300 - Train loss: 0.348641574382782, Validation loss: 0.34739041328430176
Epoch: 149/300 - Train loss: 0.3479396104812622, Validation loss: 0.34544140100479126
Epoch: 150/300 - Train loss: 0.34724512696266174, Validation loss: 0.3462366759777069
Epoch: 151/300 - Train loss: 0.34655672311782837, Validation loss: 0.3444281816482544
Epoch: 152/300 - Train loss: 0.34587475657463074, Validation loss: 0.3441106677055359
Epoch: 153/300 - Train loss: 0.34520068764686584, Validation loss: 0.3439205586910248
Epoch: 154/300 - Train loss: 0.34453365206718445, Validation loss: 0.34241992235183716
Epoch: 155/300 - Train loss: 0.3438715934753418, Validation loss: 0.3416874408721924
Epoch: 156/300 - Train loss: 0.3432151675224304, Validation loss: 0.34157252311706543
Epoch: 157/300 - Train loss: 0.3425647020339966, Validation loss: 0.34070801734924316
Epoch: 158/300 - Train loss: 0.3419201076030731, Validation loss: 0.34009549021720886
Epoch: 159/300 - Train loss: 0.34128129482269287, Validation loss: 0.3400062024593353
Epoch: 160/300 - Train loss: 0.3406486511230469, Validation loss: 0.33854225277900696
Epoch: 161/300 - Train loss: 0.3400228023529053, Validation loss: 0.337717741727829
Epoch: 162/300 - Train loss: 0.3394029438495636, Validation loss: 0.33702874183654785
Epoch: 163/300 - Train loss: 0.3387891948223114, Validation loss: 0.33669599890708923
Epoch: 164/300 - Train loss: 0.3381814956665039, Validation loss: 0.33608439564704895
Epoch: 165/300 - Train loss: 0.3375801742076874, Validation loss: 0.3355571925640106
Epoch: 166/300 - Train loss: 0.3369848132133484, Validation loss: 0.3349704146385193
Epoch: 167/300 - Train loss: 0.3363937437534332, Validation loss: 0.3338782787322998
Epoch: 168/300 - Train loss: 0.33580708503723145, Validation loss: 0.3338770568370819
Epoch: 169/300 - Train loss: 0.33522534370422363, Validation loss: 0.333192378282547
Epoch: 170/300 - Train loss: 0.3346492350101471, Validation loss: 0.3326135575771332
Epoch: 171/300 - Train loss: 0.33407819271087646, Validation loss: 0.33202314376831055
Epoch: 172/300 - Train loss: 0.33351197838783264, Validation loss: 0.33180397748947144
