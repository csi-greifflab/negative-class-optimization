Epoch: 1/300 - Train loss: 0.698852002620697, Validation loss: 0.6978476047515869
Epoch: 2/300 - Train loss: 0.6962295770645142, Validation loss: 0.6951978802680969
Epoch: 3/300 - Train loss: 0.6936461329460144, Validation loss: 0.6927686333656311
Epoch: 4/300 - Train loss: 0.6910732388496399, Validation loss: 0.6901505589485168
Epoch: 5/300 - Train loss: 0.6884802579879761, Validation loss: 0.6874804496765137
Epoch: 6/300 - Train loss: 0.6858361959457397, Validation loss: 0.6847912669181824
Epoch: 7/300 - Train loss: 0.6831091046333313, Validation loss: 0.6820862293243408
Epoch: 8/300 - Train loss: 0.6802818775177002, Validation loss: 0.6791150569915771
Epoch: 9/300 - Train loss: 0.67734694480896, Validation loss: 0.6761032342910767
Epoch: 10/300 - Train loss: 0.6742911338806152, Validation loss: 0.6727713346481323
Epoch: 11/300 - Train loss: 0.67110276222229, Validation loss: 0.6694920063018799
Epoch: 12/300 - Train loss: 0.6677756905555725, Validation loss: 0.6659977436065674
Epoch: 13/300 - Train loss: 0.6643101572990417, Validation loss: 0.6625217795372009
Epoch: 14/300 - Train loss: 0.6607056856155396, Validation loss: 0.6586405634880066
Epoch: 15/300 - Train loss: 0.6569563150405884, Validation loss: 0.6548555493354797
Epoch: 16/300 - Train loss: 0.6530669331550598, Validation loss: 0.6507174372673035
Epoch: 17/300 - Train loss: 0.6490447521209717, Validation loss: 0.646582305431366
Epoch: 18/300 - Train loss: 0.6449021697044373, Validation loss: 0.6423643231391907
Epoch: 19/300 - Train loss: 0.6406524777412415, Validation loss: 0.6380405426025391
Epoch: 20/300 - Train loss: 0.6363065838813782, Validation loss: 0.6335741877555847
Epoch: 21/300 - Train loss: 0.6318699717521667, Validation loss: 0.629173219203949
Epoch: 22/300 - Train loss: 0.6273522973060608, Validation loss: 0.6248133182525635
Epoch: 23/300 - Train loss: 0.6227628588676453, Validation loss: 0.6200747489929199
Epoch: 24/300 - Train loss: 0.6181038618087769, Validation loss: 0.6154250502586365
Epoch: 25/300 - Train loss: 0.6133812069892883, Validation loss: 0.6106777787208557
Epoch: 26/300 - Train loss: 0.6085987687110901, Validation loss: 0.6061630249023438
Epoch: 27/300 - Train loss: 0.6037607789039612, Validation loss: 0.6011583805084229
Epoch: 28/300 - Train loss: 0.5988726615905762, Validation loss: 0.5961800217628479
Epoch: 29/300 - Train loss: 0.5939354300498962, Validation loss: 0.591518759727478
Epoch: 30/300 - Train loss: 0.588953971862793, Validation loss: 0.5865193009376526
Epoch: 31/300 - Train loss: 0.5839342474937439, Validation loss: 0.5815467834472656
Epoch: 32/300 - Train loss: 0.5788832306861877, Validation loss: 0.5764793753623962
Epoch: 33/300 - Train loss: 0.573806881904602, Validation loss: 0.571341335773468
Epoch: 34/300 - Train loss: 0.5687122344970703, Validation loss: 0.566588282585144
Epoch: 35/300 - Train loss: 0.5636086463928223, Validation loss: 0.5617865920066833
Epoch: 36/300 - Train loss: 0.5585038661956787, Validation loss: 0.5565184950828552
Epoch: 37/300 - Train loss: 0.5534050464630127, Validation loss: 0.5514101386070251
Epoch: 38/300 - Train loss: 0.5483207702636719, Validation loss: 0.5462795495986938
Epoch: 39/300 - Train loss: 0.5432591438293457, Validation loss: 0.54114830493927
Epoch: 40/300 - Train loss: 0.538225531578064, Validation loss: 0.536154568195343
Epoch: 41/300 - Train loss: 0.5332244634628296, Validation loss: 0.5314613580703735
Epoch: 42/300 - Train loss: 0.5282624959945679, Validation loss: 0.5266426801681519
Epoch: 43/300 - Train loss: 0.5233426094055176, Validation loss: 0.5214870572090149
Epoch: 44/300 - Train loss: 0.5184697508811951, Validation loss: 0.5169299840927124
Epoch: 45/300 - Train loss: 0.5136476755142212, Validation loss: 0.5121622681617737
Epoch: 46/300 - Train loss: 0.5088796615600586, Validation loss: 0.5073416829109192
Epoch: 47/300 - Train loss: 0.504169225692749, Validation loss: 0.5026788115501404
Epoch: 48/300 - Train loss: 0.4995197653770447, Validation loss: 0.4987213611602783
Epoch: 49/300 - Train loss: 0.49493440985679626, Validation loss: 0.4935855567455292
Epoch: 50/300 - Train loss: 0.49041616916656494, Validation loss: 0.48931679129600525
Epoch: 51/300 - Train loss: 0.48596781492233276, Validation loss: 0.48467525839805603
Epoch: 52/300 - Train loss: 0.4815916419029236, Validation loss: 0.48075568675994873
Epoch: 53/300 - Train loss: 0.4772903323173523, Validation loss: 0.4764467775821686
Epoch: 54/300 - Train loss: 0.47306591272354126, Validation loss: 0.47228091955184937
Epoch: 55/300 - Train loss: 0.4689197242259979, Validation loss: 0.4685465395450592
Epoch: 56/300 - Train loss: 0.4648534655570984, Validation loss: 0.4640277922153473
Epoch: 57/300 - Train loss: 0.46086809039115906, Validation loss: 0.4602194130420685
Epoch: 58/300 - Train loss: 0.45696431398391724, Validation loss: 0.4564169645309448
Epoch: 59/300 - Train loss: 0.4531426727771759, Validation loss: 0.45288535952568054
Epoch: 60/300 - Train loss: 0.4494035243988037, Validation loss: 0.44905346632003784
Epoch: 61/300 - Train loss: 0.44574666023254395, Validation loss: 0.4459497630596161
Epoch: 62/300 - Train loss: 0.44217199087142944, Validation loss: 0.4420461058616638
Epoch: 63/300 - Train loss: 0.4386792778968811, Validation loss: 0.43845778703689575
Epoch: 64/300 - Train loss: 0.4352680444717407, Validation loss: 0.43506500124931335
Epoch: 65/300 - Train loss: 0.43193715810775757, Validation loss: 0.43167322874069214
Epoch: 66/300 - Train loss: 0.4286859631538391, Validation loss: 0.4287337362766266
Epoch: 67/300 - Train loss: 0.42551344633102417, Validation loss: 0.42566272616386414
Epoch: 68/300 - Train loss: 0.42241838574409485, Validation loss: 0.4230422377586365
Epoch: 69/300 - Train loss: 0.4193997383117676, Validation loss: 0.41982588171958923
Epoch: 70/300 - Train loss: 0.41645586490631104, Validation loss: 0.4167726933956146
Epoch: 71/300 - Train loss: 0.41358521580696106, Validation loss: 0.4141198694705963
Epoch: 72/300 - Train loss: 0.4107862710952759, Validation loss: 0.41112926602363586
Epoch: 73/300 - Train loss: 0.40805691480636597, Validation loss: 0.4087909758090973
Epoch: 74/300 - Train loss: 0.40539559721946716, Validation loss: 0.4067439138889313
Epoch: 75/300 - Train loss: 0.4028007686138153, Validation loss: 0.4037531018257141
Epoch: 76/300 - Train loss: 0.40027061104774475, Validation loss: 0.40120580792427063
Epoch: 77/300 - Train loss: 0.39780333638191223, Validation loss: 0.39884740114212036
Epoch: 78/300 - Train loss: 0.39539703726768494, Validation loss: 0.3965331017971039
Epoch: 79/300 - Train loss: 0.3930498957633972, Validation loss: 0.3943744897842407
Epoch: 80/300 - Train loss: 0.3907598555088043, Validation loss: 0.3916704058647156
Epoch: 81/300 - Train loss: 0.3885253369808197, Validation loss: 0.38994187116622925
Epoch: 82/300 - Train loss: 0.3863445222377777, Validation loss: 0.38760584592819214
Epoch: 83/300 - Train loss: 0.38421547412872314, Validation loss: 0.3855593204498291
Epoch: 84/300 - Train loss: 0.3821364939212799, Validation loss: 0.3835134506225586
Epoch: 85/300 - Train loss: 0.38010576367378235, Validation loss: 0.3810042440891266
Epoch: 86/300 - Train loss: 0.37812182307243347, Validation loss: 0.38027939200401306
Epoch: 87/300 - Train loss: 0.37618279457092285, Validation loss: 0.377581924200058
Epoch: 88/300 - Train loss: 0.37428727746009827, Validation loss: 0.3764461278915405
Epoch: 89/300 - Train loss: 0.372433602809906, Validation loss: 0.3740670680999756
Epoch: 90/300 - Train loss: 0.3706204295158386, Validation loss: 0.3724236488342285
Epoch: 91/300 - Train loss: 0.36884593963623047, Validation loss: 0.37065932154655457
Epoch: 92/300 - Train loss: 0.36710888147354126, Validation loss: 0.3687942624092102
Epoch: 93/300 - Train loss: 0.36540764570236206, Validation loss: 0.3672354221343994
Epoch: 94/300 - Train loss: 0.3637411892414093, Validation loss: 0.3659353256225586
Epoch: 95/300 - Train loss: 0.36210814118385315, Validation loss: 0.36359870433807373
Epoch: 96/300 - Train loss: 0.36050719022750854, Validation loss: 0.36281612515449524
Epoch: 97/300 - Train loss: 0.35893726348876953, Validation loss: 0.3613661229610443
Epoch: 98/300 - Train loss: 0.3573973774909973, Validation loss: 0.3600853383541107
Epoch: 99/300 - Train loss: 0.355886846780777, Validation loss: 0.3583582937717438
Epoch: 100/300 - Train loss: 0.3544045686721802, Validation loss: 0.35662609338760376
Epoch: 101/300 - Train loss: 0.35294896364212036, Validation loss: 0.3543822169303894
Epoch: 102/300 - Train loss: 0.35151955485343933, Validation loss: 0.35393404960632324
Epoch: 103/300 - Train loss: 0.3501152992248535, Validation loss: 0.3526478409767151
Epoch: 104/300 - Train loss: 0.34873533248901367, Validation loss: 0.3508758544921875
Epoch: 105/300 - Train loss: 0.34737882018089294, Validation loss: 0.3498610556125641
Epoch: 106/300 - Train loss: 0.3460449278354645, Validation loss: 0.3480657935142517
Epoch: 107/300 - Train loss: 0.34473302960395813, Validation loss: 0.34800395369529724
Epoch: 108/300 - Train loss: 0.3434421718120575, Validation loss: 0.3466612696647644
Epoch: 109/300 - Train loss: 0.34217214584350586, Validation loss: 0.34471359848976135
Epoch: 110/300 - Train loss: 0.3409223258495331, Validation loss: 0.34423238039016724
Epoch: 111/300 - Train loss: 0.33969205617904663, Validation loss: 0.34237492084503174
Epoch: 112/300 - Train loss: 0.33848023414611816, Validation loss: 0.34092313051223755
Epoch: 113/300 - Train loss: 0.3372868001461029, Validation loss: 0.34026899933815
Epoch: 114/300 - Train loss: 0.3361109793186188, Validation loss: 0.338610976934433
Epoch: 115/300 - Train loss: 0.3349522650241852, Validation loss: 0.33765196800231934
Epoch: 116/300 - Train loss: 0.3338100016117096, Validation loss: 0.3366076350212097
Epoch: 117/300 - Train loss: 0.3326847553253174, Validation loss: 0.3358095586299896
Epoch: 118/300 - Train loss: 0.33157581090927124, Validation loss: 0.33417630195617676
Epoch: 119/300 - Train loss: 0.330482542514801, Validation loss: 0.33410823345184326
Epoch: 120/300 - Train loss: 0.32940423488616943, Validation loss: 0.33333224058151245
Epoch: 121/300 - Train loss: 0.328340619802475, Validation loss: 0.33200472593307495
Epoch: 122/300 - Train loss: 0.3272908926010132, Validation loss: 0.3305886387825012
Epoch: 123/300 - Train loss: 0.32625505328178406, Validation loss: 0.32945558428764343
Epoch: 124/300 - Train loss: 0.3252328932285309, Validation loss: 0.3286808431148529
Epoch: 125/300 - Train loss: 0.3242238759994507, Validation loss: 0.32756197452545166
Epoch: 126/300 - Train loss: 0.3232279419898987, Validation loss: 0.32665911316871643
Epoch: 127/300 - Train loss: 0.32224470376968384, Validation loss: 0.32518985867500305
Epoch: 128/300 - Train loss: 0.3212730586528778, Validation loss: 0.3239004909992218
Epoch: 129/300 - Train loss: 0.3203124403953552, Validation loss: 0.3233523964881897
Epoch: 130/300 - Train loss: 0.3193644881248474, Validation loss: 0.3230140507221222
Epoch: 131/300 - Train loss: 0.31842803955078125, Validation loss: 0.32172834873199463
Epoch: 132/300 - Train loss: 0.3175022006034851, Validation loss: 0.32153916358947754
Epoch: 133/300 - Train loss: 0.31658652424812317, Validation loss: 0.3205118775367737
Epoch: 134/300 - Train loss: 0.3156815469264984, Validation loss: 0.31879863142967224
Epoch: 135/300 - Train loss: 0.3147878348827362, Validation loss: 0.3189668357372284
Epoch: 136/300 - Train loss: 0.31390488147735596, Validation loss: 0.31780144572257996
Epoch: 137/300 - Train loss: 0.3130323588848114, Validation loss: 0.3165220618247986
Epoch: 138/300 - Train loss: 0.31216976046562195, Validation loss: 0.31511592864990234
Epoch: 139/300 - Train loss: 0.31131795048713684, Validation loss: 0.3148950934410095
Epoch: 140/300 - Train loss: 0.3104763627052307, Validation loss: 0.3142743408679962
Epoch: 141/300 - Train loss: 0.3096446096897125, Validation loss: 0.31394851207733154
Epoch: 142/300 - Train loss: 0.30882182717323303, Validation loss: 0.3121996223926544
Epoch: 143/300 - Train loss: 0.30800890922546387, Validation loss: 0.3114447593688965
Epoch: 144/300 - Train loss: 0.3072052001953125, Validation loss: 0.31087738275527954
Epoch: 145/300 - Train loss: 0.30641013383865356, Validation loss: 0.3098646104335785
Epoch: 146/300 - Train loss: 0.3056238293647766, Validation loss: 0.30981749296188354
Epoch: 147/300 - Train loss: 0.30484557151794434, Validation loss: 0.30885347723960876
Epoch: 148/300 - Train loss: 0.30407506227493286, Validation loss: 0.3082786798477173
Epoch: 149/300 - Train loss: 0.3033137917518616, Validation loss: 0.30728790163993835
Epoch: 150/300 - Train loss: 0.30256110429763794, Validation loss: 0.3061392903327942
Epoch: 151/300 - Train loss: 0.3018166422843933, Validation loss: 0.3066583573818207
Epoch: 152/300 - Train loss: 0.3010799288749695, Validation loss: 0.3055061399936676
Epoch: 153/300 - Train loss: 0.30035141110420227, Validation loss: 0.30460935831069946
Epoch: 154/300 - Train loss: 0.2996309995651245, Validation loss: 0.3040737509727478
Epoch: 155/300 - Train loss: 0.298918217420578, Validation loss: 0.30283746123313904
Epoch: 156/300 - Train loss: 0.2982132136821747, Validation loss: 0.30313122272491455
Epoch: 157/300 - Train loss: 0.2975161671638489, Validation loss: 0.3015832304954529
Epoch: 158/300 - Train loss: 0.2968265116214752, Validation loss: 0.301111102104187
Epoch: 159/300 - Train loss: 0.2961447238922119, Validation loss: 0.3006784915924072
Epoch: 160/300 - Train loss: 0.2954707741737366, Validation loss: 0.29954931139945984
Epoch: 161/300 - Train loss: 0.2948026657104492, Validation loss: 0.2990644574165344
Epoch: 162/300 - Train loss: 0.29414013028144836, Validation loss: 0.29856204986572266
Epoch: 163/300 - Train loss: 0.2934834361076355, Validation loss: 0.2975141406059265
Epoch: 164/300 - Train loss: 0.29283350706100464, Validation loss: 0.2973773777484894
Epoch: 165/300 - Train loss: 0.2921907901763916, Validation loss: 0.2961347699165344
Epoch: 166/300 - Train loss: 0.291555255651474, Validation loss: 0.29565703868865967
Epoch: 167/300 - Train loss: 0.2909255027770996, Validation loss: 0.29518574476242065
Epoch: 168/300 - Train loss: 0.2903019189834595, Validation loss: 0.29515382647514343
Epoch: 169/300 - Train loss: 0.28968411684036255, Validation loss: 0.2940220236778259
Epoch: 170/300 - Train loss: 0.28907233476638794, Validation loss: 0.2927330732345581
Epoch: 171/300 - Train loss: 0.2884664535522461, Validation loss: 0.2922686040401459
Epoch: 172/300 - Train loss: 0.2878660261631012, Validation loss: 0.29221054911613464
Epoch: 173/300 - Train loss: 0.28727060556411743, Validation loss: 0.2912600338459015
Epoch: 174/300 - Train loss: 0.2866803705692291, Validation loss: 0.2916906774044037
