Epoch: 1/300 - Train loss: 0.6893497109413147, Validation loss: 0.6868813037872314
Epoch: 2/300 - Train loss: 0.6868456602096558, Validation loss: 0.6843365430831909
Epoch: 3/300 - Train loss: 0.6843281388282776, Validation loss: 0.6817388534545898
Epoch: 4/300 - Train loss: 0.6817765831947327, Validation loss: 0.6790536046028137
Epoch: 5/300 - Train loss: 0.6791601181030273, Validation loss: 0.6763339042663574
Epoch: 6/300 - Train loss: 0.6764647960662842, Validation loss: 0.6735329627990723
Epoch: 7/300 - Train loss: 0.6736780405044556, Validation loss: 0.6706171035766602
Epoch: 8/300 - Train loss: 0.6707941293716431, Validation loss: 0.667592465877533
Epoch: 9/300 - Train loss: 0.6678046584129333, Validation loss: 0.6643848419189453
Epoch: 10/300 - Train loss: 0.6647112965583801, Validation loss: 0.6611411571502686
Epoch: 11/300 - Train loss: 0.6615121364593506, Validation loss: 0.6578119397163391
Epoch: 12/300 - Train loss: 0.6582039594650269, Validation loss: 0.6542955636978149
Epoch: 13/300 - Train loss: 0.6547842621803284, Validation loss: 0.6507101058959961
Epoch: 14/300 - Train loss: 0.6512539982795715, Validation loss: 0.6470239162445068
Epoch: 15/300 - Train loss: 0.6476152539253235, Validation loss: 0.6430923342704773
Epoch: 16/300 - Train loss: 0.6438714861869812, Validation loss: 0.6392738223075867
Epoch: 17/300 - Train loss: 0.640024721622467, Validation loss: 0.6352996826171875
Epoch: 18/300 - Train loss: 0.6360756158828735, Validation loss: 0.631131112575531
Epoch: 19/300 - Train loss: 0.6320297718048096, Validation loss: 0.6268270611763
Epoch: 20/300 - Train loss: 0.6278975009918213, Validation loss: 0.6225894689559937
Epoch: 21/300 - Train loss: 0.6236864328384399, Validation loss: 0.6183191537857056
Epoch: 22/300 - Train loss: 0.6194114089012146, Validation loss: 0.6138788461685181
Epoch: 23/300 - Train loss: 0.6150767803192139, Validation loss: 0.6093979477882385
Epoch: 24/300 - Train loss: 0.610694408416748, Validation loss: 0.6048883199691772
Epoch: 25/300 - Train loss: 0.606272280216217, Validation loss: 0.6004935503005981
Epoch: 26/300 - Train loss: 0.6018219590187073, Validation loss: 0.595802903175354
Epoch: 27/300 - Train loss: 0.5973508358001709, Validation loss: 0.5913518071174622
Epoch: 28/300 - Train loss: 0.5928650498390198, Validation loss: 0.5868886113166809
Epoch: 29/300 - Train loss: 0.5883681178092957, Validation loss: 0.582109272480011
Epoch: 30/300 - Train loss: 0.5838650465011597, Validation loss: 0.5776832699775696
Epoch: 31/300 - Train loss: 0.5793548226356506, Validation loss: 0.57314532995224
Epoch: 32/300 - Train loss: 0.5748428702354431, Validation loss: 0.5685598254203796
Epoch: 33/300 - Train loss: 0.5703324675559998, Validation loss: 0.5639520883560181
Epoch: 34/300 - Train loss: 0.5658244490623474, Validation loss: 0.5594964623451233
Epoch: 35/300 - Train loss: 0.5613198280334473, Validation loss: 0.5545395016670227
Epoch: 36/300 - Train loss: 0.5568214058876038, Validation loss: 0.5502971410751343
Epoch: 37/300 - Train loss: 0.5523340702056885, Validation loss: 0.5458057522773743
Epoch: 38/300 - Train loss: 0.5478613972663879, Validation loss: 0.5414314270019531
Epoch: 39/300 - Train loss: 0.5434072613716125, Validation loss: 0.5367605686187744
Epoch: 40/300 - Train loss: 0.5389765501022339, Validation loss: 0.5322397947311401
Epoch: 41/300 - Train loss: 0.5345728397369385, Validation loss: 0.527987003326416
Epoch: 42/300 - Train loss: 0.5301989316940308, Validation loss: 0.5229283571243286
Epoch: 43/300 - Train loss: 0.5258579254150391, Validation loss: 0.5189257860183716
Epoch: 44/300 - Train loss: 0.5215522050857544, Validation loss: 0.5146716833114624
Epoch: 45/300 - Train loss: 0.5172848105430603, Validation loss: 0.5100985765457153
Epoch: 46/300 - Train loss: 0.5130582451820374, Validation loss: 0.5060575604438782
Epoch: 47/300 - Train loss: 0.5088748335838318, Validation loss: 0.5018877983093262
Epoch: 48/300 - Train loss: 0.5047370195388794, Validation loss: 0.4976406395435333
Epoch: 49/300 - Train loss: 0.5006466507911682, Validation loss: 0.4937879145145416
Epoch: 50/300 - Train loss: 0.49660560488700867, Validation loss: 0.4894680678844452
Epoch: 51/300 - Train loss: 0.4926149845123291, Validation loss: 0.48515889048576355
Epoch: 52/300 - Train loss: 0.48867735266685486, Validation loss: 0.4817209541797638
Epoch: 53/300 - Train loss: 0.48479434847831726, Validation loss: 0.47794049978256226
Epoch: 54/300 - Train loss: 0.48096728324890137, Validation loss: 0.47373756766319275
Epoch: 55/300 - Train loss: 0.47719806432724, Validation loss: 0.47032973170280457
Epoch: 56/300 - Train loss: 0.473487913608551, Validation loss: 0.46622008085250854
Epoch: 57/300 - Train loss: 0.469838410615921, Validation loss: 0.4626632630825043
Epoch: 58/300 - Train loss: 0.46625030040740967, Validation loss: 0.4587964713573456
Epoch: 59/300 - Train loss: 0.4627249240875244, Validation loss: 0.45515382289886475
Epoch: 60/300 - Train loss: 0.4592630863189697, Validation loss: 0.45184996724128723
Epoch: 61/300 - Train loss: 0.4558655023574829, Validation loss: 0.4487522542476654
Epoch: 62/300 - Train loss: 0.4525328278541565, Validation loss: 0.44507449865341187
Epoch: 63/300 - Train loss: 0.4492659270763397, Validation loss: 0.441685289144516
Epoch: 64/300 - Train loss: 0.446065217256546, Validation loss: 0.4382535517215729
Epoch: 65/300 - Train loss: 0.44293081760406494, Validation loss: 0.43597546219825745
Epoch: 66/300 - Train loss: 0.43986281752586365, Validation loss: 0.4319595992565155
Epoch: 67/300 - Train loss: 0.4368610978126526, Validation loss: 0.42903849482536316
Epoch: 68/300 - Train loss: 0.4339253604412079, Validation loss: 0.4255625307559967
Epoch: 69/300 - Train loss: 0.43105554580688477, Validation loss: 0.4231787621974945
Epoch: 70/300 - Train loss: 0.4282512068748474, Validation loss: 0.420276015996933
Epoch: 71/300 - Train loss: 0.4255122244358063, Validation loss: 0.41743892431259155
Epoch: 72/300 - Train loss: 0.42283761501312256, Validation loss: 0.41524410247802734
Epoch: 73/300 - Train loss: 0.4202267527580261, Validation loss: 0.41187790036201477
Epoch: 74/300 - Train loss: 0.4176793098449707, Validation loss: 0.4094904959201813
Epoch: 75/300 - Train loss: 0.4151945412158966, Validation loss: 0.4067157506942749
Epoch: 76/300 - Train loss: 0.4127707779407501, Validation loss: 0.40430524945259094
Epoch: 77/300 - Train loss: 0.410407692193985, Validation loss: 0.4018670916557312
Epoch: 78/300 - Train loss: 0.4081042408943176, Validation loss: 0.3992688059806824
Epoch: 79/300 - Train loss: 0.40585950016975403, Validation loss: 0.39711353182792664
Epoch: 80/300 - Train loss: 0.4036724865436554, Validation loss: 0.3952092230319977
Epoch: 81/300 - Train loss: 0.4015423059463501, Validation loss: 0.3928685188293457
Epoch: 82/300 - Train loss: 0.39946770668029785, Validation loss: 0.39023953676223755
Epoch: 83/300 - Train loss: 0.3974476754665375, Validation loss: 0.3882702887058258
Epoch: 84/300 - Train loss: 0.3954809904098511, Validation loss: 0.3861616551876068
Epoch: 85/300 - Train loss: 0.3935667872428894, Validation loss: 0.38412046432495117
Epoch: 86/300 - Train loss: 0.3917037844657898, Validation loss: 0.382611483335495
Epoch: 87/300 - Train loss: 0.38989102840423584, Validation loss: 0.38116520643234253
Epoch: 88/300 - Train loss: 0.3881271779537201, Validation loss: 0.37859439849853516
Epoch: 89/300 - Train loss: 0.38641098141670227, Validation loss: 0.37758541107177734
Epoch: 90/300 - Train loss: 0.38474154472351074, Validation loss: 0.3751813769340515
Epoch: 91/300 - Train loss: 0.38311767578125, Validation loss: 0.37340983748435974
Epoch: 92/300 - Train loss: 0.3815382421016693, Validation loss: 0.3723214566707611
Epoch: 93/300 - Train loss: 0.3800022602081299, Validation loss: 0.37009382247924805
Epoch: 94/300 - Train loss: 0.37850818037986755, Validation loss: 0.36883679032325745
Epoch: 95/300 - Train loss: 0.3770548701286316, Validation loss: 0.36703410744667053
Epoch: 96/300 - Train loss: 0.37564149498939514, Validation loss: 0.36583101749420166
Epoch: 97/300 - Train loss: 0.37426719069480896, Validation loss: 0.36395081877708435
Epoch: 98/300 - Train loss: 0.37293076515197754, Validation loss: 0.3632393777370453
Epoch: 99/300 - Train loss: 0.3716309070587158, Validation loss: 0.3616381883621216
Epoch: 100/300 - Train loss: 0.3703669309616089, Validation loss: 0.35996556282043457
Epoch: 101/300 - Train loss: 0.3691372573375702, Validation loss: 0.3585435748100281
Epoch: 102/300 - Train loss: 0.3679412007331848, Validation loss: 0.3576003313064575
Epoch: 103/300 - Train loss: 0.36677801609039307, Validation loss: 0.3561835289001465
Epoch: 104/300 - Train loss: 0.36564627289772034, Validation loss: 0.3551397919654846
Epoch: 105/300 - Train loss: 0.36454540491104126, Validation loss: 0.3545067012310028
Epoch: 106/300 - Train loss: 0.3634741008281708, Validation loss: 0.3525683581829071
Epoch: 107/300 - Train loss: 0.36243173480033875, Validation loss: 0.3516426682472229
Epoch: 108/300 - Train loss: 0.361417680978775, Validation loss: 0.3509710431098938
Epoch: 109/300 - Train loss: 0.36043110489845276, Validation loss: 0.3499944806098938
Epoch: 110/300 - Train loss: 0.35947102308273315, Validation loss: 0.3490743339061737
Epoch: 111/300 - Train loss: 0.3585365116596222, Validation loss: 0.3480338752269745
Epoch: 112/300 - Train loss: 0.3576269745826721, Validation loss: 0.3468509018421173
Epoch: 113/300 - Train loss: 0.3567415773868561, Validation loss: 0.3460420072078705
Epoch: 114/300 - Train loss: 0.35587966442108154, Validation loss: 0.3454544246196747
Epoch: 115/300 - Train loss: 0.3550403416156769, Validation loss: 0.3439486026763916
Epoch: 116/300 - Train loss: 0.35422295331954956, Validation loss: 0.3427564799785614
Epoch: 117/300 - Train loss: 0.3534267842769623, Validation loss: 0.34166809916496277
Epoch: 118/300 - Train loss: 0.35265111923217773, Validation loss: 0.3414593040943146
Epoch: 119/300 - Train loss: 0.3518953323364258, Validation loss: 0.34092795848846436
Epoch: 120/300 - Train loss: 0.351159006357193, Validation loss: 0.33949270844459534
Epoch: 121/300 - Train loss: 0.350441038608551, Validation loss: 0.3391698896884918
Epoch: 122/300 - Train loss: 0.34974101185798645, Validation loss: 0.3384905755519867
Epoch: 123/300 - Train loss: 0.34905847907066345, Validation loss: 0.3372572064399719
Epoch: 124/300 - Train loss: 0.3483930230140686, Validation loss: 0.33678075671195984
Epoch: 125/300 - Train loss: 0.34774383902549744, Validation loss: 0.33569133281707764
Epoch: 126/300 - Train loss: 0.3471105098724365, Validation loss: 0.3354314863681793
Epoch: 127/300 - Train loss: 0.3464925289154053, Validation loss: 0.33501458168029785
Epoch: 128/300 - Train loss: 0.3458895683288574, Validation loss: 0.3346501290798187
Epoch: 129/300 - Train loss: 0.3453013300895691, Validation loss: 0.3335278034210205
Epoch: 130/300 - Train loss: 0.3447267413139343, Validation loss: 0.3332456350326538
Epoch: 131/300 - Train loss: 0.3441660404205322, Validation loss: 0.33236372470855713
Epoch: 132/300 - Train loss: 0.3436186909675598, Validation loss: 0.3320814371109009
Epoch: 133/300 - Train loss: 0.3430843949317932, Validation loss: 0.3309381306171417
Epoch: 134/300 - Train loss: 0.34256264567375183, Validation loss: 0.330366313457489
Epoch: 135/300 - Train loss: 0.34205302596092224, Validation loss: 0.33035513758659363
Epoch: 136/300 - Train loss: 0.3415548801422119, Validation loss: 0.32956987619400024
Epoch: 137/300 - Train loss: 0.341067910194397, Validation loss: 0.3294987380504608
Epoch: 138/300 - Train loss: 0.34059178829193115, Validation loss: 0.3282964527606964
Epoch: 139/300 - Train loss: 0.34012582898139954, Validation loss: 0.32818660140037537
Epoch: 140/300 - Train loss: 0.33966949582099915, Validation loss: 0.3284774124622345
