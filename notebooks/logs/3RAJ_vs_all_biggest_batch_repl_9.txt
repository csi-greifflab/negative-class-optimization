Epoch: 1/300 - Train loss: 0.6957912445068359, Validation loss: 0.6948913931846619
Epoch: 2/300 - Train loss: 0.6938857436180115, Validation loss: 0.6929320693016052
Epoch: 3/300 - Train loss: 0.69195955991745, Validation loss: 0.690812349319458
Epoch: 4/300 - Train loss: 0.689997136592865, Validation loss: 0.6886451840400696
Epoch: 5/300 - Train loss: 0.6879780888557434, Validation loss: 0.686499834060669
Epoch: 6/300 - Train loss: 0.6859057545661926, Validation loss: 0.6842976808547974
Epoch: 7/300 - Train loss: 0.6837713718414307, Validation loss: 0.6819553375244141
Epoch: 8/300 - Train loss: 0.6815764307975769, Validation loss: 0.679658055305481
Epoch: 9/300 - Train loss: 0.6793248653411865, Validation loss: 0.677226722240448
Epoch: 10/300 - Train loss: 0.6770244836807251, Validation loss: 0.6747506856918335
Epoch: 11/300 - Train loss: 0.6746811270713806, Validation loss: 0.6722854375839233
Epoch: 12/300 - Train loss: 0.6723055243492126, Validation loss: 0.6699062585830688
Epoch: 13/300 - Train loss: 0.6698964834213257, Validation loss: 0.6673601269721985
Epoch: 14/300 - Train loss: 0.667458176612854, Validation loss: 0.6648440361022949
Epoch: 15/300 - Train loss: 0.6649977564811707, Validation loss: 0.6622463464736938
Epoch: 16/300 - Train loss: 0.662514865398407, Validation loss: 0.6597124934196472
Epoch: 17/300 - Train loss: 0.6600067615509033, Validation loss: 0.6570054888725281
Epoch: 18/300 - Train loss: 0.657475471496582, Validation loss: 0.6543751358985901
Epoch: 19/300 - Train loss: 0.6549187898635864, Validation loss: 0.6518464684486389
Epoch: 20/300 - Train loss: 0.6523393392562866, Validation loss: 0.6491904854774475
Epoch: 21/300 - Train loss: 0.649740993976593, Validation loss: 0.6464113593101501
Epoch: 22/300 - Train loss: 0.6471260786056519, Validation loss: 0.6437535881996155
Epoch: 23/300 - Train loss: 0.644496500492096, Validation loss: 0.6410435438156128
Epoch: 24/300 - Train loss: 0.6418555974960327, Validation loss: 0.6382264494895935
Epoch: 25/300 - Train loss: 0.6392067670822144, Validation loss: 0.6356736421585083
Epoch: 26/300 - Train loss: 0.6365553736686707, Validation loss: 0.6329556703567505
Epoch: 27/300 - Train loss: 0.6339066028594971, Validation loss: 0.6302599310874939
Epoch: 28/300 - Train loss: 0.6312648057937622, Validation loss: 0.627625584602356
Epoch: 29/300 - Train loss: 0.628635823726654, Validation loss: 0.6249991655349731
Epoch: 30/300 - Train loss: 0.6260197162628174, Validation loss: 0.6222447752952576
Epoch: 31/300 - Train loss: 0.6234201192855835, Validation loss: 0.6197614073753357
Epoch: 32/300 - Train loss: 0.6208399534225464, Validation loss: 0.6170820593833923
Epoch: 33/300 - Train loss: 0.618277907371521, Validation loss: 0.6146239042282104
Epoch: 34/300 - Train loss: 0.6157335042953491, Validation loss: 0.6120852828025818
Epoch: 35/300 - Train loss: 0.6132089495658875, Validation loss: 0.6095072031021118
Epoch: 36/300 - Train loss: 0.6107016801834106, Validation loss: 0.6070370674133301
Epoch: 37/300 - Train loss: 0.6082136631011963, Validation loss: 0.6046198010444641
Epoch: 38/300 - Train loss: 0.6057451963424683, Validation loss: 0.6020205020904541
Epoch: 39/300 - Train loss: 0.6032982468605042, Validation loss: 0.5997906923294067
Epoch: 40/300 - Train loss: 0.600873589515686, Validation loss: 0.5972797870635986
Epoch: 41/300 - Train loss: 0.5984716415405273, Validation loss: 0.5952052474021912
Epoch: 42/300 - Train loss: 0.5960964560508728, Validation loss: 0.5925151109695435
Epoch: 43/300 - Train loss: 0.593748927116394, Validation loss: 0.59031081199646
Epoch: 44/300 - Train loss: 0.5914305448532104, Validation loss: 0.5879491567611694
Epoch: 45/300 - Train loss: 0.5891411304473877, Validation loss: 0.5859010815620422
Epoch: 46/300 - Train loss: 0.5868806838989258, Validation loss: 0.5837183594703674
Epoch: 47/300 - Train loss: 0.5846493244171143, Validation loss: 0.581636369228363
Epoch: 48/300 - Train loss: 0.5824481248855591, Validation loss: 0.579460084438324
Epoch: 49/300 - Train loss: 0.5802778005599976, Validation loss: 0.577106773853302
Epoch: 50/300 - Train loss: 0.5781370997428894, Validation loss: 0.5752947330474854
Epoch: 51/300 - Train loss: 0.5760253667831421, Validation loss: 0.5732839107513428
Epoch: 52/300 - Train loss: 0.5739436745643616, Validation loss: 0.5711508989334106
Epoch: 53/300 - Train loss: 0.5718913078308105, Validation loss: 0.5691357254981995
Epoch: 54/300 - Train loss: 0.5698687434196472, Validation loss: 0.5671406984329224
Epoch: 55/300 - Train loss: 0.5678752064704895, Validation loss: 0.5654033422470093
Epoch: 56/300 - Train loss: 0.5659108757972717, Validation loss: 0.5632820725440979
Epoch: 57/300 - Train loss: 0.5639757513999939, Validation loss: 0.5618934035301208
Epoch: 58/300 - Train loss: 0.5620688796043396, Validation loss: 0.5597547292709351
Epoch: 59/300 - Train loss: 0.5601907968521118, Validation loss: 0.5579408407211304
Epoch: 60/300 - Train loss: 0.5583416223526001, Validation loss: 0.556422770023346
Epoch: 61/300 - Train loss: 0.556520402431488, Validation loss: 0.5546635389328003
Epoch: 62/300 - Train loss: 0.5547279119491577, Validation loss: 0.5529559850692749
Epoch: 63/300 - Train loss: 0.5529630780220032, Validation loss: 0.5512065291404724
Epoch: 64/300 - Train loss: 0.5512256622314453, Validation loss: 0.5499149560928345
Epoch: 65/300 - Train loss: 0.5495156049728394, Validation loss: 0.548076331615448
Epoch: 66/300 - Train loss: 0.5478317737579346, Validation loss: 0.5461820960044861
Epoch: 67/300 - Train loss: 0.546173095703125, Validation loss: 0.5445212125778198
Epoch: 68/300 - Train loss: 0.5445381999015808, Validation loss: 0.5435623526573181
Epoch: 69/300 - Train loss: 0.5429273843765259, Validation loss: 0.5420510172843933
Epoch: 70/300 - Train loss: 0.5413404107093811, Validation loss: 0.5401149988174438
Epoch: 71/300 - Train loss: 0.5397765040397644, Validation loss: 0.5389626622200012
Epoch: 72/300 - Train loss: 0.5382348895072937, Validation loss: 0.5375171899795532
Epoch: 73/300 - Train loss: 0.536714494228363, Validation loss: 0.535660982131958
Epoch: 74/300 - Train loss: 0.5352150797843933, Validation loss: 0.5346532464027405
Epoch: 75/300 - Train loss: 0.5337353944778442, Validation loss: 0.5327014327049255
Epoch: 76/300 - Train loss: 0.5322738289833069, Validation loss: 0.5318766236305237
Epoch: 77/300 - Train loss: 0.5308309197425842, Validation loss: 0.531032145023346
Epoch: 78/300 - Train loss: 0.5294049382209778, Validation loss: 0.5291621088981628
Epoch: 79/300 - Train loss: 0.5279949307441711, Validation loss: 0.5276135206222534
Epoch: 80/300 - Train loss: 0.5266011357307434, Validation loss: 0.5266364812850952
Epoch: 81/300 - Train loss: 0.525221586227417, Validation loss: 0.5248910188674927
Epoch: 82/300 - Train loss: 0.5238547921180725, Validation loss: 0.5238512754440308
Epoch: 83/300 - Train loss: 0.5225018858909607, Validation loss: 0.5232164263725281
Epoch: 84/300 - Train loss: 0.521161675453186, Validation loss: 0.5213382840156555
Epoch: 85/300 - Train loss: 0.5198336839675903, Validation loss: 0.5201612710952759
Epoch: 86/300 - Train loss: 0.5185166001319885, Validation loss: 0.5191664695739746
Epoch: 87/300 - Train loss: 0.5172093510627747, Validation loss: 0.5177472829818726
Epoch: 88/300 - Train loss: 0.5159112811088562, Validation loss: 0.5168587565422058
Epoch: 89/300 - Train loss: 0.5146220922470093, Validation loss: 0.5150379538536072
Epoch: 90/300 - Train loss: 0.5133413076400757, Validation loss: 0.5145645141601562
Epoch: 91/300 - Train loss: 0.5120679140090942, Validation loss: 0.5132395625114441
Epoch: 92/300 - Train loss: 0.5108016133308411, Validation loss: 0.5121690034866333
Epoch: 93/300 - Train loss: 0.5095411539077759, Validation loss: 0.5105910897254944
Epoch: 94/300 - Train loss: 0.5082874298095703, Validation loss: 0.5098875164985657
Epoch: 95/300 - Train loss: 0.5070403218269348, Validation loss: 0.50860995054245
Epoch: 96/300 - Train loss: 0.5057986378669739, Validation loss: 0.5078046917915344
Epoch: 97/300 - Train loss: 0.5045613050460815, Validation loss: 0.5060628652572632
Epoch: 98/300 - Train loss: 0.5033302903175354, Validation loss: 0.5052765011787415
Epoch: 99/300 - Train loss: 0.5021055340766907, Validation loss: 0.5041295289993286
Epoch: 100/300 - Train loss: 0.5008848309516907, Validation loss: 0.5031771063804626
Epoch: 101/300 - Train loss: 0.49966806173324585, Validation loss: 0.5017871856689453
Epoch: 102/300 - Train loss: 0.49845486879348755, Validation loss: 0.5004382729530334
Epoch: 103/300 - Train loss: 0.4972458779811859, Validation loss: 0.4992804527282715
Epoch: 104/300 - Train loss: 0.4960417151451111, Validation loss: 0.49861735105514526
Epoch: 105/300 - Train loss: 0.49484166502952576, Validation loss: 0.496995747089386
Epoch: 106/300 - Train loss: 0.4936446249485016, Validation loss: 0.4959065020084381
Epoch: 107/300 - Train loss: 0.49245214462280273, Validation loss: 0.49518612027168274
Epoch: 108/300 - Train loss: 0.4912622272968292, Validation loss: 0.49425408244132996
Epoch: 109/300 - Train loss: 0.49007561802864075, Validation loss: 0.4929039478302002
Epoch: 110/300 - Train loss: 0.4888933002948761, Validation loss: 0.49155980348587036
Epoch: 111/300 - Train loss: 0.4877149760723114, Validation loss: 0.4903075098991394
Epoch: 112/300 - Train loss: 0.48654085397720337, Validation loss: 0.48964425921440125
Epoch: 113/300 - Train loss: 0.48536980152130127, Validation loss: 0.4884452223777771
Epoch: 114/300 - Train loss: 0.4842015206813812, Validation loss: 0.4875112771987915
Epoch: 115/300 - Train loss: 0.48303693532943726, Validation loss: 0.48656368255615234
Epoch: 116/300 - Train loss: 0.48187655210494995, Validation loss: 0.48562195897102356
Epoch: 117/300 - Train loss: 0.4807194173336029, Validation loss: 0.4836025536060333
Epoch: 118/300 - Train loss: 0.4795650839805603, Validation loss: 0.4827822148799896
Epoch: 119/300 - Train loss: 0.47841230034828186, Validation loss: 0.48235470056533813
Epoch: 120/300 - Train loss: 0.4772605299949646, Validation loss: 0.48067939281463623
Epoch: 121/300 - Train loss: 0.47610923647880554, Validation loss: 0.47899097204208374
Epoch: 122/300 - Train loss: 0.47495928406715393, Validation loss: 0.47826677560806274
Epoch: 123/300 - Train loss: 0.4738103151321411, Validation loss: 0.47746115922927856
Epoch: 124/300 - Train loss: 0.47266221046447754, Validation loss: 0.47612208127975464
Epoch: 125/300 - Train loss: 0.47151434421539307, Validation loss: 0.47570469975471497
Epoch: 126/300 - Train loss: 0.4703674018383026, Validation loss: 0.47430673241615295
Epoch: 127/300 - Train loss: 0.46922245621681213, Validation loss: 0.47290652990341187
Epoch: 128/300 - Train loss: 0.46807897090911865, Validation loss: 0.4720896780490875
Epoch: 129/300 - Train loss: 0.4669378995895386, Validation loss: 0.47143879532814026
Epoch: 130/300 - Train loss: 0.46579787135124207, Validation loss: 0.470510333776474
Epoch: 131/300 - Train loss: 0.4646598994731903, Validation loss: 0.46881240606307983
Epoch: 132/300 - Train loss: 0.4635230600833893, Validation loss: 0.467564195394516
Epoch: 133/300 - Train loss: 0.4623880386352539, Validation loss: 0.4667016863822937
Epoch: 134/300 - Train loss: 0.4612542986869812, Validation loss: 0.4651449918746948
Epoch: 135/300 - Train loss: 0.4601221978664398, Validation loss: 0.4643433094024658
Epoch: 136/300 - Train loss: 0.4589911997318268, Validation loss: 0.46337512135505676
Epoch: 137/300 - Train loss: 0.4578618109226227, Validation loss: 0.4626161456108093
Epoch: 138/300 - Train loss: 0.4567338228225708, Validation loss: 0.46118828654289246
Epoch: 139/300 - Train loss: 0.45560774207115173, Validation loss: 0.4607221484184265
Epoch: 140/300 - Train loss: 0.45448246598243713, Validation loss: 0.45901361107826233
Epoch: 141/300 - Train loss: 0.45335692167282104, Validation loss: 0.45791226625442505
Epoch: 142/300 - Train loss: 0.4522317945957184, Validation loss: 0.4572750926017761
Epoch: 143/300 - Train loss: 0.45110616087913513, Validation loss: 0.4563274681568146
Epoch: 144/300 - Train loss: 0.44998082518577576, Validation loss: 0.45541879534721375
Epoch: 145/300 - Train loss: 0.44885748624801636, Validation loss: 0.45376119017601013
Epoch: 146/300 - Train loss: 0.44773799180984497, Validation loss: 0.45277875661849976
Epoch: 147/300 - Train loss: 0.4466182291507721, Validation loss: 0.45230865478515625
Epoch: 148/300 - Train loss: 0.44549909234046936, Validation loss: 0.45067349076271057
Epoch: 149/300 - Train loss: 0.44438236951828003, Validation loss: 0.4498066008090973
Epoch: 150/300 - Train loss: 0.44326674938201904, Validation loss: 0.44915005564689636
Epoch: 151/300 - Train loss: 0.44215288758277893, Validation loss: 0.44741934537887573
Epoch: 152/300 - Train loss: 0.4410404860973358, Validation loss: 0.446277379989624
Epoch: 153/300 - Train loss: 0.43992868065834045, Validation loss: 0.44540634751319885
Epoch: 154/300 - Train loss: 0.4388175308704376, Validation loss: 0.4447133541107178
Epoch: 155/300 - Train loss: 0.4377061426639557, Validation loss: 0.4435567259788513
Epoch: 156/300 - Train loss: 0.43659669160842896, Validation loss: 0.44297388195991516
Epoch: 157/300 - Train loss: 0.4354889392852783, Validation loss: 0.4412728548049927
Epoch: 158/300 - Train loss: 0.43438494205474854, Validation loss: 0.4406622052192688
Epoch: 159/300 - Train loss: 0.4332830309867859, Validation loss: 0.43937015533447266
Epoch: 160/300 - Train loss: 0.43218278884887695, Validation loss: 0.4392026960849762
Epoch: 161/300 - Train loss: 0.43108510971069336, Validation loss: 0.43708083033561707
Epoch: 162/300 - Train loss: 0.42999112606048584, Validation loss: 0.4362451136112213
Epoch: 163/300 - Train loss: 0.4289001524448395, Validation loss: 0.43572643399238586
Epoch: 164/300 - Train loss: 0.42781293392181396, Validation loss: 0.434383362531662
Epoch: 165/300 - Train loss: 0.4267289638519287, Validation loss: 0.4326530992984772
Epoch: 166/300 - Train loss: 0.42564821243286133, Validation loss: 0.43230924010276794
Epoch: 167/300 - Train loss: 0.42457154393196106, Validation loss: 0.431397408246994
Epoch: 168/300 - Train loss: 0.4234984517097473, Validation loss: 0.43027669191360474
Epoch: 169/300 - Train loss: 0.4224282205104828, Validation loss: 0.4296407699584961
Epoch: 170/300 - Train loss: 0.42135924100875854, Validation loss: 0.4282914102077484
Epoch: 171/300 - Train loss: 0.42029404640197754, Validation loss: 0.4270452857017517
Epoch: 172/300 - Train loss: 0.4192340075969696, Validation loss: 0.42607197165489197
Epoch: 173/300 - Train loss: 0.41817712783813477, Validation loss: 0.4253453314304352
Epoch: 174/300 - Train loss: 0.4171227216720581, Validation loss: 0.4247186779975891
Epoch: 175/300 - Train loss: 0.4160711467266083, Validation loss: 0.42311573028564453
Epoch: 176/300 - Train loss: 0.4150247275829315, Validation loss: 0.4222066104412079
Epoch: 177/300 - Train loss: 0.41398265957832336, Validation loss: 0.4216744303703308
Epoch: 178/300 - Train loss: 0.4129445552825928, Validation loss: 0.42031705379486084
Epoch: 179/300 - Train loss: 0.41190826892852783, Validation loss: 0.4198146462440491
Epoch: 180/300 - Train loss: 0.4108744263648987, Validation loss: 0.4187730550765991
Epoch: 181/300 - Train loss: 0.409843772649765, Validation loss: 0.4172086715698242
Epoch: 182/300 - Train loss: 0.4088174104690552, Validation loss: 0.4171988070011139
Epoch: 183/300 - Train loss: 0.40779584646224976, Validation loss: 0.41538557410240173
Epoch: 184/300 - Train loss: 0.4067789912223816, Validation loss: 0.4146648347377777
Epoch: 185/300 - Train loss: 0.4057675302028656, Validation loss: 0.4137744605541229
Epoch: 186/300 - Train loss: 0.40476101636886597, Validation loss: 0.41296887397766113
Epoch: 187/300 - Train loss: 0.40375930070877075, Validation loss: 0.4120299220085144
Epoch: 188/300 - Train loss: 0.40276262164115906, Validation loss: 0.41076886653900146
Epoch: 189/300 - Train loss: 0.401770681142807, Validation loss: 0.40979862213134766
Epoch: 190/300 - Train loss: 0.40078362822532654, Validation loss: 0.4086858034133911
Epoch: 191/300 - Train loss: 0.3998021185398102, Validation loss: 0.4080426096916199
Epoch: 192/300 - Train loss: 0.3988238573074341, Validation loss: 0.40712544322013855
Epoch: 193/300 - Train loss: 0.397849977016449, Validation loss: 0.4064280092716217
Epoch: 194/300 - Train loss: 0.3968809247016907, Validation loss: 0.40556707978248596
Epoch: 195/300 - Train loss: 0.39591580629348755, Validation loss: 0.4044523537158966
Epoch: 196/300 - Train loss: 0.3949539363384247, Validation loss: 0.4041004478931427
Epoch: 197/300 - Train loss: 0.3939964473247528, Validation loss: 0.4030366539955139
Epoch: 198/300 - Train loss: 0.3930434286594391, Validation loss: 0.40211522579193115
Epoch: 199/300 - Train loss: 0.39209532737731934, Validation loss: 0.4008742570877075
Epoch: 200/300 - Train loss: 0.39115336537361145, Validation loss: 0.4003867208957672
Epoch: 201/300 - Train loss: 0.39021745324134827, Validation loss: 0.4001103341579437
Epoch: 202/300 - Train loss: 0.38928595185279846, Validation loss: 0.3990268409252167
Epoch: 203/300 - Train loss: 0.38835880160331726, Validation loss: 0.39797115325927734
Epoch: 204/300 - Train loss: 0.3874359726905823, Validation loss: 0.3969841003417969
Epoch: 205/300 - Train loss: 0.38651785254478455, Validation loss: 0.39640986919403076
Epoch: 206/300 - Train loss: 0.38560450077056885, Validation loss: 0.3947904407978058
Epoch: 207/300 - Train loss: 0.38469502329826355, Validation loss: 0.39399561285972595
Epoch: 208/300 - Train loss: 0.3837890625, Validation loss: 0.3939121663570404
Epoch: 209/300 - Train loss: 0.38288697600364685, Validation loss: 0.39286068081855774
Epoch: 210/300 - Train loss: 0.3819877803325653, Validation loss: 0.39201298356056213
Epoch: 211/300 - Train loss: 0.3810935616493225, Validation loss: 0.3912564516067505
Epoch: 212/300 - Train loss: 0.38020437955856323, Validation loss: 0.39027678966522217
Epoch: 213/300 - Train loss: 0.37932059168815613, Validation loss: 0.3900187015533447
Epoch: 214/300 - Train loss: 0.37844181060791016, Validation loss: 0.38884398341178894
Epoch: 215/300 - Train loss: 0.3775682747364044, Validation loss: 0.38836827874183655
Epoch: 216/300 - Train loss: 0.3766999840736389, Validation loss: 0.3869195580482483
Epoch: 217/300 - Train loss: 0.37583717703819275, Validation loss: 0.38674506545066833
Epoch: 218/300 - Train loss: 0.37497979402542114, Validation loss: 0.3856182396411896
Epoch: 219/300 - Train loss: 0.3741287589073181, Validation loss: 0.3844529092311859
Epoch: 220/300 - Train loss: 0.37328311800956726, Validation loss: 0.3839832544326782
Epoch: 221/300 - Train loss: 0.3724414110183716, Validation loss: 0.38375747203826904
Epoch: 222/300 - Train loss: 0.3716040551662445, Validation loss: 0.38301026821136475
Epoch: 223/300 - Train loss: 0.3707714378833771, Validation loss: 0.38280779123306274
Epoch: 224/300 - Train loss: 0.3699437379837036, Validation loss: 0.38106271624565125
Epoch: 225/300 - Train loss: 0.3691195249557495, Validation loss: 0.3808029890060425
Epoch: 226/300 - Train loss: 0.3682991862297058, Validation loss: 0.3793204128742218
Epoch: 227/300 - Train loss: 0.36748331785202026, Validation loss: 0.3792182207107544
Epoch: 228/300 - Train loss: 0.36667245626449585, Validation loss: 0.37904706597328186
Epoch: 229/300 - Train loss: 0.3658660352230072, Validation loss: 0.3777045011520386
Epoch: 230/300 - Train loss: 0.3650631606578827, Validation loss: 0.37677496671676636
Epoch: 231/300 - Train loss: 0.36426469683647156, Validation loss: 0.37617671489715576
Epoch: 232/300 - Train loss: 0.3634706139564514, Validation loss: 0.37581777572631836
Epoch: 233/300 - Train loss: 0.36268070340156555, Validation loss: 0.37487608194351196
Epoch: 234/300 - Train loss: 0.3618943691253662, Validation loss: 0.3750779926776886
Epoch: 235/300 - Train loss: 0.36111128330230713, Validation loss: 0.37359192967414856
Epoch: 236/300 - Train loss: 0.36033234000205994, Validation loss: 0.3728056848049164
Epoch: 237/300 - Train loss: 0.3595576584339142, Validation loss: 0.37161439657211304
Epoch: 238/300 - Train loss: 0.35878777503967285, Validation loss: 0.3713855743408203
Epoch: 239/300 - Train loss: 0.35802263021469116, Validation loss: 0.37078261375427246
Epoch: 240/300 - Train loss: 0.35726121068000793, Validation loss: 0.3704851269721985
Epoch: 241/300 - Train loss: 0.3565041124820709, Validation loss: 0.36950936913490295
Epoch: 242/300 - Train loss: 0.3557509481906891, Validation loss: 0.3690771460533142
Epoch: 243/300 - Train loss: 0.35500243306159973, Validation loss: 0.36808520555496216
Epoch: 244/300 - Train loss: 0.35425814986228943, Validation loss: 0.3675001263618469
Epoch: 245/300 - Train loss: 0.35351860523223877, Validation loss: 0.3667528033256531
Epoch: 246/300 - Train loss: 0.35278230905532837, Validation loss: 0.36574849486351013
Epoch: 247/300 - Train loss: 0.3520495593547821, Validation loss: 0.3654058873653412
Epoch: 248/300 - Train loss: 0.35132086277008057, Validation loss: 0.36443382501602173
Epoch: 249/300 - Train loss: 0.350595623254776, Validation loss: 0.3645448684692383
Epoch: 250/300 - Train loss: 0.3498744070529938, Validation loss: 0.36373424530029297
Epoch: 251/300 - Train loss: 0.34915676712989807, Validation loss: 0.36302801966667175
Epoch: 252/300 - Train loss: 0.3484428822994232, Validation loss: 0.36214470863342285
Epoch: 253/300 - Train loss: 0.34773191809654236, Validation loss: 0.36128997802734375
Epoch: 254/300 - Train loss: 0.3470250368118286, Validation loss: 0.3610040247440338
Epoch: 255/300 - Train loss: 0.34632155299186707, Validation loss: 0.36080262064933777
