Epoch: 1/200 - Train loss: 0.5657293200492859, Validation loss: 0.5239622592926025
Epoch: 2/200 - Train loss: 0.4530676305294037, Validation loss: 0.4168420732021332
Epoch: 3/200 - Train loss: 0.3716607093811035, Validation loss: 0.3618745505809784
Epoch: 4/200 - Train loss: 0.32267090678215027, Validation loss: 0.32496878504753113
Epoch: 5/200 - Train loss: 0.29661616683006287, Validation loss: 0.31420034170150757
Epoch: 6/200 - Train loss: 0.27981412410736084, Validation loss: 0.3050808310508728
Epoch: 7/200 - Train loss: 0.2700534462928772, Validation loss: 0.30184486508369446
Epoch: 8/200 - Train loss: 0.26143160462379456, Validation loss: 0.2947932779788971
Epoch: 9/200 - Train loss: 0.2555167078971863, Validation loss: 0.2968371510505676
Epoch: 10/200 - Train loss: 0.25113263726234436, Validation loss: 0.29062557220458984
Epoch: 11/200 - Train loss: 0.24690912663936615, Validation loss: 0.29099467396736145
Epoch: 12/200 - Train loss: 0.24437452852725983, Validation loss: 0.2953815758228302
Epoch: 13/200 - Train loss: 0.2426844984292984, Validation loss: 0.29485517740249634
Epoch: 14/200 - Train loss: 0.24019542336463928, Validation loss: 0.2894374430179596
Epoch: 15/200 - Train loss: 0.23851367831230164, Validation loss: 0.2832132577896118
Epoch: 16/200 - Train loss: 0.23657207190990448, Validation loss: 0.2862658202648163
Epoch: 17/200 - Train loss: 0.23650521039962769, Validation loss: 0.2876281142234802
Epoch: 18/200 - Train loss: 0.23414483666419983, Validation loss: 0.2855290174484253
Epoch: 19/200 - Train loss: 0.23190250992774963, Validation loss: 0.27976828813552856
Epoch: 20/200 - Train loss: 0.2308894693851471, Validation loss: 0.28352952003479004
Epoch: 21/200 - Train loss: 0.22974561154842377, Validation loss: 0.2823508679866791
Epoch: 22/200 - Train loss: 0.22715292870998383, Validation loss: 0.27913710474967957
Epoch: 23/200 - Train loss: 0.2272958904504776, Validation loss: 0.282340943813324
Epoch: 24/200 - Train loss: 0.2247104048728943, Validation loss: 0.2848840653896332
Epoch: 25/200 - Train loss: 0.22396905720233917, Validation loss: 0.2793411910533905
Epoch: 26/200 - Train loss: 0.2220800220966339, Validation loss: 0.27937808632850647
Epoch: 27/200 - Train loss: 0.2234182506799698, Validation loss: 0.2823648452758789
Epoch: 28/200 - Train loss: 0.22278569638729095, Validation loss: 0.2818928360939026
Epoch: 29/200 - Train loss: 0.22164057195186615, Validation loss: 0.2771495282649994
Epoch: 30/200 - Train loss: 0.22072762250900269, Validation loss: 0.2862451672554016
Epoch: 31/200 - Train loss: 0.22036412358283997, Validation loss: 0.2791726291179657
Epoch: 32/200 - Train loss: 0.22000627219676971, Validation loss: 0.28651881217956543
Epoch: 33/200 - Train loss: 0.21897447109222412, Validation loss: 0.28388622403144836
Epoch: 34/200 - Train loss: 0.21844835579395294, Validation loss: 0.2830721139907837
Epoch: 35/200 - Train loss: 0.21963632106781006, Validation loss: 0.2836133539676666
Epoch: 36/200 - Train loss: 0.21718771755695343, Validation loss: 0.28528231382369995
Epoch: 37/200 - Train loss: 0.2184920758008957, Validation loss: 0.28392815589904785
Epoch: 38/200 - Train loss: 0.21844342350959778, Validation loss: 0.2800173759460449
Epoch: 39/200 - Train loss: 0.21616815030574799, Validation loss: 0.2845165431499481
Epoch: 40/200 - Train loss: 0.21617712080478668, Validation loss: 0.2872328460216522
Epoch: 41/200 - Train loss: 0.21569885313510895, Validation loss: 0.2847023010253906
Epoch: 42/200 - Train loss: 0.2170027792453766, Validation loss: 0.28738370537757874
Epoch: 43/200 - Train loss: 0.2162943333387375, Validation loss: 0.28685927391052246
Epoch: 44/200 - Train loss: 0.2144363671541214, Validation loss: 0.28352800011634827
Epoch: 45/200 - Train loss: 0.21599745750427246, Validation loss: 0.2843342423439026
Epoch: 46/200 - Train loss: 0.21464648842811584, Validation loss: 0.2848949134349823
Epoch: 47/200 - Train loss: 0.2143431305885315, Validation loss: 0.28324174880981445
Epoch: 48/200 - Train loss: 0.21393772959709167, Validation loss: 0.2864605188369751
