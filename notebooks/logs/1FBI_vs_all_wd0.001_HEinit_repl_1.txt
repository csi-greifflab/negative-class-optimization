Epoch: 1/300 - Train loss: 0.689387857913971, Validation loss: 0.6879591941833496
Epoch: 2/300 - Train loss: 0.6869291663169861, Validation loss: 0.6854133605957031
Epoch: 3/300 - Train loss: 0.6844569444656372, Validation loss: 0.6828927993774414
Epoch: 4/300 - Train loss: 0.6819597482681274, Validation loss: 0.6802806854248047
Epoch: 5/300 - Train loss: 0.6794249415397644, Validation loss: 0.6775279641151428
Epoch: 6/300 - Train loss: 0.6768404245376587, Validation loss: 0.6748613119125366
Epoch: 7/300 - Train loss: 0.6741895079612732, Validation loss: 0.6720729470252991
Epoch: 8/300 - Train loss: 0.6714591383934021, Validation loss: 0.6692218780517578
Epoch: 9/300 - Train loss: 0.6686330437660217, Validation loss: 0.6661907434463501
Epoch: 10/300 - Train loss: 0.6656988859176636, Validation loss: 0.6631283164024353
Epoch: 11/300 - Train loss: 0.6626477241516113, Validation loss: 0.6599588394165039
Epoch: 12/300 - Train loss: 0.6594725847244263, Validation loss: 0.6565151214599609
Epoch: 13/300 - Train loss: 0.6561679244041443, Validation loss: 0.6529670357704163
Epoch: 14/300 - Train loss: 0.6527256369590759, Validation loss: 0.6493996977806091
Epoch: 15/300 - Train loss: 0.6491414308547974, Validation loss: 0.6456759572029114
Epoch: 16/300 - Train loss: 0.6454133987426758, Validation loss: 0.6416789889335632
Epoch: 17/300 - Train loss: 0.6415393352508545, Validation loss: 0.6377111673355103
Epoch: 18/300 - Train loss: 0.6375205516815186, Validation loss: 0.6334674954414368
Epoch: 19/300 - Train loss: 0.6333594918251038, Validation loss: 0.6289575099945068
Epoch: 20/300 - Train loss: 0.6290563941001892, Validation loss: 0.6245256662368774
Epoch: 21/300 - Train loss: 0.6246132850646973, Validation loss: 0.6198529005050659
Epoch: 22/300 - Train loss: 0.6200350522994995, Validation loss: 0.6150525212287903
Epoch: 23/300 - Train loss: 0.6153260469436646, Validation loss: 0.6102609634399414
Epoch: 24/300 - Train loss: 0.6104933619499207, Validation loss: 0.6051924228668213
Epoch: 25/300 - Train loss: 0.6055389642715454, Validation loss: 0.600064218044281
Epoch: 26/300 - Train loss: 0.6004686951637268, Validation loss: 0.5947848558425903
Epoch: 27/300 - Train loss: 0.5952880382537842, Validation loss: 0.5893233418464661
Epoch: 28/300 - Train loss: 0.5900067090988159, Validation loss: 0.5838198065757751
Epoch: 29/300 - Train loss: 0.5846298336982727, Validation loss: 0.5783959031105042
Epoch: 30/300 - Train loss: 0.5791656374931335, Validation loss: 0.5727475881576538
Epoch: 31/300 - Train loss: 0.5736157298088074, Validation loss: 0.5670953989028931
Epoch: 32/300 - Train loss: 0.567987859249115, Validation loss: 0.5613212585449219
Epoch: 33/300 - Train loss: 0.5622861385345459, Validation loss: 0.555508017539978
Epoch: 34/300 - Train loss: 0.5565168857574463, Validation loss: 0.5495676398277283
Epoch: 35/300 - Train loss: 0.5506899952888489, Validation loss: 0.5434776544570923
Epoch: 36/300 - Train loss: 0.5448135137557983, Validation loss: 0.5373476147651672
Epoch: 37/300 - Train loss: 0.5388936400413513, Validation loss: 0.5315568447113037
Epoch: 38/300 - Train loss: 0.5329364538192749, Validation loss: 0.5254054069519043
Epoch: 39/300 - Train loss: 0.5269508361816406, Validation loss: 0.5194920301437378
Epoch: 40/300 - Train loss: 0.5209464430809021, Validation loss: 0.5132196545600891
Epoch: 41/300 - Train loss: 0.5149280428886414, Validation loss: 0.5069959163665771
Epoch: 42/300 - Train loss: 0.5089033246040344, Validation loss: 0.5009143352508545
Epoch: 43/300 - Train loss: 0.5028778910636902, Validation loss: 0.494703471660614
Epoch: 44/300 - Train loss: 0.4968605637550354, Validation loss: 0.4887946844100952
Epoch: 45/300 - Train loss: 0.4908585548400879, Validation loss: 0.48283249139785767
Epoch: 46/300 - Train loss: 0.4848772883415222, Validation loss: 0.4768046438694
Epoch: 47/300 - Train loss: 0.4789246916770935, Validation loss: 0.4707935154438019
Epoch: 48/300 - Train loss: 0.47300493717193604, Validation loss: 0.4650588035583496
Epoch: 49/300 - Train loss: 0.46712473034858704, Validation loss: 0.4590006172657013
Epoch: 50/300 - Train loss: 0.461288183927536, Validation loss: 0.4529377222061157
Epoch: 51/300 - Train loss: 0.4555013179779053, Validation loss: 0.4470502734184265
Epoch: 52/300 - Train loss: 0.44976913928985596, Validation loss: 0.4415554106235504
Epoch: 53/300 - Train loss: 0.44409674406051636, Validation loss: 0.435747891664505
Epoch: 54/300 - Train loss: 0.4384879171848297, Validation loss: 0.43027448654174805
Epoch: 55/300 - Train loss: 0.4329466223716736, Validation loss: 0.4242883622646332
Epoch: 56/300 - Train loss: 0.42747631669044495, Validation loss: 0.41871026158332825
Epoch: 57/300 - Train loss: 0.4220793843269348, Validation loss: 0.41362398862838745
Epoch: 58/300 - Train loss: 0.4167592227458954, Validation loss: 0.4085490107536316
Epoch: 59/300 - Train loss: 0.41151851415634155, Validation loss: 0.4031466841697693
Epoch: 60/300 - Train loss: 0.40636104345321655, Validation loss: 0.3985320031642914
Epoch: 61/300 - Train loss: 0.4012887477874756, Validation loss: 0.39296770095825195
Epoch: 62/300 - Train loss: 0.3963034749031067, Validation loss: 0.3880385160446167
Epoch: 63/300 - Train loss: 0.3914061486721039, Validation loss: 0.3831418454647064
Epoch: 64/300 - Train loss: 0.3865981101989746, Validation loss: 0.3783451020717621
Epoch: 65/300 - Train loss: 0.3818809688091278, Validation loss: 0.3740772306919098
Epoch: 66/300 - Train loss: 0.37725481390953064, Validation loss: 0.36920619010925293
Epoch: 67/300 - Train loss: 0.3727204203605652, Validation loss: 0.36468884348869324
Epoch: 68/300 - Train loss: 0.36827781796455383, Validation loss: 0.36035147309303284
Epoch: 69/300 - Train loss: 0.3639275133609772, Validation loss: 0.3560623228549957
Epoch: 70/300 - Train loss: 0.35966941714286804, Validation loss: 0.35179877281188965
Epoch: 71/300 - Train loss: 0.3555031716823578, Validation loss: 0.34764957427978516
Epoch: 72/300 - Train loss: 0.3514283001422882, Validation loss: 0.34366631507873535
Epoch: 73/300 - Train loss: 0.3474443554878235, Validation loss: 0.3401782810688019
Epoch: 74/300 - Train loss: 0.3435508906841278, Validation loss: 0.33629587292671204
Epoch: 75/300 - Train loss: 0.3397464454174042, Validation loss: 0.3321446180343628
Epoch: 76/300 - Train loss: 0.33602961897850037, Validation loss: 0.3287515938282013
Epoch: 77/300 - Train loss: 0.33239978551864624, Validation loss: 0.3251160979270935
Epoch: 78/300 - Train loss: 0.3288562595844269, Validation loss: 0.32194843888282776
Epoch: 79/300 - Train loss: 0.32539743185043335, Validation loss: 0.3183845579624176
Epoch: 80/300 - Train loss: 0.32202205061912537, Validation loss: 0.3149147927761078
Epoch: 81/300 - Train loss: 0.3187282681465149, Validation loss: 0.31176748871803284
Epoch: 82/300 - Train loss: 0.31551507115364075, Validation loss: 0.30818143486976624
Epoch: 83/300 - Train loss: 0.3123805522918701, Validation loss: 0.3059355914592743
Epoch: 84/300 - Train loss: 0.3093232810497284, Validation loss: 0.302727073431015
Epoch: 85/300 - Train loss: 0.30634212493896484, Validation loss: 0.29957589507102966
Epoch: 86/300 - Train loss: 0.30343562364578247, Validation loss: 0.2968086898326874
Epoch: 87/300 - Train loss: 0.3006015121936798, Validation loss: 0.29379481077194214
Epoch: 88/300 - Train loss: 0.2978382110595703, Validation loss: 0.29119807481765747
Epoch: 89/300 - Train loss: 0.29514437913894653, Validation loss: 0.2885839343070984
Epoch: 90/300 - Train loss: 0.2925187647342682, Validation loss: 0.2861265242099762
Epoch: 91/300 - Train loss: 0.28995996713638306, Validation loss: 0.28366973996162415
Epoch: 92/300 - Train loss: 0.28746655583381653, Validation loss: 0.28103289008140564
Epoch: 93/300 - Train loss: 0.28503650426864624, Validation loss: 0.27897024154663086
Epoch: 94/300 - Train loss: 0.28266796469688416, Validation loss: 0.2765653729438782
Epoch: 95/300 - Train loss: 0.28035974502563477, Validation loss: 0.27493587136268616
Epoch: 96/300 - Train loss: 0.2781102657318115, Validation loss: 0.2722506821155548
Epoch: 97/300 - Train loss: 0.27591806650161743, Validation loss: 0.27040567994117737
Epoch: 98/300 - Train loss: 0.27378159761428833, Validation loss: 0.2680719792842865
Epoch: 99/300 - Train loss: 0.2716994285583496, Validation loss: 0.2660941183567047
Epoch: 100/300 - Train loss: 0.26967018842697144, Validation loss: 0.2642040252685547
Epoch: 101/300 - Train loss: 0.2676923871040344, Validation loss: 0.2619360089302063
Epoch: 102/300 - Train loss: 0.2657645046710968, Validation loss: 0.2603389620780945
Epoch: 103/300 - Train loss: 0.2638850212097168, Validation loss: 0.258439838886261
Epoch: 104/300 - Train loss: 0.2620528042316437, Validation loss: 0.25721225142478943
Epoch: 105/300 - Train loss: 0.26026651263237, Validation loss: 0.25493451952934265
Epoch: 106/300 - Train loss: 0.25852489471435547, Validation loss: 0.25314387679100037
Epoch: 107/300 - Train loss: 0.256826788187027, Validation loss: 0.2516827881336212
Epoch: 108/300 - Train loss: 0.25517070293426514, Validation loss: 0.24992480874061584
Epoch: 109/300 - Train loss: 0.2535557746887207, Validation loss: 0.24861057102680206
Epoch: 110/300 - Train loss: 0.2519809603691101, Validation loss: 0.24701163172721863
Epoch: 111/300 - Train loss: 0.25044527649879456, Validation loss: 0.2455073893070221
Epoch: 112/300 - Train loss: 0.24894753098487854, Validation loss: 0.24417559802532196
Epoch: 113/300 - Train loss: 0.24748669564723969, Validation loss: 0.24260737001895905
Epoch: 114/300 - Train loss: 0.24606171250343323, Validation loss: 0.2413215935230255
Epoch: 115/300 - Train loss: 0.2446715533733368, Validation loss: 0.23996877670288086
Epoch: 116/300 - Train loss: 0.24331513047218323, Validation loss: 0.23844768106937408
Epoch: 117/300 - Train loss: 0.24199159443378448, Validation loss: 0.23727236688137054
Epoch: 118/300 - Train loss: 0.2407001405954361, Validation loss: 0.23592393100261688
Epoch: 119/300 - Train loss: 0.2394397258758545, Validation loss: 0.23482082784175873
Epoch: 120/300 - Train loss: 0.23820947110652924, Validation loss: 0.23346956074237823
Epoch: 121/300 - Train loss: 0.23700851202011108, Validation loss: 0.2329450398683548
Epoch: 122/300 - Train loss: 0.23583607375621796, Validation loss: 0.23115231096744537
Epoch: 123/300 - Train loss: 0.234691321849823, Validation loss: 0.23057164251804352
Epoch: 124/300 - Train loss: 0.23357345163822174, Validation loss: 0.22951367497444153
Epoch: 125/300 - Train loss: 0.23248174786567688, Validation loss: 0.22855648398399353
Epoch: 126/300 - Train loss: 0.2314155548810959, Validation loss: 0.22703352570533752
Epoch: 127/300 - Train loss: 0.23037417232990265, Validation loss: 0.22617372870445251
Epoch: 128/300 - Train loss: 0.22935692965984344, Validation loss: 0.22561706602573395
Epoch: 129/300 - Train loss: 0.22836321592330933, Validation loss: 0.22458598017692566
Epoch: 130/300 - Train loss: 0.227392315864563, Validation loss: 0.22334007918834686
Epoch: 131/300 - Train loss: 0.2264433652162552, Validation loss: 0.22228245437145233
Epoch: 132/300 - Train loss: 0.22551588714122772, Validation loss: 0.22166985273361206
Epoch: 133/300 - Train loss: 0.22460927069187164, Validation loss: 0.2209605872631073
Epoch: 134/300 - Train loss: 0.22372309863567352, Validation loss: 0.21951982378959656
Epoch: 135/300 - Train loss: 0.222856804728508, Validation loss: 0.21913248300552368
Epoch: 136/300 - Train loss: 0.22200971841812134, Validation loss: 0.2182011604309082
Epoch: 137/300 - Train loss: 0.22118142247200012, Validation loss: 0.217294380068779
Epoch: 138/300 - Train loss: 0.2203713208436966, Validation loss: 0.21646684408187866
Epoch: 139/300 - Train loss: 0.21957902610301971, Validation loss: 0.21602071821689606
Epoch: 140/300 - Train loss: 0.21880394220352173, Validation loss: 0.21516908705234528
Epoch: 141/300 - Train loss: 0.21804559230804443, Validation loss: 0.21474392712116241
Epoch: 142/300 - Train loss: 0.21730352938175201, Validation loss: 0.21374137699604034
Epoch: 143/300 - Train loss: 0.21657726168632507, Validation loss: 0.21317920088768005
Epoch: 144/300 - Train loss: 0.21586652100086212, Validation loss: 0.21265925467014313
Epoch: 145/300 - Train loss: 0.21517078578472137, Validation loss: 0.2124468833208084
Epoch: 146/300 - Train loss: 0.21448969841003418, Validation loss: 0.21145261824131012
Epoch: 147/300 - Train loss: 0.2138228714466095, Validation loss: 0.21052183210849762
Epoch: 148/300 - Train loss: 0.21316993236541748, Validation loss: 0.2100839614868164
Epoch: 149/300 - Train loss: 0.21253059804439545, Validation loss: 0.2092132568359375
Epoch: 150/300 - Train loss: 0.21190449595451355, Validation loss: 0.20918312668800354
Epoch: 151/300 - Train loss: 0.21129123866558075, Validation loss: 0.20835334062576294
Epoch: 152/300 - Train loss: 0.21069051325321198, Validation loss: 0.20794954895973206
Epoch: 153/300 - Train loss: 0.21010194718837738, Validation loss: 0.20724742114543915
Epoch: 154/300 - Train loss: 0.2095252275466919, Validation loss: 0.20641781389713287
Epoch: 155/300 - Train loss: 0.2089601308107376, Validation loss: 0.20608404278755188
Epoch: 156/300 - Train loss: 0.20840640366077423, Validation loss: 0.20590150356292725
