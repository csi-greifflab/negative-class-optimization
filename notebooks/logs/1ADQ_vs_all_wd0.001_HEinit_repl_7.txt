Epoch: 1/300 - Train loss: 0.7023695111274719, Validation loss: 0.7009831070899963
Epoch: 2/300 - Train loss: 0.7000933885574341, Validation loss: 0.6989367604255676
Epoch: 3/300 - Train loss: 0.6979213356971741, Validation loss: 0.6969098448753357
Epoch: 4/300 - Train loss: 0.6958420276641846, Validation loss: 0.6950780749320984
Epoch: 5/300 - Train loss: 0.6938436031341553, Validation loss: 0.6931427717208862
Epoch: 6/300 - Train loss: 0.6919101476669312, Validation loss: 0.6913737654685974
Epoch: 7/300 - Train loss: 0.6900262236595154, Validation loss: 0.6895793080329895
Epoch: 8/300 - Train loss: 0.688179612159729, Validation loss: 0.6877713799476624
Epoch: 9/300 - Train loss: 0.6863585710525513, Validation loss: 0.6861546039581299
Epoch: 10/300 - Train loss: 0.684546709060669, Validation loss: 0.6843794584274292
Epoch: 11/300 - Train loss: 0.6827304363250732, Validation loss: 0.6825539469718933
Epoch: 12/300 - Train loss: 0.680895984172821, Validation loss: 0.680938720703125
Epoch: 13/300 - Train loss: 0.679035484790802, Validation loss: 0.6788904666900635
Epoch: 14/300 - Train loss: 0.677143931388855, Validation loss: 0.6772016286849976
Epoch: 15/300 - Train loss: 0.6752145886421204, Validation loss: 0.6752829551696777
Epoch: 16/300 - Train loss: 0.6732420921325684, Validation loss: 0.6733097434043884
Epoch: 17/300 - Train loss: 0.6712167859077454, Validation loss: 0.6712542772293091
Epoch: 18/300 - Train loss: 0.669131875038147, Validation loss: 0.6692586541175842
Epoch: 19/300 - Train loss: 0.6669877171516418, Validation loss: 0.6671780347824097
Epoch: 20/300 - Train loss: 0.6647803783416748, Validation loss: 0.6648377776145935
Epoch: 21/300 - Train loss: 0.6625077724456787, Validation loss: 0.6627135276794434
Epoch: 22/300 - Train loss: 0.6601640582084656, Validation loss: 0.660385251045227
Epoch: 23/300 - Train loss: 0.6577525734901428, Validation loss: 0.6579718589782715
Epoch: 24/300 - Train loss: 0.6552675366401672, Validation loss: 0.6553608775138855
Epoch: 25/300 - Train loss: 0.6527099609375, Validation loss: 0.6531192660331726
Epoch: 26/300 - Train loss: 0.6500784158706665, Validation loss: 0.650481104850769
Epoch: 27/300 - Train loss: 0.6473796367645264, Validation loss: 0.6476980447769165
Epoch: 28/300 - Train loss: 0.644611656665802, Validation loss: 0.6449479460716248
Epoch: 29/300 - Train loss: 0.6417754888534546, Validation loss: 0.6420080661773682
Epoch: 30/300 - Train loss: 0.6388805508613586, Validation loss: 0.6391919255256653
Epoch: 31/300 - Train loss: 0.6359291076660156, Validation loss: 0.6361576318740845
Epoch: 32/300 - Train loss: 0.632927417755127, Validation loss: 0.6335017085075378
Epoch: 33/300 - Train loss: 0.6298691630363464, Validation loss: 0.6304636597633362
Epoch: 34/300 - Train loss: 0.62676602602005, Validation loss: 0.6272570490837097
Epoch: 35/300 - Train loss: 0.6236226558685303, Validation loss: 0.624168336391449
Epoch: 36/300 - Train loss: 0.6204423904418945, Validation loss: 0.6212750673294067
Epoch: 37/300 - Train loss: 0.6172264218330383, Validation loss: 0.6179901361465454
Epoch: 38/300 - Train loss: 0.6139893531799316, Validation loss: 0.6146208047866821
Epoch: 39/300 - Train loss: 0.6107445359230042, Validation loss: 0.6117203831672668
Epoch: 40/300 - Train loss: 0.6074995994567871, Validation loss: 0.6085159778594971
Epoch: 41/300 - Train loss: 0.6042554378509521, Validation loss: 0.605457067489624
Epoch: 42/300 - Train loss: 0.6010192036628723, Validation loss: 0.6025024652481079
Epoch: 43/300 - Train loss: 0.5977978706359863, Validation loss: 0.5990499258041382
Epoch: 44/300 - Train loss: 0.5945962071418762, Validation loss: 0.5962364077568054
Epoch: 45/300 - Train loss: 0.5914137363433838, Validation loss: 0.5932255983352661
Epoch: 46/300 - Train loss: 0.5882551670074463, Validation loss: 0.5901728868484497
Epoch: 47/300 - Train loss: 0.5851258039474487, Validation loss: 0.5869361162185669
Epoch: 48/300 - Train loss: 0.5820267200469971, Validation loss: 0.5843935608863831
Epoch: 49/300 - Train loss: 0.578963577747345, Validation loss: 0.5812761187553406
Epoch: 50/300 - Train loss: 0.5759410858154297, Validation loss: 0.5785390734672546
Epoch: 51/300 - Train loss: 0.5729634165763855, Validation loss: 0.5758098363876343
Epoch: 52/300 - Train loss: 0.5700361728668213, Validation loss: 0.5727978348731995
Epoch: 53/300 - Train loss: 0.5671635866165161, Validation loss: 0.5702760815620422
Epoch: 54/300 - Train loss: 0.5643492341041565, Validation loss: 0.5678427219390869
Epoch: 55/300 - Train loss: 0.561595618724823, Validation loss: 0.5646533966064453
Epoch: 56/300 - Train loss: 0.5589026212692261, Validation loss: 0.5621404647827148
Epoch: 57/300 - Train loss: 0.5562705993652344, Validation loss: 0.5597797632217407
Epoch: 58/300 - Train loss: 0.553702175617218, Validation loss: 0.55752032995224
Epoch: 59/300 - Train loss: 0.5511988401412964, Validation loss: 0.5548884272575378
Epoch: 60/300 - Train loss: 0.5487597584724426, Validation loss: 0.5529714226722717
Epoch: 61/300 - Train loss: 0.546385645866394, Validation loss: 0.5508682131767273
Epoch: 62/300 - Train loss: 0.5440770983695984, Validation loss: 0.5487388968467712
Epoch: 63/300 - Train loss: 0.5418347716331482, Validation loss: 0.5465908646583557
Epoch: 64/300 - Train loss: 0.5396588444709778, Validation loss: 0.5445300936698914
Epoch: 65/300 - Train loss: 0.5375489592552185, Validation loss: 0.5422691106796265
Epoch: 66/300 - Train loss: 0.535504937171936, Validation loss: 0.5404810905456543
Epoch: 67/300 - Train loss: 0.5335239768028259, Validation loss: 0.5384124517440796
Epoch: 68/300 - Train loss: 0.5316052436828613, Validation loss: 0.5369861721992493
Epoch: 69/300 - Train loss: 0.5297474265098572, Validation loss: 0.5354681611061096
Epoch: 70/300 - Train loss: 0.5279483795166016, Validation loss: 0.5332837700843811
Epoch: 71/300 - Train loss: 0.5262072682380676, Validation loss: 0.5321996808052063
Epoch: 72/300 - Train loss: 0.5245203971862793, Validation loss: 0.5303335785865784
Epoch: 73/300 - Train loss: 0.5228865742683411, Validation loss: 0.5290201306343079
Epoch: 74/300 - Train loss: 0.5213034749031067, Validation loss: 0.5270549654960632
Epoch: 75/300 - Train loss: 0.5197702050209045, Validation loss: 0.5260981321334839
Epoch: 76/300 - Train loss: 0.5182843804359436, Validation loss: 0.524815559387207
Epoch: 77/300 - Train loss: 0.5168441534042358, Validation loss: 0.5234665274620056
Epoch: 78/300 - Train loss: 0.5154450535774231, Validation loss: 0.5218154191970825
Epoch: 79/300 - Train loss: 0.5140844583511353, Validation loss: 0.5210872292518616
Epoch: 80/300 - Train loss: 0.5127615332603455, Validation loss: 0.5196391940116882
Epoch: 81/300 - Train loss: 0.5114755034446716, Validation loss: 0.5189937353134155
Epoch: 82/300 - Train loss: 0.5102251768112183, Validation loss: 0.5174379944801331
Epoch: 83/300 - Train loss: 0.5090096592903137, Validation loss: 0.5163120031356812
Epoch: 84/300 - Train loss: 0.5078238844871521, Validation loss: 0.515534520149231
Epoch: 85/300 - Train loss: 0.5066670179367065, Validation loss: 0.5142351388931274
Epoch: 86/300 - Train loss: 0.5055378675460815, Validation loss: 0.5137938857078552
Epoch: 87/300 - Train loss: 0.5044332146644592, Validation loss: 0.5117864012718201
Epoch: 88/300 - Train loss: 0.5033504962921143, Validation loss: 0.5113131999969482
Epoch: 89/300 - Train loss: 0.5022901892662048, Validation loss: 0.510201632976532
Epoch: 90/300 - Train loss: 0.5012505054473877, Validation loss: 0.5091328024864197
Epoch: 91/300 - Train loss: 0.5002299547195435, Validation loss: 0.5084726810455322
Epoch: 92/300 - Train loss: 0.4992276728153229, Validation loss: 0.5073521733283997
Epoch: 93/300 - Train loss: 0.49824222922325134, Validation loss: 0.5061204433441162
Epoch: 94/300 - Train loss: 0.49727338552474976, Validation loss: 0.5055325031280518
Epoch: 95/300 - Train loss: 0.4963197410106659, Validation loss: 0.504901647567749
Epoch: 96/300 - Train loss: 0.4953802824020386, Validation loss: 0.5038866400718689
Epoch: 97/300 - Train loss: 0.4944542646408081, Validation loss: 0.5031483769416809
Epoch: 98/300 - Train loss: 0.49353787302970886, Validation loss: 0.5019519329071045
Epoch: 99/300 - Train loss: 0.49263107776641846, Validation loss: 0.5015172958374023
Epoch: 100/300 - Train loss: 0.49173346161842346, Validation loss: 0.5007744431495667
Epoch: 101/300 - Train loss: 0.4908480942249298, Validation loss: 0.4992995858192444
Epoch: 102/300 - Train loss: 0.48997247219085693, Validation loss: 0.4983324706554413
Epoch: 103/300 - Train loss: 0.4891054332256317, Validation loss: 0.49810850620269775
Epoch: 104/300 - Train loss: 0.4882467985153198, Validation loss: 0.4964783191680908
Epoch: 105/300 - Train loss: 0.487393856048584, Validation loss: 0.49577927589416504
Epoch: 106/300 - Train loss: 0.48654747009277344, Validation loss: 0.49581360816955566
Epoch: 107/300 - Train loss: 0.4857107102870941, Validation loss: 0.4946293532848358
Epoch: 108/300 - Train loss: 0.48488152027130127, Validation loss: 0.49343761801719666
Epoch: 109/300 - Train loss: 0.48405900597572327, Validation loss: 0.4936385154724121
Epoch: 110/300 - Train loss: 0.4832436740398407, Validation loss: 0.49177125096321106
Epoch: 111/300 - Train loss: 0.4824342429637909, Validation loss: 0.49141985177993774
Epoch: 112/300 - Train loss: 0.481629341840744, Validation loss: 0.49091893434524536
Epoch: 113/300 - Train loss: 0.48083046078681946, Validation loss: 0.48972657322883606
Epoch: 114/300 - Train loss: 0.4800399839878082, Validation loss: 0.4890963137149811
Epoch: 115/300 - Train loss: 0.4792569577693939, Validation loss: 0.4886649250984192
Epoch: 116/300 - Train loss: 0.47848036885261536, Validation loss: 0.4874778389930725
Epoch: 117/300 - Train loss: 0.47770798206329346, Validation loss: 0.4867000877857208
Epoch: 118/300 - Train loss: 0.4769400954246521, Validation loss: 0.48603031039237976
Epoch: 119/300 - Train loss: 0.4761771559715271, Validation loss: 0.485391765832901
Epoch: 120/300 - Train loss: 0.4754185378551483, Validation loss: 0.48446130752563477
Epoch: 121/300 - Train loss: 0.47466355562210083, Validation loss: 0.4840735197067261
Epoch: 122/300 - Train loss: 0.4739118814468384, Validation loss: 0.48370620608329773
Epoch: 123/300 - Train loss: 0.4731658697128296, Validation loss: 0.4821566045284271
Epoch: 124/300 - Train loss: 0.47242459654808044, Validation loss: 0.4824604094028473
Epoch: 125/300 - Train loss: 0.4716891646385193, Validation loss: 0.4806858003139496
Epoch: 126/300 - Train loss: 0.47095784544944763, Validation loss: 0.4804421067237854
Epoch: 127/300 - Train loss: 0.4702308773994446, Validation loss: 0.47961342334747314
Epoch: 128/300 - Train loss: 0.4695059657096863, Validation loss: 0.4787902235984802
Epoch: 129/300 - Train loss: 0.4687845706939697, Validation loss: 0.47805967926979065
Epoch: 130/300 - Train loss: 0.46806758642196655, Validation loss: 0.4779050052165985
Epoch: 131/300 - Train loss: 0.46735337376594543, Validation loss: 0.4765958786010742
Epoch: 132/300 - Train loss: 0.4666409194469452, Validation loss: 0.47572845220565796
Epoch: 133/300 - Train loss: 0.4659312069416046, Validation loss: 0.47549837827682495
Epoch: 134/300 - Train loss: 0.4652245044708252, Validation loss: 0.4748663902282715
Epoch: 135/300 - Train loss: 0.4645189344882965, Validation loss: 0.47442832589149475
Epoch: 136/300 - Train loss: 0.463816374540329, Validation loss: 0.47318190336227417
Epoch: 137/300 - Train loss: 0.4631146490573883, Validation loss: 0.47269725799560547
Epoch: 138/300 - Train loss: 0.46241509914398193, Validation loss: 0.472096711397171
Epoch: 139/300 - Train loss: 0.46171751618385315, Validation loss: 0.47171810269355774
Epoch: 140/300 - Train loss: 0.4610235393047333, Validation loss: 0.4706585109233856
Epoch: 141/300 - Train loss: 0.4603313207626343, Validation loss: 0.46989667415618896
Epoch: 142/300 - Train loss: 0.45963987708091736, Validation loss: 0.4695988595485687
Epoch: 143/300 - Train loss: 0.45895013213157654, Validation loss: 0.46907684206962585
Epoch: 144/300 - Train loss: 0.4582625925540924, Validation loss: 0.4680270850658417
Epoch: 145/300 - Train loss: 0.45757704973220825, Validation loss: 0.4678816795349121
Epoch: 146/300 - Train loss: 0.4568937122821808, Validation loss: 0.4669259190559387
Epoch: 147/300 - Train loss: 0.45621365308761597, Validation loss: 0.4662775695323944
Epoch: 148/300 - Train loss: 0.4555373787879944, Validation loss: 0.4654257893562317
Epoch: 149/300 - Train loss: 0.45486289262771606, Validation loss: 0.4653136134147644
Epoch: 150/300 - Train loss: 0.4541907012462616, Validation loss: 0.46474283933639526
Epoch: 151/300 - Train loss: 0.45352065563201904, Validation loss: 0.46336278319358826
Epoch: 152/300 - Train loss: 0.45285269618034363, Validation loss: 0.4630656838417053
Epoch: 153/300 - Train loss: 0.45218613743782043, Validation loss: 0.4619198441505432
Epoch: 154/300 - Train loss: 0.4515218138694763, Validation loss: 0.4616473913192749
Epoch: 155/300 - Train loss: 0.4508567154407501, Validation loss: 0.4611091911792755
Epoch: 156/300 - Train loss: 0.4501901865005493, Validation loss: 0.4612925052642822
Epoch: 157/300 - Train loss: 0.44952234625816345, Validation loss: 0.4598070979118347
Epoch: 158/300 - Train loss: 0.4488530457019806, Validation loss: 0.45934873819351196
Epoch: 159/300 - Train loss: 0.44818276166915894, Validation loss: 0.4587453007698059
Epoch: 160/300 - Train loss: 0.4475124478340149, Validation loss: 0.4581833481788635
Epoch: 161/300 - Train loss: 0.44684138894081116, Validation loss: 0.4579457640647888
Epoch: 162/300 - Train loss: 0.4461698532104492, Validation loss: 0.4563599228858948
Epoch: 163/300 - Train loss: 0.4454982280731201, Validation loss: 0.45620253682136536
Epoch: 164/300 - Train loss: 0.4448261559009552, Validation loss: 0.4565170407295227
Epoch: 165/300 - Train loss: 0.4441553056240082, Validation loss: 0.45477283000946045
Epoch: 166/300 - Train loss: 0.44348466396331787, Validation loss: 0.45452067255973816
Epoch: 167/300 - Train loss: 0.4428156912326813, Validation loss: 0.45378750562667847
Epoch: 168/300 - Train loss: 0.4421485662460327, Validation loss: 0.4535475969314575
Epoch: 169/300 - Train loss: 0.4414844214916229, Validation loss: 0.45343685150146484
