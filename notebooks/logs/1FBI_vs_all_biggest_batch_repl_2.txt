Epoch: 1/300 - Train loss: 0.6935043931007385, Validation loss: 0.6896428465843201
Epoch: 2/300 - Train loss: 0.689920961856842, Validation loss: 0.6861261129379272
Epoch: 3/300 - Train loss: 0.6864324808120728, Validation loss: 0.6824795007705688
Epoch: 4/300 - Train loss: 0.6829318404197693, Validation loss: 0.6788250803947449
Epoch: 5/300 - Train loss: 0.6793354153633118, Validation loss: 0.6749902367591858
Epoch: 6/300 - Train loss: 0.6755896806716919, Validation loss: 0.6709187626838684
Epoch: 7/300 - Train loss: 0.671663224697113, Validation loss: 0.6666423678398132
Epoch: 8/300 - Train loss: 0.6675330996513367, Validation loss: 0.6621795296669006
Epoch: 9/300 - Train loss: 0.6631857752799988, Validation loss: 0.6574552059173584
Epoch: 10/300 - Train loss: 0.6586158275604248, Validation loss: 0.6524910926818848
Epoch: 11/300 - Train loss: 0.6538184285163879, Validation loss: 0.6472509503364563
Epoch: 12/300 - Train loss: 0.6488019824028015, Validation loss: 0.6419008374214172
Epoch: 13/300 - Train loss: 0.6435893177986145, Validation loss: 0.6363753080368042
Epoch: 14/300 - Train loss: 0.6381978988647461, Validation loss: 0.6306090950965881
Epoch: 15/300 - Train loss: 0.6326504349708557, Validation loss: 0.6249111294746399
Epoch: 16/300 - Train loss: 0.6269698143005371, Validation loss: 0.6190241575241089
Epoch: 17/300 - Train loss: 0.621185302734375, Validation loss: 0.6129809021949768
Epoch: 18/300 - Train loss: 0.6153234839439392, Validation loss: 0.6067852973937988
Epoch: 19/300 - Train loss: 0.6093986630439758, Validation loss: 0.6007105112075806
Epoch: 20/300 - Train loss: 0.6034242510795593, Validation loss: 0.5947670936584473
Epoch: 21/300 - Train loss: 0.5974130630493164, Validation loss: 0.5886462330818176
Epoch: 22/300 - Train loss: 0.5913722515106201, Validation loss: 0.5824400186538696
Epoch: 23/300 - Train loss: 0.5853091478347778, Validation loss: 0.5762794017791748
Epoch: 24/300 - Train loss: 0.5792272090911865, Validation loss: 0.5702425241470337
Epoch: 25/300 - Train loss: 0.5731292963027954, Validation loss: 0.5637705326080322
Epoch: 26/300 - Train loss: 0.5670162439346313, Validation loss: 0.5578560829162598
Epoch: 27/300 - Train loss: 0.5608919262886047, Validation loss: 0.5513991117477417
Epoch: 28/300 - Train loss: 0.5547593832015991, Validation loss: 0.5454021692276001
Epoch: 29/300 - Train loss: 0.548622727394104, Validation loss: 0.5390743017196655
Epoch: 30/300 - Train loss: 0.5424860119819641, Validation loss: 0.5326544046401978
Epoch: 31/300 - Train loss: 0.5363519787788391, Validation loss: 0.5267496705055237
Epoch: 32/300 - Train loss: 0.5302265286445618, Validation loss: 0.5204631090164185
Epoch: 33/300 - Train loss: 0.5241147875785828, Validation loss: 0.5144795179367065
Epoch: 34/300 - Train loss: 0.5180214643478394, Validation loss: 0.5084262490272522
Epoch: 35/300 - Train loss: 0.5119514465332031, Validation loss: 0.5022453665733337
Epoch: 36/300 - Train loss: 0.505908191204071, Validation loss: 0.4961993396282196
Epoch: 37/300 - Train loss: 0.49989742040634155, Validation loss: 0.4903525114059448
Epoch: 38/300 - Train loss: 0.4939228594303131, Validation loss: 0.48429280519485474
Epoch: 39/300 - Train loss: 0.48798683285713196, Validation loss: 0.47850412130355835
Epoch: 40/300 - Train loss: 0.4820927083492279, Validation loss: 0.47264862060546875
Epoch: 41/300 - Train loss: 0.47624337673187256, Validation loss: 0.4668409824371338
Epoch: 42/300 - Train loss: 0.47044265270233154, Validation loss: 0.4608081579208374
Epoch: 43/300 - Train loss: 0.4646931290626526, Validation loss: 0.4552806317806244
Epoch: 44/300 - Train loss: 0.45899784564971924, Validation loss: 0.4497794210910797
Epoch: 45/300 - Train loss: 0.45335838198661804, Validation loss: 0.44418373703956604
Epoch: 46/300 - Train loss: 0.4477778375148773, Validation loss: 0.4387081265449524
Epoch: 47/300 - Train loss: 0.44225820899009705, Validation loss: 0.4331943392753601
Epoch: 48/300 - Train loss: 0.43680164217948914, Validation loss: 0.4276038110256195
Epoch: 49/300 - Train loss: 0.43140995502471924, Validation loss: 0.4225179851055145
Epoch: 50/300 - Train loss: 0.4260844588279724, Validation loss: 0.4170781672000885
Epoch: 51/300 - Train loss: 0.4208276867866516, Validation loss: 0.4120326340198517
Epoch: 52/300 - Train loss: 0.41564130783081055, Validation loss: 0.4068659842014313
Epoch: 53/300 - Train loss: 0.4105265736579895, Validation loss: 0.40186455845832825
Epoch: 54/300 - Train loss: 0.40548521280288696, Validation loss: 0.3967832624912262
Epoch: 55/300 - Train loss: 0.4005182683467865, Validation loss: 0.392147421836853
Epoch: 56/300 - Train loss: 0.3956271708011627, Validation loss: 0.387134313583374
Epoch: 57/300 - Train loss: 0.39081278443336487, Validation loss: 0.38239118456840515
Epoch: 58/300 - Train loss: 0.38607582449913025, Validation loss: 0.37777242064476013
Epoch: 59/300 - Train loss: 0.3814173638820648, Validation loss: 0.37348610162734985
Epoch: 60/300 - Train loss: 0.3768380582332611, Validation loss: 0.36881160736083984
Epoch: 61/300 - Train loss: 0.37233826518058777, Validation loss: 0.3644475042819977
Epoch: 62/300 - Train loss: 0.3679186701774597, Validation loss: 0.36018651723861694
Epoch: 63/300 - Train loss: 0.36357927322387695, Validation loss: 0.35610106587409973
Epoch: 64/300 - Train loss: 0.35932064056396484, Validation loss: 0.3517405092716217
Epoch: 65/300 - Train loss: 0.3551426827907562, Validation loss: 0.34718912839889526
Epoch: 66/300 - Train loss: 0.3510451018810272, Validation loss: 0.3437836468219757
Epoch: 67/300 - Train loss: 0.34702789783477783, Validation loss: 0.3394666612148285
Epoch: 68/300 - Train loss: 0.343090683221817, Validation loss: 0.33535343408584595
Epoch: 69/300 - Train loss: 0.3392332196235657, Validation loss: 0.332376629114151
Epoch: 70/300 - Train loss: 0.33545494079589844, Validation loss: 0.32829543948173523
Epoch: 71/300 - Train loss: 0.3317553699016571, Validation loss: 0.3246862292289734
Epoch: 72/300 - Train loss: 0.3281339406967163, Validation loss: 0.3214746415615082
Epoch: 73/300 - Train loss: 0.32459011673927307, Validation loss: 0.3181268572807312
Epoch: 74/300 - Train loss: 0.3211227059364319, Validation loss: 0.31428974866867065
Epoch: 75/300 - Train loss: 0.3177310824394226, Validation loss: 0.3112385869026184
Epoch: 76/300 - Train loss: 0.3144141137599945, Validation loss: 0.3077351450920105
Epoch: 77/300 - Train loss: 0.3111710846424103, Validation loss: 0.3045347034931183
Epoch: 78/300 - Train loss: 0.30800095200538635, Validation loss: 0.30178484320640564
Epoch: 79/300 - Train loss: 0.3049026131629944, Validation loss: 0.29922744631767273
Epoch: 80/300 - Train loss: 0.3018744885921478, Validation loss: 0.29587024450302124
Epoch: 81/300 - Train loss: 0.2989157736301422, Validation loss: 0.29275253415107727
Epoch: 82/300 - Train loss: 0.2960249185562134, Validation loss: 0.2898663282394409
Epoch: 83/300 - Train loss: 0.29320085048675537, Validation loss: 0.2870921194553375
Epoch: 84/300 - Train loss: 0.29044219851493835, Validation loss: 0.2845214009284973
Epoch: 85/300 - Train loss: 0.28774771094322205, Validation loss: 0.28238940238952637
Epoch: 86/300 - Train loss: 0.28511643409729004, Validation loss: 0.28036707639694214
Epoch: 87/300 - Train loss: 0.28254711627960205, Validation loss: 0.2768694758415222
Epoch: 88/300 - Train loss: 0.28003838658332825, Validation loss: 0.2748839259147644
Epoch: 89/300 - Train loss: 0.27758872509002686, Validation loss: 0.2721444368362427
Epoch: 90/300 - Train loss: 0.27519690990448, Validation loss: 0.2697189152240753
Epoch: 91/300 - Train loss: 0.2728615403175354, Validation loss: 0.267485648393631
Epoch: 92/300 - Train loss: 0.27058154344558716, Validation loss: 0.265349417924881
Epoch: 93/300 - Train loss: 0.2683556377887726, Validation loss: 0.26347634196281433
Epoch: 94/300 - Train loss: 0.2661820948123932, Validation loss: 0.26107388734817505
Epoch: 95/300 - Train loss: 0.26405981183052063, Validation loss: 0.25944095849990845
Epoch: 96/300 - Train loss: 0.26198774576187134, Validation loss: 0.2570194900035858
Epoch: 97/300 - Train loss: 0.25996458530426025, Validation loss: 0.2548666000366211
Epoch: 98/300 - Train loss: 0.25798922777175903, Validation loss: 0.25328436493873596
Epoch: 99/300 - Train loss: 0.25606003403663635, Validation loss: 0.2513796389102936
Epoch: 100/300 - Train loss: 0.25417619943618774, Validation loss: 0.24975652992725372
Epoch: 101/300 - Train loss: 0.2523367404937744, Validation loss: 0.2478877305984497
Epoch: 102/300 - Train loss: 0.25054022669792175, Validation loss: 0.24606721103191376
Epoch: 103/300 - Train loss: 0.24878562986850739, Validation loss: 0.24464192986488342
Epoch: 104/300 - Train loss: 0.2470717430114746, Validation loss: 0.2431359440088272
Epoch: 105/300 - Train loss: 0.2453974187374115, Validation loss: 0.24131354689598083
Epoch: 106/300 - Train loss: 0.2437618374824524, Validation loss: 0.2394288331270218
Epoch: 107/300 - Train loss: 0.24216404557228088, Validation loss: 0.23807279765605927
Epoch: 108/300 - Train loss: 0.24060280621051788, Validation loss: 0.23649050295352936
Epoch: 109/300 - Train loss: 0.23907724022865295, Validation loss: 0.23525448143482208
Epoch: 110/300 - Train loss: 0.2375863492488861, Validation loss: 0.23361778259277344
Epoch: 111/300 - Train loss: 0.23612947762012482, Validation loss: 0.23260796070098877
Epoch: 112/300 - Train loss: 0.2347056120634079, Validation loss: 0.23077206313610077
Epoch: 113/300 - Train loss: 0.23331397771835327, Validation loss: 0.22987811267375946
Epoch: 114/300 - Train loss: 0.23195374011993408, Validation loss: 0.2282877117395401
Epoch: 115/300 - Train loss: 0.2306239753961563, Validation loss: 0.22755713760852814
Epoch: 116/300 - Train loss: 0.22932389378547668, Validation loss: 0.22664956748485565
Epoch: 117/300 - Train loss: 0.2280527949333191, Validation loss: 0.22483640909194946
Epoch: 118/300 - Train loss: 0.2268098145723343, Validation loss: 0.22354713082313538
Epoch: 119/300 - Train loss: 0.22559429705142975, Validation loss: 0.22284117341041565
Epoch: 120/300 - Train loss: 0.2244054228067398, Validation loss: 0.2215535044670105
Epoch: 121/300 - Train loss: 0.22324258089065552, Validation loss: 0.2203282117843628
Epoch: 122/300 - Train loss: 0.22210507094860077, Validation loss: 0.21960917115211487
Epoch: 123/300 - Train loss: 0.22099222242832184, Validation loss: 0.21855886280536652
Epoch: 124/300 - Train loss: 0.21990351378917694, Validation loss: 0.21702700853347778
Epoch: 125/300 - Train loss: 0.21883819997310638, Validation loss: 0.2159782201051712
Epoch: 126/300 - Train loss: 0.21779578924179077, Validation loss: 0.21491338312625885
Epoch: 127/300 - Train loss: 0.21677552163600922, Validation loss: 0.21405507624149323
Epoch: 128/300 - Train loss: 0.21577681601047516, Validation loss: 0.21358060836791992
Epoch: 129/300 - Train loss: 0.21479915082454681, Validation loss: 0.21165232360363007
Epoch: 130/300 - Train loss: 0.2138419896364212, Validation loss: 0.2113434225320816
Epoch: 131/300 - Train loss: 0.21290482580661774, Validation loss: 0.2105017453432083
Epoch: 132/300 - Train loss: 0.21198713779449463, Validation loss: 0.20945629477500916
Epoch: 133/300 - Train loss: 0.21108846366405487, Validation loss: 0.20859308540821075
Epoch: 134/300 - Train loss: 0.21020829677581787, Validation loss: 0.20821689069271088
Epoch: 135/300 - Train loss: 0.2093460112810135, Validation loss: 0.20786166191101074
Epoch: 136/300 - Train loss: 0.20850132405757904, Validation loss: 0.20691102743148804
Epoch: 137/300 - Train loss: 0.2076738029718399, Validation loss: 0.20581211149692535
Epoch: 138/300 - Train loss: 0.20686303079128265, Validation loss: 0.20431244373321533
Epoch: 139/300 - Train loss: 0.2060685008764267, Validation loss: 0.20430244505405426
Epoch: 140/300 - Train loss: 0.2052898406982422, Validation loss: 0.20312732458114624
Epoch: 141/300 - Train loss: 0.20452670753002167, Validation loss: 0.20319759845733643
Epoch: 142/300 - Train loss: 0.20377865433692932, Validation loss: 0.20230397582054138
Epoch: 143/300 - Train loss: 0.20304541289806366, Validation loss: 0.20190420746803284
Epoch: 144/300 - Train loss: 0.20232658088207245, Validation loss: 0.2005842626094818
Epoch: 145/300 - Train loss: 0.20162175595760345, Validation loss: 0.20043398439884186
Epoch: 146/300 - Train loss: 0.20093059539794922, Validation loss: 0.1995427906513214
Epoch: 147/300 - Train loss: 0.20025283098220825, Validation loss: 0.19898486137390137
Epoch: 148/300 - Train loss: 0.1995881199836731, Validation loss: 0.19828194379806519
Epoch: 149/300 - Train loss: 0.19893616437911987, Validation loss: 0.19730444252490997
Epoch: 150/300 - Train loss: 0.1982966512441635, Validation loss: 0.19682084023952484
Epoch: 151/300 - Train loss: 0.19766926765441895, Validation loss: 0.1960066258907318
Epoch: 152/300 - Train loss: 0.1970537006855011, Validation loss: 0.19585658609867096
Epoch: 153/300 - Train loss: 0.19644974172115326, Validation loss: 0.19528761506080627
Epoch: 154/300 - Train loss: 0.1958570033311844, Validation loss: 0.1947496086359024
Epoch: 155/300 - Train loss: 0.19527532160282135, Validation loss: 0.19427941739559174
Epoch: 156/300 - Train loss: 0.19470441341400146, Validation loss: 0.19388464093208313
Epoch: 157/300 - Train loss: 0.19414407014846802, Validation loss: 0.1932278722524643
Epoch: 158/300 - Train loss: 0.1935940384864807, Validation loss: 0.19251155853271484
