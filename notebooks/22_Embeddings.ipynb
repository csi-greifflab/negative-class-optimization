{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "We explore the added value of embeddings in the prediction of antigen specificity.\n",
    "\n",
    "We develop `script_11_compute_embeddings.py` to compute embeddings for the sequences in the global dataset, to be later used with models.\n",
    "\n",
    "From [`bio-embeddings`](https://docs.bioembeddings.com/v0.2.3/#):\n",
    "- preference is for `prottrans_t5_xl_u50`, followed by `esm1b`\n",
    "\n",
    "Notes\n",
    "- Installing `bio-embeddings` with pip is annoying. Had issues installing jsonnet and had to install separately through conda, not pip. Afterwards, installation of `bio-embeddings[all]` worked.\n",
    "- Download model files separately, check link from [my other github repo](https://github.com/ursueugen/ir-ageing/blob/main/02a_aminoacid_embeddings.ipynb).\n",
    "    - Downloading is slow, leave overnight (~8GB per model, for the large ones).\n",
    "    - Links for downloading models\n",
    "        - esm1b:\n",
    "            - model_file: http://data.bioembeddings.com/public/embeddings/embedding_models/esm1b/esm1b_t33_650M_UR50S.pt\n",
    "        - prottrans_t5_xl_u50:\n",
    "            - model_directory: http://data.bioembeddings.com/public/embeddings/embedding_models/t5/prottrans_t5_xl_u50.zip\n",
    "            - half_precision_model_directory: http://data.bioembeddings.com/public/embeddings/embedding_models/t5/half_prottrans_t5_xl_u50.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from NegativeClassOptimization import ml\n",
    "from NegativeClassOptimization import utils\n",
    "from NegativeClassOptimization import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_pos = \"3VRL\"\n",
    "ag_neg = \"1ADQ\"\n",
    "df_train, df_test = utils.load_sample_binary_dataset(ag_pos, ag_neg, num_samples=20000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TLLFPHWYFDV'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide = df_train[\"Slide\"].iloc[0]\n",
    "slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1280) (11, 1024)\n"
     ]
    }
   ],
   "source": [
    "esm1b_embedder = preprocessing.load_embedder(\"ESM1b\")\n",
    "esm1b_embedding = esm1b_embedder.embed(slide)\n",
    "esm1b_embedder.reduce_per_protein(esm1b_embedding)\n",
    "\n",
    "pt_embedder = preprocessing.load_embedder(\"ProtTransT5XLU50\")\n",
    "pt_embedding = pt_embedder.embed(slide)\n",
    "pt_embedder.reduce_per_protein(pt_embedding)\n",
    "\n",
    "print(esm1b_embedding.shape, pt_embedding.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo: adding embeddings to slides from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460483, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_slide_Variant</th>\n",
       "      <th>CDR3</th>\n",
       "      <th>Best</th>\n",
       "      <th>Slide</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Structure</th>\n",
       "      <th>UID</th>\n",
       "      <th>Antigen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5319791_04a</td>\n",
       "      <td>CARSAAFITTVGWYFDVW</td>\n",
       "      <td>True</td>\n",
       "      <td>AAFITTVGWYF</td>\n",
       "      <td>-94.7</td>\n",
       "      <td>128933-BRRSLUDUUS</td>\n",
       "      <td>1ADQ_5319791_04a</td>\n",
       "      <td>1ADQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_slide_Variant                CDR3  Best        Slide  Energy  \\\n",
       "0      5319791_04a  CARSAAFITTVGWYFDVW  True  AAFITTVGWYF   -94.7   \n",
       "\n",
       "           Structure               UID Antigen  \n",
       "0  128933-BRRSLUDUUS  1ADQ_5319791_04a    1ADQ  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.load_global_dataframe()\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_embeddings_per_residue = {}\n",
    "slide_embeddings_per_prot = {}\n",
    "\n",
    "for slide in df[\"Slide\"].iloc[:100]:\n",
    "    \n",
    "    esm1b_emb = esm1b_embedder.embed(slide)\n",
    "    esm1b_emb_per_prot = esm1b_embedder.reduce_per_protein(esm1b_emb)\n",
    "\n",
    "    pt_emb = pt_embedder.embed(slide)\n",
    "    pt_emb_per_prot = pt_embedder.reduce_per_protein(pt_emb)\n",
    "\n",
    "    slide_embeddings_per_residue[slide] = {\n",
    "        \"ESM1b\": esm1b_emb.tolist(),\n",
    "        \"ProtTransT5XLU50\": pt_emb.tolist(),\n",
    "    }\n",
    "    slide_embeddings_per_prot[slide] = {\n",
    "        \"ESM1b\": esm1b_emb_per_prot.tolist(),\n",
    "        \"ProtTransT5XLU50\": pt_emb_per_prot.tolist(),\n",
    "    }\n",
    "\n",
    "# with open(\"test.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(slide_embeddings_per_residue, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ec5334dbdc4a6f7f47854c251e8d2556e95e85daa09db51a6f2bda295b96836"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
