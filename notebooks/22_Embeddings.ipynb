{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "We explore the added value of embeddings in the prediction of antigen specificity.\n",
    "\n",
    "We develop `script_11_compute_embeddings.py` to compute embeddings for the sequences in the global dataset, to be later used with models.\n",
    "\n",
    "From [`bio-embeddings`](https://docs.bioembeddings.com/v0.2.3/#):\n",
    "- preference is for `prottrans_t5_xl_u50`, followed by `esm1b`\n",
    "\n",
    "Notes\n",
    "- Installing `bio-embeddings` with pip is annoying. Had issues installing jsonnet and had to install separately through conda, not pip. Afterwards, installation of `bio-embeddings[all]` worked.\n",
    "- Download model files separately, check link from [my other github repo](https://github.com/ursueugen/ir-ageing/blob/main/02a_aminoacid_embeddings.ipynb).\n",
    "    - Downloading is slow, leave overnight (~8GB per model, for the large ones).\n",
    "    - Links for downloading models\n",
    "        - esm1b:\n",
    "            - model_file: http://data.bioembeddings.com/public/embeddings/embedding_models/esm1b/esm1b_t33_650M_UR50S.pt\n",
    "        - prottrans_t5_xl_u50:\n",
    "            - model_directory: http://data.bioembeddings.com/public/embeddings/embedding_models/t5/prottrans_t5_xl_u50.zip\n",
    "            - half_precision_model_directory: http://data.bioembeddings.com/public/embeddings/embedding_models/t5/half_prottrans_t5_xl_u50.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugen/miniconda3/envs/nco/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/eugen/miniconda3/envs/nco/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/eugen/miniconda3/envs/nco/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from NegativeClassOptimization import ml\n",
    "from NegativeClassOptimization import utils\n",
    "from NegativeClassOptimization import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_pos = \"3VRL\"\n",
    "ag_neg = \"1ADQ\"\n",
    "num_samples = 200\n",
    "\n",
    "df = utils.load_1v1_binary_dataset(ag_pos, ag_neg, num_samples=num_samples)\n",
    "df_train = df.iloc[:int(num_samples*0.8)]\n",
    "df_test = df.iloc[int(num_samples*0.8):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CARHLLWYFDV'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide = df_train[\"Slide\"].iloc[0]\n",
    "slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1280) (11, 1024)\n"
     ]
    }
   ],
   "source": [
    "esm1b_embedder = preprocessing.load_embedder(\"ESM1b\")\n",
    "esm1b_embedding = esm1b_embedder.embed(slide)\n",
    "esm1b_embedder.reduce_per_protein(esm1b_embedding)\n",
    "\n",
    "pt_embedder = preprocessing.load_embedder(\"ProtTransT5XLU50\")\n",
    "pt_embedding = pt_embedder.embed(slide)\n",
    "pt_embedder.reduce_per_protein(pt_embedding)\n",
    "\n",
    "print(esm1b_embedding.shape, pt_embedding.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo: adding embeddings to slides from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460483, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_slide_Variant</th>\n",
       "      <th>CDR3</th>\n",
       "      <th>Best</th>\n",
       "      <th>Slide</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Structure</th>\n",
       "      <th>UID</th>\n",
       "      <th>Antigen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5319791_04a</td>\n",
       "      <td>CARSAAFITTVGWYFDVW</td>\n",
       "      <td>True</td>\n",
       "      <td>AAFITTVGWYF</td>\n",
       "      <td>-94.7</td>\n",
       "      <td>128933-BRRSLUDUUS</td>\n",
       "      <td>1ADQ_5319791_04a</td>\n",
       "      <td>1ADQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_slide_Variant                CDR3  Best        Slide  Energy  \\\n",
       "0      5319791_04a  CARSAAFITTVGWYFDVW  True  AAFITTVGWYF   -94.7   \n",
       "\n",
       "           Structure               UID Antigen  \n",
       "0  128933-BRRSLUDUUS  1ADQ_5319791_04a    1ADQ  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.load_global_dataframe()\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_embeddings_per_residue = {}\n",
    "slide_embeddings_per_prot = {}\n",
    "\n",
    "for slide in df[\"Slide\"].iloc[:3]:\n",
    "    \n",
    "    esm1b_emb = esm1b_embedder.embed(slide)\n",
    "    esm1b_emb_per_prot = esm1b_embedder.reduce_per_protein(esm1b_emb)\n",
    "\n",
    "    pt_emb = pt_embedder.embed(slide)\n",
    "    pt_emb_per_prot = pt_embedder.reduce_per_protein(pt_emb)\n",
    "\n",
    "    slide_embeddings_per_residue[slide] = {\n",
    "        \"ESM1b\": esm1b_emb.tolist(),\n",
    "        \"ProtTransT5XLU50\": pt_emb.tolist(),\n",
    "    }\n",
    "    slide_embeddings_per_prot[slide] = {\n",
    "        \"ESM1b\": esm1b_emb_per_prot.tolist(),\n",
    "        \"ProtTransT5XLU50\": pt_emb_per_prot.tolist(),\n",
    "    }\n",
    "\n",
    "# with open(\"test.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(slide_embeddings_per_residue, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSH8 hand-engineered embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VSHE_1</th>\n",
       "      <th>VSHE_2</th>\n",
       "      <th>VSHE_3</th>\n",
       "      <th>VSHE_4</th>\n",
       "      <th>VSHE_5</th>\n",
       "      <th>VSHE_6</th>\n",
       "      <th>VSHE_7</th>\n",
       "      <th>VSHE_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.15</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>1.47</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1.15</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>1.18</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.20</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>1.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>1.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>1.17</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.01</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>1.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>1.50</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VSHE_1  VSHE_2  VSHE_3  VSHE_4  VSHE_5  VSHE_6  VSHE_7  VSHE_8\n",
       "A    0.15    1.11    1.35    0.92    0.02    0.91    0.36    0.48\n",
       "R    1.47    1.45    1.24    1.27    1.55    1.47    1.30    0.83\n",
       "N    0.99    0.00    0.37    0.69    0.55    0.85    0.73    0.80\n",
       "D    1.15    0.67    0.41    0.01    2.68    1.31    0.03    0.56\n",
       "C    0.18    1.67    0.46    0.21    0.00    1.20    1.61    0.19\n",
       "Q    0.96    0.12    0.18    0.16    0.09    0.42    0.20    0.41\n",
       "E    1.18    0.40    0.10    0.36    2.16    0.17    0.91    0.02\n",
       "G    0.20    1.53    2.63    2.28    0.53    1.18    2.01    1.34\n",
       "H    0.43    0.25    0.37    0.19    0.51    1.28    0.93    0.65\n",
       "I    1.27    0.14    0.30    1.80    0.30    1.61    0.16    0.13\n",
       "L    1.36    0.07    0.26    0.80    0.22    1.37    0.08    0.62\n",
       "K    1.17    0.70    0.70    0.80    1.64    0.67    1.63    0.13\n",
       "M    1.01    0.53    0.43    0.00    0.23    0.10    0.86    0.68\n",
       "F    1.52    0.61    0.96    0.16    0.25    0.28    1.33    0.20\n",
       "P    0.22    0.17    0.50    0.05    0.01    1.34    0.19    3.56\n",
       "S    0.67    0.86    1.07    0.41    0.32    0.27    0.64    0.11\n",
       "T    0.34    0.51    0.55    1.06    0.06    0.01    0.79    0.39\n",
       "W    1.50    2.06    1.79    0.75    0.75    0.13    1.01    0.85\n",
       "Y    0.61    1.60    1.17    0.73    0.53    0.25    0.96    0.52\n",
       "V    0.76    0.92    0.17    1.91    0.22    1.40    0.24    0.03"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.get_vsh8_embedding_matrix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple network on embeddings vs one-hot\n",
    "\n",
    "We evaluate the added value of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/slack_1/global/embeddings/slide_embeddings_per_prot.pkl\", \"rb\") as f:\n",
    "    emb_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def embed_slide(slide: str, emb_dict: dict) -> np.ndarray:\n",
    "    emb_choice = \"ProtTransT5XLU50\"\n",
    "    if slide not in emb_dict:\n",
    "        # raise ValueError(f\"Slide {slide} not in embedding dictionary.\")\n",
    "        return None\n",
    "    emb = np.array(emb_dict[slide][emb_choice])\n",
    "    return emb\n",
    "\n",
    "\n",
    "slide = \"AAFITTVGWYF\"\n",
    "emb = embed_slide(slide, emb_dict)\n",
    "len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5382]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ml.SNN(\n",
    "    num_hidden_units=10, \n",
    "    input_dim=1024\n",
    "    )\n",
    "\n",
    "# utils.num_trainable_params(model) ~ 10k\n",
    "model(torch.tensor(emb).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NegativeClassOptimization import preprocessing, pipelines\n",
    "\n",
    "pipe = pipelines.BinaryclassPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/preprocessing.py:208: UserWarning: Not scaling onehot.\n",
      "  warnings.warn(\"Not scaling onehot.\")\n"
     ]
    }
   ],
   "source": [
    "pipe.step_1_process_data(\n",
    "    ag_pos=\"3VRL\",\n",
    "    ag_neg=\"1ADQ\",\n",
    "    N=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = pipe.df_train_val[\"Slide\"].apply(lambda x: embed_slide(x, emb_dict))\n",
    "embs = list(filter(lambda e: e is not None, embs))\n",
    "len(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_df(df, emb_dict):\n",
    "    slides: pd.Series = df[\"Slide\"]\n",
    "    emb = slides.apply(lambda x: embed_slide(x, emb_dict))\n",
    "    df[\"embedding\"] = emb\n",
    "    return df\n",
    "\n",
    "df_e = embed_df(pipe.df_train_val, emb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04806438,  0.04111566, -0.02125612, ...,  0.0954366 ,\n",
       "         0.01638312, -0.02267723],\n",
       "       [ 0.10578969,  0.05308867, -0.27451834, ...,  0.20939325,\n",
       "        -0.14231008, -0.10286613],\n",
       "       [ 0.02021367,  0.09454548, -0.16444129, ...,  0.21021718,\n",
       "        -0.06837969, -0.06736568],\n",
       "       ...,\n",
       "       [ 0.18288158,  0.04464582, -0.09879034, ...,  0.14656641,\n",
       "         0.0064978 , -0.0356589 ],\n",
       "       [ 0.12855272,  0.07887488, -0.04265216, ...,  0.17842086,\n",
       "        -0.04470585, -0.08178511],\n",
       "       [ 0.08736168,  0.08419388, -0.20473045, ...,  0.16757761,\n",
       "         0.00387542, -0.06436346]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.arr_from_list_series(df_e[\"embedding\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ec5334dbdc4a6f7f47854c251e8d2556e95e85daa09db51a6f2bda295b96836"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
