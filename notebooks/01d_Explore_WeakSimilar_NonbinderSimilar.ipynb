{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak and Nonbinder similar\n",
    "\n",
    "We are interested to explore the results in a new task type, which is similar to vs Weak and vs Nonbinder.\n",
    "\n",
    "We will keep in the negative datasets only the sequences that are very close to the positive dataset. In such way, we will generate vs Weak_similar and vs Nonbinder_similar. How similar? This we'll explore in this notebook. Based on the analysis from Aygul, we should be able to find a lot of sequences that are 1-mutation away from positive dataset.\n",
    "\n",
    "Implementationwise, I think the easiest way will be to define new antigens (e.g. 1ADQSIM) in MiniAbsolut, where we will edit the negative sets. We will later redefine these results as a separate tasks in the following analysis notebooks. We could of course implement a new task type, which would be more robust, but requires more effort into the codebase, which I think is unjustified for a small side-analysis. Later we can reconsider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate similar seqeunces and to implement, we first run, for each antigen, CompAIRR between high and weak and between high and nonbinders. We will then analyse the results and using the sequence pairs (separated by 1 edit distance) we will construct the new antigens in which high and weak/nonbinder are either similar or dissimilar.\n",
    "\n",
    "First, we need to generate the tsvs that can serve as input to CompAIRR, then we run CompAIRR. This was already done by us in sript_04*, we utilise the code from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugen/miniconda3/envs/nco/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/eugen/miniconda3/envs/nco/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import shutil\n",
    "\n",
    "from NegativeClassOptimization import ml\n",
    "from NegativeClassOptimization import utils, config\n",
    "from NegativeClassOptimization import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_07 import load_trainrest_from_miniabsolut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNCOMMENT TO RUN\n",
    "\n",
    "\n",
    "# for ag in config.ANTIGENS:\n",
    "\n",
    "#     print(ag)\n",
    "\n",
    "#     # Load train and rest data for each task type\n",
    "#     # from MiniAbsolut\n",
    "#     df = load_trainrest_from_miniabsolut(ag)\n",
    "#     df[\"UID\"] = df[\"binder_type\"] + \"__\" + df[\"ID_slide_Variant\"]\n",
    "\n",
    "#     # Generate df compatible with CompAIRR as input\n",
    "#     df_AIRR = df.copy()\n",
    "#     column_map = {\n",
    "#             \"binder_type\": \"repertoire_id\",\n",
    "#             \"UID\": \"sequence_id\",\n",
    "#             \"Slide\": \"junction_aa\",\n",
    "#         }\n",
    "#     df_AIRR = df[list(column_map.keys())].copy()\n",
    "#     df_AIRR = df_AIRR.rename(columns=column_map)\n",
    "\n",
    "#     # Write\n",
    "#     out_dir = config.DATA_BASE_PATH / f\"MiniAbsolut/{ag}\" / \"AIRR\"\n",
    "#     out_dir.mkdir(exist_ok=True)\n",
    "#     out_data_dir = out_dir / \"data\"\n",
    "#     out_data_dir.mkdir(exist_ok=True)\n",
    "#     df_AIRR.to_csv(out_data_dir / \"AIRR.tsv\", sep='\\t', index=False)\n",
    "#     print(f\"Written to {out_data_dir / 'AIRR.tsv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## UNCOMMENT TO RUN\n",
    "\n",
    "## Adapted from script_04b to make it run in a Jupyter notebook cell\n",
    "\n",
    "# AG='1ADQ'\n",
    "\n",
    "# # Run for each AG\n",
    "# for AG in '3VRL' '1NSN' '3RAJ' '5E94' '1H0D' '1WEJ' '1ADQ' '1FBI' '2YPV' '1OB1'\n",
    "# do\n",
    "#     echo ${AG}\n",
    "\n",
    "#     AG_PATH=${PWD}/../data/MiniAbsolut/${AG}/AIRR\n",
    "#     AIRR_FILE_RELATIVE_PATH=data/AIRR.tsv\n",
    "\n",
    "#     docker run -v ${AG_PATH}:/opt/compairr torognes/compairr \\\n",
    "#         --ignore-genes --ignore-counts \\\n",
    "#         --threads 12 \\\n",
    "#         --matrix \\\n",
    "#         --differences 1 \\\n",
    "#         --log overlaps_d1.log \\\n",
    "#         --output overlaps_d1_output.tsv \\\n",
    "#         --pairs overlaps_d1_pairs.tsv \\\n",
    "#         ${AIRR_FILE_RELATIVE_PATH} ${AIRR_FILE_RELATIVE_PATH}\n",
    "    \n",
    "#     echo \"Done for ${AG}\"\n",
    "# done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse the results, to evaluate how many sequences are 1-mutation away from the positive dataset. We have the results in an output file, so we want to compare with the file displaying the pairs, and make sure we understand the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = Path(\"01d_df_res.tsv\")\n",
    "\n",
    "if fp.exists():\n",
    "    df_res = pd.read_csv(fp, sep='\\t')\n",
    "else:\n",
    "    records = []\n",
    "    for ag in config.ANTIGENS:\n",
    "\n",
    "        print(ag)\n",
    "\n",
    "        df_pairs  = pd.read_csv(\n",
    "            f\"../data/MiniAbsolut/{ag}/AIRR/overlaps_d1_pairs.tsv\",\n",
    "            sep='\\t',\n",
    "        )\n",
    "        df_pairs = df_pairs.rename(columns={\"#repertoire_id_1\": \"repertoire_id_1\"})\n",
    "        # print(df_pairs.shape)\n",
    "        # df_pairs.head()\n",
    "\n",
    "        df_hw = df_pairs.query(f\"repertoire_id_1 == '{ag}_high' and repertoire_id_2 == '{ag}_looserX'\")\n",
    "        num_seq_h_sim_to_w = len(df_hw[\"sequence_id_1\"].unique())\n",
    "        num_seq_w_sim_to_h = len(df_hw[\"sequence_id_2\"].unique())\n",
    "\n",
    "        df_hn = df_pairs.query(f\"repertoire_id_1 == '{ag}_high' and repertoire_id_2 == '{ag}_95low'\")\n",
    "        num_seq_h_sim_to_n = len(df_hn[\"sequence_id_1\"].unique())\n",
    "        num_seq_n_sim_to_h = len(df_hn[\"sequence_id_2\"].unique())\n",
    "\n",
    "        df_miniabs = load_trainrest_from_miniabsolut(ag)\n",
    "        num_h_total = sum(df_miniabs[\"binder_type\"] == f'{ag}_high')\n",
    "        num_w_total = sum(df_miniabs[\"binder_type\"] == f'{ag}_looserX')\n",
    "        num_n_total = sum(df_miniabs[\"binder_type\"] == f'{ag}_95low')\n",
    "\n",
    "        records.append({\n",
    "            \"antigen\": ag,\n",
    "            \"num_seq_h_sim_to_w\": num_seq_h_sim_to_w,\n",
    "            \"num_seq_w_sim_to_h\": num_seq_w_sim_to_h,\n",
    "            \"num_seq_h_sim_to_n\": num_seq_h_sim_to_n,\n",
    "            \"num_seq_n_sim_to_h\": num_seq_n_sim_to_h,\n",
    "            \"num_h_total\": num_h_total,\n",
    "            \"num_w_total\": num_w_total,\n",
    "            \"num_n_total\": num_n_total,\n",
    "        })\n",
    "\n",
    "    df_res = pd.DataFrame(records)\n",
    "    df_res.to_csv(fp, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>antigen</th>\n",
       "      <th>num_seq_h_sim_to_w</th>\n",
       "      <th>num_seq_w_sim_to_h</th>\n",
       "      <th>num_seq_h_sim_to_n</th>\n",
       "      <th>num_seq_n_sim_to_h</th>\n",
       "      <th>num_h_total</th>\n",
       "      <th>num_w_total</th>\n",
       "      <th>num_n_total</th>\n",
       "      <th>perc_h_sim_to_w</th>\n",
       "      <th>perc_w_sim_to_h</th>\n",
       "      <th>perc_h_sim_to_n</th>\n",
       "      <th>perc_n_sim_to_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3VRL</td>\n",
       "      <td>14093</td>\n",
       "      <td>33160</td>\n",
       "      <td>3271</td>\n",
       "      <td>3748</td>\n",
       "      <td>24456</td>\n",
       "      <td>162506</td>\n",
       "      <td>353663</td>\n",
       "      <td>0.576259</td>\n",
       "      <td>0.204054</td>\n",
       "      <td>0.133750</td>\n",
       "      <td>0.010598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1NSN</td>\n",
       "      <td>10929</td>\n",
       "      <td>19679</td>\n",
       "      <td>4222</td>\n",
       "      <td>4316</td>\n",
       "      <td>25517</td>\n",
       "      <td>206923</td>\n",
       "      <td>403671</td>\n",
       "      <td>0.428303</td>\n",
       "      <td>0.095103</td>\n",
       "      <td>0.165458</td>\n",
       "      <td>0.010692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3RAJ</td>\n",
       "      <td>8202</td>\n",
       "      <td>21767</td>\n",
       "      <td>1721</td>\n",
       "      <td>2142</td>\n",
       "      <td>17197</td>\n",
       "      <td>227120</td>\n",
       "      <td>379685</td>\n",
       "      <td>0.476944</td>\n",
       "      <td>0.095839</td>\n",
       "      <td>0.100076</td>\n",
       "      <td>0.005642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5E94</td>\n",
       "      <td>10264</td>\n",
       "      <td>28090</td>\n",
       "      <td>1644</td>\n",
       "      <td>1942</td>\n",
       "      <td>17016</td>\n",
       "      <td>247905</td>\n",
       "      <td>389535</td>\n",
       "      <td>0.603197</td>\n",
       "      <td>0.113310</td>\n",
       "      <td>0.096615</td>\n",
       "      <td>0.004985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1H0D</td>\n",
       "      <td>13858</td>\n",
       "      <td>29319</td>\n",
       "      <td>4426</td>\n",
       "      <td>4980</td>\n",
       "      <td>29052</td>\n",
       "      <td>179923</td>\n",
       "      <td>411753</td>\n",
       "      <td>0.477007</td>\n",
       "      <td>0.162953</td>\n",
       "      <td>0.152348</td>\n",
       "      <td>0.012095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1WEJ</td>\n",
       "      <td>10413</td>\n",
       "      <td>25245</td>\n",
       "      <td>3225</td>\n",
       "      <td>4320</td>\n",
       "      <td>18695</td>\n",
       "      <td>160359</td>\n",
       "      <td>359414</td>\n",
       "      <td>0.556994</td>\n",
       "      <td>0.157428</td>\n",
       "      <td>0.172506</td>\n",
       "      <td>0.012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1ADQ</td>\n",
       "      <td>8158</td>\n",
       "      <td>17863</td>\n",
       "      <td>2196</td>\n",
       "      <td>2669</td>\n",
       "      <td>18626</td>\n",
       "      <td>199187</td>\n",
       "      <td>383757</td>\n",
       "      <td>0.437990</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.117900</td>\n",
       "      <td>0.006955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1FBI</td>\n",
       "      <td>7135</td>\n",
       "      <td>16884</td>\n",
       "      <td>2112</td>\n",
       "      <td>2853</td>\n",
       "      <td>15390</td>\n",
       "      <td>147163</td>\n",
       "      <td>402274</td>\n",
       "      <td>0.463613</td>\n",
       "      <td>0.114730</td>\n",
       "      <td>0.137232</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2YPV</td>\n",
       "      <td>13344</td>\n",
       "      <td>26078</td>\n",
       "      <td>3695</td>\n",
       "      <td>4218</td>\n",
       "      <td>26306</td>\n",
       "      <td>182158</td>\n",
       "      <td>407418</td>\n",
       "      <td>0.507261</td>\n",
       "      <td>0.143161</td>\n",
       "      <td>0.140462</td>\n",
       "      <td>0.010353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1OB1</td>\n",
       "      <td>12537</td>\n",
       "      <td>25546</td>\n",
       "      <td>3496</td>\n",
       "      <td>3809</td>\n",
       "      <td>26466</td>\n",
       "      <td>224613</td>\n",
       "      <td>383466</td>\n",
       "      <td>0.473702</td>\n",
       "      <td>0.113733</td>\n",
       "      <td>0.132094</td>\n",
       "      <td>0.009933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 antigen  num_seq_h_sim_to_w  num_seq_w_sim_to_h  \\\n",
       "0           0    3VRL               14093               33160   \n",
       "1           1    1NSN               10929               19679   \n",
       "2           2    3RAJ                8202               21767   \n",
       "3           3    5E94               10264               28090   \n",
       "4           4    1H0D               13858               29319   \n",
       "5           5    1WEJ               10413               25245   \n",
       "6           6    1ADQ                8158               17863   \n",
       "7           7    1FBI                7135               16884   \n",
       "8           8    2YPV               13344               26078   \n",
       "9           9    1OB1               12537               25546   \n",
       "\n",
       "   num_seq_h_sim_to_n  num_seq_n_sim_to_h  num_h_total  num_w_total  \\\n",
       "0                3271                3748        24456       162506   \n",
       "1                4222                4316        25517       206923   \n",
       "2                1721                2142        17197       227120   \n",
       "3                1644                1942        17016       247905   \n",
       "4                4426                4980        29052       179923   \n",
       "5                3225                4320        18695       160359   \n",
       "6                2196                2669        18626       199187   \n",
       "7                2112                2853        15390       147163   \n",
       "8                3695                4218        26306       182158   \n",
       "9                3496                3809        26466       224613   \n",
       "\n",
       "   num_n_total  perc_h_sim_to_w  perc_w_sim_to_h  perc_h_sim_to_n  \\\n",
       "0       353663         0.576259         0.204054         0.133750   \n",
       "1       403671         0.428303         0.095103         0.165458   \n",
       "2       379685         0.476944         0.095839         0.100076   \n",
       "3       389535         0.603197         0.113310         0.096615   \n",
       "4       411753         0.477007         0.162953         0.152348   \n",
       "5       359414         0.556994         0.157428         0.172506   \n",
       "6       383757         0.437990         0.089680         0.117900   \n",
       "7       402274         0.463613         0.114730         0.137232   \n",
       "8       407418         0.507261         0.143161         0.140462   \n",
       "9       383466         0.473702         0.113733         0.132094   \n",
       "\n",
       "   perc_n_sim_to_h  \n",
       "0         0.010598  \n",
       "1         0.010692  \n",
       "2         0.005642  \n",
       "3         0.004985  \n",
       "4         0.012095  \n",
       "5         0.012020  \n",
       "6         0.006955  \n",
       "7         0.007092  \n",
       "8         0.010353  \n",
       "9         0.009933  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res[\"perc_h_sim_to_w\"] = df_res[\"num_seq_h_sim_to_w\"] / df_res[\"num_h_total\"]\n",
    "df_res[\"perc_w_sim_to_h\"] = df_res[\"num_seq_w_sim_to_h\"] / df_res[\"num_w_total\"]\n",
    "df_res[\"perc_h_sim_to_n\"] = df_res[\"num_seq_h_sim_to_n\"] / df_res[\"num_h_total\"]\n",
    "df_res[\"perc_n_sim_to_h\"] = df_res[\"num_seq_n_sim_to_h\"] / df_res[\"num_n_total\"]\n",
    "\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate new MiniAbsolut Antigens\n",
    "# We leave the high unchanged and adapt the weak and non-binders accordingly!\n",
    "# Such an adjustment is possible (see df_res above).\n",
    "# Changing the high is impossible to 15k sequences, and also it would be nice\n",
    "# to keep the same size of high. \n",
    "# Don't forget later to account for the difference in %similar to w/n in high (40-60% range)\n",
    "\n",
    "## Note: the sequences are represented symmetrically repertoire 1>2 and 2>1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 3VRL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 8676\n",
      "#weak possible, with seq in hw: 24197\n",
      "#high with similar in nonb: 2036\n",
      "#nonb possible, with seq in hn: 2567\n",
      "\n",
      "\n",
      "Working on 1NSN\n",
      "Not enough sequences in weak to sample 15000 for SIM, sampling all\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 6469\n",
      "#weak possible, with seq in hw: 13213\n",
      "#high with similar in nonb: 2518\n",
      "#nonb possible, with seq in hn: 2845\n",
      "\n",
      "\n",
      "Working on 3RAJ\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 7176\n",
      "#weak possible, with seq in hw: 19646\n",
      "#high with similar in nonb: 1489\n",
      "#nonb possible, with seq in hn: 1875\n",
      "\n",
      "\n",
      "Working on 5E94\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 9046\n",
      "#weak possible, with seq in hw: 25667\n",
      "#high with similar in nonb: 1459\n",
      "#nonb possible, with seq in hn: 1751\n",
      "\n",
      "\n",
      "Working on 1H0D\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 7178\n",
      "#weak possible, with seq in hw: 18148\n",
      "#high with similar in nonb: 2295\n",
      "#nonb possible, with seq in hn: 2935\n",
      "\n",
      "\n",
      "Working on 1WEJ\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 8406\n",
      "#weak possible, with seq in hw: 21622\n",
      "#high with similar in nonb: 2612\n",
      "#nonb possible, with seq in hn: 3623\n",
      "\n",
      "\n",
      "Working on 1ADQ\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 6590\n",
      "#weak possible, with seq in hw: 15335\n",
      "#high with similar in nonb: 1768\n",
      "#nonb possible, with seq in hn: 2252\n",
      "\n",
      "\n",
      "Working on 1FBI\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 6948\n",
      "#weak possible, with seq in hw: 16530\n",
      "#high with similar in nonb: 2056\n",
      "#nonb possible, with seq in hn: 2790\n",
      "\n",
      "\n",
      "Working on 2YPV\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 7608\n",
      "#weak possible, with seq in hw: 17471\n",
      "#high with similar in nonb: 2086\n",
      "#nonb possible, with seq in hn: 2702\n",
      "\n",
      "\n",
      "Working on 1OB1\n",
      "Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\n",
      "#high with similar in weak: 7039\n",
      "#weak possible, with seq in hw: 16659\n",
      "#high with similar in nonb: 1982\n",
      "#nonb possible, with seq in hn: 2372\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ag in config.ANTIGENS:\n",
    "    print(f\"Working on {ag}\")\n",
    "\n",
    "    ## Prepare save directory, new ag\n",
    "    base_p = Path(f\"../data/MiniAbsolut\")\n",
    "    #SIM\n",
    "    ag_new_sim = f\"{ag}SIM\"\n",
    "    ag_new_sim_p = base_p / ag_new_sim\n",
    "    ag_new_sim_p.mkdir(exist_ok=True)\n",
    "    #DIF\n",
    "    ag_new_dif = f\"{ag}DIF\"\n",
    "    ag_new_dif_p = base_p / ag_new_dif\n",
    "    ag_new_dif_p.mkdir(exist_ok=True)\n",
    "\n",
    "    ## Read the pairs computed from CompAIRR\n",
    "    df_pairs  = pd.read_csv(\n",
    "                f\"../data/MiniAbsolut/{ag}/AIRR/overlaps_d1_pairs.tsv\",\n",
    "                sep='\\t',\n",
    "            )\n",
    "    df_pairs = df_pairs.rename(columns={\"#repertoire_id_1\": \"repertoire_id_1\"})\n",
    "\n",
    "    ## Read the high sequences, to be used to find neighbours\n",
    "    df_high_train = pd.read_csv(\n",
    "        f\"../data/MiniAbsolut/{ag}/high_train_15000.tsv\",\n",
    "        sep='\\t',\n",
    "    )\n",
    "\n",
    "    ## Adapt the vs Weak\n",
    "    # Filter for relevant pairs\n",
    "    df_hw = df_pairs.query(f\"repertoire_id_1 == '{ag}_high' and repertoire_id_2 == '{ag}_looserX'\")\n",
    "    df_hw_in_high = df_hw.loc[df_hw[\"junction_aa_1\"].isin(df_high_train['Slide'])]\n",
    "\n",
    "    df_weak_train = pd.read_csv(\n",
    "        f\"../data/MiniAbsolut/{ag}/looserX_train_15000.tsv\",\n",
    "        sep='\\t',\n",
    "    )\n",
    "    df_weak_rest = pd.read_csv(\n",
    "        f\"../data/MiniAbsolut/{ag}/looserX_rest.tsv\",\n",
    "        sep='\\t',\n",
    "    )\n",
    "    df_weak = pd.concat([df_weak_train, df_weak_rest])\n",
    "\n",
    "    # Find the sequences in the weak that are similar to high\n",
    "    df_weak_in_hw = df_weak.loc[df_weak[\"Slide\"].isin(df_hw_in_high['junction_aa_2'])]\n",
    "\n",
    "    # Generate sim\n",
    "    df_weak_sim = df_weak_in_hw.copy()\n",
    "    try:\n",
    "        df_weak_train_sim = df_weak_sim.sample(15000, random_state=42)\n",
    "    except ValueError:\n",
    "        print(\"Not enough sequences in weak to sample 15000 for SIM, sampling all\")\n",
    "        df_weak_train_sim = df_weak_sim.sample(df_weak_sim.shape[0], random_state=42)\n",
    "    df_weak_rest_sim = df_weak_sim.loc[~df_weak_sim[\"Slide\"].isin(df_weak_train_sim[\"Slide\"])]\n",
    "    # Save\n",
    "    df_weak_train_sim.to_csv(ag_new_sim_p / \"looserX_train_15000.tsv\", sep='\\t', index=False)\n",
    "    df_weak_rest_sim.to_csv(ag_new_sim_p / \"looserX_rest.tsv\", sep='\\t', index=False)\n",
    "\n",
    "    # Generate dif\n",
    "    df_weak_dif = df_weak.loc[~df_weak[\"Slide\"].isin(df_weak_in_hw[\"Slide\"])]\n",
    "    try:\n",
    "        df_weak_train_dif = df_weak_dif.sample(15000, random_state=42)\n",
    "    except ValueError:\n",
    "        print(\"Not enough sequences in weak to sample 15000 for DIF, sampling all\")\n",
    "        df_weak_train_dif = df_weak_dif.sample(df_weak_dif.shape[0], random_state=42)\n",
    "    df_weak_rest_dif = df_weak_dif.loc[~df_weak_dif[\"Slide\"].isin(df_weak_train_dif[\"Slide\"])]\n",
    "    # Save\n",
    "    df_weak_train_dif.to_csv(ag_new_dif_p / \"looserX_train_15000.tsv\", sep='\\t', index=False)\n",
    "    df_weak_rest_dif.to_csv(ag_new_dif_p / \"looserX_rest.tsv\", sep='\\t', index=False)\n",
    "\n",
    "    ## Adapt the vs Nonbinder\n",
    "    # Filter for relevant pairs\n",
    "    df_hn = df_pairs.query(f\"repertoire_id_1 == '{ag}_high' and repertoire_id_2 == '{ag}_95low'\")\n",
    "    df_hn_in_high = df_hn.loc[df_hn[\"junction_aa_1\"].isin(df_high_train['Slide'])]\n",
    "\n",
    "    df_nonb_train = pd.read_csv(\n",
    "        f\"../data/MiniAbsolut/{ag}/95low_train_15000.tsv\",\n",
    "        sep='\\t',\n",
    "    )\n",
    "    df_nonb_rest = pd.read_csv(\n",
    "        f\"../data/MiniAbsolut/{ag}/95low_rest.tsv\",\n",
    "        sep='\\t',\n",
    "    )\n",
    "    df_nonb = pd.concat([df_nonb_train, df_nonb_rest])\n",
    "\n",
    "    # Find the sequences in the nonbinder that are similar to high\n",
    "    df_nonb_in_hn = df_nonb.loc[df_nonb[\"Slide\"].isin(df_hn_in_high['junction_aa_2'])]\n",
    "\n",
    "    # Generate sim\n",
    "    df_nonb_sim = df_nonb_in_hn.copy()\n",
    "    try:\n",
    "        df_nonb_train_sim = df_nonb_sim.sample(15000, random_state=42)\n",
    "    except ValueError:\n",
    "        print(\"Not enough sequences in nonbinder to sample 15000 for SIM, sampling all\")\n",
    "        df_nonb_train_sim = df_nonb_sim.sample(df_nonb_sim.shape[0], random_state=42)\n",
    "    df_nonb_rest_sim = df_nonb_sim.loc[~df_nonb_sim[\"Slide\"].isin(df_nonb_train_sim[\"Slide\"])]\n",
    "    # Save\n",
    "    df_nonb_train_sim.to_csv(ag_new_sim_p / \"95low_train_15000.tsv\", sep='\\t', index=False)\n",
    "    df_nonb_rest_sim.to_csv(ag_new_sim_p / \"95low_rest.tsv\", sep='\\t', index=False)\n",
    "\n",
    "    # Generate dif\n",
    "    df_nonb_dif = df_nonb.loc[~df_nonb[\"Slide\"].isin(df_nonb_in_hn[\"Slide\"])]\n",
    "    try:\n",
    "        df_nonb_train_dif = df_nonb_dif.sample(15000, random_state=42)\n",
    "    except ValueError:\n",
    "        print(\"Not enough sequences in nonbinder to sample 15000 for DIF, sampling all\")\n",
    "        df_nonb_train_dif = df_nonb_dif.sample(df_nonb_dif.shape[0], random_state=42)\n",
    "    df_nonb_rest_dif = df_nonb_dif.loc[~df_nonb_dif[\"Slide\"].isin(df_nonb_train_dif[\"Slide\"])]\n",
    "    # Save\n",
    "    df_nonb_train_dif.to_csv(ag_new_dif_p / \"95low_train_15000.tsv\", sep='\\t', index=False)\n",
    "    df_nonb_rest_dif.to_csv(ag_new_dif_p / \"95low_rest.tsv\", sep='\\t', index=False)\n",
    "\n",
    "    print(f\"#high with similar in weak: {df_high_train['Slide'].isin(df_hw['junction_aa_1']).sum()}\")\n",
    "    print(f\"#weak possible, with seq in hw: {df_weak_in_hw.shape[0]}\")\n",
    "    print(f\"#high with similar in nonb: {df_high_train['Slide'].isin(df_hn['junction_aa_1']).sum()}\")\n",
    "    print(f\"#nonb possible, with seq in hn: {df_nonb_in_hn.shape[0]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ## Copy high train to new antigen\n",
    "    shutil.copy(\n",
    "        f\"../data/MiniAbsolut/{ag}/high_train_15000.tsv\", \n",
    "        ag_new_sim_p / \"high_train_15000.tsv\"\n",
    "    )\n",
    "    shutil.copy(\n",
    "        f\"../data/MiniAbsolut/{ag}/high_train_15000.tsv\", \n",
    "        ag_new_dif_p / \"high_train_15000.tsv\"\n",
    "    )\n",
    "    ## Copy all test to new antigen\n",
    "    for f in Path(f\"../data/MiniAbsolut/{ag}\").glob(\"*test*.tsv\"):\n",
    "        shutil.copy(f, ag_new_sim_p / f.name)\n",
    "        shutil.copy(f, ag_new_dif_p / f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
