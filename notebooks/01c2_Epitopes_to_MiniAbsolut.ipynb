{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01c2 Epitopes into MiniAbsolut\n",
    "\n",
    "We generate \"new\" antigens in MiniAbsolut and MiniAbsolut splits, which are actually nothing else than epitopes from the antigens. We follow the same code pattern used in 01b, in which we integrated experimental data into MiniAbsolut.\n",
    "\n",
    "Plan: for each Miniabsolut antigen and for each sequence type (high, weak, nonb), we combine train_15 + rest, we select 15k according to epitope/hotspot, we evaluate that it makes sense to have extra splits (if enough data), and we generate a new set train_15* and rest* accordingly. Test set remains constant. Later subsets based on the epitope of the test set can be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugen/miniconda3/nco/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import shutil\n",
    "\n",
    "from NegativeClassOptimization import ml, datasets, pipelines\n",
    "from NegativeClassOptimization import utils, config\n",
    "from NegativeClassOptimization import preprocessing\n",
    "\n",
    "from utils_07 import load_trainrest_from_miniabsolut, load_testrest_from_miniabsolut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_TRAIN = 15000\n",
    "# N_TEST = 5000\n",
    "\n",
    "N_TRAIN = 100  # 50 per part\n",
    "N_TEST = 20  # 10 per part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epitope_based_ags_map = {\n",
    "    \"1WEJ\": (\"1WEJE1\", \"F1G2K2K1N1G3I1T2W1K2T1Y1A1T1N1\"),\n",
    "    \"1H0D\": (\"1H0DE1\", \"P1Q1G1R1I2S1S2S1F1Q2V1G1F1V1H1L1F1\"),\n",
    "    \"1OB1\": (\"1OB1E1\", \"S1N1S1G1L3V1N2K1I2C2C1P1F2D2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1WEJ\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m ag \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m      8\u001b[0m ag_new, seqAGEpitope \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_trainrest_from_miniabsolut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# df.query(\"seqAGEpitope == @seqAGEpitope\").groupby(\"binder_type\").size()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseqAGEpitope == @seqAGEpitope\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/negative-class-optimization/notebooks/utils_07.py:679\u001b[0m, in \u001b[0;36mload_trainrest_from_miniabsolut\u001b[0;34m(ag, base_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(base_path\u001b[38;5;241m.\u001b[39mglob(mask_sample_size_in_filename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh_train_15000_absolut_energy_contributions.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    678\u001b[0m df_high_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fp, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 679\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_sample_size_in_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhigh_rest_absolut_energy_contributions.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    680\u001b[0m df_high_rest \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fp, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    682\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(base_path\u001b[38;5;241m.\u001b[39mglob(mask_sample_size_in_filename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlooserX_train_15000_absolut_energy_contributions.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "RUN = True\n",
    "if RUN:\n",
    "    for key, value in epitope_based_ags_map.items():\n",
    "\n",
    "        print(key)\n",
    "\n",
    "        ag = key\n",
    "        ag_new, seqAGEpitope = value\n",
    "\n",
    "        df = load_trainrest_from_miniabsolut(ag)\n",
    "\n",
    "        # df.query(\"seqAGEpitope == @seqAGEpitope\").groupby(\"binder_type\").size()\n",
    "        df = df.query(\"seqAGEpitope == @seqAGEpitope\")\n",
    "        df[\"Antigen\"] = ag_new\n",
    "        # df.head()\n",
    "\n",
    "        assert all(df.groupby(\"binder_type\").size() > N_TRAIN / 2)\n",
    "\n",
    "        # Rebuild the dataframes\n",
    "        df_high_train = df.loc[df[\"binder_type\"] == f\"{ag}_high\"].sample(N_TRAIN / 2)\n",
    "        df_high_rest = df.loc[(df[\"binder_type\"] == f\"{ag}_high\") & (~df.index.isin(df_high_train.index))]\n",
    "        df_weak_train = df.loc[df[\"binder_type\"] == f\"{ag}_looserX\"].sample(N_TRAIN / 2)\n",
    "        df_weak_rest = df.loc[(df[\"binder_type\"] == f\"{ag}_looserX\") & (~df.index.isin(df_weak_train.index))]\n",
    "        df_nonb_train = df.loc[df[\"binder_type\"] == f\"{ag}_95low\"].sample(N_TRAIN / 2)\n",
    "        df_nonb_rest = df.loc[(df[\"binder_type\"] == f\"{ag}_95low\") & (~df.index.isin(df_nonb_train.index))]\n",
    "\n",
    "        # Make the new directory in MiniAbsolut\n",
    "        new_ag_dir = config.DATA_MINIABSOLUT / f\"{ag_new}\"\n",
    "        new_ag_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Copy the test files from the original antigen\n",
    "        for file in (config.DATA_MINIABSOLUT / f\"{ag}\").glob(\"*test*.tsv\"):\n",
    "            # Copy file to new antigen directory\n",
    "            # using shutil.copyfile(src, dst)\n",
    "            new_file = new_ag_dir / file.name\n",
    "            shutil.copyfile(file, new_file)\n",
    "\n",
    "        ## Save the new files in the main folder\n",
    "        ## Columns for normal tsvs in MiniAbsolut\n",
    "        cols_sel = [\"ID_slide_Variant\", \"CDR3\", \"Best\", \"Slide\", \"Energy\", \"Structure\", \"Antigen\"]\n",
    "        df_high_train[cols_sel].to_csv(new_ag_dir / f\"high_train_15000.tsv\", sep='\\t', index=False)\n",
    "        df_high_rest[cols_sel].to_csv(new_ag_dir / f\"high_rest.tsv\", sep='\\t', index=False)\n",
    "        df_weak_train[cols_sel].to_csv(new_ag_dir / f\"looserX_train_15000.tsv\", sep='\\t', index=False)\n",
    "        df_weak_rest[cols_sel].to_csv(new_ag_dir / f\"looserX_rest.tsv\", sep='\\t', index=False)\n",
    "        df_nonb_train[cols_sel].to_csv(new_ag_dir / f\"95low_train_15000.tsv\", sep='\\t', index=False)\n",
    "        df_nonb_rest[cols_sel].to_csv(new_ag_dir / f\"95low_rest.tsv\", sep='\\t', index=False)\n",
    "\n",
    "        ###\n",
    "        # Save the new files in the \"*_energy_contributions\" folder,\n",
    "        # where other modules expect Absolut data regarding binding\n",
    "        # energy.\n",
    "        new_ag_energy_dir = new_ag_dir / \"energy_contributions\"\n",
    "        new_ag_energy_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Copy the test files from the original antigen\n",
    "        for file in (config.DATA_MINIABSOLUT / f\"{ag}/energy_contributions\").glob(\"*test*energy_contributions.tsv\"):\n",
    "            # Copy file to new antigen directory\n",
    "            # using shutil.copyfile(src, dst)\n",
    "            new_file = new_ag_energy_dir / file.name\n",
    "            shutil.copyfile(file, new_file)\n",
    "\n",
    "        df_high_train.to_csv(new_ag_energy_dir / f\"high_train_15000_absolut_energy_contributions.tsv\", sep='\\t', index=False)\n",
    "        df_high_rest.to_csv(new_ag_energy_dir / f\"high_rest_absolut_energy_contributions.tsv\", sep='\\t', index=False)\n",
    "        df_weak_train.to_csv(new_ag_energy_dir / f\"looserX_train_15000_absolut_energy_contributions.tsv\", sep='\\t', index=False)\n",
    "        df_weak_rest.to_csv(new_ag_energy_dir / f\"looserX_rest_absolut_energy_contributions.tsv\", sep='\\t', index=False)\n",
    "        df_nonb_train.to_csv(new_ag_energy_dir / f\"95low_train_15000_absolut_energy_contributions.tsv\", sep='\\t', index=False) \n",
    "        df_nonb_rest.to_csv(new_ag_energy_dir / f\"95low_rest_absolut_energy_contributions.tsv\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop alternative test set evaluations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate how many epitope-specific sequences in the positive datasets (outside of train!)\n",
    "# of the 3 antigens. It is possible to gather 3000 epitope-specific seqs for pos and\n",
    "# 3000 epitope-specific for negative parrts.\n",
    "\n",
    "# N_TEST_EPI = 3000\n",
    "N_TEST_EPI = 3\n",
    "\n",
    "def build_test_df(ag, df, subset):\n",
    "    num_seq_in_test = ((df[\"binder_type\"] == f\"{ag}_{subset}\") & (df[\"origin\"] == \"test\")).sum()\n",
    "    if num_seq_in_test > N_TEST_EPI:\n",
    "        df_subset_test = df.loc[(df[\"binder_type\"] == f\"{ag}_{subset}\") & (df[\"origin\"] == \"test\")].sample(N_TEST_EPI, random_state=42)\n",
    "    else:\n",
    "        df_subset_test = df.loc[(df[\"binder_type\"] == f\"{ag}_{subset}\") & (df[\"origin\"] == \"test\")].copy()\n",
    "        num_seq_to_sample = N_TEST_EPI - num_seq_in_test\n",
    "        df_subset_test = pd.concat([df_subset_test, df.loc[(df[\"binder_type\"] == f\"{ag}_{subset}\") & (df[\"origin\"] == \"rest\")].sample(num_seq_to_sample, random_state=42)])\n",
    "    return df_subset_test\n",
    "\n",
    "RUN = True\n",
    "if RUN:\n",
    "    for key, value in epitope_based_ags_map.items():\n",
    "\n",
    "        print(key)\n",
    "\n",
    "        ag = key\n",
    "        ag_new, seqAGEpitope = value\n",
    "        new_ag_dir = config.DATA_MINIABSOLUT / f\"{ag_new}\"\n",
    "\n",
    "        # Load all sequences from `energy_contribution` for the antigen (non-epitope specific)\n",
    "        df = load_testrest_from_miniabsolut(ag)\n",
    "        \n",
    "        df[\"Antigen\"] = ag_new\n",
    "\n",
    "        # Make epitope-specific\n",
    "        df = df.query(\"seqAGEpitope == @seqAGEpitope\")\n",
    "\n",
    "        assert all(df.groupby(\"binder_type\").size() > N_TEST_EPI)\n",
    "\n",
    "        # Rebuild the dataframes\n",
    "        df_high_test = build_test_df(ag, df, \"high\")\n",
    "        df_weak_test = build_test_df(ag, df, \"looserX\")\n",
    "        df_nonb_test = build_test_df(ag, df, \"95low\")\n",
    "        \n",
    "        df_high_rest = df.loc[(df[\"binder_type\"] == f\"{ag}_high\") & (~df.index.isin(df_high_test.index))]\n",
    "        df_weak_rest = df.loc[(df[\"binder_type\"] == f\"{ag}_looserX\") & (~df.index.isin(df_weak_test.index))]\n",
    "        df_nonb_rest = df.loc[(df[\"binder_type\"] == f\"{ag}_95low\") & (~df.index.isin(df_nonb_test.index))]\n",
    "\n",
    "\n",
    "        ## Save the new files in the main folder\n",
    "        ## Columns for normal tsvs in MiniAbsolut\n",
    "        cols_sel = [\"ID_slide_Variant\", \"CDR3\", \"Best\", \"Slide\", \"Energy\", \"Structure\", \"Antigen\"]\n",
    "        df_high_test[cols_sel].to_csv(new_ag_dir / f\"highepi_test_3000.tsv\", sep='\\t', index=False)\n",
    "        df_high_rest[cols_sel].to_csv(new_ag_dir / f\"highepi_rest.tsv\", sep='\\t', index=False)\n",
    "        df_weak_test[cols_sel].to_csv(new_ag_dir / f\"looserXepi_test_3000.tsv\", sep='\\t', index=False)\n",
    "        df_weak_rest[cols_sel].to_csv(new_ag_dir / f\"looserXepi_rest.tsv\", sep='\\t', index=False)\n",
    "        df_nonb_test[cols_sel].to_csv(new_ag_dir / f\"95lowepi_test_3000.tsv\", sep='\\t', index=False)\n",
    "        df_nonb_rest[cols_sel].to_csv(new_ag_dir / f\"95lowepi_rest.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
