Running stage '07_SN10_openset_NDBK':
> python scripts/script_07_SN10_openset_NDBK.py
Epoch 1
-------------------------------
loss: 0.764008  [    0/72281]
loss: 0.200886  [ 6400/72281]
loss: 0.098892  [12800/72281]
loss: 0.079884  [19200/72281]
loss: 0.102557  [25600/72281]
loss: 0.070399  [32000/72281]
loss: 0.173353  [38400/72281]
loss: 0.058911  [44800/72281]
loss: 0.123339  [51200/72281]
loss: 0.100638  [57600/72281]
loss: 0.035921  [64000/72281]
loss: 0.079777  [70400/72281]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.099918 

Epoch 2
-------------------------------
loss: 0.162762  [    0/72281]
loss: 0.027932  [ 6400/72281]
loss: 0.050685  [12800/72281]
loss: 0.040826  [19200/72281]
loss: 0.069572  [25600/72281]
loss: 0.050581  [32000/72281]
loss: 0.076981  [38400/72281]
loss: 0.038387  [44800/72281]
loss: 0.058501  [51200/72281]
loss: 0.053462  [57600/72281]
loss: 0.009101  [64000/72281]
loss: 0.113259  [70400/72281]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.087211 

Epoch 3
-------------------------------
loss: 0.081638  [    0/72281]
loss: 0.015628  [ 6400/72281]
loss: 0.026636  [12800/72281]
loss: 0.018607  [19200/72281]
loss: 0.040716  [25600/72281]
loss: 0.041176  [32000/72281]
loss: 0.094004  [38400/72281]
loss: 0.047504  [44800/72281]
loss: 0.095515  [51200/72281]
loss: 0.028207  [57600/72281]
loss: 0.037158  [64000/72281]
loss: 0.116880  [70400/72281]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.091373 

Epoch 4
-------------------------------
loss: 0.073162  [    0/72281]
loss: 0.091417  [ 6400/72281]
loss: 0.062063  [12800/72281]
loss: 0.074980  [19200/72281]
loss: 0.054486  [25600/72281]
loss: 0.111129  [32000/72281]
loss: 0.034730  [38400/72281]
loss: 0.040392  [44800/72281]
loss: 0.085169  [51200/72281]
loss: 0.008923  [57600/72281]
loss: 0.056683  [64000/72281]
loss: 0.098768  [70400/72281]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.082599 

Epoch 5
-------------------------------
loss: 0.035320  [    0/72281]
loss: 0.021351  [ 6400/72281]
loss: 0.056187  [12800/72281]
loss: 0.060434  [19200/72281]
loss: 0.058413  [25600/72281]
loss: 0.028727  [32000/72281]
loss: 0.046242  [38400/72281]
loss: 0.193669  [44800/72281]
loss: 0.140195  [51200/72281]
loss: 0.018378  [57600/72281]
loss: 0.116100  [64000/72281]
loss: 0.073419  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.085826 

Epoch 6
-------------------------------
loss: 0.012517  [    0/72281]
loss: 0.025272  [ 6400/72281]
loss: 0.136980  [12800/72281]
loss: 0.008910  [19200/72281]
loss: 0.077361  [25600/72281]
loss: 0.009906  [32000/72281]
loss: 0.016609  [38400/72281]
loss: 0.038351  [44800/72281]
loss: 0.166460  [51200/72281]
loss: 0.026919  [57600/72281]
loss: 0.039282  [64000/72281]
loss: 0.012856  [70400/72281]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.081783 

Epoch 7
-------------------------------
loss: 0.015150  [    0/72281]
loss: 0.021695  [ 6400/72281]
loss: 0.003416  [12800/72281]
loss: 0.105872  [19200/72281]
loss: 0.172086  [25600/72281]
loss: 0.070546  [32000/72281]
loss: 0.010677  [38400/72281]
loss: 0.111355  [44800/72281]
loss: 0.072198  [51200/72281]
loss: 0.088355  [57600/72281]
loss: 0.035692  [64000/72281]
loss: 1.589757  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077791 

Epoch 8
-------------------------------
loss: 0.023240  [    0/72281]
loss: 0.049988  [ 6400/72281]
loss: 0.012937  [12800/72281]
loss: 0.008966  [19200/72281]
loss: 0.017089  [25600/72281]
loss: 0.083846  [32000/72281]
loss: 0.008989  [38400/72281]
loss: 0.063603  [44800/72281]
loss: 0.014634  [51200/72281]
loss: 0.045405  [57600/72281]
loss: 0.081151  [64000/72281]
loss: 0.088838  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.077895 

Epoch 9
-------------------------------
loss: 0.026356  [    0/72281]
loss: 0.021191  [ 6400/72281]
loss: 0.023823  [12800/72281]
loss: 0.039116  [19200/72281]
loss: 0.079413  [25600/72281]
loss: 0.040089  [32000/72281]
loss: 0.077371  [38400/72281]
loss: 0.035001  [44800/72281]
loss: 0.027174  [51200/72281]
loss: 0.045215  [57600/72281]
loss: 0.044714  [64000/72281]
loss: 0.011454  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.083931 

Epoch 10
-------------------------------
loss: 0.004913  [    0/72281]
loss: 0.058673  [ 6400/72281]
loss: 0.004260  [12800/72281]
loss: 0.009210  [19200/72281]
loss: 0.055887  [25600/72281]
loss: 0.093877  [32000/72281]
loss: 0.031123  [38400/72281]
loss: 0.011557  [44800/72281]
loss: 0.010449  [51200/72281]
loss: 0.213844  [57600/72281]
loss: 0.091808  [64000/72281]
loss: 0.074739  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.077460 

Epoch 11
-------------------------------
loss: 0.036516  [    0/72281]
loss: 0.019092  [ 6400/72281]
loss: 0.042338  [12800/72281]
loss: 0.074146  [19200/72281]
loss: 0.006694  [25600/72281]
loss: 0.106385  [32000/72281]
loss: 0.038177  [38400/72281]
loss: 0.044700  [44800/72281]
loss: 0.037688  [51200/72281]
loss: 0.018418  [57600/72281]
loss: 0.053789  [64000/72281]
loss: 0.043665  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.078339 

Epoch 12
-------------------------------
loss: 0.003195  [    0/72281]
loss: 0.079389  [ 6400/72281]
loss: 0.028383  [12800/72281]
loss: 0.024881  [19200/72281]
loss: 0.057544  [25600/72281]
loss: 0.025328  [32000/72281]
loss: 0.012346  [38400/72281]
loss: 0.043212  [44800/72281]
loss: 0.058851  [51200/72281]
loss: 0.076077  [57600/72281]
loss: 0.009960  [64000/72281]
loss: 0.015553  [70400/72281]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.092485 

Epoch 13
-------------------------------
loss: 0.073023  [    0/72281]
loss: 0.039428  [ 6400/72281]
loss: 0.127818  [12800/72281]
loss: 0.018421  [19200/72281]
loss: 0.046042  [25600/72281]
loss: 0.016571  [32000/72281]
loss: 0.030307  [38400/72281]
loss: 0.033513  [44800/72281]
loss: 0.010063  [51200/72281]
loss: 0.031960  [57600/72281]
loss: 0.210337  [64000/72281]
loss: 0.093969  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.080006 

Epoch 14
-------------------------------
loss: 0.059310  [    0/72281]
loss: 0.007181  [ 6400/72281]
loss: 0.010950  [12800/72281]
loss: 0.171399  [19200/72281]
loss: 0.007965  [25600/72281]
loss: 0.015777  [32000/72281]
loss: 0.059364  [38400/72281]
loss: 0.042050  [44800/72281]
loss: 0.109082  [51200/72281]
loss: 0.036417  [57600/72281]
loss: 0.046568  [64000/72281]
loss: 0.051584  [70400/72281]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.075485 

Epoch 15
-------------------------------
loss: 0.005131  [    0/72281]
loss: 0.019254  [ 6400/72281]
loss: 0.078051  [12800/72281]
loss: 0.020383  [19200/72281]
loss: 0.054791  [25600/72281]
loss: 0.038064  [32000/72281]
loss: 0.070266  [38400/72281]
loss: 0.010888  [44800/72281]
loss: 0.019465  [51200/72281]
loss: 0.055772  [57600/72281]
loss: 0.008932  [64000/72281]
loss: 0.071593  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.080570 

Epoch 16
-------------------------------
loss: 0.008462  [    0/72281]
loss: 0.007034  [ 6400/72281]
loss: 0.106160  [12800/72281]
loss: 0.061042  [19200/72281]
loss: 0.011965  [25600/72281]
loss: 0.006077  [32000/72281]
loss: 0.011642  [38400/72281]
loss: 0.038875  [44800/72281]
loss: 0.002216  [51200/72281]
loss: 0.036743  [57600/72281]
loss: 0.012983  [64000/72281]
loss: 0.049996  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.083754 

Epoch 17
-------------------------------
loss: 0.015652  [    0/72281]
loss: 0.032195  [ 6400/72281]
loss: 0.021520  [12800/72281]
loss: 0.006587  [19200/72281]
loss: 0.018846  [25600/72281]
loss: 0.010527  [32000/72281]
loss: 0.078542  [38400/72281]
loss: 0.036516  [44800/72281]
loss: 1.575837  [51200/72281]
loss: 0.034198  [57600/72281]
loss: 0.014362  [64000/72281]
loss: 1.567107  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.078796 

Epoch 18
-------------------------------
loss: 0.012250  [    0/72281]
loss: 0.000783  [ 6400/72281]
loss: 0.006485  [12800/72281]
loss: 0.038986  [19200/72281]
loss: 0.006078  [25600/72281]
loss: 0.033942  [32000/72281]
loss: 0.028796  [38400/72281]
loss: 0.053533  [44800/72281]
loss: 0.025476  [51200/72281]
loss: 0.021146  [57600/72281]
loss: 1.594031  [64000/72281]
loss: 0.103240  [70400/72281]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.088150 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.782398  [    0/70880]
loss: 0.143312  [ 6400/70880]
loss: 0.070847  [12800/70880]
loss: 0.164804  [19200/70880]
loss: 0.032138  [25600/70880]
loss: 0.112705  [32000/70880]
loss: 0.118629  [38400/70880]
loss: 0.082016  [44800/70880]
loss: 0.043311  [51200/70880]
loss: 0.289019  [57600/70880]
loss: 0.060712  [64000/70880]
loss: 0.091185  [70400/70880]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.098528 

Epoch 2
-------------------------------
loss: 0.072948  [    0/70880]
loss: 0.108888  [ 6400/70880]
loss: 0.037966  [12800/70880]
loss: 0.108694  [19200/70880]
loss: 0.140701  [25600/70880]
loss: 0.083865  [32000/70880]
loss: 0.074960  [38400/70880]
loss: 0.019588  [44800/70880]
loss: 0.147290  [51200/70880]
loss: 0.132723  [57600/70880]
loss: 0.099054  [64000/70880]
loss: 1.665709  [70400/70880]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.087181 

Epoch 3
-------------------------------
loss: 0.030539  [    0/70880]
loss: 0.072496  [ 6400/70880]
loss: 0.054985  [12800/70880]
loss: 0.050229  [19200/70880]
loss: 0.076417  [25600/70880]
loss: 0.115659  [32000/70880]
loss: 0.024088  [38400/70880]
loss: 0.087821  [44800/70880]
loss: 0.273069  [51200/70880]
loss: 0.156439  [57600/70880]
loss: 0.087088  [64000/70880]
loss: 0.057560  [70400/70880]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.091430 

Epoch 4
-------------------------------
loss: 0.023249  [    0/70880]
loss: 0.023741  [ 6400/70880]
loss: 0.032800  [12800/70880]
loss: 0.077188  [19200/70880]
loss: 0.051138  [25600/70880]
loss: 0.062752  [32000/70880]
loss: 0.065777  [38400/70880]
loss: 0.039813  [44800/70880]
loss: 0.082805  [51200/70880]
loss: 0.080315  [57600/70880]
loss: 0.046000  [64000/70880]
loss: 0.011641  [70400/70880]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.082854 

Epoch 5
-------------------------------
loss: 0.053983  [    0/70880]
loss: 0.030998  [ 6400/70880]
loss: 0.045538  [12800/70880]
loss: 0.061703  [19200/70880]
loss: 0.052665  [25600/70880]
loss: 0.069370  [32000/70880]
loss: 0.010429  [38400/70880]
loss: 0.080685  [44800/70880]
loss: 0.086010  [51200/70880]
loss: 0.009314  [57600/70880]
loss: 0.026970  [64000/70880]
loss: 0.052732  [70400/70880]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.088041 

Epoch 6
-------------------------------
loss: 0.038574  [    0/70880]
loss: 0.071903  [ 6400/70880]
loss: 0.019280  [12800/70880]
loss: 0.033946  [19200/70880]
loss: 0.049621  [25600/70880]
loss: 0.087393  [32000/70880]
loss: 0.034844  [38400/70880]
loss: 0.037173  [44800/70880]
loss: 0.057684  [51200/70880]
loss: 0.041781  [57600/70880]
loss: 0.052678  [64000/70880]
loss: 0.039533  [70400/70880]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.083044 

Epoch 7
-------------------------------
loss: 0.064430  [    0/70880]
loss: 0.077862  [ 6400/70880]
loss: 0.039890  [12800/70880]
loss: 0.059543  [19200/70880]
loss: 0.066627  [25600/70880]
loss: 0.055198  [32000/70880]
loss: 0.009983  [38400/70880]
loss: 0.053575  [44800/70880]
loss: 0.062143  [51200/70880]
loss: 0.049613  [57600/70880]
loss: 0.048085  [64000/70880]
loss: 0.038741  [70400/70880]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.080356 

Epoch 8
-------------------------------
loss: 0.073111  [    0/70880]
loss: 0.047795  [ 6400/70880]
loss: 0.022701  [12800/70880]
loss: 0.018124  [19200/70880]
loss: 0.043480  [25600/70880]
loss: 0.007886  [32000/70880]
loss: 0.053893  [38400/70880]
loss: 0.020377  [44800/70880]
loss: 0.023662  [51200/70880]
loss: 0.050380  [57600/70880]
loss: 0.038076  [64000/70880]
loss: 0.019627  [70400/70880]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.081367 

Epoch 9
-------------------------------
loss: 0.059641  [    0/70880]
loss: 0.031080  [ 6400/70880]
loss: 0.046321  [12800/70880]
loss: 0.025558  [19200/70880]
loss: 0.036524  [25600/70880]
loss: 0.027667  [32000/70880]
loss: 0.020522  [38400/70880]
loss: 0.059708  [44800/70880]
loss: 0.031524  [51200/70880]
loss: 0.045032  [57600/70880]
loss: 0.039172  [64000/70880]
loss: 0.167748  [70400/70880]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.083946 

Epoch 10
-------------------------------
loss: 0.060768  [    0/70880]
loss: 0.104362  [ 6400/70880]
loss: 0.018439  [12800/70880]
loss: 0.041578  [19200/70880]
loss: 0.024391  [25600/70880]
loss: 0.076052  [32000/70880]
loss: 0.023088  [38400/70880]
loss: 0.017917  [44800/70880]
loss: 0.114926  [51200/70880]
loss: 0.107072  [57600/70880]
loss: 0.056763  [64000/70880]
loss: 0.037054  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.078039 

Epoch 11
-------------------------------
loss: 0.029483  [    0/70880]
loss: 0.018625  [ 6400/70880]
loss: 0.049146  [12800/70880]
loss: 0.021050  [19200/70880]
loss: 0.026796  [25600/70880]
loss: 0.076756  [32000/70880]
loss: 0.040117  [38400/70880]
loss: 0.083216  [44800/70880]
loss: 0.070732  [51200/70880]
loss: 0.003336  [57600/70880]
loss: 0.013549  [64000/70880]
loss: 0.070979  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.080849 

Epoch 12
-------------------------------
loss: 0.014249  [    0/70880]
loss: 0.050567  [ 6400/70880]
loss: 0.089835  [12800/70880]
loss: 1.623206  [19200/70880]
loss: 0.006456  [25600/70880]
loss: 0.021718  [32000/70880]
loss: 1.593769  [38400/70880]
loss: 0.183710  [44800/70880]
loss: 0.059291  [51200/70880]
loss: 0.008714  [57600/70880]
loss: 0.082896  [64000/70880]
loss: 0.020703  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.076353 

Epoch 13
-------------------------------
loss: 0.017995  [    0/70880]
loss: 0.035903  [ 6400/70880]
loss: 0.054526  [12800/70880]
loss: 0.010003  [19200/70880]
loss: 0.066225  [25600/70880]
loss: 0.053187  [32000/70880]
loss: 0.052071  [38400/70880]
loss: 0.038825  [44800/70880]
loss: 0.145743  [51200/70880]
loss: 0.046734  [57600/70880]
loss: 0.068950  [64000/70880]
loss: 0.040137  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.084373 

Epoch 14
-------------------------------
loss: 0.024796  [    0/70880]
loss: 0.015757  [ 6400/70880]
loss: 0.030480  [12800/70880]
loss: 0.039188  [19200/70880]
loss: 0.006719  [25600/70880]
loss: 0.048348  [32000/70880]
loss: 0.006098  [38400/70880]
loss: 0.054968  [44800/70880]
loss: 0.055128  [51200/70880]
loss: 0.036330  [57600/70880]
loss: 0.088049  [64000/70880]
loss: 0.008644  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.080161 

Epoch 15
-------------------------------
loss: 0.022957  [    0/70880]
loss: 0.047321  [ 6400/70880]
loss: 0.129981  [12800/70880]
loss: 0.005651  [19200/70880]
loss: 0.017536  [25600/70880]
loss: 0.023021  [32000/70880]
loss: 0.041550  [38400/70880]
loss: 0.020166  [44800/70880]
loss: 0.041963  [51200/70880]
loss: 0.014934  [57600/70880]
loss: 0.066767  [64000/70880]
loss: 0.097464  [70400/70880]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.093311 

Epoch 16
-------------------------------
loss: 0.051120  [    0/70880]
loss: 0.045306  [ 6400/70880]
loss: 0.023991  [12800/70880]
loss: 0.023513  [19200/70880]
loss: 0.046772  [25600/70880]
loss: 0.046747  [32000/70880]
loss: 0.018679  [38400/70880]
loss: 0.040692  [44800/70880]
loss: 0.080288  [51200/70880]
loss: 0.055819  [57600/70880]
loss: 0.022090  [64000/70880]
loss: 0.079479  [70400/70880]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.075880 

Epoch 17
-------------------------------
loss: 0.025389  [    0/70880]
loss: 0.079283  [ 6400/70880]
loss: 0.069966  [12800/70880]
loss: 0.040308  [19200/70880]
loss: 0.154487  [25600/70880]
loss: 0.074808  [32000/70880]
loss: 0.071663  [38400/70880]
loss: 0.071943  [44800/70880]
loss: 0.023240  [51200/70880]
loss: 0.015807  [57600/70880]
loss: 0.055955  [64000/70880]
loss: 0.075081  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.082389 

Epoch 18
-------------------------------
loss: 0.009610  [    0/70880]
loss: 0.012974  [ 6400/70880]
loss: 0.013762  [12800/70880]
loss: 0.012569  [19200/70880]
loss: 0.054557  [25600/70880]
loss: 0.044179  [32000/70880]
loss: 0.020337  [38400/70880]
loss: 0.029179  [44800/70880]
loss: 0.007016  [51200/70880]
loss: 0.080251  [57600/70880]
loss: 0.059176  [64000/70880]
loss: 0.140202  [70400/70880]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.087335 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.741658  [    0/71625]
loss: 0.144407  [ 6400/71625]
loss: 0.026709  [12800/71625]
loss: 0.100465  [19200/71625]
loss: 0.049973  [25600/71625]
loss: 0.092074  [32000/71625]
loss: 0.064985  [38400/71625]
loss: 0.086149  [44800/71625]
loss: 0.053414  [51200/71625]
loss: 0.076900  [57600/71625]
loss: 0.040722  [64000/71625]
loss: 0.024494  [70400/71625]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.071479 

Epoch 2
-------------------------------
loss: 0.042082  [    0/71625]
loss: 0.028763  [ 6400/71625]
loss: 0.010909  [12800/71625]
loss: 0.017530  [19200/71625]
loss: 0.039629  [25600/71625]
loss: 0.118248  [32000/71625]
loss: 0.024120  [38400/71625]
loss: 0.012009  [44800/71625]
loss: 0.030790  [51200/71625]
loss: 0.044889  [57600/71625]
loss: 0.062862  [64000/71625]
loss: 0.068062  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.042240 

Epoch 3
-------------------------------
loss: 0.012492  [    0/71625]
loss: 0.057421  [ 6400/71625]
loss: 0.057779  [12800/71625]
loss: 0.018257  [19200/71625]
loss: 0.015284  [25600/71625]
loss: 0.002234  [32000/71625]
loss: 0.011361  [38400/71625]
loss: 0.011111  [44800/71625]
loss: 0.007648  [51200/71625]
loss: 0.051546  [57600/71625]
loss: 0.071979  [64000/71625]
loss: 0.160926  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.040912 

Epoch 4
-------------------------------
loss: 0.022691  [    0/71625]
loss: 0.004654  [ 6400/71625]
loss: 0.030533  [12800/71625]
loss: 0.015461  [19200/71625]
loss: 0.029728  [25600/71625]
loss: 0.011061  [32000/71625]
loss: 0.079196  [38400/71625]
loss: 0.010971  [44800/71625]
loss: 0.018098  [51200/71625]
loss: 0.012404  [57600/71625]
loss: 0.174636  [64000/71625]
loss: 0.194154  [70400/71625]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.066082 

Epoch 5
-------------------------------
loss: 0.055415  [    0/71625]
loss: 0.121103  [ 6400/71625]
loss: 0.011832  [12800/71625]
loss: 0.007128  [19200/71625]
loss: 0.065792  [25600/71625]
loss: 0.108460  [32000/71625]
loss: 0.012529  [38400/71625]
loss: 0.021299  [44800/71625]
loss: 0.075837  [51200/71625]
loss: 0.019084  [57600/71625]
loss: 0.022596  [64000/71625]
loss: 0.020039  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.043638 

Epoch 6
-------------------------------
loss: 0.019692  [    0/71625]
loss: 0.029365  [ 6400/71625]
loss: 0.004687  [12800/71625]
loss: 0.051449  [19200/71625]
loss: 0.025398  [25600/71625]
loss: 0.024012  [32000/71625]
loss: 0.020177  [38400/71625]
loss: 0.124080  [44800/71625]
loss: 0.013893  [51200/71625]
loss: 0.016119  [57600/71625]
loss: 0.050757  [64000/71625]
loss: 0.023382  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.038989 

Epoch 7
-------------------------------
loss: 0.017692  [    0/71625]
loss: 0.015120  [ 6400/71625]
loss: 0.012145  [12800/71625]
loss: 0.017857  [19200/71625]
loss: 0.032344  [25600/71625]
loss: 0.051625  [32000/71625]
loss: 0.081852  [38400/71625]
loss: 0.026154  [44800/71625]
loss: 0.019040  [51200/71625]
loss: 0.021638  [57600/71625]
loss: 0.027419  [64000/71625]
loss: 0.012382  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.043822 

Epoch 8
-------------------------------
loss: 0.063145  [    0/71625]
loss: 0.025969  [ 6400/71625]
loss: 0.020534  [12800/71625]
loss: 0.002062  [19200/71625]
loss: 0.021169  [25600/71625]
loss: 0.010794  [32000/71625]
loss: 0.019303  [38400/71625]
loss: 0.017729  [44800/71625]
loss: 0.172541  [51200/71625]
loss: 0.017570  [57600/71625]
loss: 0.011630  [64000/71625]
loss: 0.217699  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.040643 

Epoch 9
-------------------------------
loss: 0.005426  [    0/71625]
loss: 0.014860  [ 6400/71625]
loss: 0.019930  [12800/71625]
loss: 0.010781  [19200/71625]
loss: 0.008734  [25600/71625]
loss: 0.019635  [32000/71625]
loss: 0.044375  [38400/71625]
loss: 0.074469  [44800/71625]
loss: 0.025935  [51200/71625]
loss: 0.013682  [57600/71625]
loss: 0.010919  [64000/71625]
loss: 0.042466  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.037724 

Epoch 10
-------------------------------
loss: 0.048244  [    0/71625]
loss: 0.051318  [ 6400/71625]
loss: 0.078633  [12800/71625]
loss: 0.015493  [19200/71625]
loss: 0.143663  [25600/71625]
loss: 0.014276  [32000/71625]
loss: 0.009979  [38400/71625]
loss: 0.109037  [44800/71625]
loss: 0.018739  [51200/71625]
loss: 0.087472  [57600/71625]
loss: 0.011354  [64000/71625]
loss: 0.025926  [70400/71625]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.065947 

Epoch 11
-------------------------------
loss: 0.029845  [    0/71625]
loss: 0.042529  [ 6400/71625]
loss: 0.013853  [12800/71625]
loss: 0.041806  [19200/71625]
loss: 0.016746  [25600/71625]
loss: 0.023588  [32000/71625]
loss: 0.024595  [38400/71625]
loss: 0.001781  [44800/71625]
loss: 0.011772  [51200/71625]
loss: 0.041284  [57600/71625]
loss: 0.036911  [64000/71625]
loss: 0.028469  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.039285 

Epoch 12
-------------------------------
loss: 0.020009  [    0/71625]
loss: 0.015134  [ 6400/71625]
loss: 0.103055  [12800/71625]
loss: 0.009794  [19200/71625]
loss: 0.065163  [25600/71625]
loss: 0.030843  [32000/71625]
loss: 0.004913  [38400/71625]
loss: 0.016898  [44800/71625]
loss: 0.021037  [51200/71625]
loss: 0.001172  [57600/71625]
loss: 0.070494  [64000/71625]
loss: 0.104804  [70400/71625]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.053835 

Epoch 13
-------------------------------
loss: 0.047812  [    0/71625]
loss: 0.001571  [ 6400/71625]
loss: 0.020131  [12800/71625]
loss: 0.005517  [19200/71625]
loss: 0.046649  [25600/71625]
loss: 0.088981  [32000/71625]
loss: 0.051443  [38400/71625]
loss: 0.041092  [44800/71625]
loss: 0.061091  [51200/71625]
loss: 0.033949  [57600/71625]
loss: 0.023247  [64000/71625]
loss: 0.023552  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.038742 

Epoch 14
-------------------------------
loss: 0.024580  [    0/71625]
loss: 0.031107  [ 6400/71625]
loss: 0.043024  [12800/71625]
loss: 0.018532  [19200/71625]
loss: 0.019808  [25600/71625]
loss: 0.042502  [32000/71625]
loss: 0.072440  [38400/71625]
loss: 0.020451  [44800/71625]
loss: 0.058768  [51200/71625]
loss: 0.010676  [57600/71625]
loss: 0.046042  [64000/71625]
loss: 0.027510  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.046205 

Epoch 15
-------------------------------
loss: 0.029820  [    0/71625]
loss: 0.001925  [ 6400/71625]
loss: 0.067137  [12800/71625]
loss: 0.041112  [19200/71625]
loss: 0.003701  [25600/71625]
loss: 0.048989  [32000/71625]
loss: 0.025045  [38400/71625]
loss: 0.022547  [44800/71625]
loss: 0.000244  [51200/71625]
loss: 0.042537  [57600/71625]
loss: 0.045563  [64000/71625]
loss: 0.028668  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.036754 

Epoch 16
-------------------------------
loss: 0.009246  [    0/71625]
loss: 0.096332  [ 6400/71625]
loss: 0.026555  [12800/71625]
loss: 0.052212  [19200/71625]
loss: 0.062786  [25600/71625]
loss: 0.003438  [32000/71625]
loss: 0.008155  [38400/71625]
loss: 0.017576  [44800/71625]
loss: 0.088695  [51200/71625]
loss: 0.020832  [57600/71625]
loss: 0.085230  [64000/71625]
loss: 0.067434  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.039484 

Epoch 17
-------------------------------
loss: 0.013296  [    0/71625]
loss: 0.170580  [ 6400/71625]
loss: 0.001005  [12800/71625]
loss: 0.003730  [19200/71625]
loss: 0.018174  [25600/71625]
loss: 0.117058  [32000/71625]
loss: 0.073595  [38400/71625]
loss: 0.054580  [44800/71625]
loss: 0.004299  [51200/71625]
loss: 0.020822  [57600/71625]
loss: 0.001466  [64000/71625]
loss: 0.079330  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.044014 

Epoch 18
-------------------------------
loss: 0.033133  [    0/71625]
loss: 0.006710  [ 6400/71625]
loss: 0.114218  [12800/71625]
loss: 0.024785  [19200/71625]
loss: 0.183419  [25600/71625]
loss: 0.159849  [32000/71625]
loss: 0.024833  [38400/71625]
loss: 0.087729  [44800/71625]
loss: 0.006512  [51200/71625]
loss: 0.016990  [57600/71625]
loss: 0.060470  [64000/71625]
loss: 0.017187  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.039470 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.691653  [    0/72302]
loss: 0.113831  [ 6400/72302]
loss: 0.101458  [12800/72302]
loss: 0.038165  [19200/72302]
loss: 0.067027  [25600/72302]
loss: 0.048431  [32000/72302]
loss: 0.040086  [38400/72302]
loss: 0.121730  [44800/72302]
loss: 0.292529  [51200/72302]
loss: 0.069027  [57600/72302]
loss: 0.025254  [64000/72302]
loss: 0.025674  [70400/72302]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.061950 

Epoch 2
-------------------------------
loss: 0.030622  [    0/72302]
loss: 0.012690  [ 6400/72302]
loss: 0.006474  [12800/72302]
loss: 0.127832  [19200/72302]
loss: 0.025138  [25600/72302]
loss: 0.024640  [32000/72302]
loss: 0.034656  [38400/72302]
loss: 0.127602  [44800/72302]
loss: 0.101081  [51200/72302]
loss: 0.183319  [57600/72302]
loss: 0.021687  [64000/72302]
loss: 0.026144  [70400/72302]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.053781 

Epoch 3
-------------------------------
loss: 0.022445  [    0/72302]
loss: 0.041676  [ 6400/72302]
loss: 0.058881  [12800/72302]
loss: 0.031961  [19200/72302]
loss: 0.058228  [25600/72302]
loss: 0.019553  [32000/72302]
loss: 0.021797  [38400/72302]
loss: 0.124828  [44800/72302]
loss: 0.047280  [51200/72302]
loss: 0.105882  [57600/72302]
loss: 0.031103  [64000/72302]
loss: 0.022472  [70400/72302]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.052845 

Epoch 4
-------------------------------
loss: 0.031660  [    0/72302]
loss: 0.070539  [ 6400/72302]
loss: 0.044724  [12800/72302]
loss: 0.063410  [19200/72302]
loss: 0.017199  [25600/72302]
loss: 0.025984  [32000/72302]
loss: 0.015664  [38400/72302]
loss: 0.008976  [44800/72302]
loss: 0.036051  [51200/72302]
loss: 0.031918  [57600/72302]
loss: 0.150326  [64000/72302]
loss: 0.003821  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.049651 

Epoch 5
-------------------------------
loss: 0.085813  [    0/72302]
loss: 0.053071  [ 6400/72302]
loss: 0.027760  [12800/72302]
loss: 0.002104  [19200/72302]
loss: 0.096891  [25600/72302]
loss: 0.011135  [32000/72302]
loss: 0.035666  [38400/72302]
loss: 0.071776  [44800/72302]
loss: 0.032442  [51200/72302]
loss: 0.103233  [57600/72302]
loss: 0.064128  [64000/72302]
loss: 0.015716  [70400/72302]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.045721 

Epoch 6
-------------------------------
loss: 0.009388  [    0/72302]
loss: 0.024429  [ 6400/72302]
loss: 0.130930  [12800/72302]
loss: 0.028711  [19200/72302]
loss: 0.020336  [25600/72302]
loss: 0.025823  [32000/72302]
loss: 0.012978  [38400/72302]
loss: 0.001949  [44800/72302]
loss: 0.008954  [51200/72302]
loss: 0.015054  [57600/72302]
loss: 0.039288  [64000/72302]
loss: 0.015876  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.044851 

Epoch 7
-------------------------------
loss: 0.008174  [    0/72302]
loss: 0.039217  [ 6400/72302]
loss: 0.006395  [12800/72302]
loss: 0.073204  [19200/72302]
loss: 0.058021  [25600/72302]
loss: 0.059237  [32000/72302]
loss: 0.049414  [38400/72302]
loss: 0.029429  [44800/72302]
loss: 0.016745  [51200/72302]
loss: 0.066996  [57600/72302]
loss: 0.026914  [64000/72302]
loss: 0.016814  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.042129 

Epoch 8
-------------------------------
loss: 0.009318  [    0/72302]
loss: 0.003522  [ 6400/72302]
loss: 0.021810  [12800/72302]
loss: 0.004259  [19200/72302]
loss: 0.010774  [25600/72302]
loss: 0.047776  [32000/72302]
loss: 0.030162  [38400/72302]
loss: 0.015693  [44800/72302]
loss: 0.009304  [51200/72302]
loss: 0.040904  [57600/72302]
loss: 0.003987  [64000/72302]
loss: 0.066149  [70400/72302]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.049301 

Epoch 9
-------------------------------
loss: 0.017657  [    0/72302]
loss: 0.021818  [ 6400/72302]
loss: 0.002322  [12800/72302]
loss: 0.009369  [19200/72302]
loss: 0.002326  [25600/72302]
loss: 0.010011  [32000/72302]
loss: 0.148320  [38400/72302]
loss: 0.058204  [44800/72302]
loss: 0.011101  [51200/72302]
loss: 0.014438  [57600/72302]
loss: 0.025682  [64000/72302]
loss: 0.002396  [70400/72302]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.046639 

Epoch 10
-------------------------------
loss: 0.013312  [    0/72302]
loss: 0.006493  [ 6400/72302]
loss: 0.003663  [12800/72302]
loss: 0.016117  [19200/72302]
loss: 0.010199  [25600/72302]
loss: 0.034035  [32000/72302]
loss: 0.061078  [38400/72302]
loss: 0.028456  [44800/72302]
loss: 0.002431  [51200/72302]
loss: 0.016897  [57600/72302]
loss: 0.070603  [64000/72302]
loss: 0.007757  [70400/72302]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.048872 

Epoch 11
-------------------------------
loss: 0.028913  [    0/72302]
loss: 0.018753  [ 6400/72302]
loss: 0.015173  [12800/72302]
loss: 0.031490  [19200/72302]
loss: 0.009920  [25600/72302]
loss: 0.006193  [32000/72302]
loss: 0.001081  [38400/72302]
loss: 0.019634  [44800/72302]
loss: 0.005166  [51200/72302]
loss: 0.019402  [57600/72302]
loss: 0.041199  [64000/72302]
loss: 0.005556  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.046977 

Epoch 12
-------------------------------
loss: 0.013528  [    0/72302]
loss: 0.004382  [ 6400/72302]
loss: 0.043169  [12800/72302]
loss: 0.006657  [19200/72302]
loss: 0.006590  [25600/72302]
loss: 0.019930  [32000/72302]
loss: 0.005593  [38400/72302]
loss: 0.020876  [44800/72302]
loss: 0.034230  [51200/72302]
loss: 0.011925  [57600/72302]
loss: 0.008997  [64000/72302]
loss: 0.013644  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.042240 

Epoch 13
-------------------------------
loss: 0.009414  [    0/72302]
loss: 0.004646  [ 6400/72302]
loss: 0.014248  [12800/72302]
loss: 0.017491  [19200/72302]
loss: 0.009821  [25600/72302]
loss: 0.031636  [32000/72302]
loss: 0.006835  [38400/72302]
loss: 0.008433  [44800/72302]
loss: 0.008938  [51200/72302]
loss: 0.010964  [57600/72302]
loss: 0.006400  [64000/72302]
loss: 0.002618  [70400/72302]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.046170 

Epoch 14
-------------------------------
loss: 0.031099  [    0/72302]
loss: 0.003362  [ 6400/72302]
loss: 0.016975  [12800/72302]
loss: 0.003332  [19200/72302]
loss: 0.033957  [25600/72302]
loss: 0.012300  [32000/72302]
loss: 0.039389  [38400/72302]
loss: 0.004737  [44800/72302]
loss: 0.008902  [51200/72302]
loss: 0.045417  [57600/72302]
loss: 0.010138  [64000/72302]
loss: 0.022544  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.047733 

Epoch 15
-------------------------------
loss: 0.007950  [    0/72302]
loss: 0.014844  [ 6400/72302]
loss: 0.181936  [12800/72302]
loss: 0.001398  [19200/72302]
loss: 0.004919  [25600/72302]
loss: 0.036771  [32000/72302]
loss: 0.018423  [38400/72302]
loss: 0.010878  [44800/72302]
loss: 0.110922  [51200/72302]
loss: 0.034672  [57600/72302]
loss: 0.034914  [64000/72302]
loss: 0.003305  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.045472 

Epoch 16
-------------------------------
loss: 0.007148  [    0/72302]
loss: 0.001946  [ 6400/72302]
loss: 0.003507  [12800/72302]
loss: 0.016578  [19200/72302]
loss: 0.047905  [25600/72302]
loss: 0.004819  [32000/72302]
loss: 0.024408  [38400/72302]
loss: 0.011497  [44800/72302]
loss: 0.003163  [51200/72302]
loss: 0.003403  [57600/72302]
loss: 0.028076  [64000/72302]
loss: 0.028076  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.042382 

Epoch 17
-------------------------------
loss: 0.008850  [    0/72302]
loss: 0.002247  [ 6400/72302]
loss: 0.079484  [12800/72302]
loss: 0.029531  [19200/72302]
loss: 0.016173  [25600/72302]
loss: 0.000543  [32000/72302]
loss: 0.001524  [38400/72302]
loss: 0.079836  [44800/72302]
loss: 0.020585  [51200/72302]
loss: 0.004917  [57600/72302]
loss: 0.002529  [64000/72302]
loss: 0.002476  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.043846 

Epoch 18
-------------------------------
loss: 0.010205  [    0/72302]
loss: 0.023512  [ 6400/72302]
loss: 0.115607  [12800/72302]
loss: 0.000687  [19200/72302]
loss: 0.000922  [25600/72302]
loss: 0.006662  [32000/72302]
loss: 0.003137  [38400/72302]
loss: 0.002193  [44800/72302]
loss: 0.016994  [51200/72302]
loss: 0.001817  [57600/72302]
loss: 0.004389  [64000/72302]
loss: 0.001687  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.042014 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.896230  [    0/70296]
loss: 0.138791  [ 6400/70296]
loss: 0.054548  [12800/70296]
loss: 0.149329  [19200/70296]
loss: 0.059511  [25600/70296]
loss: 0.152048  [32000/70296]
loss: 0.075063  [38400/70296]
loss: 0.178608  [44800/70296]
loss: 0.110495  [51200/70296]
loss: 0.113572  [57600/70296]
loss: 0.115498  [64000/70296]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.078537 

Epoch 2
-------------------------------
loss: 0.048480  [    0/70296]
loss: 0.212686  [ 6400/70296]
loss: 0.109154  [12800/70296]
loss: 0.150928  [19200/70296]
loss: 0.070091  [25600/70296]
loss: 0.095797  [32000/70296]
loss: 0.095194  [38400/70296]
loss: 0.062323  [44800/70296]
loss: 0.013760  [51200/70296]
loss: 0.147396  [57600/70296]
loss: 0.180558  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.068970 

Epoch 3
-------------------------------
loss: 0.142089  [    0/70296]
loss: 0.106600  [ 6400/70296]
loss: 0.033406  [12800/70296]
loss: 0.080286  [19200/70296]
loss: 0.028252  [25600/70296]
loss: 0.048721  [32000/70296]
loss: 0.083197  [38400/70296]
loss: 0.064545  [44800/70296]
loss: 0.036649  [51200/70296]
loss: 0.151755  [57600/70296]
loss: 0.052329  [64000/70296]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.064401 

Epoch 4
-------------------------------
loss: 0.078878  [    0/70296]
loss: 0.045614  [ 6400/70296]
loss: 0.026109  [12800/70296]
loss: 0.132939  [19200/70296]
loss: 0.106526  [25600/70296]
loss: 0.018303  [32000/70296]
loss: 0.068487  [38400/70296]
loss: 0.061612  [44800/70296]
loss: 0.129181  [51200/70296]
loss: 0.069646  [57600/70296]
loss: 0.028484  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067200 

Epoch 5
-------------------------------
loss: 0.010845  [    0/70296]
loss: 0.021928  [ 6400/70296]
loss: 0.120771  [12800/70296]
loss: 0.089590  [19200/70296]
loss: 0.163237  [25600/70296]
loss: 0.025943  [32000/70296]
loss: 0.061952  [38400/70296]
loss: 0.098289  [44800/70296]
loss: 0.088785  [51200/70296]
loss: 0.029394  [57600/70296]
loss: 0.078455  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.064675 

Epoch 6
-------------------------------
loss: 0.073252  [    0/70296]
loss: 0.072575  [ 6400/70296]
loss: 0.043394  [12800/70296]
loss: 0.092903  [19200/70296]
loss: 0.077643  [25600/70296]
loss: 0.107303  [32000/70296]
loss: 0.138356  [38400/70296]
loss: 0.029774  [44800/70296]
loss: 0.162084  [51200/70296]
loss: 0.074062  [57600/70296]
loss: 0.083074  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.068588 

Epoch 7
-------------------------------
loss: 0.030549  [    0/70296]
loss: 0.060086  [ 6400/70296]
loss: 0.090880  [12800/70296]
loss: 0.010879  [19200/70296]
loss: 0.024956  [25600/70296]
loss: 0.014938  [32000/70296]
loss: 0.162236  [38400/70296]
loss: 0.024604  [44800/70296]
loss: 0.085430  [51200/70296]
loss: 0.028028  [57600/70296]
loss: 0.062410  [64000/70296]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.065551 

Epoch 8
-------------------------------
loss: 0.075412  [    0/70296]
loss: 0.022446  [ 6400/70296]
loss: 0.137400  [12800/70296]
loss: 0.075623  [19200/70296]
loss: 0.115864  [25600/70296]
loss: 0.015500  [32000/70296]
loss: 0.095078  [38400/70296]
loss: 0.023505  [44800/70296]
loss: 0.055315  [51200/70296]
loss: 0.038013  [57600/70296]
loss: 0.027754  [64000/70296]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.061610 

Epoch 9
-------------------------------
loss: 0.093547  [    0/70296]
loss: 0.091570  [ 6400/70296]
loss: 0.063501  [12800/70296]
loss: 0.074046  [19200/70296]
loss: 0.021398  [25600/70296]
loss: 0.073078  [32000/70296]
loss: 0.039015  [38400/70296]
loss: 0.084651  [44800/70296]
loss: 0.164731  [51200/70296]
loss: 0.150168  [57600/70296]
loss: 0.057768  [64000/70296]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.065750 

Epoch 10
-------------------------------
loss: 0.049982  [    0/70296]
loss: 0.030482  [ 6400/70296]
loss: 0.059839  [12800/70296]
loss: 0.103843  [19200/70296]
loss: 0.068974  [25600/70296]
loss: 0.025439  [32000/70296]
loss: 0.150282  [38400/70296]
loss: 0.153607  [44800/70296]
loss: 0.065443  [51200/70296]
loss: 0.088594  [57600/70296]
loss: 0.152311  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076218 

Epoch 11
-------------------------------
loss: 0.018864  [    0/70296]
loss: 0.101989  [ 6400/70296]
loss: 0.188907  [12800/70296]
loss: 0.017506  [19200/70296]
loss: 0.071713  [25600/70296]
loss: 0.059326  [32000/70296]
loss: 0.047163  [38400/70296]
loss: 0.025564  [44800/70296]
loss: 0.072366  [51200/70296]
loss: 0.036809  [57600/70296]
loss: 0.108611  [64000/70296]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067226 

Epoch 12
-------------------------------
loss: 0.048089  [    0/70296]
loss: 0.058659  [ 6400/70296]
loss: 0.038518  [12800/70296]
loss: 0.081233  [19200/70296]
loss: 0.067946  [25600/70296]
loss: 0.115217  [32000/70296]
loss: 0.018287  [38400/70296]
loss: 0.088230  [44800/70296]
loss: 0.101606  [51200/70296]
loss: 0.063024  [57600/70296]
loss: 0.071733  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.073114 

Epoch 13
-------------------------------
loss: 0.031442  [    0/70296]
loss: 0.072156  [ 6400/70296]
loss: 0.031428  [12800/70296]
loss: 0.082177  [19200/70296]
loss: 0.024128  [25600/70296]
loss: 0.074652  [32000/70296]
loss: 0.100335  [38400/70296]
loss: 0.030865  [44800/70296]
loss: 0.020337  [51200/70296]
loss: 0.048214  [57600/70296]
loss: 0.075064  [64000/70296]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.072646 

Epoch 14
-------------------------------
loss: 0.201041  [    0/70296]
loss: 0.090567  [ 6400/70296]
loss: 0.070281  [12800/70296]
loss: 0.142324  [19200/70296]
loss: 0.039717  [25600/70296]
loss: 0.064118  [32000/70296]
loss: 0.025597  [38400/70296]
loss: 0.041534  [44800/70296]
loss: 0.086863  [51200/70296]
loss: 0.029860  [57600/70296]
loss: 0.104514  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076262 

Epoch 15
-------------------------------
loss: 0.055111  [    0/70296]
loss: 0.016443  [ 6400/70296]
loss: 0.020848  [12800/70296]
loss: 0.069490  [19200/70296]
loss: 0.043935  [25600/70296]
loss: 0.012955  [32000/70296]
loss: 0.026458  [38400/70296]
loss: 0.042724  [44800/70296]
loss: 0.029403  [51200/70296]
loss: 0.063515  [57600/70296]
loss: 0.095096  [64000/70296]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070756 

Epoch 16
-------------------------------
loss: 0.054471  [    0/70296]
loss: 0.201236  [ 6400/70296]
loss: 0.138543  [12800/70296]
loss: 0.032390  [19200/70296]
loss: 0.082805  [25600/70296]
loss: 0.004347  [32000/70296]
loss: 0.052125  [38400/70296]
loss: 0.041048  [44800/70296]
loss: 0.021198  [51200/70296]
loss: 0.038796  [57600/70296]
loss: 0.107798  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.074920 

Epoch 17
-------------------------------
loss: 0.054582  [    0/70296]
loss: 0.042678  [ 6400/70296]
loss: 0.051841  [12800/70296]
loss: 0.149660  [19200/70296]
loss: 0.034183  [25600/70296]
loss: 0.126248  [32000/70296]
loss: 0.063975  [38400/70296]
loss: 0.277335  [44800/70296]
loss: 0.110553  [51200/70296]
loss: 0.045053  [57600/70296]
loss: 0.096740  [64000/70296]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.072160 

Epoch 18
-------------------------------
loss: 0.034209  [    0/70296]
loss: 0.293411  [ 6400/70296]
loss: 0.036063  [12800/70296]
loss: 0.052665  [19200/70296]
loss: 0.045111  [25600/70296]
loss: 0.118646  [32000/70296]
loss: 0.150429  [38400/70296]
loss: 0.066765  [44800/70296]
loss: 0.132592  [51200/70296]
loss: 0.029532  [57600/70296]
loss: 0.005046  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.070105 

Epoch 19
-------------------------------
loss: 0.069578  [    0/70296]
loss: 0.037500  [ 6400/70296]
loss: 0.017425  [12800/70296]
loss: 0.069325  [19200/70296]
loss: 0.062773  [25600/70296]
loss: 0.073669  [32000/70296]
loss: 0.006634  [38400/70296]
loss: 0.067382  [44800/70296]
loss: 0.055673  [51200/70296]
loss: 0.086761  [57600/70296]
loss: 0.029341  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.070825 

Epoch 20
-------------------------------
loss: 0.126041  [    0/70296]
loss: 0.034592  [ 6400/70296]
loss: 0.043509  [12800/70296]
loss: 0.072864  [19200/70296]
Epoch 1
-------------------------------
loss: 0.899247  [    0/69398]
loss: 0.251926  [ 6400/69398]
loss: 0.207357  [12800/69398]
loss: 0.256626  [19200/69398]
loss: 0.211624  [25600/69398]
loss: 0.267039  [32000/69398]
loss: 0.322738  [38400/69398]
loss: 0.237867  [44800/69398]
loss: 0.249756  [51200/69398]
loss: 0.182009  [57600/69398]
loss: 0.156465  [64000/69398]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.206081 

Epoch 2
-------------------------------
loss: 0.207106  [    0/69398]
loss: 0.239034  [ 6400/69398]
loss: 0.205799  [12800/69398]
loss: 0.187036  [19200/69398]
loss: 0.152921  [25600/69398]
loss: 0.339915  [32000/69398]
loss: 0.140162  [38400/69398]
loss: 0.203448  [44800/69398]
loss: 0.301186  [51200/69398]
loss: 0.156769  [57600/69398]
loss: 0.192603  [64000/69398]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.180613 

Epoch 3
-------------------------------
loss: 0.179008  [    0/69398]
loss: 0.165345  [ 6400/69398]
loss: 0.199863  [12800/69398]
loss: 0.269107  [19200/69398]
loss: 0.151283  [25600/69398]
loss: 0.075509  [32000/69398]
loss: 0.155772  [38400/69398]
loss: 0.111653  [44800/69398]
loss: 0.089841  [51200/69398]
loss: 0.123128  [57600/69398]
loss: 0.226102  [64000/69398]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.162828 

Epoch 4
-------------------------------
loss: 0.133520  [    0/69398]
loss: 0.180891  [ 6400/69398]
loss: 0.142213  [12800/69398]
loss: 0.101628  [19200/69398]
loss: 0.097081  [25600/69398]
loss: 0.158001  [32000/69398]
loss: 0.208408  [38400/69398]
loss: 0.108352  [44800/69398]
loss: 0.112352  [51200/69398]
loss: 0.215096  [57600/69398]
loss: 0.246463  [64000/69398]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.191454 

Epoch 5
-------------------------------
loss: 0.051394  [    0/69398]
loss: 0.134759  [ 6400/69398]
loss: 0.198644  [12800/69398]
loss: 0.175657  [19200/69398]
loss: 0.119980  [25600/69398]
loss: 0.228442  [32000/69398]
loss: 0.138553  [38400/69398]
loss: 0.196584  [44800/69398]
loss: 0.110180  [51200/69398]
loss: 0.100114  [57600/69398]
loss: 0.204174  [64000/69398]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.166112 

Epoch 6
-------------------------------
loss: 0.123519  [    0/69398]
loss: 0.210072  [ 6400/69398]
loss: 0.171578  [12800/69398]
loss: 0.159711  [19200/69398]
loss: 0.092667  [25600/69398]
loss: 0.107151  [32000/69398]
loss: 0.104959  [38400/69398]
loss: 0.105044  [44800/69398]
loss: 0.114680  [51200/69398]
loss: 0.054455  [57600/69398]
loss: 0.095739  [64000/69398]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.159209 

Epoch 7
-------------------------------
loss: 0.152558  [    0/69398]
loss: 0.145680  [ 6400/69398]
loss: 0.153793  [12800/69398]
loss: 0.248583  [19200/69398]
loss: 0.092161  [25600/69398]
loss: 0.143076  [32000/69398]
loss: 0.212514  [38400/69398]
loss: 0.149779  [44800/69398]
loss: 0.094576  [51200/69398]
loss: 0.121671  [57600/69398]
loss: 0.182437  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.156024 

Epoch 8
-------------------------------
loss: 0.093049  [    0/69398]
loss: 0.226076  [ 6400/69398]
loss: 0.142443  [12800/69398]
loss: 0.103961  [19200/69398]
loss: 0.193057  [25600/69398]
loss: 0.241438  [32000/69398]
loss: 0.112935  [38400/69398]
loss: 0.167595  [44800/69398]
loss: 0.221885  [51200/69398]
loss: 0.114571  [57600/69398]
loss: 0.138252  [64000/69398]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.164890 

Epoch 9
-------------------------------
loss: 0.052133  [    0/69398]
loss: 0.131610  [ 6400/69398]
loss: 0.225780  [12800/69398]
loss: 0.175217  [19200/69398]
loss: 0.168431  [25600/69398]
loss: 0.159868  [32000/69398]
loss: 0.130750  [38400/69398]
loss: 0.234002  [44800/69398]
loss: 0.164989  [51200/69398]
loss: 0.106283  [57600/69398]
loss: 0.117693  [64000/69398]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.168417 

Epoch 10
-------------------------------
loss: 0.178378  [    0/69398]
loss: 0.205035  [ 6400/69398]
loss: 0.073321  [12800/69398]
loss: 0.102244  [19200/69398]
loss: 0.168243  [25600/69398]
loss: 0.116923  [32000/69398]
loss: 0.186472  [38400/69398]
loss: 0.206036  [44800/69398]
loss: 0.144033  [51200/69398]
loss: 1.705458  [57600/69398]
loss: 0.136816  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.150909 

Epoch 11
-------------------------------
loss: 0.088970  [    0/69398]
loss: 0.143488  [ 6400/69398]
loss: 0.219358  [12800/69398]
loss: 0.106926  [19200/69398]
loss: 0.095197  [25600/69398]
loss: 0.231739  [32000/69398]
loss: 0.135981  [38400/69398]
loss: 0.148632  [44800/69398]
loss: 0.224380  [51200/69398]
loss: 0.135511  [57600/69398]
loss: 0.060896  [64000/69398]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.155184 

Epoch 12
-------------------------------
loss: 0.171611  [    0/69398]
loss: 0.182393  [ 6400/69398]
loss: 0.134167  [12800/69398]
loss: 0.169685  [19200/69398]
loss: 0.189606  [25600/69398]
loss: 0.120290  [32000/69398]
loss: 0.236157  [38400/69398]
loss: 0.125170  [44800/69398]
loss: 0.171298  [51200/69398]
loss: 0.257981  [57600/69398]
loss: 0.109014  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.149208 

Epoch 13
-------------------------------
loss: 0.127523  [    0/69398]
loss: 0.176862  [ 6400/69398]
loss: 0.182953  [12800/69398]
loss: 0.186531  [19200/69398]
loss: 0.165117  [25600/69398]
loss: 0.159943  [32000/69398]
loss: 0.206471  [38400/69398]
loss: 0.162864  [44800/69398]
loss: 0.188612  [51200/69398]
loss: 0.102082  [57600/69398]
loss: 0.123818  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.151048 

Epoch 14
-------------------------------
loss: 0.124823  [    0/69398]
loss: 0.167211  [ 6400/69398]
loss: 0.079910  [12800/69398]
loss: 0.069909  [19200/69398]
loss: 0.301516  [25600/69398]
loss: 0.145022  [32000/69398]
loss: 0.237160  [38400/69398]
loss: 0.104216  [44800/69398]
loss: 0.187194  [51200/69398]
loss: 0.115233  [57600/69398]
loss: 0.157534  [64000/69398]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.152544 

Epoch 15
-------------------------------
loss: 0.173486  [    0/69398]
loss: 0.162828  [ 6400/69398]
loss: 0.122393  [12800/69398]
loss: 0.076787  [19200/69398]
loss: 0.155483  [25600/69398]
loss: 0.233414  [32000/69398]
loss: 0.181344  [38400/69398]
loss: 0.080867  [44800/69398]
loss: 0.272443  [51200/69398]
loss: 0.188226  [57600/69398]
loss: 0.127760  [64000/69398]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.151830 

Epoch 16
-------------------------------
loss: 0.080263  [    0/69398]
loss: 0.161988  [ 6400/69398]
loss: 0.143053  [12800/69398]
loss: 0.128427  [19200/69398]
loss: 0.153146  [25600/69398]
loss: 0.166878  [32000/69398]
loss: 0.134924  [38400/69398]
loss: 0.254788  [44800/69398]
loss: 0.033730  [51200/69398]
loss: 0.130421  [57600/69398]
loss: 0.120765  [64000/69398]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.150170 

Epoch 17
-------------------------------
loss: 0.094695  [    0/69398]
loss: 0.103587  [ 6400/69398]
loss: 0.201254  [12800/69398]
loss: 0.064976  [19200/69398]
loss: 0.149445  [25600/69398]
loss: 0.212722  [32000/69398]
loss: 0.103438  [38400/69398]
loss: 0.258124  [44800/69398]
loss: 0.113385  [51200/69398]
loss: 0.160207  [57600/69398]
loss: 0.156452  [64000/69398]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.146468 

Epoch 18
-------------------------------
loss: 0.065674  [    0/69398]
loss: 0.068126  [ 6400/69398]
loss: 0.228543  [12800/69398]
loss: 0.271722  [19200/69398]
loss: 0.137968  [25600/69398]
loss: 0.144409  [32000/69398]
loss: 0.068008  [38400/69398]
loss: 0.055210  [44800/69398]
loss: 0.092225  [51200/69398]
loss: 0.232644  [57600/69398]
loss: 0.076891  [64000/69398]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.182595 

Epoch 19
-------------------------------
loss: 0.103489  [    0/69398]
loss: 0.090208  [ 6400/69398]
loss: 0.115632  [12800/69398]
loss: 0.039433  [19200/69398]
loss: 0.187344  [25600/69398]
loss: 0.142278  [32000/69398]
loss: 0.310885  [38400/69398]
loss: 0.204615  [44800/69398]
loss: 0.126517  [51200/69398]
loss: 0.073254  [57600/69398]
loss: 0.243619  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.150523 

Epoch 20
-------------------------------
loss: 0.188308  [    0/69398]
loss: 0.094691  [ 6400/69398]
loss: 0.099997  [12800/69398]
loss: 0.122970  [19200/69398]
Epoch 1
-------------------------------
loss: 0.894190  [    0/69683]
loss: 0.198789  [ 6400/69683]
loss: 0.305741  [12800/69683]
loss: 0.288180  [19200/69683]
loss: 0.182183  [25600/69683]
loss: 0.312422  [32000/69683]
loss: 0.195414  [38400/69683]
loss: 0.249014  [44800/69683]
loss: 0.156574  [51200/69683]
loss: 0.218548  [57600/69683]
loss: 0.231737  [64000/69683]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.209086 

Epoch 2
-------------------------------
loss: 0.178926  [    0/69683]
loss: 0.314415  [ 6400/69683]
loss: 0.248524  [12800/69683]
loss: 0.208973  [19200/69683]
loss: 0.138611  [25600/69683]
loss: 0.109625  [32000/69683]
loss: 0.221984  [38400/69683]
loss: 0.199766  [44800/69683]
loss: 0.154916  [51200/69683]
loss: 0.118295  [57600/69683]
loss: 0.146703  [64000/69683]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.182762 

Epoch 3
-------------------------------
loss: 0.175982  [    0/69683]
loss: 0.338007  [ 6400/69683]
loss: 0.194732  [12800/69683]
loss: 0.188110  [19200/69683]
loss: 0.295912  [25600/69683]
loss: 0.215998  [32000/69683]
loss: 0.149432  [38400/69683]
loss: 0.144400  [44800/69683]
loss: 0.210069  [51200/69683]
loss: 0.228914  [57600/69683]
loss: 0.115483  [64000/69683]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.176387 

Epoch 4
-------------------------------
loss: 0.081781  [    0/69683]
loss: 0.203405  [ 6400/69683]
loss: 0.090611  [12800/69683]
loss: 0.126928  [19200/69683]
loss: 0.224892  [25600/69683]
loss: 0.208341  [32000/69683]
loss: 0.234603  [38400/69683]
loss: 0.110229  [44800/69683]
loss: 0.158316  [51200/69683]
loss: 0.164781  [57600/69683]
loss: 0.258215  [64000/69683]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.177099 

Epoch 5
-------------------------------
loss: 0.194728  [    0/69683]
loss: 0.144145  [ 6400/69683]
loss: 0.104902  [12800/69683]
loss: 0.140287  [19200/69683]
loss: 0.231453  [25600/69683]
loss: 0.148249  [32000/69683]
loss: 0.150858  [38400/69683]
loss: 0.034086  [44800/69683]
loss: 0.196608  [51200/69683]
loss: 0.114083  [57600/69683]
loss: 0.212543  [64000/69683]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.175977 

Epoch 6
-------------------------------
loss: 0.264633  [    0/69683]
loss: 0.128459  [ 6400/69683]
loss: 0.162017  [12800/69683]
loss: 0.127574  [19200/69683]
loss: 0.193539  [25600/69683]
loss: 0.114916  [32000/69683]
loss: 0.083503  [38400/69683]
loss: 0.084982  [44800/69683]
loss: 0.119064  [51200/69683]
loss: 0.122815  [57600/69683]
loss: 0.062979  [64000/69683]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.169672 

Epoch 7
-------------------------------
loss: 0.089845  [    0/69683]
loss: 0.119949  [ 6400/69683]
loss: 0.262922  [12800/69683]
loss: 0.042708  [19200/69683]
loss: 0.102029  [25600/69683]
loss: 0.229325  [32000/69683]
loss: 0.109239  [38400/69683]
loss: 0.102181  [44800/69683]
loss: 0.090634  [51200/69683]
loss: 0.233930  [57600/69683]
loss: 0.201076  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.168875 

Epoch 8
-------------------------------
loss: 0.104309  [    0/69683]
loss: 0.291584  [ 6400/69683]
loss: 0.060280  [12800/69683]
loss: 0.271977  [19200/69683]
loss: 0.264440  [25600/69683]
loss: 1.606063  [32000/69683]
loss: 0.112287  [38400/69683]
loss: 0.147716  [44800/69683]
loss: 0.129845  [51200/69683]
loss: 0.191907  [57600/69683]
loss: 0.093731  [64000/69683]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.163145 

Epoch 9
-------------------------------
loss: 0.192178  [    0/69683]
loss: 0.299938  [ 6400/69683]
loss: 0.088912  [12800/69683]
loss: 0.150371  [19200/69683]
loss: 0.221039  [25600/69683]
loss: 0.091249  [32000/69683]
loss: 0.108040  [38400/69683]
loss: 0.110932  [44800/69683]
loss: 0.186548  [51200/69683]
loss: 0.149055  [57600/69683]
loss: 0.177573  [64000/69683]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.168084 

Epoch 10
-------------------------------
loss: 0.130622  [    0/69683]
loss: 0.202068  [ 6400/69683]
loss: 0.090148  [12800/69683]
loss: 0.150639  [19200/69683]
loss: 0.104872  [25600/69683]
loss: 0.256785  [32000/69683]
loss: 0.193744  [38400/69683]
loss: 0.151609  [44800/69683]
loss: 0.142197  [51200/69683]
loss: 0.130892  [57600/69683]
loss: 0.135932  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.160649 

Epoch 11
-------------------------------
loss: 0.098489  [    0/69683]
loss: 0.157076  [ 6400/69683]
loss: 0.083746  [12800/69683]
loss: 0.134480  [19200/69683]
loss: 0.152744  [25600/69683]
loss: 0.168063  [32000/69683]
loss: 0.143145  [38400/69683]
loss: 0.081941  [44800/69683]
loss: 0.280452  [51200/69683]
loss: 0.167177  [57600/69683]
loss: 0.175468  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162909 

Epoch 12
-------------------------------
loss: 0.072582  [    0/69683]
loss: 0.130422  [ 6400/69683]
loss: 0.133148  [12800/69683]
loss: 0.093302  [19200/69683]
loss: 0.153280  [25600/69683]
loss: 0.176379  [32000/69683]
loss: 1.634858  [38400/69683]
loss: 0.227956  [44800/69683]
loss: 0.148435  [51200/69683]
loss: 0.047773  [57600/69683]
loss: 0.170334  [64000/69683]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.177008 

Epoch 13
-------------------------------
loss: 0.084818  [    0/69683]
loss: 0.130855  [ 6400/69683]
loss: 0.171011  [12800/69683]
loss: 0.144455  [19200/69683]
loss: 0.227008  [25600/69683]
loss: 0.092550  [32000/69683]
loss: 0.327955  [38400/69683]
loss: 0.223485  [44800/69683]
loss: 0.092268  [51200/69683]
loss: 0.167204  [57600/69683]
loss: 0.124861  [64000/69683]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160604 

Epoch 14
-------------------------------
loss: 0.158736  [    0/69683]
loss: 0.067160  [ 6400/69683]
loss: 0.114265  [12800/69683]
loss: 0.112477  [19200/69683]
loss: 0.067783  [25600/69683]
loss: 0.105751  [32000/69683]
loss: 0.228021  [38400/69683]
loss: 0.170159  [44800/69683]
loss: 0.112781  [51200/69683]
loss: 0.246135  [57600/69683]
loss: 0.071293  [64000/69683]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.169369 

Epoch 15
-------------------------------
loss: 0.049970  [    0/69683]
loss: 0.096901  [ 6400/69683]
loss: 0.028805  [12800/69683]
loss: 1.663013  [19200/69683]
loss: 0.128617  [25600/69683]
loss: 0.185217  [32000/69683]
loss: 0.140317  [38400/69683]
loss: 0.049230  [44800/69683]
loss: 0.224841  [51200/69683]
loss: 0.119043  [57600/69683]
loss: 0.100980  [64000/69683]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.164467 

Epoch 16
-------------------------------
loss: 0.081913  [    0/69683]
loss: 0.126135  [ 6400/69683]
loss: 0.150896  [12800/69683]
loss: 0.307880  [19200/69683]
loss: 0.095491  [25600/69683]
loss: 0.124013  [32000/69683]
loss: 0.110357  [38400/69683]
loss: 0.279459  [44800/69683]
loss: 0.081721  [51200/69683]
loss: 0.112853  [57600/69683]
loss: 0.118803  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.159799 

Epoch 17
-------------------------------
loss: 0.119903  [    0/69683]
loss: 0.176115  [ 6400/69683]
loss: 0.165678  [12800/69683]
loss: 0.199319  [19200/69683]
loss: 0.091055  [25600/69683]
loss: 0.120693  [32000/69683]
loss: 0.067716  [38400/69683]
loss: 0.294317  [44800/69683]
loss: 0.261260  [51200/69683]
loss: 0.110409  [57600/69683]
loss: 0.102476  [64000/69683]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.161101 

Epoch 18
-------------------------------
loss: 0.060434  [    0/69683]
loss: 0.173435  [ 6400/69683]
loss: 0.170774  [12800/69683]
loss: 0.098794  [19200/69683]
loss: 0.130615  [25600/69683]
loss: 0.209850  [32000/69683]
loss: 0.093856  [38400/69683]
loss: 0.114181  [44800/69683]
loss: 0.133503  [51200/69683]
loss: 0.181270  [57600/69683]
loss: 0.141459  [64000/69683]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.163196 

Epoch 19
-------------------------------
loss: 0.295198  [    0/69683]
loss: 0.120455  [ 6400/69683]
loss: 0.158654  [12800/69683]
loss: 0.072521  [19200/69683]
loss: 0.117295  [25600/69683]
loss: 0.107987  [32000/69683]
loss: 0.093249  [38400/69683]
loss: 0.098852  [44800/69683]
loss: 0.187513  [51200/69683]
loss: 1.766345  [57600/69683]
loss: 0.082067  [64000/69683]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.160118 

Epoch 20
-------------------------------
loss: 0.146133  [    0/69683]
loss: 0.119914  [ 6400/69683]
loss: 0.070140  [12800/69683]
loss: 0.167608  [19200/69683]
Epoch 1
-------------------------------
loss: 0.886757  [    0/71297]
loss: 0.150387  [ 6400/71297]
loss: 0.136395  [12800/71297]
loss: 0.200213  [19200/71297]
loss: 0.133728  [25600/71297]
loss: 0.046062  [32000/71297]
loss: 0.084762  [38400/71297]
loss: 0.135057  [44800/71297]
loss: 0.140781  [51200/71297]
loss: 0.057571  [57600/71297]
loss: 0.085399  [64000/71297]
loss: 0.049770  [70400/71297]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.105186 

Epoch 2
-------------------------------
loss: 0.148428  [    0/71297]
loss: 0.051420  [ 6400/71297]
loss: 0.051295  [12800/71297]
loss: 0.105432  [19200/71297]
loss: 0.137578  [25600/71297]
loss: 0.064484  [32000/71297]
loss: 0.055629  [38400/71297]
loss: 0.062248  [44800/71297]
loss: 0.136473  [51200/71297]
loss: 0.053772  [57600/71297]
loss: 0.169952  [64000/71297]
loss: 0.350723  [70400/71297]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.098195 

Epoch 3
-------------------------------
loss: 0.083181  [    0/71297]
loss: 0.028415  [ 6400/71297]
loss: 0.184811  [12800/71297]
loss: 0.029007  [19200/71297]
loss: 0.032494  [25600/71297]
loss: 0.130488  [32000/71297]
loss: 0.024420  [38400/71297]
loss: 0.050363  [44800/71297]
loss: 0.053273  [51200/71297]
loss: 0.045072  [57600/71297]
loss: 0.142799  [64000/71297]
loss: 0.082507  [70400/71297]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.106929 

Epoch 4
-------------------------------
loss: 0.051945  [    0/71297]
loss: 0.017155  [ 6400/71297]
loss: 0.089306  [12800/71297]
loss: 0.070464  [19200/71297]
loss: 0.021061  [25600/71297]
loss: 0.052190  [32000/71297]
loss: 0.110052  [38400/71297]
loss: 0.028421  [44800/71297]
loss: 0.035307  [51200/71297]
loss: 0.084008  [57600/71297]
loss: 0.022725  [64000/71297]
loss: 0.213759  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.090005 

Epoch 5
-------------------------------
loss: 0.082821  [    0/71297]
loss: 0.138345  [ 6400/71297]
loss: 0.034299  [12800/71297]
loss: 0.037117  [19200/71297]
loss: 0.039512  [25600/71297]
loss: 0.070845  [32000/71297]
loss: 0.056194  [38400/71297]
loss: 0.065879  [44800/71297]
loss: 0.041578  [51200/71297]
loss: 0.043203  [57600/71297]
loss: 0.147506  [64000/71297]
loss: 0.052494  [70400/71297]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.089121 

Epoch 6
-------------------------------
loss: 0.015208  [    0/71297]
loss: 0.073958  [ 6400/71297]
loss: 0.026747  [12800/71297]
loss: 0.070683  [19200/71297]
loss: 0.097975  [25600/71297]
loss: 0.088093  [32000/71297]
loss: 0.022230  [38400/71297]
loss: 0.079224  [44800/71297]
loss: 0.064389  [51200/71297]
loss: 0.065579  [57600/71297]
loss: 0.042637  [64000/71297]
loss: 0.032976  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.093599 

Epoch 7
-------------------------------
loss: 0.050489  [    0/71297]
loss: 0.196767  [ 6400/71297]
loss: 0.145311  [12800/71297]
loss: 0.042670  [19200/71297]
loss: 0.132013  [25600/71297]
loss: 0.187711  [32000/71297]
loss: 0.039780  [38400/71297]
loss: 0.101641  [44800/71297]
loss: 0.110393  [51200/71297]
loss: 0.110746  [57600/71297]
loss: 0.040110  [64000/71297]
loss: 0.039688  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.088332 

Epoch 8
-------------------------------
loss: 0.037703  [    0/71297]
loss: 0.146492  [ 6400/71297]
loss: 0.065374  [12800/71297]
loss: 0.038462  [19200/71297]
loss: 0.034134  [25600/71297]
loss: 0.041135  [32000/71297]
loss: 0.189811  [38400/71297]
loss: 0.056834  [44800/71297]
loss: 0.105516  [51200/71297]
loss: 0.103450  [57600/71297]
loss: 0.029004  [64000/71297]
loss: 0.008089  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.086896 

Epoch 9
-------------------------------
loss: 0.060102  [    0/71297]
loss: 0.098909  [ 6400/71297]
loss: 0.036231  [12800/71297]
loss: 0.035076  [19200/71297]
loss: 0.094414  [25600/71297]
loss: 0.020412  [32000/71297]
loss: 0.042446  [38400/71297]
loss: 0.032848  [44800/71297]
loss: 0.128230  [51200/71297]
loss: 0.081303  [57600/71297]
loss: 0.043226  [64000/71297]
loss: 0.120142  [70400/71297]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.089452 

Epoch 10
-------------------------------
loss: 0.051561  [    0/71297]
loss: 0.077289  [ 6400/71297]
loss: 0.020421  [12800/71297]
loss: 0.019139  [19200/71297]
loss: 0.011902  [25600/71297]
loss: 0.062870  [32000/71297]
loss: 0.056265  [38400/71297]
loss: 0.024121  [44800/71297]
loss: 0.015101  [51200/71297]
loss: 0.112963  [57600/71297]
loss: 0.076692  [64000/71297]
loss: 0.058578  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.085043 

Epoch 11
-------------------------------
loss: 0.042939  [    0/71297]
loss: 0.017046  [ 6400/71297]
loss: 0.025856  [12800/71297]
loss: 0.202800  [19200/71297]
loss: 0.019287  [25600/71297]
loss: 1.704322  [32000/71297]
loss: 0.092657  [38400/71297]
loss: 0.017706  [44800/71297]
loss: 0.152466  [51200/71297]
loss: 0.077104  [57600/71297]
loss: 0.213447  [64000/71297]
loss: 0.038796  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.087713 

Epoch 12
-------------------------------
loss: 0.052288  [    0/71297]
loss: 0.028765  [ 6400/71297]
loss: 0.087191  [12800/71297]
loss: 0.071648  [19200/71297]
loss: 0.063456  [25600/71297]
loss: 0.021829  [32000/71297]
loss: 0.063337  [38400/71297]
loss: 0.163081  [44800/71297]
loss: 0.073489  [51200/71297]
loss: 0.032023  [57600/71297]
loss: 0.042288  [64000/71297]
loss: 0.196099  [70400/71297]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.166641 

Epoch 13
-------------------------------
loss: 0.191290  [    0/71297]
loss: 0.056755  [ 6400/71297]
loss: 0.012596  [12800/71297]
loss: 0.028345  [19200/71297]
loss: 0.011274  [25600/71297]
loss: 0.111528  [32000/71297]
loss: 0.016456  [38400/71297]
loss: 0.042298  [44800/71297]
loss: 0.077808  [51200/71297]
loss: 0.143248  [57600/71297]
loss: 0.085348  [64000/71297]
loss: 0.011464  [70400/71297]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.082909 

Epoch 14
-------------------------------
loss: 0.051062  [    0/71297]
loss: 0.036360  [ 6400/71297]
loss: 0.032690  [12800/71297]
loss: 0.055372  [19200/71297]
loss: 0.026727  [25600/71297]
loss: 0.203303  [32000/71297]
loss: 0.021504  [38400/71297]
loss: 0.098016  [44800/71297]
loss: 0.094130  [51200/71297]
loss: 0.141491  [57600/71297]
loss: 0.091569  [64000/71297]
loss: 0.051771  [70400/71297]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.082141 

Epoch 15
-------------------------------
loss: 0.092453  [    0/71297]
loss: 0.022493  [ 6400/71297]
loss: 0.046131  [12800/71297]
loss: 0.094366  [19200/71297]
loss: 0.024707  [25600/71297]
loss: 0.037410  [32000/71297]
loss: 0.075981  [38400/71297]
loss: 0.029804  [44800/71297]
loss: 0.071940  [51200/71297]
loss: 0.313964  [57600/71297]
loss: 0.101553  [64000/71297]
loss: 0.170593  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.081710 

Epoch 16
-------------------------------
loss: 0.089859  [    0/71297]
loss: 0.033597  [ 6400/71297]
loss: 0.006024  [12800/71297]
loss: 0.024353  [19200/71297]
loss: 0.037706  [25600/71297]
loss: 0.007406  [32000/71297]
loss: 0.008724  [38400/71297]
loss: 0.092106  [44800/71297]
loss: 0.074890  [51200/71297]
loss: 0.052796  [57600/71297]
loss: 0.017972  [64000/71297]
loss: 0.068638  [70400/71297]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.085268 

Epoch 17
-------------------------------
loss: 0.042798  [    0/71297]
loss: 0.017990  [ 6400/71297]
loss: 0.191461  [12800/71297]
loss: 0.049236  [19200/71297]
loss: 0.049451  [25600/71297]
loss: 0.037975  [32000/71297]
loss: 0.075697  [38400/71297]
loss: 0.180590  [44800/71297]
loss: 0.041677  [51200/71297]
loss: 0.073329  [57600/71297]
loss: 0.071929  [64000/71297]
loss: 0.015743  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.086405 

Epoch 18
-------------------------------
loss: 0.048869  [    0/71297]
loss: 0.041526  [ 6400/71297]
loss: 0.028558  [12800/71297]
loss: 0.040017  [19200/71297]
loss: 0.052308  [25600/71297]
loss: 0.055351  [32000/71297]
loss: 0.125715  [38400/71297]
loss: 0.018567  [44800/71297]
loss: 0.152149  [51200/71297]
loss: 0.018300  [57600/71297]
loss: 0.084714  [64000/71297]
loss: 0.051298  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.098319 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.785343  [    0/71124]
loss: 0.219830  [ 6400/71124]
loss: 0.108500  [12800/71124]
loss: 0.112836  [19200/71124]
loss: 0.173478  [25600/71124]
loss: 0.147623  [32000/71124]
loss: 0.065443  [38400/71124]
loss: 0.154856  [44800/71124]
loss: 1.636752  [51200/71124]
loss: 0.148407  [57600/71124]
loss: 0.110570  [64000/71124]
loss: 0.031541  [70400/71124]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.165680 

Epoch 2
-------------------------------
loss: 0.063623  [    0/71124]
loss: 0.308712  [ 6400/71124]
loss: 0.181421  [12800/71124]
loss: 0.036691  [19200/71124]
loss: 0.149266  [25600/71124]
loss: 0.169806  [32000/71124]
loss: 0.075798  [38400/71124]
loss: 0.083833  [44800/71124]
loss: 0.103326  [51200/71124]
loss: 0.169606  [57600/71124]
loss: 0.103496  [64000/71124]
loss: 0.082146  [70400/71124]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.156474 

Epoch 3
-------------------------------
loss: 0.116980  [    0/71124]
loss: 0.260379  [ 6400/71124]
loss: 0.110255  [12800/71124]
loss: 0.064863  [19200/71124]
loss: 0.084787  [25600/71124]
loss: 0.077520  [32000/71124]
loss: 1.642183  [38400/71124]
loss: 0.068023  [44800/71124]
loss: 0.040135  [51200/71124]
loss: 0.120367  [57600/71124]
loss: 0.074452  [64000/71124]
loss: 0.082179  [70400/71124]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.146413 

Epoch 4
-------------------------------
loss: 0.287284  [    0/71124]
loss: 0.106694  [ 6400/71124]
loss: 0.119191  [12800/71124]
loss: 0.096878  [19200/71124]
loss: 0.125286  [25600/71124]
loss: 0.101790  [32000/71124]
loss: 0.174156  [38400/71124]
loss: 0.045519  [44800/71124]
loss: 0.039457  [51200/71124]
loss: 0.063686  [57600/71124]
loss: 0.060698  [64000/71124]
loss: 0.043016  [70400/71124]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.148659 

Epoch 5
-------------------------------
loss: 0.067671  [    0/71124]
loss: 0.090662  [ 6400/71124]
loss: 0.123234  [12800/71124]
loss: 0.060584  [19200/71124]
loss: 0.094543  [25600/71124]
loss: 0.041583  [32000/71124]
loss: 0.070167  [38400/71124]
loss: 0.127290  [44800/71124]
loss: 0.140237  [51200/71124]
loss: 0.060321  [57600/71124]
loss: 0.187741  [64000/71124]
loss: 0.133462  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.139470 

Epoch 6
-------------------------------
loss: 1.638461  [    0/71124]
loss: 0.049541  [ 6400/71124]
loss: 0.074274  [12800/71124]
loss: 0.092411  [19200/71124]
loss: 0.107456  [25600/71124]
loss: 0.045754  [32000/71124]
loss: 0.227208  [38400/71124]
loss: 0.073591  [44800/71124]
loss: 0.215474  [51200/71124]
loss: 0.164452  [57600/71124]
loss: 0.154336  [64000/71124]
loss: 0.180380  [70400/71124]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.142076 

Epoch 7
-------------------------------
loss: 1.689798  [    0/71124]
loss: 0.055294  [ 6400/71124]
loss: 0.072986  [12800/71124]
loss: 0.127273  [19200/71124]
loss: 0.115186  [25600/71124]
loss: 0.042539  [32000/71124]
loss: 0.067658  [38400/71124]
loss: 1.625983  [44800/71124]
loss: 0.123296  [51200/71124]
loss: 0.122610  [57600/71124]
loss: 1.625377  [64000/71124]
loss: 0.123051  [70400/71124]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.136430 

Epoch 8
-------------------------------
loss: 0.053598  [    0/71124]
loss: 0.053265  [ 6400/71124]
loss: 0.152979  [12800/71124]
loss: 0.021217  [19200/71124]
loss: 0.079661  [25600/71124]
loss: 0.085002  [32000/71124]
loss: 0.061325  [38400/71124]
loss: 0.092843  [44800/71124]
loss: 0.030940  [51200/71124]
loss: 0.081412  [57600/71124]
loss: 0.042128  [64000/71124]
loss: 1.619111  [70400/71124]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.138459 

Epoch 9
-------------------------------
loss: 0.200415  [    0/71124]
loss: 0.033822  [ 6400/71124]
loss: 0.035340  [12800/71124]
loss: 0.093988  [19200/71124]
loss: 0.090443  [25600/71124]
loss: 0.093601  [32000/71124]
loss: 1.609002  [38400/71124]
loss: 0.081969  [44800/71124]
loss: 0.044738  [51200/71124]
loss: 0.068821  [57600/71124]
loss: 0.100993  [64000/71124]
loss: 0.152562  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.142848 

Epoch 10
-------------------------------
loss: 1.616229  [    0/71124]
loss: 0.021856  [ 6400/71124]
loss: 0.090424  [12800/71124]
loss: 0.134645  [19200/71124]
loss: 0.055709  [25600/71124]
loss: 0.039923  [32000/71124]
loss: 0.050187  [38400/71124]
loss: 0.098243  [44800/71124]
loss: 0.052574  [51200/71124]
loss: 0.043175  [57600/71124]
loss: 0.083300  [64000/71124]
loss: 0.231793  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.134372 

Epoch 11
-------------------------------
loss: 0.089292  [    0/71124]
loss: 0.087429  [ 6400/71124]
loss: 0.093405  [12800/71124]
loss: 0.055436  [19200/71124]
loss: 0.059981  [25600/71124]
loss: 0.083564  [32000/71124]
loss: 0.102352  [38400/71124]
loss: 0.073095  [44800/71124]
loss: 0.019798  [51200/71124]
loss: 0.180105  [57600/71124]
loss: 0.021015  [64000/71124]
loss: 0.115269  [70400/71124]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.134047 

Epoch 12
-------------------------------
loss: 0.036005  [    0/71124]
loss: 0.046842  [ 6400/71124]
loss: 0.100100  [12800/71124]
loss: 0.057493  [19200/71124]
loss: 0.095094  [25600/71124]
loss: 0.061346  [32000/71124]
loss: 1.633847  [38400/71124]
loss: 0.053632  [44800/71124]
loss: 0.124003  [51200/71124]
loss: 0.061511  [57600/71124]
loss: 0.141322  [64000/71124]
loss: 0.193277  [70400/71124]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.136573 

Epoch 13
-------------------------------
loss: 0.062996  [    0/71124]
loss: 0.109675  [ 6400/71124]
loss: 0.041359  [12800/71124]
loss: 0.022598  [19200/71124]
loss: 0.104222  [25600/71124]
loss: 1.664396  [32000/71124]
loss: 0.078141  [38400/71124]
loss: 0.034139  [44800/71124]
loss: 0.032688  [51200/71124]
loss: 0.080324  [57600/71124]
loss: 0.071867  [64000/71124]
loss: 1.642312  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.134741 

Epoch 14
-------------------------------
loss: 0.196453  [    0/71124]
loss: 0.059912  [ 6400/71124]
loss: 0.080102  [12800/71124]
loss: 0.044842  [19200/71124]
loss: 0.089775  [25600/71124]
loss: 0.072797  [32000/71124]
loss: 0.037357  [38400/71124]
loss: 0.146709  [44800/71124]
loss: 0.077442  [51200/71124]
loss: 0.040056  [57600/71124]
loss: 0.056550  [64000/71124]
loss: 0.051188  [70400/71124]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.137196 

Epoch 15
-------------------------------
loss: 0.041328  [    0/71124]
loss: 0.066674  [ 6400/71124]
loss: 0.119106  [12800/71124]
loss: 0.123308  [19200/71124]
loss: 0.020862  [25600/71124]
loss: 0.026939  [32000/71124]
loss: 0.067091  [38400/71124]
loss: 0.073061  [44800/71124]
loss: 0.080654  [51200/71124]
loss: 0.090794  [57600/71124]
loss: 0.149139  [64000/71124]
loss: 0.041728  [70400/71124]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.141873 

Epoch 16
-------------------------------
loss: 0.098415  [    0/71124]
loss: 0.098942  [ 6400/71124]
loss: 0.047408  [12800/71124]
loss: 0.069752  [19200/71124]
loss: 0.070523  [25600/71124]
loss: 0.128955  [32000/71124]
loss: 0.086297  [38400/71124]
loss: 0.017179  [44800/71124]
loss: 0.072272  [51200/71124]
loss: 0.173617  [57600/71124]
loss: 0.048123  [64000/71124]
loss: 0.028462  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.136217 

Epoch 17
-------------------------------
loss: 0.068449  [    0/71124]
loss: 0.049113  [ 6400/71124]
loss: 0.067132  [12800/71124]
loss: 0.045884  [19200/71124]
loss: 0.041907  [25600/71124]
loss: 0.038863  [32000/71124]
loss: 0.040858  [38400/71124]
loss: 0.051620  [44800/71124]
loss: 0.078874  [51200/71124]
loss: 0.027303  [57600/71124]
loss: 0.049394  [64000/71124]
loss: 0.073127  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.138257 

Epoch 18
-------------------------------
loss: 0.033026  [    0/71124]
loss: 0.085221  [ 6400/71124]
loss: 0.054438  [12800/71124]
loss: 0.034216  [19200/71124]
loss: 0.063521  [25600/71124]
loss: 0.109559  [32000/71124]
loss: 0.084866  [38400/71124]
loss: 0.069078  [44800/71124]
loss: 0.039643  [51200/71124]
loss: 1.615832  [57600/71124]
loss: 0.048386  [64000/71124]
loss: 0.043841  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.133217 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.871292  [    0/71639]
loss: 0.294743  [ 6400/71639]
loss: 0.217887  [12800/71639]
loss: 0.075984  [19200/71639]
loss: 0.078994  [25600/71639]
loss: 0.159906  [32000/71639]
loss: 0.113137  [38400/71639]
loss: 0.139591  [44800/71639]
loss: 0.123481  [51200/71639]
loss: 0.095578  [57600/71639]
loss: 0.072282  [64000/71639]
loss: 1.737541  [70400/71639]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.236787 

Epoch 2
-------------------------------
loss: 0.055032  [    0/71639]
loss: 0.234001  [ 6400/71639]
loss: 0.085730  [12800/71639]
loss: 0.094360  [19200/71639]
loss: 0.054222  [25600/71639]
loss: 0.155574  [32000/71639]
loss: 0.112301  [38400/71639]
loss: 0.142566  [44800/71639]
loss: 0.059940  [51200/71639]
loss: 0.169370  [57600/71639]
loss: 0.122240  [64000/71639]
loss: 0.076252  [70400/71639]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.216109 

Epoch 3
-------------------------------
loss: 0.105145  [    0/71639]
loss: 0.125864  [ 6400/71639]
loss: 0.064843  [12800/71639]
loss: 0.055449  [19200/71639]
loss: 0.110847  [25600/71639]
loss: 0.053369  [32000/71639]
loss: 0.039538  [38400/71639]
loss: 0.118083  [44800/71639]
loss: 0.086630  [51200/71639]
loss: 0.121896  [57600/71639]
loss: 0.034360  [64000/71639]
loss: 0.079539  [70400/71639]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.210358 

Epoch 4
-------------------------------
loss: 0.075221  [    0/71639]
loss: 0.053048  [ 6400/71639]
loss: 0.041478  [12800/71639]
loss: 0.060283  [19200/71639]
loss: 0.065024  [25600/71639]
loss: 0.143866  [32000/71639]
loss: 0.055269  [38400/71639]
loss: 0.045954  [44800/71639]
loss: 0.059606  [51200/71639]
loss: 0.072916  [57600/71639]
loss: 0.053388  [64000/71639]
loss: 0.078758  [70400/71639]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.211260 

Epoch 5
-------------------------------
loss: 0.153403  [    0/71639]
loss: 0.029537  [ 6400/71639]
loss: 0.185082  [12800/71639]
loss: 0.023277  [19200/71639]
loss: 0.066267  [25600/71639]
loss: 0.122662  [32000/71639]
loss: 0.037517  [38400/71639]
loss: 0.096959  [44800/71639]
loss: 0.098665  [51200/71639]
loss: 0.093950  [57600/71639]
loss: 0.065614  [64000/71639]
loss: 0.028764  [70400/71639]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.207857 

Epoch 6
-------------------------------
loss: 0.059984  [    0/71639]
loss: 0.031873  [ 6400/71639]
loss: 0.025900  [12800/71639]
loss: 0.240527  [19200/71639]
loss: 0.099200  [25600/71639]
loss: 0.041993  [32000/71639]
loss: 0.142086  [38400/71639]
loss: 0.103503  [44800/71639]
loss: 0.105395  [51200/71639]
loss: 0.066103  [57600/71639]
loss: 0.053745  [64000/71639]
loss: 1.616068  [70400/71639]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.203420 

Epoch 7
-------------------------------
loss: 0.052915  [    0/71639]
loss: 1.649708  [ 6400/71639]
loss: 0.151460  [12800/71639]
loss: 0.046431  [19200/71639]
loss: 0.035831  [25600/71639]
loss: 0.029201  [32000/71639]
loss: 0.109719  [38400/71639]
loss: 0.093980  [44800/71639]
loss: 0.111278  [51200/71639]
loss: 0.068455  [57600/71639]
loss: 0.054420  [64000/71639]
loss: 0.066101  [70400/71639]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.199586 

Epoch 8
-------------------------------
loss: 0.056692  [    0/71639]
loss: 0.044104  [ 6400/71639]
loss: 0.042837  [12800/71639]
loss: 0.126748  [19200/71639]
loss: 0.146985  [25600/71639]
loss: 0.042331  [32000/71639]
loss: 0.100835  [38400/71639]
loss: 0.099969  [44800/71639]
loss: 0.037573  [51200/71639]
loss: 0.125894  [57600/71639]
loss: 0.014264  [64000/71639]
loss: 0.031779  [70400/71639]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.209798 

Epoch 9
-------------------------------
loss: 0.120568  [    0/71639]
loss: 1.646606  [ 6400/71639]
loss: 0.031428  [12800/71639]
loss: 1.608526  [19200/71639]
loss: 0.023226  [25600/71639]
loss: 0.060943  [32000/71639]
loss: 1.593091  [38400/71639]
loss: 0.089185  [44800/71639]
loss: 0.122738  [51200/71639]
loss: 0.062440  [57600/71639]
loss: 0.028475  [64000/71639]
loss: 0.125049  [70400/71639]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.200845 

Epoch 10
-------------------------------
loss: 0.080478  [    0/71639]
loss: 0.152604  [ 6400/71639]
loss: 0.024126  [12800/71639]
loss: 0.103747  [19200/71639]
loss: 0.057698  [25600/71639]
loss: 0.108020  [32000/71639]
loss: 1.656047  [38400/71639]
loss: 0.084977  [44800/71639]
loss: 0.039880  [51200/71639]
loss: 0.041171  [57600/71639]
loss: 0.142128  [64000/71639]
loss: 0.015311  [70400/71639]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.196712 

Epoch 11
-------------------------------
loss: 0.041264  [    0/71639]
loss: 0.019240  [ 6400/71639]
loss: 0.093425  [12800/71639]
loss: 0.053653  [19200/71639]
loss: 0.060387  [25600/71639]
loss: 0.048841  [32000/71639]
loss: 0.065353  [38400/71639]
loss: 0.140877  [44800/71639]
loss: 0.060982  [51200/71639]
loss: 0.028020  [57600/71639]
loss: 0.060116  [64000/71639]
loss: 0.053741  [70400/71639]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.200288 

Epoch 12
-------------------------------
loss: 0.033652  [    0/71639]
loss: 0.115585  [ 6400/71639]
loss: 0.090644  [12800/71639]
loss: 0.036264  [19200/71639]
loss: 0.115434  [25600/71639]
loss: 0.026625  [32000/71639]
loss: 0.024671  [38400/71639]
loss: 0.093302  [44800/71639]
loss: 1.649004  [51200/71639]
loss: 0.047480  [57600/71639]
loss: 0.110972  [64000/71639]
loss: 0.047980  [70400/71639]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.199660 

Epoch 13
-------------------------------
loss: 0.041170  [    0/71639]
loss: 0.165448  [ 6400/71639]
loss: 0.058713  [12800/71639]
loss: 0.054007  [19200/71639]
loss: 0.079324  [25600/71639]
loss: 0.139030  [32000/71639]
loss: 0.049679  [38400/71639]
loss: 0.045873  [44800/71639]
loss: 0.116461  [51200/71639]
loss: 0.191561  [57600/71639]
loss: 0.060387  [64000/71639]
loss: 0.084383  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.209945 

Epoch 14
-------------------------------
loss: 0.061623  [    0/71639]
loss: 0.066557  [ 6400/71639]
loss: 0.018280  [12800/71639]
loss: 0.037897  [19200/71639]
loss: 0.250077  [25600/71639]
loss: 1.655042  [32000/71639]
loss: 0.104037  [38400/71639]
loss: 0.089174  [44800/71639]
loss: 0.083322  [51200/71639]
loss: 0.111972  [57600/71639]
loss: 0.149332  [64000/71639]
loss: 0.051444  [70400/71639]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.198472 

Epoch 15
-------------------------------
loss: 0.116640  [    0/71639]
loss: 0.063635  [ 6400/71639]
loss: 0.165651  [12800/71639]
loss: 0.054429  [19200/71639]
loss: 0.044216  [25600/71639]
loss: 0.062170  [32000/71639]
loss: 0.015644  [38400/71639]
loss: 0.040141  [44800/71639]
loss: 0.043937  [51200/71639]
loss: 0.028142  [57600/71639]
loss: 0.046960  [64000/71639]
loss: 0.012613  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.203812 

Epoch 16
-------------------------------
loss: 0.058520  [    0/71639]
loss: 0.068526  [ 6400/71639]
loss: 0.027025  [12800/71639]
loss: 0.046447  [19200/71639]
loss: 0.061324  [25600/71639]
loss: 0.093550  [32000/71639]
loss: 0.089796  [38400/71639]
loss: 0.035163  [44800/71639]
loss: 0.092629  [51200/71639]
loss: 0.043726  [57600/71639]
loss: 0.055975  [64000/71639]
loss: 0.025796  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.197639 

Epoch 17
-------------------------------
loss: 1.609752  [    0/71639]
loss: 0.164234  [ 6400/71639]
loss: 0.021609  [12800/71639]
loss: 0.020424  [19200/71639]
loss: 0.087628  [25600/71639]
loss: 0.046364  [32000/71639]
loss: 0.075904  [38400/71639]
loss: 0.120561  [44800/71639]
loss: 0.128419  [51200/71639]
loss: 0.077003  [57600/71639]
loss: 0.075197  [64000/71639]
loss: 0.084314  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.201478 

Epoch 18
-------------------------------
loss: 0.018511  [    0/71639]
loss: 0.068895  [ 6400/71639]
loss: 0.034751  [12800/71639]
loss: 0.040711  [19200/71639]
loss: 0.103414  [25600/71639]
loss: 0.031132  [32000/71639]
loss: 0.077174  [38400/71639]
loss: 0.048755  [44800/71639]
loss: 0.053926  [51200/71639]
loss: 0.040076  [57600/71639]
loss: 0.063799  [64000/71639]
loss: 0.036182  [70400/71639]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.198277 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.767738  [    0/70535]
loss: 0.332689  [ 6400/70535]
loss: 0.181150  [12800/70535]
loss: 0.122698  [19200/70535]
loss: 0.161360  [25600/70535]
loss: 0.115007  [32000/70535]
loss: 0.145646  [38400/70535]
loss: 0.116823  [44800/70535]
loss: 0.112574  [51200/70535]
loss: 0.097811  [57600/70535]
loss: 0.103118  [64000/70535]
loss: 0.123572  [70400/70535]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.148956 

Epoch 2
-------------------------------
loss: 0.068553  [    0/70535]
loss: 0.129832  [ 6400/70535]
loss: 0.112820  [12800/70535]
loss: 0.187078  [19200/70535]
loss: 0.108376  [25600/70535]
loss: 0.163716  [32000/70535]
loss: 0.056946  [38400/70535]
loss: 0.180947  [44800/70535]
loss: 0.063499  [51200/70535]
loss: 0.172555  [57600/70535]
loss: 0.247910  [64000/70535]
loss: 0.144352  [70400/70535]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.139252 

Epoch 3
-------------------------------
loss: 0.144928  [    0/70535]
loss: 0.056445  [ 6400/70535]
loss: 0.130631  [12800/70535]
loss: 0.067467  [19200/70535]
loss: 0.069948  [25600/70535]
loss: 0.145925  [32000/70535]
loss: 0.078320  [38400/70535]
loss: 0.110104  [44800/70535]
loss: 0.158210  [51200/70535]
loss: 0.075669  [57600/70535]
loss: 0.193997  [64000/70535]
loss: 0.087760  [70400/70535]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.119822 

Epoch 4
-------------------------------
loss: 0.141804  [    0/70535]
loss: 0.066765  [ 6400/70535]
loss: 0.171723  [12800/70535]
loss: 0.197078  [19200/70535]
loss: 0.098393  [25600/70535]
loss: 0.044619  [32000/70535]
loss: 0.140623  [38400/70535]
loss: 0.071289  [44800/70535]
loss: 0.132351  [51200/70535]
loss: 0.050099  [57600/70535]
loss: 0.052007  [64000/70535]
loss: 0.034287  [70400/70535]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.120934 

Epoch 5
-------------------------------
loss: 0.071453  [    0/70535]
loss: 0.095005  [ 6400/70535]
loss: 0.059130  [12800/70535]
loss: 0.052795  [19200/70535]
loss: 0.124859  [25600/70535]
loss: 0.148232  [32000/70535]
loss: 0.073359  [38400/70535]
loss: 0.129269  [44800/70535]
loss: 0.043871  [51200/70535]
loss: 0.077318  [57600/70535]
loss: 0.126152  [64000/70535]
loss: 0.091497  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.113656 

Epoch 6
-------------------------------
loss: 0.044767  [    0/70535]
loss: 0.060708  [ 6400/70535]
loss: 0.117196  [12800/70535]
loss: 0.048731  [19200/70535]
loss: 0.071489  [25600/70535]
loss: 0.056595  [32000/70535]
loss: 0.108269  [38400/70535]
loss: 0.133212  [44800/70535]
loss: 0.058601  [51200/70535]
loss: 0.051723  [57600/70535]
loss: 0.063472  [64000/70535]
loss: 0.043178  [70400/70535]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.121099 

Epoch 7
-------------------------------
loss: 0.014170  [    0/70535]
loss: 0.122519  [ 6400/70535]
loss: 0.101554  [12800/70535]
loss: 0.106055  [19200/70535]
loss: 0.115967  [25600/70535]
loss: 0.062799  [32000/70535]
loss: 0.114742  [38400/70535]
loss: 0.050312  [44800/70535]
loss: 0.077566  [51200/70535]
loss: 0.209561  [57600/70535]
loss: 0.047409  [64000/70535]
loss: 0.073299  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.112826 

Epoch 8
-------------------------------
loss: 0.080278  [    0/70535]
loss: 0.196397  [ 6400/70535]
loss: 0.104402  [12800/70535]
loss: 0.157293  [19200/70535]
loss: 0.182236  [25600/70535]
loss: 0.118519  [32000/70535]
loss: 0.054173  [38400/70535]
loss: 0.079928  [44800/70535]
loss: 0.048551  [51200/70535]
loss: 0.020952  [57600/70535]
loss: 0.134675  [64000/70535]
loss: 0.075960  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.114622 

Epoch 9
-------------------------------
loss: 0.076931  [    0/70535]
loss: 0.108386  [ 6400/70535]
loss: 0.114639  [12800/70535]
loss: 0.074403  [19200/70535]
loss: 0.030472  [25600/70535]
loss: 0.043548  [32000/70535]
loss: 0.167054  [38400/70535]
loss: 0.126664  [44800/70535]
loss: 0.139068  [51200/70535]
loss: 0.074708  [57600/70535]
loss: 0.107649  [64000/70535]
loss: 0.062751  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.114229 

Epoch 10
-------------------------------
loss: 0.057420  [    0/70535]
loss: 0.027102  [ 6400/70535]
loss: 0.077481  [12800/70535]
loss: 1.648607  [19200/70535]
loss: 0.102359  [25600/70535]
loss: 0.099900  [32000/70535]
loss: 0.029549  [38400/70535]
loss: 0.191743  [44800/70535]
loss: 0.076282  [51200/70535]
loss: 0.181626  [57600/70535]
loss: 0.023115  [64000/70535]
loss: 0.069617  [70400/70535]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.116923 

Epoch 11
-------------------------------
loss: 0.065784  [    0/70535]
loss: 0.048411  [ 6400/70535]
loss: 0.023224  [12800/70535]
loss: 0.037902  [19200/70535]
loss: 0.019379  [25600/70535]
loss: 0.069865  [32000/70535]
loss: 0.066893  [38400/70535]
loss: 0.112366  [44800/70535]
loss: 0.126008  [51200/70535]
loss: 0.066445  [57600/70535]
loss: 0.106595  [64000/70535]
loss: 0.191766  [70400/70535]
Test Error: 
 Accuracy: 90.6%, Avg loss: 0.343938 

Epoch 12
-------------------------------
loss: 0.179948  [    0/70535]
loss: 0.035388  [ 6400/70535]
loss: 0.054036  [12800/70535]
loss: 0.146264  [19200/70535]
loss: 0.169489  [25600/70535]
loss: 0.162896  [32000/70535]
loss: 0.062377  [38400/70535]
loss: 0.112937  [44800/70535]
loss: 0.069200  [51200/70535]
loss: 0.073004  [57600/70535]
loss: 0.045479  [64000/70535]
loss: 0.072164  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.116154 

Epoch 13
-------------------------------
loss: 0.036825  [    0/70535]
loss: 0.066631  [ 6400/70535]
loss: 0.101118  [12800/70535]
loss: 0.061239  [19200/70535]
loss: 0.060666  [25600/70535]
loss: 0.069989  [32000/70535]
loss: 0.140743  [38400/70535]
loss: 0.123343  [44800/70535]
loss: 0.093505  [51200/70535]
loss: 0.047809  [57600/70535]
loss: 0.127690  [64000/70535]
loss: 0.116144  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.115816 

Epoch 14
-------------------------------
loss: 0.208225  [    0/70535]
loss: 0.103856  [ 6400/70535]
loss: 0.137087  [12800/70535]
loss: 0.074972  [19200/70535]
loss: 0.027584  [25600/70535]
loss: 0.102493  [32000/70535]
loss: 0.078432  [38400/70535]
loss: 0.025900  [44800/70535]
loss: 0.122710  [51200/70535]
loss: 0.069260  [57600/70535]
loss: 0.030340  [64000/70535]
loss: 0.032403  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.112805 

Epoch 15
-------------------------------
loss: 0.018798  [    0/70535]
loss: 0.091465  [ 6400/70535]
loss: 0.251554  [12800/70535]
loss: 0.060303  [19200/70535]
loss: 0.082696  [25600/70535]
loss: 0.097837  [32000/70535]
loss: 0.028999  [38400/70535]
loss: 0.239116  [44800/70535]
loss: 0.080332  [51200/70535]
loss: 0.161171  [57600/70535]
loss: 0.020732  [64000/70535]
loss: 0.129323  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.109328 

Epoch 16
-------------------------------
loss: 0.062039  [    0/70535]
loss: 0.128655  [ 6400/70535]
loss: 0.076609  [12800/70535]
loss: 0.125911  [19200/70535]
loss: 0.067801  [25600/70535]
loss: 0.070425  [32000/70535]
loss: 0.126334  [38400/70535]
loss: 0.067690  [44800/70535]
loss: 0.114325  [51200/70535]
loss: 0.106730  [57600/70535]
loss: 0.020820  [64000/70535]
loss: 0.124914  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.106963 

Epoch 17
-------------------------------
loss: 0.098302  [    0/70535]
loss: 0.079757  [ 6400/70535]
loss: 0.037051  [12800/70535]
loss: 0.075639  [19200/70535]
loss: 0.085823  [25600/70535]
loss: 0.103134  [32000/70535]
loss: 0.135728  [38400/70535]
loss: 0.059414  [44800/70535]
loss: 0.119440  [51200/70535]
loss: 0.075996  [57600/70535]
loss: 0.063666  [64000/70535]
loss: 0.218710  [70400/70535]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.124055 

Epoch 18
-------------------------------
loss: 0.108659  [    0/70535]
loss: 0.063205  [ 6400/70535]
loss: 0.090284  [12800/70535]
loss: 0.043570  [19200/70535]
loss: 0.193221  [25600/70535]
loss: 0.068987  [32000/70535]
loss: 0.200204  [38400/70535]
loss: 0.098691  [44800/70535]
loss: 0.096852  [51200/70535]
loss: 0.139726  [57600/70535]
loss: 0.114280  [64000/70535]
loss: 0.026250  [70400/70535]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.211936 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.828754  [    0/71724]
loss: 0.076947  [ 6400/71724]
loss: 0.101692  [12800/71724]
loss: 0.087853  [19200/71724]
loss: 0.061546  [25600/71724]
loss: 0.083648  [32000/71724]
loss: 0.031437  [38400/71724]
loss: 0.073200  [44800/71724]
loss: 0.036026  [51200/71724]
loss: 0.093487  [57600/71724]
loss: 0.077825  [64000/71724]
loss: 0.022262  [70400/71724]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.063367 

Epoch 2
-------------------------------
loss: 0.059071  [    0/71724]
loss: 0.118400  [ 6400/71724]
loss: 0.178295  [12800/71724]
loss: 0.209433  [19200/71724]
loss: 0.081638  [25600/71724]
loss: 0.119490  [32000/71724]
loss: 0.050214  [38400/71724]
loss: 0.016519  [44800/71724]
loss: 0.043634  [51200/71724]
loss: 0.066787  [57600/71724]
loss: 0.051711  [64000/71724]
loss: 0.052913  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.053977 

Epoch 3
-------------------------------
loss: 0.056081  [    0/71724]
loss: 0.186392  [ 6400/71724]
loss: 0.100627  [12800/71724]
loss: 0.028437  [19200/71724]
loss: 0.171816  [25600/71724]
loss: 0.024465  [32000/71724]
loss: 0.045058  [38400/71724]
loss: 0.024144  [44800/71724]
loss: 0.141414  [51200/71724]
loss: 0.026752  [57600/71724]
loss: 0.022484  [64000/71724]
loss: 0.055279  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.054219 

Epoch 4
-------------------------------
loss: 0.016671  [    0/71724]
loss: 0.023430  [ 6400/71724]
loss: 0.052511  [12800/71724]
loss: 0.071733  [19200/71724]
loss: 0.087041  [25600/71724]
loss: 0.099007  [32000/71724]
loss: 0.048493  [38400/71724]
loss: 0.022467  [44800/71724]
loss: 0.080533  [51200/71724]
loss: 0.028187  [57600/71724]
loss: 0.147928  [64000/71724]
loss: 0.328592  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.051370 

Epoch 5
-------------------------------
loss: 0.043344  [    0/71724]
loss: 0.079044  [ 6400/71724]
loss: 0.096319  [12800/71724]
loss: 0.020320  [19200/71724]
loss: 0.094005  [25600/71724]
loss: 0.016304  [32000/71724]
loss: 0.011363  [38400/71724]
loss: 0.103385  [44800/71724]
loss: 0.034023  [51200/71724]
loss: 0.104394  [57600/71724]
loss: 0.031896  [64000/71724]
loss: 0.067967  [70400/71724]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.050787 

Epoch 6
-------------------------------
loss: 0.023691  [    0/71724]
loss: 0.024906  [ 6400/71724]
loss: 0.089854  [12800/71724]
loss: 0.090421  [19200/71724]
loss: 0.237892  [25600/71724]
loss: 0.056174  [32000/71724]
loss: 0.121359  [38400/71724]
loss: 0.092678  [44800/71724]
loss: 0.013705  [51200/71724]
loss: 0.032103  [57600/71724]
loss: 0.022873  [64000/71724]
loss: 0.036945  [70400/71724]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.048663 

Epoch 7
-------------------------------
loss: 0.085547  [    0/71724]
loss: 0.116490  [ 6400/71724]
loss: 0.076840  [12800/71724]
loss: 0.060819  [19200/71724]
loss: 0.095565  [25600/71724]
loss: 0.009358  [32000/71724]
loss: 0.015155  [38400/71724]
loss: 0.049937  [44800/71724]
loss: 0.014312  [51200/71724]
loss: 0.038778  [57600/71724]
loss: 0.067352  [64000/71724]
loss: 0.071469  [70400/71724]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.051315 

Epoch 8
-------------------------------
loss: 0.080906  [    0/71724]
loss: 0.098471  [ 6400/71724]
loss: 0.120246  [12800/71724]
loss: 0.111093  [19200/71724]
loss: 0.043228  [25600/71724]
loss: 0.018997  [32000/71724]
loss: 0.056365  [38400/71724]
loss: 0.055454  [44800/71724]
loss: 0.064319  [51200/71724]
loss: 0.029271  [57600/71724]
loss: 0.040348  [64000/71724]
loss: 0.170354  [70400/71724]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.049552 

Epoch 9
-------------------------------
loss: 0.069144  [    0/71724]
loss: 0.027590  [ 6400/71724]
loss: 0.033188  [12800/71724]
loss: 0.024668  [19200/71724]
loss: 0.007517  [25600/71724]
loss: 0.078946  [32000/71724]
loss: 0.036730  [38400/71724]
loss: 0.013245  [44800/71724]
loss: 0.032461  [51200/71724]
loss: 0.121148  [57600/71724]
loss: 0.040932  [64000/71724]
loss: 0.011408  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.052131 

Epoch 10
-------------------------------
loss: 0.014000  [    0/71724]
loss: 0.105130  [ 6400/71724]
loss: 0.039874  [12800/71724]
loss: 0.016651  [19200/71724]
loss: 0.058591  [25600/71724]
loss: 0.085952  [32000/71724]
loss: 0.096566  [38400/71724]
loss: 0.021491  [44800/71724]
loss: 0.103723  [51200/71724]
loss: 0.034193  [57600/71724]
loss: 0.060096  [64000/71724]
loss: 0.111389  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.052118 

Epoch 11
-------------------------------
loss: 0.007246  [    0/71724]
loss: 0.006362  [ 6400/71724]
loss: 0.065697  [12800/71724]
loss: 0.012753  [19200/71724]
loss: 0.019964  [25600/71724]
loss: 0.010333  [32000/71724]
loss: 0.018336  [38400/71724]
loss: 0.023668  [44800/71724]
loss: 0.107998  [51200/71724]
loss: 0.058464  [57600/71724]
loss: 0.080710  [64000/71724]
loss: 0.040977  [70400/71724]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.049835 

Epoch 12
-------------------------------
loss: 0.008319  [    0/71724]
loss: 0.033774  [ 6400/71724]
loss: 0.017017  [12800/71724]
loss: 0.037249  [19200/71724]
loss: 0.011344  [25600/71724]
loss: 0.012622  [32000/71724]
loss: 0.064313  [38400/71724]
loss: 0.038918  [44800/71724]
loss: 0.055010  [51200/71724]
loss: 0.093542  [57600/71724]
loss: 0.046944  [64000/71724]
loss: 0.121101  [70400/71724]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.050746 

Epoch 13
-------------------------------
loss: 0.086939  [    0/71724]
loss: 0.046029  [ 6400/71724]
loss: 0.016404  [12800/71724]
loss: 0.038148  [19200/71724]
loss: 0.072747  [25600/71724]
loss: 0.011063  [32000/71724]
loss: 0.015183  [38400/71724]
loss: 0.093936  [44800/71724]
loss: 0.047874  [51200/71724]
loss: 0.114187  [57600/71724]
loss: 0.017437  [64000/71724]
loss: 0.151450  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.052507 

Epoch 14
-------------------------------
loss: 0.073425  [    0/71724]
loss: 0.097024  [ 6400/71724]
loss: 0.045358  [12800/71724]
loss: 0.045839  [19200/71724]
loss: 0.053736  [25600/71724]
loss: 0.021922  [32000/71724]
loss: 0.044801  [38400/71724]
loss: 0.023567  [44800/71724]
loss: 0.070854  [51200/71724]
loss: 0.034703  [57600/71724]
loss: 0.005252  [64000/71724]
loss: 0.118402  [70400/71724]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.052988 

Epoch 15
-------------------------------
loss: 0.035446  [    0/71724]
loss: 0.003178  [ 6400/71724]
loss: 0.040682  [12800/71724]
loss: 0.087612  [19200/71724]
loss: 0.013943  [25600/71724]
loss: 0.082641  [32000/71724]
loss: 0.028285  [38400/71724]
loss: 0.030590  [44800/71724]
loss: 0.049920  [51200/71724]
loss: 0.053738  [57600/71724]
loss: 0.028273  [64000/71724]
loss: 0.012857  [70400/71724]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.052399 

Epoch 16
-------------------------------
loss: 0.039669  [    0/71724]
loss: 0.028662  [ 6400/71724]
loss: 0.029669  [12800/71724]
loss: 0.011846  [19200/71724]
loss: 0.011488  [25600/71724]
loss: 0.011491  [32000/71724]
loss: 0.036545  [38400/71724]
loss: 0.053542  [44800/71724]
loss: 0.062317  [51200/71724]
loss: 0.033037  [57600/71724]
loss: 0.073502  [64000/71724]
loss: 0.055165  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.053351 

Epoch 17
-------------------------------
loss: 0.032716  [    0/71724]
loss: 0.056756  [ 6400/71724]
loss: 0.081211  [12800/71724]
loss: 0.051550  [19200/71724]
loss: 0.070575  [25600/71724]
loss: 0.025241  [32000/71724]
loss: 0.022391  [38400/71724]
loss: 0.021296  [44800/71724]
loss: 0.115220  [51200/71724]
loss: 0.082870  [57600/71724]
loss: 0.067222  [64000/71724]
loss: 0.022180  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.056849 

Epoch 18
-------------------------------
loss: 0.087729  [    0/71724]
loss: 0.056745  [ 6400/71724]
loss: 0.054418  [12800/71724]
loss: 0.048026  [19200/71724]
loss: 0.100427  [25600/71724]
loss: 0.127641  [32000/71724]
loss: 0.023184  [38400/71724]
loss: 0.042987  [44800/71724]
loss: 0.009798  [51200/71724]
loss: 0.105159  [57600/71724]
loss: 0.036610  [64000/71724]
loss: 0.041703  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.053621 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.799405  [    0/72202]
loss: 0.148428  [ 6400/72202]
loss: 0.105084  [12800/72202]
loss: 0.109370  [19200/72202]
loss: 0.107417  [25600/72202]
loss: 0.040851  [32000/72202]
loss: 0.034992  [38400/72202]
loss: 0.087768  [44800/72202]
loss: 0.020297  [51200/72202]
loss: 0.110177  [57600/72202]
loss: 0.060311  [64000/72202]
loss: 0.116497  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.082392 

Epoch 2
-------------------------------
loss: 0.053944  [    0/72202]
loss: 0.017810  [ 6400/72202]
loss: 0.055706  [12800/72202]
loss: 0.021237  [19200/72202]
loss: 0.166302  [25600/72202]
loss: 0.025721  [32000/72202]
loss: 0.147158  [38400/72202]
loss: 0.008695  [44800/72202]
loss: 0.062897  [51200/72202]
loss: 0.083376  [57600/72202]
loss: 0.077003  [64000/72202]
loss: 0.083389  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.075771 

Epoch 3
-------------------------------
loss: 0.021891  [    0/72202]
loss: 0.075749  [ 6400/72202]
loss: 0.102715  [12800/72202]
loss: 0.242199  [19200/72202]
loss: 0.013166  [25600/72202]
loss: 0.063926  [32000/72202]
loss: 0.011764  [38400/72202]
loss: 0.012993  [44800/72202]
loss: 0.068465  [51200/72202]
loss: 0.025006  [57600/72202]
loss: 0.446721  [64000/72202]
loss: 0.111563  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.076120 

Epoch 4
-------------------------------
loss: 0.085040  [    0/72202]
loss: 0.049707  [ 6400/72202]
loss: 0.014383  [12800/72202]
loss: 0.030017  [19200/72202]
loss: 0.015155  [25600/72202]
loss: 0.139784  [32000/72202]
loss: 0.069830  [38400/72202]
loss: 0.037421  [44800/72202]
loss: 0.061633  [51200/72202]
loss: 0.020830  [57600/72202]
loss: 0.031557  [64000/72202]
loss: 1.567970  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.076446 

Epoch 5
-------------------------------
loss: 0.089811  [    0/72202]
loss: 0.061002  [ 6400/72202]
loss: 0.020956  [12800/72202]
loss: 0.006976  [19200/72202]
loss: 0.090439  [25600/72202]
loss: 0.004528  [32000/72202]
loss: 0.097657  [38400/72202]
loss: 0.067407  [44800/72202]
loss: 0.003226  [51200/72202]
loss: 0.029857  [57600/72202]
loss: 0.080815  [64000/72202]
loss: 0.015722  [70400/72202]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.072785 

Epoch 6
-------------------------------
loss: 0.058869  [    0/72202]
loss: 0.011751  [ 6400/72202]
loss: 0.055822  [12800/72202]
loss: 0.012245  [19200/72202]
loss: 0.004796  [25600/72202]
loss: 0.004707  [32000/72202]
loss: 0.026291  [38400/72202]
loss: 0.026344  [44800/72202]
loss: 0.038103  [51200/72202]
loss: 0.024977  [57600/72202]
loss: 0.007224  [64000/72202]
loss: 0.006087  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.075501 

Epoch 7
-------------------------------
loss: 0.026300  [    0/72202]
loss: 0.016393  [ 6400/72202]
loss: 0.010774  [12800/72202]
loss: 1.565812  [19200/72202]
loss: 0.060098  [25600/72202]
loss: 0.030163  [32000/72202]
loss: 0.010386  [38400/72202]
loss: 0.053996  [44800/72202]
loss: 0.030076  [51200/72202]
loss: 0.044542  [57600/72202]
loss: 0.012692  [64000/72202]
loss: 0.024241  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.074384 

Epoch 8
-------------------------------
loss: 0.045557  [    0/72202]
loss: 0.018528  [ 6400/72202]
loss: 0.036997  [12800/72202]
loss: 0.039010  [19200/72202]
loss: 0.011610  [25600/72202]
loss: 0.078222  [32000/72202]
loss: 0.017070  [38400/72202]
loss: 0.040366  [44800/72202]
loss: 0.108888  [51200/72202]
loss: 0.003560  [57600/72202]
loss: 0.005674  [64000/72202]
loss: 0.084711  [70400/72202]
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.069739 

Epoch 9
-------------------------------
loss: 0.031811  [    0/72202]
loss: 0.000640  [ 6400/72202]
loss: 0.048465  [12800/72202]
loss: 0.091623  [19200/72202]
loss: 0.030744  [25600/72202]
loss: 0.004748  [32000/72202]
loss: 0.011094  [38400/72202]
loss: 0.014164  [44800/72202]
loss: 0.097821  [51200/72202]
loss: 0.008431  [57600/72202]
loss: 0.097452  [64000/72202]
loss: 0.041123  [70400/72202]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.071179 

Epoch 10
-------------------------------
loss: 0.043234  [    0/72202]
loss: 0.061401  [ 6400/72202]
loss: 0.069070  [12800/72202]
loss: 0.026635  [19200/72202]
loss: 0.003612  [25600/72202]
loss: 0.029291  [32000/72202]
loss: 0.030857  [38400/72202]
loss: 0.012083  [44800/72202]
loss: 0.012704  [51200/72202]
loss: 0.066557  [57600/72202]
loss: 0.033419  [64000/72202]
loss: 0.028406  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.083862 

Epoch 11
-------------------------------
loss: 0.027526  [    0/72202]
loss: 0.031544  [ 6400/72202]
loss: 0.005351  [12800/72202]
loss: 0.008072  [19200/72202]
loss: 0.002046  [25600/72202]
loss: 0.162236  [32000/72202]
loss: 0.011952  [38400/72202]
loss: 0.034030  [44800/72202]
loss: 0.025973  [51200/72202]
loss: 0.061897  [57600/72202]
loss: 0.030764  [64000/72202]
loss: 0.017461  [70400/72202]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.071914 

Epoch 12
-------------------------------
loss: 0.046974  [    0/72202]
loss: 0.022082  [ 6400/72202]
loss: 0.041128  [12800/72202]
loss: 0.051404  [19200/72202]
loss: 0.037465  [25600/72202]
loss: 0.071951  [32000/72202]
loss: 0.001561  [38400/72202]
loss: 0.010679  [44800/72202]
loss: 0.010304  [51200/72202]
loss: 0.031071  [57600/72202]
loss: 0.284572  [64000/72202]
loss: 0.015741  [70400/72202]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.072373 

Epoch 13
-------------------------------
loss: 0.070598  [    0/72202]
loss: 0.015700  [ 6400/72202]
loss: 0.044561  [12800/72202]
loss: 0.004452  [19200/72202]
loss: 0.064317  [25600/72202]
loss: 0.020510  [32000/72202]
loss: 0.061732  [38400/72202]
loss: 0.004292  [44800/72202]
loss: 0.019039  [51200/72202]
loss: 0.024803  [57600/72202]
loss: 0.006377  [64000/72202]
loss: 0.006485  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.079963 

Epoch 14
-------------------------------
loss: 0.004745  [    0/72202]
loss: 0.153186  [ 6400/72202]
loss: 0.008592  [12800/72202]
loss: 0.076600  [19200/72202]
loss: 0.023339  [25600/72202]
loss: 0.022805  [32000/72202]
loss: 0.021444  [38400/72202]
loss: 0.002246  [44800/72202]
loss: 0.088917  [51200/72202]
loss: 0.012029  [57600/72202]
loss: 0.011712  [64000/72202]
loss: 0.105987  [70400/72202]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.074103 

Epoch 15
-------------------------------
loss: 1.586707  [    0/72202]
loss: 0.005329  [ 6400/72202]
loss: 0.021660  [12800/72202]
loss: 0.007499  [19200/72202]
loss: 0.035516  [25600/72202]
loss: 0.042059  [32000/72202]
loss: 0.004200  [38400/72202]
loss: 0.059087  [44800/72202]
loss: 0.006201  [51200/72202]
loss: 0.003880  [57600/72202]
loss: 0.005594  [64000/72202]
loss: 0.016326  [70400/72202]
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.073233 

Epoch 16
-------------------------------
loss: 0.037357  [    0/72202]
loss: 0.010769  [ 6400/72202]
loss: 0.030079  [12800/72202]
loss: 0.075540  [19200/72202]
loss: 0.032055  [25600/72202]
loss: 0.020951  [32000/72202]
loss: 0.084312  [38400/72202]
loss: 0.019047  [44800/72202]
loss: 0.005664  [51200/72202]
loss: 0.005692  [57600/72202]
loss: 0.004159  [64000/72202]
loss: 0.051181  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.078785 

Epoch 17
-------------------------------
loss: 0.017379  [    0/72202]
loss: 0.000904  [ 6400/72202]
loss: 0.066643  [12800/72202]
loss: 0.010552  [19200/72202]
loss: 0.003827  [25600/72202]
loss: 0.005383  [32000/72202]
loss: 0.070467  [38400/72202]
loss: 0.006971  [44800/72202]
loss: 0.066350  [51200/72202]
loss: 0.010622  [57600/72202]
loss: 0.017504  [64000/72202]
loss: 0.020024  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.080641 

Epoch 18
-------------------------------
loss: 0.100957  [    0/72202]
loss: 0.005337  [ 6400/72202]
loss: 0.023855  [12800/72202]
loss: 0.014046  [19200/72202]
loss: 0.005278  [25600/72202]
loss: 0.038560  [32000/72202]
loss: 0.020429  [38400/72202]
loss: 0.048863  [44800/72202]
loss: 0.135928  [51200/72202]
loss: 0.018488  [57600/72202]
loss: 0.031368  [64000/72202]
loss: 0.007613  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.078995 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.880559  [    0/70508]
loss: 0.213495  [ 6400/70508]
loss: 0.239600  [12800/70508]
loss: 0.057723  [19200/70508]
loss: 0.174993  [25600/70508]
loss: 0.164912  [32000/70508]
loss: 0.170856  [38400/70508]
loss: 0.104456  [44800/70508]
loss: 0.060654  [51200/70508]
loss: 0.126519  [57600/70508]
loss: 0.096663  [64000/70508]
loss: 0.164617  [70400/70508]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.174487 

Epoch 2
-------------------------------
loss: 0.239710  [    0/70508]
loss: 0.091111  [ 6400/70508]
loss: 0.040638  [12800/70508]
loss: 0.117816  [19200/70508]
loss: 0.184919  [25600/70508]
loss: 0.090851  [32000/70508]
loss: 0.051560  [38400/70508]
loss: 0.125918  [44800/70508]
loss: 0.139952  [51200/70508]
loss: 0.177071  [57600/70508]
loss: 0.120231  [64000/70508]
loss: 0.101454  [70400/70508]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.163414 

Epoch 3
-------------------------------
loss: 0.080820  [    0/70508]
loss: 0.062305  [ 6400/70508]
loss: 0.061250  [12800/70508]
loss: 0.220056  [19200/70508]
loss: 0.141118  [25600/70508]
loss: 0.116517  [32000/70508]
loss: 0.067257  [38400/70508]
loss: 0.103563  [44800/70508]
loss: 0.168251  [51200/70508]
loss: 0.073598  [57600/70508]
loss: 0.216981  [64000/70508]
loss: 0.181011  [70400/70508]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.155864 

Epoch 4
-------------------------------
loss: 0.040559  [    0/70508]
loss: 0.055371  [ 6400/70508]
loss: 0.142955  [12800/70508]
loss: 0.093883  [19200/70508]
loss: 0.057028  [25600/70508]
loss: 0.008515  [32000/70508]
loss: 0.095451  [38400/70508]
loss: 0.040797  [44800/70508]
loss: 0.064536  [51200/70508]
loss: 0.035265  [57600/70508]
loss: 0.039180  [64000/70508]
loss: 0.129264  [70400/70508]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.155363 

Epoch 5
-------------------------------
loss: 0.120039  [    0/70508]
loss: 0.157610  [ 6400/70508]
loss: 1.586393  [12800/70508]
loss: 0.200639  [19200/70508]
loss: 0.028547  [25600/70508]
loss: 0.188914  [32000/70508]
loss: 0.048864  [38400/70508]
loss: 0.074171  [44800/70508]
loss: 0.087254  [51200/70508]
loss: 0.117736  [57600/70508]
loss: 0.076828  [64000/70508]
loss: 0.031936  [70400/70508]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.146641 

Epoch 6
-------------------------------
loss: 0.092196  [    0/70508]
loss: 0.065400  [ 6400/70508]
loss: 0.075917  [12800/70508]
loss: 0.093806  [19200/70508]
loss: 0.120619  [25600/70508]
loss: 0.150097  [32000/70508]
loss: 0.091077  [38400/70508]
loss: 0.130258  [44800/70508]
loss: 0.088079  [51200/70508]
loss: 0.109975  [57600/70508]
loss: 0.099811  [64000/70508]
loss: 0.131170  [70400/70508]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.148307 

Epoch 7
-------------------------------
loss: 0.108856  [    0/70508]
loss: 0.114305  [ 6400/70508]
loss: 0.051845  [12800/70508]
loss: 0.139223  [19200/70508]
loss: 0.077587  [25600/70508]
loss: 0.045708  [32000/70508]
loss: 0.089460  [38400/70508]
loss: 0.081240  [44800/70508]
loss: 0.074440  [51200/70508]
loss: 0.078263  [57600/70508]
loss: 0.112541  [64000/70508]
loss: 0.082786  [70400/70508]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.155751 

Epoch 8
-------------------------------
loss: 0.069168  [    0/70508]
loss: 0.139506  [ 6400/70508]
loss: 0.043071  [12800/70508]
loss: 0.036034  [19200/70508]
loss: 0.109867  [25600/70508]
loss: 0.052764  [32000/70508]
loss: 0.083571  [38400/70508]
loss: 0.104674  [44800/70508]
loss: 0.173075  [51200/70508]
loss: 0.111692  [57600/70508]
loss: 0.168016  [64000/70508]
loss: 0.066741  [70400/70508]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.143559 

Epoch 9
-------------------------------
loss: 0.055832  [    0/70508]
loss: 0.159629  [ 6400/70508]
loss: 0.152988  [12800/70508]
loss: 0.109115  [19200/70508]
loss: 0.210117  [25600/70508]
loss: 0.104796  [32000/70508]
loss: 0.057671  [38400/70508]
loss: 0.015790  [44800/70508]
loss: 0.056184  [51200/70508]
loss: 0.124130  [57600/70508]
loss: 0.047636  [64000/70508]
loss: 0.155745  [70400/70508]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.146500 

Epoch 10
-------------------------------
loss: 0.095224  [    0/70508]
loss: 0.065808  [ 6400/70508]
loss: 0.059898  [12800/70508]
loss: 0.192764  [19200/70508]
loss: 0.171785  [25600/70508]
loss: 0.246208  [32000/70508]
loss: 0.054164  [38400/70508]
loss: 0.095892  [44800/70508]
loss: 0.043063  [51200/70508]
loss: 0.111938  [57600/70508]
loss: 0.008972  [64000/70508]
loss: 0.072268  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.142019 

Epoch 11
-------------------------------
loss: 0.105093  [    0/70508]
loss: 0.076985  [ 6400/70508]
loss: 0.053133  [12800/70508]
loss: 0.048611  [19200/70508]
loss: 0.153998  [25600/70508]
loss: 0.081299  [32000/70508]
loss: 0.031202  [38400/70508]
loss: 0.033065  [44800/70508]
loss: 0.105080  [51200/70508]
loss: 0.067537  [57600/70508]
loss: 0.072914  [64000/70508]
loss: 0.017353  [70400/70508]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.144225 

Epoch 12
-------------------------------
loss: 0.034062  [    0/70508]
loss: 0.074156  [ 6400/70508]
loss: 0.176806  [12800/70508]
loss: 0.074498  [19200/70508]
loss: 0.136553  [25600/70508]
loss: 0.128101  [32000/70508]
loss: 0.009572  [38400/70508]
loss: 0.055271  [44800/70508]
loss: 0.088922  [51200/70508]
loss: 0.017783  [57600/70508]
loss: 0.022027  [64000/70508]
loss: 0.036256  [70400/70508]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.146722 

Epoch 13
-------------------------------
loss: 0.069440  [    0/70508]
loss: 0.114938  [ 6400/70508]
loss: 0.065609  [12800/70508]
loss: 0.091424  [19200/70508]
loss: 0.071432  [25600/70508]
loss: 0.055493  [32000/70508]
loss: 0.096334  [38400/70508]
loss: 0.032845  [44800/70508]
loss: 0.028547  [51200/70508]
loss: 0.125783  [57600/70508]
loss: 0.193282  [64000/70508]
loss: 0.091715  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.147168 

Epoch 14
-------------------------------
loss: 0.107247  [    0/70508]
loss: 0.066331  [ 6400/70508]
loss: 0.070308  [12800/70508]
loss: 0.171745  [19200/70508]
loss: 0.143167  [25600/70508]
loss: 0.063550  [32000/70508]
loss: 0.021676  [38400/70508]
loss: 0.081794  [44800/70508]
loss: 0.137773  [51200/70508]
loss: 0.071067  [57600/70508]
loss: 0.105748  [64000/70508]
loss: 0.057245  [70400/70508]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.144706 

Epoch 15
-------------------------------
loss: 0.081406  [    0/70508]
loss: 0.085181  [ 6400/70508]
loss: 0.055834  [12800/70508]
loss: 0.131208  [19200/70508]
loss: 0.029059  [25600/70508]
loss: 0.055522  [32000/70508]
loss: 0.077969  [38400/70508]
loss: 0.023659  [44800/70508]
loss: 0.032544  [51200/70508]
loss: 0.144213  [57600/70508]
loss: 0.044124  [64000/70508]
loss: 0.065781  [70400/70508]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.138687 

Epoch 16
-------------------------------
loss: 0.060103  [    0/70508]
loss: 0.048581  [ 6400/70508]
loss: 0.032771  [12800/70508]
loss: 0.052707  [19200/70508]
loss: 0.029442  [25600/70508]
loss: 0.051766  [32000/70508]
loss: 0.056233  [38400/70508]
loss: 0.062587  [44800/70508]
loss: 0.157138  [51200/70508]
loss: 0.062517  [57600/70508]
loss: 0.027686  [64000/70508]
loss: 0.052004  [70400/70508]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.140680 

Epoch 17
-------------------------------
loss: 0.027679  [    0/70508]
loss: 0.041848  [ 6400/70508]
loss: 0.097807  [12800/70508]
loss: 0.117097  [19200/70508]
loss: 0.126388  [25600/70508]
loss: 0.124560  [32000/70508]
loss: 0.043106  [38400/70508]
loss: 0.095179  [44800/70508]
loss: 0.113671  [51200/70508]
loss: 0.118792  [57600/70508]
loss: 0.093994  [64000/70508]
loss: 0.097849  [70400/70508]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.150565 

Epoch 18
-------------------------------
loss: 0.074842  [    0/70508]
loss: 0.092237  [ 6400/70508]
loss: 0.083586  [12800/70508]
loss: 0.024000  [19200/70508]
loss: 0.093846  [25600/70508]
loss: 0.041556  [32000/70508]
loss: 0.113383  [38400/70508]
loss: 0.123566  [44800/70508]
loss: 0.136807  [51200/70508]
loss: 0.080950  [57600/70508]
loss: 0.081850  [64000/70508]
loss: 0.191159  [70400/70508]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.140419 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.888553  [    0/71045]
loss: 0.246236  [ 6400/71045]
loss: 0.086848  [12800/71045]
loss: 0.059934  [19200/71045]
loss: 0.163021  [25600/71045]
loss: 0.061809  [32000/71045]
loss: 0.276440  [38400/71045]
loss: 0.063630  [44800/71045]
loss: 0.115377  [51200/71045]
loss: 0.047219  [57600/71045]
loss: 0.105926  [64000/71045]
loss: 0.026238  [70400/71045]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.094180 

Epoch 2
-------------------------------
loss: 0.300296  [    0/71045]
loss: 0.104705  [ 6400/71045]
loss: 0.035883  [12800/71045]
loss: 0.076950  [19200/71045]
loss: 0.083931  [25600/71045]
loss: 0.104719  [32000/71045]
loss: 0.046897  [38400/71045]
loss: 0.011865  [44800/71045]
loss: 0.091351  [51200/71045]
loss: 0.022162  [57600/71045]
loss: 0.100798  [64000/71045]
loss: 0.046740  [70400/71045]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.073633 

Epoch 3
-------------------------------
loss: 0.116806  [    0/71045]
loss: 0.066884  [ 6400/71045]
loss: 0.029873  [12800/71045]
loss: 0.113135  [19200/71045]
loss: 0.065659  [25600/71045]
loss: 0.132526  [32000/71045]
loss: 0.060679  [38400/71045]
loss: 0.026773  [44800/71045]
loss: 0.075378  [51200/71045]
loss: 0.044530  [57600/71045]
loss: 0.115380  [64000/71045]
loss: 0.079273  [70400/71045]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.053384 

Epoch 4
-------------------------------
loss: 0.096080  [    0/71045]
loss: 0.102906  [ 6400/71045]
loss: 0.183885  [12800/71045]
loss: 0.107951  [19200/71045]
loss: 0.107323  [25600/71045]
loss: 0.029384  [32000/71045]
loss: 0.085292  [38400/71045]
loss: 0.018150  [44800/71045]
loss: 0.096533  [51200/71045]
loss: 0.204975  [57600/71045]
loss: 0.057390  [64000/71045]
loss: 0.084342  [70400/71045]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.056219 

Epoch 5
-------------------------------
loss: 0.156678  [    0/71045]
loss: 0.055076  [ 6400/71045]
loss: 0.020192  [12800/71045]
loss: 0.126311  [19200/71045]
loss: 0.153176  [25600/71045]
loss: 0.068143  [32000/71045]
loss: 0.232235  [38400/71045]
loss: 0.116405  [44800/71045]
loss: 0.006656  [51200/71045]
loss: 0.017676  [57600/71045]
loss: 0.064483  [64000/71045]
loss: 0.034591  [70400/71045]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.054482 

Epoch 6
-------------------------------
loss: 0.017547  [    0/71045]
loss: 0.155304  [ 6400/71045]
loss: 0.149824  [12800/71045]
loss: 0.019981  [19200/71045]
loss: 0.105419  [25600/71045]
loss: 0.026643  [32000/71045]
loss: 0.161967  [38400/71045]
loss: 0.052941  [44800/71045]
loss: 0.114234  [51200/71045]
loss: 0.053045  [57600/71045]
loss: 0.062679  [64000/71045]
loss: 0.085009  [70400/71045]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.055018 

Epoch 7
-------------------------------
loss: 0.070700  [    0/71045]
loss: 0.012728  [ 6400/71045]
loss: 0.019950  [12800/71045]
loss: 0.006263  [19200/71045]
loss: 0.045770  [25600/71045]
loss: 0.073307  [32000/71045]
loss: 0.117437  [38400/71045]
loss: 0.033162  [44800/71045]
loss: 0.044551  [51200/71045]
loss: 0.016159  [57600/71045]
loss: 0.024524  [64000/71045]
loss: 0.028262  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.059742 

Epoch 8
-------------------------------
loss: 0.035998  [    0/71045]
loss: 0.085962  [ 6400/71045]
loss: 0.004414  [12800/71045]
loss: 0.033673  [19200/71045]
loss: 0.190058  [25600/71045]
loss: 0.060355  [32000/71045]
loss: 0.016606  [38400/71045]
loss: 0.004722  [44800/71045]
loss: 0.039189  [51200/71045]
loss: 0.112106  [57600/71045]
loss: 0.010071  [64000/71045]
loss: 0.054569  [70400/71045]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.052929 

Epoch 9
-------------------------------
loss: 0.038432  [    0/71045]
loss: 0.047196  [ 6400/71045]
loss: 0.042215  [12800/71045]
loss: 0.019290  [19200/71045]
loss: 0.047589  [25600/71045]
loss: 0.060703  [32000/71045]
loss: 0.067194  [38400/71045]
loss: 0.128558  [44800/71045]
loss: 0.075759  [51200/71045]
loss: 0.013556  [57600/71045]
loss: 0.030195  [64000/71045]
loss: 0.048634  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.058624 

Epoch 10
-------------------------------
loss: 0.033923  [    0/71045]
loss: 0.012163  [ 6400/71045]
loss: 0.034929  [12800/71045]
loss: 0.086624  [19200/71045]
loss: 0.166644  [25600/71045]
loss: 0.039171  [32000/71045]
loss: 0.067090  [38400/71045]
loss: 0.058469  [44800/71045]
loss: 0.083467  [51200/71045]
loss: 0.048052  [57600/71045]
loss: 0.043061  [64000/71045]
loss: 0.141313  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.058588 

Epoch 11
-------------------------------
loss: 0.014978  [    0/71045]
loss: 0.060027  [ 6400/71045]
loss: 0.095702  [12800/71045]
loss: 0.064848  [19200/71045]
loss: 0.048501  [25600/71045]
loss: 0.106646  [32000/71045]
loss: 0.019142  [38400/71045]
loss: 0.044952  [44800/71045]
loss: 0.021261  [51200/71045]
loss: 0.033960  [57600/71045]
loss: 0.039164  [64000/71045]
loss: 0.079621  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.063089 

Epoch 12
-------------------------------
loss: 0.026930  [    0/71045]
loss: 0.033369  [ 6400/71045]
loss: 0.124095  [12800/71045]
loss: 0.067192  [19200/71045]
loss: 0.028343  [25600/71045]
loss: 0.034852  [32000/71045]
loss: 0.084825  [38400/71045]
loss: 0.087175  [44800/71045]
loss: 0.092338  [51200/71045]
loss: 0.039685  [57600/71045]
loss: 0.115643  [64000/71045]
loss: 0.080038  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.061865 

Epoch 13
-------------------------------
loss: 0.045388  [    0/71045]
loss: 0.043955  [ 6400/71045]
loss: 0.026865  [12800/71045]
loss: 0.224627  [19200/71045]
loss: 0.040752  [25600/71045]
loss: 0.041990  [32000/71045]
loss: 0.120463  [38400/71045]
loss: 0.011593  [44800/71045]
loss: 0.012858  [51200/71045]
loss: 0.024579  [57600/71045]
loss: 0.016830  [64000/71045]
loss: 0.059101  [70400/71045]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.061285 

Epoch 14
-------------------------------
loss: 0.020637  [    0/71045]
loss: 0.057850  [ 6400/71045]
loss: 0.029443  [12800/71045]
loss: 0.071144  [19200/71045]
loss: 0.010209  [25600/71045]
loss: 0.024280  [32000/71045]
loss: 0.086186  [38400/71045]
loss: 0.039317  [44800/71045]
loss: 0.043163  [51200/71045]
loss: 0.013941  [57600/71045]
loss: 0.053455  [64000/71045]
loss: 0.058928  [70400/71045]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.111388 

Epoch 15
-------------------------------
loss: 0.124494  [    0/71045]
loss: 0.105606  [ 6400/71045]
loss: 0.028006  [12800/71045]
loss: 0.042487  [19200/71045]
loss: 0.151895  [25600/71045]
loss: 0.142742  [32000/71045]
loss: 0.080992  [38400/71045]
loss: 0.014197  [44800/71045]
loss: 0.033116  [51200/71045]
loss: 0.072864  [57600/71045]
loss: 0.007693  [64000/71045]
loss: 0.005959  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.059587 

Epoch 16
-------------------------------
loss: 0.036205  [    0/71045]
loss: 0.096020  [ 6400/71045]
loss: 0.025658  [12800/71045]
loss: 0.089119  [19200/71045]
loss: 0.024111  [25600/71045]
loss: 0.017818  [32000/71045]
loss: 0.124492  [38400/71045]
loss: 0.039029  [44800/71045]
loss: 0.003353  [51200/71045]
loss: 0.119155  [57600/71045]
loss: 0.046687  [64000/71045]
loss: 0.124129  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.059678 

Epoch 17
-------------------------------
loss: 0.052478  [    0/71045]
loss: 0.005159  [ 6400/71045]
loss: 0.055216  [12800/71045]
loss: 0.128378  [19200/71045]
loss: 0.073415  [25600/71045]
loss: 0.015651  [32000/71045]
loss: 0.044388  [38400/71045]
loss: 0.004831  [44800/71045]
loss: 0.051631  [51200/71045]
loss: 0.029862  [57600/71045]
loss: 0.056582  [64000/71045]
loss: 0.072668  [70400/71045]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.071699 

Epoch 18
-------------------------------
loss: 0.013064  [    0/71045]
loss: 0.028766  [ 6400/71045]
loss: 0.039681  [12800/71045]
loss: 0.054011  [19200/71045]
loss: 0.074231  [25600/71045]
loss: 0.051927  [32000/71045]
loss: 0.072565  [38400/71045]
loss: 0.079282  [44800/71045]
loss: 0.081992  [51200/71045]
loss: 0.084736  [57600/71045]
loss: 0.183839  [64000/71045]
loss: 0.002489  [70400/71045]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.100465 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.912205  [    0/70834]
loss: 0.098768  [ 6400/70834]
loss: 0.115768  [12800/70834]
loss: 0.317605  [19200/70834]
loss: 0.132848  [25600/70834]
loss: 0.081281  [32000/70834]
loss: 0.127326  [38400/70834]
loss: 0.041664  [44800/70834]
loss: 0.065432  [51200/70834]
loss: 0.118362  [57600/70834]
loss: 0.113376  [64000/70834]
loss: 0.056368  [70400/70834]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090661 

Epoch 2
-------------------------------
loss: 0.182966  [    0/70834]
loss: 0.192481  [ 6400/70834]
loss: 0.027553  [12800/70834]
loss: 0.065317  [19200/70834]
loss: 0.096270  [25600/70834]
loss: 0.168154  [32000/70834]
loss: 0.141514  [38400/70834]
loss: 0.112499  [44800/70834]
loss: 0.111070  [51200/70834]
loss: 0.116263  [57600/70834]
loss: 0.053020  [64000/70834]
loss: 0.100816  [70400/70834]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.086634 

Epoch 3
-------------------------------
loss: 0.053260  [    0/70834]
loss: 0.082059  [ 6400/70834]
loss: 0.038448  [12800/70834]
loss: 0.029757  [19200/70834]
loss: 0.084202  [25600/70834]
loss: 0.031321  [32000/70834]
loss: 0.160996  [38400/70834]
loss: 0.321997  [44800/70834]
loss: 0.017744  [51200/70834]
loss: 0.080060  [57600/70834]
loss: 0.083399  [64000/70834]
loss: 0.113988  [70400/70834]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.080495 

Epoch 4
-------------------------------
loss: 0.114769  [    0/70834]
loss: 0.107032  [ 6400/70834]
loss: 0.099733  [12800/70834]
loss: 0.017083  [19200/70834]
loss: 0.054777  [25600/70834]
loss: 0.118770  [32000/70834]
loss: 0.160625  [38400/70834]
loss: 0.081123  [44800/70834]
loss: 0.032770  [51200/70834]
loss: 0.043804  [57600/70834]
loss: 0.062139  [64000/70834]
loss: 0.022236  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075521 

Epoch 5
-------------------------------
loss: 0.065624  [    0/70834]
loss: 0.026918  [ 6400/70834]
loss: 0.045128  [12800/70834]
loss: 0.047742  [19200/70834]
loss: 0.090089  [25600/70834]
loss: 0.077828  [32000/70834]
loss: 0.020564  [38400/70834]
loss: 0.047149  [44800/70834]
loss: 0.076125  [51200/70834]
loss: 0.032921  [57600/70834]
loss: 0.121867  [64000/70834]
loss: 0.073305  [70400/70834]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.075376 

Epoch 6
-------------------------------
loss: 0.037573  [    0/70834]
loss: 0.085897  [ 6400/70834]
loss: 0.025268  [12800/70834]
loss: 0.131286  [19200/70834]
loss: 0.113086  [25600/70834]
loss: 0.033738  [32000/70834]
loss: 0.026368  [38400/70834]
loss: 0.127168  [44800/70834]
loss: 0.024619  [51200/70834]
loss: 0.068404  [57600/70834]
loss: 0.056975  [64000/70834]
loss: 0.032172  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.073847 

Epoch 7
-------------------------------
loss: 0.026192  [    0/70834]
loss: 0.117251  [ 6400/70834]
loss: 0.034251  [12800/70834]
loss: 0.038611  [19200/70834]
loss: 0.024077  [25600/70834]
loss: 0.078921  [32000/70834]
loss: 0.014344  [38400/70834]
loss: 0.080719  [44800/70834]
loss: 0.072926  [51200/70834]
loss: 0.158186  [57600/70834]
loss: 0.054514  [64000/70834]
loss: 0.040674  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.074781 

Epoch 8
-------------------------------
loss: 0.065155  [    0/70834]
loss: 0.046755  [ 6400/70834]
loss: 0.074922  [12800/70834]
loss: 0.075807  [19200/70834]
loss: 0.037930  [25600/70834]
loss: 0.014550  [32000/70834]
loss: 0.042482  [38400/70834]
loss: 0.101133  [44800/70834]
loss: 0.014281  [51200/70834]
loss: 0.060350  [57600/70834]
loss: 0.022134  [64000/70834]
loss: 0.050233  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076523 

Epoch 9
-------------------------------
loss: 0.032594  [    0/70834]
loss: 0.069584  [ 6400/70834]
loss: 0.082075  [12800/70834]
loss: 0.082536  [19200/70834]
loss: 0.157217  [25600/70834]
loss: 0.111404  [32000/70834]
loss: 0.082362  [38400/70834]
loss: 0.095139  [44800/70834]
loss: 0.105784  [51200/70834]
loss: 0.253532  [57600/70834]
loss: 0.066900  [64000/70834]
loss: 0.099426  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.071170 

Epoch 10
-------------------------------
loss: 0.103345  [    0/70834]
loss: 0.033154  [ 6400/70834]
loss: 0.126342  [12800/70834]
loss: 0.021947  [19200/70834]
loss: 0.067397  [25600/70834]
loss: 0.132640  [32000/70834]
loss: 0.097464  [38400/70834]
loss: 0.072360  [44800/70834]
loss: 0.015747  [51200/70834]
loss: 0.020514  [57600/70834]
loss: 0.009134  [64000/70834]
loss: 0.080401  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.074842 

Epoch 11
-------------------------------
loss: 0.025056  [    0/70834]
loss: 0.066892  [ 6400/70834]
loss: 0.037437  [12800/70834]
loss: 0.120135  [19200/70834]
loss: 0.047067  [25600/70834]
loss: 0.121058  [32000/70834]
loss: 0.047032  [38400/70834]
loss: 0.010194  [44800/70834]
loss: 0.013638  [51200/70834]
loss: 0.052278  [57600/70834]
loss: 0.076973  [64000/70834]
loss: 0.030820  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075213 

Epoch 12
-------------------------------
loss: 0.076868  [    0/70834]
loss: 0.103712  [ 6400/70834]
loss: 0.048456  [12800/70834]
loss: 0.032423  [19200/70834]
loss: 0.009112  [25600/70834]
loss: 0.051813  [32000/70834]
loss: 0.056533  [38400/70834]
loss: 0.099555  [44800/70834]
loss: 0.052437  [51200/70834]
loss: 0.048430  [57600/70834]
loss: 0.091153  [64000/70834]
loss: 0.026633  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080355 

Epoch 13
-------------------------------
loss: 0.028710  [    0/70834]
loss: 0.167938  [ 6400/70834]
loss: 0.054694  [12800/70834]
loss: 0.074755  [19200/70834]
loss: 0.007412  [25600/70834]
loss: 0.118390  [32000/70834]
loss: 0.010102  [38400/70834]
loss: 0.106567  [44800/70834]
loss: 0.043453  [51200/70834]
loss: 0.128456  [57600/70834]
loss: 0.028746  [64000/70834]
loss: 0.038725  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.077369 

Epoch 14
-------------------------------
loss: 0.165730  [    0/70834]
loss: 0.063050  [ 6400/70834]
loss: 0.026892  [12800/70834]
loss: 0.095806  [19200/70834]
loss: 0.056959  [25600/70834]
loss: 0.068236  [32000/70834]
loss: 0.043462  [38400/70834]
loss: 0.038050  [44800/70834]
loss: 0.053205  [51200/70834]
loss: 0.144041  [57600/70834]
loss: 0.092537  [64000/70834]
loss: 0.037345  [70400/70834]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.074730 

Epoch 15
-------------------------------
loss: 0.134432  [    0/70834]
loss: 0.064284  [ 6400/70834]
loss: 0.051282  [12800/70834]
loss: 0.028968  [19200/70834]
loss: 0.058693  [25600/70834]
loss: 0.075050  [32000/70834]
loss: 0.046845  [38400/70834]
loss: 1.635816  [44800/70834]
loss: 0.046679  [51200/70834]
loss: 0.156361  [57600/70834]
loss: 0.062672  [64000/70834]
loss: 0.033819  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082652 

Epoch 16
-------------------------------
loss: 0.027117  [    0/70834]
loss: 0.046682  [ 6400/70834]
loss: 0.052488  [12800/70834]
loss: 0.033823  [19200/70834]
loss: 0.017259  [25600/70834]
loss: 0.018169  [32000/70834]
loss: 0.090759  [38400/70834]
loss: 0.013917  [44800/70834]
loss: 0.017962  [51200/70834]
loss: 0.052015  [57600/70834]
loss: 0.091481  [64000/70834]
loss: 0.057494  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074522 

Epoch 17
-------------------------------
loss: 0.050885  [    0/70834]
loss: 0.065586  [ 6400/70834]
loss: 0.098356  [12800/70834]
loss: 0.077614  [19200/70834]
loss: 0.029816  [25600/70834]
loss: 0.045796  [32000/70834]
loss: 0.048382  [38400/70834]
loss: 0.060175  [44800/70834]
loss: 0.084425  [51200/70834]
loss: 0.008476  [57600/70834]
loss: 0.032720  [64000/70834]
loss: 0.169824  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080746 

Epoch 18
-------------------------------
loss: 0.100564  [    0/70834]
loss: 0.021435  [ 6400/70834]
loss: 0.106958  [12800/70834]
loss: 0.061824  [19200/70834]
loss: 0.038648  [25600/70834]
loss: 0.092606  [32000/70834]
loss: 0.039874  [38400/70834]
loss: 0.021440  [44800/70834]
loss: 0.067779  [51200/70834]
loss: 0.030532  [57600/70834]
loss: 0.059922  [64000/70834]
loss: 0.232268  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075504 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.880040  [    0/70535]
loss: 0.264103  [ 6400/70535]
loss: 0.148175  [12800/70535]
loss: 0.118537  [19200/70535]
loss: 0.043121  [25600/70535]
loss: 0.031985  [32000/70535]
loss: 0.290776  [38400/70535]
loss: 0.152699  [44800/70535]
loss: 0.162950  [51200/70535]
loss: 0.128699  [57600/70535]
loss: 0.114864  [64000/70535]
loss: 0.106891  [70400/70535]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.155679 

Epoch 2
-------------------------------
loss: 0.170595  [    0/70535]
loss: 0.124503  [ 6400/70535]
loss: 0.131027  [12800/70535]
loss: 0.091026  [19200/70535]
loss: 0.190670  [25600/70535]
loss: 0.153455  [32000/70535]
loss: 0.188067  [38400/70535]
loss: 0.063427  [44800/70535]
loss: 0.130440  [51200/70535]
loss: 0.228744  [57600/70535]
loss: 0.097563  [64000/70535]
loss: 0.115626  [70400/70535]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.132719 

Epoch 3
-------------------------------
loss: 0.062050  [    0/70535]
loss: 0.227218  [ 6400/70535]
loss: 0.133044  [12800/70535]
loss: 0.038211  [19200/70535]
loss: 0.113510  [25600/70535]
loss: 0.074586  [32000/70535]
loss: 0.065242  [38400/70535]
loss: 0.047787  [44800/70535]
loss: 0.037805  [51200/70535]
loss: 0.129652  [57600/70535]
loss: 0.144120  [64000/70535]
loss: 0.077293  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.128919 

Epoch 4
-------------------------------
loss: 0.110663  [    0/70535]
loss: 0.145819  [ 6400/70535]
loss: 0.143673  [12800/70535]
loss: 0.226406  [19200/70535]
loss: 0.081422  [25600/70535]
loss: 0.166962  [32000/70535]
loss: 0.055755  [38400/70535]
loss: 0.095835  [44800/70535]
loss: 0.061855  [51200/70535]
loss: 0.110921  [57600/70535]
loss: 0.094340  [64000/70535]
loss: 0.020910  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.124577 

Epoch 5
-------------------------------
loss: 0.103712  [    0/70535]
loss: 0.089912  [ 6400/70535]
loss: 0.170737  [12800/70535]
loss: 0.081974  [19200/70535]
loss: 0.075250  [25600/70535]
loss: 0.110418  [32000/70535]
loss: 0.164391  [38400/70535]
loss: 0.045716  [44800/70535]
loss: 0.132972  [51200/70535]
loss: 0.099230  [57600/70535]
loss: 0.092441  [64000/70535]
loss: 0.147594  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.126688 

Epoch 6
-------------------------------
loss: 0.106030  [    0/70535]
loss: 1.659808  [ 6400/70535]
loss: 0.062723  [12800/70535]
loss: 0.141163  [19200/70535]
loss: 0.134975  [25600/70535]
loss: 0.043268  [32000/70535]
loss: 0.069895  [38400/70535]
loss: 0.071444  [44800/70535]
loss: 0.106050  [51200/70535]
loss: 0.244969  [57600/70535]
loss: 0.043797  [64000/70535]
loss: 0.067860  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.123074 

Epoch 7
-------------------------------
loss: 0.141758  [    0/70535]
loss: 0.038601  [ 6400/70535]
loss: 0.037311  [12800/70535]
loss: 0.101815  [19200/70535]
loss: 0.133062  [25600/70535]
loss: 0.048721  [32000/70535]
loss: 0.115339  [38400/70535]
loss: 0.090304  [44800/70535]
loss: 0.057933  [51200/70535]
loss: 0.082314  [57600/70535]
loss: 0.105840  [64000/70535]
loss: 0.101980  [70400/70535]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.123851 

Epoch 8
-------------------------------
loss: 0.074942  [    0/70535]
loss: 0.110524  [ 6400/70535]
loss: 0.083200  [12800/70535]
loss: 0.150763  [19200/70535]
loss: 0.204355  [25600/70535]
loss: 0.139823  [32000/70535]
loss: 0.073330  [38400/70535]
loss: 0.057096  [44800/70535]
loss: 0.155203  [51200/70535]
loss: 0.015251  [57600/70535]
loss: 0.024515  [64000/70535]
loss: 0.204158  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.121556 

Epoch 9
-------------------------------
loss: 0.051136  [    0/70535]
loss: 0.065914  [ 6400/70535]
loss: 0.044958  [12800/70535]
loss: 0.150946  [19200/70535]
loss: 0.098399  [25600/70535]
loss: 0.090828  [32000/70535]
loss: 0.038657  [38400/70535]
loss: 0.173467  [44800/70535]
loss: 0.097551  [51200/70535]
loss: 0.033344  [57600/70535]
loss: 0.057108  [64000/70535]
loss: 0.092361  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.121554 

Epoch 10
-------------------------------
loss: 0.107272  [    0/70535]
loss: 0.073030  [ 6400/70535]
loss: 0.047733  [12800/70535]
loss: 0.128519  [19200/70535]
loss: 1.623006  [25600/70535]
loss: 0.086257  [32000/70535]
loss: 0.032804  [38400/70535]
loss: 0.060032  [44800/70535]
loss: 0.097802  [51200/70535]
loss: 0.055180  [57600/70535]
loss: 0.085107  [64000/70535]
loss: 0.101052  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.117188 

Epoch 11
-------------------------------
loss: 0.038920  [    0/70535]
loss: 0.081451  [ 6400/70535]
loss: 0.160875  [12800/70535]
loss: 0.260249  [19200/70535]
loss: 0.028560  [25600/70535]
loss: 0.090027  [32000/70535]
loss: 0.165277  [38400/70535]
loss: 0.043446  [44800/70535]
loss: 0.072658  [51200/70535]
loss: 0.096481  [57600/70535]
loss: 0.173698  [64000/70535]
loss: 0.022717  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.116042 

Epoch 12
-------------------------------
loss: 0.052825  [    0/70535]
loss: 0.023562  [ 6400/70535]
loss: 0.079407  [12800/70535]
loss: 0.066143  [19200/70535]
loss: 0.051381  [25600/70535]
loss: 0.060450  [32000/70535]
loss: 0.075633  [38400/70535]
loss: 0.027550  [44800/70535]
loss: 0.017997  [51200/70535]
loss: 0.039963  [57600/70535]
loss: 0.059450  [64000/70535]
loss: 0.140420  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.118592 

Epoch 13
-------------------------------
loss: 0.061529  [    0/70535]
loss: 0.074622  [ 6400/70535]
loss: 0.283447  [12800/70535]
loss: 0.029136  [19200/70535]
loss: 0.035294  [25600/70535]
loss: 0.064637  [32000/70535]
loss: 0.027603  [38400/70535]
loss: 0.047093  [44800/70535]
loss: 0.035189  [51200/70535]
loss: 0.040109  [57600/70535]
loss: 0.062867  [64000/70535]
loss: 0.107607  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.124306 

Epoch 14
-------------------------------
loss: 0.070479  [    0/70535]
loss: 0.046326  [ 6400/70535]
loss: 0.062745  [12800/70535]
loss: 0.066401  [19200/70535]
loss: 0.145929  [25600/70535]
loss: 0.125135  [32000/70535]
loss: 0.074667  [38400/70535]
loss: 0.065300  [44800/70535]
loss: 0.065944  [51200/70535]
loss: 0.039375  [57600/70535]
loss: 0.123483  [64000/70535]
loss: 0.047750  [70400/70535]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.114882 

Epoch 15
-------------------------------
loss: 0.142947  [    0/70535]
loss: 0.028667  [ 6400/70535]
loss: 0.068709  [12800/70535]
loss: 0.080608  [19200/70535]
loss: 0.032897  [25600/70535]
loss: 0.084835  [32000/70535]
loss: 0.104508  [38400/70535]
loss: 0.078983  [44800/70535]
loss: 0.155756  [51200/70535]
loss: 0.190806  [57600/70535]
loss: 0.063143  [64000/70535]
loss: 0.032774  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.118136 

Epoch 16
-------------------------------
loss: 0.038789  [    0/70535]
loss: 0.040954  [ 6400/70535]
loss: 0.043467  [12800/70535]
loss: 0.038424  [19200/70535]
loss: 0.075816  [25600/70535]
loss: 0.087498  [32000/70535]
loss: 0.070164  [38400/70535]
loss: 0.150335  [44800/70535]
loss: 0.075735  [51200/70535]
loss: 0.087245  [57600/70535]
loss: 0.171881  [64000/70535]
loss: 0.067964  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.118656 

Epoch 17
-------------------------------
loss: 0.044137  [    0/70535]
loss: 0.036230  [ 6400/70535]
loss: 0.034594  [12800/70535]
loss: 0.032200  [19200/70535]
loss: 0.094188  [25600/70535]
loss: 0.034319  [32000/70535]
loss: 0.124698  [38400/70535]
loss: 0.060887  [44800/70535]
loss: 0.102567  [51200/70535]
loss: 0.094009  [57600/70535]
loss: 0.050053  [64000/70535]
loss: 0.216593  [70400/70535]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.148945 

Epoch 18
-------------------------------
loss: 0.082482  [    0/70535]
loss: 0.026303  [ 6400/70535]
loss: 0.052988  [12800/70535]
loss: 0.053808  [19200/70535]
loss: 0.095727  [25600/70535]
loss: 0.074008  [32000/70535]
loss: 0.056815  [38400/70535]
loss: 0.096672  [44800/70535]
loss: 0.093474  [51200/70535]
loss: 0.114790  [57600/70535]
loss: 0.135529  [64000/70535]
loss: 0.184173  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.118372 

Epoch 19
-------------------------------
Epoch 1
-------------------------------
loss: 0.865972  [    0/69247]
loss: 0.337088  [ 6400/69247]
loss: 1.767109  [12800/69247]
loss: 0.395022  [19200/69247]
loss: 0.322554  [25600/69247]
loss: 0.259729  [32000/69247]
loss: 0.237439  [38400/69247]
loss: 0.174863  [44800/69247]
loss: 0.317509  [51200/69247]
loss: 0.220066  [57600/69247]
loss: 0.209797  [64000/69247]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.199373 

Epoch 2
-------------------------------
loss: 0.219881  [    0/69247]
loss: 0.308221  [ 6400/69247]
loss: 0.314395  [12800/69247]
loss: 0.228561  [19200/69247]
loss: 0.210518  [25600/69247]
loss: 0.128871  [32000/69247]
loss: 0.139487  [38400/69247]
loss: 0.156755  [44800/69247]
loss: 0.136668  [51200/69247]
loss: 0.441174  [57600/69247]
loss: 0.192634  [64000/69247]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.183218 

Epoch 3
-------------------------------
loss: 0.180201  [    0/69247]
loss: 0.335953  [ 6400/69247]
loss: 0.173424  [12800/69247]
loss: 0.306899  [19200/69247]
loss: 0.150551  [25600/69247]
loss: 0.157682  [32000/69247]
loss: 0.132522  [38400/69247]
loss: 0.304129  [44800/69247]
loss: 0.137327  [51200/69247]
loss: 0.233520  [57600/69247]
loss: 0.188597  [64000/69247]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.176124 

Epoch 4
-------------------------------
loss: 0.313964  [    0/69247]
loss: 0.280458  [ 6400/69247]
loss: 0.158398  [12800/69247]
loss: 0.148220  [19200/69247]
loss: 0.145822  [25600/69247]
loss: 0.125285  [32000/69247]
loss: 0.247023  [38400/69247]
loss: 0.346814  [44800/69247]
loss: 0.221903  [51200/69247]
loss: 0.288013  [57600/69247]
loss: 0.083345  [64000/69247]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.183766 

Epoch 5
-------------------------------
loss: 0.170579  [    0/69247]
loss: 0.249005  [ 6400/69247]
loss: 0.163639  [12800/69247]
loss: 0.085180  [19200/69247]
loss: 0.217817  [25600/69247]
loss: 0.212796  [32000/69247]
loss: 0.062374  [38400/69247]
loss: 0.131562  [44800/69247]
loss: 0.143691  [51200/69247]
loss: 0.140574  [57600/69247]
loss: 0.206807  [64000/69247]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.176139 

Epoch 6
-------------------------------
loss: 0.135654  [    0/69247]
loss: 0.325009  [ 6400/69247]
loss: 0.092807  [12800/69247]
loss: 0.213007  [19200/69247]
loss: 0.179811  [25600/69247]
loss: 0.236942  [32000/69247]
loss: 0.231281  [38400/69247]
loss: 0.150577  [44800/69247]
loss: 0.227065  [51200/69247]
loss: 0.225088  [57600/69247]
loss: 0.157372  [64000/69247]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.169631 

Epoch 7
-------------------------------
loss: 0.189645  [    0/69247]
loss: 0.253878  [ 6400/69247]
loss: 0.133948  [12800/69247]
loss: 0.103943  [19200/69247]
loss: 0.087233  [25600/69247]
loss: 0.112848  [32000/69247]
loss: 0.177266  [38400/69247]
loss: 0.194644  [44800/69247]
loss: 0.115238  [51200/69247]
loss: 0.129076  [57600/69247]
loss: 0.136857  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.166954 

Epoch 8
-------------------------------
loss: 0.131096  [    0/69247]
loss: 0.117021  [ 6400/69247]
loss: 0.192062  [12800/69247]
loss: 0.301562  [19200/69247]
loss: 0.102386  [25600/69247]
loss: 0.139567  [32000/69247]
loss: 0.255801  [38400/69247]
loss: 0.124913  [44800/69247]
loss: 0.113504  [51200/69247]
loss: 0.148081  [57600/69247]
loss: 0.161235  [64000/69247]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.168721 

Epoch 9
-------------------------------
loss: 0.064508  [    0/69247]
loss: 0.162333  [ 6400/69247]
loss: 0.223881  [12800/69247]
loss: 0.204809  [19200/69247]
loss: 0.196498  [25600/69247]
loss: 0.186792  [32000/69247]
loss: 0.175381  [38400/69247]
loss: 0.238308  [44800/69247]
loss: 0.164874  [51200/69247]
loss: 0.135725  [57600/69247]
loss: 0.102784  [64000/69247]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.163865 

Epoch 10
-------------------------------
loss: 0.156652  [    0/69247]
loss: 0.063317  [ 6400/69247]
loss: 0.148872  [12800/69247]
loss: 0.132545  [19200/69247]
loss: 0.161729  [25600/69247]
loss: 0.213213  [32000/69247]
loss: 0.201354  [38400/69247]
loss: 0.121333  [44800/69247]
loss: 0.169055  [51200/69247]
loss: 0.138916  [57600/69247]
loss: 0.178395  [64000/69247]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.161455 

Epoch 11
-------------------------------
loss: 0.241108  [    0/69247]
loss: 0.166968  [ 6400/69247]
loss: 0.136832  [12800/69247]
loss: 0.135710  [19200/69247]
loss: 0.196170  [25600/69247]
loss: 0.097488  [32000/69247]
loss: 0.299591  [38400/69247]
loss: 0.212864  [44800/69247]
loss: 0.059563  [51200/69247]
loss: 0.240132  [57600/69247]
loss: 0.160293  [64000/69247]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.162210 

Epoch 12
-------------------------------
loss: 0.130885  [    0/69247]
loss: 0.147950  [ 6400/69247]
loss: 0.168151  [12800/69247]
loss: 0.083941  [19200/69247]
loss: 0.141775  [25600/69247]
loss: 0.139106  [32000/69247]
loss: 0.093013  [38400/69247]
loss: 0.173173  [44800/69247]
loss: 0.097932  [51200/69247]
loss: 0.150960  [57600/69247]
loss: 0.078922  [64000/69247]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.162441 

Epoch 13
-------------------------------
loss: 0.313319  [    0/69247]
loss: 0.152543  [ 6400/69247]
loss: 0.132293  [12800/69247]
loss: 0.152004  [19200/69247]
loss: 0.140931  [25600/69247]
loss: 0.099899  [32000/69247]
loss: 0.250609  [38400/69247]
loss: 0.196404  [44800/69247]
loss: 0.125391  [51200/69247]
loss: 0.251594  [57600/69247]
loss: 0.148008  [64000/69247]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.173893 

Epoch 14
-------------------------------
loss: 0.226361  [    0/69247]
loss: 0.171032  [ 6400/69247]
loss: 0.110178  [12800/69247]
loss: 0.117243  [19200/69247]
loss: 0.109281  [25600/69247]
loss: 0.185827  [32000/69247]
loss: 0.222247  [38400/69247]
loss: 0.116846  [44800/69247]
loss: 0.136668  [51200/69247]
loss: 0.226040  [57600/69247]
loss: 0.175070  [64000/69247]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.160519 

Epoch 15
-------------------------------
loss: 0.078768  [    0/69247]
loss: 0.153916  [ 6400/69247]
loss: 0.064316  [12800/69247]
loss: 0.128261  [19200/69247]
loss: 0.266520  [25600/69247]
loss: 0.197329  [32000/69247]
loss: 0.122413  [38400/69247]
loss: 0.346181  [44800/69247]
loss: 0.183790  [51200/69247]
loss: 0.086679  [57600/69247]
loss: 0.168924  [64000/69247]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.162199 

Epoch 16
-------------------------------
loss: 0.157930  [    0/69247]
loss: 0.308120  [ 6400/69247]
loss: 0.117029  [12800/69247]
loss: 0.161698  [19200/69247]
loss: 0.101401  [25600/69247]
loss: 0.096874  [32000/69247]
loss: 0.202843  [38400/69247]
loss: 0.205029  [44800/69247]
loss: 0.126069  [51200/69247]
loss: 0.089200  [57600/69247]
loss: 0.128928  [64000/69247]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.164021 

Epoch 17
-------------------------------
loss: 0.220020  [    0/69247]
loss: 0.064581  [ 6400/69247]
loss: 0.235002  [12800/69247]
loss: 0.070657  [19200/69247]
loss: 0.143671  [25600/69247]
loss: 0.140293  [32000/69247]
loss: 0.105005  [38400/69247]
loss: 0.117199  [44800/69247]
loss: 0.223877  [51200/69247]
loss: 0.095561  [57600/69247]
loss: 0.296845  [64000/69247]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.156681 

Epoch 18
-------------------------------
loss: 0.135694  [    0/69247]
loss: 0.220365  [ 6400/69247]
loss: 0.317596  [12800/69247]
loss: 0.193941  [19200/69247]
loss: 0.135061  [25600/69247]
loss: 0.132728  [32000/69247]
loss: 0.142010  [38400/69247]
loss: 0.176560  [44800/69247]
loss: 0.260733  [51200/69247]
loss: 0.169597  [57600/69247]
loss: 0.107391  [64000/69247]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.157203 

Epoch 19
-------------------------------
loss: 0.124347  [    0/69247]
loss: 0.089467  [ 6400/69247]
loss: 0.187388  [12800/69247]
loss: 0.158532  [19200/69247]
loss: 0.108005  [25600/69247]
loss: 0.089116  [32000/69247]
loss: 0.108646  [38400/69247]
loss: 0.175269  [44800/69247]
loss: 0.119790  [51200/69247]
loss: 0.206887  [57600/69247]
loss: 0.083105  [64000/69247]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.154667 

Epoch 20
-------------------------------
loss: 0.133402  [    0/69247]
loss: 0.143891  [ 6400/69247]
loss: 0.117276  [12800/69247]
loss: 0.064758  [19200/69247]
Epoch 1
-------------------------------
loss: 0.893299  [    0/69812]
loss: 0.186291  [ 6400/69812]
loss: 0.244344  [12800/69812]
loss: 0.164227  [19200/69812]
loss: 0.150721  [25600/69812]
loss: 0.087390  [32000/69812]
loss: 0.099446  [38400/69812]
loss: 0.177600  [44800/69812]
loss: 0.095106  [51200/69812]
loss: 0.073041  [57600/69812]
loss: 0.165340  [64000/69812]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.104945 

Epoch 2
-------------------------------
loss: 0.117077  [    0/69812]
loss: 0.114368  [ 6400/69812]
loss: 0.160558  [12800/69812]
loss: 0.047932  [19200/69812]
loss: 0.053864  [25600/69812]
loss: 0.037123  [32000/69812]
loss: 0.087177  [38400/69812]
loss: 0.018663  [44800/69812]
loss: 0.130474  [51200/69812]
loss: 0.026583  [57600/69812]
loss: 0.118558  [64000/69812]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.095183 

Epoch 3
-------------------------------
loss: 0.046699  [    0/69812]
loss: 0.071364  [ 6400/69812]
loss: 0.116306  [12800/69812]
loss: 0.098647  [19200/69812]
loss: 0.071416  [25600/69812]
loss: 0.165221  [32000/69812]
loss: 0.149961  [38400/69812]
loss: 0.106969  [44800/69812]
loss: 0.134814  [51200/69812]
loss: 0.031587  [57600/69812]
loss: 0.084660  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089538 

Epoch 4
-------------------------------
loss: 0.154511  [    0/69812]
loss: 0.052534  [ 6400/69812]
loss: 0.075675  [12800/69812]
loss: 0.139729  [19200/69812]
loss: 0.040360  [25600/69812]
loss: 0.103631  [32000/69812]
loss: 0.136382  [38400/69812]
loss: 0.084575  [44800/69812]
loss: 0.076052  [51200/69812]
loss: 0.099171  [57600/69812]
loss: 0.054066  [64000/69812]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.094330 

Epoch 5
-------------------------------
loss: 0.152333  [    0/69812]
loss: 0.014676  [ 6400/69812]
loss: 0.119012  [12800/69812]
loss: 0.206482  [19200/69812]
loss: 0.066559  [25600/69812]
loss: 0.118828  [32000/69812]
loss: 0.036133  [38400/69812]
loss: 0.080238  [44800/69812]
loss: 0.074995  [51200/69812]
loss: 0.163489  [57600/69812]
loss: 0.067025  [64000/69812]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.097995 

Epoch 6
-------------------------------
loss: 0.052092  [    0/69812]
loss: 0.096104  [ 6400/69812]
loss: 0.163791  [12800/69812]
loss: 0.018783  [19200/69812]
loss: 0.069500  [25600/69812]
loss: 0.127833  [32000/69812]
loss: 0.097145  [38400/69812]
loss: 0.072609  [44800/69812]
loss: 0.040688  [51200/69812]
loss: 0.082733  [57600/69812]
loss: 0.058808  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088296 

Epoch 7
-------------------------------
loss: 0.068944  [    0/69812]
loss: 0.180923  [ 6400/69812]
loss: 0.128411  [12800/69812]
loss: 0.037506  [19200/69812]
loss: 0.123174  [25600/69812]
loss: 0.028583  [32000/69812]
loss: 0.043491  [38400/69812]
loss: 0.135045  [44800/69812]
loss: 0.045596  [51200/69812]
loss: 0.079801  [57600/69812]
loss: 0.122987  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.087630 

Epoch 8
-------------------------------
loss: 0.076694  [    0/69812]
loss: 0.073380  [ 6400/69812]
loss: 0.022496  [12800/69812]
loss: 0.062308  [19200/69812]
loss: 0.059430  [25600/69812]
loss: 0.102354  [32000/69812]
loss: 0.119122  [38400/69812]
loss: 0.050728  [44800/69812]
loss: 0.022391  [51200/69812]
loss: 0.051843  [57600/69812]
loss: 0.072458  [64000/69812]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082944 

Epoch 9
-------------------------------
loss: 0.039706  [    0/69812]
loss: 0.043790  [ 6400/69812]
loss: 0.015074  [12800/69812]
loss: 0.071942  [19200/69812]
loss: 0.102573  [25600/69812]
loss: 0.026963  [32000/69812]
loss: 0.039079  [38400/69812]
loss: 0.120640  [44800/69812]
loss: 0.051757  [51200/69812]
loss: 0.105417  [57600/69812]
loss: 0.098925  [64000/69812]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.086934 

Epoch 10
-------------------------------
loss: 0.045178  [    0/69812]
loss: 0.127266  [ 6400/69812]
loss: 0.060034  [12800/69812]
loss: 0.075783  [19200/69812]
loss: 0.023079  [25600/69812]
loss: 0.112886  [32000/69812]
loss: 0.066789  [38400/69812]
loss: 0.032522  [44800/69812]
loss: 0.082282  [51200/69812]
loss: 0.050354  [57600/69812]
loss: 0.109169  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.092563 

Epoch 11
-------------------------------
loss: 0.085607  [    0/69812]
loss: 0.126415  [ 6400/69812]
loss: 0.115127  [12800/69812]
loss: 0.193505  [19200/69812]
loss: 0.077701  [25600/69812]
loss: 0.061569  [32000/69812]
loss: 0.024976  [38400/69812]
loss: 0.126005  [44800/69812]
loss: 0.134716  [51200/69812]
loss: 0.061859  [57600/69812]
loss: 0.170661  [64000/69812]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.085126 

Epoch 12
-------------------------------
loss: 0.053274  [    0/69812]
loss: 0.093577  [ 6400/69812]
loss: 0.074741  [12800/69812]
loss: 0.102105  [19200/69812]
loss: 0.052796  [25600/69812]
loss: 0.117977  [32000/69812]
loss: 0.112970  [38400/69812]
loss: 0.144102  [44800/69812]
loss: 0.073988  [51200/69812]
loss: 0.099569  [57600/69812]
loss: 0.155043  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086274 

Epoch 13
-------------------------------
loss: 0.039990  [    0/69812]
loss: 0.072201  [ 6400/69812]
loss: 0.062212  [12800/69812]
loss: 0.104029  [19200/69812]
loss: 0.074182  [25600/69812]
loss: 0.068614  [32000/69812]
loss: 0.128045  [38400/69812]
loss: 0.066502  [44800/69812]
loss: 0.061810  [51200/69812]
loss: 0.125598  [57600/69812]
loss: 0.052603  [64000/69812]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.087623 

Epoch 14
-------------------------------
loss: 0.063450  [    0/69812]
loss: 0.060147  [ 6400/69812]
loss: 0.108880  [12800/69812]
loss: 0.125184  [19200/69812]
loss: 0.086711  [25600/69812]
loss: 0.051603  [32000/69812]
loss: 0.043590  [38400/69812]
loss: 0.144828  [44800/69812]
loss: 0.056963  [51200/69812]
loss: 0.124573  [57600/69812]
loss: 0.030647  [64000/69812]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083888 

Epoch 15
-------------------------------
loss: 0.064506  [    0/69812]
loss: 0.033311  [ 6400/69812]
loss: 0.060271  [12800/69812]
loss: 0.094600  [19200/69812]
loss: 0.090328  [25600/69812]
loss: 0.105113  [32000/69812]
loss: 0.255953  [38400/69812]
loss: 0.109085  [44800/69812]
loss: 0.041635  [51200/69812]
loss: 0.051755  [57600/69812]
loss: 0.051065  [64000/69812]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082887 

Epoch 16
-------------------------------
loss: 0.083210  [    0/69812]
loss: 0.019631  [ 6400/69812]
loss: 0.108463  [12800/69812]
loss: 0.173098  [19200/69812]
loss: 0.044336  [25600/69812]
loss: 0.018535  [32000/69812]
loss: 0.069695  [38400/69812]
loss: 0.026911  [44800/69812]
loss: 0.082512  [51200/69812]
loss: 0.064145  [57600/69812]
loss: 0.012019  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.087138 

Epoch 17
-------------------------------
loss: 0.082637  [    0/69812]
loss: 0.091342  [ 6400/69812]
loss: 0.081779  [12800/69812]
loss: 0.055477  [19200/69812]
loss: 0.034417  [25600/69812]
loss: 0.055982  [32000/69812]
loss: 0.048283  [38400/69812]
loss: 0.047470  [44800/69812]
loss: 0.044141  [51200/69812]
loss: 0.114362  [57600/69812]
loss: 0.079528  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089608 

Epoch 18
-------------------------------
loss: 0.052985  [    0/69812]
loss: 0.061585  [ 6400/69812]
loss: 0.112353  [12800/69812]
loss: 0.079045  [19200/69812]
loss: 0.144257  [25600/69812]
loss: 0.027442  [32000/69812]
loss: 0.086828  [38400/69812]
loss: 0.076520  [44800/69812]
loss: 0.164972  [51200/69812]
loss: 0.064436  [57600/69812]
loss: 0.235022  [64000/69812]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.091940 

Epoch 19
-------------------------------
loss: 0.071315  [    0/69812]
loss: 0.151973  [ 6400/69812]
loss: 0.039113  [12800/69812]
loss: 0.090943  [19200/69812]
loss: 0.057097  [25600/69812]
loss: 0.052340  [32000/69812]
loss: 0.132261  [38400/69812]
loss: 0.084161  [44800/69812]
loss: 0.150069  [51200/69812]
loss: 0.058259  [57600/69812]
loss: 0.076340  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.091785 

Epoch 20
-------------------------------
loss: 0.028789  [    0/69812]
loss: 0.267410  [ 6400/69812]
loss: 0.084250  [12800/69812]
loss: 0.081962  [19200/69812]
Epoch 1
-------------------------------
loss: 0.998120  [    0/70165]
loss: 0.094757  [ 6400/70165]
loss: 0.233311  [12800/70165]
loss: 0.295333  [19200/70165]
loss: 0.167716  [25600/70165]
loss: 0.047180  [32000/70165]
loss: 0.187137  [38400/70165]
loss: 0.103537  [44800/70165]
loss: 0.132180  [51200/70165]
loss: 0.037834  [57600/70165]
loss: 0.238551  [64000/70165]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.106846 

Epoch 2
-------------------------------
loss: 0.085638  [    0/70165]
loss: 0.214113  [ 6400/70165]
loss: 0.078144  [12800/70165]
loss: 0.024570  [19200/70165]
loss: 0.081853  [25600/70165]
loss: 0.099248  [32000/70165]
loss: 0.096193  [38400/70165]
loss: 0.120420  [44800/70165]
loss: 0.092134  [51200/70165]
loss: 0.090448  [57600/70165]
loss: 0.012686  [64000/70165]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.096550 

Epoch 3
-------------------------------
loss: 0.066932  [    0/70165]
loss: 0.042918  [ 6400/70165]
loss: 0.129551  [12800/70165]
loss: 0.061441  [19200/70165]
loss: 0.103541  [25600/70165]
loss: 0.075999  [32000/70165]
loss: 0.171570  [38400/70165]
loss: 0.135669  [44800/70165]
loss: 0.089866  [51200/70165]
loss: 0.055488  [57600/70165]
loss: 0.041466  [64000/70165]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.087036 

Epoch 4
-------------------------------
loss: 0.172761  [    0/70165]
loss: 0.104986  [ 6400/70165]
loss: 0.092001  [12800/70165]
loss: 0.033539  [19200/70165]
loss: 0.080173  [25600/70165]
loss: 0.065975  [32000/70165]
loss: 0.122743  [38400/70165]
loss: 0.029158  [44800/70165]
loss: 0.134605  [51200/70165]
loss: 0.114773  [57600/70165]
loss: 0.051247  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.073537 

Epoch 5
-------------------------------
loss: 0.035116  [    0/70165]
loss: 0.170382  [ 6400/70165]
loss: 0.324973  [12800/70165]
loss: 0.052826  [19200/70165]
loss: 0.055394  [25600/70165]
loss: 0.116108  [32000/70165]
loss: 0.041909  [38400/70165]
loss: 0.039532  [44800/70165]
loss: 0.158854  [51200/70165]
loss: 0.045275  [57600/70165]
loss: 0.144587  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.076383 

Epoch 6
-------------------------------
loss: 0.069803  [    0/70165]
loss: 0.175644  [ 6400/70165]
loss: 0.052308  [12800/70165]
loss: 0.025324  [19200/70165]
loss: 0.069144  [25600/70165]
loss: 0.030230  [32000/70165]
loss: 0.046391  [38400/70165]
loss: 0.196160  [44800/70165]
loss: 0.082833  [51200/70165]
loss: 0.059023  [57600/70165]
loss: 0.052920  [64000/70165]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.080930 

Epoch 7
-------------------------------
loss: 0.110507  [    0/70165]
loss: 0.050750  [ 6400/70165]
loss: 0.038077  [12800/70165]
loss: 0.042638  [19200/70165]
loss: 0.044036  [25600/70165]
loss: 0.123125  [32000/70165]
loss: 0.066268  [38400/70165]
loss: 0.080637  [44800/70165]
loss: 0.043543  [51200/70165]
loss: 0.090838  [57600/70165]
loss: 0.111761  [64000/70165]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.078075 

Epoch 8
-------------------------------
loss: 0.080508  [    0/70165]
loss: 0.013168  [ 6400/70165]
loss: 0.124937  [12800/70165]
loss: 0.032441  [19200/70165]
loss: 0.110284  [25600/70165]
loss: 0.120736  [32000/70165]
loss: 0.059956  [38400/70165]
loss: 0.142340  [44800/70165]
loss: 0.056852  [51200/70165]
loss: 0.092442  [57600/70165]
loss: 0.021404  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.073613 

Epoch 9
-------------------------------
loss: 0.059186  [    0/70165]
loss: 0.053211  [ 6400/70165]
loss: 0.022662  [12800/70165]
loss: 0.090182  [19200/70165]
loss: 0.078176  [25600/70165]
loss: 0.037726  [32000/70165]
loss: 0.063811  [38400/70165]
loss: 0.120942  [44800/70165]
loss: 0.062885  [51200/70165]
loss: 0.154284  [57600/70165]
loss: 0.097042  [64000/70165]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.070738 

Epoch 10
-------------------------------
loss: 0.076929  [    0/70165]
loss: 0.037356  [ 6400/70165]
loss: 0.155207  [12800/70165]
loss: 0.047563  [19200/70165]
loss: 0.068407  [25600/70165]
loss: 0.104267  [32000/70165]
loss: 0.081422  [38400/70165]
loss: 0.017656  [44800/70165]
loss: 0.125582  [51200/70165]
loss: 0.078535  [57600/70165]
loss: 0.065603  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.075564 

Epoch 11
-------------------------------
loss: 0.051859  [    0/70165]
loss: 0.138134  [ 6400/70165]
loss: 0.081121  [12800/70165]
loss: 0.023924  [19200/70165]
loss: 0.098126  [25600/70165]
loss: 0.067736  [32000/70165]
loss: 0.041577  [38400/70165]
loss: 0.196732  [44800/70165]
loss: 0.020148  [51200/70165]
loss: 0.184943  [57600/70165]
loss: 0.040778  [64000/70165]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.069164 

Epoch 12
-------------------------------
loss: 0.090727  [    0/70165]
loss: 0.022543  [ 6400/70165]
loss: 0.040549  [12800/70165]
loss: 0.059467  [19200/70165]
loss: 0.061699  [25600/70165]
loss: 0.143466  [32000/70165]
loss: 0.060968  [38400/70165]
loss: 0.040401  [44800/70165]
loss: 0.090378  [51200/70165]
loss: 0.022626  [57600/70165]
loss: 0.065884  [64000/70165]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.069382 

Epoch 13
-------------------------------
loss: 0.085495  [    0/70165]
loss: 0.079300  [ 6400/70165]
loss: 0.029347  [12800/70165]
loss: 0.062511  [19200/70165]
loss: 0.049249  [25600/70165]
loss: 0.053593  [32000/70165]
loss: 0.144840  [38400/70165]
loss: 0.117017  [44800/70165]
loss: 0.175016  [51200/70165]
loss: 0.058024  [57600/70165]
loss: 0.050902  [64000/70165]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.078281 

Epoch 14
-------------------------------
loss: 0.054533  [    0/70165]
loss: 0.194329  [ 6400/70165]
loss: 0.134866  [12800/70165]
loss: 0.053244  [19200/70165]
loss: 0.115062  [25600/70165]
loss: 0.070512  [32000/70165]
loss: 0.047623  [38400/70165]
loss: 0.061534  [44800/70165]
loss: 0.096468  [51200/70165]
loss: 0.069202  [57600/70165]
loss: 0.053886  [64000/70165]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.071909 

Epoch 15
-------------------------------
loss: 0.090810  [    0/70165]
loss: 0.058137  [ 6400/70165]
loss: 0.055839  [12800/70165]
loss: 0.055817  [19200/70165]
loss: 0.024079  [25600/70165]
loss: 0.028067  [32000/70165]
loss: 0.090961  [38400/70165]
loss: 0.119070  [44800/70165]
loss: 0.019978  [51200/70165]
loss: 0.041183  [57600/70165]
loss: 0.065369  [64000/70165]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.083602 

Epoch 16
-------------------------------
loss: 0.048703  [    0/70165]
loss: 0.044028  [ 6400/70165]
loss: 0.017106  [12800/70165]
loss: 0.052279  [19200/70165]
loss: 0.030403  [25600/70165]
loss: 0.062557  [32000/70165]
loss: 0.104379  [38400/70165]
loss: 0.113323  [44800/70165]
loss: 0.070108  [51200/70165]
loss: 0.164050  [57600/70165]
loss: 0.076732  [64000/70165]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.072012 

Epoch 17
-------------------------------
loss: 0.018535  [    0/70165]
loss: 0.079447  [ 6400/70165]
loss: 0.142218  [12800/70165]
loss: 0.043297  [19200/70165]
loss: 0.159292  [25600/70165]
loss: 0.135440  [32000/70165]
loss: 0.141275  [38400/70165]
loss: 0.070832  [44800/70165]
loss: 0.017728  [51200/70165]
loss: 0.101981  [57600/70165]
loss: 0.049174  [64000/70165]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.080038 

Epoch 18
-------------------------------
loss: 0.104317  [    0/70165]
loss: 0.061332  [ 6400/70165]
loss: 0.043239  [12800/70165]
loss: 0.054434  [19200/70165]
loss: 0.032664  [25600/70165]
loss: 0.025396  [32000/70165]
loss: 0.020463  [38400/70165]
loss: 0.156354  [44800/70165]
loss: 0.052652  [51200/70165]
loss: 0.050620  [57600/70165]
loss: 0.014896  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.076000 

Epoch 19
-------------------------------
loss: 0.061777  [    0/70165]
loss: 0.076157  [ 6400/70165]
loss: 0.050215  [12800/70165]
loss: 0.080855  [19200/70165]
loss: 0.051155  [25600/70165]
loss: 0.017882  [32000/70165]
loss: 0.015932  [38400/70165]
loss: 0.048659  [44800/70165]
loss: 0.058930  [51200/70165]
loss: 0.038109  [57600/70165]
loss: 0.038069  [64000/70165]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.093803 

Epoch 20
-------------------------------
loss: 0.042024  [    0/70165]
loss: 0.038991  [ 6400/70165]
loss: 0.039026  [12800/70165]
loss: 0.116349  [19200/70165]
loss: 0.052087  [    0/72281]
loss: 0.003968  [ 6400/72281]
loss: 0.054844  [12800/72281]
loss: 0.027548  [19200/72281]
loss: 0.014285  [25600/72281]
loss: 0.042848  [32000/72281]
loss: 0.068305  [38400/72281]
loss: 0.077852  [44800/72281]
loss: 0.003136  [51200/72281]
loss: 0.060142  [57600/72281]
loss: 0.030058  [64000/72281]
loss: 0.037100  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.084128 

Epoch 20
-------------------------------
loss: 0.053469  [    0/72281]
loss: 0.044911  [ 6400/72281]
loss: 0.019474  [12800/72281]
loss: 0.006017  [19200/72281]
loss: 0.105707  [25600/72281]
loss: 0.016489  [32000/72281]
loss: 0.022209  [38400/72281]
loss: 0.020592  [44800/72281]
loss: 0.039296  [51200/72281]
loss: 0.009679  [57600/72281]
loss: 0.058090  [64000/72281]
loss: 0.029264  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.082271 

Epoch 21
-------------------------------
loss: 0.041000  [    0/72281]
loss: 0.017691  [ 6400/72281]
loss: 0.033045  [12800/72281]
loss: 0.028346  [19200/72281]
loss: 0.044127  [25600/72281]
loss: 0.006509  [32000/72281]
loss: 0.004631  [38400/72281]
loss: 0.062901  [44800/72281]
loss: 0.043218  [51200/72281]
loss: 0.079620  [57600/72281]
loss: 0.043470  [64000/72281]
loss: 0.012759  [70400/72281]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.084190 

Epoch 22
-------------------------------
loss: 0.098715  [    0/72281]
loss: 0.021660  [ 6400/72281]
loss: 0.010143  [12800/72281]
loss: 0.031009  [19200/72281]
loss: 0.035128  [25600/72281]
loss: 0.060455  [32000/72281]
loss: 0.009432  [38400/72281]
loss: 0.073159  [44800/72281]
loss: 0.023764  [51200/72281]
loss: 0.271647  [57600/72281]
loss: 0.037400  [64000/72281]
loss: 0.023900  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.091163 

Epoch 23
-------------------------------
loss: 0.035753  [    0/72281]
loss: 0.019948  [ 6400/72281]
loss: 0.022399  [12800/72281]
loss: 0.077189  [19200/72281]
loss: 0.034734  [25600/72281]
loss: 0.073531  [32000/72281]
loss: 0.053371  [38400/72281]
loss: 0.014008  [44800/72281]
loss: 0.075845  [51200/72281]
loss: 0.002840  [57600/72281]
loss: 0.021736  [64000/72281]
loss: 0.011226  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.083169 

Epoch 24
-------------------------------
loss: 0.036017  [    0/72281]
loss: 0.178834  [ 6400/72281]
loss: 0.004750  [12800/72281]
loss: 0.001230  [19200/72281]
loss: 0.074253  [25600/72281]
loss: 0.021066  [32000/72281]
loss: 0.016528  [38400/72281]
loss: 0.018666  [44800/72281]
loss: 0.044223  [51200/72281]
loss: 0.002328  [57600/72281]
loss: 0.017743  [64000/72281]
loss: 0.036381  [70400/72281]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.089400 

Epoch 25
-------------------------------
loss: 0.027393  [    0/72281]
loss: 0.015171  [ 6400/72281]
loss: 0.015616  [12800/72281]
loss: 0.009201  [19200/72281]
loss: 0.025220  [25600/72281]
loss: 0.004982  [32000/72281]
loss: 0.018442  [38400/72281]
loss: 0.013487  [44800/72281]
loss: 0.007165  [51200/72281]
loss: 0.004740  [57600/72281]
loss: 0.045990  [64000/72281]
loss: 0.017784  [70400/72281]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.080147 

Epoch 26
-------------------------------
loss: 0.033332  [    0/72281]
loss: 0.034452  [ 6400/72281]
loss: 0.033602  [12800/72281]
loss: 0.002777  [19200/72281]
loss: 0.006965  [25600/72281]
loss: 0.015953  [32000/72281]
loss: 0.080335  [38400/72281]
loss: 0.003411  [44800/72281]
loss: 0.018454  [51200/72281]
loss: 0.089135  [57600/72281]
loss: 1.580853  [64000/72281]
loss: 1.570443  [70400/72281]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.085884 

Epoch 27
-------------------------------
loss: 0.163406  [    0/72281]
loss: 0.006891  [ 6400/72281]
loss: 0.010322  [12800/72281]
loss: 0.017901  [19200/72281]
loss: 0.003675  [25600/72281]
loss: 0.048862  [32000/72281]
loss: 0.012527  [38400/72281]
loss: 0.039068  [44800/72281]
loss: 0.007253  [51200/72281]
loss: 0.062502  [57600/72281]
loss: 0.011688  [64000/72281]
loss: 0.010978  [70400/72281]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.095188 

Epoch 28
-------------------------------
loss: 0.023169  [    0/72281]
loss: 0.008082  [ 6400/72281]
loss: 0.017213  [12800/72281]
loss: 0.037868  [19200/72281]
loss: 0.012882  [25600/72281]
loss: 0.054004  [32000/72281]
loss: 0.010223  [38400/72281]
loss: 0.017571  [44800/72281]
loss: 0.004491  [51200/72281]
loss: 0.008897  [57600/72281]
loss: 0.044146  [64000/72281]
loss: 0.033941  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.092784 

Epoch 29
-------------------------------
loss: 0.013982  [    0/72281]
loss: 0.073328  [ 6400/72281]
loss: 0.013358  [12800/72281]
loss: 0.043468  [19200/72281]
loss: 0.046927  [25600/72281]
loss: 0.032189  [32000/72281]
loss: 0.007458  [38400/72281]
loss: 0.008355  [44800/72281]
loss: 0.118584  [51200/72281]
loss: 0.001925  [57600/72281]
loss: 0.017745  [64000/72281]
loss: 0.010055  [70400/72281]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.086110 

Epoch 30
-------------------------------
loss: 0.015248  [    0/72281]
loss: 0.017311  [ 6400/72281]
loss: 0.016665  [12800/72281]
loss: 0.016194  [19200/72281]
loss: 0.121270  [25600/72281]
loss: 0.010328  [32000/72281]
loss: 0.056765  [38400/72281]
loss: 0.001132  [44800/72281]
loss: 0.013649  [51200/72281]
loss: 0.002955  [57600/72281]
loss: 0.074422  [64000/72281]
loss: 0.058594  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.089024 

Epoch 31
-------------------------------
loss: 0.005235  [    0/72281]
loss: 0.009181  [ 6400/72281]
loss: 0.013306  [12800/72281]
loss: 0.010128  [19200/72281]
loss: 0.030503  [25600/72281]
loss: 0.084060  [32000/72281]
loss: 0.030050  [38400/72281]
loss: 0.004610  [44800/72281]
loss: 0.045281  [51200/72281]
loss: 0.003997  [57600/72281]
loss: 0.011319  [64000/72281]
loss: 0.060516  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.086420 

Epoch 32
-------------------------------
loss: 1.597825  [    0/72281]
loss: 0.003546  [ 6400/72281]
loss: 0.039257  [12800/72281]
loss: 0.026680  [19200/72281]
loss: 0.006861  [25600/72281]
loss: 0.020741  [32000/72281]
loss: 0.049960  [38400/72281]
loss: 0.004219  [44800/72281]
loss: 0.007456  [51200/72281]
loss: 0.023147  [57600/72281]
loss: 0.055274  [64000/72281]
loss: 0.031274  [70400/72281]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.104591 

Epoch 33
-------------------------------
loss: 0.047088  [    0/72281]
loss: 0.003897  [ 6400/72281]
loss: 0.055560  [12800/72281]
loss: 0.035101  [19200/72281]
loss: 0.008629  [25600/72281]
loss: 0.012761  [32000/72281]
loss: 0.042387  [38400/72281]
loss: 0.058433  [44800/72281]
loss: 0.014735  [51200/72281]
loss: 0.029661  [57600/72281]
loss: 0.066937  [64000/72281]
loss: 0.002912  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.093114 

Epoch 34
-------------------------------
loss: 0.071716  [    0/72281]
loss: 0.024361  [ 6400/72281]
loss: 0.008203  [12800/72281]
loss: 0.009331  [19200/72281]
loss: 0.005738  [25600/72281]
loss: 0.021296  [32000/72281]
loss: 0.064079  [38400/72281]
loss: 0.007293  [44800/72281]
loss: 0.013383  [51200/72281]
loss: 0.073882  [57600/72281]
loss: 0.065258  [64000/72281]
loss: 0.176106  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.084785 

Epoch 35
-------------------------------
loss: 0.002116  [    0/72281]
loss: 0.012205  [ 6400/72281]
loss: 0.003340  [12800/72281]
loss: 0.064933  [19200/72281]
loss: 0.079313  [25600/72281]
loss: 0.019191  [32000/72281]
loss: 0.065237  [38400/72281]
loss: 0.072534  [44800/72281]
loss: 0.011865  [51200/72281]
loss: 0.018743  [57600/72281]
loss: 0.041157  [64000/72281]
loss: 0.011730  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.087938 

Epoch 36
-------------------------------
loss: 0.011755  [    0/72281]
loss: 0.004419  [ 6400/72281]
loss: 0.011181  [12800/72281]
loss: 0.014421  [19200/72281]
loss: 0.067817  [25600/72281]
loss: 0.079406  [32000/72281]
loss: 0.004344  [38400/72281]
loss: 0.047255  [44800/72281]
loss: 0.002113  [51200/72281]
loss: 0.011309  [57600/72281]
loss: 0.032405  [64000/72281]
loss: 0.002825  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.087342 

Epoch 37
-------------------------------
loss: 0.046045  [    0/72281]
loss: 0.054364  [    0/70880]
loss: 0.029386  [ 6400/70880]
loss: 0.023830  [12800/70880]
loss: 0.029812  [19200/70880]
loss: 0.044288  [25600/70880]
loss: 0.017509  [32000/70880]
loss: 0.022653  [38400/70880]
loss: 0.010894  [44800/70880]
loss: 0.069234  [51200/70880]
loss: 0.028965  [57600/70880]
loss: 0.038475  [64000/70880]
loss: 0.026352  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.080597 

Epoch 20
-------------------------------
loss: 0.079313  [    0/70880]
loss: 0.004981  [ 6400/70880]
loss: 0.039227  [12800/70880]
loss: 0.071714  [19200/70880]
loss: 0.017922  [25600/70880]
loss: 0.008287  [32000/70880]
loss: 0.018509  [38400/70880]
loss: 0.012097  [44800/70880]
loss: 0.029186  [51200/70880]
loss: 0.089401  [57600/70880]
loss: 0.015353  [64000/70880]
loss: 0.102952  [70400/70880]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.088739 

Epoch 21
-------------------------------
loss: 0.013739  [    0/70880]
loss: 0.007971  [ 6400/70880]
loss: 0.110610  [12800/70880]
loss: 0.034512  [19200/70880]
loss: 0.037666  [25600/70880]
loss: 0.096237  [32000/70880]
loss: 0.039093  [38400/70880]
loss: 0.043869  [44800/70880]
loss: 0.049047  [51200/70880]
loss: 0.205933  [57600/70880]
loss: 0.061142  [64000/70880]
loss: 0.019169  [70400/70880]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.084657 

Epoch 22
-------------------------------
loss: 0.066389  [    0/70880]
loss: 0.029791  [ 6400/70880]
loss: 0.003700  [12800/70880]
loss: 0.053742  [19200/70880]
loss: 0.025246  [25600/70880]
loss: 0.018749  [32000/70880]
loss: 0.112534  [38400/70880]
loss: 0.100956  [44800/70880]
loss: 0.002959  [51200/70880]
loss: 0.044474  [57600/70880]
loss: 0.102169  [64000/70880]
loss: 0.048855  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.083897 

Epoch 23
-------------------------------
loss: 0.041281  [    0/70880]
loss: 0.151422  [ 6400/70880]
loss: 0.023738  [12800/70880]
loss: 0.075726  [19200/70880]
loss: 0.072442  [25600/70880]
loss: 0.078998  [32000/70880]
loss: 0.041083  [38400/70880]
loss: 0.022625  [44800/70880]
loss: 0.041943  [51200/70880]
loss: 0.062041  [57600/70880]
loss: 0.030909  [64000/70880]
loss: 0.092020  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.096371 

Epoch 24
-------------------------------
loss: 0.015753  [    0/70880]
loss: 0.071909  [ 6400/70880]
loss: 0.035433  [12800/70880]
loss: 0.025118  [19200/70880]
loss: 0.042450  [25600/70880]
loss: 0.130949  [32000/70880]
loss: 0.030377  [38400/70880]
loss: 0.010944  [44800/70880]
loss: 0.019391  [51200/70880]
loss: 0.009555  [57600/70880]
loss: 0.026207  [64000/70880]
loss: 0.018472  [70400/70880]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.094125 

Epoch 25
-------------------------------
loss: 0.037657  [    0/70880]
loss: 0.059847  [ 6400/70880]
loss: 0.020835  [12800/70880]
loss: 0.013946  [19200/70880]
loss: 0.028902  [25600/70880]
loss: 0.119020  [32000/70880]
loss: 0.018217  [38400/70880]
loss: 0.042779  [44800/70880]
loss: 0.017045  [51200/70880]
loss: 0.018814  [57600/70880]
loss: 0.035351  [64000/70880]
loss: 0.012395  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.090458 

Epoch 26
-------------------------------
loss: 0.012018  [    0/70880]
loss: 0.021901  [ 6400/70880]
loss: 0.265058  [12800/70880]
loss: 0.050502  [19200/70880]
loss: 0.059301  [25600/70880]
loss: 0.025702  [32000/70880]
loss: 0.042294  [38400/70880]
loss: 0.018228  [44800/70880]
loss: 0.059914  [51200/70880]
loss: 0.111399  [57600/70880]
loss: 0.049314  [64000/70880]
loss: 0.055991  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.094105 

Epoch 27
-------------------------------
loss: 0.052656  [    0/70880]
loss: 0.019139  [ 6400/70880]
loss: 0.032904  [12800/70880]
loss: 0.041482  [19200/70880]
loss: 0.093581  [25600/70880]
loss: 0.030717  [32000/70880]
loss: 0.012924  [38400/70880]
loss: 0.117298  [44800/70880]
loss: 0.007061  [51200/70880]
loss: 0.148265  [57600/70880]
loss: 0.053386  [64000/70880]
loss: 0.026038  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.097796 

Epoch 28
-------------------------------
loss: 0.028607  [    0/70880]
loss: 0.030646  [ 6400/70880]
loss: 0.006409  [12800/70880]
loss: 0.043505  [19200/70880]
loss: 0.083565  [25600/70880]
loss: 0.090048  [32000/70880]
loss: 0.121038  [38400/70880]
loss: 1.583125  [44800/70880]
loss: 0.002911  [51200/70880]
loss: 0.024739  [57600/70880]
loss: 0.013655  [64000/70880]
loss: 0.044881  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.091301 

Epoch 29
-------------------------------
loss: 0.048599  [    0/70880]
loss: 0.007440  [ 6400/70880]
loss: 0.076979  [12800/70880]
loss: 0.031671  [19200/70880]
loss: 0.107467  [25600/70880]
loss: 0.034395  [32000/70880]
loss: 0.046281  [38400/70880]
loss: 0.016242  [44800/70880]
loss: 0.018861  [51200/70880]
loss: 0.053403  [57600/70880]
loss: 0.084867  [64000/70880]
loss: 0.020316  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.106732 

Epoch 30
-------------------------------
loss: 0.006538  [    0/70880]
loss: 0.095171  [ 6400/70880]
loss: 0.026064  [12800/70880]
loss: 0.061509  [19200/70880]
loss: 0.115167  [25600/70880]
loss: 0.041722  [32000/70880]
loss: 0.060876  [38400/70880]
loss: 0.122629  [44800/70880]
loss: 0.002746  [51200/70880]
loss: 0.025282  [57600/70880]
loss: 0.089187  [64000/70880]
loss: 0.007420  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.082910 

Epoch 31
-------------------------------
loss: 0.046607  [    0/70880]
loss: 0.017815  [ 6400/70880]
loss: 0.024435  [12800/70880]
loss: 0.040105  [19200/70880]
loss: 0.050980  [25600/70880]
loss: 0.104749  [32000/70880]
loss: 0.008644  [38400/70880]
loss: 0.014007  [44800/70880]
loss: 0.012964  [51200/70880]
loss: 0.048479  [57600/70880]
loss: 0.012162  [64000/70880]
loss: 0.046536  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.089517 

Epoch 32
-------------------------------
loss: 0.027576  [    0/70880]
loss: 0.057365  [ 6400/70880]
loss: 0.065127  [12800/70880]
loss: 0.073363  [19200/70880]
loss: 0.013118  [25600/70880]
loss: 0.115625  [32000/70880]
loss: 0.077985  [38400/70880]
loss: 0.010621  [44800/70880]
loss: 0.030976  [51200/70880]
loss: 0.014196  [57600/70880]
loss: 0.023210  [64000/70880]
loss: 0.064246  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.092527 

Epoch 33
-------------------------------
loss: 0.030243  [    0/70880]
loss: 0.009517  [ 6400/70880]
loss: 0.012359  [12800/70880]
loss: 0.009899  [19200/70880]
loss: 0.004178  [25600/70880]
loss: 0.019061  [32000/70880]
loss: 0.034563  [38400/70880]
loss: 0.008847  [44800/70880]
loss: 0.070660  [51200/70880]
loss: 0.168547  [57600/70880]
loss: 0.016662  [64000/70880]
loss: 0.022517  [70400/70880]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.098858 

Epoch 34
-------------------------------
loss: 0.031477  [    0/70880]
loss: 0.018837  [ 6400/70880]
loss: 0.068041  [12800/70880]
loss: 0.011718  [19200/70880]
loss: 0.044632  [25600/70880]
loss: 0.018214  [32000/70880]
loss: 0.013610  [38400/70880]
loss: 0.020106  [44800/70880]
loss: 0.124327  [51200/70880]
loss: 0.016148  [57600/70880]
loss: 0.026291  [64000/70880]
loss: 0.051135  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.105001 

Epoch 35
-------------------------------
loss: 0.059123  [    0/70880]
loss: 0.019011  [ 6400/70880]
loss: 0.038711  [12800/70880]
loss: 0.046015  [19200/70880]
loss: 0.001882  [25600/70880]
loss: 0.004317  [32000/70880]
loss: 0.038876  [38400/70880]
loss: 0.003629  [44800/70880]
loss: 0.028183  [51200/70880]
loss: 0.109186  [57600/70880]
loss: 0.042118  [64000/70880]
loss: 0.004367  [70400/70880]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.113545 

Epoch 36
-------------------------------
loss: 0.151176  [    0/70880]
loss: 0.128647  [ 6400/70880]
loss: 0.015719  [12800/70880]
loss: 0.145153  [19200/70880]
loss: 0.025409  [25600/70880]
loss: 0.008726  [32000/70880]
loss: 0.039498  [38400/70880]
loss: 0.074524  [44800/70880]
loss: 0.021169  [51200/70880]
loss: 0.000372  [57600/70880]
loss: 0.032634  [64000/70880]
loss: 0.134523  [70400/70880]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.090713 

Epoch 37
-------------------------------
loss: 0.048572  [    0/70880]
loss: 0.004972  [    0/71625]
loss: 0.067497  [ 6400/71625]
loss: 0.084264  [12800/71625]
loss: 0.003917  [19200/71625]
loss: 0.026288  [25600/71625]
loss: 0.045543  [32000/71625]
loss: 0.015648  [38400/71625]
loss: 0.008534  [44800/71625]
loss: 0.042626  [51200/71625]
loss: 0.008439  [57600/71625]
loss: 0.003878  [64000/71625]
loss: 0.023371  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.043064 

Epoch 20
-------------------------------
loss: 0.012393  [    0/71625]
loss: 0.005598  [ 6400/71625]
loss: 0.002895  [12800/71625]
loss: 0.013198  [19200/71625]
loss: 0.010240  [25600/71625]
loss: 0.013889  [32000/71625]
loss: 0.011946  [38400/71625]
loss: 0.014931  [44800/71625]
loss: 0.023137  [51200/71625]
loss: 0.014458  [57600/71625]
loss: 0.028446  [64000/71625]
loss: 0.039732  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.047041 

Epoch 21
-------------------------------
loss: 0.002167  [    0/71625]
loss: 0.007582  [ 6400/71625]
loss: 0.018621  [12800/71625]
loss: 0.071457  [19200/71625]
loss: 0.019001  [25600/71625]
loss: 0.004152  [32000/71625]
loss: 0.012681  [38400/71625]
loss: 0.002686  [44800/71625]
loss: 0.011365  [51200/71625]
loss: 0.054695  [57600/71625]
loss: 0.039211  [64000/71625]
loss: 0.012007  [70400/71625]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.040316 

Epoch 22
-------------------------------
loss: 0.166526  [    0/71625]
loss: 0.005367  [ 6400/71625]
loss: 0.008636  [12800/71625]
loss: 0.019087  [19200/71625]
loss: 0.010676  [25600/71625]
loss: 0.001308  [32000/71625]
loss: 0.099336  [38400/71625]
loss: 0.110802  [44800/71625]
loss: 0.004469  [51200/71625]
loss: 0.000580  [57600/71625]
loss: 0.024720  [64000/71625]
loss: 0.016690  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.051591 

Epoch 23
-------------------------------
loss: 0.009620  [    0/71625]
loss: 0.002833  [ 6400/71625]
loss: 0.039233  [12800/71625]
loss: 0.010994  [19200/71625]
loss: 0.020861  [25600/71625]
loss: 0.036935  [32000/71625]
loss: 0.046476  [38400/71625]
loss: 0.013179  [44800/71625]
loss: 0.006585  [51200/71625]
loss: 0.003250  [57600/71625]
loss: 0.014438  [64000/71625]
loss: 0.038910  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.044999 

Epoch 24
-------------------------------
loss: 0.008654  [    0/71625]
loss: 0.005421  [ 6400/71625]
loss: 0.073534  [12800/71625]
loss: 0.023032  [19200/71625]
loss: 0.013159  [25600/71625]
loss: 0.005250  [32000/71625]
loss: 0.044559  [38400/71625]
loss: 0.009386  [44800/71625]
loss: 0.009352  [51200/71625]
loss: 0.017273  [57600/71625]
loss: 0.010613  [64000/71625]
loss: 0.001139  [70400/71625]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.040992 

Epoch 25
-------------------------------
loss: 0.018965  [    0/71625]
loss: 0.023556  [ 6400/71625]
loss: 0.018241  [12800/71625]
loss: 0.124009  [19200/71625]
loss: 0.022976  [25600/71625]
loss: 0.031339  [32000/71625]
loss: 0.008618  [38400/71625]
loss: 0.037122  [44800/71625]
loss: 0.017715  [51200/71625]
loss: 0.031182  [57600/71625]
loss: 0.006338  [64000/71625]
loss: 0.005277  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.042671 

Epoch 26
-------------------------------
loss: 0.033603  [    0/71625]
loss: 0.004934  [ 6400/71625]
loss: 0.019843  [12800/71625]
loss: 0.045436  [19200/71625]
loss: 0.091599  [25600/71625]
loss: 0.021839  [32000/71625]
loss: 0.095211  [38400/71625]
loss: 0.012574  [44800/71625]
loss: 0.113849  [51200/71625]
loss: 0.117548  [57600/71625]
loss: 0.002682  [64000/71625]
loss: 0.024439  [70400/71625]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.052807 

Epoch 27
-------------------------------
loss: 0.018271  [    0/71625]
loss: 0.058143  [ 6400/71625]
loss: 0.005901  [12800/71625]
loss: 0.010125  [19200/71625]
loss: 0.033243  [25600/71625]
loss: 0.003921  [32000/71625]
loss: 0.116029  [38400/71625]
loss: 0.080574  [44800/71625]
loss: 0.030529  [51200/71625]
loss: 0.014831  [57600/71625]
loss: 0.038718  [64000/71625]
loss: 0.043630  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.043355 

Epoch 28
-------------------------------
loss: 0.095234  [    0/71625]
loss: 0.070454  [ 6400/71625]
loss: 0.041021  [12800/71625]
loss: 0.015437  [19200/71625]
loss: 0.050732  [25600/71625]
loss: 0.012038  [32000/71625]
loss: 0.012133  [38400/71625]
loss: 0.098243  [44800/71625]
loss: 0.015275  [51200/71625]
loss: 0.015569  [57600/71625]
loss: 0.012036  [64000/71625]
loss: 0.019373  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.044826 

Epoch 29
-------------------------------
loss: 0.014281  [    0/71625]
loss: 0.003547  [ 6400/71625]
loss: 0.014408  [12800/71625]
loss: 0.007853  [19200/71625]
loss: 0.023615  [25600/71625]
loss: 0.024229  [32000/71625]
loss: 0.062215  [38400/71625]
loss: 0.052935  [44800/71625]
loss: 0.052707  [51200/71625]
loss: 0.031315  [57600/71625]
loss: 0.014789  [64000/71625]
loss: 0.087130  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.047292 

Epoch 30
-------------------------------
loss: 0.035376  [    0/71625]
loss: 0.021905  [ 6400/71625]
loss: 0.015234  [12800/71625]
loss: 0.040705  [19200/71625]
loss: 0.016584  [25600/71625]
loss: 0.003597  [32000/71625]
loss: 0.192376  [38400/71625]
loss: 0.035022  [44800/71625]
loss: 0.009482  [51200/71625]
loss: 0.018847  [57600/71625]
loss: 0.002476  [64000/71625]
loss: 0.007337  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.042944 

Epoch 31
-------------------------------
loss: 0.039517  [    0/71625]
loss: 0.004226  [ 6400/71625]
loss: 0.041631  [12800/71625]
loss: 0.005003  [19200/71625]
loss: 0.010807  [25600/71625]
loss: 0.002367  [32000/71625]
loss: 0.006572  [38400/71625]
loss: 0.003980  [44800/71625]
loss: 0.009573  [51200/71625]
loss: 0.013595  [57600/71625]
loss: 0.028623  [64000/71625]
loss: 0.005848  [70400/71625]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.053507 

Epoch 32
-------------------------------
loss: 0.016078  [    0/71625]
loss: 0.070731  [ 6400/71625]
loss: 0.047432  [12800/71625]
loss: 0.007445  [19200/71625]
loss: 0.054477  [25600/71625]
loss: 0.022786  [32000/71625]
loss: 0.005904  [38400/71625]
loss: 0.002197  [44800/71625]
loss: 0.004474  [51200/71625]
loss: 0.003439  [57600/71625]
loss: 0.022603  [64000/71625]
loss: 0.002699  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.062261 

Epoch 33
-------------------------------
loss: 0.008409  [    0/71625]
loss: 0.003711  [ 6400/71625]
loss: 0.012802  [12800/71625]
loss: 0.002173  [19200/71625]
loss: 0.001255  [25600/71625]
loss: 0.030285  [32000/71625]
loss: 0.018951  [38400/71625]
loss: 0.029975  [44800/71625]
loss: 0.057915  [51200/71625]
loss: 0.009853  [57600/71625]
loss: 0.025156  [64000/71625]
loss: 0.015323  [70400/71625]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.104750 

Epoch 34
-------------------------------
loss: 0.000321  [    0/71625]
loss: 0.066285  [ 6400/71625]
loss: 0.068403  [12800/71625]
loss: 0.004044  [19200/71625]
loss: 0.000799  [25600/71625]
loss: 0.010197  [32000/71625]
loss: 0.047739  [38400/71625]
loss: 0.006560  [44800/71625]
loss: 0.029123  [51200/71625]
loss: 0.024474  [57600/71625]
loss: 0.063137  [64000/71625]
loss: 0.077460  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.060001 

Epoch 35
-------------------------------
loss: 0.029039  [    0/71625]
loss: 0.001689  [ 6400/71625]
loss: 0.014399  [12800/71625]
loss: 0.003118  [19200/71625]
loss: 0.018388  [25600/71625]
loss: 0.024039  [32000/71625]
loss: 0.002499  [38400/71625]
loss: 0.043557  [44800/71625]
loss: 0.042284  [51200/71625]
loss: 0.042185  [57600/71625]
loss: 0.011416  [64000/71625]
loss: 0.026412  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.054474 

Epoch 36
-------------------------------
loss: 0.023428  [    0/71625]
loss: 0.038657  [ 6400/71625]
loss: 0.099968  [12800/71625]
loss: 0.002968  [19200/71625]
loss: 0.003062  [25600/71625]
loss: 0.002783  [32000/71625]
loss: 0.030348  [38400/71625]
loss: 0.014039  [44800/71625]
loss: 0.018151  [51200/71625]
loss: 0.045238  [57600/71625]
loss: 0.065139  [64000/71625]
loss: 0.007719  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.067769 

Epoch 37
-------------------------------
loss: 0.009367  [    0/71625]
loss: 0.023839  [    0/72302]
loss: 0.003382  [ 6400/72302]
loss: 0.006791  [12800/72302]
loss: 0.046380  [19200/72302]
loss: 0.058404  [25600/72302]
loss: 0.001939  [32000/72302]
loss: 0.006123  [38400/72302]
loss: 0.010848  [44800/72302]
loss: 0.008556  [51200/72302]
loss: 0.001826  [57600/72302]
loss: 0.017980  [64000/72302]
loss: 0.037638  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.045249 

Epoch 20
-------------------------------
loss: 0.017420  [    0/72302]
loss: 0.004352  [ 6400/72302]
loss: 0.000032  [12800/72302]
loss: 0.005359  [19200/72302]
loss: 0.010898  [25600/72302]
loss: 0.009162  [32000/72302]
loss: 0.019646  [38400/72302]
loss: 0.003984  [44800/72302]
loss: 0.116799  [51200/72302]
loss: 0.036272  [57600/72302]
loss: 0.000960  [64000/72302]
loss: 0.001908  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.047915 

Epoch 21
-------------------------------
loss: 0.017031  [    0/72302]
loss: 0.007025  [ 6400/72302]
loss: 0.021351  [12800/72302]
loss: 0.000377  [19200/72302]
loss: 0.011726  [25600/72302]
loss: 0.031767  [32000/72302]
loss: 0.003561  [38400/72302]
loss: 0.029858  [44800/72302]
loss: 0.000715  [51200/72302]
loss: 0.032030  [57600/72302]
loss: 0.015671  [64000/72302]
loss: 0.001123  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.055627 

Epoch 22
-------------------------------
loss: 0.003196  [    0/72302]
loss: 0.013207  [ 6400/72302]
loss: 0.013641  [12800/72302]
loss: 0.035191  [19200/72302]
loss: 0.033815  [25600/72302]
loss: 0.002315  [32000/72302]
loss: 0.001295  [38400/72302]
loss: 0.054879  [44800/72302]
loss: 0.005531  [51200/72302]
loss: 0.004351  [57600/72302]
loss: 0.039041  [64000/72302]
loss: 0.011079  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.051754 

Epoch 23
-------------------------------
loss: 0.000129  [    0/72302]
loss: 0.002030  [ 6400/72302]
loss: 0.000905  [12800/72302]
loss: 0.011514  [19200/72302]
loss: 0.003291  [25600/72302]
loss: 0.000562  [32000/72302]
loss: 0.003872  [38400/72302]
loss: 0.014520  [44800/72302]
loss: 0.000675  [51200/72302]
loss: 0.010390  [57600/72302]
loss: 0.000839  [64000/72302]
loss: 0.014269  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.044367 

Epoch 24
-------------------------------
loss: 0.001453  [    0/72302]
loss: 0.000961  [ 6400/72302]
loss: 0.045562  [12800/72302]
loss: 0.000958  [19200/72302]
loss: 0.011908  [25600/72302]
loss: 0.030062  [32000/72302]
loss: 0.006989  [38400/72302]
loss: 0.006688  [44800/72302]
loss: 0.020244  [51200/72302]
loss: 0.006636  [57600/72302]
loss: 0.001087  [64000/72302]
loss: 0.072407  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.047379 

Epoch 25
-------------------------------
loss: 0.023340  [    0/72302]
loss: 0.000362  [ 6400/72302]
loss: 0.020089  [12800/72302]
loss: 0.010540  [19200/72302]
loss: 0.001933  [25600/72302]
loss: 0.000424  [32000/72302]
loss: 0.003576  [38400/72302]
loss: 0.038705  [44800/72302]
loss: 0.001454  [51200/72302]
loss: 0.001655  [57600/72302]
loss: 0.001403  [64000/72302]
loss: 0.000992  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.046515 

Epoch 26
-------------------------------
loss: 0.004585  [    0/72302]
loss: 0.008299  [ 6400/72302]
loss: 0.003212  [12800/72302]
loss: 0.038797  [19200/72302]
loss: 0.003775  [25600/72302]
loss: 0.002057  [32000/72302]
loss: 0.030304  [38400/72302]
loss: 0.008414  [44800/72302]
loss: 0.011959  [51200/72302]
loss: 0.000366  [57600/72302]
loss: 0.129743  [64000/72302]
loss: 0.003739  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.045176 

Epoch 27
-------------------------------
loss: 0.002039  [    0/72302]
loss: 0.003249  [ 6400/72302]
loss: 0.000821  [12800/72302]
loss: 0.005652  [19200/72302]
loss: 0.003886  [25600/72302]
loss: 0.002006  [32000/72302]
loss: 0.003883  [38400/72302]
loss: 0.000634  [44800/72302]
loss: 0.007177  [51200/72302]
loss: 0.002829  [57600/72302]
loss: 0.011077  [64000/72302]
loss: 0.001235  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.046783 

Epoch 28
-------------------------------
loss: 0.000279  [    0/72302]
loss: 0.013157  [ 6400/72302]
loss: 0.000616  [12800/72302]
loss: 0.026958  [19200/72302]
loss: 0.004085  [25600/72302]
loss: 0.009457  [32000/72302]
loss: 0.000425  [38400/72302]
loss: 0.013817  [44800/72302]
loss: 0.003351  [51200/72302]
loss: 0.018064  [57600/72302]
loss: 0.001735  [64000/72302]
loss: 0.001898  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.047217 

Epoch 29
-------------------------------
loss: 0.056232  [    0/72302]
loss: 0.021340  [ 6400/72302]
loss: 0.002696  [12800/72302]
loss: 0.008590  [19200/72302]
loss: 0.000501  [25600/72302]
loss: 0.000505  [32000/72302]
loss: 0.008767  [38400/72302]
loss: 0.093006  [44800/72302]
loss: 0.002099  [51200/72302]
loss: 0.000774  [57600/72302]
loss: 0.008865  [64000/72302]
loss: 0.000549  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.060969 

Epoch 30
-------------------------------
loss: 0.029335  [    0/72302]
loss: 0.016099  [ 6400/72302]
loss: 0.011087  [12800/72302]
loss: 0.029260  [19200/72302]
loss: 0.002744  [25600/72302]
loss: 0.004048  [32000/72302]
loss: 0.002567  [38400/72302]
loss: 0.011929  [44800/72302]
loss: 0.000318  [51200/72302]
loss: 0.001518  [57600/72302]
loss: 0.037421  [64000/72302]
loss: 0.028709  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.050130 

Epoch 31
-------------------------------
loss: 0.000050  [    0/72302]
loss: 0.008334  [ 6400/72302]
loss: 0.018572  [12800/72302]
loss: 0.019237  [19200/72302]
loss: 0.006817  [25600/72302]
loss: 0.080674  [32000/72302]
loss: 0.005865  [38400/72302]
loss: 0.006934  [44800/72302]
loss: 0.004433  [51200/72302]
loss: 0.026075  [57600/72302]
loss: 0.003911  [64000/72302]
loss: 0.001480  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.050074 

Epoch 32
-------------------------------
loss: 0.038184  [    0/72302]
loss: 0.011652  [ 6400/72302]
loss: 0.001058  [12800/72302]
loss: 0.003923  [19200/72302]
loss: 0.000414  [25600/72302]
loss: 0.009041  [32000/72302]
loss: 0.124480  [38400/72302]
loss: 0.020519  [44800/72302]
loss: 0.094580  [51200/72302]
loss: 0.007446  [57600/72302]
loss: 0.015207  [64000/72302]
loss: 0.003097  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.062528 

Epoch 33
-------------------------------
loss: 0.000884  [    0/72302]
loss: 0.006406  [ 6400/72302]
loss: 0.017818  [12800/72302]
loss: 0.009257  [19200/72302]
loss: 0.012114  [25600/72302]
loss: 0.035660  [32000/72302]
loss: 0.001315  [38400/72302]
loss: 0.001004  [44800/72302]
loss: 0.003429  [51200/72302]
loss: 0.005969  [57600/72302]
loss: 0.004648  [64000/72302]
loss: 0.003065  [70400/72302]
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.052366 

Epoch 34
-------------------------------
loss: 0.053453  [    0/72302]
loss: 0.000284  [ 6400/72302]
loss: 0.024644  [12800/72302]
loss: 0.019136  [19200/72302]
loss: 0.001440  [25600/72302]
loss: 0.005082  [32000/72302]
loss: 0.015244  [38400/72302]
loss: 0.003985  [44800/72302]
loss: 0.003426  [51200/72302]
loss: 0.000231  [57600/72302]
loss: 0.003162  [64000/72302]
loss: 0.001145  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.049000 

Epoch 35
-------------------------------
loss: 0.004037  [    0/72302]
loss: 0.011577  [ 6400/72302]
loss: 0.029304  [12800/72302]
loss: 0.007619  [19200/72302]
loss: 0.006186  [25600/72302]
loss: 0.010468  [32000/72302]
loss: 0.003047  [38400/72302]
loss: 0.000907  [44800/72302]
loss: 0.004007  [51200/72302]
loss: 0.080864  [57600/72302]
loss: 0.011858  [64000/72302]
loss: 0.003654  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.049755 

Epoch 36
-------------------------------
loss: 0.005426  [    0/72302]
loss: 0.004926  [ 6400/72302]
loss: 0.007417  [12800/72302]
loss: 0.001004  [19200/72302]
loss: 0.001188  [25600/72302]
loss: 0.003086  [32000/72302]
loss: 0.029335  [38400/72302]
loss: 0.059370  [44800/72302]
loss: 0.002413  [51200/72302]
loss: 0.050111  [57600/72302]
loss: 0.000507  [64000/72302]
loss: 0.088143  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.060671 

Epoch 37
-------------------------------
loss: 0.005821  [    0/72302]
loss: 0.238683  [    0/70535]
loss: 0.014980  [ 6400/70535]
loss: 0.062718  [12800/70535]
loss: 0.049162  [19200/70535]
loss: 1.581497  [25600/70535]
loss: 0.064749  [32000/70535]
loss: 0.108884  [38400/70535]
loss: 0.108033  [44800/70535]
loss: 0.125479  [51200/70535]
loss: 0.058457  [57600/70535]
loss: 0.062551  [64000/70535]
loss: 0.156933  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.113024 

Epoch 20
-------------------------------
loss: 0.100440  [    0/70535]
loss: 0.039653  [ 6400/70535]
loss: 0.041309  [12800/70535]
loss: 0.082571  [19200/70535]
loss: 0.096305  [25600/70535]
loss: 0.047430  [32000/70535]
loss: 0.081429  [38400/70535]
loss: 0.091170  [44800/70535]
loss: 0.128306  [51200/70535]
loss: 0.085340  [57600/70535]
loss: 0.127973  [64000/70535]
loss: 0.146943  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.109146 

Epoch 21
-------------------------------
loss: 0.136252  [    0/70535]
loss: 0.068638  [ 6400/70535]
loss: 0.120012  [12800/70535]
loss: 0.081950  [19200/70535]
loss: 0.081888  [25600/70535]
loss: 0.063824  [32000/70535]
loss: 0.144920  [38400/70535]
loss: 0.121083  [44800/70535]
loss: 0.085386  [51200/70535]
loss: 0.026422  [57600/70535]
loss: 0.121145  [64000/70535]
loss: 0.102405  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.113628 

Epoch 22
-------------------------------
loss: 0.052096  [    0/70535]
loss: 0.091317  [ 6400/70535]
loss: 0.087648  [12800/70535]
loss: 0.054907  [19200/70535]
loss: 0.120094  [25600/70535]
loss: 0.220140  [32000/70535]
loss: 0.091191  [38400/70535]
loss: 0.106305  [44800/70535]
loss: 0.197759  [51200/70535]
loss: 0.076006  [57600/70535]
loss: 0.121369  [64000/70535]
loss: 0.021969  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.109237 

Epoch 23
-------------------------------
loss: 0.100023  [    0/70535]
loss: 0.028748  [ 6400/70535]
loss: 0.149077  [12800/70535]
loss: 0.078457  [19200/70535]
loss: 0.104394  [25600/70535]
loss: 0.055546  [32000/70535]
loss: 0.128529  [38400/70535]
loss: 0.072376  [44800/70535]
loss: 0.179255  [51200/70535]
loss: 0.114416  [57600/70535]
loss: 0.101963  [64000/70535]
loss: 0.080136  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.111921 

Epoch 24
-------------------------------
loss: 0.057306  [    0/70535]
loss: 0.048433  [ 6400/70535]
loss: 0.119353  [12800/70535]
loss: 0.048743  [19200/70535]
loss: 0.051625  [25600/70535]
loss: 0.037953  [32000/70535]
loss: 0.024117  [38400/70535]
loss: 0.110275  [44800/70535]
loss: 0.118208  [51200/70535]
loss: 0.130345  [57600/70535]
loss: 0.097199  [64000/70535]
loss: 0.120227  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.112046 

Epoch 25
-------------------------------
loss: 0.109698  [    0/70535]
loss: 0.070192  [ 6400/70535]
loss: 0.091038  [12800/70535]
loss: 0.063015  [19200/70535]
loss: 0.028007  [25600/70535]
loss: 0.054771  [32000/70535]
loss: 0.076469  [38400/70535]
loss: 0.057505  [44800/70535]
loss: 0.025904  [51200/70535]
loss: 0.051366  [57600/70535]
loss: 0.152559  [64000/70535]
loss: 0.038057  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.113741 

Epoch 26
-------------------------------
loss: 0.065111  [    0/70535]
loss: 0.042728  [ 6400/70535]
loss: 0.033079  [12800/70535]
loss: 0.066436  [19200/70535]
loss: 0.123867  [25600/70535]
loss: 0.071322  [32000/70535]
loss: 0.053388  [38400/70535]
loss: 0.119851  [44800/70535]
loss: 0.156028  [51200/70535]
loss: 0.233574  [57600/70535]
loss: 0.053887  [64000/70535]
loss: 0.071476  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.114235 

Epoch 27
-------------------------------
loss: 0.096127  [    0/70535]
loss: 0.040227  [ 6400/70535]
loss: 0.075124  [12800/70535]
loss: 0.076826  [19200/70535]
loss: 0.051233  [25600/70535]
loss: 0.043253  [32000/70535]
loss: 0.101205  [38400/70535]
loss: 0.076592  [44800/70535]
loss: 0.119768  [51200/70535]
loss: 0.073127  [57600/70535]
loss: 0.112398  [64000/70535]
loss: 0.058814  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.111238 

Epoch 28
-------------------------------
loss: 0.095941  [    0/70535]
loss: 0.202776  [ 6400/70535]
loss: 0.062863  [12800/70535]
loss: 0.171570  [19200/70535]
loss: 0.204389  [25600/70535]
loss: 0.102253  [32000/70535]
loss: 0.204784  [38400/70535]
loss: 0.073484  [44800/70535]
loss: 0.169317  [51200/70535]
loss: 0.027158  [57600/70535]
loss: 0.063180  [64000/70535]
loss: 0.144854  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.113929 

Epoch 29
-------------------------------
loss: 0.089535  [    0/70535]
loss: 0.055507  [ 6400/70535]
loss: 0.076416  [12800/70535]
loss: 0.047720  [19200/70535]
loss: 0.050753  [25600/70535]
loss: 0.080794  [32000/70535]
loss: 0.098850  [38400/70535]
loss: 0.081277  [44800/70535]
loss: 0.101864  [51200/70535]
loss: 0.136219  [57600/70535]
loss: 0.076614  [64000/70535]
loss: 0.153836  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.115569 

Epoch 30
-------------------------------
loss: 0.114958  [    0/70535]
loss: 0.052368  [ 6400/70535]
loss: 0.111865  [12800/70535]
loss: 0.042546  [19200/70535]
loss: 0.033518  [25600/70535]
loss: 0.057610  [32000/70535]
loss: 0.070648  [38400/70535]
loss: 0.007331  [44800/70535]
loss: 0.056230  [51200/70535]
loss: 0.053249  [57600/70535]
loss: 0.082127  [64000/70535]
loss: 0.077508  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.118925 

Epoch 31
-------------------------------
loss: 0.037306  [    0/70535]
loss: 0.060308  [ 6400/70535]
loss: 1.587960  [12800/70535]
loss: 0.098302  [19200/70535]
loss: 0.062669  [25600/70535]
loss: 0.057200  [32000/70535]
loss: 0.086960  [38400/70535]
loss: 0.077078  [44800/70535]
loss: 0.054542  [51200/70535]
loss: 0.151479  [57600/70535]
loss: 0.066764  [64000/70535]
loss: 0.085337  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.116030 

Epoch 32
-------------------------------
loss: 0.123767  [    0/70535]
loss: 0.022576  [ 6400/70535]
loss: 0.040354  [12800/70535]
loss: 0.072221  [19200/70535]
loss: 0.142038  [25600/70535]
loss: 0.108074  [32000/70535]
loss: 0.074873  [38400/70535]
loss: 0.159483  [44800/70535]
loss: 0.041573  [51200/70535]
loss: 0.091843  [57600/70535]
loss: 0.067395  [64000/70535]
loss: 0.092772  [70400/70535]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.121872 

Epoch 33
-------------------------------
loss: 0.125136  [    0/70535]
loss: 0.071135  [ 6400/70535]
loss: 0.036937  [12800/70535]
loss: 0.044034  [19200/70535]
loss: 0.090292  [25600/70535]
loss: 0.116934  [32000/70535]
loss: 0.068246  [38400/70535]
loss: 0.111114  [44800/70535]
loss: 0.051108  [51200/70535]
loss: 0.056119  [57600/70535]
loss: 0.123514  [64000/70535]
loss: 0.171886  [70400/70535]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.167733 

Epoch 34
-------------------------------
loss: 0.053396  [    0/70535]
loss: 0.033273  [ 6400/70535]
loss: 0.043706  [12800/70535]
loss: 0.061998  [19200/70535]
loss: 0.046861  [25600/70535]
loss: 0.120787  [32000/70535]
loss: 0.053482  [38400/70535]
loss: 0.029254  [44800/70535]
loss: 0.056154  [51200/70535]
loss: 0.044057  [57600/70535]
loss: 0.075360  [64000/70535]
loss: 0.097871  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.119297 

Epoch 35
-------------------------------
loss: 0.070638  [    0/70535]
loss: 0.042926  [ 6400/70535]
loss: 0.033949  [12800/70535]
loss: 0.036893  [19200/70535]
loss: 0.118227  [25600/70535]
loss: 0.049323  [32000/70535]
loss: 0.128155  [38400/70535]
loss: 0.092137  [44800/70535]
loss: 0.097214  [51200/70535]
loss: 0.106466  [57600/70535]
loss: 0.088666  [64000/70535]
loss: 0.085491  [70400/70535]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.150555 

Epoch 36
-------------------------------
loss: 0.203386  [    0/70535]
loss: 0.105823  [ 6400/70535]
loss: 0.164360  [12800/70535]
loss: 0.087639  [19200/70535]
loss: 0.014414  [25600/70535]
loss: 0.095903  [32000/70535]
loss: 0.094118  [38400/70535]
loss: 0.029862  [44800/70535]
loss: 0.057966  [51200/70535]
loss: 0.061421  [57600/70535]
loss: 0.094699  [64000/70535]
loss: 0.034914  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.118299 

Epoch 37
-------------------------------
loss: 0.044945  [    0/70535]
loss: 1.656812  [    0/71124]
loss: 0.141125  [ 6400/71124]
loss: 0.092824  [12800/71124]
loss: 0.175055  [19200/71124]
loss: 0.081721  [25600/71124]
loss: 1.915070  [32000/71124]
loss: 0.116419  [38400/71124]
loss: 0.052604  [44800/71124]
loss: 0.030095  [51200/71124]
loss: 0.051986  [57600/71124]
loss: 0.121388  [64000/71124]
loss: 0.089904  [70400/71124]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.153302 

Epoch 20
-------------------------------
loss: 0.079363  [    0/71124]
loss: 0.067586  [ 6400/71124]
loss: 0.046640  [12800/71124]
loss: 0.045884  [19200/71124]
loss: 0.037680  [25600/71124]
loss: 0.118404  [32000/71124]
loss: 0.024756  [38400/71124]
loss: 0.074491  [44800/71124]
loss: 0.062088  [51200/71124]
loss: 1.648278  [57600/71124]
loss: 0.030018  [64000/71124]
loss: 0.188232  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.135137 

Epoch 21
-------------------------------
loss: 0.131911  [    0/71124]
loss: 0.089293  [ 6400/71124]
loss: 0.049135  [12800/71124]
loss: 0.104988  [19200/71124]
loss: 0.099428  [25600/71124]
loss: 0.050062  [32000/71124]
loss: 0.082374  [38400/71124]
loss: 0.013056  [44800/71124]
loss: 0.078622  [51200/71124]
loss: 0.164541  [57600/71124]
loss: 0.026775  [64000/71124]
loss: 1.742913  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.134715 

Epoch 22
-------------------------------
loss: 0.074141  [    0/71124]
loss: 0.077465  [ 6400/71124]
loss: 1.673447  [12800/71124]
loss: 0.053544  [19200/71124]
loss: 0.032286  [25600/71124]
loss: 0.054693  [32000/71124]
loss: 0.047772  [38400/71124]
loss: 0.050893  [44800/71124]
loss: 0.073492  [51200/71124]
loss: 0.043748  [57600/71124]
loss: 0.160344  [64000/71124]
loss: 0.060368  [70400/71124]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.135898 

Epoch 23
-------------------------------
loss: 0.048398  [    0/71124]
loss: 0.071739  [ 6400/71124]
loss: 0.070154  [12800/71124]
loss: 0.093228  [19200/71124]
loss: 0.053441  [25600/71124]
loss: 0.051201  [32000/71124]
loss: 0.050970  [38400/71124]
loss: 0.093811  [44800/71124]
loss: 0.094117  [51200/71124]
loss: 0.077914  [57600/71124]
loss: 0.065509  [64000/71124]
loss: 0.076240  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.135979 

Epoch 24
-------------------------------
loss: 0.048790  [    0/71124]
loss: 0.031759  [ 6400/71124]
loss: 0.039124  [12800/71124]
loss: 0.049600  [19200/71124]
loss: 0.069775  [25600/71124]
loss: 0.105882  [32000/71124]
loss: 0.124472  [38400/71124]
loss: 0.075286  [44800/71124]
loss: 0.077878  [51200/71124]
loss: 0.090563  [57600/71124]
loss: 0.068303  [64000/71124]
loss: 0.070261  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.137174 

Epoch 25
-------------------------------
loss: 0.060069  [    0/71124]
loss: 0.007833  [ 6400/71124]
loss: 0.052846  [12800/71124]
loss: 0.069692  [19200/71124]
loss: 0.071526  [25600/71124]
loss: 0.035308  [32000/71124]
loss: 0.053951  [38400/71124]
loss: 0.012692  [44800/71124]
loss: 0.037758  [51200/71124]
loss: 0.018820  [57600/71124]
loss: 0.092763  [64000/71124]
loss: 0.060939  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.136582 

Epoch 26
-------------------------------
loss: 0.021192  [    0/71124]
loss: 0.117215  [ 6400/71124]
loss: 0.064561  [12800/71124]
loss: 0.014405  [19200/71124]
loss: 0.095497  [25600/71124]
loss: 0.072481  [32000/71124]
loss: 0.051652  [38400/71124]
loss: 0.041410  [44800/71124]
loss: 0.059306  [51200/71124]
loss: 0.116373  [57600/71124]
loss: 0.052969  [64000/71124]
loss: 0.006793  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.138303 

Epoch 27
-------------------------------
loss: 0.108834  [    0/71124]
loss: 0.048177  [ 6400/71124]
loss: 0.067583  [12800/71124]
loss: 0.052359  [19200/71124]
loss: 0.090857  [25600/71124]
loss: 0.035505  [32000/71124]
loss: 0.072252  [38400/71124]
loss: 0.037462  [44800/71124]
loss: 0.058097  [51200/71124]
loss: 0.089199  [57600/71124]
loss: 0.109477  [64000/71124]
loss: 0.010957  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.136324 

Epoch 28
-------------------------------
loss: 0.092325  [    0/71124]
loss: 0.038917  [ 6400/71124]
loss: 0.068604  [12800/71124]
loss: 0.041335  [19200/71124]
loss: 0.037337  [25600/71124]
loss: 0.069895  [32000/71124]
loss: 0.154581  [38400/71124]
loss: 0.132520  [44800/71124]
loss: 0.041571  [51200/71124]
loss: 0.038923  [57600/71124]
loss: 0.077764  [64000/71124]
loss: 0.063616  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.135787 

Epoch 29
-------------------------------
loss: 0.082837  [    0/71124]
loss: 0.073567  [ 6400/71124]
loss: 0.028793  [12800/71124]
loss: 0.088868  [19200/71124]
loss: 0.052598  [25600/71124]
loss: 1.588164  [32000/71124]
loss: 0.078164  [38400/71124]
loss: 0.022127  [44800/71124]
loss: 0.034512  [51200/71124]
loss: 0.135997  [57600/71124]
loss: 0.224068  [64000/71124]
loss: 0.038742  [70400/71124]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.141368 

Epoch 30
-------------------------------
loss: 0.102866  [    0/71124]
loss: 0.037987  [ 6400/71124]
loss: 0.040489  [12800/71124]
loss: 0.063106  [19200/71124]
loss: 0.042990  [25600/71124]
loss: 0.061602  [32000/71124]
loss: 1.597772  [38400/71124]
loss: 0.053250  [44800/71124]
loss: 0.138179  [51200/71124]
loss: 0.096635  [57600/71124]
loss: 0.039987  [64000/71124]
loss: 0.049193  [70400/71124]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.141604 

Epoch 31
-------------------------------
loss: 0.121740  [    0/71124]
loss: 0.025801  [ 6400/71124]
loss: 0.047910  [12800/71124]
loss: 0.031639  [19200/71124]
loss: 0.038824  [25600/71124]
loss: 0.052868  [32000/71124]
loss: 0.096764  [38400/71124]
loss: 1.625060  [44800/71124]
loss: 0.081921  [51200/71124]
loss: 0.026578  [57600/71124]
loss: 0.034875  [64000/71124]
loss: 0.063843  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.135441 

Epoch 32
-------------------------------
loss: 0.020898  [    0/71124]
loss: 1.610373  [ 6400/71124]
loss: 0.007190  [12800/71124]
loss: 0.041839  [19200/71124]
loss: 0.058435  [25600/71124]
loss: 0.062766  [32000/71124]
loss: 0.052612  [38400/71124]
loss: 1.647206  [44800/71124]
loss: 0.055364  [51200/71124]
loss: 0.157761  [57600/71124]
loss: 0.046463  [64000/71124]
loss: 0.074631  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.134616 

Epoch 33
-------------------------------
loss: 0.025674  [    0/71124]
loss: 0.041698  [ 6400/71124]
loss: 1.626047  [12800/71124]
loss: 0.136156  [19200/71124]
loss: 0.060925  [25600/71124]
loss: 0.052876  [32000/71124]
loss: 0.091870  [38400/71124]
loss: 1.637336  [44800/71124]
loss: 0.063963  [51200/71124]
loss: 0.045927  [57600/71124]
loss: 0.040003  [64000/71124]
loss: 0.053222  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.136103 

Epoch 34
-------------------------------
loss: 0.057187  [    0/71124]
loss: 0.087495  [ 6400/71124]
loss: 0.023381  [12800/71124]
loss: 0.111720  [19200/71124]
loss: 0.063632  [25600/71124]
loss: 0.010645  [32000/71124]
loss: 0.091444  [38400/71124]
loss: 0.037656  [44800/71124]
loss: 0.098259  [51200/71124]
loss: 0.103726  [57600/71124]
loss: 0.099738  [64000/71124]
loss: 0.142372  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.140437 

Epoch 35
-------------------------------
loss: 0.065654  [    0/71124]
loss: 0.090091  [ 6400/71124]
loss: 0.028480  [12800/71124]
loss: 0.068257  [19200/71124]
loss: 0.198050  [25600/71124]
loss: 0.043221  [32000/71124]
loss: 0.036918  [38400/71124]
loss: 0.026998  [44800/71124]
loss: 0.034961  [51200/71124]
loss: 0.076260  [57600/71124]
loss: 0.090867  [64000/71124]
loss: 0.050197  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.141820 

Epoch 36
-------------------------------
loss: 0.012856  [    0/71124]
loss: 0.066584  [ 6400/71124]
loss: 0.042222  [12800/71124]
loss: 0.039545  [19200/71124]
loss: 0.068376  [25600/71124]
loss: 0.036270  [32000/71124]
loss: 0.041620  [38400/71124]
loss: 0.091807  [44800/71124]
loss: 0.047448  [51200/71124]
loss: 0.162030  [57600/71124]
loss: 0.052098  [64000/71124]
loss: 0.088744  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.137285 

Epoch 37
-------------------------------
loss: 0.081728  [    0/71124]
loss: 0.028452  [    0/71639]
loss: 0.038139  [ 6400/71639]
loss: 0.018220  [12800/71639]
loss: 0.019596  [19200/71639]
loss: 0.035366  [25600/71639]
loss: 0.162839  [32000/71639]
loss: 0.046915  [38400/71639]
loss: 0.038343  [44800/71639]
loss: 0.188300  [51200/71639]
loss: 0.063265  [57600/71639]
loss: 0.031170  [64000/71639]
loss: 0.090423  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.201434 

Epoch 20
-------------------------------
loss: 0.118103  [    0/71639]
loss: 0.034625  [ 6400/71639]
loss: 0.029416  [12800/71639]
loss: 0.045885  [19200/71639]
loss: 0.037121  [25600/71639]
loss: 0.034527  [32000/71639]
loss: 0.105630  [38400/71639]
loss: 0.035581  [44800/71639]
loss: 0.051774  [51200/71639]
loss: 0.083984  [57600/71639]
loss: 0.083197  [64000/71639]
loss: 0.110262  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.206518 

Epoch 21
-------------------------------
loss: 0.042853  [    0/71639]
loss: 0.032275  [ 6400/71639]
loss: 0.058228  [12800/71639]
loss: 0.018134  [19200/71639]
loss: 0.025121  [25600/71639]
loss: 0.088307  [32000/71639]
loss: 0.035284  [38400/71639]
loss: 0.037013  [44800/71639]
loss: 0.019529  [51200/71639]
loss: 0.041546  [57600/71639]
loss: 0.094782  [64000/71639]
loss: 0.056689  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.201613 

Epoch 22
-------------------------------
loss: 0.031779  [    0/71639]
loss: 0.001165  [ 6400/71639]
loss: 0.123379  [12800/71639]
loss: 0.132544  [19200/71639]
loss: 0.064813  [25600/71639]
loss: 0.073499  [32000/71639]
loss: 0.081138  [38400/71639]
loss: 0.153166  [44800/71639]
loss: 0.072327  [51200/71639]
loss: 0.189597  [57600/71639]
loss: 0.047665  [64000/71639]
loss: 0.034930  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.210779 

Epoch 23
-------------------------------
loss: 0.038689  [    0/71639]
loss: 0.073363  [ 6400/71639]
loss: 0.090644  [12800/71639]
loss: 0.042967  [19200/71639]
loss: 0.109273  [25600/71639]
loss: 0.016779  [32000/71639]
loss: 0.176036  [38400/71639]
loss: 0.010071  [44800/71639]
loss: 0.031489  [51200/71639]
loss: 0.014162  [57600/71639]
loss: 0.077100  [64000/71639]
loss: 0.118733  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.199189 

Epoch 24
-------------------------------
loss: 0.053794  [    0/71639]
loss: 0.040279  [ 6400/71639]
loss: 0.025493  [12800/71639]
loss: 0.045131  [19200/71639]
loss: 0.041012  [25600/71639]
loss: 1.658957  [32000/71639]
loss: 0.033441  [38400/71639]
loss: 0.050107  [44800/71639]
loss: 0.041477  [51200/71639]
loss: 0.022655  [57600/71639]
loss: 0.108742  [64000/71639]
loss: 0.095398  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.204066 

Epoch 25
-------------------------------
loss: 0.073472  [    0/71639]
loss: 0.004587  [ 6400/71639]
loss: 0.057344  [12800/71639]
loss: 0.019051  [19200/71639]
loss: 0.116094  [25600/71639]
loss: 0.010854  [32000/71639]
loss: 0.027870  [38400/71639]
loss: 0.013130  [44800/71639]
loss: 0.200964  [51200/71639]
loss: 0.042768  [57600/71639]
loss: 0.075102  [64000/71639]
loss: 0.067966  [70400/71639]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.204828 

Epoch 26
-------------------------------
loss: 0.010875  [    0/71639]
loss: 0.062189  [ 6400/71639]
loss: 0.068451  [12800/71639]
loss: 0.041185  [19200/71639]
loss: 0.078010  [25600/71639]
loss: 0.053191  [32000/71639]
loss: 0.005591  [38400/71639]
loss: 0.034372  [44800/71639]
loss: 0.055384  [51200/71639]
loss: 0.083461  [57600/71639]
loss: 0.100852  [64000/71639]
loss: 0.026015  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.198868 

Epoch 27
-------------------------------
loss: 0.017961  [    0/71639]
loss: 1.606578  [ 6400/71639]
loss: 0.072939  [12800/71639]
loss: 0.019552  [19200/71639]
loss: 0.078801  [25600/71639]
loss: 0.085067  [32000/71639]
loss: 0.045602  [38400/71639]
loss: 0.050316  [44800/71639]
loss: 0.114703  [51200/71639]
loss: 0.056059  [57600/71639]
loss: 0.024250  [64000/71639]
loss: 0.028637  [70400/71639]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.203646 

Epoch 28
-------------------------------
loss: 0.070555  [    0/71639]
loss: 0.156258  [ 6400/71639]
loss: 0.165628  [12800/71639]
loss: 0.128115  [19200/71639]
loss: 0.022598  [25600/71639]
loss: 0.043343  [32000/71639]
loss: 0.118945  [38400/71639]
loss: 0.088126  [44800/71639]
loss: 0.054475  [51200/71639]
loss: 0.084002  [57600/71639]
loss: 0.007930  [64000/71639]
loss: 0.033823  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.201621 

Epoch 29
-------------------------------
loss: 0.011437  [    0/71639]
loss: 0.047709  [ 6400/71639]
loss: 0.049118  [12800/71639]
loss: 0.056102  [19200/71639]
loss: 0.083261  [25600/71639]
loss: 0.038377  [32000/71639]
loss: 0.113484  [38400/71639]
loss: 1.673985  [44800/71639]
loss: 0.143550  [51200/71639]
loss: 0.017174  [57600/71639]
loss: 0.063823  [64000/71639]
loss: 0.096317  [70400/71639]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.216190 

Epoch 30
-------------------------------
loss: 0.055261  [    0/71639]
loss: 0.088603  [ 6400/71639]
loss: 0.005434  [12800/71639]
loss: 0.065412  [19200/71639]
loss: 0.046228  [25600/71639]
loss: 0.136516  [32000/71639]
loss: 0.033218  [38400/71639]
loss: 0.013478  [44800/71639]
loss: 0.034165  [51200/71639]
loss: 1.601520  [57600/71639]
loss: 0.061968  [64000/71639]
loss: 0.030640  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.198019 

Epoch 31
-------------------------------
loss: 0.034631  [    0/71639]
loss: 0.075252  [ 6400/71639]
loss: 0.054669  [12800/71639]
loss: 0.060211  [19200/71639]
loss: 0.060631  [25600/71639]
loss: 0.084812  [32000/71639]
loss: 0.062204  [38400/71639]
loss: 0.010471  [44800/71639]
loss: 0.011691  [51200/71639]
loss: 0.010902  [57600/71639]
loss: 3.179169  [64000/71639]
loss: 0.099268  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.200461 

Epoch 32
-------------------------------
loss: 0.070660  [    0/71639]
loss: 0.078530  [ 6400/71639]
loss: 1.749139  [12800/71639]
loss: 0.045417  [19200/71639]
loss: 0.117461  [25600/71639]
loss: 0.135563  [32000/71639]
loss: 0.095567  [38400/71639]
loss: 0.008837  [44800/71639]
loss: 0.086314  [51200/71639]
loss: 0.039611  [57600/71639]
loss: 0.191716  [64000/71639]
loss: 0.045056  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.203587 

Epoch 33
-------------------------------
loss: 1.606175  [    0/71639]
loss: 0.121788  [ 6400/71639]
loss: 1.579666  [12800/71639]
loss: 0.056477  [19200/71639]
loss: 0.041647  [25600/71639]
loss: 0.034317  [32000/71639]
loss: 0.262893  [38400/71639]
loss: 0.115624  [44800/71639]
loss: 0.035536  [51200/71639]
loss: 0.144638  [57600/71639]
loss: 0.057120  [64000/71639]
loss: 0.025499  [70400/71639]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.200193 

Epoch 34
-------------------------------
loss: 0.055699  [    0/71639]
loss: 0.022387  [ 6400/71639]
loss: 0.068754  [12800/71639]
loss: 0.079242  [19200/71639]
loss: 0.047320  [25600/71639]
loss: 0.036917  [32000/71639]
loss: 0.158331  [38400/71639]
loss: 0.043868  [44800/71639]
loss: 0.029707  [51200/71639]
loss: 0.069001  [57600/71639]
loss: 0.057139  [64000/71639]
loss: 0.059659  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.208403 

Epoch 35
-------------------------------
loss: 0.024236  [    0/71639]
loss: 0.117123  [ 6400/71639]
loss: 0.015836  [12800/71639]
loss: 0.055586  [19200/71639]
loss: 0.040719  [25600/71639]
loss: 0.021578  [32000/71639]
loss: 0.084843  [38400/71639]
loss: 0.043333  [44800/71639]
loss: 0.151434  [51200/71639]
loss: 0.117105  [57600/71639]
loss: 0.116186  [64000/71639]
loss: 0.032745  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.200271 

Epoch 36
-------------------------------
loss: 0.052505  [    0/71639]
loss: 1.617242  [ 6400/71639]
loss: 0.046211  [12800/71639]
loss: 0.026008  [19200/71639]
loss: 0.015359  [25600/71639]
loss: 0.050437  [32000/71639]
loss: 0.082496  [38400/71639]
loss: 0.041845  [44800/71639]
loss: 0.068380  [51200/71639]
loss: 0.005423  [57600/71639]
loss: 0.035336  [64000/71639]
loss: 0.045762  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.201399 

Epoch 37
-------------------------------
loss: 0.045545  [    0/71639]
loss: 0.015442  [    0/71724]
loss: 0.022770  [ 6400/71724]
loss: 0.028038  [12800/71724]
loss: 0.015369  [19200/71724]
loss: 0.056513  [25600/71724]
loss: 0.079544  [32000/71724]
loss: 0.032328  [38400/71724]
loss: 0.017452  [44800/71724]
loss: 0.051538  [51200/71724]
loss: 0.025679  [57600/71724]
loss: 0.104372  [64000/71724]
loss: 0.038059  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.060305 

Epoch 20
-------------------------------
loss: 0.033208  [    0/71724]
loss: 0.003153  [ 6400/71724]
loss: 0.028874  [12800/71724]
loss: 0.040900  [19200/71724]
loss: 0.020209  [25600/71724]
loss: 0.167430  [32000/71724]
loss: 0.120129  [38400/71724]
loss: 0.049208  [44800/71724]
loss: 0.045753  [51200/71724]
loss: 0.007651  [57600/71724]
loss: 0.018574  [64000/71724]
loss: 0.003878  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066952 

Epoch 21
-------------------------------
loss: 0.075520  [    0/71724]
loss: 0.126266  [ 6400/71724]
loss: 0.017454  [12800/71724]
loss: 0.095921  [19200/71724]
loss: 0.006500  [25600/71724]
loss: 0.007205  [32000/71724]
loss: 0.061523  [38400/71724]
loss: 0.043513  [44800/71724]
loss: 0.057494  [51200/71724]
loss: 0.127011  [57600/71724]
loss: 0.083441  [64000/71724]
loss: 0.018527  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.061440 

Epoch 22
-------------------------------
loss: 0.037375  [    0/71724]
loss: 0.086889  [ 6400/71724]
loss: 0.017835  [12800/71724]
loss: 0.057191  [19200/71724]
loss: 0.040018  [25600/71724]
loss: 0.013448  [32000/71724]
loss: 0.005293  [38400/71724]
loss: 0.015188  [44800/71724]
loss: 0.089846  [51200/71724]
loss: 0.011887  [57600/71724]
loss: 0.010194  [64000/71724]
loss: 0.093736  [70400/71724]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.077028 

Epoch 23
-------------------------------
loss: 0.008189  [    0/71724]
loss: 0.017974  [ 6400/71724]
loss: 0.015371  [12800/71724]
loss: 0.007075  [19200/71724]
loss: 0.016132  [25600/71724]
loss: 0.031138  [32000/71724]
loss: 0.057117  [38400/71724]
loss: 0.024653  [44800/71724]
loss: 0.050273  [51200/71724]
loss: 0.078650  [57600/71724]
loss: 0.069280  [64000/71724]
loss: 0.011897  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.061613 

Epoch 24
-------------------------------
loss: 0.041219  [    0/71724]
loss: 0.048878  [ 6400/71724]
loss: 0.020093  [12800/71724]
loss: 0.118294  [19200/71724]
loss: 0.027760  [25600/71724]
loss: 0.040390  [32000/71724]
loss: 0.037423  [38400/71724]
loss: 0.014069  [44800/71724]
loss: 0.106739  [51200/71724]
loss: 0.028600  [57600/71724]
loss: 0.022791  [64000/71724]
loss: 0.019609  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.061761 

Epoch 25
-------------------------------
loss: 0.009810  [    0/71724]
loss: 0.035057  [ 6400/71724]
loss: 0.043918  [12800/71724]
loss: 0.063179  [19200/71724]
loss: 0.014175  [25600/71724]
loss: 0.050147  [32000/71724]
loss: 0.026213  [38400/71724]
loss: 0.016114  [44800/71724]
loss: 0.111971  [51200/71724]
loss: 0.047147  [57600/71724]
loss: 0.049555  [64000/71724]
loss: 0.011231  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067250 

Epoch 26
-------------------------------
loss: 0.050317  [    0/71724]
loss: 0.003908  [ 6400/71724]
loss: 0.005429  [12800/71724]
loss: 0.010646  [19200/71724]
loss: 0.034144  [25600/71724]
loss: 0.052153  [32000/71724]
loss: 0.004383  [38400/71724]
loss: 0.068267  [44800/71724]
loss: 0.031510  [51200/71724]
loss: 0.019856  [57600/71724]
loss: 0.134304  [64000/71724]
loss: 0.087776  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066159 

Epoch 27
-------------------------------
loss: 0.036710  [    0/71724]
loss: 0.009463  [ 6400/71724]
loss: 0.022029  [12800/71724]
loss: 0.123905  [19200/71724]
loss: 0.003509  [25600/71724]
loss: 0.050748  [32000/71724]
loss: 0.011925  [38400/71724]
loss: 0.095645  [44800/71724]
loss: 0.013622  [51200/71724]
loss: 0.024209  [57600/71724]
loss: 0.068458  [64000/71724]
loss: 0.003288  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067798 

Epoch 28
-------------------------------
loss: 0.017545  [    0/71724]
loss: 0.035620  [ 6400/71724]
loss: 0.014565  [12800/71724]
loss: 0.025743  [19200/71724]
loss: 0.006341  [25600/71724]
loss: 0.004260  [32000/71724]
loss: 0.050309  [38400/71724]
loss: 0.009271  [44800/71724]
loss: 0.026567  [51200/71724]
loss: 0.019005  [57600/71724]
loss: 0.047059  [64000/71724]
loss: 0.041416  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.061889 

Epoch 29
-------------------------------
loss: 0.109470  [    0/71724]
loss: 0.033575  [ 6400/71724]
loss: 0.027844  [12800/71724]
loss: 0.144849  [19200/71724]
loss: 0.017389  [25600/71724]
loss: 0.142883  [32000/71724]
loss: 0.027675  [38400/71724]
loss: 0.003692  [44800/71724]
loss: 0.018591  [51200/71724]
loss: 0.188064  [57600/71724]
loss: 0.125107  [64000/71724]
loss: 0.081992  [70400/71724]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077065 

Epoch 30
-------------------------------
loss: 0.025097  [    0/71724]
loss: 0.020819  [ 6400/71724]
loss: 0.020246  [12800/71724]
loss: 0.026127  [19200/71724]
loss: 0.012770  [25600/71724]
loss: 0.070103  [32000/71724]
loss: 0.109340  [38400/71724]
loss: 0.072302  [44800/71724]
loss: 0.007504  [51200/71724]
loss: 0.014778  [57600/71724]
loss: 0.027143  [64000/71724]
loss: 0.008698  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.069223 

Epoch 31
-------------------------------
loss: 0.084739  [    0/71724]
loss: 0.028841  [ 6400/71724]
loss: 0.029824  [12800/71724]
loss: 0.092404  [19200/71724]
loss: 0.025291  [25600/71724]
loss: 0.018186  [32000/71724]
loss: 0.022771  [38400/71724]
loss: 0.007419  [44800/71724]
loss: 0.028843  [51200/71724]
loss: 0.025606  [57600/71724]
loss: 0.021246  [64000/71724]
loss: 0.032561  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.074757 

Epoch 32
-------------------------------
loss: 0.025834  [    0/71724]
loss: 0.117345  [ 6400/71724]
loss: 0.004562  [12800/71724]
loss: 0.011449  [19200/71724]
loss: 0.010428  [25600/71724]
loss: 0.011988  [32000/71724]
loss: 0.005738  [38400/71724]
loss: 0.095382  [44800/71724]
loss: 0.046232  [51200/71724]
loss: 0.027864  [57600/71724]
loss: 0.010855  [64000/71724]
loss: 0.035101  [70400/71724]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083128 

Epoch 33
-------------------------------
loss: 0.024476  [    0/71724]
loss: 0.010518  [ 6400/71724]
loss: 0.071483  [12800/71724]
loss: 0.020141  [19200/71724]
loss: 0.087069  [25600/71724]
loss: 0.074707  [32000/71724]
loss: 0.056494  [38400/71724]
loss: 0.005144  [44800/71724]
loss: 0.022082  [51200/71724]
loss: 0.136779  [57600/71724]
loss: 0.016260  [64000/71724]
loss: 0.029210  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.070699 

Epoch 34
-------------------------------
loss: 0.016663  [    0/71724]
loss: 0.023372  [ 6400/71724]
loss: 0.018987  [12800/71724]
loss: 0.009900  [19200/71724]
loss: 0.068462  [25600/71724]
loss: 0.011168  [32000/71724]
loss: 0.011111  [38400/71724]
loss: 0.044541  [44800/71724]
loss: 0.014779  [51200/71724]
loss: 0.020863  [57600/71724]
loss: 0.037328  [64000/71724]
loss: 0.023191  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072048 

Epoch 35
-------------------------------
loss: 0.043490  [    0/71724]
loss: 0.043802  [ 6400/71724]
loss: 0.076034  [12800/71724]
loss: 0.011664  [19200/71724]
loss: 0.010380  [25600/71724]
loss: 0.035266  [32000/71724]
loss: 0.045688  [38400/71724]
loss: 0.035676  [44800/71724]
loss: 0.029168  [51200/71724]
loss: 0.002504  [57600/71724]
loss: 0.016162  [64000/71724]
loss: 0.008727  [70400/71724]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.198372 

Epoch 36
-------------------------------
loss: 0.008077  [    0/71724]
loss: 0.174903  [ 6400/71724]
loss: 0.071050  [12800/71724]
loss: 0.056200  [19200/71724]
loss: 0.024301  [25600/71724]
loss: 0.010677  [32000/71724]
loss: 0.022066  [38400/71724]
loss: 0.030149  [44800/71724]
loss: 0.060046  [51200/71724]
loss: 0.049656  [57600/71724]
loss: 0.007020  [64000/71724]
loss: 0.101447  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069894 

Epoch 37
-------------------------------
loss: 0.091608  [    0/71724]
loss: 0.103053  [    0/71297]
loss: 0.027729  [ 6400/71297]
loss: 0.047428  [12800/71297]
loss: 0.002454  [19200/71297]
loss: 0.043445  [25600/71297]
loss: 0.025348  [32000/71297]
loss: 0.012298  [38400/71297]
loss: 0.050743  [44800/71297]
loss: 0.088011  [51200/71297]
loss: 0.079847  [57600/71297]
loss: 0.068107  [64000/71297]
loss: 0.027369  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.083872 

Epoch 20
-------------------------------
loss: 0.025758  [    0/71297]
loss: 0.034340  [ 6400/71297]
loss: 0.065736  [12800/71297]
loss: 0.063526  [19200/71297]
loss: 0.028841  [25600/71297]
loss: 0.124752  [32000/71297]
loss: 0.144591  [38400/71297]
loss: 0.007008  [44800/71297]
loss: 0.050683  [51200/71297]
loss: 0.077952  [57600/71297]
loss: 0.098747  [64000/71297]
loss: 0.096563  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.082017 

Epoch 21
-------------------------------
loss: 0.037062  [    0/71297]
loss: 0.049462  [ 6400/71297]
loss: 0.032418  [12800/71297]
loss: 0.021670  [19200/71297]
loss: 0.096588  [25600/71297]
loss: 0.017343  [32000/71297]
loss: 0.031935  [38400/71297]
loss: 0.057372  [44800/71297]
loss: 0.029417  [51200/71297]
loss: 0.031050  [57600/71297]
loss: 0.010200  [64000/71297]
loss: 0.012174  [70400/71297]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.084975 

Epoch 22
-------------------------------
loss: 0.045892  [    0/71297]
loss: 0.011610  [ 6400/71297]
loss: 0.191993  [12800/71297]
loss: 0.037661  [19200/71297]
loss: 0.015369  [25600/71297]
loss: 0.063242  [32000/71297]
loss: 0.031891  [38400/71297]
loss: 0.036974  [44800/71297]
loss: 0.047634  [51200/71297]
loss: 0.018699  [57600/71297]
loss: 0.123335  [64000/71297]
loss: 0.028978  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.085801 

Epoch 23
-------------------------------
loss: 0.026944  [    0/71297]
loss: 0.035284  [ 6400/71297]
loss: 0.013866  [12800/71297]
loss: 0.010668  [19200/71297]
loss: 0.110608  [25600/71297]
loss: 0.006931  [32000/71297]
loss: 0.066260  [38400/71297]
loss: 0.044084  [44800/71297]
loss: 0.067557  [51200/71297]
loss: 0.053511  [57600/71297]
loss: 0.064541  [64000/71297]
loss: 0.040948  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.085368 

Epoch 24
-------------------------------
loss: 0.123666  [    0/71297]
loss: 0.053589  [ 6400/71297]
loss: 0.057963  [12800/71297]
loss: 0.057756  [19200/71297]
loss: 0.052715  [25600/71297]
loss: 0.083010  [32000/71297]
loss: 0.058671  [38400/71297]
loss: 0.044432  [44800/71297]
loss: 0.022446  [51200/71297]
loss: 0.007932  [57600/71297]
loss: 0.075740  [64000/71297]
loss: 0.079733  [70400/71297]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.097927 

Epoch 25
-------------------------------
loss: 0.008137  [    0/71297]
loss: 0.095795  [ 6400/71297]
loss: 0.039429  [12800/71297]
loss: 0.064339  [19200/71297]
loss: 0.019096  [25600/71297]
loss: 0.021802  [32000/71297]
loss: 0.013589  [38400/71297]
loss: 0.084949  [44800/71297]
loss: 0.018571  [51200/71297]
loss: 0.063439  [57600/71297]
loss: 0.101649  [64000/71297]
loss: 0.050263  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.085217 

Epoch 26
-------------------------------
loss: 0.034527  [    0/71297]
loss: 0.033185  [ 6400/71297]
loss: 0.025422  [12800/71297]
loss: 0.078099  [19200/71297]
loss: 0.088784  [25600/71297]
loss: 0.054975  [32000/71297]
loss: 0.062070  [38400/71297]
loss: 0.104905  [44800/71297]
loss: 0.038737  [51200/71297]
loss: 0.004206  [57600/71297]
loss: 0.083115  [64000/71297]
loss: 0.042315  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.086035 

Epoch 27
-------------------------------
loss: 0.070332  [    0/71297]
loss: 0.042565  [ 6400/71297]
loss: 0.046890  [12800/71297]
loss: 0.017775  [19200/71297]
loss: 0.086988  [25600/71297]
loss: 0.048601  [32000/71297]
loss: 0.164387  [38400/71297]
loss: 0.028784  [44800/71297]
loss: 0.021655  [51200/71297]
loss: 0.169671  [57600/71297]
loss: 0.042777  [64000/71297]
loss: 0.066310  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.086600 

Epoch 28
-------------------------------
loss: 0.048450  [    0/71297]
loss: 0.175860  [ 6400/71297]
loss: 0.023832  [12800/71297]
loss: 0.049144  [19200/71297]
loss: 0.014794  [25600/71297]
loss: 0.060398  [32000/71297]
loss: 0.057582  [38400/71297]
loss: 0.048644  [44800/71297]
loss: 0.039846  [51200/71297]
loss: 0.049642  [57600/71297]
loss: 0.054511  [64000/71297]
loss: 0.101012  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.086642 

Epoch 29
-------------------------------
loss: 0.002691  [    0/71297]
loss: 0.021232  [ 6400/71297]
loss: 0.038632  [12800/71297]
loss: 0.014043  [19200/71297]
loss: 0.051351  [25600/71297]
loss: 0.035695  [32000/71297]
loss: 1.622547  [38400/71297]
loss: 0.182114  [44800/71297]
loss: 0.033735  [51200/71297]
loss: 0.002802  [57600/71297]
loss: 0.043477  [64000/71297]
loss: 0.173023  [70400/71297]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.087848 

Epoch 30
-------------------------------
loss: 0.064641  [    0/71297]
loss: 0.077056  [ 6400/71297]
loss: 0.020659  [12800/71297]
loss: 0.090324  [19200/71297]
loss: 0.065258  [25600/71297]
loss: 0.028431  [32000/71297]
loss: 0.072050  [38400/71297]
loss: 0.060884  [44800/71297]
loss: 0.008734  [51200/71297]
loss: 0.010979  [57600/71297]
loss: 0.000908  [64000/71297]
loss: 0.009005  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.092073 

Epoch 31
-------------------------------
loss: 0.014927  [    0/71297]
loss: 0.031532  [ 6400/71297]
loss: 0.113530  [12800/71297]
loss: 0.024047  [19200/71297]
loss: 0.109933  [25600/71297]
loss: 0.029044  [32000/71297]
loss: 0.105444  [38400/71297]
loss: 0.104535  [44800/71297]
loss: 0.156088  [51200/71297]
loss: 0.132279  [57600/71297]
loss: 0.018400  [64000/71297]
loss: 0.074268  [70400/71297]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.089130 

Epoch 32
-------------------------------
loss: 0.095910  [    0/71297]
loss: 0.055418  [ 6400/71297]
loss: 0.027245  [12800/71297]
loss: 0.033872  [19200/71297]
loss: 0.016739  [25600/71297]
loss: 1.669752  [32000/71297]
loss: 0.033927  [38400/71297]
loss: 0.089078  [44800/71297]
loss: 0.019137  [51200/71297]
loss: 0.026388  [57600/71297]
loss: 0.014632  [64000/71297]
loss: 0.034107  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.085652 

Epoch 33
-------------------------------
loss: 0.012246  [    0/71297]
loss: 0.027619  [ 6400/71297]
loss: 0.045671  [12800/71297]
loss: 0.074543  [19200/71297]
loss: 0.047188  [25600/71297]
loss: 0.018417  [32000/71297]
loss: 0.127906  [38400/71297]
loss: 0.083259  [44800/71297]
loss: 0.095611  [51200/71297]
loss: 0.017904  [57600/71297]
loss: 0.033574  [64000/71297]
loss: 0.108087  [70400/71297]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.094657 

Epoch 34
-------------------------------
loss: 0.079294  [    0/71297]
loss: 0.030569  [ 6400/71297]
loss: 0.130694  [12800/71297]
loss: 0.010970  [19200/71297]
loss: 0.132425  [25600/71297]
loss: 0.064577  [32000/71297]
loss: 0.009785  [38400/71297]
loss: 0.010015  [44800/71297]
loss: 0.170346  [51200/71297]
loss: 0.028907  [57600/71297]
loss: 0.008821  [64000/71297]
loss: 0.011552  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.101454 

Epoch 35
-------------------------------
loss: 0.002415  [    0/71297]
loss: 0.016486  [ 6400/71297]
loss: 0.026391  [12800/71297]
loss: 1.711614  [19200/71297]
loss: 0.015878  [25600/71297]
loss: 0.066064  [32000/71297]
loss: 0.043035  [38400/71297]
loss: 0.005240  [44800/71297]
loss: 0.057044  [51200/71297]
loss: 0.050700  [57600/71297]
loss: 0.038222  [64000/71297]
loss: 0.141141  [70400/71297]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.089116 

Epoch 36
-------------------------------
loss: 0.056887  [    0/71297]
loss: 0.150881  [ 6400/71297]
loss: 0.057056  [12800/71297]
loss: 0.037535  [19200/71297]
loss: 0.024090  [25600/71297]
loss: 0.162564  [32000/71297]
loss: 0.012320  [38400/71297]
loss: 0.006804  [44800/71297]
loss: 0.026626  [51200/71297]
loss: 0.046664  [57600/71297]
loss: 0.041146  [64000/71297]
loss: 0.057103  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.086621 

Epoch 37
-------------------------------
loss: 0.019184  [    0/71297]
loss: 0.001309  [    0/72202]
loss: 0.004835  [ 6400/72202]
loss: 0.083307  [12800/72202]
loss: 0.039123  [19200/72202]
loss: 0.009149  [25600/72202]
loss: 0.024920  [32000/72202]
loss: 0.051299  [38400/72202]
loss: 0.026811  [44800/72202]
loss: 0.006924  [51200/72202]
loss: 0.088086  [57600/72202]
loss: 0.002334  [64000/72202]
loss: 0.009401  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.076932 

Epoch 20
-------------------------------
loss: 0.103537  [    0/72202]
loss: 0.012758  [ 6400/72202]
loss: 0.008181  [12800/72202]
loss: 0.034637  [19200/72202]
loss: 0.006213  [25600/72202]
loss: 0.165412  [32000/72202]
loss: 0.029344  [38400/72202]
loss: 0.042237  [44800/72202]
loss: 0.021944  [51200/72202]
loss: 0.003511  [57600/72202]
loss: 0.004047  [64000/72202]
loss: 0.053610  [70400/72202]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.073154 

Epoch 21
-------------------------------
loss: 0.024983  [    0/72202]
loss: 0.145025  [ 6400/72202]
loss: 0.011369  [12800/72202]
loss: 0.035961  [19200/72202]
loss: 0.025380  [25600/72202]
loss: 0.002794  [32000/72202]
loss: 0.042349  [38400/72202]
loss: 0.007691  [44800/72202]
loss: 0.028375  [51200/72202]
loss: 0.034026  [57600/72202]
loss: 0.008062  [64000/72202]
loss: 0.045978  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.078439 

Epoch 22
-------------------------------
loss: 0.022833  [    0/72202]
loss: 0.031293  [ 6400/72202]
loss: 0.135985  [12800/72202]
loss: 0.007644  [19200/72202]
loss: 0.002827  [25600/72202]
loss: 0.006500  [32000/72202]
loss: 0.017441  [38400/72202]
loss: 0.019044  [44800/72202]
loss: 0.006238  [51200/72202]
loss: 0.028161  [57600/72202]
loss: 0.020448  [64000/72202]
loss: 0.004388  [70400/72202]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.085172 

Epoch 23
-------------------------------
loss: 0.020248  [    0/72202]
loss: 0.004634  [ 6400/72202]
loss: 0.008843  [12800/72202]
loss: 0.010135  [19200/72202]
loss: 0.004986  [25600/72202]
loss: 0.042277  [32000/72202]
loss: 0.028992  [38400/72202]
loss: 0.011540  [44800/72202]
loss: 0.008261  [51200/72202]
loss: 0.057598  [57600/72202]
loss: 0.038465  [64000/72202]
loss: 0.054119  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.076712 

Epoch 24
-------------------------------
loss: 0.036759  [    0/72202]
loss: 0.019193  [ 6400/72202]
loss: 0.129800  [12800/72202]
loss: 0.006679  [19200/72202]
loss: 0.040199  [25600/72202]
loss: 0.006838  [32000/72202]
loss: 0.004211  [38400/72202]
loss: 0.007461  [44800/72202]
loss: 0.033668  [51200/72202]
loss: 0.008549  [57600/72202]
loss: 0.079145  [64000/72202]
loss: 0.007457  [70400/72202]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.075506 

Epoch 25
-------------------------------
loss: 0.067923  [    0/72202]
loss: 0.006258  [ 6400/72202]
loss: 0.027082  [12800/72202]
loss: 0.028738  [19200/72202]
loss: 0.163872  [25600/72202]
loss: 0.103987  [32000/72202]
loss: 0.024692  [38400/72202]
loss: 0.025639  [44800/72202]
loss: 0.003958  [51200/72202]
loss: 0.007075  [57600/72202]
loss: 0.001632  [64000/72202]
loss: 0.004770  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.080279 

Epoch 26
-------------------------------
loss: 0.005892  [    0/72202]
loss: 0.009299  [ 6400/72202]
loss: 0.043802  [12800/72202]
loss: 0.037295  [19200/72202]
loss: 0.028694  [25600/72202]
loss: 0.024284  [32000/72202]
loss: 0.018241  [38400/72202]
loss: 0.039960  [44800/72202]
loss: 0.032801  [51200/72202]
loss: 0.035337  [57600/72202]
loss: 0.025809  [64000/72202]
loss: 0.004048  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.080297 

Epoch 27
-------------------------------
loss: 0.147202  [    0/72202]
loss: 0.008887  [ 6400/72202]
loss: 0.024717  [12800/72202]
loss: 0.011412  [19200/72202]
loss: 0.018927  [25600/72202]
loss: 1.566642  [32000/72202]
loss: 0.017424  [38400/72202]
loss: 0.003343  [44800/72202]
loss: 0.014077  [51200/72202]
loss: 0.001387  [57600/72202]
loss: 0.012620  [64000/72202]
loss: 0.015907  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.090129 

Epoch 28
-------------------------------
loss: 0.036812  [    0/72202]
loss: 0.007260  [ 6400/72202]
loss: 0.002512  [12800/72202]
loss: 0.097954  [19200/72202]
loss: 0.036686  [25600/72202]
loss: 0.019362  [32000/72202]
loss: 0.000644  [38400/72202]
loss: 0.008033  [44800/72202]
loss: 0.004879  [51200/72202]
loss: 0.013670  [57600/72202]
loss: 0.004293  [64000/72202]
loss: 0.002740  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.081997 

Epoch 29
-------------------------------
loss: 0.019311  [    0/72202]
loss: 0.024236  [ 6400/72202]
loss: 0.007580  [12800/72202]
loss: 0.002721  [19200/72202]
loss: 0.004395  [25600/72202]
loss: 0.009953  [32000/72202]
loss: 0.060486  [38400/72202]
loss: 0.045943  [44800/72202]
loss: 0.023121  [51200/72202]
loss: 0.031764  [57600/72202]
loss: 0.050674  [64000/72202]
loss: 0.004418  [70400/72202]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.076664 

Epoch 30
-------------------------------
loss: 0.015101  [    0/72202]
loss: 0.043007  [ 6400/72202]
loss: 0.031721  [12800/72202]
loss: 0.013114  [19200/72202]
loss: 0.110136  [25600/72202]
loss: 0.003043  [32000/72202]
loss: 0.006034  [38400/72202]
loss: 0.030293  [44800/72202]
loss: 0.007271  [51200/72202]
loss: 0.035909  [57600/72202]
loss: 0.013071  [64000/72202]
loss: 0.017803  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.088108 

Epoch 31
-------------------------------
loss: 0.046835  [    0/72202]
loss: 0.056517  [ 6400/72202]
loss: 0.005880  [12800/72202]
loss: 0.008038  [19200/72202]
loss: 0.059989  [25600/72202]
loss: 0.013737  [32000/72202]
loss: 0.006024  [38400/72202]
loss: 0.013867  [44800/72202]
loss: 0.004877  [51200/72202]
loss: 0.002108  [57600/72202]
loss: 0.053667  [64000/72202]
loss: 0.018689  [70400/72202]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.087278 

Epoch 32
-------------------------------
loss: 0.113303  [    0/72202]
loss: 0.002477  [ 6400/72202]
loss: 0.066694  [12800/72202]
loss: 0.001901  [19200/72202]
loss: 0.006279  [25600/72202]
loss: 0.035226  [32000/72202]
loss: 0.003111  [38400/72202]
loss: 0.005576  [44800/72202]
loss: 0.053346  [51200/72202]
loss: 0.058820  [57600/72202]
loss: 0.021183  [64000/72202]
loss: 0.015673  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.086921 

Epoch 33
-------------------------------
loss: 0.050748  [    0/72202]
loss: 0.072796  [ 6400/72202]
loss: 0.015075  [12800/72202]
loss: 0.030102  [19200/72202]
loss: 1.569985  [25600/72202]
loss: 0.075812  [32000/72202]
loss: 0.034618  [38400/72202]
loss: 0.041400  [44800/72202]
loss: 0.008385  [51200/72202]
loss: 0.022011  [57600/72202]
loss: 0.045603  [64000/72202]
loss: 0.000601  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.090187 

Epoch 34
-------------------------------
loss: 0.025979  [    0/72202]
loss: 0.010150  [ 6400/72202]
loss: 0.004026  [12800/72202]
loss: 0.022290  [19200/72202]
loss: 0.007951  [25600/72202]
loss: 0.004765  [32000/72202]
loss: 0.000492  [38400/72202]
loss: 0.005908  [44800/72202]
loss: 0.012019  [51200/72202]
loss: 0.004631  [57600/72202]
loss: 0.057577  [64000/72202]
loss: 0.005904  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.083759 

Epoch 35
-------------------------------
loss: 0.004476  [    0/72202]
loss: 0.015980  [ 6400/72202]
loss: 0.015261  [12800/72202]
loss: 0.011892  [19200/72202]
loss: 0.003432  [25600/72202]
loss: 0.024889  [32000/72202]
loss: 0.005747  [38400/72202]
loss: 0.002882  [44800/72202]
loss: 0.001415  [51200/72202]
loss: 0.081042  [57600/72202]
loss: 0.039320  [64000/72202]
loss: 0.033469  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.082894 

Epoch 36
-------------------------------
loss: 0.001603  [    0/72202]
loss: 0.001545  [ 6400/72202]
loss: 0.056211  [12800/72202]
loss: 0.002117  [19200/72202]
loss: 0.000726  [25600/72202]
loss: 0.032316  [32000/72202]
loss: 0.056954  [38400/72202]
loss: 0.030943  [44800/72202]
loss: 0.018218  [51200/72202]
loss: 0.002370  [57600/72202]
loss: 0.000307  [64000/72202]
loss: 0.037210  [70400/72202]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.198294 

Epoch 37
-------------------------------
loss: 0.239126  [    0/72202]
loss: 0.078069  [    0/70508]
loss: 0.052363  [ 6400/70508]
loss: 0.048780  [12800/70508]
loss: 0.079055  [19200/70508]
loss: 0.079769  [25600/70508]
loss: 0.073265  [32000/70508]
loss: 0.168044  [38400/70508]
loss: 0.032864  [44800/70508]
loss: 0.077510  [51200/70508]
loss: 0.064749  [57600/70508]
loss: 0.065577  [64000/70508]
loss: 0.127827  [70400/70508]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.147896 

Epoch 20
-------------------------------
loss: 0.074802  [    0/70508]
loss: 0.158263  [ 6400/70508]
loss: 0.047602  [12800/70508]
loss: 0.043723  [19200/70508]
loss: 0.218988  [25600/70508]
loss: 0.042222  [32000/70508]
loss: 0.050860  [38400/70508]
loss: 0.077055  [44800/70508]
loss: 0.083086  [51200/70508]
loss: 0.183264  [57600/70508]
loss: 0.119257  [64000/70508]
loss: 0.060572  [70400/70508]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.159083 

Epoch 21
-------------------------------
loss: 0.120381  [    0/70508]
loss: 0.025665  [ 6400/70508]
loss: 0.135286  [12800/70508]
loss: 0.103941  [19200/70508]
loss: 0.099048  [25600/70508]
loss: 0.139316  [32000/70508]
loss: 0.084556  [38400/70508]
loss: 0.055086  [44800/70508]
loss: 0.120297  [51200/70508]
loss: 0.151415  [57600/70508]
loss: 0.051719  [64000/70508]
loss: 0.118133  [70400/70508]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.153162 

Epoch 22
-------------------------------
loss: 0.129833  [    0/70508]
loss: 0.075117  [ 6400/70508]
loss: 0.039534  [12800/70508]
loss: 0.099219  [19200/70508]
loss: 0.079096  [25600/70508]
loss: 0.066502  [32000/70508]
loss: 0.052995  [38400/70508]
loss: 0.086648  [44800/70508]
loss: 0.062051  [51200/70508]
loss: 0.119518  [57600/70508]
loss: 0.163472  [64000/70508]
loss: 0.053054  [70400/70508]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.151581 

Epoch 23
-------------------------------
loss: 0.063553  [    0/70508]
loss: 0.034000  [ 6400/70508]
loss: 0.085402  [12800/70508]
loss: 0.135281  [19200/70508]
loss: 0.059774  [25600/70508]
loss: 0.050082  [32000/70508]
loss: 0.068194  [38400/70508]
loss: 0.025529  [44800/70508]
loss: 0.064389  [51200/70508]
loss: 0.110333  [57600/70508]
loss: 0.041043  [64000/70508]
loss: 0.023908  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.146855 

Epoch 24
-------------------------------
loss: 0.108353  [    0/70508]
loss: 0.078317  [ 6400/70508]
loss: 0.092171  [12800/70508]
loss: 0.076151  [19200/70508]
loss: 0.077657  [25600/70508]
loss: 0.090640  [32000/70508]
loss: 0.056825  [38400/70508]
loss: 0.078647  [44800/70508]
loss: 0.066286  [51200/70508]
loss: 0.051908  [57600/70508]
loss: 0.075156  [64000/70508]
loss: 0.081721  [70400/70508]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.147393 

Epoch 25
-------------------------------
loss: 0.060860  [    0/70508]
loss: 0.030345  [ 6400/70508]
loss: 0.039835  [12800/70508]
loss: 0.037451  [19200/70508]
loss: 0.063936  [25600/70508]
loss: 0.075020  [32000/70508]
loss: 0.072076  [38400/70508]
loss: 0.023050  [44800/70508]
loss: 0.145099  [51200/70508]
loss: 0.073804  [57600/70508]
loss: 0.057143  [64000/70508]
loss: 0.058578  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.148369 

Epoch 26
-------------------------------
loss: 0.072415  [    0/70508]
loss: 0.077786  [ 6400/70508]
loss: 0.109861  [12800/70508]
loss: 0.104112  [19200/70508]
loss: 0.091966  [25600/70508]
loss: 0.078418  [32000/70508]
loss: 0.060108  [38400/70508]
loss: 0.068437  [44800/70508]
loss: 0.041660  [51200/70508]
loss: 0.109039  [57600/70508]
loss: 0.112091  [64000/70508]
loss: 0.059001  [70400/70508]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.141444 

Epoch 27
-------------------------------
loss: 0.079795  [    0/70508]
loss: 0.091489  [ 6400/70508]
loss: 0.040345  [12800/70508]
loss: 0.060336  [19200/70508]
loss: 0.031228  [25600/70508]
loss: 0.051092  [32000/70508]
loss: 0.110840  [38400/70508]
loss: 0.049727  [44800/70508]
loss: 0.035390  [51200/70508]
loss: 0.093853  [57600/70508]
loss: 0.028502  [64000/70508]
loss: 0.125274  [70400/70508]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.155842 

Epoch 28
-------------------------------
loss: 0.106863  [    0/70508]
loss: 0.020978  [ 6400/70508]
loss: 0.053257  [12800/70508]
loss: 0.038005  [19200/70508]
loss: 0.060176  [25600/70508]
loss: 0.039848  [32000/70508]
loss: 0.015545  [38400/70508]
loss: 0.038075  [44800/70508]
loss: 0.055687  [51200/70508]
loss: 0.045275  [57600/70508]
loss: 0.096018  [64000/70508]
loss: 0.053253  [70400/70508]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.142531 

Epoch 29
-------------------------------
loss: 0.057729  [    0/70508]
loss: 0.099017  [ 6400/70508]
loss: 0.070233  [12800/70508]
loss: 0.071001  [19200/70508]
loss: 0.058330  [25600/70508]
loss: 0.100402  [32000/70508]
loss: 0.024320  [38400/70508]
loss: 0.076020  [44800/70508]
loss: 0.146819  [51200/70508]
loss: 0.216354  [57600/70508]
loss: 0.064183  [64000/70508]
loss: 0.083221  [70400/70508]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.164287 

Epoch 30
-------------------------------
loss: 0.112590  [    0/70508]
loss: 0.070969  [ 6400/70508]
loss: 1.601159  [12800/70508]
loss: 0.166714  [19200/70508]
loss: 0.123102  [25600/70508]
loss: 0.049236  [32000/70508]
loss: 0.026380  [38400/70508]
loss: 0.040132  [44800/70508]
loss: 0.085853  [51200/70508]
loss: 0.074743  [57600/70508]
loss: 0.048863  [64000/70508]
loss: 0.021033  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.143068 

Epoch 31
-------------------------------
loss: 0.059432  [    0/70508]
loss: 0.083152  [ 6400/70508]
loss: 0.130146  [12800/70508]
loss: 0.032712  [19200/70508]
loss: 0.127330  [25600/70508]
loss: 0.109102  [32000/70508]
loss: 0.005797  [38400/70508]
loss: 0.016083  [44800/70508]
loss: 0.045543  [51200/70508]
loss: 0.087148  [57600/70508]
loss: 0.154680  [64000/70508]
loss: 0.105340  [70400/70508]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.143193 

Epoch 32
-------------------------------
loss: 0.100284  [    0/70508]
loss: 0.068494  [ 6400/70508]
loss: 0.084544  [12800/70508]
loss: 0.025238  [19200/70508]
loss: 0.070765  [25600/70508]
loss: 0.069582  [32000/70508]
loss: 0.020706  [38400/70508]
loss: 0.063567  [44800/70508]
loss: 0.047934  [51200/70508]
loss: 0.061305  [57600/70508]
loss: 0.048702  [64000/70508]
loss: 0.035759  [70400/70508]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.146644 

Epoch 33
-------------------------------
loss: 0.016276  [    0/70508]
loss: 0.003367  [ 6400/70508]
loss: 0.071247  [12800/70508]
loss: 0.069651  [19200/70508]
loss: 0.097032  [25600/70508]
loss: 0.048900  [32000/70508]
loss: 0.042307  [38400/70508]
loss: 0.069603  [44800/70508]
loss: 0.051353  [51200/70508]
loss: 0.054498  [57600/70508]
loss: 0.102336  [64000/70508]
loss: 0.026622  [70400/70508]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.158825 

Epoch 34
-------------------------------
loss: 0.047656  [    0/70508]
loss: 0.041056  [ 6400/70508]
loss: 0.052608  [12800/70508]
loss: 0.060246  [19200/70508]
loss: 0.060399  [25600/70508]
loss: 0.139329  [32000/70508]
loss: 0.024334  [38400/70508]
loss: 0.159393  [44800/70508]
loss: 0.074073  [51200/70508]
loss: 0.081613  [57600/70508]
loss: 0.014115  [64000/70508]
loss: 0.064982  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.146946 

Epoch 35
-------------------------------
loss: 0.096336  [    0/70508]
loss: 0.166825  [ 6400/70508]
loss: 0.128515  [12800/70508]
loss: 0.053115  [19200/70508]
loss: 0.057029  [25600/70508]
loss: 0.118580  [32000/70508]
loss: 0.081685  [38400/70508]
loss: 0.089310  [44800/70508]
loss: 0.140250  [51200/70508]
loss: 0.106651  [57600/70508]
loss: 0.105927  [64000/70508]
loss: 0.038672  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.145285 

Epoch 36
-------------------------------
loss: 0.071618  [    0/70508]
loss: 0.015679  [ 6400/70508]
loss: 0.045725  [12800/70508]
loss: 0.118239  [19200/70508]
loss: 0.063686  [25600/70508]
loss: 0.076566  [32000/70508]
loss: 0.182121  [38400/70508]
loss: 0.082053  [44800/70508]
loss: 0.051854  [51200/70508]
loss: 0.036281  [57600/70508]
loss: 0.064417  [64000/70508]
loss: 0.129392  [70400/70508]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.151180 

Epoch 37
-------------------------------
loss: 0.058246  [    0/70508]
loss: 0.118773  [25600/70296]
loss: 0.062917  [32000/70296]
loss: 0.121550  [38400/70296]
loss: 0.082346  [44800/70296]
loss: 0.092739  [51200/70296]
loss: 0.068673  [57600/70296]
loss: 0.071389  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075939 

Epoch 21
-------------------------------
loss: 0.071492  [    0/70296]
loss: 0.015671  [ 6400/70296]
loss: 0.053493  [12800/70296]
loss: 0.237597  [19200/70296]
loss: 0.060409  [25600/70296]
loss: 0.063906  [32000/70296]
loss: 0.048103  [38400/70296]
loss: 0.052279  [44800/70296]
loss: 0.036784  [51200/70296]
loss: 0.052432  [57600/70296]
loss: 0.095477  [64000/70296]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073013 

Epoch 22
-------------------------------
loss: 0.030888  [    0/70296]
loss: 0.081427  [ 6400/70296]
loss: 0.026090  [12800/70296]
loss: 0.069754  [19200/70296]
loss: 0.041523  [25600/70296]
loss: 0.035198  [32000/70296]
loss: 0.036790  [38400/70296]
loss: 0.067719  [44800/70296]
loss: 0.085563  [51200/70296]
loss: 0.084883  [57600/70296]
loss: 0.051099  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074737 

Epoch 23
-------------------------------
loss: 0.033079  [    0/70296]
loss: 0.087706  [ 6400/70296]
loss: 0.095826  [12800/70296]
loss: 0.022194  [19200/70296]
loss: 0.020537  [25600/70296]
loss: 0.023327  [32000/70296]
loss: 0.202493  [38400/70296]
loss: 0.053117  [44800/70296]
loss: 0.033059  [51200/70296]
loss: 0.075184  [57600/70296]
loss: 0.043293  [64000/70296]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.091348 

Epoch 24
-------------------------------
loss: 0.090911  [    0/70296]
loss: 0.061526  [ 6400/70296]
loss: 0.010643  [12800/70296]
loss: 0.039669  [19200/70296]
loss: 0.024216  [25600/70296]
loss: 0.095393  [32000/70296]
loss: 0.123149  [38400/70296]
loss: 0.052764  [44800/70296]
loss: 0.210545  [51200/70296]
loss: 0.073464  [57600/70296]
loss: 0.148455  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083111 

Epoch 25
-------------------------------
loss: 0.015595  [    0/70296]
loss: 0.029699  [ 6400/70296]
loss: 0.022011  [12800/70296]
loss: 0.091494  [19200/70296]
loss: 0.054235  [25600/70296]
loss: 0.087208  [32000/70296]
loss: 0.030841  [38400/70296]
loss: 0.009174  [44800/70296]
loss: 0.133788  [51200/70296]
loss: 0.124627  [57600/70296]
loss: 0.024103  [64000/70296]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.083921 

Epoch 26
-------------------------------
loss: 0.064772  [    0/70296]
loss: 0.024941  [ 6400/70296]
loss: 0.082818  [12800/70296]
loss: 0.017453  [19200/70296]
loss: 0.049980  [25600/70296]
loss: 0.042258  [32000/70296]
loss: 0.053231  [38400/70296]
loss: 0.097777  [44800/70296]
loss: 0.154253  [51200/70296]
loss: 0.072382  [57600/70296]
loss: 0.015598  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.079621 

Epoch 27
-------------------------------
loss: 0.073719  [    0/70296]
loss: 0.155558  [ 6400/70296]
loss: 0.082454  [12800/70296]
loss: 0.129436  [19200/70296]
loss: 0.106634  [25600/70296]
loss: 0.033411  [32000/70296]
loss: 0.052907  [38400/70296]
loss: 0.076345  [44800/70296]
loss: 0.092707  [51200/70296]
loss: 0.003608  [57600/70296]
loss: 0.031453  [64000/70296]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070461 

Epoch 28
-------------------------------
loss: 0.101307  [    0/70296]
loss: 0.041209  [ 6400/70296]
loss: 0.027145  [12800/70296]
loss: 0.034868  [19200/70296]
loss: 0.020405  [25600/70296]
loss: 0.102226  [32000/70296]
loss: 0.092155  [38400/70296]
loss: 0.069184  [44800/70296]
loss: 0.033999  [51200/70296]
loss: 0.076577  [57600/70296]
loss: 0.037133  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.078958 

Epoch 29
-------------------------------
loss: 0.085082  [    0/70296]
loss: 0.038120  [ 6400/70296]
loss: 0.064684  [12800/70296]
loss: 0.052470  [19200/70296]
loss: 0.040182  [25600/70296]
loss: 0.035059  [32000/70296]
loss: 0.055619  [38400/70296]
loss: 0.026831  [44800/70296]
loss: 0.082252  [51200/70296]
loss: 0.150834  [57600/70296]
loss: 0.021009  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083180 

Epoch 30
-------------------------------
loss: 0.039593  [    0/70296]
loss: 0.118581  [ 6400/70296]
loss: 0.037178  [12800/70296]
loss: 0.009528  [19200/70296]
loss: 0.008344  [25600/70296]
loss: 0.105252  [32000/70296]
loss: 0.021460  [38400/70296]
loss: 0.112441  [44800/70296]
loss: 0.027799  [51200/70296]
loss: 0.022228  [57600/70296]
loss: 0.185131  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.077534 

Epoch 31
-------------------------------
loss: 0.024681  [    0/70296]
loss: 0.035438  [ 6400/70296]
loss: 0.037997  [12800/70296]
loss: 0.025160  [19200/70296]
loss: 0.012173  [25600/70296]
loss: 0.050054  [32000/70296]
loss: 0.039608  [38400/70296]
loss: 0.041922  [44800/70296]
loss: 0.023924  [51200/70296]
loss: 0.044441  [57600/70296]
loss: 0.032561  [64000/70296]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.077171 

Epoch 32
-------------------------------
loss: 0.101789  [    0/70296]
loss: 0.069440  [ 6400/70296]
loss: 0.019973  [12800/70296]
loss: 0.046042  [19200/70296]
loss: 0.042100  [25600/70296]
loss: 0.171851  [32000/70296]
loss: 0.079936  [38400/70296]
loss: 0.116972  [44800/70296]
loss: 0.133473  [51200/70296]
loss: 0.070017  [57600/70296]
loss: 0.077990  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.076710 

Epoch 33
-------------------------------
loss: 0.070882  [    0/70296]
loss: 0.107735  [ 6400/70296]
loss: 0.027650  [12800/70296]
loss: 0.042407  [19200/70296]
loss: 0.026390  [25600/70296]
loss: 0.045829  [32000/70296]
loss: 0.016400  [38400/70296]
loss: 0.062676  [44800/70296]
loss: 0.049444  [51200/70296]
loss: 0.153151  [57600/70296]
loss: 0.223663  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075381 

Epoch 34
-------------------------------
loss: 0.063273  [    0/70296]
loss: 0.064308  [ 6400/70296]
loss: 0.156491  [12800/70296]
loss: 0.017671  [19200/70296]
loss: 0.023520  [25600/70296]
loss: 0.089470  [32000/70296]
loss: 0.044142  [38400/70296]
loss: 0.017995  [44800/70296]
loss: 0.036452  [51200/70296]
loss: 0.020790  [57600/70296]
loss: 0.148512  [64000/70296]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084329 

Epoch 35
-------------------------------
loss: 0.043503  [    0/70296]
loss: 0.042999  [ 6400/70296]
loss: 0.061886  [12800/70296]
loss: 0.119073  [19200/70296]
loss: 0.015418  [25600/70296]
loss: 0.032626  [32000/70296]
loss: 0.159110  [38400/70296]
loss: 0.153885  [44800/70296]
loss: 0.041995  [51200/70296]
loss: 0.051097  [57600/70296]
loss: 0.101435  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.081098 

Epoch 36
-------------------------------
loss: 0.031187  [    0/70296]
loss: 0.077183  [ 6400/70296]
loss: 0.131538  [12800/70296]
loss: 0.036878  [19200/70296]
loss: 0.021152  [25600/70296]
loss: 0.106540  [32000/70296]
loss: 0.206181  [38400/70296]
loss: 0.031999  [44800/70296]
loss: 0.084411  [51200/70296]
loss: 0.045228  [57600/70296]
loss: 0.045076  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.073834 

Epoch 37
-------------------------------
loss: 0.039918  [    0/70296]
loss: 0.091605  [ 6400/70296]
loss: 0.034841  [12800/70296]
loss: 0.108667  [19200/70296]
loss: 0.034820  [25600/70296]
loss: 0.091884  [32000/70296]
loss: 0.083303  [38400/70296]
loss: 0.035019  [44800/70296]
loss: 0.172590  [51200/70296]
loss: 0.017323  [57600/70296]
loss: 0.250315  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075982 

Epoch 38
-------------------------------
loss: 0.121416  [    0/70296]
loss: 0.109782  [ 6400/70296]
loss: 0.034464  [12800/70296]
loss: 0.040833  [19200/70296]
loss: 0.092183  [25600/70296]
loss: 0.029167  [32000/70296]
loss: 0.090189  [38400/70296]
loss: 0.070043  [44800/70296]
loss: 0.038398  [51200/70296]
loss: 0.049522  [57600/70296]
loss: 0.064189  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080060 

Epoch 39
-------------------------------
loss: 0.050748  [    0/70296]
loss: 0.068708  [ 6400/70296]
loss: 0.126607  [12800/70296]
loss: 0.042289  [19200/70296]
loss: 0.018486  [25600/70296]
loss: 0.052371  [32000/70296]
loss: 0.043457  [38400/70296]
loss: 0.098698  [44800/70296]
loss: 0.055324  [51200/70296]
loss: 0.144092  [25600/69398]
loss: 0.146552  [32000/69398]
loss: 0.172664  [38400/69398]
loss: 0.096299  [44800/69398]
loss: 0.195020  [51200/69398]
loss: 0.149419  [57600/69398]
loss: 0.150721  [64000/69398]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.152465 

Epoch 21
-------------------------------
loss: 0.143869  [    0/69398]
loss: 0.117229  [ 6400/69398]
loss: 0.168998  [12800/69398]
loss: 0.185549  [19200/69398]
loss: 0.142720  [25600/69398]
loss: 0.254089  [32000/69398]
loss: 0.081447  [38400/69398]
loss: 0.203403  [44800/69398]
loss: 0.217616  [51200/69398]
loss: 0.241998  [57600/69398]
loss: 0.155508  [64000/69398]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.155882 

Epoch 22
-------------------------------
loss: 0.087642  [    0/69398]
loss: 0.134246  [ 6400/69398]
loss: 0.112168  [12800/69398]
loss: 0.320163  [19200/69398]
loss: 0.165813  [25600/69398]
loss: 0.148075  [32000/69398]
loss: 0.270846  [38400/69398]
loss: 0.095246  [44800/69398]
loss: 0.104322  [51200/69398]
loss: 0.252012  [57600/69398]
loss: 0.148485  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.151142 

Epoch 23
-------------------------------
loss: 0.233017  [    0/69398]
loss: 0.145931  [ 6400/69398]
loss: 0.107143  [12800/69398]
loss: 0.159319  [19200/69398]
loss: 0.118857  [25600/69398]
loss: 0.042336  [32000/69398]
loss: 0.165893  [38400/69398]
loss: 0.329331  [44800/69398]
loss: 0.083914  [51200/69398]
loss: 0.078954  [57600/69398]
loss: 0.099986  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.151625 

Epoch 24
-------------------------------
loss: 0.130795  [    0/69398]
loss: 0.160132  [ 6400/69398]
loss: 0.046498  [12800/69398]
loss: 0.110218  [19200/69398]
loss: 0.039928  [25600/69398]
loss: 0.099011  [32000/69398]
loss: 0.312513  [38400/69398]
loss: 0.161757  [44800/69398]
loss: 0.126434  [51200/69398]
loss: 0.109998  [57600/69398]
loss: 0.156607  [64000/69398]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.150612 

Epoch 25
-------------------------------
loss: 0.128848  [    0/69398]
loss: 0.244135  [ 6400/69398]
loss: 0.140265  [12800/69398]
loss: 0.132871  [19200/69398]
loss: 0.128294  [25600/69398]
loss: 0.183483  [32000/69398]
loss: 0.141662  [38400/69398]
loss: 0.090435  [44800/69398]
loss: 0.049473  [51200/69398]
loss: 0.136115  [57600/69398]
loss: 0.195644  [64000/69398]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.161041 

Epoch 26
-------------------------------
loss: 0.121078  [    0/69398]
loss: 0.119100  [ 6400/69398]
loss: 0.173363  [12800/69398]
loss: 0.174861  [19200/69398]
loss: 0.198668  [25600/69398]
loss: 0.171715  [32000/69398]
loss: 0.235502  [38400/69398]
loss: 0.186058  [44800/69398]
loss: 0.158444  [51200/69398]
loss: 0.099531  [57600/69398]
loss: 0.139765  [64000/69398]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.145311 

Epoch 27
-------------------------------
loss: 0.135199  [    0/69398]
loss: 0.107819  [ 6400/69398]
loss: 0.163932  [12800/69398]
loss: 0.167161  [19200/69398]
loss: 0.053544  [25600/69398]
loss: 0.123900  [32000/69398]
loss: 0.333294  [38400/69398]
loss: 0.071143  [44800/69398]
loss: 0.163342  [51200/69398]
loss: 0.112738  [57600/69398]
loss: 0.222035  [64000/69398]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.160376 

Epoch 28
-------------------------------
loss: 0.206585  [    0/69398]
loss: 0.047954  [ 6400/69398]
loss: 0.153106  [12800/69398]
loss: 0.105599  [19200/69398]
loss: 0.111510  [25600/69398]
loss: 0.133518  [32000/69398]
loss: 0.143316  [38400/69398]
loss: 0.213202  [44800/69398]
loss: 0.111732  [51200/69398]
loss: 0.080187  [57600/69398]
loss: 0.072265  [64000/69398]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.160252 

Epoch 29
-------------------------------
loss: 0.128268  [    0/69398]
loss: 0.181861  [ 6400/69398]
loss: 0.144672  [12800/69398]
loss: 0.114038  [19200/69398]
loss: 0.224001  [25600/69398]
loss: 0.182582  [32000/69398]
loss: 0.122240  [38400/69398]
loss: 0.293827  [44800/69398]
loss: 0.108524  [51200/69398]
loss: 0.072424  [57600/69398]
loss: 0.165962  [64000/69398]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.149054 

Epoch 30
-------------------------------
loss: 0.111670  [    0/69398]
loss: 0.095444  [ 6400/69398]
loss: 0.080055  [12800/69398]
loss: 0.120779  [19200/69398]
loss: 0.135826  [25600/69398]
loss: 0.211829  [32000/69398]
loss: 0.099890  [38400/69398]
loss: 0.069084  [44800/69398]
loss: 0.225482  [51200/69398]
loss: 0.144586  [57600/69398]
loss: 0.245985  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.154520 

Epoch 31
-------------------------------
loss: 0.085705  [    0/69398]
loss: 0.122663  [ 6400/69398]
loss: 0.092147  [12800/69398]
loss: 0.071350  [19200/69398]
loss: 0.055449  [25600/69398]
loss: 0.232717  [32000/69398]
loss: 0.214035  [38400/69398]
loss: 0.161253  [44800/69398]
loss: 0.056044  [51200/69398]
loss: 0.133438  [57600/69398]
loss: 0.091949  [64000/69398]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.155994 

Epoch 32
-------------------------------
loss: 0.132476  [    0/69398]
loss: 0.080551  [ 6400/69398]
loss: 0.104723  [12800/69398]
loss: 0.190171  [19200/69398]
loss: 0.058951  [25600/69398]
loss: 0.128419  [32000/69398]
loss: 0.063450  [38400/69398]
loss: 0.121263  [44800/69398]
loss: 0.160123  [51200/69398]
loss: 0.178481  [57600/69398]
loss: 0.122295  [64000/69398]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.152224 

Epoch 33
-------------------------------
loss: 0.118651  [    0/69398]
loss: 0.073925  [ 6400/69398]
loss: 0.106376  [12800/69398]
loss: 0.103338  [19200/69398]
loss: 0.092114  [25600/69398]
loss: 0.179939  [32000/69398]
loss: 0.188672  [38400/69398]
loss: 0.248459  [44800/69398]
loss: 0.168240  [51200/69398]
loss: 0.118483  [57600/69398]
loss: 0.080534  [64000/69398]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.164455 

Epoch 34
-------------------------------
loss: 0.092678  [    0/69398]
loss: 0.105537  [ 6400/69398]
loss: 0.061212  [12800/69398]
loss: 0.101170  [19200/69398]
loss: 0.036380  [25600/69398]
loss: 0.182718  [32000/69398]
loss: 0.184397  [38400/69398]
loss: 0.109296  [44800/69398]
loss: 1.704532  [51200/69398]
loss: 0.136863  [57600/69398]
loss: 0.134370  [64000/69398]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.148764 

Epoch 35
-------------------------------
loss: 1.621321  [    0/69398]
loss: 0.102327  [ 6400/69398]
loss: 0.124775  [12800/69398]
loss: 0.102813  [19200/69398]
loss: 0.119769  [25600/69398]
loss: 0.098992  [32000/69398]
loss: 0.118747  [38400/69398]
loss: 0.145537  [44800/69398]
loss: 0.090621  [51200/69398]
loss: 0.101414  [57600/69398]
loss: 0.298756  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.155374 

Epoch 36
-------------------------------
loss: 0.116493  [    0/69398]
loss: 0.103658  [ 6400/69398]
loss: 0.157365  [12800/69398]
loss: 0.256087  [19200/69398]
loss: 0.152979  [25600/69398]
loss: 0.177098  [32000/69398]
loss: 0.153756  [38400/69398]
loss: 0.086582  [44800/69398]
loss: 0.094167  [51200/69398]
loss: 0.151189  [57600/69398]
loss: 0.230522  [64000/69398]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.167791 

Epoch 37
-------------------------------
loss: 0.131206  [    0/69398]
loss: 0.222555  [ 6400/69398]
loss: 0.048611  [12800/69398]
loss: 0.061234  [19200/69398]
loss: 0.069152  [25600/69398]
loss: 0.148365  [32000/69398]
loss: 0.142630  [38400/69398]
loss: 0.055613  [44800/69398]
loss: 0.174368  [51200/69398]
loss: 0.273740  [57600/69398]
loss: 0.133533  [64000/69398]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.161056 

Epoch 38
-------------------------------
loss: 0.128514  [    0/69398]
loss: 0.150872  [ 6400/69398]
loss: 0.218608  [12800/69398]
loss: 0.122002  [19200/69398]
loss: 0.139202  [25600/69398]
loss: 0.220132  [32000/69398]
loss: 0.170215  [38400/69398]
loss: 0.085380  [44800/69398]
loss: 0.150446  [51200/69398]
loss: 0.103678  [57600/69398]
loss: 0.058208  [64000/69398]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.156415 

Epoch 39
-------------------------------
loss: 0.095675  [    0/69398]
loss: 0.069830  [ 6400/69398]
loss: 0.217568  [12800/69398]
loss: 0.112906  [19200/69398]
loss: 0.094729  [25600/69398]
loss: 0.101631  [32000/69398]
loss: 0.141616  [38400/69398]
loss: 0.053203  [44800/69398]
loss: 0.163230  [51200/69398]
loss: 0.114054  [25600/69683]
loss: 0.118158  [32000/69683]
loss: 0.153960  [38400/69683]
loss: 0.211955  [44800/69683]
loss: 0.093962  [51200/69683]
loss: 0.110887  [57600/69683]
loss: 0.072782  [64000/69683]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.153661 

Epoch 21
-------------------------------
loss: 0.269897  [    0/69683]
loss: 0.102311  [ 6400/69683]
loss: 0.077312  [12800/69683]
loss: 0.057681  [19200/69683]
loss: 0.098890  [25600/69683]
loss: 0.146062  [32000/69683]
loss: 0.113473  [38400/69683]
loss: 0.108965  [44800/69683]
loss: 0.133558  [51200/69683]
loss: 0.119100  [57600/69683]
loss: 0.058985  [64000/69683]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.163907 

Epoch 22
-------------------------------
loss: 0.146060  [    0/69683]
loss: 0.141718  [ 6400/69683]
loss: 0.223192  [12800/69683]
loss: 0.174776  [19200/69683]
loss: 0.048067  [25600/69683]
loss: 0.132029  [32000/69683]
loss: 0.100183  [38400/69683]
loss: 0.104090  [44800/69683]
loss: 0.136311  [51200/69683]
loss: 0.118864  [57600/69683]
loss: 0.117966  [64000/69683]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.154162 

Epoch 23
-------------------------------
loss: 0.029496  [    0/69683]
loss: 0.087551  [ 6400/69683]
loss: 0.069798  [12800/69683]
loss: 0.233038  [19200/69683]
loss: 0.121123  [25600/69683]
loss: 0.147252  [32000/69683]
loss: 0.148023  [38400/69683]
loss: 0.204306  [44800/69683]
loss: 0.146531  [51200/69683]
loss: 0.198205  [57600/69683]
loss: 0.170964  [64000/69683]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.167692 

Epoch 24
-------------------------------
loss: 0.050372  [    0/69683]
loss: 0.114022  [ 6400/69683]
loss: 0.300767  [12800/69683]
loss: 0.166079  [19200/69683]
loss: 0.212466  [25600/69683]
loss: 0.177186  [32000/69683]
loss: 0.142286  [38400/69683]
loss: 0.149368  [44800/69683]
loss: 0.253727  [51200/69683]
loss: 0.200303  [57600/69683]
loss: 0.138030  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162082 

Epoch 25
-------------------------------
loss: 0.184840  [    0/69683]
loss: 0.175812  [ 6400/69683]
loss: 0.139091  [12800/69683]
loss: 0.077176  [19200/69683]
loss: 0.154750  [25600/69683]
loss: 0.080705  [32000/69683]
loss: 0.154169  [38400/69683]
loss: 0.070558  [44800/69683]
loss: 0.071138  [51200/69683]
loss: 0.231998  [57600/69683]
loss: 0.135522  [64000/69683]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.155588 

Epoch 26
-------------------------------
loss: 0.072501  [    0/69683]
loss: 0.122934  [ 6400/69683]
loss: 0.138162  [12800/69683]
loss: 0.196231  [19200/69683]
loss: 0.166577  [25600/69683]
loss: 0.303622  [32000/69683]
loss: 0.174174  [38400/69683]
loss: 0.093517  [44800/69683]
loss: 0.191902  [51200/69683]
loss: 0.054277  [57600/69683]
loss: 0.075335  [64000/69683]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.155561 

Epoch 27
-------------------------------
loss: 0.121156  [    0/69683]
loss: 0.189660  [ 6400/69683]
loss: 0.130750  [12800/69683]
loss: 0.093699  [19200/69683]
loss: 0.084955  [25600/69683]
loss: 0.088806  [32000/69683]
loss: 0.044745  [38400/69683]
loss: 0.078829  [44800/69683]
loss: 0.228786  [51200/69683]
loss: 0.212668  [57600/69683]
loss: 0.128606  [64000/69683]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.165739 

Epoch 28
-------------------------------
loss: 0.156412  [    0/69683]
loss: 0.133563  [ 6400/69683]
loss: 0.154996  [12800/69683]
loss: 0.134588  [19200/69683]
loss: 0.083663  [25600/69683]
loss: 0.152003  [32000/69683]
loss: 0.069711  [38400/69683]
loss: 0.166349  [44800/69683]
loss: 0.105079  [51200/69683]
loss: 0.156554  [57600/69683]
loss: 1.740285  [64000/69683]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.154222 

Epoch 29
-------------------------------
loss: 0.040288  [    0/69683]
loss: 0.158507  [ 6400/69683]
loss: 1.697969  [12800/69683]
loss: 0.165052  [19200/69683]
loss: 0.181697  [25600/69683]
loss: 0.097032  [32000/69683]
loss: 0.258075  [38400/69683]
loss: 0.096198  [44800/69683]
loss: 0.213691  [51200/69683]
loss: 0.185216  [57600/69683]
loss: 0.132658  [64000/69683]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.156666 

Epoch 30
-------------------------------
loss: 0.123219  [    0/69683]
loss: 0.074543  [ 6400/69683]
loss: 0.109000  [12800/69683]
loss: 0.139581  [19200/69683]
loss: 0.077419  [25600/69683]
loss: 0.046951  [32000/69683]
loss: 0.164596  [38400/69683]
loss: 0.176571  [44800/69683]
loss: 0.168947  [51200/69683]
loss: 0.162833  [57600/69683]
loss: 0.099868  [64000/69683]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.167226 

Epoch 31
-------------------------------
loss: 0.113624  [    0/69683]
loss: 0.184675  [ 6400/69683]
loss: 0.136643  [12800/69683]
loss: 0.161810  [19200/69683]
loss: 0.162232  [25600/69683]
loss: 0.167330  [32000/69683]
loss: 0.092177  [38400/69683]
loss: 0.224497  [44800/69683]
loss: 0.099598  [51200/69683]
loss: 0.095036  [57600/69683]
loss: 0.137814  [64000/69683]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.153913 

Epoch 32
-------------------------------
loss: 0.060295  [    0/69683]
loss: 0.080174  [ 6400/69683]
loss: 0.127668  [12800/69683]
loss: 0.159128  [19200/69683]
loss: 0.117955  [25600/69683]
loss: 0.127054  [32000/69683]
loss: 0.185722  [38400/69683]
loss: 0.081611  [44800/69683]
loss: 0.026601  [51200/69683]
loss: 0.148051  [57600/69683]
loss: 0.217725  [64000/69683]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.161536 

Epoch 33
-------------------------------
loss: 0.061004  [    0/69683]
loss: 0.111501  [ 6400/69683]
loss: 0.141219  [12800/69683]
loss: 0.114660  [19200/69683]
loss: 0.164371  [25600/69683]
loss: 0.170232  [32000/69683]
loss: 0.105167  [38400/69683]
loss: 0.069136  [44800/69683]
loss: 0.121805  [51200/69683]
loss: 0.242483  [57600/69683]
loss: 0.123462  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157556 

Epoch 34
-------------------------------
loss: 0.148151  [    0/69683]
loss: 0.085069  [ 6400/69683]
loss: 0.066312  [12800/69683]
loss: 0.115428  [19200/69683]
loss: 1.619762  [25600/69683]
loss: 0.132824  [32000/69683]
loss: 0.116610  [38400/69683]
loss: 0.177279  [44800/69683]
loss: 0.208871  [51200/69683]
loss: 0.241493  [57600/69683]
loss: 0.201857  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.161820 

Epoch 35
-------------------------------
loss: 0.146762  [    0/69683]
loss: 0.135111  [ 6400/69683]
loss: 0.116993  [12800/69683]
loss: 0.221700  [19200/69683]
loss: 0.104094  [25600/69683]
loss: 0.113727  [32000/69683]
loss: 1.729591  [38400/69683]
loss: 0.181124  [44800/69683]
loss: 0.109146  [51200/69683]
loss: 0.109838  [57600/69683]
loss: 0.092693  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157943 

Epoch 36
-------------------------------
loss: 0.162121  [    0/69683]
loss: 0.121395  [ 6400/69683]
loss: 0.080406  [12800/69683]
loss: 0.095276  [19200/69683]
loss: 0.199008  [25600/69683]
loss: 0.149811  [32000/69683]
loss: 0.167037  [38400/69683]
loss: 0.172754  [44800/69683]
loss: 0.160632  [51200/69683]
loss: 0.165911  [57600/69683]
loss: 0.144048  [64000/69683]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.171438 

Epoch 37
-------------------------------
loss: 0.143830  [    0/69683]
loss: 0.134228  [ 6400/69683]
loss: 0.102265  [12800/69683]
loss: 0.131864  [19200/69683]
loss: 0.090928  [25600/69683]
loss: 0.176675  [32000/69683]
loss: 0.173514  [38400/69683]
loss: 0.055644  [44800/69683]
loss: 0.189991  [51200/69683]
loss: 0.070131  [57600/69683]
loss: 0.328055  [64000/69683]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.152469 

Epoch 38
-------------------------------
loss: 0.179853  [    0/69683]
loss: 0.118806  [ 6400/69683]
loss: 0.160964  [12800/69683]
loss: 0.080806  [19200/69683]
loss: 0.115828  [25600/69683]
loss: 0.169824  [32000/69683]
loss: 0.124877  [38400/69683]
loss: 0.063418  [44800/69683]
loss: 0.211703  [51200/69683]
loss: 0.321751  [57600/69683]
loss: 0.057468  [64000/69683]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.161752 

Epoch 39
-------------------------------
loss: 0.145892  [    0/69683]
loss: 0.129936  [ 6400/69683]
loss: 0.136824  [12800/69683]
loss: 0.033666  [19200/69683]
loss: 0.133676  [25600/69683]
loss: 0.154456  [32000/69683]
loss: 0.141415  [38400/69683]
loss: 0.229094  [44800/69683]
loss: 0.089538  [51200/69683]
loss: 0.084925  [    0/70834]
loss: 0.074979  [ 6400/70834]
loss: 0.058939  [12800/70834]
loss: 0.042046  [19200/70834]
loss: 0.007001  [25600/70834]
loss: 0.009010  [32000/70834]
loss: 0.075759  [38400/70834]
loss: 0.045043  [44800/70834]
loss: 0.006619  [51200/70834]
loss: 0.080225  [57600/70834]
loss: 0.088996  [64000/70834]
loss: 0.052368  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085179 

Epoch 20
-------------------------------
loss: 0.106277  [    0/70834]
loss: 0.137691  [ 6400/70834]
loss: 0.119197  [12800/70834]
loss: 0.109053  [19200/70834]
loss: 0.076344  [25600/70834]
loss: 0.046516  [32000/70834]
loss: 0.060668  [38400/70834]
loss: 0.127021  [44800/70834]
loss: 0.024594  [51200/70834]
loss: 0.029736  [57600/70834]
loss: 0.168574  [64000/70834]
loss: 0.053177  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085057 

Epoch 21
-------------------------------
loss: 0.054337  [    0/70834]
loss: 0.064399  [ 6400/70834]
loss: 0.008315  [12800/70834]
loss: 0.225719  [19200/70834]
loss: 0.075162  [25600/70834]
loss: 0.180488  [32000/70834]
loss: 0.013028  [38400/70834]
loss: 0.077772  [44800/70834]
loss: 0.023579  [51200/70834]
loss: 0.092101  [57600/70834]
loss: 0.028128  [64000/70834]
loss: 0.054165  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.079506 

Epoch 22
-------------------------------
loss: 0.008575  [    0/70834]
loss: 0.094840  [ 6400/70834]
loss: 0.082054  [12800/70834]
loss: 0.071991  [19200/70834]
loss: 0.012071  [25600/70834]
loss: 0.019975  [32000/70834]
loss: 0.008599  [38400/70834]
loss: 0.045465  [44800/70834]
loss: 0.030757  [51200/70834]
loss: 0.091349  [57600/70834]
loss: 0.059352  [64000/70834]
loss: 0.014537  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075639 

Epoch 23
-------------------------------
loss: 0.147509  [    0/70834]
loss: 0.069925  [ 6400/70834]
loss: 0.052289  [12800/70834]
loss: 0.063478  [19200/70834]
loss: 0.155446  [25600/70834]
loss: 0.212550  [32000/70834]
loss: 0.056805  [38400/70834]
loss: 0.052449  [44800/70834]
loss: 0.053175  [51200/70834]
loss: 0.073275  [57600/70834]
loss: 0.048015  [64000/70834]
loss: 0.064093  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.084682 

Epoch 24
-------------------------------
loss: 0.063686  [    0/70834]
loss: 0.032687  [ 6400/70834]
loss: 0.037080  [12800/70834]
loss: 0.129826  [19200/70834]
loss: 0.028948  [25600/70834]
loss: 0.144728  [32000/70834]
loss: 0.079878  [38400/70834]
loss: 0.013297  [44800/70834]
loss: 0.067522  [51200/70834]
loss: 0.034654  [57600/70834]
loss: 0.069363  [64000/70834]
loss: 0.030836  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082608 

Epoch 25
-------------------------------
loss: 0.064750  [    0/70834]
loss: 0.201760  [ 6400/70834]
loss: 0.085596  [12800/70834]
loss: 0.074217  [19200/70834]
loss: 0.020646  [25600/70834]
loss: 0.079508  [32000/70834]
loss: 0.009994  [38400/70834]
loss: 0.007795  [44800/70834]
loss: 0.025820  [51200/70834]
loss: 0.023328  [57600/70834]
loss: 0.065048  [64000/70834]
loss: 0.024339  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.082271 

Epoch 26
-------------------------------
loss: 0.023100  [    0/70834]
loss: 0.071892  [ 6400/70834]
loss: 0.077097  [12800/70834]
loss: 0.070689  [19200/70834]
loss: 0.026606  [25600/70834]
loss: 0.003805  [32000/70834]
loss: 0.111883  [38400/70834]
loss: 0.045878  [44800/70834]
loss: 0.031940  [51200/70834]
loss: 0.096859  [57600/70834]
loss: 0.100813  [64000/70834]
loss: 0.050368  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072395 

Epoch 27
-------------------------------
loss: 0.009493  [    0/70834]
loss: 0.083645  [ 6400/70834]
loss: 0.072896  [12800/70834]
loss: 0.140293  [19200/70834]
loss: 0.097923  [25600/70834]
loss: 0.029252  [32000/70834]
loss: 0.063248  [38400/70834]
loss: 0.027266  [44800/70834]
loss: 0.065836  [51200/70834]
loss: 0.167195  [57600/70834]
loss: 0.055086  [64000/70834]
loss: 0.048011  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072725 

Epoch 28
-------------------------------
loss: 0.067324  [    0/70834]
loss: 0.034531  [ 6400/70834]
loss: 0.070531  [12800/70834]
loss: 0.028875  [19200/70834]
loss: 0.055863  [25600/70834]
loss: 0.039453  [32000/70834]
loss: 0.011533  [38400/70834]
loss: 0.021709  [44800/70834]
loss: 0.137865  [51200/70834]
loss: 0.142654  [57600/70834]
loss: 0.039880  [64000/70834]
loss: 0.095155  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.079931 

Epoch 29
-------------------------------
loss: 0.012813  [    0/70834]
loss: 0.084966  [ 6400/70834]
loss: 0.017170  [12800/70834]
loss: 0.022553  [19200/70834]
loss: 0.144662  [25600/70834]
loss: 0.050336  [32000/70834]
loss: 0.132477  [38400/70834]
loss: 0.080724  [44800/70834]
loss: 0.112291  [51200/70834]
loss: 0.069564  [57600/70834]
loss: 0.122837  [64000/70834]
loss: 0.018920  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.091679 

Epoch 30
-------------------------------
loss: 0.064179  [    0/70834]
loss: 0.049776  [ 6400/70834]
loss: 0.034923  [12800/70834]
loss: 0.075162  [19200/70834]
loss: 0.049830  [25600/70834]
loss: 0.063252  [32000/70834]
loss: 0.029508  [38400/70834]
loss: 0.038677  [44800/70834]
loss: 0.048033  [51200/70834]
loss: 0.035407  [57600/70834]
loss: 0.069890  [64000/70834]
loss: 0.036861  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.072708 

Epoch 31
-------------------------------
loss: 0.061769  [    0/70834]
loss: 0.063223  [ 6400/70834]
loss: 0.069672  [12800/70834]
loss: 0.128154  [19200/70834]
loss: 0.040793  [25600/70834]
loss: 0.030692  [32000/70834]
loss: 0.047001  [38400/70834]
loss: 0.035287  [44800/70834]
loss: 0.055712  [51200/70834]
loss: 0.082232  [57600/70834]
loss: 0.154264  [64000/70834]
loss: 0.061018  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.085771 

Epoch 32
-------------------------------
loss: 0.031350  [    0/70834]
loss: 0.015034  [ 6400/70834]
loss: 0.057391  [12800/70834]
loss: 0.031251  [19200/70834]
loss: 0.022443  [25600/70834]
loss: 0.066870  [32000/70834]
loss: 0.034836  [38400/70834]
loss: 0.096442  [44800/70834]
loss: 0.048553  [51200/70834]
loss: 0.046672  [57600/70834]
loss: 0.129781  [64000/70834]
loss: 0.080267  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.079715 

Epoch 33
-------------------------------
loss: 0.088143  [    0/70834]
loss: 0.028204  [ 6400/70834]
loss: 0.143163  [12800/70834]
loss: 0.120676  [19200/70834]
loss: 0.011775  [25600/70834]
loss: 0.020902  [32000/70834]
loss: 0.062322  [38400/70834]
loss: 0.116923  [44800/70834]
loss: 0.035269  [51200/70834]
loss: 0.079338  [57600/70834]
loss: 0.060998  [64000/70834]
loss: 0.020552  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.079240 

Epoch 34
-------------------------------
loss: 0.020327  [    0/70834]
loss: 0.075462  [ 6400/70834]
loss: 0.052014  [12800/70834]
loss: 0.041594  [19200/70834]
loss: 0.082704  [25600/70834]
loss: 0.011275  [32000/70834]
loss: 0.018057  [38400/70834]
loss: 0.046097  [44800/70834]
loss: 0.045934  [51200/70834]
loss: 0.097367  [57600/70834]
loss: 0.055407  [64000/70834]
loss: 0.044287  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.081353 

Epoch 35
-------------------------------
loss: 0.117362  [    0/70834]
loss: 0.012110  [ 6400/70834]
loss: 0.029716  [12800/70834]
loss: 0.146066  [19200/70834]
loss: 0.073322  [25600/70834]
loss: 0.059470  [32000/70834]
loss: 0.030717  [38400/70834]
loss: 0.148507  [44800/70834]
loss: 0.015116  [51200/70834]
loss: 0.049017  [57600/70834]
loss: 0.029344  [64000/70834]
loss: 0.024425  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.086272 

Epoch 36
-------------------------------
loss: 0.084844  [    0/70834]
loss: 0.014856  [ 6400/70834]
loss: 0.146838  [12800/70834]
loss: 0.008546  [19200/70834]
loss: 0.053180  [25600/70834]
loss: 0.055823  [32000/70834]
loss: 0.022139  [38400/70834]
loss: 0.019529  [44800/70834]
loss: 0.025313  [51200/70834]
loss: 0.071433  [57600/70834]
loss: 0.054093  [64000/70834]
loss: 0.072650  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.080746 

Epoch 37
-------------------------------
loss: 0.025943  [    0/70834]
loss: 0.099437  [    0/71045]
loss: 0.075647  [ 6400/71045]
loss: 0.081552  [12800/71045]
loss: 0.017534  [19200/71045]
loss: 0.070164  [25600/71045]
loss: 0.133219  [32000/71045]
loss: 0.007960  [38400/71045]
loss: 0.045529  [44800/71045]
loss: 0.042137  [51200/71045]
loss: 0.018970  [57600/71045]
loss: 0.025906  [64000/71045]
loss: 0.056089  [70400/71045]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076174 

Epoch 20
-------------------------------
loss: 0.040509  [    0/71045]
loss: 0.013296  [ 6400/71045]
loss: 0.149029  [12800/71045]
loss: 0.143548  [19200/71045]
loss: 0.101053  [25600/71045]
loss: 0.019911  [32000/71045]
loss: 0.040690  [38400/71045]
loss: 0.024479  [44800/71045]
loss: 0.044991  [51200/71045]
loss: 0.058940  [57600/71045]
loss: 0.061970  [64000/71045]
loss: 0.061957  [70400/71045]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.069762 

Epoch 21
-------------------------------
loss: 0.056714  [    0/71045]
loss: 0.023859  [ 6400/71045]
loss: 0.122878  [12800/71045]
loss: 0.052867  [19200/71045]
loss: 0.036440  [25600/71045]
loss: 0.022903  [32000/71045]
loss: 0.063200  [38400/71045]
loss: 0.099529  [44800/71045]
loss: 0.020585  [51200/71045]
loss: 0.026756  [57600/71045]
loss: 0.016948  [64000/71045]
loss: 0.005093  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.061484 

Epoch 22
-------------------------------
loss: 0.079030  [    0/71045]
loss: 0.035259  [ 6400/71045]
loss: 0.030673  [12800/71045]
loss: 0.023954  [19200/71045]
loss: 0.018103  [25600/71045]
loss: 0.004732  [32000/71045]
loss: 0.040015  [38400/71045]
loss: 0.028999  [44800/71045]
loss: 0.107784  [51200/71045]
loss: 0.004238  [57600/71045]
loss: 0.094213  [64000/71045]
loss: 0.001801  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.061018 

Epoch 23
-------------------------------
loss: 0.010414  [    0/71045]
loss: 0.017175  [ 6400/71045]
loss: 0.065300  [12800/71045]
loss: 0.019768  [19200/71045]
loss: 0.128259  [25600/71045]
loss: 0.117340  [32000/71045]
loss: 0.041558  [38400/71045]
loss: 0.096167  [44800/71045]
loss: 0.049690  [51200/71045]
loss: 0.043897  [57600/71045]
loss: 0.043826  [64000/71045]
loss: 0.054046  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.069075 

Epoch 24
-------------------------------
loss: 0.053548  [    0/71045]
loss: 0.019588  [ 6400/71045]
loss: 0.017593  [12800/71045]
loss: 0.149095  [19200/71045]
loss: 0.100601  [25600/71045]
loss: 0.022778  [32000/71045]
loss: 0.073320  [38400/71045]
loss: 0.034538  [44800/71045]
loss: 0.014414  [51200/71045]
loss: 0.053022  [57600/71045]
loss: 0.030322  [64000/71045]
loss: 0.036034  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.063887 

Epoch 25
-------------------------------
loss: 0.015394  [    0/71045]
loss: 0.132698  [ 6400/71045]
loss: 0.013244  [12800/71045]
loss: 0.124039  [19200/71045]
loss: 0.025092  [25600/71045]
loss: 0.007844  [32000/71045]
loss: 0.084037  [38400/71045]
loss: 0.017617  [44800/71045]
loss: 0.031924  [51200/71045]
loss: 0.008074  [57600/71045]
loss: 0.059116  [64000/71045]
loss: 0.034876  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.065402 

Epoch 26
-------------------------------
loss: 0.005531  [    0/71045]
loss: 0.146776  [ 6400/71045]
loss: 0.016838  [12800/71045]
loss: 0.050800  [19200/71045]
loss: 0.069552  [25600/71045]
loss: 0.124642  [32000/71045]
loss: 0.031682  [38400/71045]
loss: 0.075502  [44800/71045]
loss: 0.035548  [51200/71045]
loss: 0.055050  [57600/71045]
loss: 0.055299  [64000/71045]
loss: 0.010879  [70400/71045]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.069188 

Epoch 27
-------------------------------
loss: 0.042019  [    0/71045]
loss: 0.012060  [ 6400/71045]
loss: 0.005499  [12800/71045]
loss: 0.104433  [19200/71045]
loss: 0.022874  [25600/71045]
loss: 0.014630  [32000/71045]
loss: 0.036158  [38400/71045]
loss: 0.109016  [44800/71045]
loss: 0.058871  [51200/71045]
loss: 0.013863  [57600/71045]
loss: 0.040517  [64000/71045]
loss: 0.012705  [70400/71045]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.069273 

Epoch 28
-------------------------------
loss: 0.019150  [    0/71045]
loss: 0.021451  [ 6400/71045]
loss: 0.049965  [12800/71045]
loss: 0.076009  [19200/71045]
loss: 0.030323  [25600/71045]
loss: 0.056020  [32000/71045]
loss: 0.014392  [38400/71045]
loss: 0.046479  [44800/71045]
loss: 0.005935  [51200/71045]
loss: 0.037589  [57600/71045]
loss: 0.010426  [64000/71045]
loss: 0.013228  [70400/71045]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.071021 

Epoch 29
-------------------------------
loss: 0.047920  [    0/71045]
loss: 0.035179  [ 6400/71045]
loss: 0.011302  [12800/71045]
loss: 0.071212  [19200/71045]
loss: 0.027091  [25600/71045]
loss: 0.066775  [32000/71045]
loss: 0.020300  [38400/71045]
loss: 0.053137  [44800/71045]
loss: 0.061957  [51200/71045]
loss: 0.069554  [57600/71045]
loss: 0.023526  [64000/71045]
loss: 0.039097  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067095 

Epoch 30
-------------------------------
loss: 0.028186  [    0/71045]
loss: 0.065068  [ 6400/71045]
loss: 0.016641  [12800/71045]
loss: 0.014022  [19200/71045]
loss: 0.028299  [25600/71045]
loss: 0.020474  [32000/71045]
loss: 0.081406  [38400/71045]
loss: 0.130183  [44800/71045]
loss: 0.100182  [51200/71045]
loss: 0.010722  [57600/71045]
loss: 0.020802  [64000/71045]
loss: 0.037956  [70400/71045]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072957 

Epoch 31
-------------------------------
loss: 0.006437  [    0/71045]
loss: 0.002458  [ 6400/71045]
loss: 0.190061  [12800/71045]
loss: 0.040156  [19200/71045]
loss: 0.097821  [25600/71045]
loss: 0.082407  [32000/71045]
loss: 0.009447  [38400/71045]
loss: 0.054674  [44800/71045]
loss: 0.050452  [51200/71045]
loss: 0.021356  [57600/71045]
loss: 0.084150  [64000/71045]
loss: 0.071197  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.066917 

Epoch 32
-------------------------------
loss: 0.026620  [    0/71045]
loss: 0.040221  [ 6400/71045]
loss: 0.066183  [12800/71045]
loss: 0.046968  [19200/71045]
loss: 0.021394  [25600/71045]
loss: 0.008954  [32000/71045]
loss: 0.060063  [38400/71045]
loss: 0.018364  [44800/71045]
loss: 0.060984  [51200/71045]
loss: 0.061354  [57600/71045]
loss: 0.008228  [64000/71045]
loss: 0.002024  [70400/71045]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075396 

Epoch 33
-------------------------------
loss: 0.049084  [    0/71045]
loss: 0.006061  [ 6400/71045]
loss: 0.036127  [12800/71045]
loss: 0.102159  [19200/71045]
loss: 0.087367  [25600/71045]
loss: 0.091013  [32000/71045]
loss: 0.029185  [38400/71045]
loss: 0.026451  [44800/71045]
loss: 0.008943  [51200/71045]
loss: 0.120577  [57600/71045]
loss: 0.042675  [64000/71045]
loss: 0.028894  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070159 

Epoch 34
-------------------------------
loss: 0.023040  [    0/71045]
loss: 0.015636  [ 6400/71045]
loss: 0.068973  [12800/71045]
loss: 0.023569  [19200/71045]
loss: 0.007723  [25600/71045]
loss: 0.011822  [32000/71045]
loss: 0.034786  [38400/71045]
loss: 0.082203  [44800/71045]
loss: 0.061197  [51200/71045]
loss: 0.029022  [57600/71045]
loss: 0.106507  [64000/71045]
loss: 0.122078  [70400/71045]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.080241 

Epoch 35
-------------------------------
loss: 0.052539  [    0/71045]
loss: 0.018931  [ 6400/71045]
loss: 0.013638  [12800/71045]
loss: 0.004749  [19200/71045]
loss: 0.027830  [25600/71045]
loss: 0.077796  [32000/71045]
loss: 0.064747  [38400/71045]
loss: 0.097625  [44800/71045]
loss: 0.037326  [51200/71045]
loss: 0.083891  [57600/71045]
loss: 0.037306  [64000/71045]
loss: 0.026843  [70400/71045]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.069745 

Epoch 36
-------------------------------
loss: 0.007209  [    0/71045]
loss: 0.031416  [ 6400/71045]
loss: 0.113816  [12800/71045]
loss: 0.021862  [19200/71045]
loss: 0.014417  [25600/71045]
loss: 0.012354  [32000/71045]
loss: 0.010070  [38400/71045]
loss: 0.070180  [44800/71045]
loss: 0.018700  [51200/71045]
loss: 0.037917  [57600/71045]
loss: 0.033124  [64000/71045]
loss: 0.048181  [70400/71045]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.069961 

Epoch 37
-------------------------------
loss: 0.020695  [    0/71045]
loss: 0.118292  [25600/69247]
loss: 0.096312  [32000/69247]
loss: 0.196118  [38400/69247]
loss: 0.215535  [44800/69247]
loss: 0.092846  [51200/69247]
loss: 0.174919  [57600/69247]
loss: 0.133644  [64000/69247]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.163110 

Epoch 21
-------------------------------
loss: 0.067484  [    0/69247]
loss: 0.083071  [ 6400/69247]
loss: 0.223001  [12800/69247]
loss: 0.163844  [19200/69247]
loss: 0.241798  [25600/69247]
loss: 0.173213  [32000/69247]
loss: 0.258131  [38400/69247]
loss: 0.205313  [44800/69247]
loss: 0.152506  [51200/69247]
loss: 0.176039  [57600/69247]
loss: 0.221142  [64000/69247]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.162078 

Epoch 22
-------------------------------
loss: 0.111295  [    0/69247]
loss: 0.137727  [ 6400/69247]
loss: 0.196348  [12800/69247]
loss: 0.120826  [19200/69247]
loss: 0.113328  [25600/69247]
loss: 0.240717  [32000/69247]
loss: 0.358881  [38400/69247]
loss: 0.148375  [44800/69247]
loss: 0.141127  [51200/69247]
loss: 0.170322  [57600/69247]
loss: 0.095143  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.166971 

Epoch 23
-------------------------------
loss: 0.189976  [    0/69247]
loss: 0.054228  [ 6400/69247]
loss: 0.247147  [12800/69247]
loss: 0.119594  [19200/69247]
loss: 0.125512  [25600/69247]
loss: 0.132269  [32000/69247]
loss: 0.214553  [38400/69247]
loss: 0.107263  [44800/69247]
loss: 0.050152  [51200/69247]
loss: 0.142965  [57600/69247]
loss: 0.126035  [64000/69247]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.162892 

Epoch 24
-------------------------------
loss: 0.072485  [    0/69247]
loss: 0.139677  [ 6400/69247]
loss: 0.122362  [12800/69247]
loss: 0.113113  [19200/69247]
loss: 0.171560  [25600/69247]
loss: 0.162500  [32000/69247]
loss: 0.093528  [38400/69247]
loss: 0.108417  [44800/69247]
loss: 0.092090  [51200/69247]
loss: 0.207380  [57600/69247]
loss: 0.134453  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.159874 

Epoch 25
-------------------------------
loss: 0.179095  [    0/69247]
loss: 0.104111  [ 6400/69247]
loss: 1.719164  [12800/69247]
loss: 0.162750  [19200/69247]
loss: 0.283202  [25600/69247]
loss: 0.255383  [32000/69247]
loss: 0.248255  [38400/69247]
loss: 0.157262  [44800/69247]
loss: 0.085044  [51200/69247]
loss: 0.159896  [57600/69247]
loss: 0.181244  [64000/69247]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.155077 

Epoch 26
-------------------------------
loss: 0.120406  [    0/69247]
loss: 0.142401  [ 6400/69247]
loss: 0.153164  [12800/69247]
loss: 0.173504  [19200/69247]
loss: 0.110475  [25600/69247]
loss: 0.129684  [32000/69247]
loss: 0.187949  [38400/69247]
loss: 0.075885  [44800/69247]
loss: 0.133097  [51200/69247]
loss: 0.157252  [57600/69247]
loss: 0.163286  [64000/69247]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.160229 

Epoch 27
-------------------------------
loss: 0.096635  [    0/69247]
loss: 0.171542  [ 6400/69247]
loss: 0.151028  [12800/69247]
loss: 0.177605  [19200/69247]
loss: 0.164872  [25600/69247]
loss: 0.159309  [32000/69247]
loss: 0.080488  [38400/69247]
loss: 0.089852  [44800/69247]
loss: 0.233683  [51200/69247]
loss: 0.091014  [57600/69247]
loss: 0.075223  [64000/69247]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.153598 

Epoch 28
-------------------------------
loss: 0.157879  [    0/69247]
loss: 0.183712  [ 6400/69247]
loss: 0.192413  [12800/69247]
loss: 0.165342  [19200/69247]
loss: 0.129621  [25600/69247]
loss: 0.114634  [32000/69247]
loss: 0.179557  [38400/69247]
loss: 0.290198  [44800/69247]
loss: 0.131032  [51200/69247]
loss: 0.155107  [57600/69247]
loss: 0.164140  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.154733 

Epoch 29
-------------------------------
loss: 0.091419  [    0/69247]
loss: 0.098399  [ 6400/69247]
loss: 0.281972  [12800/69247]
loss: 0.112143  [19200/69247]
loss: 0.114177  [25600/69247]
loss: 0.272441  [32000/69247]
loss: 0.259190  [38400/69247]
loss: 0.098560  [44800/69247]
loss: 0.076054  [51200/69247]
loss: 0.139916  [57600/69247]
loss: 0.091086  [64000/69247]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.157805 

Epoch 30
-------------------------------
loss: 0.187234  [    0/69247]
loss: 0.159140  [ 6400/69247]
loss: 0.213178  [12800/69247]
loss: 0.105959  [19200/69247]
loss: 0.097945  [25600/69247]
loss: 0.167077  [32000/69247]
loss: 0.128859  [38400/69247]
loss: 0.164506  [44800/69247]
loss: 0.161497  [51200/69247]
loss: 0.199914  [57600/69247]
loss: 0.114439  [64000/69247]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.160537 

Epoch 31
-------------------------------
loss: 0.103792  [    0/69247]
loss: 0.208533  [ 6400/69247]
loss: 0.146982  [12800/69247]
loss: 0.120984  [19200/69247]
loss: 0.106421  [25600/69247]
loss: 0.147352  [32000/69247]
loss: 0.153054  [38400/69247]
loss: 0.162717  [44800/69247]
loss: 0.162119  [51200/69247]
loss: 0.147973  [57600/69247]
loss: 0.263142  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.161775 

Epoch 32
-------------------------------
loss: 0.092068  [    0/69247]
loss: 0.136334  [ 6400/69247]
loss: 0.138644  [12800/69247]
loss: 0.215867  [19200/69247]
loss: 0.224269  [25600/69247]
loss: 0.144686  [32000/69247]
loss: 0.131101  [38400/69247]
loss: 0.107610  [44800/69247]
loss: 0.176255  [51200/69247]
loss: 0.148378  [57600/69247]
loss: 0.124792  [64000/69247]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.163734 

Epoch 33
-------------------------------
loss: 1.714293  [    0/69247]
loss: 0.119458  [ 6400/69247]
loss: 0.165982  [12800/69247]
loss: 0.061035  [19200/69247]
loss: 0.075928  [25600/69247]
loss: 0.285044  [32000/69247]
loss: 0.136560  [38400/69247]
loss: 0.127701  [44800/69247]
loss: 0.124885  [51200/69247]
loss: 0.084991  [57600/69247]
loss: 0.096208  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.157027 

Epoch 34
-------------------------------
loss: 0.078830  [    0/69247]
loss: 0.122167  [ 6400/69247]
loss: 0.209883  [12800/69247]
loss: 0.116595  [19200/69247]
loss: 0.132281  [25600/69247]
loss: 0.148623  [32000/69247]
loss: 0.058212  [38400/69247]
loss: 0.137527  [44800/69247]
loss: 0.084671  [51200/69247]
loss: 0.145941  [57600/69247]
loss: 0.088648  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.157567 

Epoch 35
-------------------------------
loss: 0.084182  [    0/69247]
loss: 0.124777  [ 6400/69247]
loss: 0.281896  [12800/69247]
loss: 0.137130  [19200/69247]
loss: 0.171590  [25600/69247]
loss: 0.147283  [32000/69247]
loss: 0.110764  [38400/69247]
loss: 0.162995  [44800/69247]
loss: 0.165934  [51200/69247]
loss: 0.221703  [57600/69247]
loss: 0.222665  [64000/69247]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.156503 

Epoch 36
-------------------------------
loss: 0.074928  [    0/69247]
loss: 0.185519  [ 6400/69247]
loss: 0.170289  [12800/69247]
loss: 0.093764  [19200/69247]
loss: 0.089064  [25600/69247]
loss: 0.118742  [32000/69247]
loss: 0.177461  [38400/69247]
loss: 0.119330  [44800/69247]
loss: 0.137617  [51200/69247]
loss: 0.083219  [57600/69247]
loss: 0.123509  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.154430 

Epoch 37
-------------------------------
loss: 0.151539  [    0/69247]
loss: 0.129734  [ 6400/69247]
loss: 0.220280  [12800/69247]
loss: 0.164919  [19200/69247]
loss: 0.140359  [25600/69247]
loss: 0.223132  [32000/69247]
loss: 0.127123  [38400/69247]
loss: 0.115330  [44800/69247]
loss: 0.053046  [51200/69247]
loss: 0.131956  [57600/69247]
loss: 0.188201  [64000/69247]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.151972 

Epoch 38
-------------------------------
loss: 0.213217  [    0/69247]
loss: 0.244589  [ 6400/69247]
loss: 0.168331  [12800/69247]
loss: 0.188040  [19200/69247]
loss: 0.183181  [25600/69247]
loss: 0.185448  [32000/69247]
loss: 0.116620  [38400/69247]
loss: 0.078003  [44800/69247]
loss: 0.224992  [51200/69247]
loss: 0.219229  [57600/69247]
loss: 0.166169  [64000/69247]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.155428 

Epoch 39
-------------------------------
loss: 0.122531  [    0/69247]
loss: 0.228513  [ 6400/69247]
loss: 0.128826  [12800/69247]
loss: 0.162924  [19200/69247]
loss: 0.202906  [25600/69247]
loss: 0.177877  [32000/69247]
loss: 0.106857  [38400/69247]
loss: 0.089234  [44800/69247]
loss: 0.124977  [51200/69247]
loss: 0.071908  [    0/70535]
loss: 0.083532  [ 6400/70535]
loss: 0.044481  [12800/70535]
loss: 0.067085  [19200/70535]
loss: 0.198291  [25600/70535]
loss: 0.122141  [32000/70535]
loss: 0.069126  [38400/70535]
loss: 0.047644  [44800/70535]
loss: 0.011808  [51200/70535]
loss: 0.086982  [57600/70535]
loss: 0.048973  [64000/70535]
loss: 0.162424  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.123986 

Epoch 20
-------------------------------
loss: 0.129039  [    0/70535]
loss: 0.025353  [ 6400/70535]
loss: 0.095656  [12800/70535]
loss: 0.023360  [19200/70535]
loss: 0.089246  [25600/70535]
loss: 0.096157  [32000/70535]
loss: 0.080187  [38400/70535]
loss: 0.075117  [44800/70535]
loss: 0.146959  [51200/70535]
loss: 0.061726  [57600/70535]
loss: 0.157789  [64000/70535]
loss: 0.075697  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.115845 

Epoch 21
-------------------------------
loss: 0.133023  [    0/70535]
loss: 0.047036  [ 6400/70535]
loss: 0.016111  [12800/70535]
loss: 0.077110  [19200/70535]
loss: 0.042706  [25600/70535]
loss: 0.034771  [32000/70535]
loss: 0.070849  [38400/70535]
loss: 0.043909  [44800/70535]
loss: 0.055288  [51200/70535]
loss: 0.045477  [57600/70535]
loss: 0.086247  [64000/70535]
loss: 0.086739  [70400/70535]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.145979 

Epoch 22
-------------------------------
loss: 0.023053  [    0/70535]
loss: 0.040846  [ 6400/70535]
loss: 0.035444  [12800/70535]
loss: 0.082610  [19200/70535]
loss: 0.221818  [25600/70535]
loss: 0.037356  [32000/70535]
loss: 0.075566  [38400/70535]
loss: 0.126085  [44800/70535]
loss: 0.058090  [51200/70535]
loss: 0.085633  [57600/70535]
loss: 0.151197  [64000/70535]
loss: 0.048648  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.118252 

Epoch 23
-------------------------------
loss: 0.064362  [    0/70535]
loss: 0.075372  [ 6400/70535]
loss: 0.074656  [12800/70535]
loss: 0.123531  [19200/70535]
loss: 0.205014  [25600/70535]
loss: 0.099205  [32000/70535]
loss: 0.084628  [38400/70535]
loss: 0.031085  [44800/70535]
loss: 0.037589  [51200/70535]
loss: 0.021305  [57600/70535]
loss: 0.021747  [64000/70535]
loss: 0.048341  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.118833 

Epoch 24
-------------------------------
loss: 0.122262  [    0/70535]
loss: 1.705526  [ 6400/70535]
loss: 0.149246  [12800/70535]
loss: 0.109627  [19200/70535]
loss: 0.054628  [25600/70535]
loss: 0.148144  [32000/70535]
loss: 0.068304  [38400/70535]
loss: 0.029612  [44800/70535]
loss: 0.183348  [51200/70535]
loss: 0.095296  [57600/70535]
loss: 0.139956  [64000/70535]
loss: 0.044112  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119205 

Epoch 25
-------------------------------
loss: 0.043366  [    0/70535]
loss: 0.118368  [ 6400/70535]
loss: 0.097030  [12800/70535]
loss: 0.046585  [19200/70535]
loss: 0.015807  [25600/70535]
loss: 0.024250  [32000/70535]
loss: 0.068979  [38400/70535]
loss: 0.006442  [44800/70535]
loss: 0.037067  [51200/70535]
loss: 0.051806  [57600/70535]
loss: 0.076325  [64000/70535]
loss: 0.078852  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119584 

Epoch 26
-------------------------------
loss: 0.060519  [    0/70535]
loss: 0.054361  [ 6400/70535]
loss: 0.065723  [12800/70535]
loss: 0.213819  [19200/70535]
loss: 0.054908  [25600/70535]
loss: 0.070542  [32000/70535]
loss: 0.030399  [38400/70535]
loss: 0.065187  [44800/70535]
loss: 0.032703  [51200/70535]
loss: 0.120726  [57600/70535]
loss: 0.047190  [64000/70535]
loss: 0.063736  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.117650 

Epoch 27
-------------------------------
loss: 0.061453  [    0/70535]
loss: 0.052409  [ 6400/70535]
loss: 0.021102  [12800/70535]
loss: 0.036270  [19200/70535]
loss: 0.044319  [25600/70535]
loss: 0.046635  [32000/70535]
loss: 0.054212  [38400/70535]
loss: 0.062822  [44800/70535]
loss: 0.027573  [51200/70535]
loss: 0.129658  [57600/70535]
loss: 0.071919  [64000/70535]
loss: 0.085470  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.121957 

Epoch 28
-------------------------------
loss: 0.099774  [    0/70535]
loss: 0.056248  [ 6400/70535]
loss: 0.044156  [12800/70535]
loss: 0.049862  [19200/70535]
loss: 0.042454  [25600/70535]
loss: 0.047082  [32000/70535]
loss: 0.085699  [38400/70535]
loss: 0.088747  [44800/70535]
loss: 0.110310  [51200/70535]
loss: 0.071625  [57600/70535]
loss: 0.069881  [64000/70535]
loss: 0.068277  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.123568 

Epoch 29
-------------------------------
loss: 0.022666  [    0/70535]
loss: 0.084483  [ 6400/70535]
loss: 0.097010  [12800/70535]
loss: 1.640793  [19200/70535]
loss: 0.061752  [25600/70535]
loss: 0.010089  [32000/70535]
loss: 0.162306  [38400/70535]
loss: 0.019272  [44800/70535]
loss: 0.126597  [51200/70535]
loss: 0.085317  [57600/70535]
loss: 0.092398  [64000/70535]
loss: 0.045168  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.120983 

Epoch 30
-------------------------------
loss: 0.109678  [    0/70535]
loss: 0.083689  [ 6400/70535]
loss: 0.051573  [12800/70535]
loss: 0.122852  [19200/70535]
loss: 0.083475  [25600/70535]
loss: 0.145552  [32000/70535]
loss: 0.037458  [38400/70535]
loss: 0.038838  [44800/70535]
loss: 0.066056  [51200/70535]
loss: 0.048614  [57600/70535]
loss: 0.072743  [64000/70535]
loss: 0.046421  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.123220 

Epoch 31
-------------------------------
loss: 0.043437  [    0/70535]
loss: 0.031210  [ 6400/70535]
loss: 0.157176  [12800/70535]
loss: 0.071539  [19200/70535]
loss: 0.079878  [25600/70535]
loss: 0.040299  [32000/70535]
loss: 0.083432  [38400/70535]
loss: 0.137009  [44800/70535]
loss: 0.080678  [51200/70535]
loss: 0.051201  [57600/70535]
loss: 0.064157  [64000/70535]
loss: 0.060203  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.127115 

Epoch 32
-------------------------------
loss: 0.111323  [    0/70535]
loss: 0.063862  [ 6400/70535]
loss: 0.036637  [12800/70535]
loss: 0.098293  [19200/70535]
loss: 0.101276  [25600/70535]
loss: 0.162166  [32000/70535]
loss: 0.078710  [38400/70535]
loss: 0.147011  [44800/70535]
loss: 0.028609  [51200/70535]
loss: 0.030692  [57600/70535]
loss: 0.122044  [64000/70535]
loss: 0.075083  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.128775 

Epoch 33
-------------------------------
loss: 0.014648  [    0/70535]
loss: 0.082880  [ 6400/70535]
loss: 0.051677  [12800/70535]
loss: 0.095442  [19200/70535]
loss: 0.045683  [25600/70535]
loss: 0.226221  [32000/70535]
loss: 0.075193  [38400/70535]
loss: 0.034775  [44800/70535]
loss: 0.056127  [51200/70535]
loss: 0.187583  [57600/70535]
loss: 0.101467  [64000/70535]
loss: 0.080661  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119960 

Epoch 34
-------------------------------
loss: 0.112594  [    0/70535]
loss: 0.109323  [ 6400/70535]
loss: 0.072023  [12800/70535]
loss: 0.030449  [19200/70535]
loss: 0.019439  [25600/70535]
loss: 0.026860  [32000/70535]
loss: 0.032136  [38400/70535]
loss: 0.038454  [44800/70535]
loss: 0.011430  [51200/70535]
loss: 0.053284  [57600/70535]
loss: 0.077179  [64000/70535]
loss: 0.243352  [70400/70535]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.115695 

Epoch 35
-------------------------------
loss: 0.095858  [    0/70535]
loss: 0.089964  [ 6400/70535]
loss: 0.090119  [12800/70535]
loss: 0.106255  [19200/70535]
loss: 0.084477  [25600/70535]
loss: 0.065538  [32000/70535]
loss: 0.017068  [38400/70535]
loss: 0.075234  [44800/70535]
loss: 0.070662  [51200/70535]
loss: 0.062005  [57600/70535]
loss: 0.076364  [64000/70535]
loss: 0.065474  [70400/70535]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.118684 

Epoch 36
-------------------------------
loss: 0.032830  [    0/70535]
loss: 0.049727  [ 6400/70535]
loss: 0.034136  [12800/70535]
loss: 0.018600  [19200/70535]
loss: 0.016795  [25600/70535]
loss: 0.113976  [32000/70535]
loss: 0.101316  [38400/70535]
loss: 0.087624  [44800/70535]
loss: 0.050682  [51200/70535]
loss: 0.098538  [57600/70535]
loss: 0.118356  [64000/70535]
loss: 0.079218  [70400/70535]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.116558 

Epoch 37
-------------------------------
loss: 0.038627  [    0/70535]
loss: 0.012704  [25600/69812]
loss: 0.140560  [32000/69812]
loss: 0.051756  [38400/69812]
loss: 0.124300  [44800/69812]
loss: 0.044640  [51200/69812]
loss: 0.105333  [57600/69812]
loss: 0.049389  [64000/69812]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.082191 

Epoch 21
-------------------------------
loss: 0.068501  [    0/69812]
loss: 0.028788  [ 6400/69812]
loss: 0.034751  [12800/69812]
loss: 0.043843  [19200/69812]
loss: 0.136055  [25600/69812]
loss: 0.107695  [32000/69812]
loss: 0.090323  [38400/69812]
loss: 0.037606  [44800/69812]
loss: 0.074964  [51200/69812]
loss: 0.084702  [57600/69812]
loss: 0.066945  [64000/69812]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.090907 

Epoch 22
-------------------------------
loss: 0.075887  [    0/69812]
loss: 0.052567  [ 6400/69812]
loss: 0.038743  [12800/69812]
loss: 0.122331  [19200/69812]
loss: 0.055493  [25600/69812]
loss: 0.060041  [32000/69812]
loss: 0.091011  [38400/69812]
loss: 0.066376  [44800/69812]
loss: 0.029898  [51200/69812]
loss: 0.070446  [57600/69812]
loss: 0.053760  [64000/69812]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.102410 

Epoch 23
-------------------------------
loss: 0.086976  [    0/69812]
loss: 0.024798  [ 6400/69812]
loss: 0.085832  [12800/69812]
loss: 0.106331  [19200/69812]
loss: 0.075582  [25600/69812]
loss: 0.017674  [32000/69812]
loss: 0.025231  [38400/69812]
loss: 0.045992  [44800/69812]
loss: 0.048080  [51200/69812]
loss: 0.066958  [57600/69812]
loss: 0.169731  [64000/69812]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.088659 

Epoch 24
-------------------------------
loss: 0.026222  [    0/69812]
loss: 0.046265  [ 6400/69812]
loss: 0.069681  [12800/69812]
loss: 0.064756  [19200/69812]
loss: 0.032944  [25600/69812]
loss: 0.135702  [32000/69812]
loss: 0.034029  [38400/69812]
loss: 0.144578  [44800/69812]
loss: 0.039200  [51200/69812]
loss: 0.109747  [57600/69812]
loss: 0.155628  [64000/69812]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.080436 

Epoch 25
-------------------------------
loss: 0.059701  [    0/69812]
loss: 0.151179  [ 6400/69812]
loss: 0.107893  [12800/69812]
loss: 0.064926  [19200/69812]
loss: 0.089291  [25600/69812]
loss: 0.101961  [32000/69812]
loss: 0.061863  [38400/69812]
loss: 0.194991  [44800/69812]
loss: 0.125358  [51200/69812]
loss: 0.055835  [57600/69812]
loss: 0.109572  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088416 

Epoch 26
-------------------------------
loss: 0.168285  [    0/69812]
loss: 0.176183  [ 6400/69812]
loss: 0.121518  [12800/69812]
loss: 0.036647  [19200/69812]
loss: 0.068067  [25600/69812]
loss: 0.014050  [32000/69812]
loss: 0.089795  [38400/69812]
loss: 0.112578  [44800/69812]
loss: 0.109388  [51200/69812]
loss: 0.073649  [57600/69812]
loss: 0.054369  [64000/69812]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083128 

Epoch 27
-------------------------------
loss: 0.102974  [    0/69812]
loss: 0.098865  [ 6400/69812]
loss: 0.093217  [12800/69812]
loss: 0.087041  [19200/69812]
loss: 0.036261  [25600/69812]
loss: 0.063326  [32000/69812]
loss: 0.081740  [38400/69812]
loss: 0.043044  [44800/69812]
loss: 0.066816  [51200/69812]
loss: 0.028259  [57600/69812]
loss: 0.131708  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086712 

Epoch 28
-------------------------------
loss: 0.063800  [    0/69812]
loss: 0.063650  [ 6400/69812]
loss: 0.076851  [12800/69812]
loss: 0.188954  [19200/69812]
loss: 0.193705  [25600/69812]
loss: 0.057537  [32000/69812]
loss: 0.055452  [38400/69812]
loss: 0.021597  [44800/69812]
loss: 0.071689  [51200/69812]
loss: 0.122272  [57600/69812]
loss: 0.136425  [64000/69812]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086098 

Epoch 29
-------------------------------
loss: 0.037261  [    0/69812]
loss: 0.021527  [ 6400/69812]
loss: 0.128777  [12800/69812]
loss: 0.013140  [19200/69812]
loss: 0.052778  [25600/69812]
loss: 0.041072  [32000/69812]
loss: 0.062805  [38400/69812]
loss: 0.129302  [44800/69812]
loss: 0.105805  [51200/69812]
loss: 0.130455  [57600/69812]
loss: 0.077666  [64000/69812]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.092050 

Epoch 30
-------------------------------
loss: 0.099732  [    0/69812]
loss: 0.104924  [ 6400/69812]
loss: 0.062438  [12800/69812]
loss: 0.132635  [19200/69812]
loss: 0.059339  [25600/69812]
loss: 0.158180  [32000/69812]
loss: 0.127374  [38400/69812]
loss: 0.047207  [44800/69812]
loss: 0.124644  [51200/69812]
loss: 0.100694  [57600/69812]
loss: 0.107555  [64000/69812]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.095730 

Epoch 31
-------------------------------
loss: 0.074452  [    0/69812]
loss: 0.081887  [ 6400/69812]
loss: 0.065671  [12800/69812]
loss: 0.123257  [19200/69812]
loss: 0.028287  [25600/69812]
loss: 0.055082  [32000/69812]
loss: 0.016377  [38400/69812]
loss: 0.139670  [44800/69812]
loss: 0.108040  [51200/69812]
loss: 0.018461  [57600/69812]
loss: 0.039004  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.093277 

Epoch 32
-------------------------------
loss: 0.032581  [    0/69812]
loss: 0.015530  [ 6400/69812]
loss: 0.101483  [12800/69812]
loss: 0.089925  [19200/69812]
loss: 0.133957  [25600/69812]
loss: 0.054642  [32000/69812]
loss: 0.083084  [38400/69812]
loss: 0.076538  [44800/69812]
loss: 0.078758  [51200/69812]
loss: 0.035692  [57600/69812]
loss: 0.195528  [64000/69812]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.095368 

Epoch 33
-------------------------------
loss: 0.066441  [    0/69812]
loss: 0.043405  [ 6400/69812]
loss: 0.014161  [12800/69812]
loss: 0.065260  [19200/69812]
loss: 0.141411  [25600/69812]
loss: 0.107011  [32000/69812]
loss: 0.025658  [38400/69812]
loss: 0.036613  [44800/69812]
loss: 0.047209  [51200/69812]
loss: 0.074060  [57600/69812]
loss: 0.148820  [64000/69812]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084104 

Epoch 34
-------------------------------
loss: 0.064081  [    0/69812]
loss: 0.031848  [ 6400/69812]
loss: 0.058548  [12800/69812]
loss: 0.168296  [19200/69812]
loss: 0.199934  [25600/69812]
loss: 0.081495  [32000/69812]
loss: 0.211598  [38400/69812]
loss: 0.031002  [44800/69812]
loss: 0.056662  [51200/69812]
loss: 0.052913  [57600/69812]
loss: 0.107814  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089798 

Epoch 35
-------------------------------
loss: 0.057543  [    0/69812]
loss: 0.024287  [ 6400/69812]
loss: 0.061544  [12800/69812]
loss: 0.053459  [19200/69812]
loss: 0.078486  [25600/69812]
loss: 0.083064  [32000/69812]
loss: 0.194793  [38400/69812]
loss: 0.061623  [44800/69812]
loss: 0.082460  [51200/69812]
loss: 0.124243  [57600/69812]
loss: 0.040391  [64000/69812]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.094072 

Epoch 36
-------------------------------
loss: 0.135002  [    0/69812]
loss: 0.077333  [ 6400/69812]
loss: 0.092296  [12800/69812]
loss: 0.090410  [19200/69812]
loss: 0.151052  [25600/69812]
loss: 0.142865  [32000/69812]
loss: 0.007301  [38400/69812]
loss: 0.064062  [44800/69812]
loss: 0.092849  [51200/69812]
loss: 0.077736  [57600/69812]
loss: 0.075807  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088423 

Epoch 37
-------------------------------
loss: 0.046588  [    0/69812]
loss: 0.049222  [ 6400/69812]
loss: 0.040204  [12800/69812]
loss: 0.037080  [19200/69812]
loss: 0.077273  [25600/69812]
loss: 0.041068  [32000/69812]
loss: 0.138447  [38400/69812]
loss: 0.029933  [44800/69812]
loss: 0.039058  [51200/69812]
loss: 0.041590  [57600/69812]
loss: 0.091490  [64000/69812]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.094333 

Epoch 38
-------------------------------
loss: 0.064125  [    0/69812]
loss: 0.088891  [ 6400/69812]
loss: 0.013130  [12800/69812]
loss: 0.034374  [19200/69812]
loss: 0.041917  [25600/69812]
loss: 0.037479  [32000/69812]
loss: 0.080104  [38400/69812]
loss: 0.098893  [44800/69812]
loss: 0.067403  [51200/69812]
loss: 0.034942  [57600/69812]
loss: 0.144878  [64000/69812]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.099098 

Epoch 39
-------------------------------
loss: 0.037271  [    0/69812]
loss: 0.035973  [ 6400/69812]
loss: 0.136160  [12800/69812]
loss: 0.037669  [19200/69812]
loss: 0.015919  [25600/69812]
loss: 0.179049  [32000/69812]
loss: 0.050148  [38400/69812]
loss: 0.031253  [44800/69812]
loss: 0.043316  [51200/69812]
loss: 0.071143  [25600/70165]
loss: 0.165587  [32000/70165]
loss: 0.054692  [38400/70165]
loss: 0.049039  [44800/70165]
loss: 0.231699  [51200/70165]
loss: 0.038190  [57600/70165]
loss: 0.134096  [64000/70165]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.085439 

Epoch 21
-------------------------------
loss: 0.024798  [    0/70165]
loss: 0.025498  [ 6400/70165]
loss: 0.068423  [12800/70165]
loss: 0.065096  [19200/70165]
loss: 0.106817  [25600/70165]
loss: 0.035828  [32000/70165]
loss: 0.020046  [38400/70165]
loss: 0.053921  [44800/70165]
loss: 0.048040  [51200/70165]
loss: 0.023032  [57600/70165]
loss: 0.062933  [64000/70165]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.072339 

Epoch 22
-------------------------------
loss: 0.021833  [    0/70165]
loss: 0.082934  [ 6400/70165]
loss: 0.065855  [12800/70165]
loss: 0.083302  [19200/70165]
loss: 0.061765  [25600/70165]
loss: 0.083820  [32000/70165]
loss: 0.033065  [38400/70165]
loss: 0.028986  [44800/70165]
loss: 0.037798  [51200/70165]
loss: 0.059145  [57600/70165]
loss: 0.136525  [64000/70165]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.085852 

Epoch 23
-------------------------------
loss: 0.026375  [    0/70165]
loss: 0.021724  [ 6400/70165]
loss: 0.029435  [12800/70165]
loss: 0.054041  [19200/70165]
loss: 0.045116  [25600/70165]
loss: 0.053570  [32000/70165]
loss: 0.045063  [38400/70165]
loss: 0.067126  [44800/70165]
loss: 0.069345  [51200/70165]
loss: 0.027722  [57600/70165]
loss: 0.118265  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.076119 

Epoch 24
-------------------------------
loss: 0.075604  [    0/70165]
loss: 0.072820  [ 6400/70165]
loss: 0.010986  [12800/70165]
loss: 0.025865  [19200/70165]
loss: 0.061835  [25600/70165]
loss: 0.033906  [32000/70165]
loss: 0.047880  [38400/70165]
loss: 0.076239  [44800/70165]
loss: 0.036025  [51200/70165]
loss: 0.095908  [57600/70165]
loss: 0.053663  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.074918 

Epoch 25
-------------------------------
loss: 0.009958  [    0/70165]
loss: 0.023102  [ 6400/70165]
loss: 0.038906  [12800/70165]
loss: 0.039508  [19200/70165]
loss: 0.086809  [25600/70165]
loss: 0.072727  [32000/70165]
loss: 0.062044  [38400/70165]
loss: 0.010801  [44800/70165]
loss: 0.073139  [51200/70165]
loss: 0.095782  [57600/70165]
loss: 0.115837  [64000/70165]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.078803 

Epoch 26
-------------------------------
loss: 0.127343  [    0/70165]
loss: 0.032474  [ 6400/70165]
loss: 0.088525  [12800/70165]
loss: 0.070851  [19200/70165]
loss: 0.077034  [25600/70165]
loss: 0.030055  [32000/70165]
loss: 0.042455  [38400/70165]
loss: 0.054259  [44800/70165]
loss: 0.035963  [51200/70165]
loss: 0.032836  [57600/70165]
loss: 0.011765  [64000/70165]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.071951 

Epoch 27
-------------------------------
loss: 0.118611  [    0/70165]
loss: 0.022836  [ 6400/70165]
loss: 0.151545  [12800/70165]
loss: 0.063798  [19200/70165]
loss: 0.100261  [25600/70165]
loss: 0.058560  [32000/70165]
loss: 0.168511  [38400/70165]
loss: 0.048193  [44800/70165]
loss: 0.029416  [51200/70165]
loss: 0.064245  [57600/70165]
loss: 0.014496  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.078334 

Epoch 28
-------------------------------
loss: 0.024585  [    0/70165]
loss: 0.048588  [ 6400/70165]
loss: 0.009634  [12800/70165]
loss: 0.087341  [19200/70165]
loss: 0.067541  [25600/70165]
loss: 0.084204  [32000/70165]
loss: 0.062467  [38400/70165]
loss: 0.042094  [44800/70165]
loss: 0.013516  [51200/70165]
loss: 0.108261  [57600/70165]
loss: 0.152124  [64000/70165]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.083221 

Epoch 29
-------------------------------
loss: 0.084788  [    0/70165]
loss: 0.022539  [ 6400/70165]
loss: 0.039943  [12800/70165]
loss: 0.024367  [19200/70165]
loss: 0.132349  [25600/70165]
loss: 0.043743  [32000/70165]
loss: 0.159092  [38400/70165]
loss: 0.050871  [44800/70165]
loss: 0.058027  [51200/70165]
loss: 0.124755  [57600/70165]
loss: 0.043697  [64000/70165]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.092551 

Epoch 30
-------------------------------
loss: 0.075931  [    0/70165]
loss: 0.013449  [ 6400/70165]
loss: 0.028345  [12800/70165]
loss: 0.109556  [19200/70165]
loss: 0.027424  [25600/70165]
loss: 0.069893  [32000/70165]
loss: 0.069380  [38400/70165]
loss: 0.101830  [44800/70165]
loss: 0.037398  [51200/70165]
loss: 0.080196  [57600/70165]
loss: 0.025170  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.077622 

Epoch 31
-------------------------------
loss: 0.161078  [    0/70165]
loss: 0.075680  [ 6400/70165]
loss: 0.021102  [12800/70165]
loss: 0.142388  [19200/70165]
loss: 0.022673  [25600/70165]
loss: 0.039317  [32000/70165]
loss: 0.007478  [38400/70165]
loss: 0.045594  [44800/70165]
loss: 0.089787  [51200/70165]
loss: 0.119376  [57600/70165]
loss: 0.043093  [64000/70165]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.074239 

Epoch 32
-------------------------------
loss: 0.058280  [    0/70165]
loss: 0.079398  [ 6400/70165]
loss: 0.099247  [12800/70165]
loss: 0.053925  [19200/70165]
loss: 0.116450  [25600/70165]
loss: 0.069630  [32000/70165]
loss: 0.041474  [38400/70165]
loss: 0.025240  [44800/70165]
loss: 0.055280  [51200/70165]
loss: 0.098198  [57600/70165]
loss: 0.034368  [64000/70165]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.097898 

Epoch 33
-------------------------------
loss: 0.015734  [    0/70165]
loss: 0.027733  [ 6400/70165]
loss: 0.065218  [12800/70165]
loss: 0.022610  [19200/70165]
loss: 0.031745  [25600/70165]
loss: 0.084422  [32000/70165]
loss: 0.022874  [38400/70165]
loss: 0.027135  [44800/70165]
loss: 0.138865  [51200/70165]
loss: 0.041942  [57600/70165]
loss: 0.124439  [64000/70165]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078742 

Epoch 34
-------------------------------
loss: 0.082976  [    0/70165]
loss: 0.072466  [ 6400/70165]
loss: 0.090108  [12800/70165]
loss: 0.064916  [19200/70165]
loss: 0.028520  [25600/70165]
loss: 0.011054  [32000/70165]
loss: 0.118635  [38400/70165]
loss: 0.050201  [44800/70165]
loss: 0.083985  [51200/70165]
loss: 0.026899  [57600/70165]
loss: 0.054199  [64000/70165]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076765 

Epoch 35
-------------------------------
loss: 0.012360  [    0/70165]
loss: 0.022378  [ 6400/70165]
loss: 0.054873  [12800/70165]
loss: 0.100255  [19200/70165]
loss: 0.060633  [25600/70165]
loss: 0.067128  [32000/70165]
loss: 0.070581  [38400/70165]
loss: 0.164384  [44800/70165]
loss: 0.049921  [51200/70165]
loss: 0.043992  [57600/70165]
loss: 0.109575  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.076544 

Epoch 36
-------------------------------
loss: 0.061494  [    0/70165]
loss: 0.056425  [ 6400/70165]
loss: 0.054471  [12800/70165]
loss: 0.081425  [19200/70165]
loss: 0.078341  [25600/70165]
loss: 0.146013  [32000/70165]
loss: 0.107843  [38400/70165]
loss: 0.129308  [44800/70165]
loss: 0.055415  [51200/70165]
loss: 0.160603  [57600/70165]
loss: 0.075542  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.083102 

Epoch 37
-------------------------------
loss: 0.068130  [    0/70165]
loss: 0.019294  [ 6400/70165]
loss: 0.075735  [12800/70165]
loss: 0.014614  [19200/70165]
loss: 0.048418  [25600/70165]
loss: 0.016808  [32000/70165]
loss: 0.026133  [38400/70165]
loss: 0.058326  [44800/70165]
loss: 0.079359  [51200/70165]
loss: 0.063739  [57600/70165]
loss: 0.064022  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.077484 

Epoch 38
-------------------------------
loss: 0.065498  [    0/70165]
loss: 0.107757  [ 6400/70165]
loss: 0.121382  [12800/70165]
loss: 0.041801  [19200/70165]
loss: 0.036057  [25600/70165]
loss: 0.037742  [32000/70165]
loss: 0.110651  [38400/70165]
loss: 0.088135  [44800/70165]
loss: 0.077397  [51200/70165]
loss: 0.033497  [57600/70165]
loss: 0.082536  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082380 

Epoch 39
-------------------------------
loss: 0.032784  [    0/70165]
loss: 0.078036  [ 6400/70165]
loss: 0.057561  [12800/70165]
loss: 0.065373  [19200/70165]
loss: 0.067028  [25600/70165]
loss: 0.031443  [32000/70165]
loss: 0.027004  [38400/70165]
loss: 0.018123  [44800/70165]
loss: 0.037107  [51200/70165]
2022/09/20 13:02:33 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:02:37 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:05:07 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:05:55 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:06:10 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:06:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:06:23 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:06:35 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:07:02 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:07:06 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:07:19 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:07:21 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:07:39 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:07:59 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:08:03 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:08:06 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:08:21 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:08:21 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.001120  [ 6400/72281]
loss: 0.075745  [12800/72281]
loss: 0.002336  [19200/72281]
loss: 0.004008  [25600/72281]
loss: 0.009184  [32000/72281]
loss: 0.028096  [38400/72281]
loss: 0.029839  [44800/72281]
loss: 0.021423  [51200/72281]
loss: 0.032740  [57600/72281]
loss: 0.022027  [64000/72281]
loss: 0.040983  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.095968 

Epoch 38
-------------------------------
loss: 0.187730  [    0/72281]
loss: 0.002400  [ 6400/72281]
loss: 0.000061  [12800/72281]
loss: 0.075186  [19200/72281]
loss: 0.059471  [25600/72281]
loss: 0.021709  [32000/72281]
loss: 0.019880  [38400/72281]
loss: 0.028548  [44800/72281]
loss: 0.019504  [51200/72281]
loss: 0.012340  [57600/72281]
loss: 0.026372  [64000/72281]
loss: 0.076138  [70400/72281]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.106868 

Epoch 39
-------------------------------
loss: 0.010486  [    0/72281]
loss: 0.066826  [ 6400/72281]
loss: 0.001223  [12800/72281]
loss: 0.014692  [19200/72281]
loss: 0.005043  [25600/72281]
loss: 0.019427  [32000/72281]
loss: 0.049273  [38400/72281]
loss: 0.023368  [44800/72281]
loss: 0.053464  [51200/72281]
loss: 0.169110  [57600/72281]
loss: 0.008149  [64000/72281]
loss: 0.065409  [70400/72281]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.110694 

Epoch 40
-------------------------------
loss: 0.002755  [    0/72281]
loss: 0.049274  [ 6400/72281]
loss: 0.004087  [12800/72281]
loss: 0.100785  [19200/72281]
loss: 0.043688  [25600/72281]
loss: 0.039048  [32000/72281]
loss: 0.012538  [38400/72281]
loss: 0.048418  [44800/72281]
loss: 0.074090  [51200/72281]
loss: 0.001004  [57600/72281]
loss: 0.003843  [64000/72281]
loss: 0.015129  [70400/72281]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.101501 

Epoch 41
-------------------------------
loss: 0.010672  [    0/72281]
loss: 0.011914  [ 6400/72281]
loss: 0.008087  [12800/72281]
loss: 0.012126  [19200/72281]
loss: 0.018769  [25600/72281]
loss: 0.034474  [32000/72281]
loss: 0.012831  [38400/72281]
loss: 0.021828  [44800/72281]
loss: 0.034118  [51200/72281]
loss: 0.021503  [57600/72281]
loss: 0.083674  [64000/72281]
loss: 0.068927  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.101923 

Epoch 42
-------------------------------
loss: 0.051157  [    0/72281]
loss: 0.021165  [ 6400/72281]
loss: 0.000781  [12800/72281]
loss: 0.044554  [19200/72281]
loss: 0.006735  [25600/72281]
loss: 0.087470  [32000/72281]
loss: 0.005226  [38400/72281]
loss: 0.043954  [44800/72281]
loss: 0.055864  [51200/72281]
loss: 0.016921  [57600/72281]
loss: 0.023184  [64000/72281]
loss: 0.045253  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.102844 

Epoch 43
-------------------------------
loss: 1.610981  [    0/72281]
loss: 0.005532  [ 6400/72281]
loss: 0.003761  [12800/72281]
loss: 0.001612  [19200/72281]
loss: 0.002554  [25600/72281]
loss: 0.126972  [32000/72281]
loss: 0.037966  [38400/72281]
loss: 0.061002  [44800/72281]
loss: 0.001437  [51200/72281]
loss: 0.019075  [57600/72281]
loss: 0.091534  [64000/72281]
loss: 0.008120  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.092218 

Epoch 44
-------------------------------
loss: 0.023083  [    0/72281]
loss: 0.002282  [ 6400/72281]
loss: 0.064513  [12800/72281]
loss: 0.094632  [19200/72281]
loss: 0.036340  [25600/72281]
loss: 0.095104  [32000/72281]
loss: 0.029434  [38400/72281]
loss: 0.038841  [44800/72281]
loss: 0.122092  [51200/72281]
loss: 0.000229  [57600/72281]
loss: 0.013534  [64000/72281]
loss: 0.073970  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.090190 

Epoch 45
-------------------------------
loss: 0.004438  [    0/72281]
loss: 0.031024  [ 6400/72281]
loss: 0.011950  [12800/72281]
loss: 0.011565  [19200/72281]
loss: 0.020644  [25600/72281]
loss: 0.003291  [32000/72281]
loss: 0.023135  [38400/72281]
loss: 0.009584  [44800/72281]
loss: 0.011221  [51200/72281]
loss: 0.042269  [57600/72281]
loss: 0.021582  [64000/72281]
loss: 0.052858  [70400/72281]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.104223 

Epoch 46
-------------------------------
loss: 0.006283  [    0/72281]
loss: 0.083203  [ 6400/72281]
loss: 0.007050  [12800/72281]
loss: 0.026885  [19200/72281]
loss: 0.019260  [25600/72281]
loss: 0.002489  [32000/72281]
loss: 0.018208  [38400/72281]
loss: 0.044696  [44800/72281]
loss: 0.006992  [51200/72281]
loss: 0.081035  [57600/72281]
loss: 0.049825  [64000/72281]
loss: 0.000975  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.090546 

Epoch 47
-------------------------------
loss: 0.019134  [    0/72281]
loss: 0.001732  [ 6400/72281]
loss: 0.009047  [12800/72281]
loss: 0.003668  [19200/72281]
loss: 0.011387  [25600/72281]
loss: 0.019996  [32000/72281]
loss: 0.035797  [38400/72281]
loss: 0.011338  [44800/72281]
loss: 0.005208  [51200/72281]
loss: 0.005513  [57600/72281]
loss: 0.063828  [64000/72281]
loss: 0.015497  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.101724 

Epoch 48
-------------------------------
loss: 0.006821  [    0/72281]
loss: 0.006604  [ 6400/72281]
loss: 0.001548  [12800/72281]
loss: 0.006984  [19200/72281]
loss: 0.012121  [25600/72281]
loss: 0.017992  [32000/72281]
loss: 0.001764  [38400/72281]
loss: 0.006451  [44800/72281]
loss: 0.016420  [51200/72281]
loss: 0.002462  [57600/72281]
loss: 0.205106  [64000/72281]
loss: 0.001458  [70400/72281]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.093090 

Epoch 49
-------------------------------
loss: 0.012686  [    0/72281]
loss: 0.022441  [ 6400/72281]
loss: 0.023558  [12800/72281]
loss: 0.013622  [19200/72281]
loss: 0.028072  [25600/72281]
loss: 0.031005  [32000/72281]
loss: 0.052710  [38400/72281]
loss: 0.018872  [44800/72281]
loss: 0.036231  [51200/72281]
loss: 0.005497  [57600/72281]
loss: 0.006511  [64000/72281]
loss: 0.003891  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.111818 

Epoch 50
-------------------------------
loss: 0.003022  [    0/72281]
loss: 0.015100  [ 6400/72281]
loss: 0.034640  [12800/72281]
loss: 0.070927  [19200/72281]
loss: 0.049045  [25600/72281]
loss: 0.021817  [32000/72281]
loss: 0.062406  [38400/72281]
loss: 0.018841  [44800/72281]
loss: 0.135688  [51200/72281]
loss: 0.072377  [57600/72281]
loss: 0.011931  [64000/72281]
loss: 0.018100  [70400/72281]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.115711 

Epoch 1
-------------------------------
loss: 0.712973  [    0/69609]
loss: 0.310817  [ 6400/69609]
loss: 0.369056  [12800/69609]
loss: 0.278102  [19200/69609]
loss: 0.238976  [25600/69609]
loss: 0.395046  [32000/69609]
loss: 0.230909  [38400/69609]
loss: 0.272524  [44800/69609]
loss: 0.323819  [51200/69609]
loss: 0.116422  [57600/69609]
loss: 0.140234  [64000/69609]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.184499 

Epoch 2
-------------------------------
loss: 0.263310  [    0/69609]
loss: 0.134655  [ 6400/69609]
loss: 0.183979  [12800/69609]
loss: 0.200769  [19200/69609]
loss: 0.163942  [25600/69609]
loss: 0.197765  [32000/69609]
loss: 0.197265  [38400/69609]
loss: 0.107994  [44800/69609]
loss: 0.162917  [51200/69609]
loss: 0.275979  [57600/69609]
loss: 0.121478  [64000/69609]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.165194 

Epoch 3
-------------------------------
loss: 0.110796  [    0/69609]
loss: 0.077842  [ 6400/69609]
loss: 0.233385  [12800/69609]
loss: 0.387861  [19200/69609]
loss: 0.137172  [25600/69609]
loss: 0.111024  [32000/69609]
loss: 0.152886  [38400/69609]
loss: 0.147814  [44800/69609]
loss: 0.133087  [51200/69609]
loss: 0.167136  [57600/69609]
loss: 0.107788  [64000/69609]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162582 

Epoch 4
-------------------------------
loss: 0.106109  [    0/69609]
loss: 0.198437  [ 6400/69609]
loss: 0.207422  [12800/69609]
loss: 0.167016  [19200/69609]
loss: 0.109777  [25600/69609]
loss: 0.136696  [32000/69609]
loss: 0.119540  [38400/69609]
loss: 0.070010  [44800/69609]
loss: 0.133647  [51200/69609]
loss: 0.227244  [57600/69609]
loss: 0.140720  [64000/69609]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.156601 

Epoch 5
-------------------------------
loss: 0.240920  [    0/69609]
loss: 0.052735  [ 6400/69609]
loss: 0.129346  [12800/69609]
loss: 0.132902  [19200/69609]
loss: 0.078862  [25600/69609]
loss: 0.192164  [32000/69609]
loss: 0.057011  [ 6400/70880]
loss: 0.007137  [12800/70880]
loss: 0.051266  [19200/70880]
loss: 0.015622  [25600/70880]
loss: 0.013169  [32000/70880]
loss: 0.096517  [38400/70880]
loss: 0.024248  [44800/70880]
loss: 0.004420  [51200/70880]
loss: 0.004852  [57600/70880]
loss: 0.002840  [64000/70880]
loss: 0.016328  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.088521 

Epoch 38
-------------------------------
loss: 0.005410  [    0/70880]
loss: 0.111298  [ 6400/70880]
loss: 0.015935  [12800/70880]
loss: 0.035014  [19200/70880]
loss: 0.014591  [25600/70880]
loss: 0.052275  [32000/70880]
loss: 0.047643  [38400/70880]
loss: 0.035178  [44800/70880]
loss: 0.014075  [51200/70880]
loss: 0.007671  [57600/70880]
loss: 0.030985  [64000/70880]
loss: 0.021941  [70400/70880]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.091359 

Epoch 39
-------------------------------
loss: 0.027120  [    0/70880]
loss: 0.019015  [ 6400/70880]
loss: 0.071068  [12800/70880]
loss: 0.021108  [19200/70880]
loss: 0.007981  [25600/70880]
loss: 0.026322  [32000/70880]
loss: 0.004007  [38400/70880]
loss: 0.012789  [44800/70880]
loss: 0.076368  [51200/70880]
loss: 0.138422  [57600/70880]
loss: 0.094967  [64000/70880]
loss: 0.033931  [70400/70880]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.107355 

Epoch 40
-------------------------------
loss: 0.023230  [    0/70880]
loss: 0.016869  [ 6400/70880]
loss: 0.063042  [12800/70880]
loss: 0.054547  [19200/70880]
loss: 0.021976  [25600/70880]
loss: 0.055359  [32000/70880]
loss: 0.047499  [38400/70880]
loss: 0.010523  [44800/70880]
loss: 0.066185  [51200/70880]
loss: 0.066864  [57600/70880]
loss: 0.010096  [64000/70880]
loss: 0.084801  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.090742 

Epoch 41
-------------------------------
loss: 0.013536  [    0/70880]
loss: 0.029216  [ 6400/70880]
loss: 0.048885  [12800/70880]
loss: 0.013972  [19200/70880]
loss: 0.022724  [25600/70880]
loss: 0.017591  [32000/70880]
loss: 0.012995  [38400/70880]
loss: 0.015768  [44800/70880]
loss: 0.012776  [51200/70880]
loss: 0.007416  [57600/70880]
loss: 0.068411  [64000/70880]
loss: 0.000484  [70400/70880]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.110082 

Epoch 42
-------------------------------
loss: 0.037709  [    0/70880]
loss: 0.122071  [ 6400/70880]
loss: 0.010950  [12800/70880]
loss: 0.007737  [19200/70880]
loss: 0.027688  [25600/70880]
loss: 0.008605  [32000/70880]
loss: 0.023231  [38400/70880]
loss: 0.019351  [44800/70880]
loss: 0.072115  [51200/70880]
loss: 0.007613  [57600/70880]
loss: 0.013400  [64000/70880]
loss: 0.013852  [70400/70880]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.115278 

Epoch 43
-------------------------------
loss: 0.052780  [    0/70880]
loss: 0.027248  [ 6400/70880]
loss: 0.009759  [12800/70880]
loss: 0.032818  [19200/70880]
loss: 0.035733  [25600/70880]
loss: 0.033205  [32000/70880]
loss: 0.020524  [38400/70880]
loss: 0.027625  [44800/70880]
loss: 0.063130  [51200/70880]
loss: 0.015854  [57600/70880]
loss: 0.038357  [64000/70880]
loss: 0.107944  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.100026 

Epoch 44
-------------------------------
loss: 0.024608  [    0/70880]
loss: 0.027163  [ 6400/70880]
loss: 0.086017  [12800/70880]
loss: 0.010941  [19200/70880]
loss: 0.053052  [25600/70880]
loss: 0.043132  [32000/70880]
loss: 0.011151  [38400/70880]
loss: 0.090676  [44800/70880]
loss: 0.061580  [51200/70880]
loss: 0.032359  [57600/70880]
loss: 0.042473  [64000/70880]
loss: 0.110288  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.098223 

Epoch 45
-------------------------------
loss: 0.038835  [    0/70880]
loss: 0.091946  [ 6400/70880]
loss: 0.142222  [12800/70880]
loss: 0.005630  [19200/70880]
loss: 0.022582  [25600/70880]
loss: 0.019109  [32000/70880]
loss: 0.046244  [38400/70880]
loss: 0.077556  [44800/70880]
loss: 0.025722  [51200/70880]
loss: 0.080260  [57600/70880]
loss: 0.029465  [64000/70880]
loss: 0.047468  [70400/70880]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.097938 

Epoch 46
-------------------------------
loss: 0.009548  [    0/70880]
loss: 0.030646  [ 6400/70880]
loss: 0.003156  [12800/70880]
loss: 0.047451  [19200/70880]
loss: 0.046388  [25600/70880]
loss: 0.006024  [32000/70880]
loss: 0.027313  [38400/70880]
loss: 0.018843  [44800/70880]
loss: 0.004551  [51200/70880]
loss: 0.027273  [57600/70880]
loss: 0.015428  [64000/70880]
loss: 0.043714  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.107001 

Epoch 47
-------------------------------
loss: 0.045484  [    0/70880]
loss: 0.031102  [ 6400/70880]
loss: 0.008958  [12800/70880]
loss: 0.040915  [19200/70880]
loss: 0.033751  [25600/70880]
loss: 0.058759  [32000/70880]
loss: 0.112777  [38400/70880]
loss: 0.028141  [44800/70880]
loss: 0.063778  [51200/70880]
loss: 0.042289  [57600/70880]
loss: 0.063149  [64000/70880]
loss: 0.024363  [70400/70880]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.117232 

Epoch 48
-------------------------------
loss: 0.031792  [    0/70880]
loss: 0.011629  [ 6400/70880]
loss: 0.056105  [12800/70880]
loss: 0.055140  [19200/70880]
loss: 0.067030  [25600/70880]
loss: 0.038328  [32000/70880]
loss: 0.032750  [38400/70880]
loss: 0.056680  [44800/70880]
loss: 0.074168  [51200/70880]
loss: 0.011466  [57600/70880]
loss: 0.046409  [64000/70880]
loss: 0.013619  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.095063 

Epoch 49
-------------------------------
loss: 0.028534  [    0/70880]
loss: 0.055000  [ 6400/70880]
loss: 0.013814  [12800/70880]
loss: 0.029762  [19200/70880]
loss: 0.035119  [25600/70880]
loss: 0.010962  [32000/70880]
loss: 0.006279  [38400/70880]
loss: 0.066427  [44800/70880]
loss: 0.021555  [51200/70880]
loss: 0.012120  [57600/70880]
loss: 0.017381  [64000/70880]
loss: 0.032911  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.103351 

Epoch 50
-------------------------------
loss: 0.055015  [    0/70880]
loss: 0.030639  [ 6400/70880]
loss: 0.004198  [12800/70880]
loss: 0.036376  [19200/70880]
loss: 0.008629  [25600/70880]
loss: 0.011524  [32000/70880]
loss: 0.018869  [38400/70880]
loss: 0.247244  [44800/70880]
loss: 0.004045  [51200/70880]
loss: 0.022773  [57600/70880]
loss: 0.175187  [64000/70880]
loss: 0.024597  [70400/70880]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.092520 

Epoch 1
-------------------------------
loss: 0.734335  [    0/71031]
loss: 0.152995  [ 6400/71031]
loss: 0.059434  [12800/71031]
loss: 0.235671  [19200/71031]
loss: 0.160429  [25600/71031]
loss: 0.107184  [32000/71031]
loss: 0.193246  [38400/71031]
loss: 0.120571  [44800/71031]
loss: 0.084002  [51200/71031]
loss: 0.120757  [57600/71031]
loss: 0.095299  [64000/71031]
loss: 0.151655  [70400/71031]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.148878 

Epoch 2
-------------------------------
loss: 0.117903  [    0/71031]
loss: 0.073840  [ 6400/71031]
loss: 0.057937  [12800/71031]
loss: 0.031792  [19200/71031]
loss: 0.079394  [25600/71031]
loss: 0.109168  [32000/71031]
loss: 0.054695  [38400/71031]
loss: 0.038584  [44800/71031]
loss: 0.161661  [51200/71031]
loss: 0.122288  [57600/71031]
loss: 0.072306  [64000/71031]
loss: 0.039772  [70400/71031]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.132443 

Epoch 3
-------------------------------
loss: 0.060328  [    0/71031]
loss: 0.058677  [ 6400/71031]
loss: 0.018186  [12800/71031]
loss: 0.111635  [19200/71031]
loss: 0.079689  [25600/71031]
loss: 0.022059  [32000/71031]
loss: 0.099092  [38400/71031]
loss: 0.080095  [44800/71031]
loss: 0.078543  [51200/71031]
loss: 0.143613  [57600/71031]
loss: 0.116012  [64000/71031]
loss: 0.147468  [70400/71031]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.131885 

Epoch 4
-------------------------------
loss: 0.106632  [    0/71031]
loss: 0.102989  [ 6400/71031]
loss: 0.122270  [12800/71031]
loss: 0.055860  [19200/71031]
loss: 0.118221  [25600/71031]
loss: 0.238904  [32000/71031]
loss: 0.124825  [38400/71031]
loss: 0.012646  [44800/71031]
loss: 0.062448  [51200/71031]
loss: 0.026046  [57600/71031]
loss: 0.083439  [64000/71031]
loss: 0.139749  [70400/71031]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.130863 

Epoch 5
-------------------------------
loss: 0.087844  [    0/71031]
loss: 0.031434  [ 6400/71031]
loss: 0.002001  [ 6400/71625]
loss: 0.010028  [12800/71625]
loss: 0.000323  [19200/71625]
loss: 0.006489  [25600/71625]
loss: 0.017602  [32000/71625]
loss: 0.001089  [38400/71625]
loss: 0.009648  [44800/71625]
loss: 0.091961  [51200/71625]
loss: 0.008084  [57600/71625]
loss: 0.014451  [64000/71625]
loss: 0.039693  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.057617 

Epoch 38
-------------------------------
loss: 0.049127  [    0/71625]
loss: 0.034405  [ 6400/71625]
loss: 0.033546  [12800/71625]
loss: 0.005374  [19200/71625]
loss: 0.000639  [25600/71625]
loss: 0.002422  [32000/71625]
loss: 0.007125  [38400/71625]
loss: 0.002157  [44800/71625]
loss: 0.065162  [51200/71625]
loss: 0.001828  [57600/71625]
loss: 0.011663  [64000/71625]
loss: 0.062007  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.068538 

Epoch 39
-------------------------------
loss: 0.051769  [    0/71625]
loss: 0.051240  [ 6400/71625]
loss: 0.013723  [12800/71625]
loss: 0.047926  [19200/71625]
loss: 0.003520  [25600/71625]
loss: 0.013196  [32000/71625]
loss: 0.004210  [38400/71625]
loss: 0.011005  [44800/71625]
loss: 0.002633  [51200/71625]
loss: 0.014892  [57600/71625]
loss: 0.004725  [64000/71625]
loss: 0.010368  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.065883 

Epoch 40
-------------------------------
loss: 0.036364  [    0/71625]
loss: 0.003255  [ 6400/71625]
loss: 0.045382  [12800/71625]
loss: 0.028813  [19200/71625]
loss: 0.003108  [25600/71625]
loss: 0.109582  [32000/71625]
loss: 0.063709  [38400/71625]
loss: 0.034146  [44800/71625]
loss: 0.005451  [51200/71625]
loss: 0.018548  [57600/71625]
loss: 0.105346  [64000/71625]
loss: 0.005719  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.056206 

Epoch 41
-------------------------------
loss: 0.003340  [    0/71625]
loss: 0.022882  [ 6400/71625]
loss: 0.068263  [12800/71625]
loss: 0.003321  [19200/71625]
loss: 0.007633  [25600/71625]
loss: 0.004606  [32000/71625]
loss: 0.019844  [38400/71625]
loss: 0.022774  [44800/71625]
loss: 0.006751  [51200/71625]
loss: 0.116168  [57600/71625]
loss: 0.002164  [64000/71625]
loss: 0.078558  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.057949 

Epoch 42
-------------------------------
loss: 0.056137  [    0/71625]
loss: 0.000776  [ 6400/71625]
loss: 0.028130  [12800/71625]
loss: 0.008730  [19200/71625]
loss: 0.001083  [25600/71625]
loss: 0.003426  [32000/71625]
loss: 0.002092  [38400/71625]
loss: 0.012896  [44800/71625]
loss: 0.007035  [51200/71625]
loss: 0.002388  [57600/71625]
loss: 0.025433  [64000/71625]
loss: 0.037949  [70400/71625]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.065870 

Epoch 43
-------------------------------
loss: 0.020940  [    0/71625]
loss: 0.073391  [ 6400/71625]
loss: 0.001053  [12800/71625]
loss: 0.003702  [19200/71625]
loss: 1.589362  [25600/71625]
loss: 0.022909  [32000/71625]
loss: 0.003787  [38400/71625]
loss: 0.002692  [44800/71625]
loss: 0.001557  [51200/71625]
loss: 0.023910  [57600/71625]
loss: 0.016637  [64000/71625]
loss: 0.008806  [70400/71625]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.149765 

Epoch 44
-------------------------------
loss: 0.054199  [    0/71625]
loss: 0.014443  [ 6400/71625]
loss: 0.015243  [12800/71625]
loss: 0.011089  [19200/71625]
loss: 0.026175  [25600/71625]
loss: 0.068338  [32000/71625]
loss: 0.004125  [38400/71625]
loss: 0.004988  [44800/71625]
loss: 0.061883  [51200/71625]
loss: 0.003272  [57600/71625]
loss: 0.000298  [64000/71625]
loss: 0.096656  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.072291 

Epoch 45
-------------------------------
loss: 0.028826  [    0/71625]
loss: 0.004988  [ 6400/71625]
loss: 0.001079  [12800/71625]
loss: 0.004612  [19200/71625]
loss: 0.016631  [25600/71625]
loss: 0.001164  [32000/71625]
loss: 0.021164  [38400/71625]
loss: 0.005082  [44800/71625]
loss: 0.001403  [51200/71625]
loss: 0.004677  [57600/71625]
loss: 0.013129  [64000/71625]
loss: 0.032734  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.081441 

Epoch 46
-------------------------------
loss: 0.018715  [    0/71625]
loss: 0.025418  [ 6400/71625]
loss: 0.000721  [12800/71625]
loss: 0.054428  [19200/71625]
loss: 0.007854  [25600/71625]
loss: 0.084336  [32000/71625]
loss: 0.018678  [38400/71625]
loss: 0.006190  [44800/71625]
loss: 0.008899  [51200/71625]
loss: 0.000970  [57600/71625]
loss: 0.028899  [64000/71625]
loss: 0.018804  [70400/71625]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.068967 

Epoch 47
-------------------------------
loss: 0.027804  [    0/71625]
loss: 0.008416  [ 6400/71625]
loss: 0.009648  [12800/71625]
loss: 0.002187  [19200/71625]
loss: 0.003159  [25600/71625]
loss: 0.003969  [32000/71625]
loss: 0.004712  [38400/71625]
loss: 0.025442  [44800/71625]
loss: 0.045450  [51200/71625]
loss: 0.017010  [57600/71625]
loss: 0.003141  [64000/71625]
loss: 0.003651  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.066273 

Epoch 48
-------------------------------
loss: 0.004007  [    0/71625]
loss: 0.007796  [ 6400/71625]
loss: 0.009242  [12800/71625]
loss: 0.010521  [19200/71625]
loss: 0.011740  [25600/71625]
loss: 0.023778  [32000/71625]
loss: 0.022696  [38400/71625]
loss: 0.038632  [44800/71625]
loss: 0.003617  [51200/71625]
loss: 0.237531  [57600/71625]
loss: 0.050893  [64000/71625]
loss: 0.000925  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.055723 

Epoch 49
-------------------------------
loss: 0.010993  [    0/71625]
loss: 0.007072  [ 6400/71625]
loss: 0.001073  [12800/71625]
loss: 0.025771  [19200/71625]
loss: 0.022173  [25600/71625]
loss: 0.004888  [32000/71625]
loss: 0.030181  [38400/71625]
loss: 0.006559  [44800/71625]
loss: 0.012269  [51200/71625]
loss: 0.016646  [57600/71625]
loss: 0.010770  [64000/71625]
loss: 0.008732  [70400/71625]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.063942 

Epoch 50
-------------------------------
loss: 0.000703  [    0/71625]
loss: 0.004511  [ 6400/71625]
loss: 0.004636  [12800/71625]
loss: 0.013190  [19200/71625]
loss: 0.022950  [25600/71625]
loss: 0.006580  [32000/71625]
loss: 0.008660  [38400/71625]
loss: 0.060152  [44800/71625]
loss: 0.007975  [51200/71625]
loss: 0.002817  [57600/71625]
loss: 0.006473  [64000/71625]
loss: 0.010063  [70400/71625]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.069925 

Epoch 1
-------------------------------
loss: 0.727564  [    0/71122]
loss: 0.142319  [ 6400/71122]
loss: 0.063683  [12800/71122]
loss: 0.115357  [19200/71122]
loss: 0.105662  [25600/71122]
loss: 0.063531  [32000/71122]
loss: 0.070697  [38400/71122]
loss: 0.033957  [44800/71122]
loss: 0.326321  [51200/71122]
loss: 0.198412  [57600/71122]
loss: 0.075759  [64000/71122]
loss: 0.053420  [70400/71122]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.081478 

Epoch 2
-------------------------------
loss: 0.049537  [    0/71122]
loss: 0.155251  [ 6400/71122]
loss: 0.099802  [12800/71122]
loss: 0.119234  [19200/71122]
loss: 0.097767  [25600/71122]
loss: 0.215065  [32000/71122]
loss: 0.061836  [38400/71122]
loss: 0.061771  [44800/71122]
loss: 0.018437  [51200/71122]
loss: 0.013294  [57600/71122]
loss: 0.109912  [64000/71122]
loss: 0.129340  [70400/71122]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.073344 

Epoch 3
-------------------------------
loss: 0.019702  [    0/71122]
loss: 0.026505  [ 6400/71122]
loss: 0.053655  [12800/71122]
loss: 0.057159  [19200/71122]
loss: 0.056284  [25600/71122]
loss: 0.149069  [32000/71122]
loss: 0.053133  [38400/71122]
loss: 0.049760  [44800/71122]
loss: 0.291868  [51200/71122]
loss: 0.032270  [57600/71122]
loss: 0.096671  [64000/71122]
loss: 0.078831  [70400/71122]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.072274 

Epoch 4
-------------------------------
loss: 0.039976  [    0/71122]
loss: 0.092522  [ 6400/71122]
loss: 0.027264  [12800/71122]
loss: 0.034266  [19200/71122]
loss: 0.093372  [25600/71122]
loss: 0.213176  [32000/71122]
loss: 0.065789  [38400/71122]
loss: 0.012668  [44800/71122]
loss: 0.091174  [51200/71122]
loss: 0.078251  [57600/71122]
loss: 0.021719  [64000/71122]
loss: 0.025700  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.076934 

Epoch 5
-------------------------------
loss: 0.021456  [    0/71122]
loss: 0.026738  [ 6400/71122]
2022/09/20 13:11:34 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 13:11:35 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.024485  [ 6400/72302]
loss: 0.084169  [12800/72302]
loss: 0.002236  [19200/72302]
loss: 0.039698  [25600/72302]
loss: 0.006699  [32000/72302]
loss: 0.009589  [38400/72302]
loss: 0.010535  [44800/72302]
loss: 0.002938  [51200/72302]
loss: 0.000610  [57600/72302]
loss: 0.020081  [64000/72302]
loss: 0.009140  [70400/72302]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.069963 

Epoch 38
-------------------------------
loss: 0.001653  [    0/72302]
loss: 0.001425  [ 6400/72302]
loss: 0.001027  [12800/72302]
loss: 0.005419  [19200/72302]
loss: 0.000750  [25600/72302]
loss: 0.001164  [32000/72302]
loss: 0.000685  [38400/72302]
loss: 0.011840  [44800/72302]
loss: 0.000645  [51200/72302]
loss: 0.001446  [57600/72302]
loss: 0.028438  [64000/72302]
loss: 0.069783  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.046386 

Epoch 39
-------------------------------
loss: 0.064811  [    0/72302]
loss: 0.007390  [ 6400/72302]
loss: 0.012825  [12800/72302]
loss: 0.001669  [19200/72302]
loss: 0.025846  [25600/72302]
loss: 0.004684  [32000/72302]
loss: 1.563563  [38400/72302]
loss: 0.006535  [44800/72302]
loss: 0.012691  [51200/72302]
loss: 0.002745  [57600/72302]
loss: 0.002852  [64000/72302]
loss: 0.000634  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.049037 

Epoch 40
-------------------------------
loss: 0.001747  [    0/72302]
loss: 0.000765  [ 6400/72302]
loss: 0.046526  [12800/72302]
loss: 0.044504  [19200/72302]
loss: 0.002595  [25600/72302]
loss: 0.018602  [32000/72302]
loss: 0.017187  [38400/72302]
loss: 0.000620  [44800/72302]
loss: 0.003150  [51200/72302]
loss: 0.078949  [57600/72302]
loss: 0.001249  [64000/72302]
loss: 0.016520  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.059946 

Epoch 41
-------------------------------
loss: 0.005138  [    0/72302]
loss: 0.072607  [ 6400/72302]
loss: 0.058585  [12800/72302]
loss: 0.001327  [19200/72302]
loss: 0.000808  [25600/72302]
loss: 0.004615  [32000/72302]
loss: 0.073906  [38400/72302]
loss: 0.010567  [44800/72302]
loss: 0.005299  [51200/72302]
loss: 0.000390  [57600/72302]
loss: 0.000783  [64000/72302]
loss: 0.004256  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.073556 

Epoch 42
-------------------------------
loss: 0.007007  [    0/72302]
loss: 0.008526  [ 6400/72302]
loss: 0.003157  [12800/72302]
loss: 0.000660  [19200/72302]
loss: 0.000538  [25600/72302]
loss: 0.079055  [32000/72302]
loss: 0.053555  [38400/72302]
loss: 0.000646  [44800/72302]
loss: 0.001659  [51200/72302]
loss: 0.077129  [57600/72302]
loss: 0.003949  [64000/72302]
loss: 0.000907  [70400/72302]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.050910 

Epoch 43
-------------------------------
loss: 0.003814  [    0/72302]
loss: 0.012350  [ 6400/72302]
loss: 0.000039  [12800/72302]
loss: 0.001116  [19200/72302]
loss: 0.080174  [25600/72302]
loss: 0.018121  [32000/72302]
loss: 0.001789  [38400/72302]
loss: 0.044147  [44800/72302]
loss: 0.004984  [51200/72302]
loss: 0.000184  [57600/72302]
loss: 0.075216  [64000/72302]
loss: 0.019408  [70400/72302]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.065497 

Epoch 44
-------------------------------
loss: 0.008731  [    0/72302]
loss: 0.004249  [ 6400/72302]
loss: 0.000698  [12800/72302]
loss: 0.011629  [19200/72302]
loss: 0.004912  [25600/72302]
loss: 0.009158  [32000/72302]
loss: 0.003973  [38400/72302]
loss: 0.061681  [44800/72302]
loss: 0.005284  [51200/72302]
loss: 0.056212  [57600/72302]
loss: 0.056835  [64000/72302]
loss: 0.009744  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.052658 

Epoch 45
-------------------------------
loss: 0.005314  [    0/72302]
loss: 0.002100  [ 6400/72302]
loss: 0.002650  [12800/72302]
loss: 0.000345  [19200/72302]
loss: 0.000787  [25600/72302]
loss: 0.003539  [32000/72302]
loss: 0.009040  [38400/72302]
loss: 0.002540  [44800/72302]
loss: 0.002975  [51200/72302]
loss: 0.029167  [57600/72302]
loss: 0.000372  [64000/72302]
loss: 0.072080  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.066573 

Epoch 46
-------------------------------
loss: 0.000615  [    0/72302]
loss: 0.004811  [ 6400/72302]
loss: 0.001771  [12800/72302]
loss: 0.041335  [19200/72302]
loss: 0.000593  [25600/72302]
loss: 0.002162  [32000/72302]
loss: 0.003630  [38400/72302]
loss: 0.017654  [44800/72302]
loss: 0.006920  [51200/72302]
loss: 0.017567  [57600/72302]
loss: 0.003696  [64000/72302]
loss: 0.016787  [70400/72302]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.141329 

Epoch 47
-------------------------------
loss: 0.011112  [    0/72302]
loss: 0.001282  [ 6400/72302]
loss: 0.004790  [12800/72302]
loss: 0.035367  [19200/72302]
loss: 0.030245  [25600/72302]
loss: 0.001167  [32000/72302]
loss: 0.011363  [38400/72302]
loss: 0.000789  [44800/72302]
loss: 0.003394  [51200/72302]
loss: 0.082463  [57600/72302]
loss: 0.001329  [64000/72302]
loss: 0.004783  [70400/72302]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.078561 

Epoch 48
-------------------------------
loss: 0.001193  [    0/72302]
loss: 0.006358  [ 6400/72302]
loss: 0.001239  [12800/72302]
loss: 0.004886  [19200/72302]
loss: 0.000859  [25600/72302]
loss: 0.000340  [32000/72302]
loss: 0.003106  [38400/72302]
loss: 0.008610  [44800/72302]
loss: 0.002088  [51200/72302]
loss: 0.002654  [57600/72302]
loss: 0.017425  [64000/72302]
loss: 0.000511  [70400/72302]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.057580 

Epoch 49
-------------------------------
loss: 0.000116  [    0/72302]
loss: 0.001596  [ 6400/72302]
loss: 0.023762  [12800/72302]
loss: 0.000857  [19200/72302]
loss: 0.002533  [25600/72302]
loss: 0.002422  [32000/72302]
loss: 0.006238  [38400/72302]
loss: 0.006139  [44800/72302]
loss: 0.007981  [51200/72302]
loss: 0.073257  [57600/72302]
loss: 0.001945  [64000/72302]
loss: 0.001927  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.062194 

Epoch 50
-------------------------------
loss: 0.003320  [    0/72302]
loss: 0.004523  [ 6400/72302]
loss: 0.002005  [12800/72302]
loss: 0.000065  [19200/72302]
loss: 0.045629  [25600/72302]
loss: 0.000707  [32000/72302]
loss: 0.007033  [38400/72302]
loss: 0.000728  [44800/72302]
loss: 0.015976  [51200/72302]
loss: 0.025900  [57600/72302]
loss: 0.000536  [64000/72302]
loss: 0.045139  [70400/72302]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.078433 

Epoch 1
-------------------------------
loss: 0.700790  [    0/71418]
loss: 0.168324  [ 6400/71418]
loss: 0.070864  [12800/71418]
loss: 0.037036  [19200/71418]
loss: 0.047664  [25600/71418]
loss: 0.062240  [32000/71418]
loss: 0.079814  [38400/71418]
loss: 0.135330  [44800/71418]
loss: 1.669327  [51200/71418]
loss: 0.065107  [57600/71418]
loss: 0.020482  [64000/71418]
loss: 0.044004  [70400/71418]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.096340 

Epoch 2
-------------------------------
loss: 0.052220  [    0/71418]
loss: 0.255865  [ 6400/71418]
loss: 0.041209  [12800/71418]
loss: 0.210537  [19200/71418]
loss: 0.064905  [25600/71418]
loss: 0.070223  [32000/71418]
loss: 0.006742  [38400/71418]
loss: 0.023634  [44800/71418]
loss: 0.051918  [51200/71418]
loss: 0.006335  [57600/71418]
loss: 0.048300  [64000/71418]
loss: 0.127222  [70400/71418]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084024 

Epoch 3
-------------------------------
loss: 0.032081  [    0/71418]
loss: 0.029324  [ 6400/71418]
loss: 0.057386  [12800/71418]
loss: 0.035714  [19200/71418]
loss: 0.031849  [25600/71418]
loss: 0.046052  [32000/71418]
loss: 0.051286  [38400/71418]
loss: 0.069948  [44800/71418]
loss: 0.130759  [51200/71418]
loss: 0.052726  [57600/71418]
loss: 0.081844  [64000/71418]
loss: 0.079832  [70400/71418]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.090987 

Epoch 4
-------------------------------
loss: 0.003461  [    0/71418]
loss: 0.028201  [ 6400/71418]
loss: 0.061337  [12800/71418]
loss: 0.028331  [19200/71418]
loss: 0.098468  [25600/71418]
loss: 0.146831  [32000/71418]
loss: 0.040786  [38400/71418]
loss: 0.041390  [44800/71418]
loss: 0.006919  [51200/71418]
loss: 0.014768  [57600/71418]
loss: 0.025432  [64000/71418]
loss: 0.035932  [70400/71418]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.079431 

Epoch 5
-------------------------------
loss: 0.026574  [    0/71418]
loss: 0.013410  [ 6400/71418]
loss: 0.012213  [ 6400/71724]
loss: 0.047842  [12800/71724]
loss: 0.026198  [19200/71724]
loss: 0.032914  [25600/71724]
loss: 0.133845  [32000/71724]
loss: 0.051902  [38400/71724]
loss: 0.018865  [44800/71724]
loss: 0.068890  [51200/71724]
loss: 0.025481  [57600/71724]
loss: 0.072468  [64000/71724]
loss: 0.014515  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076805 

Epoch 38
-------------------------------
loss: 0.006576  [    0/71724]
loss: 0.122091  [ 6400/71724]
loss: 0.036950  [12800/71724]
loss: 0.009473  [19200/71724]
loss: 0.016102  [25600/71724]
loss: 0.031464  [32000/71724]
loss: 0.100580  [38400/71724]
loss: 0.054131  [44800/71724]
loss: 0.015771  [51200/71724]
loss: 0.018740  [57600/71724]
loss: 0.018199  [64000/71724]
loss: 0.136362  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.076765 

Epoch 39
-------------------------------
loss: 0.002369  [    0/71724]
loss: 0.091548  [ 6400/71724]
loss: 0.012877  [12800/71724]
loss: 0.075199  [19200/71724]
loss: 0.071621  [25600/71724]
loss: 0.199032  [32000/71724]
loss: 0.010983  [38400/71724]
loss: 0.023425  [44800/71724]
loss: 0.013034  [51200/71724]
loss: 0.029985  [57600/71724]
loss: 0.013683  [64000/71724]
loss: 0.018973  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.077982 

Epoch 40
-------------------------------
loss: 0.034515  [    0/71724]
loss: 0.024273  [ 6400/71724]
loss: 0.003688  [12800/71724]
loss: 0.002204  [19200/71724]
loss: 0.200867  [25600/71724]
loss: 0.027366  [32000/71724]
loss: 0.051243  [38400/71724]
loss: 0.003228  [44800/71724]
loss: 0.010675  [51200/71724]
loss: 0.038117  [57600/71724]
loss: 0.027111  [64000/71724]
loss: 0.068317  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.075333 

Epoch 41
-------------------------------
loss: 0.081643  [    0/71724]
loss: 0.077046  [ 6400/71724]
loss: 0.055441  [12800/71724]
loss: 0.102172  [19200/71724]
loss: 0.043595  [25600/71724]
loss: 0.071483  [32000/71724]
loss: 0.019800  [38400/71724]
loss: 0.071409  [44800/71724]
loss: 0.016223  [51200/71724]
loss: 0.030311  [57600/71724]
loss: 0.127874  [64000/71724]
loss: 0.012307  [70400/71724]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.099061 

Epoch 42
-------------------------------
loss: 0.035621  [    0/71724]
loss: 0.006287  [ 6400/71724]
loss: 0.015128  [12800/71724]
loss: 0.003932  [19200/71724]
loss: 0.016948  [25600/71724]
loss: 0.016942  [32000/71724]
loss: 0.053651  [38400/71724]
loss: 0.012223  [44800/71724]
loss: 0.008037  [51200/71724]
loss: 0.017344  [57600/71724]
loss: 0.058607  [64000/71724]
loss: 0.075934  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.079185 

Epoch 43
-------------------------------
loss: 0.017509  [    0/71724]
loss: 0.010460  [ 6400/71724]
loss: 0.004828  [12800/71724]
loss: 0.017079  [19200/71724]
loss: 0.033602  [25600/71724]
loss: 0.056059  [32000/71724]
loss: 0.081425  [38400/71724]
loss: 0.005725  [44800/71724]
loss: 0.010681  [51200/71724]
loss: 0.148865  [57600/71724]
loss: 0.019407  [64000/71724]
loss: 0.012282  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.071524 

Epoch 44
-------------------------------
loss: 0.011898  [    0/71724]
loss: 0.035320  [ 6400/71724]
loss: 0.058235  [12800/71724]
loss: 0.065530  [19200/71724]
loss: 0.007062  [25600/71724]
loss: 0.010213  [32000/71724]
loss: 0.022472  [38400/71724]
loss: 0.013125  [44800/71724]
loss: 0.015814  [51200/71724]
loss: 0.030987  [57600/71724]
loss: 0.012154  [64000/71724]
loss: 0.031445  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.078607 

Epoch 45
-------------------------------
loss: 0.023826  [    0/71724]
loss: 0.023556  [ 6400/71724]
loss: 0.001970  [12800/71724]
loss: 0.015447  [19200/71724]
loss: 0.128564  [25600/71724]
loss: 0.002854  [32000/71724]
loss: 0.012545  [38400/71724]
loss: 0.113654  [44800/71724]
loss: 0.026791  [51200/71724]
loss: 0.018419  [57600/71724]
loss: 0.127878  [64000/71724]
loss: 0.031916  [70400/71724]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.082857 

Epoch 46
-------------------------------
loss: 0.020404  [    0/71724]
loss: 0.005217  [ 6400/71724]
loss: 0.024070  [12800/71724]
loss: 0.048970  [19200/71724]
loss: 0.003313  [25600/71724]
loss: 0.029980  [32000/71724]
loss: 0.101197  [38400/71724]
loss: 0.122679  [44800/71724]
loss: 0.015487  [51200/71724]
loss: 0.112938  [57600/71724]
loss: 0.056327  [64000/71724]
loss: 0.055806  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.086757 

Epoch 47
-------------------------------
loss: 0.045060  [    0/71724]
loss: 0.042940  [ 6400/71724]
loss: 0.133808  [12800/71724]
loss: 0.007967  [19200/71724]
loss: 0.018542  [25600/71724]
loss: 0.069900  [32000/71724]
loss: 0.017652  [38400/71724]
loss: 0.009982  [44800/71724]
loss: 0.038257  [51200/71724]
loss: 0.034470  [57600/71724]
loss: 0.041899  [64000/71724]
loss: 0.053263  [70400/71724]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.075950 

Epoch 48
-------------------------------
loss: 0.004413  [    0/71724]
loss: 0.063721  [ 6400/71724]
loss: 0.182052  [12800/71724]
loss: 0.119462  [19200/71724]
loss: 0.016395  [25600/71724]
loss: 0.002258  [32000/71724]
loss: 0.006048  [38400/71724]
loss: 0.047421  [44800/71724]
loss: 0.058938  [51200/71724]
loss: 0.024149  [57600/71724]
loss: 0.006402  [64000/71724]
loss: 0.157899  [70400/71724]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.087525 

Epoch 49
-------------------------------
loss: 0.016422  [    0/71724]
loss: 0.015216  [ 6400/71724]
loss: 0.013025  [12800/71724]
loss: 0.018315  [19200/71724]
loss: 0.083804  [25600/71724]
loss: 0.017815  [32000/71724]
loss: 0.059330  [38400/71724]
loss: 0.091321  [44800/71724]
loss: 0.039314  [51200/71724]
loss: 0.012891  [57600/71724]
loss: 0.004677  [64000/71724]
loss: 0.037310  [70400/71724]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.085683 

Epoch 50
-------------------------------
loss: 0.020468  [    0/71724]
loss: 0.032680  [ 6400/71724]
loss: 0.028485  [12800/71724]
loss: 0.002024  [19200/71724]
loss: 0.126575  [25600/71724]
loss: 0.066923  [32000/71724]
loss: 0.055414  [38400/71724]
loss: 0.049116  [44800/71724]
loss: 0.031561  [51200/71724]
loss: 0.060845  [57600/71724]
loss: 0.105379  [64000/71724]
loss: 0.078841  [70400/71724]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.080690 

Epoch 1
-------------------------------
loss: 0.748428  [    0/71130]
loss: 0.165468  [ 6400/71130]
loss: 0.060421  [12800/71130]
loss: 0.071292  [19200/71130]
loss: 0.119312  [25600/71130]
loss: 0.078783  [32000/71130]
loss: 0.099192  [38400/71130]
loss: 0.145475  [44800/71130]
loss: 0.126151  [51200/71130]
loss: 0.076689  [57600/71130]
loss: 0.030274  [64000/71130]
loss: 0.063380  [70400/71130]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074922 

Epoch 2
-------------------------------
loss: 0.078361  [    0/71130]
loss: 0.104249  [ 6400/71130]
loss: 0.048987  [12800/71130]
loss: 0.037479  [19200/71130]
loss: 0.027893  [25600/71130]
loss: 0.013359  [32000/71130]
loss: 0.055984  [38400/71130]
loss: 0.121676  [44800/71130]
loss: 0.100951  [51200/71130]
loss: 0.015802  [57600/71130]
loss: 0.039497  [64000/71130]
loss: 0.064089  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.062392 

Epoch 3
-------------------------------
loss: 0.025293  [    0/71130]
loss: 0.023676  [ 6400/71130]
loss: 0.094693  [12800/71130]
loss: 0.062685  [19200/71130]
loss: 0.036235  [25600/71130]
loss: 0.102046  [32000/71130]
loss: 0.089400  [38400/71130]
loss: 0.067062  [44800/71130]
loss: 0.130728  [51200/71130]
loss: 0.048531  [57600/71130]
loss: 0.011477  [64000/71130]
loss: 0.042401  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.064771 

Epoch 4
-------------------------------
loss: 0.029853  [    0/71130]
loss: 0.021146  [ 6400/71130]
loss: 0.031673  [12800/71130]
loss: 0.093780  [19200/71130]
loss: 0.086999  [25600/71130]
loss: 0.023613  [32000/71130]
loss: 0.040187  [38400/71130]
loss: 0.128734  [44800/71130]
loss: 0.029114  [51200/71130]
loss: 0.020668  [57600/71130]
loss: 0.030460  [64000/71130]
loss: 0.032743  [70400/71130]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.071352 

Epoch 5
-------------------------------
loss: 0.091624  [    0/71130]
loss: 0.115813  [ 6400/71130]
loss: 0.059312  [ 6400/70535]
loss: 0.046907  [12800/70535]
loss: 0.083036  [19200/70535]
loss: 0.211614  [25600/70535]
loss: 0.007626  [32000/70535]
loss: 0.060660  [38400/70535]
loss: 0.069054  [44800/70535]
loss: 0.052242  [51200/70535]
loss: 0.041596  [57600/70535]
loss: 0.044228  [64000/70535]
loss: 0.056563  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.243307 

Epoch 38
-------------------------------
loss: 0.131780  [    0/70535]
loss: 0.100680  [ 6400/70535]
loss: 0.066100  [12800/70535]
loss: 0.063576  [19200/70535]
loss: 0.034455  [25600/70535]
loss: 0.021957  [32000/70535]
loss: 0.046810  [38400/70535]
loss: 0.050126  [44800/70535]
loss: 0.083002  [51200/70535]
loss: 0.055452  [57600/70535]
loss: 0.210500  [64000/70535]
loss: 0.153704  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.117649 

Epoch 39
-------------------------------
loss: 0.136832  [    0/70535]
loss: 0.225062  [ 6400/70535]
loss: 0.090497  [12800/70535]
loss: 0.061157  [19200/70535]
loss: 0.067680  [25600/70535]
loss: 0.283444  [32000/70535]
loss: 0.132735  [38400/70535]
loss: 0.053157  [44800/70535]
loss: 0.099347  [51200/70535]
loss: 0.032966  [57600/70535]
loss: 0.048296  [64000/70535]
loss: 0.041810  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.116463 

Epoch 40
-------------------------------
loss: 0.134085  [    0/70535]
loss: 0.096343  [ 6400/70535]
loss: 0.081959  [12800/70535]
loss: 0.095048  [19200/70535]
loss: 0.161772  [25600/70535]
loss: 0.087634  [32000/70535]
loss: 0.141762  [38400/70535]
loss: 0.073031  [44800/70535]
loss: 0.053550  [51200/70535]
loss: 0.039912  [57600/70535]
loss: 0.112429  [64000/70535]
loss: 0.108231  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.119019 

Epoch 41
-------------------------------
loss: 0.038595  [    0/70535]
loss: 0.034657  [ 6400/70535]
loss: 0.089288  [12800/70535]
loss: 0.137614  [19200/70535]
loss: 0.054761  [25600/70535]
loss: 0.063668  [32000/70535]
loss: 0.043196  [38400/70535]
loss: 0.040980  [44800/70535]
loss: 0.078522  [51200/70535]
loss: 0.052877  [57600/70535]
loss: 0.120712  [64000/70535]
loss: 0.066003  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112275 

Epoch 42
-------------------------------
loss: 0.036583  [    0/70535]
loss: 0.169864  [ 6400/70535]
loss: 0.089468  [12800/70535]
loss: 0.171065  [19200/70535]
loss: 0.035175  [25600/70535]
loss: 0.072606  [32000/70535]
loss: 0.053694  [38400/70535]
loss: 0.034606  [44800/70535]
loss: 0.011367  [51200/70535]
loss: 0.161369  [57600/70535]
loss: 0.038246  [64000/70535]
loss: 0.110402  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.112808 

Epoch 43
-------------------------------
loss: 0.056109  [    0/70535]
loss: 0.037831  [ 6400/70535]
loss: 0.069119  [12800/70535]
loss: 0.035527  [19200/70535]
loss: 0.061715  [25600/70535]
loss: 0.054314  [32000/70535]
loss: 0.080378  [38400/70535]
loss: 0.180393  [44800/70535]
loss: 0.097283  [51200/70535]
loss: 0.095026  [57600/70535]
loss: 0.165854  [64000/70535]
loss: 0.125101  [70400/70535]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.147602 

Epoch 44
-------------------------------
loss: 0.053091  [    0/70535]
loss: 0.050996  [ 6400/70535]
loss: 0.047624  [12800/70535]
loss: 0.045134  [19200/70535]
loss: 0.190028  [25600/70535]
loss: 0.115290  [32000/70535]
loss: 0.059055  [38400/70535]
loss: 0.015563  [44800/70535]
loss: 0.091754  [51200/70535]
loss: 0.022285  [57600/70535]
loss: 0.095179  [64000/70535]
loss: 0.068847  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.114856 

Epoch 45
-------------------------------
loss: 0.048704  [    0/70535]
loss: 0.081138  [ 6400/70535]
loss: 0.216211  [12800/70535]
loss: 0.072617  [19200/70535]
loss: 0.057236  [25600/70535]
loss: 0.121167  [32000/70535]
loss: 0.051646  [38400/70535]
loss: 0.052725  [44800/70535]
loss: 0.203742  [51200/70535]
loss: 0.052644  [57600/70535]
loss: 0.086697  [64000/70535]
loss: 0.039664  [70400/70535]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.148699 

Epoch 46
-------------------------------
loss: 0.042050  [    0/70535]
loss: 0.039400  [ 6400/70535]
loss: 0.102779  [12800/70535]
loss: 0.059211  [19200/70535]
loss: 0.247790  [25600/70535]
loss: 0.022343  [32000/70535]
loss: 0.030938  [38400/70535]
loss: 0.023406  [44800/70535]
loss: 0.101451  [51200/70535]
loss: 0.041688  [57600/70535]
loss: 0.054603  [64000/70535]
loss: 0.094673  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.121268 

Epoch 47
-------------------------------
loss: 0.036829  [    0/70535]
loss: 0.048058  [ 6400/70535]
loss: 0.101668  [12800/70535]
loss: 0.079574  [19200/70535]
loss: 0.078621  [25600/70535]
loss: 0.031779  [32000/70535]
loss: 0.133310  [38400/70535]
loss: 0.034663  [44800/70535]
loss: 0.147554  [51200/70535]
loss: 0.055158  [57600/70535]
loss: 0.151236  [64000/70535]
loss: 0.121209  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.115808 

Epoch 48
-------------------------------
loss: 0.115552  [    0/70535]
loss: 0.127757  [ 6400/70535]
loss: 0.201122  [12800/70535]
loss: 0.101465  [19200/70535]
loss: 0.075795  [25600/70535]
loss: 0.028934  [32000/70535]
loss: 0.069852  [38400/70535]
loss: 0.054257  [44800/70535]
loss: 0.126313  [51200/70535]
loss: 0.078593  [57600/70535]
loss: 0.061999  [64000/70535]
loss: 0.145283  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117456 

Epoch 49
-------------------------------
loss: 0.054537  [    0/70535]
loss: 0.058373  [ 6400/70535]
loss: 1.719037  [12800/70535]
loss: 0.072136  [19200/70535]
loss: 0.093858  [25600/70535]
loss: 0.055320  [32000/70535]
loss: 0.104117  [38400/70535]
loss: 0.143657  [44800/70535]
loss: 0.220748  [51200/70535]
loss: 0.165407  [57600/70535]
loss: 0.054853  [64000/70535]
loss: 0.050749  [70400/70535]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.126699 

Epoch 50
-------------------------------
loss: 0.037846  [    0/70535]
loss: 0.007252  [ 6400/70535]
loss: 0.123595  [12800/70535]
loss: 0.080558  [19200/70535]
loss: 0.118608  [25600/70535]
loss: 0.107451  [32000/70535]
loss: 0.113927  [38400/70535]
loss: 0.122604  [44800/70535]
loss: 0.076560  [51200/70535]
loss: 0.035456  [57600/70535]
loss: 0.040463  [64000/70535]
loss: 0.105337  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.119738 

Epoch 1
-------------------------------
loss: 0.747445  [    0/70755]
loss: 0.249252  [ 6400/70755]
loss: 0.288921  [12800/70755]
loss: 0.212083  [19200/70755]
loss: 0.201898  [25600/70755]
loss: 0.181726  [32000/70755]
loss: 0.296854  [38400/70755]
loss: 0.130163  [44800/70755]
loss: 0.239250  [51200/70755]
loss: 0.206626  [57600/70755]
loss: 0.201292  [64000/70755]
loss: 0.122157  [70400/70755]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.176547 

Epoch 2
-------------------------------
loss: 0.090868  [    0/70755]
loss: 0.292029  [ 6400/70755]
loss: 0.085816  [12800/70755]
loss: 0.194615  [19200/70755]
loss: 0.236563  [25600/70755]
loss: 0.231102  [32000/70755]
loss: 0.203600  [38400/70755]
loss: 0.180168  [44800/70755]
loss: 0.224066  [51200/70755]
loss: 0.036149  [57600/70755]
loss: 0.173451  [64000/70755]
loss: 0.149921  [70400/70755]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.159440 

Epoch 3
-------------------------------
loss: 0.120688  [    0/70755]
loss: 0.166407  [ 6400/70755]
loss: 0.156621  [12800/70755]
loss: 0.300643  [19200/70755]
loss: 0.279679  [25600/70755]
loss: 0.170080  [32000/70755]
loss: 0.127471  [38400/70755]
loss: 0.147308  [44800/70755]
loss: 0.271272  [51200/70755]
loss: 0.201179  [57600/70755]
loss: 0.187478  [64000/70755]
loss: 0.178816  [70400/70755]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.147079 

Epoch 4
-------------------------------
loss: 0.183205  [    0/70755]
loss: 0.091711  [ 6400/70755]
loss: 0.205688  [12800/70755]
loss: 0.174754  [19200/70755]
loss: 0.135797  [25600/70755]
loss: 0.184274  [32000/70755]
loss: 0.261235  [38400/70755]
loss: 0.149094  [44800/70755]
loss: 0.112011  [51200/70755]
loss: 0.289437  [57600/70755]
loss: 0.108756  [64000/70755]
loss: 0.182219  [70400/70755]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.153687 

Epoch 5
-------------------------------
loss: 0.129792  [    0/70755]
loss: 0.100492  [ 6400/70755]
loss: 0.022023  [ 6400/72202]
loss: 0.061000  [12800/72202]
loss: 0.000909  [19200/72202]
loss: 0.040472  [25600/72202]
loss: 0.036208  [32000/72202]
loss: 0.042394  [38400/72202]
loss: 0.049248  [44800/72202]
loss: 0.018984  [51200/72202]
loss: 0.010133  [57600/72202]
loss: 0.006034  [64000/72202]
loss: 0.002682  [70400/72202]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.095041 

Epoch 38
-------------------------------
loss: 0.005087  [    0/72202]
loss: 0.021286  [ 6400/72202]
loss: 0.001172  [12800/72202]
loss: 0.045394  [19200/72202]
loss: 0.013279  [25600/72202]
loss: 0.028434  [32000/72202]
loss: 0.004601  [38400/72202]
loss: 0.005880  [44800/72202]
loss: 0.001670  [51200/72202]
loss: 0.016589  [57600/72202]
loss: 0.001854  [64000/72202]
loss: 0.016432  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.087283 

Epoch 39
-------------------------------
loss: 0.001286  [    0/72202]
loss: 0.012706  [ 6400/72202]
loss: 0.056629  [12800/72202]
loss: 0.005662  [19200/72202]
loss: 0.006117  [25600/72202]
loss: 0.005172  [32000/72202]
loss: 0.041118  [38400/72202]
loss: 0.132038  [44800/72202]
loss: 0.021095  [51200/72202]
loss: 0.010145  [57600/72202]
loss: 0.103915  [64000/72202]
loss: 0.004795  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.088305 

Epoch 40
-------------------------------
loss: 0.008028  [    0/72202]
loss: 0.000997  [ 6400/72202]
loss: 0.004760  [12800/72202]
loss: 0.044154  [19200/72202]
loss: 0.074107  [25600/72202]
loss: 0.006500  [32000/72202]
loss: 0.031158  [38400/72202]
loss: 0.002658  [44800/72202]
loss: 0.031620  [51200/72202]
loss: 0.007124  [57600/72202]
loss: 0.002762  [64000/72202]
loss: 0.022035  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.089207 

Epoch 41
-------------------------------
loss: 0.030757  [    0/72202]
loss: 0.011172  [ 6400/72202]
loss: 0.002038  [12800/72202]
loss: 0.044912  [19200/72202]
loss: 0.018132  [25600/72202]
loss: 0.007973  [32000/72202]
loss: 0.003796  [38400/72202]
loss: 0.020637  [44800/72202]
loss: 0.006507  [51200/72202]
loss: 0.009190  [57600/72202]
loss: 0.028599  [64000/72202]
loss: 0.001233  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.085860 

Epoch 42
-------------------------------
loss: 0.019198  [    0/72202]
loss: 0.003705  [ 6400/72202]
loss: 0.031000  [12800/72202]
loss: 0.008916  [19200/72202]
loss: 0.002481  [25600/72202]
loss: 0.062929  [32000/72202]
loss: 0.031784  [38400/72202]
loss: 0.017713  [44800/72202]
loss: 0.056632  [51200/72202]
loss: 0.146240  [57600/72202]
loss: 0.022989  [64000/72202]
loss: 0.012092  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.085757 

Epoch 43
-------------------------------
loss: 0.008081  [    0/72202]
loss: 0.000692  [ 6400/72202]
loss: 0.013999  [12800/72202]
loss: 0.007505  [19200/72202]
loss: 0.002903  [25600/72202]
loss: 0.028953  [32000/72202]
loss: 0.004212  [38400/72202]
loss: 0.001728  [44800/72202]
loss: 0.031835  [51200/72202]
loss: 0.002374  [57600/72202]
loss: 0.128168  [64000/72202]
loss: 0.075699  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.100017 

Epoch 44
-------------------------------
loss: 0.006271  [    0/72202]
loss: 0.006234  [ 6400/72202]
loss: 0.007988  [12800/72202]
loss: 0.006250  [19200/72202]
loss: 0.012335  [25600/72202]
loss: 0.002217  [32000/72202]
loss: 0.034731  [38400/72202]
loss: 0.001647  [44800/72202]
loss: 0.020470  [51200/72202]
loss: 0.058290  [57600/72202]
loss: 0.057301  [64000/72202]
loss: 0.006346  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.091646 

Epoch 45
-------------------------------
loss: 0.001731  [    0/72202]
loss: 0.012289  [ 6400/72202]
loss: 0.004148  [12800/72202]
loss: 0.020385  [19200/72202]
loss: 1.570397  [25600/72202]
loss: 0.005594  [32000/72202]
loss: 0.004917  [38400/72202]
loss: 0.005701  [44800/72202]
loss: 0.026599  [51200/72202]
loss: 0.023603  [57600/72202]
loss: 0.035736  [64000/72202]
loss: 0.042899  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.098848 

Epoch 46
-------------------------------
loss: 0.001506  [    0/72202]
loss: 0.048126  [ 6400/72202]
loss: 0.026826  [12800/72202]
loss: 0.008357  [19200/72202]
loss: 0.007775  [25600/72202]
loss: 0.143909  [32000/72202]
loss: 0.092762  [38400/72202]
loss: 0.003294  [44800/72202]
loss: 0.041823  [51200/72202]
loss: 0.012540  [57600/72202]
loss: 0.042193  [64000/72202]
loss: 0.009862  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.103007 

Epoch 47
-------------------------------
loss: 0.003681  [    0/72202]
loss: 0.057864  [ 6400/72202]
loss: 0.038703  [12800/72202]
loss: 0.063701  [19200/72202]
loss: 0.009063  [25600/72202]
loss: 0.004291  [32000/72202]
loss: 0.011751  [38400/72202]
loss: 0.051328  [44800/72202]
loss: 0.085165  [51200/72202]
loss: 0.000931  [57600/72202]
loss: 0.015549  [64000/72202]
loss: 0.002798  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.093492 

Epoch 48
-------------------------------
loss: 0.044837  [    0/72202]
loss: 0.008180  [ 6400/72202]
loss: 0.027233  [12800/72202]
loss: 0.103692  [19200/72202]
loss: 0.000825  [25600/72202]
loss: 0.003150  [32000/72202]
loss: 0.028031  [38400/72202]
loss: 0.004210  [44800/72202]
loss: 0.076372  [51200/72202]
loss: 0.004250  [57600/72202]
loss: 0.014412  [64000/72202]
loss: 0.010313  [70400/72202]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.090444 

Epoch 49
-------------------------------
loss: 0.002922  [    0/72202]
loss: 0.010817  [ 6400/72202]
loss: 0.005835  [12800/72202]
loss: 0.003320  [19200/72202]
loss: 0.063548  [25600/72202]
loss: 0.006044  [32000/72202]
loss: 0.041268  [38400/72202]
loss: 0.003909  [44800/72202]
loss: 0.186433  [51200/72202]
loss: 0.000598  [57600/72202]
loss: 0.076508  [64000/72202]
loss: 0.007223  [70400/72202]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.111363 

Epoch 50
-------------------------------
loss: 0.038109  [    0/72202]
loss: 0.043318  [ 6400/72202]
loss: 0.004936  [12800/72202]
loss: 0.000786  [19200/72202]
loss: 0.092120  [25600/72202]
loss: 0.002213  [32000/72202]
loss: 0.007212  [38400/72202]
loss: 0.001321  [44800/72202]
loss: 0.024357  [51200/72202]
loss: 0.000436  [57600/72202]
loss: 0.006401  [64000/72202]
loss: 0.049041  [70400/72202]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.096994 

Epoch 1
-------------------------------
loss: 0.727886  [    0/70506]
loss: 0.249652  [ 6400/70506]
loss: 0.087308  [12800/70506]
loss: 0.035632  [19200/70506]
loss: 0.030815  [25600/70506]
loss: 0.056722  [32000/70506]
loss: 0.160325  [38400/70506]
loss: 0.029212  [44800/70506]
loss: 0.089125  [51200/70506]
loss: 0.115223  [57600/70506]
loss: 0.035448  [64000/70506]
loss: 0.080015  [70400/70506]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.064715 

Epoch 2
-------------------------------
loss: 0.121628  [    0/70506]
loss: 0.060615  [ 6400/70506]
loss: 0.177957  [12800/70506]
loss: 0.102666  [19200/70506]
loss: 0.010347  [25600/70506]
loss: 0.073771  [32000/70506]
loss: 0.022536  [38400/70506]
loss: 0.037380  [44800/70506]
loss: 0.036711  [51200/70506]
loss: 0.025165  [57600/70506]
loss: 0.098124  [64000/70506]
loss: 0.032514  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.053320 

Epoch 3
-------------------------------
loss: 0.012513  [    0/70506]
loss: 0.047290  [ 6400/70506]
loss: 0.045790  [12800/70506]
loss: 0.022701  [19200/70506]
loss: 0.034529  [25600/70506]
loss: 0.015962  [32000/70506]
loss: 0.070491  [38400/70506]
loss: 0.063691  [44800/70506]
loss: 0.029986  [51200/70506]
loss: 0.013227  [57600/70506]
loss: 0.240767  [64000/70506]
loss: 0.061530  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.050041 

Epoch 4
-------------------------------
loss: 0.026224  [    0/70506]
loss: 0.041315  [ 6400/70506]
loss: 0.068317  [12800/70506]
loss: 0.090769  [19200/70506]
loss: 0.030470  [25600/70506]
loss: 0.151851  [32000/70506]
loss: 0.019388  [38400/70506]
loss: 0.048419  [44800/70506]
loss: 0.064412  [51200/70506]
loss: 0.031171  [57600/70506]
loss: 0.042882  [64000/70506]
loss: 0.027583  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.054356 

Epoch 5
-------------------------------
loss: 0.019718  [    0/70506]
loss: 0.107620  [ 6400/70506]
loss: 0.069931  [ 6400/71124]
loss: 0.006502  [12800/71124]
loss: 0.218432  [19200/71124]
loss: 0.043494  [25600/71124]
loss: 0.085182  [32000/71124]
loss: 0.107931  [38400/71124]
loss: 0.093154  [44800/71124]
loss: 0.153205  [51200/71124]
loss: 0.073264  [57600/71124]
loss: 0.037575  [64000/71124]
loss: 0.025370  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.139915 

Epoch 38
-------------------------------
loss: 0.033342  [    0/71124]
loss: 0.058856  [ 6400/71124]
loss: 0.030061  [12800/71124]
loss: 0.077940  [19200/71124]
loss: 0.076869  [25600/71124]
loss: 3.232569  [32000/71124]
loss: 0.123185  [38400/71124]
loss: 0.018902  [44800/71124]
loss: 0.028731  [51200/71124]
loss: 0.079179  [57600/71124]
loss: 0.053021  [64000/71124]
loss: 0.080351  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.139352 

Epoch 39
-------------------------------
loss: 0.036269  [    0/71124]
loss: 0.076394  [ 6400/71124]
loss: 0.113158  [12800/71124]
loss: 0.050791  [19200/71124]
loss: 1.603466  [25600/71124]
loss: 0.168041  [32000/71124]
loss: 3.228801  [38400/71124]
loss: 0.129934  [44800/71124]
loss: 0.088807  [51200/71124]
loss: 0.040032  [57600/71124]
loss: 0.058726  [64000/71124]
loss: 0.120344  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.136713 

Epoch 40
-------------------------------
loss: 0.037681  [    0/71124]
loss: 0.076577  [ 6400/71124]
loss: 0.029427  [12800/71124]
loss: 0.039115  [19200/71124]
loss: 0.207371  [25600/71124]
loss: 0.048111  [32000/71124]
loss: 0.055708  [38400/71124]
loss: 1.677714  [44800/71124]
loss: 0.049284  [51200/71124]
loss: 0.096355  [57600/71124]
loss: 0.043831  [64000/71124]
loss: 0.072804  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.141685 

Epoch 41
-------------------------------
loss: 0.053858  [    0/71124]
loss: 0.058389  [ 6400/71124]
loss: 0.048961  [12800/71124]
loss: 1.622214  [19200/71124]
loss: 0.065476  [25600/71124]
loss: 0.077081  [32000/71124]
loss: 0.053902  [38400/71124]
loss: 1.624572  [44800/71124]
loss: 0.025673  [51200/71124]
loss: 0.150072  [57600/71124]
loss: 0.059356  [64000/71124]
loss: 0.073906  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.140105 

Epoch 42
-------------------------------
loss: 0.034071  [    0/71124]
loss: 0.059015  [ 6400/71124]
loss: 0.061970  [12800/71124]
loss: 0.144858  [19200/71124]
loss: 0.032024  [25600/71124]
loss: 0.039157  [32000/71124]
loss: 0.032967  [38400/71124]
loss: 0.045846  [44800/71124]
loss: 0.132854  [51200/71124]
loss: 0.061945  [57600/71124]
loss: 1.592146  [64000/71124]
loss: 0.044531  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.139943 

Epoch 43
-------------------------------
loss: 0.069427  [    0/71124]
loss: 0.089480  [ 6400/71124]
loss: 0.058199  [12800/71124]
loss: 1.583704  [19200/71124]
loss: 0.071243  [25600/71124]
loss: 0.081434  [32000/71124]
loss: 1.644081  [38400/71124]
loss: 0.067604  [44800/71124]
loss: 0.056558  [51200/71124]
loss: 0.082327  [57600/71124]
loss: 0.036102  [64000/71124]
loss: 0.050919  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.140534 

Epoch 44
-------------------------------
loss: 0.081588  [    0/71124]
loss: 0.102159  [ 6400/71124]
loss: 0.083517  [12800/71124]
loss: 0.067391  [19200/71124]
loss: 0.088674  [25600/71124]
loss: 0.030156  [32000/71124]
loss: 0.073948  [38400/71124]
loss: 0.030901  [44800/71124]
loss: 0.050329  [51200/71124]
loss: 0.059546  [57600/71124]
loss: 1.618959  [64000/71124]
loss: 0.033034  [70400/71124]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.142296 

Epoch 45
-------------------------------
loss: 0.054638  [    0/71124]
loss: 0.065190  [ 6400/71124]
loss: 0.054900  [12800/71124]
loss: 0.077003  [19200/71124]
loss: 0.114167  [25600/71124]
loss: 0.047415  [32000/71124]
loss: 0.046921  [38400/71124]
loss: 0.106419  [44800/71124]
loss: 0.132839  [51200/71124]
loss: 0.048364  [57600/71124]
loss: 0.042179  [64000/71124]
loss: 0.075975  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.148208 

Epoch 46
-------------------------------
loss: 0.079776  [    0/71124]
loss: 0.205856  [ 6400/71124]
loss: 0.178374  [12800/71124]
loss: 0.050926  [19200/71124]
loss: 0.024075  [25600/71124]
loss: 0.049469  [32000/71124]
loss: 0.020251  [38400/71124]
loss: 0.045055  [44800/71124]
loss: 0.138407  [51200/71124]
loss: 0.038476  [57600/71124]
loss: 0.094673  [64000/71124]
loss: 0.153298  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.145561 

Epoch 47
-------------------------------
loss: 0.029064  [    0/71124]
loss: 0.045090  [ 6400/71124]
loss: 0.082374  [12800/71124]
loss: 0.050306  [19200/71124]
loss: 0.036469  [25600/71124]
loss: 0.087356  [32000/71124]
loss: 0.088341  [38400/71124]
loss: 0.033859  [44800/71124]
loss: 0.117323  [51200/71124]
loss: 0.092047  [57600/71124]
loss: 0.145678  [64000/71124]
loss: 0.047039  [70400/71124]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.139358 

Epoch 48
-------------------------------
loss: 0.081179  [    0/71124]
loss: 0.126181  [ 6400/71124]
loss: 1.604423  [12800/71124]
loss: 0.078546  [19200/71124]
loss: 0.049527  [25600/71124]
loss: 0.226830  [32000/71124]
loss: 0.039133  [38400/71124]
loss: 0.045090  [44800/71124]
loss: 0.064831  [51200/71124]
loss: 0.060068  [57600/71124]
loss: 0.075871  [64000/71124]
loss: 0.046710  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.146269 

Epoch 49
-------------------------------
loss: 0.165501  [    0/71124]
loss: 0.129336  [ 6400/71124]
loss: 0.055313  [12800/71124]
loss: 0.039494  [19200/71124]
loss: 0.068978  [25600/71124]
loss: 0.149340  [32000/71124]
loss: 0.027095  [38400/71124]
loss: 0.035168  [44800/71124]
loss: 0.062329  [51200/71124]
loss: 0.062593  [57600/71124]
loss: 1.629190  [64000/71124]
loss: 0.057324  [70400/71124]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.141435 

Epoch 50
-------------------------------
loss: 0.070641  [    0/71124]
loss: 0.040146  [ 6400/71124]
loss: 0.031400  [12800/71124]
loss: 0.038556  [19200/71124]
loss: 0.073360  [25600/71124]
loss: 0.044702  [32000/71124]
loss: 0.053457  [38400/71124]
loss: 0.029509  [44800/71124]
loss: 1.582082  [51200/71124]
loss: 0.065628  [57600/71124]
loss: 0.034515  [64000/71124]
loss: 0.082411  [70400/71124]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.143784 

Epoch 1
-------------------------------
loss: 0.780645  [    0/71194]
loss: 0.273600  [ 6400/71194]
loss: 0.174257  [12800/71194]
loss: 0.125092  [19200/71194]
loss: 0.201176  [25600/71194]
loss: 0.105712  [32000/71194]
loss: 0.257944  [38400/71194]
loss: 0.167229  [44800/71194]
loss: 0.097681  [51200/71194]
loss: 1.618428  [57600/71194]
loss: 0.113136  [64000/71194]
loss: 0.104921  [70400/71194]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.134047 

Epoch 2
-------------------------------
loss: 0.123880  [    0/71194]
loss: 0.075478  [ 6400/71194]
loss: 0.199954  [12800/71194]
loss: 0.075584  [19200/71194]
loss: 0.162714  [25600/71194]
loss: 0.089008  [32000/71194]
loss: 0.058153  [38400/71194]
loss: 0.131428  [44800/71194]
loss: 0.044181  [51200/71194]
loss: 0.043892  [57600/71194]
loss: 0.077776  [64000/71194]
loss: 0.171474  [70400/71194]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.124395 

Epoch 3
-------------------------------
loss: 0.126737  [    0/71194]
loss: 0.136308  [ 6400/71194]
loss: 0.047787  [12800/71194]
loss: 0.127672  [19200/71194]
loss: 0.055471  [25600/71194]
loss: 0.080052  [32000/71194]
loss: 0.064000  [38400/71194]
loss: 0.073412  [44800/71194]
loss: 0.079096  [51200/71194]
loss: 0.163838  [57600/71194]
loss: 0.089690  [64000/71194]
loss: 0.070002  [70400/71194]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.123272 

Epoch 4
-------------------------------
loss: 1.623502  [    0/71194]
loss: 0.200817  [ 6400/71194]
loss: 0.086682  [12800/71194]
loss: 0.056439  [19200/71194]
loss: 0.040719  [25600/71194]
loss: 0.037855  [32000/71194]
loss: 0.129773  [38400/71194]
loss: 0.052117  [44800/71194]
loss: 0.072414  [51200/71194]
loss: 0.131366  [57600/71194]
loss: 0.093735  [64000/71194]
loss: 0.018087  [70400/71194]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112023 

Epoch 5
-------------------------------
loss: 0.104099  [    0/71194]
loss: 0.121757  [ 6400/71194]
loss: 0.025034  [ 6400/71297]
loss: 0.017863  [12800/71297]
loss: 0.004192  [19200/71297]
loss: 0.007289  [25600/71297]
loss: 0.134524  [32000/71297]
loss: 0.009588  [38400/71297]
loss: 0.155617  [44800/71297]
loss: 0.017003  [51200/71297]
loss: 0.082257  [57600/71297]
loss: 0.070274  [64000/71297]
loss: 0.078028  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.091449 

Epoch 38
-------------------------------
loss: 0.092063  [    0/71297]
loss: 0.017603  [ 6400/71297]
loss: 0.092773  [12800/71297]
loss: 0.072540  [19200/71297]
loss: 0.084341  [25600/71297]
loss: 0.009484  [32000/71297]
loss: 0.081476  [38400/71297]
loss: 0.017944  [44800/71297]
loss: 0.012788  [51200/71297]
loss: 0.040221  [57600/71297]
loss: 0.015774  [64000/71297]
loss: 0.025063  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.088632 

Epoch 39
-------------------------------
loss: 0.047268  [    0/71297]
loss: 0.108713  [ 6400/71297]
loss: 0.050040  [12800/71297]
loss: 0.052338  [19200/71297]
loss: 0.013008  [25600/71297]
loss: 0.038373  [32000/71297]
loss: 0.050119  [38400/71297]
loss: 0.003649  [44800/71297]
loss: 0.035984  [51200/71297]
loss: 0.096047  [57600/71297]
loss: 0.012888  [64000/71297]
loss: 0.010267  [70400/71297]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.086316 

Epoch 40
-------------------------------
loss: 0.065215  [    0/71297]
loss: 0.039673  [ 6400/71297]
loss: 0.032821  [12800/71297]
loss: 0.006293  [19200/71297]
loss: 0.067195  [25600/71297]
loss: 0.024004  [32000/71297]
loss: 0.045264  [38400/71297]
loss: 0.010831  [44800/71297]
loss: 0.084976  [51200/71297]
loss: 0.003765  [57600/71297]
loss: 0.023012  [64000/71297]
loss: 0.049258  [70400/71297]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.095005 

Epoch 41
-------------------------------
loss: 0.073453  [    0/71297]
loss: 0.105201  [ 6400/71297]
loss: 0.059324  [12800/71297]
loss: 0.009461  [19200/71297]
loss: 0.043850  [25600/71297]
loss: 0.047100  [32000/71297]
loss: 0.046379  [38400/71297]
loss: 0.079781  [44800/71297]
loss: 0.052707  [51200/71297]
loss: 0.008462  [57600/71297]
loss: 0.024463  [64000/71297]
loss: 0.062931  [70400/71297]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.090513 

Epoch 42
-------------------------------
loss: 0.008371  [    0/71297]
loss: 0.011234  [ 6400/71297]
loss: 0.017963  [12800/71297]
loss: 0.032908  [19200/71297]
loss: 0.016222  [25600/71297]
loss: 0.145804  [32000/71297]
loss: 0.049377  [38400/71297]
loss: 0.031298  [44800/71297]
loss: 0.062834  [51200/71297]
loss: 0.015269  [57600/71297]
loss: 0.079902  [64000/71297]
loss: 0.040174  [70400/71297]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.087650 

Epoch 43
-------------------------------
loss: 0.011711  [    0/71297]
loss: 0.023933  [ 6400/71297]
loss: 0.064422  [12800/71297]
loss: 0.052198  [19200/71297]
loss: 0.129497  [25600/71297]
loss: 0.062647  [32000/71297]
loss: 0.013053  [38400/71297]
loss: 0.006507  [44800/71297]
loss: 0.029852  [51200/71297]
loss: 0.015101  [57600/71297]
loss: 0.071543  [64000/71297]
loss: 0.033847  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.092466 

Epoch 44
-------------------------------
loss: 0.040043  [    0/71297]
loss: 0.010710  [ 6400/71297]
loss: 0.032962  [12800/71297]
loss: 0.040613  [19200/71297]
loss: 0.008905  [25600/71297]
loss: 0.027003  [32000/71297]
loss: 0.161573  [38400/71297]
loss: 0.067507  [44800/71297]
loss: 0.029883  [51200/71297]
loss: 0.041890  [57600/71297]
loss: 0.090286  [64000/71297]
loss: 0.164660  [70400/71297]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.106636 

Epoch 45
-------------------------------
loss: 0.030738  [    0/71297]
loss: 0.058332  [ 6400/71297]
loss: 0.029426  [12800/71297]
loss: 0.033438  [19200/71297]
loss: 0.003254  [25600/71297]
loss: 0.042256  [32000/71297]
loss: 0.048189  [38400/71297]
loss: 0.061515  [44800/71297]
loss: 0.034049  [51200/71297]
loss: 0.031832  [57600/71297]
loss: 0.245500  [64000/71297]
loss: 0.085144  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.090898 

Epoch 46
-------------------------------
loss: 0.034007  [    0/71297]
loss: 0.037827  [ 6400/71297]
loss: 0.017660  [12800/71297]
loss: 0.056706  [19200/71297]
loss: 0.026212  [25600/71297]
loss: 0.077923  [32000/71297]
loss: 0.161775  [38400/71297]
loss: 0.025297  [44800/71297]
loss: 0.025562  [51200/71297]
loss: 0.030424  [57600/71297]
loss: 0.011338  [64000/71297]
loss: 0.124699  [70400/71297]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.109558 

Epoch 47
-------------------------------
loss: 0.084538  [    0/71297]
loss: 0.047092  [ 6400/71297]
loss: 0.157823  [12800/71297]
loss: 0.032508  [19200/71297]
loss: 0.027818  [25600/71297]
loss: 0.057879  [32000/71297]
loss: 0.013778  [38400/71297]
loss: 0.007353  [44800/71297]
loss: 0.113735  [51200/71297]
loss: 0.121369  [57600/71297]
loss: 0.014297  [64000/71297]
loss: 0.029717  [70400/71297]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.086451 

Epoch 48
-------------------------------
loss: 0.065416  [    0/71297]
loss: 0.064079  [ 6400/71297]
loss: 0.005019  [12800/71297]
loss: 0.009621  [19200/71297]
loss: 0.011725  [25600/71297]
loss: 0.030743  [32000/71297]
loss: 0.024148  [38400/71297]
loss: 0.015624  [44800/71297]
loss: 0.146890  [51200/71297]
loss: 0.101948  [57600/71297]
loss: 1.727260  [64000/71297]
loss: 0.078466  [70400/71297]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.089960 

Epoch 49
-------------------------------
loss: 0.010662  [    0/71297]
loss: 0.016224  [ 6400/71297]
loss: 0.046466  [12800/71297]
loss: 0.046579  [19200/71297]
loss: 0.033330  [25600/71297]
loss: 0.084406  [32000/71297]
loss: 0.015123  [38400/71297]
loss: 0.029459  [44800/71297]
loss: 0.014626  [51200/71297]
loss: 0.005063  [57600/71297]
loss: 0.054611  [64000/71297]
loss: 0.077996  [70400/71297]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.109771 

Epoch 50
-------------------------------
loss: 0.012745  [    0/71297]
loss: 0.088950  [ 6400/71297]
loss: 0.033940  [12800/71297]
loss: 0.020650  [19200/71297]
loss: 0.011430  [25600/71297]
loss: 0.006573  [32000/71297]
loss: 0.085466  [38400/71297]
loss: 0.036876  [44800/71297]
loss: 0.036949  [51200/71297]
loss: 0.081559  [57600/71297]
loss: 0.072134  [64000/71297]
loss: 0.044725  [70400/71297]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.091570 

Epoch 1
-------------------------------
loss: 0.744193  [    0/70644]
loss: 0.093221  [ 6400/70644]
loss: 0.175706  [12800/70644]
loss: 0.118578  [19200/70644]
loss: 0.069412  [25600/70644]
loss: 0.142281  [32000/70644]
loss: 0.147852  [38400/70644]
loss: 0.152538  [44800/70644]
loss: 0.083792  [51200/70644]
loss: 0.115484  [57600/70644]
loss: 0.105031  [64000/70644]
loss: 0.108640  [70400/70644]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.102154 

Epoch 2
-------------------------------
loss: 0.030373  [    0/70644]
loss: 0.131291  [ 6400/70644]
loss: 0.143320  [12800/70644]
loss: 0.153459  [19200/70644]
loss: 0.050556  [25600/70644]
loss: 0.053181  [32000/70644]
loss: 0.080073  [38400/70644]
loss: 0.068861  [44800/70644]
loss: 0.066030  [51200/70644]
loss: 0.119173  [57600/70644]
loss: 0.207391  [64000/70644]
loss: 0.167590  [70400/70644]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088312 

Epoch 3
-------------------------------
loss: 0.111748  [    0/70644]
loss: 0.182847  [ 6400/70644]
loss: 0.038553  [12800/70644]
loss: 0.364861  [19200/70644]
loss: 0.058907  [25600/70644]
loss: 0.052793  [32000/70644]
loss: 0.096277  [38400/70644]
loss: 0.074452  [44800/70644]
loss: 0.038099  [51200/70644]
loss: 0.033022  [57600/70644]
loss: 0.090922  [64000/70644]
loss: 0.114468  [70400/70644]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088197 

Epoch 4
-------------------------------
loss: 0.021948  [    0/70644]
loss: 0.080931  [ 6400/70644]
loss: 0.224186  [12800/70644]
loss: 0.037653  [19200/70644]
loss: 0.132724  [25600/70644]
loss: 0.077786  [32000/70644]
loss: 0.061607  [38400/70644]
loss: 0.079332  [44800/70644]
loss: 0.055194  [51200/70644]
loss: 0.091632  [57600/70644]
loss: 0.083670  [64000/70644]
loss: 0.167997  [70400/70644]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.093245 

Epoch 5
-------------------------------
loss: 0.135773  [    0/70644]
loss: 0.016594  [ 6400/70644]
loss: 0.033158  [ 6400/71639]
loss: 0.075909  [12800/71639]
loss: 0.041006  [19200/71639]
loss: 0.018468  [25600/71639]
loss: 0.015501  [32000/71639]
loss: 0.031258  [38400/71639]
loss: 0.041996  [44800/71639]
loss: 0.073559  [51200/71639]
loss: 0.021069  [57600/71639]
loss: 0.113978  [64000/71639]
loss: 0.038363  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.201772 

Epoch 38
-------------------------------
loss: 0.046761  [    0/71639]
loss: 0.035388  [ 6400/71639]
loss: 0.092014  [12800/71639]
loss: 0.041646  [19200/71639]
loss: 0.029118  [25600/71639]
loss: 0.086552  [32000/71639]
loss: 0.042924  [38400/71639]
loss: 0.101712  [44800/71639]
loss: 0.061646  [51200/71639]
loss: 1.612106  [57600/71639]
loss: 0.074676  [64000/71639]
loss: 0.027258  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.200812 

Epoch 39
-------------------------------
loss: 0.045073  [    0/71639]
loss: 0.027869  [ 6400/71639]
loss: 0.187095  [12800/71639]
loss: 0.034421  [19200/71639]
loss: 0.086289  [25600/71639]
loss: 0.065147  [32000/71639]
loss: 0.025825  [38400/71639]
loss: 0.042286  [44800/71639]
loss: 0.026622  [51200/71639]
loss: 0.115909  [57600/71639]
loss: 0.046240  [64000/71639]
loss: 0.128217  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.203157 

Epoch 40
-------------------------------
loss: 0.030812  [    0/71639]
loss: 0.058112  [ 6400/71639]
loss: 0.017387  [12800/71639]
loss: 0.068456  [19200/71639]
loss: 0.026880  [25600/71639]
loss: 0.015989  [32000/71639]
loss: 0.016382  [38400/71639]
loss: 0.137580  [44800/71639]
loss: 0.048521  [51200/71639]
loss: 0.094173  [57600/71639]
loss: 0.094012  [64000/71639]
loss: 0.183522  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.208494 

Epoch 41
-------------------------------
loss: 0.007542  [    0/71639]
loss: 1.595168  [ 6400/71639]
loss: 0.056130  [12800/71639]
loss: 0.071251  [19200/71639]
loss: 0.042877  [25600/71639]
loss: 0.042908  [32000/71639]
loss: 0.077602  [38400/71639]
loss: 0.031555  [44800/71639]
loss: 0.026563  [51200/71639]
loss: 0.034526  [57600/71639]
loss: 0.065735  [64000/71639]
loss: 0.032784  [70400/71639]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.199785 

Epoch 42
-------------------------------
loss: 0.210370  [    0/71639]
loss: 0.020143  [ 6400/71639]
loss: 0.017458  [12800/71639]
loss: 0.037522  [19200/71639]
loss: 0.014251  [25600/71639]
loss: 0.049399  [32000/71639]
loss: 0.076815  [38400/71639]
loss: 0.019240  [44800/71639]
loss: 0.071349  [51200/71639]
loss: 0.069332  [57600/71639]
loss: 0.045851  [64000/71639]
loss: 0.055621  [70400/71639]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.204511 

Epoch 43
-------------------------------
loss: 0.013015  [    0/71639]
loss: 0.061267  [ 6400/71639]
loss: 0.036690  [12800/71639]
loss: 0.065395  [19200/71639]
loss: 0.054990  [25600/71639]
loss: 0.079418  [32000/71639]
loss: 0.058715  [38400/71639]
loss: 0.050691  [44800/71639]
loss: 0.042505  [51200/71639]
loss: 0.027610  [57600/71639]
loss: 1.643358  [64000/71639]
loss: 0.070395  [70400/71639]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.210582 

Epoch 44
-------------------------------
loss: 0.070135  [    0/71639]
loss: 0.032601  [ 6400/71639]
loss: 0.059116  [12800/71639]
loss: 0.087307  [19200/71639]
loss: 0.049222  [25600/71639]
loss: 1.632900  [32000/71639]
loss: 0.031873  [38400/71639]
loss: 0.058665  [44800/71639]
loss: 0.065132  [51200/71639]
loss: 0.077055  [57600/71639]
loss: 0.036156  [64000/71639]
loss: 0.032535  [70400/71639]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.204644 

Epoch 45
-------------------------------
loss: 0.037654  [    0/71639]
loss: 0.051238  [ 6400/71639]
loss: 0.090338  [12800/71639]
loss: 0.104146  [19200/71639]
loss: 0.008069  [25600/71639]
loss: 0.063007  [32000/71639]
loss: 0.122601  [38400/71639]
loss: 0.129374  [44800/71639]
loss: 0.170953  [51200/71639]
loss: 0.061178  [57600/71639]
loss: 0.059189  [64000/71639]
loss: 0.210536  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.207644 

Epoch 46
-------------------------------
loss: 0.074660  [    0/71639]
loss: 0.045593  [ 6400/71639]
loss: 0.063825  [12800/71639]
loss: 0.067576  [19200/71639]
loss: 0.020656  [25600/71639]
loss: 0.039600  [32000/71639]
loss: 1.573209  [38400/71639]
loss: 0.104276  [44800/71639]
loss: 0.080035  [51200/71639]
loss: 0.076774  [57600/71639]
loss: 0.079503  [64000/71639]
loss: 0.049674  [70400/71639]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.202510 

Epoch 47
-------------------------------
loss: 0.058160  [    0/71639]
loss: 0.035088  [ 6400/71639]
loss: 0.014360  [12800/71639]
loss: 1.603088  [19200/71639]
loss: 0.033619  [25600/71639]
loss: 0.055824  [32000/71639]
loss: 0.074741  [38400/71639]
loss: 0.040593  [44800/71639]
loss: 1.619838  [51200/71639]
loss: 0.051354  [57600/71639]
loss: 0.041617  [64000/71639]
loss: 0.025911  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.203029 

Epoch 48
-------------------------------
loss: 0.084780  [    0/71639]
loss: 0.020970  [ 6400/71639]
loss: 0.105552  [12800/71639]
loss: 0.031043  [19200/71639]
loss: 0.043431  [25600/71639]
loss: 0.131595  [32000/71639]
loss: 0.049811  [38400/71639]
loss: 0.046286  [44800/71639]
loss: 0.081774  [51200/71639]
loss: 0.052963  [57600/71639]
loss: 0.206797  [64000/71639]
loss: 0.022405  [70400/71639]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.203686 

Epoch 49
-------------------------------
loss: 0.046151  [    0/71639]
loss: 0.046150  [ 6400/71639]
loss: 0.145721  [12800/71639]
loss: 0.047669  [19200/71639]
loss: 0.012008  [25600/71639]
loss: 0.101400  [32000/71639]
loss: 0.031274  [38400/71639]
loss: 0.094142  [44800/71639]
loss: 0.087851  [51200/71639]
loss: 0.020496  [57600/71639]
loss: 0.026513  [64000/71639]
loss: 0.094971  [70400/71639]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.209010 

Epoch 50
-------------------------------
loss: 0.043565  [    0/71639]
loss: 0.013575  [ 6400/71639]
loss: 0.028256  [12800/71639]
loss: 0.188273  [19200/71639]
loss: 1.615419  [25600/71639]
loss: 0.080995  [32000/71639]
loss: 0.031562  [38400/71639]
loss: 0.018726  [44800/71639]
loss: 0.048874  [51200/71639]
loss: 0.065648  [57600/71639]
loss: 0.025508  [64000/71639]
loss: 0.048603  [70400/71639]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.207861 

Epoch 1
-------------------------------
loss: 0.734596  [    0/72203]
loss: 0.327805  [ 6400/72203]
loss: 0.188213  [12800/72203]
loss: 0.126707  [19200/72203]
loss: 1.689822  [25600/72203]
loss: 0.092213  [32000/72203]
loss: 0.044643  [38400/72203]
loss: 0.125756  [44800/72203]
loss: 0.250041  [51200/72203]
loss: 0.113358  [57600/72203]
loss: 0.103663  [64000/72203]
loss: 0.105378  [70400/72203]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.164433 

Epoch 2
-------------------------------
loss: 0.192501  [    0/72203]
loss: 0.034771  [ 6400/72203]
loss: 0.070329  [12800/72203]
loss: 0.080713  [19200/72203]
loss: 0.132587  [25600/72203]
loss: 0.098681  [32000/72203]
loss: 0.213711  [38400/72203]
loss: 0.119843  [44800/72203]
loss: 0.073976  [51200/72203]
loss: 1.663743  [57600/72203]
loss: 0.033065  [64000/72203]
loss: 0.109288  [70400/72203]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.155225 

Epoch 3
-------------------------------
loss: 0.063816  [    0/72203]
loss: 0.120137  [ 6400/72203]
loss: 0.029516  [12800/72203]
loss: 0.125377  [19200/72203]
loss: 0.095156  [25600/72203]
loss: 0.131118  [32000/72203]
loss: 0.043774  [38400/72203]
loss: 0.056553  [44800/72203]
loss: 0.073573  [51200/72203]
loss: 1.713362  [57600/72203]
loss: 0.085939  [64000/72203]
loss: 0.275812  [70400/72203]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.145571 

Epoch 4
-------------------------------
loss: 0.084103  [    0/72203]
loss: 0.037865  [ 6400/72203]
loss: 0.027964  [12800/72203]
loss: 0.039545  [19200/72203]
loss: 0.118770  [25600/72203]
loss: 0.142686  [32000/72203]
loss: 0.083668  [38400/72203]
loss: 0.081723  [44800/72203]
loss: 0.080946  [51200/72203]
loss: 0.127014  [57600/72203]
loss: 0.016021  [64000/72203]
loss: 0.087044  [70400/72203]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.148942 

Epoch 5
-------------------------------
loss: 0.061700  [    0/72203]
loss: 0.035783  [ 6400/72203]
loss: 0.035624  [ 6400/70508]
loss: 0.072323  [12800/70508]
loss: 0.104717  [19200/70508]
loss: 0.077529  [25600/70508]
loss: 0.047365  [32000/70508]
loss: 0.121236  [38400/70508]
loss: 0.110034  [44800/70508]
loss: 0.055440  [51200/70508]
loss: 0.022689  [57600/70508]
loss: 0.077569  [64000/70508]
loss: 0.127702  [70400/70508]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.152472 

Epoch 38
-------------------------------
loss: 0.081136  [    0/70508]
loss: 0.013720  [ 6400/70508]
loss: 0.053311  [12800/70508]
loss: 0.034874  [19200/70508]
loss: 0.091924  [25600/70508]
loss: 0.103126  [32000/70508]
loss: 1.627804  [38400/70508]
loss: 0.052147  [44800/70508]
loss: 0.062674  [51200/70508]
loss: 0.025661  [57600/70508]
loss: 0.055264  [64000/70508]
loss: 0.058941  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.148786 

Epoch 39
-------------------------------
loss: 0.026227  [    0/70508]
loss: 0.032917  [ 6400/70508]
loss: 0.029147  [12800/70508]
loss: 0.084427  [19200/70508]
loss: 0.017070  [25600/70508]
loss: 0.096143  [32000/70508]
loss: 0.075867  [38400/70508]
loss: 0.010356  [44800/70508]
loss: 0.050421  [51200/70508]
loss: 0.063807  [57600/70508]
loss: 0.075204  [64000/70508]
loss: 0.103577  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.155423 

Epoch 40
-------------------------------
loss: 0.050706  [    0/70508]
loss: 0.112489  [ 6400/70508]
loss: 0.071288  [12800/70508]
loss: 0.046015  [19200/70508]
loss: 0.064275  [25600/70508]
loss: 0.038115  [32000/70508]
loss: 0.046119  [38400/70508]
loss: 0.102129  [44800/70508]
loss: 0.078113  [51200/70508]
loss: 0.083098  [57600/70508]
loss: 0.084646  [64000/70508]
loss: 0.104495  [70400/70508]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.151389 

Epoch 41
-------------------------------
loss: 0.115432  [    0/70508]
loss: 0.046581  [ 6400/70508]
loss: 0.077677  [12800/70508]
loss: 0.041920  [19200/70508]
loss: 0.108801  [25600/70508]
loss: 0.117025  [32000/70508]
loss: 0.041333  [38400/70508]
loss: 0.115045  [44800/70508]
loss: 0.052447  [51200/70508]
loss: 0.050058  [57600/70508]
loss: 0.112756  [64000/70508]
loss: 0.051209  [70400/70508]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.150090 

Epoch 42
-------------------------------
loss: 0.139978  [    0/70508]
loss: 0.137015  [ 6400/70508]
loss: 0.048895  [12800/70508]
loss: 0.007967  [19200/70508]
loss: 0.017011  [25600/70508]
loss: 0.020083  [32000/70508]
loss: 0.111294  [38400/70508]
loss: 0.044705  [44800/70508]
loss: 0.070918  [51200/70508]
loss: 0.064061  [57600/70508]
loss: 0.178533  [64000/70508]
loss: 0.014163  [70400/70508]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.160282 

Epoch 43
-------------------------------
loss: 0.181184  [    0/70508]
loss: 0.029684  [ 6400/70508]
loss: 0.030217  [12800/70508]
loss: 0.064376  [19200/70508]
loss: 0.052105  [25600/70508]
loss: 0.060244  [32000/70508]
loss: 0.143217  [38400/70508]
loss: 0.083413  [44800/70508]
loss: 0.088865  [51200/70508]
loss: 0.096276  [57600/70508]
loss: 0.084600  [64000/70508]
loss: 0.137609  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.149895 

Epoch 44
-------------------------------
loss: 0.062301  [    0/70508]
loss: 0.051926  [ 6400/70508]
loss: 0.113702  [12800/70508]
loss: 0.016655  [19200/70508]
loss: 0.117966  [25600/70508]
loss: 0.167657  [32000/70508]
loss: 0.068661  [38400/70508]
loss: 0.029622  [44800/70508]
loss: 0.073238  [51200/70508]
loss: 0.081538  [57600/70508]
loss: 0.070509  [64000/70508]
loss: 0.029665  [70400/70508]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.164912 

Epoch 45
-------------------------------
loss: 0.061717  [    0/70508]
loss: 0.051842  [ 6400/70508]
loss: 0.056366  [12800/70508]
loss: 0.054891  [19200/70508]
loss: 0.151437  [25600/70508]
loss: 0.071771  [32000/70508]
loss: 0.009950  [38400/70508]
loss: 0.023441  [44800/70508]
loss: 0.064610  [51200/70508]
loss: 0.085319  [57600/70508]
loss: 0.049990  [64000/70508]
loss: 0.054250  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.153057 

Epoch 46
-------------------------------
loss: 0.076451  [    0/70508]
loss: 0.121145  [ 6400/70508]
loss: 0.053007  [12800/70508]
loss: 0.052047  [19200/70508]
loss: 0.162356  [25600/70508]
loss: 0.030739  [32000/70508]
loss: 0.161031  [38400/70508]
loss: 0.085689  [44800/70508]
loss: 0.078896  [51200/70508]
loss: 0.053090  [57600/70508]
loss: 0.006059  [64000/70508]
loss: 0.095489  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.160206 

Epoch 47
-------------------------------
loss: 0.019216  [    0/70508]
loss: 0.102642  [ 6400/70508]
loss: 0.027936  [12800/70508]
loss: 0.056281  [19200/70508]
loss: 0.013307  [25600/70508]
loss: 0.084643  [32000/70508]
loss: 0.095429  [38400/70508]
loss: 0.057032  [44800/70508]
loss: 0.090539  [51200/70508]
loss: 0.055208  [57600/70508]
loss: 0.082352  [64000/70508]
loss: 0.093770  [70400/70508]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.157258 

Epoch 48
-------------------------------
loss: 0.050615  [    0/70508]
loss: 0.085744  [ 6400/70508]
loss: 0.105104  [12800/70508]
loss: 0.067174  [19200/70508]
loss: 1.654549  [25600/70508]
loss: 0.048119  [32000/70508]
loss: 0.097013  [38400/70508]
loss: 0.060477  [44800/70508]
loss: 0.057445  [51200/70508]
loss: 0.093265  [57600/70508]
loss: 0.098172  [64000/70508]
loss: 0.082773  [70400/70508]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.161730 

Epoch 49
-------------------------------
loss: 0.106864  [    0/70508]
loss: 0.041001  [ 6400/70508]
loss: 0.038310  [12800/70508]
loss: 0.012944  [19200/70508]
loss: 0.121182  [25600/70508]
loss: 0.069233  [32000/70508]
loss: 0.091817  [38400/70508]
loss: 0.137487  [44800/70508]
loss: 0.078890  [51200/70508]
loss: 0.023608  [57600/70508]
loss: 0.085718  [64000/70508]
loss: 0.111946  [70400/70508]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.157237 

Epoch 50
-------------------------------
loss: 0.062561  [    0/70508]
loss: 0.107710  [ 6400/70508]
loss: 0.028100  [12800/70508]
loss: 0.010926  [19200/70508]
loss: 0.044701  [25600/70508]
loss: 0.039371  [32000/70508]
loss: 0.078342  [38400/70508]
loss: 0.033891  [44800/70508]
loss: 0.011893  [51200/70508]
loss: 0.126392  [57600/70508]
loss: 0.053620  [64000/70508]
loss: 0.088046  [70400/70508]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.160285 

Epoch 1
-------------------------------
loss: 0.769148  [    0/70999]
loss: 0.341612  [ 6400/70999]
loss: 0.339127  [12800/70999]
loss: 0.137693  [19200/70999]
loss: 0.270423  [25600/70999]
loss: 0.213458  [32000/70999]
loss: 0.155113  [38400/70999]
loss: 0.154126  [44800/70999]
loss: 0.089123  [51200/70999]
loss: 0.233044  [57600/70999]
loss: 0.263819  [64000/70999]
loss: 0.117180  [70400/70999]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.199111 

Epoch 2
-------------------------------
loss: 0.115839  [    0/70999]
loss: 0.145829  [ 6400/70999]
loss: 0.143593  [12800/70999]
loss: 0.140685  [19200/70999]
loss: 0.133569  [25600/70999]
loss: 0.106493  [32000/70999]
loss: 0.115579  [38400/70999]
loss: 0.192466  [44800/70999]
loss: 0.158077  [51200/70999]
loss: 0.167243  [57600/70999]
loss: 0.171483  [64000/70999]
loss: 0.140557  [70400/70999]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.184211 

Epoch 3
-------------------------------
loss: 1.663385  [    0/70999]
loss: 0.233237  [ 6400/70999]
loss: 0.185351  [12800/70999]
loss: 0.159191  [19200/70999]
loss: 0.224045  [25600/70999]
loss: 0.260027  [32000/70999]
loss: 0.157353  [38400/70999]
loss: 0.154852  [44800/70999]
loss: 0.208639  [51200/70999]
loss: 0.205003  [57600/70999]
loss: 0.122855  [64000/70999]
loss: 0.139603  [70400/70999]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.164923 

Epoch 4
-------------------------------
loss: 0.119831  [    0/70999]
loss: 0.198912  [ 6400/70999]
loss: 0.257752  [12800/70999]
loss: 0.138236  [19200/70999]
loss: 0.256346  [25600/70999]
loss: 0.054049  [32000/70999]
loss: 0.089151  [38400/70999]
loss: 0.045741  [44800/70999]
loss: 0.155546  [51200/70999]
loss: 0.098038  [57600/70999]
loss: 0.125896  [64000/70999]
loss: 0.161224  [70400/70999]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.145597 

Epoch 5
-------------------------------
loss: 0.252476  [    0/70999]
loss: 0.132003  [ 6400/70999]
loss: 0.124099  [ 6400/70834]
loss: 0.072470  [12800/70834]
loss: 0.002067  [19200/70834]
loss: 0.082266  [25600/70834]
loss: 0.116937  [32000/70834]
loss: 0.024327  [38400/70834]
loss: 0.018015  [44800/70834]
loss: 0.061383  [51200/70834]
loss: 0.036126  [57600/70834]
loss: 0.014888  [64000/70834]
loss: 0.050274  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.084949 

Epoch 38
-------------------------------
loss: 0.037327  [    0/70834]
loss: 0.069060  [ 6400/70834]
loss: 0.022080  [12800/70834]
loss: 0.023435  [19200/70834]
loss: 0.014789  [25600/70834]
loss: 0.002163  [32000/70834]
loss: 0.031887  [38400/70834]
loss: 0.032299  [44800/70834]
loss: 0.041454  [51200/70834]
loss: 0.043314  [57600/70834]
loss: 0.059127  [64000/70834]
loss: 0.119035  [70400/70834]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.095518 

Epoch 39
-------------------------------
loss: 0.170151  [    0/70834]
loss: 0.032564  [ 6400/70834]
loss: 0.091337  [12800/70834]
loss: 0.140130  [19200/70834]
loss: 0.038691  [25600/70834]
loss: 0.216137  [32000/70834]
loss: 0.079070  [38400/70834]
loss: 0.068309  [44800/70834]
loss: 0.065219  [51200/70834]
loss: 0.099503  [57600/70834]
loss: 0.025417  [64000/70834]
loss: 0.010596  [70400/70834]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.086625 

Epoch 40
-------------------------------
loss: 0.027779  [    0/70834]
loss: 0.042864  [ 6400/70834]
loss: 0.073996  [12800/70834]
loss: 0.150027  [19200/70834]
loss: 0.091441  [25600/70834]
loss: 0.036182  [32000/70834]
loss: 0.005248  [38400/70834]
loss: 0.151153  [44800/70834]
loss: 0.055674  [51200/70834]
loss: 0.037828  [57600/70834]
loss: 0.015229  [64000/70834]
loss: 0.023710  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.093711 

Epoch 41
-------------------------------
loss: 0.092371  [    0/70834]
loss: 0.062971  [ 6400/70834]
loss: 0.130359  [12800/70834]
loss: 0.050704  [19200/70834]
loss: 0.020064  [25600/70834]
loss: 0.021856  [32000/70834]
loss: 0.041215  [38400/70834]
loss: 0.059901  [44800/70834]
loss: 0.093008  [51200/70834]
loss: 0.040883  [57600/70834]
loss: 0.070459  [64000/70834]
loss: 0.067717  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.077665 

Epoch 42
-------------------------------
loss: 0.005250  [    0/70834]
loss: 0.064283  [ 6400/70834]
loss: 0.041226  [12800/70834]
loss: 0.042581  [19200/70834]
loss: 0.014214  [25600/70834]
loss: 0.036794  [32000/70834]
loss: 0.024235  [38400/70834]
loss: 0.051332  [44800/70834]
loss: 0.063322  [51200/70834]
loss: 0.046985  [57600/70834]
loss: 0.121751  [64000/70834]
loss: 0.020920  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082090 

Epoch 43
-------------------------------
loss: 0.026142  [    0/70834]
loss: 0.076617  [ 6400/70834]
loss: 0.062036  [12800/70834]
loss: 0.072083  [19200/70834]
loss: 0.041657  [25600/70834]
loss: 0.044611  [32000/70834]
loss: 0.109552  [38400/70834]
loss: 0.031161  [44800/70834]
loss: 0.030242  [51200/70834]
loss: 0.014086  [57600/70834]
loss: 0.016937  [64000/70834]
loss: 0.057613  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.086442 

Epoch 44
-------------------------------
loss: 0.011641  [    0/70834]
loss: 0.044374  [ 6400/70834]
loss: 0.022442  [12800/70834]
loss: 0.119444  [19200/70834]
loss: 0.092739  [25600/70834]
loss: 0.061497  [32000/70834]
loss: 0.119913  [38400/70834]
loss: 0.262823  [44800/70834]
loss: 0.074704  [51200/70834]
loss: 0.019010  [57600/70834]
loss: 0.103139  [64000/70834]
loss: 0.018657  [70400/70834]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.088048 

Epoch 45
-------------------------------
loss: 0.019335  [    0/70834]
loss: 0.058694  [ 6400/70834]
loss: 0.165148  [12800/70834]
loss: 0.105570  [19200/70834]
loss: 0.060361  [25600/70834]
loss: 0.022717  [32000/70834]
loss: 0.197987  [38400/70834]
loss: 0.101736  [44800/70834]
loss: 0.008373  [51200/70834]
loss: 0.185102  [57600/70834]
loss: 0.045063  [64000/70834]
loss: 0.126620  [70400/70834]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.079368 

Epoch 46
-------------------------------
loss: 0.017522  [    0/70834]
loss: 0.057547  [ 6400/70834]
loss: 0.015677  [12800/70834]
loss: 0.126839  [19200/70834]
loss: 0.058679  [25600/70834]
loss: 0.031129  [32000/70834]
loss: 0.047136  [38400/70834]
loss: 0.133473  [44800/70834]
loss: 0.050524  [51200/70834]
loss: 0.050498  [57600/70834]
loss: 0.041616  [64000/70834]
loss: 0.085833  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076247 

Epoch 47
-------------------------------
loss: 0.060927  [    0/70834]
loss: 0.022218  [ 6400/70834]
loss: 0.063342  [12800/70834]
loss: 0.038441  [19200/70834]
loss: 0.066173  [25600/70834]
loss: 0.005246  [32000/70834]
loss: 0.048604  [38400/70834]
loss: 0.091850  [44800/70834]
loss: 0.020619  [51200/70834]
loss: 0.095988  [57600/70834]
loss: 0.119425  [64000/70834]
loss: 0.038453  [70400/70834]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.088063 

Epoch 48
-------------------------------
loss: 0.058406  [    0/70834]
loss: 0.067538  [ 6400/70834]
loss: 0.098199  [12800/70834]
loss: 0.027013  [19200/70834]
loss: 0.080929  [25600/70834]
loss: 0.015860  [32000/70834]
loss: 0.034821  [38400/70834]
loss: 0.173522  [44800/70834]
loss: 0.042609  [51200/70834]
loss: 0.060442  [57600/70834]
loss: 0.091771  [64000/70834]
loss: 0.091048  [70400/70834]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.083421 

Epoch 49
-------------------------------
loss: 0.067886  [    0/70834]
loss: 0.027609  [ 6400/70834]
loss: 0.024437  [12800/70834]
loss: 0.099339  [19200/70834]
loss: 0.151372  [25600/70834]
loss: 0.072631  [32000/70834]
loss: 0.037790  [38400/70834]
loss: 0.037967  [44800/70834]
loss: 0.153721  [51200/70834]
loss: 0.071644  [57600/70834]
loss: 0.031158  [64000/70834]
loss: 0.003491  [70400/70834]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.092065 

Epoch 50
-------------------------------
loss: 0.024360  [    0/70834]
loss: 0.110325  [ 6400/70834]
loss: 0.228355  [12800/70834]
loss: 0.038144  [19200/70834]
loss: 0.012282  [25600/70834]
loss: 0.059287  [32000/70834]
loss: 0.097695  [38400/70834]
loss: 0.026374  [44800/70834]
loss: 0.038589  [51200/70834]
loss: 0.029913  [57600/70834]
loss: 0.047841  [64000/70834]
loss: 0.037943  [70400/70834]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.077223 

Epoch 1
-------------------------------
loss: 0.756797  [    0/70196]
loss: 0.120266  [ 6400/70196]
loss: 0.104226  [12800/70196]
loss: 0.117452  [19200/70196]
loss: 0.216572  [25600/70196]
loss: 0.154143  [32000/70196]
loss: 0.071463  [38400/70196]
loss: 0.066167  [44800/70196]
loss: 0.190788  [51200/70196]
loss: 0.107879  [57600/70196]
loss: 0.124297  [64000/70196]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.099155 

Epoch 2
-------------------------------
loss: 0.036919  [    0/70196]
loss: 0.086048  [ 6400/70196]
loss: 0.148993  [12800/70196]
loss: 0.123341  [19200/70196]
loss: 0.111158  [25600/70196]
loss: 0.099640  [32000/70196]
loss: 0.170446  [38400/70196]
loss: 0.056760  [44800/70196]
loss: 0.157087  [51200/70196]
loss: 0.181620  [57600/70196]
loss: 0.045060  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081179 

Epoch 3
-------------------------------
loss: 0.158629  [    0/70196]
loss: 0.025042  [ 6400/70196]
loss: 0.054378  [12800/70196]
loss: 0.118568  [19200/70196]
loss: 0.268174  [25600/70196]
loss: 0.086186  [32000/70196]
loss: 0.047836  [38400/70196]
loss: 0.141085  [44800/70196]
loss: 0.112096  [51200/70196]
loss: 0.028026  [57600/70196]
loss: 0.066608  [64000/70196]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084746 

Epoch 4
-------------------------------
loss: 0.154767  [    0/70196]
loss: 0.115970  [ 6400/70196]
loss: 0.065032  [12800/70196]
loss: 0.123216  [19200/70196]
loss: 0.051238  [25600/70196]
loss: 0.035001  [32000/70196]
loss: 0.048554  [38400/70196]
loss: 0.067581  [44800/70196]
loss: 0.044948  [51200/70196]
loss: 0.041929  [57600/70196]
loss: 0.067219  [64000/70196]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.081982 

Epoch 5
-------------------------------
loss: 0.010381  [    0/70196]
loss: 0.080002  [ 6400/70196]
loss: 0.052918  [12800/70196]
loss: 0.191548  [19200/70196]
loss: 0.044675  [25600/70196]
loss: 0.103292  [32000/70196]
loss: 0.033406  [ 6400/71045]
loss: 0.049504  [12800/71045]
loss: 0.027659  [19200/71045]
loss: 0.002076  [25600/71045]
loss: 0.037183  [32000/71045]
loss: 0.039507  [38400/71045]
loss: 0.067528  [44800/71045]
loss: 0.186433  [51200/71045]
loss: 0.005569  [57600/71045]
loss: 0.031052  [64000/71045]
loss: 0.065416  [70400/71045]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.084591 

Epoch 38
-------------------------------
loss: 0.044635  [    0/71045]
loss: 0.043779  [ 6400/71045]
loss: 0.043751  [12800/71045]
loss: 0.029508  [19200/71045]
loss: 0.062509  [25600/71045]
loss: 0.037003  [32000/71045]
loss: 0.075108  [38400/71045]
loss: 0.003403  [44800/71045]
loss: 0.089255  [51200/71045]
loss: 0.014348  [57600/71045]
loss: 0.077932  [64000/71045]
loss: 0.025161  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073561 

Epoch 39
-------------------------------
loss: 0.010783  [    0/71045]
loss: 0.012583  [ 6400/71045]
loss: 0.013498  [12800/71045]
loss: 0.076954  [19200/71045]
loss: 0.038377  [25600/71045]
loss: 0.020241  [32000/71045]
loss: 0.027075  [38400/71045]
loss: 0.026396  [44800/71045]
loss: 0.121040  [51200/71045]
loss: 0.040526  [57600/71045]
loss: 0.100270  [64000/71045]
loss: 0.042456  [70400/71045]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.090643 

Epoch 40
-------------------------------
loss: 0.011853  [    0/71045]
loss: 0.020896  [ 6400/71045]
loss: 0.059876  [12800/71045]
loss: 0.034963  [19200/71045]
loss: 0.014389  [25600/71045]
loss: 0.023173  [32000/71045]
loss: 0.080109  [38400/71045]
loss: 0.091682  [44800/71045]
loss: 0.029982  [51200/71045]
loss: 0.006225  [57600/71045]
loss: 0.023420  [64000/71045]
loss: 0.009429  [70400/71045]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.073043 

Epoch 41
-------------------------------
loss: 0.006715  [    0/71045]
loss: 0.017688  [ 6400/71045]
loss: 0.080659  [12800/71045]
loss: 0.135543  [19200/71045]
loss: 0.042400  [25600/71045]
loss: 0.052709  [32000/71045]
loss: 0.004920  [38400/71045]
loss: 0.023613  [44800/71045]
loss: 0.088442  [51200/71045]
loss: 0.032378  [57600/71045]
loss: 0.060882  [64000/71045]
loss: 0.141039  [70400/71045]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076469 

Epoch 42
-------------------------------
loss: 0.043917  [    0/71045]
loss: 0.014112  [ 6400/71045]
loss: 0.011605  [12800/71045]
loss: 0.045274  [19200/71045]
loss: 0.039461  [25600/71045]
loss: 0.004060  [32000/71045]
loss: 0.067480  [38400/71045]
loss: 0.030913  [44800/71045]
loss: 0.027860  [51200/71045]
loss: 0.035908  [57600/71045]
loss: 0.041030  [64000/71045]
loss: 0.068470  [70400/71045]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.083063 

Epoch 43
-------------------------------
loss: 0.065024  [    0/71045]
loss: 0.023094  [ 6400/71045]
loss: 0.043855  [12800/71045]
loss: 0.014132  [19200/71045]
loss: 0.023021  [25600/71045]
loss: 0.009239  [32000/71045]
loss: 0.016737  [38400/71045]
loss: 0.012779  [44800/71045]
loss: 0.032881  [51200/71045]
loss: 0.010488  [57600/71045]
loss: 0.019168  [64000/71045]
loss: 0.039591  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.074316 

Epoch 44
-------------------------------
loss: 0.045838  [    0/71045]
loss: 0.022792  [ 6400/71045]
loss: 0.012067  [12800/71045]
loss: 0.053969  [19200/71045]
loss: 0.081180  [25600/71045]
loss: 0.060074  [32000/71045]
loss: 0.038296  [38400/71045]
loss: 0.022177  [44800/71045]
loss: 0.039976  [51200/71045]
loss: 0.031719  [57600/71045]
loss: 0.017545  [64000/71045]
loss: 0.005412  [70400/71045]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.085183 

Epoch 45
-------------------------------
loss: 0.032941  [    0/71045]
loss: 0.090527  [ 6400/71045]
loss: 0.063330  [12800/71045]
loss: 0.092216  [19200/71045]
loss: 0.002451  [25600/71045]
loss: 0.107579  [32000/71045]
loss: 0.012751  [38400/71045]
loss: 0.062615  [44800/71045]
loss: 0.051634  [51200/71045]
loss: 0.067259  [57600/71045]
loss: 0.015353  [64000/71045]
loss: 0.003408  [70400/71045]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085248 

Epoch 46
-------------------------------
loss: 0.061824  [    0/71045]
loss: 0.010987  [ 6400/71045]
loss: 0.016962  [12800/71045]
loss: 0.014715  [19200/71045]
loss: 0.017898  [25600/71045]
loss: 0.035798  [32000/71045]
loss: 0.041143  [38400/71045]
loss: 0.043401  [44800/71045]
loss: 0.015256  [51200/71045]
loss: 0.022435  [57600/71045]
loss: 0.010554  [64000/71045]
loss: 0.047468  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.072531 

Epoch 47
-------------------------------
loss: 0.016338  [    0/71045]
loss: 0.026572  [ 6400/71045]
loss: 0.033585  [12800/71045]
loss: 0.005033  [19200/71045]
loss: 0.016609  [25600/71045]
loss: 0.123758  [32000/71045]
loss: 0.023380  [38400/71045]
loss: 0.005524  [44800/71045]
loss: 0.068449  [51200/71045]
loss: 0.031134  [57600/71045]
loss: 0.010158  [64000/71045]
loss: 0.059850  [70400/71045]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.084808 

Epoch 48
-------------------------------
loss: 0.025422  [    0/71045]
loss: 0.033788  [ 6400/71045]
loss: 0.023432  [12800/71045]
loss: 0.012815  [19200/71045]
loss: 0.019152  [25600/71045]
loss: 0.037042  [32000/71045]
loss: 0.069594  [38400/71045]
loss: 0.033659  [44800/71045]
loss: 0.005796  [51200/71045]
loss: 0.006253  [57600/71045]
loss: 0.106461  [64000/71045]
loss: 0.001481  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077777 

Epoch 49
-------------------------------
loss: 0.030301  [    0/71045]
loss: 0.014112  [ 6400/71045]
loss: 0.017815  [12800/71045]
loss: 0.021537  [19200/71045]
loss: 0.034540  [25600/71045]
loss: 0.068620  [32000/71045]
loss: 0.070970  [38400/71045]
loss: 0.100344  [44800/71045]
loss: 0.085462  [51200/71045]
loss: 0.052478  [57600/71045]
loss: 0.052830  [64000/71045]
loss: 0.019475  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.075410 

Epoch 50
-------------------------------
loss: 0.036953  [    0/71045]
loss: 0.022896  [ 6400/71045]
loss: 0.046135  [12800/71045]
loss: 0.049646  [19200/71045]
loss: 0.029190  [25600/71045]
loss: 0.058820  [32000/71045]
loss: 0.052075  [38400/71045]
loss: 0.051265  [44800/71045]
loss: 0.044936  [51200/71045]
loss: 0.016748  [57600/71045]
loss: 0.080930  [64000/71045]
loss: 0.021967  [70400/71045]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077946 

Epoch 1
-------------------------------
loss: 0.757545  [    0/71198]
loss: 0.071168  [ 6400/71198]
loss: 0.035107  [12800/71198]
loss: 0.129351  [19200/71198]
loss: 0.059795  [25600/71198]
loss: 0.052685  [32000/71198]
loss: 0.213186  [38400/71198]
loss: 0.127808  [44800/71198]
loss: 0.090118  [51200/71198]
loss: 0.055593  [57600/71198]
loss: 0.098371  [64000/71198]
loss: 0.298370  [70400/71198]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.072368 

Epoch 2
-------------------------------
loss: 0.030560  [    0/71198]
loss: 0.188285  [ 6400/71198]
loss: 0.069409  [12800/71198]
loss: 0.041436  [19200/71198]
loss: 0.080682  [25600/71198]
loss: 0.104239  [32000/71198]
loss: 0.065188  [38400/71198]
loss: 0.110632  [44800/71198]
loss: 0.065029  [51200/71198]
loss: 0.050294  [57600/71198]
loss: 0.060075  [64000/71198]
loss: 0.203856  [70400/71198]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.070256 

Epoch 3
-------------------------------
loss: 0.038841  [    0/71198]
loss: 0.039063  [ 6400/71198]
loss: 0.092494  [12800/71198]
loss: 0.040491  [19200/71198]
loss: 0.129500  [25600/71198]
loss: 0.120877  [32000/71198]
loss: 0.071514  [38400/71198]
loss: 0.053079  [44800/71198]
loss: 0.182861  [51200/71198]
loss: 0.037612  [57600/71198]
loss: 0.017397  [64000/71198]
loss: 0.086085  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.055621 

Epoch 4
-------------------------------
loss: 0.064614  [    0/71198]
loss: 0.042112  [ 6400/71198]
loss: 0.089902  [12800/71198]
loss: 0.058495  [19200/71198]
loss: 0.035708  [25600/71198]
loss: 0.100431  [32000/71198]
loss: 0.036783  [38400/71198]
loss: 0.074706  [44800/71198]
loss: 0.016629  [51200/71198]
loss: 0.037526  [57600/71198]
loss: 0.056095  [64000/71198]
loss: 0.042220  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.054816 

Epoch 5
-------------------------------
loss: 0.034228  [    0/71198]
loss: 0.254001  [ 6400/71198]
loss: 0.234662  [57600/69683]
loss: 0.147602  [64000/69683]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.152143 

Epoch 40
-------------------------------
loss: 0.080385  [    0/69683]
loss: 0.142524  [ 6400/69683]
loss: 0.050653  [12800/69683]
loss: 0.164302  [19200/69683]
loss: 0.199758  [25600/69683]
loss: 0.149977  [32000/69683]
loss: 0.115365  [38400/69683]
loss: 0.132334  [44800/69683]
loss: 0.096707  [51200/69683]
loss: 0.058363  [57600/69683]
loss: 0.108588  [64000/69683]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160463 

Epoch 41
-------------------------------
loss: 0.119902  [    0/69683]
loss: 0.120834  [ 6400/69683]
loss: 0.230886  [12800/69683]
loss: 0.095743  [19200/69683]
loss: 0.107353  [25600/69683]
loss: 0.138045  [32000/69683]
loss: 0.103913  [38400/69683]
loss: 0.155814  [44800/69683]
loss: 0.194999  [51200/69683]
loss: 0.147884  [57600/69683]
loss: 0.193300  [64000/69683]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.150587 

Epoch 42
-------------------------------
loss: 0.222614  [    0/69683]
loss: 0.140636  [ 6400/69683]
loss: 0.119144  [12800/69683]
loss: 0.156697  [19200/69683]
loss: 0.162214  [25600/69683]
loss: 0.063874  [32000/69683]
loss: 0.047397  [38400/69683]
loss: 0.145943  [44800/69683]
loss: 0.115815  [51200/69683]
loss: 0.113416  [57600/69683]
loss: 0.133781  [64000/69683]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.162549 

Epoch 43
-------------------------------
loss: 0.106460  [    0/69683]
loss: 0.052175  [ 6400/69683]
loss: 0.075224  [12800/69683]
loss: 0.088895  [19200/69683]
loss: 0.142465  [25600/69683]
loss: 0.098158  [32000/69683]
loss: 0.116353  [38400/69683]
loss: 0.114262  [44800/69683]
loss: 0.072579  [51200/69683]
loss: 0.116946  [57600/69683]
loss: 0.135666  [64000/69683]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157755 

Epoch 44
-------------------------------
loss: 0.080768  [    0/69683]
loss: 0.152459  [ 6400/69683]
loss: 0.151175  [12800/69683]
loss: 0.071520  [19200/69683]
loss: 0.076543  [25600/69683]
loss: 0.145193  [32000/69683]
loss: 0.249576  [38400/69683]
loss: 0.156118  [44800/69683]
loss: 0.119697  [51200/69683]
loss: 0.160064  [57600/69683]
loss: 0.255490  [64000/69683]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.157787 

Epoch 45
-------------------------------
loss: 0.087667  [    0/69683]
loss: 0.120064  [ 6400/69683]
loss: 0.149018  [12800/69683]
loss: 0.078521  [19200/69683]
loss: 0.084030  [25600/69683]
loss: 0.301216  [32000/69683]
loss: 0.199919  [38400/69683]
loss: 0.079676  [44800/69683]
loss: 0.093637  [51200/69683]
loss: 0.160679  [57600/69683]
loss: 0.079504  [64000/69683]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.161486 

Epoch 46
-------------------------------
loss: 0.113220  [    0/69683]
loss: 0.057694  [ 6400/69683]
loss: 0.119864  [12800/69683]
loss: 0.268349  [19200/69683]
loss: 0.191118  [25600/69683]
loss: 0.087932  [32000/69683]
loss: 0.124556  [38400/69683]
loss: 0.118612  [44800/69683]
loss: 0.032469  [51200/69683]
loss: 0.127167  [57600/69683]
loss: 0.103652  [64000/69683]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.153345 

Epoch 47
-------------------------------
loss: 0.167208  [    0/69683]
loss: 0.052133  [ 6400/69683]
loss: 0.132977  [12800/69683]
loss: 0.223140  [19200/69683]
loss: 0.096216  [25600/69683]
loss: 0.266313  [32000/69683]
loss: 0.094549  [38400/69683]
loss: 0.127374  [44800/69683]
loss: 0.092039  [51200/69683]
loss: 0.075962  [57600/69683]
loss: 0.082082  [64000/69683]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.167809 

Epoch 48
-------------------------------
loss: 0.111498  [    0/69683]
loss: 0.103045  [ 6400/69683]
loss: 0.051024  [12800/69683]
loss: 0.060995  [19200/69683]
loss: 0.097779  [25600/69683]
loss: 0.185933  [32000/69683]
loss: 0.060070  [38400/69683]
loss: 0.113686  [44800/69683]
loss: 0.176271  [51200/69683]
loss: 0.160441  [57600/69683]
loss: 0.223053  [64000/69683]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.168898 

Epoch 49
-------------------------------
loss: 0.137482  [    0/69683]
loss: 0.213010  [ 6400/69683]
loss: 0.147544  [12800/69683]
loss: 0.102446  [19200/69683]
loss: 0.069892  [25600/69683]
loss: 0.162006  [32000/69683]
loss: 0.084807  [38400/69683]
loss: 0.069963  [44800/69683]
loss: 0.155953  [51200/69683]
loss: 0.074201  [57600/69683]
loss: 0.133443  [64000/69683]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.157156 

Epoch 50
-------------------------------
loss: 0.158506  [    0/69683]
loss: 0.206759  [ 6400/69683]
loss: 0.159093  [12800/69683]
loss: 0.138846  [19200/69683]
loss: 0.130104  [25600/69683]
loss: 0.215738  [32000/69683]
loss: 0.094504  [38400/69683]
loss: 0.270461  [44800/69683]
loss: 0.078226  [51200/69683]
loss: 0.136501  [57600/69683]
loss: 0.087362  [64000/69683]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159429 

Epoch 1
-------------------------------
loss: 0.762425  [    0/70451]
loss: 0.342689  [ 6400/70451]
loss: 0.272311  [12800/70451]
loss: 0.171009  [19200/70451]
loss: 0.181082  [25600/70451]
loss: 0.273473  [32000/70451]
loss: 0.120867  [38400/70451]
loss: 0.213688  [44800/70451]
loss: 0.229566  [51200/70451]
loss: 0.243285  [57600/70451]
loss: 0.093526  [64000/70451]
loss: 0.151155  [56100/70451]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.171505 

Epoch 2
-------------------------------
loss: 0.045889  [    0/70451]
loss: 0.252797  [ 6400/70451]
loss: 0.191263  [12800/70451]
loss: 0.116734  [19200/70451]
loss: 0.598886  [25600/70451]
loss: 0.156154  [32000/70451]
loss: 0.134104  [38400/70451]
loss: 0.246126  [44800/70451]
loss: 0.133350  [51200/70451]
loss: 0.082745  [57600/70451]
loss: 0.227721  [64000/70451]
loss: 0.183158  [56100/70451]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.153522 

Epoch 3
-------------------------------
loss: 0.211893  [    0/70451]
loss: 0.182787  [ 6400/70451]
loss: 0.053602  [12800/70451]
loss: 0.256937  [19200/70451]
loss: 0.120237  [25600/70451]
loss: 0.104563  [32000/70451]
loss: 0.108259  [38400/70451]
loss: 0.201175  [44800/70451]
loss: 0.196957  [51200/70451]
loss: 0.268010  [57600/70451]
loss: 0.091488  [64000/70451]
loss: 0.102448  [56100/70451]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.149968 

Epoch 4
-------------------------------
loss: 0.081530  [    0/70451]
loss: 0.083562  [ 6400/70451]
loss: 0.108121  [12800/70451]
loss: 0.120967  [19200/70451]
loss: 0.165611  [25600/70451]
loss: 0.141410  [32000/70451]
loss: 0.241111  [38400/70451]
loss: 0.089412  [44800/70451]
loss: 0.212815  [51200/70451]
loss: 0.166498  [57600/70451]
loss: 0.122700  [64000/70451]
loss: 0.183120  [56100/70451]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.140109 

Epoch 5
-------------------------------
loss: 0.118289  [    0/70451]
loss: 0.216753  [ 6400/70451]
loss: 0.099974  [12800/70451]
loss: 0.190638  [19200/70451]
loss: 0.117504  [25600/70451]
loss: 0.065956  [32000/70451]
loss: 0.101794  [38400/70451]
loss: 0.115461  [44800/70451]
loss: 0.072267  [51200/70451]
loss: 0.114503  [57600/70451]
loss: 0.130521  [64000/70451]
loss: 0.198091  [56100/70451]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.145473 

Epoch 6
-------------------------------
loss: 0.082521  [    0/70451]
loss: 0.153964  [ 6400/70451]
loss: 0.123736  [12800/70451]
loss: 0.163721  [19200/70451]
loss: 0.097177  [25600/70451]
loss: 0.149012  [32000/70451]
loss: 0.093288  [38400/70451]
loss: 0.151407  [44800/70451]
loss: 0.102608  [51200/70451]
loss: 0.163799  [57600/70451]
loss: 0.135351  [64000/70451]
loss: 0.122545  [56100/70451]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.145977 

Epoch 7
-------------------------------
loss: 0.160860  [    0/70451]
loss: 0.168879  [ 6400/70451]
loss: 0.222895  [12800/70451]
loss: 0.046692  [19200/70451]
loss: 0.243347  [25600/70451]
loss: 0.082515  [32000/70451]
loss: 0.164436  [38400/70451]
loss: 0.136154  [44800/70451]
loss: 0.093025  [51200/70451]
loss: 0.138033  [57600/70451]
loss: 0.283726  [64000/70451]
loss: 0.151413  [56100/70451]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.144768 

Epoch 8
-------------------------------
loss: 0.151499  [    0/70451]
loss: 0.160213  [ 6400/70451]
loss: 0.203589  [12800/70451]
loss: 0.115086  [19200/70451]
loss: 0.289401  [25600/70451]
loss: 0.147350  [32000/70451]
loss: 0.173845  [38400/70451]
loss: 0.007933  [57600/70296]
loss: 0.090371  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.080787 

Epoch 40
-------------------------------
loss: 0.010267  [    0/70296]
loss: 0.136373  [ 6400/70296]
loss: 0.117669  [12800/70296]
loss: 0.027071  [19200/70296]
loss: 0.024958  [25600/70296]
loss: 0.030060  [32000/70296]
loss: 0.055772  [38400/70296]
loss: 0.057626  [44800/70296]
loss: 0.015312  [51200/70296]
loss: 0.046058  [57600/70296]
loss: 0.069062  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.084955 

Epoch 41
-------------------------------
loss: 0.164854  [    0/70296]
loss: 0.077769  [ 6400/70296]
loss: 0.100229  [12800/70296]
loss: 0.027926  [19200/70296]
loss: 0.014355  [25600/70296]
loss: 0.103555  [32000/70296]
loss: 0.106393  [38400/70296]
loss: 0.079181  [44800/70296]
loss: 0.126436  [51200/70296]
loss: 0.091754  [57600/70296]
loss: 0.123171  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080836 

Epoch 42
-------------------------------
loss: 0.067378  [    0/70296]
loss: 0.017992  [ 6400/70296]
loss: 0.026986  [12800/70296]
loss: 0.010392  [19200/70296]
loss: 0.032701  [25600/70296]
loss: 0.016595  [32000/70296]
loss: 0.058791  [38400/70296]
loss: 0.055214  [44800/70296]
loss: 0.030358  [51200/70296]
loss: 0.052564  [57600/70296]
loss: 0.042306  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085827 

Epoch 43
-------------------------------
loss: 0.082597  [    0/70296]
loss: 0.061289  [ 6400/70296]
loss: 0.028581  [12800/70296]
loss: 0.093543  [19200/70296]
loss: 0.036064  [25600/70296]
loss: 0.029563  [32000/70296]
loss: 0.046320  [38400/70296]
loss: 0.035865  [44800/70296]
loss: 0.043152  [51200/70296]
loss: 0.062002  [57600/70296]
loss: 0.076969  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.078514 

Epoch 44
-------------------------------
loss: 0.004939  [    0/70296]
loss: 0.054585  [ 6400/70296]
loss: 0.015638  [12800/70296]
loss: 0.015957  [19200/70296]
loss: 0.022918  [25600/70296]
loss: 0.030296  [32000/70296]
loss: 0.088410  [38400/70296]
loss: 0.030910  [44800/70296]
loss: 0.103234  [51200/70296]
loss: 0.128746  [57600/70296]
loss: 0.147503  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083099 

Epoch 45
-------------------------------
loss: 0.125954  [    0/70296]
loss: 0.019936  [ 6400/70296]
loss: 0.007045  [12800/70296]
loss: 0.003909  [19200/70296]
loss: 0.124420  [25600/70296]
loss: 0.030907  [32000/70296]
loss: 0.092005  [38400/70296]
loss: 0.111560  [44800/70296]
loss: 0.015404  [51200/70296]
loss: 0.057409  [57600/70296]
loss: 0.065916  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077670 

Epoch 46
-------------------------------
loss: 0.059344  [    0/70296]
loss: 0.030527  [ 6400/70296]
loss: 0.063307  [12800/70296]
loss: 0.011257  [19200/70296]
loss: 0.008878  [25600/70296]
loss: 0.075891  [32000/70296]
loss: 0.135119  [38400/70296]
loss: 0.017248  [44800/70296]
loss: 0.042142  [51200/70296]
loss: 0.004448  [57600/70296]
loss: 0.022197  [64000/70296]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075667 

Epoch 47
-------------------------------
loss: 0.031863  [    0/70296]
loss: 0.019333  [ 6400/70296]
loss: 0.073408  [12800/70296]
loss: 0.055092  [19200/70296]
loss: 0.075909  [25600/70296]
loss: 0.035342  [32000/70296]
loss: 0.033983  [38400/70296]
loss: 0.077015  [44800/70296]
loss: 0.060715  [51200/70296]
loss: 0.072770  [57600/70296]
loss: 0.102242  [64000/70296]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.084750 

Epoch 48
-------------------------------
loss: 0.018931  [    0/70296]
loss: 0.120097  [ 6400/70296]
loss: 0.040594  [12800/70296]
loss: 0.024828  [19200/70296]
loss: 0.019155  [25600/70296]
loss: 0.029981  [32000/70296]
loss: 0.030383  [38400/70296]
loss: 0.090882  [44800/70296]
loss: 0.104467  [51200/70296]
loss: 0.077052  [57600/70296]
loss: 0.089260  [64000/70296]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.079186 

Epoch 49
-------------------------------
loss: 0.070198  [    0/70296]
loss: 0.117264  [ 6400/70296]
loss: 0.071913  [12800/70296]
loss: 0.131421  [19200/70296]
loss: 0.024982  [25600/70296]
loss: 0.059091  [32000/70296]
loss: 0.059180  [38400/70296]
loss: 0.007495  [44800/70296]
loss: 0.016615  [51200/70296]
loss: 0.038282  [57600/70296]
loss: 0.025881  [64000/70296]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.090297 

Epoch 50
-------------------------------
loss: 0.045485  [    0/70296]
loss: 0.102219  [ 6400/70296]
loss: 0.018502  [12800/70296]
loss: 0.040422  [19200/70296]
loss: 0.048454  [25600/70296]
loss: 0.040006  [32000/70296]
loss: 0.078574  [38400/70296]
loss: 0.031558  [44800/70296]
loss: 0.033587  [51200/70296]
loss: 0.047951  [57600/70296]
loss: 0.049247  [64000/70296]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.103457 

Epoch 1
-------------------------------
loss: 0.762169  [    0/70787]
loss: 0.098592  [ 6400/70787]
loss: 0.086186  [12800/70787]
loss: 0.095638  [19200/70787]
loss: 0.054516  [25600/70787]
loss: 0.170503  [32000/70787]
loss: 0.140974  [38400/70787]
loss: 0.087095  [44800/70787]
loss: 0.150773  [51200/70787]
loss: 0.078079  [57600/70787]
loss: 0.082755  [64000/70787]
loss: 0.089307  [70400/70787]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.087734 

Epoch 2
-------------------------------
loss: 0.162754  [    0/70787]
loss: 0.109640  [ 6400/70787]
loss: 0.058168  [12800/70787]
loss: 0.130719  [19200/70787]
loss: 0.097423  [25600/70787]
loss: 0.082252  [32000/70787]
loss: 0.066360  [38400/70787]
loss: 0.094587  [44800/70787]
loss: 0.048075  [51200/70787]
loss: 0.065334  [57600/70787]
loss: 0.021625  [64000/70787]
loss: 0.107759  [70400/70787]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.076235 

Epoch 3
-------------------------------
loss: 0.073570  [    0/70787]
loss: 0.132653  [ 6400/70787]
loss: 0.074692  [12800/70787]
loss: 0.202327  [19200/70787]
loss: 0.144216  [25600/70787]
loss: 0.087358  [32000/70787]
loss: 0.063657  [38400/70787]
loss: 0.081946  [44800/70787]
loss: 0.050244  [51200/70787]
loss: 0.112505  [57600/70787]
loss: 0.032069  [64000/70787]
loss: 0.049757  [70400/70787]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.072773 

Epoch 4
-------------------------------
loss: 0.046257  [    0/70787]
loss: 0.077826  [ 6400/70787]
loss: 0.112410  [12800/70787]
loss: 0.113335  [19200/70787]
loss: 0.114465  [25600/70787]
loss: 0.059914  [32000/70787]
loss: 0.116718  [38400/70787]
loss: 0.064088  [44800/70787]
loss: 0.096823  [51200/70787]
loss: 0.087877  [57600/70787]
loss: 0.050118  [64000/70787]
loss: 0.076402  [70400/70787]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.130238 

Epoch 5
-------------------------------
loss: 0.258087  [    0/70787]
loss: 0.080167  [ 6400/70787]
loss: 0.103143  [12800/70787]
loss: 0.026053  [19200/70787]
loss: 0.087734  [25600/70787]
loss: 0.234214  [32000/70787]
loss: 0.126132  [38400/70787]
loss: 0.061760  [44800/70787]
loss: 0.061100  [51200/70787]
loss: 0.093259  [57600/70787]
loss: 0.141583  [64000/70787]
loss: 0.117994  [70400/70787]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.101728 

Epoch 6
-------------------------------
loss: 0.169767  [    0/70787]
loss: 0.075431  [ 6400/70787]
loss: 0.052944  [12800/70787]
loss: 0.074936  [19200/70787]
loss: 0.018556  [25600/70787]
loss: 0.089564  [32000/70787]
loss: 0.029163  [38400/70787]
loss: 0.253626  [44800/70787]
loss: 0.049582  [51200/70787]
loss: 0.077417  [57600/70787]
loss: 0.082309  [64000/70787]
loss: 0.044685  [70400/70787]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.072113 

Epoch 7
-------------------------------
loss: 0.125703  [    0/70787]
loss: 0.054077  [ 6400/70787]
loss: 0.086265  [12800/70787]
loss: 0.085437  [19200/70787]
loss: 0.024395  [25600/70787]
loss: 0.037536  [32000/70787]
loss: 0.323208  [38400/70787]
loss: 0.046756  [44800/70787]
loss: 0.028708  [51200/70787]
loss: 0.025987  [57600/70787]
loss: 0.051678  [64000/70787]
loss: 0.062508  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.066792 

Epoch 8
-------------------------------
loss: 0.053673  [    0/70787]
loss: 0.064809  [ 6400/70787]
loss: 0.060974  [12800/70787]
loss: 0.056618  [19200/70787]
loss: 0.024058  [25600/70787]
loss: 0.072214  [32000/70787]
loss: 0.123203  [38400/70787]
loss: 0.157891  [57600/69247]
loss: 0.109407  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.158379 

Epoch 40
-------------------------------
loss: 0.133753  [    0/69247]
loss: 0.099327  [ 6400/69247]
loss: 0.155818  [12800/69247]
loss: 0.100030  [19200/69247]
loss: 0.206134  [25600/69247]
loss: 0.068259  [32000/69247]
loss: 0.133698  [38400/69247]
loss: 0.191134  [44800/69247]
loss: 0.148436  [51200/69247]
loss: 0.125725  [57600/69247]
loss: 0.205630  [64000/69247]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.158635 

Epoch 41
-------------------------------
loss: 0.118301  [    0/69247]
loss: 0.160923  [ 6400/69247]
loss: 0.143616  [12800/69247]
loss: 0.112806  [19200/69247]
loss: 0.145890  [25600/69247]
loss: 0.155675  [32000/69247]
loss: 0.106002  [38400/69247]
loss: 0.165339  [44800/69247]
loss: 0.151192  [51200/69247]
loss: 0.101774  [57600/69247]
loss: 0.086378  [64000/69247]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.155040 

Epoch 42
-------------------------------
loss: 0.129963  [    0/69247]
loss: 0.109449  [ 6400/69247]
loss: 0.074459  [12800/69247]
loss: 0.189569  [19200/69247]
loss: 0.199241  [25600/69247]
loss: 0.229987  [32000/69247]
loss: 0.157617  [38400/69247]
loss: 0.066491  [44800/69247]
loss: 0.195881  [51200/69247]
loss: 0.098969  [57600/69247]
loss: 0.185388  [64000/69247]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.156394 

Epoch 43
-------------------------------
loss: 0.166781  [    0/69247]
loss: 0.230678  [ 6400/69247]
loss: 0.103388  [12800/69247]
loss: 0.157718  [19200/69247]
loss: 0.124773  [25600/69247]
loss: 0.056660  [32000/69247]
loss: 0.248781  [38400/69247]
loss: 0.170327  [44800/69247]
loss: 0.079127  [51200/69247]
loss: 0.121157  [57600/69247]
loss: 0.079157  [64000/69247]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.152672 

Epoch 44
-------------------------------
loss: 0.234324  [    0/69247]
loss: 0.192781  [ 6400/69247]
loss: 0.133504  [12800/69247]
loss: 0.049176  [19200/69247]
loss: 0.067644  [25600/69247]
loss: 0.089246  [32000/69247]
loss: 0.110645  [38400/69247]
loss: 1.731569  [44800/69247]
loss: 0.067140  [51200/69247]
loss: 0.095726  [57600/69247]
loss: 0.118749  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.165139 

Epoch 45
-------------------------------
loss: 0.153698  [    0/69247]
loss: 0.166694  [ 6400/69247]
loss: 0.097452  [12800/69247]
loss: 0.125563  [19200/69247]
loss: 0.146757  [25600/69247]
loss: 0.062733  [32000/69247]
loss: 0.128394  [38400/69247]
loss: 0.092134  [44800/69247]
loss: 0.062972  [51200/69247]
loss: 0.160912  [57600/69247]
loss: 0.107592  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.159881 

Epoch 46
-------------------------------
loss: 0.140873  [    0/69247]
loss: 0.192296  [ 6400/69247]
loss: 0.122000  [12800/69247]
loss: 0.204041  [19200/69247]
loss: 0.143733  [25600/69247]
loss: 0.137101  [32000/69247]
loss: 0.275153  [38400/69247]
loss: 0.118810  [44800/69247]
loss: 0.083702  [51200/69247]
loss: 0.117351  [57600/69247]
loss: 0.084052  [64000/69247]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.154501 

Epoch 47
-------------------------------
loss: 0.142205  [    0/69247]
loss: 0.141361  [ 6400/69247]
loss: 0.121418  [12800/69247]
loss: 0.186436  [19200/69247]
loss: 0.126451  [25600/69247]
loss: 0.165835  [32000/69247]
loss: 0.102783  [38400/69247]
loss: 0.133923  [44800/69247]
loss: 0.287771  [51200/69247]
loss: 0.070145  [57600/69247]
loss: 0.057297  [64000/69247]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.153957 

Epoch 48
-------------------------------
loss: 0.082002  [    0/69247]
loss: 0.194273  [ 6400/69247]
loss: 0.127289  [12800/69247]
loss: 0.267590  [19200/69247]
loss: 0.076816  [25600/69247]
loss: 0.095474  [32000/69247]
loss: 0.183670  [38400/69247]
loss: 0.067149  [44800/69247]
loss: 0.107771  [51200/69247]
loss: 0.136258  [57600/69247]
loss: 0.096000  [64000/69247]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.154250 

Epoch 49
-------------------------------
loss: 0.112749  [    0/69247]
loss: 0.148940  [ 6400/69247]
loss: 0.151032  [12800/69247]
loss: 0.149653  [19200/69247]
loss: 0.254081  [25600/69247]
loss: 0.094677  [32000/69247]
loss: 0.127596  [38400/69247]
loss: 0.216437  [44800/69247]
loss: 1.718133  [51200/69247]
loss: 0.190699  [57600/69247]
loss: 0.168298  [64000/69247]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.171068 

Epoch 50
-------------------------------
loss: 0.104065  [    0/69247]
loss: 0.124618  [ 6400/69247]
loss: 0.116342  [12800/69247]
loss: 0.115260  [19200/69247]
loss: 0.054158  [25600/69247]
loss: 0.129356  [32000/69247]
loss: 0.107435  [38400/69247]
loss: 0.155634  [44800/69247]
loss: 0.131863  [51200/69247]
loss: 0.117791  [57600/69247]
loss: 0.149042  [64000/69247]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.168023 

Epoch 1
-------------------------------
loss: 0.747205  [    0/71333]
loss: 0.221968  [ 6400/71333]
loss: 0.127084  [12800/71333]
loss: 0.073306  [19200/71333]
loss: 1.824730  [25600/71333]
loss: 0.109456  [32000/71333]
loss: 0.133819  [38400/71333]
loss: 0.160255  [44800/71333]
loss: 0.087762  [51200/71333]
loss: 1.699423  [57600/71333]
loss: 0.045335  [64000/71333]
loss: 0.241455  [70400/71333]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.177869 

Epoch 2
-------------------------------
loss: 0.162649  [    0/71333]
loss: 0.113743  [ 6400/71333]
loss: 0.124750  [12800/71333]
loss: 0.135100  [19200/71333]
loss: 0.106632  [25600/71333]
loss: 0.110932  [32000/71333]
loss: 0.063303  [38400/71333]
loss: 0.080017  [44800/71333]
loss: 0.053144  [51200/71333]
loss: 0.077189  [57600/71333]
loss: 0.074986  [64000/71333]
loss: 0.153952  [70400/71333]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.154493 

Epoch 3
-------------------------------
loss: 0.105305  [    0/71333]
loss: 0.132703  [ 6400/71333]
loss: 0.104637  [12800/71333]
loss: 0.219473  [19200/71333]
loss: 0.087551  [25600/71333]
loss: 1.848838  [32000/71333]
loss: 0.073135  [38400/71333]
loss: 0.042155  [44800/71333]
loss: 0.100676  [51200/71333]
loss: 0.143785  [57600/71333]
loss: 0.076940  [64000/71333]
loss: 0.112169  [70400/71333]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.152322 

Epoch 4
-------------------------------
loss: 0.095488  [    0/71333]
loss: 0.044003  [ 6400/71333]
loss: 0.172034  [12800/71333]
loss: 0.101991  [19200/71333]
loss: 0.101465  [25600/71333]
loss: 0.088015  [32000/71333]
loss: 0.102576  [38400/71333]
loss: 0.127452  [44800/71333]
loss: 0.088222  [51200/71333]
loss: 0.091176  [57600/71333]
loss: 0.102583  [64000/71333]
loss: 0.060415  [70400/71333]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.153409 

Epoch 5
-------------------------------
loss: 0.049336  [    0/71333]
loss: 0.105656  [ 6400/71333]
loss: 0.122910  [12800/71333]
loss: 0.107248  [19200/71333]
loss: 0.021336  [25600/71333]
loss: 0.018570  [32000/71333]
loss: 0.055450  [38400/71333]
loss: 0.154867  [44800/71333]
loss: 0.061224  [51200/71333]
loss: 0.144004  [57600/71333]
loss: 0.066896  [64000/71333]
loss: 0.070195  [70400/71333]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.150156 

Epoch 6
-------------------------------
loss: 0.096411  [    0/71333]
loss: 0.051080  [ 6400/71333]
loss: 0.044674  [12800/71333]
loss: 0.037333  [19200/71333]
loss: 0.018040  [25600/71333]
loss: 0.038374  [32000/71333]
loss: 0.059298  [38400/71333]
loss: 0.093250  [44800/71333]
loss: 0.240152  [51200/71333]
loss: 0.062786  [57600/71333]
loss: 0.228990  [64000/71333]
loss: 1.588990  [70400/71333]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.146199 

Epoch 7
-------------------------------
loss: 0.025086  [    0/71333]
loss: 0.050536  [ 6400/71333]
loss: 0.036917  [12800/71333]
loss: 0.089296  [19200/71333]
loss: 0.055942  [25600/71333]
loss: 0.100813  [32000/71333]
loss: 0.033667  [38400/71333]
loss: 0.024723  [44800/71333]
loss: 0.115143  [51200/71333]
loss: 0.103620  [57600/71333]
loss: 0.106890  [64000/71333]
loss: 0.064281  [70400/71333]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.157279 

Epoch 8
-------------------------------
loss: 0.174014  [    0/71333]
loss: 0.113107  [ 6400/71333]
loss: 0.027410  [12800/71333]
loss: 0.045944  [19200/71333]
loss: 0.107025  [25600/71333]
loss: 0.037426  [32000/71333]
loss: 0.103444  [38400/71333]
loss: 0.129548  [57600/69398]
loss: 0.110915  [64000/69398]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.168050 

Epoch 40
-------------------------------
loss: 0.115602  [    0/69398]
loss: 0.116194  [ 6400/69398]
loss: 0.098966  [12800/69398]
loss: 0.110284  [19200/69398]
loss: 0.143882  [25600/69398]
loss: 0.082495  [32000/69398]
loss: 0.099000  [38400/69398]
loss: 0.149731  [44800/69398]
loss: 0.055381  [51200/69398]
loss: 0.112158  [57600/69398]
loss: 0.112570  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.156968 

Epoch 41
-------------------------------
loss: 0.121652  [    0/69398]
loss: 0.151832  [ 6400/69398]
loss: 1.675280  [12800/69398]
loss: 0.219030  [19200/69398]
loss: 0.478815  [25600/69398]
loss: 0.213915  [32000/69398]
loss: 0.153335  [38400/69398]
loss: 0.141641  [44800/69398]
loss: 0.291975  [51200/69398]
loss: 0.107433  [57600/69398]
loss: 0.244654  [64000/69398]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.150755 

Epoch 42
-------------------------------
loss: 0.081832  [    0/69398]
loss: 0.140118  [ 6400/69398]
loss: 0.147941  [12800/69398]
loss: 0.223875  [19200/69398]
loss: 0.206983  [25600/69398]
loss: 0.169651  [32000/69398]
loss: 0.020736  [38400/69398]
loss: 1.818079  [44800/69398]
loss: 0.125447  [51200/69398]
loss: 0.093989  [57600/69398]
loss: 0.181496  [64000/69398]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.170416 

Epoch 43
-------------------------------
loss: 0.108416  [    0/69398]
loss: 0.198479  [ 6400/69398]
loss: 0.136271  [12800/69398]
loss: 0.082410  [19200/69398]
loss: 0.036545  [25600/69398]
loss: 0.106634  [32000/69398]
loss: 0.052543  [38400/69398]
loss: 0.186830  [44800/69398]
loss: 0.072226  [51200/69398]
loss: 0.114887  [57600/69398]
loss: 0.067994  [64000/69398]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.149058 

Epoch 44
-------------------------------
loss: 0.138116  [    0/69398]
loss: 0.211704  [ 6400/69398]
loss: 0.054470  [12800/69398]
loss: 0.092217  [19200/69398]
loss: 0.150853  [25600/69398]
loss: 0.218708  [32000/69398]
loss: 0.113341  [38400/69398]
loss: 0.124115  [44800/69398]
loss: 0.180457  [51200/69398]
loss: 0.073125  [57600/69398]
loss: 0.084676  [64000/69398]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.150683 

Epoch 45
-------------------------------
loss: 0.078787  [    0/69398]
loss: 0.138926  [ 6400/69398]
loss: 0.110731  [12800/69398]
loss: 0.226408  [19200/69398]
loss: 0.158555  [25600/69398]
loss: 0.088065  [32000/69398]
loss: 0.149790  [38400/69398]
loss: 0.109641  [44800/69398]
loss: 0.090741  [51200/69398]
loss: 0.203779  [57600/69398]
loss: 0.134593  [64000/69398]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.161748 

Epoch 46
-------------------------------
loss: 0.214227  [    0/69398]
loss: 0.164774  [ 6400/69398]
loss: 0.071279  [12800/69398]
loss: 0.074129  [19200/69398]
loss: 0.068370  [25600/69398]
loss: 0.070912  [32000/69398]
loss: 0.144904  [38400/69398]
loss: 0.181893  [44800/69398]
loss: 0.106249  [51200/69398]
loss: 0.104457  [57600/69398]
loss: 1.660267  [64000/69398]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.168126 

Epoch 47
-------------------------------
loss: 0.207225  [    0/69398]
loss: 0.177246  [ 6400/69398]
loss: 0.188661  [12800/69398]
loss: 0.181104  [19200/69398]
loss: 0.128148  [25600/69398]
loss: 0.109776  [32000/69398]
loss: 0.095718  [38400/69398]
loss: 0.115970  [44800/69398]
loss: 0.226037  [51200/69398]
loss: 0.248767  [57600/69398]
loss: 0.121323  [64000/69398]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.162842 

Epoch 48
-------------------------------
loss: 0.189781  [    0/69398]
loss: 0.192981  [ 6400/69398]
loss: 0.294981  [12800/69398]
loss: 0.123575  [19200/69398]
loss: 0.161459  [25600/69398]
loss: 0.055245  [32000/69398]
loss: 0.161737  [38400/69398]
loss: 0.301306  [44800/69398]
loss: 0.122111  [51200/69398]
loss: 0.282382  [57600/69398]
loss: 0.048471  [64000/69398]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.158157 

Epoch 49
-------------------------------
loss: 0.084342  [    0/69398]
loss: 0.204054  [ 6400/69398]
loss: 0.127607  [12800/69398]
loss: 0.190702  [19200/69398]
loss: 0.114839  [25600/69398]
loss: 0.215499  [32000/69398]
loss: 0.099626  [38400/69398]
loss: 0.176191  [44800/69398]
loss: 0.178182  [51200/69398]
loss: 0.159981  [57600/69398]
loss: 0.110363  [64000/69398]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.156615 

Epoch 50
-------------------------------
loss: 0.178098  [    0/69398]
loss: 0.081751  [ 6400/69398]
loss: 0.146401  [12800/69398]
loss: 0.230029  [19200/69398]
loss: 0.362149  [25600/69398]
loss: 0.178841  [32000/69398]
loss: 0.201790  [38400/69398]
loss: 0.104401  [44800/69398]
loss: 0.181145  [51200/69398]
loss: 0.121045  [57600/69398]
loss: 0.115672  [64000/69398]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.154790 

Epoch 1
-------------------------------
loss: 0.746518  [    0/69874]
loss: 0.469169  [ 6400/69874]
loss: 0.226662  [12800/69874]
loss: 0.198712  [19200/69874]
loss: 0.216404  [25600/69874]
loss: 0.206937  [32000/69874]
loss: 0.141642  [38400/69874]
loss: 0.154744  [44800/69874]
loss: 0.278479  [51200/69874]
loss: 0.230618  [57600/69874]
loss: 0.316167  [64000/69874]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.191730 

Epoch 2
-------------------------------
loss: 0.094305  [    0/69874]
loss: 0.215198  [ 6400/69874]
loss: 0.253406  [12800/69874]
loss: 0.135534  [19200/69874]
loss: 0.273297  [25600/69874]
loss: 0.132546  [32000/69874]
loss: 0.290693  [38400/69874]
loss: 0.371456  [44800/69874]
loss: 0.212246  [51200/69874]
loss: 0.123308  [57600/69874]
loss: 0.094819  [64000/69874]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177712 

Epoch 3
-------------------------------
loss: 0.135431  [    0/69874]
loss: 0.061490  [ 6400/69874]
loss: 0.160106  [12800/69874]
loss: 0.225560  [19200/69874]
loss: 0.132870  [25600/69874]
loss: 0.189237  [32000/69874]
loss: 0.254558  [38400/69874]
loss: 0.107484  [44800/69874]
loss: 0.144461  [51200/69874]
loss: 0.054174  [57600/69874]
loss: 0.207496  [64000/69874]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.167864 

Epoch 4
-------------------------------
loss: 0.163044  [    0/69874]
loss: 0.108045  [ 6400/69874]
loss: 0.157352  [12800/69874]
loss: 0.202075  [19200/69874]
loss: 0.158316  [25600/69874]
loss: 0.231703  [32000/69874]
loss: 0.143213  [38400/69874]
loss: 0.232328  [44800/69874]
loss: 0.241747  [51200/69874]
loss: 0.147075  [57600/69874]
loss: 0.169887  [64000/69874]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.164033 

Epoch 5
-------------------------------
loss: 0.162244  [    0/69874]
loss: 0.181655  [ 6400/69874]
loss: 0.092110  [12800/69874]
loss: 0.184390  [19200/69874]
loss: 0.124433  [25600/69874]
loss: 0.193525  [32000/69874]
loss: 0.224393  [38400/69874]
loss: 0.193134  [44800/69874]
loss: 0.109750  [51200/69874]
loss: 0.139355  [57600/69874]
loss: 0.146910  [64000/69874]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.162004 

Epoch 6
-------------------------------
loss: 0.140556  [    0/69874]
loss: 0.101466  [ 6400/69874]
loss: 0.092242  [12800/69874]
loss: 0.231826  [19200/69874]
loss: 0.195847  [25600/69874]
loss: 0.248362  [32000/69874]
loss: 0.159672  [38400/69874]
loss: 0.137820  [44800/69874]
loss: 0.195556  [51200/69874]
loss: 0.204820  [57600/69874]
loss: 0.109422  [64000/69874]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.154156 

Epoch 7
-------------------------------
loss: 0.267430  [    0/69874]
loss: 0.119281  [ 6400/69874]
loss: 0.236415  [12800/69874]
loss: 0.276691  [19200/69874]
loss: 0.130264  [25600/69874]
loss: 0.081859  [32000/69874]
loss: 0.204602  [38400/69874]
loss: 0.187074  [44800/69874]
loss: 0.142644  [51200/69874]
loss: 0.322670  [57600/69874]
loss: 0.132830  [64000/69874]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.154557 

Epoch 8
-------------------------------
loss: 0.115190  [    0/69874]
loss: 0.077083  [ 6400/69874]
loss: 0.072155  [12800/69874]
loss: 0.100097  [19200/69874]
loss: 0.110663  [25600/69874]
loss: 0.089444  [32000/69874]
loss: 0.190804  [38400/69874]
loss: 0.323673  [44800/69874]
loss: 0.163016  [51200/69874]
loss: 0.235397  [57600/69874]
loss: 0.205686  [64000/69874]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.158185 

Epoch 9
-------------------------------
loss: 0.040173  [ 6400/70535]
loss: 0.052318  [12800/70535]
loss: 0.033210  [19200/70535]
loss: 0.134197  [25600/70535]
loss: 0.046478  [32000/70535]
loss: 0.109659  [38400/70535]
loss: 0.018230  [44800/70535]
loss: 0.098722  [51200/70535]
loss: 0.116232  [57600/70535]
loss: 0.025554  [64000/70535]
loss: 0.107084  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119067 

Epoch 38
-------------------------------
loss: 0.148575  [    0/70535]
loss: 0.151570  [ 6400/70535]
loss: 0.064799  [12800/70535]
loss: 0.058415  [19200/70535]
loss: 0.019360  [25600/70535]
loss: 0.048275  [32000/70535]
loss: 0.152477  [38400/70535]
loss: 0.076912  [44800/70535]
loss: 0.067328  [51200/70535]
loss: 0.109796  [57600/70535]
loss: 0.058175  [64000/70535]
loss: 0.029338  [70400/70535]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.132671 

Epoch 39
-------------------------------
loss: 0.071133  [    0/70535]
loss: 0.094618  [ 6400/70535]
loss: 0.045037  [12800/70535]
loss: 0.063376  [19200/70535]
loss: 0.118402  [25600/70535]
loss: 0.117826  [32000/70535]
loss: 0.127123  [38400/70535]
loss: 0.068968  [44800/70535]
loss: 0.062048  [51200/70535]
loss: 0.066015  [57600/70535]
loss: 0.018476  [64000/70535]
loss: 0.065856  [70400/70535]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.124310 

Epoch 40
-------------------------------
loss: 0.060432  [    0/70535]
loss: 0.115237  [ 6400/70535]
loss: 0.101194  [12800/70535]
loss: 0.070711  [19200/70535]
loss: 0.116984  [25600/70535]
loss: 0.153012  [32000/70535]
loss: 0.100494  [38400/70535]
loss: 0.063823  [44800/70535]
loss: 0.075736  [51200/70535]
loss: 0.095862  [57600/70535]
loss: 0.097107  [64000/70535]
loss: 0.284007  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.122902 

Epoch 41
-------------------------------
loss: 0.106344  [    0/70535]
loss: 0.125132  [ 6400/70535]
loss: 0.024530  [12800/70535]
loss: 0.023101  [19200/70535]
loss: 0.014559  [25600/70535]
loss: 0.056716  [32000/70535]
loss: 0.055831  [38400/70535]
loss: 0.030213  [44800/70535]
loss: 0.070460  [51200/70535]
loss: 0.070559  [57600/70535]
loss: 0.179502  [64000/70535]
loss: 0.106145  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.123956 

Epoch 42
-------------------------------
loss: 0.072558  [    0/70535]
loss: 0.038634  [ 6400/70535]
loss: 0.035544  [12800/70535]
loss: 0.053739  [19200/70535]
loss: 0.043027  [25600/70535]
loss: 0.096515  [32000/70535]
loss: 0.080874  [38400/70535]
loss: 0.029118  [44800/70535]
loss: 0.041941  [51200/70535]
loss: 0.104578  [57600/70535]
loss: 0.057358  [64000/70535]
loss: 0.077266  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.128792 

Epoch 43
-------------------------------
loss: 0.128250  [    0/70535]
loss: 0.055765  [ 6400/70535]
loss: 0.167376  [12800/70535]
loss: 0.009581  [19200/70535]
loss: 0.041250  [25600/70535]
loss: 0.018111  [32000/70535]
loss: 0.266855  [38400/70535]
loss: 0.121056  [44800/70535]
loss: 0.169035  [51200/70535]
loss: 0.068219  [57600/70535]
loss: 0.043178  [64000/70535]
loss: 0.114930  [70400/70535]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.145802 

Epoch 44
-------------------------------
loss: 0.062850  [    0/70535]
loss: 0.054630  [ 6400/70535]
loss: 0.047661  [12800/70535]
loss: 0.074521  [19200/70535]
loss: 0.136242  [25600/70535]
loss: 0.138304  [32000/70535]
loss: 0.043734  [38400/70535]
loss: 0.062336  [44800/70535]
loss: 1.654149  [51200/70535]
loss: 0.114639  [57600/70535]
loss: 0.120738  [64000/70535]
loss: 0.029724  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.122039 

Epoch 45
-------------------------------
loss: 0.078350  [    0/70535]
loss: 0.157915  [ 6400/70535]
loss: 0.058803  [12800/70535]
loss: 0.048833  [19200/70535]
loss: 0.029868  [25600/70535]
loss: 0.038777  [32000/70535]
loss: 0.223615  [38400/70535]
loss: 0.046450  [44800/70535]
loss: 0.092179  [51200/70535]
loss: 0.068469  [57600/70535]
loss: 0.052153  [64000/70535]
loss: 0.077036  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.121445 

Epoch 46
-------------------------------
loss: 0.086693  [    0/70535]
loss: 0.065723  [ 6400/70535]
loss: 0.090163  [12800/70535]
loss: 0.175112  [19200/70535]
loss: 0.086716  [25600/70535]
loss: 0.084449  [32000/70535]
loss: 1.635132  [38400/70535]
loss: 0.074692  [44800/70535]
loss: 0.077292  [51200/70535]
loss: 0.030967  [57600/70535]
loss: 0.077606  [64000/70535]
loss: 0.053113  [70400/70535]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.120943 

Epoch 47
-------------------------------
loss: 0.065775  [    0/70535]
loss: 0.056141  [ 6400/70535]
loss: 0.036814  [12800/70535]
loss: 0.019530  [19200/70535]
loss: 0.034009  [25600/70535]
loss: 0.086387  [32000/70535]
loss: 0.146210  [38400/70535]
loss: 0.132464  [44800/70535]
loss: 0.046402  [51200/70535]
loss: 0.070666  [57600/70535]
loss: 0.191890  [64000/70535]
loss: 0.023505  [70400/70535]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.120909 

Epoch 48
-------------------------------
loss: 0.017031  [    0/70535]
loss: 0.066652  [ 6400/70535]
loss: 0.109230  [12800/70535]
loss: 0.067243  [19200/70535]
loss: 0.101254  [25600/70535]
loss: 0.086052  [32000/70535]
loss: 0.008121  [38400/70535]
loss: 0.088879  [44800/70535]
loss: 0.029481  [51200/70535]
loss: 0.054925  [57600/70535]
loss: 0.063258  [64000/70535]
loss: 0.039373  [70400/70535]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.131032 

Epoch 49
-------------------------------
loss: 0.033828  [    0/70535]
loss: 0.086425  [ 6400/70535]
loss: 0.055412  [12800/70535]
loss: 0.089599  [19200/70535]
loss: 0.120025  [25600/70535]
loss: 0.024548  [32000/70535]
loss: 0.037088  [38400/70535]
loss: 0.085661  [44800/70535]
loss: 0.148986  [51200/70535]
loss: 0.047180  [57600/70535]
loss: 0.059183  [64000/70535]
loss: 0.051929  [70400/70535]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.126330 

Epoch 50
-------------------------------
loss: 0.012717  [    0/70535]
loss: 0.111114  [ 6400/70535]
loss: 0.046899  [12800/70535]
loss: 0.074247  [19200/70535]
loss: 0.068916  [25600/70535]
loss: 0.076811  [32000/70535]
loss: 0.093256  [38400/70535]
loss: 0.024170  [44800/70535]
loss: 0.093059  [51200/70535]
loss: 0.018664  [57600/70535]
loss: 0.190377  [64000/70535]
loss: 0.036888  [70400/70535]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.138645 

Epoch 1
-------------------------------
loss: 0.772742  [    0/69845]
loss: 0.258253  [ 6400/69845]
loss: 0.319216  [12800/69845]
loss: 0.263154  [19200/69845]
loss: 0.210597  [25600/69845]
loss: 0.241561  [32000/69845]
loss: 0.195485  [38400/69845]
loss: 0.199021  [44800/69845]
loss: 0.254005  [51200/69845]
loss: 0.146065  [57600/69845]
loss: 0.244728  [64000/69845]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.200951 

Epoch 2
-------------------------------
loss: 0.328982  [    0/69845]
loss: 0.182351  [ 6400/69845]
loss: 0.153968  [12800/69845]
loss: 0.088434  [19200/69845]
loss: 0.091406  [25600/69845]
loss: 0.237035  [32000/69845]
loss: 0.193840  [38400/69845]
loss: 0.242864  [44800/69845]
loss: 0.158239  [51200/69845]
loss: 0.133544  [57600/69845]
loss: 0.143086  [64000/69845]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174441 

Epoch 3
-------------------------------
loss: 0.103494  [    0/69845]
loss: 0.131503  [ 6400/69845]
loss: 0.144257  [12800/69845]
loss: 0.271005  [19200/69845]
loss: 0.127186  [25600/69845]
loss: 0.262357  [32000/69845]
loss: 0.199985  [38400/69845]
loss: 0.136961  [44800/69845]
loss: 0.129974  [51200/69845]
loss: 0.103578  [57600/69845]
loss: 0.097947  [64000/69845]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.168494 

Epoch 4
-------------------------------
loss: 0.096432  [    0/69845]
loss: 0.185694  [ 6400/69845]
loss: 0.160763  [12800/69845]
loss: 0.173856  [19200/69845]
loss: 0.107930  [25600/69845]
loss: 0.065486  [32000/69845]
loss: 0.090645  [38400/69845]
loss: 0.233046  [44800/69845]
loss: 0.242387  [51200/69845]
loss: 0.145416  [57600/69845]
loss: 0.174233  [64000/69845]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.165442 

Epoch 5
-------------------------------
loss: 0.164204  [    0/69845]
loss: 0.252292  [ 6400/69845]
loss: 0.093692  [12800/69845]
loss: 0.076279  [19200/69845]
loss: 0.060246  [25600/69845]
loss: 0.129879  [32000/69845]
loss: 0.081639  [57600/69812]
loss: 0.083745  [64000/69812]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083150 

Epoch 40
-------------------------------
loss: 0.053456  [    0/69812]
loss: 0.056680  [ 6400/69812]
loss: 0.124312  [12800/69812]
loss: 0.151404  [19200/69812]
loss: 0.127195  [25600/69812]
loss: 0.053088  [32000/69812]
loss: 0.059733  [38400/69812]
loss: 0.048122  [44800/69812]
loss: 0.026130  [51200/69812]
loss: 0.091567  [57600/69812]
loss: 0.067839  [64000/69812]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.090512 

Epoch 41
-------------------------------
loss: 0.075472  [    0/69812]
loss: 0.099155  [ 6400/69812]
loss: 0.059214  [12800/69812]
loss: 0.007566  [19200/69812]
loss: 0.089129  [25600/69812]
loss: 0.107327  [32000/69812]
loss: 0.038253  [38400/69812]
loss: 0.106517  [44800/69812]
loss: 0.040016  [51200/69812]
loss: 0.025390  [57600/69812]
loss: 0.036386  [64000/69812]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.095525 

Epoch 42
-------------------------------
loss: 0.044683  [    0/69812]
loss: 0.036213  [ 6400/69812]
loss: 0.088657  [12800/69812]
loss: 0.101874  [19200/69812]
loss: 0.006087  [25600/69812]
loss: 0.164258  [32000/69812]
loss: 0.099336  [38400/69812]
loss: 0.052401  [44800/69812]
loss: 0.040451  [51200/69812]
loss: 0.054435  [57600/69812]
loss: 0.075654  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089277 

Epoch 43
-------------------------------
loss: 0.074628  [    0/69812]
loss: 0.011750  [ 6400/69812]
loss: 0.102265  [12800/69812]
loss: 0.063343  [19200/69812]
loss: 0.060936  [25600/69812]
loss: 0.094271  [32000/69812]
loss: 0.103866  [38400/69812]
loss: 0.028289  [44800/69812]
loss: 0.073317  [51200/69812]
loss: 0.128513  [57600/69812]
loss: 0.031853  [64000/69812]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.087247 

Epoch 44
-------------------------------
loss: 0.128171  [    0/69812]
loss: 0.079210  [ 6400/69812]
loss: 0.071195  [12800/69812]
loss: 0.039683  [19200/69812]
loss: 0.007648  [25600/69812]
loss: 0.090061  [32000/69812]
loss: 0.056871  [38400/69812]
loss: 0.122352  [44800/69812]
loss: 0.059463  [51200/69812]
loss: 0.090374  [57600/69812]
loss: 0.145561  [64000/69812]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.093833 

Epoch 45
-------------------------------
loss: 0.036986  [    0/69812]
loss: 0.030191  [ 6400/69812]
loss: 0.047753  [12800/69812]
loss: 0.071526  [19200/69812]
loss: 0.065522  [25600/69812]
loss: 0.102358  [32000/69812]
loss: 0.135198  [38400/69812]
loss: 0.023607  [44800/69812]
loss: 0.058156  [51200/69812]
loss: 0.062549  [57600/69812]
loss: 0.107745  [64000/69812]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.100322 

Epoch 46
-------------------------------
loss: 0.024958  [    0/69812]
loss: 0.036874  [ 6400/69812]
loss: 0.168242  [12800/69812]
loss: 0.018425  [19200/69812]
loss: 0.069002  [25600/69812]
loss: 0.041706  [32000/69812]
loss: 0.091201  [38400/69812]
loss: 0.029093  [44800/69812]
loss: 0.070200  [51200/69812]
loss: 0.065137  [57600/69812]
loss: 0.121994  [64000/69812]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.095478 

Epoch 47
-------------------------------
loss: 0.080143  [    0/69812]
loss: 0.077833  [ 6400/69812]
loss: 0.029071  [12800/69812]
loss: 0.069794  [19200/69812]
loss: 0.081245  [25600/69812]
loss: 0.013572  [32000/69812]
loss: 0.046632  [38400/69812]
loss: 0.079479  [44800/69812]
loss: 0.040879  [51200/69812]
loss: 0.024121  [57600/69812]
loss: 0.011171  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.090767 

Epoch 48
-------------------------------
loss: 0.097371  [    0/69812]
loss: 0.035540  [ 6400/69812]
loss: 0.141905  [12800/69812]
loss: 0.039437  [19200/69812]
loss: 0.021917  [25600/69812]
loss: 0.147008  [32000/69812]
loss: 0.060067  [38400/69812]
loss: 0.060063  [44800/69812]
loss: 0.081913  [51200/69812]
loss: 0.053434  [57600/69812]
loss: 0.038770  [64000/69812]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.097474 

Epoch 49
-------------------------------
loss: 0.006459  [    0/69812]
loss: 0.040664  [ 6400/69812]
loss: 0.116825  [12800/69812]
loss: 0.025283  [19200/69812]
loss: 0.050301  [25600/69812]
loss: 0.059705  [32000/69812]
loss: 0.182074  [38400/69812]
loss: 0.023772  [44800/69812]
loss: 0.035014  [51200/69812]
loss: 0.080061  [57600/69812]
loss: 0.236392  [64000/69812]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.091455 

Epoch 50
-------------------------------
loss: 0.052313  [    0/69812]
loss: 0.104115  [ 6400/69812]
loss: 0.082832  [12800/69812]
loss: 0.087612  [19200/69812]
loss: 0.154344  [25600/69812]
loss: 0.089342  [32000/69812]
loss: 0.089312  [38400/69812]
loss: 0.053257  [44800/69812]
loss: 0.043105  [51200/69812]
loss: 0.059381  [57600/69812]
loss: 0.174195  [64000/69812]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.095691 

Epoch 1
-------------------------------
loss: 0.772777  [    0/70247]
loss: 0.094539  [ 6400/70247]
loss: 0.117747  [12800/70247]
loss: 0.079255  [19200/70247]
loss: 0.153069  [25600/70247]
loss: 0.079844  [32000/70247]
loss: 0.065938  [38400/70247]
loss: 0.039591  [44800/70247]
loss: 0.099936  [51200/70247]
loss: 0.101447  [57600/70247]
loss: 0.121037  [64000/70247]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.079155 

Epoch 2
-------------------------------
loss: 0.054365  [    0/70247]
loss: 0.055071  [ 6400/70247]
loss: 0.089223  [12800/70247]
loss: 0.065411  [19200/70247]
loss: 0.134525  [25600/70247]
loss: 0.057566  [32000/70247]
loss: 0.135076  [38400/70247]
loss: 0.071321  [44800/70247]
loss: 0.029370  [51200/70247]
loss: 0.051293  [57600/70247]
loss: 0.093943  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.066615 

Epoch 3
-------------------------------
loss: 0.061858  [    0/70247]
loss: 0.101159  [ 6400/70247]
loss: 0.063070  [12800/70247]
loss: 0.047398  [19200/70247]
loss: 0.079394  [25600/70247]
loss: 0.080102  [32000/70247]
loss: 0.099675  [38400/70247]
loss: 0.097041  [44800/70247]
loss: 0.076995  [51200/70247]
loss: 0.033551  [57600/70247]
loss: 0.063484  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.065139 

Epoch 4
-------------------------------
loss: 0.108513  [    0/70247]
loss: 0.061733  [ 6400/70247]
loss: 0.152744  [12800/70247]
loss: 0.046714  [19200/70247]
loss: 0.091686  [25600/70247]
loss: 0.165667  [32000/70247]
loss: 0.079594  [38400/70247]
loss: 0.223288  [44800/70247]
loss: 0.034258  [51200/70247]
loss: 0.018531  [57600/70247]
loss: 0.038306  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.067215 

Epoch 5
-------------------------------
loss: 0.058670  [    0/70247]
loss: 0.055836  [ 6400/70247]
loss: 0.087967  [12800/70247]
loss: 0.106149  [19200/70247]
loss: 0.094231  [25600/70247]
loss: 0.038138  [32000/70247]
loss: 0.019848  [38400/70247]
loss: 0.056697  [44800/70247]
loss: 0.146258  [51200/70247]
loss: 0.144851  [57600/70247]
loss: 0.090748  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.066082 

Epoch 6
-------------------------------
loss: 0.087794  [    0/70247]
loss: 0.008358  [ 6400/70247]
loss: 0.029179  [12800/70247]
loss: 0.060017  [19200/70247]
loss: 0.067143  [25600/70247]
loss: 0.053984  [32000/70247]
loss: 0.085253  [38400/70247]
loss: 0.143595  [44800/70247]
loss: 0.110906  [51200/70247]
loss: 0.091769  [57600/70247]
loss: 0.077940  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.059055 

Epoch 7
-------------------------------
loss: 0.163629  [    0/70247]
loss: 0.072275  [ 6400/70247]
loss: 0.124921  [12800/70247]
loss: 0.079073  [19200/70247]
loss: 0.052976  [25600/70247]
loss: 0.067672  [32000/70247]
loss: 0.054265  [38400/70247]
loss: 0.093589  [44800/70247]
loss: 0.053811  [51200/70247]
loss: 0.096729  [57600/70247]
loss: 0.041274  [64000/70247]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.059377 

Epoch 8
-------------------------------
loss: 0.104125  [    0/70247]
loss: 0.062461  [ 6400/70247]
loss: 0.082778  [12800/70247]
loss: 0.018578  [19200/70247]
loss: 0.097212  [25600/70247]
loss: 0.179672  [32000/70247]
loss: 0.074904  [38400/70247]
loss: 0.079974  [44800/70247]
loss: 0.041435  [51200/70247]
loss: 0.072657  [57600/70247]
loss: 0.005001  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.072554 

Epoch 9
-------------------------------
loss: 0.071269  [57600/70165]
loss: 0.033637  [64000/70165]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084666 

Epoch 40
-------------------------------
loss: 0.043184  [    0/70165]
loss: 0.003401  [ 6400/70165]
loss: 0.095201  [12800/70165]
loss: 0.027759  [19200/70165]
loss: 0.075774  [25600/70165]
loss: 0.057210  [32000/70165]
loss: 0.042887  [38400/70165]
loss: 0.103591  [44800/70165]
loss: 0.017943  [51200/70165]
loss: 0.034053  [57600/70165]
loss: 0.115937  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082906 

Epoch 41
-------------------------------
loss: 0.091675  [    0/70165]
loss: 0.051908  [ 6400/70165]
loss: 0.132886  [12800/70165]
loss: 0.015154  [19200/70165]
loss: 0.121970  [25600/70165]
loss: 0.045574  [32000/70165]
loss: 0.020109  [38400/70165]
loss: 0.075849  [44800/70165]
loss: 0.075143  [51200/70165]
loss: 0.050723  [57600/70165]
loss: 0.049154  [64000/70165]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085456 

Epoch 42
-------------------------------
loss: 0.026673  [    0/70165]
loss: 0.020046  [ 6400/70165]
loss: 0.056954  [12800/70165]
loss: 0.043442  [19200/70165]
loss: 0.030915  [25600/70165]
loss: 0.141471  [32000/70165]
loss: 0.038656  [38400/70165]
loss: 0.051936  [44800/70165]
loss: 0.011422  [51200/70165]
loss: 0.048117  [57600/70165]
loss: 0.058514  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.078783 

Epoch 43
-------------------------------
loss: 0.092478  [    0/70165]
loss: 0.034378  [ 6400/70165]
loss: 0.044917  [12800/70165]
loss: 0.012718  [19200/70165]
loss: 0.109098  [25600/70165]
loss: 0.051710  [32000/70165]
loss: 0.055524  [38400/70165]
loss: 0.055010  [44800/70165]
loss: 0.042834  [51200/70165]
loss: 0.127187  [57600/70165]
loss: 0.131943  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081300 

Epoch 44
-------------------------------
loss: 0.031415  [    0/70165]
loss: 0.047595  [ 6400/70165]
loss: 0.022676  [12800/70165]
loss: 0.014969  [19200/70165]
loss: 0.053942  [25600/70165]
loss: 0.071237  [32000/70165]
loss: 0.117346  [38400/70165]
loss: 0.033520  [44800/70165]
loss: 0.031847  [51200/70165]
loss: 0.021141  [57600/70165]
loss: 0.076635  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.087306 

Epoch 45
-------------------------------
loss: 0.032237  [    0/70165]
loss: 0.085757  [ 6400/70165]
loss: 0.032777  [12800/70165]
loss: 0.060675  [19200/70165]
loss: 0.033953  [25600/70165]
loss: 0.039152  [32000/70165]
loss: 0.248423  [38400/70165]
loss: 0.036184  [44800/70165]
loss: 0.076958  [51200/70165]
loss: 0.033182  [57600/70165]
loss: 0.008298  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.083082 

Epoch 46
-------------------------------
loss: 0.041700  [    0/70165]
loss: 0.026706  [ 6400/70165]
loss: 0.054610  [12800/70165]
loss: 0.021769  [19200/70165]
loss: 0.019442  [25600/70165]
loss: 0.063428  [32000/70165]
loss: 0.069041  [38400/70165]
loss: 0.069573  [44800/70165]
loss: 0.048430  [51200/70165]
loss: 0.032088  [57600/70165]
loss: 0.040163  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082515 

Epoch 47
-------------------------------
loss: 0.097613  [    0/70165]
loss: 0.038182  [ 6400/70165]
loss: 0.051152  [12800/70165]
loss: 0.049158  [19200/70165]
loss: 0.060323  [25600/70165]
loss: 0.017678  [32000/70165]
loss: 0.020433  [38400/70165]
loss: 0.150728  [44800/70165]
loss: 0.031515  [51200/70165]
loss: 0.103519  [57600/70165]
loss: 0.030927  [64000/70165]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.085226 

Epoch 48
-------------------------------
loss: 0.042144  [    0/70165]
loss: 0.074696  [ 6400/70165]
loss: 0.015287  [12800/70165]
loss: 0.035186  [19200/70165]
loss: 0.072746  [25600/70165]
loss: 0.186402  [32000/70165]
loss: 0.125302  [38400/70165]
loss: 0.046922  [44800/70165]
loss: 0.026336  [51200/70165]
loss: 0.078456  [57600/70165]
loss: 0.049385  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086100 

Epoch 49
-------------------------------
loss: 0.141932  [    0/70165]
loss: 0.021872  [ 6400/70165]
loss: 0.045845  [12800/70165]
loss: 0.050945  [19200/70165]
loss: 0.123233  [25600/70165]
loss: 0.058988  [32000/70165]
loss: 0.094897  [38400/70165]
loss: 0.103698  [44800/70165]
loss: 0.020744  [51200/70165]
loss: 0.030016  [57600/70165]
loss: 0.049867  [64000/70165]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.084646 

Epoch 50
-------------------------------
loss: 0.058210  [    0/70165]
loss: 0.064235  [ 6400/70165]
loss: 0.013459  [12800/70165]
loss: 0.069070  [19200/70165]
loss: 0.019919  [25600/70165]
loss: 0.035783  [32000/70165]
loss: 0.154293  [38400/70165]
loss: 0.065054  [44800/70165]
loss: 0.049496  [51200/70165]
loss: 0.146878  [57600/70165]
loss: 0.017074  [64000/70165]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.085083 

Epoch 1
-------------------------------
loss: 0.712719  [    0/72298]
loss: 0.079950  [ 6400/72298]
loss: 0.039486  [12800/72298]
loss: 0.068933  [19200/72298]
loss: 0.041416  [25600/72298]
loss: 0.056021  [32000/72298]
loss: 0.035361  [38400/72298]
loss: 0.017455  [44800/72298]
loss: 0.073623  [51200/72298]
loss: 0.045736  [57600/72298]
loss: 0.062206  [64000/72298]
loss: 0.042831  [70400/72298]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.064685 

Epoch 2
-------------------------------
loss: 0.054781  [    0/72298]
loss: 0.039064  [ 6400/72298]
loss: 0.115271  [12800/72298]
loss: 0.022847  [19200/72298]
loss: 0.045356  [25600/72298]
loss: 0.034743  [32000/72298]
loss: 0.057380  [38400/72298]
loss: 0.135630  [44800/72298]
loss: 0.044562  [51200/72298]
loss: 0.055012  [57600/72298]
loss: 0.165566  [64000/72298]
loss: 0.014292  [70400/72298]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.055066 

Epoch 3
-------------------------------
loss: 0.035942  [    0/72298]
loss: 0.024192  [ 6400/72298]
loss: 0.060833  [12800/72298]
loss: 0.029358  [19200/72298]
loss: 0.119159  [25600/72298]
loss: 0.030021  [32000/72298]
loss: 0.076566  [38400/72298]
loss: 0.078369  [44800/72298]
loss: 0.069280  [51200/72298]
loss: 0.126947  [57600/72298]
loss: 0.083719  [64000/72298]
loss: 0.100487  [70400/72298]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.059347 

Epoch 4
-------------------------------
loss: 0.031459  [    0/72298]
loss: 0.031090  [ 6400/72298]
loss: 0.058692  [12800/72298]
loss: 0.071595  [19200/72298]
loss: 0.039819  [25600/72298]
loss: 0.034845  [32000/72298]
loss: 0.138035  [38400/72298]
loss: 0.031770  [44800/72298]
loss: 0.050945  [51200/72298]
loss: 0.050709  [57600/72298]
loss: 0.019888  [64000/72298]
loss: 0.076738  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.047339 

Epoch 5
-------------------------------
loss: 0.022696  [    0/72298]
loss: 0.021626  [ 6400/72298]
loss: 0.050408  [12800/72298]
loss: 0.008914  [19200/72298]
loss: 0.044617  [25600/72298]
loss: 0.005147  [32000/72298]
loss: 0.064463  [38400/72298]
loss: 0.049799  [44800/72298]
loss: 0.032738  [51200/72298]
loss: 0.011006  [57600/72298]
loss: 0.027900  [64000/72298]
loss: 0.017650  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.053522 

Epoch 6
-------------------------------
loss: 0.033313  [    0/72298]
loss: 0.013004  [ 6400/72298]
loss: 0.008118  [12800/72298]
loss: 0.012588  [19200/72298]
loss: 0.051685  [25600/72298]
loss: 0.046706  [32000/72298]
loss: 0.035014  [38400/72298]
loss: 0.023364  [44800/72298]
loss: 0.092277  [51200/72298]
loss: 0.023446  [57600/72298]
loss: 0.016704  [64000/72298]
loss: 0.022904  [70400/72298]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.048527 

Epoch 7
-------------------------------
loss: 0.001915  [    0/72298]
loss: 0.109665  [ 6400/72298]
loss: 0.024271  [12800/72298]
loss: 0.044952  [19200/72298]
loss: 0.021608  [25600/72298]
loss: 0.028065  [32000/72298]
loss: 0.052353  [38400/72298]
loss: 0.054087  [44800/72298]
loss: 0.011580  [51200/72298]
loss: 0.014946  [57600/72298]
loss: 0.020600  [64000/72298]
loss: 0.017957  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.055373 

Epoch 8
-------------------------------
loss: 0.009904  [    0/72298]
loss: 0.047382  [ 6400/72298]
loss: 0.025785  [12800/72298]
loss: 0.013680  [19200/72298]
loss: 0.011210  [25600/72298]
loss: 0.025291  [32000/72298]
loss: 0.049802  [38400/72298]
loss: 0.292239  [38400/69609]
loss: 0.054135  [44800/69609]
loss: 0.104606  [51200/69609]
loss: 0.090781  [57600/69609]
loss: 0.071265  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.148029 

Epoch 6
-------------------------------
loss: 0.168030  [    0/69609]
loss: 0.140437  [ 6400/69609]
loss: 0.121306  [12800/69609]
loss: 0.187417  [19200/69609]
loss: 0.100377  [25600/69609]
loss: 0.188169  [32000/69609]
loss: 0.079099  [38400/69609]
loss: 0.164465  [44800/69609]
loss: 0.193970  [51200/69609]
loss: 0.091117  [57600/69609]
loss: 0.123291  [64000/69609]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.150706 

Epoch 7
-------------------------------
loss: 0.076471  [    0/69609]
loss: 0.120704  [ 6400/69609]
loss: 0.159367  [12800/69609]
loss: 0.169870  [19200/69609]
loss: 0.286904  [25600/69609]
loss: 0.062361  [32000/69609]
loss: 0.079742  [38400/69609]
loss: 0.140841  [44800/69609]
loss: 0.153506  [51200/69609]
loss: 0.154857  [57600/69609]
loss: 0.114076  [64000/69609]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.149818 

Epoch 8
-------------------------------
loss: 0.169269  [    0/69609]
loss: 0.155058  [ 6400/69609]
loss: 0.091604  [12800/69609]
loss: 0.090796  [19200/69609]
loss: 0.088459  [25600/69609]
loss: 0.174644  [32000/69609]
loss: 0.061391  [38400/69609]
loss: 0.298910  [44800/69609]
loss: 0.242550  [51200/69609]
loss: 0.080055  [57600/69609]
loss: 0.162039  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.144265 

Epoch 9
-------------------------------
loss: 0.222732  [    0/69609]
loss: 0.041993  [ 6400/69609]
loss: 0.153462  [12800/69609]
loss: 0.120012  [19200/69609]
loss: 0.059946  [25600/69609]
loss: 0.069498  [32000/69609]
loss: 0.246702  [38400/69609]
loss: 0.067148  [44800/69609]
loss: 0.106755  [51200/69609]
loss: 0.076908  [57600/69609]
loss: 0.179382  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.142324 

Epoch 10
-------------------------------
loss: 0.103224  [    0/69609]
loss: 0.144082  [ 6400/69609]
loss: 0.121070  [12800/69609]
loss: 0.100387  [19200/69609]
loss: 0.105080  [25600/69609]
loss: 0.147352  [32000/69609]
loss: 0.120861  [38400/69609]
loss: 0.161066  [44800/69609]
loss: 0.244211  [51200/69609]
loss: 0.147788  [57600/69609]
loss: 0.060086  [64000/69609]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.137379 

Epoch 11
-------------------------------
loss: 0.078730  [    0/69609]
loss: 0.081001  [ 6400/69609]
loss: 0.100352  [12800/69609]
loss: 0.117447  [19200/69609]
loss: 0.102215  [25600/69609]
loss: 0.149555  [32000/69609]
loss: 0.122392  [38400/69609]
loss: 0.047657  [44800/69609]
loss: 0.124644  [51200/69609]
loss: 0.212039  [57600/69609]
loss: 0.141211  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.140676 

Epoch 12
-------------------------------
loss: 0.057111  [    0/69609]
loss: 0.166251  [ 6400/69609]
loss: 0.125519  [12800/69609]
loss: 0.109841  [19200/69609]
loss: 0.094812  [25600/69609]
loss: 0.217233  [32000/69609]
loss: 0.172881  [38400/69609]
loss: 0.203742  [44800/69609]
loss: 0.123102  [51200/69609]
loss: 0.079945  [57600/69609]
loss: 0.043387  [64000/69609]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.135765 

Epoch 13
-------------------------------
loss: 0.057708  [    0/69609]
loss: 0.074982  [ 6400/69609]
loss: 0.267266  [12800/69609]
loss: 0.116629  [19200/69609]
loss: 0.236429  [25600/69609]
loss: 0.200172  [32000/69609]
loss: 0.055746  [38400/69609]
loss: 0.129805  [44800/69609]
loss: 0.065185  [51200/69609]
loss: 0.009837  [57600/69609]
loss: 0.068866  [64000/69609]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.138941 

Epoch 14
-------------------------------
loss: 0.231584  [    0/69609]
loss: 0.080258  [ 6400/69609]
loss: 0.095801  [12800/69609]
loss: 0.152736  [19200/69609]
loss: 0.212623  [25600/69609]
loss: 0.083131  [32000/69609]
loss: 0.216833  [38400/69609]
loss: 0.177703  [44800/69609]
loss: 0.150866  [51200/69609]
loss: 0.080771  [57600/69609]
loss: 0.154447  [64000/69609]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.138554 

Epoch 15
-------------------------------
loss: 0.076482  [    0/69609]
loss: 0.128231  [ 6400/69609]
loss: 0.058820  [12800/69609]
loss: 0.120814  [19200/69609]
loss: 0.126327  [25600/69609]
loss: 0.096288  [32000/69609]
loss: 0.074726  [38400/69609]
loss: 0.153601  [44800/69609]
loss: 0.089388  [51200/69609]
loss: 0.109570  [57600/69609]
loss: 0.121349  [64000/69609]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.139688 

Epoch 16
-------------------------------
loss: 0.072918  [    0/69609]
loss: 0.153125  [ 6400/69609]
loss: 0.151476  [12800/69609]
loss: 0.207930  [19200/69609]
loss: 0.174557  [25600/69609]
loss: 0.136855  [32000/69609]
loss: 0.111006  [38400/69609]
loss: 0.096370  [44800/69609]
loss: 0.106819  [51200/69609]
loss: 0.124563  [57600/69609]
loss: 0.145588  [64000/69609]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.139459 

Epoch 17
-------------------------------
loss: 0.093882  [    0/69609]
loss: 0.052134  [ 6400/69609]
loss: 0.258967  [12800/69609]
loss: 0.185732  [19200/69609]
loss: 0.091531  [25600/69609]
loss: 0.139071  [32000/69609]
loss: 0.154141  [38400/69609]
loss: 0.195329  [44800/69609]
loss: 0.286993  [51200/69609]
loss: 0.090901  [57600/69609]
loss: 0.110660  [64000/69609]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.131071 

Epoch 18
-------------------------------
loss: 0.075803  [    0/69609]
loss: 0.089460  [ 6400/69609]
loss: 0.137687  [12800/69609]
loss: 0.083775  [19200/69609]
loss: 0.190332  [25600/69609]
loss: 0.084108  [32000/69609]
loss: 0.102272  [38400/69609]
loss: 0.068554  [44800/69609]
loss: 0.090488  [51200/69609]
loss: 0.139043  [57600/69609]
loss: 0.216478  [64000/69609]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.131775 

Epoch 19
-------------------------------
loss: 0.080532  [    0/69609]
loss: 0.161936  [ 6400/69609]
loss: 0.066544  [12800/69609]
loss: 0.113545  [19200/69609]
loss: 0.181681  [25600/69609]
loss: 0.096289  [32000/69609]
loss: 0.081714  [38400/69609]
loss: 0.073643  [44800/69609]
loss: 0.197855  [51200/69609]
loss: 0.106323  [57600/69609]
loss: 0.102092  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.134880 

Epoch 20
-------------------------------
loss: 0.036471  [    0/69609]
loss: 0.088378  [ 6400/69609]
loss: 0.107371  [12800/69609]
loss: 0.215287  [19200/69609]
loss: 0.117173  [25600/69609]
loss: 0.262305  [32000/69609]
loss: 0.107534  [38400/69609]
loss: 0.081721  [44800/69609]
loss: 0.116835  [51200/69609]
loss: 0.081359  [57600/69609]
loss: 0.148153  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.140579 

Epoch 21
-------------------------------
loss: 0.221344  [    0/69609]
loss: 0.148538  [ 6400/69609]
loss: 0.135682  [12800/69609]
loss: 0.093947  [19200/69609]
loss: 0.173841  [25600/69609]
loss: 0.158612  [32000/69609]
loss: 0.193098  [38400/69609]
loss: 0.221351  [44800/69609]
loss: 0.065358  [51200/69609]
loss: 0.077686  [57600/69609]
loss: 0.084241  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.143800 

Epoch 22
-------------------------------
loss: 0.134127  [    0/69609]
loss: 0.086805  [ 6400/69609]
loss: 0.052922  [12800/69609]
loss: 0.128512  [19200/69609]
loss: 0.216789  [25600/69609]
loss: 0.074553  [32000/69609]
loss: 0.094290  [38400/69609]
loss: 0.258148  [44800/69609]
loss: 0.141271  [51200/69609]
loss: 0.023894  [57600/69609]
loss: 0.109997  [64000/69609]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.131789 

Epoch 23
-------------------------------
loss: 0.100956  [    0/69609]
loss: 0.063422  [ 6400/69609]
loss: 0.048283  [12800/69609]
loss: 0.139098  [19200/69609]
loss: 0.087041  [25600/69609]
loss: 0.182883  [32000/69609]
loss: 0.106377  [38400/69609]
loss: 0.105686  [44800/69609]
loss: 0.118724  [51200/69609]
loss: 0.123574  [57600/69609]
loss: 0.135482  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.140885 

Epoch 24
-------------------------------
loss: 0.072171  [    0/69609]
loss: 0.084665  [ 6400/69609]
loss: 0.166366  [12800/69609]
loss: 0.066564  [19200/69609]
loss: 0.053509  [25600/69609]
loss: 0.202531  [32000/69609]
loss: 0.066801  [38400/69609]
loss: 0.098172  [44800/69609]
loss: 0.136676  [51200/69609]
loss: 0.148123  [57600/69609]
loss: 0.212354  [64000/69609]
loss: 0.073220  [12800/71031]
loss: 0.150341  [19200/71031]
loss: 0.022586  [25600/71031]
loss: 0.051063  [32000/71031]
loss: 0.131314  [38400/71031]
loss: 0.058854  [44800/71031]
loss: 0.050091  [51200/71031]
loss: 0.078139  [57600/71031]
loss: 0.116676  [64000/71031]
loss: 0.093544  [70400/71031]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.125975 

Epoch 6
-------------------------------
loss: 0.095992  [    0/71031]
loss: 0.101247  [ 6400/71031]
loss: 0.086204  [12800/71031]
loss: 0.059290  [19200/71031]
loss: 0.031466  [25600/71031]
loss: 0.111005  [32000/71031]
loss: 0.017019  [38400/71031]
loss: 0.048173  [44800/71031]
loss: 0.161937  [51200/71031]
loss: 0.096023  [57600/71031]
loss: 0.154794  [64000/71031]
loss: 0.070344  [70400/71031]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.127251 

Epoch 7
-------------------------------
loss: 0.109471  [    0/71031]
loss: 0.049460  [ 6400/71031]
loss: 0.030048  [12800/71031]
loss: 0.027291  [19200/71031]
loss: 0.045364  [25600/71031]
loss: 0.108992  [32000/71031]
loss: 0.070241  [38400/71031]
loss: 0.059416  [44800/71031]
loss: 0.053736  [51200/71031]
loss: 0.072702  [57600/71031]
loss: 0.094696  [64000/71031]
loss: 0.050067  [70400/71031]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.124512 

Epoch 8
-------------------------------
loss: 0.058711  [    0/71031]
loss: 0.070497  [ 6400/71031]
loss: 0.033740  [12800/71031]
loss: 0.419264  [19200/71031]
loss: 0.038558  [25600/71031]
loss: 0.148681  [32000/71031]
loss: 0.083858  [38400/71031]
loss: 1.646030  [44800/71031]
loss: 0.103270  [51200/71031]
loss: 0.041916  [57600/71031]
loss: 0.083948  [64000/71031]
loss: 0.027710  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.129574 

Epoch 9
-------------------------------
loss: 0.034738  [    0/71031]
loss: 0.034696  [ 6400/71031]
loss: 0.023431  [12800/71031]
loss: 0.092829  [19200/71031]
loss: 0.038434  [25600/71031]
loss: 0.049296  [32000/71031]
loss: 0.047568  [38400/71031]
loss: 0.070208  [44800/71031]
loss: 0.122943  [51200/71031]
loss: 0.028526  [57600/71031]
loss: 0.167054  [64000/71031]
loss: 0.141968  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.122525 

Epoch 10
-------------------------------
loss: 0.031130  [    0/71031]
loss: 0.078498  [ 6400/71031]
loss: 0.048897  [12800/71031]
loss: 0.036033  [19200/71031]
loss: 0.035576  [25600/71031]
loss: 0.034482  [32000/71031]
loss: 0.045606  [38400/71031]
loss: 0.052524  [44800/71031]
loss: 0.032826  [51200/71031]
loss: 0.036256  [57600/71031]
loss: 0.122847  [64000/71031]
loss: 0.091750  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.123720 

Epoch 11
-------------------------------
loss: 0.088359  [    0/71031]
loss: 0.039731  [ 6400/71031]
loss: 0.081101  [12800/71031]
loss: 0.053973  [19200/71031]
loss: 0.056479  [25600/71031]
loss: 0.047944  [32000/71031]
loss: 0.086884  [38400/71031]
loss: 0.059244  [44800/71031]
loss: 0.125807  [51200/71031]
loss: 0.043233  [57600/71031]
loss: 0.073555  [64000/71031]
loss: 0.011557  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.119478 

Epoch 12
-------------------------------
loss: 0.016856  [    0/71031]
loss: 0.022689  [ 6400/71031]
loss: 0.035271  [12800/71031]
loss: 0.029974  [19200/71031]
loss: 0.041491  [25600/71031]
loss: 0.183067  [32000/71031]
loss: 0.099447  [38400/71031]
loss: 0.096737  [44800/71031]
loss: 0.058400  [51200/71031]
loss: 0.049477  [57600/71031]
loss: 0.202774  [64000/71031]
loss: 0.027725  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.121019 

Epoch 13
-------------------------------
loss: 0.014239  [    0/71031]
loss: 0.105249  [ 6400/71031]
loss: 0.122096  [12800/71031]
loss: 0.069823  [19200/71031]
loss: 0.065780  [25600/71031]
loss: 0.100925  [32000/71031]
loss: 0.048699  [38400/71031]
loss: 0.085432  [44800/71031]
loss: 0.088341  [51200/71031]
loss: 0.056139  [57600/71031]
loss: 0.047916  [64000/71031]
loss: 0.076896  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.123014 

Epoch 14
-------------------------------
loss: 0.077797  [    0/71031]
loss: 0.046739  [ 6400/71031]
loss: 0.072297  [12800/71031]
loss: 0.040962  [19200/71031]
loss: 0.070632  [25600/71031]
loss: 0.011539  [32000/71031]
loss: 0.062677  [38400/71031]
loss: 0.042552  [44800/71031]
loss: 0.121896  [51200/71031]
loss: 0.008187  [57600/71031]
loss: 0.165667  [64000/71031]
loss: 0.062813  [70400/71031]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.129421 

Epoch 15
-------------------------------
loss: 0.053271  [    0/71031]
loss: 0.043470  [ 6400/71031]
loss: 0.064546  [12800/71031]
loss: 0.076034  [19200/71031]
loss: 0.049153  [25600/71031]
loss: 0.046470  [32000/71031]
loss: 0.017166  [38400/71031]
loss: 0.034900  [44800/71031]
loss: 0.083458  [51200/71031]
loss: 0.018345  [57600/71031]
loss: 0.038223  [64000/71031]
loss: 0.156411  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.130873 

Epoch 16
-------------------------------
loss: 0.066266  [    0/71031]
loss: 0.027876  [ 6400/71031]
loss: 0.089863  [12800/71031]
loss: 0.032653  [19200/71031]
loss: 0.054557  [25600/71031]
loss: 0.068756  [32000/71031]
loss: 0.032489  [38400/71031]
loss: 0.060768  [44800/71031]
loss: 0.096973  [51200/71031]
loss: 0.063028  [57600/71031]
loss: 0.204819  [64000/71031]
loss: 0.193659  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.132057 

Epoch 17
-------------------------------
loss: 0.067477  [    0/71031]
loss: 0.148005  [ 6400/71031]
loss: 0.038924  [12800/71031]
loss: 0.045581  [19200/71031]
loss: 0.095726  [25600/71031]
loss: 0.080898  [32000/71031]
loss: 0.025427  [38400/71031]
loss: 0.041765  [44800/71031]
loss: 0.010722  [51200/71031]
loss: 0.013462  [57600/71031]
loss: 0.047070  [64000/71031]
loss: 0.046321  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.124036 

Epoch 18
-------------------------------
loss: 0.084232  [    0/71031]
loss: 0.070115  [ 6400/71031]
loss: 0.105456  [12800/71031]
loss: 0.121162  [19200/71031]
loss: 0.182796  [25600/71031]
loss: 0.006782  [32000/71031]
loss: 0.048829  [38400/71031]
loss: 0.079896  [44800/71031]
loss: 0.059324  [51200/71031]
loss: 0.072970  [57600/71031]
loss: 0.053019  [64000/71031]
loss: 0.014219  [70400/71031]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.124163 

Epoch 19
-------------------------------
loss: 0.026446  [    0/71031]
loss: 0.181596  [ 6400/71031]
loss: 0.017627  [12800/71031]
loss: 0.052975  [19200/71031]
loss: 0.020197  [25600/71031]
loss: 0.021718  [32000/71031]
loss: 0.043476  [38400/71031]
loss: 0.012938  [44800/71031]
loss: 0.045206  [51200/71031]
loss: 1.661997  [57600/71031]
loss: 0.145648  [64000/71031]
loss: 0.064075  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.124850 

Epoch 20
-------------------------------
loss: 0.127288  [    0/71031]
loss: 0.016080  [ 6400/71031]
loss: 0.057454  [12800/71031]
loss: 0.089029  [19200/71031]
loss: 0.027971  [25600/71031]
loss: 0.038777  [32000/71031]
loss: 0.018329  [38400/71031]
loss: 0.217224  [44800/71031]
loss: 0.025891  [51200/71031]
loss: 0.125088  [57600/71031]
loss: 0.029386  [64000/71031]
loss: 0.107120  [70400/71031]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.126403 

Epoch 21
-------------------------------
loss: 0.107290  [    0/71031]
loss: 0.054429  [ 6400/71031]
loss: 0.021594  [12800/71031]
loss: 0.014036  [19200/71031]
loss: 0.081346  [25600/71031]
loss: 0.038490  [32000/71031]
loss: 0.029703  [38400/71031]
loss: 0.031789  [44800/71031]
loss: 0.157399  [51200/71031]
loss: 0.073286  [57600/71031]
loss: 0.027604  [64000/71031]
loss: 0.091022  [70400/71031]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.131137 

Epoch 22
-------------------------------
loss: 0.040548  [    0/71031]
loss: 0.028440  [ 6400/71031]
loss: 0.040700  [12800/71031]
loss: 0.029463  [19200/71031]
loss: 0.091374  [25600/71031]
loss: 0.063090  [32000/71031]
loss: 0.023295  [38400/71031]
loss: 0.091640  [44800/71031]
loss: 0.070265  [51200/71031]
loss: 0.056021  [57600/71031]
loss: 0.065696  [64000/71031]
loss: 0.046611  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.130768 

Epoch 23
-------------------------------
loss: 0.007781  [    0/71031]
loss: 0.126125  [ 6400/71031]
loss: 0.054188  [12800/71031]
loss: 0.032107  [12800/71122]
loss: 0.046915  [19200/71122]
loss: 0.038257  [25600/71122]
loss: 0.047512  [32000/71122]
loss: 0.098142  [38400/71122]
loss: 0.090690  [44800/71122]
loss: 0.037202  [51200/71122]
loss: 0.054532  [57600/71122]
loss: 0.121899  [64000/71122]
loss: 0.027480  [70400/71122]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.078611 

Epoch 6
-------------------------------
loss: 0.019357  [    0/71122]
loss: 0.076867  [ 6400/71122]
loss: 0.006350  [12800/71122]
loss: 0.042285  [19200/71122]
loss: 0.048395  [25600/71122]
loss: 0.007462  [32000/71122]
loss: 0.048236  [38400/71122]
loss: 0.067173  [44800/71122]
loss: 0.016923  [51200/71122]
loss: 0.025182  [57600/71122]
loss: 0.084672  [64000/71122]
loss: 0.014338  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.075107 

Epoch 7
-------------------------------
loss: 0.100311  [    0/71122]
loss: 1.596028  [ 6400/71122]
loss: 0.088003  [12800/71122]
loss: 0.037876  [19200/71122]
loss: 0.048783  [25600/71122]
loss: 0.025699  [32000/71122]
loss: 0.047286  [38400/71122]
loss: 0.051636  [44800/71122]
loss: 0.009899  [51200/71122]
loss: 0.017035  [57600/71122]
loss: 0.052708  [64000/71122]
loss: 0.035300  [70400/71122]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.080850 

Epoch 8
-------------------------------
loss: 0.031819  [    0/71122]
loss: 0.022826  [ 6400/71122]
loss: 0.007120  [12800/71122]
loss: 0.033867  [19200/71122]
loss: 0.024284  [25600/71122]
loss: 0.026814  [32000/71122]
loss: 0.049559  [38400/71122]
loss: 0.038473  [44800/71122]
loss: 0.070770  [51200/71122]
loss: 0.069020  [57600/71122]
loss: 0.073948  [64000/71122]
loss: 0.017824  [70400/71122]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.080611 

Epoch 9
-------------------------------
loss: 0.058102  [    0/71122]
loss: 0.020236  [ 6400/71122]
loss: 0.018906  [12800/71122]
loss: 0.117779  [19200/71122]
loss: 0.009597  [25600/71122]
loss: 0.042813  [32000/71122]
loss: 0.044654  [38400/71122]
loss: 0.071645  [44800/71122]
loss: 0.015342  [51200/71122]
loss: 0.006427  [57600/71122]
loss: 0.036050  [64000/71122]
loss: 0.063904  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.074891 

Epoch 10
-------------------------------
loss: 0.142961  [    0/71122]
loss: 0.040481  [ 6400/71122]
loss: 0.047291  [12800/71122]
loss: 0.004353  [19200/71122]
loss: 0.060121  [25600/71122]
loss: 0.023787  [32000/71122]
loss: 0.001371  [38400/71122]
loss: 0.003400  [44800/71122]
loss: 0.021682  [51200/71122]
loss: 0.011453  [57600/71122]
loss: 0.019981  [64000/71122]
loss: 0.026733  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.073794 

Epoch 11
-------------------------------
loss: 0.063958  [    0/71122]
loss: 0.005749  [ 6400/71122]
loss: 0.050448  [12800/71122]
loss: 0.032636  [19200/71122]
loss: 0.045107  [25600/71122]
loss: 0.079819  [32000/71122]
loss: 0.013753  [38400/71122]
loss: 0.009631  [44800/71122]
loss: 0.033283  [51200/71122]
loss: 0.016469  [57600/71122]
loss: 0.060297  [64000/71122]
loss: 0.049972  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.076172 

Epoch 12
-------------------------------
loss: 0.044717  [    0/71122]
loss: 0.021600  [ 6400/71122]
loss: 0.026647  [12800/71122]
loss: 0.028591  [19200/71122]
loss: 0.053825  [25600/71122]
loss: 0.030269  [32000/71122]
loss: 0.022002  [38400/71122]
loss: 0.032826  [44800/71122]
loss: 0.027911  [51200/71122]
loss: 0.022007  [57600/71122]
loss: 0.089450  [64000/71122]
loss: 0.045773  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.073361 

Epoch 13
-------------------------------
loss: 0.045891  [    0/71122]
loss: 0.032859  [ 6400/71122]
loss: 0.074528  [12800/71122]
loss: 0.046835  [19200/71122]
loss: 0.010878  [25600/71122]
loss: 0.033750  [32000/71122]
loss: 0.034164  [38400/71122]
loss: 0.060297  [44800/71122]
loss: 0.026161  [51200/71122]
loss: 0.074940  [57600/71122]
loss: 0.041973  [64000/71122]
loss: 0.013634  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.074639 

Epoch 14
-------------------------------
loss: 0.027482  [    0/71122]
loss: 0.020849  [ 6400/71122]
loss: 0.042382  [12800/71122]
loss: 0.047632  [19200/71122]
loss: 0.133384  [25600/71122]
loss: 0.017211  [32000/71122]
loss: 0.030790  [38400/71122]
loss: 0.005338  [44800/71122]
loss: 0.010666  [51200/71122]
loss: 0.018431  [57600/71122]
loss: 0.016994  [64000/71122]
loss: 0.017170  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.074714 

Epoch 15
-------------------------------
loss: 0.014563  [    0/71122]
loss: 0.015915  [ 6400/71122]
loss: 0.054002  [12800/71122]
loss: 0.053464  [19200/71122]
loss: 0.024855  [25600/71122]
loss: 0.013046  [32000/71122]
loss: 0.006006  [38400/71122]
loss: 0.189340  [44800/71122]
loss: 0.048602  [51200/71122]
loss: 0.047632  [57600/71122]
loss: 0.031556  [64000/71122]
loss: 0.005806  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.079634 

Epoch 16
-------------------------------
loss: 0.013644  [    0/71122]
loss: 0.035184  [ 6400/71122]
loss: 0.009809  [12800/71122]
loss: 0.076534  [19200/71122]
loss: 0.011125  [25600/71122]
loss: 0.009309  [32000/71122]
loss: 0.140428  [38400/71122]
loss: 0.062548  [44800/71122]
loss: 0.011777  [51200/71122]
loss: 0.018277  [57600/71122]
loss: 0.011755  [64000/71122]
loss: 0.085405  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.080358 

Epoch 17
-------------------------------
loss: 0.005853  [    0/71122]
loss: 0.010261  [ 6400/71122]
loss: 0.008731  [12800/71122]
loss: 0.140862  [19200/71122]
loss: 0.016249  [25600/71122]
loss: 0.030848  [32000/71122]
loss: 0.014279  [38400/71122]
loss: 0.082727  [44800/71122]
loss: 0.001920  [51200/71122]
loss: 0.015436  [57600/71122]
loss: 0.037017  [64000/71122]
loss: 0.067975  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.074001 

Epoch 18
-------------------------------
loss: 0.005629  [    0/71122]
loss: 0.071621  [ 6400/71122]
loss: 0.001196  [12800/71122]
loss: 0.075434  [19200/71122]
loss: 0.052517  [25600/71122]
loss: 0.006954  [32000/71122]
loss: 0.009834  [38400/71122]
loss: 0.035715  [44800/71122]
loss: 0.004434  [51200/71122]
loss: 0.020004  [57600/71122]
loss: 0.030791  [64000/71122]
loss: 0.321931  [70400/71122]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.078202 

Epoch 19
-------------------------------
loss: 0.107373  [    0/71122]
loss: 0.033708  [ 6400/71122]
loss: 0.014150  [12800/71122]
loss: 0.065007  [19200/71122]
loss: 0.090323  [25600/71122]
loss: 0.003435  [32000/71122]
loss: 0.018781  [38400/71122]
loss: 0.064009  [44800/71122]
loss: 0.062406  [51200/71122]
loss: 0.034303  [57600/71122]
loss: 0.015612  [64000/71122]
loss: 0.008219  [70400/71122]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068926 

Epoch 20
-------------------------------
loss: 0.049179  [    0/71122]
loss: 0.090360  [ 6400/71122]
loss: 0.020185  [12800/71122]
loss: 0.017976  [19200/71122]
loss: 0.004150  [25600/71122]
loss: 0.018966  [32000/71122]
loss: 0.001410  [38400/71122]
loss: 0.034155  [44800/71122]
loss: 0.017220  [51200/71122]
loss: 0.014590  [57600/71122]
loss: 0.026413  [64000/71122]
loss: 0.019699  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.080871 

Epoch 21
-------------------------------
loss: 0.046743  [    0/71122]
loss: 0.062073  [ 6400/71122]
loss: 0.021122  [12800/71122]
loss: 0.033356  [19200/71122]
loss: 0.071700  [25600/71122]
loss: 0.053537  [32000/71122]
loss: 0.099636  [38400/71122]
loss: 0.084845  [44800/71122]
loss: 0.018657  [51200/71122]
loss: 0.011707  [57600/71122]
loss: 0.024382  [64000/71122]
loss: 0.040688  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.074073 

Epoch 22
-------------------------------
loss: 0.063883  [    0/71122]
loss: 0.036896  [ 6400/71122]
loss: 0.005414  [12800/71122]
loss: 0.007441  [19200/71122]
loss: 0.046697  [25600/71122]
loss: 0.013203  [32000/71122]
loss: 0.010757  [38400/71122]
loss: 0.039418  [44800/71122]
loss: 0.003925  [51200/71122]
loss: 0.012029  [57600/71122]
loss: 0.029521  [64000/71122]
loss: 0.006439  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.074436 

Epoch 23
-------------------------------
loss: 0.023692  [    0/71122]
loss: 0.144148  [ 6400/71122]
loss: 0.026785  [12800/71122]
loss: 0.027916  [12800/71418]
loss: 0.013081  [19200/71418]
loss: 0.091338  [25600/71418]
loss: 0.065127  [32000/71418]
loss: 0.046307  [38400/71418]
loss: 0.013039  [44800/71418]
loss: 0.039130  [51200/71418]
loss: 0.013583  [57600/71418]
loss: 0.077823  [64000/71418]
loss: 0.120589  [70400/71418]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.075473 

Epoch 6
-------------------------------
loss: 0.012182  [    0/71418]
loss: 0.026473  [ 6400/71418]
loss: 0.031476  [12800/71418]
loss: 0.008970  [19200/71418]
loss: 0.013687  [25600/71418]
loss: 0.019436  [32000/71418]
loss: 0.153402  [38400/71418]
loss: 0.039315  [44800/71418]
loss: 0.072991  [51200/71418]
loss: 0.045319  [57600/71418]
loss: 0.036122  [64000/71418]
loss: 0.063867  [70400/71418]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.074553 

Epoch 7
-------------------------------
loss: 0.029231  [    0/71418]
loss: 0.050877  [ 6400/71418]
loss: 0.062130  [12800/71418]
loss: 0.036823  [19200/71418]
loss: 0.060412  [25600/71418]
loss: 0.076912  [32000/71418]
loss: 0.016636  [38400/71418]
loss: 0.086636  [44800/71418]
loss: 0.027973  [51200/71418]
loss: 0.090497  [57600/71418]
loss: 0.142963  [64000/71418]
loss: 0.031708  [70400/71418]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.086515 

Epoch 8
-------------------------------
loss: 0.034398  [    0/71418]
loss: 0.008934  [ 6400/71418]
loss: 0.023704  [12800/71418]
loss: 0.000812  [19200/71418]
loss: 0.004416  [25600/71418]
loss: 0.043415  [32000/71418]
loss: 0.023973  [38400/71418]
loss: 0.059719  [44800/71418]
loss: 0.060209  [51200/71418]
loss: 0.003437  [57600/71418]
loss: 0.066528  [64000/71418]
loss: 0.012435  [70400/71418]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072588 

Epoch 9
-------------------------------
loss: 0.010689  [    0/71418]
loss: 0.014377  [ 6400/71418]
loss: 0.009722  [12800/71418]
loss: 0.005298  [19200/71418]
loss: 0.020743  [25600/71418]
loss: 0.035623  [32000/71418]
loss: 0.102665  [38400/71418]
loss: 0.021462  [44800/71418]
loss: 0.046275  [51200/71418]
loss: 0.008252  [57600/71418]
loss: 0.013271  [64000/71418]
loss: 0.033602  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.080306 

Epoch 10
-------------------------------
loss: 0.016214  [    0/71418]
loss: 0.017473  [ 6400/71418]
loss: 0.022345  [12800/71418]
loss: 0.009398  [19200/71418]
loss: 0.042525  [25600/71418]
loss: 0.040657  [32000/71418]
loss: 0.135412  [38400/71418]
loss: 0.033597  [44800/71418]
loss: 0.007146  [51200/71418]
loss: 0.058079  [57600/71418]
loss: 0.009632  [64000/71418]
loss: 0.218072  [70400/71418]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.115950 

Epoch 11
-------------------------------
loss: 0.110120  [    0/71418]
loss: 0.020810  [ 6400/71418]
loss: 0.007136  [12800/71418]
loss: 0.004378  [19200/71418]
loss: 0.033012  [25600/71418]
loss: 0.024455  [32000/71418]
loss: 0.049237  [38400/71418]
loss: 0.052093  [44800/71418]
loss: 0.042435  [51200/71418]
loss: 0.009885  [57600/71418]
loss: 0.012465  [64000/71418]
loss: 0.158159  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.112084 

Epoch 12
-------------------------------
loss: 0.019855  [    0/71418]
loss: 0.011711  [ 6400/71418]
loss: 0.010691  [12800/71418]
loss: 0.027870  [19200/71418]
loss: 0.021944  [25600/71418]
loss: 0.043071  [32000/71418]
loss: 0.073855  [38400/71418]
loss: 0.006939  [44800/71418]
loss: 0.041182  [51200/71418]
loss: 0.056212  [57600/71418]
loss: 0.014511  [64000/71418]
loss: 0.015016  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.094112 

Epoch 13
-------------------------------
loss: 0.017326  [    0/71418]
loss: 0.125683  [ 6400/71418]
loss: 0.008650  [12800/71418]
loss: 0.085618  [19200/71418]
loss: 0.059208  [25600/71418]
loss: 0.055607  [32000/71418]
loss: 0.025941  [38400/71418]
loss: 0.035140  [44800/71418]
loss: 0.015515  [51200/71418]
loss: 0.011346  [57600/71418]
loss: 0.006825  [64000/71418]
loss: 0.017719  [70400/71418]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.101373 

Epoch 14
-------------------------------
loss: 0.043679  [    0/71418]
loss: 0.036893  [ 6400/71418]
loss: 0.003721  [12800/71418]
loss: 0.015538  [19200/71418]
loss: 0.029164  [25600/71418]
loss: 0.021494  [32000/71418]
loss: 0.034532  [38400/71418]
loss: 0.030706  [44800/71418]
loss: 0.016291  [51200/71418]
loss: 0.023944  [57600/71418]
loss: 0.010673  [64000/71418]
loss: 0.016259  [70400/71418]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.112510 

Epoch 15
-------------------------------
loss: 0.029569  [    0/71418]
loss: 0.017894  [ 6400/71418]
loss: 0.008540  [12800/71418]
loss: 0.028770  [19200/71418]
loss: 0.039343  [25600/71418]
loss: 0.090368  [32000/71418]
loss: 0.013200  [38400/71418]
loss: 0.018573  [44800/71418]
loss: 0.010887  [51200/71418]
loss: 0.045503  [57600/71418]
loss: 0.173537  [64000/71418]
loss: 0.009143  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.081691 

Epoch 16
-------------------------------
loss: 0.017090  [    0/71418]
loss: 0.007143  [ 6400/71418]
loss: 1.589113  [12800/71418]
loss: 0.043687  [19200/71418]
loss: 0.010088  [25600/71418]
loss: 0.060682  [32000/71418]
loss: 0.054327  [38400/71418]
loss: 0.047376  [44800/71418]
loss: 0.014384  [51200/71418]
loss: 0.011876  [57600/71418]
loss: 0.055480  [64000/71418]
loss: 0.032574  [70400/71418]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.108663 

Epoch 17
-------------------------------
loss: 0.001065  [    0/71418]
loss: 0.012245  [ 6400/71418]
loss: 0.003156  [12800/71418]
loss: 0.018899  [19200/71418]
loss: 0.048709  [25600/71418]
loss: 0.012611  [32000/71418]
loss: 0.044296  [38400/71418]
loss: 0.007336  [44800/71418]
loss: 0.015431  [51200/71418]
loss: 0.007055  [57600/71418]
loss: 0.076045  [64000/71418]
loss: 0.016954  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.096590 

Epoch 18
-------------------------------
loss: 1.568598  [    0/71418]
loss: 0.049146  [ 6400/71418]
loss: 0.027816  [12800/71418]
loss: 0.046293  [19200/71418]
loss: 0.018194  [25600/71418]
loss: 0.004501  [32000/71418]
loss: 0.060733  [38400/71418]
loss: 0.022977  [44800/71418]
loss: 0.053929  [51200/71418]
loss: 0.013303  [57600/71418]
loss: 1.568398  [64000/71418]
loss: 0.026423  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.108069 

Epoch 19
-------------------------------
loss: 0.002408  [    0/71418]
loss: 0.068891  [ 6400/71418]
loss: 0.007094  [12800/71418]
loss: 0.003946  [19200/71418]
loss: 0.014883  [25600/71418]
loss: 0.044369  [32000/71418]
loss: 0.009777  [38400/71418]
loss: 0.069462  [44800/71418]
loss: 0.060376  [51200/71418]
loss: 0.073754  [57600/71418]
loss: 0.002431  [64000/71418]
loss: 0.009340  [70400/71418]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.135487 

Epoch 20
-------------------------------
loss: 0.016012  [    0/71418]
loss: 0.022248  [ 6400/71418]
loss: 0.000203  [12800/71418]
loss: 0.011310  [19200/71418]
loss: 0.035657  [25600/71418]
loss: 0.007586  [32000/71418]
loss: 0.052434  [38400/71418]
loss: 0.001145  [44800/71418]
loss: 0.035905  [51200/71418]
loss: 0.039239  [57600/71418]
loss: 0.006543  [64000/71418]
loss: 0.022852  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.107927 

Epoch 21
-------------------------------
loss: 0.010919  [    0/71418]
loss: 0.004891  [ 6400/71418]
loss: 0.010829  [12800/71418]
loss: 0.033240  [19200/71418]
loss: 0.000435  [25600/71418]
loss: 0.033108  [32000/71418]
loss: 0.053222  [38400/71418]
loss: 0.051364  [44800/71418]
loss: 0.004852  [51200/71418]
loss: 0.029332  [57600/71418]
loss: 0.097381  [64000/71418]
loss: 0.007709  [70400/71418]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.115595 

Epoch 22
-------------------------------
loss: 0.003050  [    0/71418]
loss: 0.036820  [ 6400/71418]
loss: 0.004075  [12800/71418]
loss: 0.274678  [19200/71418]
loss: 0.005503  [25600/71418]
loss: 0.012466  [32000/71418]
loss: 0.008864  [38400/71418]
loss: 0.119495  [44800/71418]
loss: 0.084493  [51200/71418]
loss: 0.042846  [57600/71418]
loss: 0.035253  [64000/71418]
loss: 0.070055  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.113264 

Epoch 23
-------------------------------
loss: 0.066915  [    0/71418]
loss: 0.027221  [ 6400/71418]
loss: 0.013302  [12800/71418]
loss: 0.238770  [12800/70755]
loss: 0.199317  [19200/70755]
loss: 0.111691  [25600/70755]
loss: 0.173008  [32000/70755]
loss: 0.150353  [38400/70755]
loss: 0.192780  [44800/70755]
loss: 0.194148  [51200/70755]
loss: 0.154604  [57600/70755]
loss: 0.098425  [64000/70755]
loss: 0.171203  [70400/70755]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.145070 

Epoch 6
-------------------------------
loss: 0.117351  [    0/70755]
loss: 0.161007  [ 6400/70755]
loss: 0.143572  [12800/70755]
loss: 0.116385  [19200/70755]
loss: 0.071885  [25600/70755]
loss: 0.063968  [32000/70755]
loss: 0.176572  [38400/70755]
loss: 0.102672  [44800/70755]
loss: 0.049500  [51200/70755]
loss: 0.203956  [57600/70755]
loss: 0.157322  [64000/70755]
loss: 0.149942  [70400/70755]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.143183 

Epoch 7
-------------------------------
loss: 0.188003  [    0/70755]
loss: 0.219381  [ 6400/70755]
loss: 0.145259  [12800/70755]
loss: 0.228277  [19200/70755]
loss: 0.253707  [25600/70755]
loss: 0.113280  [32000/70755]
loss: 0.186910  [38400/70755]
loss: 0.175256  [44800/70755]
loss: 0.140327  [51200/70755]
loss: 0.197697  [57600/70755]
loss: 0.112851  [64000/70755]
loss: 0.031511  [70400/70755]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.136976 

Epoch 8
-------------------------------
loss: 0.177246  [    0/70755]
loss: 0.127641  [ 6400/70755]
loss: 0.145835  [12800/70755]
loss: 0.090345  [19200/70755]
loss: 0.115797  [25600/70755]
loss: 0.182218  [32000/70755]
loss: 0.127151  [38400/70755]
loss: 0.103380  [44800/70755]
loss: 0.142282  [51200/70755]
loss: 0.124980  [57600/70755]
loss: 0.146469  [64000/70755]
loss: 0.167261  [70400/70755]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.155715 

Epoch 9
-------------------------------
loss: 0.181463  [    0/70755]
loss: 0.096832  [ 6400/70755]
loss: 0.078284  [12800/70755]
loss: 0.182473  [19200/70755]
loss: 0.054194  [25600/70755]
loss: 0.118313  [32000/70755]
loss: 0.052270  [38400/70755]
loss: 0.092049  [44800/70755]
loss: 0.192976  [51200/70755]
loss: 0.141273  [57600/70755]
loss: 0.155145  [64000/70755]
loss: 0.120790  [70400/70755]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.135052 

Epoch 10
-------------------------------
loss: 0.079135  [    0/70755]
loss: 0.088628  [ 6400/70755]
loss: 0.134682  [12800/70755]
loss: 0.205018  [19200/70755]
loss: 0.108443  [25600/70755]
loss: 0.220485  [32000/70755]
loss: 0.106790  [38400/70755]
loss: 0.097499  [44800/70755]
loss: 0.194810  [51200/70755]
loss: 0.256322  [57600/70755]
loss: 0.127294  [64000/70755]
loss: 0.187030  [70400/70755]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.138421 

Epoch 11
-------------------------------
loss: 0.021765  [    0/70755]
loss: 0.047099  [ 6400/70755]
loss: 0.177945  [12800/70755]
loss: 0.116573  [19200/70755]
loss: 0.216195  [25600/70755]
loss: 0.229377  [32000/70755]
loss: 0.103135  [38400/70755]
loss: 0.144676  [44800/70755]
loss: 0.171756  [51200/70755]
loss: 0.222829  [57600/70755]
loss: 0.183485  [64000/70755]
loss: 0.203858  [70400/70755]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.160300 

Epoch 12
-------------------------------
loss: 0.120615  [    0/70755]
loss: 0.161000  [ 6400/70755]
loss: 0.177585  [12800/70755]
loss: 0.181227  [19200/70755]
loss: 0.290237  [25600/70755]
loss: 0.234077  [32000/70755]
loss: 0.092860  [38400/70755]
loss: 0.120026  [44800/70755]
loss: 0.238053  [51200/70755]
loss: 0.081415  [57600/70755]
loss: 0.137744  [64000/70755]
loss: 0.128511  [70400/70755]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.136809 

Epoch 13
-------------------------------
loss: 0.186446  [    0/70755]
loss: 0.212818  [ 6400/70755]
loss: 0.146322  [12800/70755]
loss: 0.084542  [19200/70755]
loss: 0.072604  [25600/70755]
loss: 0.136856  [32000/70755]
loss: 0.138814  [38400/70755]
loss: 0.078503  [44800/70755]
loss: 0.085567  [51200/70755]
loss: 0.143693  [57600/70755]
loss: 0.131405  [64000/70755]
loss: 0.148308  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.128984 

Epoch 14
-------------------------------
loss: 0.120048  [    0/70755]
loss: 0.092194  [ 6400/70755]
loss: 0.103891  [12800/70755]
loss: 0.116957  [19200/70755]
loss: 0.241935  [25600/70755]
loss: 0.119527  [32000/70755]
loss: 0.073997  [38400/70755]
loss: 0.154389  [44800/70755]
loss: 0.207853  [51200/70755]
loss: 0.090688  [57600/70755]
loss: 0.065972  [64000/70755]
loss: 0.150451  [70400/70755]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.129895 

Epoch 15
-------------------------------
loss: 0.194938  [    0/70755]
loss: 0.170769  [ 6400/70755]
loss: 0.091974  [12800/70755]
loss: 0.049780  [19200/70755]
loss: 0.096878  [25600/70755]
loss: 0.052046  [32000/70755]
loss: 0.068806  [38400/70755]
loss: 0.118594  [44800/70755]
loss: 0.059618  [51200/70755]
loss: 0.125447  [57600/70755]
loss: 0.080024  [64000/70755]
loss: 0.070276  [70400/70755]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.133565 

Epoch 16
-------------------------------
loss: 0.063850  [    0/70755]
loss: 0.093116  [ 6400/70755]
loss: 0.087756  [12800/70755]
loss: 0.174067  [19200/70755]
loss: 0.142006  [25600/70755]
loss: 0.067857  [32000/70755]
loss: 0.077613  [38400/70755]
loss: 0.135728  [44800/70755]
loss: 0.234782  [51200/70755]
loss: 0.136358  [57600/70755]
loss: 0.133191  [64000/70755]
loss: 0.133654  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.130265 

Epoch 17
-------------------------------
loss: 0.105730  [    0/70755]
loss: 0.105480  [ 6400/70755]
loss: 0.290222  [12800/70755]
loss: 0.100005  [19200/70755]
loss: 0.119629  [25600/70755]
loss: 0.107107  [32000/70755]
loss: 0.089487  [38400/70755]
loss: 0.107448  [44800/70755]
loss: 0.089639  [51200/70755]
loss: 0.139059  [57600/70755]
loss: 0.121945  [64000/70755]
loss: 0.108933  [70400/70755]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.139386 

Epoch 18
-------------------------------
loss: 0.055188  [    0/70755]
loss: 0.260611  [ 6400/70755]
loss: 0.152017  [12800/70755]
loss: 0.121223  [19200/70755]
loss: 0.083834  [25600/70755]
loss: 0.056229  [32000/70755]
loss: 0.120618  [38400/70755]
loss: 0.117463  [44800/70755]
loss: 0.090028  [51200/70755]
loss: 0.065736  [57600/70755]
loss: 0.099578  [64000/70755]
loss: 0.189009  [70400/70755]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.140520 

Epoch 19
-------------------------------
loss: 0.188777  [    0/70755]
loss: 0.328195  [ 6400/70755]
loss: 0.165762  [12800/70755]
loss: 0.036749  [19200/70755]
loss: 0.088934  [25600/70755]
loss: 0.074828  [32000/70755]
loss: 0.198791  [38400/70755]
loss: 0.074625  [44800/70755]
loss: 0.144354  [51200/70755]
loss: 0.096783  [57600/70755]
loss: 0.078812  [64000/70755]
loss: 0.150795  [70400/70755]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.132700 

Epoch 20
-------------------------------
loss: 0.191579  [    0/70755]
loss: 0.084091  [ 6400/70755]
loss: 0.119396  [12800/70755]
loss: 0.159597  [19200/70755]
loss: 0.121649  [25600/70755]
loss: 0.130778  [32000/70755]
loss: 0.133374  [38400/70755]
loss: 0.133445  [44800/70755]
loss: 0.064729  [51200/70755]
loss: 0.040894  [57600/70755]
loss: 0.058628  [64000/70755]
loss: 0.045668  [70400/70755]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.149512 

Epoch 21
-------------------------------
loss: 0.067044  [    0/70755]
loss: 0.057811  [ 6400/70755]
loss: 0.055557  [12800/70755]
loss: 0.114520  [19200/70755]
loss: 0.129636  [25600/70755]
loss: 0.100211  [32000/70755]
loss: 0.170224  [38400/70755]
loss: 0.179106  [44800/70755]
loss: 0.046222  [51200/70755]
loss: 0.128223  [57600/70755]
loss: 0.072624  [64000/70755]
loss: 0.130335  [70400/70755]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.130940 

Epoch 22
-------------------------------
loss: 0.099925  [    0/70755]
loss: 0.067487  [ 6400/70755]
loss: 0.068530  [12800/70755]
loss: 0.218053  [19200/70755]
loss: 0.067051  [25600/70755]
loss: 0.070321  [32000/70755]
loss: 0.135240  [38400/70755]
loss: 0.100652  [44800/70755]
loss: 0.135412  [51200/70755]
loss: 0.078903  [57600/70755]
loss: 0.200304  [64000/70755]
loss: 0.128415  [70400/70755]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.129613 

Epoch 23
-------------------------------
loss: 0.115570  [    0/70755]
loss: 0.093935  [ 6400/70755]
loss: 0.152776  [12800/70755]
loss: 0.152028  [12800/71194]
loss: 0.182093  [19200/71194]
loss: 0.072903  [25600/71194]
loss: 0.083101  [32000/71194]
loss: 0.168455  [38400/71194]
loss: 0.140800  [44800/71194]
loss: 0.047995  [51200/71194]
loss: 0.064207  [57600/71194]
loss: 0.146159  [64000/71194]
loss: 0.034382  [70400/71194]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.105869 

Epoch 6
-------------------------------
loss: 0.025396  [    0/71194]
loss: 0.056826  [ 6400/71194]
loss: 0.097495  [12800/71194]
loss: 0.160042  [19200/71194]
loss: 0.034285  [25600/71194]
loss: 0.088396  [32000/71194]
loss: 0.054536  [38400/71194]
loss: 0.064026  [44800/71194]
loss: 0.065216  [51200/71194]
loss: 0.051608  [57600/71194]
loss: 0.089543  [64000/71194]
loss: 0.112987  [70400/71194]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.102651 

Epoch 7
-------------------------------
loss: 0.117214  [    0/71194]
loss: 0.035178  [ 6400/71194]
loss: 0.101709  [12800/71194]
loss: 0.032974  [19200/71194]
loss: 0.067144  [25600/71194]
loss: 0.195891  [32000/71194]
loss: 0.092639  [38400/71194]
loss: 0.041598  [44800/71194]
loss: 0.106407  [51200/71194]
loss: 0.063935  [57600/71194]
loss: 0.129361  [64000/71194]
loss: 0.059412  [70400/71194]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.114011 

Epoch 8
-------------------------------
loss: 0.055388  [    0/71194]
loss: 0.091081  [ 6400/71194]
loss: 0.068928  [12800/71194]
loss: 0.067652  [19200/71194]
loss: 0.024650  [25600/71194]
loss: 0.129380  [32000/71194]
loss: 0.046787  [38400/71194]
loss: 0.128328  [44800/71194]
loss: 0.106533  [51200/71194]
loss: 0.070621  [57600/71194]
loss: 0.091509  [64000/71194]
loss: 0.036867  [70400/71194]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.106007 

Epoch 9
-------------------------------
loss: 0.124943  [    0/71194]
loss: 0.021900  [ 6400/71194]
loss: 0.047430  [12800/71194]
loss: 0.085296  [19200/71194]
loss: 0.028886  [25600/71194]
loss: 0.044349  [32000/71194]
loss: 0.048498  [38400/71194]
loss: 0.126805  [44800/71194]
loss: 0.178116  [51200/71194]
loss: 0.025884  [57600/71194]
loss: 0.007404  [64000/71194]
loss: 0.075638  [70400/71194]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.105253 

Epoch 10
-------------------------------
loss: 0.033010  [    0/71194]
loss: 0.042723  [ 6400/71194]
loss: 0.013290  [12800/71194]
loss: 0.064460  [19200/71194]
loss: 0.048960  [25600/71194]
loss: 0.064181  [32000/71194]
loss: 0.034133  [38400/71194]
loss: 0.072972  [44800/71194]
loss: 0.132040  [51200/71194]
loss: 0.061122  [57600/71194]
loss: 0.048409  [64000/71194]
loss: 0.288232  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.100827 

Epoch 11
-------------------------------
loss: 0.038871  [    0/71194]
loss: 0.040053  [ 6400/71194]
loss: 0.038909  [12800/71194]
loss: 0.083990  [19200/71194]
loss: 0.067494  [25600/71194]
loss: 0.150030  [32000/71194]
loss: 0.069306  [38400/71194]
loss: 0.081726  [44800/71194]
loss: 0.087802  [51200/71194]
loss: 0.020264  [57600/71194]
loss: 0.035975  [64000/71194]
loss: 0.264387  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.101848 

Epoch 12
-------------------------------
loss: 0.129304  [    0/71194]
loss: 0.037458  [ 6400/71194]
loss: 0.055787  [12800/71194]
loss: 0.007502  [19200/71194]
loss: 0.061486  [25600/71194]
loss: 0.260350  [32000/71194]
loss: 0.074641  [38400/71194]
loss: 0.029587  [44800/71194]
loss: 0.082920  [51200/71194]
loss: 0.052823  [57600/71194]
loss: 0.110014  [64000/71194]
loss: 0.078875  [70400/71194]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.104738 

Epoch 13
-------------------------------
loss: 0.019634  [    0/71194]
loss: 0.059727  [ 6400/71194]
loss: 0.049923  [12800/71194]
loss: 0.014514  [19200/71194]
loss: 0.203679  [25600/71194]
loss: 0.117608  [32000/71194]
loss: 0.065347  [38400/71194]
loss: 0.131729  [44800/71194]
loss: 0.052654  [51200/71194]
loss: 0.149589  [57600/71194]
loss: 0.035805  [64000/71194]
loss: 0.154481  [70400/71194]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.100886 

Epoch 14
-------------------------------
loss: 0.057018  [    0/71194]
loss: 0.010627  [ 6400/71194]
loss: 0.109428  [12800/71194]
loss: 0.018475  [19200/71194]
loss: 0.065301  [25600/71194]
loss: 0.061583  [32000/71194]
loss: 0.068077  [38400/71194]
loss: 0.068479  [44800/71194]
loss: 0.090485  [51200/71194]
loss: 0.050739  [57600/71194]
loss: 0.034666  [64000/71194]
loss: 0.173192  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.099275 

Epoch 15
-------------------------------
loss: 0.158286  [    0/71194]
loss: 0.140091  [ 6400/71194]
loss: 0.064410  [12800/71194]
loss: 0.145574  [19200/71194]
loss: 0.066301  [25600/71194]
loss: 0.145332  [32000/71194]
loss: 0.110401  [38400/71194]
loss: 0.031347  [44800/71194]
loss: 0.048766  [51200/71194]
loss: 0.054781  [57600/71194]
loss: 0.196565  [64000/71194]
loss: 0.036823  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.104443 

Epoch 16
-------------------------------
loss: 0.026934  [    0/71194]
loss: 0.018847  [ 6400/71194]
loss: 0.042562  [12800/71194]
loss: 0.083594  [19200/71194]
loss: 0.019753  [25600/71194]
loss: 0.031154  [32000/71194]
loss: 0.037597  [38400/71194]
loss: 0.139911  [44800/71194]
loss: 1.652534  [51200/71194]
loss: 0.055732  [57600/71194]
loss: 0.065234  [64000/71194]
loss: 0.058598  [70400/71194]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.131771 

Epoch 17
-------------------------------
loss: 0.061617  [    0/71194]
loss: 0.020277  [ 6400/71194]
loss: 0.012186  [12800/71194]
loss: 0.077518  [19200/71194]
loss: 0.078855  [25600/71194]
loss: 0.105849  [32000/71194]
loss: 0.072897  [38400/71194]
loss: 0.099223  [44800/71194]
loss: 0.057464  [51200/71194]
loss: 1.638039  [57600/71194]
loss: 0.048056  [64000/71194]
loss: 0.067894  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.100435 

Epoch 18
-------------------------------
loss: 0.072269  [    0/71194]
loss: 0.032713  [ 6400/71194]
loss: 0.041241  [12800/71194]
loss: 0.058989  [19200/71194]
loss: 0.022655  [25600/71194]
loss: 0.054882  [32000/71194]
loss: 0.056562  [38400/71194]
loss: 1.612969  [44800/71194]
loss: 0.022365  [51200/71194]
loss: 0.106970  [57600/71194]
loss: 0.120910  [64000/71194]
loss: 0.030393  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.099862 

Epoch 19
-------------------------------
loss: 0.028734  [    0/71194]
loss: 0.117711  [ 6400/71194]
loss: 0.005886  [12800/71194]
loss: 0.004957  [19200/71194]
loss: 0.023749  [25600/71194]
loss: 0.074036  [32000/71194]
loss: 0.043875  [38400/71194]
loss: 0.104571  [44800/71194]
loss: 0.052352  [51200/71194]
loss: 0.022362  [57600/71194]
loss: 0.114056  [64000/71194]
loss: 0.095971  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.102352 

Epoch 20
-------------------------------
loss: 0.119811  [    0/71194]
loss: 0.063696  [ 6400/71194]
loss: 0.079970  [12800/71194]
loss: 0.062387  [19200/71194]
loss: 0.076943  [25600/71194]
loss: 0.068092  [32000/71194]
loss: 0.011640  [38400/71194]
loss: 0.053755  [44800/71194]
loss: 0.021332  [51200/71194]
loss: 0.076015  [57600/71194]
loss: 0.039842  [64000/71194]
loss: 0.057031  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.107037 

Epoch 21
-------------------------------
loss: 0.044626  [    0/71194]
loss: 0.035711  [ 6400/71194]
loss: 0.031806  [12800/71194]
loss: 1.651435  [19200/71194]
loss: 0.048506  [25600/71194]
loss: 0.052086  [32000/71194]
loss: 0.069623  [38400/71194]
loss: 0.006173  [44800/71194]
loss: 0.031034  [51200/71194]
loss: 0.020223  [57600/71194]
loss: 0.033939  [64000/71194]
loss: 0.027289  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.106427 

Epoch 22
-------------------------------
loss: 0.028697  [    0/71194]
loss: 0.055264  [ 6400/71194]
loss: 0.063575  [12800/71194]
loss: 0.064849  [19200/71194]
loss: 0.080939  [25600/71194]
loss: 0.008450  [32000/71194]
loss: 0.046554  [38400/71194]
loss: 0.170133  [44800/71194]
loss: 0.035754  [51200/71194]
loss: 0.053825  [57600/71194]
loss: 0.029634  [64000/71194]
loss: 0.071688  [70400/71194]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.102198 

Epoch 23
-------------------------------
loss: 0.048223  [    0/71194]
loss: 0.033940  [ 6400/71194]
loss: 0.118375  [12800/71194]
loss: 0.041031  [12800/71130]
loss: 0.043181  [19200/71130]
loss: 0.048881  [25600/71130]
loss: 0.057160  [32000/71130]
loss: 0.124902  [38400/71130]
loss: 0.144392  [44800/71130]
loss: 0.039290  [51200/71130]
loss: 0.093686  [57600/71130]
loss: 0.016611  [64000/71130]
loss: 0.106577  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066431 

Epoch 6
-------------------------------
loss: 0.086333  [    0/71130]
loss: 0.059696  [ 6400/71130]
loss: 0.078637  [12800/71130]
loss: 0.034834  [19200/71130]
loss: 0.023388  [25600/71130]
loss: 0.022887  [32000/71130]
loss: 0.012602  [38400/71130]
loss: 0.061530  [44800/71130]
loss: 0.013422  [51200/71130]
loss: 0.038202  [57600/71130]
loss: 0.036049  [64000/71130]
loss: 0.043922  [70400/71130]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.061769 

Epoch 7
-------------------------------
loss: 0.104920  [    0/71130]
loss: 0.125905  [ 6400/71130]
loss: 0.120335  [12800/71130]
loss: 0.031391  [19200/71130]
loss: 0.015155  [25600/71130]
loss: 0.144074  [32000/71130]
loss: 0.033125  [38400/71130]
loss: 0.064440  [44800/71130]
loss: 0.015996  [51200/71130]
loss: 0.038753  [57600/71130]
loss: 0.044459  [64000/71130]
loss: 0.073821  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073021 

Epoch 8
-------------------------------
loss: 0.051244  [    0/71130]
loss: 0.023424  [ 6400/71130]
loss: 0.040153  [12800/71130]
loss: 0.033845  [19200/71130]
loss: 0.110365  [25600/71130]
loss: 0.053890  [32000/71130]
loss: 0.058474  [38400/71130]
loss: 0.059397  [44800/71130]
loss: 0.071633  [51200/71130]
loss: 0.098120  [57600/71130]
loss: 0.111046  [64000/71130]
loss: 0.094405  [70400/71130]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.054108 

Epoch 9
-------------------------------
loss: 0.038212  [    0/71130]
loss: 0.108620  [ 6400/71130]
loss: 0.017392  [12800/71130]
loss: 0.034255  [19200/71130]
loss: 0.083312  [25600/71130]
loss: 0.111641  [32000/71130]
loss: 0.006715  [38400/71130]
loss: 0.006414  [44800/71130]
loss: 0.080659  [51200/71130]
loss: 0.069147  [57600/71130]
loss: 0.044632  [64000/71130]
loss: 0.150872  [70400/71130]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.057080 

Epoch 10
-------------------------------
loss: 0.011927  [    0/71130]
loss: 0.030124  [ 6400/71130]
loss: 0.150914  [12800/71130]
loss: 0.017918  [19200/71130]
loss: 0.062366  [25600/71130]
loss: 0.071805  [32000/71130]
loss: 0.024018  [38400/71130]
loss: 0.021833  [44800/71130]
loss: 0.027015  [51200/71130]
loss: 0.086403  [57600/71130]
loss: 0.018118  [64000/71130]
loss: 0.054477  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067544 

Epoch 11
-------------------------------
loss: 0.039248  [    0/71130]
loss: 0.105701  [ 6400/71130]
loss: 0.019883  [12800/71130]
loss: 0.032689  [19200/71130]
loss: 0.062205  [25600/71130]
loss: 0.047006  [32000/71130]
loss: 0.135962  [38400/71130]
loss: 0.020365  [44800/71130]
loss: 0.202057  [51200/71130]
loss: 0.013607  [57600/71130]
loss: 0.016072  [64000/71130]
loss: 0.012215  [70400/71130]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.063332 

Epoch 12
-------------------------------
loss: 0.051617  [    0/71130]
loss: 0.026511  [ 6400/71130]
loss: 0.048267  [12800/71130]
loss: 0.031230  [19200/71130]
loss: 0.071904  [25600/71130]
loss: 0.078532  [32000/71130]
loss: 0.131137  [38400/71130]
loss: 0.003172  [44800/71130]
loss: 0.087825  [51200/71130]
loss: 0.029855  [57600/71130]
loss: 0.023706  [64000/71130]
loss: 0.142216  [70400/71130]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.063554 

Epoch 13
-------------------------------
loss: 0.053031  [    0/71130]
loss: 0.032989  [ 6400/71130]
loss: 0.070072  [12800/71130]
loss: 0.059449  [19200/71130]
loss: 0.021436  [25600/71130]
loss: 0.029081  [32000/71130]
loss: 0.024048  [38400/71130]
loss: 0.008590  [44800/71130]
loss: 0.134127  [51200/71130]
loss: 0.047864  [57600/71130]
loss: 0.135442  [64000/71130]
loss: 0.039233  [70400/71130]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.067234 

Epoch 14
-------------------------------
loss: 0.054120  [    0/71130]
loss: 0.253264  [ 6400/71130]
loss: 0.063482  [12800/71130]
loss: 0.018550  [19200/71130]
loss: 0.028438  [25600/71130]
loss: 0.087916  [32000/71130]
loss: 0.066438  [38400/71130]
loss: 0.071860  [44800/71130]
loss: 0.012215  [51200/71130]
loss: 0.180123  [57600/71130]
loss: 0.031258  [64000/71130]
loss: 0.030893  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.065281 

Epoch 15
-------------------------------
loss: 0.025676  [    0/71130]
loss: 0.063611  [ 6400/71130]
loss: 0.055583  [12800/71130]
loss: 0.033368  [19200/71130]
loss: 0.025818  [25600/71130]
loss: 0.014100  [32000/71130]
loss: 0.038893  [38400/71130]
loss: 0.034800  [44800/71130]
loss: 0.071059  [51200/71130]
loss: 0.006754  [57600/71130]
loss: 0.062710  [64000/71130]
loss: 0.196988  [70400/71130]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.064328 

Epoch 16
-------------------------------
loss: 0.019709  [    0/71130]
loss: 0.031044  [ 6400/71130]
loss: 0.052055  [12800/71130]
loss: 0.024826  [19200/71130]
loss: 0.209129  [25600/71130]
loss: 0.030983  [32000/71130]
loss: 0.005069  [38400/71130]
loss: 0.060517  [44800/71130]
loss: 0.019302  [51200/71130]
loss: 0.127833  [57600/71130]
loss: 0.051211  [64000/71130]
loss: 0.051367  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066687 

Epoch 17
-------------------------------
loss: 0.056202  [    0/71130]
loss: 0.049997  [ 6400/71130]
loss: 0.004475  [12800/71130]
loss: 0.081292  [19200/71130]
loss: 0.031277  [25600/71130]
loss: 0.014027  [32000/71130]
loss: 0.144429  [38400/71130]
loss: 0.076858  [44800/71130]
loss: 0.087237  [51200/71130]
loss: 0.020150  [57600/71130]
loss: 0.018166  [64000/71130]
loss: 0.040657  [70400/71130]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.076235 

Epoch 18
-------------------------------
loss: 0.087490  [    0/71130]
loss: 0.044889  [ 6400/71130]
loss: 0.038848  [12800/71130]
loss: 0.017302  [19200/71130]
loss: 0.040635  [25600/71130]
loss: 0.035042  [32000/71130]
loss: 0.029832  [38400/71130]
loss: 0.018618  [44800/71130]
loss: 0.033619  [51200/71130]
loss: 0.005947  [57600/71130]
loss: 0.148183  [64000/71130]
loss: 0.159176  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070892 

Epoch 19
-------------------------------
loss: 0.040485  [    0/71130]
loss: 0.111565  [ 6400/71130]
loss: 0.065818  [12800/71130]
loss: 0.016089  [19200/71130]
loss: 0.120279  [25600/71130]
loss: 0.042912  [32000/71130]
loss: 0.044151  [38400/71130]
loss: 0.036733  [44800/71130]
loss: 0.128908  [51200/71130]
loss: 0.020641  [57600/71130]
loss: 0.040208  [64000/71130]
loss: 0.032617  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071572 

Epoch 20
-------------------------------
loss: 0.027008  [    0/71130]
loss: 0.142996  [ 6400/71130]
loss: 0.004563  [12800/71130]
loss: 0.016756  [19200/71130]
loss: 0.013427  [25600/71130]
loss: 0.059124  [32000/71130]
loss: 0.025723  [38400/71130]
loss: 0.047005  [44800/71130]
loss: 0.121599  [51200/71130]
loss: 0.053639  [57600/71130]
loss: 0.013981  [64000/71130]
loss: 0.023301  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.071319 

Epoch 21
-------------------------------
loss: 0.069731  [    0/71130]
loss: 0.024896  [ 6400/71130]
loss: 0.037385  [12800/71130]
loss: 0.044559  [19200/71130]
loss: 0.033749  [25600/71130]
loss: 0.081757  [32000/71130]
loss: 0.046245  [38400/71130]
loss: 0.004599  [44800/71130]
loss: 0.110845  [51200/71130]
loss: 0.021087  [57600/71130]
loss: 0.029830  [64000/71130]
loss: 0.056557  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073170 

Epoch 22
-------------------------------
loss: 0.049279  [    0/71130]
loss: 0.005859  [ 6400/71130]
loss: 0.154611  [12800/71130]
loss: 0.035442  [19200/71130]
loss: 0.022028  [25600/71130]
loss: 0.039082  [32000/71130]
loss: 0.053463  [38400/71130]
loss: 0.010449  [44800/71130]
loss: 0.070097  [51200/71130]
loss: 0.022562  [57600/71130]
loss: 0.010019  [64000/71130]
loss: 0.053097  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066933 

Epoch 23
-------------------------------
loss: 0.022162  [    0/71130]
loss: 0.088206  [ 6400/71130]
loss: 0.004268  [12800/71130]
loss: 0.035626  [12800/70506]
loss: 0.097865  [19200/70506]
loss: 0.091114  [25600/70506]
loss: 0.044891  [32000/70506]
loss: 0.061321  [38400/70506]
loss: 0.039678  [44800/70506]
loss: 0.046237  [51200/70506]
loss: 0.093116  [57600/70506]
loss: 0.011649  [64000/70506]
loss: 0.035246  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.055621 

Epoch 6
-------------------------------
loss: 0.017500  [    0/70506]
loss: 0.131190  [ 6400/70506]
loss: 0.065770  [12800/70506]
loss: 0.050880  [19200/70506]
loss: 0.049719  [25600/70506]
loss: 0.093343  [32000/70506]
loss: 0.114714  [38400/70506]
loss: 0.175030  [44800/70506]
loss: 0.027350  [51200/70506]
loss: 0.056633  [57600/70506]
loss: 0.084593  [64000/70506]
loss: 0.069242  [70400/70506]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.051570 

Epoch 7
-------------------------------
loss: 0.015195  [    0/70506]
loss: 0.020949  [ 6400/70506]
loss: 0.047049  [12800/70506]
loss: 0.057028  [19200/70506]
loss: 0.021768  [25600/70506]
loss: 0.077197  [32000/70506]
loss: 0.011053  [38400/70506]
loss: 0.015342  [44800/70506]
loss: 0.046121  [51200/70506]
loss: 0.022478  [57600/70506]
loss: 0.130397  [64000/70506]
loss: 0.037837  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.059240 

Epoch 8
-------------------------------
loss: 0.055848  [    0/70506]
loss: 0.059148  [ 6400/70506]
loss: 0.026505  [12800/70506]
loss: 0.047600  [19200/70506]
loss: 0.099444  [25600/70506]
loss: 0.197701  [32000/70506]
loss: 0.091591  [38400/70506]
loss: 0.033944  [44800/70506]
loss: 0.050134  [51200/70506]
loss: 0.033906  [57600/70506]
loss: 0.017261  [64000/70506]
loss: 0.043531  [70400/70506]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.055177 

Epoch 9
-------------------------------
loss: 0.031489  [    0/70506]
loss: 0.022890  [ 6400/70506]
loss: 0.006275  [12800/70506]
loss: 0.026185  [19200/70506]
loss: 0.036889  [25600/70506]
loss: 0.022152  [32000/70506]
loss: 0.095608  [38400/70506]
loss: 0.061627  [44800/70506]
loss: 0.074084  [51200/70506]
loss: 0.033059  [57600/70506]
loss: 0.019327  [64000/70506]
loss: 0.069690  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.059490 

Epoch 10
-------------------------------
loss: 0.109706  [    0/70506]
loss: 0.058917  [ 6400/70506]
loss: 0.026304  [12800/70506]
loss: 0.050016  [19200/70506]
loss: 0.021218  [25600/70506]
loss: 0.096004  [32000/70506]
loss: 0.025158  [38400/70506]
loss: 0.034509  [44800/70506]
loss: 0.070672  [51200/70506]
loss: 0.024305  [57600/70506]
loss: 0.066395  [64000/70506]
loss: 0.020951  [70400/70506]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.056926 

Epoch 11
-------------------------------
loss: 0.060416  [    0/70506]
loss: 0.059445  [ 6400/70506]
loss: 0.112406  [12800/70506]
loss: 0.158209  [19200/70506]
loss: 0.055301  [25600/70506]
loss: 0.049545  [32000/70506]
loss: 0.012642  [38400/70506]
loss: 0.067617  [44800/70506]
loss: 0.013693  [51200/70506]
loss: 0.014269  [57600/70506]
loss: 0.085624  [64000/70506]
loss: 0.044731  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.065848 

Epoch 12
-------------------------------
loss: 0.083892  [    0/70506]
loss: 0.019018  [ 6400/70506]
loss: 0.083780  [12800/70506]
loss: 0.075316  [19200/70506]
loss: 0.066656  [25600/70506]
loss: 0.076010  [32000/70506]
loss: 0.068010  [38400/70506]
loss: 0.048731  [44800/70506]
loss: 0.021370  [51200/70506]
loss: 0.111457  [57600/70506]
loss: 0.049398  [64000/70506]
loss: 0.030442  [70400/70506]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.064926 

Epoch 13
-------------------------------
loss: 0.039245  [    0/70506]
loss: 0.004494  [ 6400/70506]
loss: 0.050849  [12800/70506]
loss: 0.082371  [19200/70506]
loss: 0.039430  [25600/70506]
loss: 0.081010  [32000/70506]
loss: 0.112726  [38400/70506]
loss: 0.042486  [44800/70506]
loss: 0.041780  [51200/70506]
loss: 0.049046  [57600/70506]
loss: 0.143848  [64000/70506]
loss: 0.008151  [70400/70506]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.055143 

Epoch 14
-------------------------------
loss: 0.020655  [    0/70506]
loss: 0.011480  [ 6400/70506]
loss: 0.016596  [12800/70506]
loss: 0.025058  [19200/70506]
loss: 0.138896  [25600/70506]
loss: 0.051869  [32000/70506]
loss: 0.036429  [38400/70506]
loss: 0.048435  [44800/70506]
loss: 0.091270  [51200/70506]
loss: 0.040732  [57600/70506]
loss: 0.022622  [64000/70506]
loss: 0.049499  [70400/70506]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.054654 

Epoch 15
-------------------------------
loss: 0.025457  [    0/70506]
loss: 0.021983  [ 6400/70506]
loss: 0.036505  [12800/70506]
loss: 0.051622  [19200/70506]
loss: 0.109790  [25600/70506]
loss: 0.011770  [32000/70506]
loss: 0.074518  [38400/70506]
loss: 0.015627  [44800/70506]
loss: 0.040281  [51200/70506]
loss: 0.037043  [57600/70506]
loss: 0.082773  [64000/70506]
loss: 0.022048  [70400/70506]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.056904 

Epoch 16
-------------------------------
loss: 0.000514  [    0/70506]
loss: 0.055606  [ 6400/70506]
loss: 0.080510  [12800/70506]
loss: 0.144207  [19200/70506]
loss: 0.007387  [25600/70506]
loss: 0.074960  [32000/70506]
loss: 0.017909  [38400/70506]
loss: 0.007850  [44800/70506]
loss: 0.070636  [51200/70506]
loss: 0.052459  [57600/70506]
loss: 0.084442  [64000/70506]
loss: 0.074438  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.061125 

Epoch 17
-------------------------------
loss: 0.039452  [    0/70506]
loss: 0.104774  [ 6400/70506]
loss: 0.054013  [12800/70506]
loss: 0.200585  [19200/70506]
loss: 0.082226  [25600/70506]
loss: 0.062196  [32000/70506]
loss: 0.045342  [38400/70506]
loss: 0.021616  [44800/70506]
loss: 0.003030  [51200/70506]
loss: 0.015012  [57600/70506]
loss: 0.003611  [64000/70506]
loss: 0.040951  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.057934 

Epoch 18
-------------------------------
loss: 0.075583  [    0/70506]
loss: 0.042237  [ 6400/70506]
loss: 0.081381  [12800/70506]
loss: 0.002336  [19200/70506]
loss: 0.145430  [25600/70506]
loss: 0.013210  [32000/70506]
loss: 0.013591  [38400/70506]
loss: 0.044975  [44800/70506]
loss: 0.005453  [51200/70506]
loss: 0.061570  [57600/70506]
loss: 0.027268  [64000/70506]
loss: 0.138743  [70400/70506]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.056560 

Epoch 19
-------------------------------
loss: 0.045277  [    0/70506]
loss: 0.008734  [ 6400/70506]
loss: 0.036179  [12800/70506]
loss: 0.065013  [19200/70506]
loss: 0.115127  [25600/70506]
loss: 0.073438  [32000/70506]
loss: 0.006457  [38400/70506]
loss: 0.016806  [44800/70506]
loss: 0.025256  [51200/70506]
loss: 0.044887  [57600/70506]
loss: 0.050331  [64000/70506]
loss: 0.077294  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.062010 

Epoch 20
-------------------------------
loss: 0.111436  [    0/70506]
loss: 0.060319  [ 6400/70506]
loss: 0.050145  [12800/70506]
loss: 0.114303  [19200/70506]
loss: 0.008483  [25600/70506]
loss: 0.153604  [32000/70506]
loss: 0.022707  [38400/70506]
loss: 0.028687  [44800/70506]
loss: 0.034585  [51200/70506]
loss: 0.061325  [57600/70506]
loss: 0.049587  [64000/70506]
loss: 0.020595  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.060993 

Epoch 21
-------------------------------
loss: 0.016181  [    0/70506]
loss: 0.053591  [ 6400/70506]
loss: 0.010348  [12800/70506]
loss: 0.024042  [19200/70506]
loss: 0.029322  [25600/70506]
loss: 0.042888  [32000/70506]
loss: 0.006023  [38400/70506]
loss: 0.033779  [44800/70506]
loss: 0.022653  [51200/70506]
loss: 0.007410  [57600/70506]
loss: 0.018981  [64000/70506]
loss: 0.118552  [70400/70506]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.056290 

Epoch 22
-------------------------------
loss: 0.011890  [    0/70506]
loss: 0.006646  [ 6400/70506]
loss: 0.020926  [12800/70506]
loss: 0.005299  [19200/70506]
loss: 0.099795  [25600/70506]
loss: 0.022935  [32000/70506]
loss: 0.012296  [38400/70506]
loss: 0.007059  [44800/70506]
loss: 0.062636  [51200/70506]
loss: 0.035760  [57600/70506]
loss: 0.010786  [64000/70506]
loss: 0.028959  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.061885 

Epoch 23
-------------------------------
loss: 0.035145  [    0/70506]
loss: 0.013470  [ 6400/70506]
loss: 0.055844  [12800/70506]
loss: 0.114381  [12800/72203]
loss: 0.016882  [19200/72203]
loss: 0.147164  [25600/72203]
loss: 0.147069  [32000/72203]
loss: 0.041894  [38400/72203]
loss: 0.065825  [44800/72203]
loss: 0.085805  [51200/72203]
loss: 0.019955  [57600/72203]
loss: 0.126542  [64000/72203]
loss: 0.043909  [70400/72203]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.139828 

Epoch 6
-------------------------------
loss: 0.085439  [    0/72203]
loss: 0.052157  [ 6400/72203]
loss: 0.021801  [12800/72203]
loss: 0.016269  [19200/72203]
loss: 0.048333  [25600/72203]
loss: 0.080250  [32000/72203]
loss: 0.024326  [38400/72203]
loss: 0.042993  [44800/72203]
loss: 0.060103  [51200/72203]
loss: 0.052679  [57600/72203]
loss: 0.085400  [64000/72203]
loss: 0.060176  [70400/72203]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.141534 

Epoch 7
-------------------------------
loss: 0.021116  [    0/72203]
loss: 0.071170  [ 6400/72203]
loss: 0.028193  [12800/72203]
loss: 0.092598  [19200/72203]
loss: 0.048842  [25600/72203]
loss: 0.007107  [32000/72203]
loss: 0.037577  [38400/72203]
loss: 1.636953  [44800/72203]
loss: 0.016488  [51200/72203]
loss: 0.026020  [57600/72203]
loss: 0.070504  [64000/72203]
loss: 0.052020  [70400/72203]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.139013 

Epoch 8
-------------------------------
loss: 0.054283  [    0/72203]
loss: 0.040684  [ 6400/72203]
loss: 0.077060  [12800/72203]
loss: 0.063716  [19200/72203]
loss: 0.063000  [25600/72203]
loss: 0.015171  [32000/72203]
loss: 0.048235  [38400/72203]
loss: 0.128702  [44800/72203]
loss: 0.071106  [51200/72203]
loss: 0.089853  [57600/72203]
loss: 0.140000  [64000/72203]
loss: 0.105787  [70400/72203]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.138771 

Epoch 9
-------------------------------
loss: 0.038569  [    0/72203]
loss: 0.026793  [ 6400/72203]
loss: 0.040115  [12800/72203]
loss: 0.157748  [19200/72203]
loss: 0.002022  [25600/72203]
loss: 0.027057  [32000/72203]
loss: 0.031298  [38400/72203]
loss: 0.113444  [44800/72203]
loss: 0.045321  [51200/72203]
loss: 0.076468  [57600/72203]
loss: 0.028389  [64000/72203]
loss: 0.042253  [70400/72203]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.145737 

Epoch 10
-------------------------------
loss: 0.168393  [    0/72203]
loss: 0.026434  [ 6400/72203]
loss: 0.097551  [12800/72203]
loss: 0.056848  [19200/72203]
loss: 1.617928  [25600/72203]
loss: 0.026774  [32000/72203]
loss: 0.026021  [38400/72203]
loss: 1.680245  [44800/72203]
loss: 0.069861  [51200/72203]
loss: 0.152364  [57600/72203]
loss: 0.040167  [64000/72203]
loss: 0.035965  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.139768 

Epoch 11
-------------------------------
loss: 1.607566  [    0/72203]
loss: 1.671240  [ 6400/72203]
loss: 0.042468  [12800/72203]
loss: 0.098051  [19200/72203]
loss: 0.201444  [25600/72203]
loss: 0.132350  [32000/72203]
loss: 0.076396  [38400/72203]
loss: 0.048768  [44800/72203]
loss: 0.052327  [51200/72203]
loss: 0.054875  [57600/72203]
loss: 0.042993  [64000/72203]
loss: 0.033936  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.140001 

Epoch 12
-------------------------------
loss: 1.606691  [    0/72203]
loss: 0.056318  [ 6400/72203]
loss: 0.151841  [12800/72203]
loss: 0.043557  [19200/72203]
loss: 0.092789  [25600/72203]
loss: 0.030574  [32000/72203]
loss: 0.089989  [38400/72203]
loss: 0.073033  [44800/72203]
loss: 0.031491  [51200/72203]
loss: 0.002609  [57600/72203]
loss: 0.045522  [64000/72203]
loss: 0.089896  [70400/72203]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.144679 

Epoch 13
-------------------------------
loss: 0.053678  [    0/72203]
loss: 0.080317  [ 6400/72203]
loss: 0.109628  [12800/72203]
loss: 0.025405  [19200/72203]
loss: 0.096639  [25600/72203]
loss: 0.097469  [32000/72203]
loss: 0.116932  [38400/72203]
loss: 0.052855  [44800/72203]
loss: 0.077867  [51200/72203]
loss: 0.086630  [57600/72203]
loss: 0.098272  [64000/72203]
loss: 0.067604  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.139459 

Epoch 14
-------------------------------
loss: 0.015097  [    0/72203]
loss: 0.041549  [ 6400/72203]
loss: 0.012749  [12800/72203]
loss: 0.031392  [19200/72203]
loss: 0.052092  [25600/72203]
loss: 0.122003  [32000/72203]
loss: 0.071470  [38400/72203]
loss: 0.029492  [44800/72203]
loss: 0.143036  [51200/72203]
loss: 0.057115  [57600/72203]
loss: 0.145874  [64000/72203]
loss: 1.580211  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.138915 

Epoch 15
-------------------------------
loss: 0.057650  [    0/72203]
loss: 0.064178  [ 6400/72203]
loss: 0.088541  [12800/72203]
loss: 0.069177  [19200/72203]
loss: 0.055577  [25600/72203]
loss: 0.014663  [32000/72203]
loss: 0.112085  [38400/72203]
loss: 0.014225  [44800/72203]
loss: 0.011201  [51200/72203]
loss: 0.110642  [57600/72203]
loss: 0.026254  [64000/72203]
loss: 0.093849  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.142319 

Epoch 16
-------------------------------
loss: 0.027172  [    0/72203]
loss: 0.035691  [ 6400/72203]
loss: 0.074833  [12800/72203]
loss: 0.062862  [19200/72203]
loss: 0.041821  [25600/72203]
loss: 0.046483  [32000/72203]
loss: 0.031972  [38400/72203]
loss: 0.040450  [44800/72203]
loss: 0.092762  [51200/72203]
loss: 0.175804  [57600/72203]
loss: 0.062436  [64000/72203]
loss: 0.035196  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.147227 

Epoch 17
-------------------------------
loss: 0.049502  [    0/72203]
loss: 0.065298  [ 6400/72203]
loss: 1.597092  [12800/72203]
loss: 0.065715  [19200/72203]
loss: 0.027528  [25600/72203]
loss: 0.089414  [32000/72203]
loss: 0.093305  [38400/72203]
loss: 0.034440  [44800/72203]
loss: 0.029708  [51200/72203]
loss: 0.039691  [57600/72203]
loss: 0.022734  [64000/72203]
loss: 0.042848  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.137619 

Epoch 18
-------------------------------
loss: 0.038170  [    0/72203]
loss: 0.039498  [ 6400/72203]
loss: 0.027954  [12800/72203]
loss: 0.062208  [19200/72203]
loss: 0.023127  [25600/72203]
loss: 0.091973  [32000/72203]
loss: 0.008215  [38400/72203]
loss: 0.032059  [44800/72203]
loss: 0.048840  [51200/72203]
loss: 0.100653  [57600/72203]
loss: 0.067494  [64000/72203]
loss: 0.105427  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.144508 

Epoch 19
-------------------------------
loss: 0.087659  [    0/72203]
loss: 0.021983  [ 6400/72203]
loss: 0.031109  [12800/72203]
loss: 0.052121  [19200/72203]
loss: 0.120580  [25600/72203]
loss: 1.600688  [32000/72203]
loss: 0.028539  [38400/72203]
loss: 0.030784  [44800/72203]
loss: 0.125659  [51200/72203]
loss: 0.054912  [57600/72203]
loss: 0.122993  [64000/72203]
loss: 0.068455  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.144219 

Epoch 20
-------------------------------
loss: 0.011034  [    0/72203]
loss: 0.031677  [ 6400/72203]
loss: 0.040676  [12800/72203]
loss: 0.025748  [19200/72203]
loss: 0.044483  [25600/72203]
loss: 0.038628  [32000/72203]
loss: 0.050523  [38400/72203]
loss: 0.155992  [44800/72203]
loss: 0.077929  [51200/72203]
loss: 0.064020  [57600/72203]
loss: 0.045265  [64000/72203]
loss: 0.179810  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.147039 

Epoch 21
-------------------------------
loss: 0.012613  [    0/72203]
loss: 0.017934  [ 6400/72203]
loss: 0.035764  [12800/72203]
loss: 1.603582  [19200/72203]
loss: 0.037642  [25600/72203]
loss: 0.067982  [32000/72203]
loss: 0.051823  [38400/72203]
loss: 0.013951  [44800/72203]
loss: 0.133656  [51200/72203]
loss: 0.012124  [57600/72203]
loss: 0.144571  [64000/72203]
loss: 0.082452  [70400/72203]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.148147 

Epoch 22
-------------------------------
loss: 0.056204  [    0/72203]
loss: 0.020121  [ 6400/72203]
loss: 0.048903  [12800/72203]
loss: 0.048935  [19200/72203]
loss: 0.056308  [25600/72203]
loss: 0.010063  [32000/72203]
loss: 0.091138  [38400/72203]
loss: 0.121226  [44800/72203]
loss: 0.063112  [51200/72203]
loss: 0.051343  [57600/72203]
loss: 0.074226  [64000/72203]
loss: 0.101171  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.144489 

Epoch 23
-------------------------------
loss: 0.091977  [    0/72203]
loss: 0.028159  [ 6400/72203]
loss: 0.122426  [12800/72203]
loss: 0.114134  [12800/70644]
loss: 0.008738  [19200/70644]
loss: 0.024848  [25600/70644]
loss: 0.090611  [32000/70644]
loss: 0.084277  [38400/70644]
loss: 0.078790  [44800/70644]
loss: 0.085941  [51200/70644]
loss: 0.126133  [57600/70644]
loss: 0.024400  [64000/70644]
loss: 0.127200  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.085569 

Epoch 6
-------------------------------
loss: 0.052392  [    0/70644]
loss: 0.094589  [ 6400/70644]
loss: 0.031384  [12800/70644]
loss: 0.049352  [19200/70644]
loss: 0.104921  [25600/70644]
loss: 0.021028  [32000/70644]
loss: 0.017919  [38400/70644]
loss: 0.100743  [44800/70644]
loss: 0.112870  [51200/70644]
loss: 0.038641  [57600/70644]
loss: 0.072518  [64000/70644]
loss: 0.054573  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084453 

Epoch 7
-------------------------------
loss: 0.078381  [    0/70644]
loss: 0.113069  [ 6400/70644]
loss: 0.058238  [12800/70644]
loss: 0.076205  [19200/70644]
loss: 0.129182  [25600/70644]
loss: 0.059181  [32000/70644]
loss: 0.050980  [38400/70644]
loss: 0.244981  [44800/70644]
loss: 0.038908  [51200/70644]
loss: 0.028738  [57600/70644]
loss: 0.108356  [64000/70644]
loss: 0.076278  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083179 

Epoch 8
-------------------------------
loss: 0.106039  [    0/70644]
loss: 0.074671  [ 6400/70644]
loss: 0.107263  [12800/70644]
loss: 0.170803  [19200/70644]
loss: 0.019492  [25600/70644]
loss: 0.085452  [32000/70644]
loss: 0.038617  [38400/70644]
loss: 0.038999  [44800/70644]
loss: 0.125938  [51200/70644]
loss: 0.052030  [57600/70644]
loss: 0.099134  [64000/70644]
loss: 0.045858  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084848 

Epoch 9
-------------------------------
loss: 0.069573  [    0/70644]
loss: 0.033021  [ 6400/70644]
loss: 0.034254  [12800/70644]
loss: 0.016293  [19200/70644]
loss: 0.018787  [25600/70644]
loss: 0.031675  [32000/70644]
loss: 0.095027  [38400/70644]
loss: 0.070223  [44800/70644]
loss: 0.100058  [51200/70644]
loss: 0.127558  [57600/70644]
loss: 0.084119  [64000/70644]
loss: 0.076964  [70400/70644]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.078572 

Epoch 10
-------------------------------
loss: 0.065131  [    0/70644]
loss: 0.063081  [ 6400/70644]
loss: 0.081718  [12800/70644]
loss: 0.094232  [19200/70644]
loss: 0.133020  [25600/70644]
loss: 0.063456  [32000/70644]
loss: 0.027155  [38400/70644]
loss: 0.063441  [44800/70644]
loss: 0.029492  [51200/70644]
loss: 0.057613  [57600/70644]
loss: 0.063029  [64000/70644]
loss: 0.061040  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.068578 

Epoch 11
-------------------------------
loss: 0.103145  [    0/70644]
loss: 0.039426  [ 6400/70644]
loss: 0.014923  [12800/70644]
loss: 0.090988  [19200/70644]
loss: 0.105702  [25600/70644]
loss: 0.040597  [32000/70644]
loss: 0.035579  [38400/70644]
loss: 0.005399  [44800/70644]
loss: 0.111552  [51200/70644]
loss: 0.036690  [57600/70644]
loss: 0.118882  [64000/70644]
loss: 0.054825  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.072255 

Epoch 12
-------------------------------
loss: 0.048722  [    0/70644]
loss: 0.047756  [ 6400/70644]
loss: 0.012036  [12800/70644]
loss: 0.080106  [19200/70644]
loss: 0.146969  [25600/70644]
loss: 0.081158  [32000/70644]
loss: 0.061576  [38400/70644]
loss: 0.081136  [44800/70644]
loss: 0.036122  [51200/70644]
loss: 0.052806  [57600/70644]
loss: 0.162868  [64000/70644]
loss: 0.061070  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.072696 

Epoch 13
-------------------------------
loss: 0.048071  [    0/70644]
loss: 0.022258  [ 6400/70644]
loss: 0.101188  [12800/70644]
loss: 0.085641  [19200/70644]
loss: 0.074240  [25600/70644]
loss: 0.068361  [32000/70644]
loss: 0.072288  [38400/70644]
loss: 0.101336  [44800/70644]
loss: 0.081865  [51200/70644]
loss: 0.036955  [57600/70644]
loss: 0.120574  [64000/70644]
loss: 0.055085  [70400/70644]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082164 

Epoch 14
-------------------------------
loss: 0.018457  [    0/70644]
loss: 0.040114  [ 6400/70644]
loss: 0.075054  [12800/70644]
loss: 0.114241  [19200/70644]
loss: 0.097604  [25600/70644]
loss: 0.089332  [32000/70644]
loss: 0.013413  [38400/70644]
loss: 0.062883  [44800/70644]
loss: 0.169582  [51200/70644]
loss: 0.093090  [57600/70644]
loss: 0.135404  [64000/70644]
loss: 0.038451  [70400/70644]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082794 

Epoch 15
-------------------------------
loss: 0.033501  [    0/70644]
loss: 0.032318  [ 6400/70644]
loss: 0.050061  [12800/70644]
loss: 0.033844  [19200/70644]
loss: 0.020439  [25600/70644]
loss: 0.057292  [32000/70644]
loss: 0.144943  [38400/70644]
loss: 0.098770  [44800/70644]
loss: 0.011887  [51200/70644]
loss: 0.013275  [57600/70644]
loss: 0.083502  [64000/70644]
loss: 0.020441  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078549 

Epoch 16
-------------------------------
loss: 0.085954  [    0/70644]
loss: 0.021884  [ 6400/70644]
loss: 0.117418  [12800/70644]
loss: 0.050997  [19200/70644]
loss: 0.108586  [25600/70644]
loss: 0.109403  [32000/70644]
loss: 0.021685  [38400/70644]
loss: 0.099347  [44800/70644]
loss: 0.081684  [51200/70644]
loss: 0.027097  [57600/70644]
loss: 0.045443  [64000/70644]
loss: 0.084405  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.076957 

Epoch 17
-------------------------------
loss: 0.087593  [    0/70644]
loss: 0.069644  [ 6400/70644]
loss: 0.051846  [12800/70644]
loss: 0.019220  [19200/70644]
loss: 0.045764  [25600/70644]
loss: 0.078212  [32000/70644]
loss: 0.098175  [38400/70644]
loss: 0.080354  [44800/70644]
loss: 0.058761  [51200/70644]
loss: 0.129106  [57600/70644]
loss: 0.069397  [64000/70644]
loss: 0.075304  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082571 

Epoch 18
-------------------------------
loss: 0.046069  [    0/70644]
loss: 0.058460  [ 6400/70644]
loss: 0.037642  [12800/70644]
loss: 0.027484  [19200/70644]
loss: 0.021276  [25600/70644]
loss: 0.056670  [32000/70644]
loss: 0.055086  [38400/70644]
loss: 0.074833  [44800/70644]
loss: 0.030405  [51200/70644]
loss: 0.031731  [57600/70644]
loss: 0.091031  [64000/70644]
loss: 0.028579  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076926 

Epoch 19
-------------------------------
loss: 0.042499  [    0/70644]
loss: 0.018259  [ 6400/70644]
loss: 0.083901  [12800/70644]
loss: 0.097783  [19200/70644]
loss: 0.090073  [25600/70644]
loss: 0.070035  [32000/70644]
loss: 0.077590  [38400/70644]
loss: 0.109530  [44800/70644]
loss: 0.044585  [51200/70644]
loss: 0.059187  [57600/70644]
loss: 0.087134  [64000/70644]
loss: 0.043894  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.087728 

Epoch 20
-------------------------------
loss: 0.033349  [    0/70644]
loss: 0.019937  [ 6400/70644]
loss: 0.027899  [12800/70644]
loss: 0.124041  [19200/70644]
loss: 0.130178  [25600/70644]
loss: 0.073908  [32000/70644]
loss: 0.050059  [38400/70644]
loss: 0.109542  [44800/70644]
loss: 0.072647  [51200/70644]
loss: 0.049509  [57600/70644]
loss: 0.089984  [64000/70644]
loss: 0.030465  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.078600 

Epoch 21
-------------------------------
loss: 0.076190  [    0/70644]
loss: 0.080046  [ 6400/70644]
loss: 0.026454  [12800/70644]
loss: 0.022538  [19200/70644]
loss: 0.153460  [25600/70644]
loss: 0.059342  [32000/70644]
loss: 0.025231  [38400/70644]
loss: 0.107065  [44800/70644]
loss: 0.146737  [51200/70644]
loss: 0.013154  [57600/70644]
loss: 0.047547  [64000/70644]
loss: 0.043434  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.081443 

Epoch 22
-------------------------------
loss: 0.011897  [    0/70644]
loss: 0.062679  [ 6400/70644]
loss: 0.070156  [12800/70644]
loss: 0.036916  [19200/70644]
loss: 0.070594  [25600/70644]
loss: 0.034441  [32000/70644]
loss: 0.036716  [38400/70644]
loss: 0.101158  [44800/70644]
loss: 0.094786  [51200/70644]
loss: 0.039306  [57600/70644]
loss: 0.047904  [64000/70644]
loss: 0.047156  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.082355 

Epoch 23
-------------------------------
loss: 0.020312  [    0/70644]
loss: 0.062789  [ 6400/70644]
loss: 0.010081  [12800/70644]
loss: 0.048636  [12800/70999]
loss: 0.188987  [19200/70999]
loss: 0.107085  [25600/70999]
loss: 0.265369  [32000/70999]
loss: 0.102165  [38400/70999]
loss: 0.150393  [44800/70999]
loss: 0.157289  [51200/70999]
loss: 0.144852  [57600/70999]
loss: 0.086620  [64000/70999]
loss: 0.193832  [70400/70999]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.140970 

Epoch 6
-------------------------------
loss: 0.089530  [    0/70999]
loss: 0.241834  [ 6400/70999]
loss: 0.096959  [12800/70999]
loss: 0.070693  [19200/70999]
loss: 0.047312  [25600/70999]
loss: 0.080423  [32000/70999]
loss: 0.153460  [38400/70999]
loss: 0.167088  [44800/70999]
loss: 0.095837  [51200/70999]
loss: 0.156567  [57600/70999]
loss: 0.139149  [64000/70999]
loss: 0.197223  [70400/70999]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160389 

Epoch 7
-------------------------------
loss: 0.184521  [    0/70999]
loss: 0.126524  [ 6400/70999]
loss: 0.181227  [12800/70999]
loss: 0.063585  [19200/70999]
loss: 0.240698  [25600/70999]
loss: 0.041944  [32000/70999]
loss: 0.062864  [38400/70999]
loss: 0.159690  [44800/70999]
loss: 0.139682  [51200/70999]
loss: 0.100170  [57600/70999]
loss: 0.114765  [64000/70999]
loss: 0.095337  [70400/70999]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.143269 

Epoch 8
-------------------------------
loss: 0.052590  [    0/70999]
loss: 0.105200  [ 6400/70999]
loss: 0.112219  [12800/70999]
loss: 0.092475  [19200/70999]
loss: 0.192278  [25600/70999]
loss: 0.168907  [32000/70999]
loss: 0.163171  [38400/70999]
loss: 0.087536  [44800/70999]
loss: 0.129295  [51200/70999]
loss: 0.092172  [57600/70999]
loss: 0.157115  [64000/70999]
loss: 0.091282  [70400/70999]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.133560 

Epoch 9
-------------------------------
loss: 0.209353  [    0/70999]
loss: 0.106058  [ 6400/70999]
loss: 0.095115  [12800/70999]
loss: 0.095756  [19200/70999]
loss: 0.227961  [25600/70999]
loss: 0.074502  [32000/70999]
loss: 0.254901  [38400/70999]
loss: 0.118515  [44800/70999]
loss: 0.178281  [51200/70999]
loss: 0.129658  [57600/70999]
loss: 0.102506  [64000/70999]
loss: 0.081427  [70400/70999]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.135986 

Epoch 10
-------------------------------
loss: 0.192549  [    0/70999]
loss: 0.117734  [ 6400/70999]
loss: 0.089856  [12800/70999]
loss: 0.145280  [19200/70999]
loss: 0.134630  [25600/70999]
loss: 0.090399  [32000/70999]
loss: 0.101975  [38400/70999]
loss: 0.129142  [44800/70999]
loss: 0.154176  [51200/70999]
loss: 0.107891  [57600/70999]
loss: 0.140555  [64000/70999]
loss: 0.165140  [70400/70999]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.157126 

Epoch 11
-------------------------------
loss: 0.404574  [    0/70999]
loss: 0.154307  [ 6400/70999]
loss: 0.142757  [12800/70999]
loss: 0.078278  [19200/70999]
loss: 0.102766  [25600/70999]
loss: 0.349001  [32000/70999]
loss: 0.055979  [38400/70999]
loss: 0.066447  [44800/70999]
loss: 0.059103  [51200/70999]
loss: 0.187047  [57600/70999]
loss: 0.099026  [64000/70999]
loss: 0.092845  [70400/70999]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139281 

Epoch 12
-------------------------------
loss: 0.107012  [    0/70999]
loss: 0.272565  [ 6400/70999]
loss: 0.208322  [12800/70999]
loss: 0.123911  [19200/70999]
loss: 0.035983  [25600/70999]
loss: 0.081299  [32000/70999]
loss: 0.203772  [38400/70999]
loss: 0.171602  [44800/70999]
loss: 0.143084  [51200/70999]
loss: 0.151191  [57600/70999]
loss: 0.090447  [64000/70999]
loss: 0.105901  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.144221 

Epoch 13
-------------------------------
loss: 0.151597  [    0/70999]
loss: 0.151320  [ 6400/70999]
loss: 0.211366  [12800/70999]
loss: 0.062094  [19200/70999]
loss: 0.188397  [25600/70999]
loss: 0.075729  [32000/70999]
loss: 0.150825  [38400/70999]
loss: 0.120273  [44800/70999]
loss: 0.182374  [51200/70999]
loss: 0.131087  [57600/70999]
loss: 0.075876  [64000/70999]
loss: 0.156215  [70400/70999]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.146238 

Epoch 14
-------------------------------
loss: 0.167908  [    0/70999]
loss: 0.084573  [ 6400/70999]
loss: 0.071942  [12800/70999]
loss: 0.085791  [19200/70999]
loss: 0.161781  [25600/70999]
loss: 0.092059  [32000/70999]
loss: 0.074455  [38400/70999]
loss: 0.152360  [44800/70999]
loss: 0.105630  [51200/70999]
loss: 0.189010  [57600/70999]
loss: 0.047751  [64000/70999]
loss: 0.137381  [70400/70999]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.144872 

Epoch 15
-------------------------------
loss: 0.118353  [    0/70999]
loss: 0.042457  [ 6400/70999]
loss: 0.168993  [12800/70999]
loss: 0.320205  [19200/70999]
loss: 0.084126  [25600/70999]
loss: 0.149809  [32000/70999]
loss: 0.160100  [38400/70999]
loss: 0.136609  [44800/70999]
loss: 0.122063  [51200/70999]
loss: 0.157015  [57600/70999]
loss: 0.125316  [64000/70999]
loss: 0.068680  [70400/70999]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.131416 

Epoch 16
-------------------------------
loss: 0.063074  [    0/70999]
loss: 0.143297  [ 6400/70999]
loss: 0.227226  [12800/70999]
loss: 0.147572  [19200/70999]
loss: 0.124262  [25600/70999]
loss: 0.039611  [32000/70999]
loss: 0.160063  [38400/70999]
loss: 0.165914  [44800/70999]
loss: 0.231308  [51200/70999]
loss: 0.034376  [57600/70999]
loss: 0.125976  [64000/70999]
loss: 0.233159  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.132409 

Epoch 17
-------------------------------
loss: 0.061161  [    0/70999]
loss: 0.208890  [ 6400/70999]
loss: 0.105485  [12800/70999]
loss: 0.119578  [19200/70999]
loss: 0.180415  [25600/70999]
loss: 0.192810  [32000/70999]
loss: 0.060484  [38400/70999]
loss: 0.059147  [44800/70999]
loss: 0.233246  [51200/70999]
loss: 0.176208  [57600/70999]
loss: 0.161016  [64000/70999]
loss: 0.178483  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.134355 

Epoch 18
-------------------------------
loss: 0.052941  [    0/70999]
loss: 0.161323  [ 6400/70999]
loss: 0.092361  [12800/70999]
loss: 0.081186  [19200/70999]
loss: 0.087082  [25600/70999]
loss: 0.081345  [32000/70999]
loss: 0.116130  [38400/70999]
loss: 0.063450  [44800/70999]
loss: 0.103390  [51200/70999]
loss: 0.140244  [57600/70999]
loss: 0.089299  [64000/70999]
loss: 0.093671  [70400/70999]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.136978 

Epoch 19
-------------------------------
loss: 0.096004  [    0/70999]
loss: 0.213746  [ 6400/70999]
loss: 0.129695  [12800/70999]
loss: 0.150525  [19200/70999]
loss: 0.236891  [25600/70999]
loss: 0.142775  [32000/70999]
loss: 0.079454  [38400/70999]
loss: 0.105574  [44800/70999]
loss: 0.109831  [51200/70999]
loss: 0.162084  [57600/70999]
loss: 0.143783  [64000/70999]
loss: 0.057625  [70400/70999]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150932 

Epoch 20
-------------------------------
loss: 0.080364  [    0/70999]
loss: 0.096666  [ 6400/70999]
loss: 0.095916  [12800/70999]
loss: 0.121205  [19200/70999]
loss: 0.233609  [25600/70999]
loss: 0.081642  [32000/70999]
loss: 0.039966  [38400/70999]
loss: 0.062618  [44800/70999]
loss: 0.122133  [51200/70999]
loss: 0.093812  [57600/70999]
loss: 0.071389  [64000/70999]
loss: 0.194705  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.137149 

Epoch 21
-------------------------------
loss: 0.067451  [    0/70999]
loss: 0.055932  [ 6400/70999]
loss: 0.103112  [12800/70999]
loss: 0.061015  [19200/70999]
loss: 0.224715  [25600/70999]
loss: 0.167909  [32000/70999]
loss: 0.160787  [38400/70999]
loss: 0.074634  [44800/70999]
loss: 0.132298  [51200/70999]
loss: 0.169806  [57600/70999]
loss: 0.145095  [64000/70999]
loss: 0.097661  [70400/70999]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.146614 

Epoch 22
-------------------------------
loss: 0.067013  [    0/70999]
loss: 0.147381  [ 6400/70999]
loss: 0.076878  [12800/70999]
loss: 0.165281  [19200/70999]
loss: 0.110259  [25600/70999]
loss: 0.156490  [32000/70999]
loss: 0.124659  [38400/70999]
loss: 0.103807  [44800/70999]
loss: 0.103808  [51200/70999]
loss: 0.118611  [57600/70999]
loss: 0.047460  [64000/70999]
loss: 0.089133  [70400/70999]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.132824 

Epoch 23
-------------------------------
loss: 0.045174  [    0/70999]
loss: 0.076637  [ 6400/70999]
loss: 0.023024  [12800/70999]
loss: 0.093690  [12800/71198]
loss: 0.007845  [19200/71198]
loss: 0.208664  [25600/71198]
loss: 0.093698  [32000/71198]
loss: 0.048426  [38400/71198]
loss: 0.049942  [44800/71198]
loss: 0.085010  [51200/71198]
loss: 0.046672  [57600/71198]
loss: 0.435270  [64000/71198]
loss: 0.028300  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.053863 

Epoch 6
-------------------------------
loss: 0.032963  [    0/71198]
loss: 0.069098  [ 6400/71198]
loss: 0.100198  [12800/71198]
loss: 0.050497  [19200/71198]
loss: 0.037021  [25600/71198]
loss: 0.045395  [32000/71198]
loss: 0.094649  [38400/71198]
loss: 0.167140  [44800/71198]
loss: 0.043905  [51200/71198]
loss: 0.131691  [57600/71198]
loss: 0.064954  [64000/71198]
loss: 0.055583  [70400/71198]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.053073 

Epoch 7
-------------------------------
loss: 0.055914  [    0/71198]
loss: 0.064723  [ 6400/71198]
loss: 0.043428  [12800/71198]
loss: 0.049034  [19200/71198]
loss: 0.016211  [25600/71198]
loss: 0.056326  [32000/71198]
loss: 0.064778  [38400/71198]
loss: 0.030778  [44800/71198]
loss: 0.069381  [51200/71198]
loss: 0.026308  [57600/71198]
loss: 0.054398  [64000/71198]
loss: 0.155105  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.055097 

Epoch 8
-------------------------------
loss: 0.148015  [    0/71198]
loss: 0.013203  [ 6400/71198]
loss: 0.110991  [12800/71198]
loss: 0.034459  [19200/71198]
loss: 0.029953  [25600/71198]
loss: 0.039880  [32000/71198]
loss: 0.112910  [38400/71198]
loss: 0.055427  [44800/71198]
loss: 0.189898  [51200/71198]
loss: 0.112610  [57600/71198]
loss: 0.057081  [64000/71198]
loss: 0.025350  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.056844 

Epoch 9
-------------------------------
loss: 0.020708  [    0/71198]
loss: 0.030684  [ 6400/71198]
loss: 0.044731  [12800/71198]
loss: 0.075650  [19200/71198]
loss: 0.145870  [25600/71198]
loss: 0.057773  [32000/71198]
loss: 0.065886  [38400/71198]
loss: 0.006819  [44800/71198]
loss: 0.050350  [51200/71198]
loss: 0.056720  [57600/71198]
loss: 0.068081  [64000/71198]
loss: 0.119000  [70400/71198]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.056202 

Epoch 10
-------------------------------
loss: 0.077324  [    0/71198]
loss: 0.119422  [ 6400/71198]
loss: 0.107519  [12800/71198]
loss: 0.070191  [19200/71198]
loss: 0.025925  [25600/71198]
loss: 0.107397  [32000/71198]
loss: 0.059074  [38400/71198]
loss: 0.083161  [44800/71198]
loss: 0.066920  [51200/71198]
loss: 0.025741  [57600/71198]
loss: 0.011036  [64000/71198]
loss: 0.075126  [70400/71198]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.103603 

Epoch 11
-------------------------------
loss: 0.167832  [    0/71198]
loss: 0.030664  [ 6400/71198]
loss: 0.072437  [12800/71198]
loss: 0.076058  [19200/71198]
loss: 0.104918  [25600/71198]
loss: 0.078218  [32000/71198]
loss: 0.010429  [38400/71198]
loss: 0.067603  [44800/71198]
loss: 0.089723  [51200/71198]
loss: 0.043968  [57600/71198]
loss: 0.046110  [64000/71198]
loss: 0.052170  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.061686 

Epoch 12
-------------------------------
loss: 0.033205  [    0/71198]
loss: 0.037601  [ 6400/71198]
loss: 0.012594  [12800/71198]
loss: 0.040087  [19200/71198]
loss: 0.036213  [25600/71198]
loss: 0.044442  [32000/71198]
loss: 0.050106  [38400/71198]
loss: 0.021977  [44800/71198]
loss: 0.079698  [51200/71198]
loss: 0.034732  [57600/71198]
loss: 0.021860  [64000/71198]
loss: 0.077281  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.063475 

Epoch 13
-------------------------------
loss: 0.044068  [    0/71198]
loss: 0.019049  [ 6400/71198]
loss: 0.046083  [12800/71198]
loss: 0.046594  [19200/71198]
loss: 0.030657  [25600/71198]
loss: 0.044634  [32000/71198]
loss: 0.021006  [38400/71198]
loss: 0.041943  [44800/71198]
loss: 0.030915  [51200/71198]
loss: 0.014980  [57600/71198]
loss: 0.068852  [64000/71198]
loss: 0.159161  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.060756 

Epoch 14
-------------------------------
loss: 0.025831  [    0/71198]
loss: 0.063003  [ 6400/71198]
loss: 0.007766  [12800/71198]
loss: 0.028663  [19200/71198]
loss: 0.098815  [25600/71198]
loss: 0.144715  [32000/71198]
loss: 0.009274  [38400/71198]
loss: 0.107470  [44800/71198]
loss: 0.016186  [51200/71198]
loss: 0.244006  [57600/71198]
loss: 0.046122  [64000/71198]
loss: 0.127501  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.062046 

Epoch 15
-------------------------------
loss: 0.041088  [    0/71198]
loss: 0.103780  [ 6400/71198]
loss: 0.070871  [12800/71198]
loss: 0.043117  [19200/71198]
loss: 0.166175  [25600/71198]
loss: 0.008233  [32000/71198]
loss: 0.048246  [38400/71198]
loss: 0.059811  [44800/71198]
loss: 0.028092  [51200/71198]
loss: 0.056478  [57600/71198]
loss: 0.050620  [64000/71198]
loss: 0.093146  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.061053 

Epoch 16
-------------------------------
loss: 0.038479  [    0/71198]
loss: 0.069187  [ 6400/71198]
loss: 0.089806  [12800/71198]
loss: 0.015399  [19200/71198]
loss: 0.039361  [25600/71198]
loss: 0.334301  [32000/71198]
loss: 0.033513  [38400/71198]
loss: 0.106387  [44800/71198]
loss: 0.072034  [51200/71198]
loss: 0.058814  [57600/71198]
loss: 0.075845  [64000/71198]
loss: 0.022644  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.061996 

Epoch 17
-------------------------------
loss: 0.059772  [    0/71198]
loss: 0.023292  [ 6400/71198]
loss: 0.063554  [12800/71198]
loss: 0.006771  [19200/71198]
loss: 0.058777  [25600/71198]
loss: 0.042101  [32000/71198]
loss: 0.011263  [38400/71198]
loss: 0.021420  [44800/71198]
loss: 0.065111  [51200/71198]
loss: 0.052298  [57600/71198]
loss: 0.067330  [64000/71198]
loss: 0.035530  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.064575 

Epoch 18
-------------------------------
loss: 0.066740  [    0/71198]
loss: 0.065844  [ 6400/71198]
loss: 0.134060  [12800/71198]
loss: 0.063810  [19200/71198]
loss: 0.052366  [25600/71198]
loss: 0.088601  [32000/71198]
loss: 0.140978  [38400/71198]
loss: 0.044718  [44800/71198]
loss: 0.049698  [51200/71198]
loss: 0.016158  [57600/71198]
loss: 0.013688  [64000/71198]
loss: 0.097817  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067557 

Epoch 19
-------------------------------
loss: 0.018405  [    0/71198]
loss: 0.033828  [ 6400/71198]
loss: 0.015548  [12800/71198]
loss: 0.082180  [19200/71198]
loss: 0.056074  [25600/71198]
loss: 0.204191  [32000/71198]
loss: 0.048384  [38400/71198]
loss: 0.024330  [44800/71198]
loss: 0.067238  [51200/71198]
loss: 0.032825  [57600/71198]
loss: 0.034715  [64000/71198]
loss: 0.096858  [70400/71198]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070927 

Epoch 20
-------------------------------
loss: 0.057887  [    0/71198]
loss: 0.010392  [ 6400/71198]
loss: 0.025810  [12800/71198]
loss: 0.016440  [19200/71198]
loss: 0.016884  [25600/71198]
loss: 0.053046  [32000/71198]
loss: 0.005866  [38400/71198]
loss: 0.021988  [44800/71198]
loss: 0.033541  [51200/71198]
loss: 0.065639  [57600/71198]
loss: 0.047973  [64000/71198]
loss: 0.029240  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067274 

Epoch 21
-------------------------------
loss: 0.013405  [    0/71198]
loss: 0.106451  [ 6400/71198]
loss: 0.074852  [12800/71198]
loss: 0.075809  [19200/71198]
loss: 0.070198  [25600/71198]
loss: 0.063582  [32000/71198]
loss: 0.051733  [38400/71198]
loss: 0.083494  [44800/71198]
loss: 0.063762  [51200/71198]
loss: 0.095695  [57600/71198]
loss: 0.049280  [64000/71198]
loss: 0.054611  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067637 

Epoch 22
-------------------------------
loss: 0.123385  [    0/71198]
loss: 0.132965  [ 6400/71198]
loss: 0.029846  [12800/71198]
loss: 0.069235  [19200/71198]
loss: 0.062405  [25600/71198]
loss: 0.012470  [32000/71198]
loss: 0.068862  [38400/71198]
loss: 0.076386  [44800/71198]
loss: 0.040793  [51200/71198]
loss: 0.030950  [57600/71198]
loss: 0.026662  [64000/71198]
loss: 0.034326  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069799 

Epoch 23
-------------------------------
loss: 0.053926  [    0/71198]
loss: 0.018854  [ 6400/71198]
loss: 0.046840  [12800/71198]
loss: 0.165131  [44800/70451]
loss: 0.109717  [51200/70451]
loss: 0.085353  [57600/70451]
loss: 0.185817  [64000/70451]
loss: 0.213300  [56100/70451]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.129761 

Epoch 9
-------------------------------
loss: 0.118667  [    0/70451]
loss: 0.151269  [ 6400/70451]
loss: 0.133020  [12800/70451]
loss: 0.202680  [19200/70451]
loss: 0.226765  [25600/70451]
loss: 0.106308  [32000/70451]
loss: 0.119605  [38400/70451]
loss: 0.146495  [44800/70451]
loss: 0.130174  [51200/70451]
loss: 0.048542  [57600/70451]
loss: 0.153431  [64000/70451]
loss: 0.099255  [56100/70451]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.128609 

Epoch 10
-------------------------------
loss: 0.131955  [    0/70451]
loss: 0.163465  [ 6400/70451]
loss: 0.124101  [12800/70451]
loss: 0.068462  [19200/70451]
loss: 0.157107  [25600/70451]
loss: 0.180938  [32000/70451]
loss: 0.076877  [38400/70451]
loss: 0.163103  [44800/70451]
loss: 0.064851  [51200/70451]
loss: 0.119513  [57600/70451]
loss: 0.086463  [64000/70451]
loss: 0.246237  [56100/70451]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.134709 

Epoch 11
-------------------------------
loss: 0.095777  [    0/70451]
loss: 0.089401  [ 6400/70451]
loss: 0.099366  [12800/70451]
loss: 0.123907  [19200/70451]
loss: 0.124308  [25600/70451]
loss: 0.132629  [32000/70451]
loss: 0.212649  [38400/70451]
loss: 0.140701  [44800/70451]
loss: 0.141978  [51200/70451]
loss: 0.139172  [57600/70451]
loss: 0.162747  [64000/70451]
loss: 0.290984  [56100/70451]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.135516 

Epoch 12
-------------------------------
loss: 0.107577  [    0/70451]
loss: 0.172223  [ 6400/70451]
loss: 0.084638  [12800/70451]
loss: 0.124340  [19200/70451]
loss: 0.115510  [25600/70451]
loss: 0.152257  [32000/70451]
loss: 0.064228  [38400/70451]
loss: 0.107005  [44800/70451]
loss: 0.186457  [51200/70451]
loss: 1.814872  [57600/70451]
loss: 0.086765  [64000/70451]
loss: 0.097859  [56100/70451]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.138458 

Epoch 13
-------------------------------
loss: 0.186438  [    0/70451]
loss: 0.089306  [ 6400/70451]
loss: 0.134418  [12800/70451]
loss: 0.130905  [19200/70451]
loss: 0.072304  [25600/70451]
loss: 0.062700  [32000/70451]
loss: 0.115745  [38400/70451]
loss: 0.179208  [44800/70451]
loss: 0.134770  [51200/70451]
loss: 0.065855  [57600/70451]
loss: 0.121407  [64000/70451]
loss: 0.211125  [56100/70451]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.142559 

Epoch 14
-------------------------------
loss: 0.088353  [    0/70451]
loss: 0.047210  [ 6400/70451]
loss: 0.037934  [12800/70451]
loss: 0.137237  [19200/70451]
loss: 0.072125  [25600/70451]
loss: 0.100695  [32000/70451]
loss: 0.092390  [38400/70451]
loss: 0.122461  [44800/70451]
loss: 0.123955  [51200/70451]
loss: 0.108042  [57600/70451]
loss: 0.115745  [64000/70451]
loss: 0.170242  [56100/70451]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.132139 

Epoch 15
-------------------------------
loss: 0.128801  [    0/70451]
loss: 0.140443  [ 6400/70451]
loss: 0.246512  [12800/70451]
loss: 0.052050  [19200/70451]
loss: 0.157936  [25600/70451]
loss: 0.177234  [32000/70451]
loss: 0.145754  [38400/70451]
loss: 0.180449  [44800/70451]
loss: 0.069106  [51200/70451]
loss: 0.222583  [57600/70451]
loss: 0.075152  [64000/70451]
loss: 0.098468  [56100/70451]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.128405 

Epoch 16
-------------------------------
loss: 0.208706  [    0/70451]
loss: 0.049136  [ 6400/70451]
loss: 0.159411  [12800/70451]
loss: 0.265623  [19200/70451]
loss: 0.095165  [25600/70451]
loss: 0.070854  [32000/70451]
loss: 0.095839  [38400/70451]
loss: 0.047931  [44800/70451]
loss: 0.203855  [51200/70451]
loss: 0.175446  [57600/70451]
loss: 0.158473  [64000/70451]
loss: 0.098842  [56100/70451]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.128949 

Epoch 17
-------------------------------
loss: 0.141377  [    0/70451]
loss: 0.055072  [ 6400/70451]
loss: 0.055069  [12800/70451]
loss: 0.087820  [19200/70451]
loss: 0.071740  [25600/70451]
loss: 0.101750  [32000/70451]
loss: 0.096959  [38400/70451]
loss: 0.190987  [44800/70451]
loss: 0.050837  [51200/70451]
loss: 0.080041  [57600/70451]
loss: 0.089169  [64000/70451]
loss: 0.041659  [56100/70451]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.140598 

Epoch 18
-------------------------------
loss: 0.210107  [    0/70451]
loss: 0.079417  [ 6400/70451]
loss: 0.293628  [12800/70451]
loss: 0.183141  [19200/70451]
loss: 0.063331  [25600/70451]
loss: 0.116989  [32000/70451]
loss: 0.202789  [38400/70451]
loss: 0.092823  [44800/70451]
loss: 0.034175  [51200/70451]
loss: 0.202969  [57600/70451]
loss: 0.215521  [64000/70451]
loss: 0.156641  [56100/70451]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.131037 

Epoch 19
-------------------------------
loss: 0.178491  [    0/70451]
loss: 0.075143  [ 6400/70451]
loss: 0.226861  [12800/70451]
loss: 0.140469  [19200/70451]
loss: 0.128811  [25600/70451]
loss: 0.183964  [32000/70451]
loss: 0.134893  [38400/70451]
loss: 0.113764  [44800/70451]
loss: 0.158973  [51200/70451]
loss: 0.115335  [57600/70451]
loss: 0.070973  [64000/70451]
loss: 0.147498  [56100/70451]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.153311 

Epoch 20
-------------------------------
loss: 0.096616  [    0/70451]
loss: 0.141932  [ 6400/70451]
loss: 0.110255  [12800/70451]
loss: 0.228341  [19200/70451]
loss: 0.154056  [25600/70451]
loss: 0.178379  [32000/70451]
loss: 0.132256  [38400/70451]
loss: 0.138967  [44800/70451]
loss: 0.091826  [51200/70451]
loss: 0.204893  [57600/70451]
loss: 0.147531  [64000/70451]
loss: 0.202617  [56100/70451]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.133273 

Epoch 21
-------------------------------
loss: 0.055258  [    0/70451]
loss: 0.111728  [ 6400/70451]
loss: 0.075171  [12800/70451]
loss: 0.187308  [19200/70451]
loss: 0.064889  [25600/70451]
loss: 0.103262  [32000/70451]
loss: 0.064208  [38400/70451]
loss: 0.091793  [44800/70451]
loss: 0.128683  [51200/70451]
loss: 0.086482  [57600/70451]
loss: 0.131381  [64000/70451]
loss: 0.078973  [56100/70451]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.147566 

Epoch 22
-------------------------------
loss: 0.094456  [    0/70451]
loss: 0.181278  [ 6400/70451]
loss: 0.082783  [12800/70451]
loss: 0.086626  [19200/70451]
loss: 0.109959  [25600/70451]
loss: 0.103563  [32000/70451]
loss: 0.040133  [38400/70451]
loss: 0.062902  [44800/70451]
loss: 0.138456  [51200/70451]
loss: 0.240877  [57600/70451]
loss: 0.124333  [64000/70451]
loss: 0.073871  [56100/70451]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.134527 

Epoch 23
-------------------------------
loss: 0.125093  [    0/70451]
loss: 0.096378  [ 6400/70451]
loss: 0.102584  [12800/70451]
loss: 0.110400  [19200/70451]
loss: 0.176637  [25600/70451]
loss: 0.185773  [32000/70451]
loss: 0.171027  [38400/70451]
loss: 0.083869  [44800/70451]
loss: 0.061441  [51200/70451]
loss: 0.076099  [57600/70451]
loss: 0.093228  [64000/70451]
loss: 0.042458  [56100/70451]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.140731 

Epoch 24
-------------------------------
loss: 0.065986  [    0/70451]
loss: 0.126906  [ 6400/70451]
loss: 0.056256  [12800/70451]
loss: 0.093757  [19200/70451]
loss: 0.115425  [25600/70451]
loss: 0.119028  [32000/70451]
loss: 0.086194  [38400/70451]
loss: 0.131612  [44800/70451]
loss: 0.155060  [51200/70451]
loss: 0.284236  [57600/70451]
loss: 0.213346  [64000/70451]
loss: 0.089274  [56100/70451]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.130725 

Epoch 25
-------------------------------
loss: 0.138884  [    0/70451]
loss: 0.084448  [ 6400/70451]
loss: 0.160395  [12800/70451]
loss: 0.290964  [19200/70451]
loss: 0.040161  [25600/70451]
loss: 0.109096  [32000/70451]
loss: 0.161770  [38400/70451]
loss: 0.119715  [44800/70451]
loss: 0.089439  [51200/70451]
loss: 0.202599  [57600/70451]
loss: 0.144939  [64000/70451]
loss: 0.157309  [56100/70451]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.149538 

Epoch 26
-------------------------------
loss: 0.111426  [    0/70451]
loss: 0.048348  [ 6400/70451]
loss: 0.147440  [12800/70451]
loss: 0.078170  [19200/70451]
loss: 0.084988  [25600/70451]
loss: 0.107075  [32000/70451]
loss: 0.195965  [38400/70451]
loss: 0.106816  [44800/70451]
loss: 0.025152  [38400/70196]
loss: 0.100606  [44800/70196]
loss: 0.036777  [51200/70196]
loss: 0.032628  [57600/70196]
loss: 0.069705  [64000/70196]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085258 

Epoch 6
-------------------------------
loss: 0.117115  [    0/70196]
loss: 0.025523  [ 6400/70196]
loss: 0.081879  [12800/70196]
loss: 0.054842  [19200/70196]
loss: 0.162945  [25600/70196]
loss: 0.038570  [32000/70196]
loss: 0.116452  [38400/70196]
loss: 0.114949  [44800/70196]
loss: 0.187008  [51200/70196]
loss: 0.032333  [57600/70196]
loss: 0.035289  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.076886 

Epoch 7
-------------------------------
loss: 0.066405  [    0/70196]
loss: 0.103993  [ 6400/70196]
loss: 0.044084  [12800/70196]
loss: 0.071137  [19200/70196]
loss: 0.120695  [25600/70196]
loss: 0.085789  [32000/70196]
loss: 0.049221  [38400/70196]
loss: 0.114901  [44800/70196]
loss: 0.062247  [51200/70196]
loss: 0.065305  [57600/70196]
loss: 0.098057  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078222 

Epoch 8
-------------------------------
loss: 0.083691  [    0/70196]
loss: 0.120973  [ 6400/70196]
loss: 0.213850  [12800/70196]
loss: 0.037053  [19200/70196]
loss: 0.048313  [25600/70196]
loss: 0.092900  [32000/70196]
loss: 0.048598  [38400/70196]
loss: 0.015110  [44800/70196]
loss: 0.023246  [51200/70196]
loss: 0.028549  [57600/70196]
loss: 0.031214  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.078888 

Epoch 9
-------------------------------
loss: 0.044606  [    0/70196]
loss: 0.191577  [ 6400/70196]
loss: 0.059561  [12800/70196]
loss: 0.063925  [19200/70196]
loss: 0.009889  [25600/70196]
loss: 0.189976  [32000/70196]
loss: 0.079730  [38400/70196]
loss: 0.115177  [44800/70196]
loss: 0.110370  [51200/70196]
loss: 0.192956  [57600/70196]
loss: 0.041103  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.077381 

Epoch 10
-------------------------------
loss: 0.028313  [    0/70196]
loss: 0.201357  [ 6400/70196]
loss: 0.139917  [12800/70196]
loss: 0.101725  [19200/70196]
loss: 0.023747  [25600/70196]
loss: 0.100034  [32000/70196]
loss: 0.055102  [38400/70196]
loss: 0.080492  [44800/70196]
loss: 0.086360  [51200/70196]
loss: 0.117665  [57600/70196]
loss: 0.112224  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081437 

Epoch 11
-------------------------------
loss: 0.029095  [    0/70196]
loss: 0.071534  [ 6400/70196]
loss: 0.088503  [12800/70196]
loss: 0.025737  [19200/70196]
loss: 0.114120  [25600/70196]
loss: 0.106934  [32000/70196]
loss: 0.084152  [38400/70196]
loss: 0.071718  [44800/70196]
loss: 0.026778  [51200/70196]
loss: 0.038723  [57600/70196]
loss: 0.094336  [64000/70196]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.074422 

Epoch 12
-------------------------------
loss: 0.008886  [    0/70196]
loss: 0.070530  [ 6400/70196]
loss: 0.041700  [12800/70196]
loss: 0.051894  [19200/70196]
loss: 0.063244  [25600/70196]
loss: 0.062556  [32000/70196]
loss: 0.083431  [38400/70196]
loss: 0.123360  [44800/70196]
loss: 0.291127  [51200/70196]
loss: 0.087316  [57600/70196]
loss: 0.034173  [64000/70196]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077485 

Epoch 13
-------------------------------
loss: 0.129271  [    0/70196]
loss: 0.038911  [ 6400/70196]
loss: 0.068799  [12800/70196]
loss: 0.087277  [19200/70196]
loss: 0.104581  [25600/70196]
loss: 0.121097  [32000/70196]
loss: 0.122747  [38400/70196]
loss: 0.133468  [44800/70196]
loss: 0.024012  [51200/70196]
loss: 0.025511  [57600/70196]
loss: 0.046828  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083628 

Epoch 14
-------------------------------
loss: 0.070352  [    0/70196]
loss: 0.056726  [ 6400/70196]
loss: 0.065178  [12800/70196]
loss: 0.011491  [19200/70196]
loss: 0.086196  [25600/70196]
loss: 0.084559  [32000/70196]
loss: 0.042949  [38400/70196]
loss: 0.029278  [44800/70196]
loss: 0.075825  [51200/70196]
loss: 0.128174  [57600/70196]
loss: 0.046126  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.077763 

Epoch 15
-------------------------------
loss: 0.020910  [    0/70196]
loss: 0.063003  [ 6400/70196]
loss: 0.031917  [12800/70196]
loss: 0.099006  [19200/70196]
loss: 0.089356  [25600/70196]
loss: 0.084803  [32000/70196]
loss: 0.081643  [38400/70196]
loss: 0.112501  [44800/70196]
loss: 0.090061  [51200/70196]
loss: 0.046693  [57600/70196]
loss: 0.023046  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078582 

Epoch 16
-------------------------------
loss: 0.051057  [    0/70196]
loss: 0.017435  [ 6400/70196]
loss: 0.079760  [12800/70196]
loss: 0.025327  [19200/70196]
loss: 0.018298  [25600/70196]
loss: 0.129418  [32000/70196]
loss: 0.073441  [38400/70196]
loss: 0.101918  [44800/70196]
loss: 0.018697  [51200/70196]
loss: 0.077895  [57600/70196]
loss: 0.128551  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082415 

Epoch 17
-------------------------------
loss: 0.130293  [    0/70196]
loss: 0.009989  [ 6400/70196]
loss: 0.214949  [12800/70196]
loss: 0.053591  [19200/70196]
loss: 0.079105  [25600/70196]
loss: 0.050112  [32000/70196]
loss: 0.056596  [38400/70196]
loss: 0.108565  [44800/70196]
loss: 0.092668  [51200/70196]
loss: 0.026589  [57600/70196]
loss: 0.066582  [64000/70196]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.072303 

Epoch 18
-------------------------------
loss: 0.177697  [    0/70196]
loss: 0.079837  [ 6400/70196]
loss: 0.173663  [12800/70196]
loss: 0.057221  [19200/70196]
loss: 0.116063  [25600/70196]
loss: 0.077309  [32000/70196]
loss: 0.033063  [38400/70196]
loss: 0.064614  [44800/70196]
loss: 0.135664  [51200/70196]
loss: 0.088328  [57600/70196]
loss: 0.044395  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080796 

Epoch 19
-------------------------------
loss: 0.100332  [    0/70196]
loss: 0.023834  [ 6400/70196]
loss: 0.157668  [12800/70196]
loss: 0.048113  [19200/70196]
loss: 0.239411  [25600/70196]
loss: 0.050997  [32000/70196]
loss: 0.030114  [38400/70196]
loss: 0.113300  [44800/70196]
loss: 0.038614  [51200/70196]
loss: 0.037224  [57600/70196]
loss: 0.037146  [64000/70196]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.070154 

Epoch 20
-------------------------------
loss: 0.036044  [    0/70196]
loss: 0.045765  [ 6400/70196]
loss: 0.180451  [12800/70196]
loss: 0.095174  [19200/70196]
loss: 0.105206  [25600/70196]
loss: 0.076016  [32000/70196]
loss: 0.032717  [38400/70196]
loss: 0.033133  [44800/70196]
loss: 0.091240  [51200/70196]
loss: 0.034040  [57600/70196]
loss: 0.020210  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.075518 

Epoch 21
-------------------------------
loss: 0.068819  [    0/70196]
loss: 0.079896  [ 6400/70196]
loss: 0.065734  [12800/70196]
loss: 0.029569  [19200/70196]
loss: 0.084343  [25600/70196]
loss: 0.043428  [32000/70196]
loss: 0.025160  [38400/70196]
loss: 0.132752  [44800/70196]
loss: 0.013412  [51200/70196]
loss: 0.075838  [57600/70196]
loss: 0.021093  [64000/70196]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.079204 

Epoch 22
-------------------------------
loss: 0.054385  [    0/70196]
loss: 0.055009  [ 6400/70196]
loss: 0.022571  [12800/70196]
loss: 0.117245  [19200/70196]
loss: 0.061330  [25600/70196]
loss: 0.041053  [32000/70196]
loss: 0.070927  [38400/70196]
loss: 0.094166  [44800/70196]
loss: 0.044753  [51200/70196]
loss: 0.030571  [57600/70196]
loss: 0.028086  [64000/70196]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.092895 

Epoch 23
-------------------------------
loss: 0.065101  [    0/70196]
loss: 0.149138  [ 6400/70196]
loss: 0.036458  [12800/70196]
loss: 0.083550  [19200/70196]
loss: 0.063983  [25600/70196]
loss: 0.063780  [32000/70196]
loss: 0.080341  [38400/70196]
loss: 0.027448  [44800/70196]
loss: 0.104131  [51200/70196]
loss: 0.037257  [57600/70196]
loss: 0.207398  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083005 

Epoch 24
-------------------------------
loss: 0.033486  [    0/70196]
loss: 0.086624  [ 6400/70196]
loss: 0.051737  [12800/70196]
loss: 0.019718  [19200/70196]
loss: 0.032358  [25600/70196]
loss: 0.050216  [32000/70196]
loss: 0.016416  [38400/70196]
loss: 0.028974  [44800/70196]
loss: 0.040381  [51200/70196]
loss: 0.136721  [57600/70196]
loss: 0.141618  [64000/70196]
loss: 0.047578  [44800/71333]
loss: 0.076896  [51200/71333]
loss: 0.049223  [57600/71333]
loss: 0.101423  [64000/71333]
loss: 0.133286  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.143644 

Epoch 9
-------------------------------
loss: 1.621604  [    0/71333]
loss: 0.024654  [ 6400/71333]
loss: 0.083483  [12800/71333]
loss: 0.100198  [19200/71333]
loss: 0.042344  [25600/71333]
loss: 0.045150  [32000/71333]
loss: 0.034258  [38400/71333]
loss: 0.084288  [44800/71333]
loss: 0.064164  [51200/71333]
loss: 0.099797  [57600/71333]
loss: 0.120759  [64000/71333]
loss: 0.016136  [70400/71333]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.143479 

Epoch 10
-------------------------------
loss: 0.042035  [    0/71333]
loss: 0.117322  [ 6400/71333]
loss: 0.043823  [12800/71333]
loss: 0.024776  [19200/71333]
loss: 0.062219  [25600/71333]
loss: 0.114910  [32000/71333]
loss: 0.021591  [38400/71333]
loss: 1.601537  [44800/71333]
loss: 0.045968  [51200/71333]
loss: 0.182260  [57600/71333]
loss: 0.112078  [64000/71333]
loss: 1.733981  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.143296 

Epoch 11
-------------------------------
loss: 0.024789  [    0/71333]
loss: 0.050646  [ 6400/71333]
loss: 0.141272  [12800/71333]
loss: 0.194459  [19200/71333]
loss: 0.041556  [25600/71333]
loss: 0.037590  [32000/71333]
loss: 0.045130  [38400/71333]
loss: 0.040420  [44800/71333]
loss: 0.011701  [51200/71333]
loss: 0.140016  [57600/71333]
loss: 0.060206  [64000/71333]
loss: 0.030874  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.138654 

Epoch 12
-------------------------------
loss: 0.017287  [    0/71333]
loss: 0.113658  [ 6400/71333]
loss: 0.030506  [12800/71333]
loss: 0.100010  [19200/71333]
loss: 0.113365  [25600/71333]
loss: 0.019602  [32000/71333]
loss: 0.041788  [38400/71333]
loss: 0.086130  [44800/71333]
loss: 0.016125  [51200/71333]
loss: 0.027805  [57600/71333]
loss: 0.047585  [64000/71333]
loss: 0.098430  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.143735 

Epoch 13
-------------------------------
loss: 0.034714  [    0/71333]
loss: 0.143117  [ 6400/71333]
loss: 0.031000  [12800/71333]
loss: 0.052135  [19200/71333]
loss: 0.094384  [25600/71333]
loss: 0.005454  [32000/71333]
loss: 0.099359  [38400/71333]
loss: 0.051773  [44800/71333]
loss: 0.130678  [51200/71333]
loss: 0.034421  [57600/71333]
loss: 0.034639  [64000/71333]
loss: 0.022394  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.138582 

Epoch 14
-------------------------------
loss: 0.026058  [    0/71333]
loss: 0.080295  [ 6400/71333]
loss: 0.109229  [12800/71333]
loss: 0.051039  [19200/71333]
loss: 0.038206  [25600/71333]
loss: 0.002772  [32000/71333]
loss: 0.064653  [38400/71333]
loss: 0.127720  [44800/71333]
loss: 0.007008  [51200/71333]
loss: 0.043350  [57600/71333]
loss: 0.073831  [64000/71333]
loss: 0.029327  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.142536 

Epoch 15
-------------------------------
loss: 0.035431  [    0/71333]
loss: 0.190815  [ 6400/71333]
loss: 0.035857  [12800/71333]
loss: 0.030589  [19200/71333]
loss: 0.081848  [25600/71333]
loss: 0.053837  [32000/71333]
loss: 0.115056  [38400/71333]
loss: 0.030934  [44800/71333]
loss: 0.036027  [51200/71333]
loss: 0.026060  [57600/71333]
loss: 0.180668  [64000/71333]
loss: 0.093966  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.149635 

Epoch 16
-------------------------------
loss: 0.034139  [    0/71333]
loss: 0.050153  [ 6400/71333]
loss: 0.048904  [12800/71333]
loss: 0.016203  [19200/71333]
loss: 0.053017  [25600/71333]
loss: 0.032687  [32000/71333]
loss: 0.078100  [38400/71333]
loss: 0.049684  [44800/71333]
loss: 0.019187  [51200/71333]
loss: 0.058891  [57600/71333]
loss: 0.059848  [64000/71333]
loss: 0.068784  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.148872 

Epoch 17
-------------------------------
loss: 0.013718  [    0/71333]
loss: 0.013906  [ 6400/71333]
loss: 0.046218  [12800/71333]
loss: 0.050690  [19200/71333]
loss: 0.077371  [25600/71333]
loss: 0.100856  [32000/71333]
loss: 0.054222  [38400/71333]
loss: 1.726561  [44800/71333]
loss: 0.087019  [51200/71333]
loss: 0.021631  [57600/71333]
loss: 0.038242  [64000/71333]
loss: 0.094764  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.141342 

Epoch 18
-------------------------------
loss: 0.076345  [    0/71333]
loss: 0.013922  [ 6400/71333]
loss: 0.114380  [12800/71333]
loss: 0.060905  [19200/71333]
loss: 0.077192  [25600/71333]
loss: 0.147083  [32000/71333]
loss: 0.060569  [38400/71333]
loss: 0.008674  [44800/71333]
loss: 0.029519  [51200/71333]
loss: 0.078476  [57600/71333]
loss: 0.057911  [64000/71333]
loss: 0.029653  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.152306 

Epoch 19
-------------------------------
loss: 0.098493  [    0/71333]
loss: 0.033914  [ 6400/71333]
loss: 0.076095  [12800/71333]
loss: 0.063158  [19200/71333]
loss: 0.127164  [25600/71333]
loss: 0.080099  [32000/71333]
loss: 0.129562  [38400/71333]
loss: 0.062735  [44800/71333]
loss: 0.070095  [51200/71333]
loss: 1.579484  [57600/71333]
loss: 0.043619  [64000/71333]
loss: 0.080258  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.143801 

Epoch 20
-------------------------------
loss: 0.056466  [    0/71333]
loss: 0.042170  [ 6400/71333]
loss: 0.034137  [12800/71333]
loss: 0.048545  [19200/71333]
loss: 0.060611  [25600/71333]
loss: 0.009930  [32000/71333]
loss: 0.089577  [38400/71333]
loss: 0.079988  [44800/71333]
loss: 0.121363  [51200/71333]
loss: 0.071566  [57600/71333]
loss: 0.074116  [64000/71333]
loss: 0.036008  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.145108 

Epoch 21
-------------------------------
loss: 0.040555  [    0/71333]
loss: 0.081904  [ 6400/71333]
loss: 0.086307  [12800/71333]
loss: 0.039172  [19200/71333]
loss: 0.086745  [25600/71333]
loss: 0.054873  [32000/71333]
loss: 0.078787  [38400/71333]
loss: 0.105192  [44800/71333]
loss: 0.095816  [51200/71333]
loss: 0.130979  [57600/71333]
loss: 0.011901  [64000/71333]
loss: 0.063324  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.147217 

Epoch 22
-------------------------------
loss: 0.018892  [    0/71333]
loss: 0.057250  [ 6400/71333]
loss: 0.058474  [12800/71333]
loss: 0.101662  [19200/71333]
loss: 0.038811  [25600/71333]
loss: 0.043440  [32000/71333]
loss: 0.014500  [38400/71333]
loss: 0.078378  [44800/71333]
loss: 0.088651  [51200/71333]
loss: 0.069166  [57600/71333]
loss: 0.010324  [64000/71333]
loss: 0.109504  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.141383 

Epoch 23
-------------------------------
loss: 0.039542  [    0/71333]
loss: 0.032840  [ 6400/71333]
loss: 0.197562  [12800/71333]
loss: 0.034021  [19200/71333]
loss: 0.037146  [25600/71333]
loss: 0.055157  [32000/71333]
loss: 0.070559  [38400/71333]
loss: 0.009526  [44800/71333]
loss: 0.026333  [51200/71333]
loss: 0.018671  [57600/71333]
loss: 0.063391  [64000/71333]
loss: 0.048708  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.140293 

Epoch 24
-------------------------------
loss: 0.036537  [    0/71333]
loss: 0.068489  [ 6400/71333]
loss: 0.022253  [12800/71333]
loss: 0.051030  [19200/71333]
loss: 0.036183  [25600/71333]
loss: 0.040207  [32000/71333]
loss: 1.609517  [38400/71333]
loss: 0.038904  [44800/71333]
loss: 0.070154  [51200/71333]
loss: 0.076321  [57600/71333]
loss: 0.032122  [64000/71333]
loss: 0.107805  [70400/71333]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.146323 

Epoch 25
-------------------------------
loss: 0.024180  [    0/71333]
loss: 0.032545  [ 6400/71333]
loss: 0.008599  [12800/71333]
loss: 0.040519  [19200/71333]
loss: 0.070236  [25600/71333]
loss: 0.031544  [32000/71333]
loss: 0.028348  [38400/71333]
loss: 0.040497  [44800/71333]
loss: 0.042436  [51200/71333]
loss: 0.036500  [57600/71333]
loss: 0.032386  [64000/71333]
loss: 0.062216  [70400/71333]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.142178 

Epoch 26
-------------------------------
loss: 0.039344  [    0/71333]
loss: 0.022752  [ 6400/71333]
loss: 0.074709  [12800/71333]
loss: 0.023762  [19200/71333]
loss: 0.027067  [25600/71333]
loss: 0.047067  [32000/71333]
loss: 0.076612  [38400/71333]
loss: 0.134910  [44800/71333]
loss: 0.068647  [44800/70787]
loss: 0.054535  [51200/70787]
loss: 0.058974  [57600/70787]
loss: 0.063210  [64000/70787]
loss: 0.039811  [70400/70787]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.074296 

Epoch 9
-------------------------------
loss: 0.065935  [    0/70787]
loss: 0.084788  [ 6400/70787]
loss: 0.016972  [12800/70787]
loss: 0.021359  [19200/70787]
loss: 0.004896  [25600/70787]
loss: 0.160388  [32000/70787]
loss: 0.091180  [38400/70787]
loss: 0.043458  [44800/70787]
loss: 0.050604  [51200/70787]
loss: 0.070006  [57600/70787]
loss: 0.120525  [64000/70787]
loss: 0.090664  [70400/70787]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.068941 

Epoch 10
-------------------------------
loss: 0.030916  [    0/70787]
loss: 0.036020  [ 6400/70787]
loss: 0.123162  [12800/70787]
loss: 0.109716  [19200/70787]
loss: 0.095408  [25600/70787]
loss: 0.083281  [32000/70787]
loss: 0.041950  [38400/70787]
loss: 0.084386  [44800/70787]
loss: 0.049368  [51200/70787]
loss: 0.128134  [57600/70787]
loss: 0.029468  [64000/70787]
loss: 0.009391  [70400/70787]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.066316 

Epoch 11
-------------------------------
loss: 0.084426  [    0/70787]
loss: 0.043187  [ 6400/70787]
loss: 0.022595  [12800/70787]
loss: 0.066991  [19200/70787]
loss: 0.107688  [25600/70787]
loss: 0.046070  [32000/70787]
loss: 0.121277  [38400/70787]
loss: 0.034233  [44800/70787]
loss: 0.136530  [51200/70787]
loss: 0.161708  [57600/70787]
loss: 0.051643  [64000/70787]
loss: 0.012792  [70400/70787]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.064179 

Epoch 12
-------------------------------
loss: 0.086225  [    0/70787]
loss: 0.050901  [ 6400/70787]
loss: 0.150417  [12800/70787]
loss: 0.036004  [19200/70787]
loss: 0.030759  [25600/70787]
loss: 0.013304  [32000/70787]
loss: 0.104962  [38400/70787]
loss: 0.109070  [44800/70787]
loss: 0.153304  [51200/70787]
loss: 0.113477  [57600/70787]
loss: 0.034432  [64000/70787]
loss: 0.166441  [70400/70787]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.067313 

Epoch 13
-------------------------------
loss: 0.102111  [    0/70787]
loss: 0.041386  [ 6400/70787]
loss: 0.067184  [12800/70787]
loss: 0.007317  [19200/70787]
loss: 0.006075  [25600/70787]
loss: 0.064158  [32000/70787]
loss: 0.081014  [38400/70787]
loss: 0.076976  [44800/70787]
loss: 0.185268  [51200/70787]
loss: 0.038741  [57600/70787]
loss: 0.077343  [64000/70787]
loss: 0.096749  [70400/70787]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.065412 

Epoch 14
-------------------------------
loss: 0.034398  [    0/70787]
loss: 0.018163  [ 6400/70787]
loss: 0.090817  [12800/70787]
loss: 0.055729  [19200/70787]
loss: 0.045297  [25600/70787]
loss: 0.075738  [32000/70787]
loss: 0.071966  [38400/70787]
loss: 0.033449  [44800/70787]
loss: 0.017848  [51200/70787]
loss: 0.103360  [57600/70787]
loss: 0.134964  [64000/70787]
loss: 0.058825  [70400/70787]
Test Error: 
 Accuracy: 88.4%, Avg loss: 0.528319 

Epoch 15
-------------------------------
loss: 0.483694  [    0/70787]
loss: 0.077815  [ 6400/70787]
loss: 0.040085  [12800/70787]
loss: 0.073417  [19200/70787]
loss: 0.050500  [25600/70787]
loss: 0.038467  [32000/70787]
loss: 0.041189  [38400/70787]
loss: 0.055496  [44800/70787]
loss: 0.061041  [51200/70787]
loss: 0.028870  [57600/70787]
loss: 0.066740  [64000/70787]
loss: 0.088063  [70400/70787]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.070809 

Epoch 16
-------------------------------
loss: 0.062432  [    0/70787]
loss: 0.078240  [ 6400/70787]
loss: 0.030764  [12800/70787]
loss: 0.052371  [19200/70787]
loss: 0.012269  [25600/70787]
loss: 0.092039  [32000/70787]
loss: 0.079530  [38400/70787]
loss: 0.147449  [44800/70787]
loss: 0.052794  [51200/70787]
loss: 0.031658  [57600/70787]
loss: 0.105181  [64000/70787]
loss: 0.037764  [70400/70787]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081356 

Epoch 17
-------------------------------
loss: 0.054964  [    0/70787]
loss: 0.017316  [ 6400/70787]
loss: 0.112995  [12800/70787]
loss: 0.091999  [19200/70787]
loss: 0.038609  [25600/70787]
loss: 0.042980  [32000/70787]
loss: 0.099705  [38400/70787]
loss: 0.056726  [44800/70787]
loss: 0.186942  [51200/70787]
loss: 0.017888  [57600/70787]
loss: 0.067669  [64000/70787]
loss: 0.063384  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075282 

Epoch 18
-------------------------------
loss: 0.106920  [    0/70787]
loss: 0.010398  [ 6400/70787]
loss: 0.061794  [12800/70787]
loss: 0.048199  [19200/70787]
loss: 0.031638  [25600/70787]
loss: 0.037640  [32000/70787]
loss: 0.142736  [38400/70787]
loss: 0.155615  [44800/70787]
loss: 0.104303  [51200/70787]
loss: 0.062244  [57600/70787]
loss: 0.135704  [64000/70787]
loss: 0.095509  [70400/70787]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.125112 

Epoch 19
-------------------------------
loss: 0.118938  [    0/70787]
loss: 0.074781  [ 6400/70787]
loss: 0.028589  [12800/70787]
loss: 0.047787  [19200/70787]
loss: 0.049790  [25600/70787]
loss: 0.197187  [32000/70787]
loss: 0.134546  [38400/70787]
loss: 0.097062  [44800/70787]
loss: 0.116122  [51200/70787]
loss: 0.094141  [57600/70787]
loss: 0.169763  [64000/70787]
loss: 0.018968  [70400/70787]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.074840 

Epoch 20
-------------------------------
loss: 0.019879  [    0/70787]
loss: 0.048076  [ 6400/70787]
loss: 0.012462  [12800/70787]
loss: 0.021633  [19200/70787]
loss: 0.010923  [25600/70787]
loss: 0.032803  [32000/70787]
loss: 0.091933  [38400/70787]
loss: 0.083656  [44800/70787]
loss: 0.088197  [51200/70787]
loss: 0.081643  [57600/70787]
loss: 0.080717  [64000/70787]
loss: 0.069362  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.084257 

Epoch 21
-------------------------------
loss: 0.076396  [    0/70787]
loss: 0.015463  [ 6400/70787]
loss: 0.016062  [12800/70787]
loss: 0.070451  [19200/70787]
loss: 0.102681  [25600/70787]
loss: 0.048852  [32000/70787]
loss: 0.012442  [38400/70787]
loss: 0.024116  [44800/70787]
loss: 0.041504  [51200/70787]
loss: 0.071636  [57600/70787]
loss: 0.057370  [64000/70787]
loss: 0.032632  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080771 

Epoch 22
-------------------------------
loss: 0.034234  [    0/70787]
loss: 0.066314  [ 6400/70787]
loss: 0.025145  [12800/70787]
loss: 0.025286  [19200/70787]
loss: 0.043857  [25600/70787]
loss: 0.065319  [32000/70787]
loss: 0.037224  [38400/70787]
loss: 0.043951  [44800/70787]
loss: 0.041582  [51200/70787]
loss: 0.039884  [57600/70787]
loss: 0.070356  [64000/70787]
loss: 0.016609  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077119 

Epoch 23
-------------------------------
loss: 0.055457  [    0/70787]
loss: 0.030871  [ 6400/70787]
loss: 0.021914  [12800/70787]
loss: 0.016830  [19200/70787]
loss: 0.070964  [25600/70787]
loss: 0.025876  [32000/70787]
loss: 0.031927  [38400/70787]
loss: 0.121797  [44800/70787]
loss: 0.074918  [51200/70787]
loss: 0.058167  [57600/70787]
loss: 0.050050  [64000/70787]
loss: 0.032000  [70400/70787]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.111264 

Epoch 24
-------------------------------
loss: 0.102938  [    0/70787]
loss: 0.120266  [ 6400/70787]
loss: 0.062504  [12800/70787]
loss: 0.021839  [19200/70787]
loss: 0.054642  [25600/70787]
loss: 0.020376  [32000/70787]
loss: 0.014647  [38400/70787]
loss: 0.022066  [44800/70787]
loss: 0.027510  [51200/70787]
loss: 0.045372  [57600/70787]
loss: 0.083934  [64000/70787]
loss: 0.097935  [70400/70787]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078413 

Epoch 25
-------------------------------
loss: 0.065060  [    0/70787]
loss: 0.027298  [ 6400/70787]
loss: 0.014464  [12800/70787]
loss: 0.011603  [19200/70787]
loss: 0.048430  [25600/70787]
loss: 0.005486  [32000/70787]
loss: 0.024681  [38400/70787]
loss: 0.032872  [44800/70787]
loss: 0.053089  [51200/70787]
loss: 0.039792  [57600/70787]
loss: 0.053108  [64000/70787]
loss: 0.089717  [70400/70787]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.087741 

Epoch 26
-------------------------------
loss: 0.068493  [    0/70787]
loss: 0.028938  [ 6400/70787]
loss: 0.031327  [12800/70787]
loss: 0.011456  [19200/70787]
loss: 0.032967  [25600/70787]
loss: 0.077352  [32000/70787]
loss: 0.067057  [38400/70787]
loss: 0.121596  [44800/70787]
loss: 0.154459  [    0/69874]
loss: 0.081029  [ 6400/69874]
loss: 0.038655  [12800/69874]
loss: 0.202358  [19200/69874]
loss: 0.157183  [25600/69874]
loss: 0.112362  [32000/69874]
loss: 0.213179  [38400/69874]
loss: 0.126329  [44800/69874]
loss: 0.083247  [51200/69874]
loss: 0.292630  [57600/69874]
loss: 0.205729  [64000/69874]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.149645 

Epoch 10
-------------------------------
loss: 0.145208  [    0/69874]
loss: 0.147704  [ 6400/69874]
loss: 0.120700  [12800/69874]
loss: 0.130010  [19200/69874]
loss: 0.132094  [25600/69874]
loss: 0.164102  [32000/69874]
loss: 0.052198  [38400/69874]
loss: 0.078242  [44800/69874]
loss: 0.170774  [51200/69874]
loss: 0.116892  [57600/69874]
loss: 0.168544  [64000/69874]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.151232 

Epoch 11
-------------------------------
loss: 0.104859  [    0/69874]
loss: 0.116185  [ 6400/69874]
loss: 0.131901  [12800/69874]
loss: 0.120152  [19200/69874]
loss: 0.163912  [25600/69874]
loss: 0.129751  [32000/69874]
loss: 0.110903  [38400/69874]
loss: 0.120720  [44800/69874]
loss: 0.088480  [51200/69874]
loss: 0.118704  [57600/69874]
loss: 0.066291  [64000/69874]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150833 

Epoch 12
-------------------------------
loss: 0.165918  [    0/69874]
loss: 0.126260  [ 6400/69874]
loss: 0.100090  [12800/69874]
loss: 0.086145  [19200/69874]
loss: 0.257359  [25600/69874]
loss: 0.108161  [32000/69874]
loss: 0.155716  [38400/69874]
loss: 0.116800  [44800/69874]
loss: 0.237314  [51200/69874]
loss: 0.094093  [57600/69874]
loss: 0.145313  [64000/69874]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.163738 

Epoch 13
-------------------------------
loss: 0.246027  [    0/69874]
loss: 0.220893  [ 6400/69874]
loss: 0.221254  [12800/69874]
loss: 0.216269  [19200/69874]
loss: 0.199584  [25600/69874]
loss: 0.097433  [32000/69874]
loss: 0.201697  [38400/69874]
loss: 0.046813  [44800/69874]
loss: 0.177490  [51200/69874]
loss: 0.175366  [57600/69874]
loss: 0.199419  [64000/69874]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.150737 

Epoch 14
-------------------------------
loss: 0.076209  [    0/69874]
loss: 0.168370  [ 6400/69874]
loss: 0.200176  [12800/69874]
loss: 0.210165  [19200/69874]
loss: 0.200373  [25600/69874]
loss: 0.214484  [32000/69874]
loss: 0.132112  [38400/69874]
loss: 0.221018  [44800/69874]
loss: 0.283398  [51200/69874]
loss: 0.160558  [57600/69874]
loss: 0.198800  [64000/69874]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.154986 

Epoch 15
-------------------------------
loss: 0.110129  [    0/69874]
loss: 0.125942  [ 6400/69874]
loss: 0.092678  [12800/69874]
loss: 0.046758  [19200/69874]
loss: 0.053218  [25600/69874]
loss: 0.109407  [32000/69874]
loss: 0.111742  [38400/69874]
loss: 0.107948  [44800/69874]
loss: 0.109443  [51200/69874]
loss: 0.099448  [57600/69874]
loss: 0.142463  [64000/69874]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153496 

Epoch 16
-------------------------------
loss: 0.087347  [    0/69874]
loss: 0.090592  [ 6400/69874]
loss: 0.228734  [12800/69874]
loss: 0.097399  [19200/69874]
loss: 0.121685  [25600/69874]
loss: 0.204204  [32000/69874]
loss: 0.133058  [38400/69874]
loss: 0.139686  [44800/69874]
loss: 0.108479  [51200/69874]
loss: 0.130040  [57600/69874]
loss: 0.136885  [64000/69874]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.163676 

Epoch 17
-------------------------------
loss: 0.092474  [    0/69874]
loss: 0.123341  [ 6400/69874]
loss: 0.082304  [12800/69874]
loss: 0.169066  [19200/69874]
loss: 0.131951  [25600/69874]
loss: 0.200660  [32000/69874]
loss: 0.108548  [38400/69874]
loss: 0.044544  [44800/69874]
loss: 0.108947  [51200/69874]
loss: 0.189049  [57600/69874]
loss: 0.125883  [64000/69874]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.159172 

Epoch 18
-------------------------------
loss: 0.049169  [    0/69874]
loss: 0.144116  [ 6400/69874]
loss: 0.158740  [12800/69874]
loss: 0.088413  [19200/69874]
loss: 0.125271  [25600/69874]
loss: 0.285463  [32000/69874]
loss: 0.109062  [38400/69874]
loss: 0.103621  [44800/69874]
loss: 0.298143  [51200/69874]
loss: 0.105868  [57600/69874]
loss: 0.118904  [64000/69874]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.158266 

Epoch 19
-------------------------------
loss: 0.039237  [    0/69874]
loss: 0.086090  [ 6400/69874]
loss: 0.158793  [12800/69874]
loss: 0.125673  [19200/69874]
loss: 0.156257  [25600/69874]
loss: 0.080151  [32000/69874]
loss: 0.077701  [38400/69874]
loss: 0.320616  [44800/69874]
loss: 0.129020  [51200/69874]
loss: 0.076777  [57600/69874]
loss: 0.093016  [64000/69874]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.150409 

Epoch 20
-------------------------------
loss: 0.152528  [    0/69874]
loss: 0.107179  [ 6400/69874]
loss: 0.167884  [12800/69874]
loss: 0.158756  [19200/69874]
loss: 0.140874  [25600/69874]
loss: 0.135165  [32000/69874]
loss: 0.101416  [38400/69874]
loss: 0.173617  [44800/69874]
loss: 0.050464  [51200/69874]
loss: 0.168519  [57600/69874]
loss: 0.227482  [64000/69874]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.152151 

Epoch 21
-------------------------------
loss: 0.123258  [    0/69874]
loss: 0.181280  [ 6400/69874]
loss: 0.105193  [12800/69874]
loss: 0.031450  [19200/69874]
loss: 0.077467  [25600/69874]
loss: 0.131158  [32000/69874]
loss: 0.145782  [38400/69874]
loss: 0.084477  [44800/69874]
loss: 0.077543  [51200/69874]
loss: 0.192331  [57600/69874]
loss: 1.649677  [64000/69874]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.163380 

Epoch 22
-------------------------------
loss: 0.155516  [    0/69874]
loss: 0.110210  [ 6400/69874]
loss: 0.089033  [12800/69874]
loss: 0.084940  [19200/69874]
loss: 0.097297  [25600/69874]
loss: 0.144014  [32000/69874]
loss: 0.152364  [38400/69874]
loss: 0.044344  [44800/69874]
loss: 0.235042  [51200/69874]
loss: 0.023657  [57600/69874]
loss: 0.203195  [64000/69874]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.148299 

Epoch 23
-------------------------------
loss: 0.119297  [    0/69874]
loss: 0.152692  [ 6400/69874]
loss: 0.178018  [12800/69874]
loss: 0.104117  [19200/69874]
loss: 0.094953  [25600/69874]
loss: 0.103523  [32000/69874]
loss: 0.130542  [38400/69874]
loss: 0.107250  [44800/69874]
loss: 0.191732  [51200/69874]
loss: 0.128749  [57600/69874]
loss: 0.117086  [64000/69874]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.152159 

Epoch 24
-------------------------------
loss: 0.098887  [    0/69874]
loss: 0.162800  [ 6400/69874]
loss: 0.118760  [12800/69874]
loss: 0.101523  [19200/69874]
loss: 0.148074  [25600/69874]
loss: 0.115411  [32000/69874]
loss: 0.209711  [38400/69874]
loss: 0.144678  [44800/69874]
loss: 0.094795  [51200/69874]
loss: 0.154156  [57600/69874]
loss: 0.106884  [64000/69874]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.147660 

Epoch 25
-------------------------------
loss: 0.182410  [    0/69874]
loss: 0.117693  [ 6400/69874]
loss: 0.111007  [12800/69874]
loss: 0.068234  [19200/69874]
loss: 0.089368  [25600/69874]
loss: 0.142245  [32000/69874]
loss: 0.127553  [38400/69874]
loss: 0.196656  [44800/69874]
loss: 0.137478  [51200/69874]
loss: 0.106712  [57600/69874]
loss: 0.281299  [64000/69874]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.150121 

Epoch 26
-------------------------------
loss: 0.055877  [    0/69874]
loss: 0.155110  [ 6400/69874]
loss: 0.137306  [12800/69874]
loss: 0.131602  [19200/69874]
loss: 0.129768  [25600/69874]
loss: 0.093866  [32000/69874]
loss: 0.067285  [38400/69874]
loss: 0.172688  [44800/69874]
loss: 0.149533  [51200/69874]
loss: 0.192944  [57600/69874]
loss: 0.112346  [64000/69874]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.143939 

Epoch 27
-------------------------------
loss: 0.134193  [    0/69874]
loss: 0.131778  [ 6400/69874]
loss: 0.133448  [12800/69874]
loss: 0.085389  [19200/69874]
loss: 0.184428  [25600/69874]
loss: 0.024914  [32000/69874]
loss: 0.140085  [38400/69874]
loss: 0.137013  [44800/69874]
loss: 0.138696  [51200/69874]
loss: 0.144074  [57600/69874]
loss: 0.128150  [64000/69874]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157108 

Epoch 28
-------------------------------
loss: 0.076128  [    0/69874]
loss: 0.204479  [ 6400/69874]
loss: 0.104472  [12800/69874]
loss: 0.053913  [19200/69874]
loss: 0.203248  [25600/69874]
loss: 0.113953  [38400/69845]
loss: 0.219813  [44800/69845]
loss: 0.116934  [51200/69845]
loss: 0.082847  [57600/69845]
loss: 0.133926  [64000/69845]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.159523 

Epoch 6
-------------------------------
loss: 0.143303  [    0/69845]
loss: 0.231762  [ 6400/69845]
loss: 0.153062  [12800/69845]
loss: 0.104517  [19200/69845]
loss: 0.118761  [25600/69845]
loss: 0.164119  [32000/69845]
loss: 0.077672  [38400/69845]
loss: 0.094652  [44800/69845]
loss: 0.195480  [51200/69845]
loss: 0.069397  [57600/69845]
loss: 0.121979  [64000/69845]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.161833 

Epoch 7
-------------------------------
loss: 0.147943  [    0/69845]
loss: 0.191567  [ 6400/69845]
loss: 0.108860  [12800/69845]
loss: 0.213112  [19200/69845]
loss: 0.142351  [25600/69845]
loss: 0.137084  [32000/69845]
loss: 0.146667  [38400/69845]
loss: 0.201458  [44800/69845]
loss: 0.120258  [51200/69845]
loss: 0.233250  [57600/69845]
loss: 0.185387  [64000/69845]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.155892 

Epoch 8
-------------------------------
loss: 0.085467  [    0/69845]
loss: 0.193569  [ 6400/69845]
loss: 0.198173  [12800/69845]
loss: 0.166260  [19200/69845]
loss: 0.122250  [25600/69845]
loss: 0.162312  [32000/69845]
loss: 0.138911  [38400/69845]
loss: 0.148140  [44800/69845]
loss: 0.145861  [51200/69845]
loss: 0.063369  [57600/69845]
loss: 0.092939  [64000/69845]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160717 

Epoch 9
-------------------------------
loss: 0.204249  [    0/69845]
loss: 0.116392  [ 6400/69845]
loss: 0.253640  [12800/69845]
loss: 0.068525  [19200/69845]
loss: 0.178226  [25600/69845]
loss: 0.276284  [32000/69845]
loss: 0.140501  [38400/69845]
loss: 0.179359  [44800/69845]
loss: 0.106248  [51200/69845]
loss: 0.122419  [57600/69845]
loss: 0.105458  [64000/69845]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.158749 

Epoch 10
-------------------------------
loss: 0.071523  [    0/69845]
loss: 0.195697  [ 6400/69845]
loss: 0.065551  [12800/69845]
loss: 0.131003  [19200/69845]
loss: 0.120537  [25600/69845]
loss: 0.200049  [32000/69845]
loss: 0.254521  [38400/69845]
loss: 0.168873  [44800/69845]
loss: 0.115654  [51200/69845]
loss: 0.106526  [57600/69845]
loss: 0.204231  [64000/69845]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.157345 

Epoch 11
-------------------------------
loss: 0.073235  [    0/69845]
loss: 0.182973  [ 6400/69845]
loss: 0.111327  [12800/69845]
loss: 0.292379  [19200/69845]
loss: 0.126930  [25600/69845]
loss: 0.098154  [32000/69845]
loss: 0.076682  [38400/69845]
loss: 0.108753  [44800/69845]
loss: 0.083823  [51200/69845]
loss: 0.087019  [57600/69845]
loss: 0.163639  [64000/69845]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.152292 

Epoch 12
-------------------------------
loss: 0.080120  [    0/69845]
loss: 0.232865  [ 6400/69845]
loss: 0.209540  [12800/69845]
loss: 0.217970  [19200/69845]
loss: 0.174305  [25600/69845]
loss: 0.093307  [32000/69845]
loss: 0.184190  [38400/69845]
loss: 0.148193  [44800/69845]
loss: 0.117925  [51200/69845]
loss: 0.090216  [57600/69845]
loss: 0.057068  [64000/69845]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.151801 

Epoch 13
-------------------------------
loss: 0.058844  [    0/69845]
loss: 0.101982  [ 6400/69845]
loss: 0.230884  [12800/69845]
loss: 0.161143  [19200/69845]
loss: 0.129616  [25600/69845]
loss: 0.101838  [32000/69845]
loss: 0.132260  [38400/69845]
loss: 0.112867  [44800/69845]
loss: 0.170457  [51200/69845]
loss: 0.132679  [57600/69845]
loss: 0.104438  [64000/69845]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.147417 

Epoch 14
-------------------------------
loss: 0.194066  [    0/69845]
loss: 0.035899  [ 6400/69845]
loss: 0.106279  [12800/69845]
loss: 0.069829  [19200/69845]
loss: 0.179673  [25600/69845]
loss: 0.147195  [32000/69845]
loss: 0.152803  [38400/69845]
loss: 0.138930  [44800/69845]
loss: 0.119240  [51200/69845]
loss: 0.045869  [57600/69845]
loss: 0.110571  [64000/69845]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.166436 

Epoch 15
-------------------------------
loss: 0.126844  [    0/69845]
loss: 0.126861  [ 6400/69845]
loss: 0.065584  [12800/69845]
loss: 0.094253  [19200/69845]
loss: 0.216867  [25600/69845]
loss: 0.150466  [32000/69845]
loss: 0.168256  [38400/69845]
loss: 0.210462  [44800/69845]
loss: 0.179266  [51200/69845]
loss: 0.136438  [57600/69845]
loss: 0.123815  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147632 

Epoch 16
-------------------------------
loss: 0.090671  [    0/69845]
loss: 0.170400  [ 6400/69845]
loss: 0.063541  [12800/69845]
loss: 0.113899  [19200/69845]
loss: 0.168117  [25600/69845]
loss: 0.149765  [32000/69845]
loss: 0.064466  [38400/69845]
loss: 0.150594  [44800/69845]
loss: 0.158103  [51200/69845]
loss: 0.183702  [57600/69845]
loss: 0.081200  [64000/69845]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.153556 

Epoch 17
-------------------------------
loss: 0.091457  [    0/69845]
loss: 0.065956  [ 6400/69845]
loss: 0.136717  [12800/69845]
loss: 0.118881  [19200/69845]
loss: 0.147904  [25600/69845]
loss: 0.155300  [32000/69845]
loss: 0.072911  [38400/69845]
loss: 0.063671  [44800/69845]
loss: 0.197560  [51200/69845]
loss: 0.207769  [57600/69845]
loss: 0.190606  [64000/69845]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.144353 

Epoch 18
-------------------------------
loss: 0.077328  [    0/69845]
loss: 0.209920  [ 6400/69845]
loss: 0.074656  [12800/69845]
loss: 0.176491  [19200/69845]
loss: 0.398465  [25600/69845]
loss: 0.120755  [32000/69845]
loss: 0.153105  [38400/69845]
loss: 0.255760  [44800/69845]
loss: 0.076673  [51200/69845]
loss: 0.216859  [57600/69845]
loss: 0.068505  [64000/69845]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.170302 

Epoch 19
-------------------------------
loss: 0.105878  [    0/69845]
loss: 0.112962  [ 6400/69845]
loss: 0.236331  [12800/69845]
loss: 0.156668  [19200/69845]
loss: 0.133729  [25600/69845]
loss: 0.123521  [32000/69845]
loss: 0.064418  [38400/69845]
loss: 0.122798  [44800/69845]
loss: 0.188465  [51200/69845]
loss: 0.072751  [57600/69845]
loss: 0.095973  [64000/69845]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.151017 

Epoch 20
-------------------------------
loss: 0.136649  [    0/69845]
loss: 0.152519  [ 6400/69845]
loss: 0.100751  [12800/69845]
loss: 0.064420  [19200/69845]
loss: 0.072236  [25600/69845]
loss: 0.095353  [32000/69845]
loss: 0.140341  [38400/69845]
loss: 0.098708  [44800/69845]
loss: 0.172740  [51200/69845]
loss: 0.190006  [57600/69845]
loss: 0.197896  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147152 

Epoch 21
-------------------------------
loss: 0.062350  [    0/69845]
loss: 0.121175  [ 6400/69845]
loss: 0.056031  [12800/69845]
loss: 0.161047  [19200/69845]
loss: 0.134390  [25600/69845]
loss: 0.171275  [32000/69845]
loss: 0.177052  [38400/69845]
loss: 0.151414  [44800/69845]
loss: 0.150508  [51200/69845]
loss: 0.103796  [57600/69845]
loss: 0.139351  [64000/69845]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.152104 

Epoch 22
-------------------------------
loss: 0.154680  [    0/69845]
loss: 0.098511  [ 6400/69845]
loss: 0.108780  [12800/69845]
loss: 0.075313  [19200/69845]
loss: 0.109469  [25600/69845]
loss: 0.239401  [32000/69845]
loss: 0.072955  [38400/69845]
loss: 0.141111  [44800/69845]
loss: 0.111016  [51200/69845]
loss: 0.238264  [57600/69845]
loss: 0.133550  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.152572 

Epoch 23
-------------------------------
loss: 0.097671  [    0/69845]
loss: 0.068355  [ 6400/69845]
loss: 0.074274  [12800/69845]
loss: 0.086272  [19200/69845]
loss: 0.179535  [25600/69845]
loss: 0.032154  [32000/69845]
loss: 0.079752  [38400/69845]
loss: 0.121317  [44800/69845]
loss: 0.182033  [51200/69845]
loss: 0.136697  [57600/69845]
loss: 0.241422  [64000/69845]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.162812 

Epoch 24
-------------------------------
loss: 0.068394  [    0/69845]
loss: 0.154489  [ 6400/69845]
loss: 0.097682  [12800/69845]
loss: 0.112255  [19200/69845]
loss: 0.227319  [25600/69845]
loss: 0.197097  [32000/69845]
loss: 0.124681  [38400/69845]
loss: 0.111391  [44800/69845]
loss: 0.065659  [51200/69845]
loss: 0.153838  [57600/69845]
loss: 0.057969  [64000/69845]
loss: 0.023916  [44800/72298]
loss: 0.016130  [51200/72298]
loss: 0.188950  [57600/72298]
loss: 0.004579  [64000/72298]
loss: 0.143320  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.057790 

Epoch 9
-------------------------------
loss: 0.022838  [    0/72298]
loss: 0.095979  [ 6400/72298]
loss: 0.049933  [12800/72298]
loss: 0.007495  [19200/72298]
loss: 0.154361  [25600/72298]
loss: 0.017988  [32000/72298]
loss: 0.020792  [38400/72298]
loss: 0.182910  [44800/72298]
loss: 0.030164  [51200/72298]
loss: 0.075133  [57600/72298]
loss: 0.054334  [64000/72298]
loss: 0.027139  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.067430 

Epoch 10
-------------------------------
loss: 0.030015  [    0/72298]
loss: 0.021764  [ 6400/72298]
loss: 0.003123  [12800/72298]
loss: 0.017553  [19200/72298]
loss: 0.012976  [25600/72298]
loss: 0.007924  [32000/72298]
loss: 0.061602  [38400/72298]
loss: 0.006330  [44800/72298]
loss: 0.026913  [51200/72298]
loss: 0.064875  [57600/72298]
loss: 0.004779  [64000/72298]
loss: 0.023851  [70400/72298]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.060556 

Epoch 11
-------------------------------
loss: 0.018205  [    0/72298]
loss: 0.016750  [ 6400/72298]
loss: 0.000493  [12800/72298]
loss: 0.001192  [19200/72298]
loss: 0.013558  [25600/72298]
loss: 0.097081  [32000/72298]
loss: 0.005187  [38400/72298]
loss: 0.011580  [44800/72298]
loss: 0.133449  [51200/72298]
loss: 0.019580  [57600/72298]
loss: 0.035775  [64000/72298]
loss: 0.014714  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.066692 

Epoch 12
-------------------------------
loss: 0.011280  [    0/72298]
loss: 0.034359  [ 6400/72298]
loss: 0.045773  [12800/72298]
loss: 0.018876  [19200/72298]
loss: 0.026874  [25600/72298]
loss: 0.018646  [32000/72298]
loss: 0.055396  [38400/72298]
loss: 0.027250  [44800/72298]
loss: 0.010234  [51200/72298]
loss: 0.051625  [57600/72298]
loss: 0.027134  [64000/72298]
loss: 0.004232  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.069570 

Epoch 13
-------------------------------
loss: 0.024692  [    0/72298]
loss: 0.038178  [ 6400/72298]
loss: 0.019698  [12800/72298]
loss: 0.028717  [19200/72298]
loss: 0.031723  [25600/72298]
loss: 0.054605  [32000/72298]
loss: 0.023318  [38400/72298]
loss: 0.024579  [44800/72298]
loss: 0.044257  [51200/72298]
loss: 0.008480  [57600/72298]
loss: 0.006542  [64000/72298]
loss: 0.020939  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.058140 

Epoch 14
-------------------------------
loss: 0.080383  [    0/72298]
loss: 0.013159  [ 6400/72298]
loss: 0.010718  [12800/72298]
loss: 0.011736  [19200/72298]
loss: 0.026772  [25600/72298]
loss: 0.047643  [32000/72298]
loss: 0.010646  [38400/72298]
loss: 0.003941  [44800/72298]
loss: 0.013430  [51200/72298]
loss: 0.014835  [57600/72298]
loss: 0.077586  [64000/72298]
loss: 0.016186  [70400/72298]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.058746 

Epoch 15
-------------------------------
loss: 1.573136  [    0/72298]
loss: 0.027799  [ 6400/72298]
loss: 0.005418  [12800/72298]
loss: 0.035031  [19200/72298]
loss: 0.025536  [25600/72298]
loss: 0.058340  [32000/72298]
loss: 0.007505  [38400/72298]
loss: 0.065989  [44800/72298]
loss: 0.009652  [51200/72298]
loss: 0.019747  [57600/72298]
loss: 0.018778  [64000/72298]
loss: 0.038855  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.060635 

Epoch 16
-------------------------------
loss: 0.034051  [    0/72298]
loss: 0.005729  [ 6400/72298]
loss: 0.058601  [12800/72298]
loss: 0.006093  [19200/72298]
loss: 0.082049  [25600/72298]
loss: 0.001508  [32000/72298]
loss: 0.000163  [38400/72298]
loss: 0.013259  [44800/72298]
loss: 0.019388  [51200/72298]
loss: 0.006588  [57600/72298]
loss: 0.032627  [64000/72298]
loss: 0.005693  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.072875 

Epoch 17
-------------------------------
loss: 0.018015  [    0/72298]
loss: 0.006310  [ 6400/72298]
loss: 0.027600  [12800/72298]
loss: 0.011587  [19200/72298]
loss: 0.041339  [25600/72298]
loss: 0.004482  [32000/72298]
loss: 0.008171  [38400/72298]
loss: 0.038424  [44800/72298]
loss: 0.016426  [51200/72298]
loss: 0.008457  [57600/72298]
loss: 0.005872  [64000/72298]
loss: 0.012482  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.070387 

Epoch 18
-------------------------------
loss: 0.009411  [    0/72298]
loss: 0.025724  [ 6400/72298]
loss: 0.003062  [12800/72298]
loss: 0.003532  [19200/72298]
loss: 0.154009  [25600/72298]
loss: 0.006283  [32000/72298]
loss: 0.011500  [38400/72298]
loss: 0.019903  [44800/72298]
loss: 0.055190  [51200/72298]
loss: 0.047141  [57600/72298]
loss: 0.002250  [64000/72298]
loss: 0.002824  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.059777 

Epoch 19
-------------------------------
loss: 0.040819  [    0/72298]
loss: 0.005872  [ 6400/72298]
loss: 0.020170  [12800/72298]
loss: 0.063908  [19200/72298]
loss: 0.006632  [25600/72298]
loss: 0.053567  [32000/72298]
loss: 0.023375  [38400/72298]
loss: 0.026702  [44800/72298]
loss: 0.021691  [51200/72298]
loss: 0.025023  [57600/72298]
loss: 0.003085  [64000/72298]
loss: 0.039248  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.068458 

Epoch 20
-------------------------------
loss: 0.061891  [    0/72298]
loss: 0.042734  [ 6400/72298]
loss: 0.022849  [12800/72298]
loss: 0.011484  [19200/72298]
loss: 0.005991  [25600/72298]
loss: 0.017155  [32000/72298]
loss: 0.001992  [38400/72298]
loss: 0.027273  [44800/72298]
loss: 0.015896  [51200/72298]
loss: 0.004938  [57600/72298]
loss: 0.013741  [64000/72298]
loss: 0.009006  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.069876 

Epoch 21
-------------------------------
loss: 0.007783  [    0/72298]
loss: 0.097279  [ 6400/72298]
loss: 0.003293  [12800/72298]
loss: 0.015325  [19200/72298]
loss: 0.010472  [25600/72298]
loss: 0.015987  [32000/72298]
loss: 0.099989  [38400/72298]
loss: 0.002763  [44800/72298]
loss: 0.003998  [51200/72298]
loss: 0.008408  [57600/72298]
loss: 0.024772  [64000/72298]
loss: 0.010553  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.073575 

Epoch 22
-------------------------------
loss: 0.000585  [    0/72298]
loss: 0.154902  [ 6400/72298]
loss: 0.003424  [12800/72298]
loss: 0.004128  [19200/72298]
loss: 0.017432  [25600/72298]
loss: 0.017327  [32000/72298]
loss: 0.000409  [38400/72298]
loss: 0.048398  [44800/72298]
loss: 0.001287  [51200/72298]
loss: 0.043174  [57600/72298]
loss: 0.008949  [64000/72298]
loss: 0.108569  [70400/72298]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.067534 

Epoch 23
-------------------------------
loss: 0.003789  [    0/72298]
loss: 0.014665  [ 6400/72298]
loss: 0.001199  [12800/72298]
loss: 0.061113  [19200/72298]
loss: 0.005060  [25600/72298]
loss: 0.054350  [32000/72298]
loss: 0.005568  [38400/72298]
loss: 0.024870  [44800/72298]
loss: 0.099747  [51200/72298]
loss: 0.078318  [57600/72298]
loss: 0.003361  [64000/72298]
loss: 0.100024  [70400/72298]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.080078 

Epoch 24
-------------------------------
loss: 0.000349  [    0/72298]
loss: 0.010223  [ 6400/72298]
loss: 0.028821  [12800/72298]
loss: 0.000412  [19200/72298]
loss: 0.087236  [25600/72298]
loss: 0.006616  [32000/72298]
loss: 0.005694  [38400/72298]
loss: 0.028614  [44800/72298]
loss: 0.011934  [51200/72298]
loss: 0.013619  [57600/72298]
loss: 0.004873  [64000/72298]
loss: 0.044256  [70400/72298]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.069369 

Epoch 25
-------------------------------
loss: 0.003729  [    0/72298]
loss: 0.002908  [ 6400/72298]
loss: 0.014694  [12800/72298]
loss: 0.016826  [19200/72298]
loss: 0.004384  [25600/72298]
loss: 0.003664  [32000/72298]
loss: 0.010671  [38400/72298]
loss: 0.002040  [44800/72298]
loss: 0.017099  [51200/72298]
loss: 0.041301  [57600/72298]
loss: 0.028416  [64000/72298]
loss: 0.075417  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.063065 

Epoch 26
-------------------------------
loss: 0.007995  [    0/72298]
loss: 0.002374  [ 6400/72298]
loss: 0.004997  [12800/72298]
loss: 0.028014  [19200/72298]
loss: 0.016716  [25600/72298]
loss: 0.005214  [32000/72298]
loss: 0.005519  [38400/72298]
loss: 0.011157  [44800/72298]
loss: 0.076222  [    0/70247]
loss: 0.077464  [ 6400/70247]
loss: 0.118847  [12800/70247]
loss: 0.056092  [19200/70247]
loss: 0.028471  [25600/70247]
loss: 0.101573  [32000/70247]
loss: 0.041329  [38400/70247]
loss: 0.071289  [44800/70247]
loss: 0.055092  [51200/70247]
loss: 0.080185  [57600/70247]
loss: 0.026423  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.064006 

Epoch 10
-------------------------------
loss: 0.017748  [    0/70247]
loss: 0.061610  [ 6400/70247]
loss: 0.038165  [12800/70247]
loss: 0.049689  [19200/70247]
loss: 0.049132  [25600/70247]
loss: 0.092302  [32000/70247]
loss: 0.067600  [38400/70247]
loss: 0.105111  [44800/70247]
loss: 0.149609  [51200/70247]
loss: 0.054385  [57600/70247]
loss: 0.010365  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.068621 

Epoch 11
-------------------------------
loss: 0.035520  [    0/70247]
loss: 0.022048  [ 6400/70247]
loss: 0.040864  [12800/70247]
loss: 0.066577  [19200/70247]
loss: 0.036360  [25600/70247]
loss: 0.059949  [32000/70247]
loss: 0.058107  [38400/70247]
loss: 0.100250  [44800/70247]
loss: 0.063442  [51200/70247]
loss: 0.039723  [57600/70247]
loss: 0.056807  [64000/70247]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.062399 

Epoch 12
-------------------------------
loss: 0.076068  [    0/70247]
loss: 0.048493  [ 6400/70247]
loss: 0.054186  [12800/70247]
loss: 0.045307  [19200/70247]
loss: 0.041098  [25600/70247]
loss: 0.113854  [32000/70247]
loss: 0.040339  [38400/70247]
loss: 0.092326  [44800/70247]
loss: 0.062242  [51200/70247]
loss: 0.065865  [57600/70247]
loss: 0.093274  [64000/70247]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067998 

Epoch 13
-------------------------------
loss: 0.070619  [    0/70247]
loss: 0.101292  [ 6400/70247]
loss: 0.145866  [12800/70247]
loss: 0.035988  [19200/70247]
loss: 0.012591  [25600/70247]
loss: 0.037538  [32000/70247]
loss: 0.090857  [38400/70247]
loss: 0.020234  [44800/70247]
loss: 0.033862  [51200/70247]
loss: 0.055751  [57600/70247]
loss: 0.083585  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.066642 

Epoch 14
-------------------------------
loss: 0.074325  [    0/70247]
loss: 0.041462  [ 6400/70247]
loss: 0.016299  [12800/70247]
loss: 0.073659  [19200/70247]
loss: 0.034421  [25600/70247]
loss: 0.016154  [32000/70247]
loss: 0.141279  [38400/70247]
loss: 0.033666  [44800/70247]
loss: 0.099072  [51200/70247]
loss: 0.044764  [57600/70247]
loss: 0.048188  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.068548 

Epoch 15
-------------------------------
loss: 0.014293  [    0/70247]
loss: 0.077216  [ 6400/70247]
loss: 0.094313  [12800/70247]
loss: 0.040717  [19200/70247]
loss: 0.028877  [25600/70247]
loss: 0.044316  [32000/70247]
loss: 0.076815  [38400/70247]
loss: 0.018363  [44800/70247]
loss: 0.122017  [51200/70247]
loss: 0.037313  [57600/70247]
loss: 0.064262  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.069080 

Epoch 16
-------------------------------
loss: 0.005802  [    0/70247]
loss: 0.083818  [ 6400/70247]
loss: 0.035249  [12800/70247]
loss: 0.092054  [19200/70247]
loss: 0.037073  [25600/70247]
loss: 0.038574  [32000/70247]
loss: 0.042022  [38400/70247]
loss: 0.047985  [44800/70247]
loss: 0.090519  [51200/70247]
loss: 0.035078  [57600/70247]
loss: 0.056501  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.069036 

Epoch 17
-------------------------------
loss: 0.078581  [    0/70247]
loss: 0.056103  [ 6400/70247]
loss: 0.028053  [12800/70247]
loss: 0.043752  [19200/70247]
loss: 0.008178  [25600/70247]
loss: 0.019474  [32000/70247]
loss: 0.047447  [38400/70247]
loss: 0.021229  [44800/70247]
loss: 0.068468  [51200/70247]
loss: 0.061180  [57600/70247]
loss: 0.040763  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.068265 

Epoch 18
-------------------------------
loss: 0.035663  [    0/70247]
loss: 0.072557  [ 6400/70247]
loss: 0.057207  [12800/70247]
loss: 0.176441  [19200/70247]
loss: 0.028114  [25600/70247]
loss: 0.017227  [32000/70247]
loss: 0.042667  [38400/70247]
loss: 0.079236  [44800/70247]
loss: 0.035167  [51200/70247]
loss: 0.048205  [57600/70247]
loss: 0.049375  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074126 

Epoch 19
-------------------------------
loss: 0.120316  [    0/70247]
loss: 0.048231  [ 6400/70247]
loss: 0.065128  [12800/70247]
loss: 0.019018  [19200/70247]
loss: 0.056415  [25600/70247]
loss: 0.056293  [32000/70247]
loss: 0.023836  [38400/70247]
loss: 0.111511  [44800/70247]
loss: 0.095703  [51200/70247]
loss: 0.058435  [57600/70247]
loss: 0.088786  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075839 

Epoch 20
-------------------------------
loss: 0.032905  [    0/70247]
loss: 0.030932  [ 6400/70247]
loss: 0.045686  [12800/70247]
loss: 0.008598  [19200/70247]
loss: 0.020747  [25600/70247]
loss: 0.077094  [32000/70247]
loss: 0.009730  [38400/70247]
loss: 0.021294  [44800/70247]
loss: 0.052521  [51200/70247]
loss: 0.032806  [57600/70247]
loss: 0.038384  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.068075 

Epoch 21
-------------------------------
loss: 0.042089  [    0/70247]
loss: 0.091474  [ 6400/70247]
loss: 0.035502  [12800/70247]
loss: 0.031159  [19200/70247]
loss: 0.003096  [25600/70247]
loss: 0.033953  [32000/70247]
loss: 0.041772  [38400/70247]
loss: 0.057556  [44800/70247]
loss: 0.025660  [51200/70247]
loss: 0.072970  [57600/70247]
loss: 0.005300  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.078866 

Epoch 22
-------------------------------
loss: 0.055416  [    0/70247]
loss: 0.066193  [ 6400/70247]
loss: 0.081217  [12800/70247]
loss: 0.071042  [19200/70247]
loss: 0.037872  [25600/70247]
loss: 0.112308  [32000/70247]
loss: 0.149622  [38400/70247]
loss: 0.122864  [44800/70247]
loss: 0.046572  [51200/70247]
loss: 0.159299  [57600/70247]
loss: 0.174537  [64000/70247]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.080555 

Epoch 23
-------------------------------
loss: 0.066972  [    0/70247]
loss: 0.012696  [ 6400/70247]
loss: 0.034328  [12800/70247]
loss: 0.046697  [19200/70247]
loss: 0.004685  [25600/70247]
loss: 0.037404  [32000/70247]
loss: 0.043083  [38400/70247]
loss: 0.023477  [44800/70247]
loss: 0.080557  [51200/70247]
loss: 0.091193  [57600/70247]
loss: 0.020212  [64000/70247]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088174 

Epoch 24
-------------------------------
loss: 0.088672  [    0/70247]
loss: 0.064108  [ 6400/70247]
loss: 0.006317  [12800/70247]
loss: 0.031501  [19200/70247]
loss: 0.069834  [25600/70247]
loss: 0.280753  [32000/70247]
loss: 0.008801  [38400/70247]
loss: 0.061478  [44800/70247]
loss: 0.075212  [51200/70247]
loss: 0.084487  [57600/70247]
loss: 0.067072  [64000/70247]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.083879 

Epoch 25
-------------------------------
loss: 0.023202  [    0/70247]
loss: 0.073130  [ 6400/70247]
loss: 0.019666  [12800/70247]
loss: 0.016647  [19200/70247]
loss: 0.046714  [25600/70247]
loss: 0.084932  [32000/70247]
loss: 0.016047  [38400/70247]
loss: 0.061956  [44800/70247]
loss: 0.120974  [51200/70247]
loss: 0.020283  [57600/70247]
loss: 0.128788  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.073070 

Epoch 26
-------------------------------
loss: 0.080204  [    0/70247]
loss: 0.041733  [ 6400/70247]
loss: 0.055081  [12800/70247]
loss: 0.052596  [19200/70247]
loss: 0.068040  [25600/70247]
loss: 0.024862  [32000/70247]
loss: 0.037256  [38400/70247]
loss: 0.031171  [44800/70247]
loss: 0.071333  [51200/70247]
loss: 0.054365  [57600/70247]
loss: 0.030315  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075652 

Epoch 27
-------------------------------
loss: 0.102859  [    0/70247]
loss: 0.007150  [ 6400/70247]
loss: 0.005512  [12800/70247]
loss: 0.009280  [19200/70247]
loss: 0.028944  [25600/70247]
loss: 0.030984  [32000/70247]
loss: 0.054469  [38400/70247]
loss: 0.094928  [44800/70247]
loss: 0.056664  [51200/70247]
loss: 0.054878  [57600/70247]
loss: 0.023338  [64000/70247]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078681 

Epoch 28
-------------------------------
loss: 0.014452  [    0/70247]
loss: 0.018111  [ 6400/70247]
loss: 0.027503  [12800/70247]
loss: 0.043367  [19200/70247]
loss: 0.040507  [25600/70247]
loss: 0.011573  [19200/71122]
loss: 0.038724  [25600/71122]
loss: 0.074503  [32000/71122]
loss: 0.002194  [38400/71122]
loss: 0.021513  [44800/71122]
loss: 0.017324  [51200/71122]
loss: 0.036674  [57600/71122]
loss: 0.047851  [64000/71122]
loss: 0.010616  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.069691 

Epoch 24
-------------------------------
loss: 0.129892  [    0/71122]
loss: 0.011557  [ 6400/71122]
loss: 0.035890  [12800/71122]
loss: 0.008317  [19200/71122]
loss: 0.003036  [25600/71122]
loss: 0.061538  [32000/71122]
loss: 0.044327  [38400/71122]
loss: 0.060003  [44800/71122]
loss: 0.066719  [51200/71122]
loss: 0.006920  [57600/71122]
loss: 0.008419  [64000/71122]
loss: 0.149212  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.066062 

Epoch 25
-------------------------------
loss: 0.012748  [    0/71122]
loss: 0.069532  [ 6400/71122]
loss: 0.001243  [12800/71122]
loss: 0.028108  [19200/71122]
loss: 0.020035  [25600/71122]
loss: 0.009718  [32000/71122]
loss: 0.034154  [38400/71122]
loss: 0.019461  [44800/71122]
loss: 0.007869  [51200/71122]
loss: 0.020643  [57600/71122]
loss: 0.031094  [64000/71122]
loss: 0.295079  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.066350 

Epoch 26
-------------------------------
loss: 0.092032  [    0/71122]
loss: 0.082914  [ 6400/71122]
loss: 0.016474  [12800/71122]
loss: 0.017664  [19200/71122]
loss: 0.028871  [25600/71122]
loss: 0.024523  [32000/71122]
loss: 0.051751  [38400/71122]
loss: 0.008527  [44800/71122]
loss: 0.026081  [51200/71122]
loss: 0.021710  [57600/71122]
loss: 0.011685  [64000/71122]
loss: 0.080869  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.062767 

Epoch 27
-------------------------------
loss: 0.018124  [    0/71122]
loss: 0.015224  [ 6400/71122]
loss: 0.029412  [12800/71122]
loss: 0.034299  [19200/71122]
loss: 0.013729  [25600/71122]
loss: 0.095372  [32000/71122]
loss: 0.045968  [38400/71122]
loss: 0.062856  [44800/71122]
loss: 0.035231  [51200/71122]
loss: 0.003021  [57600/71122]
loss: 0.030000  [64000/71122]
loss: 0.002095  [70400/71122]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066717 

Epoch 28
-------------------------------
loss: 0.004064  [    0/71122]
loss: 0.188435  [ 6400/71122]
loss: 0.008985  [12800/71122]
loss: 0.006149  [19200/71122]
loss: 0.021413  [25600/71122]
loss: 0.047671  [32000/71122]
loss: 0.008802  [38400/71122]
loss: 0.003786  [44800/71122]
loss: 0.050528  [51200/71122]
loss: 0.051836  [57600/71122]
loss: 0.000771  [64000/71122]
loss: 0.084522  [70400/71122]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.065471 

Epoch 29
-------------------------------
loss: 0.011856  [    0/71122]
loss: 0.010567  [ 6400/71122]
loss: 0.042268  [12800/71122]
loss: 0.055304  [19200/71122]
loss: 0.041227  [25600/71122]
loss: 0.096273  [32000/71122]
loss: 0.019923  [38400/71122]
loss: 0.043186  [44800/71122]
loss: 0.057824  [51200/71122]
loss: 0.026601  [57600/71122]
loss: 0.003976  [64000/71122]
loss: 0.023017  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.064960 

Epoch 30
-------------------------------
loss: 0.038687  [    0/71122]
loss: 0.141936  [ 6400/71122]
loss: 0.050673  [12800/71122]
loss: 0.024553  [19200/71122]
loss: 0.032205  [25600/71122]
loss: 0.097692  [32000/71122]
loss: 0.043412  [38400/71122]
loss: 0.015659  [44800/71122]
loss: 0.033135  [51200/71122]
loss: 0.021906  [57600/71122]
loss: 0.056145  [64000/71122]
loss: 0.007007  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.068130 

Epoch 31
-------------------------------
loss: 0.049461  [    0/71122]
loss: 0.053132  [ 6400/71122]
loss: 0.044352  [12800/71122]
loss: 0.024019  [19200/71122]
loss: 0.042598  [25600/71122]
loss: 0.014100  [32000/71122]
loss: 0.117465  [38400/71122]
loss: 0.062203  [44800/71122]
loss: 0.027262  [51200/71122]
loss: 0.049971  [57600/71122]
loss: 0.116305  [64000/71122]
loss: 0.037291  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.066064 

Epoch 32
-------------------------------
loss: 0.011653  [    0/71122]
loss: 0.027387  [ 6400/71122]
loss: 0.024858  [12800/71122]
loss: 0.087724  [19200/71122]
loss: 0.054993  [25600/71122]
loss: 0.048824  [32000/71122]
loss: 0.011851  [38400/71122]
loss: 0.002495  [44800/71122]
loss: 0.017349  [51200/71122]
loss: 0.011457  [57600/71122]
loss: 0.046379  [64000/71122]
loss: 0.034243  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.065408 

Epoch 33
-------------------------------
loss: 0.019323  [    0/71122]
loss: 0.036028  [ 6400/71122]
loss: 0.013279  [12800/71122]
loss: 0.045516  [19200/71122]
loss: 0.004822  [25600/71122]
loss: 0.006669  [32000/71122]
loss: 0.016287  [38400/71122]
loss: 0.008992  [44800/71122]
loss: 0.013645  [51200/71122]
loss: 0.022872  [57600/71122]
loss: 0.061849  [64000/71122]
loss: 0.033134  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.067438 

Epoch 34
-------------------------------
loss: 0.076212  [    0/71122]
loss: 0.018812  [ 6400/71122]
loss: 0.018785  [12800/71122]
loss: 0.022125  [19200/71122]
loss: 0.009506  [25600/71122]
loss: 0.025192  [32000/71122]
loss: 0.089422  [38400/71122]
loss: 0.167140  [44800/71122]
loss: 0.021218  [51200/71122]
loss: 0.131382  [57600/71122]
loss: 0.107649  [64000/71122]
loss: 0.003612  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.068433 

Epoch 35
-------------------------------
loss: 0.078703  [    0/71122]
loss: 0.010328  [ 6400/71122]
loss: 0.054803  [12800/71122]
loss: 0.004048  [19200/71122]
loss: 0.017802  [25600/71122]
loss: 0.027972  [32000/71122]
loss: 0.058245  [38400/71122]
loss: 0.078999  [44800/71122]
loss: 0.032322  [51200/71122]
loss: 0.019633  [57600/71122]
loss: 0.006042  [64000/71122]
loss: 0.024930  [70400/71122]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.083940 

Epoch 36
-------------------------------
loss: 0.073036  [    0/71122]
loss: 0.094116  [ 6400/71122]
loss: 0.060698  [12800/71122]
loss: 0.044948  [19200/71122]
loss: 0.029870  [25600/71122]
loss: 0.024799  [32000/71122]
loss: 0.018660  [38400/71122]
loss: 0.027350  [44800/71122]
loss: 0.003677  [51200/71122]
loss: 0.140438  [57600/71122]
loss: 0.029970  [64000/71122]
loss: 0.018719  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.073701 

Epoch 37
-------------------------------
loss: 0.017852  [    0/71122]
loss: 0.081897  [ 6400/71122]
loss: 0.001177  [12800/71122]
loss: 0.010054  [19200/71122]
loss: 0.024227  [25600/71122]
loss: 0.025793  [32000/71122]
loss: 0.017903  [38400/71122]
loss: 0.008661  [44800/71122]
loss: 0.010163  [51200/71122]
loss: 0.236791  [57600/71122]
loss: 0.002347  [64000/71122]
loss: 0.039674  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.070510 

Epoch 38
-------------------------------
loss: 0.002667  [    0/71122]
loss: 0.012514  [ 6400/71122]
loss: 0.010307  [12800/71122]
loss: 0.004257  [19200/71122]
loss: 0.003548  [25600/71122]
loss: 0.013716  [32000/71122]
loss: 0.050751  [38400/71122]
loss: 0.020796  [44800/71122]
loss: 0.098313  [51200/71122]
loss: 0.063572  [57600/71122]
loss: 0.029135  [64000/71122]
loss: 0.031657  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.085530 

Epoch 39
-------------------------------
loss: 0.128078  [    0/71122]
loss: 0.018166  [ 6400/71122]
loss: 0.130015  [12800/71122]
loss: 0.059099  [19200/71122]
loss: 0.103556  [25600/71122]
loss: 0.012278  [32000/71122]
loss: 0.008564  [38400/71122]
loss: 0.008258  [44800/71122]
loss: 0.021141  [51200/71122]
loss: 0.059235  [57600/71122]
loss: 0.013437  [64000/71122]
loss: 0.028902  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.064903 

Epoch 40
-------------------------------
loss: 0.020403  [    0/71122]
loss: 0.094703  [ 6400/71122]
loss: 0.016916  [12800/71122]
loss: 0.007722  [19200/71122]
loss: 0.028700  [25600/71122]
loss: 0.047961  [32000/71122]
loss: 0.002733  [38400/71122]
loss: 0.130771  [44800/71122]
loss: 0.159058  [51200/71122]
loss: 0.036512  [57600/71122]
loss: 0.011113  [64000/71122]
loss: 0.019676  [70400/71122]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071205 

Epoch 41
-------------------------------
loss: 0.005791  [    0/71122]
loss: 0.008458  [ 6400/71122]
loss: 0.015527  [12800/71122]
loss: 0.239830  [19200/71122]
loss: 0.017573  [19200/71418]
loss: 0.036927  [25600/71418]
loss: 0.019182  [32000/71418]
loss: 0.051525  [38400/71418]
loss: 0.029598  [44800/71418]
loss: 0.083170  [51200/71418]
loss: 0.086595  [57600/71418]
loss: 0.002769  [64000/71418]
loss: 0.009938  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.100542 

Epoch 24
-------------------------------
loss: 0.021092  [    0/71418]
loss: 0.018655  [ 6400/71418]
loss: 0.008161  [12800/71418]
loss: 0.058092  [19200/71418]
loss: 0.002283  [25600/71418]
loss: 0.023844  [32000/71418]
loss: 0.030249  [38400/71418]
loss: 0.053113  [44800/71418]
loss: 0.020179  [51200/71418]
loss: 0.010715  [57600/71418]
loss: 0.002516  [64000/71418]
loss: 0.024036  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.120594 

Epoch 25
-------------------------------
loss: 0.001653  [    0/71418]
loss: 0.007085  [ 6400/71418]
loss: 0.061061  [12800/71418]
loss: 0.022065  [19200/71418]
loss: 0.014347  [25600/71418]
loss: 0.036524  [32000/71418]
loss: 0.005529  [38400/71418]
loss: 0.013787  [44800/71418]
loss: 0.086802  [51200/71418]
loss: 0.057402  [57600/71418]
loss: 0.070548  [64000/71418]
loss: 0.024276  [70400/71418]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.121691 

Epoch 26
-------------------------------
loss: 0.008575  [    0/71418]
loss: 0.012386  [ 6400/71418]
loss: 0.017382  [12800/71418]
loss: 0.029754  [19200/71418]
loss: 0.014518  [25600/71418]
loss: 0.124340  [32000/71418]
loss: 0.022719  [38400/71418]
loss: 0.036860  [44800/71418]
loss: 0.004418  [51200/71418]
loss: 0.224259  [57600/71418]
loss: 0.016607  [64000/71418]
loss: 0.039478  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.147766 

Epoch 27
-------------------------------
loss: 0.003213  [    0/71418]
loss: 0.051004  [ 6400/71418]
loss: 0.000768  [12800/71418]
loss: 0.060813  [19200/71418]
loss: 0.014984  [25600/71418]
loss: 0.016821  [32000/71418]
loss: 0.035751  [38400/71418]
loss: 0.010879  [44800/71418]
loss: 0.067518  [51200/71418]
loss: 0.020113  [57600/71418]
loss: 0.051523  [64000/71418]
loss: 0.059581  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.125193 

Epoch 28
-------------------------------
loss: 0.017450  [    0/71418]
loss: 0.003649  [ 6400/71418]
loss: 0.008548  [12800/71418]
loss: 0.024839  [19200/71418]
loss: 0.018043  [25600/71418]
loss: 0.040355  [32000/71418]
loss: 0.022142  [38400/71418]
loss: 0.023750  [44800/71418]
loss: 0.004799  [51200/71418]
loss: 0.006514  [57600/71418]
loss: 0.036904  [64000/71418]
loss: 0.024572  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.138416 

Epoch 29
-------------------------------
loss: 0.082048  [    0/71418]
loss: 0.009861  [ 6400/71418]
loss: 0.001584  [12800/71418]
loss: 0.004537  [19200/71418]
loss: 0.004404  [25600/71418]
loss: 0.042309  [32000/71418]
loss: 0.023025  [38400/71418]
loss: 0.011812  [44800/71418]
loss: 0.052658  [51200/71418]
loss: 0.042539  [57600/71418]
loss: 0.016448  [64000/71418]
loss: 0.002065  [70400/71418]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.132825 

Epoch 30
-------------------------------
loss: 0.014618  [    0/71418]
loss: 0.035439  [ 6400/71418]
loss: 0.014353  [12800/71418]
loss: 0.012466  [19200/71418]
loss: 0.030280  [25600/71418]
loss: 0.012877  [32000/71418]
loss: 0.016816  [38400/71418]
loss: 0.039781  [44800/71418]
loss: 0.016523  [51200/71418]
loss: 0.028427  [57600/71418]
loss: 0.000998  [64000/71418]
loss: 0.116855  [70400/71418]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.126310 

Epoch 31
-------------------------------
loss: 0.002901  [    0/71418]
loss: 0.002683  [ 6400/71418]
loss: 0.000593  [12800/71418]
loss: 0.007815  [19200/71418]
loss: 0.052543  [25600/71418]
loss: 0.019670  [32000/71418]
loss: 0.056530  [38400/71418]
loss: 0.008776  [44800/71418]
loss: 0.004602  [51200/71418]
loss: 0.001146  [57600/71418]
loss: 0.006823  [64000/71418]
loss: 0.113053  [70400/71418]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.126680 

Epoch 32
-------------------------------
loss: 0.048971  [    0/71418]
loss: 0.013240  [ 6400/71418]
loss: 0.041365  [12800/71418]
loss: 0.016806  [19200/71418]
loss: 0.011515  [25600/71418]
loss: 0.040485  [32000/71418]
loss: 0.001040  [38400/71418]
loss: 0.021744  [44800/71418]
loss: 0.014884  [51200/71418]
loss: 0.008973  [57600/71418]
loss: 0.005117  [64000/71418]
loss: 0.086900  [70400/71418]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.119224 

Epoch 33
-------------------------------
loss: 0.005052  [    0/71418]
loss: 0.015521  [ 6400/71418]
loss: 0.016913  [12800/71418]
loss: 0.035138  [19200/71418]
loss: 0.064530  [25600/71418]
loss: 0.119223  [32000/71418]
loss: 0.009321  [38400/71418]
loss: 0.004237  [44800/71418]
loss: 0.051567  [51200/71418]
loss: 0.002635  [57600/71418]
loss: 0.026170  [64000/71418]
loss: 0.090399  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.133134 

Epoch 34
-------------------------------
loss: 0.014697  [    0/71418]
loss: 0.004613  [ 6400/71418]
loss: 0.004166  [12800/71418]
loss: 0.015701  [19200/71418]
loss: 0.031812  [25600/71418]
loss: 0.076761  [32000/71418]
loss: 0.172517  [38400/71418]
loss: 0.068664  [44800/71418]
loss: 0.002415  [51200/71418]
loss: 0.002892  [57600/71418]
loss: 0.198824  [64000/71418]
loss: 0.055158  [70400/71418]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.183054 

Epoch 35
-------------------------------
loss: 0.002316  [    0/71418]
loss: 0.032152  [ 6400/71418]
loss: 0.026290  [12800/71418]
loss: 0.032222  [19200/71418]
loss: 0.004073  [25600/71418]
loss: 0.008055  [32000/71418]
loss: 0.107653  [38400/71418]
loss: 0.084053  [44800/71418]
loss: 0.104108  [51200/71418]
loss: 0.038339  [57600/71418]
loss: 0.031864  [64000/71418]
loss: 0.019502  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.164984 

Epoch 36
-------------------------------
loss: 0.003669  [    0/71418]
loss: 0.007444  [ 6400/71418]
loss: 0.004434  [12800/71418]
loss: 0.000464  [19200/71418]
loss: 0.083386  [25600/71418]
loss: 0.001458  [32000/71418]
loss: 0.006726  [38400/71418]
loss: 0.011332  [44800/71418]
loss: 0.036408  [51200/71418]
loss: 0.004057  [57600/71418]
loss: 0.003465  [64000/71418]
loss: 0.024044  [70400/71418]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.138422 

Epoch 37
-------------------------------
loss: 0.028861  [    0/71418]
loss: 0.009138  [ 6400/71418]
loss: 0.015927  [12800/71418]
loss: 0.036760  [19200/71418]
loss: 0.008849  [25600/71418]
loss: 0.052156  [32000/71418]
loss: 0.051033  [38400/71418]
loss: 0.003011  [44800/71418]
loss: 0.041341  [51200/71418]
loss: 0.068702  [57600/71418]
loss: 0.020266  [64000/71418]
loss: 0.010073  [70400/71418]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.143705 

Epoch 38
-------------------------------
loss: 0.036134  [    0/71418]
loss: 0.029641  [ 6400/71418]
loss: 0.015214  [12800/71418]
loss: 0.006860  [19200/71418]
loss: 0.022477  [25600/71418]
loss: 0.013271  [32000/71418]
loss: 0.002690  [38400/71418]
loss: 0.009098  [44800/71418]
loss: 0.001270  [51200/71418]
loss: 0.017615  [57600/71418]
loss: 0.002887  [64000/71418]
loss: 0.028872  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.127789 

Epoch 39
-------------------------------
loss: 0.003355  [    0/71418]
loss: 0.017162  [ 6400/71418]
loss: 0.010112  [12800/71418]
loss: 0.016252  [19200/71418]
loss: 0.003715  [25600/71418]
loss: 0.009303  [32000/71418]
loss: 0.004189  [38400/71418]
loss: 0.035737  [44800/71418]
loss: 0.000926  [51200/71418]
loss: 0.031887  [57600/71418]
loss: 0.001987  [64000/71418]
loss: 0.024148  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.137670 

Epoch 40
-------------------------------
loss: 0.095208  [    0/71418]
loss: 0.003976  [ 6400/71418]
loss: 0.010310  [12800/71418]
loss: 0.006611  [19200/71418]
loss: 0.099408  [25600/71418]
loss: 0.004452  [32000/71418]
loss: 0.045403  [38400/71418]
loss: 0.011442  [44800/71418]
loss: 0.134068  [51200/71418]
loss: 0.045249  [57600/71418]
loss: 0.025775  [64000/71418]
loss: 0.010853  [70400/71418]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.131749 

Epoch 41
-------------------------------
loss: 0.004776  [    0/71418]
loss: 0.024645  [ 6400/71418]
loss: 0.076679  [12800/71418]
loss: 0.023537  [19200/71418]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.136301 

Epoch 25
-------------------------------
loss: 0.103576  [    0/69609]
loss: 0.133986  [ 6400/69609]
loss: 0.066276  [12800/69609]
loss: 0.149448  [19200/69609]
loss: 0.119020  [25600/69609]
loss: 0.245592  [32000/69609]
loss: 0.091673  [38400/69609]
loss: 0.121624  [44800/69609]
loss: 0.103522  [51200/69609]
loss: 0.079904  [57600/69609]
loss: 0.082715  [64000/69609]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.131866 

Epoch 26
-------------------------------
loss: 0.048491  [    0/69609]
loss: 0.064917  [ 6400/69609]
loss: 0.075541  [12800/69609]
loss: 0.091775  [19200/69609]
loss: 0.057683  [25600/69609]
loss: 0.060831  [32000/69609]
loss: 0.176734  [38400/69609]
loss: 0.105765  [44800/69609]
loss: 0.200299  [51200/69609]
loss: 0.133410  [57600/69609]
loss: 0.304914  [64000/69609]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.138450 

Epoch 27
-------------------------------
loss: 0.098481  [    0/69609]
loss: 0.119221  [ 6400/69609]
loss: 0.189265  [12800/69609]
loss: 0.095242  [19200/69609]
loss: 0.109393  [25600/69609]
loss: 0.219645  [32000/69609]
loss: 0.237686  [38400/69609]
loss: 0.094400  [44800/69609]
loss: 0.089903  [51200/69609]
loss: 0.087152  [57600/69609]
loss: 0.067553  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.138283 

Epoch 28
-------------------------------
loss: 0.064838  [    0/69609]
loss: 0.057638  [ 6400/69609]
loss: 0.056331  [12800/69609]
loss: 0.066140  [19200/69609]
loss: 0.105154  [25600/69609]
loss: 0.188994  [32000/69609]
loss: 0.090479  [38400/69609]
loss: 0.056465  [44800/69609]
loss: 0.055240  [51200/69609]
loss: 0.069827  [57600/69609]
loss: 0.132206  [64000/69609]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.151715 

Epoch 29
-------------------------------
loss: 0.122018  [    0/69609]
loss: 0.101007  [ 6400/69609]
loss: 0.066510  [12800/69609]
loss: 0.137488  [19200/69609]
loss: 0.084521  [25600/69609]
loss: 0.083787  [32000/69609]
loss: 0.243088  [38400/69609]
loss: 0.082274  [44800/69609]
loss: 0.104943  [51200/69609]
loss: 0.021455  [57600/69609]
loss: 0.133768  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.142340 

Epoch 30
-------------------------------
loss: 0.017494  [    0/69609]
loss: 0.111958  [ 6400/69609]
loss: 0.190716  [12800/69609]
loss: 0.113906  [19200/69609]
loss: 0.134324  [25600/69609]
loss: 0.152917  [32000/69609]
loss: 0.224520  [38400/69609]
loss: 0.118845  [44800/69609]
loss: 0.127007  [51200/69609]
loss: 0.119255  [57600/69609]
loss: 0.052721  [64000/69609]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.136929 

Epoch 31
-------------------------------
loss: 0.126116  [    0/69609]
loss: 0.135496  [ 6400/69609]
loss: 0.086847  [12800/69609]
loss: 0.064098  [19200/69609]
loss: 0.104831  [25600/69609]
loss: 0.080795  [32000/69609]
loss: 0.233892  [38400/69609]
loss: 0.096156  [44800/69609]
loss: 0.208989  [51200/69609]
loss: 0.200581  [57600/69609]
loss: 0.152402  [64000/69609]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.138487 

Epoch 32
-------------------------------
loss: 0.107787  [    0/69609]
loss: 0.049932  [ 6400/69609]
loss: 0.204840  [12800/69609]
loss: 0.135368  [19200/69609]
loss: 0.109551  [25600/69609]
loss: 0.081736  [32000/69609]
loss: 0.154955  [38400/69609]
loss: 0.037696  [44800/69609]
loss: 0.064268  [51200/69609]
loss: 0.080334  [57600/69609]
loss: 0.080929  [64000/69609]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.157131 

Epoch 33
-------------------------------
loss: 0.071978  [    0/69609]
loss: 0.126592  [ 6400/69609]
loss: 0.092957  [12800/69609]
loss: 0.133507  [19200/69609]
loss: 0.190413  [25600/69609]
loss: 0.105886  [32000/69609]
loss: 0.117093  [38400/69609]
loss: 0.090177  [44800/69609]
loss: 0.048729  [51200/69609]
loss: 0.046332  [57600/69609]
loss: 0.047122  [64000/69609]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139706 

Epoch 34
-------------------------------
loss: 0.088342  [    0/69609]
loss: 0.053215  [ 6400/69609]
loss: 0.136502  [12800/69609]
loss: 0.060422  [19200/69609]
loss: 0.116508  [25600/69609]
loss: 0.122036  [32000/69609]
loss: 0.111712  [38400/69609]
loss: 0.134437  [44800/69609]
loss: 0.149722  [51200/69609]
loss: 0.145076  [57600/69609]
loss: 0.085736  [64000/69609]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.142940 

Epoch 35
-------------------------------
loss: 0.106680  [    0/69609]
loss: 0.124069  [ 6400/69609]
loss: 0.106139  [12800/69609]
loss: 0.149009  [19200/69609]
loss: 0.064095  [25600/69609]
loss: 0.143172  [32000/69609]
loss: 0.135983  [38400/69609]
loss: 0.054934  [44800/69609]
loss: 0.120318  [51200/69609]
loss: 0.137716  [57600/69609]
loss: 0.049272  [64000/69609]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.134953 

Epoch 36
-------------------------------
loss: 0.155342  [    0/69609]
loss: 0.079788  [ 6400/69609]
loss: 0.070131  [12800/69609]
loss: 0.149407  [19200/69609]
loss: 0.083310  [25600/69609]
loss: 0.089427  [32000/69609]
loss: 0.077644  [38400/69609]
loss: 0.149197  [44800/69609]
loss: 0.155822  [51200/69609]
loss: 0.094594  [57600/69609]
loss: 0.128903  [64000/69609]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139084 

Epoch 37
-------------------------------
loss: 0.048182  [    0/69609]
loss: 0.132167  [ 6400/69609]
loss: 0.168368  [12800/69609]
loss: 0.064433  [19200/69609]
loss: 0.078294  [25600/69609]
loss: 0.082093  [32000/69609]
loss: 0.134800  [38400/69609]
loss: 0.040627  [44800/69609]
loss: 0.092027  [51200/69609]
loss: 0.094608  [57600/69609]
loss: 0.083418  [64000/69609]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140332 

Epoch 38
-------------------------------
loss: 0.047396  [    0/69609]
loss: 0.046644  [ 6400/69609]
loss: 0.067096  [12800/69609]
loss: 0.127763  [19200/69609]
loss: 0.035642  [25600/69609]
loss: 0.076955  [32000/69609]
loss: 0.167812  [38400/69609]
loss: 0.107005  [44800/69609]
loss: 0.044543  [51200/69609]
loss: 0.076034  [57600/69609]
loss: 0.078115  [64000/69609]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.148398 

Epoch 39
-------------------------------
loss: 0.089665  [    0/69609]
loss: 0.106990  [ 6400/69609]
loss: 0.093527  [12800/69609]
loss: 0.051680  [19200/69609]
loss: 0.086629  [25600/69609]
loss: 0.139402  [32000/69609]
loss: 0.224390  [38400/69609]
loss: 0.068123  [44800/69609]
loss: 0.231233  [51200/69609]
loss: 0.097611  [57600/69609]
loss: 0.039838  [64000/69609]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.142069 

Epoch 40
-------------------------------
loss: 0.079265  [    0/69609]
loss: 0.164555  [ 6400/69609]
loss: 0.122977  [12800/69609]
loss: 0.133527  [19200/69609]
loss: 0.136591  [25600/69609]
loss: 0.154164  [32000/69609]
loss: 0.043418  [38400/69609]
loss: 0.113007  [44800/69609]
loss: 0.043948  [51200/69609]
loss: 0.090459  [57600/69609]
loss: 0.095324  [64000/69609]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146161 

Epoch 41
-------------------------------
loss: 0.082898  [    0/69609]
loss: 0.091805  [ 6400/69609]
loss: 0.087615  [12800/69609]
loss: 0.088950  [19200/69609]
loss: 0.154449  [25600/69609]
loss: 0.064940  [32000/69609]
loss: 0.106169  [38400/69609]
loss: 0.077942  [44800/69609]
loss: 0.096010  [51200/69609]
loss: 0.115028  [57600/69609]
loss: 0.129753  [64000/69609]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.141136 

Epoch 42
-------------------------------
loss: 0.227828  [    0/69609]
loss: 0.064154  [ 6400/69609]
loss: 0.099594  [12800/69609]
loss: 0.161515  [19200/69609]
loss: 0.185897  [25600/69609]
loss: 0.122912  [32000/69609]
loss: 0.120875  [38400/69609]
loss: 0.178038  [44800/69609]
loss: 0.113157  [51200/69609]
loss: 0.170588  [57600/69609]
loss: 0.157265  [64000/69609]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.142457 

Epoch 43
-------------------------------
loss: 0.208191  [    0/69609]
loss: 0.059163  [ 6400/69609]
loss: 0.059766  [12800/69609]
loss: 0.111242  [19200/69609]
loss: 0.087696  [25600/69609]
loss: 0.071828  [32000/69609]
loss: 0.182922  [38400/69609]
loss: 0.117385  [44800/69609]
loss: 0.137052  [51200/69609]
loss: 0.078873  [57600/69609]
loss: 0.113031  [64000/69609]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.138546 

Epoch 44
-------------------------------
loss: 0.082784  [    0/69609]
loss: 0.084266  [ 6400/69609]
loss: 0.087872  [19200/71031]
loss: 0.119508  [25600/71031]
loss: 0.222904  [32000/71031]
loss: 0.049079  [38400/71031]
loss: 0.023619  [44800/71031]
loss: 0.067356  [51200/71031]
loss: 0.043553  [57600/71031]
loss: 0.094143  [64000/71031]
loss: 0.052487  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.123696 

Epoch 24
-------------------------------
loss: 0.043027  [    0/71031]
loss: 0.041414  [ 6400/71031]
loss: 0.035215  [12800/71031]
loss: 0.015274  [19200/71031]
loss: 0.082112  [25600/71031]
loss: 0.076145  [32000/71031]
loss: 0.051969  [38400/71031]
loss: 0.081083  [44800/71031]
loss: 0.061842  [51200/71031]
loss: 0.058062  [57600/71031]
loss: 0.100474  [64000/71031]
loss: 0.077759  [70400/71031]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.124960 

Epoch 25
-------------------------------
loss: 0.054217  [    0/71031]
loss: 0.002208  [ 6400/71031]
loss: 0.033722  [12800/71031]
loss: 0.016239  [19200/71031]
loss: 0.085879  [25600/71031]
loss: 0.021064  [32000/71031]
loss: 0.009988  [38400/71031]
loss: 0.026429  [44800/71031]
loss: 0.058735  [51200/71031]
loss: 0.064946  [57600/71031]
loss: 0.052288  [64000/71031]
loss: 0.038393  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.121089 

Epoch 26
-------------------------------
loss: 0.051711  [    0/71031]
loss: 0.053576  [ 6400/71031]
loss: 0.037910  [12800/71031]
loss: 0.066810  [19200/71031]
loss: 0.104690  [25600/71031]
loss: 0.065889  [32000/71031]
loss: 0.222317  [38400/71031]
loss: 0.027425  [44800/71031]
loss: 0.039345  [51200/71031]
loss: 0.042858  [57600/71031]
loss: 0.065467  [64000/71031]
loss: 0.016662  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.124965 

Epoch 27
-------------------------------
loss: 0.110605  [    0/71031]
loss: 0.035186  [ 6400/71031]
loss: 0.014728  [12800/71031]
loss: 0.011987  [19200/71031]
loss: 0.042769  [25600/71031]
loss: 0.040426  [32000/71031]
loss: 0.041564  [38400/71031]
loss: 0.007390  [44800/71031]
loss: 0.165399  [51200/71031]
loss: 0.040731  [57600/71031]
loss: 0.020337  [64000/71031]
loss: 0.042328  [70400/71031]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.126526 

Epoch 28
-------------------------------
loss: 0.004866  [    0/71031]
loss: 0.048096  [ 6400/71031]
loss: 0.013802  [12800/71031]
loss: 0.016931  [19200/71031]
loss: 0.059515  [25600/71031]
loss: 0.103538  [32000/71031]
loss: 0.093386  [38400/71031]
loss: 0.130583  [44800/71031]
loss: 0.039227  [51200/71031]
loss: 0.063380  [57600/71031]
loss: 0.051003  [64000/71031]
loss: 0.058660  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.127954 

Epoch 29
-------------------------------
loss: 0.021676  [    0/71031]
loss: 0.025681  [ 6400/71031]
loss: 0.040651  [12800/71031]
loss: 0.112804  [19200/71031]
loss: 0.028454  [25600/71031]
loss: 0.058208  [32000/71031]
loss: 0.024467  [38400/71031]
loss: 0.037712  [44800/71031]
loss: 0.024463  [51200/71031]
loss: 0.050434  [57600/71031]
loss: 0.029251  [64000/71031]
loss: 0.028116  [70400/71031]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.122662 

Epoch 30
-------------------------------
loss: 0.013859  [    0/71031]
loss: 0.028685  [ 6400/71031]
loss: 0.046235  [12800/71031]
loss: 0.014279  [19200/71031]
loss: 0.130148  [25600/71031]
loss: 0.061163  [32000/71031]
loss: 0.047640  [38400/71031]
loss: 0.057654  [44800/71031]
loss: 0.039241  [51200/71031]
loss: 0.024489  [57600/71031]
loss: 0.091155  [64000/71031]
loss: 0.027515  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.130805 

Epoch 31
-------------------------------
loss: 0.034260  [    0/71031]
loss: 0.032538  [ 6400/71031]
loss: 0.081453  [12800/71031]
loss: 0.010843  [19200/71031]
loss: 0.154749  [25600/71031]
loss: 0.126718  [32000/71031]
loss: 0.035469  [38400/71031]
loss: 0.041956  [44800/71031]
loss: 0.055419  [51200/71031]
loss: 0.020901  [57600/71031]
loss: 0.077620  [64000/71031]
loss: 0.076686  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.128111 

Epoch 32
-------------------------------
loss: 0.087643  [    0/71031]
loss: 0.033591  [ 6400/71031]
loss: 0.087781  [12800/71031]
loss: 0.028289  [19200/71031]
loss: 0.033809  [25600/71031]
loss: 0.026183  [32000/71031]
loss: 0.047461  [38400/71031]
loss: 0.034828  [44800/71031]
loss: 0.014247  [51200/71031]
loss: 0.070627  [57600/71031]
loss: 0.048925  [64000/71031]
loss: 0.082744  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.124387 

Epoch 33
-------------------------------
loss: 0.062934  [    0/71031]
loss: 0.065586  [ 6400/71031]
loss: 0.028637  [12800/71031]
loss: 0.099173  [19200/71031]
loss: 0.052288  [25600/71031]
loss: 0.075644  [32000/71031]
loss: 1.589661  [38400/71031]
loss: 0.059928  [44800/71031]
loss: 0.044554  [51200/71031]
loss: 0.067326  [57600/71031]
loss: 0.053222  [64000/71031]
loss: 0.038962  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.122498 

Epoch 34
-------------------------------
loss: 0.069039  [    0/71031]
loss: 0.264062  [ 6400/71031]
loss: 0.007343  [12800/71031]
loss: 0.023052  [19200/71031]
loss: 0.044118  [25600/71031]
loss: 0.083857  [32000/71031]
loss: 0.053299  [38400/71031]
loss: 0.044935  [44800/71031]
loss: 0.110054  [51200/71031]
loss: 0.088055  [57600/71031]
loss: 1.626674  [64000/71031]
loss: 0.010606  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.132580 

Epoch 35
-------------------------------
loss: 0.030632  [    0/71031]
loss: 0.018362  [ 6400/71031]
loss: 0.070082  [12800/71031]
loss: 0.090828  [19200/71031]
loss: 0.036855  [25600/71031]
loss: 0.056395  [32000/71031]
loss: 0.032688  [38400/71031]
loss: 0.051765  [44800/71031]
loss: 0.067136  [51200/71031]
loss: 0.030770  [57600/71031]
loss: 0.142602  [64000/71031]
loss: 0.035110  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.129463 

Epoch 36
-------------------------------
loss: 0.056688  [    0/71031]
loss: 0.035031  [ 6400/71031]
loss: 0.090578  [12800/71031]
loss: 0.021982  [19200/71031]
loss: 0.045312  [25600/71031]
loss: 0.038339  [32000/71031]
loss: 0.039212  [38400/71031]
loss: 0.127971  [44800/71031]
loss: 0.129460  [51200/71031]
loss: 0.027250  [57600/71031]
loss: 0.058600  [64000/71031]
loss: 0.027064  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.140296 

Epoch 37
-------------------------------
loss: 0.005424  [    0/71031]
loss: 0.049149  [ 6400/71031]
loss: 0.009740  [12800/71031]
loss: 0.073875  [19200/71031]
loss: 0.031833  [25600/71031]
loss: 0.054646  [32000/71031]
loss: 0.025088  [38400/71031]
loss: 0.064747  [44800/71031]
loss: 0.214582  [51200/71031]
loss: 0.086879  [57600/71031]
loss: 0.063145  [64000/71031]
loss: 0.093316  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.125436 

Epoch 38
-------------------------------
loss: 0.105229  [    0/71031]
loss: 0.015633  [ 6400/71031]
loss: 0.021755  [12800/71031]
loss: 0.129760  [19200/71031]
loss: 0.050953  [25600/71031]
loss: 0.134481  [32000/71031]
loss: 0.025633  [38400/71031]
loss: 0.113284  [44800/71031]
loss: 0.062446  [51200/71031]
loss: 0.052558  [57600/71031]
loss: 0.033092  [64000/71031]
loss: 0.029222  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.135404 

Epoch 39
-------------------------------
loss: 0.039460  [    0/71031]
loss: 0.021093  [ 6400/71031]
loss: 0.096558  [12800/71031]
loss: 0.070089  [19200/71031]
loss: 0.020712  [25600/71031]
loss: 0.022280  [32000/71031]
loss: 0.057622  [38400/71031]
loss: 0.073518  [44800/71031]
loss: 0.024733  [51200/71031]
loss: 0.133780  [57600/71031]
loss: 0.021939  [64000/71031]
loss: 0.064149  [70400/71031]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.130016 

Epoch 40
-------------------------------
loss: 0.041553  [    0/71031]
loss: 0.052381  [ 6400/71031]
loss: 0.042619  [12800/71031]
loss: 0.136452  [19200/71031]
loss: 0.017826  [25600/71031]
loss: 0.004352  [32000/71031]
loss: 0.045469  [38400/71031]
loss: 0.004775  [44800/71031]
loss: 0.084794  [51200/71031]
loss: 0.081830  [57600/71031]
loss: 0.102713  [64000/71031]
loss: 0.066696  [70400/71031]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.124688 

Epoch 41
-------------------------------
loss: 0.187787  [    0/71031]
loss: 0.035675  [ 6400/71031]
loss: 0.027543  [12800/71031]
loss: 0.011760  [19200/71031]
loss: 0.135057  [19200/70755]
loss: 0.029153  [25600/70755]
loss: 0.057035  [32000/70755]
loss: 0.143591  [38400/70755]
loss: 0.094869  [44800/70755]
loss: 0.087492  [51200/70755]
loss: 0.109922  [57600/70755]
loss: 0.251827  [64000/70755]
loss: 0.097396  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.132346 

Epoch 24
-------------------------------
loss: 0.164635  [    0/70755]
loss: 0.115622  [ 6400/70755]
loss: 0.132419  [12800/70755]
loss: 0.130913  [19200/70755]
loss: 0.110219  [25600/70755]
loss: 0.206080  [32000/70755]
loss: 0.087230  [38400/70755]
loss: 0.128662  [44800/70755]
loss: 0.318420  [51200/70755]
loss: 0.100850  [57600/70755]
loss: 0.111648  [64000/70755]
loss: 0.067288  [70400/70755]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.128198 

Epoch 25
-------------------------------
loss: 0.156973  [    0/70755]
loss: 0.120315  [ 6400/70755]
loss: 0.084960  [12800/70755]
loss: 0.097366  [19200/70755]
loss: 0.157464  [25600/70755]
loss: 0.043635  [32000/70755]
loss: 0.158230  [38400/70755]
loss: 0.082613  [44800/70755]
loss: 0.120340  [51200/70755]
loss: 0.124500  [57600/70755]
loss: 0.156587  [64000/70755]
loss: 0.165440  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.132153 

Epoch 26
-------------------------------
loss: 0.096932  [    0/70755]
loss: 0.154359  [ 6400/70755]
loss: 0.132040  [12800/70755]
loss: 0.155301  [19200/70755]
loss: 0.221742  [25600/70755]
loss: 0.143005  [32000/70755]
loss: 0.121750  [38400/70755]
loss: 0.122543  [44800/70755]
loss: 0.115505  [51200/70755]
loss: 0.148542  [57600/70755]
loss: 0.104128  [64000/70755]
loss: 0.101229  [70400/70755]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.128108 

Epoch 27
-------------------------------
loss: 0.112767  [    0/70755]
loss: 0.088213  [ 6400/70755]
loss: 0.109508  [12800/70755]
loss: 0.060212  [19200/70755]
loss: 0.111914  [25600/70755]
loss: 0.132964  [32000/70755]
loss: 0.330340  [38400/70755]
loss: 0.178504  [44800/70755]
loss: 0.083020  [51200/70755]
loss: 0.122395  [57600/70755]
loss: 0.201422  [64000/70755]
loss: 0.175321  [70400/70755]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.134891 

Epoch 28
-------------------------------
loss: 0.136705  [    0/70755]
loss: 0.080824  [ 6400/70755]
loss: 0.150957  [12800/70755]
loss: 0.140114  [19200/70755]
loss: 0.114350  [25600/70755]
loss: 0.126119  [32000/70755]
loss: 0.095972  [38400/70755]
loss: 0.199765  [44800/70755]
loss: 0.238948  [51200/70755]
loss: 0.217253  [57600/70755]
loss: 0.092344  [64000/70755]
loss: 0.238008  [70400/70755]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.144477 

Epoch 29
-------------------------------
loss: 0.083942  [    0/70755]
loss: 0.050233  [ 6400/70755]
loss: 0.152456  [12800/70755]
loss: 0.230127  [19200/70755]
loss: 0.133575  [25600/70755]
loss: 0.159194  [32000/70755]
loss: 0.070581  [38400/70755]
loss: 0.102007  [44800/70755]
loss: 0.093853  [51200/70755]
loss: 0.158764  [57600/70755]
loss: 0.117521  [64000/70755]
loss: 0.189984  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.135842 

Epoch 30
-------------------------------
loss: 0.065833  [    0/70755]
loss: 0.065298  [ 6400/70755]
loss: 0.210504  [12800/70755]
loss: 0.111135  [19200/70755]
loss: 0.067560  [25600/70755]
loss: 0.089131  [32000/70755]
loss: 0.244232  [38400/70755]
loss: 0.112369  [44800/70755]
loss: 0.114715  [51200/70755]
loss: 0.098595  [57600/70755]
loss: 0.257011  [64000/70755]
loss: 0.220719  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.134907 

Epoch 31
-------------------------------
loss: 0.181516  [    0/70755]
loss: 0.180531  [ 6400/70755]
loss: 0.111327  [12800/70755]
loss: 0.114392  [19200/70755]
loss: 0.171812  [25600/70755]
loss: 0.097815  [32000/70755]
loss: 0.084348  [38400/70755]
loss: 0.235829  [44800/70755]
loss: 0.186176  [51200/70755]
loss: 0.082755  [57600/70755]
loss: 0.132827  [64000/70755]
loss: 0.090358  [70400/70755]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.139273 

Epoch 32
-------------------------------
loss: 0.086834  [    0/70755]
loss: 0.161460  [ 6400/70755]
loss: 0.052038  [12800/70755]
loss: 0.117494  [19200/70755]
loss: 0.079788  [25600/70755]
loss: 0.164686  [32000/70755]
loss: 0.133351  [38400/70755]
loss: 0.136234  [44800/70755]
loss: 0.132628  [51200/70755]
loss: 0.299924  [57600/70755]
loss: 0.149472  [64000/70755]
loss: 0.021749  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.135704 

Epoch 33
-------------------------------
loss: 0.184966  [    0/70755]
loss: 0.065479  [ 6400/70755]
loss: 0.150063  [12800/70755]
loss: 0.280693  [19200/70755]
loss: 0.118542  [25600/70755]
loss: 0.105715  [32000/70755]
loss: 0.080467  [38400/70755]
loss: 0.062992  [44800/70755]
loss: 0.097403  [51200/70755]
loss: 0.198466  [57600/70755]
loss: 0.033764  [64000/70755]
loss: 0.196276  [70400/70755]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.185140 

Epoch 34
-------------------------------
loss: 0.047536  [    0/70755]
loss: 0.124321  [ 6400/70755]
loss: 0.171554  [12800/70755]
loss: 0.121707  [19200/70755]
loss: 0.055785  [25600/70755]
loss: 0.122825  [32000/70755]
loss: 0.150507  [38400/70755]
loss: 0.170973  [44800/70755]
loss: 0.175278  [51200/70755]
loss: 0.087404  [57600/70755]
loss: 0.064683  [64000/70755]
loss: 0.103630  [70400/70755]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.129539 

Epoch 35
-------------------------------
loss: 0.187621  [    0/70755]
loss: 0.158183  [ 6400/70755]
loss: 0.148544  [12800/70755]
loss: 0.130201  [19200/70755]
loss: 0.159885  [25600/70755]
loss: 0.148928  [32000/70755]
loss: 0.121974  [38400/70755]
loss: 0.154841  [44800/70755]
loss: 0.066320  [51200/70755]
loss: 0.165354  [57600/70755]
loss: 0.138267  [64000/70755]
loss: 0.076277  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.138073 

Epoch 36
-------------------------------
loss: 0.162130  [    0/70755]
loss: 0.050324  [ 6400/70755]
loss: 0.135111  [12800/70755]
loss: 0.116735  [19200/70755]
loss: 0.103980  [25600/70755]
loss: 0.046496  [32000/70755]
loss: 0.159173  [38400/70755]
loss: 0.129760  [44800/70755]
loss: 0.075566  [51200/70755]
loss: 0.133406  [57600/70755]
loss: 0.123925  [64000/70755]
loss: 0.190321  [70400/70755]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.154963 

Epoch 37
-------------------------------
loss: 0.154763  [    0/70755]
loss: 0.154631  [ 6400/70755]
loss: 0.085540  [12800/70755]
loss: 0.079602  [19200/70755]
loss: 0.142964  [25600/70755]
loss: 0.157275  [32000/70755]
loss: 0.105383  [38400/70755]
loss: 0.138549  [44800/70755]
loss: 0.125507  [51200/70755]
loss: 0.138679  [57600/70755]
loss: 0.119555  [64000/70755]
loss: 0.170790  [70400/70755]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.136670 

Epoch 38
-------------------------------
loss: 0.092584  [    0/70755]
loss: 0.136547  [ 6400/70755]
loss: 0.103505  [12800/70755]
loss: 0.020687  [19200/70755]
loss: 0.054372  [25600/70755]
loss: 0.130703  [32000/70755]
loss: 0.116703  [38400/70755]
loss: 0.057669  [44800/70755]
loss: 0.072544  [51200/70755]
loss: 0.080890  [57600/70755]
loss: 0.190655  [64000/70755]
loss: 0.170600  [70400/70755]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.129740 

Epoch 39
-------------------------------
loss: 0.137873  [    0/70755]
loss: 0.048986  [ 6400/70755]
loss: 0.115636  [12800/70755]
loss: 0.128677  [19200/70755]
loss: 0.130375  [25600/70755]
loss: 0.094700  [32000/70755]
loss: 0.116498  [38400/70755]
loss: 0.098890  [44800/70755]
loss: 0.087951  [51200/70755]
loss: 0.134972  [57600/70755]
loss: 0.091002  [64000/70755]
loss: 0.169681  [70400/70755]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.141379 

Epoch 40
-------------------------------
loss: 0.083282  [    0/70755]
loss: 0.061810  [ 6400/70755]
loss: 0.120175  [12800/70755]
loss: 0.239021  [19200/70755]
loss: 0.210784  [25600/70755]
loss: 0.145593  [32000/70755]
loss: 0.064771  [38400/70755]
loss: 0.074229  [44800/70755]
loss: 0.286054  [51200/70755]
loss: 0.094761  [57600/70755]
loss: 0.115320  [64000/70755]
loss: 0.212882  [70400/70755]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.132760 

Epoch 41
-------------------------------
loss: 0.082478  [    0/70755]
loss: 0.125023  [ 6400/70755]
loss: 0.069362  [12800/70755]
loss: 0.149744  [19200/70755]
loss: 0.058992  [19200/71194]
loss: 0.046604  [25600/71194]
loss: 0.067787  [32000/71194]
loss: 0.084535  [38400/71194]
loss: 0.101470  [44800/71194]
loss: 0.046655  [51200/71194]
loss: 0.128372  [57600/71194]
loss: 0.065412  [64000/71194]
loss: 0.128307  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.105040 

Epoch 24
-------------------------------
loss: 0.026071  [    0/71194]
loss: 0.002957  [ 6400/71194]
loss: 0.022659  [12800/71194]
loss: 0.052034  [19200/71194]
loss: 0.053267  [25600/71194]
loss: 0.126663  [32000/71194]
loss: 0.023681  [38400/71194]
loss: 0.054381  [44800/71194]
loss: 0.041195  [51200/71194]
loss: 0.054523  [57600/71194]
loss: 0.088503  [64000/71194]
loss: 0.036756  [70400/71194]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.113263 

Epoch 25
-------------------------------
loss: 0.027657  [    0/71194]
loss: 0.045342  [ 6400/71194]
loss: 0.092357  [12800/71194]
loss: 0.041644  [19200/71194]
loss: 0.059316  [25600/71194]
loss: 0.143720  [32000/71194]
loss: 0.046166  [38400/71194]
loss: 0.081244  [44800/71194]
loss: 0.056553  [51200/71194]
loss: 0.087245  [57600/71194]
loss: 0.209939  [64000/71194]
loss: 0.026901  [70400/71194]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.103460 

Epoch 26
-------------------------------
loss: 0.070026  [    0/71194]
loss: 0.075140  [ 6400/71194]
loss: 0.024369  [12800/71194]
loss: 0.025905  [19200/71194]
loss: 0.011920  [25600/71194]
loss: 0.124833  [32000/71194]
loss: 0.059365  [38400/71194]
loss: 0.062867  [44800/71194]
loss: 0.100873  [51200/71194]
loss: 0.013049  [57600/71194]
loss: 0.076367  [64000/71194]
loss: 0.035218  [70400/71194]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.115211 

Epoch 27
-------------------------------
loss: 0.008915  [    0/71194]
loss: 0.066058  [ 6400/71194]
loss: 0.031419  [12800/71194]
loss: 0.060113  [19200/71194]
loss: 0.066976  [25600/71194]
loss: 0.093438  [32000/71194]
loss: 0.013998  [38400/71194]
loss: 0.106241  [44800/71194]
loss: 0.051969  [51200/71194]
loss: 0.017243  [57600/71194]
loss: 0.101782  [64000/71194]
loss: 0.055278  [70400/71194]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.104036 

Epoch 28
-------------------------------
loss: 0.034320  [    0/71194]
loss: 0.019525  [ 6400/71194]
loss: 0.089058  [12800/71194]
loss: 0.044708  [19200/71194]
loss: 0.006820  [25600/71194]
loss: 0.018684  [32000/71194]
loss: 0.055239  [38400/71194]
loss: 0.065329  [44800/71194]
loss: 0.053210  [51200/71194]
loss: 0.017332  [57600/71194]
loss: 0.072808  [64000/71194]
loss: 0.120286  [70400/71194]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.111543 

Epoch 29
-------------------------------
loss: 0.026431  [    0/71194]
loss: 0.036426  [ 6400/71194]
loss: 0.054502  [12800/71194]
loss: 0.106184  [19200/71194]
loss: 0.022333  [25600/71194]
loss: 0.156927  [32000/71194]
loss: 0.014493  [38400/71194]
loss: 1.655031  [44800/71194]
loss: 0.038842  [51200/71194]
loss: 0.054560  [57600/71194]
loss: 0.116787  [64000/71194]
loss: 0.053784  [70400/71194]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.101766 

Epoch 30
-------------------------------
loss: 0.005740  [    0/71194]
loss: 0.051974  [ 6400/71194]
loss: 0.030953  [12800/71194]
loss: 0.108059  [19200/71194]
loss: 0.056240  [25600/71194]
loss: 0.077624  [32000/71194]
loss: 0.043671  [38400/71194]
loss: 0.060742  [44800/71194]
loss: 0.094703  [51200/71194]
loss: 0.038902  [57600/71194]
loss: 0.140610  [64000/71194]
loss: 0.037740  [70400/71194]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.101614 

Epoch 31
-------------------------------
loss: 0.105898  [    0/71194]
loss: 0.094725  [ 6400/71194]
loss: 0.057543  [12800/71194]
loss: 0.104065  [19200/71194]
loss: 0.042481  [25600/71194]
loss: 0.124812  [32000/71194]
loss: 0.064719  [38400/71194]
loss: 0.049337  [44800/71194]
loss: 0.022035  [51200/71194]
loss: 0.135929  [57600/71194]
loss: 1.589435  [64000/71194]
loss: 0.054580  [70400/71194]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.102460 

Epoch 32
-------------------------------
loss: 0.045552  [    0/71194]
loss: 0.012684  [ 6400/71194]
loss: 0.044385  [12800/71194]
loss: 1.580790  [19200/71194]
loss: 0.082638  [25600/71194]
loss: 0.028937  [32000/71194]
loss: 0.120960  [38400/71194]
loss: 0.024162  [44800/71194]
loss: 0.059019  [51200/71194]
loss: 0.034703  [57600/71194]
loss: 0.070660  [64000/71194]
loss: 0.138138  [70400/71194]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.103075 

Epoch 33
-------------------------------
loss: 0.045296  [    0/71194]
loss: 0.054472  [ 6400/71194]
loss: 0.032748  [12800/71194]
loss: 0.042449  [19200/71194]
loss: 0.070313  [25600/71194]
loss: 0.122971  [32000/71194]
loss: 0.075192  [38400/71194]
loss: 0.126776  [44800/71194]
loss: 0.045987  [51200/71194]
loss: 0.038770  [57600/71194]
loss: 0.018305  [64000/71194]
loss: 0.066201  [70400/71194]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.116330 

Epoch 34
-------------------------------
loss: 0.024590  [    0/71194]
loss: 0.064237  [ 6400/71194]
loss: 0.028782  [12800/71194]
loss: 0.050927  [19200/71194]
loss: 0.041975  [25600/71194]
loss: 0.048984  [32000/71194]
loss: 0.039209  [38400/71194]
loss: 0.024559  [44800/71194]
loss: 0.026550  [51200/71194]
loss: 0.058095  [57600/71194]
loss: 0.133363  [64000/71194]
loss: 0.036454  [70400/71194]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.106053 

Epoch 35
-------------------------------
loss: 0.201338  [    0/71194]
loss: 0.015922  [ 6400/71194]
loss: 0.086489  [12800/71194]
loss: 0.024091  [19200/71194]
loss: 0.058806  [25600/71194]
loss: 0.044537  [32000/71194]
loss: 0.029277  [38400/71194]
loss: 0.155378  [44800/71194]
loss: 0.116994  [51200/71194]
loss: 0.061875  [57600/71194]
loss: 0.025552  [64000/71194]
loss: 0.050415  [70400/71194]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.101755 

Epoch 36
-------------------------------
loss: 0.016758  [    0/71194]
loss: 0.019360  [ 6400/71194]
loss: 0.031554  [12800/71194]
loss: 0.037114  [19200/71194]
loss: 0.025143  [25600/71194]
loss: 0.045319  [32000/71194]
loss: 0.017625  [38400/71194]
loss: 0.038904  [44800/71194]
loss: 0.034908  [51200/71194]
loss: 0.013784  [57600/71194]
loss: 0.029470  [64000/71194]
loss: 0.124499  [70400/71194]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.110674 

Epoch 37
-------------------------------
loss: 0.116652  [    0/71194]
loss: 0.069886  [ 6400/71194]
loss: 0.069741  [12800/71194]
loss: 0.102907  [19200/71194]
loss: 0.120640  [25600/71194]
loss: 0.016538  [32000/71194]
loss: 0.067292  [38400/71194]
loss: 0.055460  [44800/71194]
loss: 0.140879  [51200/71194]
loss: 0.012710  [57600/71194]
loss: 0.040076  [64000/71194]
loss: 0.072117  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.108996 

Epoch 38
-------------------------------
loss: 0.060664  [    0/71194]
loss: 0.038394  [ 6400/71194]
loss: 0.052536  [12800/71194]
loss: 0.074901  [19200/71194]
loss: 0.009997  [25600/71194]
loss: 0.063483  [32000/71194]
loss: 0.094482  [38400/71194]
loss: 0.032023  [44800/71194]
loss: 0.041175  [51200/71194]
loss: 0.060535  [57600/71194]
loss: 0.039109  [64000/71194]
loss: 0.099745  [70400/71194]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.110934 

Epoch 39
-------------------------------
loss: 0.092402  [    0/71194]
loss: 0.055492  [ 6400/71194]
loss: 0.132318  [12800/71194]
loss: 0.025116  [19200/71194]
loss: 0.043286  [25600/71194]
loss: 0.050969  [32000/71194]
loss: 0.040881  [38400/71194]
loss: 0.046525  [44800/71194]
loss: 0.067922  [51200/71194]
loss: 0.084857  [57600/71194]
loss: 0.019382  [64000/71194]
loss: 0.082874  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.103383 

Epoch 40
-------------------------------
loss: 0.006024  [    0/71194]
loss: 0.224232  [ 6400/71194]
loss: 0.045607  [12800/71194]
loss: 0.111076  [19200/71194]
loss: 0.007138  [25600/71194]
loss: 0.028962  [32000/71194]
loss: 0.027977  [38400/71194]
loss: 0.040874  [44800/71194]
loss: 0.089499  [51200/71194]
loss: 0.061398  [57600/71194]
loss: 0.036600  [64000/71194]
loss: 0.035739  [70400/71194]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.106177 

Epoch 41
-------------------------------
loss: 0.032767  [    0/71194]
loss: 0.028172  [ 6400/71194]
loss: 0.032356  [12800/71194]
loss: 0.042510  [19200/71194]
loss: 0.024240  [19200/70506]
loss: 0.164526  [25600/70506]
loss: 0.035613  [32000/70506]
loss: 0.039277  [38400/70506]
loss: 0.016502  [44800/70506]
loss: 0.035645  [51200/70506]
loss: 0.018520  [57600/70506]
loss: 0.028792  [64000/70506]
loss: 0.017034  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.060633 

Epoch 24
-------------------------------
loss: 0.022232  [    0/70506]
loss: 0.025128  [ 6400/70506]
loss: 0.032741  [12800/70506]
loss: 0.030141  [19200/70506]
loss: 0.072717  [25600/70506]
loss: 0.042014  [32000/70506]
loss: 0.004586  [38400/70506]
loss: 0.015156  [44800/70506]
loss: 0.079825  [51200/70506]
loss: 0.069810  [57600/70506]
loss: 0.093886  [64000/70506]
loss: 0.018602  [70400/70506]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.060322 

Epoch 25
-------------------------------
loss: 0.110915  [    0/70506]
loss: 0.014816  [ 6400/70506]
loss: 0.036529  [12800/70506]
loss: 0.024006  [19200/70506]
loss: 0.059484  [25600/70506]
loss: 0.058283  [32000/70506]
loss: 0.069870  [38400/70506]
loss: 0.046808  [44800/70506]
loss: 0.012367  [51200/70506]
loss: 0.019219  [57600/70506]
loss: 0.036709  [64000/70506]
loss: 0.039265  [70400/70506]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.080920 

Epoch 26
-------------------------------
loss: 0.032857  [    0/70506]
loss: 0.010727  [ 6400/70506]
loss: 0.056061  [12800/70506]
loss: 0.019764  [19200/70506]
loss: 0.012785  [25600/70506]
loss: 0.020586  [32000/70506]
loss: 0.014104  [38400/70506]
loss: 0.012342  [44800/70506]
loss: 0.035437  [51200/70506]
loss: 0.004210  [57600/70506]
loss: 0.023868  [64000/70506]
loss: 0.006602  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.060005 

Epoch 27
-------------------------------
loss: 0.030111  [    0/70506]
loss: 0.041620  [ 6400/70506]
loss: 0.046537  [12800/70506]
loss: 0.072169  [19200/70506]
loss: 0.078198  [25600/70506]
loss: 0.095403  [32000/70506]
loss: 0.204521  [38400/70506]
loss: 0.005133  [44800/70506]
loss: 0.053145  [51200/70506]
loss: 0.017739  [57600/70506]
loss: 0.036672  [64000/70506]
loss: 0.017499  [70400/70506]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.066310 

Epoch 28
-------------------------------
loss: 0.009587  [    0/70506]
loss: 0.033193  [ 6400/70506]
loss: 0.016275  [12800/70506]
loss: 0.061694  [19200/70506]
loss: 0.069699  [25600/70506]
loss: 0.047467  [32000/70506]
loss: 0.085656  [38400/70506]
loss: 0.038164  [44800/70506]
loss: 0.037285  [51200/70506]
loss: 0.018462  [57600/70506]
loss: 0.010279  [64000/70506]
loss: 0.133006  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.176679 

Epoch 29
-------------------------------
loss: 0.021589  [    0/70506]
loss: 0.067726  [ 6400/70506]
loss: 0.027246  [12800/70506]
loss: 0.013694  [19200/70506]
loss: 0.000463  [25600/70506]
loss: 0.020929  [32000/70506]
loss: 0.024021  [38400/70506]
loss: 0.003643  [44800/70506]
loss: 0.032685  [51200/70506]
loss: 0.023761  [57600/70506]
loss: 0.038209  [64000/70506]
loss: 0.038494  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.063126 

Epoch 30
-------------------------------
loss: 0.060833  [    0/70506]
loss: 0.012721  [ 6400/70506]
loss: 0.032462  [12800/70506]
loss: 0.054355  [19200/70506]
loss: 0.018280  [25600/70506]
loss: 0.023354  [32000/70506]
loss: 0.078849  [38400/70506]
loss: 0.021820  [44800/70506]
loss: 0.075103  [51200/70506]
loss: 0.042642  [57600/70506]
loss: 0.023724  [64000/70506]
loss: 0.022185  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.065887 

Epoch 31
-------------------------------
loss: 0.069829  [    0/70506]
loss: 0.023965  [ 6400/70506]
loss: 0.007977  [12800/70506]
loss: 0.044919  [19200/70506]
loss: 0.013419  [25600/70506]
loss: 0.008358  [32000/70506]
loss: 0.033879  [38400/70506]
loss: 0.016347  [44800/70506]
loss: 0.041156  [51200/70506]
loss: 0.057610  [57600/70506]
loss: 0.115055  [64000/70506]
loss: 0.033474  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066011 

Epoch 32
-------------------------------
loss: 0.006273  [    0/70506]
loss: 0.009456  [ 6400/70506]
loss: 0.060298  [12800/70506]
loss: 0.014128  [19200/70506]
loss: 0.013398  [25600/70506]
loss: 0.093895  [32000/70506]
loss: 0.006736  [38400/70506]
loss: 0.007808  [44800/70506]
loss: 0.031044  [51200/70506]
loss: 0.031011  [57600/70506]
loss: 0.021131  [64000/70506]
loss: 0.013569  [70400/70506]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070195 

Epoch 33
-------------------------------
loss: 0.007379  [    0/70506]
loss: 0.006080  [ 6400/70506]
loss: 0.024597  [12800/70506]
loss: 0.039823  [19200/70506]
loss: 0.021494  [25600/70506]
loss: 0.011447  [32000/70506]
loss: 0.126301  [38400/70506]
loss: 0.052942  [44800/70506]
loss: 0.056816  [51200/70506]
loss: 0.066127  [57600/70506]
loss: 0.036887  [64000/70506]
loss: 0.019720  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.063037 

Epoch 34
-------------------------------
loss: 0.028571  [    0/70506]
loss: 0.022404  [ 6400/70506]
loss: 0.009333  [12800/70506]
loss: 0.038278  [19200/70506]
loss: 0.026071  [25600/70506]
loss: 0.063351  [32000/70506]
loss: 0.034657  [38400/70506]
loss: 0.043888  [44800/70506]
loss: 0.032793  [51200/70506]
loss: 0.004394  [57600/70506]
loss: 0.046921  [64000/70506]
loss: 0.103444  [70400/70506]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.065899 

Epoch 35
-------------------------------
loss: 0.040688  [    0/70506]
loss: 0.092053  [ 6400/70506]
loss: 0.014656  [12800/70506]
loss: 0.010841  [19200/70506]
loss: 0.031961  [25600/70506]
loss: 0.047759  [32000/70506]
loss: 0.022418  [38400/70506]
loss: 0.033178  [44800/70506]
loss: 0.023195  [51200/70506]
loss: 0.010469  [57600/70506]
loss: 0.036595  [64000/70506]
loss: 0.008039  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067208 

Epoch 36
-------------------------------
loss: 0.088217  [    0/70506]
loss: 0.004970  [ 6400/70506]
loss: 0.012407  [12800/70506]
loss: 0.118530  [19200/70506]
loss: 0.103566  [25600/70506]
loss: 0.102028  [32000/70506]
loss: 0.095801  [38400/70506]
loss: 0.013410  [44800/70506]
loss: 0.048184  [51200/70506]
loss: 0.009379  [57600/70506]
loss: 0.007795  [64000/70506]
loss: 0.036534  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.062169 

Epoch 37
-------------------------------
loss: 0.032809  [    0/70506]
loss: 0.031546  [ 6400/70506]
loss: 0.006539  [12800/70506]
loss: 0.038133  [19200/70506]
loss: 0.072402  [25600/70506]
loss: 0.057640  [32000/70506]
loss: 0.044259  [38400/70506]
loss: 0.069664  [44800/70506]
loss: 0.008762  [51200/70506]
loss: 0.064474  [57600/70506]
loss: 0.149179  [64000/70506]
loss: 0.047815  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.068090 

Epoch 38
-------------------------------
loss: 0.007236  [    0/70506]
loss: 0.026824  [ 6400/70506]
loss: 0.046155  [12800/70506]
loss: 0.097400  [19200/70506]
loss: 0.020061  [25600/70506]
loss: 0.071205  [32000/70506]
loss: 0.007278  [38400/70506]
loss: 0.063729  [44800/70506]
loss: 0.016797  [51200/70506]
loss: 0.053746  [57600/70506]
loss: 0.091034  [64000/70506]
loss: 0.056543  [70400/70506]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.069871 

Epoch 39
-------------------------------
loss: 0.015442  [    0/70506]
loss: 0.015410  [ 6400/70506]
loss: 0.007789  [12800/70506]
loss: 0.008366  [19200/70506]
loss: 0.029137  [25600/70506]
loss: 0.053780  [32000/70506]
loss: 0.059981  [38400/70506]
loss: 0.016214  [44800/70506]
loss: 0.029346  [51200/70506]
loss: 0.052118  [57600/70506]
loss: 0.015750  [64000/70506]
loss: 0.008316  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.062808 

Epoch 40
-------------------------------
loss: 0.041755  [    0/70506]
loss: 0.036587  [ 6400/70506]
loss: 0.005194  [12800/70506]
loss: 0.090835  [19200/70506]
loss: 0.135740  [25600/70506]
loss: 0.100022  [32000/70506]
loss: 0.029938  [38400/70506]
loss: 0.057011  [44800/70506]
loss: 0.060295  [51200/70506]
loss: 0.032640  [57600/70506]
loss: 0.052233  [64000/70506]
loss: 0.124965  [70400/70506]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082216 

Epoch 41
-------------------------------
loss: 0.028369  [    0/70506]
loss: 0.003942  [ 6400/70506]
loss: 0.067760  [12800/70506]
loss: 0.032042  [19200/70506]
loss: 0.023124  [19200/71130]
loss: 0.100852  [25600/71130]
loss: 0.064503  [32000/71130]
loss: 0.068006  [38400/71130]
loss: 0.074559  [44800/71130]
loss: 0.046678  [51200/71130]
loss: 0.038765  [57600/71130]
loss: 0.087133  [64000/71130]
loss: 0.034024  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.069800 

Epoch 24
-------------------------------
loss: 0.026642  [    0/71130]
loss: 0.079982  [ 6400/71130]
loss: 0.108155  [12800/71130]
loss: 0.073385  [19200/71130]
loss: 0.010984  [25600/71130]
loss: 0.014902  [32000/71130]
loss: 0.107059  [38400/71130]
loss: 0.014927  [44800/71130]
loss: 0.084006  [51200/71130]
loss: 0.079877  [57600/71130]
loss: 0.049140  [64000/71130]
loss: 0.025553  [70400/71130]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080954 

Epoch 25
-------------------------------
loss: 0.034717  [    0/71130]
loss: 0.036696  [ 6400/71130]
loss: 0.031336  [12800/71130]
loss: 0.047393  [19200/71130]
loss: 0.064325  [25600/71130]
loss: 0.024697  [32000/71130]
loss: 0.068179  [38400/71130]
loss: 0.005372  [44800/71130]
loss: 0.052616  [51200/71130]
loss: 0.068012  [57600/71130]
loss: 0.028739  [64000/71130]
loss: 0.015468  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.068736 

Epoch 26
-------------------------------
loss: 0.057045  [    0/71130]
loss: 0.043251  [ 6400/71130]
loss: 0.021774  [12800/71130]
loss: 0.011268  [19200/71130]
loss: 0.018588  [25600/71130]
loss: 0.022422  [32000/71130]
loss: 0.017938  [38400/71130]
loss: 0.075538  [44800/71130]
loss: 0.041466  [51200/71130]
loss: 0.097629  [57600/71130]
loss: 0.020794  [64000/71130]
loss: 0.067352  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067056 

Epoch 27
-------------------------------
loss: 0.029517  [    0/71130]
loss: 0.011015  [ 6400/71130]
loss: 0.037765  [12800/71130]
loss: 0.069769  [19200/71130]
loss: 0.056458  [25600/71130]
loss: 0.053875  [32000/71130]
loss: 0.067787  [38400/71130]
loss: 0.099734  [44800/71130]
loss: 0.209748  [51200/71130]
loss: 0.013413  [57600/71130]
loss: 0.023127  [64000/71130]
loss: 0.075436  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.071008 

Epoch 28
-------------------------------
loss: 0.055551  [    0/71130]
loss: 0.007069  [ 6400/71130]
loss: 0.093574  [12800/71130]
loss: 0.058511  [19200/71130]
loss: 0.014404  [25600/71130]
loss: 0.017350  [32000/71130]
loss: 0.041069  [38400/71130]
loss: 0.025089  [44800/71130]
loss: 0.017505  [51200/71130]
loss: 0.192008  [57600/71130]
loss: 0.039903  [64000/71130]
loss: 0.095099  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072954 

Epoch 29
-------------------------------
loss: 0.029966  [    0/71130]
loss: 0.009137  [ 6400/71130]
loss: 0.277772  [12800/71130]
loss: 0.037981  [19200/71130]
loss: 0.018831  [25600/71130]
loss: 0.022748  [32000/71130]
loss: 0.144568  [38400/71130]
loss: 0.021378  [44800/71130]
loss: 0.002454  [51200/71130]
loss: 0.008386  [57600/71130]
loss: 0.036577  [64000/71130]
loss: 0.052733  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.074226 

Epoch 30
-------------------------------
loss: 0.073207  [    0/71130]
loss: 0.017044  [ 6400/71130]
loss: 0.124163  [12800/71130]
loss: 0.146611  [19200/71130]
loss: 0.038998  [25600/71130]
loss: 0.047057  [32000/71130]
loss: 0.010203  [38400/71130]
loss: 0.048589  [44800/71130]
loss: 0.011186  [51200/71130]
loss: 0.069649  [57600/71130]
loss: 0.038623  [64000/71130]
loss: 0.036649  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.074433 

Epoch 31
-------------------------------
loss: 0.064295  [    0/71130]
loss: 0.085722  [ 6400/71130]
loss: 0.039708  [12800/71130]
loss: 0.205075  [19200/71130]
loss: 0.103618  [25600/71130]
loss: 0.018989  [32000/71130]
loss: 0.029005  [38400/71130]
loss: 0.073270  [44800/71130]
loss: 0.072845  [51200/71130]
loss: 0.063485  [57600/71130]
loss: 0.019652  [64000/71130]
loss: 0.050809  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.076011 

Epoch 32
-------------------------------
loss: 0.065849  [    0/71130]
loss: 0.052292  [ 6400/71130]
loss: 0.055817  [12800/71130]
loss: 0.077505  [19200/71130]
loss: 0.073434  [25600/71130]
loss: 0.075771  [32000/71130]
loss: 0.103675  [38400/71130]
loss: 0.058193  [44800/71130]
loss: 0.025644  [51200/71130]
loss: 0.046490  [57600/71130]
loss: 0.108584  [64000/71130]
loss: 0.029410  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067380 

Epoch 33
-------------------------------
loss: 0.032780  [    0/71130]
loss: 0.028001  [ 6400/71130]
loss: 0.009193  [12800/71130]
loss: 0.039381  [19200/71130]
loss: 0.049732  [25600/71130]
loss: 0.013298  [32000/71130]
loss: 0.022276  [38400/71130]
loss: 0.218210  [44800/71130]
loss: 0.011772  [51200/71130]
loss: 0.056508  [57600/71130]
loss: 0.065543  [64000/71130]
loss: 0.007457  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076689 

Epoch 34
-------------------------------
loss: 0.025785  [    0/71130]
loss: 0.067974  [ 6400/71130]
loss: 0.011618  [12800/71130]
loss: 0.054826  [19200/71130]
loss: 0.013782  [25600/71130]
loss: 0.098143  [32000/71130]
loss: 0.046156  [38400/71130]
loss: 0.060408  [44800/71130]
loss: 0.072179  [51200/71130]
loss: 0.010457  [57600/71130]
loss: 0.006223  [64000/71130]
loss: 0.096541  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070735 

Epoch 35
-------------------------------
loss: 0.013356  [    0/71130]
loss: 0.013790  [ 6400/71130]
loss: 0.008900  [12800/71130]
loss: 0.020844  [19200/71130]
loss: 0.039617  [25600/71130]
loss: 0.025190  [32000/71130]
loss: 0.020702  [38400/71130]
loss: 0.048547  [44800/71130]
loss: 0.016819  [51200/71130]
loss: 0.062634  [57600/71130]
loss: 0.089115  [64000/71130]
loss: 0.055051  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068664 

Epoch 36
-------------------------------
loss: 0.036625  [    0/71130]
loss: 0.078581  [ 6400/71130]
loss: 0.081029  [12800/71130]
loss: 0.082438  [19200/71130]
loss: 0.014920  [25600/71130]
loss: 0.032973  [32000/71130]
loss: 0.071495  [38400/71130]
loss: 0.080604  [44800/71130]
loss: 0.025819  [51200/71130]
loss: 0.037574  [57600/71130]
loss: 0.068922  [64000/71130]
loss: 0.095992  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073467 

Epoch 37
-------------------------------
loss: 0.020303  [    0/71130]
loss: 0.032318  [ 6400/71130]
loss: 0.012048  [12800/71130]
loss: 0.011696  [19200/71130]
loss: 0.032314  [25600/71130]
loss: 0.024833  [32000/71130]
loss: 0.039577  [38400/71130]
loss: 0.132983  [44800/71130]
loss: 0.005062  [51200/71130]
loss: 0.048584  [57600/71130]
loss: 0.078391  [64000/71130]
loss: 0.060235  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.070151 

Epoch 38
-------------------------------
loss: 0.005113  [    0/71130]
loss: 0.045862  [ 6400/71130]
loss: 0.066486  [12800/71130]
loss: 0.087893  [19200/71130]
loss: 0.019466  [25600/71130]
loss: 0.037848  [32000/71130]
loss: 0.019575  [38400/71130]
loss: 0.031601  [44800/71130]
loss: 0.102570  [51200/71130]
loss: 0.073195  [57600/71130]
loss: 0.108967  [64000/71130]
loss: 0.092283  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072142 

Epoch 39
-------------------------------
loss: 0.027592  [    0/71130]
loss: 0.015563  [ 6400/71130]
loss: 0.009842  [12800/71130]
loss: 0.049879  [19200/71130]
loss: 0.055099  [25600/71130]
loss: 0.004583  [32000/71130]
loss: 0.087847  [38400/71130]
loss: 0.053141  [44800/71130]
loss: 0.015864  [51200/71130]
loss: 0.022696  [57600/71130]
loss: 0.082641  [64000/71130]
loss: 0.034411  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072262 

Epoch 40
-------------------------------
loss: 0.023621  [    0/71130]
loss: 0.037826  [ 6400/71130]
loss: 0.075965  [12800/71130]
loss: 0.027545  [19200/71130]
loss: 0.080716  [25600/71130]
loss: 0.328522  [32000/71130]
loss: 0.088800  [38400/71130]
loss: 0.071183  [44800/71130]
loss: 0.005313  [51200/71130]
loss: 0.082679  [57600/71130]
loss: 0.056446  [64000/71130]
loss: 0.088065  [70400/71130]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070500 

Epoch 41
-------------------------------
loss: 0.034858  [    0/71130]
loss: 0.045769  [ 6400/71130]
loss: 0.041681  [12800/71130]
loss: 0.014712  [19200/71130]
loss: 0.058588  [19200/72203]
loss: 0.029372  [25600/72203]
loss: 0.036552  [32000/72203]
loss: 0.029898  [38400/72203]
loss: 0.097515  [44800/72203]
loss: 0.148968  [51200/72203]
loss: 0.010405  [57600/72203]
loss: 0.030130  [64000/72203]
loss: 0.042540  [70400/72203]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.141711 

Epoch 24
-------------------------------
loss: 0.091022  [    0/72203]
loss: 0.007776  [ 6400/72203]
loss: 0.057872  [12800/72203]
loss: 0.056749  [19200/72203]
loss: 0.095063  [25600/72203]
loss: 0.086374  [32000/72203]
loss: 0.061296  [38400/72203]
loss: 0.012392  [44800/72203]
loss: 0.047517  [51200/72203]
loss: 0.044357  [57600/72203]
loss: 0.150895  [64000/72203]
loss: 0.014115  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.145147 

Epoch 25
-------------------------------
loss: 0.051231  [    0/72203]
loss: 0.016783  [ 6400/72203]
loss: 0.054751  [12800/72203]
loss: 0.052522  [19200/72203]
loss: 0.002454  [25600/72203]
loss: 0.043247  [32000/72203]
loss: 0.052409  [38400/72203]
loss: 0.038415  [44800/72203]
loss: 0.062067  [51200/72203]
loss: 0.014904  [57600/72203]
loss: 0.075911  [64000/72203]
loss: 0.063181  [70400/72203]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.142629 

Epoch 26
-------------------------------
loss: 0.032107  [    0/72203]
loss: 0.012548  [ 6400/72203]
loss: 0.124868  [12800/72203]
loss: 0.044904  [19200/72203]
loss: 0.006690  [25600/72203]
loss: 0.022046  [32000/72203]
loss: 0.091418  [38400/72203]
loss: 0.112153  [44800/72203]
loss: 0.036667  [51200/72203]
loss: 0.060032  [57600/72203]
loss: 0.024991  [64000/72203]
loss: 0.054309  [70400/72203]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.146810 

Epoch 27
-------------------------------
loss: 0.082244  [    0/72203]
loss: 1.581440  [ 6400/72203]
loss: 0.046740  [12800/72203]
loss: 0.005665  [19200/72203]
loss: 0.036791  [25600/72203]
loss: 0.099098  [32000/72203]
loss: 0.098713  [38400/72203]
loss: 0.085606  [44800/72203]
loss: 0.035525  [51200/72203]
loss: 0.068042  [57600/72203]
loss: 0.046733  [64000/72203]
loss: 0.050231  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.142826 

Epoch 28
-------------------------------
loss: 0.056226  [    0/72203]
loss: 0.098442  [ 6400/72203]
loss: 0.110495  [12800/72203]
loss: 0.158690  [19200/72203]
loss: 0.021982  [25600/72203]
loss: 0.175306  [32000/72203]
loss: 0.090063  [38400/72203]
loss: 0.078154  [44800/72203]
loss: 0.018434  [51200/72203]
loss: 0.039848  [57600/72203]
loss: 0.049269  [64000/72203]
loss: 0.027198  [70400/72203]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.143669 

Epoch 29
-------------------------------
loss: 0.074523  [    0/72203]
loss: 0.057781  [ 6400/72203]
loss: 0.075650  [12800/72203]
loss: 0.034265  [19200/72203]
loss: 0.027119  [25600/72203]
loss: 0.022227  [32000/72203]
loss: 0.074994  [38400/72203]
loss: 0.022385  [44800/72203]
loss: 0.038305  [51200/72203]
loss: 0.016895  [57600/72203]
loss: 0.107059  [64000/72203]
loss: 0.060615  [70400/72203]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.151291 

Epoch 30
-------------------------------
loss: 0.037109  [    0/72203]
loss: 0.114634  [ 6400/72203]
loss: 0.045757  [12800/72203]
loss: 0.087003  [19200/72203]
loss: 0.011080  [25600/72203]
loss: 0.086093  [32000/72203]
loss: 0.027399  [38400/72203]
loss: 0.021886  [44800/72203]
loss: 1.681884  [51200/72203]
loss: 0.106293  [57600/72203]
loss: 0.056042  [64000/72203]
loss: 0.008853  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.146984 

Epoch 31
-------------------------------
loss: 0.011531  [    0/72203]
loss: 0.101058  [ 6400/72203]
loss: 0.044392  [12800/72203]
loss: 0.052620  [19200/72203]
loss: 0.091991  [25600/72203]
loss: 0.014126  [32000/72203]
loss: 0.038095  [38400/72203]
loss: 0.096840  [44800/72203]
loss: 0.019937  [51200/72203]
loss: 0.072885  [57600/72203]
loss: 0.003218  [64000/72203]
loss: 0.080018  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.143652 

Epoch 32
-------------------------------
loss: 0.051063  [    0/72203]
loss: 0.031729  [ 6400/72203]
loss: 0.083544  [12800/72203]
loss: 0.014283  [19200/72203]
loss: 0.034134  [25600/72203]
loss: 0.038872  [32000/72203]
loss: 0.027823  [38400/72203]
loss: 0.010016  [44800/72203]
loss: 0.103474  [51200/72203]
loss: 0.045012  [57600/72203]
loss: 0.005771  [64000/72203]
loss: 0.050013  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.146837 

Epoch 33
-------------------------------
loss: 0.089111  [    0/72203]
loss: 0.088721  [ 6400/72203]
loss: 1.640707  [12800/72203]
loss: 0.190654  [19200/72203]
loss: 1.583047  [25600/72203]
loss: 0.008098  [32000/72203]
loss: 0.024684  [38400/72203]
loss: 0.036410  [44800/72203]
loss: 0.125354  [51200/72203]
loss: 0.074911  [57600/72203]
loss: 0.004268  [64000/72203]
loss: 0.007098  [70400/72203]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.146667 

Epoch 34
-------------------------------
loss: 0.006213  [    0/72203]
loss: 0.139035  [ 6400/72203]
loss: 0.018369  [12800/72203]
loss: 0.027165  [19200/72203]
loss: 0.110732  [25600/72203]
loss: 0.091834  [32000/72203]
loss: 0.072552  [38400/72203]
loss: 0.012807  [44800/72203]
loss: 0.036779  [51200/72203]
loss: 0.033346  [57600/72203]
loss: 0.069997  [64000/72203]
loss: 0.053145  [70400/72203]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.141217 

Epoch 35
-------------------------------
loss: 0.045669  [    0/72203]
loss: 0.063644  [ 6400/72203]
loss: 0.158064  [12800/72203]
loss: 0.030864  [19200/72203]
loss: 0.025337  [25600/72203]
loss: 0.027948  [32000/72203]
loss: 0.065511  [38400/72203]
loss: 0.091608  [44800/72203]
loss: 0.038788  [51200/72203]
loss: 0.009285  [57600/72203]
loss: 0.055518  [64000/72203]
loss: 0.048186  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.147093 

Epoch 36
-------------------------------
loss: 0.142661  [    0/72203]
loss: 0.094040  [ 6400/72203]
loss: 0.153094  [12800/72203]
loss: 1.620558  [19200/72203]
loss: 0.062286  [25600/72203]
loss: 0.106383  [32000/72203]
loss: 0.082576  [38400/72203]
loss: 0.017634  [44800/72203]
loss: 0.032999  [51200/72203]
loss: 0.037183  [57600/72203]
loss: 0.067376  [64000/72203]
loss: 0.117788  [70400/72203]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.144705 

Epoch 37
-------------------------------
loss: 0.144012  [    0/72203]
loss: 0.066166  [ 6400/72203]
loss: 0.027566  [12800/72203]
loss: 0.073330  [19200/72203]
loss: 0.004132  [25600/72203]
loss: 0.043966  [32000/72203]
loss: 0.020317  [38400/72203]
loss: 0.058545  [44800/72203]
loss: 0.041374  [51200/72203]
loss: 0.013960  [57600/72203]
loss: 0.042928  [64000/72203]
loss: 0.073692  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.149731 

Epoch 38
-------------------------------
loss: 0.016170  [    0/72203]
loss: 0.029720  [ 6400/72203]
loss: 0.113889  [12800/72203]
loss: 1.593601  [19200/72203]
loss: 0.081580  [25600/72203]
loss: 0.081971  [32000/72203]
loss: 0.038673  [38400/72203]
loss: 0.208075  [44800/72203]
loss: 0.023613  [51200/72203]
loss: 0.072709  [57600/72203]
loss: 0.046363  [64000/72203]
loss: 0.031628  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.144589 

Epoch 39
-------------------------------
loss: 0.059155  [    0/72203]
loss: 0.044702  [ 6400/72203]
loss: 0.024964  [12800/72203]
loss: 0.061097  [19200/72203]
loss: 0.112460  [25600/72203]
loss: 0.032676  [32000/72203]
loss: 0.026304  [38400/72203]
loss: 0.075284  [44800/72203]
loss: 1.596473  [51200/72203]
loss: 0.016150  [57600/72203]
loss: 0.171365  [64000/72203]
loss: 0.017703  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.146693 

Epoch 40
-------------------------------
loss: 0.023567  [    0/72203]
loss: 0.078215  [ 6400/72203]
loss: 0.047353  [12800/72203]
loss: 0.131344  [19200/72203]
loss: 0.018663  [25600/72203]
loss: 0.078704  [32000/72203]
loss: 0.018778  [38400/72203]
loss: 0.049248  [44800/72203]
loss: 0.036517  [51200/72203]
loss: 0.022424  [57600/72203]
loss: 0.020069  [64000/72203]
loss: 0.140157  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.143200 

Epoch 41
-------------------------------
loss: 0.058554  [    0/72203]
loss: 0.148580  [ 6400/72203]
loss: 0.067091  [12800/72203]
loss: 0.048003  [19200/72203]
loss: 0.006055  [19200/70644]
loss: 0.047873  [25600/70644]
loss: 0.027985  [32000/70644]
loss: 0.102548  [38400/70644]
loss: 0.024501  [44800/70644]
loss: 0.056800  [51200/70644]
loss: 0.156920  [57600/70644]
loss: 0.176673  [64000/70644]
loss: 0.006285  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083178 

Epoch 24
-------------------------------
loss: 0.063836  [    0/70644]
loss: 0.135963  [ 6400/70644]
loss: 0.059275  [12800/70644]
loss: 0.149009  [19200/70644]
loss: 0.028700  [25600/70644]
loss: 0.029205  [32000/70644]
loss: 0.021313  [38400/70644]
loss: 0.072694  [44800/70644]
loss: 0.037013  [51200/70644]
loss: 0.013586  [57600/70644]
loss: 0.037131  [64000/70644]
loss: 0.061441  [70400/70644]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.079536 

Epoch 25
-------------------------------
loss: 0.096202  [    0/70644]
loss: 0.060103  [ 6400/70644]
loss: 0.073195  [12800/70644]
loss: 0.090858  [19200/70644]
loss: 0.037942  [25600/70644]
loss: 0.071438  [32000/70644]
loss: 0.077252  [38400/70644]
loss: 0.018135  [44800/70644]
loss: 0.033057  [51200/70644]
loss: 0.106843  [57600/70644]
loss: 0.074554  [64000/70644]
loss: 0.131433  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082278 

Epoch 26
-------------------------------
loss: 0.057591  [    0/70644]
loss: 0.040334  [ 6400/70644]
loss: 0.015898  [12800/70644]
loss: 0.083897  [19200/70644]
loss: 0.033192  [25600/70644]
loss: 0.071965  [32000/70644]
loss: 0.077689  [38400/70644]
loss: 0.055221  [44800/70644]
loss: 0.041504  [51200/70644]
loss: 0.036873  [57600/70644]
loss: 0.068305  [64000/70644]
loss: 0.038794  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080040 

Epoch 27
-------------------------------
loss: 0.009453  [    0/70644]
loss: 0.047368  [ 6400/70644]
loss: 0.010429  [12800/70644]
loss: 0.092116  [19200/70644]
loss: 0.080244  [25600/70644]
loss: 0.045948  [32000/70644]
loss: 0.282398  [38400/70644]
loss: 0.038639  [44800/70644]
loss: 0.055059  [51200/70644]
loss: 0.077457  [57600/70644]
loss: 0.089789  [64000/70644]
loss: 0.086757  [70400/70644]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.091396 

Epoch 28
-------------------------------
loss: 0.119806  [    0/70644]
loss: 0.187095  [ 6400/70644]
loss: 0.047089  [12800/70644]
loss: 0.055098  [19200/70644]
loss: 0.051738  [25600/70644]
loss: 0.032937  [32000/70644]
loss: 0.081943  [38400/70644]
loss: 0.069592  [44800/70644]
loss: 0.022861  [51200/70644]
loss: 0.050520  [57600/70644]
loss: 0.045772  [64000/70644]
loss: 0.186240  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082811 

Epoch 29
-------------------------------
loss: 0.038318  [    0/70644]
loss: 0.021504  [ 6400/70644]
loss: 0.105275  [12800/70644]
loss: 0.046555  [19200/70644]
loss: 0.037245  [25600/70644]
loss: 0.215351  [32000/70644]
loss: 0.105566  [38400/70644]
loss: 0.116170  [44800/70644]
loss: 0.058428  [51200/70644]
loss: 0.040168  [57600/70644]
loss: 0.064895  [64000/70644]
loss: 0.079253  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082136 

Epoch 30
-------------------------------
loss: 0.186208  [    0/70644]
loss: 0.038007  [ 6400/70644]
loss: 0.052562  [12800/70644]
loss: 0.073142  [19200/70644]
loss: 0.027603  [25600/70644]
loss: 0.036465  [32000/70644]
loss: 0.031636  [38400/70644]
loss: 0.026453  [44800/70644]
loss: 0.057893  [51200/70644]
loss: 0.041925  [57600/70644]
loss: 0.023404  [64000/70644]
loss: 0.116675  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085739 

Epoch 31
-------------------------------
loss: 0.085547  [    0/70644]
loss: 0.030649  [ 6400/70644]
loss: 0.050653  [12800/70644]
loss: 0.093501  [19200/70644]
loss: 0.026258  [25600/70644]
loss: 0.034498  [32000/70644]
loss: 0.051415  [38400/70644]
loss: 0.035485  [44800/70644]
loss: 0.072681  [51200/70644]
loss: 0.048120  [57600/70644]
loss: 0.031162  [64000/70644]
loss: 0.032525  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.085616 

Epoch 32
-------------------------------
loss: 0.061234  [    0/70644]
loss: 0.033206  [ 6400/70644]
loss: 0.083405  [12800/70644]
loss: 0.031646  [19200/70644]
loss: 0.030156  [25600/70644]
loss: 0.035957  [32000/70644]
loss: 0.060538  [38400/70644]
loss: 0.056598  [44800/70644]
loss: 0.075775  [51200/70644]
loss: 0.065010  [57600/70644]
loss: 0.099339  [64000/70644]
loss: 0.170988  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.081658 

Epoch 33
-------------------------------
loss: 0.025500  [    0/70644]
loss: 0.024505  [ 6400/70644]
loss: 0.018937  [12800/70644]
loss: 0.107748  [19200/70644]
loss: 0.021137  [25600/70644]
loss: 0.079859  [32000/70644]
loss: 0.143199  [38400/70644]
loss: 0.039865  [44800/70644]
loss: 0.070052  [51200/70644]
loss: 0.117915  [57600/70644]
loss: 0.075311  [64000/70644]
loss: 0.032899  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082769 

Epoch 34
-------------------------------
loss: 0.023175  [    0/70644]
loss: 0.066661  [ 6400/70644]
loss: 0.079743  [12800/70644]
loss: 0.069614  [19200/70644]
loss: 0.050179  [25600/70644]
loss: 0.037950  [32000/70644]
loss: 0.075761  [38400/70644]
loss: 0.120808  [44800/70644]
loss: 0.035713  [51200/70644]
loss: 0.024851  [57600/70644]
loss: 0.021130  [64000/70644]
loss: 0.083884  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.082438 

Epoch 35
-------------------------------
loss: 0.060605  [    0/70644]
loss: 0.045268  [ 6400/70644]
loss: 0.026204  [12800/70644]
loss: 0.058786  [19200/70644]
loss: 0.037082  [25600/70644]
loss: 0.043221  [32000/70644]
loss: 0.077553  [38400/70644]
loss: 0.005440  [44800/70644]
loss: 0.057665  [51200/70644]
loss: 0.033118  [57600/70644]
loss: 0.052470  [64000/70644]
loss: 0.075576  [70400/70644]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.077068 

Epoch 36
-------------------------------
loss: 0.133782  [    0/70644]
loss: 0.019235  [ 6400/70644]
loss: 0.015504  [12800/70644]
loss: 0.018599  [19200/70644]
loss: 0.029096  [25600/70644]
loss: 0.062528  [32000/70644]
loss: 0.069834  [38400/70644]
loss: 0.141909  [44800/70644]
loss: 0.026868  [51200/70644]
loss: 0.046145  [57600/70644]
loss: 0.064089  [64000/70644]
loss: 0.054298  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.088672 

Epoch 37
-------------------------------
loss: 0.018875  [    0/70644]
loss: 0.096950  [ 6400/70644]
loss: 0.054544  [12800/70644]
loss: 0.047844  [19200/70644]
loss: 0.187410  [25600/70644]
loss: 0.020321  [32000/70644]
loss: 0.040884  [38400/70644]
loss: 0.024567  [44800/70644]
loss: 0.043171  [51200/70644]
loss: 0.027073  [57600/70644]
loss: 0.084940  [64000/70644]
loss: 0.064617  [70400/70644]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.081524 

Epoch 38
-------------------------------
loss: 0.033171  [    0/70644]
loss: 0.047192  [ 6400/70644]
loss: 0.033192  [12800/70644]
loss: 0.108733  [19200/70644]
loss: 0.024715  [25600/70644]
loss: 0.077374  [32000/70644]
loss: 0.027391  [38400/70644]
loss: 0.064269  [44800/70644]
loss: 0.148628  [51200/70644]
loss: 0.098981  [57600/70644]
loss: 0.105521  [64000/70644]
loss: 0.023124  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.091215 

Epoch 39
-------------------------------
loss: 0.051202  [    0/70644]
loss: 0.136980  [ 6400/70644]
loss: 0.055859  [12800/70644]
loss: 0.010940  [19200/70644]
loss: 0.105755  [25600/70644]
loss: 0.010940  [32000/70644]
loss: 0.066400  [38400/70644]
loss: 0.056213  [44800/70644]
loss: 0.023698  [51200/70644]
loss: 0.108496  [57600/70644]
loss: 0.055062  [64000/70644]
loss: 0.058300  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.088953 

Epoch 40
-------------------------------
loss: 0.027548  [    0/70644]
loss: 0.086489  [ 6400/70644]
loss: 0.063798  [12800/70644]
loss: 0.074932  [19200/70644]
loss: 0.010451  [25600/70644]
loss: 0.097656  [32000/70644]
loss: 0.078981  [38400/70644]
loss: 0.043455  [44800/70644]
loss: 0.003473  [51200/70644]
loss: 0.020806  [57600/70644]
loss: 0.027122  [64000/70644]
loss: 0.063174  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.087140 

Epoch 41
-------------------------------
loss: 0.005000  [    0/70644]
loss: 0.150711  [ 6400/70644]
loss: 0.168302  [12800/70644]
loss: 0.046279  [19200/70644]
loss: 0.077092  [19200/70999]
loss: 0.093711  [25600/70999]
loss: 0.154612  [32000/70999]
loss: 0.055042  [38400/70999]
loss: 0.128563  [44800/70999]
loss: 0.091144  [51200/70999]
loss: 0.112367  [57600/70999]
loss: 0.077841  [64000/70999]
loss: 0.097667  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.135955 

Epoch 24
-------------------------------
loss: 0.175102  [    0/70999]
loss: 0.100031  [ 6400/70999]
loss: 0.072834  [12800/70999]
loss: 0.117818  [19200/70999]
loss: 0.038744  [25600/70999]
loss: 0.120371  [32000/70999]
loss: 0.071242  [38400/70999]
loss: 0.257243  [44800/70999]
loss: 0.142604  [51200/70999]
loss: 0.045839  [57600/70999]
loss: 0.118776  [64000/70999]
loss: 0.120477  [70400/70999]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.173671 

Epoch 25
-------------------------------
loss: 0.167935  [    0/70999]
loss: 0.163552  [ 6400/70999]
loss: 0.116929  [12800/70999]
loss: 0.060970  [19200/70999]
loss: 0.196509  [25600/70999]
loss: 0.113246  [32000/70999]
loss: 0.150397  [38400/70999]
loss: 0.161617  [44800/70999]
loss: 0.127473  [51200/70999]
loss: 0.057008  [57600/70999]
loss: 0.112477  [64000/70999]
loss: 0.163386  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.136408 

Epoch 26
-------------------------------
loss: 0.110042  [    0/70999]
loss: 0.034571  [ 6400/70999]
loss: 0.157529  [12800/70999]
loss: 0.038931  [19200/70999]
loss: 0.055692  [25600/70999]
loss: 0.114523  [32000/70999]
loss: 0.224968  [38400/70999]
loss: 0.191106  [44800/70999]
loss: 0.154665  [51200/70999]
loss: 0.158075  [57600/70999]
loss: 0.212518  [64000/70999]
loss: 0.127613  [70400/70999]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.137356 

Epoch 27
-------------------------------
loss: 0.124548  [    0/70999]
loss: 0.230322  [ 6400/70999]
loss: 0.270217  [12800/70999]
loss: 0.048146  [19200/70999]
loss: 0.118013  [25600/70999]
loss: 0.127068  [32000/70999]
loss: 0.157470  [38400/70999]
loss: 0.240004  [44800/70999]
loss: 0.083901  [51200/70999]
loss: 0.084556  [57600/70999]
loss: 0.113687  [64000/70999]
loss: 0.226557  [70400/70999]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.134740 

Epoch 28
-------------------------------
loss: 0.140184  [    0/70999]
loss: 0.150402  [ 6400/70999]
loss: 0.178424  [12800/70999]
loss: 0.083214  [19200/70999]
loss: 0.111529  [25600/70999]
loss: 0.130861  [32000/70999]
loss: 0.140836  [38400/70999]
loss: 0.095151  [44800/70999]
loss: 0.140182  [51200/70999]
loss: 0.170007  [57600/70999]
loss: 0.135032  [64000/70999]
loss: 0.040373  [70400/70999]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.144747 

Epoch 29
-------------------------------
loss: 0.122536  [    0/70999]
loss: 0.113945  [ 6400/70999]
loss: 0.134835  [12800/70999]
loss: 0.078692  [19200/70999]
loss: 0.118169  [25600/70999]
loss: 0.092484  [32000/70999]
loss: 0.049458  [38400/70999]
loss: 0.157683  [44800/70999]
loss: 0.040317  [51200/70999]
loss: 0.152386  [57600/70999]
loss: 0.103990  [64000/70999]
loss: 0.131661  [70400/70999]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.142172 

Epoch 30
-------------------------------
loss: 0.181083  [    0/70999]
loss: 0.197145  [ 6400/70999]
loss: 0.077906  [12800/70999]
loss: 0.142442  [19200/70999]
loss: 0.196614  [25600/70999]
loss: 0.185577  [32000/70999]
loss: 0.087872  [38400/70999]
loss: 0.119276  [44800/70999]
loss: 0.030155  [51200/70999]
loss: 0.100446  [57600/70999]
loss: 0.091254  [64000/70999]
loss: 0.088261  [70400/70999]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.161284 

Epoch 31
-------------------------------
loss: 0.177808  [    0/70999]
loss: 0.156980  [ 6400/70999]
loss: 0.053223  [12800/70999]
loss: 0.110253  [19200/70999]
loss: 0.083616  [25600/70999]
loss: 0.046675  [32000/70999]
loss: 0.107765  [38400/70999]
loss: 0.166455  [44800/70999]
loss: 0.172896  [51200/70999]
loss: 0.241157  [57600/70999]
loss: 0.113340  [64000/70999]
loss: 0.136191  [70400/70999]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.150241 

Epoch 32
-------------------------------
loss: 0.227644  [    0/70999]
loss: 0.194599  [ 6400/70999]
loss: 0.063252  [12800/70999]
loss: 0.079471  [19200/70999]
loss: 0.060088  [25600/70999]
loss: 0.075857  [32000/70999]
loss: 0.022107  [38400/70999]
loss: 0.165521  [44800/70999]
loss: 0.123341  [51200/70999]
loss: 0.147047  [57600/70999]
loss: 0.221064  [64000/70999]
loss: 0.064697  [70400/70999]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.135333 

Epoch 33
-------------------------------
loss: 0.065097  [    0/70999]
loss: 0.214526  [ 6400/70999]
loss: 0.113654  [12800/70999]
loss: 0.138104  [19200/70999]
loss: 0.120362  [25600/70999]
loss: 0.108969  [32000/70999]
loss: 0.131173  [38400/70999]
loss: 0.084055  [44800/70999]
loss: 0.145578  [51200/70999]
loss: 0.170452  [57600/70999]
loss: 0.086030  [64000/70999]
loss: 0.132341  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.142028 

Epoch 34
-------------------------------
loss: 0.154328  [    0/70999]
loss: 0.112448  [ 6400/70999]
loss: 0.082955  [12800/70999]
loss: 0.072809  [19200/70999]
loss: 0.060093  [25600/70999]
loss: 0.050343  [32000/70999]
loss: 0.157103  [38400/70999]
loss: 0.078725  [44800/70999]
loss: 0.040740  [51200/70999]
loss: 0.135688  [57600/70999]
loss: 0.161200  [64000/70999]
loss: 0.155013  [70400/70999]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.136397 

Epoch 35
-------------------------------
loss: 0.095512  [    0/70999]
loss: 0.104093  [ 6400/70999]
loss: 0.075527  [12800/70999]
loss: 0.058047  [19200/70999]
loss: 0.082833  [25600/70999]
loss: 0.016009  [32000/70999]
loss: 0.143966  [38400/70999]
loss: 0.102443  [44800/70999]
loss: 0.211443  [51200/70999]
loss: 0.036445  [57600/70999]
loss: 0.119820  [64000/70999]
loss: 0.125362  [70400/70999]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139757 

Epoch 36
-------------------------------
loss: 0.190098  [    0/70999]
loss: 0.178298  [ 6400/70999]
loss: 0.079325  [12800/70999]
loss: 0.036292  [19200/70999]
loss: 0.093952  [25600/70999]
loss: 0.071076  [32000/70999]
loss: 0.127027  [38400/70999]
loss: 0.075479  [44800/70999]
loss: 0.083738  [51200/70999]
loss: 0.112279  [57600/70999]
loss: 0.045384  [64000/70999]
loss: 0.084176  [70400/70999]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.137715 

Epoch 37
-------------------------------
loss: 0.113183  [    0/70999]
loss: 0.072157  [ 6400/70999]
loss: 0.052868  [12800/70999]
loss: 0.113944  [19200/70999]
loss: 0.104633  [25600/70999]
loss: 0.104031  [32000/70999]
loss: 0.185400  [38400/70999]
loss: 0.083638  [44800/70999]
loss: 0.061766  [51200/70999]
loss: 0.055277  [57600/70999]
loss: 0.439321  [64000/70999]
loss: 0.064495  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.148152 

Epoch 38
-------------------------------
loss: 0.073795  [    0/70999]
loss: 0.279013  [ 6400/70999]
loss: 0.133127  [12800/70999]
loss: 0.190843  [19200/70999]
loss: 0.066110  [25600/70999]
loss: 0.116823  [32000/70999]
loss: 0.198405  [38400/70999]
loss: 0.128894  [44800/70999]
loss: 0.105240  [51200/70999]
loss: 0.127160  [57600/70999]
loss: 0.148590  [64000/70999]
loss: 0.054763  [70400/70999]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.143932 

Epoch 39
-------------------------------
loss: 0.146773  [    0/70999]
loss: 0.178456  [ 6400/70999]
loss: 0.082239  [12800/70999]
loss: 0.101938  [19200/70999]
loss: 0.102324  [25600/70999]
loss: 0.104114  [32000/70999]
loss: 0.161976  [38400/70999]
loss: 0.098944  [44800/70999]
loss: 0.132981  [51200/70999]
loss: 0.155541  [57600/70999]
loss: 0.212775  [64000/70999]
loss: 0.104145  [70400/70999]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.152054 

Epoch 40
-------------------------------
loss: 0.117213  [    0/70999]
loss: 0.181441  [ 6400/70999]
loss: 0.057851  [12800/70999]
loss: 0.136523  [19200/70999]
loss: 0.163022  [25600/70999]
loss: 0.057952  [32000/70999]
loss: 0.144856  [38400/70999]
loss: 0.247196  [44800/70999]
loss: 0.135809  [51200/70999]
loss: 0.133541  [57600/70999]
loss: 0.076541  [64000/70999]
loss: 0.105282  [70400/70999]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.141402 

Epoch 41
-------------------------------
loss: 0.069273  [    0/70999]
loss: 0.159127  [ 6400/70999]
loss: 0.027274  [12800/70999]
loss: 0.163796  [19200/70999]
2022/09/20 14:02:58 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.164366  [51200/70451]
loss: 0.076362  [57600/70451]
loss: 0.136802  [64000/70451]
loss: 0.265627  [56100/70451]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.141911 

Epoch 27
-------------------------------
loss: 0.048606  [    0/70451]
loss: 0.098334  [ 6400/70451]
loss: 0.124490  [12800/70451]
loss: 0.044029  [19200/70451]
loss: 0.043759  [25600/70451]
loss: 0.117313  [32000/70451]
loss: 0.104618  [38400/70451]
loss: 0.186901  [44800/70451]
loss: 0.108493  [51200/70451]
loss: 0.131131  [57600/70451]
loss: 0.080987  [64000/70451]
loss: 0.105790  [56100/70451]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.146449 

Epoch 28
-------------------------------
loss: 0.093231  [    0/70451]
loss: 0.082826  [ 6400/70451]
loss: 0.053166  [12800/70451]
loss: 0.054261  [19200/70451]
loss: 0.103010  [25600/70451]
loss: 0.062896  [32000/70451]
loss: 0.098549  [38400/70451]
loss: 0.087573  [44800/70451]
loss: 0.132736  [51200/70451]
loss: 0.055106  [57600/70451]
loss: 0.140933  [64000/70451]
loss: 0.083240  [56100/70451]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.166899 

Epoch 29
-------------------------------
loss: 0.067396  [    0/70451]
loss: 0.163065  [ 6400/70451]
loss: 0.046705  [12800/70451]
loss: 0.119940  [19200/70451]
loss: 0.060052  [25600/70451]
loss: 0.022992  [32000/70451]
loss: 0.087218  [38400/70451]
loss: 0.138474  [44800/70451]
loss: 0.131002  [51200/70451]
loss: 0.126159  [57600/70451]
loss: 0.133430  [64000/70451]
loss: 0.048343  [56100/70451]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.135024 

Epoch 30
-------------------------------
loss: 0.079544  [    0/70451]
loss: 0.070388  [ 6400/70451]
loss: 0.060073  [12800/70451]
loss: 0.092593  [19200/70451]
loss: 0.191627  [25600/70451]
loss: 0.078797  [32000/70451]
loss: 0.139871  [38400/70451]
loss: 0.053996  [44800/70451]
loss: 0.133687  [51200/70451]
loss: 0.134255  [57600/70451]
loss: 0.088423  [64000/70451]
loss: 0.042178  [56100/70451]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.147376 

Epoch 31
-------------------------------
loss: 0.156440  [    0/70451]
loss: 0.100626  [ 6400/70451]
loss: 0.110745  [12800/70451]
loss: 0.122711  [19200/70451]
loss: 0.122851  [25600/70451]
loss: 0.097532  [32000/70451]
loss: 0.047076  [38400/70451]
loss: 0.141762  [44800/70451]
loss: 0.169834  [51200/70451]
loss: 0.048506  [57600/70451]
loss: 0.126246  [64000/70451]
loss: 0.229097  [56100/70451]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.163599 

Epoch 32
-------------------------------
loss: 0.164949  [    0/70451]
loss: 0.076049  [ 6400/70451]
loss: 0.139463  [12800/70451]
loss: 0.095638  [19200/70451]
loss: 0.158638  [25600/70451]
loss: 0.044778  [32000/70451]
loss: 0.137121  [38400/70451]
loss: 0.098354  [44800/70451]
loss: 0.087782  [51200/70451]
loss: 0.071648  [57600/70451]
loss: 0.091622  [64000/70451]
loss: 0.125471  [56100/70451]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.142034 

Epoch 33
-------------------------------
loss: 0.199836  [    0/70451]
loss: 0.055820  [ 6400/70451]
loss: 0.092925  [12800/70451]
loss: 0.060418  [19200/70451]
loss: 0.087017  [25600/70451]
loss: 0.079305  [32000/70451]
loss: 0.161678  [38400/70451]
loss: 0.145616  [44800/70451]
loss: 0.173365  [51200/70451]
loss: 0.169303  [57600/70451]
loss: 0.095387  [64000/70451]
loss: 0.149421  [56100/70451]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.128699 

Epoch 34
-------------------------------
loss: 0.239484  [    0/70451]
loss: 0.068407  [ 6400/70451]
loss: 0.195924  [12800/70451]
loss: 0.167106  [19200/70451]
loss: 0.140672  [25600/70451]
loss: 0.055851  [32000/70451]
loss: 0.103139  [38400/70451]
loss: 0.099707  [44800/70451]
loss: 0.062469  [51200/70451]
loss: 0.084370  [57600/70451]
loss: 0.099966  [64000/70451]
loss: 0.095113  [56100/70451]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.136319 

Epoch 35
-------------------------------
loss: 0.122484  [    0/70451]
loss: 0.115473  [ 6400/70451]
loss: 0.063371  [12800/70451]
loss: 0.051449  [19200/70451]
loss: 0.137795  [25600/70451]
loss: 0.092161  [32000/70451]
loss: 0.134896  [38400/70451]
loss: 0.047693  [44800/70451]
loss: 0.118996  [51200/70451]
loss: 0.154920  [57600/70451]
loss: 0.101441  [64000/70451]
loss: 0.228478  [56100/70451]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.128974 

Epoch 36
-------------------------------
loss: 0.154569  [    0/70451]
loss: 0.146970  [ 6400/70451]
loss: 0.108020  [12800/70451]
loss: 0.188346  [19200/70451]
loss: 0.072080  [25600/70451]
loss: 0.229235  [32000/70451]
loss: 0.126893  [38400/70451]
loss: 0.099806  [44800/70451]
loss: 0.114402  [51200/70451]
loss: 0.078803  [57600/70451]
loss: 0.146003  [64000/70451]
loss: 0.054250  [56100/70451]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.130612 

Epoch 37
-------------------------------
loss: 0.069162  [    0/70451]
loss: 0.146743  [ 6400/70451]
loss: 0.057048  [12800/70451]
loss: 0.088429  [19200/70451]
loss: 0.073088  [25600/70451]
loss: 0.143836  [32000/70451]
loss: 0.116667  [38400/70451]
loss: 0.043537  [44800/70451]
loss: 0.068176  [51200/70451]
loss: 0.099835  [57600/70451]
loss: 0.090252  [64000/70451]
loss: 0.206516  [56100/70451]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.129840 

Epoch 38
-------------------------------
loss: 0.132738  [    0/70451]
loss: 0.173062  [ 6400/70451]
loss: 0.153119  [12800/70451]
loss: 0.142788  [19200/70451]
loss: 0.204416  [25600/70451]
loss: 0.102340  [32000/70451]
loss: 0.251451  [38400/70451]
loss: 0.157642  [44800/70451]
loss: 0.035293  [51200/70451]
loss: 0.091114  [57600/70451]
loss: 0.154864  [64000/70451]
loss: 0.199359  [56100/70451]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.124651 

Epoch 39
-------------------------------
loss: 0.101845  [    0/70451]
loss: 0.075833  [ 6400/70451]
loss: 0.108282  [12800/70451]
loss: 0.093317  [19200/70451]
loss: 0.157660  [25600/70451]
loss: 0.058616  [32000/70451]
loss: 0.130225  [38400/70451]
loss: 0.134594  [44800/70451]
loss: 0.045206  [51200/70451]
loss: 0.166534  [57600/70451]
loss: 0.056222  [64000/70451]
loss: 0.063956  [56100/70451]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.131165 

Epoch 40
-------------------------------
loss: 0.098267  [    0/70451]
loss: 0.090810  [ 6400/70451]
loss: 0.136313  [12800/70451]
loss: 0.110611  [19200/70451]
loss: 0.095689  [25600/70451]
loss: 0.109966  [32000/70451]
loss: 0.110893  [38400/70451]
loss: 0.265200  [44800/70451]
loss: 0.146293  [51200/70451]
loss: 0.108808  [57600/70451]
loss: 0.142657  [64000/70451]
loss: 0.101421  [56100/70451]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.130855 

Epoch 41
-------------------------------
loss: 0.081780  [    0/70451]
loss: 0.037073  [ 6400/70451]
loss: 0.047073  [12800/70451]
loss: 0.071065  [19200/70451]
loss: 0.178704  [25600/70451]
loss: 0.079157  [32000/70451]
loss: 0.177485  [38400/70451]
loss: 0.118510  [44800/70451]
loss: 0.059692  [51200/70451]
loss: 0.208317  [57600/70451]
loss: 0.125468  [64000/70451]
loss: 0.154588  [56100/70451]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.128807 

Epoch 42
-------------------------------
loss: 0.172008  [    0/70451]
loss: 0.087273  [ 6400/70451]
loss: 0.135740  [12800/70451]
loss: 0.183844  [19200/70451]
loss: 0.068635  [25600/70451]
loss: 0.189025  [32000/70451]
loss: 0.127851  [38400/70451]
loss: 0.101129  [44800/70451]
loss: 0.067554  [51200/70451]
loss: 0.168566  [57600/70451]
loss: 0.104164  [64000/70451]
loss: 0.061679  [56100/70451]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.126930 

Epoch 43
-------------------------------
loss: 0.100030  [    0/70451]
loss: 0.062270  [ 6400/70451]
loss: 0.171041  [12800/70451]
loss: 0.212582  [19200/70451]
loss: 0.160210  [25600/70451]
loss: 0.109469  [32000/70451]
loss: 0.149838  [38400/70451]
loss: 0.084357  [44800/70451]
loss: 0.118183  [51200/70451]
loss: 0.170556  [57600/70451]
loss: 0.049605  [64000/70451]
loss: 0.068347  [56100/70451]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.137780 

Epoch 44
-------------------------------
loss: 0.136709  [    0/70451]
loss: 0.166805  [ 6400/70451]
loss: 0.053378  [12800/70451]
loss: 0.137738  [19200/70451]
loss: 0.105719  [25600/70451]
loss: 0.163316  [32000/70451]
loss: 0.189103  [38400/70451]
loss: 0.078490  [44800/70451]
loss: 0.146498  [51200/70451]
loss: 0.005597  [19200/71198]
loss: 0.018476  [25600/71198]
loss: 0.034849  [32000/71198]
loss: 0.116633  [38400/71198]
loss: 0.025761  [44800/71198]
loss: 0.053081  [51200/71198]
loss: 0.070078  [57600/71198]
loss: 0.018579  [64000/71198]
loss: 0.056261  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073735 

Epoch 24
-------------------------------
loss: 0.056757  [    0/71198]
loss: 0.079568  [ 6400/71198]
loss: 0.109533  [12800/71198]
loss: 0.005734  [19200/71198]
loss: 0.003953  [25600/71198]
loss: 0.070400  [32000/71198]
loss: 0.013527  [38400/71198]
loss: 0.040190  [44800/71198]
loss: 0.017603  [51200/71198]
loss: 0.041322  [57600/71198]
loss: 0.066731  [64000/71198]
loss: 0.056699  [70400/71198]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.066440 

Epoch 25
-------------------------------
loss: 0.001331  [    0/71198]
loss: 0.073173  [ 6400/71198]
loss: 0.060202  [12800/71198]
loss: 0.026727  [19200/71198]
loss: 0.033899  [25600/71198]
loss: 0.047818  [32000/71198]
loss: 0.102144  [38400/71198]
loss: 0.110379  [44800/71198]
loss: 0.020963  [51200/71198]
loss: 0.045989  [57600/71198]
loss: 0.047161  [64000/71198]
loss: 0.042890  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.071761 

Epoch 26
-------------------------------
loss: 0.026062  [    0/71198]
loss: 0.029472  [ 6400/71198]
loss: 0.048815  [12800/71198]
loss: 0.049521  [19200/71198]
loss: 0.043922  [25600/71198]
loss: 0.042598  [32000/71198]
loss: 0.134217  [38400/71198]
loss: 0.046194  [44800/71198]
loss: 0.022516  [51200/71198]
loss: 0.016101  [57600/71198]
loss: 0.049769  [64000/71198]
loss: 0.010482  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.074304 

Epoch 27
-------------------------------
loss: 0.010607  [    0/71198]
loss: 0.016820  [ 6400/71198]
loss: 0.019821  [12800/71198]
loss: 0.078792  [19200/71198]
loss: 0.029665  [25600/71198]
loss: 0.014772  [32000/71198]
loss: 0.055593  [38400/71198]
loss: 0.031131  [44800/71198]
loss: 0.052639  [51200/71198]
loss: 0.030921  [57600/71198]
loss: 0.018871  [64000/71198]
loss: 0.039169  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.068173 

Epoch 28
-------------------------------
loss: 0.013666  [    0/71198]
loss: 0.047641  [ 6400/71198]
loss: 0.009180  [12800/71198]
loss: 0.040014  [19200/71198]
loss: 0.030236  [25600/71198]
loss: 0.045417  [32000/71198]
loss: 0.037949  [38400/71198]
loss: 0.013724  [44800/71198]
loss: 0.056652  [51200/71198]
loss: 0.038382  [57600/71198]
loss: 0.028639  [64000/71198]
loss: 0.012084  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.073303 

Epoch 29
-------------------------------
loss: 0.028508  [    0/71198]
loss: 0.101840  [ 6400/71198]
loss: 0.039739  [12800/71198]
loss: 0.098810  [19200/71198]
loss: 0.080369  [25600/71198]
loss: 0.004624  [32000/71198]
loss: 0.079239  [38400/71198]
loss: 0.034449  [44800/71198]
loss: 0.037043  [51200/71198]
loss: 0.057298  [57600/71198]
loss: 0.026779  [64000/71198]
loss: 0.018743  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.070440 

Epoch 30
-------------------------------
loss: 0.006472  [    0/71198]
loss: 0.108143  [ 6400/71198]
loss: 0.047875  [12800/71198]
loss: 0.099677  [19200/71198]
loss: 0.018269  [25600/71198]
loss: 0.012189  [32000/71198]
loss: 0.020770  [38400/71198]
loss: 0.037609  [44800/71198]
loss: 0.055356  [51200/71198]
loss: 0.032095  [57600/71198]
loss: 0.043916  [64000/71198]
loss: 0.064052  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069394 

Epoch 31
-------------------------------
loss: 0.028474  [    0/71198]
loss: 0.026483  [ 6400/71198]
loss: 0.054270  [12800/71198]
loss: 0.030654  [19200/71198]
loss: 0.016579  [25600/71198]
loss: 0.041837  [32000/71198]
loss: 0.009359  [38400/71198]
loss: 0.031481  [44800/71198]
loss: 0.084527  [51200/71198]
loss: 0.019764  [57600/71198]
loss: 0.046675  [64000/71198]
loss: 0.026245  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.070868 

Epoch 32
-------------------------------
loss: 0.072017  [    0/71198]
loss: 0.029268  [ 6400/71198]
loss: 0.009287  [12800/71198]
loss: 0.048636  [19200/71198]
loss: 0.096374  [25600/71198]
loss: 0.037464  [32000/71198]
loss: 0.028544  [38400/71198]
loss: 0.017353  [44800/71198]
loss: 0.113857  [51200/71198]
loss: 0.070442  [57600/71198]
loss: 0.015669  [64000/71198]
loss: 0.024902  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069227 

Epoch 33
-------------------------------
loss: 0.029151  [    0/71198]
loss: 0.045058  [ 6400/71198]
loss: 0.023597  [12800/71198]
loss: 0.008435  [19200/71198]
loss: 0.108998  [25600/71198]
loss: 0.056584  [32000/71198]
loss: 0.145728  [38400/71198]
loss: 0.029398  [44800/71198]
loss: 0.151634  [51200/71198]
loss: 0.017349  [57600/71198]
loss: 0.093515  [64000/71198]
loss: 0.028044  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070203 

Epoch 34
-------------------------------
loss: 0.025936  [    0/71198]
loss: 0.031013  [ 6400/71198]
loss: 0.138239  [12800/71198]
loss: 0.010591  [19200/71198]
loss: 0.051322  [25600/71198]
loss: 0.012858  [32000/71198]
loss: 0.019336  [38400/71198]
loss: 0.021018  [44800/71198]
loss: 0.042989  [51200/71198]
loss: 0.080263  [57600/71198]
loss: 0.113234  [64000/71198]
loss: 0.041231  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.071429 

Epoch 35
-------------------------------
loss: 0.041101  [    0/71198]
loss: 0.037854  [ 6400/71198]
loss: 0.115831  [12800/71198]
loss: 0.047427  [19200/71198]
loss: 0.052499  [25600/71198]
loss: 0.046983  [32000/71198]
loss: 0.009788  [38400/71198]
loss: 0.103250  [44800/71198]
loss: 0.036023  [51200/71198]
loss: 0.025537  [57600/71198]
loss: 0.046382  [64000/71198]
loss: 0.025751  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071846 

Epoch 36
-------------------------------
loss: 0.015563  [    0/71198]
loss: 0.041047  [ 6400/71198]
loss: 0.051843  [12800/71198]
loss: 0.014158  [19200/71198]
loss: 0.020651  [25600/71198]
loss: 0.042152  [32000/71198]
loss: 0.012057  [38400/71198]
loss: 0.030296  [44800/71198]
loss: 0.011143  [51200/71198]
loss: 0.046433  [57600/71198]
loss: 0.029041  [64000/71198]
loss: 0.010139  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069298 

Epoch 37
-------------------------------
loss: 0.052367  [    0/71198]
loss: 0.051325  [ 6400/71198]
loss: 0.020186  [12800/71198]
loss: 0.021960  [19200/71198]
loss: 0.010815  [25600/71198]
loss: 0.061646  [32000/71198]
loss: 0.007414  [38400/71198]
loss: 0.027504  [44800/71198]
loss: 0.025157  [51200/71198]
loss: 0.142680  [57600/71198]
loss: 0.060298  [64000/71198]
loss: 0.040732  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.079938 

Epoch 38
-------------------------------
loss: 0.091643  [    0/71198]
loss: 0.138568  [ 6400/71198]
loss: 0.015043  [12800/71198]
loss: 0.011881  [19200/71198]
loss: 0.077114  [25600/71198]
loss: 0.061473  [32000/71198]
loss: 0.014692  [38400/71198]
loss: 0.024437  [44800/71198]
loss: 0.070938  [51200/71198]
loss: 0.026715  [57600/71198]
loss: 0.033731  [64000/71198]
loss: 0.017332  [70400/71198]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.079521 

Epoch 39
-------------------------------
loss: 0.085431  [    0/71198]
loss: 0.029095  [ 6400/71198]
loss: 0.014518  [12800/71198]
loss: 0.119747  [19200/71198]
loss: 0.086958  [25600/71198]
loss: 0.090541  [32000/71198]
loss: 0.016448  [38400/71198]
loss: 0.038724  [44800/71198]
loss: 0.022767  [51200/71198]
loss: 0.022027  [57600/71198]
loss: 0.086982  [64000/71198]
loss: 0.041347  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076654 

Epoch 40
-------------------------------
loss: 0.220015  [    0/71198]
loss: 0.020061  [ 6400/71198]
loss: 0.057286  [12800/71198]
loss: 0.003962  [19200/71198]
loss: 0.099989  [25600/71198]
loss: 0.035578  [32000/71198]
loss: 0.068575  [38400/71198]
loss: 0.031809  [44800/71198]
loss: 0.006769  [51200/71198]
loss: 0.062349  [57600/71198]
loss: 0.026263  [64000/71198]
loss: 0.077189  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.077078 

Epoch 41
-------------------------------
loss: 0.025746  [    0/71198]
loss: 0.055264  [ 6400/71198]
loss: 0.022712  [12800/71198]
loss: 0.046917  [19200/71198]
loss: 0.113979  [51200/71333]
loss: 0.054689  [57600/71333]
loss: 0.004564  [64000/71333]
loss: 0.064878  [70400/71333]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.155193 

Epoch 27
-------------------------------
loss: 0.032534  [    0/71333]
loss: 1.630093  [ 6400/71333]
loss: 0.011770  [12800/71333]
loss: 0.027675  [19200/71333]
loss: 0.029807  [25600/71333]
loss: 0.079769  [32000/71333]
loss: 0.057031  [38400/71333]
loss: 0.021410  [44800/71333]
loss: 0.074583  [51200/71333]
loss: 0.093261  [57600/71333]
loss: 0.055070  [64000/71333]
loss: 0.052516  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.145899 

Epoch 28
-------------------------------
loss: 0.070981  [    0/71333]
loss: 0.144616  [ 6400/71333]
loss: 0.040191  [12800/71333]
loss: 0.016935  [19200/71333]
loss: 0.027064  [25600/71333]
loss: 0.029959  [32000/71333]
loss: 0.040765  [38400/71333]
loss: 0.009396  [44800/71333]
loss: 0.071669  [51200/71333]
loss: 0.074562  [57600/71333]
loss: 0.077060  [64000/71333]
loss: 0.179235  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.145535 

Epoch 29
-------------------------------
loss: 0.065607  [    0/71333]
loss: 0.160796  [ 6400/71333]
loss: 0.027695  [12800/71333]
loss: 0.093976  [19200/71333]
loss: 0.033200  [25600/71333]
loss: 0.005258  [32000/71333]
loss: 0.040274  [38400/71333]
loss: 0.076691  [44800/71333]
loss: 0.045643  [51200/71333]
loss: 0.127963  [57600/71333]
loss: 0.067411  [64000/71333]
loss: 0.013468  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.150366 

Epoch 30
-------------------------------
loss: 0.055894  [    0/71333]
loss: 0.053161  [ 6400/71333]
loss: 0.028617  [12800/71333]
loss: 0.031695  [19200/71333]
loss: 0.054856  [25600/71333]
loss: 0.102981  [32000/71333]
loss: 0.005698  [38400/71333]
loss: 0.079297  [44800/71333]
loss: 0.197085  [51200/71333]
loss: 0.230706  [57600/71333]
loss: 0.107419  [64000/71333]
loss: 0.028266  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.142953 

Epoch 31
-------------------------------
loss: 0.008500  [    0/71333]
loss: 0.025336  [ 6400/71333]
loss: 0.114480  [12800/71333]
loss: 0.112667  [19200/71333]
loss: 0.040433  [25600/71333]
loss: 1.654055  [32000/71333]
loss: 0.145603  [38400/71333]
loss: 0.023640  [44800/71333]
loss: 0.023933  [51200/71333]
loss: 0.108846  [57600/71333]
loss: 0.089464  [64000/71333]
loss: 0.089065  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.144066 

Epoch 32
-------------------------------
loss: 0.042810  [    0/71333]
loss: 0.067940  [ 6400/71333]
loss: 0.050746  [12800/71333]
loss: 0.061253  [19200/71333]
loss: 0.048196  [25600/71333]
loss: 0.068529  [32000/71333]
loss: 0.036894  [38400/71333]
loss: 0.039467  [44800/71333]
loss: 0.015641  [51200/71333]
loss: 0.069775  [57600/71333]
loss: 0.116232  [64000/71333]
loss: 1.621791  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.148615 

Epoch 33
-------------------------------
loss: 0.034162  [    0/71333]
loss: 0.078099  [ 6400/71333]
loss: 0.009155  [12800/71333]
loss: 0.015374  [19200/71333]
loss: 0.062516  [25600/71333]
loss: 0.049847  [32000/71333]
loss: 0.026101  [38400/71333]
loss: 0.031722  [44800/71333]
loss: 0.030982  [51200/71333]
loss: 0.012111  [57600/71333]
loss: 0.031515  [64000/71333]
loss: 0.038399  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.143455 

Epoch 34
-------------------------------
loss: 0.044814  [    0/71333]
loss: 0.014422  [ 6400/71333]
loss: 0.071009  [12800/71333]
loss: 0.010493  [19200/71333]
loss: 0.026060  [25600/71333]
loss: 0.051432  [32000/71333]
loss: 0.094960  [38400/71333]
loss: 0.009600  [44800/71333]
loss: 0.052705  [51200/71333]
loss: 0.007506  [57600/71333]
loss: 0.019034  [64000/71333]
loss: 0.065142  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.148752 

Epoch 35
-------------------------------
loss: 1.601339  [    0/71333]
loss: 0.025109  [ 6400/71333]
loss: 0.041129  [12800/71333]
loss: 0.271324  [19200/71333]
loss: 0.070349  [25600/71333]
loss: 0.038271  [32000/71333]
loss: 0.019383  [38400/71333]
loss: 0.073792  [44800/71333]
loss: 0.044259  [51200/71333]
loss: 0.115269  [57600/71333]
loss: 0.056754  [64000/71333]
loss: 0.066645  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.147490 

Epoch 36
-------------------------------
loss: 0.082790  [    0/71333]
loss: 0.119063  [ 6400/71333]
loss: 0.096393  [12800/71333]
loss: 0.016121  [19200/71333]
loss: 0.047666  [25600/71333]
loss: 0.051532  [32000/71333]
loss: 0.066795  [38400/71333]
loss: 0.113920  [44800/71333]
loss: 0.046179  [51200/71333]
loss: 0.048933  [57600/71333]
loss: 0.131527  [64000/71333]
loss: 0.045654  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.148429 

Epoch 37
-------------------------------
loss: 0.128545  [    0/71333]
loss: 0.006579  [ 6400/71333]
loss: 0.098101  [12800/71333]
loss: 0.059794  [19200/71333]
loss: 0.039147  [25600/71333]
loss: 0.017919  [32000/71333]
loss: 0.031350  [38400/71333]
loss: 0.036017  [44800/71333]
loss: 0.092342  [51200/71333]
loss: 0.136385  [57600/71333]
loss: 0.100643  [64000/71333]
loss: 0.046949  [70400/71333]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.145444 

Epoch 38
-------------------------------
loss: 0.072829  [    0/71333]
loss: 0.000698  [ 6400/71333]
loss: 0.014659  [12800/71333]
loss: 0.071612  [19200/71333]
loss: 0.055175  [25600/71333]
loss: 0.035547  [32000/71333]
loss: 0.060331  [38400/71333]
loss: 0.048774  [44800/71333]
loss: 0.135167  [51200/71333]
loss: 0.017489  [57600/71333]
loss: 0.121369  [64000/71333]
loss: 0.024850  [70400/71333]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.155864 

Epoch 39
-------------------------------
loss: 0.084017  [    0/71333]
loss: 0.023579  [ 6400/71333]
loss: 0.054960  [12800/71333]
loss: 0.081636  [19200/71333]
loss: 0.078411  [25600/71333]
loss: 0.155636  [32000/71333]
loss: 0.090691  [38400/71333]
loss: 0.054559  [44800/71333]
loss: 0.065412  [51200/71333]
loss: 0.048950  [57600/71333]
loss: 0.062328  [64000/71333]
loss: 0.045245  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.151164 

Epoch 40
-------------------------------
loss: 0.045228  [    0/71333]
loss: 0.050709  [ 6400/71333]
loss: 0.107913  [12800/71333]
loss: 0.041129  [19200/71333]
loss: 0.127125  [25600/71333]
loss: 0.034677  [32000/71333]
loss: 0.065098  [38400/71333]
loss: 1.611286  [44800/71333]
loss: 0.041799  [51200/71333]
loss: 0.022700  [57600/71333]
loss: 0.038068  [64000/71333]
loss: 0.068245  [70400/71333]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.148080 

Epoch 41
-------------------------------
loss: 0.043440  [    0/71333]
loss: 0.095231  [ 6400/71333]
loss: 0.108905  [12800/71333]
loss: 0.102895  [19200/71333]
loss: 0.003280  [25600/71333]
loss: 0.150959  [32000/71333]
loss: 0.010267  [38400/71333]
loss: 0.026937  [44800/71333]
loss: 0.032641  [51200/71333]
loss: 0.035222  [57600/71333]
loss: 0.041756  [64000/71333]
loss: 0.061193  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.145892 

Epoch 42
-------------------------------
loss: 0.038375  [    0/71333]
loss: 0.024964  [ 6400/71333]
loss: 0.130468  [12800/71333]
loss: 0.062027  [19200/71333]
loss: 0.108029  [25600/71333]
loss: 0.049321  [32000/71333]
loss: 0.193621  [38400/71333]
loss: 0.047945  [44800/71333]
loss: 0.136456  [51200/71333]
loss: 0.030186  [57600/71333]
loss: 0.113372  [64000/71333]
loss: 0.060329  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.151410 

Epoch 43
-------------------------------
loss: 0.094157  [    0/71333]
loss: 0.013444  [ 6400/71333]
loss: 0.010414  [12800/71333]
loss: 0.061538  [19200/71333]
loss: 0.086947  [25600/71333]
loss: 0.005036  [32000/71333]
loss: 0.045463  [38400/71333]
loss: 0.028992  [44800/71333]
loss: 0.088040  [51200/71333]
loss: 0.085459  [57600/71333]
loss: 0.044172  [64000/71333]
loss: 0.022047  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.155848 

Epoch 44
-------------------------------
loss: 0.028891  [    0/71333]
loss: 0.059919  [ 6400/71333]
loss: 0.041640  [12800/71333]
loss: 0.031427  [19200/71333]
loss: 0.143225  [25600/71333]
loss: 0.070805  [32000/71333]
loss: 0.047693  [38400/71333]
loss: 0.066023  [44800/71333]
loss: 0.117316  [51200/71333]
loss: 0.055664  [51200/70787]
loss: 0.069870  [57600/70787]
loss: 0.057349  [64000/70787]
loss: 0.094921  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085257 

Epoch 27
-------------------------------
loss: 0.023824  [    0/70787]
loss: 0.067454  [ 6400/70787]
loss: 0.024691  [12800/70787]
loss: 0.067957  [19200/70787]
loss: 0.018420  [25600/70787]
loss: 0.030651  [32000/70787]
loss: 0.084347  [38400/70787]
loss: 0.062711  [44800/70787]
loss: 0.106334  [51200/70787]
loss: 0.050022  [57600/70787]
loss: 0.039373  [64000/70787]
loss: 0.060839  [70400/70787]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.109367 

Epoch 28
-------------------------------
loss: 0.056582  [    0/70787]
loss: 0.008191  [ 6400/70787]
loss: 0.048478  [12800/70787]
loss: 0.055006  [19200/70787]
loss: 0.008049  [25600/70787]
loss: 0.151548  [32000/70787]
loss: 0.049248  [38400/70787]
loss: 0.025127  [44800/70787]
loss: 0.095868  [51200/70787]
loss: 0.149081  [57600/70787]
loss: 0.052214  [64000/70787]
loss: 0.025734  [70400/70787]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.085269 

Epoch 29
-------------------------------
loss: 0.042547  [    0/70787]
loss: 0.045781  [ 6400/70787]
loss: 0.025874  [12800/70787]
loss: 0.093287  [19200/70787]
loss: 0.118789  [25600/70787]
loss: 0.071382  [32000/70787]
loss: 0.011690  [38400/70787]
loss: 0.088633  [44800/70787]
loss: 0.067492  [51200/70787]
loss: 0.063489  [57600/70787]
loss: 0.030730  [64000/70787]
loss: 0.042054  [70400/70787]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.091624 

Epoch 30
-------------------------------
loss: 0.055194  [    0/70787]
loss: 0.011276  [ 6400/70787]
loss: 0.023604  [12800/70787]
loss: 0.098782  [19200/70787]
loss: 0.026597  [25600/70787]
loss: 0.077902  [32000/70787]
loss: 0.051702  [38400/70787]
loss: 0.055096  [44800/70787]
loss: 0.068230  [51200/70787]
loss: 0.012080  [57600/70787]
loss: 0.158683  [64000/70787]
loss: 0.188972  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085603 

Epoch 31
-------------------------------
loss: 0.043836  [    0/70787]
loss: 0.020702  [ 6400/70787]
loss: 0.086148  [12800/70787]
loss: 0.067555  [19200/70787]
loss: 0.065244  [25600/70787]
loss: 0.098313  [32000/70787]
loss: 0.051009  [38400/70787]
loss: 0.060791  [44800/70787]
loss: 0.047479  [51200/70787]
loss: 0.027819  [57600/70787]
loss: 0.116324  [64000/70787]
loss: 0.048325  [70400/70787]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.096134 

Epoch 32
-------------------------------
loss: 0.010488  [    0/70787]
loss: 0.063135  [ 6400/70787]
loss: 0.062387  [12800/70787]
loss: 0.045015  [19200/70787]
loss: 0.006260  [25600/70787]
loss: 0.135044  [32000/70787]
loss: 0.060558  [38400/70787]
loss: 0.076503  [44800/70787]
loss: 0.055929  [51200/70787]
loss: 0.105979  [57600/70787]
loss: 0.091265  [64000/70787]
loss: 0.054220  [70400/70787]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.094045 

Epoch 33
-------------------------------
loss: 0.010294  [    0/70787]
loss: 0.009390  [ 6400/70787]
loss: 0.085547  [12800/70787]
loss: 0.056168  [19200/70787]
loss: 0.025638  [25600/70787]
loss: 0.013082  [32000/70787]
loss: 0.042686  [38400/70787]
loss: 0.039495  [44800/70787]
loss: 0.031535  [51200/70787]
loss: 0.013023  [57600/70787]
loss: 0.039337  [64000/70787]
loss: 0.066293  [70400/70787]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.104571 

Epoch 34
-------------------------------
loss: 0.047963  [    0/70787]
loss: 0.014711  [ 6400/70787]
loss: 0.045043  [12800/70787]
loss: 0.031372  [19200/70787]
loss: 0.069418  [25600/70787]
loss: 0.086298  [32000/70787]
loss: 0.020098  [38400/70787]
loss: 0.036970  [44800/70787]
loss: 0.040174  [51200/70787]
loss: 0.072396  [57600/70787]
loss: 0.072647  [64000/70787]
loss: 0.173271  [70400/70787]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.089647 

Epoch 35
-------------------------------
loss: 0.090387  [    0/70787]
loss: 0.097070  [ 6400/70787]
loss: 0.027120  [12800/70787]
loss: 0.031099  [19200/70787]
loss: 0.121740  [25600/70787]
loss: 0.044710  [32000/70787]
loss: 0.129663  [38400/70787]
loss: 0.016939  [44800/70787]
loss: 0.129272  [51200/70787]
loss: 0.081454  [57600/70787]
loss: 0.095975  [64000/70787]
loss: 0.060835  [70400/70787]
Test Error: 
 Accuracy: 88.9%, Avg loss: 0.481032 

Epoch 36
-------------------------------
loss: 0.415580  [    0/70787]
loss: 0.117345  [ 6400/70787]
loss: 0.036103  [12800/70787]
loss: 0.048555  [19200/70787]
loss: 0.016740  [25600/70787]
loss: 0.072344  [32000/70787]
loss: 0.034933  [38400/70787]
loss: 0.056791  [44800/70787]
loss: 0.060947  [51200/70787]
loss: 0.024060  [57600/70787]
loss: 0.126186  [64000/70787]
loss: 0.051645  [70400/70787]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.090064 

Epoch 37
-------------------------------
loss: 0.054252  [    0/70787]
loss: 0.069900  [ 6400/70787]
loss: 0.035407  [12800/70787]
loss: 0.023834  [19200/70787]
loss: 0.029562  [25600/70787]
loss: 0.031441  [32000/70787]
loss: 0.036655  [38400/70787]
loss: 0.026307  [44800/70787]
loss: 0.063815  [51200/70787]
loss: 0.086075  [57600/70787]
loss: 0.137681  [64000/70787]
loss: 0.048230  [70400/70787]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.088156 

Epoch 38
-------------------------------
loss: 0.005712  [    0/70787]
loss: 0.039870  [ 6400/70787]
loss: 0.050994  [12800/70787]
loss: 0.061100  [19200/70787]
loss: 0.084368  [25600/70787]
loss: 0.011012  [32000/70787]
loss: 0.023003  [38400/70787]
loss: 0.065474  [44800/70787]
loss: 0.040715  [51200/70787]
loss: 0.090962  [57600/70787]
loss: 0.056481  [64000/70787]
loss: 0.087657  [70400/70787]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.253613 

Epoch 39
-------------------------------
loss: 0.152010  [    0/70787]
loss: 0.019139  [ 6400/70787]
loss: 0.022722  [12800/70787]
loss: 0.032901  [19200/70787]
loss: 0.028176  [25600/70787]
loss: 0.031025  [32000/70787]
loss: 0.100053  [38400/70787]
loss: 0.077408  [44800/70787]
loss: 0.009664  [51200/70787]
loss: 0.121226  [57600/70787]
loss: 0.066476  [64000/70787]
loss: 0.043773  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083911 

Epoch 40
-------------------------------
loss: 0.057853  [    0/70787]
loss: 0.028793  [ 6400/70787]
loss: 0.079745  [12800/70787]
loss: 0.016625  [19200/70787]
loss: 0.028137  [25600/70787]
loss: 0.008003  [32000/70787]
loss: 0.023385  [38400/70787]
loss: 0.023351  [44800/70787]
loss: 0.144248  [51200/70787]
loss: 0.033373  [57600/70787]
loss: 0.020286  [64000/70787]
loss: 0.183528  [70400/70787]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.115085 

Epoch 41
-------------------------------
loss: 0.163062  [    0/70787]
loss: 0.078489  [ 6400/70787]
loss: 0.054479  [12800/70787]
loss: 0.077003  [19200/70787]
loss: 0.032516  [25600/70787]
loss: 0.048259  [32000/70787]
loss: 0.099018  [38400/70787]
loss: 0.076204  [44800/70787]
loss: 0.077114  [51200/70787]
loss: 0.017806  [57600/70787]
loss: 0.030790  [64000/70787]
loss: 0.051535  [70400/70787]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.139277 

Epoch 42
-------------------------------
loss: 0.202983  [    0/70787]
loss: 0.023747  [ 6400/70787]
loss: 0.041920  [12800/70787]
loss: 0.011634  [19200/70787]
loss: 0.025435  [25600/70787]
loss: 0.071262  [32000/70787]
loss: 0.004169  [38400/70787]
loss: 0.013772  [44800/70787]
loss: 0.062586  [51200/70787]
loss: 0.039428  [57600/70787]
loss: 0.023291  [64000/70787]
loss: 0.043721  [70400/70787]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.091376 

Epoch 43
-------------------------------
loss: 0.148519  [    0/70787]
loss: 0.102445  [ 6400/70787]
loss: 0.059273  [12800/70787]
loss: 0.015216  [19200/70787]
loss: 0.033866  [25600/70787]
loss: 0.032105  [32000/70787]
loss: 0.047276  [38400/70787]
loss: 0.031644  [44800/70787]
loss: 0.030131  [51200/70787]
loss: 0.043196  [57600/70787]
loss: 0.007679  [64000/70787]
loss: 0.014940  [70400/70787]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.099055 

Epoch 44
-------------------------------
loss: 0.095289  [    0/70787]
loss: 0.013810  [ 6400/70787]
loss: 0.052017  [12800/70787]
loss: 0.099343  [19200/70787]
loss: 0.048666  [25600/70787]
loss: 0.014920  [32000/70787]
loss: 0.079799  [38400/70787]
loss: 0.036560  [44800/70787]
loss: 0.055370  [51200/70787]
2022/09/20 14:05:22 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:05:31 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084218 

Epoch 25
-------------------------------
loss: 0.062307  [    0/70196]
loss: 0.059792  [ 6400/70196]
loss: 0.087343  [12800/70196]
loss: 0.030959  [19200/70196]
loss: 0.050984  [25600/70196]
loss: 0.052280  [32000/70196]
loss: 0.062606  [38400/70196]
loss: 0.042965  [44800/70196]
loss: 0.054725  [51200/70196]
loss: 0.061472  [57600/70196]
loss: 0.042669  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.085179 

Epoch 26
-------------------------------
loss: 0.118866  [    0/70196]
loss: 0.025655  [ 6400/70196]
loss: 0.014650  [12800/70196]
loss: 0.153880  [19200/70196]
loss: 0.081947  [25600/70196]
loss: 0.131219  [32000/70196]
loss: 0.060290  [38400/70196]
loss: 0.059049  [44800/70196]
loss: 0.027116  [51200/70196]
loss: 0.104318  [57600/70196]
loss: 0.024444  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.086000 

Epoch 27
-------------------------------
loss: 0.105028  [    0/70196]
loss: 0.028878  [ 6400/70196]
loss: 0.028602  [12800/70196]
loss: 0.098796  [19200/70196]
loss: 0.115973  [25600/70196]
loss: 0.037760  [32000/70196]
loss: 0.143132  [38400/70196]
loss: 0.074793  [44800/70196]
loss: 0.036110  [51200/70196]
loss: 0.030554  [57600/70196]
loss: 0.054725  [64000/70196]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.119839 

Epoch 28
-------------------------------
loss: 0.073040  [    0/70196]
loss: 0.149298  [ 6400/70196]
loss: 0.022236  [12800/70196]
loss: 0.037395  [19200/70196]
loss: 0.053481  [25600/70196]
loss: 0.047445  [32000/70196]
loss: 0.030156  [38400/70196]
loss: 0.033921  [44800/70196]
loss: 0.010684  [51200/70196]
loss: 0.068944  [57600/70196]
loss: 0.034338  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.084814 

Epoch 29
-------------------------------
loss: 0.043794  [    0/70196]
loss: 0.023710  [ 6400/70196]
loss: 0.017013  [12800/70196]
loss: 0.066740  [19200/70196]
loss: 0.032982  [25600/70196]
loss: 0.043261  [32000/70196]
loss: 0.092477  [38400/70196]
loss: 0.076874  [44800/70196]
loss: 0.009883  [51200/70196]
loss: 0.117975  [57600/70196]
loss: 0.078556  [64000/70196]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088981 

Epoch 30
-------------------------------
loss: 0.159566  [    0/70196]
loss: 0.105824  [ 6400/70196]
loss: 0.046549  [12800/70196]
loss: 0.046317  [19200/70196]
loss: 0.047500  [25600/70196]
loss: 0.092490  [32000/70196]
loss: 0.050642  [38400/70196]
loss: 0.088250  [44800/70196]
loss: 0.043188  [51200/70196]
loss: 0.117034  [57600/70196]
loss: 0.044814  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.087059 

Epoch 31
-------------------------------
loss: 0.043330  [    0/70196]
loss: 0.121812  [ 6400/70196]
loss: 0.052031  [12800/70196]
loss: 0.067382  [19200/70196]
loss: 0.011299  [25600/70196]
loss: 0.015445  [32000/70196]
loss: 0.103210  [38400/70196]
loss: 0.016948  [44800/70196]
loss: 0.138577  [51200/70196]
loss: 0.142605  [57600/70196]
loss: 0.082812  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.090638 

Epoch 32
-------------------------------
loss: 0.077357  [    0/70196]
loss: 0.035898  [ 6400/70196]
loss: 0.057250  [12800/70196]
loss: 0.122890  [19200/70196]
loss: 0.058165  [25600/70196]
loss: 0.082404  [32000/70196]
loss: 0.167127  [38400/70196]
loss: 0.073118  [44800/70196]
loss: 0.043719  [51200/70196]
loss: 0.076271  [57600/70196]
loss: 0.020833  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.086340 

Epoch 33
-------------------------------
loss: 0.043917  [    0/70196]
loss: 0.144015  [ 6400/70196]
loss: 0.035968  [12800/70196]
loss: 0.049516  [19200/70196]
loss: 0.041286  [25600/70196]
loss: 0.012274  [32000/70196]
loss: 0.047955  [38400/70196]
loss: 0.038232  [44800/70196]
loss: 0.047248  [51200/70196]
loss: 0.024780  [57600/70196]
loss: 0.071822  [64000/70196]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.091221 

Epoch 34
-------------------------------
loss: 0.059899  [    0/70196]
loss: 0.015704  [ 6400/70196]
loss: 0.052469  [12800/70196]
loss: 0.056684  [19200/70196]
loss: 0.042165  [25600/70196]
loss: 0.099686  [32000/70196]
loss: 0.063231  [38400/70196]
loss: 0.045645  [44800/70196]
loss: 0.026095  [51200/70196]
loss: 0.035160  [57600/70196]
loss: 0.030369  [64000/70196]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.095722 

Epoch 35
-------------------------------
loss: 0.064138  [    0/70196]
loss: 0.048855  [ 6400/70196]
loss: 0.114066  [12800/70196]
loss: 0.091809  [19200/70196]
loss: 0.158412  [25600/70196]
loss: 0.082836  [32000/70196]
loss: 0.058875  [38400/70196]
loss: 0.059891  [44800/70196]
loss: 0.085416  [51200/70196]
loss: 0.096950  [57600/70196]
loss: 0.005519  [64000/70196]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.091973 

Epoch 36
-------------------------------
loss: 0.071778  [    0/70196]
loss: 0.014519  [ 6400/70196]
loss: 0.161857  [12800/70196]
loss: 0.091544  [19200/70196]
loss: 0.071770  [25600/70196]
loss: 0.014246  [32000/70196]
loss: 0.048170  [38400/70196]
loss: 0.057040  [44800/70196]
loss: 0.017423  [51200/70196]
loss: 0.032023  [57600/70196]
loss: 0.038184  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.085105 

Epoch 37
-------------------------------
loss: 0.050567  [    0/70196]
loss: 0.079641  [ 6400/70196]
loss: 0.176685  [12800/70196]
loss: 0.019515  [19200/70196]
loss: 0.005380  [25600/70196]
loss: 0.132033  [32000/70196]
loss: 0.070287  [38400/70196]
loss: 0.099891  [44800/70196]
loss: 0.069120  [51200/70196]
loss: 0.108587  [57600/70196]
loss: 0.111956  [64000/70196]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085473 

Epoch 38
-------------------------------
loss: 0.153247  [    0/70196]
loss: 0.036800  [ 6400/70196]
loss: 0.055680  [12800/70196]
loss: 0.116850  [19200/70196]
loss: 0.065449  [25600/70196]
loss: 0.040782  [32000/70196]
loss: 0.137281  [38400/70196]
loss: 0.146393  [44800/70196]
loss: 0.037819  [51200/70196]
loss: 0.062785  [57600/70196]
loss: 0.034027  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.085584 

Epoch 39
-------------------------------
loss: 0.018369  [    0/70196]
loss: 0.087962  [ 6400/70196]
loss: 0.061507  [12800/70196]
loss: 0.173276  [19200/70196]
loss: 0.081076  [25600/70196]
loss: 0.026859  [32000/70196]
loss: 0.028121  [38400/70196]
loss: 0.213912  [44800/70196]
loss: 0.062496  [51200/70196]
loss: 0.047799  [57600/70196]
loss: 0.007775  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.088575 

Epoch 40
-------------------------------
loss: 0.136639  [    0/70196]
loss: 0.012399  [ 6400/70196]
loss: 0.035188  [12800/70196]
loss: 0.058581  [19200/70196]
loss: 0.027445  [25600/70196]
loss: 0.152885  [32000/70196]
loss: 0.044421  [38400/70196]
loss: 0.032219  [44800/70196]
loss: 0.096555  [51200/70196]
loss: 0.154147  [57600/70196]
loss: 0.038607  [64000/70196]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.105681 

Epoch 41
-------------------------------
loss: 0.038383  [    0/70196]
loss: 0.042483  [ 6400/70196]
loss: 0.057625  [12800/70196]
loss: 0.054439  [19200/70196]
loss: 0.046371  [25600/70196]
loss: 0.080883  [32000/70196]
loss: 0.097635  [38400/70196]
loss: 0.039245  [44800/70196]
loss: 0.054011  [51200/70196]
loss: 0.104048  [57600/70196]
loss: 0.156710  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.090133 

Epoch 42
-------------------------------
loss: 0.024748  [    0/70196]
loss: 0.109216  [ 6400/70196]
loss: 0.065484  [12800/70196]
loss: 0.082478  [19200/70196]
loss: 0.019091  [25600/70196]
loss: 0.128803  [32000/70196]
loss: 0.126343  [38400/70196]
loss: 0.034875  [44800/70196]
loss: 0.016443  [51200/70196]
loss: 0.024538  [57600/70196]
loss: 0.060279  [64000/70196]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.094126 

Epoch 43
-------------------------------
loss: 0.019588  [    0/70196]
loss: 0.032832  [ 6400/70196]
loss: 0.055022  [12800/70196]
loss: 0.038242  [19200/70196]
loss: 0.027620  [25600/70196]
loss: 0.066016  [32000/70196]
loss: 0.104927  [38400/70196]
loss: 0.019691  [44800/70196]
loss: 0.054718  [51200/70196]
loss: 0.054754  [57600/70196]
loss: 0.058261  [64000/70196]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.101175 

Epoch 44
-------------------------------
loss: 0.103274  [    0/70196]
loss: 0.125563  [ 6400/70196]
loss: 0.122754  [32000/69874]
loss: 0.076335  [38400/69874]
loss: 0.158013  [44800/69874]
loss: 0.117243  [51200/69874]
loss: 0.122787  [57600/69874]
loss: 0.192081  [64000/69874]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.156371 

Epoch 29
-------------------------------
loss: 0.105711  [    0/69874]
loss: 0.236782  [ 6400/69874]
loss: 0.087118  [12800/69874]
loss: 0.093922  [19200/69874]
loss: 0.176372  [25600/69874]
loss: 0.210156  [32000/69874]
loss: 0.147913  [38400/69874]
loss: 0.099795  [44800/69874]
loss: 0.128012  [51200/69874]
loss: 0.119776  [57600/69874]
loss: 0.145009  [64000/69874]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.151319 

Epoch 30
-------------------------------
loss: 0.144088  [    0/69874]
loss: 0.090821  [ 6400/69874]
loss: 0.075490  [12800/69874]
loss: 0.073887  [19200/69874]
loss: 0.108931  [25600/69874]
loss: 0.104838  [32000/69874]
loss: 0.198773  [38400/69874]
loss: 0.262291  [44800/69874]
loss: 0.190729  [51200/69874]
loss: 0.077694  [57600/69874]
loss: 0.148455  [64000/69874]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.150271 

Epoch 31
-------------------------------
loss: 0.172513  [    0/69874]
loss: 0.066956  [ 6400/69874]
loss: 0.148250  [12800/69874]
loss: 0.203752  [19200/69874]
loss: 0.106562  [25600/69874]
loss: 0.053951  [32000/69874]
loss: 0.119276  [38400/69874]
loss: 0.142289  [44800/69874]
loss: 0.197103  [51200/69874]
loss: 0.174521  [57600/69874]
loss: 0.075303  [64000/69874]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.147262 

Epoch 32
-------------------------------
loss: 0.035788  [    0/69874]
loss: 0.121655  [ 6400/69874]
loss: 0.254735  [12800/69874]
loss: 0.126294  [19200/69874]
loss: 0.199485  [25600/69874]
loss: 0.055494  [32000/69874]
loss: 0.089374  [38400/69874]
loss: 0.111098  [44800/69874]
loss: 0.208794  [51200/69874]
loss: 0.112961  [57600/69874]
loss: 0.094371  [64000/69874]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.162206 

Epoch 33
-------------------------------
loss: 0.041613  [    0/69874]
loss: 0.095388  [ 6400/69874]
loss: 0.135136  [12800/69874]
loss: 0.141666  [19200/69874]
loss: 0.168204  [25600/69874]
loss: 0.083993  [32000/69874]
loss: 0.104054  [38400/69874]
loss: 0.056135  [44800/69874]
loss: 0.182617  [51200/69874]
loss: 0.160247  [57600/69874]
loss: 0.120132  [64000/69874]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.157294 

Epoch 34
-------------------------------
loss: 0.106123  [    0/69874]
loss: 0.117893  [ 6400/69874]
loss: 0.194610  [12800/69874]
loss: 0.130168  [19200/69874]
loss: 0.114547  [25600/69874]
loss: 0.108592  [32000/69874]
loss: 0.136503  [38400/69874]
loss: 0.041361  [44800/69874]
loss: 0.116534  [51200/69874]
loss: 0.201469  [57600/69874]
loss: 0.119284  [64000/69874]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.161579 

Epoch 35
-------------------------------
loss: 0.258313  [    0/69874]
loss: 0.065266  [ 6400/69874]
loss: 0.105698  [12800/69874]
loss: 0.088793  [19200/69874]
loss: 0.169897  [25600/69874]
loss: 0.155820  [32000/69874]
loss: 0.201728  [38400/69874]
loss: 0.122693  [44800/69874]
loss: 0.065013  [51200/69874]
loss: 0.229691  [57600/69874]
loss: 0.132595  [64000/69874]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.154585 

Epoch 36
-------------------------------
loss: 0.139643  [    0/69874]
loss: 0.064409  [ 6400/69874]
loss: 0.077896  [12800/69874]
loss: 0.120882  [19200/69874]
loss: 0.136857  [25600/69874]
loss: 0.104841  [32000/69874]
loss: 0.137683  [38400/69874]
loss: 0.207591  [44800/69874]
loss: 0.143348  [51200/69874]
loss: 0.169656  [57600/69874]
loss: 0.144429  [64000/69874]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150947 

Epoch 37
-------------------------------
loss: 0.046866  [    0/69874]
loss: 0.167537  [ 6400/69874]
loss: 0.081381  [12800/69874]
loss: 0.170543  [19200/69874]
loss: 0.190072  [25600/69874]
loss: 0.152727  [32000/69874]
loss: 0.097870  [38400/69874]
loss: 0.114702  [44800/69874]
loss: 0.100708  [51200/69874]
loss: 0.059212  [57600/69874]
loss: 0.120458  [64000/69874]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.142947 

Epoch 38
-------------------------------
loss: 0.198976  [    0/69874]
loss: 0.089747  [ 6400/69874]
loss: 0.059968  [12800/69874]
loss: 0.135228  [19200/69874]
loss: 0.161504  [25600/69874]
loss: 0.103127  [32000/69874]
loss: 0.121880  [38400/69874]
loss: 0.065989  [44800/69874]
loss: 0.095335  [51200/69874]
loss: 0.131987  [57600/69874]
loss: 0.298548  [64000/69874]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.151999 

Epoch 39
-------------------------------
loss: 0.120417  [    0/69874]
loss: 0.211846  [ 6400/69874]
loss: 0.117355  [12800/69874]
loss: 0.033153  [19200/69874]
loss: 0.161507  [25600/69874]
loss: 0.058966  [32000/69874]
loss: 0.072674  [38400/69874]
loss: 0.061728  [44800/69874]
loss: 0.221399  [51200/69874]
loss: 0.163587  [57600/69874]
loss: 0.169277  [64000/69874]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.164734 

Epoch 40
-------------------------------
loss: 0.091718  [    0/69874]
loss: 0.232238  [ 6400/69874]
loss: 0.096471  [12800/69874]
loss: 0.238444  [19200/69874]
loss: 0.192294  [25600/69874]
loss: 0.126882  [32000/69874]
loss: 0.199562  [38400/69874]
loss: 0.089298  [44800/69874]
loss: 0.049800  [51200/69874]
loss: 0.192819  [57600/69874]
loss: 0.076875  [64000/69874]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.151773 

Epoch 41
-------------------------------
loss: 0.072054  [    0/69874]
loss: 0.037323  [ 6400/69874]
loss: 0.080975  [12800/69874]
loss: 0.066934  [19200/69874]
loss: 0.040795  [25600/69874]
loss: 0.180535  [32000/69874]
loss: 0.099009  [38400/69874]
loss: 0.125633  [44800/69874]
loss: 0.131941  [51200/69874]
loss: 0.182044  [57600/69874]
loss: 0.088797  [64000/69874]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.154676 

Epoch 42
-------------------------------
loss: 0.181658  [    0/69874]
loss: 0.221966  [ 6400/69874]
loss: 0.160374  [12800/69874]
loss: 0.081192  [19200/69874]
loss: 0.135242  [25600/69874]
loss: 0.117066  [32000/69874]
loss: 0.077643  [38400/69874]
loss: 0.192411  [44800/69874]
loss: 0.128902  [51200/69874]
loss: 0.118265  [57600/69874]
loss: 0.115999  [64000/69874]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.147820 

Epoch 43
-------------------------------
loss: 0.089973  [    0/69874]
loss: 0.080584  [ 6400/69874]
loss: 0.124118  [12800/69874]
loss: 0.180481  [19200/69874]
loss: 0.114891  [25600/69874]
loss: 0.114288  [32000/69874]
loss: 0.236124  [38400/69874]
loss: 0.143549  [44800/69874]
loss: 0.117128  [51200/69874]
loss: 0.082120  [57600/69874]
loss: 0.182146  [64000/69874]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.147172 

Epoch 44
-------------------------------
loss: 0.066080  [    0/69874]
loss: 0.122918  [ 6400/69874]
loss: 0.246585  [12800/69874]
loss: 0.055123  [19200/69874]
loss: 0.083117  [25600/69874]
loss: 0.185763  [32000/69874]
loss: 0.091688  [38400/69874]
loss: 0.137730  [44800/69874]
loss: 0.116709  [51200/69874]
loss: 0.104022  [57600/69874]
loss: 0.103294  [64000/69874]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.158563 

Epoch 45
-------------------------------
loss: 0.100568  [    0/69874]
loss: 0.029207  [ 6400/69874]
loss: 0.127044  [12800/69874]
loss: 0.113460  [19200/69874]
loss: 0.117948  [25600/69874]
loss: 0.081175  [32000/69874]
loss: 0.206388  [38400/69874]
loss: 0.032039  [44800/69874]
loss: 0.125567  [51200/69874]
loss: 0.108273  [57600/69874]
loss: 0.102897  [64000/69874]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.153438 

Epoch 46
-------------------------------
loss: 0.051862  [    0/69874]
loss: 0.169347  [ 6400/69874]
loss: 0.236995  [12800/69874]
loss: 1.686402  [19200/69874]
loss: 0.138452  [25600/69874]
loss: 0.137729  [32000/69874]
loss: 0.131407  [38400/69874]
loss: 0.159588  [44800/69874]
loss: 0.125695  [51200/69874]
loss: 0.046515  [57600/69874]
loss: 0.156447  [64000/69874]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.149591 

Epoch 47
-------------------------------
loss: 0.093984  [    0/69874]
loss: 0.037748  [ 6400/69874]
loss: 0.065925  [12800/69874]
loss: 0.071238  [19200/69874]
loss: 0.204712  [25600/69874]
loss: 0.197739  [32000/69874]
loss: 0.105671  [38400/69874]
loss: 0.115786  [44800/69874]
loss: 0.132660  [51200/69874]
loss: 0.189236  [57600/69874]
loss: 0.044043  [51200/72298]
loss: 0.007750  [57600/72298]
loss: 0.037919  [64000/72298]
loss: 0.000525  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.074455 

Epoch 27
-------------------------------
loss: 0.009253  [    0/72298]
loss: 0.005431  [ 6400/72298]
loss: 0.003370  [12800/72298]
loss: 0.038711  [19200/72298]
loss: 0.003132  [25600/72298]
loss: 0.072677  [32000/72298]
loss: 0.003611  [38400/72298]
loss: 0.052642  [44800/72298]
loss: 0.006145  [51200/72298]
loss: 0.018959  [57600/72298]
loss: 0.032885  [64000/72298]
loss: 0.013568  [70400/72298]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.074996 

Epoch 28
-------------------------------
loss: 0.010641  [    0/72298]
loss: 0.036273  [ 6400/72298]
loss: 0.005294  [12800/72298]
loss: 0.055833  [19200/72298]
loss: 0.147180  [25600/72298]
loss: 0.018364  [32000/72298]
loss: 0.016179  [38400/72298]
loss: 0.040683  [44800/72298]
loss: 0.013583  [51200/72298]
loss: 0.011068  [57600/72298]
loss: 0.009859  [64000/72298]
loss: 0.003475  [70400/72298]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.069764 

Epoch 29
-------------------------------
loss: 0.009343  [    0/72298]
loss: 0.000778  [ 6400/72298]
loss: 0.000672  [12800/72298]
loss: 0.004064  [19200/72298]
loss: 0.007564  [25600/72298]
loss: 0.000382  [32000/72298]
loss: 0.014303  [38400/72298]
loss: 0.016386  [44800/72298]
loss: 0.009942  [51200/72298]
loss: 0.015435  [57600/72298]
loss: 0.051430  [64000/72298]
loss: 0.004753  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.076722 

Epoch 30
-------------------------------
loss: 0.001924  [    0/72298]
loss: 0.035402  [ 6400/72298]
loss: 0.013566  [12800/72298]
loss: 0.008920  [19200/72298]
loss: 0.001558  [25600/72298]
loss: 0.030085  [32000/72298]
loss: 0.045951  [38400/72298]
loss: 0.009567  [44800/72298]
loss: 0.034733  [51200/72298]
loss: 0.002441  [57600/72298]
loss: 0.014883  [64000/72298]
loss: 0.003580  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.064174 

Epoch 31
-------------------------------
loss: 0.036546  [    0/72298]
loss: 0.002466  [ 6400/72298]
loss: 0.021068  [12800/72298]
loss: 0.000069  [19200/72298]
loss: 0.030335  [25600/72298]
loss: 0.030474  [32000/72298]
loss: 0.007430  [38400/72298]
loss: 0.078960  [44800/72298]
loss: 0.002388  [51200/72298]
loss: 0.018957  [57600/72298]
loss: 0.002716  [64000/72298]
loss: 0.043243  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.077343 

Epoch 32
-------------------------------
loss: 0.084277  [    0/72298]
loss: 0.007090  [ 6400/72298]
loss: 0.004130  [12800/72298]
loss: 0.020910  [19200/72298]
loss: 0.001423  [25600/72298]
loss: 0.006426  [32000/72298]
loss: 0.054304  [38400/72298]
loss: 0.006023  [44800/72298]
loss: 0.024923  [51200/72298]
loss: 0.011578  [57600/72298]
loss: 0.022907  [64000/72298]
loss: 0.027652  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.080966 

Epoch 33
-------------------------------
loss: 0.018935  [    0/72298]
loss: 0.005075  [ 6400/72298]
loss: 0.003224  [12800/72298]
loss: 0.009554  [19200/72298]
loss: 0.018158  [25600/72298]
loss: 0.056033  [32000/72298]
loss: 0.012517  [38400/72298]
loss: 0.007460  [44800/72298]
loss: 0.002056  [51200/72298]
loss: 0.089677  [57600/72298]
loss: 0.012333  [64000/72298]
loss: 0.003142  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.084785 

Epoch 34
-------------------------------
loss: 0.065913  [    0/72298]
loss: 0.005994  [ 6400/72298]
loss: 0.004530  [12800/72298]
loss: 0.019041  [19200/72298]
loss: 0.020398  [25600/72298]
loss: 0.005557  [32000/72298]
loss: 0.001137  [38400/72298]
loss: 0.061124  [44800/72298]
loss: 0.045245  [51200/72298]
loss: 0.004934  [57600/72298]
loss: 0.029461  [64000/72298]
loss: 0.011462  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.087495 

Epoch 35
-------------------------------
loss: 0.027309  [    0/72298]
loss: 0.000083  [ 6400/72298]
loss: 0.001435  [12800/72298]
loss: 0.002186  [19200/72298]
loss: 0.040594  [25600/72298]
loss: 0.012879  [32000/72298]
loss: 0.035921  [38400/72298]
loss: 0.013609  [44800/72298]
loss: 0.023850  [51200/72298]
loss: 0.072592  [57600/72298]
loss: 0.068336  [64000/72298]
loss: 0.021666  [70400/72298]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.077377 

Epoch 36
-------------------------------
loss: 0.023610  [    0/72298]
loss: 0.000164  [ 6400/72298]
loss: 0.030903  [12800/72298]
loss: 0.000200  [19200/72298]
loss: 0.020018  [25600/72298]
loss: 0.008956  [32000/72298]
loss: 0.009028  [38400/72298]
loss: 0.062726  [44800/72298]
loss: 0.004918  [51200/72298]
loss: 0.061563  [57600/72298]
loss: 0.023864  [64000/72298]
loss: 0.003703  [70400/72298]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.081060 

Epoch 37
-------------------------------
loss: 0.003593  [    0/72298]
loss: 0.006453  [ 6400/72298]
loss: 0.003002  [12800/72298]
loss: 0.007895  [19200/72298]
loss: 0.009941  [25600/72298]
loss: 0.004740  [32000/72298]
loss: 0.002386  [38400/72298]
loss: 0.002089  [44800/72298]
loss: 0.043266  [51200/72298]
loss: 0.087813  [57600/72298]
loss: 0.043013  [64000/72298]
loss: 0.114758  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.077703 

Epoch 38
-------------------------------
loss: 0.032727  [    0/72298]
loss: 0.015947  [ 6400/72298]
loss: 0.010636  [12800/72298]
loss: 0.067420  [19200/72298]
loss: 0.024361  [25600/72298]
loss: 0.000068  [32000/72298]
loss: 0.033016  [38400/72298]
loss: 0.000425  [44800/72298]
loss: 0.057343  [51200/72298]
loss: 0.015799  [57600/72298]
loss: 0.002702  [64000/72298]
loss: 0.021933  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.081901 

Epoch 39
-------------------------------
loss: 0.000696  [    0/72298]
loss: 0.000778  [ 6400/72298]
loss: 0.006837  [12800/72298]
loss: 0.009407  [19200/72298]
loss: 0.000066  [25600/72298]
loss: 0.122473  [32000/72298]
loss: 0.010609  [38400/72298]
loss: 0.001220  [44800/72298]
loss: 0.037436  [51200/72298]
loss: 0.006465  [57600/72298]
loss: 0.002887  [64000/72298]
loss: 0.018543  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.082532 

Epoch 40
-------------------------------
loss: 0.035666  [    0/72298]
loss: 0.020252  [ 6400/72298]
loss: 0.016131  [12800/72298]
loss: 0.000031  [19200/72298]
loss: 0.017375  [25600/72298]
loss: 0.028371  [32000/72298]
loss: 0.034103  [38400/72298]
loss: 0.041047  [44800/72298]
loss: 0.017234  [51200/72298]
loss: 0.006234  [57600/72298]
loss: 0.159996  [64000/72298]
loss: 0.093473  [70400/72298]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.095857 

Epoch 41
-------------------------------
loss: 0.004130  [    0/72298]
loss: 0.070470  [ 6400/72298]
loss: 0.002423  [12800/72298]
loss: 0.003071  [19200/72298]
loss: 0.002377  [25600/72298]
loss: 0.000272  [32000/72298]
loss: 0.008793  [38400/72298]
loss: 0.003310  [44800/72298]
loss: 0.012467  [51200/72298]
loss: 0.000369  [57600/72298]
loss: 0.037995  [64000/72298]
loss: 0.018287  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.078476 

Epoch 42
-------------------------------
loss: 0.031065  [    0/72298]
loss: 0.054693  [ 6400/72298]
loss: 0.006283  [12800/72298]
loss: 0.005105  [19200/72298]
loss: 0.000486  [25600/72298]
loss: 0.006777  [32000/72298]
loss: 0.021547  [38400/72298]
loss: 0.005655  [44800/72298]
loss: 0.025665  [51200/72298]
loss: 0.090972  [57600/72298]
loss: 0.004315  [64000/72298]
loss: 0.004102  [70400/72298]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.093196 

Epoch 43
-------------------------------
loss: 0.006756  [    0/72298]
loss: 0.013148  [ 6400/72298]
loss: 0.058404  [12800/72298]
loss: 0.002749  [19200/72298]
loss: 0.012313  [25600/72298]
loss: 0.001703  [32000/72298]
loss: 0.001758  [38400/72298]
loss: 0.016951  [44800/72298]
loss: 0.018379  [51200/72298]
loss: 0.003570  [57600/72298]
loss: 0.014678  [64000/72298]
loss: 0.000204  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.086922 

Epoch 44
-------------------------------
loss: 0.003980  [    0/72298]
loss: 0.001801  [ 6400/72298]
loss: 0.059451  [12800/72298]
loss: 0.004152  [19200/72298]
loss: 0.002828  [25600/72298]
loss: 0.012558  [32000/72298]
loss: 0.001714  [38400/72298]
loss: 0.004282  [44800/72298]
loss: 0.013478  [51200/72298]
2022/09/20 14:07:18 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.159267 

Epoch 25
-------------------------------
loss: 0.043094  [    0/69845]
loss: 0.143634  [ 6400/69845]
loss: 0.096570  [12800/69845]
loss: 0.120431  [19200/69845]
loss: 0.151359  [25600/69845]
loss: 0.113143  [32000/69845]
loss: 0.219012  [38400/69845]
loss: 0.103906  [44800/69845]
loss: 0.083007  [51200/69845]
loss: 0.021341  [57600/69845]
loss: 0.209871  [64000/69845]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.152970 

Epoch 26
-------------------------------
loss: 0.122928  [    0/69845]
loss: 0.106862  [ 6400/69845]
loss: 0.144539  [12800/69845]
loss: 0.194553  [19200/69845]
loss: 0.136433  [25600/69845]
loss: 0.130285  [32000/69845]
loss: 0.152211  [38400/69845]
loss: 0.136178  [44800/69845]
loss: 0.186705  [51200/69845]
loss: 0.129899  [57600/69845]
loss: 0.092942  [64000/69845]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.157986 

Epoch 27
-------------------------------
loss: 0.062789  [    0/69845]
loss: 0.023121  [ 6400/69845]
loss: 0.172538  [12800/69845]
loss: 0.059782  [19200/69845]
loss: 0.105265  [25600/69845]
loss: 0.101028  [32000/69845]
loss: 0.128856  [38400/69845]
loss: 0.134867  [44800/69845]
loss: 0.158555  [51200/69845]
loss: 0.145162  [57600/69845]
loss: 0.174710  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.149211 

Epoch 28
-------------------------------
loss: 0.172214  [    0/69845]
loss: 0.144452  [ 6400/69845]
loss: 0.119713  [12800/69845]
loss: 0.168974  [19200/69845]
loss: 0.253906  [25600/69845]
loss: 0.120925  [32000/69845]
loss: 0.055141  [38400/69845]
loss: 0.096936  [44800/69845]
loss: 0.137581  [51200/69845]
loss: 0.213621  [57600/69845]
loss: 0.163812  [64000/69845]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.148754 

Epoch 29
-------------------------------
loss: 0.097272  [    0/69845]
loss: 0.192186  [ 6400/69845]
loss: 0.031814  [12800/69845]
loss: 0.100989  [19200/69845]
loss: 0.290185  [25600/69845]
loss: 0.122915  [32000/69845]
loss: 0.088213  [38400/69845]
loss: 0.111502  [44800/69845]
loss: 0.211791  [51200/69845]
loss: 0.110164  [57600/69845]
loss: 0.134931  [64000/69845]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.150368 

Epoch 30
-------------------------------
loss: 0.115132  [    0/69845]
loss: 0.102078  [ 6400/69845]
loss: 0.158294  [12800/69845]
loss: 0.061290  [19200/69845]
loss: 0.096743  [25600/69845]
loss: 0.120421  [32000/69845]
loss: 0.042634  [38400/69845]
loss: 0.175938  [44800/69845]
loss: 0.333443  [51200/69845]
loss: 0.080605  [57600/69845]
loss: 0.126487  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.151081 

Epoch 31
-------------------------------
loss: 0.155942  [    0/69845]
loss: 0.092094  [ 6400/69845]
loss: 0.097586  [12800/69845]
loss: 0.161924  [19200/69845]
loss: 0.232398  [25600/69845]
loss: 0.078645  [32000/69845]
loss: 0.054840  [38400/69845]
loss: 0.095062  [44800/69845]
loss: 0.090509  [51200/69845]
loss: 0.093224  [57600/69845]
loss: 0.058855  [64000/69845]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.152251 

Epoch 32
-------------------------------
loss: 0.063183  [    0/69845]
loss: 0.104408  [ 6400/69845]
loss: 0.159968  [12800/69845]
loss: 0.097330  [19200/69845]
loss: 0.121804  [25600/69845]
loss: 0.169762  [32000/69845]
loss: 0.082494  [38400/69845]
loss: 0.135708  [44800/69845]
loss: 0.070845  [51200/69845]
loss: 0.179516  [57600/69845]
loss: 0.170709  [64000/69845]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.149039 

Epoch 33
-------------------------------
loss: 0.215269  [    0/69845]
loss: 0.119825  [ 6400/69845]
loss: 0.026836  [12800/69845]
loss: 0.151663  [19200/69845]
loss: 0.167766  [25600/69845]
loss: 0.102661  [32000/69845]
loss: 0.112919  [38400/69845]
loss: 0.145602  [44800/69845]
loss: 0.058657  [51200/69845]
loss: 0.156930  [57600/69845]
loss: 0.139612  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147312 

Epoch 34
-------------------------------
loss: 0.103066  [    0/69845]
loss: 0.197810  [ 6400/69845]
loss: 0.190018  [12800/69845]
loss: 0.152306  [19200/69845]
loss: 0.161905  [25600/69845]
loss: 0.060349  [32000/69845]
loss: 0.161652  [38400/69845]
loss: 0.055246  [44800/69845]
loss: 0.098605  [51200/69845]
loss: 0.068511  [57600/69845]
loss: 0.207243  [64000/69845]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.148816 

Epoch 35
-------------------------------
loss: 0.153307  [    0/69845]
loss: 0.155511  [ 6400/69845]
loss: 0.089696  [12800/69845]
loss: 0.084352  [19200/69845]
loss: 0.047804  [25600/69845]
loss: 0.066512  [32000/69845]
loss: 0.115617  [38400/69845]
loss: 0.164200  [44800/69845]
loss: 0.095506  [51200/69845]
loss: 0.237670  [57600/69845]
loss: 0.083834  [64000/69845]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.151276 

Epoch 36
-------------------------------
loss: 0.116062  [    0/69845]
loss: 0.163584  [ 6400/69845]
loss: 0.086794  [12800/69845]
loss: 0.090231  [19200/69845]
loss: 0.072933  [25600/69845]
loss: 0.081979  [32000/69845]
loss: 0.083594  [38400/69845]
loss: 0.127041  [44800/69845]
loss: 0.258146  [51200/69845]
loss: 0.166044  [57600/69845]
loss: 0.099008  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.150892 

Epoch 37
-------------------------------
loss: 0.097337  [    0/69845]
loss: 0.051243  [ 6400/69845]
loss: 0.072348  [12800/69845]
loss: 0.098085  [19200/69845]
loss: 0.088707  [25600/69845]
loss: 0.130016  [32000/69845]
loss: 0.081669  [38400/69845]
loss: 0.076297  [44800/69845]
loss: 0.083983  [51200/69845]
loss: 0.073050  [57600/69845]
loss: 0.071890  [64000/69845]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.162730 

Epoch 38
-------------------------------
loss: 0.060900  [    0/69845]
loss: 0.089964  [ 6400/69845]
loss: 0.136950  [12800/69845]
loss: 0.105325  [19200/69845]
loss: 0.078715  [25600/69845]
loss: 0.206265  [32000/69845]
loss: 0.182147  [38400/69845]
loss: 0.098851  [44800/69845]
loss: 0.105789  [51200/69845]
loss: 0.082601  [57600/69845]
loss: 0.098997  [64000/69845]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.161950 

Epoch 39
-------------------------------
loss: 0.124442  [    0/69845]
loss: 0.076677  [ 6400/69845]
loss: 0.230291  [12800/69845]
loss: 0.109711  [19200/69845]
loss: 0.076288  [25600/69845]
loss: 0.171579  [32000/69845]
loss: 0.113180  [38400/69845]
loss: 0.048661  [44800/69845]
loss: 0.185970  [51200/69845]
loss: 0.053827  [57600/69845]
loss: 0.066178  [64000/69845]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.156437 

Epoch 40
-------------------------------
loss: 0.099104  [    0/69845]
loss: 0.161090  [ 6400/69845]
loss: 0.106817  [12800/69845]
loss: 0.142201  [19200/69845]
loss: 0.186023  [25600/69845]
loss: 0.179170  [32000/69845]
loss: 0.118403  [38400/69845]
loss: 0.098930  [44800/69845]
loss: 0.087102  [51200/69845]
loss: 0.144112  [57600/69845]
loss: 0.099880  [64000/69845]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.159916 

Epoch 41
-------------------------------
loss: 0.127195  [    0/69845]
loss: 0.099901  [ 6400/69845]
loss: 0.094095  [12800/69845]
loss: 0.033728  [19200/69845]
loss: 0.131598  [25600/69845]
loss: 0.090907  [32000/69845]
loss: 0.068509  [38400/69845]
loss: 0.098489  [44800/69845]
loss: 0.162539  [51200/69845]
loss: 0.167042  [57600/69845]
loss: 0.263244  [64000/69845]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.149261 

Epoch 42
-------------------------------
loss: 0.073364  [    0/69845]
loss: 0.138382  [ 6400/69845]
loss: 0.313609  [12800/69845]
loss: 0.210100  [19200/69845]
loss: 0.108920  [25600/69845]
loss: 0.034945  [32000/69845]
loss: 0.136402  [38400/69845]
loss: 0.131816  [44800/69845]
loss: 0.061972  [51200/69845]
loss: 0.108384  [57600/69845]
loss: 0.174377  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.153457 

Epoch 43
-------------------------------
loss: 0.134466  [    0/69845]
loss: 0.197526  [ 6400/69845]
loss: 0.126923  [12800/69845]
loss: 0.122431  [19200/69845]
loss: 0.125956  [25600/69845]
loss: 0.091496  [32000/69845]
loss: 0.055250  [38400/69845]
loss: 0.092311  [44800/69845]
loss: 0.099269  [51200/69845]
loss: 0.278518  [57600/69845]
loss: 0.136470  [64000/69845]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.150466 

Epoch 44
-------------------------------
loss: 0.065517  [    0/69845]
loss: 0.076582  [ 6400/69845]
2022/09/20 14:10:08 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:10:21 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:10:26 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:10:29 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:11:47 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:12:09 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.093888  [32000/70247]
loss: 0.123492  [38400/70247]
loss: 0.024218  [44800/70247]
loss: 0.101505  [51200/70247]
loss: 0.037551  [57600/70247]
loss: 0.031315  [64000/70247]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076331 

Epoch 29
-------------------------------
loss: 0.051701  [    0/70247]
loss: 0.048222  [ 6400/70247]
loss: 0.053462  [12800/70247]
loss: 0.049466  [19200/70247]
loss: 0.014721  [25600/70247]
loss: 0.090028  [32000/70247]
loss: 0.029297  [38400/70247]
loss: 0.011037  [44800/70247]
loss: 0.062687  [51200/70247]
loss: 0.073412  [57600/70247]
loss: 0.156099  [64000/70247]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076098 

Epoch 30
-------------------------------
loss: 0.076554  [    0/70247]
loss: 0.023320  [ 6400/70247]
loss: 0.103256  [12800/70247]
loss: 0.071592  [19200/70247]
loss: 0.118036  [25600/70247]
loss: 0.185991  [32000/70247]
loss: 0.018749  [38400/70247]
loss: 0.052072  [44800/70247]
loss: 0.079325  [51200/70247]
loss: 0.039925  [57600/70247]
loss: 0.259844  [64000/70247]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.079947 

Epoch 31
-------------------------------
loss: 0.029041  [    0/70247]
loss: 0.026598  [ 6400/70247]
loss: 0.091183  [12800/70247]
loss: 0.048704  [19200/70247]
loss: 0.022777  [25600/70247]
loss: 0.079659  [32000/70247]
loss: 0.049349  [38400/70247]
loss: 0.056532  [44800/70247]
loss: 0.022769  [51200/70247]
loss: 0.054071  [57600/70247]
loss: 0.083788  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.088023 

Epoch 32
-------------------------------
loss: 0.044378  [    0/70247]
loss: 0.066019  [ 6400/70247]
loss: 0.027256  [12800/70247]
loss: 0.010692  [19200/70247]
loss: 0.023790  [25600/70247]
loss: 0.251962  [32000/70247]
loss: 0.195436  [38400/70247]
loss: 0.024896  [44800/70247]
loss: 0.039473  [51200/70247]
loss: 0.045241  [57600/70247]
loss: 0.049900  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.082883 

Epoch 33
-------------------------------
loss: 0.018775  [    0/70247]
loss: 0.111057  [ 6400/70247]
loss: 0.069523  [12800/70247]
loss: 0.087463  [19200/70247]
loss: 0.121033  [25600/70247]
loss: 0.038087  [32000/70247]
loss: 0.047611  [38400/70247]
loss: 0.002683  [44800/70247]
loss: 0.093750  [51200/70247]
loss: 0.014823  [57600/70247]
loss: 0.057235  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.082997 

Epoch 34
-------------------------------
loss: 0.003674  [    0/70247]
loss: 0.024116  [ 6400/70247]
loss: 0.013600  [12800/70247]
loss: 0.066051  [19200/70247]
loss: 0.063934  [25600/70247]
loss: 0.076787  [32000/70247]
loss: 0.035986  [38400/70247]
loss: 0.092025  [44800/70247]
loss: 0.092416  [51200/70247]
loss: 0.053899  [57600/70247]
loss: 0.037837  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.079141 

Epoch 35
-------------------------------
loss: 0.010625  [    0/70247]
loss: 0.017159  [ 6400/70247]
loss: 0.008252  [12800/70247]
loss: 0.117175  [19200/70247]
loss: 0.071741  [25600/70247]
loss: 0.046297  [32000/70247]
loss: 0.066716  [38400/70247]
loss: 0.058463  [44800/70247]
loss: 0.052966  [51200/70247]
loss: 0.021778  [57600/70247]
loss: 0.027463  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.082387 

Epoch 36
-------------------------------
loss: 0.030239  [    0/70247]
loss: 0.080896  [ 6400/70247]
loss: 0.018168  [12800/70247]
loss: 0.013462  [19200/70247]
loss: 0.059231  [25600/70247]
loss: 0.050502  [32000/70247]
loss: 0.051003  [38400/70247]
loss: 0.073921  [44800/70247]
loss: 0.063100  [51200/70247]
loss: 0.017824  [57600/70247]
loss: 0.145537  [64000/70247]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.094369 

Epoch 37
-------------------------------
loss: 0.183261  [    0/70247]
loss: 0.055384  [ 6400/70247]
loss: 0.018131  [12800/70247]
loss: 0.045593  [19200/70247]
loss: 0.032540  [25600/70247]
loss: 0.023268  [32000/70247]
loss: 0.036088  [38400/70247]
loss: 0.048461  [44800/70247]
loss: 0.120872  [51200/70247]
loss: 0.036087  [57600/70247]
loss: 0.077767  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.084958 

Epoch 38
-------------------------------
loss: 0.077696  [    0/70247]
loss: 0.035435  [ 6400/70247]
loss: 0.019056  [12800/70247]
loss: 0.130961  [19200/70247]
loss: 0.073878  [25600/70247]
loss: 0.116089  [32000/70247]
loss: 0.014769  [38400/70247]
loss: 0.109468  [44800/70247]
loss: 0.137546  [51200/70247]
loss: 0.140056  [57600/70247]
loss: 0.023507  [64000/70247]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.080034 

Epoch 39
-------------------------------
loss: 0.044433  [    0/70247]
loss: 0.019128  [ 6400/70247]
loss: 0.122428  [12800/70247]
loss: 0.024767  [19200/70247]
loss: 0.016183  [25600/70247]
loss: 0.134381  [32000/70247]
loss: 0.021742  [38400/70247]
loss: 0.042010  [44800/70247]
loss: 0.070571  [51200/70247]
loss: 0.030810  [57600/70247]
loss: 0.068323  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.081930 

Epoch 40
-------------------------------
loss: 0.019525  [    0/70247]
loss: 0.067427  [ 6400/70247]
loss: 0.095124  [12800/70247]
loss: 0.033850  [19200/70247]
loss: 0.037329  [25600/70247]
loss: 0.160619  [32000/70247]
loss: 0.013812  [38400/70247]
loss: 0.050779  [44800/70247]
loss: 0.012353  [51200/70247]
loss: 0.090969  [57600/70247]
loss: 0.051337  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.090314 

Epoch 41
-------------------------------
loss: 0.065548  [    0/70247]
loss: 0.020782  [ 6400/70247]
loss: 0.067945  [12800/70247]
loss: 0.063479  [19200/70247]
loss: 0.015116  [25600/70247]
loss: 0.175309  [32000/70247]
loss: 0.057054  [38400/70247]
loss: 0.117308  [44800/70247]
loss: 0.034261  [51200/70247]
loss: 0.051043  [57600/70247]
loss: 0.077576  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.080282 

Epoch 42
-------------------------------
loss: 0.079828  [    0/70247]
loss: 0.029864  [ 6400/70247]
loss: 0.029481  [12800/70247]
loss: 0.036512  [19200/70247]
loss: 0.027465  [25600/70247]
loss: 0.004850  [32000/70247]
loss: 0.117694  [38400/70247]
loss: 0.066456  [44800/70247]
loss: 0.015424  [51200/70247]
loss: 0.107916  [57600/70247]
loss: 0.079463  [64000/70247]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.083838 

Epoch 43
-------------------------------
loss: 0.071757  [    0/70247]
loss: 0.033130  [ 6400/70247]
loss: 0.050524  [12800/70247]
loss: 0.115015  [19200/70247]
loss: 0.117587  [25600/70247]
loss: 0.116554  [32000/70247]
loss: 0.106380  [38400/70247]
loss: 0.015838  [44800/70247]
loss: 0.035327  [51200/70247]
loss: 0.019471  [57600/70247]
loss: 0.094118  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.086683 

Epoch 44
-------------------------------
loss: 0.034355  [    0/70247]
loss: 0.012991  [ 6400/70247]
loss: 0.032224  [12800/70247]
loss: 0.053125  [19200/70247]
loss: 0.085073  [25600/70247]
loss: 0.165389  [32000/70247]
loss: 0.040272  [38400/70247]
loss: 0.044232  [44800/70247]
loss: 0.099185  [51200/70247]
loss: 0.024907  [57600/70247]
loss: 0.014412  [64000/70247]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.088282 

Epoch 45
-------------------------------
loss: 0.043487  [    0/70247]
loss: 0.039697  [ 6400/70247]
loss: 0.006979  [12800/70247]
loss: 0.009813  [19200/70247]
loss: 0.023235  [25600/70247]
loss: 0.011050  [32000/70247]
loss: 0.025091  [38400/70247]
loss: 0.074547  [44800/70247]
loss: 0.060665  [51200/70247]
loss: 0.021024  [57600/70247]
loss: 0.041157  [64000/70247]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.085570 

Epoch 46
-------------------------------
loss: 0.029315  [    0/70247]
loss: 0.077064  [ 6400/70247]
loss: 0.057774  [12800/70247]
loss: 0.015647  [19200/70247]
loss: 0.019381  [25600/70247]
loss: 0.042003  [32000/70247]
loss: 0.035453  [38400/70247]
loss: 0.039840  [44800/70247]
loss: 0.085848  [51200/70247]
loss: 0.031720  [57600/70247]
loss: 0.027999  [64000/70247]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.083797 

Epoch 47
-------------------------------
loss: 0.096741  [    0/70247]
loss: 0.056802  [ 6400/70247]
loss: 0.057151  [12800/70247]
loss: 0.063186  [19200/70247]
loss: 0.079724  [25600/70247]
loss: 0.071876  [32000/70247]
loss: 0.083312  [38400/70247]
loss: 0.073736  [44800/70247]
loss: 0.061129  [51200/70247]
loss: 0.019679  [57600/70247]
2022/09/20 14:12:30 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:13:12 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:13:16 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:13:29 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:13:33 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:14:01 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:14:24 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:15:42 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.010769  [25600/71122]
loss: 0.035348  [32000/71122]
loss: 0.038933  [38400/71122]
loss: 0.090769  [44800/71122]
loss: 0.033511  [51200/71122]
loss: 0.084326  [57600/71122]
loss: 0.037246  [64000/71122]
loss: 0.025407  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.064771 

Epoch 42
-------------------------------
loss: 0.005726  [    0/71122]
loss: 0.009400  [ 6400/71122]
loss: 0.043603  [12800/71122]
loss: 0.052217  [19200/71122]
loss: 0.044800  [25600/71122]
loss: 0.054218  [32000/71122]
loss: 0.010738  [38400/71122]
loss: 0.042017  [44800/71122]
loss: 0.019391  [51200/71122]
loss: 0.111132  [57600/71122]
loss: 0.016393  [64000/71122]
loss: 0.075322  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.080418 

Epoch 43
-------------------------------
loss: 0.007810  [    0/71122]
loss: 0.055387  [ 6400/71122]
loss: 0.047005  [12800/71122]
loss: 0.005750  [19200/71122]
loss: 0.079682  [25600/71122]
loss: 0.009615  [32000/71122]
loss: 0.017031  [38400/71122]
loss: 0.137979  [44800/71122]
loss: 0.012445  [51200/71122]
loss: 0.017616  [57600/71122]
loss: 0.010726  [64000/71122]
loss: 0.045338  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.063996 

Epoch 44
-------------------------------
loss: 0.011953  [    0/71122]
loss: 0.027583  [ 6400/71122]
loss: 0.050686  [12800/71122]
loss: 0.017895  [19200/71122]
loss: 0.003816  [25600/71122]
loss: 0.019217  [32000/71122]
loss: 0.017644  [38400/71122]
loss: 0.058676  [44800/71122]
loss: 0.024636  [51200/71122]
loss: 0.060265  [57600/71122]
loss: 0.067118  [64000/71122]
loss: 0.088501  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.067506 

Epoch 45
-------------------------------
loss: 0.012869  [    0/71122]
loss: 0.017324  [ 6400/71122]
loss: 0.030210  [12800/71122]
loss: 0.014559  [19200/71122]
loss: 0.007854  [25600/71122]
loss: 0.012620  [32000/71122]
loss: 0.056049  [38400/71122]
loss: 0.006661  [44800/71122]
loss: 0.055910  [51200/71122]
loss: 0.003316  [57600/71122]
loss: 0.007552  [64000/71122]
loss: 0.030107  [70400/71122]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.090425 

Epoch 46
-------------------------------
loss: 0.010346  [    0/71122]
loss: 0.004619  [ 6400/71122]
loss: 0.072049  [12800/71122]
loss: 0.011822  [19200/71122]
loss: 0.017986  [25600/71122]
loss: 0.125014  [32000/71122]
loss: 0.041328  [38400/71122]
loss: 0.026556  [44800/71122]
loss: 0.017438  [51200/71122]
loss: 0.004939  [57600/71122]
loss: 0.014063  [64000/71122]
loss: 0.007061  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.067095 

Epoch 47
-------------------------------
loss: 0.051332  [    0/71122]
loss: 0.006620  [ 6400/71122]
loss: 0.005781  [12800/71122]
loss: 0.049970  [19200/71122]
loss: 0.031274  [25600/71122]
loss: 0.001148  [32000/71122]
loss: 0.053167  [38400/71122]
loss: 0.017617  [44800/71122]
loss: 0.054539  [51200/71122]
loss: 0.049759  [57600/71122]
loss: 0.018400  [64000/71122]
loss: 0.012510  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.068371 

Epoch 48
-------------------------------
loss: 0.008985  [    0/71122]
loss: 0.004056  [ 6400/71122]
loss: 0.018427  [12800/71122]
loss: 0.032652  [19200/71122]
loss: 0.165142  [25600/71122]
loss: 0.001020  [32000/71122]
loss: 0.067984  [38400/71122]
loss: 0.064439  [44800/71122]
loss: 0.018231  [51200/71122]
loss: 0.015739  [57600/71122]
loss: 0.018913  [64000/71122]
loss: 0.066760  [70400/71122]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.070209 

Epoch 49
-------------------------------
loss: 0.007335  [    0/71122]
loss: 0.004526  [ 6400/71122]
loss: 0.005310  [12800/71122]
loss: 0.024747  [19200/71122]
loss: 0.030714  [25600/71122]
loss: 0.086802  [32000/71122]
loss: 0.014317  [38400/71122]
loss: 0.073482  [44800/71122]
loss: 0.118472  [51200/71122]
loss: 0.009378  [57600/71122]
loss: 0.000896  [64000/71122]
loss: 0.064407  [70400/71122]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.072425 

Epoch 50
-------------------------------
loss: 0.015008  [    0/71122]
loss: 0.006379  [ 6400/71122]
loss: 0.022777  [12800/71122]
loss: 0.004537  [19200/71122]
loss: 0.029826  [25600/71122]
loss: 0.042632  [32000/71122]
loss: 0.043666  [38400/71122]
loss: 0.127997  [44800/71122]
loss: 0.077354  [51200/71122]
loss: 0.069244  [57600/71122]
loss: 0.177966  [64000/71122]
loss: 0.007746  [70400/71122]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.069234 

Epoch 1
-------------------------------
loss: 0.705401  [    0/71706]
loss: 0.305799  [ 6400/71706]
loss: 0.283375  [12800/71706]
loss: 0.250668  [19200/71706]
loss: 0.206389  [25600/71706]
loss: 0.089766  [32000/71706]
loss: 0.129966  [38400/71706]
loss: 0.047835  [44800/71706]
loss: 0.051248  [51200/71706]
loss: 0.085052  [57600/71706]
loss: 0.081081  [64000/71706]
loss: 0.187838  [70400/71706]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.100594 

Epoch 2
-------------------------------
loss: 0.047411  [    0/71706]
loss: 0.074184  [ 6400/71706]
loss: 0.110847  [12800/71706]
loss: 0.162878  [19200/71706]
loss: 0.170782  [25600/71706]
loss: 0.089934  [32000/71706]
loss: 0.057514  [38400/71706]
loss: 0.072521  [44800/71706]
loss: 0.096735  [51200/71706]
loss: 0.083886  [57600/71706]
loss: 0.125056  [64000/71706]
loss: 0.058000  [70400/71706]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.083924 

Epoch 3
-------------------------------
loss: 0.076000  [    0/71706]
loss: 0.032668  [ 6400/71706]
loss: 0.287512  [12800/71706]
loss: 0.131846  [19200/71706]
loss: 0.041980  [25600/71706]
loss: 0.042781  [32000/71706]
loss: 0.060872  [38400/71706]
loss: 0.033144  [44800/71706]
loss: 0.035753  [51200/71706]
loss: 0.065863  [57600/71706]
loss: 0.065530  [64000/71706]
loss: 0.025607  [70400/71706]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.084855 

Epoch 4
-------------------------------
loss: 0.200644  [    0/71706]
loss: 0.079764  [ 6400/71706]
loss: 0.035884  [12800/71706]
loss: 0.104729  [19200/71706]
loss: 0.072277  [25600/71706]
loss: 0.075322  [32000/71706]
loss: 0.117993  [38400/71706]
loss: 0.014780  [44800/71706]
loss: 0.092604  [51200/71706]
loss: 0.096838  [57600/71706]
loss: 0.174527  [64000/71706]
loss: 0.014432  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.080102 

Epoch 5
-------------------------------
loss: 0.026606  [    0/71706]
loss: 0.056418  [ 6400/71706]
loss: 0.025082  [12800/71706]
loss: 0.081320  [19200/71706]
loss: 0.060663  [25600/71706]
loss: 0.066718  [32000/71706]
loss: 0.023390  [38400/71706]
loss: 0.043839  [44800/71706]
loss: 0.054993  [51200/71706]
loss: 0.343945  [57600/71706]
loss: 0.042536  [64000/71706]
loss: 0.113167  [70400/71706]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085734 

Epoch 6
-------------------------------
loss: 0.031790  [    0/71706]
loss: 0.035270  [ 6400/71706]
loss: 0.023645  [12800/71706]
loss: 0.043862  [19200/71706]
loss: 0.141643  [25600/71706]
loss: 0.094235  [32000/71706]
loss: 0.073208  [38400/71706]
loss: 0.020752  [44800/71706]
loss: 0.077580  [51200/71706]
loss: 0.087647  [57600/71706]
loss: 0.048129  [64000/71706]
loss: 0.013162  [70400/71706]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.083280 

Epoch 7
-------------------------------
loss: 0.028415  [    0/71706]
loss: 0.093376  [ 6400/71706]
loss: 0.016081  [12800/71706]
loss: 0.027101  [19200/71706]
loss: 0.051064  [25600/71706]
loss: 0.025429  [32000/71706]
loss: 0.036741  [38400/71706]
loss: 0.027258  [44800/71706]
loss: 0.082462  [51200/71706]
loss: 0.047602  [57600/71706]
loss: 0.089926  [64000/71706]
loss: 0.043479  [70400/71706]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077188 

Epoch 8
-------------------------------
loss: 0.080652  [    0/71706]
loss: 0.027868  [ 6400/71706]
loss: 0.025846  [12800/71706]
loss: 0.012217  [19200/71706]
loss: 0.032891  [25600/71706]
loss: 0.098128  [32000/71706]
loss: 0.082573  [38400/71706]
loss: 0.032320  [44800/71706]
loss: 0.051675  [51200/71706]
loss: 0.121050  [57600/71706]
loss: 0.052885  [64000/71706]
loss: 0.069321  [70400/71706]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.078250 

Epoch 9
-------------------------------
loss: 0.057743  [    0/71706]
loss: 0.100304  [ 6400/71706]
loss: 0.134100  [12800/71706]
loss: 0.037126  [19200/71706]
loss: 0.039642  [25600/71706]
loss: 0.005720  [25600/71418]
loss: 0.018399  [32000/71418]
loss: 0.009709  [38400/71418]
loss: 0.010309  [44800/71418]
loss: 0.045856  [51200/71418]
loss: 0.005646  [57600/71418]
loss: 0.000404  [64000/71418]
loss: 0.002250  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.170106 

Epoch 42
-------------------------------
loss: 0.013972  [    0/71418]
loss: 0.009612  [ 6400/71418]
loss: 0.015431  [12800/71418]
loss: 0.000535  [19200/71418]
loss: 0.030011  [25600/71418]
loss: 0.017812  [32000/71418]
loss: 0.011216  [38400/71418]
loss: 0.015318  [44800/71418]
loss: 0.000537  [51200/71418]
loss: 0.000574  [57600/71418]
loss: 0.004698  [64000/71418]
loss: 0.049913  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.150123 

Epoch 43
-------------------------------
loss: 0.032798  [    0/71418]
loss: 0.003415  [ 6400/71418]
loss: 0.088542  [12800/71418]
loss: 0.017269  [19200/71418]
loss: 0.043297  [25600/71418]
loss: 0.019364  [32000/71418]
loss: 0.004292  [38400/71418]
loss: 0.001098  [44800/71418]
loss: 0.002406  [51200/71418]
loss: 0.169556  [57600/71418]
loss: 0.012857  [64000/71418]
loss: 0.190036  [70400/71418]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.142678 

Epoch 44
-------------------------------
loss: 0.003281  [    0/71418]
loss: 0.052585  [ 6400/71418]
loss: 0.048973  [12800/71418]
loss: 0.159255  [19200/71418]
loss: 0.006053  [25600/71418]
loss: 0.004640  [32000/71418]
loss: 0.020994  [38400/71418]
loss: 0.174291  [44800/71418]
loss: 0.016391  [51200/71418]
loss: 0.004601  [57600/71418]
loss: 0.058178  [64000/71418]
loss: 0.013152  [70400/71418]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.160992 

Epoch 45
-------------------------------
loss: 0.014761  [    0/71418]
loss: 0.012091  [ 6400/71418]
loss: 0.051253  [12800/71418]
loss: 0.164312  [19200/71418]
loss: 0.010792  [25600/71418]
loss: 0.032789  [32000/71418]
loss: 0.020916  [38400/71418]
loss: 0.003025  [44800/71418]
loss: 0.020350  [51200/71418]
loss: 0.021681  [57600/71418]
loss: 0.095774  [64000/71418]
loss: 0.000435  [70400/71418]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.167271 

Epoch 46
-------------------------------
loss: 0.000832  [    0/71418]
loss: 0.001519  [ 6400/71418]
loss: 0.063110  [12800/71418]
loss: 0.001124  [19200/71418]
loss: 0.000882  [25600/71418]
loss: 0.053282  [32000/71418]
loss: 0.027290  [38400/71418]
loss: 0.020289  [44800/71418]
loss: 0.090557  [51200/71418]
loss: 0.015868  [57600/71418]
loss: 0.019241  [64000/71418]
loss: 0.000213  [70400/71418]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.156766 

Epoch 47
-------------------------------
loss: 0.018104  [    0/71418]
loss: 0.003878  [ 6400/71418]
loss: 0.013773  [12800/71418]
loss: 0.013552  [19200/71418]
loss: 0.005930  [25600/71418]
loss: 0.001511  [32000/71418]
loss: 1.612972  [38400/71418]
loss: 0.000114  [44800/71418]
loss: 0.035670  [51200/71418]
loss: 0.008959  [57600/71418]
loss: 0.005525  [64000/71418]
loss: 0.037382  [70400/71418]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.169512 

Epoch 48
-------------------------------
loss: 0.008179  [    0/71418]
loss: 0.006558  [ 6400/71418]
loss: 0.057007  [12800/71418]
loss: 0.036179  [19200/71418]
loss: 0.067130  [25600/71418]
loss: 0.013808  [32000/71418]
loss: 0.003419  [38400/71418]
loss: 0.048253  [44800/71418]
loss: 0.045178  [51200/71418]
loss: 0.003922  [57600/71418]
loss: 0.011100  [64000/71418]
loss: 0.010028  [70400/71418]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.186109 

Epoch 49
-------------------------------
loss: 0.077416  [    0/71418]
loss: 0.000177  [ 6400/71418]
loss: 0.000246  [12800/71418]
loss: 0.031903  [19200/71418]
loss: 0.077181  [25600/71418]
loss: 0.013877  [32000/71418]
loss: 0.001333  [38400/71418]
loss: 0.005289  [44800/71418]
loss: 0.003822  [51200/71418]
loss: 0.017492  [57600/71418]
loss: 0.082844  [64000/71418]
loss: 0.003697  [70400/71418]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.188734 

Epoch 50
-------------------------------
loss: 0.071017  [    0/71418]
loss: 0.003431  [ 6400/71418]
loss: 0.001569  [12800/71418]
loss: 0.014444  [19200/71418]
loss: 0.007329  [25600/71418]
loss: 0.055515  [32000/71418]
loss: 0.005030  [38400/71418]
loss: 0.006686  [44800/71418]
loss: 0.043692  [51200/71418]
loss: 0.009666  [57600/71418]
loss: 0.018951  [64000/71418]
loss: 0.003512  [70400/71418]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.198095 

Epoch 1
-------------------------------
loss: 0.718540  [    0/72604]
loss: 0.095301  [ 6400/72604]
loss: 0.091083  [12800/72604]
loss: 0.057852  [19200/72604]
loss: 0.023306  [25600/72604]
loss: 0.011373  [32000/72604]
loss: 0.057357  [38400/72604]
loss: 0.119927  [44800/72604]
loss: 0.039657  [51200/72604]
loss: 0.009808  [57600/72604]
loss: 0.012773  [64000/72604]
loss: 0.026150  [70400/72604]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.052681 

Epoch 2
-------------------------------
loss: 0.010104  [    0/72604]
loss: 0.138491  [ 6400/72604]
loss: 0.087295  [12800/72604]
loss: 0.111936  [19200/72604]
loss: 0.028494  [25600/72604]
loss: 0.017968  [32000/72604]
loss: 0.003370  [38400/72604]
loss: 0.001568  [44800/72604]
loss: 0.029152  [51200/72604]
loss: 0.016684  [57600/72604]
loss: 0.103315  [64000/72604]
loss: 0.012733  [70400/72604]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.037387 

Epoch 3
-------------------------------
loss: 0.070070  [    0/72604]
loss: 0.037615  [ 6400/72604]
loss: 0.007951  [12800/72604]
loss: 0.027417  [19200/72604]
loss: 0.001348  [25600/72604]
loss: 0.025073  [32000/72604]
loss: 0.003593  [38400/72604]
loss: 0.032111  [44800/72604]
loss: 0.024922  [51200/72604]
loss: 0.013704  [57600/72604]
loss: 0.010996  [64000/72604]
loss: 0.010965  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.029242 

Epoch 4
-------------------------------
loss: 0.015555  [    0/72604]
loss: 0.043080  [ 6400/72604]
loss: 0.057164  [12800/72604]
loss: 0.039368  [19200/72604]
loss: 0.004230  [25600/72604]
loss: 0.039891  [32000/72604]
loss: 0.066737  [38400/72604]
loss: 0.080596  [44800/72604]
loss: 0.024151  [51200/72604]
loss: 0.027269  [57600/72604]
loss: 0.006855  [64000/72604]
loss: 0.068518  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.034818 

Epoch 5
-------------------------------
loss: 0.083480  [    0/72604]
loss: 0.033154  [ 6400/72604]
loss: 0.006683  [12800/72604]
loss: 0.011715  [19200/72604]
loss: 0.050250  [25600/72604]
loss: 0.008993  [32000/72604]
loss: 0.016415  [38400/72604]
loss: 0.001337  [44800/72604]
loss: 0.004199  [51200/72604]
loss: 0.022971  [57600/72604]
loss: 0.006331  [64000/72604]
loss: 0.019932  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.036421 

Epoch 6
-------------------------------
loss: 0.016437  [    0/72604]
loss: 0.005926  [ 6400/72604]
loss: 0.019071  [12800/72604]
loss: 0.023200  [19200/72604]
loss: 0.008271  [25600/72604]
loss: 0.000982  [32000/72604]
loss: 0.009953  [38400/72604]
loss: 0.014001  [44800/72604]
loss: 0.022829  [51200/72604]
loss: 0.013498  [57600/72604]
loss: 0.004880  [64000/72604]
loss: 0.002010  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.050880 

Epoch 7
-------------------------------
loss: 0.001495  [    0/72604]
loss: 0.002580  [ 6400/72604]
loss: 0.006136  [12800/72604]
loss: 0.000224  [19200/72604]
loss: 0.006839  [25600/72604]
loss: 0.015066  [32000/72604]
loss: 0.003572  [38400/72604]
loss: 0.004291  [44800/72604]
loss: 0.021933  [51200/72604]
loss: 0.000759  [57600/72604]
loss: 0.013031  [64000/72604]
loss: 0.067536  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.079233 

Epoch 8
-------------------------------
loss: 0.009015  [    0/72604]
loss: 0.039729  [ 6400/72604]
loss: 0.000441  [12800/72604]
loss: 0.004975  [19200/72604]
loss: 0.165662  [25600/72604]
loss: 0.007921  [32000/72604]
loss: 0.003486  [38400/72604]
loss: 0.014756  [44800/72604]
loss: 0.065589  [51200/72604]
loss: 0.007915  [57600/72604]
loss: 0.207317  [64000/72604]
loss: 0.028666  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.047557 

Epoch 9
-------------------------------
loss: 0.000543  [    0/72604]
loss: 0.001235  [ 6400/72604]
loss: 0.001452  [12800/72604]
loss: 0.001633  [19200/72604]
loss: 0.004560  [25600/72604]
2022/09/20 14:16:40 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 14:16:58 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.165405  [12800/69609]
loss: 0.099806  [19200/69609]
loss: 0.168685  [25600/69609]
loss: 0.150411  [32000/69609]
loss: 0.037553  [38400/69609]
loss: 0.055418  [44800/69609]
loss: 0.043921  [51200/69609]
loss: 0.211827  [57600/69609]
loss: 0.077847  [64000/69609]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.135407 

Epoch 45
-------------------------------
loss: 0.080408  [    0/69609]
loss: 0.045849  [ 6400/69609]
loss: 0.167458  [12800/69609]
loss: 0.061325  [19200/69609]
loss: 0.070151  [25600/69609]
loss: 0.058987  [32000/69609]
loss: 0.113360  [38400/69609]
loss: 0.080773  [44800/69609]
loss: 0.124580  [51200/69609]
loss: 0.152859  [57600/69609]
loss: 0.118596  [64000/69609]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.138632 

Epoch 46
-------------------------------
loss: 0.101033  [    0/69609]
loss: 0.113533  [ 6400/69609]
loss: 0.069721  [12800/69609]
loss: 0.066827  [19200/69609]
loss: 0.089623  [25600/69609]
loss: 0.149083  [32000/69609]
loss: 0.102631  [38400/69609]
loss: 0.123193  [44800/69609]
loss: 0.209998  [51200/69609]
loss: 0.132009  [57600/69609]
loss: 0.052865  [64000/69609]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.145492 

Epoch 47
-------------------------------
loss: 0.108049  [    0/69609]
loss: 0.044501  [ 6400/69609]
loss: 0.082330  [12800/69609]
loss: 0.160966  [19200/69609]
loss: 0.176702  [25600/69609]
loss: 0.091283  [32000/69609]
loss: 0.127002  [38400/69609]
loss: 0.158454  [44800/69609]
loss: 0.170585  [51200/69609]
loss: 0.150737  [57600/69609]
loss: 0.177150  [64000/69609]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.140892 

Epoch 48
-------------------------------
loss: 0.073248  [    0/69609]
loss: 0.299101  [ 6400/69609]
loss: 0.151166  [12800/69609]
loss: 0.135850  [19200/69609]
loss: 0.202067  [25600/69609]
loss: 0.075318  [32000/69609]
loss: 0.111231  [38400/69609]
loss: 0.285759  [44800/69609]
loss: 0.062957  [51200/69609]
loss: 0.133433  [57600/69609]
loss: 0.106022  [64000/69609]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.147059 

Epoch 49
-------------------------------
loss: 0.067511  [    0/69609]
loss: 0.103076  [ 6400/69609]
loss: 0.112639  [12800/69609]
loss: 0.044285  [19200/69609]
loss: 0.128259  [25600/69609]
loss: 0.047080  [32000/69609]
loss: 0.128906  [38400/69609]
loss: 0.111567  [44800/69609]
loss: 0.159398  [51200/69609]
loss: 0.084055  [57600/69609]
loss: 0.182381  [64000/69609]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.137939 

Epoch 50
-------------------------------
loss: 0.108184  [    0/69609]
loss: 0.110217  [ 6400/69609]
loss: 0.087254  [12800/69609]
loss: 0.055970  [19200/69609]
loss: 0.106628  [25600/69609]
loss: 0.072829  [32000/69609]
loss: 0.110508  [38400/69609]
loss: 0.119327  [44800/69609]
loss: 0.151592  [51200/69609]
loss: 0.078751  [57600/69609]
loss: 0.277774  [64000/69609]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.139852 

Epoch 1
-------------------------------
loss: 0.665702  [    0/71414]
loss: 0.237770  [ 6400/71414]
loss: 0.141154  [12800/71414]
loss: 0.163968  [19200/71414]
loss: 0.105241  [25600/71414]
loss: 0.167786  [32000/71414]
loss: 0.179502  [38400/71414]
loss: 0.152055  [44800/71414]
loss: 0.143627  [51200/71414]
loss: 0.070572  [57600/71414]
loss: 0.194586  [64000/71414]
loss: 0.115451  [70400/71414]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.131044 

Epoch 2
-------------------------------
loss: 0.047703  [    0/71414]
loss: 0.096839  [ 6400/71414]
loss: 0.073877  [12800/71414]
loss: 0.116207  [19200/71414]
loss: 0.081897  [25600/71414]
loss: 0.027924  [32000/71414]
loss: 0.046486  [38400/71414]
loss: 0.087864  [44800/71414]
loss: 0.075045  [51200/71414]
loss: 0.156346  [57600/71414]
loss: 0.055056  [64000/71414]
loss: 0.080813  [70400/71414]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.116313 

Epoch 3
-------------------------------
loss: 0.108162  [    0/71414]
loss: 0.069588  [ 6400/71414]
loss: 0.122482  [12800/71414]
loss: 1.712697  [19200/71414]
loss: 0.023321  [25600/71414]
loss: 0.073990  [32000/71414]
loss: 0.207615  [38400/71414]
loss: 0.115033  [44800/71414]
loss: 0.213450  [51200/71414]
loss: 0.136513  [57600/71414]
loss: 0.043618  [64000/71414]
loss: 0.035145  [70400/71414]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.115591 

Epoch 4
-------------------------------
loss: 0.111471  [    0/71414]
loss: 0.050106  [ 6400/71414]
loss: 0.071027  [12800/71414]
loss: 0.060133  [19200/71414]
loss: 0.188373  [25600/71414]
loss: 0.086321  [32000/71414]
loss: 0.164575  [38400/71414]
loss: 0.058759  [44800/71414]
loss: 0.116783  [51200/71414]
loss: 0.037731  [57600/71414]
loss: 0.149065  [64000/71414]
loss: 0.270167  [70400/71414]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.131974 

Epoch 5
-------------------------------
loss: 1.651289  [    0/71414]
loss: 0.087880  [ 6400/71414]
loss: 0.137575  [12800/71414]
loss: 0.080714  [19200/71414]
loss: 0.068495  [25600/71414]
loss: 0.059449  [32000/71414]
loss: 0.052125  [38400/71414]
loss: 0.133557  [44800/71414]
loss: 0.079729  [51200/71414]
loss: 0.092831  [57600/71414]
loss: 0.113449  [64000/71414]
loss: 0.057474  [70400/71414]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.104670 

Epoch 6
-------------------------------
loss: 0.055687  [    0/71414]
loss: 0.038531  [ 6400/71414]
loss: 0.112427  [12800/71414]
loss: 0.063571  [19200/71414]
loss: 0.084493  [25600/71414]
loss: 0.081575  [32000/71414]
loss: 0.161154  [38400/71414]
loss: 0.064128  [44800/71414]
loss: 0.207785  [51200/71414]
loss: 0.045502  [57600/71414]
loss: 0.028048  [64000/71414]
loss: 0.044467  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.104532 

Epoch 7
-------------------------------
loss: 0.054463  [    0/71414]
loss: 0.068346  [ 6400/71414]
loss: 0.068082  [12800/71414]
loss: 0.114372  [19200/71414]
loss: 0.146994  [25600/71414]
loss: 0.061055  [32000/71414]
loss: 0.052277  [38400/71414]
loss: 0.218168  [44800/71414]
loss: 0.081606  [51200/71414]
loss: 0.096680  [57600/71414]
loss: 0.025551  [64000/71414]
loss: 0.207531  [70400/71414]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.103031 

Epoch 8
-------------------------------
loss: 0.050660  [    0/71414]
loss: 0.063579  [ 6400/71414]
loss: 1.606606  [12800/71414]
loss: 0.083470  [19200/71414]
loss: 0.077993  [25600/71414]
loss: 0.066814  [32000/71414]
loss: 0.074480  [38400/71414]
loss: 0.100544  [44800/71414]
loss: 0.130923  [51200/71414]
loss: 0.072754  [57600/71414]
loss: 0.035264  [64000/71414]
loss: 0.084271  [70400/71414]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102205 

Epoch 9
-------------------------------
loss: 1.653939  [    0/71414]
loss: 0.131841  [ 6400/71414]
loss: 0.203828  [12800/71414]
loss: 0.023171  [19200/71414]
loss: 1.650270  [25600/71414]
loss: 0.058237  [32000/71414]
loss: 0.059975  [38400/71414]
loss: 0.049606  [44800/71414]
loss: 0.062977  [51200/71414]
loss: 0.059439  [57600/71414]
loss: 0.108850  [64000/71414]
loss: 0.147854  [70400/71414]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.100258 

Epoch 10
-------------------------------
loss: 0.108904  [    0/71414]
loss: 0.190293  [ 6400/71414]
loss: 0.081789  [12800/71414]
loss: 0.154629  [19200/71414]
loss: 0.007672  [25600/71414]
loss: 0.077306  [32000/71414]
loss: 0.075244  [38400/71414]
loss: 0.134873  [44800/71414]
loss: 0.016908  [51200/71414]
loss: 0.040485  [57600/71414]
loss: 0.079121  [64000/71414]
loss: 0.104355  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102558 

Epoch 11
-------------------------------
loss: 0.039890  [    0/71414]
loss: 0.051402  [ 6400/71414]
loss: 0.088621  [12800/71414]
loss: 0.084152  [19200/71414]
loss: 0.021730  [25600/71414]
loss: 0.054705  [32000/71414]
loss: 0.059461  [38400/71414]
loss: 0.133276  [44800/71414]
loss: 1.593442  [51200/71414]
loss: 0.022636  [57600/71414]
loss: 0.174149  [64000/71414]
loss: 0.034717  [70400/71414]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.105045 

Epoch 12
-------------------------------
loss: 0.062254  [    0/71414]
loss: 0.091836  [ 6400/71414]
loss: 0.046740  [12800/71414]
loss: 0.139408  [19200/71414]
loss: 0.040520  [25600/71414]
loss: 0.023877  [32000/71414]
loss: 0.110386  [38400/71414]
loss: 0.088953  [44800/71414]
loss: 0.068647  [51200/71414]
loss: 0.214986  [57600/71414]
loss: 0.039258  [25600/71031]
loss: 0.053479  [32000/71031]
loss: 0.030302  [38400/71031]
loss: 0.071181  [44800/71031]
loss: 0.034775  [51200/71031]
loss: 0.050283  [57600/71031]
loss: 0.095640  [64000/71031]
loss: 0.115420  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.127652 

Epoch 42
-------------------------------
loss: 0.011048  [    0/71031]
loss: 0.004950  [ 6400/71031]
loss: 0.026850  [12800/71031]
loss: 0.005125  [19200/71031]
loss: 0.018065  [25600/71031]
loss: 0.002578  [32000/71031]
loss: 0.029614  [38400/71031]
loss: 0.059363  [44800/71031]
loss: 0.237083  [51200/71031]
loss: 0.056707  [57600/71031]
loss: 0.209723  [64000/71031]
loss: 0.040718  [70400/71031]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.126973 

Epoch 43
-------------------------------
loss: 0.078662  [    0/71031]
loss: 0.049773  [ 6400/71031]
loss: 0.097201  [12800/71031]
loss: 0.019047  [19200/71031]
loss: 0.025881  [25600/71031]
loss: 0.033192  [32000/71031]
loss: 0.102805  [38400/71031]
loss: 0.017762  [44800/71031]
loss: 0.018469  [51200/71031]
loss: 0.065152  [57600/71031]
loss: 0.167189  [64000/71031]
loss: 0.064920  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.135462 

Epoch 44
-------------------------------
loss: 0.044795  [    0/71031]
loss: 0.057552  [ 6400/71031]
loss: 0.054991  [12800/71031]
loss: 0.061830  [19200/71031]
loss: 0.099307  [25600/71031]
loss: 0.058646  [32000/71031]
loss: 0.043567  [38400/71031]
loss: 0.072595  [44800/71031]
loss: 0.058732  [51200/71031]
loss: 0.075756  [57600/71031]
loss: 0.065193  [64000/71031]
loss: 0.061869  [70400/71031]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.128582 

Epoch 45
-------------------------------
loss: 0.031550  [    0/71031]
loss: 0.047512  [ 6400/71031]
loss: 0.037907  [12800/71031]
loss: 0.018847  [19200/71031]
loss: 0.048075  [25600/71031]
loss: 0.065781  [32000/71031]
loss: 0.108965  [38400/71031]
loss: 0.088711  [44800/71031]
loss: 0.043549  [51200/71031]
loss: 0.044004  [57600/71031]
loss: 0.027629  [64000/71031]
loss: 0.088095  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.136850 

Epoch 46
-------------------------------
loss: 0.119172  [    0/71031]
loss: 0.035415  [ 6400/71031]
loss: 0.023012  [12800/71031]
loss: 0.026183  [19200/71031]
loss: 0.123977  [25600/71031]
loss: 0.068113  [32000/71031]
loss: 0.073406  [38400/71031]
loss: 0.014063  [44800/71031]
loss: 0.037793  [51200/71031]
loss: 0.056629  [57600/71031]
loss: 0.089133  [64000/71031]
loss: 0.095586  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.131911 

Epoch 47
-------------------------------
loss: 0.040640  [    0/71031]
loss: 0.029673  [ 6400/71031]
loss: 0.062847  [12800/71031]
loss: 0.057869  [19200/71031]
loss: 0.100651  [25600/71031]
loss: 0.054932  [32000/71031]
loss: 0.055991  [38400/71031]
loss: 0.084618  [44800/71031]
loss: 0.165617  [51200/71031]
loss: 0.010527  [57600/71031]
loss: 0.110398  [64000/71031]
loss: 0.027595  [70400/71031]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.134584 

Epoch 48
-------------------------------
loss: 0.011698  [    0/71031]
loss: 0.042875  [ 6400/71031]
loss: 0.054500  [12800/71031]
loss: 0.106545  [19200/71031]
loss: 0.020551  [25600/71031]
loss: 0.093819  [32000/71031]
loss: 0.175341  [38400/71031]
loss: 0.056766  [44800/71031]
loss: 0.066347  [51200/71031]
loss: 0.031501  [57600/71031]
loss: 0.069206  [64000/71031]
loss: 0.019208  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.138816 

Epoch 49
-------------------------------
loss: 1.572567  [    0/71031]
loss: 0.038491  [ 6400/71031]
loss: 0.072480  [12800/71031]
loss: 0.087053  [19200/71031]
loss: 0.019134  [25600/71031]
loss: 0.108064  [32000/71031]
loss: 0.012648  [38400/71031]
loss: 0.103645  [44800/71031]
loss: 0.095104  [51200/71031]
loss: 0.022330  [57600/71031]
loss: 0.030017  [64000/71031]
loss: 0.103334  [70400/71031]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.124722 

Epoch 50
-------------------------------
loss: 0.120231  [    0/71031]
loss: 0.029622  [ 6400/71031]
loss: 0.053249  [12800/71031]
loss: 0.045247  [19200/71031]
loss: 0.015754  [25600/71031]
loss: 0.100319  [32000/71031]
loss: 0.034011  [38400/71031]
loss: 0.066029  [44800/71031]
loss: 0.004945  [51200/71031]
loss: 0.010254  [57600/71031]
loss: 0.075838  [64000/71031]
loss: 0.020225  [70400/71031]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.131966 

Epoch 1
-------------------------------
loss: 0.714415  [    0/70010]
loss: 0.263891  [ 6400/70010]
loss: 0.179828  [12800/70010]
loss: 0.088485  [19200/70010]
loss: 0.136407  [25600/70010]
loss: 0.176806  [32000/70010]
loss: 0.087531  [38400/70010]
loss: 0.172232  [44800/70010]
loss: 0.129178  [51200/70010]
loss: 0.167692  [57600/70010]
loss: 0.220073  [64000/70010]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112171 

Epoch 2
-------------------------------
loss: 0.191712  [    0/70010]
loss: 0.086897  [ 6400/70010]
loss: 0.048592  [12800/70010]
loss: 0.063738  [19200/70010]
loss: 0.115604  [25600/70010]
loss: 0.101318  [32000/70010]
loss: 0.092522  [38400/70010]
loss: 0.174958  [44800/70010]
loss: 0.133364  [51200/70010]
loss: 0.355009  [57600/70010]
loss: 0.127531  [64000/70010]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.098342 

Epoch 3
-------------------------------
loss: 0.104890  [    0/70010]
loss: 0.087755  [ 6400/70010]
loss: 0.212558  [12800/70010]
loss: 0.068095  [19200/70010]
loss: 0.072650  [25600/70010]
loss: 0.206719  [32000/70010]
loss: 0.123380  [38400/70010]
loss: 0.054237  [44800/70010]
loss: 0.161377  [51200/70010]
loss: 0.025910  [57600/70010]
loss: 0.141821  [64000/70010]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.110444 

Epoch 4
-------------------------------
loss: 0.075374  [    0/70010]
loss: 0.071915  [ 6400/70010]
loss: 0.067392  [12800/70010]
loss: 0.189063  [19200/70010]
loss: 0.104630  [25600/70010]
loss: 0.103942  [32000/70010]
loss: 0.094563  [38400/70010]
loss: 0.128131  [44800/70010]
loss: 0.225247  [51200/70010]
loss: 0.143782  [57600/70010]
loss: 0.141419  [64000/70010]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.095756 

Epoch 5
-------------------------------
loss: 0.058284  [    0/70010]
loss: 0.108500  [ 6400/70010]
loss: 0.116514  [12800/70010]
loss: 0.025932  [19200/70010]
loss: 0.184458  [25600/70010]
loss: 0.090490  [32000/70010]
loss: 0.336178  [38400/70010]
loss: 0.052349  [44800/70010]
loss: 0.171528  [51200/70010]
loss: 0.051023  [57600/70010]
loss: 0.177931  [64000/70010]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.096412 

Epoch 6
-------------------------------
loss: 0.153961  [    0/70010]
loss: 0.038139  [ 6400/70010]
loss: 0.110896  [12800/70010]
loss: 0.098620  [19200/70010]
loss: 0.032338  [25600/70010]
loss: 0.169600  [32000/70010]
loss: 0.222343  [38400/70010]
loss: 0.047814  [44800/70010]
loss: 0.052789  [51200/70010]
loss: 0.060929  [57600/70010]
loss: 0.083781  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.087928 

Epoch 7
-------------------------------
loss: 0.023126  [    0/70010]
loss: 0.093948  [ 6400/70010]
loss: 0.065677  [12800/70010]
loss: 0.091680  [19200/70010]
loss: 0.075515  [25600/70010]
loss: 0.084385  [32000/70010]
loss: 0.068273  [38400/70010]
loss: 0.085289  [44800/70010]
loss: 0.093638  [51200/70010]
loss: 0.090559  [57600/70010]
loss: 0.138613  [64000/70010]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089911 

Epoch 8
-------------------------------
loss: 0.140715  [    0/70010]
loss: 0.079639  [ 6400/70010]
loss: 0.318421  [12800/70010]
loss: 0.137466  [19200/70010]
loss: 0.178180  [25600/70010]
loss: 0.196268  [32000/70010]
loss: 0.088003  [38400/70010]
loss: 0.130482  [44800/70010]
loss: 0.099677  [51200/70010]
loss: 0.055173  [57600/70010]
loss: 0.095573  [64000/70010]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.087441 

Epoch 9
-------------------------------
loss: 0.036851  [    0/70010]
loss: 0.040453  [ 6400/70010]
loss: 0.187173  [12800/70010]
loss: 0.162750  [19200/70010]
loss: 0.217100  [25600/70010]
loss: 0.237152  [32000/70010]
loss: 0.131441  [38400/70010]
loss: 0.101723  [44800/70010]
loss: 0.008794  [51200/70010]
loss: 0.093740  [57600/70010]
loss: 0.143755  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.085728 

loss: 0.015997  [25600/71194]
loss: 0.062109  [32000/71194]
loss: 0.086954  [38400/71194]
loss: 0.030959  [44800/71194]
loss: 0.051314  [51200/71194]
loss: 0.120848  [57600/71194]
loss: 0.020644  [64000/71194]
loss: 0.087480  [70400/71194]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.113088 

Epoch 42
-------------------------------
loss: 0.040517  [    0/71194]
loss: 0.025824  [ 6400/71194]
loss: 0.076805  [12800/71194]
loss: 0.009063  [19200/71194]
loss: 0.074849  [25600/71194]
loss: 0.056289  [32000/71194]
loss: 0.191869  [38400/71194]
loss: 0.066356  [44800/71194]
loss: 0.172096  [51200/71194]
loss: 0.122408  [57600/71194]
loss: 0.117479  [64000/71194]
loss: 0.062616  [70400/71194]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.103556 

Epoch 43
-------------------------------
loss: 0.036668  [    0/71194]
loss: 0.127369  [ 6400/71194]
loss: 0.064890  [12800/71194]
loss: 0.099702  [19200/71194]
loss: 0.013603  [25600/71194]
loss: 0.082893  [32000/71194]
loss: 0.049599  [38400/71194]
loss: 0.012334  [44800/71194]
loss: 0.011170  [51200/71194]
loss: 0.065213  [57600/71194]
loss: 0.061239  [64000/71194]
loss: 0.016476  [70400/71194]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.101725 

Epoch 44
-------------------------------
loss: 0.075728  [    0/71194]
loss: 0.041424  [ 6400/71194]
loss: 0.033411  [12800/71194]
loss: 0.007894  [19200/71194]
loss: 0.163549  [25600/71194]
loss: 0.078884  [32000/71194]
loss: 0.018525  [38400/71194]
loss: 0.083539  [44800/71194]
loss: 0.048343  [51200/71194]
loss: 0.066503  [57600/71194]
loss: 0.034576  [64000/71194]
loss: 0.060147  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.107940 

Epoch 45
-------------------------------
loss: 0.029123  [    0/71194]
loss: 0.040036  [ 6400/71194]
loss: 0.048073  [12800/71194]
loss: 0.056471  [19200/71194]
loss: 1.690340  [25600/71194]
loss: 0.042746  [32000/71194]
loss: 0.021903  [38400/71194]
loss: 0.042816  [44800/71194]
loss: 0.062891  [51200/71194]
loss: 0.037825  [57600/71194]
loss: 0.066355  [64000/71194]
loss: 0.046149  [70400/71194]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.107059 

Epoch 46
-------------------------------
loss: 0.047438  [    0/71194]
loss: 0.015778  [ 6400/71194]
loss: 0.014420  [12800/71194]
loss: 0.119796  [19200/71194]
loss: 0.041560  [25600/71194]
loss: 0.130478  [32000/71194]
loss: 0.030784  [38400/71194]
loss: 0.005422  [44800/71194]
loss: 0.071724  [51200/71194]
loss: 0.086691  [57600/71194]
loss: 0.037146  [64000/71194]
loss: 0.021163  [70400/71194]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.110035 

Epoch 47
-------------------------------
loss: 0.086423  [    0/71194]
loss: 0.044405  [ 6400/71194]
loss: 0.074033  [12800/71194]
loss: 0.087830  [19200/71194]
loss: 0.023250  [25600/71194]
loss: 0.011921  [32000/71194]
loss: 0.057771  [38400/71194]
loss: 0.029743  [44800/71194]
loss: 0.033604  [51200/71194]
loss: 0.019222  [57600/71194]
loss: 0.008404  [64000/71194]
loss: 0.033068  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.109943 

Epoch 48
-------------------------------
loss: 0.079293  [    0/71194]
loss: 0.019624  [ 6400/71194]
loss: 0.081050  [12800/71194]
loss: 0.038816  [19200/71194]
loss: 0.007336  [25600/71194]
loss: 0.054380  [32000/71194]
loss: 0.085979  [38400/71194]
loss: 0.031900  [44800/71194]
loss: 0.028329  [51200/71194]
loss: 0.037317  [57600/71194]
loss: 0.023585  [64000/71194]
loss: 0.060896  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.110725 

Epoch 49
-------------------------------
loss: 0.114004  [    0/71194]
loss: 0.063089  [ 6400/71194]
loss: 0.036417  [12800/71194]
loss: 0.137631  [19200/71194]
loss: 0.006996  [25600/71194]
loss: 0.061027  [32000/71194]
loss: 0.063725  [38400/71194]
loss: 0.007825  [44800/71194]
loss: 0.061369  [51200/71194]
loss: 0.022124  [57600/71194]
loss: 0.053382  [64000/71194]
loss: 0.015232  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.107543 

Epoch 50
-------------------------------
loss: 0.115538  [    0/71194]
loss: 0.018033  [ 6400/71194]
loss: 0.042341  [12800/71194]
loss: 0.005423  [19200/71194]
loss: 0.028543  [25600/71194]
loss: 0.021843  [32000/71194]
loss: 0.132440  [38400/71194]
loss: 0.070506  [44800/71194]
loss: 0.027145  [51200/71194]
loss: 0.104111  [57600/71194]
loss: 0.075251  [64000/71194]
loss: 0.100951  [70400/71194]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.107415 

Epoch 1
-------------------------------
loss: 0.701099  [    0/70446]
loss: 0.383482  [ 6400/70446]
loss: 0.339846  [12800/70446]
loss: 0.144411  [19200/70446]
loss: 0.298385  [25600/70446]
loss: 0.155614  [32000/70446]
loss: 0.093634  [38400/70446]
loss: 0.350830  [44800/70446]
loss: 0.188309  [51200/70446]
loss: 0.273355  [57600/70446]
loss: 0.166513  [64000/70446]
loss: 0.188578  [50600/70446]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.189049 

Epoch 2
-------------------------------
loss: 0.239343  [    0/70446]
loss: 0.197266  [ 6400/70446]
loss: 0.258432  [12800/70446]
loss: 0.123211  [19200/70446]
loss: 0.274864  [25600/70446]
loss: 0.158116  [32000/70446]
loss: 0.285648  [38400/70446]
loss: 0.135876  [44800/70446]
loss: 0.113833  [51200/70446]
loss: 0.106983  [57600/70446]
loss: 0.098087  [64000/70446]
loss: 0.117013  [50600/70446]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.173430 

Epoch 3
-------------------------------
loss: 0.107210  [    0/70446]
loss: 0.167995  [ 6400/70446]
loss: 0.189780  [12800/70446]
loss: 0.255700  [19200/70446]
loss: 0.171469  [25600/70446]
loss: 0.196871  [32000/70446]
loss: 0.305904  [38400/70446]
loss: 0.252591  [44800/70446]
loss: 0.081212  [51200/70446]
loss: 0.181762  [57600/70446]
loss: 0.172282  [64000/70446]
loss: 0.199341  [50600/70446]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.170678 

Epoch 4
-------------------------------
loss: 0.172609  [    0/70446]
loss: 0.155519  [ 6400/70446]
loss: 0.128799  [12800/70446]
loss: 0.188877  [19200/70446]
loss: 0.180166  [25600/70446]
loss: 0.138266  [32000/70446]
loss: 0.208351  [38400/70446]
loss: 0.219850  [44800/70446]
loss: 0.196068  [51200/70446]
loss: 0.105303  [57600/70446]
loss: 0.094025  [64000/70446]
loss: 0.201895  [50600/70446]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.171457 

Epoch 5
-------------------------------
loss: 0.236608  [    0/70446]
loss: 0.077194  [ 6400/70446]
loss: 0.087118  [12800/70446]
loss: 0.144531  [19200/70446]
loss: 0.112211  [25600/70446]
loss: 0.227571  [32000/70446]
loss: 0.225801  [38400/70446]
loss: 0.171850  [44800/70446]
loss: 0.106799  [51200/70446]
loss: 0.257126  [57600/70446]
loss: 0.136170  [64000/70446]
loss: 0.084086  [50600/70446]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.161777 

Epoch 6
-------------------------------
loss: 0.099829  [    0/70446]
loss: 0.143946  [ 6400/70446]
loss: 0.226282  [12800/70446]
loss: 0.308818  [19200/70446]
loss: 0.077257  [25600/70446]
loss: 0.183859  [32000/70446]
loss: 0.127738  [38400/70446]
loss: 0.106249  [44800/70446]
loss: 0.120909  [51200/70446]
loss: 0.215588  [57600/70446]
loss: 0.233142  [64000/70446]
loss: 0.142605  [50600/70446]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.154908 

Epoch 7
-------------------------------
loss: 0.080957  [    0/70446]
loss: 0.060126  [ 6400/70446]
loss: 0.191171  [12800/70446]
loss: 0.106632  [19200/70446]
loss: 0.096659  [25600/70446]
loss: 0.165944  [32000/70446]
loss: 0.062152  [38400/70446]
loss: 0.201137  [44800/70446]
loss: 0.215027  [51200/70446]
loss: 0.129646  [57600/70446]
loss: 0.130190  [64000/70446]
loss: 0.104579  [50600/70446]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.153514 

Epoch 8
-------------------------------
loss: 0.096517  [    0/70446]
loss: 0.175630  [ 6400/70446]
loss: 0.080652  [12800/70446]
loss: 0.151072  [19200/70446]
loss: 0.077417  [25600/70446]
loss: 0.077833  [32000/70446]
loss: 0.134930  [38400/70446]
loss: 0.083178  [44800/70446]
loss: 0.085055  [51200/70446]
loss: 0.137468  [57600/70446]
loss: 0.132682  [64000/70446]
loss: 0.165533  [50600/70446]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.155838 

Epoch 9
-------------------------------
loss: 0.129225  [    0/70446]
loss: 0.088667  [ 6400/70446]
loss: 0.171027  [12800/70446]
loss: 0.106907  [19200/70446]
loss: 0.268681  [25600/70446]
loss: 0.033648  [25600/70506]
loss: 0.006508  [32000/70506]
loss: 0.028625  [38400/70506]
loss: 0.015243  [44800/70506]
loss: 0.046333  [51200/70506]
loss: 0.072176  [57600/70506]
loss: 0.085945  [64000/70506]
loss: 0.123988  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066395 

Epoch 42
-------------------------------
loss: 0.015600  [    0/70506]
loss: 0.078977  [ 6400/70506]
loss: 0.035598  [12800/70506]
loss: 0.006589  [19200/70506]
loss: 0.018572  [25600/70506]
loss: 0.038670  [32000/70506]
loss: 0.008727  [38400/70506]
loss: 0.133741  [44800/70506]
loss: 0.042773  [51200/70506]
loss: 0.057291  [57600/70506]
loss: 0.017768  [64000/70506]
loss: 0.143203  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.064845 

Epoch 43
-------------------------------
loss: 0.039269  [    0/70506]
loss: 0.029796  [ 6400/70506]
loss: 0.014580  [12800/70506]
loss: 0.009825  [19200/70506]
loss: 0.017833  [25600/70506]
loss: 0.068262  [32000/70506]
loss: 0.049950  [38400/70506]
loss: 0.023672  [44800/70506]
loss: 0.031987  [51200/70506]
loss: 0.043120  [57600/70506]
loss: 0.017854  [64000/70506]
loss: 0.047520  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068315 

Epoch 44
-------------------------------
loss: 0.015254  [    0/70506]
loss: 0.018778  [ 6400/70506]
loss: 0.010265  [12800/70506]
loss: 0.023573  [19200/70506]
loss: 0.084581  [25600/70506]
loss: 0.007754  [32000/70506]
loss: 0.063347  [38400/70506]
loss: 0.038884  [44800/70506]
loss: 0.036037  [51200/70506]
loss: 0.050315  [57600/70506]
loss: 0.020350  [64000/70506]
loss: 0.047821  [70400/70506]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.089214 

Epoch 45
-------------------------------
loss: 0.040354  [    0/70506]
loss: 0.032686  [ 6400/70506]
loss: 0.035729  [12800/70506]
loss: 0.096557  [19200/70506]
loss: 0.011207  [25600/70506]
loss: 0.024728  [32000/70506]
loss: 0.007944  [38400/70506]
loss: 0.037642  [44800/70506]
loss: 0.021983  [51200/70506]
loss: 0.004091  [57600/70506]
loss: 0.089201  [64000/70506]
loss: 0.023860  [70400/70506]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.074349 

Epoch 46
-------------------------------
loss: 0.024115  [    0/70506]
loss: 0.015100  [ 6400/70506]
loss: 0.062358  [12800/70506]
loss: 0.041192  [19200/70506]
loss: 0.015124  [25600/70506]
loss: 0.016823  [32000/70506]
loss: 0.045231  [38400/70506]
loss: 0.107168  [44800/70506]
loss: 0.057174  [51200/70506]
loss: 0.052084  [57600/70506]
loss: 0.066860  [64000/70506]
loss: 0.030109  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.060682 

Epoch 47
-------------------------------
loss: 0.015729  [    0/70506]
loss: 0.022202  [ 6400/70506]
loss: 0.012916  [12800/70506]
loss: 0.074023  [19200/70506]
loss: 0.009212  [25600/70506]
loss: 0.008798  [32000/70506]
loss: 0.019103  [38400/70506]
loss: 0.007033  [44800/70506]
loss: 0.202301  [51200/70506]
loss: 0.048961  [57600/70506]
loss: 0.007329  [64000/70506]
loss: 0.003366  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066665 

Epoch 48
-------------------------------
loss: 0.044076  [    0/70506]
loss: 0.011754  [ 6400/70506]
loss: 0.048286  [12800/70506]
loss: 0.005063  [19200/70506]
loss: 0.026239  [25600/70506]
loss: 0.017515  [32000/70506]
loss: 0.054034  [38400/70506]
loss: 0.002818  [44800/70506]
loss: 0.084636  [51200/70506]
loss: 0.073046  [57600/70506]
loss: 0.108606  [64000/70506]
loss: 0.035667  [70400/70506]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066122 

Epoch 49
-------------------------------
loss: 0.009861  [    0/70506]
loss: 0.012908  [ 6400/70506]
loss: 0.105131  [12800/70506]
loss: 0.099423  [19200/70506]
loss: 0.007980  [25600/70506]
loss: 0.022720  [32000/70506]
loss: 0.032177  [38400/70506]
loss: 0.097022  [44800/70506]
loss: 0.050904  [51200/70506]
loss: 0.071123  [57600/70506]
loss: 0.066994  [64000/70506]
loss: 0.008560  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.065252 

Epoch 50
-------------------------------
loss: 0.068130  [    0/70506]
loss: 0.004213  [ 6400/70506]
loss: 0.006467  [12800/70506]
loss: 0.053173  [19200/70506]
loss: 0.133309  [25600/70506]
loss: 0.012631  [32000/70506]
loss: 0.016941  [38400/70506]
loss: 0.028344  [44800/70506]
loss: 0.057590  [51200/70506]
loss: 0.037483  [57600/70506]
loss: 0.005962  [64000/70506]
loss: 0.014284  [70400/70506]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.064915 

Epoch 1
-------------------------------
loss: 0.708706  [    0/71130]
loss: 0.146137  [ 6400/71130]
loss: 0.106651  [12800/71130]
loss: 0.429592  [19200/71130]
loss: 0.096314  [25600/71130]
loss: 0.179796  [32000/71130]
loss: 0.022315  [38400/71130]
loss: 0.105126  [44800/71130]
loss: 0.145405  [51200/71130]
loss: 0.104101  [57600/71130]
loss: 0.120332  [64000/71130]
loss: 0.065188  [70400/71130]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.090096 

Epoch 2
-------------------------------
loss: 0.154873  [    0/71130]
loss: 0.037050  [ 6400/71130]
loss: 0.053820  [12800/71130]
loss: 0.143031  [19200/71130]
loss: 0.099256  [25600/71130]
loss: 0.161114  [32000/71130]
loss: 0.096891  [38400/71130]
loss: 0.057603  [44800/71130]
loss: 0.128047  [51200/71130]
loss: 0.031804  [57600/71130]
loss: 0.123683  [64000/71130]
loss: 0.096447  [70400/71130]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067090 

Epoch 3
-------------------------------
loss: 0.070486  [    0/71130]
loss: 0.078673  [ 6400/71130]
loss: 0.131134  [12800/71130]
loss: 0.042656  [19200/71130]
loss: 0.159553  [25600/71130]
loss: 0.184785  [32000/71130]
loss: 0.035685  [38400/71130]
loss: 0.076597  [44800/71130]
loss: 0.118784  [51200/71130]
loss: 0.163993  [57600/71130]
loss: 0.051585  [64000/71130]
loss: 0.111173  [70400/71130]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.070131 

Epoch 4
-------------------------------
loss: 0.030737  [    0/71130]
loss: 0.033242  [ 6400/71130]
loss: 0.021228  [12800/71130]
loss: 0.080825  [19200/71130]
loss: 0.022279  [25600/71130]
loss: 0.188922  [32000/71130]
loss: 0.097733  [38400/71130]
loss: 0.038097  [44800/71130]
loss: 0.052542  [51200/71130]
loss: 0.126805  [57600/71130]
loss: 0.034652  [64000/71130]
loss: 0.013980  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.059424 

Epoch 5
-------------------------------
loss: 0.033814  [    0/71130]
loss: 0.029983  [ 6400/71130]
loss: 0.167266  [12800/71130]
loss: 0.065706  [19200/71130]
loss: 0.113445  [25600/71130]
loss: 0.026795  [32000/71130]
loss: 0.078236  [38400/71130]
loss: 0.039411  [44800/71130]
loss: 0.056906  [51200/71130]
loss: 0.115488  [57600/71130]
loss: 0.047892  [64000/71130]
loss: 0.049021  [70400/71130]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.063313 

Epoch 6
-------------------------------
loss: 0.079490  [    0/71130]
loss: 0.041539  [ 6400/71130]
loss: 0.035685  [12800/71130]
loss: 0.035291  [19200/71130]
loss: 0.074638  [25600/71130]
loss: 0.026767  [32000/71130]
loss: 0.070686  [38400/71130]
loss: 0.062702  [44800/71130]
loss: 0.040096  [51200/71130]
loss: 0.123270  [57600/71130]
loss: 0.065521  [64000/71130]
loss: 0.068613  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067514 

Epoch 7
-------------------------------
loss: 0.037704  [    0/71130]
loss: 0.070609  [ 6400/71130]
loss: 0.094823  [12800/71130]
loss: 0.033884  [19200/71130]
loss: 0.047271  [25600/71130]
loss: 0.092323  [32000/71130]
loss: 0.025616  [38400/71130]
loss: 0.063741  [44800/71130]
loss: 0.070737  [51200/71130]
loss: 0.008968  [57600/71130]
loss: 0.037969  [64000/71130]
loss: 0.040545  [70400/71130]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.063021 

Epoch 8
-------------------------------
loss: 0.070828  [    0/71130]
loss: 0.077523  [ 6400/71130]
loss: 0.068832  [12800/71130]
loss: 0.033655  [19200/71130]
loss: 0.075072  [25600/71130]
loss: 0.111257  [32000/71130]
loss: 0.048085  [38400/71130]
loss: 0.058898  [44800/71130]
loss: 0.018403  [51200/71130]
loss: 0.109639  [57600/71130]
loss: 0.188858  [64000/71130]
loss: 0.095708  [70400/71130]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.061359 

Epoch 9
-------------------------------
loss: 0.110275  [    0/71130]
loss: 0.050200  [ 6400/71130]
loss: 0.070930  [12800/71130]
loss: 0.107913  [19200/71130]
loss: 0.021013  [25600/71130]
loss: 0.160930  [25600/70755]
loss: 0.095263  [32000/70755]
loss: 0.152132  [38400/70755]
loss: 0.079178  [44800/70755]
loss: 0.091973  [51200/70755]
loss: 0.069946  [57600/70755]
loss: 0.127782  [64000/70755]
loss: 0.092392  [70400/70755]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.145806 

Epoch 42
-------------------------------
loss: 0.146457  [    0/70755]
loss: 0.115742  [ 6400/70755]
loss: 0.107642  [12800/70755]
loss: 0.091485  [19200/70755]
loss: 0.178891  [25600/70755]
loss: 0.117867  [32000/70755]
loss: 0.127343  [38400/70755]
loss: 0.232713  [44800/70755]
loss: 0.075357  [51200/70755]
loss: 0.158645  [57600/70755]
loss: 0.070016  [64000/70755]
loss: 0.046579  [70400/70755]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.136931 

Epoch 43
-------------------------------
loss: 0.050068  [    0/70755]
loss: 0.040779  [ 6400/70755]
loss: 0.065605  [12800/70755]
loss: 0.029404  [19200/70755]
loss: 0.170296  [25600/70755]
loss: 0.171004  [32000/70755]
loss: 0.089126  [38400/70755]
loss: 0.094677  [44800/70755]
loss: 0.081078  [51200/70755]
loss: 0.126847  [57600/70755]
loss: 0.147436  [64000/70755]
loss: 0.165237  [70400/70755]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.148927 

Epoch 44
-------------------------------
loss: 0.058927  [    0/70755]
loss: 0.169183  [ 6400/70755]
loss: 0.141326  [12800/70755]
loss: 0.121119  [19200/70755]
loss: 0.027879  [25600/70755]
loss: 0.168098  [32000/70755]
loss: 0.053862  [38400/70755]
loss: 0.250628  [44800/70755]
loss: 0.087344  [51200/70755]
loss: 0.127382  [57600/70755]
loss: 0.140767  [64000/70755]
loss: 0.067421  [70400/70755]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.132319 

Epoch 45
-------------------------------
loss: 0.076329  [    0/70755]
loss: 0.143721  [ 6400/70755]
loss: 0.091745  [12800/70755]
loss: 0.128301  [19200/70755]
loss: 0.085653  [25600/70755]
loss: 0.159511  [32000/70755]
loss: 0.100824  [38400/70755]
loss: 0.118871  [44800/70755]
loss: 0.134470  [51200/70755]
loss: 0.088271  [57600/70755]
loss: 0.064390  [64000/70755]
loss: 0.059399  [70400/70755]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.134302 

Epoch 46
-------------------------------
loss: 0.105850  [    0/70755]
loss: 0.052054  [ 6400/70755]
loss: 0.074160  [12800/70755]
loss: 0.118792  [19200/70755]
loss: 0.095347  [25600/70755]
loss: 0.149438  [32000/70755]
loss: 0.112706  [38400/70755]
loss: 0.050073  [44800/70755]
loss: 0.177991  [51200/70755]
loss: 0.152032  [57600/70755]
loss: 0.218556  [64000/70755]
loss: 0.142786  [70400/70755]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.136487 

Epoch 47
-------------------------------
loss: 0.168213  [    0/70755]
loss: 0.072838  [ 6400/70755]
loss: 0.056521  [12800/70755]
loss: 0.154098  [19200/70755]
loss: 0.113353  [25600/70755]
loss: 0.128648  [32000/70755]
loss: 0.046062  [38400/70755]
loss: 0.079393  [44800/70755]
loss: 0.209537  [51200/70755]
loss: 0.026962  [57600/70755]
loss: 0.222489  [64000/70755]
loss: 0.171228  [70400/70755]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.137343 

Epoch 48
-------------------------------
loss: 0.058176  [    0/70755]
loss: 0.057963  [ 6400/70755]
loss: 0.110173  [12800/70755]
loss: 0.116359  [19200/70755]
loss: 0.068916  [25600/70755]
loss: 0.044989  [32000/70755]
loss: 0.303413  [38400/70755]
loss: 0.134037  [44800/70755]
loss: 0.146400  [51200/70755]
loss: 0.056711  [57600/70755]
loss: 0.163988  [64000/70755]
loss: 0.096767  [70400/70755]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.137169 

Epoch 49
-------------------------------
loss: 0.161939  [    0/70755]
loss: 0.091257  [ 6400/70755]
loss: 0.091104  [12800/70755]
loss: 0.096281  [19200/70755]
loss: 0.176179  [25600/70755]
loss: 0.095173  [32000/70755]
loss: 0.138021  [38400/70755]
loss: 0.076802  [44800/70755]
loss: 0.156685  [51200/70755]
loss: 0.147675  [57600/70755]
loss: 0.255782  [64000/70755]
loss: 0.108197  [70400/70755]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.135314 

Epoch 50
-------------------------------
loss: 0.180902  [    0/70755]
loss: 0.190663  [ 6400/70755]
loss: 0.085062  [12800/70755]
loss: 0.075921  [19200/70755]
loss: 0.034971  [25600/70755]
loss: 0.205732  [32000/70755]
loss: 0.063712  [38400/70755]
loss: 0.133956  [44800/70755]
loss: 0.073794  [51200/70755]
loss: 0.096074  [57600/70755]
loss: 0.085353  [64000/70755]
loss: 0.144388  [70400/70755]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.138700 

Epoch 1
-------------------------------
loss: 0.710853  [    0/71180]
loss: 0.170554  [ 6400/71180]
loss: 0.235966  [12800/71180]
loss: 0.102931  [19200/71180]
loss: 0.101502  [25600/71180]
loss: 0.064288  [32000/71180]
loss: 0.307407  [38400/71180]
loss: 0.128868  [44800/71180]
loss: 0.296297  [51200/71180]
loss: 0.076114  [57600/71180]
loss: 0.073428  [64000/71180]
loss: 0.163957  [70400/71180]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.145443 

Epoch 2
-------------------------------
loss: 0.117164  [    0/71180]
loss: 0.078264  [ 6400/71180]
loss: 0.135926  [12800/71180]
loss: 0.095879  [19200/71180]
loss: 0.055406  [25600/71180]
loss: 0.095762  [32000/71180]
loss: 0.074984  [38400/71180]
loss: 0.102871  [44800/71180]
loss: 0.122528  [51200/71180]
loss: 0.272279  [57600/71180]
loss: 0.067902  [64000/71180]
loss: 0.073999  [70400/71180]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.143542 

Epoch 3
-------------------------------
loss: 0.095953  [    0/71180]
loss: 0.118930  [ 6400/71180]
loss: 0.094946  [12800/71180]
loss: 0.127661  [19200/71180]
loss: 0.097316  [25600/71180]
loss: 0.111981  [32000/71180]
loss: 0.092227  [38400/71180]
loss: 0.252040  [44800/71180]
loss: 0.113836  [51200/71180]
loss: 0.099030  [57600/71180]
loss: 0.161988  [64000/71180]
loss: 0.090396  [70400/71180]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.129679 

Epoch 4
-------------------------------
loss: 0.085315  [    0/71180]
loss: 0.121113  [ 6400/71180]
loss: 0.087019  [12800/71180]
loss: 0.114885  [19200/71180]
loss: 0.062554  [25600/71180]
loss: 0.131078  [32000/71180]
loss: 0.069179  [38400/71180]
loss: 0.025821  [44800/71180]
loss: 0.028940  [51200/71180]
loss: 0.106515  [57600/71180]
loss: 0.156618  [64000/71180]
loss: 0.060542  [70400/71180]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.138254 

Epoch 5
-------------------------------
loss: 0.178237  [    0/71180]
loss: 0.072106  [ 6400/71180]
loss: 0.136986  [12800/71180]
loss: 0.118102  [19200/71180]
loss: 0.114989  [25600/71180]
loss: 0.042532  [32000/71180]
loss: 0.119968  [38400/71180]
loss: 0.073378  [44800/71180]
loss: 0.047020  [51200/71180]
loss: 0.068422  [57600/71180]
loss: 0.111549  [64000/71180]
loss: 0.198660  [70400/71180]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.136507 

Epoch 6
-------------------------------
loss: 0.049256  [    0/71180]
loss: 0.102292  [ 6400/71180]
loss: 0.079956  [12800/71180]
loss: 0.141704  [19200/71180]
loss: 0.125595  [25600/71180]
loss: 0.094401  [32000/71180]
loss: 0.084660  [38400/71180]
loss: 0.128743  [44800/71180]
loss: 0.088360  [51200/71180]
loss: 0.107905  [57600/71180]
loss: 0.093301  [64000/71180]
loss: 0.047752  [70400/71180]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.123293 

Epoch 7
-------------------------------
loss: 0.046509  [    0/71180]
loss: 0.077813  [ 6400/71180]
loss: 0.188097  [12800/71180]
loss: 0.057454  [19200/71180]
loss: 0.267881  [25600/71180]
loss: 0.046502  [32000/71180]
loss: 0.048031  [38400/71180]
loss: 0.200584  [44800/71180]
loss: 0.149976  [51200/71180]
loss: 0.115470  [57600/71180]
loss: 0.093336  [64000/71180]
loss: 0.149899  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.119794 

Epoch 8
-------------------------------
loss: 0.080720  [    0/71180]
loss: 0.119596  [ 6400/71180]
loss: 0.085187  [12800/71180]
loss: 0.040322  [19200/71180]
loss: 0.041886  [25600/71180]
loss: 0.133104  [32000/71180]
loss: 0.072110  [38400/71180]
loss: 0.115028  [44800/71180]
loss: 0.131718  [51200/71180]
loss: 0.053742  [57600/71180]
loss: 0.090093  [64000/71180]
loss: 0.156660  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.127142 

Epoch 9
-------------------------------
loss: 0.091553  [    0/71180]
loss: 0.251980  [ 6400/71180]
loss: 0.176148  [12800/71180]
loss: 0.053311  [19200/71180]
loss: 0.076471  [25600/71180]
loss: 0.005359  [25600/71130]
loss: 0.044467  [32000/71130]
loss: 0.105252  [38400/71130]
loss: 0.085706  [44800/71130]
loss: 0.009850  [51200/71130]
loss: 0.059129  [57600/71130]
loss: 0.082647  [64000/71130]
loss: 0.105113  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070255 

Epoch 42
-------------------------------
loss: 0.037628  [    0/71130]
loss: 0.002930  [ 6400/71130]
loss: 0.005270  [12800/71130]
loss: 0.027806  [19200/71130]
loss: 0.000366  [25600/71130]
loss: 0.035562  [32000/71130]
loss: 0.018043  [38400/71130]
loss: 0.010947  [44800/71130]
loss: 0.036240  [51200/71130]
loss: 0.013154  [57600/71130]
loss: 0.015407  [64000/71130]
loss: 0.016536  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.074056 

Epoch 43
-------------------------------
loss: 0.100552  [    0/71130]
loss: 0.006495  [ 6400/71130]
loss: 0.009375  [12800/71130]
loss: 0.003815  [19200/71130]
loss: 0.018210  [25600/71130]
loss: 0.036476  [32000/71130]
loss: 0.076549  [38400/71130]
loss: 0.012841  [44800/71130]
loss: 0.001195  [51200/71130]
loss: 0.057686  [57600/71130]
loss: 0.022508  [64000/71130]
loss: 0.023902  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.074181 

Epoch 44
-------------------------------
loss: 0.115354  [    0/71130]
loss: 0.082706  [ 6400/71130]
loss: 0.004357  [12800/71130]
loss: 0.076534  [19200/71130]
loss: 0.200511  [25600/71130]
loss: 0.100982  [32000/71130]
loss: 0.019113  [38400/71130]
loss: 0.021211  [44800/71130]
loss: 0.119881  [51200/71130]
loss: 0.025864  [57600/71130]
loss: 0.047488  [64000/71130]
loss: 0.016293  [70400/71130]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073639 

Epoch 45
-------------------------------
loss: 0.101966  [    0/71130]
loss: 0.029819  [ 6400/71130]
loss: 0.012199  [12800/71130]
loss: 0.018343  [19200/71130]
loss: 0.163741  [25600/71130]
loss: 0.015503  [32000/71130]
loss: 0.027622  [38400/71130]
loss: 0.004295  [44800/71130]
loss: 0.031842  [51200/71130]
loss: 0.008400  [57600/71130]
loss: 0.022811  [64000/71130]
loss: 0.023550  [70400/71130]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.085252 

Epoch 46
-------------------------------
loss: 0.045257  [    0/71130]
loss: 0.149789  [ 6400/71130]
loss: 0.028226  [12800/71130]
loss: 0.093232  [19200/71130]
loss: 0.025201  [25600/71130]
loss: 0.015902  [32000/71130]
loss: 0.095148  [38400/71130]
loss: 0.003428  [44800/71130]
loss: 0.068325  [51200/71130]
loss: 0.079401  [57600/71130]
loss: 0.111270  [64000/71130]
loss: 0.045116  [70400/71130]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.076324 

Epoch 47
-------------------------------
loss: 0.055500  [    0/71130]
loss: 0.015343  [ 6400/71130]
loss: 0.048193  [12800/71130]
loss: 0.087156  [19200/71130]
loss: 0.052306  [25600/71130]
loss: 0.028996  [32000/71130]
loss: 0.040165  [38400/71130]
loss: 0.058339  [44800/71130]
loss: 0.012931  [51200/71130]
loss: 0.014394  [57600/71130]
loss: 0.022495  [64000/71130]
loss: 0.015647  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073100 

Epoch 48
-------------------------------
loss: 0.021510  [    0/71130]
loss: 0.009389  [ 6400/71130]
loss: 0.019406  [12800/71130]
loss: 0.111337  [19200/71130]
loss: 0.009107  [25600/71130]
loss: 0.018634  [32000/71130]
loss: 0.102765  [38400/71130]
loss: 0.053923  [44800/71130]
loss: 0.235719  [51200/71130]
loss: 0.018756  [57600/71130]
loss: 0.011309  [64000/71130]
loss: 0.078605  [70400/71130]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.087688 

Epoch 49
-------------------------------
loss: 0.023794  [    0/71130]
loss: 0.221842  [ 6400/71130]
loss: 0.021975  [12800/71130]
loss: 0.029084  [19200/71130]
loss: 0.018274  [25600/71130]
loss: 0.024864  [32000/71130]
loss: 0.010918  [38400/71130]
loss: 0.049423  [44800/71130]
loss: 0.014662  [51200/71130]
loss: 0.040170  [57600/71130]
loss: 0.006225  [64000/71130]
loss: 0.216751  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.074165 

Epoch 50
-------------------------------
loss: 0.066365  [    0/71130]
loss: 0.020557  [ 6400/71130]
loss: 0.083674  [12800/71130]
loss: 0.035523  [19200/71130]
loss: 0.068423  [25600/71130]
loss: 0.005106  [32000/71130]
loss: 0.034107  [38400/71130]
loss: 0.047563  [44800/71130]
loss: 0.053899  [51200/71130]
loss: 0.073644  [57600/71130]
loss: 0.058888  [64000/71130]
loss: 0.024735  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.075283 

Epoch 1
-------------------------------
loss: 0.677031  [    0/69822]
loss: 0.083266  [ 6400/69822]
loss: 0.077484  [12800/69822]
loss: 0.085981  [19200/69822]
loss: 0.210226  [25600/69822]
loss: 0.215363  [32000/69822]
loss: 0.178951  [38400/69822]
loss: 0.316251  [44800/69822]
loss: 0.110538  [51200/69822]
loss: 0.096798  [57600/69822]
loss: 0.068549  [64000/69822]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.076835 

Epoch 2
-------------------------------
loss: 0.039429  [    0/69822]
loss: 0.045037  [ 6400/69822]
loss: 0.113671  [12800/69822]
loss: 0.066645  [19200/69822]
loss: 0.145510  [25600/69822]
loss: 0.131599  [32000/69822]
loss: 0.173466  [38400/69822]
loss: 0.156847  [44800/69822]
loss: 0.119159  [51200/69822]
loss: 0.030236  [57600/69822]
loss: 0.115598  [64000/69822]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.071596 

Epoch 3
-------------------------------
loss: 0.100388  [    0/69822]
loss: 0.061983  [ 6400/69822]
loss: 0.092893  [12800/69822]
loss: 0.052430  [19200/69822]
loss: 0.058115  [25600/69822]
loss: 0.073819  [32000/69822]
loss: 0.093584  [38400/69822]
loss: 0.155173  [44800/69822]
loss: 0.024696  [51200/69822]
loss: 0.065188  [57600/69822]
loss: 0.120052  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.068827 

Epoch 4
-------------------------------
loss: 0.115761  [    0/69822]
loss: 0.042007  [ 6400/69822]
loss: 0.103027  [12800/69822]
loss: 0.162002  [19200/69822]
loss: 0.174932  [25600/69822]
loss: 0.072276  [32000/69822]
loss: 0.033405  [38400/69822]
loss: 0.043334  [44800/69822]
loss: 0.100570  [51200/69822]
loss: 0.055714  [57600/69822]
loss: 0.040064  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.064227 

Epoch 5
-------------------------------
loss: 0.059051  [    0/69822]
loss: 0.064183  [ 6400/69822]
loss: 0.091161  [12800/69822]
loss: 0.053587  [19200/69822]
loss: 0.051378  [25600/69822]
loss: 0.042814  [32000/69822]
loss: 0.044227  [38400/69822]
loss: 0.016578  [44800/69822]
loss: 0.087494  [51200/69822]
loss: 0.146871  [57600/69822]
loss: 0.034085  [64000/69822]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067381 

Epoch 6
-------------------------------
loss: 0.113217  [    0/69822]
loss: 0.051683  [ 6400/69822]
loss: 0.031874  [12800/69822]
loss: 0.229086  [19200/69822]
loss: 0.032530  [25600/69822]
loss: 0.125623  [32000/69822]
loss: 0.164553  [38400/69822]
loss: 0.032759  [44800/69822]
loss: 0.102549  [51200/69822]
loss: 0.126060  [57600/69822]
loss: 0.047266  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073347 

Epoch 7
-------------------------------
loss: 0.058329  [    0/69822]
loss: 0.079585  [ 6400/69822]
loss: 0.036332  [12800/69822]
loss: 0.014377  [19200/69822]
loss: 0.215883  [25600/69822]
loss: 0.046073  [32000/69822]
loss: 0.103012  [38400/69822]
loss: 0.048318  [44800/69822]
loss: 0.047500  [51200/69822]
loss: 0.079112  [57600/69822]
loss: 0.072224  [64000/69822]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066773 

Epoch 8
-------------------------------
loss: 0.059398  [    0/69822]
loss: 0.159663  [ 6400/69822]
loss: 0.048018  [12800/69822]
loss: 0.082780  [19200/69822]
loss: 0.044680  [25600/69822]
loss: 0.119371  [32000/69822]
loss: 0.038096  [38400/69822]
loss: 0.021691  [44800/69822]
loss: 0.083094  [51200/69822]
loss: 0.082161  [57600/69822]
loss: 0.190292  [64000/69822]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075165 

Epoch 9
-------------------------------
loss: 0.209572  [    0/69822]
loss: 0.058632  [ 6400/69822]
loss: 0.013486  [12800/69822]
loss: 0.061311  [19200/69822]
loss: 0.028806  [25600/69822]
loss: 0.045804  [32000/69822]
loss: 0.066597  [38400/69822]
loss: 0.013662  [44800/69822]
loss: 0.035090  [51200/69822]
loss: 0.070352  [57600/69822]
loss: 0.050587  [64000/69822]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067055 

loss: 0.035822  [25600/72203]
loss: 0.059908  [32000/72203]
loss: 0.071851  [38400/72203]
loss: 0.035690  [44800/72203]
loss: 0.095415  [51200/72203]
loss: 0.236432  [57600/72203]
loss: 0.055635  [64000/72203]
loss: 0.045822  [70400/72203]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.154594 

Epoch 42
-------------------------------
loss: 0.092892  [    0/72203]
loss: 0.009322  [ 6400/72203]
loss: 0.041692  [12800/72203]
loss: 0.059828  [19200/72203]
loss: 0.023558  [25600/72203]
loss: 0.097333  [32000/72203]
loss: 0.063970  [38400/72203]
loss: 0.039055  [44800/72203]
loss: 0.074127  [51200/72203]
loss: 0.039217  [57600/72203]
loss: 0.027744  [64000/72203]
loss: 0.078850  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.156413 

Epoch 43
-------------------------------
loss: 0.072778  [    0/72203]
loss: 0.083528  [ 6400/72203]
loss: 0.067186  [12800/72203]
loss: 0.025021  [19200/72203]
loss: 0.017025  [25600/72203]
loss: 0.066337  [32000/72203]
loss: 0.063569  [38400/72203]
loss: 0.138794  [44800/72203]
loss: 0.034019  [51200/72203]
loss: 0.072629  [57600/72203]
loss: 0.048275  [64000/72203]
loss: 0.047296  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.148016 

Epoch 44
-------------------------------
loss: 0.038489  [    0/72203]
loss: 0.058634  [ 6400/72203]
loss: 0.155127  [12800/72203]
loss: 0.063941  [19200/72203]
loss: 0.062556  [25600/72203]
loss: 0.040063  [32000/72203]
loss: 0.011308  [38400/72203]
loss: 0.025679  [44800/72203]
loss: 0.053339  [51200/72203]
loss: 0.061368  [57600/72203]
loss: 0.066287  [64000/72203]
loss: 0.042462  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.146423 

Epoch 45
-------------------------------
loss: 0.005111  [    0/72203]
loss: 0.023116  [ 6400/72203]
loss: 0.003466  [12800/72203]
loss: 0.003059  [19200/72203]
loss: 0.057818  [25600/72203]
loss: 0.047336  [32000/72203]
loss: 0.059374  [38400/72203]
loss: 0.053009  [44800/72203]
loss: 0.019934  [51200/72203]
loss: 0.104205  [57600/72203]
loss: 1.570162  [64000/72203]
loss: 0.112929  [70400/72203]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.144906 

Epoch 46
-------------------------------
loss: 0.051213  [    0/72203]
loss: 0.055524  [ 6400/72203]
loss: 0.049782  [12800/72203]
loss: 0.123968  [19200/72203]
loss: 0.078991  [25600/72203]
loss: 0.067188  [32000/72203]
loss: 0.065514  [38400/72203]
loss: 0.057627  [44800/72203]
loss: 0.025663  [51200/72203]
loss: 0.158751  [57600/72203]
loss: 0.066549  [64000/72203]
loss: 0.068333  [70400/72203]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.155031 

Epoch 47
-------------------------------
loss: 0.026530  [    0/72203]
loss: 0.107936  [ 6400/72203]
loss: 0.036865  [12800/72203]
loss: 0.022837  [19200/72203]
loss: 0.073462  [25600/72203]
loss: 0.076429  [32000/72203]
loss: 0.042769  [38400/72203]
loss: 0.043179  [44800/72203]
loss: 0.019872  [51200/72203]
loss: 0.021064  [57600/72203]
loss: 0.070049  [64000/72203]
loss: 0.017991  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.148650 

Epoch 48
-------------------------------
loss: 0.042494  [    0/72203]
loss: 0.040940  [ 6400/72203]
loss: 0.020200  [12800/72203]
loss: 0.009709  [19200/72203]
loss: 0.067432  [25600/72203]
loss: 0.034094  [32000/72203]
loss: 0.025267  [38400/72203]
loss: 1.584781  [44800/72203]
loss: 0.015272  [51200/72203]
loss: 0.036213  [57600/72203]
loss: 0.032092  [64000/72203]
loss: 0.036391  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.150501 

Epoch 49
-------------------------------
loss: 0.010496  [    0/72203]
loss: 0.064934  [ 6400/72203]
loss: 0.036027  [12800/72203]
loss: 1.623432  [19200/72203]
loss: 0.034295  [25600/72203]
loss: 0.102084  [32000/72203]
loss: 1.635268  [38400/72203]
loss: 0.014672  [44800/72203]
loss: 0.107516  [51200/72203]
loss: 0.039500  [57600/72203]
loss: 0.029584  [64000/72203]
loss: 0.028797  [70400/72203]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.148011 

Epoch 50
-------------------------------
loss: 0.060792  [    0/72203]
loss: 0.047619  [ 6400/72203]
loss: 0.119551  [12800/72203]
loss: 0.031579  [19200/72203]
loss: 0.087342  [25600/72203]
loss: 0.028799  [32000/72203]
loss: 0.109311  [38400/72203]
loss: 0.107193  [44800/72203]
loss: 0.005786  [51200/72203]
loss: 0.053362  [57600/72203]
loss: 0.034026  [64000/72203]
loss: 0.028869  [70400/72203]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.152032 

Epoch 1
-------------------------------
loss: 0.687044  [    0/70482]
loss: 0.383299  [ 6400/70482]
loss: 0.274883  [12800/70482]
loss: 0.335203  [19200/70482]
loss: 0.319465  [25600/70482]
loss: 0.370753  [32000/70482]
loss: 0.208852  [38400/70482]
loss: 0.146432  [44800/70482]
loss: 0.125470  [51200/70482]
loss: 0.126824  [57600/70482]
loss: 0.433321  [64000/70482]
loss: 0.199539  [70400/70482]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.194145 

Epoch 2
-------------------------------
loss: 0.140514  [    0/70482]
loss: 0.324950  [ 6400/70482]
loss: 0.181835  [12800/70482]
loss: 0.397358  [19200/70482]
loss: 0.100527  [25600/70482]
loss: 0.173805  [32000/70482]
loss: 0.188835  [38400/70482]
loss: 0.124345  [44800/70482]
loss: 0.165432  [51200/70482]
loss: 0.187559  [57600/70482]
loss: 0.164926  [64000/70482]
loss: 0.143945  [70400/70482]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.171176 

Epoch 3
-------------------------------
loss: 0.161575  [    0/70482]
loss: 0.177484  [ 6400/70482]
loss: 0.080783  [12800/70482]
loss: 0.181192  [19200/70482]
loss: 0.124161  [25600/70482]
loss: 0.095816  [32000/70482]
loss: 0.259328  [38400/70482]
loss: 0.245463  [44800/70482]
loss: 0.174356  [51200/70482]
loss: 0.178401  [57600/70482]
loss: 0.245879  [64000/70482]
loss: 0.243552  [70400/70482]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.169006 

Epoch 4
-------------------------------
loss: 0.089564  [    0/70482]
loss: 0.243398  [ 6400/70482]
loss: 0.051025  [12800/70482]
loss: 0.117117  [19200/70482]
loss: 0.080833  [25600/70482]
loss: 0.115156  [32000/70482]
loss: 0.214778  [38400/70482]
loss: 0.755294  [44800/70482]
loss: 0.144094  [51200/70482]
loss: 0.080573  [57600/70482]
loss: 0.156473  [64000/70482]
loss: 0.069685  [70400/70482]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.156408 

Epoch 5
-------------------------------
loss: 0.157068  [    0/70482]
loss: 0.137648  [ 6400/70482]
loss: 0.156573  [12800/70482]
loss: 0.302485  [19200/70482]
loss: 0.172339  [25600/70482]
loss: 0.118916  [32000/70482]
loss: 0.157399  [38400/70482]
loss: 0.073559  [44800/70482]
loss: 0.136861  [51200/70482]
loss: 0.116505  [57600/70482]
loss: 0.226247  [64000/70482]
loss: 0.211019  [70400/70482]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.158180 

Epoch 6
-------------------------------
loss: 0.105229  [    0/70482]
loss: 0.238188  [ 6400/70482]
loss: 0.171327  [12800/70482]
loss: 0.123466  [19200/70482]
loss: 0.129366  [25600/70482]
loss: 0.177120  [32000/70482]
loss: 0.197380  [38400/70482]
loss: 0.111579  [44800/70482]
loss: 0.251881  [51200/70482]
loss: 0.137366  [57600/70482]
loss: 0.134541  [64000/70482]
loss: 0.110886  [70400/70482]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.155347 

Epoch 7
-------------------------------
loss: 0.124498  [    0/70482]
loss: 0.080501  [ 6400/70482]
loss: 0.145909  [12800/70482]
loss: 0.190703  [19200/70482]
loss: 0.183999  [25600/70482]
loss: 0.141108  [32000/70482]
loss: 0.204480  [38400/70482]
loss: 0.235875  [44800/70482]
loss: 0.137278  [51200/70482]
loss: 0.098471  [57600/70482]
loss: 0.224806  [64000/70482]
loss: 0.165553  [70400/70482]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.151908 

Epoch 8
-------------------------------
loss: 0.185469  [    0/70482]
loss: 0.061737  [ 6400/70482]
loss: 0.114367  [12800/70482]
loss: 0.055865  [19200/70482]
loss: 0.176074  [25600/70482]
loss: 0.094689  [32000/70482]
loss: 0.100531  [38400/70482]
loss: 0.172554  [44800/70482]
loss: 0.101564  [51200/70482]
loss: 0.236872  [57600/70482]
loss: 0.191496  [64000/70482]
loss: 0.167417  [70400/70482]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147421 

Epoch 9
-------------------------------
loss: 0.090286  [    0/70482]
loss: 0.258277  [ 6400/70482]
loss: 0.149635  [12800/70482]
loss: 0.215326  [19200/70482]
loss: 0.129038  [25600/70482]
loss: 0.206038  [25600/70999]
loss: 0.089848  [32000/70999]
loss: 0.131057  [38400/70999]
loss: 0.206031  [44800/70999]
loss: 0.093571  [51200/70999]
loss: 0.204688  [57600/70999]
loss: 0.112352  [64000/70999]
loss: 0.103274  [70400/70999]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.157821 

Epoch 42
-------------------------------
loss: 0.060187  [    0/70999]
loss: 0.067781  [ 6400/70999]
loss: 0.148105  [12800/70999]
loss: 0.104980  [19200/70999]
loss: 0.192694  [25600/70999]
loss: 1.620281  [32000/70999]
loss: 0.072850  [38400/70999]
loss: 0.137168  [44800/70999]
loss: 0.024829  [51200/70999]
loss: 0.251684  [57600/70999]
loss: 0.175129  [64000/70999]
loss: 0.148697  [70400/70999]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.140295 

Epoch 43
-------------------------------
loss: 0.117350  [    0/70999]
loss: 0.093964  [ 6400/70999]
loss: 0.103949  [12800/70999]
loss: 0.164690  [19200/70999]
loss: 0.098269  [25600/70999]
loss: 0.072493  [32000/70999]
loss: 0.041993  [38400/70999]
loss: 0.117806  [44800/70999]
loss: 0.124051  [51200/70999]
loss: 0.133274  [57600/70999]
loss: 0.116306  [64000/70999]
loss: 0.102627  [70400/70999]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.132300 

Epoch 44
-------------------------------
loss: 0.231035  [    0/70999]
loss: 0.151827  [ 6400/70999]
loss: 0.188164  [12800/70999]
loss: 0.041330  [19200/70999]
loss: 0.068540  [25600/70999]
loss: 0.035710  [32000/70999]
loss: 0.095551  [38400/70999]
loss: 0.094701  [44800/70999]
loss: 0.199026  [51200/70999]
loss: 0.064103  [57600/70999]
loss: 0.137600  [64000/70999]
loss: 0.097653  [70400/70999]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139694 

Epoch 45
-------------------------------
loss: 0.101264  [    0/70999]
loss: 0.130815  [ 6400/70999]
loss: 0.127006  [12800/70999]
loss: 0.103252  [19200/70999]
loss: 0.164580  [25600/70999]
loss: 0.170621  [32000/70999]
loss: 0.093296  [38400/70999]
loss: 0.084609  [44800/70999]
loss: 0.169747  [51200/70999]
loss: 0.050936  [57600/70999]
loss: 0.101870  [64000/70999]
loss: 0.148966  [70400/70999]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146511 

Epoch 46
-------------------------------
loss: 0.105978  [    0/70999]
loss: 0.108803  [ 6400/70999]
loss: 0.054836  [12800/70999]
loss: 0.104144  [19200/70999]
loss: 0.137928  [25600/70999]
loss: 0.191613  [32000/70999]
loss: 0.067088  [38400/70999]
loss: 0.120827  [44800/70999]
loss: 0.116117  [51200/70999]
loss: 0.108739  [57600/70999]
loss: 0.111139  [64000/70999]
loss: 0.045174  [70400/70999]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139561 

Epoch 47
-------------------------------
loss: 0.143293  [    0/70999]
loss: 0.053907  [ 6400/70999]
loss: 1.724149  [12800/70999]
loss: 0.114656  [19200/70999]
loss: 0.090022  [25600/70999]
loss: 0.119463  [32000/70999]
loss: 0.024533  [38400/70999]
loss: 0.081753  [44800/70999]
loss: 0.102189  [51200/70999]
loss: 0.108671  [57600/70999]
loss: 0.157745  [64000/70999]
loss: 0.154491  [70400/70999]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.129196 

Epoch 48
-------------------------------
loss: 0.104762  [    0/70999]
loss: 0.096067  [ 6400/70999]
loss: 0.067605  [12800/70999]
loss: 0.172967  [19200/70999]
loss: 0.157270  [25600/70999]
loss: 0.162810  [32000/70999]
loss: 0.187345  [38400/70999]
loss: 0.160759  [44800/70999]
loss: 0.095711  [51200/70999]
loss: 0.133011  [57600/70999]
loss: 0.095900  [64000/70999]
loss: 0.125295  [70400/70999]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.171204 

Epoch 49
-------------------------------
loss: 0.064607  [    0/70999]
loss: 0.110958  [ 6400/70999]
loss: 0.047533  [12800/70999]
loss: 0.160201  [19200/70999]
loss: 0.074521  [25600/70999]
loss: 0.129123  [32000/70999]
loss: 0.157461  [38400/70999]
loss: 0.107773  [44800/70999]
loss: 0.040542  [51200/70999]
loss: 0.130305  [57600/70999]
loss: 0.112052  [64000/70999]
loss: 0.135446  [70400/70999]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.173578 

Epoch 50
-------------------------------
loss: 0.134983  [    0/70999]
loss: 0.111420  [ 6400/70999]
loss: 0.082535  [12800/70999]
loss: 0.050586  [19200/70999]
loss: 0.175623  [25600/70999]
loss: 0.155696  [32000/70999]
loss: 0.155645  [38400/70999]
loss: 0.062668  [44800/70999]
loss: 0.066011  [51200/70999]
loss: 0.113297  [57600/70999]
loss: 0.036910  [64000/70999]
loss: 0.047594  [70400/70999]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.130772 

Epoch 1
-------------------------------
loss: 0.723366  [    0/71235]
loss: 0.335718  [ 6400/71235]
loss: 0.187523  [12800/71235]
loss: 0.187603  [19200/71235]
loss: 0.218122  [25600/71235]
loss: 0.211750  [32000/71235]
loss: 0.117777  [38400/71235]
loss: 0.122125  [44800/71235]
loss: 0.062404  [51200/71235]
loss: 0.100982  [57600/71235]
loss: 0.275440  [64000/71235]
loss: 0.191152  [70400/71235]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.136544 

Epoch 2
-------------------------------
loss: 0.067083  [    0/71235]
loss: 0.107895  [ 6400/71235]
loss: 0.093648  [12800/71235]
loss: 0.099003  [19200/71235]
loss: 0.140911  [25600/71235]
loss: 0.115679  [32000/71235]
loss: 0.126498  [38400/71235]
loss: 0.090729  [44800/71235]
loss: 0.082601  [51200/71235]
loss: 0.145028  [57600/71235]
loss: 0.064519  [64000/71235]
loss: 0.117225  [70400/71235]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.115476 

Epoch 3
-------------------------------
loss: 0.093710  [    0/71235]
loss: 0.066142  [ 6400/71235]
loss: 0.063784  [12800/71235]
loss: 0.070296  [19200/71235]
loss: 0.054185  [25600/71235]
loss: 0.052436  [32000/71235]
loss: 0.119172  [38400/71235]
loss: 0.056576  [44800/71235]
loss: 1.637897  [51200/71235]
loss: 0.072650  [57600/71235]
loss: 0.140216  [64000/71235]
loss: 0.088285  [70400/71235]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.111178 

Epoch 4
-------------------------------
loss: 0.029444  [    0/71235]
loss: 0.087813  [ 6400/71235]
loss: 0.134551  [12800/71235]
loss: 0.092006  [19200/71235]
loss: 0.105493  [25600/71235]
loss: 0.121485  [32000/71235]
loss: 0.128297  [38400/71235]
loss: 0.044229  [44800/71235]
loss: 0.050888  [51200/71235]
loss: 0.050136  [57600/71235]
loss: 0.025996  [64000/71235]
loss: 0.198315  [70400/71235]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.109732 

Epoch 5
-------------------------------
loss: 0.051338  [    0/71235]
loss: 0.039605  [ 6400/71235]
loss: 0.040559  [12800/71235]
loss: 0.050184  [19200/71235]
loss: 0.118407  [25600/71235]
loss: 0.073191  [32000/71235]
loss: 0.036498  [38400/71235]
loss: 0.075140  [44800/71235]
loss: 0.020634  [51200/71235]
loss: 0.086644  [57600/71235]
loss: 0.123675  [64000/71235]
loss: 0.131592  [70400/71235]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.110732 

Epoch 6
-------------------------------
loss: 0.045595  [    0/71235]
loss: 0.076516  [ 6400/71235]
loss: 0.083150  [12800/71235]
loss: 0.123807  [19200/71235]
loss: 0.118296  [25600/71235]
loss: 0.070925  [32000/71235]
loss: 0.057222  [38400/71235]
loss: 0.084466  [44800/71235]
loss: 0.112354  [51200/71235]
loss: 0.080279  [57600/71235]
loss: 0.156904  [64000/71235]
loss: 0.146129  [70400/71235]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.133687 

Epoch 7
-------------------------------
loss: 0.131884  [    0/71235]
loss: 0.032728  [ 6400/71235]
loss: 0.045215  [12800/71235]
loss: 0.089697  [19200/71235]
loss: 0.146381  [25600/71235]
loss: 0.065470  [32000/71235]
loss: 0.069322  [38400/71235]
loss: 0.090822  [44800/71235]
loss: 0.151318  [51200/71235]
loss: 0.064223  [57600/71235]
loss: 0.108316  [64000/71235]
loss: 0.068280  [70400/71235]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.216387 

Epoch 8
-------------------------------
loss: 0.222560  [    0/71235]
loss: 0.070816  [ 6400/71235]
loss: 0.143826  [12800/71235]
loss: 0.090393  [19200/71235]
loss: 0.112609  [25600/71235]
loss: 0.050905  [32000/71235]
loss: 0.114453  [38400/71235]
loss: 0.025414  [44800/71235]
loss: 0.208193  [51200/71235]
loss: 0.208674  [57600/71235]
loss: 0.070012  [64000/71235]
loss: 0.098393  [70400/71235]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.111777 

Epoch 9
-------------------------------
loss: 0.034721  [    0/71235]
loss: 0.118953  [ 6400/71235]
loss: 0.039882  [12800/71235]
loss: 0.098261  [19200/71235]
loss: 0.055691  [25600/71235]
loss: 0.035254  [25600/70644]
loss: 0.034875  [32000/70644]
loss: 0.062970  [38400/70644]
loss: 0.111980  [44800/70644]
loss: 0.029800  [51200/70644]
loss: 0.046696  [57600/70644]
loss: 0.050576  [64000/70644]
loss: 0.028876  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082439 

Epoch 42
-------------------------------
loss: 0.030629  [    0/70644]
loss: 0.024040  [ 6400/70644]
loss: 0.018040  [12800/70644]
loss: 0.085690  [19200/70644]
loss: 0.146843  [25600/70644]
loss: 0.026604  [32000/70644]
loss: 0.134399  [38400/70644]
loss: 0.015990  [44800/70644]
loss: 0.034608  [51200/70644]
loss: 0.047502  [57600/70644]
loss: 0.045262  [64000/70644]
loss: 0.037376  [70400/70644]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.105340 

Epoch 43
-------------------------------
loss: 0.045156  [    0/70644]
loss: 0.010310  [ 6400/70644]
loss: 0.037180  [12800/70644]
loss: 0.035349  [19200/70644]
loss: 0.134812  [25600/70644]
loss: 0.083398  [32000/70644]
loss: 0.072291  [38400/70644]
loss: 0.053105  [44800/70644]
loss: 0.076137  [51200/70644]
loss: 0.027447  [57600/70644]
loss: 0.082986  [64000/70644]
loss: 0.039474  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.084149 

Epoch 44
-------------------------------
loss: 0.073741  [    0/70644]
loss: 0.081134  [ 6400/70644]
loss: 0.097427  [12800/70644]
loss: 0.070089  [19200/70644]
loss: 0.049403  [25600/70644]
loss: 0.098346  [32000/70644]
loss: 0.037467  [38400/70644]
loss: 0.068848  [44800/70644]
loss: 0.007566  [51200/70644]
loss: 0.046167  [57600/70644]
loss: 0.029558  [64000/70644]
loss: 0.047830  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083794 

Epoch 45
-------------------------------
loss: 0.132868  [    0/70644]
loss: 0.179686  [ 6400/70644]
loss: 0.119487  [12800/70644]
loss: 0.125366  [19200/70644]
loss: 0.030739  [25600/70644]
loss: 0.030133  [32000/70644]
loss: 0.044084  [38400/70644]
loss: 0.054940  [44800/70644]
loss: 0.108147  [51200/70644]
loss: 0.073404  [57600/70644]
loss: 0.069471  [64000/70644]
loss: 0.016755  [70400/70644]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.088239 

Epoch 46
-------------------------------
loss: 0.010987  [    0/70644]
loss: 0.135576  [ 6400/70644]
loss: 0.041652  [12800/70644]
loss: 0.032051  [19200/70644]
loss: 0.023252  [25600/70644]
loss: 0.019490  [32000/70644]
loss: 0.011857  [38400/70644]
loss: 0.038349  [44800/70644]
loss: 0.099630  [51200/70644]
loss: 0.035686  [57600/70644]
loss: 0.171092  [64000/70644]
loss: 0.184406  [70400/70644]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.090213 

Epoch 47
-------------------------------
loss: 0.019562  [    0/70644]
loss: 0.060075  [ 6400/70644]
loss: 0.043196  [12800/70644]
loss: 0.073288  [19200/70644]
loss: 0.020059  [25600/70644]
loss: 0.074070  [32000/70644]
loss: 0.023508  [38400/70644]
loss: 0.012020  [44800/70644]
loss: 0.063901  [51200/70644]
loss: 0.069758  [57600/70644]
loss: 0.080447  [64000/70644]
loss: 0.086173  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.088493 

Epoch 48
-------------------------------
loss: 0.057247  [    0/70644]
loss: 0.140941  [ 6400/70644]
loss: 0.049811  [12800/70644]
loss: 0.024229  [19200/70644]
loss: 0.074862  [25600/70644]
loss: 0.072860  [32000/70644]
loss: 0.093068  [38400/70644]
loss: 0.049327  [44800/70644]
loss: 0.025541  [51200/70644]
loss: 0.111332  [57600/70644]
loss: 0.016097  [64000/70644]
loss: 0.016329  [70400/70644]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.084711 

Epoch 49
-------------------------------
loss: 0.007704  [    0/70644]
loss: 0.034906  [ 6400/70644]
loss: 0.010383  [12800/70644]
loss: 0.036941  [19200/70644]
loss: 0.084509  [25600/70644]
loss: 0.029671  [32000/70644]
loss: 0.050887  [38400/70644]
loss: 0.077016  [44800/70644]
loss: 0.136673  [51200/70644]
loss: 0.015358  [57600/70644]
loss: 0.157035  [64000/70644]
loss: 0.048126  [70400/70644]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.105611 

Epoch 50
-------------------------------
loss: 0.026740  [    0/70644]
loss: 0.096779  [ 6400/70644]
loss: 0.111024  [12800/70644]
loss: 0.030375  [19200/70644]
loss: 0.067273  [25600/70644]
loss: 0.064444  [32000/70644]
loss: 0.062846  [38400/70644]
loss: 0.002759  [44800/70644]
loss: 0.042215  [51200/70644]
loss: 0.023774  [57600/70644]
loss: 0.115838  [64000/70644]
loss: 0.010524  [70400/70644]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083249 

Epoch 1
-------------------------------
loss: 0.715935  [    0/70555]
loss: 0.258956  [ 6400/70555]
loss: 0.171544  [12800/70555]
loss: 0.184526  [19200/70555]
loss: 0.212232  [25600/70555]
loss: 0.132150  [32000/70555]
loss: 0.148131  [38400/70555]
loss: 0.119236  [44800/70555]
loss: 0.124918  [51200/70555]
loss: 0.091363  [57600/70555]
loss: 0.119740  [64000/70555]
loss: 0.097356  [70400/70555]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.108388 

Epoch 2
-------------------------------
loss: 0.096403  [    0/70555]
loss: 0.097068  [ 6400/70555]
loss: 0.176288  [12800/70555]
loss: 0.034397  [19200/70555]
loss: 0.090989  [25600/70555]
loss: 0.088159  [32000/70555]
loss: 0.153989  [38400/70555]
loss: 0.131700  [44800/70555]
loss: 0.093489  [51200/70555]
loss: 0.103050  [57600/70555]
loss: 0.113594  [64000/70555]
loss: 0.021379  [70400/70555]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.098741 

Epoch 3
-------------------------------
loss: 0.074098  [    0/70555]
loss: 0.039459  [ 6400/70555]
loss: 0.147990  [12800/70555]
loss: 0.056579  [19200/70555]
loss: 0.098452  [25600/70555]
loss: 0.143500  [32000/70555]
loss: 0.400846  [38400/70555]
loss: 0.092046  [44800/70555]
loss: 0.104979  [51200/70555]
loss: 0.155894  [57600/70555]
loss: 0.046986  [64000/70555]
loss: 0.080799  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089003 

Epoch 4
-------------------------------
loss: 0.129937  [    0/70555]
loss: 0.111798  [ 6400/70555]
loss: 0.287904  [12800/70555]
loss: 0.083150  [19200/70555]
loss: 0.094875  [25600/70555]
loss: 0.046662  [32000/70555]
loss: 0.081627  [38400/70555]
loss: 0.108360  [44800/70555]
loss: 0.077507  [51200/70555]
loss: 0.091434  [57600/70555]
loss: 0.123249  [64000/70555]
loss: 0.137939  [70400/70555]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.092477 

Epoch 5
-------------------------------
loss: 0.040052  [    0/70555]
loss: 0.019994  [ 6400/70555]
loss: 0.061446  [12800/70555]
loss: 0.169367  [19200/70555]
loss: 0.196615  [25600/70555]
loss: 0.049400  [32000/70555]
loss: 0.102239  [38400/70555]
loss: 0.173662  [44800/70555]
loss: 0.120736  [51200/70555]
loss: 0.071944  [57600/70555]
loss: 0.128681  [64000/70555]
loss: 0.108906  [70400/70555]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.092836 

Epoch 6
-------------------------------
loss: 0.081219  [    0/70555]
loss: 0.056781  [ 6400/70555]
loss: 0.021536  [12800/70555]
loss: 0.046483  [19200/70555]
loss: 0.021402  [25600/70555]
loss: 0.095518  [32000/70555]
loss: 0.086863  [38400/70555]
loss: 0.033252  [44800/70555]
loss: 0.103061  [51200/70555]
loss: 0.083775  [57600/70555]
loss: 0.091732  [64000/70555]
loss: 0.097400  [70400/70555]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.094709 

Epoch 7
-------------------------------
loss: 0.034188  [    0/70555]
loss: 0.085642  [ 6400/70555]
loss: 0.012372  [12800/70555]
loss: 0.110982  [19200/70555]
loss: 0.079884  [25600/70555]
loss: 0.088601  [32000/70555]
loss: 0.132050  [38400/70555]
loss: 0.068556  [44800/70555]
loss: 0.073875  [51200/70555]
loss: 0.072414  [57600/70555]
loss: 0.079682  [64000/70555]
loss: 0.090559  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.085905 

Epoch 8
-------------------------------
loss: 0.083835  [    0/70555]
loss: 0.093906  [ 6400/70555]
loss: 0.042816  [12800/70555]
loss: 0.063274  [19200/70555]
loss: 0.072806  [25600/70555]
loss: 0.068854  [32000/70555]
loss: 0.179982  [38400/70555]
loss: 0.034388  [44800/70555]
loss: 0.028955  [51200/70555]
loss: 0.042830  [57600/70555]
loss: 0.124941  [64000/70555]
loss: 0.089722  [70400/70555]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.082792 

Epoch 9
-------------------------------
loss: 0.035845  [    0/70555]
loss: 0.024983  [ 6400/70555]
loss: 0.048850  [12800/70555]
loss: 0.078017  [19200/70555]
loss: 0.071363  [25600/70555]
loss: 0.154749  [57600/70451]
loss: 0.109598  [64000/70451]
loss: 0.078492  [56100/70451]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.131133 

Epoch 45
-------------------------------
loss: 0.054213  [    0/70451]
loss: 0.274413  [ 6400/70451]
loss: 0.100684  [12800/70451]
loss: 0.072881  [19200/70451]
loss: 0.027513  [25600/70451]
loss: 0.102284  [32000/70451]
loss: 0.166084  [38400/70451]
loss: 0.138421  [44800/70451]
loss: 0.229454  [51200/70451]
loss: 0.132474  [57600/70451]
loss: 0.059848  [64000/70451]
loss: 0.191868  [56100/70451]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.165642 

Epoch 46
-------------------------------
loss: 0.201099  [    0/70451]
loss: 0.066064  [ 6400/70451]
loss: 0.110633  [12800/70451]
loss: 0.155180  [19200/70451]
loss: 0.150359  [25600/70451]
loss: 0.158280  [32000/70451]
loss: 0.037261  [38400/70451]
loss: 0.138386  [44800/70451]
loss: 0.162341  [51200/70451]
loss: 0.130998  [57600/70451]
loss: 0.205368  [64000/70451]
loss: 0.070221  [56100/70451]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.135447 

Epoch 47
-------------------------------
loss: 0.106300  [    0/70451]
loss: 0.079680  [ 6400/70451]
loss: 0.066957  [12800/70451]
loss: 0.042805  [19200/70451]
loss: 0.087066  [25600/70451]
loss: 0.145597  [32000/70451]
loss: 0.060553  [38400/70451]
loss: 0.070846  [44800/70451]
loss: 0.056228  [51200/70451]
loss: 0.199299  [57600/70451]
loss: 0.057274  [64000/70451]
loss: 0.097464  [56100/70451]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.131505 

Epoch 48
-------------------------------
loss: 0.056884  [    0/70451]
loss: 0.189500  [ 6400/70451]
loss: 0.122226  [12800/70451]
loss: 0.124055  [19200/70451]
loss: 0.192870  [25600/70451]
loss: 0.196022  [32000/70451]
loss: 0.082846  [38400/70451]
loss: 0.122128  [44800/70451]
loss: 0.152630  [51200/70451]
loss: 0.329268  [57600/70451]
loss: 0.093654  [64000/70451]
loss: 0.049110  [56100/70451]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.149938 

Epoch 49
-------------------------------
loss: 0.211507  [    0/70451]
loss: 0.073368  [ 6400/70451]
loss: 0.102608  [12800/70451]
loss: 0.114776  [19200/70451]
loss: 0.087284  [25600/70451]
loss: 0.094834  [32000/70451]
loss: 0.152508  [38400/70451]
loss: 0.160185  [44800/70451]
loss: 0.136422  [51200/70451]
loss: 0.156340  [57600/70451]
loss: 0.082482  [64000/70451]
loss: 0.058674  [56100/70451]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.132749 

Epoch 50
-------------------------------
loss: 0.027999  [    0/70451]
loss: 0.051869  [ 6400/70451]
loss: 0.045722  [12800/70451]
loss: 0.126020  [19200/70451]
loss: 0.048610  [25600/70451]
loss: 0.105455  [32000/70451]
loss: 0.052824  [38400/70451]
loss: 0.091472  [44800/70451]
loss: 0.103639  [51200/70451]
loss: 0.092744  [57600/70451]
loss: 0.071248  [64000/70451]
loss: 0.123927  [56100/70451]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.169766 

Epoch 1
-------------------------------
loss: 0.697630  [    0/70415]
loss: 0.316064  [ 6400/70415]
loss: 0.161553  [12800/70415]
loss: 0.175881  [19200/70415]
loss: 0.135194  [25600/70415]
loss: 0.153388  [32000/70415]
loss: 0.236186  [38400/70415]
loss: 0.088780  [44800/70415]
loss: 0.144373  [51200/70415]
loss: 0.098869  [57600/70415]
loss: 0.144010  [64000/70415]
loss: 0.185606  [16500/70415]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.131891 

Epoch 2
-------------------------------
loss: 0.037753  [    0/70415]
loss: 0.083569  [ 6400/70415]
loss: 0.141434  [12800/70415]
loss: 0.154044  [19200/70415]
loss: 0.145731  [25600/70415]
loss: 0.153847  [32000/70415]
loss: 0.208318  [38400/70415]
loss: 0.147897  [44800/70415]
loss: 0.231952  [51200/70415]
loss: 0.087190  [57600/70415]
loss: 0.065264  [64000/70415]
loss: 0.264383  [16500/70415]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.111890 

Epoch 3
-------------------------------
loss: 0.083051  [    0/70415]
loss: 0.071180  [ 6400/70415]
loss: 0.028089  [12800/70415]
loss: 0.174580  [19200/70415]
loss: 0.132041  [25600/70415]
loss: 0.074214  [32000/70415]
loss: 0.206001  [38400/70415]
loss: 0.132036  [44800/70415]
loss: 0.101698  [51200/70415]
loss: 0.097352  [57600/70415]
loss: 0.119039  [64000/70415]
loss: 0.074446  [16500/70415]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.110929 

Epoch 4
-------------------------------
loss: 0.143542  [    0/70415]
loss: 0.087426  [ 6400/70415]
loss: 0.072998  [12800/70415]
loss: 0.105102  [19200/70415]
loss: 0.043351  [25600/70415]
loss: 0.049666  [32000/70415]
loss: 0.126340  [38400/70415]
loss: 0.118749  [44800/70415]
loss: 0.105021  [51200/70415]
loss: 0.145626  [57600/70415]
loss: 0.109154  [64000/70415]
loss: 0.136252  [16500/70415]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.108895 

Epoch 5
-------------------------------
loss: 0.100960  [    0/70415]
loss: 0.066379  [ 6400/70415]
loss: 0.085915  [12800/70415]
loss: 0.090440  [19200/70415]
loss: 0.243515  [25600/70415]
loss: 0.080789  [32000/70415]
loss: 0.134668  [38400/70415]
loss: 0.046232  [44800/70415]
loss: 0.074614  [51200/70415]
loss: 0.053903  [57600/70415]
loss: 0.101426  [64000/70415]
loss: 0.114049  [16500/70415]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.109599 

Epoch 6
-------------------------------
loss: 0.081141  [    0/70415]
loss: 0.179824  [ 6400/70415]
loss: 0.163011  [12800/70415]
loss: 0.166616  [19200/70415]
loss: 0.079818  [25600/70415]
loss: 0.050400  [32000/70415]
loss: 0.096074  [38400/70415]
loss: 0.185388  [44800/70415]
loss: 0.132208  [51200/70415]
loss: 0.049148  [57600/70415]
loss: 0.091728  [64000/70415]
loss: 0.194767  [16500/70415]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.123599 

Epoch 7
-------------------------------
loss: 0.080138  [    0/70415]
loss: 0.049227  [ 6400/70415]
loss: 0.051621  [12800/70415]
loss: 0.038069  [19200/70415]
loss: 0.067507  [25600/70415]
loss: 0.074010  [32000/70415]
loss: 0.167046  [38400/70415]
loss: 0.097489  [44800/70415]
loss: 0.060122  [51200/70415]
loss: 0.149803  [57600/70415]
loss: 0.031745  [64000/70415]
loss: 0.285164  [16500/70415]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.183258 

Epoch 8
-------------------------------
loss: 0.047660  [    0/70415]
loss: 0.238603  [ 6400/70415]
loss: 0.128135  [12800/70415]
loss: 0.096675  [19200/70415]
loss: 0.085578  [25600/70415]
loss: 0.087783  [32000/70415]
loss: 0.193127  [38400/70415]
loss: 0.060901  [44800/70415]
loss: 0.066119  [51200/70415]
loss: 0.071471  [57600/70415]
loss: 0.090833  [64000/70415]
loss: 0.005059  [16500/70415]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.108022 

Epoch 9
-------------------------------
loss: 0.050148  [    0/70415]
loss: 0.122135  [ 6400/70415]
loss: 0.101061  [12800/70415]
loss: 0.139819  [19200/70415]
loss: 0.086487  [25600/70415]
loss: 0.016573  [32000/70415]
loss: 0.174364  [38400/70415]
loss: 0.034034  [44800/70415]
loss: 0.107229  [51200/70415]
loss: 0.034255  [57600/70415]
loss: 0.026103  [64000/70415]
loss: 0.056012  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.104997 

Epoch 10
-------------------------------
loss: 0.125495  [    0/70415]
loss: 0.080560  [ 6400/70415]
loss: 0.085352  [12800/70415]
loss: 0.172852  [19200/70415]
loss: 0.131226  [25600/70415]
loss: 0.132302  [32000/70415]
loss: 0.058231  [38400/70415]
loss: 0.165708  [44800/70415]
loss: 0.065173  [51200/70415]
loss: 0.066886  [57600/70415]
loss: 0.100730  [64000/70415]
loss: 0.186714  [16500/70415]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.115348 

Epoch 11
-------------------------------
loss: 0.240677  [    0/70415]
loss: 0.073979  [ 6400/70415]
loss: 0.026834  [12800/70415]
loss: 0.031338  [19200/70415]
loss: 0.107583  [25600/70415]
loss: 0.063520  [32000/70415]
loss: 0.155215  [38400/70415]
loss: 0.094127  [44800/70415]
loss: 0.130119  [51200/70415]
loss: 0.050343  [57600/70415]
loss: 0.097804  [64000/70415]
loss: 0.053061  [16500/70415]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.107093 

Epoch 12
-------------------------------
loss: 0.042464  [    0/70415]
loss: 0.030685  [ 6400/70415]
loss: 0.058803  [12800/70415]
loss: 0.071159  [19200/70415]
loss: 0.065087  [25600/70415]
loss: 0.180763  [32000/70415]
loss: 0.034601  [38400/70415]
loss: 0.123977  [44800/70415]
loss: 0.056925  [51200/70415]
loss: 0.040950  [57600/70415]
loss: 0.036857  [57600/71333]
loss: 0.052160  [64000/71333]
loss: 0.055272  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.148640 

Epoch 45
-------------------------------
loss: 0.045850  [    0/71333]
loss: 1.623943  [ 6400/71333]
loss: 0.051102  [12800/71333]
loss: 0.014745  [19200/71333]
loss: 0.030673  [25600/71333]
loss: 0.012602  [32000/71333]
loss: 0.027087  [38400/71333]
loss: 0.098992  [44800/71333]
loss: 0.085838  [51200/71333]
loss: 0.064491  [57600/71333]
loss: 0.040940  [64000/71333]
loss: 0.033524  [70400/71333]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.162340 

Epoch 46
-------------------------------
loss: 0.112284  [    0/71333]
loss: 0.054164  [ 6400/71333]
loss: 0.030941  [12800/71333]
loss: 0.126662  [19200/71333]
loss: 0.061082  [25600/71333]
loss: 1.701089  [32000/71333]
loss: 0.082799  [38400/71333]
loss: 0.069028  [44800/71333]
loss: 0.029060  [51200/71333]
loss: 0.025790  [57600/71333]
loss: 0.105414  [64000/71333]
loss: 0.063972  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.150477 

Epoch 47
-------------------------------
loss: 0.040780  [    0/71333]
loss: 0.044473  [ 6400/71333]
loss: 0.071768  [12800/71333]
loss: 0.024094  [19200/71333]
loss: 0.064163  [25600/71333]
loss: 0.079838  [32000/71333]
loss: 0.057236  [38400/71333]
loss: 0.060435  [44800/71333]
loss: 0.040025  [51200/71333]
loss: 0.019987  [57600/71333]
loss: 0.008916  [64000/71333]
loss: 0.008027  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.148410 

Epoch 48
-------------------------------
loss: 0.071498  [    0/71333]
loss: 0.045035  [ 6400/71333]
loss: 0.015835  [12800/71333]
loss: 0.074989  [19200/71333]
loss: 0.089613  [25600/71333]
loss: 0.052472  [32000/71333]
loss: 0.098599  [38400/71333]
loss: 0.037408  [44800/71333]
loss: 0.012413  [51200/71333]
loss: 0.016037  [57600/71333]
loss: 0.042536  [64000/71333]
loss: 0.019718  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.148954 

Epoch 49
-------------------------------
loss: 0.032329  [    0/71333]
loss: 0.073001  [ 6400/71333]
loss: 0.036058  [12800/71333]
loss: 0.012214  [19200/71333]
loss: 0.115747  [25600/71333]
loss: 0.067922  [32000/71333]
loss: 0.069792  [38400/71333]
loss: 0.036856  [44800/71333]
loss: 0.048684  [51200/71333]
loss: 0.055086  [57600/71333]
loss: 0.104526  [64000/71333]
loss: 0.072407  [70400/71333]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.151376 

Epoch 50
-------------------------------
loss: 0.013225  [    0/71333]
loss: 0.082981  [ 6400/71333]
loss: 0.140184  [12800/71333]
loss: 1.589869  [19200/71333]
loss: 0.020673  [25600/71333]
loss: 1.587720  [32000/71333]
loss: 0.018245  [38400/71333]
loss: 0.058353  [44800/71333]
loss: 0.052322  [51200/71333]
loss: 0.071926  [57600/71333]
loss: 0.024110  [64000/71333]
loss: 0.019512  [70400/71333]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.154766 

Epoch 1
-------------------------------
loss: 0.696885  [    0/70588]
loss: 0.214930  [ 6400/70588]
loss: 0.360393  [12800/70588]
loss: 0.105684  [19200/70588]
loss: 0.181345  [25600/70588]
loss: 0.240085  [32000/70588]
loss: 0.181590  [38400/70588]
loss: 0.143070  [44800/70588]
loss: 0.127949  [51200/70588]
loss: 0.261180  [57600/70588]
loss: 0.249249  [64000/70588]
loss: 0.233150  [70400/70588]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.204624 

Epoch 2
-------------------------------
loss: 0.205975  [    0/70588]
loss: 0.156949  [ 6400/70588]
loss: 0.181795  [12800/70588]
loss: 0.187259  [19200/70588]
loss: 0.162823  [25600/70588]
loss: 0.137297  [32000/70588]
loss: 0.198363  [38400/70588]
loss: 0.192145  [44800/70588]
loss: 0.085866  [51200/70588]
loss: 0.144286  [57600/70588]
loss: 0.123163  [64000/70588]
loss: 0.102165  [70400/70588]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.165227 

Epoch 3
-------------------------------
loss: 0.208337  [    0/70588]
loss: 0.124225  [ 6400/70588]
loss: 0.232517  [12800/70588]
loss: 0.140546  [19200/70588]
loss: 0.242492  [25600/70588]
loss: 0.098889  [32000/70588]
loss: 0.151104  [38400/70588]
loss: 0.104249  [44800/70588]
loss: 0.207403  [51200/70588]
loss: 0.262115  [57600/70588]
loss: 0.317993  [64000/70588]
loss: 0.091050  [70400/70588]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.156428 

Epoch 4
-------------------------------
loss: 0.142722  [    0/70588]
loss: 0.180560  [ 6400/70588]
loss: 0.170269  [12800/70588]
loss: 0.167733  [19200/70588]
loss: 0.237969  [25600/70588]
loss: 0.108470  [32000/70588]
loss: 0.071112  [38400/70588]
loss: 0.127992  [44800/70588]
loss: 0.129667  [51200/70588]
loss: 0.150456  [57600/70588]
loss: 0.107697  [64000/70588]
loss: 0.186234  [70400/70588]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.152430 

Epoch 5
-------------------------------
loss: 0.149737  [    0/70588]
loss: 0.308339  [ 6400/70588]
loss: 0.143891  [12800/70588]
loss: 0.282975  [19200/70588]
loss: 0.155688  [25600/70588]
loss: 0.195214  [32000/70588]
loss: 0.150276  [38400/70588]
loss: 0.085514  [44800/70588]
loss: 0.061453  [51200/70588]
loss: 0.106766  [57600/70588]
loss: 0.122739  [64000/70588]
loss: 0.197508  [70400/70588]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.148765 

Epoch 6
-------------------------------
loss: 0.138518  [    0/70588]
loss: 0.107393  [ 6400/70588]
loss: 0.165010  [12800/70588]
loss: 0.265120  [19200/70588]
loss: 0.151154  [25600/70588]
loss: 0.119115  [32000/70588]
loss: 0.079074  [38400/70588]
loss: 0.127141  [44800/70588]
loss: 0.134818  [51200/70588]
loss: 0.277611  [57600/70588]
loss: 0.115780  [64000/70588]
loss: 0.124532  [70400/70588]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.140023 

Epoch 7
-------------------------------
loss: 0.090129  [    0/70588]
loss: 0.120251  [ 6400/70588]
loss: 0.151997  [12800/70588]
loss: 0.120145  [19200/70588]
loss: 0.094379  [25600/70588]
loss: 0.174546  [32000/70588]
loss: 0.087901  [38400/70588]
loss: 0.178645  [44800/70588]
loss: 0.083612  [51200/70588]
loss: 0.048521  [57600/70588]
loss: 0.128695  [64000/70588]
loss: 0.174915  [70400/70588]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153172 

Epoch 8
-------------------------------
loss: 0.078902  [    0/70588]
loss: 0.131600  [ 6400/70588]
loss: 0.190398  [12800/70588]
loss: 0.162161  [19200/70588]
loss: 0.093142  [25600/70588]
loss: 0.111625  [32000/70588]
loss: 0.025301  [38400/70588]
loss: 0.102120  [44800/70588]
loss: 0.092825  [51200/70588]
loss: 0.217539  [57600/70588]
loss: 0.060368  [64000/70588]
loss: 0.116521  [70400/70588]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.154194 

Epoch 9
-------------------------------
loss: 0.265310  [    0/70588]
loss: 0.110962  [ 6400/70588]
loss: 0.149920  [12800/70588]
loss: 0.177818  [19200/70588]
loss: 0.153102  [25600/70588]
loss: 0.085221  [32000/70588]
loss: 0.128034  [38400/70588]
loss: 0.142751  [44800/70588]
loss: 0.079103  [51200/70588]
loss: 0.089190  [57600/70588]
loss: 0.114801  [64000/70588]
loss: 0.072547  [70400/70588]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.150657 

Epoch 10
-------------------------------
loss: 0.132834  [    0/70588]
loss: 0.260444  [ 6400/70588]
loss: 0.138805  [12800/70588]
loss: 0.096318  [19200/70588]
loss: 0.174401  [25600/70588]
loss: 0.159120  [32000/70588]
loss: 0.139506  [38400/70588]
loss: 0.119086  [44800/70588]
loss: 0.097485  [51200/70588]
loss: 0.056052  [57600/70588]
loss: 0.060581  [64000/70588]
loss: 0.074169  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.147584 

Epoch 11
-------------------------------
loss: 0.055992  [    0/70588]
loss: 0.057372  [ 6400/70588]
loss: 0.070016  [12800/70588]
loss: 0.165036  [19200/70588]
loss: 0.223001  [25600/70588]
loss: 0.124632  [32000/70588]
loss: 0.123964  [38400/70588]
loss: 0.115143  [44800/70588]
loss: 0.095519  [51200/70588]
loss: 0.046554  [57600/70588]
loss: 0.148875  [64000/70588]
loss: 0.162545  [70400/70588]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.150386 

Epoch 12
-------------------------------
loss: 0.100419  [    0/70588]
loss: 0.170402  [ 6400/70588]
loss: 0.089562  [12800/70588]
loss: 0.038716  [19200/70588]
loss: 0.140764  [25600/70588]
loss: 0.252868  [32000/70588]
loss: 0.125332  [38400/70588]
loss: 0.195173  [44800/70588]
loss: 0.150370  [51200/70588]
loss: 0.134540  [57600/70588]
loss: 0.060748  [25600/71198]
loss: 0.002978  [32000/71198]
loss: 0.015847  [38400/71198]
loss: 0.030952  [44800/71198]
loss: 0.063433  [51200/71198]
loss: 0.103679  [57600/71198]
loss: 0.074163  [64000/71198]
loss: 0.076887  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070647 

Epoch 42
-------------------------------
loss: 0.093412  [    0/71198]
loss: 0.010609  [ 6400/71198]
loss: 0.021747  [12800/71198]
loss: 0.061933  [19200/71198]
loss: 0.049566  [25600/71198]
loss: 0.044663  [32000/71198]
loss: 0.075334  [38400/71198]
loss: 0.058276  [44800/71198]
loss: 0.104642  [51200/71198]
loss: 0.050697  [57600/71198]
loss: 0.103605  [64000/71198]
loss: 0.017945  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.075034 

Epoch 43
-------------------------------
loss: 0.051638  [    0/71198]
loss: 0.005733  [ 6400/71198]
loss: 0.158055  [12800/71198]
loss: 0.033770  [19200/71198]
loss: 0.072559  [25600/71198]
loss: 0.038672  [32000/71198]
loss: 0.071637  [38400/71198]
loss: 0.025365  [44800/71198]
loss: 0.031275  [51200/71198]
loss: 0.027505  [57600/71198]
loss: 0.027981  [64000/71198]
loss: 0.045993  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070112 

Epoch 44
-------------------------------
loss: 0.030781  [    0/71198]
loss: 0.098176  [ 6400/71198]
loss: 0.048235  [12800/71198]
loss: 0.058377  [19200/71198]
loss: 0.016530  [25600/71198]
loss: 0.028495  [32000/71198]
loss: 0.080186  [38400/71198]
loss: 0.032783  [44800/71198]
loss: 0.078402  [51200/71198]
loss: 0.015776  [57600/71198]
loss: 0.095496  [64000/71198]
loss: 0.071124  [70400/71198]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.073468 

Epoch 45
-------------------------------
loss: 0.014300  [    0/71198]
loss: 0.059276  [ 6400/71198]
loss: 0.073596  [12800/71198]
loss: 0.127119  [19200/71198]
loss: 0.009952  [25600/71198]
loss: 0.080856  [32000/71198]
loss: 0.022168  [38400/71198]
loss: 0.002154  [44800/71198]
loss: 0.008376  [51200/71198]
loss: 0.008224  [57600/71198]
loss: 0.048191  [64000/71198]
loss: 0.009567  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073597 

Epoch 46
-------------------------------
loss: 0.005896  [    0/71198]
loss: 0.077842  [ 6400/71198]
loss: 0.035555  [12800/71198]
loss: 0.015977  [19200/71198]
loss: 0.069566  [25600/71198]
loss: 0.021835  [32000/71198]
loss: 0.080953  [38400/71198]
loss: 0.020093  [44800/71198]
loss: 0.022334  [51200/71198]
loss: 0.008156  [57600/71198]
loss: 0.038285  [64000/71198]
loss: 0.034697  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.074892 

Epoch 47
-------------------------------
loss: 0.047679  [    0/71198]
loss: 0.115527  [ 6400/71198]
loss: 0.081012  [12800/71198]
loss: 0.019607  [19200/71198]
loss: 0.036439  [25600/71198]
loss: 0.009051  [32000/71198]
loss: 0.106297  [38400/71198]
loss: 0.043159  [44800/71198]
loss: 0.020115  [51200/71198]
loss: 0.142159  [57600/71198]
loss: 0.033255  [64000/71198]
loss: 0.022839  [70400/71198]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076444 

Epoch 48
-------------------------------
loss: 0.086075  [    0/71198]
loss: 0.081541  [ 6400/71198]
loss: 0.107907  [12800/71198]
loss: 0.023503  [19200/71198]
loss: 0.008204  [25600/71198]
loss: 0.029787  [32000/71198]
loss: 0.087594  [38400/71198]
loss: 0.106338  [44800/71198]
loss: 0.029706  [51200/71198]
loss: 0.054386  [57600/71198]
loss: 0.069881  [64000/71198]
loss: 0.030593  [70400/71198]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070615 

Epoch 49
-------------------------------
loss: 0.073307  [    0/71198]
loss: 0.115057  [ 6400/71198]
loss: 0.015552  [12800/71198]
loss: 0.016500  [19200/71198]
loss: 0.032238  [25600/71198]
loss: 0.056490  [32000/71198]
loss: 0.054748  [38400/71198]
loss: 0.115997  [44800/71198]
loss: 0.076395  [51200/71198]
loss: 0.058787  [57600/71198]
loss: 0.032948  [64000/71198]
loss: 0.036272  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076036 

Epoch 50
-------------------------------
loss: 0.010704  [    0/71198]
loss: 0.035715  [ 6400/71198]
loss: 0.074776  [12800/71198]
loss: 0.035635  [19200/71198]
loss: 0.029143  [25600/71198]
loss: 0.009882  [32000/71198]
loss: 0.053648  [38400/71198]
loss: 0.013087  [44800/71198]
loss: 0.028445  [51200/71198]
loss: 0.039592  [57600/71198]
loss: 0.114760  [64000/71198]
loss: 0.155736  [70400/71198]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076224 

Epoch 1
-------------------------------
loss: 0.717496  [    0/69711]
loss: 0.129610  [ 6400/69711]
loss: 0.132736  [12800/69711]
loss: 0.107776  [19200/69711]
loss: 0.167456  [25600/69711]
loss: 0.133496  [32000/69711]
loss: 0.062107  [38400/69711]
loss: 0.123843  [44800/69711]
loss: 0.041844  [51200/69711]
loss: 0.036064  [57600/69711]
loss: 0.029256  [64000/69711]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.088945 

Epoch 2
-------------------------------
loss: 0.336027  [    0/69711]
loss: 0.098076  [ 6400/69711]
loss: 0.042532  [12800/69711]
loss: 0.105330  [19200/69711]
loss: 0.165150  [25600/69711]
loss: 0.150097  [32000/69711]
loss: 0.074313  [38400/69711]
loss: 0.065158  [44800/69711]
loss: 0.082624  [51200/69711]
loss: 0.174997  [57600/69711]
loss: 0.161216  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.070325 

Epoch 3
-------------------------------
loss: 0.086454  [    0/69711]
loss: 0.131273  [ 6400/69711]
loss: 0.129604  [12800/69711]
loss: 0.043504  [19200/69711]
loss: 0.129626  [25600/69711]
loss: 0.032716  [32000/69711]
loss: 0.095699  [38400/69711]
loss: 0.076230  [44800/69711]
loss: 0.153869  [51200/69711]
loss: 0.059406  [57600/69711]
loss: 0.067063  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.069986 

Epoch 4
-------------------------------
loss: 0.091255  [    0/69711]
loss: 0.150883  [ 6400/69711]
loss: 0.066158  [12800/69711]
loss: 0.074504  [19200/69711]
loss: 0.030272  [25600/69711]
loss: 0.087293  [32000/69711]
loss: 0.024159  [38400/69711]
loss: 0.136229  [44800/69711]
loss: 0.053753  [51200/69711]
loss: 0.061785  [57600/69711]
loss: 0.073725  [64000/69711]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.074837 

Epoch 5
-------------------------------
loss: 0.119625  [    0/69711]
loss: 0.126056  [ 6400/69711]
loss: 0.026915  [12800/69711]
loss: 0.063715  [19200/69711]
loss: 0.050462  [25600/69711]
loss: 0.140067  [32000/69711]
loss: 0.065890  [38400/69711]
loss: 0.336822  [44800/69711]
loss: 0.032374  [51200/69711]
loss: 0.070102  [57600/69711]
loss: 0.086235  [64000/69711]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.065538 

Epoch 6
-------------------------------
loss: 0.051750  [    0/69711]
loss: 0.065386  [ 6400/69711]
loss: 0.052138  [12800/69711]
loss: 0.075056  [19200/69711]
loss: 0.114922  [25600/69711]
loss: 0.040456  [32000/69711]
loss: 0.072796  [38400/69711]
loss: 0.145477  [44800/69711]
loss: 0.196174  [51200/69711]
loss: 0.085123  [57600/69711]
loss: 0.091831  [64000/69711]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.077799 

Epoch 7
-------------------------------
loss: 0.066591  [    0/69711]
loss: 0.087814  [ 6400/69711]
loss: 0.055460  [12800/69711]
loss: 0.161994  [19200/69711]
loss: 0.055744  [25600/69711]
loss: 0.106042  [32000/69711]
loss: 0.063887  [38400/69711]
loss: 0.122592  [44800/69711]
loss: 0.039701  [51200/69711]
loss: 0.064997  [57600/69711]
loss: 0.125657  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.072500 

Epoch 8
-------------------------------
loss: 0.051864  [    0/69711]
loss: 0.058615  [ 6400/69711]
loss: 0.022894  [12800/69711]
loss: 0.115254  [19200/69711]
loss: 0.054547  [25600/69711]
loss: 0.106967  [32000/69711]
loss: 0.019077  [38400/69711]
loss: 0.108243  [44800/69711]
loss: 0.018352  [51200/69711]
loss: 0.033536  [57600/69711]
loss: 0.069310  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074002 

Epoch 9
-------------------------------
loss: 0.079534  [    0/69711]
loss: 0.020718  [ 6400/69711]
loss: 0.106522  [12800/69711]
loss: 0.178540  [19200/69711]
loss: 0.106145  [25600/69711]
loss: 0.075005  [32000/69711]
loss: 0.063322  [38400/69711]
loss: 0.069537  [44800/69711]
loss: 0.026542  [51200/69711]
loss: 0.073678  [57600/69711]
loss: 0.086918  [64000/69711]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067996 

loss: 0.028815  [57600/72298]
loss: 0.000540  [64000/72298]
loss: 0.050912  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.093796 

Epoch 45
-------------------------------
loss: 0.009059  [    0/72298]
loss: 0.004029  [ 6400/72298]
loss: 0.008548  [12800/72298]
loss: 0.014311  [19200/72298]
loss: 0.040697  [25600/72298]
loss: 0.034535  [32000/72298]
loss: 0.093685  [38400/72298]
loss: 0.000137  [44800/72298]
loss: 0.013386  [51200/72298]
loss: 0.067356  [57600/72298]
loss: 0.007842  [64000/72298]
loss: 0.030493  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.089626 

Epoch 46
-------------------------------
loss: 0.004344  [    0/72298]
loss: 0.010252  [ 6400/72298]
loss: 0.001505  [12800/72298]
loss: 0.002120  [19200/72298]
loss: 0.000612  [25600/72298]
loss: 0.005180  [32000/72298]
loss: 0.000468  [38400/72298]
loss: 0.013054  [44800/72298]
loss: 0.023465  [51200/72298]
loss: 0.001363  [57600/72298]
loss: 0.060035  [64000/72298]
loss: 0.009807  [70400/72298]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.099476 

Epoch 47
-------------------------------
loss: 0.002938  [    0/72298]
loss: 0.027242  [ 6400/72298]
loss: 0.001609  [12800/72298]
loss: 0.030523  [19200/72298]
loss: 0.075518  [25600/72298]
loss: 0.000831  [32000/72298]
loss: 0.010403  [38400/72298]
loss: 0.007521  [44800/72298]
loss: 0.039898  [51200/72298]
loss: 0.002428  [57600/72298]
loss: 0.011242  [64000/72298]
loss: 0.064682  [70400/72298]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.087835 

Epoch 48
-------------------------------
loss: 0.016445  [    0/72298]
loss: 0.004316  [ 6400/72298]
loss: 0.009297  [12800/72298]
loss: 0.005968  [19200/72298]
loss: 0.018034  [25600/72298]
loss: 0.030556  [32000/72298]
loss: 0.028361  [38400/72298]
loss: 0.007078  [44800/72298]
loss: 0.005548  [51200/72298]
loss: 0.046220  [57600/72298]
loss: 0.042809  [64000/72298]
loss: 0.000778  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.097352 

Epoch 49
-------------------------------
loss: 0.019276  [    0/72298]
loss: 0.067191  [ 6400/72298]
loss: 0.090078  [12800/72298]
loss: 0.023659  [19200/72298]
loss: 0.041117  [25600/72298]
loss: 0.005987  [32000/72298]
loss: 0.086823  [38400/72298]
loss: 0.002127  [44800/72298]
loss: 0.009092  [51200/72298]
loss: 0.047357  [57600/72298]
loss: 0.004695  [64000/72298]
loss: 0.067417  [70400/72298]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.092147 

Epoch 50
-------------------------------
loss: 0.020695  [    0/72298]
loss: 0.071583  [ 6400/72298]
loss: 0.027618  [12800/72298]
loss: 0.020505  [19200/72298]
loss: 0.058637  [25600/72298]
loss: 0.012017  [32000/72298]
loss: 0.002205  [38400/72298]
loss: 0.048284  [44800/72298]
loss: 0.002581  [51200/72298]
loss: 0.001938  [57600/72298]
loss: 0.035102  [64000/72298]
loss: 0.000813  [70400/72298]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.090525 

Epoch 1
-------------------------------
loss: 0.671004  [    0/72227]
loss: 0.325510  [ 6400/72227]
loss: 0.314479  [12800/72227]
loss: 0.197320  [19200/72227]
loss: 0.106780  [25600/72227]
loss: 0.087156  [32000/72227]
loss: 0.089696  [38400/72227]
loss: 0.057417  [44800/72227]
loss: 0.071208  [51200/72227]
loss: 0.049720  [57600/72227]
loss: 0.086753  [64000/72227]
loss: 0.041302  [70400/72227]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.107095 

Epoch 2
-------------------------------
loss: 0.048617  [    0/72227]
loss: 0.085657  [ 6400/72227]
loss: 0.076457  [12800/72227]
loss: 0.061123  [19200/72227]
loss: 0.097072  [25600/72227]
loss: 0.103736  [32000/72227]
loss: 0.065039  [38400/72227]
loss: 0.150241  [44800/72227]
loss: 0.160433  [51200/72227]
loss: 0.028431  [57600/72227]
loss: 0.234979  [64000/72227]
loss: 0.145613  [70400/72227]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090563 

Epoch 3
-------------------------------
loss: 0.061542  [    0/72227]
loss: 0.067693  [ 6400/72227]
loss: 0.065807  [12800/72227]
loss: 0.023975  [19200/72227]
loss: 0.053590  [25600/72227]
loss: 0.045167  [32000/72227]
loss: 0.096018  [38400/72227]
loss: 0.035673  [44800/72227]
loss: 0.108052  [51200/72227]
loss: 0.042272  [57600/72227]
loss: 0.021816  [64000/72227]
loss: 0.098886  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.079831 

Epoch 4
-------------------------------
loss: 0.081276  [    0/72227]
loss: 0.014432  [ 6400/72227]
loss: 1.625380  [12800/72227]
loss: 0.024411  [19200/72227]
loss: 0.015754  [25600/72227]
loss: 0.076857  [32000/72227]
loss: 0.044856  [38400/72227]
loss: 0.107612  [44800/72227]
loss: 0.045679  [51200/72227]
loss: 0.032668  [57600/72227]
loss: 0.061454  [64000/72227]
loss: 0.065992  [70400/72227]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.089839 

Epoch 5
-------------------------------
loss: 0.074755  [    0/72227]
loss: 0.082845  [ 6400/72227]
loss: 0.080907  [12800/72227]
loss: 0.036603  [19200/72227]
loss: 0.010303  [25600/72227]
loss: 0.149220  [32000/72227]
loss: 0.077173  [38400/72227]
loss: 0.036572  [44800/72227]
loss: 0.110669  [51200/72227]
loss: 0.036589  [57600/72227]
loss: 0.026247  [64000/72227]
loss: 0.132920  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075485 

Epoch 6
-------------------------------
loss: 0.008403  [    0/72227]
loss: 0.045442  [ 6400/72227]
loss: 0.017505  [12800/72227]
loss: 0.058807  [19200/72227]
loss: 0.033918  [25600/72227]
loss: 0.045691  [32000/72227]
loss: 0.069194  [38400/72227]
loss: 0.018652  [44800/72227]
loss: 0.034169  [51200/72227]
loss: 0.191361  [57600/72227]
loss: 0.084014  [64000/72227]
loss: 0.095598  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075339 

Epoch 7
-------------------------------
loss: 0.201081  [    0/72227]
loss: 0.022844  [ 6400/72227]
loss: 0.025053  [12800/72227]
loss: 0.002378  [19200/72227]
loss: 0.014977  [25600/72227]
loss: 0.052605  [32000/72227]
loss: 0.026072  [38400/72227]
loss: 0.017794  [44800/72227]
loss: 0.029206  [51200/72227]
loss: 0.080188  [57600/72227]
loss: 0.074806  [64000/72227]
loss: 0.054467  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.074194 

Epoch 8
-------------------------------
loss: 0.016275  [    0/72227]
loss: 0.032437  [ 6400/72227]
loss: 0.008342  [12800/72227]
loss: 0.038118  [19200/72227]
loss: 0.037169  [25600/72227]
loss: 0.006851  [32000/72227]
loss: 0.060566  [38400/72227]
loss: 0.047421  [44800/72227]
loss: 0.006711  [51200/72227]
loss: 0.122916  [57600/72227]
loss: 0.027934  [64000/72227]
loss: 0.031882  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072085 

Epoch 9
-------------------------------
loss: 0.014030  [    0/72227]
loss: 0.009542  [ 6400/72227]
loss: 0.033981  [12800/72227]
loss: 0.074261  [19200/72227]
loss: 0.032272  [25600/72227]
loss: 0.068549  [32000/72227]
loss: 0.022832  [38400/72227]
loss: 0.028306  [44800/72227]
loss: 0.121750  [51200/72227]
loss: 0.026275  [57600/72227]
loss: 0.071226  [64000/72227]
loss: 0.010699  [70400/72227]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.089040 

Epoch 10
-------------------------------
loss: 0.054687  [    0/72227]
loss: 0.009602  [ 6400/72227]
loss: 0.057356  [12800/72227]
loss: 0.022035  [19200/72227]
loss: 0.010130  [25600/72227]
loss: 0.045348  [32000/72227]
loss: 0.017620  [38400/72227]
loss: 0.019751  [44800/72227]
loss: 0.009210  [51200/72227]
loss: 0.015214  [57600/72227]
loss: 0.035490  [64000/72227]
loss: 0.046950  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.065948 

Epoch 11
-------------------------------
loss: 0.037010  [    0/72227]
loss: 0.056737  [ 6400/72227]
loss: 0.010648  [12800/72227]
loss: 0.034258  [19200/72227]
loss: 0.029778  [25600/72227]
loss: 0.030633  [32000/72227]
loss: 0.011061  [38400/72227]
loss: 0.018072  [44800/72227]
loss: 0.038501  [51200/72227]
loss: 0.005583  [57600/72227]
loss: 0.205642  [64000/72227]
loss: 0.087028  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075316 

Epoch 12
-------------------------------
loss: 0.094931  [    0/72227]
loss: 0.049748  [ 6400/72227]
loss: 0.044257  [12800/72227]
loss: 0.023763  [19200/72227]
loss: 0.130797  [25600/72227]
loss: 0.075372  [32000/72227]
loss: 0.011333  [38400/72227]
loss: 0.044635  [44800/72227]
loss: 0.066002  [51200/72227]
loss: 0.085739  [57600/72227]
loss: 0.111166  [57600/70787]
loss: 0.086843  [64000/70787]
loss: 0.031643  [70400/70787]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.088650 

Epoch 45
-------------------------------
loss: 0.025028  [    0/70787]
loss: 0.092917  [ 6400/70787]
loss: 0.016741  [12800/70787]
loss: 0.057354  [19200/70787]
loss: 0.078889  [25600/70787]
loss: 0.055955  [32000/70787]
loss: 0.043132  [38400/70787]
loss: 0.035444  [44800/70787]
loss: 0.054698  [51200/70787]
loss: 0.069688  [57600/70787]
loss: 0.046289  [64000/70787]
loss: 0.016541  [70400/70787]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.090975 

Epoch 46
-------------------------------
loss: 0.027072  [    0/70787]
loss: 0.156677  [ 6400/70787]
loss: 0.008698  [12800/70787]
loss: 0.020485  [19200/70787]
loss: 0.032084  [25600/70787]
loss: 0.039471  [32000/70787]
loss: 0.128399  [38400/70787]
loss: 0.021777  [44800/70787]
loss: 0.024211  [51200/70787]
loss: 0.049612  [57600/70787]
loss: 0.032588  [64000/70787]
loss: 0.213497  [70400/70787]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.097329 

Epoch 47
-------------------------------
loss: 0.034027  [    0/70787]
loss: 0.021404  [ 6400/70787]
loss: 0.072485  [12800/70787]
loss: 0.055697  [19200/70787]
loss: 0.038132  [25600/70787]
loss: 0.052576  [32000/70787]
loss: 0.034794  [38400/70787]
loss: 0.028166  [44800/70787]
loss: 0.119384  [51200/70787]
loss: 0.025811  [57600/70787]
loss: 0.056395  [64000/70787]
loss: 0.034280  [70400/70787]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083648 

Epoch 48
-------------------------------
loss: 0.007818  [    0/70787]
loss: 0.105400  [ 6400/70787]
loss: 0.087055  [12800/70787]
loss: 0.043683  [19200/70787]
loss: 0.080098  [25600/70787]
loss: 0.089531  [32000/70787]
loss: 0.114326  [38400/70787]
loss: 0.057969  [44800/70787]
loss: 0.087135  [51200/70787]
loss: 0.012039  [57600/70787]
loss: 0.030486  [64000/70787]
loss: 0.053434  [70400/70787]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.093228 

Epoch 49
-------------------------------
loss: 0.029660  [    0/70787]
loss: 0.039630  [ 6400/70787]
loss: 0.036050  [12800/70787]
loss: 0.048297  [19200/70787]
loss: 0.031441  [25600/70787]
loss: 0.103125  [32000/70787]
loss: 0.032380  [38400/70787]
loss: 0.037385  [44800/70787]
loss: 0.076668  [51200/70787]
loss: 0.074367  [57600/70787]
loss: 0.072693  [64000/70787]
loss: 0.088246  [70400/70787]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.202525 

Epoch 50
-------------------------------
loss: 0.274561  [    0/70787]
loss: 0.044278  [ 6400/70787]
loss: 0.043810  [12800/70787]
loss: 0.028467  [19200/70787]
loss: 0.071699  [25600/70787]
loss: 0.045562  [32000/70787]
loss: 0.014738  [38400/70787]
loss: 0.081220  [44800/70787]
loss: 0.039175  [51200/70787]
loss: 0.055766  [57600/70787]
loss: 0.084078  [64000/70787]
loss: 0.072799  [70400/70787]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.087354 

Epoch 1
-------------------------------
loss: 0.720770  [    0/70562]
loss: 0.152497  [ 6400/70562]
loss: 0.224059  [12800/70562]
loss: 0.103292  [19200/70562]
loss: 0.102261  [25600/70562]
loss: 0.139694  [32000/70562]
loss: 0.032648  [38400/70562]
loss: 0.107700  [44800/70562]
loss: 0.091810  [51200/70562]
loss: 0.142782  [57600/70562]
loss: 0.148821  [64000/70562]
loss: 0.069839  [70400/70562]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.098828 

Epoch 2
-------------------------------
loss: 0.110741  [    0/70562]
loss: 0.119506  [ 6400/70562]
loss: 0.178199  [12800/70562]
loss: 0.100742  [19200/70562]
loss: 0.060254  [25600/70562]
loss: 0.172792  [32000/70562]
loss: 0.088828  [38400/70562]
loss: 0.057368  [44800/70562]
loss: 0.150118  [51200/70562]
loss: 0.098850  [57600/70562]
loss: 0.081984  [64000/70562]
loss: 0.050423  [70400/70562]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.098376 

Epoch 3
-------------------------------
loss: 0.058823  [    0/70562]
loss: 0.128654  [ 6400/70562]
loss: 0.128032  [12800/70562]
loss: 0.048472  [19200/70562]
loss: 0.127357  [25600/70562]
loss: 0.082828  [32000/70562]
loss: 0.086803  [38400/70562]
loss: 0.022782  [44800/70562]
loss: 0.226407  [51200/70562]
loss: 0.039855  [57600/70562]
loss: 0.199888  [64000/70562]
loss: 0.102348  [70400/70562]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088203 

Epoch 4
-------------------------------
loss: 0.058219  [    0/70562]
loss: 0.143486  [ 6400/70562]
loss: 0.041640  [12800/70562]
loss: 0.050460  [19200/70562]
loss: 0.249228  [25600/70562]
loss: 0.103850  [32000/70562]
loss: 0.058157  [38400/70562]
loss: 0.013601  [44800/70562]
loss: 0.102304  [51200/70562]
loss: 0.144951  [57600/70562]
loss: 0.147481  [64000/70562]
loss: 0.050089  [70400/70562]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089518 

Epoch 5
-------------------------------
loss: 0.114478  [    0/70562]
loss: 0.056475  [ 6400/70562]
loss: 0.102617  [12800/70562]
loss: 0.120463  [19200/70562]
loss: 0.173930  [25600/70562]
loss: 0.139919  [32000/70562]
loss: 0.077581  [38400/70562]
loss: 0.139750  [44800/70562]
loss: 0.034429  [51200/70562]
loss: 0.118222  [57600/70562]
loss: 0.051656  [64000/70562]
loss: 0.063197  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.077296 

Epoch 6
-------------------------------
loss: 0.073175  [    0/70562]
loss: 0.014637  [ 6400/70562]
loss: 0.042847  [12800/70562]
loss: 0.063972  [19200/70562]
loss: 0.046049  [25600/70562]
loss: 0.075297  [32000/70562]
loss: 0.045177  [38400/70562]
loss: 0.145667  [44800/70562]
loss: 0.021925  [51200/70562]
loss: 0.025238  [57600/70562]
loss: 0.074467  [64000/70562]
loss: 0.036140  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080046 

Epoch 7
-------------------------------
loss: 0.085808  [    0/70562]
loss: 0.059972  [ 6400/70562]
loss: 0.041790  [12800/70562]
loss: 0.050031  [19200/70562]
loss: 0.067524  [25600/70562]
loss: 1.796096  [32000/70562]
loss: 0.024521  [38400/70562]
loss: 0.101412  [44800/70562]
loss: 0.047113  [51200/70562]
loss: 0.109110  [57600/70562]
loss: 0.022625  [64000/70562]
loss: 0.083240  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.077427 

Epoch 8
-------------------------------
loss: 0.039290  [    0/70562]
loss: 0.136173  [ 6400/70562]
loss: 0.041982  [12800/70562]
loss: 0.094566  [19200/70562]
loss: 0.026449  [25600/70562]
loss: 0.072681  [32000/70562]
loss: 0.101639  [38400/70562]
loss: 0.058966  [44800/70562]
loss: 0.080121  [51200/70562]
loss: 0.093140  [57600/70562]
loss: 0.058129  [64000/70562]
loss: 0.077041  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.077808 

Epoch 9
-------------------------------
loss: 0.063866  [    0/70562]
loss: 0.028275  [ 6400/70562]
loss: 0.096961  [12800/70562]
loss: 0.330640  [19200/70562]
loss: 0.054584  [25600/70562]
loss: 0.089533  [32000/70562]
loss: 0.063517  [38400/70562]
loss: 0.071008  [44800/70562]
loss: 0.157071  [51200/70562]
loss: 0.048586  [57600/70562]
loss: 0.026761  [64000/70562]
loss: 0.080845  [70400/70562]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076449 

Epoch 10
-------------------------------
loss: 0.042424  [    0/70562]
loss: 0.066828  [ 6400/70562]
loss: 0.118335  [12800/70562]
loss: 0.055295  [19200/70562]
loss: 0.049586  [25600/70562]
loss: 0.093026  [32000/70562]
loss: 0.062143  [38400/70562]
loss: 0.286377  [44800/70562]
loss: 0.072489  [51200/70562]
loss: 0.202357  [57600/70562]
loss: 0.080114  [64000/70562]
loss: 0.024533  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082778 

Epoch 11
-------------------------------
loss: 0.056911  [    0/70562]
loss: 0.017236  [ 6400/70562]
loss: 0.061501  [12800/70562]
loss: 0.127057  [19200/70562]
loss: 0.031301  [25600/70562]
loss: 0.074220  [32000/70562]
loss: 0.073754  [38400/70562]
loss: 0.051491  [44800/70562]
loss: 0.170852  [51200/70562]
loss: 0.043507  [57600/70562]
loss: 0.103951  [64000/70562]
loss: 0.145361  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081837 

Epoch 12
-------------------------------
loss: 0.050196  [    0/70562]
loss: 0.045223  [ 6400/70562]
loss: 0.061724  [12800/70562]
loss: 0.052388  [19200/70562]
loss: 0.060591  [25600/70562]
loss: 0.076587  [32000/70562]
loss: 0.108269  [38400/70562]
loss: 0.102413  [44800/70562]
loss: 0.056180  [51200/70562]
loss: 0.037107  [57600/70562]
loss: 0.025887  [12800/70196]
loss: 0.031381  [19200/70196]
loss: 0.027570  [25600/70196]
loss: 0.067436  [32000/70196]
loss: 0.040064  [38400/70196]
loss: 0.040141  [44800/70196]
loss: 0.070188  [51200/70196]
loss: 0.032356  [57600/70196]
loss: 0.080689  [64000/70196]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.088808 

Epoch 45
-------------------------------
loss: 0.062201  [    0/70196]
loss: 0.088593  [ 6400/70196]
loss: 0.033562  [12800/70196]
loss: 0.159434  [19200/70196]
loss: 0.016390  [25600/70196]
loss: 0.052709  [32000/70196]
loss: 0.058457  [38400/70196]
loss: 0.061533  [44800/70196]
loss: 0.065476  [51200/70196]
loss: 0.022729  [57600/70196]
loss: 0.047221  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.099024 

Epoch 46
-------------------------------
loss: 0.041341  [    0/70196]
loss: 0.094218  [ 6400/70196]
loss: 0.010678  [12800/70196]
loss: 0.064298  [19200/70196]
loss: 0.044709  [25600/70196]
loss: 0.054106  [32000/70196]
loss: 0.133274  [38400/70196]
loss: 0.079478  [44800/70196]
loss: 0.051400  [51200/70196]
loss: 0.184788  [57600/70196]
loss: 0.044891  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.087236 

Epoch 47
-------------------------------
loss: 0.056492  [    0/70196]
loss: 0.068246  [ 6400/70196]
loss: 0.065982  [12800/70196]
loss: 0.082341  [19200/70196]
loss: 0.055050  [25600/70196]
loss: 0.072871  [32000/70196]
loss: 0.014229  [38400/70196]
loss: 0.065404  [44800/70196]
loss: 0.157563  [51200/70196]
loss: 0.153668  [57600/70196]
loss: 0.040558  [64000/70196]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.097376 

Epoch 48
-------------------------------
loss: 0.019245  [    0/70196]
loss: 0.101968  [ 6400/70196]
loss: 0.030323  [12800/70196]
loss: 0.064200  [19200/70196]
loss: 0.026399  [25600/70196]
loss: 0.081157  [32000/70196]
loss: 0.219111  [38400/70196]
loss: 0.190848  [44800/70196]
loss: 0.128648  [51200/70196]
loss: 0.041250  [57600/70196]
loss: 0.011578  [64000/70196]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.089055 

Epoch 49
-------------------------------
loss: 0.006705  [    0/70196]
loss: 0.033553  [ 6400/70196]
loss: 0.041584  [12800/70196]
loss: 0.020363  [19200/70196]
loss: 0.024288  [25600/70196]
loss: 0.052277  [32000/70196]
loss: 0.010813  [38400/70196]
loss: 0.059336  [44800/70196]
loss: 0.070090  [51200/70196]
loss: 0.084286  [57600/70196]
loss: 0.097865  [64000/70196]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.091167 

Epoch 50
-------------------------------
loss: 0.052779  [    0/70196]
loss: 0.034831  [ 6400/70196]
loss: 0.129787  [12800/70196]
loss: 0.069048  [19200/70196]
loss: 0.080104  [25600/70196]
loss: 0.024317  [32000/70196]
loss: 0.034937  [38400/70196]
loss: 0.029786  [44800/70196]
loss: 0.143708  [51200/70196]
loss: 0.121994  [57600/70196]
loss: 0.046283  [64000/70196]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.090329 

Epoch 1
-------------------------------
loss: 0.714645  [    0/69684]
loss: 0.235392  [ 6400/69684]
loss: 0.150537  [12800/69684]
loss: 0.099928  [19200/69684]
loss: 0.150186  [25600/69684]
loss: 0.117830  [32000/69684]
loss: 0.071737  [38400/69684]
loss: 0.149648  [44800/69684]
loss: 0.177340  [51200/69684]
loss: 0.132891  [57600/69684]
loss: 0.139922  [64000/69684]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.105780 

Epoch 2
-------------------------------
loss: 0.079981  [    0/69684]
loss: 0.137185  [ 6400/69684]
loss: 0.039945  [12800/69684]
loss: 0.076334  [19200/69684]
loss: 0.094500  [25600/69684]
loss: 0.073610  [32000/69684]
loss: 0.091078  [38400/69684]
loss: 0.071540  [44800/69684]
loss: 0.061969  [51200/69684]
loss: 0.068331  [57600/69684]
loss: 0.131442  [64000/69684]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.092417 

Epoch 3
-------------------------------
loss: 0.032764  [    0/69684]
loss: 0.036569  [ 6400/69684]
loss: 0.095807  [12800/69684]
loss: 0.179183  [19200/69684]
loss: 0.219882  [25600/69684]
loss: 0.099159  [32000/69684]
loss: 0.075545  [38400/69684]
loss: 0.053765  [44800/69684]
loss: 0.045404  [51200/69684]
loss: 0.083991  [57600/69684]
loss: 0.031858  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.087633 

Epoch 4
-------------------------------
loss: 0.025825  [    0/69684]
loss: 0.120751  [ 6400/69684]
loss: 0.118730  [12800/69684]
loss: 0.092027  [19200/69684]
loss: 0.054597  [25600/69684]
loss: 0.143035  [32000/69684]
loss: 0.162428  [38400/69684]
loss: 0.177752  [44800/69684]
loss: 0.088355  [51200/69684]
loss: 0.208507  [57600/69684]
loss: 0.035122  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084072 

Epoch 5
-------------------------------
loss: 0.143778  [    0/69684]
loss: 0.119955  [ 6400/69684]
loss: 0.081304  [12800/69684]
loss: 0.032749  [19200/69684]
loss: 0.118998  [25600/69684]
loss: 0.140222  [32000/69684]
loss: 0.125390  [38400/69684]
loss: 0.181310  [44800/69684]
loss: 0.038994  [51200/69684]
loss: 0.105064  [57600/69684]
loss: 0.094655  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.082743 

Epoch 6
-------------------------------
loss: 0.086574  [    0/69684]
loss: 0.071767  [ 6400/69684]
loss: 0.037497  [12800/69684]
loss: 0.144111  [19200/69684]
loss: 0.088659  [25600/69684]
loss: 0.096831  [32000/69684]
loss: 0.149009  [38400/69684]
loss: 0.139134  [44800/69684]
loss: 0.088806  [51200/69684]
loss: 0.111282  [57600/69684]
loss: 0.045262  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.080546 

Epoch 7
-------------------------------
loss: 0.054613  [    0/69684]
loss: 0.045340  [ 6400/69684]
loss: 0.043793  [12800/69684]
loss: 0.247012  [19200/69684]
loss: 0.092694  [25600/69684]
loss: 0.194201  [32000/69684]
loss: 0.053393  [38400/69684]
loss: 0.268857  [44800/69684]
loss: 0.263359  [51200/69684]
loss: 0.130226  [57600/69684]
loss: 0.162843  [64000/69684]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.088234 

Epoch 8
-------------------------------
loss: 0.069653  [    0/69684]
loss: 0.137522  [ 6400/69684]
loss: 0.038286  [12800/69684]
loss: 0.074269  [19200/69684]
loss: 0.098819  [25600/69684]
loss: 0.050242  [32000/69684]
loss: 0.119254  [38400/69684]
loss: 0.091503  [44800/69684]
loss: 0.123640  [51200/69684]
loss: 0.035508  [57600/69684]
loss: 0.038969  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082025 

Epoch 9
-------------------------------
loss: 0.081022  [    0/69684]
loss: 0.030131  [ 6400/69684]
loss: 0.076070  [12800/69684]
loss: 0.148031  [19200/69684]
loss: 0.032620  [25600/69684]
loss: 0.136528  [32000/69684]
loss: 0.022451  [38400/69684]
loss: 0.108380  [44800/69684]
loss: 0.054456  [51200/69684]
loss: 0.156076  [57600/69684]
loss: 0.109569  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085177 

Epoch 10
-------------------------------
loss: 0.070003  [    0/69684]
loss: 0.280161  [ 6400/69684]
loss: 0.104427  [12800/69684]
loss: 0.095180  [19200/69684]
loss: 0.047617  [25600/69684]
loss: 0.101058  [32000/69684]
loss: 0.085346  [38400/69684]
loss: 0.064907  [44800/69684]
loss: 0.034415  [51200/69684]
loss: 0.045272  [57600/69684]
loss: 0.129640  [64000/69684]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.093906 

Epoch 11
-------------------------------
loss: 0.081275  [    0/69684]
loss: 0.063944  [ 6400/69684]
loss: 0.070565  [12800/69684]
loss: 0.031883  [19200/69684]
loss: 0.049297  [25600/69684]
loss: 0.031804  [32000/69684]
loss: 0.063838  [38400/69684]
loss: 0.056088  [44800/69684]
loss: 0.023295  [51200/69684]
loss: 0.129337  [57600/69684]
loss: 0.077351  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.085610 

Epoch 12
-------------------------------
loss: 0.062110  [    0/69684]
loss: 0.065689  [ 6400/69684]
loss: 0.083132  [12800/69684]
loss: 0.185449  [19200/69684]
loss: 0.065395  [25600/69684]
loss: 0.149545  [32000/69684]
loss: 0.108023  [38400/69684]
loss: 0.096636  [44800/69684]
loss: 0.239417  [51200/69684]
loss: 0.024683  [57600/69684]
loss: 0.064577  [64000/69684]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080931 

Epoch 13
-------------------------------
loss: 0.111977  [    0/69684]
loss: 0.079431  [ 6400/69684]
loss: 0.044681  [12800/69684]
loss: 0.143602  [19200/69684]
loss: 0.039840  [25600/69684]
loss: 0.132830  [32000/69684]
loss: 0.047057  [38400/69684]
loss: 0.067619  [64000/69874]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.140956 

Epoch 48
-------------------------------
loss: 0.087291  [    0/69874]
loss: 0.097550  [ 6400/69874]
loss: 0.181916  [12800/69874]
loss: 0.122949  [19200/69874]
loss: 0.162575  [25600/69874]
loss: 0.160954  [32000/69874]
loss: 0.190365  [38400/69874]
loss: 0.202976  [44800/69874]
loss: 0.109298  [51200/69874]
loss: 0.123947  [57600/69874]
loss: 0.146651  [64000/69874]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.161857 

Epoch 49
-------------------------------
loss: 0.149767  [    0/69874]
loss: 0.136124  [ 6400/69874]
loss: 0.128927  [12800/69874]
loss: 0.133808  [19200/69874]
loss: 0.058112  [25600/69874]
loss: 0.130640  [32000/69874]
loss: 0.099582  [38400/69874]
loss: 0.116634  [44800/69874]
loss: 0.121360  [51200/69874]
loss: 0.150879  [57600/69874]
loss: 0.024140  [64000/69874]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.145664 

Epoch 50
-------------------------------
loss: 0.155469  [    0/69874]
loss: 0.101173  [ 6400/69874]
loss: 0.110759  [12800/69874]
loss: 0.126555  [19200/69874]
loss: 0.116568  [25600/69874]
loss: 0.122846  [32000/69874]
loss: 0.086462  [38400/69874]
loss: 0.177763  [44800/69874]
loss: 0.202757  [51200/69874]
loss: 0.079651  [57600/69874]
loss: 0.066889  [64000/69874]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153497 

Epoch 1
-------------------------------
loss: 0.703650  [    0/70676]
loss: 0.174008  [ 6400/70676]
loss: 0.135723  [12800/70676]
loss: 0.126325  [19200/70676]
loss: 0.145649  [25600/70676]
loss: 0.211470  [32000/70676]
loss: 0.227927  [38400/70676]
loss: 0.150075  [44800/70676]
loss: 0.207541  [51200/70676]
loss: 0.156864  [57600/70676]
loss: 0.190142  [64000/70676]
loss: 0.101133  [70400/70676]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.176759 

Epoch 2
-------------------------------
loss: 0.134363  [    0/70676]
loss: 0.300956  [ 6400/70676]
loss: 0.113128  [12800/70676]
loss: 0.226716  [19200/70676]
loss: 0.131465  [25600/70676]
loss: 0.536204  [32000/70676]
loss: 0.248657  [38400/70676]
loss: 0.103844  [44800/70676]
loss: 0.136468  [51200/70676]
loss: 0.281997  [57600/70676]
loss: 0.286527  [64000/70676]
loss: 0.103604  [70400/70676]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157684 

Epoch 3
-------------------------------
loss: 0.079296  [    0/70676]
loss: 0.186205  [ 6400/70676]
loss: 0.094963  [12800/70676]
loss: 0.054697  [19200/70676]
loss: 0.085498  [25600/70676]
loss: 0.167684  [32000/70676]
loss: 0.163514  [38400/70676]
loss: 0.081473  [44800/70676]
loss: 0.134992  [51200/70676]
loss: 0.145445  [57600/70676]
loss: 0.183455  [64000/70676]
loss: 0.163033  [70400/70676]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.157829 

Epoch 4
-------------------------------
loss: 0.132406  [    0/70676]
loss: 0.166798  [ 6400/70676]
loss: 0.202542  [12800/70676]
loss: 0.067090  [19200/70676]
loss: 0.250128  [25600/70676]
loss: 0.104028  [32000/70676]
loss: 0.163140  [38400/70676]
loss: 0.085888  [44800/70676]
loss: 0.103393  [51200/70676]
loss: 0.230803  [57600/70676]
loss: 0.208232  [64000/70676]
loss: 0.206962  [70400/70676]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.154281 

Epoch 5
-------------------------------
loss: 0.061727  [    0/70676]
loss: 0.144940  [ 6400/70676]
loss: 0.122813  [12800/70676]
loss: 0.090623  [19200/70676]
loss: 0.096641  [25600/70676]
loss: 0.137553  [32000/70676]
loss: 0.264682  [38400/70676]
loss: 0.252839  [44800/70676]
loss: 0.130937  [51200/70676]
loss: 0.115882  [57600/70676]
loss: 0.037768  [64000/70676]
loss: 0.185087  [70400/70676]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.154156 

Epoch 6
-------------------------------
loss: 0.090621  [    0/70676]
loss: 0.162266  [ 6400/70676]
loss: 0.098118  [12800/70676]
loss: 0.209314  [19200/70676]
loss: 0.070923  [25600/70676]
loss: 0.194871  [32000/70676]
loss: 0.156335  [38400/70676]
loss: 0.118514  [44800/70676]
loss: 0.146760  [51200/70676]
loss: 0.112107  [57600/70676]
loss: 0.135755  [64000/70676]
loss: 0.191225  [70400/70676]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147018 

Epoch 7
-------------------------------
loss: 0.209337  [    0/70676]
loss: 0.247698  [ 6400/70676]
loss: 0.079842  [12800/70676]
loss: 0.224540  [19200/70676]
loss: 0.148473  [25600/70676]
loss: 0.154484  [32000/70676]
loss: 0.056846  [38400/70676]
loss: 0.050878  [44800/70676]
loss: 0.239489  [51200/70676]
loss: 0.189984  [57600/70676]
loss: 0.110871  [64000/70676]
loss: 0.291416  [70400/70676]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.143463 

Epoch 8
-------------------------------
loss: 0.113820  [    0/70676]
loss: 0.048065  [ 6400/70676]
loss: 0.125797  [12800/70676]
loss: 0.150702  [19200/70676]
loss: 0.127357  [25600/70676]
loss: 0.088906  [32000/70676]
loss: 0.119361  [38400/70676]
loss: 0.239531  [44800/70676]
loss: 0.175419  [51200/70676]
loss: 0.175856  [57600/70676]
loss: 0.135855  [64000/70676]
loss: 0.091343  [70400/70676]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.144635 

Epoch 9
-------------------------------
loss: 0.078244  [    0/70676]
loss: 0.082900  [ 6400/70676]
loss: 0.132458  [12800/70676]
loss: 0.103872  [19200/70676]
loss: 0.222253  [25600/70676]
loss: 0.303627  [32000/70676]
loss: 0.098297  [38400/70676]
loss: 0.247887  [44800/70676]
loss: 0.140762  [51200/70676]
loss: 0.229246  [57600/70676]
loss: 0.182890  [64000/70676]
loss: 0.157848  [70400/70676]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.149799 

Epoch 10
-------------------------------
loss: 0.059798  [    0/70676]
loss: 0.159358  [ 6400/70676]
loss: 0.202740  [12800/70676]
loss: 0.143099  [19200/70676]
loss: 0.070200  [25600/70676]
loss: 0.112419  [32000/70676]
loss: 0.074335  [38400/70676]
loss: 0.076565  [44800/70676]
loss: 0.146682  [51200/70676]
loss: 0.071385  [57600/70676]
loss: 0.146227  [64000/70676]
loss: 0.080338  [70400/70676]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159415 

Epoch 11
-------------------------------
loss: 0.127486  [    0/70676]
loss: 0.171308  [ 6400/70676]
loss: 0.073717  [12800/70676]
loss: 0.123428  [19200/70676]
loss: 0.059504  [25600/70676]
loss: 0.071092  [32000/70676]
loss: 0.131488  [38400/70676]
loss: 0.111767  [44800/70676]
loss: 0.072396  [51200/70676]
loss: 0.084444  [57600/70676]
loss: 0.148320  [64000/70676]
loss: 0.171082  [70400/70676]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.146476 

Epoch 12
-------------------------------
loss: 0.123424  [    0/70676]
loss: 0.086909  [ 6400/70676]
loss: 0.145673  [12800/70676]
loss: 0.209962  [19200/70676]
loss: 0.180779  [25600/70676]
loss: 0.187958  [32000/70676]
loss: 0.258387  [38400/70676]
loss: 0.109675  [44800/70676]
loss: 0.065637  [51200/70676]
loss: 0.096403  [57600/70676]
loss: 0.057086  [64000/70676]
loss: 0.112553  [70400/70676]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.139803 

Epoch 13
-------------------------------
loss: 0.064469  [    0/70676]
loss: 0.134655  [ 6400/70676]
loss: 0.104793  [12800/70676]
loss: 0.089846  [19200/70676]
loss: 0.072572  [25600/70676]
loss: 0.065969  [32000/70676]
loss: 0.145426  [38400/70676]
loss: 0.150674  [44800/70676]
loss: 0.101065  [51200/70676]
loss: 0.203154  [57600/70676]
loss: 0.074630  [64000/70676]
loss: 0.133431  [70400/70676]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.136459 

Epoch 14
-------------------------------
loss: 0.104618  [    0/70676]
loss: 0.133278  [ 6400/70676]
loss: 0.157312  [12800/70676]
loss: 0.157114  [19200/70676]
loss: 0.083876  [25600/70676]
loss: 0.246342  [32000/70676]
loss: 0.068472  [38400/70676]
loss: 0.067672  [44800/70676]
loss: 0.066725  [51200/70676]
loss: 0.197556  [57600/70676]
loss: 0.181202  [64000/70676]
loss: 0.152353  [70400/70676]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.148962 

Epoch 15
-------------------------------
loss: 0.156846  [    0/70676]
loss: 0.161889  [ 6400/70676]
loss: 0.073883  [12800/70676]
loss: 0.064077  [19200/70676]
loss: 0.275324  [25600/70676]
loss: 0.125072  [32000/70676]
loss: 0.122634  [38400/70676]
loss: 0.114654  [44800/70676]
loss: 0.322919  [51200/70676]
loss: 0.140715  [57600/70676]
loss: 0.060609  [64000/70676]
loss: 0.202690  [70400/70676]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.151609 

Epoch 16
-------------------------------
loss: 0.057740  [12800/69845]
loss: 0.116019  [19200/69845]
loss: 0.193125  [25600/69845]
loss: 0.091452  [32000/69845]
loss: 0.227524  [38400/69845]
loss: 0.111018  [44800/69845]
loss: 0.163685  [51200/69845]
loss: 0.093008  [57600/69845]
loss: 0.203348  [64000/69845]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.145846 

Epoch 45
-------------------------------
loss: 0.142026  [    0/69845]
loss: 0.089884  [ 6400/69845]
loss: 0.190511  [12800/69845]
loss: 0.110826  [19200/69845]
loss: 0.080259  [25600/69845]
loss: 0.103364  [32000/69845]
loss: 0.203649  [38400/69845]
loss: 0.098679  [44800/69845]
loss: 0.146398  [51200/69845]
loss: 0.128914  [57600/69845]
loss: 0.077812  [64000/69845]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.154786 

Epoch 46
-------------------------------
loss: 0.108302  [    0/69845]
loss: 0.090693  [ 6400/69845]
loss: 0.065259  [12800/69845]
loss: 0.109905  [19200/69845]
loss: 0.134934  [25600/69845]
loss: 0.177914  [32000/69845]
loss: 0.110080  [38400/69845]
loss: 0.045623  [44800/69845]
loss: 0.126500  [51200/69845]
loss: 0.136330  [57600/69845]
loss: 0.089040  [64000/69845]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.154537 

Epoch 47
-------------------------------
loss: 0.048451  [    0/69845]
loss: 0.095693  [ 6400/69845]
loss: 0.098200  [12800/69845]
loss: 0.109915  [19200/69845]
loss: 0.090860  [25600/69845]
loss: 0.138258  [32000/69845]
loss: 0.065369  [38400/69845]
loss: 0.194488  [44800/69845]
loss: 0.136444  [51200/69845]
loss: 0.163156  [57600/69845]
loss: 0.080428  [64000/69845]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.171810 

Epoch 48
-------------------------------
loss: 0.131346  [    0/69845]
loss: 0.157515  [ 6400/69845]
loss: 0.065912  [12800/69845]
loss: 0.113288  [19200/69845]
loss: 0.062591  [25600/69845]
loss: 0.173902  [32000/69845]
loss: 0.188605  [38400/69845]
loss: 0.072595  [44800/69845]
loss: 0.194629  [51200/69845]
loss: 0.101546  [57600/69845]
loss: 0.256936  [64000/69845]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.147585 

Epoch 49
-------------------------------
loss: 0.125521  [    0/69845]
loss: 0.175682  [ 6400/69845]
loss: 0.118983  [12800/69845]
loss: 0.065302  [19200/69845]
loss: 0.182454  [25600/69845]
loss: 0.101765  [32000/69845]
loss: 0.044273  [38400/69845]
loss: 0.056928  [44800/69845]
loss: 0.073940  [51200/69845]
loss: 0.064420  [57600/69845]
loss: 0.095865  [64000/69845]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.148321 

Epoch 50
-------------------------------
loss: 0.034774  [    0/69845]
loss: 0.130453  [ 6400/69845]
loss: 0.015198  [12800/69845]
loss: 0.117829  [19200/69845]
loss: 0.087502  [25600/69845]
loss: 0.117419  [32000/69845]
loss: 0.105696  [38400/69845]
loss: 0.052626  [44800/69845]
loss: 0.118777  [51200/69845]
loss: 0.169777  [57600/69845]
loss: 0.072143  [64000/69845]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.152881 

Epoch 1
-------------------------------
loss: 0.709636  [    0/70227]
loss: 0.270371  [ 6400/70227]
loss: 0.316548  [12800/70227]
loss: 0.176569  [19200/70227]
loss: 0.216750  [25600/70227]
loss: 0.144881  [32000/70227]
loss: 0.364454  [38400/70227]
loss: 0.306217  [44800/70227]
loss: 0.254473  [51200/70227]
loss: 0.129529  [57600/70227]
loss: 0.194590  [64000/70227]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.184196 

Epoch 2
-------------------------------
loss: 0.181579  [    0/70227]
loss: 0.129048  [ 6400/70227]
loss: 0.152251  [12800/70227]
loss: 0.187158  [19200/70227]
loss: 0.241842  [25600/70227]
loss: 0.095970  [32000/70227]
loss: 0.075095  [38400/70227]
loss: 0.112542  [44800/70227]
loss: 0.155457  [51200/70227]
loss: 0.228524  [57600/70227]
loss: 0.215579  [64000/70227]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.171553 

Epoch 3
-------------------------------
loss: 0.212235  [    0/70227]
loss: 0.202800  [ 6400/70227]
loss: 0.105469  [12800/70227]
loss: 0.121725  [19200/70227]
loss: 0.134279  [25600/70227]
loss: 0.194862  [32000/70227]
loss: 0.166105  [38400/70227]
loss: 0.160011  [44800/70227]
loss: 0.114736  [51200/70227]
loss: 0.268538  [57600/70227]
loss: 0.069864  [64000/70227]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.173635 

Epoch 4
-------------------------------
loss: 0.217777  [    0/70227]
loss: 0.176863  [ 6400/70227]
loss: 0.097457  [12800/70227]
loss: 0.095563  [19200/70227]
loss: 0.229178  [25600/70227]
loss: 0.211013  [32000/70227]
loss: 0.134161  [38400/70227]
loss: 0.167002  [44800/70227]
loss: 0.153682  [51200/70227]
loss: 0.144373  [57600/70227]
loss: 0.257011  [64000/70227]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.161286 

Epoch 5
-------------------------------
loss: 0.143199  [    0/70227]
loss: 0.078264  [ 6400/70227]
loss: 0.096233  [12800/70227]
loss: 0.169971  [19200/70227]
loss: 0.143230  [25600/70227]
loss: 0.139629  [32000/70227]
loss: 0.073365  [38400/70227]
loss: 0.125395  [44800/70227]
loss: 0.186077  [51200/70227]
loss: 0.181998  [57600/70227]
loss: 0.099103  [64000/70227]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.155178 

Epoch 6
-------------------------------
loss: 0.171042  [    0/70227]
loss: 0.191737  [ 6400/70227]
loss: 0.207237  [12800/70227]
loss: 0.156860  [19200/70227]
loss: 0.108309  [25600/70227]
loss: 0.215825  [32000/70227]
loss: 0.168616  [38400/70227]
loss: 0.062672  [44800/70227]
loss: 0.267566  [51200/70227]
loss: 0.099673  [57600/70227]
loss: 0.125988  [64000/70227]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.148188 

Epoch 7
-------------------------------
loss: 0.085598  [    0/70227]
loss: 0.067953  [ 6400/70227]
loss: 0.260199  [12800/70227]
loss: 0.211495  [19200/70227]
loss: 0.119596  [25600/70227]
loss: 0.185391  [32000/70227]
loss: 0.128826  [38400/70227]
loss: 0.268355  [44800/70227]
loss: 0.158232  [51200/70227]
loss: 0.128875  [57600/70227]
loss: 0.116819  [64000/70227]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.146016 

Epoch 8
-------------------------------
loss: 0.147051  [    0/70227]
loss: 0.131765  [ 6400/70227]
loss: 0.235670  [12800/70227]
loss: 0.234921  [19200/70227]
loss: 0.146246  [25600/70227]
loss: 0.145108  [32000/70227]
loss: 0.033684  [38400/70227]
loss: 0.098941  [44800/70227]
loss: 0.164798  [51200/70227]
loss: 0.110434  [57600/70227]
loss: 0.078388  [64000/70227]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.164811 

Epoch 9
-------------------------------
loss: 0.135007  [    0/70227]
loss: 0.214405  [ 6400/70227]
loss: 0.330352  [12800/70227]
loss: 0.157321  [19200/70227]
loss: 0.130294  [25600/70227]
loss: 0.210978  [32000/70227]
loss: 0.197113  [38400/70227]
loss: 0.135362  [44800/70227]
loss: 0.152109  [51200/70227]
loss: 0.089624  [57600/70227]
loss: 0.126658  [64000/70227]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.147957 

Epoch 10
-------------------------------
loss: 0.127270  [    0/70227]
loss: 0.209039  [ 6400/70227]
loss: 0.145109  [12800/70227]
loss: 0.127480  [19200/70227]
loss: 0.171920  [25600/70227]
loss: 0.177965  [32000/70227]
loss: 0.130370  [38400/70227]
loss: 0.095269  [44800/70227]
loss: 0.148730  [51200/70227]
loss: 0.128760  [57600/70227]
loss: 0.114260  [64000/70227]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.152047 

Epoch 11
-------------------------------
loss: 0.088674  [    0/70227]
loss: 0.283966  [ 6400/70227]
loss: 0.033697  [12800/70227]
loss: 0.196252  [19200/70227]
loss: 0.165865  [25600/70227]
loss: 0.142353  [32000/70227]
loss: 0.146889  [38400/70227]
loss: 0.199133  [44800/70227]
loss: 0.127859  [51200/70227]
loss: 0.100821  [57600/70227]
loss: 0.075147  [64000/70227]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.162266 

Epoch 12
-------------------------------
loss: 0.076135  [    0/70227]
loss: 0.121180  [ 6400/70227]
loss: 0.189173  [12800/70227]
loss: 0.218262  [19200/70227]
loss: 0.089021  [25600/70227]
loss: 0.118396  [32000/70227]
loss: 0.166917  [38400/70227]
loss: 0.180210  [44800/70227]
loss: 0.151548  [51200/70227]
loss: 0.131144  [57600/70227]
loss: 0.128075  [64000/70227]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.151666 

Epoch 13
-------------------------------
loss: 0.182877  [    0/70227]
loss: 0.144003  [ 6400/70227]
loss: 0.071324  [12800/70227]
loss: 0.085087  [19200/70227]
loss: 0.015957  [25600/70227]
loss: 0.160780  [32000/70227]
loss: 0.103586  [38400/70227]
loss: 0.008107  [32000/72604]
loss: 0.000229  [38400/72604]
loss: 0.018181  [44800/72604]
loss: 0.007778  [51200/72604]
loss: 0.004221  [57600/72604]
loss: 0.001180  [64000/72604]
loss: 0.035094  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.035761 

Epoch 10
-------------------------------
loss: 0.002855  [    0/72604]
loss: 0.000803  [ 6400/72604]
loss: 0.003372  [12800/72604]
loss: 0.002275  [19200/72604]
loss: 0.001885  [25600/72604]
loss: 0.004770  [32000/72604]
loss: 0.001364  [38400/72604]
loss: 0.000761  [44800/72604]
loss: 0.053763  [51200/72604]
loss: 0.001066  [57600/72604]
loss: 0.032698  [64000/72604]
loss: 0.006556  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.059901 

Epoch 11
-------------------------------
loss: 0.002053  [    0/72604]
loss: 0.014221  [ 6400/72604]
loss: 0.000747  [12800/72604]
loss: 0.002691  [19200/72604]
loss: 0.003996  [25600/72604]
loss: 0.016493  [32000/72604]
loss: 0.000332  [38400/72604]
loss: 0.100698  [44800/72604]
loss: 0.000173  [51200/72604]
loss: 0.010491  [57600/72604]
loss: 0.241334  [64000/72604]
loss: 0.052641  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.036005 

Epoch 12
-------------------------------
loss: 0.004941  [    0/72604]
loss: 0.003090  [ 6400/72604]
loss: 0.004641  [12800/72604]
loss: 0.000460  [19200/72604]
loss: 0.027869  [25600/72604]
loss: 0.000672  [32000/72604]
loss: 0.001374  [38400/72604]
loss: 0.077666  [44800/72604]
loss: 0.001403  [51200/72604]
loss: 0.102262  [57600/72604]
loss: 0.000759  [64000/72604]
loss: 0.067018  [70400/72604]
Test Error: 
 Accuracy: 99.3%, Avg loss: 0.036185 

Epoch 13
-------------------------------
loss: 0.019406  [    0/72604]
loss: 0.009320  [ 6400/72604]
loss: 0.003589  [12800/72604]
loss: 0.007998  [19200/72604]
loss: 0.112762  [25600/72604]
loss: 0.001432  [32000/72604]
loss: 0.036082  [38400/72604]
loss: 0.005116  [44800/72604]
loss: 0.005456  [51200/72604]
loss: 0.003807  [57600/72604]
loss: 0.000641  [64000/72604]
loss: 0.002170  [70400/72604]
Test Error: 
 Accuracy: 99.3%, Avg loss: 0.038180 

Epoch 14
-------------------------------
loss: 0.001211  [    0/72604]
loss: 0.000052  [ 6400/72604]
loss: 0.005463  [12800/72604]
loss: 0.022432  [19200/72604]
loss: 0.008835  [25600/72604]
loss: 0.000271  [32000/72604]
loss: 0.000071  [38400/72604]
loss: 0.004946  [44800/72604]
loss: 0.003448  [51200/72604]
loss: 0.001265  [57600/72604]
loss: 0.000048  [64000/72604]
loss: 0.000910  [70400/72604]
Test Error: 
 Accuracy: 99.3%, Avg loss: 0.059636 

Epoch 15
-------------------------------
loss: 0.002009  [    0/72604]
loss: 0.002983  [ 6400/72604]
loss: 0.008715  [12800/72604]
loss: 0.000009  [19200/72604]
loss: 0.022448  [25600/72604]
loss: 0.012243  [32000/72604]
loss: 0.004226  [38400/72604]
loss: 0.022991  [44800/72604]
loss: 0.000175  [51200/72604]
loss: 0.016683  [57600/72604]
loss: 0.011519  [64000/72604]
loss: 0.000955  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.059873 

Epoch 16
-------------------------------
loss: 0.001242  [    0/72604]
loss: 0.000071  [ 6400/72604]
loss: 0.000780  [12800/72604]
loss: 0.024479  [19200/72604]
loss: 0.000134  [25600/72604]
loss: 0.015318  [32000/72604]
loss: 0.003501  [38400/72604]
loss: 0.000108  [44800/72604]
loss: 0.001675  [51200/72604]
loss: 0.002553  [57600/72604]
loss: 0.000244  [64000/72604]
loss: 0.052190  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.060632 

Epoch 17
-------------------------------
loss: 0.001783  [    0/72604]
loss: 0.004183  [ 6400/72604]
loss: 0.021955  [12800/72604]
loss: 0.001178  [19200/72604]
loss: 0.000909  [25600/72604]
loss: 0.000442  [32000/72604]
loss: 0.009363  [38400/72604]
loss: 0.002195  [44800/72604]
loss: 0.003129  [51200/72604]
loss: 0.130230  [57600/72604]
loss: 0.003399  [64000/72604]
loss: 0.001185  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.082759 

Epoch 18
-------------------------------
loss: 0.001049  [    0/72604]
loss: 0.000783  [ 6400/72604]
loss: 0.000073  [12800/72604]
loss: 0.000365  [19200/72604]
loss: 0.000491  [25600/72604]
loss: 0.006085  [32000/72604]
loss: 0.000018  [38400/72604]
loss: 0.013059  [44800/72604]
loss: 0.031650  [51200/72604]
loss: 0.002560  [57600/72604]
loss: 0.000026  [64000/72604]
loss: 0.001869  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.039664 

Epoch 19
-------------------------------
loss: 0.028060  [    0/72604]
loss: 0.000143  [ 6400/72604]
loss: 0.000217  [12800/72604]
loss: 0.064558  [19200/72604]
loss: 0.033041  [25600/72604]
loss: 0.008637  [32000/72604]
loss: 0.014859  [38400/72604]
loss: 0.000200  [44800/72604]
loss: 0.004547  [51200/72604]
loss: 0.004819  [57600/72604]
loss: 0.000025  [64000/72604]
loss: 0.000224  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.045579 

Epoch 20
-------------------------------
loss: 0.000018  [    0/72604]
loss: 0.006277  [ 6400/72604]
loss: 0.010219  [12800/72604]
loss: 0.022306  [19200/72604]
loss: 0.000359  [25600/72604]
loss: 0.002588  [32000/72604]
loss: 0.027369  [38400/72604]
loss: 0.000075  [44800/72604]
loss: 0.031199  [51200/72604]
loss: 0.086164  [57600/72604]
loss: 0.000810  [64000/72604]
loss: 0.042629  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.040746 

Epoch 21
-------------------------------
loss: 0.000810  [    0/72604]
loss: 0.000896  [ 6400/72604]
loss: 0.149356  [12800/72604]
loss: 0.010874  [19200/72604]
loss: 0.080284  [25600/72604]
loss: 0.034055  [32000/72604]
loss: 0.000209  [38400/72604]
loss: 0.016597  [44800/72604]
loss: 0.020525  [51200/72604]
loss: 0.160855  [57600/72604]
loss: 0.000818  [64000/72604]
loss: 0.001420  [70400/72604]
Test Error: 
 Accuracy: 99.3%, Avg loss: 0.065389 

Epoch 22
-------------------------------
loss: 0.015753  [    0/72604]
loss: 0.000031  [ 6400/72604]
loss: 0.004877  [12800/72604]
loss: 0.014585  [19200/72604]
loss: 0.001534  [25600/72604]
loss: 0.000980  [32000/72604]
loss: 0.021721  [38400/72604]
loss: 0.000242  [44800/72604]
loss: 0.034826  [51200/72604]
loss: 0.064754  [57600/72604]
loss: 0.023230  [64000/72604]
loss: 0.019164  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.061445 

Epoch 23
-------------------------------
loss: 0.000073  [    0/72604]
loss: 0.012462  [ 6400/72604]
loss: 0.000314  [12800/72604]
loss: 0.000307  [19200/72604]
loss: 0.000946  [25600/72604]
loss: 0.000776  [32000/72604]
loss: 0.043058  [38400/72604]
loss: 0.000014  [44800/72604]
loss: 0.002092  [51200/72604]
loss: 0.011206  [57600/72604]
loss: 0.003126  [64000/72604]
loss: 0.011481  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.065198 

Epoch 24
-------------------------------
loss: 0.003433  [    0/72604]
loss: 0.017305  [ 6400/72604]
loss: 0.001556  [12800/72604]
loss: 0.000040  [19200/72604]
loss: 0.001832  [25600/72604]
loss: 0.018111  [32000/72604]
loss: 0.000307  [38400/72604]
loss: 0.002149  [44800/72604]
loss: 0.000459  [51200/72604]
loss: 0.000020  [57600/72604]
loss: 0.040237  [64000/72604]
loss: 0.000735  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.064432 

Epoch 25
-------------------------------
loss: 0.003429  [    0/72604]
loss: 0.000277  [ 6400/72604]
loss: 0.003223  [12800/72604]
loss: 0.001254  [19200/72604]
loss: 0.000003  [25600/72604]
loss: 0.006690  [32000/72604]
loss: 0.000078  [38400/72604]
loss: 0.025989  [44800/72604]
loss: 0.006530  [51200/72604]
loss: 0.073633  [57600/72604]
loss: 0.039132  [64000/72604]
loss: 0.016985  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.067425 

Epoch 26
-------------------------------
loss: 0.010521  [    0/72604]
loss: 0.009034  [ 6400/72604]
loss: 0.000091  [12800/72604]
loss: 0.000009  [19200/72604]
loss: 0.000014  [25600/72604]
loss: 0.000277  [32000/72604]
loss: 0.000881  [38400/72604]
loss: 0.000743  [44800/72604]
loss: 0.000614  [51200/72604]
loss: 0.005873  [57600/72604]
loss: 0.000336  [64000/72604]
loss: 0.003732  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.045625 

Epoch 27
-------------------------------
loss: 0.009524  [    0/72604]
loss: 0.007653  [ 6400/72604]
loss: 0.008891  [12800/72604]
loss: 0.000029  [19200/72604]
loss: 0.000019  [25600/72604]
loss: 0.008919  [32000/72604]
loss: 0.079024  [32000/71706]
loss: 0.072363  [38400/71706]
loss: 0.075927  [44800/71706]
loss: 0.062841  [51200/71706]
loss: 0.034533  [57600/71706]
loss: 0.096455  [64000/71706]
loss: 0.076536  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.063209 

Epoch 10
-------------------------------
loss: 0.020128  [    0/71706]
loss: 0.125621  [ 6400/71706]
loss: 0.071770  [12800/71706]
loss: 0.030712  [19200/71706]
loss: 0.159793  [25600/71706]
loss: 0.062080  [32000/71706]
loss: 0.129340  [38400/71706]
loss: 0.157373  [44800/71706]
loss: 0.051425  [51200/71706]
loss: 0.060048  [57600/71706]
loss: 0.087688  [64000/71706]
loss: 0.044016  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.062834 

Epoch 11
-------------------------------
loss: 0.091204  [    0/71706]
loss: 0.127470  [ 6400/71706]
loss: 0.084501  [12800/71706]
loss: 0.012366  [19200/71706]
loss: 0.042556  [25600/71706]
loss: 0.040421  [32000/71706]
loss: 0.038339  [38400/71706]
loss: 0.105045  [44800/71706]
loss: 0.025349  [51200/71706]
loss: 0.009972  [57600/71706]
loss: 0.051435  [64000/71706]
loss: 0.054444  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.065156 

Epoch 12
-------------------------------
loss: 0.049105  [    0/71706]
loss: 0.019503  [ 6400/71706]
loss: 0.015028  [12800/71706]
loss: 0.041551  [19200/71706]
loss: 0.033449  [25600/71706]
loss: 0.104783  [32000/71706]
loss: 0.061807  [38400/71706]
loss: 0.029971  [44800/71706]
loss: 0.020845  [51200/71706]
loss: 0.015365  [57600/71706]
loss: 0.074069  [64000/71706]
loss: 0.034568  [70400/71706]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.064053 

Epoch 13
-------------------------------
loss: 0.117834  [    0/71706]
loss: 0.021245  [ 6400/71706]
loss: 0.113757  [12800/71706]
loss: 0.043922  [19200/71706]
loss: 0.015032  [25600/71706]
loss: 0.040765  [32000/71706]
loss: 0.121378  [38400/71706]
loss: 0.009361  [44800/71706]
loss: 0.027947  [51200/71706]
loss: 0.070229  [57600/71706]
loss: 0.033384  [64000/71706]
loss: 0.044854  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069881 

Epoch 14
-------------------------------
loss: 0.020017  [    0/71706]
loss: 0.045124  [ 6400/71706]
loss: 0.162926  [12800/71706]
loss: 0.010381  [19200/71706]
loss: 0.066897  [25600/71706]
loss: 0.040828  [32000/71706]
loss: 0.025091  [38400/71706]
loss: 0.013823  [44800/71706]
loss: 0.081836  [51200/71706]
loss: 0.113328  [57600/71706]
loss: 0.024254  [64000/71706]
loss: 0.010846  [70400/71706]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.073667 

Epoch 15
-------------------------------
loss: 0.014274  [    0/71706]
loss: 0.042314  [ 6400/71706]
loss: 0.017172  [12800/71706]
loss: 0.080248  [19200/71706]
loss: 0.040036  [25600/71706]
loss: 0.014728  [32000/71706]
loss: 0.061223  [38400/71706]
loss: 0.086539  [44800/71706]
loss: 0.050176  [51200/71706]
loss: 0.036148  [57600/71706]
loss: 0.061955  [64000/71706]
loss: 0.015896  [70400/71706]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.063129 

Epoch 16
-------------------------------
loss: 0.113596  [    0/71706]
loss: 0.207301  [ 6400/71706]
loss: 0.063815  [12800/71706]
loss: 0.073944  [19200/71706]
loss: 0.081674  [25600/71706]
loss: 0.013924  [32000/71706]
loss: 0.047200  [38400/71706]
loss: 0.007096  [44800/71706]
loss: 0.103747  [51200/71706]
loss: 0.049953  [57600/71706]
loss: 0.013498  [64000/71706]
loss: 0.083128  [70400/71706]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.065226 

Epoch 17
-------------------------------
loss: 0.042712  [    0/71706]
loss: 0.056528  [ 6400/71706]
loss: 0.125756  [12800/71706]
loss: 0.225468  [19200/71706]
loss: 0.012735  [25600/71706]
loss: 0.033039  [32000/71706]
loss: 0.040395  [38400/71706]
loss: 0.039536  [44800/71706]
loss: 0.050631  [51200/71706]
loss: 0.065637  [57600/71706]
loss: 0.040502  [64000/71706]
loss: 0.021386  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.069893 

Epoch 18
-------------------------------
loss: 0.042279  [    0/71706]
loss: 0.202435  [ 6400/71706]
loss: 0.043412  [12800/71706]
loss: 0.037282  [19200/71706]
loss: 0.015579  [25600/71706]
loss: 0.028988  [32000/71706]
loss: 0.036772  [38400/71706]
loss: 0.056685  [44800/71706]
loss: 0.035635  [51200/71706]
loss: 0.009038  [57600/71706]
loss: 0.079173  [64000/71706]
loss: 0.095816  [70400/71706]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.064352 

Epoch 19
-------------------------------
loss: 0.037624  [    0/71706]
loss: 0.060744  [ 6400/71706]
loss: 0.018306  [12800/71706]
loss: 0.058421  [19200/71706]
loss: 0.032972  [25600/71706]
loss: 0.022495  [32000/71706]
loss: 0.038322  [38400/71706]
loss: 0.032427  [44800/71706]
loss: 0.038321  [51200/71706]
loss: 0.050569  [57600/71706]
loss: 0.073871  [64000/71706]
loss: 0.037235  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.064879 

Epoch 20
-------------------------------
loss: 0.060025  [    0/71706]
loss: 0.153009  [ 6400/71706]
loss: 0.031037  [12800/71706]
loss: 0.045103  [19200/71706]
loss: 0.140055  [25600/71706]
loss: 0.079499  [32000/71706]
loss: 0.014225  [38400/71706]
loss: 0.035244  [44800/71706]
loss: 0.008568  [51200/71706]
loss: 0.156097  [57600/71706]
loss: 0.009848  [64000/71706]
loss: 0.124679  [70400/71706]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.067164 

Epoch 21
-------------------------------
loss: 0.032240  [    0/71706]
loss: 0.040116  [ 6400/71706]
loss: 0.045088  [12800/71706]
loss: 0.051812  [19200/71706]
loss: 0.084967  [25600/71706]
loss: 0.026318  [32000/71706]
loss: 0.028447  [38400/71706]
loss: 0.111727  [44800/71706]
loss: 0.091169  [51200/71706]
loss: 0.016008  [57600/71706]
loss: 0.085767  [64000/71706]
loss: 0.054690  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066410 

Epoch 22
-------------------------------
loss: 0.029636  [    0/71706]
loss: 0.025750  [ 6400/71706]
loss: 0.116384  [12800/71706]
loss: 0.122486  [19200/71706]
loss: 0.117848  [25600/71706]
loss: 0.088868  [32000/71706]
loss: 0.049401  [38400/71706]
loss: 0.038742  [44800/71706]
loss: 0.015265  [51200/71706]
loss: 0.022835  [57600/71706]
loss: 0.021270  [64000/71706]
loss: 0.170216  [70400/71706]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.073655 

Epoch 23
-------------------------------
loss: 0.188547  [    0/71706]
loss: 0.021753  [ 6400/71706]
loss: 0.038453  [12800/71706]
loss: 0.060077  [19200/71706]
loss: 0.055150  [25600/71706]
loss: 0.059170  [32000/71706]
loss: 0.048571  [38400/71706]
loss: 0.076557  [44800/71706]
loss: 0.090742  [51200/71706]
loss: 0.090231  [57600/71706]
loss: 0.047369  [64000/71706]
loss: 0.053898  [70400/71706]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.067722 

Epoch 24
-------------------------------
loss: 0.074467  [    0/71706]
loss: 0.084836  [ 6400/71706]
loss: 0.078178  [12800/71706]
loss: 0.023151  [19200/71706]
loss: 0.024128  [25600/71706]
loss: 0.019778  [32000/71706]
loss: 0.073084  [38400/71706]
loss: 0.011724  [44800/71706]
loss: 0.039973  [51200/71706]
loss: 0.114761  [57600/71706]
loss: 0.095701  [64000/71706]
loss: 0.020143  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.072156 

Epoch 25
-------------------------------
loss: 0.079737  [    0/71706]
loss: 0.098743  [ 6400/71706]
loss: 0.058068  [12800/71706]
loss: 0.021448  [19200/71706]
loss: 0.015981  [25600/71706]
loss: 0.049081  [32000/71706]
loss: 0.019909  [38400/71706]
loss: 0.068023  [44800/71706]
loss: 0.059999  [51200/71706]
loss: 0.068370  [57600/71706]
loss: 0.126487  [64000/71706]
loss: 0.004416  [70400/71706]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.065789 

Epoch 26
-------------------------------
loss: 0.026690  [    0/71706]
loss: 0.035592  [ 6400/71706]
loss: 0.017550  [12800/71706]
loss: 0.277229  [19200/71706]
loss: 0.040765  [25600/71706]
loss: 0.085393  [32000/71706]
loss: 0.025632  [38400/71706]
loss: 0.038138  [44800/71706]
loss: 0.017305  [51200/71706]
loss: 0.057090  [57600/71706]
loss: 0.019447  [64000/71706]
loss: 0.018020  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071320 

Epoch 27
-------------------------------
loss: 0.022738  [    0/71706]
loss: 0.062120  [ 6400/71706]
loss: 0.022902  [12800/71706]
loss: 0.024838  [19200/71706]
loss: 0.008932  [25600/71706]
loss: 0.069821  [32000/71706]
loss: 0.074486  [64000/71414]
loss: 0.189392  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.105667 

Epoch 13
-------------------------------
loss: 0.022628  [    0/71414]
loss: 0.099784  [ 6400/71414]
loss: 0.056090  [12800/71414]
loss: 0.139435  [19200/71414]
loss: 0.158112  [25600/71414]
loss: 0.114731  [32000/71414]
loss: 0.073308  [38400/71414]
loss: 0.098682  [44800/71414]
loss: 0.039914  [51200/71414]
loss: 0.051947  [57600/71414]
loss: 0.150707  [64000/71414]
loss: 0.109008  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.102104 

Epoch 14
-------------------------------
loss: 0.060210  [    0/71414]
loss: 0.066994  [ 6400/71414]
loss: 0.035113  [12800/71414]
loss: 0.033204  [19200/71414]
loss: 0.197178  [25600/71414]
loss: 0.045561  [32000/71414]
loss: 0.028384  [38400/71414]
loss: 0.074466  [44800/71414]
loss: 0.099255  [51200/71414]
loss: 0.018028  [57600/71414]
loss: 0.058813  [64000/71414]
loss: 0.213984  [70400/71414]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.111454 

Epoch 15
-------------------------------
loss: 0.083896  [    0/71414]
loss: 0.059352  [ 6400/71414]
loss: 0.128349  [12800/71414]
loss: 0.029910  [19200/71414]
loss: 0.037564  [25600/71414]
loss: 0.101681  [32000/71414]
loss: 0.050334  [38400/71414]
loss: 0.125493  [44800/71414]
loss: 0.094211  [51200/71414]
loss: 0.033841  [57600/71414]
loss: 0.036155  [64000/71414]
loss: 0.250616  [70400/71414]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.106818 

Epoch 16
-------------------------------
loss: 0.076392  [    0/71414]
loss: 0.061550  [ 6400/71414]
loss: 0.051981  [12800/71414]
loss: 0.075863  [19200/71414]
loss: 0.074915  [25600/71414]
loss: 0.074749  [32000/71414]
loss: 0.054503  [38400/71414]
loss: 0.036149  [44800/71414]
loss: 0.085462  [51200/71414]
loss: 0.016158  [57600/71414]
loss: 0.022272  [64000/71414]
loss: 0.057621  [70400/71414]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.109178 

Epoch 17
-------------------------------
loss: 0.107256  [    0/71414]
loss: 0.032017  [ 6400/71414]
loss: 0.044837  [12800/71414]
loss: 0.072554  [19200/71414]
loss: 0.154320  [25600/71414]
loss: 0.023694  [32000/71414]
loss: 0.052009  [38400/71414]
loss: 0.038370  [44800/71414]
loss: 0.023007  [51200/71414]
loss: 0.066712  [57600/71414]
loss: 0.038991  [64000/71414]
loss: 0.072490  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.110028 

Epoch 18
-------------------------------
loss: 0.043460  [    0/71414]
loss: 0.100703  [ 6400/71414]
loss: 0.032459  [12800/71414]
loss: 0.162760  [19200/71414]
loss: 0.144906  [25600/71414]
loss: 0.036592  [32000/71414]
loss: 0.092137  [38400/71414]
loss: 0.078182  [44800/71414]
loss: 0.017851  [51200/71414]
loss: 0.107262  [57600/71414]
loss: 0.066245  [64000/71414]
loss: 0.048708  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.106820 

Epoch 19
-------------------------------
loss: 0.038456  [    0/71414]
loss: 0.101974  [ 6400/71414]
loss: 0.027828  [12800/71414]
loss: 0.070034  [19200/71414]
loss: 0.027690  [25600/71414]
loss: 0.085478  [32000/71414]
loss: 0.054095  [38400/71414]
loss: 0.039402  [44800/71414]
loss: 0.068210  [51200/71414]
loss: 0.157992  [57600/71414]
loss: 0.129940  [64000/71414]
loss: 0.127806  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.103308 

Epoch 20
-------------------------------
loss: 0.133459  [    0/71414]
loss: 0.030495  [ 6400/71414]
loss: 0.060930  [12800/71414]
loss: 0.070915  [19200/71414]
loss: 0.096062  [25600/71414]
loss: 0.049739  [32000/71414]
loss: 0.120570  [38400/71414]
loss: 0.179305  [44800/71414]
loss: 0.014975  [51200/71414]
loss: 0.081635  [57600/71414]
loss: 0.015925  [64000/71414]
loss: 0.081252  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.103204 

Epoch 21
-------------------------------
loss: 0.050332  [    0/71414]
loss: 0.041736  [ 6400/71414]
loss: 0.030292  [12800/71414]
loss: 0.044357  [19200/71414]
loss: 0.106759  [25600/71414]
loss: 0.028664  [32000/71414]
loss: 0.060289  [38400/71414]
loss: 0.022499  [44800/71414]
loss: 0.036636  [51200/71414]
loss: 0.094109  [57600/71414]
loss: 0.115542  [64000/71414]
loss: 0.034810  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.100291 

Epoch 22
-------------------------------
loss: 0.043031  [    0/71414]
loss: 0.031618  [ 6400/71414]
loss: 0.025378  [12800/71414]
loss: 0.038000  [19200/71414]
loss: 0.029009  [25600/71414]
loss: 0.057685  [32000/71414]
loss: 0.048780  [38400/71414]
loss: 0.107543  [44800/71414]
loss: 0.034698  [51200/71414]
loss: 0.125132  [57600/71414]
loss: 0.054798  [64000/71414]
loss: 0.060177  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101980 

Epoch 23
-------------------------------
loss: 0.058180  [    0/71414]
loss: 0.040551  [ 6400/71414]
loss: 0.074419  [12800/71414]
loss: 0.023689  [19200/71414]
loss: 0.117740  [25600/71414]
loss: 0.121244  [32000/71414]
loss: 0.141127  [38400/71414]
loss: 0.012393  [44800/71414]
loss: 0.039038  [51200/71414]
loss: 0.074952  [57600/71414]
loss: 0.093249  [64000/71414]
loss: 0.031613  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.105991 

Epoch 24
-------------------------------
loss: 0.082977  [    0/71414]
loss: 0.041836  [ 6400/71414]
loss: 0.012880  [12800/71414]
loss: 0.070320  [19200/71414]
loss: 0.090440  [25600/71414]
loss: 0.095052  [32000/71414]
loss: 0.071608  [38400/71414]
loss: 0.064561  [44800/71414]
loss: 0.007316  [51200/71414]
loss: 0.038231  [57600/71414]
loss: 0.066423  [64000/71414]
loss: 0.056826  [70400/71414]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.107664 

Epoch 25
-------------------------------
loss: 0.030788  [    0/71414]
loss: 0.003718  [ 6400/71414]
loss: 0.051431  [12800/71414]
loss: 0.021058  [19200/71414]
loss: 0.051583  [25600/71414]
loss: 0.050638  [32000/71414]
loss: 0.083974  [38400/71414]
loss: 0.091625  [44800/71414]
loss: 0.028871  [51200/71414]
loss: 0.011987  [57600/71414]
loss: 0.204749  [64000/71414]
loss: 0.084371  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.115936 

Epoch 26
-------------------------------
loss: 0.023776  [    0/71414]
loss: 0.030459  [ 6400/71414]
loss: 0.008541  [12800/71414]
loss: 0.070556  [19200/71414]
loss: 0.150351  [25600/71414]
loss: 0.042006  [32000/71414]
loss: 0.115636  [38400/71414]
loss: 0.138977  [44800/71414]
loss: 0.091889  [51200/71414]
loss: 0.042961  [57600/71414]
loss: 0.047663  [64000/71414]
loss: 0.129934  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.103492 

Epoch 27
-------------------------------
loss: 0.086528  [    0/71414]
loss: 0.031645  [ 6400/71414]
loss: 0.062888  [12800/71414]
loss: 0.041036  [19200/71414]
loss: 0.032744  [25600/71414]
loss: 0.060549  [32000/71414]
loss: 0.101220  [38400/71414]
loss: 0.097648  [44800/71414]
loss: 0.126740  [51200/71414]
loss: 0.093972  [57600/71414]
loss: 1.614243  [64000/71414]
loss: 0.077115  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.109742 

Epoch 28
-------------------------------
loss: 0.057656  [    0/71414]
loss: 0.033843  [ 6400/71414]
loss: 0.085197  [12800/71414]
loss: 0.008296  [19200/71414]
loss: 0.052123  [25600/71414]
loss: 0.062672  [32000/71414]
loss: 0.084210  [38400/71414]
loss: 0.030486  [44800/71414]
loss: 0.081962  [51200/71414]
loss: 0.029743  [57600/71414]
loss: 0.032682  [64000/71414]
loss: 0.055358  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.106443 

Epoch 29
-------------------------------
loss: 0.111737  [    0/71414]
loss: 0.016206  [ 6400/71414]
loss: 0.106116  [12800/71414]
loss: 0.107530  [19200/71414]
loss: 0.103639  [25600/71414]
loss: 0.093135  [32000/71414]
loss: 0.087872  [38400/71414]
loss: 0.033891  [44800/71414]
loss: 1.618563  [51200/71414]
loss: 0.162080  [57600/71414]
loss: 0.100200  [64000/71414]
loss: 0.060064  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.105870 

Epoch 30
-------------------------------
loss: 0.059119  [    0/71414]
loss: 0.010840  [ 6400/71414]
loss: 0.062479  [12800/71414]
loss: 0.032266  [19200/71414]
loss: 0.048724  [25600/71414]
loss: 0.042528  [32000/71414]
loss: 0.070476  [38400/71414]
loss: 0.010073  [44800/71414]
loss: 0.100893  [51200/71414]
loss: 0.036123  [57600/71414]
loss: 0.053371  [64000/71414]
loss: 0.112657  [64000/70247]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.083894 

Epoch 48
-------------------------------
loss: 0.028011  [    0/70247]
loss: 0.075660  [ 6400/70247]
loss: 0.118419  [12800/70247]
loss: 0.023412  [19200/70247]
loss: 0.215411  [25600/70247]
loss: 0.010397  [32000/70247]
loss: 0.028994  [38400/70247]
loss: 0.073003  [44800/70247]
loss: 0.103468  [51200/70247]
loss: 0.087315  [57600/70247]
loss: 0.027618  [64000/70247]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.090511 

Epoch 49
-------------------------------
loss: 0.029048  [    0/70247]
loss: 0.024902  [ 6400/70247]
loss: 0.061400  [12800/70247]
loss: 0.038688  [19200/70247]
loss: 0.044817  [25600/70247]
loss: 0.009457  [32000/70247]
loss: 0.026023  [38400/70247]
loss: 0.076900  [44800/70247]
loss: 0.041434  [51200/70247]
loss: 0.035184  [57600/70247]
loss: 0.054576  [64000/70247]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.088040 

Epoch 50
-------------------------------
loss: 0.044283  [    0/70247]
loss: 0.039431  [ 6400/70247]
loss: 0.042711  [12800/70247]
loss: 0.034894  [19200/70247]
loss: 0.009594  [25600/70247]
loss: 0.081794  [32000/70247]
loss: 0.006115  [38400/70247]
loss: 0.090350  [44800/70247]
loss: 0.051401  [51200/70247]
loss: 0.034636  [57600/70247]
loss: 0.185428  [64000/70247]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.098530 

Epoch 1
-------------------------------
loss: 0.720904  [    0/69985]
loss: 0.135885  [ 6400/69985]
loss: 0.073815  [12800/69985]
loss: 0.082841  [19200/69985]
loss: 0.247211  [25600/69985]
loss: 0.071603  [32000/69985]
loss: 0.103890  [38400/69985]
loss: 0.179430  [44800/69985]
loss: 0.089770  [51200/69985]
loss: 0.191595  [57600/69985]
loss: 0.101345  [64000/69985]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.094806 

Epoch 2
-------------------------------
loss: 0.145159  [    0/69985]
loss: 0.047526  [ 6400/69985]
loss: 0.168887  [12800/69985]
loss: 0.047851  [19200/69985]
loss: 0.095628  [25600/69985]
loss: 0.120057  [32000/69985]
loss: 0.118912  [38400/69985]
loss: 0.088444  [44800/69985]
loss: 0.053954  [51200/69985]
loss: 0.101499  [57600/69985]
loss: 0.067519  [64000/69985]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.082991 

Epoch 3
-------------------------------
loss: 0.056476  [    0/69985]
loss: 0.083119  [ 6400/69985]
loss: 0.125776  [12800/69985]
loss: 0.053218  [19200/69985]
loss: 0.040786  [25600/69985]
loss: 0.105043  [32000/69985]
loss: 0.108534  [38400/69985]
loss: 0.095805  [44800/69985]
loss: 0.212955  [51200/69985]
loss: 0.077739  [57600/69985]
loss: 0.067794  [64000/69985]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.085133 

Epoch 4
-------------------------------
loss: 0.047914  [    0/69985]
loss: 0.048998  [ 6400/69985]
loss: 0.023348  [12800/69985]
loss: 0.035240  [19200/69985]
loss: 0.028647  [25600/69985]
loss: 0.098637  [32000/69985]
loss: 0.109860  [38400/69985]
loss: 0.088224  [44800/69985]
loss: 0.075314  [51200/69985]
loss: 0.038691  [57600/69985]
loss: 0.099455  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.080747 

Epoch 5
-------------------------------
loss: 0.037532  [    0/69985]
loss: 0.090756  [ 6400/69985]
loss: 0.048121  [12800/69985]
loss: 0.052316  [19200/69985]
loss: 0.245551  [25600/69985]
loss: 0.084603  [32000/69985]
loss: 0.170957  [38400/69985]
loss: 0.078579  [44800/69985]
loss: 0.040169  [51200/69985]
loss: 0.129361  [57600/69985]
loss: 0.137672  [64000/69985]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.071721 

Epoch 6
-------------------------------
loss: 0.036619  [    0/69985]
loss: 0.036922  [ 6400/69985]
loss: 0.027252  [12800/69985]
loss: 0.160842  [19200/69985]
loss: 0.009806  [25600/69985]
loss: 0.041814  [32000/69985]
loss: 0.137711  [38400/69985]
loss: 0.078532  [44800/69985]
loss: 0.054832  [51200/69985]
loss: 0.126285  [57600/69985]
loss: 0.088723  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.073464 

Epoch 7
-------------------------------
loss: 0.077134  [    0/69985]
loss: 0.138320  [ 6400/69985]
loss: 0.051959  [12800/69985]
loss: 0.083369  [19200/69985]
loss: 0.053499  [25600/69985]
loss: 0.105222  [32000/69985]
loss: 0.048945  [38400/69985]
loss: 0.071955  [44800/69985]
loss: 0.034874  [51200/69985]
loss: 0.058609  [57600/69985]
loss: 0.069508  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.075869 

Epoch 8
-------------------------------
loss: 0.091083  [    0/69985]
loss: 0.091590  [ 6400/69985]
loss: 0.053983  [12800/69985]
loss: 0.094374  [19200/69985]
loss: 0.101673  [25600/69985]
loss: 0.024591  [32000/69985]
loss: 0.030600  [38400/69985]
loss: 0.131891  [44800/69985]
loss: 0.033473  [51200/69985]
loss: 0.079923  [57600/69985]
loss: 0.048400  [64000/69985]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.085092 

Epoch 9
-------------------------------
loss: 0.095088  [    0/69985]
loss: 0.132855  [ 6400/69985]
loss: 0.072942  [12800/69985]
loss: 0.071495  [19200/69985]
loss: 0.154475  [25600/69985]
loss: 0.046234  [32000/69985]
loss: 0.068946  [38400/69985]
loss: 0.096365  [44800/69985]
loss: 0.026894  [51200/69985]
loss: 0.072886  [57600/69985]
loss: 0.077197  [64000/69985]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.075006 

Epoch 10
-------------------------------
loss: 0.075905  [    0/69985]
loss: 0.057757  [ 6400/69985]
loss: 0.050286  [12800/69985]
loss: 0.078914  [19200/69985]
loss: 0.147505  [25600/69985]
loss: 0.039777  [32000/69985]
loss: 0.044071  [38400/69985]
loss: 0.054367  [44800/69985]
loss: 0.061103  [51200/69985]
loss: 0.066649  [57600/69985]
loss: 0.138521  [64000/69985]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084317 

Epoch 11
-------------------------------
loss: 0.008364  [    0/69985]
loss: 0.068591  [ 6400/69985]
loss: 0.037345  [12800/69985]
loss: 0.064794  [19200/69985]
loss: 0.122310  [25600/69985]
loss: 0.119754  [32000/69985]
loss: 0.093540  [38400/69985]
loss: 0.109619  [44800/69985]
loss: 0.059042  [51200/69985]
loss: 0.143378  [57600/69985]
loss: 0.007389  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.078285 

Epoch 12
-------------------------------
loss: 0.133145  [    0/69985]
loss: 0.061255  [ 6400/69985]
loss: 0.068343  [12800/69985]
loss: 0.060311  [19200/69985]
loss: 0.082792  [25600/69985]
loss: 0.201099  [32000/69985]
loss: 0.033091  [38400/69985]
loss: 0.051622  [44800/69985]
loss: 0.040302  [51200/69985]
loss: 0.080555  [57600/69985]
loss: 0.032402  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.077491 

Epoch 13
-------------------------------
loss: 0.055734  [    0/69985]
loss: 0.085884  [ 6400/69985]
loss: 0.074367  [12800/69985]
loss: 0.098554  [19200/69985]
loss: 0.030498  [25600/69985]
loss: 0.084354  [32000/69985]
loss: 0.061890  [38400/69985]
loss: 0.080206  [44800/69985]
loss: 0.062115  [51200/69985]
loss: 0.049491  [57600/69985]
loss: 0.060661  [64000/69985]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.074842 

Epoch 14
-------------------------------
loss: 0.030686  [    0/69985]
loss: 0.049022  [ 6400/69985]
loss: 0.075310  [12800/69985]
loss: 0.093575  [19200/69985]
loss: 0.050098  [25600/69985]
loss: 0.066847  [32000/69985]
loss: 0.396187  [38400/69985]
loss: 0.032884  [44800/69985]
loss: 0.051574  [51200/69985]
loss: 0.087583  [57600/69985]
loss: 0.079135  [64000/69985]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076885 

Epoch 15
-------------------------------
loss: 0.087758  [    0/69985]
loss: 0.117935  [ 6400/69985]
loss: 0.040278  [12800/69985]
loss: 0.069035  [19200/69985]
loss: 0.035382  [25600/69985]
loss: 0.048568  [32000/69985]
loss: 0.095631  [38400/69985]
loss: 0.140744  [44800/69985]
loss: 0.054442  [51200/69985]
loss: 0.088193  [57600/69985]
loss: 0.043083  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.080679 

Epoch 16
-------------------------------
loss: 0.050125  [    0/69985]
loss: 0.041020  [ 6400/69985]
loss: 0.071059  [12800/69985]
loss: 0.068550  [19200/69985]
loss: 0.096650  [25600/69985]
loss: 0.028705  [32000/69985]
loss: 0.043485  [38400/69985]
loss: 0.045040  [44800/69985]
loss: 0.056894  [51200/69985]
loss: 0.107507  [57600/69985]
loss: 0.021929  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081926 

Epoch 17
-------------------------------
loss: 0.088812  [    0/69985]
Epoch 10
-------------------------------
loss: 0.057588  [    0/70010]
loss: 0.091668  [ 6400/70010]
loss: 0.156918  [12800/70010]
loss: 0.071114  [19200/70010]
loss: 0.111539  [25600/70010]
loss: 0.069653  [32000/70010]
loss: 0.099639  [38400/70010]
loss: 0.071022  [44800/70010]
loss: 0.079195  [51200/70010]
loss: 0.186646  [57600/70010]
loss: 0.066811  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086053 

Epoch 11
-------------------------------
loss: 0.100082  [    0/70010]
loss: 0.110314  [ 6400/70010]
loss: 0.080662  [12800/70010]
loss: 0.100027  [19200/70010]
loss: 0.038507  [25600/70010]
loss: 0.166876  [32000/70010]
loss: 0.062168  [38400/70010]
loss: 0.047218  [44800/70010]
loss: 0.129528  [51200/70010]
loss: 0.172170  [57600/70010]
loss: 0.087476  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085069 

Epoch 12
-------------------------------
loss: 0.032276  [    0/70010]
loss: 0.142731  [ 6400/70010]
loss: 0.095448  [12800/70010]
loss: 0.162854  [19200/70010]
loss: 0.119779  [25600/70010]
loss: 0.061772  [32000/70010]
loss: 0.146881  [38400/70010]
loss: 0.085363  [44800/70010]
loss: 0.182089  [51200/70010]
loss: 0.152013  [57600/70010]
loss: 0.073070  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082705 

Epoch 13
-------------------------------
loss: 0.034023  [    0/70010]
loss: 0.108185  [ 6400/70010]
loss: 0.162751  [12800/70010]
loss: 0.138215  [19200/70010]
loss: 0.106963  [25600/70010]
loss: 0.044183  [32000/70010]
loss: 0.046978  [38400/70010]
loss: 0.048484  [44800/70010]
loss: 0.035491  [51200/70010]
loss: 0.022687  [57600/70010]
loss: 0.065782  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089053 

Epoch 14
-------------------------------
loss: 0.035383  [    0/70010]
loss: 0.066828  [ 6400/70010]
loss: 0.040439  [12800/70010]
loss: 0.068350  [19200/70010]
loss: 0.067552  [25600/70010]
loss: 0.063903  [32000/70010]
loss: 0.213497  [38400/70010]
loss: 0.059061  [44800/70010]
loss: 0.074691  [51200/70010]
loss: 0.015841  [57600/70010]
loss: 0.067776  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.084945 

Epoch 15
-------------------------------
loss: 0.084657  [    0/70010]
loss: 0.110821  [ 6400/70010]
loss: 0.061942  [12800/70010]
loss: 0.068285  [19200/70010]
loss: 0.086042  [25600/70010]
loss: 0.097906  [32000/70010]
loss: 0.034463  [38400/70010]
loss: 0.095373  [44800/70010]
loss: 0.029165  [51200/70010]
loss: 0.157533  [57600/70010]
loss: 0.073626  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.085397 

Epoch 16
-------------------------------
loss: 0.042668  [    0/70010]
loss: 0.018200  [ 6400/70010]
loss: 0.126428  [12800/70010]
loss: 0.068031  [19200/70010]
loss: 0.030257  [25600/70010]
loss: 0.064751  [32000/70010]
loss: 0.102689  [38400/70010]
loss: 0.020144  [44800/70010]
loss: 0.047295  [51200/70010]
loss: 0.156180  [57600/70010]
loss: 0.025020  [64000/70010]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.092935 

Epoch 17
-------------------------------
loss: 0.141794  [    0/70010]
loss: 0.065406  [ 6400/70010]
loss: 0.133581  [12800/70010]
loss: 0.034442  [19200/70010]
loss: 0.086852  [25600/70010]
loss: 0.094308  [32000/70010]
loss: 0.163274  [38400/70010]
loss: 0.036065  [44800/70010]
loss: 0.039028  [51200/70010]
loss: 0.063328  [57600/70010]
loss: 0.098334  [64000/70010]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.099706 

Epoch 18
-------------------------------
loss: 0.202422  [    0/70010]
loss: 0.041039  [ 6400/70010]
loss: 0.070082  [12800/70010]
loss: 0.173545  [19200/70010]
loss: 0.036898  [25600/70010]
loss: 0.126069  [32000/70010]
loss: 0.018703  [38400/70010]
loss: 0.112794  [44800/70010]
loss: 0.201495  [51200/70010]
loss: 0.031542  [57600/70010]
loss: 0.065046  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081638 

Epoch 19
-------------------------------
loss: 0.095238  [    0/70010]
loss: 0.079075  [ 6400/70010]
loss: 0.122319  [12800/70010]
loss: 0.068365  [19200/70010]
loss: 0.055522  [25600/70010]
loss: 0.172370  [32000/70010]
loss: 0.048881  [38400/70010]
loss: 0.175342  [44800/70010]
loss: 0.150250  [51200/70010]
loss: 0.072696  [57600/70010]
loss: 0.111265  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086911 

Epoch 20
-------------------------------
loss: 0.047541  [    0/70010]
loss: 0.059312  [ 6400/70010]
loss: 0.100699  [12800/70010]
loss: 0.056415  [19200/70010]
loss: 0.113377  [25600/70010]
loss: 0.022138  [32000/70010]
loss: 0.122648  [38400/70010]
loss: 0.111911  [44800/70010]
loss: 0.095461  [51200/70010]
loss: 0.077379  [57600/70010]
loss: 0.016191  [64000/70010]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.091481 

Epoch 21
-------------------------------
loss: 0.007722  [    0/70010]
loss: 0.080373  [ 6400/70010]
loss: 0.125943  [12800/70010]
loss: 0.083989  [19200/70010]
loss: 0.102526  [25600/70010]
loss: 0.022578  [32000/70010]
loss: 0.033340  [38400/70010]
loss: 0.112134  [44800/70010]
loss: 0.091616  [51200/70010]
loss: 0.081686  [57600/70010]
loss: 0.051944  [64000/70010]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084060 

Epoch 22
-------------------------------
loss: 0.049016  [    0/70010]
loss: 0.059011  [ 6400/70010]
loss: 0.051989  [12800/70010]
loss: 0.038332  [19200/70010]
loss: 0.041194  [25600/70010]
loss: 0.084441  [32000/70010]
loss: 0.170074  [38400/70010]
loss: 0.067669  [44800/70010]
loss: 0.069097  [51200/70010]
loss: 0.103630  [57600/70010]
loss: 0.061589  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.089678 

Epoch 23
-------------------------------
loss: 0.056055  [    0/70010]
loss: 0.016663  [ 6400/70010]
loss: 0.033894  [12800/70010]
loss: 0.027820  [19200/70010]
loss: 0.097866  [25600/70010]
loss: 0.147644  [32000/70010]
loss: 0.168309  [38400/70010]
loss: 0.111544  [44800/70010]
loss: 0.031168  [51200/70010]
loss: 0.050413  [57600/70010]
loss: 0.076266  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.085824 

Epoch 24
-------------------------------
loss: 0.050133  [    0/70010]
loss: 0.049602  [ 6400/70010]
loss: 0.038315  [12800/70010]
loss: 0.078614  [19200/70010]
loss: 0.019193  [25600/70010]
loss: 0.138959  [32000/70010]
loss: 0.087270  [38400/70010]
loss: 0.055999  [44800/70010]
loss: 0.074705  [51200/70010]
loss: 0.157653  [57600/70010]
loss: 0.077283  [64000/70010]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083622 

Epoch 25
-------------------------------
loss: 0.036509  [    0/70010]
loss: 0.090729  [ 6400/70010]
loss: 0.137978  [12800/70010]
loss: 0.186347  [19200/70010]
loss: 0.059210  [25600/70010]
loss: 0.101514  [32000/70010]
loss: 0.028121  [38400/70010]
loss: 0.055147  [44800/70010]
loss: 0.066709  [51200/70010]
loss: 0.085955  [57600/70010]
loss: 0.093974  [64000/70010]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084504 

Epoch 26
-------------------------------
loss: 0.175383  [    0/70010]
loss: 0.069018  [ 6400/70010]
loss: 0.157692  [12800/70010]
loss: 0.042961  [19200/70010]
loss: 0.015689  [25600/70010]
loss: 0.110979  [32000/70010]
loss: 0.113577  [38400/70010]
loss: 0.040922  [44800/70010]
loss: 0.080658  [51200/70010]
loss: 0.030261  [57600/70010]
loss: 0.025148  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.092673 

Epoch 27
-------------------------------
loss: 0.040354  [    0/70010]
loss: 0.093735  [ 6400/70010]
loss: 0.087183  [12800/70010]
loss: 0.006118  [19200/70010]
loss: 0.120763  [25600/70010]
loss: 0.090336  [32000/70010]
loss: 0.100686  [38400/70010]
loss: 0.139169  [44800/70010]
loss: 0.035306  [51200/70010]
loss: 0.036628  [57600/70010]
loss: 0.120305  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085581 

Epoch 28
-------------------------------
loss: 0.167763  [    0/70010]
loss: 0.107004  [ 6400/70010]
loss: 0.096010  [12800/70010]
loss: 0.181496  [19200/70010]
loss: 0.076477  [25600/70010]
loss: 0.038801  [32000/70010]
loss: 0.153998  [38400/70010]
loss: 0.092852  [44800/70010]
loss: 0.080706  [51200/70010]
loss: 0.085201  [57600/70010]
loss: 0.091361  [64000/70010]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.085224 

Epoch 29
-------------------------------
loss: 0.099712  [    0/70010]
loss: 0.103331  [ 6400/70010]
loss: 0.049197  [12800/70010]
loss: 0.218479  [32000/70446]
loss: 0.122778  [38400/70446]
loss: 0.232573  [44800/70446]
loss: 0.121268  [51200/70446]
loss: 0.127749  [57600/70446]
loss: 0.142803  [64000/70446]
loss: 0.209272  [50600/70446]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.161704 

Epoch 10
-------------------------------
loss: 0.267375  [    0/70446]
loss: 0.110947  [ 6400/70446]
loss: 0.137887  [12800/70446]
loss: 0.090650  [19200/70446]
loss: 0.135722  [25600/70446]
loss: 0.235351  [32000/70446]
loss: 0.111789  [38400/70446]
loss: 0.148395  [44800/70446]
loss: 0.127949  [51200/70446]
loss: 0.082890  [57600/70446]
loss: 0.148389  [64000/70446]
loss: 0.090108  [50600/70446]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.150011 

Epoch 11
-------------------------------
loss: 0.106172  [    0/70446]
loss: 0.090071  [ 6400/70446]
loss: 0.092504  [12800/70446]
loss: 0.176916  [19200/70446]
loss: 0.144589  [25600/70446]
loss: 0.139662  [32000/70446]
loss: 0.265911  [38400/70446]
loss: 0.176673  [44800/70446]
loss: 0.259512  [51200/70446]
loss: 0.142882  [57600/70446]
loss: 0.284054  [64000/70446]
loss: 0.088328  [50600/70446]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.149330 

Epoch 12
-------------------------------
loss: 0.052389  [    0/70446]
loss: 0.063825  [ 6400/70446]
loss: 0.184254  [12800/70446]
loss: 0.108202  [19200/70446]
loss: 0.087590  [25600/70446]
loss: 0.134697  [32000/70446]
loss: 0.155202  [38400/70446]
loss: 0.139880  [44800/70446]
loss: 0.109070  [51200/70446]
loss: 0.096451  [57600/70446]
loss: 0.131893  [64000/70446]
loss: 0.097084  [50600/70446]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.150138 

Epoch 13
-------------------------------
loss: 0.083062  [    0/70446]
loss: 0.134103  [ 6400/70446]
loss: 0.160953  [12800/70446]
loss: 0.048960  [19200/70446]
loss: 0.167309  [25600/70446]
loss: 0.112002  [32000/70446]
loss: 0.052339  [38400/70446]
loss: 0.162603  [44800/70446]
loss: 0.113515  [51200/70446]
loss: 0.165754  [57600/70446]
loss: 0.103972  [64000/70446]
loss: 0.104017  [50600/70446]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.149613 

Epoch 14
-------------------------------
loss: 0.205070  [    0/70446]
loss: 0.093533  [ 6400/70446]
loss: 0.126279  [12800/70446]
loss: 0.116104  [19200/70446]
loss: 0.173400  [25600/70446]
loss: 0.144692  [32000/70446]
loss: 0.114175  [38400/70446]
loss: 0.028269  [44800/70446]
loss: 0.165900  [51200/70446]
loss: 0.119103  [57600/70446]
loss: 0.157707  [64000/70446]
loss: 0.240845  [50600/70446]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.155133 

Epoch 15
-------------------------------
loss: 0.179015  [    0/70446]
loss: 0.119232  [ 6400/70446]
loss: 0.158982  [12800/70446]
loss: 0.111046  [19200/70446]
loss: 0.209123  [25600/70446]
loss: 0.167080  [32000/70446]
loss: 0.127237  [38400/70446]
loss: 0.215121  [44800/70446]
loss: 0.150127  [51200/70446]
loss: 0.099138  [57600/70446]
loss: 0.177799  [64000/70446]
loss: 0.095255  [50600/70446]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.143821 

Epoch 16
-------------------------------
loss: 0.159071  [    0/70446]
loss: 0.167381  [ 6400/70446]
loss: 0.113498  [12800/70446]
loss: 0.063161  [19200/70446]
loss: 0.069911  [25600/70446]
loss: 0.121782  [32000/70446]
loss: 0.156072  [38400/70446]
loss: 0.119006  [44800/70446]
loss: 0.146316  [51200/70446]
loss: 0.172452  [57600/70446]
loss: 0.102449  [64000/70446]
loss: 0.086062  [50600/70446]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.148755 

Epoch 17
-------------------------------
loss: 0.053238  [    0/70446]
loss: 0.105311  [ 6400/70446]
loss: 0.083363  [12800/70446]
loss: 0.259889  [19200/70446]
loss: 0.075491  [25600/70446]
loss: 0.053695  [32000/70446]
loss: 0.085521  [38400/70446]
loss: 0.073495  [44800/70446]
loss: 0.165461  [51200/70446]
loss: 0.082356  [57600/70446]
loss: 0.212611  [64000/70446]
loss: 0.080506  [50600/70446]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.152829 

Epoch 18
-------------------------------
loss: 0.164993  [    0/70446]
loss: 0.052316  [ 6400/70446]
loss: 0.108100  [12800/70446]
loss: 0.210696  [19200/70446]
loss: 0.120907  [25600/70446]
loss: 0.143254  [32000/70446]
loss: 0.208480  [38400/70446]
loss: 0.166676  [44800/70446]
loss: 0.112760  [51200/70446]
loss: 0.225302  [57600/70446]
loss: 0.304602  [64000/70446]
loss: 0.151980  [50600/70446]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.144328 

Epoch 19
-------------------------------
loss: 0.046380  [    0/70446]
loss: 0.128196  [ 6400/70446]
loss: 0.208465  [12800/70446]
loss: 0.100196  [19200/70446]
loss: 0.145483  [25600/70446]
loss: 0.184417  [32000/70446]
loss: 0.058630  [38400/70446]
loss: 0.059984  [44800/70446]
loss: 0.148685  [51200/70446]
loss: 0.087470  [57600/70446]
loss: 0.199168  [64000/70446]
loss: 0.191602  [50600/70446]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.149830 

Epoch 20
-------------------------------
loss: 0.159839  [    0/70446]
loss: 0.129004  [ 6400/70446]
loss: 0.075679  [12800/70446]
loss: 0.085340  [19200/70446]
loss: 0.117318  [25600/70446]
loss: 0.088299  [32000/70446]
loss: 0.144915  [38400/70446]
loss: 0.114710  [44800/70446]
loss: 0.131605  [51200/70446]
loss: 0.181831  [57600/70446]
loss: 0.151259  [64000/70446]
loss: 0.102181  [50600/70446]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.149119 

Epoch 21
-------------------------------
loss: 0.144425  [    0/70446]
loss: 0.152876  [ 6400/70446]
loss: 0.058711  [12800/70446]
loss: 0.050073  [19200/70446]
loss: 0.067079  [25600/70446]
loss: 0.165773  [32000/70446]
loss: 0.186011  [38400/70446]
loss: 0.230362  [44800/70446]
loss: 0.106731  [51200/70446]
loss: 0.205834  [57600/70446]
loss: 0.138845  [64000/70446]
loss: 0.083593  [50600/70446]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.144734 

Epoch 22
-------------------------------
loss: 0.099462  [    0/70446]
loss: 0.076009  [ 6400/70446]
loss: 0.032587  [12800/70446]
loss: 0.029370  [19200/70446]
loss: 0.175923  [25600/70446]
loss: 0.204154  [32000/70446]
loss: 0.139564  [38400/70446]
loss: 0.238942  [44800/70446]
loss: 0.220463  [51200/70446]
loss: 0.197542  [57600/70446]
loss: 0.059847  [64000/70446]
loss: 0.113445  [50600/70446]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146321 

Epoch 23
-------------------------------
loss: 0.113007  [    0/70446]
loss: 0.255751  [ 6400/70446]
loss: 0.150424  [12800/70446]
loss: 0.186450  [19200/70446]
loss: 0.171135  [25600/70446]
loss: 0.100211  [32000/70446]
loss: 0.132644  [38400/70446]
loss: 0.090260  [44800/70446]
loss: 0.095270  [51200/70446]
loss: 0.055652  [57600/70446]
loss: 0.106336  [64000/70446]
loss: 0.166179  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.142869 

Epoch 24
-------------------------------
loss: 0.058558  [    0/70446]
loss: 0.115014  [ 6400/70446]
loss: 0.069936  [12800/70446]
loss: 0.157807  [19200/70446]
loss: 0.119185  [25600/70446]
loss: 0.168691  [32000/70446]
loss: 0.041734  [38400/70446]
loss: 0.099865  [44800/70446]
loss: 0.148710  [51200/70446]
loss: 0.112652  [57600/70446]
loss: 0.135498  [64000/70446]
loss: 0.111244  [50600/70446]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140476 

Epoch 25
-------------------------------
loss: 0.141837  [    0/70446]
loss: 0.276976  [ 6400/70446]
loss: 0.172171  [12800/70446]
loss: 0.115814  [19200/70446]
loss: 0.074088  [25600/70446]
loss: 0.165697  [32000/70446]
loss: 0.064096  [38400/70446]
loss: 0.094157  [44800/70446]
loss: 0.086241  [51200/70446]
loss: 0.101449  [57600/70446]
loss: 0.058274  [64000/70446]
loss: 0.070673  [50600/70446]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.154046 

Epoch 26
-------------------------------
loss: 0.187417  [    0/70446]
loss: 0.111146  [ 6400/70446]
loss: 0.100270  [12800/70446]
loss: 0.028132  [19200/70446]
loss: 0.090352  [25600/70446]
loss: 0.088112  [32000/70446]
loss: 0.067113  [38400/70446]
loss: 0.073461  [44800/70446]
loss: 0.090726  [51200/70446]
loss: 0.215123  [57600/70446]
loss: 0.073966  [64000/70446]
loss: 0.063171  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.141559 

Epoch 27
-------------------------------
loss: 0.214410  [    0/70446]
loss: 0.091206  [ 6400/70446]
loss: 0.142585  [12800/70446]
loss: 0.043379  [19200/70446]
loss: 0.144959  [25600/70446]
loss: 0.131262  [32000/70446]
loss: 0.135109  [32000/71130]
loss: 0.035431  [38400/71130]
loss: 0.069557  [44800/71130]
loss: 0.074582  [51200/71130]
loss: 0.070324  [57600/71130]
loss: 0.066657  [64000/71130]
loss: 0.071421  [70400/71130]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.065203 

Epoch 10
-------------------------------
loss: 0.028087  [    0/71130]
loss: 0.065162  [ 6400/71130]
loss: 0.093408  [12800/71130]
loss: 0.015032  [19200/71130]
loss: 0.053717  [25600/71130]
loss: 0.021830  [32000/71130]
loss: 0.082690  [38400/71130]
loss: 0.041303  [44800/71130]
loss: 0.042455  [51200/71130]
loss: 0.103242  [57600/71130]
loss: 0.017777  [64000/71130]
loss: 0.093589  [70400/71130]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.060000 

Epoch 11
-------------------------------
loss: 0.119368  [    0/71130]
loss: 0.070590  [ 6400/71130]
loss: 0.069286  [12800/71130]
loss: 0.020368  [19200/71130]
loss: 0.058032  [25600/71130]
loss: 0.056330  [32000/71130]
loss: 0.072570  [38400/71130]
loss: 0.015931  [44800/71130]
loss: 0.316618  [51200/71130]
loss: 0.053942  [57600/71130]
loss: 0.070524  [64000/71130]
loss: 0.047147  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072676 

Epoch 12
-------------------------------
loss: 0.028468  [    0/71130]
loss: 0.049299  [ 6400/71130]
loss: 0.043863  [12800/71130]
loss: 0.013977  [19200/71130]
loss: 0.162506  [25600/71130]
loss: 0.074060  [32000/71130]
loss: 0.075501  [38400/71130]
loss: 0.031582  [44800/71130]
loss: 0.090398  [51200/71130]
loss: 1.584919  [57600/71130]
loss: 0.028312  [64000/71130]
loss: 0.032202  [70400/71130]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.062503 

Epoch 13
-------------------------------
loss: 0.005510  [    0/71130]
loss: 0.095269  [ 6400/71130]
loss: 0.051064  [12800/71130]
loss: 0.111618  [19200/71130]
loss: 0.065913  [25600/71130]
loss: 0.056157  [32000/71130]
loss: 0.025975  [38400/71130]
loss: 0.082110  [44800/71130]
loss: 0.108149  [51200/71130]
loss: 0.054542  [57600/71130]
loss: 0.142637  [64000/71130]
loss: 0.082974  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069596 

Epoch 14
-------------------------------
loss: 0.037003  [    0/71130]
loss: 0.046512  [ 6400/71130]
loss: 0.012117  [12800/71130]
loss: 0.072815  [19200/71130]
loss: 0.049952  [25600/71130]
loss: 0.042887  [32000/71130]
loss: 0.046192  [38400/71130]
loss: 0.066767  [44800/71130]
loss: 0.017255  [51200/71130]
loss: 0.008361  [57600/71130]
loss: 0.038549  [64000/71130]
loss: 0.088187  [70400/71130]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.059928 

Epoch 15
-------------------------------
loss: 0.052112  [    0/71130]
loss: 0.022611  [ 6400/71130]
loss: 0.073400  [12800/71130]
loss: 0.027526  [19200/71130]
loss: 0.058596  [25600/71130]
loss: 0.062775  [32000/71130]
loss: 0.073551  [38400/71130]
loss: 0.063782  [44800/71130]
loss: 0.020747  [51200/71130]
loss: 0.038545  [57600/71130]
loss: 0.116564  [64000/71130]
loss: 0.197238  [70400/71130]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.064529 

Epoch 16
-------------------------------
loss: 0.077374  [    0/71130]
loss: 0.035459  [ 6400/71130]
loss: 0.028937  [12800/71130]
loss: 0.041722  [19200/71130]
loss: 0.115729  [25600/71130]
loss: 0.044573  [32000/71130]
loss: 0.253964  [38400/71130]
loss: 0.064427  [44800/71130]
loss: 0.059081  [51200/71130]
loss: 0.054513  [57600/71130]
loss: 0.018461  [64000/71130]
loss: 0.094998  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.063842 

Epoch 17
-------------------------------
loss: 0.045928  [    0/71130]
loss: 0.013494  [ 6400/71130]
loss: 0.068348  [12800/71130]
loss: 0.035282  [19200/71130]
loss: 0.089396  [25600/71130]
loss: 0.050594  [32000/71130]
loss: 0.023952  [38400/71130]
loss: 0.034919  [44800/71130]
loss: 0.113589  [51200/71130]
loss: 0.090395  [57600/71130]
loss: 0.062836  [64000/71130]
loss: 0.051297  [70400/71130]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.061278 

Epoch 18
-------------------------------
loss: 0.046483  [    0/71130]
loss: 0.056814  [ 6400/71130]
loss: 0.045045  [12800/71130]
loss: 0.091826  [19200/71130]
loss: 0.032528  [25600/71130]
loss: 0.080260  [32000/71130]
loss: 0.094893  [38400/71130]
loss: 0.065810  [44800/71130]
loss: 0.010369  [51200/71130]
loss: 0.130934  [57600/71130]
loss: 0.039512  [64000/71130]
loss: 0.111947  [70400/71130]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.071153 

Epoch 19
-------------------------------
loss: 0.009337  [    0/71130]
loss: 0.049623  [ 6400/71130]
loss: 0.022602  [12800/71130]
loss: 0.110042  [19200/71130]
loss: 0.053992  [25600/71130]
loss: 0.125094  [32000/71130]
loss: 0.009956  [38400/71130]
loss: 0.102714  [44800/71130]
loss: 0.035878  [51200/71130]
loss: 0.119141  [57600/71130]
loss: 0.170395  [64000/71130]
loss: 0.020503  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.065362 

Epoch 20
-------------------------------
loss: 0.067403  [    0/71130]
loss: 0.091108  [ 6400/71130]
loss: 0.071830  [12800/71130]
loss: 0.033320  [19200/71130]
loss: 0.022310  [25600/71130]
loss: 0.092784  [32000/71130]
loss: 0.090125  [38400/71130]
loss: 0.071010  [44800/71130]
loss: 0.060393  [51200/71130]
loss: 0.009515  [57600/71130]
loss: 0.070229  [64000/71130]
loss: 0.102729  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.065091 

Epoch 21
-------------------------------
loss: 0.042302  [    0/71130]
loss: 0.044237  [ 6400/71130]
loss: 0.049324  [12800/71130]
loss: 0.042446  [19200/71130]
loss: 0.052743  [25600/71130]
loss: 0.015448  [32000/71130]
loss: 0.035295  [38400/71130]
loss: 0.035111  [44800/71130]
loss: 0.119478  [51200/71130]
loss: 0.081344  [57600/71130]
loss: 0.068567  [64000/71130]
loss: 0.011773  [70400/71130]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.064726 

Epoch 22
-------------------------------
loss: 0.018516  [    0/71130]
loss: 0.086985  [ 6400/71130]
loss: 0.038656  [12800/71130]
loss: 0.079805  [19200/71130]
loss: 0.022237  [25600/71130]
loss: 0.112313  [32000/71130]
loss: 0.076017  [38400/71130]
loss: 0.075452  [44800/71130]
loss: 0.088633  [51200/71130]
loss: 0.047317  [57600/71130]
loss: 0.054776  [64000/71130]
loss: 0.061843  [70400/71130]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.081652 

Epoch 23
-------------------------------
loss: 0.062457  [    0/71130]
loss: 0.076140  [ 6400/71130]
loss: 0.018243  [12800/71130]
loss: 0.016518  [19200/71130]
loss: 0.014752  [25600/71130]
loss: 0.042724  [32000/71130]
loss: 0.016529  [38400/71130]
loss: 0.023363  [44800/71130]
loss: 0.042790  [51200/71130]
loss: 0.062872  [57600/71130]
loss: 0.017038  [64000/71130]
loss: 0.030981  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066992 

Epoch 24
-------------------------------
loss: 0.040265  [    0/71130]
loss: 0.039488  [ 6400/71130]
loss: 0.028749  [12800/71130]
loss: 0.119403  [19200/71130]
loss: 0.050249  [25600/71130]
loss: 0.035798  [32000/71130]
loss: 0.075505  [38400/71130]
loss: 0.043493  [44800/71130]
loss: 0.058152  [51200/71130]
loss: 0.021198  [57600/71130]
loss: 0.027016  [64000/71130]
loss: 0.007742  [70400/71130]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.066091 

Epoch 25
-------------------------------
loss: 0.053121  [    0/71130]
loss: 0.028811  [ 6400/71130]
loss: 0.014055  [12800/71130]
loss: 0.082829  [19200/71130]
loss: 0.084100  [25600/71130]
loss: 0.144074  [32000/71130]
loss: 0.032110  [38400/71130]
loss: 0.027053  [44800/71130]
loss: 0.070094  [51200/71130]
loss: 0.037516  [57600/71130]
loss: 0.027980  [64000/71130]
loss: 0.030863  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068253 

Epoch 26
-------------------------------
loss: 0.031953  [    0/71130]
loss: 0.013786  [ 6400/71130]
loss: 0.024425  [12800/71130]
loss: 0.069668  [19200/71130]
loss: 0.057724  [25600/71130]
loss: 0.048482  [32000/71130]
loss: 0.057114  [38400/71130]
loss: 0.018778  [44800/71130]
loss: 0.042722  [51200/71130]
loss: 0.083808  [57600/71130]
loss: 0.008558  [64000/71130]
loss: 0.019231  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.065298 

Epoch 27
-------------------------------
loss: 0.004271  [    0/71130]
loss: 0.043428  [ 6400/71130]
loss: 0.024740  [12800/71130]
loss: 0.095053  [19200/71130]
loss: 0.028019  [25600/71130]
loss: 0.024550  [32000/71130]
loss: 0.117883  [32000/71180]
loss: 0.093392  [38400/71180]
loss: 0.066325  [44800/71180]
loss: 0.084134  [51200/71180]
loss: 0.072386  [57600/71180]
loss: 0.053130  [64000/71180]
loss: 0.117638  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.122287 

Epoch 10
-------------------------------
loss: 0.028407  [    0/71180]
loss: 0.117181  [ 6400/71180]
loss: 0.049714  [12800/71180]
loss: 0.142765  [19200/71180]
loss: 0.026081  [25600/71180]
loss: 0.085564  [32000/71180]
loss: 0.138036  [38400/71180]
loss: 0.080321  [44800/71180]
loss: 0.050825  [51200/71180]
loss: 0.153943  [57600/71180]
loss: 0.142904  [64000/71180]
loss: 0.117099  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.126584 

Epoch 11
-------------------------------
loss: 0.026706  [    0/71180]
loss: 0.073038  [ 6400/71180]
loss: 0.133932  [12800/71180]
loss: 0.114020  [19200/71180]
loss: 0.091059  [25600/71180]
loss: 0.075345  [32000/71180]
loss: 0.077429  [38400/71180]
loss: 0.044084  [44800/71180]
loss: 0.141603  [51200/71180]
loss: 0.076451  [57600/71180]
loss: 0.048764  [64000/71180]
loss: 0.241727  [70400/71180]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.119094 

Epoch 12
-------------------------------
loss: 0.062984  [    0/71180]
loss: 0.110378  [ 6400/71180]
loss: 0.060600  [12800/71180]
loss: 0.039106  [19200/71180]
loss: 0.067867  [25600/71180]
loss: 0.073092  [32000/71180]
loss: 0.075888  [38400/71180]
loss: 0.087127  [44800/71180]
loss: 0.113972  [51200/71180]
loss: 0.051847  [57600/71180]
loss: 0.014096  [64000/71180]
loss: 0.115617  [70400/71180]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.129507 

Epoch 13
-------------------------------
loss: 0.210624  [    0/71180]
loss: 0.075761  [ 6400/71180]
loss: 0.053548  [12800/71180]
loss: 0.083762  [19200/71180]
loss: 0.086182  [25600/71180]
loss: 0.084166  [32000/71180]
loss: 0.054033  [38400/71180]
loss: 0.084766  [44800/71180]
loss: 0.109596  [51200/71180]
loss: 1.746186  [57600/71180]
loss: 0.102189  [64000/71180]
loss: 0.039613  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.118288 

Epoch 14
-------------------------------
loss: 0.130841  [    0/71180]
loss: 0.060458  [ 6400/71180]
loss: 0.047374  [12800/71180]
loss: 0.083773  [19200/71180]
loss: 0.069448  [25600/71180]
loss: 0.144711  [32000/71180]
loss: 0.026826  [38400/71180]
loss: 0.120550  [44800/71180]
loss: 0.078433  [51200/71180]
loss: 0.062735  [57600/71180]
loss: 0.103415  [64000/71180]
loss: 0.038510  [70400/71180]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.124232 

Epoch 15
-------------------------------
loss: 0.168094  [    0/71180]
loss: 0.100046  [ 6400/71180]
loss: 0.083844  [12800/71180]
loss: 0.039039  [19200/71180]
loss: 0.033123  [25600/71180]
loss: 0.060120  [32000/71180]
loss: 0.102758  [38400/71180]
loss: 0.097219  [44800/71180]
loss: 0.115822  [51200/71180]
loss: 0.048829  [57600/71180]
loss: 0.098520  [64000/71180]
loss: 0.035770  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.123752 

Epoch 16
-------------------------------
loss: 0.081254  [    0/71180]
loss: 0.041704  [ 6400/71180]
loss: 0.073416  [12800/71180]
loss: 0.093285  [19200/71180]
loss: 0.068258  [25600/71180]
loss: 0.052085  [32000/71180]
loss: 0.094863  [38400/71180]
loss: 0.099700  [44800/71180]
loss: 0.025713  [51200/71180]
loss: 0.050260  [57600/71180]
loss: 0.055218  [64000/71180]
loss: 0.074797  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.123989 

Epoch 17
-------------------------------
loss: 0.064524  [    0/71180]
loss: 0.068240  [ 6400/71180]
loss: 0.032287  [12800/71180]
loss: 0.140747  [19200/71180]
loss: 0.033152  [25600/71180]
loss: 0.038966  [32000/71180]
loss: 0.052295  [38400/71180]
loss: 0.080579  [44800/71180]
loss: 0.132632  [51200/71180]
loss: 0.116375  [57600/71180]
loss: 0.024360  [64000/71180]
loss: 0.040147  [70400/71180]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.122521 

Epoch 18
-------------------------------
loss: 0.068336  [    0/71180]
loss: 0.069988  [ 6400/71180]
loss: 0.135050  [12800/71180]
loss: 0.098892  [19200/71180]
loss: 0.022374  [25600/71180]
loss: 0.075481  [32000/71180]
loss: 0.069953  [38400/71180]
loss: 0.088744  [44800/71180]
loss: 0.065777  [51200/71180]
loss: 0.050266  [57600/71180]
loss: 0.069212  [64000/71180]
loss: 0.109698  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.121995 

Epoch 19
-------------------------------
loss: 0.091443  [    0/71180]
loss: 0.074781  [ 6400/71180]
loss: 0.077975  [12800/71180]
loss: 0.025942  [19200/71180]
loss: 0.074835  [25600/71180]
loss: 0.193360  [32000/71180]
loss: 0.110869  [38400/71180]
loss: 0.102031  [44800/71180]
loss: 0.044180  [51200/71180]
loss: 0.131548  [57600/71180]
loss: 0.173757  [64000/71180]
loss: 0.053500  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.124640 

Epoch 20
-------------------------------
loss: 0.101515  [    0/71180]
loss: 0.079141  [ 6400/71180]
loss: 0.043469  [12800/71180]
loss: 0.117640  [19200/71180]
loss: 0.061739  [25600/71180]
loss: 0.279786  [32000/71180]
loss: 0.165467  [38400/71180]
loss: 0.082229  [44800/71180]
loss: 0.070354  [51200/71180]
loss: 0.159766  [57600/71180]
loss: 0.046310  [64000/71180]
loss: 0.044812  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.134985 

Epoch 21
-------------------------------
loss: 0.149462  [    0/71180]
loss: 0.087966  [ 6400/71180]
loss: 0.040746  [12800/71180]
loss: 0.038982  [19200/71180]
loss: 0.381388  [25600/71180]
loss: 0.101797  [32000/71180]
loss: 0.078600  [38400/71180]
loss: 0.092458  [44800/71180]
loss: 0.048116  [51200/71180]
loss: 0.046578  [57600/71180]
loss: 0.073270  [64000/71180]
loss: 0.097472  [70400/71180]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.150155 

Epoch 22
-------------------------------
loss: 0.105593  [    0/71180]
loss: 0.069060  [ 6400/71180]
loss: 0.098393  [12800/71180]
loss: 0.120403  [19200/71180]
loss: 0.011344  [25600/71180]
loss: 0.081136  [32000/71180]
loss: 0.030514  [38400/71180]
loss: 0.067570  [44800/71180]
loss: 0.071510  [51200/71180]
loss: 0.043009  [57600/71180]
loss: 0.051335  [64000/71180]
loss: 0.048909  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.120105 

Epoch 23
-------------------------------
loss: 0.039183  [    0/71180]
loss: 0.048490  [ 6400/71180]
loss: 0.097719  [12800/71180]
loss: 0.080078  [19200/71180]
loss: 0.076621  [25600/71180]
loss: 0.041712  [32000/71180]
loss: 0.074561  [38400/71180]
loss: 1.677906  [44800/71180]
loss: 0.102564  [51200/71180]
loss: 0.109684  [57600/71180]
loss: 0.081158  [64000/71180]
loss: 0.125980  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.118856 

Epoch 24
-------------------------------
loss: 0.021567  [    0/71180]
loss: 0.076594  [ 6400/71180]
loss: 0.070997  [12800/71180]
loss: 0.068499  [19200/71180]
loss: 0.085090  [25600/71180]
loss: 0.054224  [32000/71180]
loss: 0.143258  [38400/71180]
loss: 0.097739  [44800/71180]
loss: 0.040194  [51200/71180]
loss: 0.112456  [57600/71180]
loss: 0.119499  [64000/71180]
loss: 0.069592  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.123847 

Epoch 25
-------------------------------
loss: 0.085933  [    0/71180]
loss: 0.124870  [ 6400/71180]
loss: 0.052539  [12800/71180]
loss: 0.056341  [19200/71180]
loss: 0.044757  [25600/71180]
loss: 0.072187  [32000/71180]
loss: 0.049103  [38400/71180]
loss: 0.156089  [44800/71180]
loss: 0.064030  [51200/71180]
loss: 0.045492  [57600/71180]
loss: 0.064968  [64000/71180]
loss: 0.073183  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.124007 

Epoch 26
-------------------------------
loss: 0.145204  [    0/71180]
loss: 0.016097  [ 6400/71180]
loss: 0.046423  [12800/71180]
loss: 0.043321  [19200/71180]
loss: 0.087338  [25600/71180]
loss: 0.128920  [32000/71180]
loss: 0.111580  [38400/71180]
loss: 0.016070  [44800/71180]
loss: 0.039518  [51200/71180]
loss: 0.028759  [57600/71180]
loss: 0.107987  [64000/71180]
loss: 0.085728  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.125157 

Epoch 27
-------------------------------
loss: 0.011801  [    0/71180]
loss: 0.046571  [ 6400/71180]
loss: 0.054037  [12800/71180]
loss: 0.070780  [19200/71180]
loss: 0.098376  [25600/71180]
loss: 0.110122  [32000/71180]
loss: 0.090122  [32000/70482]
loss: 0.197416  [38400/70482]
loss: 0.112984  [44800/70482]
loss: 0.112956  [51200/70482]
loss: 0.156914  [57600/70482]
loss: 0.202595  [64000/70482]
loss: 0.111468  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.141401 

Epoch 10
-------------------------------
loss: 0.102650  [    0/70482]
loss: 0.113057  [ 6400/70482]
loss: 0.100948  [12800/70482]
loss: 0.049874  [19200/70482]
loss: 0.130460  [25600/70482]
loss: 0.249013  [32000/70482]
loss: 0.192722  [38400/70482]
loss: 0.226441  [44800/70482]
loss: 0.075320  [51200/70482]
loss: 0.161083  [57600/70482]
loss: 0.086605  [64000/70482]
loss: 0.086555  [70400/70482]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.143573 

Epoch 11
-------------------------------
loss: 0.144042  [    0/70482]
loss: 0.168298  [ 6400/70482]
loss: 0.123083  [12800/70482]
loss: 0.026307  [19200/70482]
loss: 0.109326  [25600/70482]
loss: 0.206200  [32000/70482]
loss: 0.188349  [38400/70482]
loss: 0.134843  [44800/70482]
loss: 0.070324  [51200/70482]
loss: 0.100778  [57600/70482]
loss: 0.242046  [64000/70482]
loss: 0.249023  [70400/70482]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.143501 

Epoch 12
-------------------------------
loss: 0.097470  [    0/70482]
loss: 0.093489  [ 6400/70482]
loss: 0.075924  [12800/70482]
loss: 0.108959  [19200/70482]
loss: 0.249006  [25600/70482]
loss: 0.089570  [32000/70482]
loss: 0.194923  [38400/70482]
loss: 0.073546  [44800/70482]
loss: 0.090645  [51200/70482]
loss: 0.043488  [57600/70482]
loss: 0.124028  [64000/70482]
loss: 0.045137  [70400/70482]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.159891 

Epoch 13
-------------------------------
loss: 0.082540  [    0/70482]
loss: 0.093431  [ 6400/70482]
loss: 0.121537  [12800/70482]
loss: 0.057705  [19200/70482]
loss: 0.183390  [25600/70482]
loss: 0.112113  [32000/70482]
loss: 0.074403  [38400/70482]
loss: 0.215624  [44800/70482]
loss: 0.158324  [51200/70482]
loss: 0.125737  [57600/70482]
loss: 0.133110  [64000/70482]
loss: 0.068001  [70400/70482]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.152545 

Epoch 14
-------------------------------
loss: 0.116302  [    0/70482]
loss: 0.186782  [ 6400/70482]
loss: 0.123451  [12800/70482]
loss: 0.084863  [19200/70482]
loss: 0.211865  [25600/70482]
loss: 0.080460  [32000/70482]
loss: 0.214130  [38400/70482]
loss: 0.189076  [44800/70482]
loss: 0.222136  [51200/70482]
loss: 0.060968  [57600/70482]
loss: 0.199176  [64000/70482]
loss: 0.111006  [70400/70482]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.141872 

Epoch 15
-------------------------------
loss: 0.171475  [    0/70482]
loss: 0.159139  [ 6400/70482]
loss: 0.084901  [12800/70482]
loss: 0.089890  [19200/70482]
loss: 0.051172  [25600/70482]
loss: 0.123365  [32000/70482]
loss: 0.131797  [38400/70482]
loss: 0.066673  [44800/70482]
loss: 0.135770  [51200/70482]
loss: 0.139501  [57600/70482]
loss: 0.217239  [64000/70482]
loss: 0.099903  [70400/70482]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.146716 

Epoch 16
-------------------------------
loss: 0.182019  [    0/70482]
loss: 0.119781  [ 6400/70482]
loss: 0.121041  [12800/70482]
loss: 0.090471  [19200/70482]
loss: 0.181458  [25600/70482]
loss: 0.124383  [32000/70482]
loss: 0.104873  [38400/70482]
loss: 0.106654  [44800/70482]
loss: 0.156577  [51200/70482]
loss: 0.073843  [57600/70482]
loss: 0.041604  [64000/70482]
loss: 0.082373  [70400/70482]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.144259 

Epoch 17
-------------------------------
loss: 0.144804  [    0/70482]
loss: 0.080435  [ 6400/70482]
loss: 0.105130  [12800/70482]
loss: 0.198766  [19200/70482]
loss: 0.130817  [25600/70482]
loss: 0.206003  [32000/70482]
loss: 0.047818  [38400/70482]
loss: 0.148177  [44800/70482]
loss: 0.118266  [51200/70482]
loss: 0.103118  [57600/70482]
loss: 0.161172  [64000/70482]
loss: 0.109235  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.145592 

Epoch 18
-------------------------------
loss: 0.153462  [    0/70482]
loss: 0.116783  [ 6400/70482]
loss: 0.061725  [12800/70482]
loss: 0.128553  [19200/70482]
loss: 0.162842  [25600/70482]
loss: 0.147062  [32000/70482]
loss: 0.080695  [38400/70482]
loss: 0.095868  [44800/70482]
loss: 0.166933  [51200/70482]
loss: 0.111195  [57600/70482]
loss: 0.140440  [64000/70482]
loss: 0.141752  [70400/70482]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.148095 

Epoch 19
-------------------------------
loss: 0.135185  [    0/70482]
loss: 0.167278  [ 6400/70482]
loss: 0.139818  [12800/70482]
loss: 0.095341  [19200/70482]
loss: 0.121320  [25600/70482]
loss: 0.131919  [32000/70482]
loss: 0.109864  [38400/70482]
loss: 0.099735  [44800/70482]
loss: 0.121293  [51200/70482]
loss: 0.147169  [57600/70482]
loss: 0.103557  [64000/70482]
loss: 0.136349  [70400/70482]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.148902 

Epoch 20
-------------------------------
loss: 0.172838  [    0/70482]
loss: 0.048526  [ 6400/70482]
loss: 0.327237  [12800/70482]
loss: 0.103961  [19200/70482]
loss: 0.080430  [25600/70482]
loss: 0.099390  [32000/70482]
loss: 0.094472  [38400/70482]
loss: 0.166460  [44800/70482]
loss: 0.114307  [51200/70482]
loss: 0.097844  [57600/70482]
loss: 0.060806  [64000/70482]
loss: 0.072115  [70400/70482]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.141001 

Epoch 21
-------------------------------
loss: 0.112251  [    0/70482]
loss: 0.170066  [ 6400/70482]
loss: 0.181633  [12800/70482]
loss: 0.126386  [19200/70482]
loss: 0.058576  [25600/70482]
loss: 0.205256  [32000/70482]
loss: 0.170226  [38400/70482]
loss: 0.077496  [44800/70482]
loss: 0.105961  [51200/70482]
loss: 0.157111  [57600/70482]
loss: 0.043414  [64000/70482]
loss: 0.055133  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.140241 

Epoch 22
-------------------------------
loss: 0.056251  [    0/70482]
loss: 0.102500  [ 6400/70482]
loss: 0.094135  [12800/70482]
loss: 0.058138  [19200/70482]
loss: 0.183835  [25600/70482]
loss: 0.109768  [32000/70482]
loss: 0.164422  [38400/70482]
loss: 0.149707  [44800/70482]
loss: 0.108066  [51200/70482]
loss: 0.134336  [57600/70482]
loss: 0.124295  [64000/70482]
loss: 0.231404  [70400/70482]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.138496 

Epoch 23
-------------------------------
loss: 0.121086  [    0/70482]
loss: 0.094120  [ 6400/70482]
loss: 0.096549  [12800/70482]
loss: 0.157229  [19200/70482]
loss: 0.079768  [25600/70482]
loss: 0.131985  [32000/70482]
loss: 0.157159  [38400/70482]
loss: 0.218999  [44800/70482]
loss: 0.124157  [51200/70482]
loss: 0.071536  [57600/70482]
loss: 0.199451  [64000/70482]
loss: 0.240106  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.142753 

Epoch 24
-------------------------------
loss: 0.057255  [    0/70482]
loss: 0.138188  [ 6400/70482]
loss: 0.066582  [12800/70482]
loss: 1.443450  [19200/70482]
loss: 0.134142  [25600/70482]
loss: 0.114805  [32000/70482]
loss: 0.131779  [38400/70482]
loss: 0.118209  [44800/70482]
loss: 0.121405  [51200/70482]
loss: 0.053180  [57600/70482]
loss: 0.117172  [64000/70482]
loss: 0.147091  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.142265 

Epoch 25
-------------------------------
loss: 0.095039  [    0/70482]
loss: 0.135420  [ 6400/70482]
loss: 0.151716  [12800/70482]
loss: 0.055146  [19200/70482]
loss: 0.125454  [25600/70482]
loss: 0.108697  [32000/70482]
loss: 0.083140  [38400/70482]
loss: 0.117798  [44800/70482]
loss: 0.139899  [51200/70482]
loss: 0.179482  [57600/70482]
loss: 0.223611  [64000/70482]
loss: 0.127648  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139264 

Epoch 26
-------------------------------
loss: 0.257484  [    0/70482]
loss: 0.094753  [ 6400/70482]
loss: 0.119091  [12800/70482]
loss: 0.136597  [19200/70482]
loss: 0.059689  [25600/70482]
loss: 0.108342  [32000/70482]
loss: 0.135594  [38400/70482]
loss: 0.212692  [44800/70482]
loss: 0.162158  [51200/70482]
loss: 0.114566  [57600/70482]
loss: 0.221713  [64000/70482]
loss: 0.157823  [70400/70482]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.136634 

Epoch 27
-------------------------------
loss: 0.084391  [    0/70482]
loss: 0.072718  [ 6400/70482]
loss: 0.060579  [12800/70482]
loss: 0.097549  [19200/70482]
loss: 0.105040  [25600/70482]
loss: 0.117098  [32000/70482]
Epoch 10
-------------------------------
loss: 0.035771  [    0/69822]
loss: 0.173335  [ 6400/69822]
loss: 0.090330  [12800/69822]
loss: 0.035668  [19200/69822]
loss: 0.115273  [25600/69822]
loss: 0.083369  [32000/69822]
loss: 0.063538  [38400/69822]
loss: 0.129439  [44800/69822]
loss: 0.013658  [51200/69822]
loss: 0.079113  [57600/69822]
loss: 0.134709  [64000/69822]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066874 

Epoch 11
-------------------------------
loss: 0.066537  [    0/69822]
loss: 0.094941  [ 6400/69822]
loss: 0.041282  [12800/69822]
loss: 0.101951  [19200/69822]
loss: 0.028772  [25600/69822]
loss: 0.039759  [32000/69822]
loss: 0.021846  [38400/69822]
loss: 0.119450  [44800/69822]
loss: 0.257502  [51200/69822]
loss: 0.063108  [57600/69822]
loss: 0.033385  [64000/69822]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066982 

Epoch 12
-------------------------------
loss: 0.051795  [    0/69822]
loss: 0.009311  [ 6400/69822]
loss: 0.031744  [12800/69822]
loss: 0.023282  [19200/69822]
loss: 0.201630  [25600/69822]
loss: 0.231081  [32000/69822]
loss: 0.048664  [38400/69822]
loss: 0.043263  [44800/69822]
loss: 0.208177  [51200/69822]
loss: 0.058459  [57600/69822]
loss: 0.057885  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.068938 

Epoch 13
-------------------------------
loss: 0.062897  [    0/69822]
loss: 0.017803  [ 6400/69822]
loss: 0.125323  [12800/69822]
loss: 0.076010  [19200/69822]
loss: 0.024589  [25600/69822]
loss: 0.060755  [32000/69822]
loss: 0.162161  [38400/69822]
loss: 0.087953  [44800/69822]
loss: 0.011018  [51200/69822]
loss: 0.030448  [57600/69822]
loss: 0.118792  [64000/69822]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.065505 

Epoch 14
-------------------------------
loss: 0.067783  [    0/69822]
loss: 0.084037  [ 6400/69822]
loss: 0.059009  [12800/69822]
loss: 0.113044  [19200/69822]
loss: 0.116917  [25600/69822]
loss: 0.026420  [32000/69822]
loss: 0.041771  [38400/69822]
loss: 0.054611  [44800/69822]
loss: 0.100684  [51200/69822]
loss: 0.048597  [57600/69822]
loss: 0.169546  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.069441 

Epoch 15
-------------------------------
loss: 0.064309  [    0/69822]
loss: 0.043530  [ 6400/69822]
loss: 0.102026  [12800/69822]
loss: 0.030206  [19200/69822]
loss: 0.005367  [25600/69822]
loss: 0.061750  [32000/69822]
loss: 0.037256  [38400/69822]
loss: 0.032923  [44800/69822]
loss: 0.054579  [51200/69822]
loss: 0.049560  [57600/69822]
loss: 0.021983  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.066452 

Epoch 16
-------------------------------
loss: 0.062942  [    0/69822]
loss: 0.057454  [ 6400/69822]
loss: 0.046896  [12800/69822]
loss: 0.093869  [19200/69822]
loss: 0.153523  [25600/69822]
loss: 0.029429  [32000/69822]
loss: 0.018945  [38400/69822]
loss: 0.084865  [44800/69822]
loss: 0.082720  [51200/69822]
loss: 0.095629  [57600/69822]
loss: 0.098914  [64000/69822]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.076614 

Epoch 17
-------------------------------
loss: 0.043882  [    0/69822]
loss: 0.031749  [ 6400/69822]
loss: 0.052830  [12800/69822]
loss: 0.026549  [19200/69822]
loss: 0.117084  [25600/69822]
loss: 0.050528  [32000/69822]
loss: 0.152672  [38400/69822]
loss: 0.054965  [44800/69822]
loss: 0.078759  [51200/69822]
loss: 0.035894  [57600/69822]
loss: 0.076778  [64000/69822]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.065236 

Epoch 18
-------------------------------
loss: 0.047071  [    0/69822]
loss: 0.161171  [ 6400/69822]
loss: 0.040585  [12800/69822]
loss: 0.082275  [19200/69822]
loss: 0.038715  [25600/69822]
loss: 0.124010  [32000/69822]
loss: 0.070216  [38400/69822]
loss: 0.014457  [44800/69822]
loss: 0.024052  [51200/69822]
loss: 0.026406  [57600/69822]
loss: 0.134402  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.068789 

Epoch 19
-------------------------------
loss: 0.028871  [    0/69822]
loss: 0.057633  [ 6400/69822]
loss: 0.029066  [12800/69822]
loss: 0.028765  [19200/69822]
loss: 0.066835  [25600/69822]
loss: 0.029474  [32000/69822]
loss: 0.018344  [38400/69822]
loss: 0.056328  [44800/69822]
loss: 0.095604  [51200/69822]
loss: 0.015854  [57600/69822]
loss: 0.088462  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070412 

Epoch 20
-------------------------------
loss: 0.028182  [    0/69822]
loss: 0.186567  [ 6400/69822]
loss: 0.055627  [12800/69822]
loss: 0.020305  [19200/69822]
loss: 0.034138  [25600/69822]
loss: 0.097917  [32000/69822]
loss: 0.024880  [38400/69822]
loss: 0.185804  [44800/69822]
loss: 0.071980  [51200/69822]
loss: 0.011504  [57600/69822]
loss: 0.150700  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.070575 

Epoch 21
-------------------------------
loss: 0.040646  [    0/69822]
loss: 0.020690  [ 6400/69822]
loss: 0.026175  [12800/69822]
loss: 0.089049  [19200/69822]
loss: 0.059805  [25600/69822]
loss: 0.057149  [32000/69822]
loss: 0.043549  [38400/69822]
loss: 0.048284  [44800/69822]
loss: 0.060118  [51200/69822]
loss: 0.028566  [57600/69822]
loss: 0.087969  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067415 

Epoch 22
-------------------------------
loss: 0.029560  [    0/69822]
loss: 0.023940  [ 6400/69822]
loss: 0.070446  [12800/69822]
loss: 0.066241  [19200/69822]
loss: 0.072160  [25600/69822]
loss: 0.098819  [32000/69822]
loss: 0.030072  [38400/69822]
loss: 0.069434  [44800/69822]
loss: 0.055774  [51200/69822]
loss: 0.169445  [57600/69822]
loss: 0.066865  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.073045 

Epoch 23
-------------------------------
loss: 0.046565  [    0/69822]
loss: 0.045127  [ 6400/69822]
loss: 0.044336  [12800/69822]
loss: 0.030943  [19200/69822]
loss: 0.126995  [25600/69822]
loss: 0.058581  [32000/69822]
loss: 0.125022  [38400/69822]
loss: 0.099594  [44800/69822]
loss: 0.082315  [51200/69822]
loss: 0.048214  [57600/69822]
loss: 0.039778  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070748 

Epoch 24
-------------------------------
loss: 0.123743  [    0/69822]
loss: 0.037038  [ 6400/69822]
loss: 0.016256  [12800/69822]
loss: 0.042590  [19200/69822]
loss: 0.022746  [25600/69822]
loss: 0.115290  [32000/69822]
loss: 0.052456  [38400/69822]
loss: 0.150749  [44800/69822]
loss: 0.066389  [51200/69822]
loss: 0.079272  [57600/69822]
loss: 0.063046  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070847 

Epoch 25
-------------------------------
loss: 0.024140  [    0/69822]
loss: 0.020128  [ 6400/69822]
loss: 0.028973  [12800/69822]
loss: 0.026834  [19200/69822]
loss: 0.067762  [25600/69822]
loss: 0.031082  [32000/69822]
loss: 0.125113  [38400/69822]
loss: 0.031546  [44800/69822]
loss: 0.046101  [51200/69822]
loss: 0.071315  [57600/69822]
loss: 0.034549  [64000/69822]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.073624 

Epoch 26
-------------------------------
loss: 0.085256  [    0/69822]
loss: 0.005716  [ 6400/69822]
loss: 0.125012  [12800/69822]
loss: 0.054238  [19200/69822]
loss: 0.025726  [25600/69822]
loss: 0.094840  [32000/69822]
loss: 0.045854  [38400/69822]
loss: 0.045406  [44800/69822]
loss: 0.113644  [51200/69822]
loss: 0.025504  [57600/69822]
loss: 0.115414  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072082 

Epoch 27
-------------------------------
loss: 0.074576  [    0/69822]
loss: 0.031037  [ 6400/69822]
loss: 0.058379  [12800/69822]
loss: 0.107146  [19200/69822]
loss: 0.143305  [25600/69822]
loss: 0.040824  [32000/69822]
loss: 0.017190  [38400/69822]
loss: 0.013976  [44800/69822]
loss: 0.089433  [51200/69822]
loss: 0.033639  [57600/69822]
loss: 0.027390  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.077837 

Epoch 28
-------------------------------
loss: 0.077152  [    0/69822]
loss: 0.011895  [ 6400/69822]
loss: 0.052984  [12800/69822]
loss: 0.015042  [19200/69822]
loss: 0.064088  [25600/69822]
loss: 0.062074  [32000/69822]
loss: 0.022637  [38400/69822]
loss: 0.018326  [44800/69822]
loss: 0.020276  [51200/69822]
loss: 0.036964  [57600/69822]
loss: 0.020926  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070307 

Epoch 29
-------------------------------
loss: 0.064629  [    0/69822]
loss: 0.029975  [ 6400/69822]
loss: 0.053657  [12800/69822]
loss: 0.133040  [32000/70555]
loss: 0.054111  [38400/70555]
loss: 0.051992  [44800/70555]
loss: 0.128656  [51200/70555]
loss: 0.135779  [57600/70555]
loss: 0.039168  [64000/70555]
loss: 0.064091  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.074029 

Epoch 10
-------------------------------
loss: 0.075132  [    0/70555]
loss: 0.136065  [ 6400/70555]
loss: 0.016241  [12800/70555]
loss: 0.064606  [19200/70555]
loss: 0.170277  [25600/70555]
loss: 0.069262  [32000/70555]
loss: 0.116875  [38400/70555]
loss: 0.085833  [44800/70555]
loss: 0.153043  [51200/70555]
loss: 0.033058  [57600/70555]
loss: 0.057351  [64000/70555]
loss: 0.107232  [70400/70555]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.085545 

Epoch 11
-------------------------------
loss: 0.175233  [    0/70555]
loss: 0.039462  [ 6400/70555]
loss: 0.165116  [12800/70555]
loss: 0.116977  [19200/70555]
loss: 0.118525  [25600/70555]
loss: 0.017259  [32000/70555]
loss: 0.183196  [38400/70555]
loss: 0.146139  [44800/70555]
loss: 0.121108  [51200/70555]
loss: 0.101844  [57600/70555]
loss: 0.106737  [64000/70555]
loss: 0.125765  [70400/70555]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089333 

Epoch 12
-------------------------------
loss: 0.084271  [    0/70555]
loss: 0.141500  [ 6400/70555]
loss: 0.162050  [12800/70555]
loss: 0.146462  [19200/70555]
loss: 0.111955  [25600/70555]
loss: 0.066535  [32000/70555]
loss: 0.048806  [38400/70555]
loss: 0.129664  [44800/70555]
loss: 0.043352  [51200/70555]
loss: 0.066446  [57600/70555]
loss: 0.131409  [64000/70555]
loss: 0.069924  [70400/70555]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.099450 

Epoch 13
-------------------------------
loss: 0.065608  [    0/70555]
loss: 0.036633  [ 6400/70555]
loss: 0.029888  [12800/70555]
loss: 0.126802  [19200/70555]
loss: 0.062301  [25600/70555]
loss: 0.025494  [32000/70555]
loss: 0.103369  [38400/70555]
loss: 0.051631  [44800/70555]
loss: 0.109330  [51200/70555]
loss: 0.070172  [57600/70555]
loss: 0.128381  [64000/70555]
loss: 0.110594  [70400/70555]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.092242 

Epoch 14
-------------------------------
loss: 0.073359  [    0/70555]
loss: 0.052586  [ 6400/70555]
loss: 0.125450  [12800/70555]
loss: 0.172295  [19200/70555]
loss: 0.136806  [25600/70555]
loss: 0.094999  [32000/70555]
loss: 0.024527  [38400/70555]
loss: 0.057746  [44800/70555]
loss: 0.095313  [51200/70555]
loss: 0.073263  [57600/70555]
loss: 0.056833  [64000/70555]
loss: 0.028411  [70400/70555]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.092888 

Epoch 15
-------------------------------
loss: 0.119869  [    0/70555]
loss: 0.068783  [ 6400/70555]
loss: 0.046690  [12800/70555]
loss: 0.130994  [19200/70555]
loss: 0.027082  [25600/70555]
loss: 0.050041  [32000/70555]
loss: 0.077423  [38400/70555]
loss: 0.025991  [44800/70555]
loss: 0.043340  [51200/70555]
loss: 0.079322  [57600/70555]
loss: 0.049631  [64000/70555]
loss: 0.086668  [70400/70555]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.080608 

Epoch 16
-------------------------------
loss: 0.120170  [    0/70555]
loss: 0.156760  [ 6400/70555]
loss: 0.120197  [12800/70555]
loss: 0.096162  [19200/70555]
loss: 0.087692  [25600/70555]
loss: 0.008556  [32000/70555]
loss: 0.051930  [38400/70555]
loss: 0.052125  [44800/70555]
loss: 0.027457  [51200/70555]
loss: 0.079554  [57600/70555]
loss: 0.088944  [64000/70555]
loss: 0.033911  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085571 

Epoch 17
-------------------------------
loss: 0.046355  [    0/70555]
loss: 0.091984  [ 6400/70555]
loss: 0.156864  [12800/70555]
loss: 0.048698  [19200/70555]
loss: 0.151668  [25600/70555]
loss: 0.077632  [32000/70555]
loss: 0.098915  [38400/70555]
loss: 0.023115  [44800/70555]
loss: 0.028225  [51200/70555]
loss: 0.158811  [57600/70555]
loss: 0.053396  [64000/70555]
loss: 0.090582  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081487 

Epoch 18
-------------------------------
loss: 0.043646  [    0/70555]
loss: 0.080638  [ 6400/70555]
loss: 0.057506  [12800/70555]
loss: 0.094374  [19200/70555]
loss: 0.080118  [25600/70555]
loss: 0.042553  [32000/70555]
loss: 0.032964  [38400/70555]
loss: 0.088430  [44800/70555]
loss: 0.120123  [51200/70555]
loss: 0.038690  [57600/70555]
loss: 0.143914  [64000/70555]
loss: 0.030667  [70400/70555]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.085931 

Epoch 19
-------------------------------
loss: 0.051570  [    0/70555]
loss: 0.024351  [ 6400/70555]
loss: 0.027608  [12800/70555]
loss: 0.014792  [19200/70555]
loss: 0.075413  [25600/70555]
loss: 0.032010  [32000/70555]
loss: 0.052010  [38400/70555]
loss: 0.056566  [44800/70555]
loss: 0.188532  [51200/70555]
loss: 0.124530  [57600/70555]
loss: 0.101262  [64000/70555]
loss: 0.176245  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086214 

Epoch 20
-------------------------------
loss: 0.086609  [    0/70555]
loss: 0.076898  [ 6400/70555]
loss: 0.054902  [12800/70555]
loss: 0.197204  [19200/70555]
loss: 0.055119  [25600/70555]
loss: 0.027506  [32000/70555]
loss: 0.083282  [38400/70555]
loss: 0.156693  [44800/70555]
loss: 0.087236  [51200/70555]
loss: 0.098428  [57600/70555]
loss: 0.119105  [64000/70555]
loss: 0.057312  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085439 

Epoch 21
-------------------------------
loss: 0.072716  [    0/70555]
loss: 0.033599  [ 6400/70555]
loss: 0.042417  [12800/70555]
loss: 0.087789  [19200/70555]
loss: 0.096775  [25600/70555]
loss: 0.130551  [32000/70555]
loss: 0.147479  [38400/70555]
loss: 0.138112  [44800/70555]
loss: 0.141780  [51200/70555]
loss: 0.029078  [57600/70555]
loss: 0.083184  [64000/70555]
loss: 0.102402  [70400/70555]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.077495 

Epoch 22
-------------------------------
loss: 0.039493  [    0/70555]
loss: 0.052600  [ 6400/70555]
loss: 0.100254  [12800/70555]
loss: 0.070404  [19200/70555]
loss: 0.151181  [25600/70555]
loss: 0.034822  [32000/70555]
loss: 0.112026  [38400/70555]
loss: 0.068300  [44800/70555]
loss: 0.043585  [51200/70555]
loss: 0.138981  [57600/70555]
loss: 0.087980  [64000/70555]
loss: 0.089548  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.078414 

Epoch 23
-------------------------------
loss: 0.064181  [    0/70555]
loss: 0.135898  [ 6400/70555]
loss: 0.074111  [12800/70555]
loss: 0.107019  [19200/70555]
loss: 0.203038  [25600/70555]
loss: 0.046699  [32000/70555]
loss: 0.095327  [38400/70555]
loss: 0.031441  [44800/70555]
loss: 0.094616  [51200/70555]
loss: 0.095350  [57600/70555]
loss: 0.064726  [64000/70555]
loss: 0.049651  [70400/70555]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.090699 

Epoch 24
-------------------------------
loss: 0.039989  [    0/70555]
loss: 0.032226  [ 6400/70555]
loss: 0.035201  [12800/70555]
loss: 0.060452  [19200/70555]
loss: 0.034689  [25600/70555]
loss: 0.113309  [32000/70555]
loss: 0.022361  [38400/70555]
loss: 0.113446  [44800/70555]
loss: 0.097459  [51200/70555]
loss: 0.049255  [57600/70555]
loss: 0.028016  [64000/70555]
loss: 0.007295  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.081292 

Epoch 25
-------------------------------
loss: 0.025305  [    0/70555]
loss: 0.064559  [ 6400/70555]
loss: 0.094656  [12800/70555]
loss: 0.058926  [19200/70555]
loss: 0.088065  [25600/70555]
loss: 0.037018  [32000/70555]
loss: 0.097193  [38400/70555]
loss: 0.055440  [44800/70555]
loss: 0.103271  [51200/70555]
loss: 0.085701  [57600/70555]
loss: 0.069346  [64000/70555]
loss: 0.074010  [70400/70555]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080391 

Epoch 26
-------------------------------
loss: 0.054879  [    0/70555]
loss: 0.024157  [ 6400/70555]
loss: 0.048548  [12800/70555]
loss: 0.080386  [19200/70555]
loss: 0.085978  [25600/70555]
loss: 0.070644  [32000/70555]
loss: 0.040917  [38400/70555]
loss: 0.056825  [44800/70555]
loss: 0.048302  [51200/70555]
loss: 0.029085  [57600/70555]
loss: 0.071482  [64000/70555]
loss: 0.078996  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.079836 

Epoch 27
-------------------------------
loss: 0.049625  [    0/70555]
loss: 0.049280  [ 6400/70555]
loss: 0.119989  [12800/70555]
loss: 0.141426  [19200/70555]
loss: 0.062605  [25600/70555]
loss: 0.045350  [32000/70555]
loss: 0.064630  [32000/71235]
loss: 0.093738  [38400/71235]
loss: 0.048347  [44800/71235]
loss: 0.049477  [51200/71235]
loss: 0.219521  [57600/71235]
loss: 0.082900  [64000/71235]
loss: 0.175019  [70400/71235]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117182 

Epoch 10
-------------------------------
loss: 0.067467  [    0/71235]
loss: 0.098690  [ 6400/71235]
loss: 0.048972  [12800/71235]
loss: 0.109075  [19200/71235]
loss: 0.093280  [25600/71235]
loss: 0.070621  [32000/71235]
loss: 0.088798  [38400/71235]
loss: 0.074840  [44800/71235]
loss: 0.296258  [51200/71235]
loss: 0.112689  [57600/71235]
loss: 0.061925  [64000/71235]
loss: 0.152069  [70400/71235]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.110838 

Epoch 11
-------------------------------
loss: 0.123606  [    0/71235]
loss: 0.096587  [ 6400/71235]
loss: 0.209901  [12800/71235]
loss: 0.078923  [19200/71235]
loss: 0.177031  [25600/71235]
loss: 0.055943  [32000/71235]
loss: 0.055296  [38400/71235]
loss: 0.139072  [44800/71235]
loss: 0.074605  [51200/71235]
loss: 0.059636  [57600/71235]
loss: 0.119460  [64000/71235]
loss: 0.149751  [70400/71235]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.110654 

Epoch 12
-------------------------------
loss: 0.097158  [    0/71235]
loss: 0.139172  [ 6400/71235]
loss: 0.142132  [12800/71235]
loss: 0.095767  [19200/71235]
loss: 0.102831  [25600/71235]
loss: 0.087917  [32000/71235]
loss: 0.116000  [38400/71235]
loss: 0.119629  [44800/71235]
loss: 0.137581  [51200/71235]
loss: 0.092449  [57600/71235]
loss: 0.132606  [64000/71235]
loss: 0.166031  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.107352 

Epoch 13
-------------------------------
loss: 0.140604  [    0/71235]
loss: 0.148513  [ 6400/71235]
loss: 0.097465  [12800/71235]
loss: 0.098559  [19200/71235]
loss: 0.044353  [25600/71235]
loss: 0.163419  [32000/71235]
loss: 0.082776  [38400/71235]
loss: 0.073955  [44800/71235]
loss: 0.106486  [51200/71235]
loss: 0.035997  [57600/71235]
loss: 0.053276  [64000/71235]
loss: 0.082405  [70400/71235]
Test Error: 
 Accuracy: 88.9%, Avg loss: 0.286541 

Epoch 14
-------------------------------
loss: 0.343824  [    0/71235]
loss: 0.063609  [ 6400/71235]
loss: 0.074930  [12800/71235]
loss: 0.118887  [19200/71235]
loss: 0.071120  [25600/71235]
loss: 0.065512  [32000/71235]
loss: 0.102804  [38400/71235]
loss: 0.112832  [44800/71235]
loss: 0.074117  [51200/71235]
loss: 0.047496  [57600/71235]
loss: 0.026159  [64000/71235]
loss: 0.125999  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.108612 

Epoch 15
-------------------------------
loss: 0.103417  [    0/71235]
loss: 0.181333  [ 6400/71235]
loss: 0.083243  [12800/71235]
loss: 0.243115  [19200/71235]
loss: 0.063058  [25600/71235]
loss: 0.086203  [32000/71235]
loss: 0.057622  [38400/71235]
loss: 0.091276  [44800/71235]
loss: 0.045565  [51200/71235]
loss: 0.115099  [57600/71235]
loss: 0.055043  [64000/71235]
loss: 0.114481  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.109070 

Epoch 16
-------------------------------
loss: 0.057941  [    0/71235]
loss: 0.109947  [ 6400/71235]
loss: 0.010787  [12800/71235]
loss: 0.029642  [19200/71235]
loss: 0.041655  [25600/71235]
loss: 0.091626  [32000/71235]
loss: 0.048838  [38400/71235]
loss: 0.050908  [44800/71235]
loss: 0.036420  [51200/71235]
loss: 0.114047  [57600/71235]
loss: 0.092147  [64000/71235]
loss: 0.074760  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.104481 

Epoch 17
-------------------------------
loss: 0.139843  [    0/71235]
loss: 0.132871  [ 6400/71235]
loss: 0.097959  [12800/71235]
loss: 0.128280  [19200/71235]
loss: 0.160674  [25600/71235]
loss: 0.127503  [32000/71235]
loss: 0.071966  [38400/71235]
loss: 0.116666  [44800/71235]
loss: 0.029946  [51200/71235]
loss: 0.098110  [57600/71235]
loss: 0.064232  [64000/71235]
loss: 0.038906  [70400/71235]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.115600 

Epoch 18
-------------------------------
loss: 0.081422  [    0/71235]
loss: 0.110972  [ 6400/71235]
loss: 0.011403  [12800/71235]
loss: 0.051487  [19200/71235]
loss: 0.076349  [25600/71235]
loss: 0.073807  [32000/71235]
loss: 0.113614  [38400/71235]
loss: 0.033295  [44800/71235]
loss: 0.067895  [51200/71235]
loss: 0.123574  [57600/71235]
loss: 0.177320  [64000/71235]
loss: 0.027952  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112127 

Epoch 19
-------------------------------
loss: 0.046364  [    0/71235]
loss: 0.133490  [ 6400/71235]
loss: 0.073185  [12800/71235]
loss: 0.070244  [19200/71235]
loss: 0.011861  [25600/71235]
loss: 0.180579  [32000/71235]
loss: 0.093307  [38400/71235]
loss: 0.096624  [44800/71235]
loss: 0.056394  [51200/71235]
loss: 0.052375  [57600/71235]
loss: 0.043938  [64000/71235]
loss: 0.090172  [70400/71235]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.125925 

Epoch 20
-------------------------------
loss: 0.019332  [    0/71235]
loss: 0.067527  [ 6400/71235]
loss: 0.123514  [12800/71235]
loss: 0.118147  [19200/71235]
loss: 0.081866  [25600/71235]
loss: 0.082595  [32000/71235]
loss: 0.106366  [38400/71235]
loss: 0.108951  [44800/71235]
loss: 0.135419  [51200/71235]
loss: 0.031083  [57600/71235]
loss: 0.014343  [64000/71235]
loss: 0.043499  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.103320 

Epoch 21
-------------------------------
loss: 0.116086  [    0/71235]
loss: 0.063311  [ 6400/71235]
loss: 0.054739  [12800/71235]
loss: 0.085586  [19200/71235]
loss: 0.138919  [25600/71235]
loss: 0.113812  [32000/71235]
loss: 0.047662  [38400/71235]
loss: 0.065500  [44800/71235]
loss: 0.158474  [51200/71235]
loss: 0.042969  [57600/71235]
loss: 0.045189  [64000/71235]
loss: 0.030198  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.109922 

Epoch 22
-------------------------------
loss: 0.025497  [    0/71235]
loss: 0.047993  [ 6400/71235]
loss: 0.133832  [12800/71235]
loss: 0.052251  [19200/71235]
loss: 0.058898  [25600/71235]
loss: 0.126269  [32000/71235]
loss: 0.022046  [38400/71235]
loss: 0.206333  [44800/71235]
loss: 0.066797  [51200/71235]
loss: 0.102753  [57600/71235]
loss: 0.057562  [64000/71235]
loss: 0.074358  [70400/71235]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.108464 

Epoch 23
-------------------------------
loss: 0.171794  [    0/71235]
loss: 0.023662  [ 6400/71235]
loss: 0.102796  [12800/71235]
loss: 0.074459  [19200/71235]
loss: 1.634686  [25600/71235]
loss: 0.051257  [32000/71235]
loss: 0.107565  [38400/71235]
loss: 0.145486  [44800/71235]
loss: 0.056950  [51200/71235]
loss: 0.084537  [57600/71235]
loss: 0.085186  [64000/71235]
loss: 0.096626  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.107874 

Epoch 24
-------------------------------
loss: 0.047248  [    0/71235]
loss: 0.033636  [ 6400/71235]
loss: 0.096786  [12800/71235]
loss: 0.067504  [19200/71235]
loss: 0.063776  [25600/71235]
loss: 0.102130  [32000/71235]
loss: 0.077533  [38400/71235]
loss: 0.074110  [44800/71235]
loss: 0.023582  [51200/71235]
loss: 0.047292  [57600/71235]
loss: 0.108250  [64000/71235]
loss: 0.033596  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110544 

Epoch 25
-------------------------------
loss: 0.079195  [    0/71235]
loss: 0.067187  [ 6400/71235]
loss: 0.042070  [12800/71235]
loss: 0.019556  [19200/71235]
loss: 0.153306  [25600/71235]
loss: 0.076359  [32000/71235]
loss: 0.104872  [38400/71235]
loss: 0.137306  [44800/71235]
loss: 0.040448  [51200/71235]
loss: 0.116535  [57600/71235]
loss: 0.035922  [64000/71235]
loss: 0.069348  [70400/71235]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.157586 

Epoch 26
-------------------------------
loss: 0.105141  [    0/71235]
loss: 0.025726  [ 6400/71235]
loss: 0.186067  [12800/71235]
loss: 0.055175  [19200/71235]
loss: 0.086783  [25600/71235]
loss: 0.095221  [32000/71235]
loss: 0.084011  [38400/71235]
loss: 0.027481  [44800/71235]
loss: 0.038674  [51200/71235]
loss: 0.054485  [57600/71235]
loss: 0.081628  [64000/71235]
loss: 0.129613  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.109318 

Epoch 27
-------------------------------
loss: 0.064811  [    0/71235]
loss: 0.084840  [ 6400/71235]
loss: 0.028369  [12800/71235]
loss: 0.040593  [19200/71235]
loss: 0.052080  [25600/71235]
loss: 0.064017  [32000/71235]
loss: 0.052060  [64000/70415]
loss: 0.035712  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102384 

Epoch 13
-------------------------------
loss: 0.113464  [    0/70415]
loss: 0.069285  [ 6400/70415]
loss: 0.057679  [12800/70415]
loss: 0.179566  [19200/70415]
loss: 0.054512  [25600/70415]
loss: 0.061148  [32000/70415]
loss: 0.059346  [38400/70415]
loss: 0.079391  [44800/70415]
loss: 0.035683  [51200/70415]
loss: 0.183182  [57600/70415]
loss: 0.082278  [64000/70415]
loss: 0.037530  [16500/70415]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.109364 

Epoch 14
-------------------------------
loss: 0.139055  [    0/70415]
loss: 0.064125  [ 6400/70415]
loss: 0.055478  [12800/70415]
loss: 0.093282  [19200/70415]
loss: 0.061785  [25600/70415]
loss: 0.072942  [32000/70415]
loss: 0.096146  [38400/70415]
loss: 0.072290  [44800/70415]
loss: 1.644457  [51200/70415]
loss: 0.063054  [57600/70415]
loss: 0.149187  [64000/70415]
loss: 0.016368  [16500/70415]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.106187 

Epoch 15
-------------------------------
loss: 0.213352  [    0/70415]
loss: 0.150838  [ 6400/70415]
loss: 0.044366  [12800/70415]
loss: 0.118910  [19200/70415]
loss: 0.173189  [25600/70415]
loss: 0.067970  [32000/70415]
loss: 0.113860  [38400/70415]
loss: 0.111718  [44800/70415]
loss: 0.043829  [51200/70415]
loss: 0.089130  [57600/70415]
loss: 0.085419  [64000/70415]
loss: 0.227869  [16500/70415]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.127708 

Epoch 16
-------------------------------
loss: 0.100159  [    0/70415]
loss: 0.057141  [ 6400/70415]
loss: 0.093503  [12800/70415]
loss: 0.032180  [19200/70415]
loss: 0.056350  [25600/70415]
loss: 0.090471  [32000/70415]
loss: 0.135667  [38400/70415]
loss: 0.177915  [44800/70415]
loss: 0.023761  [51200/70415]
loss: 0.069504  [57600/70415]
loss: 0.043694  [64000/70415]
loss: 0.032027  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.103356 

Epoch 17
-------------------------------
loss: 0.043873  [    0/70415]
loss: 0.087727  [ 6400/70415]
loss: 0.072183  [12800/70415]
loss: 0.043714  [19200/70415]
loss: 0.023581  [25600/70415]
loss: 0.055310  [32000/70415]
loss: 0.122215  [38400/70415]
loss: 0.096226  [44800/70415]
loss: 0.115606  [51200/70415]
loss: 0.152992  [57600/70415]
loss: 0.091506  [64000/70415]
loss: 0.336042  [16500/70415]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.148271 

Epoch 18
-------------------------------
loss: 0.057420  [    0/70415]
loss: 0.075606  [ 6400/70415]
loss: 0.072441  [12800/70415]
loss: 0.137739  [19200/70415]
loss: 0.079997  [25600/70415]
loss: 0.052999  [32000/70415]
loss: 0.093777  [38400/70415]
loss: 0.054652  [44800/70415]
loss: 0.070928  [51200/70415]
loss: 0.100084  [57600/70415]
loss: 0.037455  [64000/70415]
loss: 0.000887  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.103173 

Epoch 19
-------------------------------
loss: 0.103096  [    0/70415]
loss: 0.028265  [ 6400/70415]
loss: 0.091582  [12800/70415]
loss: 0.037606  [19200/70415]
loss: 0.089375  [25600/70415]
loss: 0.038967  [32000/70415]
loss: 0.098079  [38400/70415]
loss: 0.062073  [44800/70415]
loss: 0.252744  [51200/70415]
loss: 0.057866  [57600/70415]
loss: 0.081063  [64000/70415]
loss: 0.000314  [16500/70415]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.108465 

Epoch 20
-------------------------------
loss: 0.053567  [    0/70415]
loss: 0.076289  [ 6400/70415]
loss: 0.092110  [12800/70415]
loss: 0.082203  [19200/70415]
loss: 0.061947  [25600/70415]
loss: 0.111417  [32000/70415]
loss: 0.030121  [38400/70415]
loss: 0.079822  [44800/70415]
loss: 0.023039  [51200/70415]
loss: 0.063302  [57600/70415]
loss: 0.035696  [64000/70415]
loss: 0.063856  [16500/70415]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.104014 

Epoch 21
-------------------------------
loss: 0.030657  [    0/70415]
loss: 0.033217  [ 6400/70415]
loss: 0.089680  [12800/70415]
loss: 0.050321  [19200/70415]
loss: 0.049495  [25600/70415]
loss: 0.042200  [32000/70415]
loss: 0.086512  [38400/70415]
loss: 0.028972  [44800/70415]
loss: 0.051456  [51200/70415]
loss: 0.122464  [57600/70415]
loss: 0.100784  [64000/70415]
loss: 0.024820  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.111960 

Epoch 22
-------------------------------
loss: 0.046787  [    0/70415]
loss: 0.068878  [ 6400/70415]
loss: 0.032007  [12800/70415]
loss: 0.133228  [19200/70415]
loss: 0.100980  [25600/70415]
loss: 0.129628  [32000/70415]
loss: 0.277969  [38400/70415]
loss: 0.077938  [44800/70415]
loss: 0.051313  [51200/70415]
loss: 0.098383  [57600/70415]
loss: 0.056049  [64000/70415]
loss: 0.193703  [16500/70415]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.124015 

Epoch 23
-------------------------------
loss: 0.016083  [    0/70415]
loss: 0.060386  [ 6400/70415]
loss: 0.050655  [12800/70415]
loss: 0.034271  [19200/70415]
loss: 0.111828  [25600/70415]
loss: 0.041168  [32000/70415]
loss: 0.097569  [38400/70415]
loss: 0.127662  [44800/70415]
loss: 0.015756  [51200/70415]
loss: 0.136334  [57600/70415]
loss: 0.085504  [64000/70415]
loss: 0.205058  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112110 

Epoch 24
-------------------------------
loss: 0.154854  [    0/70415]
loss: 0.025537  [ 6400/70415]
loss: 0.093366  [12800/70415]
loss: 0.096917  [19200/70415]
loss: 0.078898  [25600/70415]
loss: 0.170874  [32000/70415]
loss: 0.015406  [38400/70415]
loss: 0.136556  [44800/70415]
loss: 0.084847  [51200/70415]
loss: 0.122452  [57600/70415]
loss: 0.031890  [64000/70415]
loss: 0.114314  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.123475 

Epoch 25
-------------------------------
loss: 0.089415  [    0/70415]
loss: 0.086930  [ 6400/70415]
loss: 0.139271  [12800/70415]
loss: 0.122801  [19200/70415]
loss: 0.097984  [25600/70415]
loss: 0.028954  [32000/70415]
loss: 0.056677  [38400/70415]
loss: 0.088784  [44800/70415]
loss: 0.115463  [51200/70415]
loss: 0.045395  [57600/70415]
loss: 0.073112  [64000/70415]
loss: 0.114697  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.118186 

Epoch 26
-------------------------------
loss: 0.037640  [    0/70415]
loss: 0.181612  [ 6400/70415]
loss: 0.046818  [12800/70415]
loss: 0.062609  [19200/70415]
loss: 0.039825  [25600/70415]
loss: 0.103201  [32000/70415]
loss: 0.120041  [38400/70415]
loss: 0.100182  [44800/70415]
loss: 0.219939  [51200/70415]
loss: 0.075361  [57600/70415]
loss: 0.090033  [64000/70415]
loss: 0.025012  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.115516 

Epoch 27
-------------------------------
loss: 0.157528  [    0/70415]
loss: 0.099233  [ 6400/70415]
loss: 0.045012  [12800/70415]
loss: 0.177278  [19200/70415]
loss: 0.060657  [25600/70415]
loss: 0.047213  [32000/70415]
loss: 0.056115  [38400/70415]
loss: 0.083032  [44800/70415]
loss: 0.070064  [51200/70415]
loss: 0.127125  [57600/70415]
loss: 0.052921  [64000/70415]
loss: 0.029362  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.117619 

Epoch 28
-------------------------------
loss: 0.065241  [    0/70415]
loss: 0.062071  [ 6400/70415]
loss: 0.051245  [12800/70415]
loss: 0.045728  [19200/70415]
loss: 0.057038  [25600/70415]
loss: 0.186589  [32000/70415]
loss: 0.048287  [38400/70415]
loss: 0.034140  [44800/70415]
loss: 0.083404  [51200/70415]
loss: 0.091379  [57600/70415]
loss: 0.034945  [64000/70415]
loss: 0.022417  [16500/70415]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.115333 

Epoch 29
-------------------------------
loss: 0.109030  [    0/70415]
loss: 0.030581  [ 6400/70415]
loss: 0.098216  [12800/70415]
loss: 0.105733  [19200/70415]
loss: 0.095600  [25600/70415]
loss: 0.013935  [32000/70415]
loss: 0.056279  [38400/70415]
loss: 0.045287  [44800/70415]
loss: 0.071031  [51200/70415]
loss: 0.101621  [57600/70415]
loss: 0.078201  [64000/70415]
loss: 0.028939  [16500/70415]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119134 

Epoch 30
-------------------------------
loss: 0.038366  [    0/70415]
loss: 0.084030  [ 6400/70415]
loss: 0.094543  [12800/70415]
loss: 0.130147  [19200/70415]
loss: 0.043789  [25600/70415]
loss: 0.072105  [32000/70415]
loss: 0.021129  [38400/70415]
loss: 0.066440  [44800/70415]
loss: 0.223871  [51200/70415]
loss: 0.025571  [57600/70415]
loss: 0.090261  [64000/70415]
loss: 0.118370  [64000/70588]
loss: 0.105151  [70400/70588]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.153839 

Epoch 13
-------------------------------
loss: 0.096336  [    0/70588]
loss: 0.091348  [ 6400/70588]
loss: 0.115664  [12800/70588]
loss: 0.358593  [19200/70588]
loss: 0.195416  [25600/70588]
loss: 0.097527  [32000/70588]
loss: 0.156239  [38400/70588]
loss: 0.070428  [44800/70588]
loss: 0.102538  [51200/70588]
loss: 0.102800  [57600/70588]
loss: 0.149209  [64000/70588]
loss: 0.109626  [70400/70588]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.151909 

Epoch 14
-------------------------------
loss: 0.128456  [    0/70588]
loss: 0.140249  [ 6400/70588]
loss: 0.103525  [12800/70588]
loss: 0.065812  [19200/70588]
loss: 0.106602  [25600/70588]
loss: 0.179998  [32000/70588]
loss: 1.445481  [38400/70588]
loss: 0.143746  [44800/70588]
loss: 0.168426  [51200/70588]
loss: 0.149210  [57600/70588]
loss: 0.121328  [64000/70588]
loss: 0.195205  [70400/70588]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.152513 

Epoch 15
-------------------------------
loss: 0.168855  [    0/70588]
loss: 0.133392  [ 6400/70588]
loss: 0.111824  [12800/70588]
loss: 0.208805  [19200/70588]
loss: 0.224392  [25600/70588]
loss: 0.184538  [32000/70588]
loss: 0.136527  [38400/70588]
loss: 0.040423  [44800/70588]
loss: 0.151036  [51200/70588]
loss: 0.146170  [57600/70588]
loss: 0.124249  [64000/70588]
loss: 0.158692  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.146763 

Epoch 16
-------------------------------
loss: 0.111977  [    0/70588]
loss: 0.105057  [ 6400/70588]
loss: 0.269183  [12800/70588]
loss: 0.069221  [19200/70588]
loss: 0.054924  [25600/70588]
loss: 0.172793  [32000/70588]
loss: 0.091521  [38400/70588]
loss: 0.111385  [44800/70588]
loss: 0.038632  [51200/70588]
loss: 0.041315  [57600/70588]
loss: 0.079819  [64000/70588]
loss: 0.151853  [70400/70588]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.145290 

Epoch 17
-------------------------------
loss: 0.210269  [    0/70588]
loss: 0.059656  [ 6400/70588]
loss: 0.172361  [12800/70588]
loss: 0.116274  [19200/70588]
loss: 0.076463  [25600/70588]
loss: 0.093516  [32000/70588]
loss: 0.100052  [38400/70588]
loss: 0.145373  [44800/70588]
loss: 0.221586  [51200/70588]
loss: 0.065463  [57600/70588]
loss: 0.068575  [64000/70588]
loss: 0.225501  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.148552 

Epoch 18
-------------------------------
loss: 0.157367  [    0/70588]
loss: 0.069865  [ 6400/70588]
loss: 0.186982  [12800/70588]
loss: 0.131666  [19200/70588]
loss: 0.090427  [25600/70588]
loss: 0.120137  [32000/70588]
loss: 0.081906  [38400/70588]
loss: 0.134365  [44800/70588]
loss: 0.127349  [51200/70588]
loss: 0.082476  [57600/70588]
loss: 0.138827  [64000/70588]
loss: 0.107356  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.144734 

Epoch 19
-------------------------------
loss: 0.086727  [    0/70588]
loss: 0.107702  [ 6400/70588]
loss: 0.091272  [12800/70588]
loss: 0.165389  [19200/70588]
loss: 0.209232  [25600/70588]
loss: 0.111271  [32000/70588]
loss: 0.071969  [38400/70588]
loss: 0.152016  [44800/70588]
loss: 0.173273  [51200/70588]
loss: 0.217733  [57600/70588]
loss: 0.077951  [64000/70588]
loss: 0.234386  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.138718 

Epoch 20
-------------------------------
loss: 0.143149  [    0/70588]
loss: 0.135432  [ 6400/70588]
loss: 0.083281  [12800/70588]
loss: 0.193379  [19200/70588]
loss: 0.104446  [25600/70588]
loss: 0.144714  [32000/70588]
loss: 0.133323  [38400/70588]
loss: 0.059566  [44800/70588]
loss: 0.154622  [51200/70588]
loss: 0.132514  [57600/70588]
loss: 0.109238  [64000/70588]
loss: 0.060031  [70400/70588]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.153100 

Epoch 21
-------------------------------
loss: 0.095560  [    0/70588]
loss: 0.124672  [ 6400/70588]
loss: 0.092801  [12800/70588]
loss: 0.201194  [19200/70588]
loss: 0.126946  [25600/70588]
loss: 0.245907  [32000/70588]
loss: 0.133021  [38400/70588]
loss: 0.067036  [44800/70588]
loss: 0.117506  [51200/70588]
loss: 0.079844  [57600/70588]
loss: 0.049349  [64000/70588]
loss: 0.140433  [70400/70588]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.151712 

Epoch 22
-------------------------------
loss: 0.087426  [    0/70588]
loss: 0.124938  [ 6400/70588]
loss: 0.162753  [12800/70588]
loss: 0.110698  [19200/70588]
loss: 0.195320  [25600/70588]
loss: 0.230948  [32000/70588]
loss: 0.179241  [38400/70588]
loss: 0.111074  [44800/70588]
loss: 0.182064  [51200/70588]
loss: 0.123452  [57600/70588]
loss: 0.056127  [64000/70588]
loss: 0.111202  [70400/70588]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.145748 

Epoch 23
-------------------------------
loss: 0.176943  [    0/70588]
loss: 0.225397  [ 6400/70588]
loss: 0.099771  [12800/70588]
loss: 0.109246  [19200/70588]
loss: 0.256097  [25600/70588]
loss: 0.062518  [32000/70588]
loss: 0.156841  [38400/70588]
loss: 0.090347  [44800/70588]
loss: 0.068455  [51200/70588]
loss: 0.161830  [57600/70588]
loss: 0.143976  [64000/70588]
loss: 0.127151  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.145973 

Epoch 24
-------------------------------
loss: 0.074494  [    0/70588]
loss: 0.124891  [ 6400/70588]
loss: 0.221127  [12800/70588]
loss: 0.090865  [19200/70588]
loss: 0.112095  [25600/70588]
loss: 0.132545  [32000/70588]
loss: 0.120964  [38400/70588]
loss: 0.133045  [44800/70588]
loss: 0.079345  [51200/70588]
loss: 0.071536  [57600/70588]
loss: 0.058280  [64000/70588]
loss: 0.163643  [70400/70588]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.142486 

Epoch 25
-------------------------------
loss: 0.147759  [    0/70588]
loss: 0.116424  [ 6400/70588]
loss: 0.089157  [12800/70588]
loss: 0.067509  [19200/70588]
loss: 0.093673  [25600/70588]
loss: 0.252511  [32000/70588]
loss: 0.062423  [38400/70588]
loss: 0.074152  [44800/70588]
loss: 0.122411  [51200/70588]
loss: 0.071792  [57600/70588]
loss: 0.109770  [64000/70588]
loss: 0.197770  [70400/70588]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.144567 

Epoch 26
-------------------------------
loss: 0.070392  [    0/70588]
loss: 0.154061  [ 6400/70588]
loss: 0.147281  [12800/70588]
loss: 0.137394  [19200/70588]
loss: 0.085303  [25600/70588]
loss: 0.179970  [32000/70588]
loss: 0.046569  [38400/70588]
loss: 0.056435  [44800/70588]
loss: 0.073376  [51200/70588]
loss: 0.077929  [57600/70588]
loss: 0.112357  [64000/70588]
loss: 0.110247  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.144070 

Epoch 27
-------------------------------
loss: 0.151712  [    0/70588]
loss: 0.088406  [ 6400/70588]
loss: 0.097758  [12800/70588]
loss: 0.168560  [19200/70588]
loss: 0.124180  [25600/70588]
loss: 0.227368  [32000/70588]
loss: 0.147626  [38400/70588]
loss: 0.077358  [44800/70588]
loss: 0.099233  [51200/70588]
loss: 0.121076  [57600/70588]
loss: 0.214137  [64000/70588]
loss: 0.113371  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.147704 

Epoch 28
-------------------------------
loss: 0.110687  [    0/70588]
loss: 0.144832  [ 6400/70588]
loss: 0.105953  [12800/70588]
loss: 0.110000  [19200/70588]
loss: 0.066327  [25600/70588]
loss: 0.120084  [32000/70588]
loss: 0.227919  [38400/70588]
loss: 0.081375  [44800/70588]
loss: 0.169159  [51200/70588]
loss: 0.082565  [57600/70588]
loss: 0.066013  [64000/70588]
loss: 0.108082  [70400/70588]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.130088 

Epoch 29
-------------------------------
loss: 0.053900  [    0/70588]
loss: 0.173227  [ 6400/70588]
loss: 0.057599  [12800/70588]
loss: 0.161464  [19200/70588]
loss: 0.162976  [25600/70588]
loss: 0.081371  [32000/70588]
loss: 0.123228  [38400/70588]
loss: 0.065581  [44800/70588]
loss: 0.217919  [51200/70588]
loss: 0.082538  [57600/70588]
loss: 0.092234  [64000/70588]
loss: 0.139896  [70400/70588]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.142415 

Epoch 30
-------------------------------
loss: 0.125805  [    0/70588]
loss: 0.178738  [ 6400/70588]
loss: 0.049320  [12800/70588]
loss: 0.076189  [19200/70588]
loss: 0.162902  [25600/70588]
loss: 0.109942  [32000/70588]
loss: 0.066949  [38400/70588]
loss: 0.229917  [44800/70588]
loss: 0.204931  [51200/70588]
loss: 0.167702  [57600/70588]
loss: 0.045672  [64000/70588]
loss: 0.028990  [64000/72227]
loss: 0.074978  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.083218 

Epoch 13
-------------------------------
loss: 0.081409  [    0/72227]
loss: 0.066334  [ 6400/72227]
loss: 0.007456  [12800/72227]
loss: 0.146228  [19200/72227]
loss: 0.021861  [25600/72227]
loss: 0.064402  [32000/72227]
loss: 0.022686  [38400/72227]
loss: 0.013954  [44800/72227]
loss: 0.022659  [51200/72227]
loss: 0.026317  [57600/72227]
loss: 0.046265  [64000/72227]
loss: 0.022002  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.077585 

Epoch 14
-------------------------------
loss: 0.034604  [    0/72227]
loss: 0.013832  [ 6400/72227]
loss: 0.082396  [12800/72227]
loss: 0.086537  [19200/72227]
loss: 0.019101  [25600/72227]
loss: 0.080712  [32000/72227]
loss: 0.051691  [38400/72227]
loss: 0.035146  [44800/72227]
loss: 0.010958  [51200/72227]
loss: 0.097769  [57600/72227]
loss: 0.210424  [64000/72227]
loss: 0.024712  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.074055 

Epoch 15
-------------------------------
loss: 0.012455  [    0/72227]
loss: 0.116591  [ 6400/72227]
loss: 0.013251  [12800/72227]
loss: 0.023849  [19200/72227]
loss: 0.025390  [25600/72227]
loss: 0.018367  [32000/72227]
loss: 0.007131  [38400/72227]
loss: 0.022967  [44800/72227]
loss: 0.034763  [51200/72227]
loss: 0.064000  [57600/72227]
loss: 0.010183  [64000/72227]
loss: 0.010892  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070828 

Epoch 16
-------------------------------
loss: 0.009485  [    0/72227]
loss: 0.035678  [ 6400/72227]
loss: 0.033751  [12800/72227]
loss: 0.007981  [19200/72227]
loss: 0.064104  [25600/72227]
loss: 0.020797  [32000/72227]
loss: 0.059707  [38400/72227]
loss: 0.002868  [44800/72227]
loss: 0.022807  [51200/72227]
loss: 0.058707  [57600/72227]
loss: 0.056254  [64000/72227]
loss: 0.050073  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077233 

Epoch 17
-------------------------------
loss: 0.016174  [    0/72227]
loss: 0.003527  [ 6400/72227]
loss: 0.055394  [12800/72227]
loss: 0.016707  [19200/72227]
loss: 0.029108  [25600/72227]
loss: 0.026503  [32000/72227]
loss: 0.037775  [38400/72227]
loss: 0.033114  [44800/72227]
loss: 0.020297  [51200/72227]
loss: 0.009590  [57600/72227]
loss: 0.033510  [64000/72227]
loss: 0.060816  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.077685 

Epoch 18
-------------------------------
loss: 0.038579  [    0/72227]
loss: 0.166540  [ 6400/72227]
loss: 0.025491  [12800/72227]
loss: 0.019710  [19200/72227]
loss: 0.009294  [25600/72227]
loss: 0.072151  [32000/72227]
loss: 0.118756  [38400/72227]
loss: 0.013448  [44800/72227]
loss: 0.029291  [51200/72227]
loss: 0.242868  [57600/72227]
loss: 0.008713  [64000/72227]
loss: 0.030115  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.076036 

Epoch 19
-------------------------------
loss: 0.022738  [    0/72227]
loss: 0.041199  [ 6400/72227]
loss: 0.055600  [12800/72227]
loss: 0.006220  [19200/72227]
loss: 0.012120  [25600/72227]
loss: 0.066132  [32000/72227]
loss: 0.078507  [38400/72227]
loss: 0.002291  [44800/72227]
loss: 0.098817  [51200/72227]
loss: 0.018707  [57600/72227]
loss: 0.013485  [64000/72227]
loss: 0.003378  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.081793 

Epoch 20
-------------------------------
loss: 0.036760  [    0/72227]
loss: 0.058116  [ 6400/72227]
loss: 0.038792  [12800/72227]
loss: 0.008393  [19200/72227]
loss: 0.002284  [25600/72227]
loss: 0.013456  [32000/72227]
loss: 0.057657  [38400/72227]
loss: 0.043923  [44800/72227]
loss: 0.006501  [51200/72227]
loss: 0.055391  [57600/72227]
loss: 0.028079  [64000/72227]
loss: 0.046377  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.073402 

Epoch 21
-------------------------------
loss: 0.046041  [    0/72227]
loss: 0.048163  [ 6400/72227]
loss: 0.056603  [12800/72227]
loss: 0.073393  [19200/72227]
loss: 0.005255  [25600/72227]
loss: 0.056938  [32000/72227]
loss: 0.046446  [38400/72227]
loss: 0.063335  [44800/72227]
loss: 0.005207  [51200/72227]
loss: 0.025166  [57600/72227]
loss: 0.020936  [64000/72227]
loss: 0.040000  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.078108 

Epoch 22
-------------------------------
loss: 0.082777  [    0/72227]
loss: 0.055626  [ 6400/72227]
loss: 0.003318  [12800/72227]
loss: 0.041041  [19200/72227]
loss: 0.017733  [25600/72227]
loss: 0.013299  [32000/72227]
loss: 0.003955  [38400/72227]
loss: 0.064809  [44800/72227]
loss: 0.023443  [51200/72227]
loss: 0.071851  [57600/72227]
loss: 0.012419  [64000/72227]
loss: 0.005385  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077690 

Epoch 23
-------------------------------
loss: 0.034880  [    0/72227]
loss: 0.028021  [ 6400/72227]
loss: 0.062192  [12800/72227]
loss: 0.006350  [19200/72227]
loss: 0.109900  [25600/72227]
loss: 0.084176  [32000/72227]
loss: 0.061490  [38400/72227]
loss: 0.017664  [44800/72227]
loss: 0.054277  [51200/72227]
loss: 0.032054  [57600/72227]
loss: 0.084111  [64000/72227]
loss: 0.006125  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076683 

Epoch 24
-------------------------------
loss: 0.108851  [    0/72227]
loss: 0.035322  [ 6400/72227]
loss: 0.166835  [12800/72227]
loss: 0.076650  [19200/72227]
loss: 0.023678  [25600/72227]
loss: 0.132831  [32000/72227]
loss: 0.037782  [38400/72227]
loss: 0.073492  [44800/72227]
loss: 0.025746  [51200/72227]
loss: 0.057237  [57600/72227]
loss: 0.031848  [64000/72227]
loss: 0.058699  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.086338 

Epoch 25
-------------------------------
loss: 0.009076  [    0/72227]
loss: 0.004271  [ 6400/72227]
loss: 0.011112  [12800/72227]
loss: 0.023860  [19200/72227]
loss: 0.042926  [25600/72227]
loss: 0.131939  [32000/72227]
loss: 0.039208  [38400/72227]
loss: 0.165207  [44800/72227]
loss: 0.051269  [51200/72227]
loss: 0.064767  [57600/72227]
loss: 0.063763  [64000/72227]
loss: 0.042609  [70400/72227]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.090109 

Epoch 26
-------------------------------
loss: 0.041379  [    0/72227]
loss: 0.011279  [ 6400/72227]
loss: 0.037850  [12800/72227]
loss: 0.072368  [19200/72227]
loss: 0.028303  [25600/72227]
loss: 0.008309  [32000/72227]
loss: 0.034010  [38400/72227]
loss: 0.061974  [44800/72227]
loss: 0.054601  [51200/72227]
loss: 0.016297  [57600/72227]
loss: 0.015333  [64000/72227]
loss: 0.061777  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.074722 

Epoch 27
-------------------------------
loss: 0.045763  [    0/72227]
loss: 0.030047  [ 6400/72227]
loss: 0.143367  [12800/72227]
loss: 1.585561  [19200/72227]
loss: 0.023066  [25600/72227]
loss: 0.015822  [32000/72227]
loss: 0.040819  [38400/72227]
loss: 0.007078  [44800/72227]
loss: 0.079909  [51200/72227]
loss: 0.023791  [57600/72227]
loss: 0.023680  [64000/72227]
loss: 0.049350  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.079084 

Epoch 28
-------------------------------
loss: 0.000933  [    0/72227]
loss: 0.033494  [ 6400/72227]
loss: 0.077949  [12800/72227]
loss: 0.021846  [19200/72227]
loss: 0.015458  [25600/72227]
loss: 0.006095  [32000/72227]
loss: 0.020470  [38400/72227]
loss: 0.042483  [44800/72227]
loss: 0.068020  [51200/72227]
loss: 0.053229  [57600/72227]
loss: 0.014654  [64000/72227]
loss: 0.025408  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.077058 

Epoch 29
-------------------------------
loss: 1.596460  [    0/72227]
loss: 0.043035  [ 6400/72227]
loss: 0.006128  [12800/72227]
loss: 0.009347  [19200/72227]
loss: 0.010989  [25600/72227]
loss: 0.004084  [32000/72227]
loss: 0.189064  [38400/72227]
loss: 0.061689  [44800/72227]
loss: 0.059935  [51200/72227]
loss: 0.030671  [57600/72227]
loss: 0.133593  [64000/72227]
loss: 0.076844  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072516 

Epoch 30
-------------------------------
loss: 0.009153  [    0/72227]
loss: 0.086623  [ 6400/72227]
loss: 0.022830  [12800/72227]
loss: 0.032842  [19200/72227]
loss: 0.091846  [25600/72227]
loss: 0.009138  [32000/72227]
loss: 0.045714  [38400/72227]
loss: 0.016424  [44800/72227]
loss: 0.084389  [51200/72227]
loss: 0.016708  [57600/72227]
loss: 0.017116  [64000/72227]
Epoch 10
-------------------------------
loss: 0.056927  [    0/69711]
loss: 0.155947  [ 6400/69711]
loss: 0.024928  [12800/69711]
loss: 0.044207  [19200/69711]
loss: 0.357499  [25600/69711]
loss: 0.079076  [32000/69711]
loss: 0.071738  [38400/69711]
loss: 0.089001  [44800/69711]
loss: 0.148915  [51200/69711]
loss: 0.054841  [57600/69711]
loss: 0.138741  [64000/69711]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.091294 

Epoch 11
-------------------------------
loss: 0.083702  [    0/69711]
loss: 0.087110  [ 6400/69711]
loss: 0.040082  [12800/69711]
loss: 0.011827  [19200/69711]
loss: 0.040737  [25600/69711]
loss: 0.042549  [32000/69711]
loss: 0.033055  [38400/69711]
loss: 0.060707  [44800/69711]
loss: 0.086604  [51200/69711]
loss: 0.063647  [57600/69711]
loss: 0.070914  [64000/69711]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081616 

Epoch 12
-------------------------------
loss: 0.178405  [    0/69711]
loss: 0.079959  [ 6400/69711]
loss: 0.046267  [12800/69711]
loss: 0.131937  [19200/69711]
loss: 0.011933  [25600/69711]
loss: 0.093796  [32000/69711]
loss: 0.044479  [38400/69711]
loss: 0.054626  [44800/69711]
loss: 0.051979  [51200/69711]
loss: 0.014169  [57600/69711]
loss: 0.060701  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077845 

Epoch 13
-------------------------------
loss: 0.078622  [    0/69711]
loss: 0.059762  [ 6400/69711]
loss: 0.083247  [12800/69711]
loss: 0.084209  [19200/69711]
loss: 0.125007  [25600/69711]
loss: 0.031602  [32000/69711]
loss: 0.027147  [38400/69711]
loss: 0.034132  [44800/69711]
loss: 0.031751  [51200/69711]
loss: 0.105745  [57600/69711]
loss: 0.016543  [64000/69711]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.066679 

Epoch 14
-------------------------------
loss: 0.029290  [    0/69711]
loss: 0.027326  [ 6400/69711]
loss: 0.045890  [12800/69711]
loss: 0.096979  [19200/69711]
loss: 0.062557  [25600/69711]
loss: 0.082044  [32000/69711]
loss: 0.040088  [38400/69711]
loss: 0.028298  [44800/69711]
loss: 0.101634  [51200/69711]
loss: 0.193637  [57600/69711]
loss: 0.055457  [64000/69711]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.075862 

Epoch 15
-------------------------------
loss: 0.020315  [    0/69711]
loss: 0.109645  [ 6400/69711]
loss: 0.056189  [12800/69711]
loss: 0.011904  [19200/69711]
loss: 0.036668  [25600/69711]
loss: 0.025066  [32000/69711]
loss: 0.079793  [38400/69711]
loss: 0.063680  [44800/69711]
loss: 0.069595  [51200/69711]
loss: 0.026787  [57600/69711]
loss: 0.043807  [64000/69711]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066592 

Epoch 16
-------------------------------
loss: 0.070370  [    0/69711]
loss: 0.040816  [ 6400/69711]
loss: 0.144080  [12800/69711]
loss: 0.002473  [19200/69711]
loss: 0.087353  [25600/69711]
loss: 0.282119  [32000/69711]
loss: 0.048325  [38400/69711]
loss: 0.024435  [44800/69711]
loss: 0.020990  [51200/69711]
loss: 0.027529  [57600/69711]
loss: 0.038704  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.071977 

Epoch 17
-------------------------------
loss: 0.134537  [    0/69711]
loss: 0.067584  [ 6400/69711]
loss: 0.020978  [12800/69711]
loss: 0.089987  [19200/69711]
loss: 1.631714  [25600/69711]
loss: 0.047219  [32000/69711]
loss: 0.032008  [38400/69711]
loss: 0.052880  [44800/69711]
loss: 0.075675  [51200/69711]
loss: 0.069843  [57600/69711]
loss: 0.086382  [64000/69711]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.067796 

Epoch 18
-------------------------------
loss: 0.044624  [    0/69711]
loss: 0.133255  [ 6400/69711]
loss: 0.008372  [12800/69711]
loss: 0.049117  [19200/69711]
loss: 0.059498  [25600/69711]
loss: 0.154471  [32000/69711]
loss: 0.185422  [38400/69711]
loss: 0.113443  [44800/69711]
loss: 0.070436  [51200/69711]
loss: 0.008724  [57600/69711]
loss: 0.074592  [64000/69711]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072368 

Epoch 19
-------------------------------
loss: 0.100488  [    0/69711]
loss: 0.058671  [ 6400/69711]
loss: 0.030612  [12800/69711]
loss: 0.024539  [19200/69711]
loss: 0.113479  [25600/69711]
loss: 0.082701  [32000/69711]
loss: 0.120981  [38400/69711]
loss: 0.090396  [44800/69711]
loss: 0.056958  [51200/69711]
loss: 0.021221  [57600/69711]
loss: 0.021147  [64000/69711]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.091613 

Epoch 20
-------------------------------
loss: 0.110081  [    0/69711]
loss: 0.042302  [ 6400/69711]
loss: 0.113103  [12800/69711]
loss: 0.104669  [19200/69711]
loss: 0.130700  [25600/69711]
loss: 0.098704  [32000/69711]
loss: 0.039550  [38400/69711]
loss: 0.058828  [44800/69711]
loss: 0.055193  [51200/69711]
loss: 0.007667  [57600/69711]
loss: 0.156098  [64000/69711]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.068247 

Epoch 21
-------------------------------
loss: 0.049232  [    0/69711]
loss: 0.077362  [ 6400/69711]
loss: 0.013646  [12800/69711]
loss: 0.093656  [19200/69711]
loss: 0.057451  [25600/69711]
loss: 0.037907  [32000/69711]
loss: 0.085206  [38400/69711]
loss: 0.020239  [44800/69711]
loss: 0.028693  [51200/69711]
loss: 0.085256  [57600/69711]
loss: 0.039778  [64000/69711]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067383 

Epoch 22
-------------------------------
loss: 0.117733  [    0/69711]
loss: 0.032119  [ 6400/69711]
loss: 0.006653  [12800/69711]
loss: 0.072768  [19200/69711]
loss: 0.080320  [25600/69711]
loss: 0.037057  [32000/69711]
loss: 0.060064  [38400/69711]
loss: 0.115748  [44800/69711]
loss: 0.056579  [51200/69711]
loss: 0.036723  [57600/69711]
loss: 0.053449  [64000/69711]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085996 

Epoch 23
-------------------------------
loss: 0.046095  [    0/69711]
loss: 0.083474  [ 6400/69711]
loss: 0.047497  [12800/69711]
loss: 0.103841  [19200/69711]
loss: 0.060763  [25600/69711]
loss: 0.096126  [32000/69711]
loss: 0.037104  [38400/69711]
loss: 0.064545  [44800/69711]
loss: 0.091298  [51200/69711]
loss: 0.020412  [57600/69711]
loss: 0.060802  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075337 

Epoch 24
-------------------------------
loss: 0.011823  [    0/69711]
loss: 0.022680  [ 6400/69711]
loss: 0.105600  [12800/69711]
loss: 0.031430  [19200/69711]
loss: 0.012154  [25600/69711]
loss: 0.038315  [32000/69711]
loss: 0.049585  [38400/69711]
loss: 0.126412  [44800/69711]
loss: 0.023252  [51200/69711]
loss: 0.092184  [57600/69711]
loss: 0.042352  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075639 

Epoch 25
-------------------------------
loss: 0.060283  [    0/69711]
loss: 0.047157  [ 6400/69711]
loss: 0.029505  [12800/69711]
loss: 0.065132  [19200/69711]
loss: 0.144083  [25600/69711]
loss: 0.087259  [32000/69711]
loss: 0.010822  [38400/69711]
loss: 0.044270  [44800/69711]
loss: 0.116210  [51200/69711]
loss: 0.030336  [57600/69711]
loss: 0.083587  [64000/69711]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084910 

Epoch 26
-------------------------------
loss: 0.058579  [    0/69711]
loss: 0.042345  [ 6400/69711]
loss: 0.082421  [12800/69711]
loss: 0.062501  [19200/69711]
loss: 0.092634  [25600/69711]
loss: 0.027919  [32000/69711]
loss: 0.057754  [38400/69711]
loss: 0.042374  [44800/69711]
loss: 0.034199  [51200/69711]
loss: 0.111552  [57600/69711]
loss: 0.078658  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075875 

Epoch 27
-------------------------------
loss: 0.081396  [    0/69711]
loss: 0.034167  [ 6400/69711]
loss: 0.038429  [12800/69711]
loss: 0.117918  [19200/69711]
loss: 0.037150  [25600/69711]
loss: 0.030662  [32000/69711]
loss: 0.046218  [38400/69711]
loss: 0.170960  [44800/69711]
loss: 0.043057  [51200/69711]
loss: 0.112280  [57600/69711]
loss: 0.069040  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.072443 

Epoch 28
-------------------------------
loss: 0.049200  [    0/69711]
loss: 0.038525  [ 6400/69711]
loss: 0.082802  [12800/69711]
loss: 0.033293  [19200/69711]
loss: 0.029061  [25600/69711]
loss: 0.048294  [32000/69711]
loss: 0.116046  [38400/69711]
loss: 0.023462  [44800/69711]
loss: 0.162783  [51200/69711]
loss: 0.085717  [57600/69711]
loss: 0.053130  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.071917 

Epoch 29
-------------------------------
loss: 0.197028  [    0/69711]
loss: 0.184560  [ 6400/69711]
loss: 0.113191  [12800/69711]
loss: 0.015562  [64000/70562]
loss: 0.069244  [70400/70562]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.086059 

Epoch 13
-------------------------------
loss: 0.045800  [    0/70562]
loss: 0.049697  [ 6400/70562]
loss: 0.028528  [12800/70562]
loss: 0.023043  [19200/70562]
loss: 0.100992  [25600/70562]
loss: 0.046898  [32000/70562]
loss: 0.070540  [38400/70562]
loss: 0.085056  [44800/70562]
loss: 0.049978  [51200/70562]
loss: 0.066978  [57600/70562]
loss: 0.147310  [64000/70562]
loss: 0.040516  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.079813 

Epoch 14
-------------------------------
loss: 0.067986  [    0/70562]
loss: 0.036396  [ 6400/70562]
loss: 0.032315  [12800/70562]
loss: 0.025000  [19200/70562]
loss: 0.031562  [25600/70562]
loss: 0.095425  [32000/70562]
loss: 0.025041  [38400/70562]
loss: 0.066742  [44800/70562]
loss: 0.023537  [51200/70562]
loss: 0.140935  [57600/70562]
loss: 0.033689  [64000/70562]
loss: 0.033561  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081210 

Epoch 15
-------------------------------
loss: 0.036354  [    0/70562]
loss: 0.055825  [ 6400/70562]
loss: 0.090077  [12800/70562]
loss: 0.055961  [19200/70562]
loss: 0.044326  [25600/70562]
loss: 0.071729  [32000/70562]
loss: 0.019718  [38400/70562]
loss: 0.045009  [44800/70562]
loss: 0.156058  [51200/70562]
loss: 0.051902  [57600/70562]
loss: 0.115605  [64000/70562]
loss: 0.328628  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081928 

Epoch 16
-------------------------------
loss: 0.043531  [    0/70562]
loss: 0.027593  [ 6400/70562]
loss: 0.021490  [12800/70562]
loss: 0.061602  [19200/70562]
loss: 0.192747  [25600/70562]
loss: 0.030955  [32000/70562]
loss: 0.036674  [38400/70562]
loss: 0.036664  [44800/70562]
loss: 0.062769  [51200/70562]
loss: 0.020679  [57600/70562]
loss: 0.123223  [64000/70562]
loss: 0.081828  [70400/70562]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076774 

Epoch 17
-------------------------------
loss: 0.065304  [    0/70562]
loss: 0.053178  [ 6400/70562]
loss: 0.053261  [12800/70562]
loss: 0.080989  [19200/70562]
loss: 0.087897  [25600/70562]
loss: 0.204703  [32000/70562]
loss: 0.022862  [38400/70562]
loss: 0.012305  [44800/70562]
loss: 0.083334  [51200/70562]
loss: 0.021319  [57600/70562]
loss: 0.085908  [64000/70562]
loss: 0.086416  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.074468 

Epoch 18
-------------------------------
loss: 0.363895  [    0/70562]
loss: 0.070408  [ 6400/70562]
loss: 0.077999  [12800/70562]
loss: 0.059758  [19200/70562]
loss: 0.033983  [25600/70562]
loss: 0.023003  [32000/70562]
loss: 0.047153  [38400/70562]
loss: 0.077704  [44800/70562]
loss: 0.055545  [51200/70562]
loss: 0.150294  [57600/70562]
loss: 0.036075  [64000/70562]
loss: 0.065968  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.080332 

Epoch 19
-------------------------------
loss: 0.035342  [    0/70562]
loss: 0.082758  [ 6400/70562]
loss: 0.006195  [12800/70562]
loss: 0.037724  [19200/70562]
loss: 0.008951  [25600/70562]
loss: 0.032596  [32000/70562]
loss: 0.074999  [38400/70562]
loss: 0.129429  [44800/70562]
loss: 0.045946  [51200/70562]
loss: 0.017502  [57600/70562]
loss: 0.072381  [64000/70562]
loss: 0.028133  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081537 

Epoch 20
-------------------------------
loss: 0.044107  [    0/70562]
loss: 0.072006  [ 6400/70562]
loss: 0.124878  [12800/70562]
loss: 0.126420  [19200/70562]
loss: 0.072102  [25600/70562]
loss: 0.030648  [32000/70562]
loss: 0.042202  [38400/70562]
loss: 0.099868  [44800/70562]
loss: 0.068970  [51200/70562]
loss: 0.054788  [57600/70562]
loss: 0.158706  [64000/70562]
loss: 0.122088  [70400/70562]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.081868 

Epoch 21
-------------------------------
loss: 0.098725  [    0/70562]
loss: 0.065230  [ 6400/70562]
loss: 0.096625  [12800/70562]
loss: 0.100029  [19200/70562]
loss: 0.044272  [25600/70562]
loss: 0.194932  [32000/70562]
loss: 0.026859  [38400/70562]
loss: 0.071176  [44800/70562]
loss: 0.097148  [51200/70562]
loss: 0.052732  [57600/70562]
loss: 0.054204  [64000/70562]
loss: 0.037242  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082307 

Epoch 22
-------------------------------
loss: 0.018039  [    0/70562]
loss: 0.018774  [ 6400/70562]
loss: 0.073335  [12800/70562]
loss: 0.047211  [19200/70562]
loss: 0.040195  [25600/70562]
loss: 0.071528  [32000/70562]
loss: 0.021520  [38400/70562]
loss: 0.224684  [44800/70562]
loss: 0.194505  [51200/70562]
loss: 0.093926  [57600/70562]
loss: 0.033803  [64000/70562]
loss: 0.058072  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.075740 

Epoch 23
-------------------------------
loss: 0.086308  [    0/70562]
loss: 0.107137  [ 6400/70562]
loss: 0.034535  [12800/70562]
loss: 0.079665  [19200/70562]
loss: 0.040633  [25600/70562]
loss: 0.236572  [32000/70562]
loss: 0.049509  [38400/70562]
loss: 0.079450  [44800/70562]
loss: 0.076372  [51200/70562]
loss: 0.027172  [57600/70562]
loss: 0.037491  [64000/70562]
loss: 0.060863  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082379 

Epoch 24
-------------------------------
loss: 0.089381  [    0/70562]
loss: 0.085984  [ 6400/70562]
loss: 0.110162  [12800/70562]
loss: 0.046943  [19200/70562]
loss: 0.037065  [25600/70562]
loss: 0.089341  [32000/70562]
loss: 0.037000  [38400/70562]
loss: 0.060442  [44800/70562]
loss: 0.048016  [51200/70562]
loss: 0.030642  [57600/70562]
loss: 0.071058  [64000/70562]
loss: 0.056267  [70400/70562]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.072442 

Epoch 25
-------------------------------
loss: 0.046085  [    0/70562]
loss: 0.082499  [ 6400/70562]
loss: 0.012963  [12800/70562]
loss: 0.094871  [19200/70562]
loss: 0.062059  [25600/70562]
loss: 0.032423  [32000/70562]
loss: 0.011527  [38400/70562]
loss: 0.060624  [44800/70562]
loss: 0.109188  [51200/70562]
loss: 0.005442  [57600/70562]
loss: 0.055293  [64000/70562]
loss: 0.041140  [70400/70562]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.073358 

Epoch 26
-------------------------------
loss: 0.017604  [    0/70562]
loss: 0.013523  [ 6400/70562]
loss: 0.028087  [12800/70562]
loss: 0.066787  [19200/70562]
loss: 0.045482  [25600/70562]
loss: 0.138680  [32000/70562]
loss: 0.082461  [38400/70562]
loss: 0.054630  [44800/70562]
loss: 0.082183  [51200/70562]
loss: 0.143058  [57600/70562]
loss: 0.098771  [64000/70562]
loss: 0.134016  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.076287 

Epoch 27
-------------------------------
loss: 0.052430  [    0/70562]
loss: 0.026948  [ 6400/70562]
loss: 0.055220  [12800/70562]
loss: 0.031675  [19200/70562]
loss: 0.214877  [25600/70562]
loss: 0.142033  [32000/70562]
loss: 0.043208  [38400/70562]
loss: 0.006649  [44800/70562]
loss: 0.092068  [51200/70562]
loss: 0.097470  [57600/70562]
loss: 0.057097  [64000/70562]
loss: 0.044258  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.076889 

Epoch 28
-------------------------------
loss: 0.030042  [    0/70562]
loss: 0.096944  [ 6400/70562]
loss: 0.042467  [12800/70562]
loss: 0.031713  [19200/70562]
loss: 0.172665  [25600/70562]
loss: 0.038202  [32000/70562]
loss: 0.097517  [38400/70562]
loss: 0.037056  [44800/70562]
loss: 0.090931  [51200/70562]
loss: 0.085769  [57600/70562]
loss: 0.058776  [64000/70562]
loss: 0.093271  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080599 

Epoch 29
-------------------------------
loss: 0.027384  [    0/70562]
loss: 0.014668  [ 6400/70562]
loss: 0.071893  [12800/70562]
loss: 0.058766  [19200/70562]
loss: 0.035204  [25600/70562]
loss: 0.035551  [32000/70562]
loss: 0.103469  [38400/70562]
loss: 0.039510  [44800/70562]
loss: 0.053300  [51200/70562]
loss: 0.084824  [57600/70562]
loss: 0.082905  [64000/70562]
loss: 0.044657  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.076280 

Epoch 30
-------------------------------
loss: 0.042678  [    0/70562]
loss: 0.139902  [ 6400/70562]
loss: 0.152103  [12800/70562]
loss: 0.103471  [19200/70562]
loss: 0.031570  [25600/70562]
loss: 0.037934  [32000/70562]
loss: 0.034142  [38400/70562]
loss: 0.043537  [44800/70562]
loss: 0.097067  [51200/70562]
loss: 0.125363  [57600/70562]
loss: 0.018819  [64000/70562]
loss: 0.063236  [44800/69684]
loss: 0.127562  [51200/69684]
loss: 0.048975  [57600/69684]
loss: 0.106492  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086222 

Epoch 14
-------------------------------
loss: 0.022847  [    0/69684]
loss: 0.094914  [ 6400/69684]
loss: 0.166020  [12800/69684]
loss: 0.044509  [19200/69684]
loss: 0.037850  [25600/69684]
loss: 0.039787  [32000/69684]
loss: 0.110768  [38400/69684]
loss: 0.098451  [44800/69684]
loss: 0.062496  [51200/69684]
loss: 0.084575  [57600/69684]
loss: 0.023501  [64000/69684]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090562 

Epoch 15
-------------------------------
loss: 0.188751  [    0/69684]
loss: 0.068434  [ 6400/69684]
loss: 0.043280  [12800/69684]
loss: 0.059689  [19200/69684]
loss: 0.047193  [25600/69684]
loss: 0.023834  [32000/69684]
loss: 0.033138  [38400/69684]
loss: 0.141609  [44800/69684]
loss: 0.067965  [51200/69684]
loss: 0.072178  [57600/69684]
loss: 0.196887  [64000/69684]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.091461 

Epoch 16
-------------------------------
loss: 0.089684  [    0/69684]
loss: 0.078662  [ 6400/69684]
loss: 0.051465  [12800/69684]
loss: 0.026460  [19200/69684]
loss: 0.112762  [25600/69684]
loss: 0.060071  [32000/69684]
loss: 0.077798  [38400/69684]
loss: 0.071971  [44800/69684]
loss: 0.057512  [51200/69684]
loss: 0.083586  [57600/69684]
loss: 0.031422  [64000/69684]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.084278 

Epoch 17
-------------------------------
loss: 0.042121  [    0/69684]
loss: 0.084955  [ 6400/69684]
loss: 0.104290  [12800/69684]
loss: 0.057672  [19200/69684]
loss: 0.013086  [25600/69684]
loss: 0.091529  [32000/69684]
loss: 0.137369  [38400/69684]
loss: 0.072184  [44800/69684]
loss: 0.046628  [51200/69684]
loss: 0.061229  [57600/69684]
loss: 0.070318  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078717 

Epoch 18
-------------------------------
loss: 0.062809  [    0/69684]
loss: 0.066089  [ 6400/69684]
loss: 0.073699  [12800/69684]
loss: 0.108581  [19200/69684]
loss: 0.104528  [25600/69684]
loss: 0.164572  [32000/69684]
loss: 0.095934  [38400/69684]
loss: 0.050202  [44800/69684]
loss: 0.020538  [51200/69684]
loss: 0.284285  [57600/69684]
loss: 0.058647  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.079214 

Epoch 19
-------------------------------
loss: 0.083554  [    0/69684]
loss: 0.110128  [ 6400/69684]
loss: 0.086491  [12800/69684]
loss: 0.050153  [19200/69684]
loss: 0.058583  [25600/69684]
loss: 0.094227  [32000/69684]
loss: 0.114272  [38400/69684]
loss: 0.061017  [44800/69684]
loss: 0.024799  [51200/69684]
loss: 0.123500  [57600/69684]
loss: 0.042500  [64000/69684]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.091685 

Epoch 20
-------------------------------
loss: 0.066204  [    0/69684]
loss: 0.053702  [ 6400/69684]
loss: 0.075367  [12800/69684]
loss: 0.020718  [19200/69684]
loss: 0.069339  [25600/69684]
loss: 0.095687  [32000/69684]
loss: 0.161486  [38400/69684]
loss: 0.065326  [44800/69684]
loss: 0.102421  [51200/69684]
loss: 0.082887  [57600/69684]
loss: 0.061923  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082461 

Epoch 21
-------------------------------
loss: 0.023538  [    0/69684]
loss: 0.038633  [ 6400/69684]
loss: 0.023978  [12800/69684]
loss: 0.078507  [19200/69684]
loss: 0.095992  [25600/69684]
loss: 0.121507  [32000/69684]
loss: 0.037096  [38400/69684]
loss: 0.037056  [44800/69684]
loss: 0.061431  [51200/69684]
loss: 0.130033  [57600/69684]
loss: 0.029523  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086981 

Epoch 22
-------------------------------
loss: 0.114838  [    0/69684]
loss: 0.083487  [ 6400/69684]
loss: 0.054030  [12800/69684]
loss: 0.065231  [19200/69684]
loss: 0.027098  [25600/69684]
loss: 0.202488  [32000/69684]
loss: 0.132650  [38400/69684]
loss: 0.054290  [44800/69684]
loss: 0.084646  [51200/69684]
loss: 0.030259  [57600/69684]
loss: 0.014153  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.087692 

Epoch 23
-------------------------------
loss: 0.069795  [    0/69684]
loss: 0.113874  [ 6400/69684]
loss: 0.098383  [12800/69684]
loss: 0.057689  [19200/69684]
loss: 0.107623  [25600/69684]
loss: 0.029588  [32000/69684]
loss: 0.040163  [38400/69684]
loss: 0.052310  [44800/69684]
loss: 0.078515  [51200/69684]
loss: 0.013081  [57600/69684]
loss: 0.129021  [64000/69684]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081241 

Epoch 24
-------------------------------
loss: 0.071268  [    0/69684]
loss: 0.070591  [ 6400/69684]
loss: 0.057596  [12800/69684]
loss: 0.051256  [19200/69684]
loss: 0.041780  [25600/69684]
loss: 0.053430  [32000/69684]
loss: 0.131861  [38400/69684]
loss: 0.059436  [44800/69684]
loss: 0.135563  [51200/69684]
loss: 0.074336  [57600/69684]
loss: 0.032811  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.087430 

Epoch 25
-------------------------------
loss: 0.044037  [    0/69684]
loss: 0.026195  [ 6400/69684]
loss: 0.046949  [12800/69684]
loss: 0.141989  [19200/69684]
loss: 0.034279  [25600/69684]
loss: 0.072244  [32000/69684]
loss: 0.035473  [38400/69684]
loss: 0.064610  [44800/69684]
loss: 0.057245  [51200/69684]
loss: 0.126188  [57600/69684]
loss: 0.121013  [64000/69684]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.086774 

Epoch 26
-------------------------------
loss: 0.048812  [    0/69684]
loss: 0.071080  [ 6400/69684]
loss: 0.063414  [12800/69684]
loss: 0.103708  [19200/69684]
loss: 0.078531  [25600/69684]
loss: 0.102681  [32000/69684]
loss: 0.096761  [38400/69684]
loss: 0.133702  [44800/69684]
loss: 0.107604  [51200/69684]
loss: 0.097639  [57600/69684]
loss: 0.101908  [64000/69684]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082178 

Epoch 27
-------------------------------
loss: 0.040796  [    0/69684]
loss: 0.113979  [ 6400/69684]
loss: 0.117008  [12800/69684]
loss: 0.046291  [19200/69684]
loss: 0.104493  [25600/69684]
loss: 0.057596  [32000/69684]
loss: 0.029230  [38400/69684]
loss: 0.066037  [44800/69684]
loss: 0.092051  [51200/69684]
loss: 0.041714  [57600/69684]
loss: 0.098874  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082166 

Epoch 28
-------------------------------
loss: 0.174609  [    0/69684]
loss: 0.115089  [ 6400/69684]
loss: 0.039436  [12800/69684]
loss: 0.113074  [19200/69684]
loss: 0.186355  [25600/69684]
loss: 0.085345  [32000/69684]
loss: 0.038294  [38400/69684]
loss: 0.040143  [44800/69684]
loss: 0.032038  [51200/69684]
loss: 0.128554  [57600/69684]
loss: 0.120106  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088931 

Epoch 29
-------------------------------
loss: 0.037790  [    0/69684]
loss: 0.039038  [ 6400/69684]
loss: 0.150314  [12800/69684]
loss: 0.045801  [19200/69684]
loss: 0.055207  [25600/69684]
loss: 0.025030  [32000/69684]
loss: 0.051015  [38400/69684]
loss: 0.077175  [44800/69684]
loss: 0.059515  [51200/69684]
loss: 0.124638  [57600/69684]
loss: 0.086445  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.082048 

Epoch 30
-------------------------------
loss: 0.052488  [    0/69684]
loss: 0.020752  [ 6400/69684]
loss: 0.083675  [12800/69684]
loss: 0.097169  [19200/69684]
loss: 0.062673  [25600/69684]
loss: 0.038744  [32000/69684]
loss: 0.018940  [38400/69684]
loss: 0.059647  [44800/69684]
loss: 0.055822  [51200/69684]
loss: 0.027217  [57600/69684]
loss: 0.067774  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.092373 

Epoch 31
-------------------------------
loss: 0.079075  [    0/69684]
loss: 0.111792  [ 6400/69684]
loss: 0.091874  [12800/69684]
loss: 0.022942  [19200/69684]
loss: 0.067901  [25600/69684]
loss: 0.047965  [32000/69684]
loss: 0.084720  [38400/69684]
loss: 0.080145  [44800/69684]
loss: 0.084602  [51200/69684]
loss: 0.077395  [57600/69684]
loss: 0.091973  [64000/69684]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082513 

Epoch 32
-------------------------------
loss: 0.085496  [    0/69684]
loss: 0.064555  [ 6400/69684]
loss: 0.033836  [12800/69684]
loss: 0.017500  [19200/69684]
loss: 0.128827  [25600/69684]
loss: 0.167613  [32000/69684]
loss: 0.187739  [38400/69684]
loss: 0.008635  [44800/69684]
loss: 0.025648  [51200/69684]
loss: 0.083940  [57600/69684]
loss: 0.044139  [64000/69684]
loss: 0.318539  [    0/70676]
loss: 0.093608  [ 6400/70676]
loss: 0.074257  [12800/70676]
loss: 0.135144  [19200/70676]
loss: 0.144235  [25600/70676]
loss: 0.177497  [32000/70676]
loss: 0.095833  [38400/70676]
loss: 0.105077  [44800/70676]
loss: 0.081939  [51200/70676]
loss: 0.103360  [57600/70676]
loss: 0.143032  [64000/70676]
loss: 0.048733  [70400/70676]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.160792 

Epoch 17
-------------------------------
loss: 0.088375  [    0/70676]
loss: 0.065864  [ 6400/70676]
loss: 0.053388  [12800/70676]
loss: 0.067746  [19200/70676]
loss: 0.075546  [25600/70676]
loss: 0.166265  [32000/70676]
loss: 0.075497  [38400/70676]
loss: 0.150176  [44800/70676]
loss: 0.203170  [51200/70676]
loss: 0.127162  [57600/70676]
loss: 0.148936  [64000/70676]
loss: 0.159873  [70400/70676]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.139844 

Epoch 18
-------------------------------
loss: 0.074214  [    0/70676]
loss: 0.049160  [ 6400/70676]
loss: 0.214491  [12800/70676]
loss: 0.137946  [19200/70676]
loss: 0.169863  [25600/70676]
loss: 0.164819  [32000/70676]
loss: 0.117050  [38400/70676]
loss: 0.199605  [44800/70676]
loss: 0.117247  [51200/70676]
loss: 0.199242  [57600/70676]
loss: 0.197576  [64000/70676]
loss: 0.147532  [70400/70676]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.136633 

Epoch 19
-------------------------------
loss: 0.129274  [    0/70676]
loss: 0.178433  [ 6400/70676]
loss: 0.100633  [12800/70676]
loss: 0.122738  [19200/70676]
loss: 0.076973  [25600/70676]
loss: 0.133857  [32000/70676]
loss: 0.088372  [38400/70676]
loss: 0.099276  [44800/70676]
loss: 0.097340  [51200/70676]
loss: 0.107301  [57600/70676]
loss: 0.106500  [64000/70676]
loss: 0.110198  [70400/70676]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.142414 

Epoch 20
-------------------------------
loss: 0.057231  [    0/70676]
loss: 0.170598  [ 6400/70676]
loss: 0.084778  [12800/70676]
loss: 0.060461  [19200/70676]
loss: 0.123693  [25600/70676]
loss: 0.136891  [32000/70676]
loss: 0.131873  [38400/70676]
loss: 0.154143  [44800/70676]
loss: 0.131433  [51200/70676]
loss: 0.080196  [57600/70676]
loss: 0.119460  [64000/70676]
loss: 0.142641  [70400/70676]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.145404 

Epoch 21
-------------------------------
loss: 0.093587  [    0/70676]
loss: 0.121003  [ 6400/70676]
loss: 0.145411  [12800/70676]
loss: 0.068296  [19200/70676]
loss: 0.165648  [25600/70676]
loss: 0.094485  [32000/70676]
loss: 0.071198  [38400/70676]
loss: 0.087643  [44800/70676]
loss: 0.217990  [51200/70676]
loss: 0.153584  [57600/70676]
loss: 0.170636  [64000/70676]
loss: 0.030803  [70400/70676]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.141299 

Epoch 22
-------------------------------
loss: 0.262471  [    0/70676]
loss: 0.229989  [ 6400/70676]
loss: 0.126712  [12800/70676]
loss: 0.066246  [19200/70676]
loss: 0.184561  [25600/70676]
loss: 0.101913  [32000/70676]
loss: 0.131239  [38400/70676]
loss: 0.151954  [44800/70676]
loss: 0.146857  [51200/70676]
loss: 0.128333  [57600/70676]
loss: 0.065990  [64000/70676]
loss: 0.112745  [70400/70676]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.144998 

Epoch 23
-------------------------------
loss: 0.064865  [    0/70676]
loss: 0.112322  [ 6400/70676]
loss: 0.098619  [12800/70676]
loss: 0.109488  [19200/70676]
loss: 0.050841  [25600/70676]
loss: 0.136236  [32000/70676]
loss: 0.134383  [38400/70676]
loss: 0.137090  [44800/70676]
loss: 0.071538  [51200/70676]
loss: 0.159798  [57600/70676]
loss: 0.141488  [64000/70676]
loss: 0.129002  [70400/70676]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.143753 

Epoch 24
-------------------------------
loss: 0.121618  [    0/70676]
loss: 0.140637  [ 6400/70676]
loss: 0.185348  [12800/70676]
loss: 0.116720  [19200/70676]
loss: 0.096499  [25600/70676]
loss: 0.120749  [32000/70676]
loss: 0.230443  [38400/70676]
loss: 0.120573  [44800/70676]
loss: 0.067864  [51200/70676]
loss: 0.029955  [57600/70676]
loss: 0.120481  [64000/70676]
loss: 0.036405  [70400/70676]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.136977 

Epoch 25
-------------------------------
loss: 0.111966  [    0/70676]
loss: 0.105155  [ 6400/70676]
loss: 0.097789  [12800/70676]
loss: 0.063607  [19200/70676]
loss: 0.130463  [25600/70676]
loss: 0.247932  [32000/70676]
loss: 0.106542  [38400/70676]
loss: 0.054135  [44800/70676]
loss: 0.205686  [51200/70676]
loss: 0.258439  [57600/70676]
loss: 0.117707  [64000/70676]
loss: 0.097458  [70400/70676]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159848 

Epoch 26
-------------------------------
loss: 0.193181  [    0/70676]
loss: 0.136182  [ 6400/70676]
loss: 0.065875  [12800/70676]
loss: 0.200510  [19200/70676]
loss: 0.085363  [25600/70676]
loss: 0.167007  [32000/70676]
loss: 0.092920  [38400/70676]
loss: 0.092397  [44800/70676]
loss: 0.112595  [51200/70676]
loss: 0.056389  [57600/70676]
loss: 0.181771  [64000/70676]
loss: 0.055677  [70400/70676]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.148773 

Epoch 27
-------------------------------
loss: 0.110466  [    0/70676]
loss: 0.137653  [ 6400/70676]
loss: 0.108273  [12800/70676]
loss: 1.648389  [19200/70676]
loss: 0.183645  [25600/70676]
loss: 0.039264  [32000/70676]
loss: 0.067554  [38400/70676]
loss: 0.061896  [44800/70676]
loss: 0.104081  [51200/70676]
loss: 0.124315  [57600/70676]
loss: 0.114523  [64000/70676]
loss: 0.129106  [70400/70676]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.144017 

Epoch 28
-------------------------------
loss: 0.037024  [    0/70676]
loss: 0.100327  [ 6400/70676]
loss: 0.068857  [12800/70676]
loss: 0.105936  [19200/70676]
loss: 0.138715  [25600/70676]
loss: 0.163794  [32000/70676]
loss: 0.141434  [38400/70676]
loss: 0.095063  [44800/70676]
loss: 0.083681  [51200/70676]
loss: 0.205821  [57600/70676]
loss: 0.107262  [64000/70676]
loss: 0.094409  [70400/70676]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139600 

Epoch 29
-------------------------------
loss: 0.074108  [    0/70676]
loss: 0.068776  [ 6400/70676]
loss: 1.698128  [12800/70676]
loss: 0.062044  [19200/70676]
loss: 0.019423  [25600/70676]
loss: 0.115560  [32000/70676]
loss: 0.079454  [38400/70676]
loss: 0.053170  [44800/70676]
loss: 0.135476  [51200/70676]
loss: 0.106015  [57600/70676]
loss: 0.110756  [64000/70676]
loss: 0.060680  [70400/70676]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.144067 

Epoch 30
-------------------------------
loss: 0.075683  [    0/70676]
loss: 0.170214  [ 6400/70676]
loss: 0.078132  [12800/70676]
loss: 1.726647  [19200/70676]
loss: 0.144078  [25600/70676]
loss: 0.198809  [32000/70676]
loss: 0.108718  [38400/70676]
loss: 0.225255  [44800/70676]
loss: 0.146784  [51200/70676]
loss: 0.234173  [57600/70676]
loss: 0.026647  [64000/70676]
loss: 0.068918  [70400/70676]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.153841 

Epoch 31
-------------------------------
loss: 0.125878  [    0/70676]
loss: 0.084861  [ 6400/70676]
loss: 0.062738  [12800/70676]
loss: 0.156037  [19200/70676]
loss: 0.027329  [25600/70676]
loss: 0.111861  [32000/70676]
loss: 0.118936  [38400/70676]
loss: 0.040666  [44800/70676]
loss: 0.114621  [51200/70676]
loss: 0.091031  [57600/70676]
loss: 0.068349  [64000/70676]
loss: 0.112756  [70400/70676]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.166543 

Epoch 32
-------------------------------
loss: 0.152142  [    0/70676]
loss: 0.173997  [ 6400/70676]
loss: 0.039880  [12800/70676]
loss: 0.050175  [19200/70676]
loss: 0.103999  [25600/70676]
loss: 0.094189  [32000/70676]
loss: 0.152033  [38400/70676]
loss: 0.070880  [44800/70676]
loss: 0.090511  [51200/70676]
loss: 0.103503  [57600/70676]
loss: 0.156527  [64000/70676]
loss: 0.145454  [70400/70676]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.145838 

Epoch 33
-------------------------------
loss: 0.090398  [    0/70676]
loss: 0.076631  [ 6400/70676]
loss: 0.105492  [12800/70676]
loss: 0.169706  [19200/70676]
loss: 0.127520  [25600/70676]
loss: 0.056366  [32000/70676]
loss: 0.138493  [38400/70676]
loss: 0.101591  [44800/70676]
loss: 0.070262  [51200/70676]
loss: 0.109404  [57600/70676]
loss: 0.100698  [64000/70676]
loss: 0.028105  [70400/70676]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162503 

Epoch 34
-------------------------------
loss: 0.091350  [    0/70676]
loss: 0.095726  [44800/70227]
loss: 0.123145  [51200/70227]
loss: 0.109877  [57600/70227]
loss: 0.124502  [64000/70227]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.151441 

Epoch 14
-------------------------------
loss: 0.142951  [    0/70227]
loss: 0.159151  [ 6400/70227]
loss: 0.130063  [12800/70227]
loss: 0.101222  [19200/70227]
loss: 0.105769  [25600/70227]
loss: 0.237057  [32000/70227]
loss: 0.199361  [38400/70227]
loss: 0.141511  [44800/70227]
loss: 0.051791  [51200/70227]
loss: 0.136223  [57600/70227]
loss: 0.122023  [64000/70227]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.153189 

Epoch 15
-------------------------------
loss: 0.235851  [    0/70227]
loss: 0.111659  [ 6400/70227]
loss: 0.094848  [12800/70227]
loss: 0.086063  [19200/70227]
loss: 0.099763  [25600/70227]
loss: 0.088475  [32000/70227]
loss: 0.268087  [38400/70227]
loss: 0.151428  [44800/70227]
loss: 0.169979  [51200/70227]
loss: 0.078066  [57600/70227]
loss: 0.103620  [64000/70227]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.163914 

Epoch 16
-------------------------------
loss: 0.140119  [    0/70227]
loss: 0.157188  [ 6400/70227]
loss: 0.060964  [12800/70227]
loss: 0.110257  [19200/70227]
loss: 0.149463  [25600/70227]
loss: 0.097642  [32000/70227]
loss: 0.126358  [38400/70227]
loss: 0.152748  [44800/70227]
loss: 0.085707  [51200/70227]
loss: 0.182185  [57600/70227]
loss: 0.040126  [64000/70227]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.148881 

Epoch 17
-------------------------------
loss: 0.124632  [    0/70227]
loss: 0.183180  [ 6400/70227]
loss: 0.076742  [12800/70227]
loss: 0.113431  [19200/70227]
loss: 0.103310  [25600/70227]
loss: 0.115527  [32000/70227]
loss: 0.088614  [38400/70227]
loss: 0.095914  [44800/70227]
loss: 0.112332  [51200/70227]
loss: 0.169888  [57600/70227]
loss: 0.068788  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.139716 

Epoch 18
-------------------------------
loss: 0.089098  [    0/70227]
loss: 0.210106  [ 6400/70227]
loss: 0.082485  [12800/70227]
loss: 0.066772  [19200/70227]
loss: 0.023789  [25600/70227]
loss: 0.079392  [32000/70227]
loss: 0.199387  [38400/70227]
loss: 0.081250  [44800/70227]
loss: 0.123751  [51200/70227]
loss: 0.122680  [57600/70227]
loss: 0.035286  [64000/70227]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147963 

Epoch 19
-------------------------------
loss: 0.051766  [    0/70227]
loss: 0.165455  [ 6400/70227]
loss: 0.042975  [12800/70227]
loss: 0.184816  [19200/70227]
loss: 0.089186  [25600/70227]
loss: 0.122610  [32000/70227]
loss: 0.079419  [38400/70227]
loss: 0.152556  [44800/70227]
loss: 0.160129  [51200/70227]
loss: 0.177903  [57600/70227]
loss: 0.118180  [64000/70227]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.147623 

Epoch 20
-------------------------------
loss: 0.109040  [    0/70227]
loss: 0.172055  [ 6400/70227]
loss: 0.102201  [12800/70227]
loss: 0.156739  [19200/70227]
loss: 0.057659  [25600/70227]
loss: 0.141466  [32000/70227]
loss: 0.140701  [38400/70227]
loss: 0.146470  [44800/70227]
loss: 0.075506  [51200/70227]
loss: 0.148900  [57600/70227]
loss: 0.222059  [64000/70227]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.186909 

Epoch 21
-------------------------------
loss: 0.222069  [    0/70227]
loss: 0.139483  [ 6400/70227]
loss: 0.125721  [12800/70227]
loss: 0.095822  [19200/70227]
loss: 0.138731  [25600/70227]
loss: 0.211747  [32000/70227]
loss: 0.165611  [38400/70227]
loss: 0.083650  [44800/70227]
loss: 0.207804  [51200/70227]
loss: 0.095340  [57600/70227]
loss: 0.098227  [64000/70227]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.148641 

Epoch 22
-------------------------------
loss: 0.112707  [    0/70227]
loss: 0.113768  [ 6400/70227]
loss: 0.037776  [12800/70227]
loss: 0.159710  [19200/70227]
loss: 0.133971  [25600/70227]
loss: 0.074039  [32000/70227]
loss: 0.262558  [38400/70227]
loss: 0.131631  [44800/70227]
loss: 0.250439  [51200/70227]
loss: 0.078087  [57600/70227]
loss: 0.111827  [64000/70227]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.146289 

Epoch 23
-------------------------------
loss: 0.163809  [    0/70227]
loss: 0.099760  [ 6400/70227]
loss: 0.137295  [12800/70227]
loss: 0.154851  [19200/70227]
loss: 0.088692  [25600/70227]
loss: 0.154726  [32000/70227]
loss: 0.151437  [38400/70227]
loss: 0.061300  [44800/70227]
loss: 0.107607  [51200/70227]
loss: 0.165582  [57600/70227]
loss: 0.132163  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.139740 

Epoch 24
-------------------------------
loss: 0.163241  [    0/70227]
loss: 0.122525  [ 6400/70227]
loss: 0.208973  [12800/70227]
loss: 0.122826  [19200/70227]
loss: 0.128584  [25600/70227]
loss: 0.119045  [32000/70227]
loss: 0.077104  [38400/70227]
loss: 0.174611  [44800/70227]
loss: 0.057588  [51200/70227]
loss: 0.147323  [57600/70227]
loss: 0.146250  [64000/70227]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.142246 

Epoch 25
-------------------------------
loss: 0.078752  [    0/70227]
loss: 0.116554  [ 6400/70227]
loss: 0.216429  [12800/70227]
loss: 0.178491  [19200/70227]
loss: 0.119151  [25600/70227]
loss: 0.175090  [32000/70227]
loss: 0.206809  [38400/70227]
loss: 0.163791  [44800/70227]
loss: 0.128914  [51200/70227]
loss: 0.126197  [57600/70227]
loss: 0.076052  [64000/70227]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147791 

Epoch 26
-------------------------------
loss: 0.091578  [    0/70227]
loss: 0.150939  [ 6400/70227]
loss: 0.068664  [12800/70227]
loss: 0.123766  [19200/70227]
loss: 0.295954  [25600/70227]
loss: 0.126885  [32000/70227]
loss: 0.076172  [38400/70227]
loss: 0.081790  [44800/70227]
loss: 0.077817  [51200/70227]
loss: 0.125172  [57600/70227]
loss: 0.052726  [64000/70227]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.140334 

Epoch 27
-------------------------------
loss: 0.161155  [    0/70227]
loss: 0.088238  [ 6400/70227]
loss: 0.185170  [12800/70227]
loss: 0.120732  [19200/70227]
loss: 0.231219  [25600/70227]
loss: 0.086188  [32000/70227]
loss: 0.095610  [38400/70227]
loss: 0.133916  [44800/70227]
loss: 0.123974  [51200/70227]
loss: 0.089289  [57600/70227]
loss: 0.114768  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.143945 

Epoch 28
-------------------------------
loss: 0.059198  [    0/70227]
loss: 0.074414  [ 6400/70227]
loss: 0.136511  [12800/70227]
loss: 0.129066  [19200/70227]
loss: 0.153589  [25600/70227]
loss: 0.131531  [32000/70227]
loss: 0.056478  [38400/70227]
loss: 0.109292  [44800/70227]
loss: 0.169264  [51200/70227]
loss: 0.078053  [57600/70227]
loss: 0.127137  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.140162 

Epoch 29
-------------------------------
loss: 0.123060  [    0/70227]
loss: 0.115854  [ 6400/70227]
loss: 0.101214  [12800/70227]
loss: 0.118501  [19200/70227]
loss: 0.098683  [25600/70227]
loss: 0.100533  [32000/70227]
loss: 0.331606  [38400/70227]
loss: 0.172295  [44800/70227]
loss: 0.069219  [51200/70227]
loss: 0.064375  [57600/70227]
loss: 0.083976  [64000/70227]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.156414 

Epoch 30
-------------------------------
loss: 0.208276  [    0/70227]
loss: 0.141373  [ 6400/70227]
loss: 0.120992  [12800/70227]
loss: 0.157570  [19200/70227]
loss: 0.100740  [25600/70227]
loss: 0.091683  [32000/70227]
loss: 0.153133  [38400/70227]
loss: 0.294872  [44800/70227]
loss: 0.090457  [51200/70227]
loss: 0.132495  [57600/70227]
loss: 0.158517  [64000/70227]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.166830 

Epoch 31
-------------------------------
loss: 0.186773  [    0/70227]
loss: 0.115298  [ 6400/70227]
loss: 0.196266  [12800/70227]
loss: 0.070017  [19200/70227]
loss: 0.094684  [25600/70227]
loss: 0.079176  [32000/70227]
loss: 0.200210  [38400/70227]
loss: 0.249364  [44800/70227]
loss: 0.221713  [51200/70227]
loss: 0.090118  [57600/70227]
loss: 0.113462  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146183 

Epoch 32
-------------------------------
loss: 0.162775  [    0/70227]
loss: 0.119996  [ 6400/70227]
loss: 0.083130  [12800/70227]
loss: 0.076595  [19200/70227]
loss: 0.098600  [25600/70227]
loss: 0.181046  [32000/70227]
loss: 0.191627  [38400/70227]
loss: 0.130533  [44800/70227]
loss: 0.049318  [51200/70227]
loss: 0.183115  [57600/70227]
loss: 0.183733  [64000/70227]
loss: 0.000139  [38400/72604]
loss: 0.000000  [44800/72604]
loss: 0.049206  [51200/72604]
loss: 0.004431  [57600/72604]
loss: 0.000188  [64000/72604]
loss: 0.000984  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.051429 

Epoch 28
-------------------------------
loss: 0.000088  [    0/72604]
loss: 0.014092  [ 6400/72604]
loss: 0.009082  [12800/72604]
loss: 0.000392  [19200/72604]
loss: 0.000001  [25600/72604]
loss: 0.008879  [32000/72604]
loss: 0.000371  [38400/72604]
loss: 0.004577  [44800/72604]
loss: 0.000246  [51200/72604]
loss: 0.051175  [57600/72604]
loss: 0.139944  [64000/72604]
loss: 0.000370  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.046730 

Epoch 29
-------------------------------
loss: 0.008853  [    0/72604]
loss: 0.001925  [ 6400/72604]
loss: 0.000105  [12800/72604]
loss: 0.000907  [19200/72604]
loss: 0.000225  [25600/72604]
loss: 0.000009  [32000/72604]
loss: 0.043914  [38400/72604]
loss: 0.000868  [44800/72604]
loss: 0.000107  [51200/72604]
loss: 0.000752  [57600/72604]
loss: 0.004443  [64000/72604]
loss: 0.057720  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.054979 

Epoch 30
-------------------------------
loss: 0.003028  [    0/72604]
loss: 0.000009  [ 6400/72604]
loss: 0.000580  [12800/72604]
loss: 0.003611  [19200/72604]
loss: 0.001074  [25600/72604]
loss: 0.000001  [32000/72604]
loss: 0.034204  [38400/72604]
loss: 0.003573  [44800/72604]
loss: 0.000200  [51200/72604]
loss: 0.000266  [57600/72604]
loss: 0.007033  [64000/72604]
loss: 0.000493  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.050312 

Epoch 31
-------------------------------
loss: 0.001162  [    0/72604]
loss: 0.039428  [ 6400/72604]
loss: 0.022183  [12800/72604]
loss: 0.000006  [19200/72604]
loss: 0.019318  [25600/72604]
loss: 0.007706  [32000/72604]
loss: 0.020716  [38400/72604]
loss: 0.000077  [44800/72604]
loss: 0.000422  [51200/72604]
loss: 0.000077  [57600/72604]
loss: 0.000649  [64000/72604]
loss: 0.000014  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.072646 

Epoch 32
-------------------------------
loss: 0.000151  [    0/72604]
loss: 0.000681  [ 6400/72604]
loss: 0.000953  [12800/72604]
loss: 0.000171  [19200/72604]
loss: 0.010086  [25600/72604]
loss: 0.018191  [32000/72604]
loss: 0.003079  [38400/72604]
loss: 0.017608  [44800/72604]
loss: 0.027385  [51200/72604]
loss: 0.044078  [57600/72604]
loss: 0.020945  [64000/72604]
loss: 0.069589  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.074147 

Epoch 33
-------------------------------
loss: 0.096603  [    0/72604]
loss: 0.000028  [ 6400/72604]
loss: 0.000001  [12800/72604]
loss: 0.002037  [19200/72604]
loss: 0.012239  [25600/72604]
loss: 0.000464  [32000/72604]
loss: 0.018856  [38400/72604]
loss: 0.000003  [44800/72604]
loss: 0.013079  [51200/72604]
loss: 0.010054  [57600/72604]
loss: 0.001221  [64000/72604]
loss: 0.010526  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.064959 

Epoch 34
-------------------------------
loss: 0.000941  [    0/72604]
loss: 0.000390  [ 6400/72604]
loss: 0.000172  [12800/72604]
loss: 0.000042  [19200/72604]
loss: 0.000000  [25600/72604]
loss: 0.000402  [32000/72604]
loss: 0.000668  [38400/72604]
loss: 0.007908  [44800/72604]
loss: 0.000956  [51200/72604]
loss: 0.000592  [57600/72604]
loss: 0.013345  [64000/72604]
loss: 0.059366  [70400/72604]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.065611 

Epoch 35
-------------------------------
loss: 0.000004  [    0/72604]
loss: 0.003833  [ 6400/72604]
loss: 0.000054  [12800/72604]
loss: 0.003053  [19200/72604]
loss: 0.040113  [25600/72604]
loss: 0.001653  [32000/72604]
loss: 0.000002  [38400/72604]
loss: 0.031313  [44800/72604]
loss: 0.011317  [51200/72604]
loss: 0.000344  [57600/72604]
loss: 0.000087  [64000/72604]
loss: 0.016746  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.050737 

Epoch 36
-------------------------------
loss: 0.003578  [    0/72604]
loss: 0.000022  [ 6400/72604]
loss: 0.000031  [12800/72604]
loss: 0.001850  [19200/72604]
loss: 0.000180  [25600/72604]
loss: 0.000043  [32000/72604]
loss: 0.000718  [38400/72604]
loss: 0.022287  [44800/72604]
loss: 0.000244  [51200/72604]
loss: 0.001763  [57600/72604]
loss: 0.001483  [64000/72604]
loss: 0.000331  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.066481 

Epoch 37
-------------------------------
loss: 0.041565  [    0/72604]
loss: 0.001192  [ 6400/72604]
loss: 0.007780  [12800/72604]
loss: 0.000366  [19200/72604]
loss: 0.000491  [25600/72604]
loss: 0.001160  [32000/72604]
loss: 0.012978  [38400/72604]
loss: 0.000545  [44800/72604]
loss: 0.000776  [51200/72604]
loss: 0.116172  [57600/72604]
loss: 0.002354  [64000/72604]
loss: 0.003955  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.078973 

Epoch 38
-------------------------------
loss: 0.008362  [    0/72604]
loss: 0.034204  [ 6400/72604]
loss: 0.001027  [12800/72604]
loss: 0.031000  [19200/72604]
loss: 0.000547  [25600/72604]
loss: 0.000010  [32000/72604]
loss: 0.000002  [38400/72604]
loss: 0.000504  [44800/72604]
loss: 0.000001  [51200/72604]
loss: 0.004139  [57600/72604]
loss: 0.000086  [64000/72604]
loss: 0.000834  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.090311 

Epoch 39
-------------------------------
loss: 0.012183  [    0/72604]
loss: 0.021936  [ 6400/72604]
loss: 0.000009  [12800/72604]
loss: 0.007453  [19200/72604]
loss: 0.000004  [25600/72604]
loss: 0.000056  [32000/72604]
loss: 0.000023  [38400/72604]
loss: 0.000503  [44800/72604]
loss: 0.097246  [51200/72604]
loss: 0.000723  [57600/72604]
loss: 0.002580  [64000/72604]
loss: 0.010804  [70400/72604]
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.067116 

Epoch 40
-------------------------------
loss: 0.004069  [    0/72604]
loss: 0.005596  [ 6400/72604]
loss: 0.000630  [12800/72604]
loss: 0.000723  [19200/72604]
loss: 0.001999  [25600/72604]
loss: 0.008944  [32000/72604]
loss: 0.085163  [38400/72604]
loss: 0.000291  [44800/72604]
loss: 0.005111  [51200/72604]
loss: 0.000101  [57600/72604]
loss: 0.000529  [64000/72604]
loss: 0.000430  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.062289 

Epoch 41
-------------------------------
loss: 0.000003  [    0/72604]
loss: 0.001978  [ 6400/72604]
loss: 0.007701  [12800/72604]
loss: 0.000020  [19200/72604]
loss: 0.000016  [25600/72604]
loss: 0.001080  [32000/72604]
loss: 0.000055  [38400/72604]
loss: 0.007699  [44800/72604]
loss: 0.042616  [51200/72604]
loss: 0.000025  [57600/72604]
loss: 0.000000  [64000/72604]
loss: 0.000036  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.053771 

Epoch 42
-------------------------------
loss: 0.022473  [    0/72604]
loss: 0.002217  [ 6400/72604]
loss: 0.003319  [12800/72604]
loss: 0.000007  [19200/72604]
loss: 0.000002  [25600/72604]
loss: 0.000025  [32000/72604]
loss: 0.000219  [38400/72604]
loss: 0.009901  [44800/72604]
loss: 0.023474  [51200/72604]
loss: 0.000228  [57600/72604]
loss: 0.001165  [64000/72604]
loss: 0.000140  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.116645 

Epoch 43
-------------------------------
loss: 0.013861  [    0/72604]
loss: 0.008798  [ 6400/72604]
loss: 0.000051  [12800/72604]
loss: 0.000106  [19200/72604]
loss: 0.002459  [25600/72604]
loss: 0.000004  [32000/72604]
loss: 0.007477  [38400/72604]
loss: 0.000030  [44800/72604]
loss: 0.123790  [51200/72604]
loss: 0.000064  [57600/72604]
loss: 0.035106  [64000/72604]
loss: 0.000068  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.089294 

Epoch 44
-------------------------------
loss: 0.000079  [    0/72604]
loss: 0.000199  [ 6400/72604]
loss: 0.033097  [12800/72604]
loss: 0.000016  [19200/72604]
loss: 0.000498  [25600/72604]
loss: 0.000018  [32000/72604]
loss: 0.048713  [38400/72604]
loss: 0.000212  [44800/72604]
loss: 0.000551  [51200/72604]
loss: 0.000007  [57600/72604]
loss: 0.162396  [64000/72604]
loss: 0.000165  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.081800 

Epoch 45
-------------------------------
loss: 0.008762  [    0/72604]
loss: 0.000000  [ 6400/72604]
loss: 0.000000  [12800/72604]
loss: 0.006926  [19200/72604]
loss: 0.006641  [25600/72604]
loss: 0.004223  [32000/72604]
loss: 0.007164  [38400/72604]
loss: 0.060822  [38400/71706]
loss: 0.022218  [44800/71706]
loss: 0.052515  [51200/71706]
loss: 0.039326  [57600/71706]
loss: 0.042045  [64000/71706]
loss: 0.026067  [70400/71706]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.065628 

Epoch 28
-------------------------------
loss: 0.041013  [    0/71706]
loss: 0.010020  [ 6400/71706]
loss: 0.013034  [12800/71706]
loss: 0.084649  [19200/71706]
loss: 0.128491  [25600/71706]
loss: 0.014038  [32000/71706]
loss: 0.014105  [38400/71706]
loss: 0.037469  [44800/71706]
loss: 0.065060  [51200/71706]
loss: 0.070473  [57600/71706]
loss: 0.011663  [64000/71706]
loss: 0.039218  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068905 

Epoch 29
-------------------------------
loss: 0.024567  [    0/71706]
loss: 0.045693  [ 6400/71706]
loss: 0.041695  [12800/71706]
loss: 0.047703  [19200/71706]
loss: 0.042796  [25600/71706]
loss: 0.026436  [32000/71706]
loss: 0.085286  [38400/71706]
loss: 0.010325  [44800/71706]
loss: 0.033172  [51200/71706]
loss: 0.096793  [57600/71706]
loss: 0.032001  [64000/71706]
loss: 0.051645  [70400/71706]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.108419 

Epoch 30
-------------------------------
loss: 0.179951  [    0/71706]
loss: 0.057892  [ 6400/71706]
loss: 0.028348  [12800/71706]
loss: 0.035981  [19200/71706]
loss: 0.052947  [25600/71706]
loss: 0.021425  [32000/71706]
loss: 0.006893  [38400/71706]
loss: 0.041717  [44800/71706]
loss: 0.110173  [51200/71706]
loss: 0.039482  [57600/71706]
loss: 0.019829  [64000/71706]
loss: 0.040031  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071589 

Epoch 31
-------------------------------
loss: 0.010825  [    0/71706]
loss: 0.001979  [ 6400/71706]
loss: 0.081143  [12800/71706]
loss: 0.005271  [19200/71706]
loss: 0.028471  [25600/71706]
loss: 0.091443  [32000/71706]
loss: 0.152359  [38400/71706]
loss: 0.010584  [44800/71706]
loss: 0.012629  [51200/71706]
loss: 0.032583  [57600/71706]
loss: 0.011210  [64000/71706]
loss: 0.061279  [70400/71706]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.074252 

Epoch 32
-------------------------------
loss: 0.140309  [    0/71706]
loss: 0.124164  [ 6400/71706]
loss: 0.094123  [12800/71706]
loss: 0.083107  [19200/71706]
loss: 0.027866  [25600/71706]
loss: 0.064159  [32000/71706]
loss: 0.007261  [38400/71706]
loss: 0.143918  [44800/71706]
loss: 0.009286  [51200/71706]
loss: 0.086055  [57600/71706]
loss: 0.034384  [64000/71706]
loss: 0.055700  [70400/71706]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.063162 

Epoch 33
-------------------------------
loss: 0.030803  [    0/71706]
loss: 0.168307  [ 6400/71706]
loss: 0.051316  [12800/71706]
loss: 0.049086  [19200/71706]
loss: 0.024754  [25600/71706]
loss: 0.035523  [32000/71706]
loss: 0.238514  [38400/71706]
loss: 0.004867  [44800/71706]
loss: 0.034097  [51200/71706]
loss: 0.051314  [57600/71706]
loss: 0.055598  [64000/71706]
loss: 0.031251  [70400/71706]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.064394 

Epoch 34
-------------------------------
loss: 0.009494  [    0/71706]
loss: 0.111782  [ 6400/71706]
loss: 0.035877  [12800/71706]
loss: 0.018751  [19200/71706]
loss: 0.130811  [25600/71706]
loss: 0.011073  [32000/71706]
loss: 0.027148  [38400/71706]
loss: 0.067216  [44800/71706]
loss: 0.026359  [51200/71706]
loss: 0.033699  [57600/71706]
loss: 0.015469  [64000/71706]
loss: 0.035941  [70400/71706]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.068185 

Epoch 35
-------------------------------
loss: 0.118327  [    0/71706]
loss: 0.021441  [ 6400/71706]
loss: 0.058559  [12800/71706]
loss: 0.031140  [19200/71706]
loss: 0.025325  [25600/71706]
loss: 0.066161  [32000/71706]
loss: 0.024151  [38400/71706]
loss: 0.020750  [44800/71706]
loss: 0.016996  [51200/71706]
loss: 0.033700  [57600/71706]
loss: 0.040068  [64000/71706]
loss: 0.037703  [70400/71706]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.065969 

Epoch 36
-------------------------------
loss: 0.015072  [    0/71706]
loss: 0.013363  [ 6400/71706]
loss: 0.013951  [12800/71706]
loss: 0.108031  [19200/71706]
loss: 0.010297  [25600/71706]
loss: 0.076504  [32000/71706]
loss: 0.023931  [38400/71706]
loss: 0.051846  [44800/71706]
loss: 0.039777  [51200/71706]
loss: 0.150013  [57600/71706]
loss: 0.068088  [64000/71706]
loss: 0.028676  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.078200 

Epoch 37
-------------------------------
loss: 0.127590  [    0/71706]
loss: 0.045023  [ 6400/71706]
loss: 0.085812  [12800/71706]
loss: 0.006720  [19200/71706]
loss: 0.074520  [25600/71706]
loss: 0.050016  [32000/71706]
loss: 0.021216  [38400/71706]
loss: 0.057745  [44800/71706]
loss: 0.046443  [51200/71706]
loss: 0.022115  [57600/71706]
loss: 0.125477  [64000/71706]
loss: 0.083889  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073774 

Epoch 38
-------------------------------
loss: 0.103265  [    0/71706]
loss: 0.008666  [ 6400/71706]
loss: 0.017723  [12800/71706]
loss: 0.061102  [19200/71706]
loss: 0.039063  [25600/71706]
loss: 0.085531  [32000/71706]
loss: 0.064792  [38400/71706]
loss: 0.105796  [44800/71706]
loss: 0.054297  [51200/71706]
loss: 0.054004  [57600/71706]
loss: 0.008531  [64000/71706]
loss: 0.033473  [70400/71706]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075464 

Epoch 39
-------------------------------
loss: 0.115181  [    0/71706]
loss: 0.034975  [ 6400/71706]
loss: 0.049194  [12800/71706]
loss: 0.026989  [19200/71706]
loss: 0.010110  [25600/71706]
loss: 0.009939  [32000/71706]
loss: 0.047030  [38400/71706]
loss: 0.014843  [44800/71706]
loss: 0.150253  [51200/71706]
loss: 0.022555  [57600/71706]
loss: 0.022677  [64000/71706]
loss: 0.016177  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072817 

Epoch 40
-------------------------------
loss: 0.098577  [    0/71706]
loss: 0.042332  [ 6400/71706]
loss: 0.052470  [12800/71706]
loss: 0.027237  [19200/71706]
loss: 0.057046  [25600/71706]
loss: 0.110376  [32000/71706]
loss: 0.115834  [38400/71706]
loss: 0.001960  [44800/71706]
loss: 0.072166  [51200/71706]
loss: 0.083652  [57600/71706]
loss: 0.024781  [64000/71706]
loss: 0.089895  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068112 

Epoch 41
-------------------------------
loss: 0.163235  [    0/71706]
loss: 0.079668  [ 6400/71706]
loss: 0.124704  [12800/71706]
loss: 0.059688  [19200/71706]
loss: 0.029308  [25600/71706]
loss: 0.012602  [32000/71706]
loss: 0.022640  [38400/71706]
loss: 0.144459  [44800/71706]
loss: 0.091203  [51200/71706]
loss: 0.023750  [57600/71706]
loss: 0.025843  [64000/71706]
loss: 0.061211  [70400/71706]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.078274 

Epoch 42
-------------------------------
loss: 0.028188  [    0/71706]
loss: 0.006824  [ 6400/71706]
loss: 0.141347  [12800/71706]
loss: 0.056525  [19200/71706]
loss: 0.041506  [25600/71706]
loss: 0.016901  [32000/71706]
loss: 0.079904  [38400/71706]
loss: 0.023861  [44800/71706]
loss: 0.008738  [51200/71706]
loss: 0.076079  [57600/71706]
loss: 0.026873  [64000/71706]
loss: 0.046072  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069722 

Epoch 43
-------------------------------
loss: 0.087913  [    0/71706]
loss: 0.013355  [ 6400/71706]
loss: 0.013012  [12800/71706]
loss: 0.023827  [19200/71706]
loss: 0.017219  [25600/71706]
loss: 0.042836  [32000/71706]
loss: 0.167186  [38400/71706]
loss: 0.016194  [44800/71706]
loss: 0.048168  [51200/71706]
loss: 0.130286  [57600/71706]
loss: 0.068718  [64000/71706]
loss: 0.037889  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076132 

Epoch 44
-------------------------------
loss: 0.036957  [    0/71706]
loss: 0.005978  [ 6400/71706]
loss: 0.094810  [12800/71706]
loss: 0.062021  [19200/71706]
loss: 0.054785  [25600/71706]
loss: 0.054445  [32000/71706]
loss: 0.050693  [38400/71706]
loss: 0.018697  [44800/71706]
loss: 0.035093  [51200/71706]
loss: 0.004614  [57600/71706]
loss: 0.052786  [64000/71706]
loss: 0.011755  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067647 

Epoch 45
-------------------------------
loss: 0.010405  [    0/71706]
loss: 0.018312  [ 6400/71706]
loss: 0.004830  [12800/71706]
loss: 0.145114  [19200/71706]
loss: 0.063360  [25600/71706]
loss: 0.040345  [32000/71706]
loss: 0.010564  [38400/71706]
loss: 0.030871  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.107675 

Epoch 31
-------------------------------
loss: 0.132370  [    0/71414]
loss: 0.019134  [ 6400/71414]
loss: 0.149486  [12800/71414]
loss: 0.042286  [19200/71414]
loss: 0.030892  [25600/71414]
loss: 0.077075  [32000/71414]
loss: 0.021375  [38400/71414]
loss: 0.053367  [44800/71414]
loss: 0.227833  [51200/71414]
loss: 0.054447  [57600/71414]
loss: 0.015206  [64000/71414]
loss: 0.020608  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.104058 

Epoch 32
-------------------------------
loss: 0.074524  [    0/71414]
loss: 0.066849  [ 6400/71414]
loss: 0.016233  [12800/71414]
loss: 0.026513  [19200/71414]
loss: 0.101699  [25600/71414]
loss: 0.034528  [32000/71414]
loss: 0.163211  [38400/71414]
loss: 0.064195  [44800/71414]
loss: 0.013650  [51200/71414]
loss: 0.060107  [57600/71414]
loss: 0.130471  [64000/71414]
loss: 0.016181  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.103325 

Epoch 33
-------------------------------
loss: 0.036710  [    0/71414]
loss: 0.030959  [ 6400/71414]
loss: 0.058443  [12800/71414]
loss: 0.088313  [19200/71414]
loss: 0.066438  [25600/71414]
loss: 0.075767  [32000/71414]
loss: 0.085193  [38400/71414]
loss: 0.068287  [44800/71414]
loss: 0.011001  [51200/71414]
loss: 0.012685  [57600/71414]
loss: 0.161168  [64000/71414]
loss: 0.013577  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.104389 

Epoch 34
-------------------------------
loss: 0.028086  [    0/71414]
loss: 0.018262  [ 6400/71414]
loss: 0.081041  [12800/71414]
loss: 0.060193  [19200/71414]
loss: 0.034559  [25600/71414]
loss: 0.043128  [32000/71414]
loss: 0.022404  [38400/71414]
loss: 0.014550  [44800/71414]
loss: 0.072807  [51200/71414]
loss: 0.054128  [57600/71414]
loss: 0.129271  [64000/71414]
loss: 0.038668  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.106174 

Epoch 35
-------------------------------
loss: 0.055216  [    0/71414]
loss: 0.094324  [ 6400/71414]
loss: 0.057068  [12800/71414]
loss: 0.041387  [19200/71414]
loss: 0.044822  [25600/71414]
loss: 0.070355  [32000/71414]
loss: 0.065651  [38400/71414]
loss: 0.268479  [44800/71414]
loss: 0.055332  [51200/71414]
loss: 0.104879  [57600/71414]
loss: 0.186278  [64000/71414]
loss: 0.041736  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.108706 

Epoch 36
-------------------------------
loss: 0.047990  [    0/71414]
loss: 0.102329  [ 6400/71414]
loss: 0.022306  [12800/71414]
loss: 0.051851  [19200/71414]
loss: 0.055676  [25600/71414]
loss: 0.129813  [32000/71414]
loss: 0.016898  [38400/71414]
loss: 0.097377  [44800/71414]
loss: 0.031482  [51200/71414]
loss: 0.038951  [57600/71414]
loss: 0.089673  [64000/71414]
loss: 0.082915  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.108104 

Epoch 37
-------------------------------
loss: 0.004425  [    0/71414]
loss: 0.080431  [ 6400/71414]
loss: 0.029509  [12800/71414]
loss: 0.033903  [19200/71414]
loss: 0.168069  [25600/71414]
loss: 0.093221  [32000/71414]
loss: 0.048180  [38400/71414]
loss: 0.024566  [44800/71414]
loss: 0.012460  [51200/71414]
loss: 0.096790  [57600/71414]
loss: 0.057383  [64000/71414]
loss: 0.178722  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.105206 

Epoch 38
-------------------------------
loss: 0.035571  [    0/71414]
loss: 0.097312  [ 6400/71414]
loss: 0.061786  [12800/71414]
loss: 0.049910  [19200/71414]
loss: 0.013232  [25600/71414]
loss: 0.042711  [32000/71414]
loss: 0.086858  [38400/71414]
loss: 0.056237  [44800/71414]
loss: 0.020064  [51200/71414]
loss: 0.032134  [57600/71414]
loss: 0.037321  [64000/71414]
loss: 0.072468  [70400/71414]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.111010 

Epoch 39
-------------------------------
loss: 0.070327  [    0/71414]
loss: 0.007005  [ 6400/71414]
loss: 0.105049  [12800/71414]
loss: 0.052603  [19200/71414]
loss: 0.030407  [25600/71414]
loss: 0.036027  [32000/71414]
loss: 0.077432  [38400/71414]
loss: 0.057974  [44800/71414]
loss: 0.188086  [51200/71414]
loss: 1.614214  [57600/71414]
loss: 0.026952  [64000/71414]
loss: 0.068319  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110938 

Epoch 40
-------------------------------
loss: 0.059511  [    0/71414]
loss: 0.067728  [ 6400/71414]
loss: 0.059420  [12800/71414]
loss: 0.055718  [19200/71414]
loss: 0.016449  [25600/71414]
loss: 0.037245  [32000/71414]
loss: 0.013496  [38400/71414]
loss: 0.066799  [44800/71414]
loss: 0.054149  [51200/71414]
loss: 0.060342  [57600/71414]
loss: 0.052659  [64000/71414]
loss: 0.041208  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.105855 

Epoch 41
-------------------------------
loss: 0.059871  [    0/71414]
loss: 0.057650  [ 6400/71414]
loss: 0.026682  [12800/71414]
loss: 0.061722  [19200/71414]
loss: 0.100520  [25600/71414]
loss: 0.044653  [32000/71414]
loss: 0.291547  [38400/71414]
loss: 0.057237  [44800/71414]
loss: 0.057150  [51200/71414]
loss: 0.031858  [57600/71414]
loss: 0.035450  [64000/71414]
loss: 0.075806  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110377 

Epoch 42
-------------------------------
loss: 0.052828  [    0/71414]
loss: 0.107500  [ 6400/71414]
loss: 0.100004  [12800/71414]
loss: 0.085429  [19200/71414]
loss: 0.061410  [25600/71414]
loss: 0.078632  [32000/71414]
loss: 0.023550  [38400/71414]
loss: 0.026153  [44800/71414]
loss: 0.070803  [51200/71414]
loss: 0.104060  [57600/71414]
loss: 0.050264  [64000/71414]
loss: 0.123421  [70400/71414]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.111431 

Epoch 43
-------------------------------
loss: 0.016293  [    0/71414]
loss: 0.011785  [ 6400/71414]
loss: 0.036448  [12800/71414]
loss: 0.072390  [19200/71414]
loss: 0.092377  [25600/71414]
loss: 0.110033  [32000/71414]
loss: 0.073119  [38400/71414]
loss: 0.083312  [44800/71414]
loss: 0.058153  [51200/71414]
loss: 0.022247  [57600/71414]
loss: 0.102275  [64000/71414]
loss: 0.041901  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.106899 

Epoch 44
-------------------------------
loss: 0.059385  [    0/71414]
loss: 0.019583  [ 6400/71414]
loss: 0.107621  [12800/71414]
loss: 0.078344  [19200/71414]
loss: 0.027731  [25600/71414]
loss: 0.050819  [32000/71414]
loss: 0.066194  [38400/71414]
loss: 0.045062  [44800/71414]
loss: 0.119229  [51200/71414]
loss: 0.014707  [57600/71414]
loss: 0.194345  [64000/71414]
loss: 0.032892  [70400/71414]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.104644 

Epoch 45
-------------------------------
loss: 0.033020  [    0/71414]
loss: 0.119058  [ 6400/71414]
loss: 0.020424  [12800/71414]
loss: 0.124193  [19200/71414]
loss: 0.085146  [25600/71414]
loss: 0.053477  [32000/71414]
loss: 0.069041  [38400/71414]
loss: 0.040982  [44800/71414]
loss: 0.164284  [51200/71414]
loss: 0.047057  [57600/71414]
loss: 0.083805  [64000/71414]
loss: 0.063969  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.105446 

Epoch 46
-------------------------------
loss: 0.065107  [    0/71414]
loss: 0.038085  [ 6400/71414]
loss: 0.065040  [12800/71414]
loss: 0.150732  [19200/71414]
loss: 0.022674  [25600/71414]
loss: 0.016433  [32000/71414]
loss: 0.080820  [38400/71414]
loss: 0.075841  [44800/71414]
loss: 0.083042  [51200/71414]
loss: 0.033581  [57600/71414]
loss: 1.620288  [64000/71414]
loss: 0.060115  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.107127 

Epoch 47
-------------------------------
loss: 0.057636  [    0/71414]
loss: 0.078707  [ 6400/71414]
loss: 0.028043  [12800/71414]
loss: 0.086921  [19200/71414]
loss: 0.079326  [25600/71414]
loss: 0.026700  [32000/71414]
loss: 0.047359  [38400/71414]
loss: 0.141789  [44800/71414]
loss: 0.024413  [51200/71414]
loss: 0.082592  [57600/71414]
loss: 0.058928  [64000/71414]
loss: 0.106550  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.108526 

Epoch 48
-------------------------------
loss: 0.058655  [    0/71414]
loss: 0.105491  [ 6400/71414]
loss: 0.016255  [12800/71414]
loss: 0.080401  [19200/71414]
loss: 0.061000  [25600/71414]
loss: 0.076227  [32000/71414]
loss: 0.096691  [38400/71414]
loss: 0.041149  [44800/71414]
loss: 0.111269  [51200/71414]
loss: 0.064944  [57600/71414]
loss: 0.119276  [64000/71414]
loss: 0.076238  [70400/71414]
2022/09/20 15:04:02 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.167017  [38400/70446]
loss: 0.051106  [44800/70446]
loss: 0.135209  [51200/70446]
loss: 0.055916  [57600/70446]
loss: 0.137139  [64000/70446]
loss: 0.267366  [50600/70446]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.144655 

Epoch 28
-------------------------------
loss: 0.135797  [    0/70446]
loss: 0.154969  [ 6400/70446]
loss: 0.208952  [12800/70446]
loss: 0.095590  [19200/70446]
loss: 0.145252  [25600/70446]
loss: 0.080462  [32000/70446]
loss: 0.108553  [38400/70446]
loss: 0.074520  [44800/70446]
loss: 0.048460  [51200/70446]
loss: 0.141708  [57600/70446]
loss: 0.091688  [64000/70446]
loss: 0.095457  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.140461 

Epoch 29
-------------------------------
loss: 0.030586  [    0/70446]
loss: 0.179881  [ 6400/70446]
loss: 0.119793  [12800/70446]
loss: 0.192438  [19200/70446]
loss: 0.093030  [25600/70446]
loss: 0.132400  [32000/70446]
loss: 0.066864  [38400/70446]
loss: 0.062934  [44800/70446]
loss: 0.190713  [51200/70446]
loss: 0.111565  [57600/70446]
loss: 0.255436  [64000/70446]
loss: 0.168792  [50600/70446]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.142563 

Epoch 30
-------------------------------
loss: 0.176914  [    0/70446]
loss: 0.114819  [ 6400/70446]
loss: 0.166753  [12800/70446]
loss: 0.108480  [19200/70446]
loss: 0.135723  [25600/70446]
loss: 0.168537  [32000/70446]
loss: 0.107760  [38400/70446]
loss: 0.111683  [44800/70446]
loss: 0.209397  [51200/70446]
loss: 0.150734  [57600/70446]
loss: 0.080836  [64000/70446]
loss: 0.113835  [50600/70446]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.139491 

Epoch 31
-------------------------------
loss: 0.109808  [    0/70446]
loss: 0.133962  [ 6400/70446]
loss: 0.071362  [12800/70446]
loss: 0.165540  [19200/70446]
loss: 0.041994  [25600/70446]
loss: 0.106598  [32000/70446]
loss: 0.087563  [38400/70446]
loss: 0.101910  [44800/70446]
loss: 0.115314  [51200/70446]
loss: 0.188128  [57600/70446]
loss: 0.116207  [64000/70446]
loss: 0.119202  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.141016 

Epoch 32
-------------------------------
loss: 0.111234  [    0/70446]
loss: 0.064160  [ 6400/70446]
loss: 0.227817  [12800/70446]
loss: 0.046028  [19200/70446]
loss: 0.078249  [25600/70446]
loss: 0.054462  [32000/70446]
loss: 0.103753  [38400/70446]
loss: 0.154999  [44800/70446]
loss: 0.153555  [51200/70446]
loss: 0.174856  [57600/70446]
loss: 0.097838  [64000/70446]
loss: 0.050258  [50600/70446]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.143440 

Epoch 33
-------------------------------
loss: 0.147617  [    0/70446]
loss: 0.105491  [ 6400/70446]
loss: 0.094556  [12800/70446]
loss: 0.175633  [19200/70446]
loss: 0.058876  [25600/70446]
loss: 0.174807  [32000/70446]
loss: 0.106409  [38400/70446]
loss: 0.187856  [44800/70446]
loss: 0.107405  [51200/70446]
loss: 0.068514  [57600/70446]
loss: 0.129599  [64000/70446]
loss: 0.053195  [50600/70446]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.145325 

Epoch 34
-------------------------------
loss: 0.213014  [    0/70446]
loss: 0.099262  [ 6400/70446]
loss: 0.172505  [12800/70446]
loss: 0.148702  [19200/70446]
loss: 0.247331  [25600/70446]
loss: 0.101536  [32000/70446]
loss: 0.039495  [38400/70446]
loss: 0.124422  [44800/70446]
loss: 0.110129  [51200/70446]
loss: 0.169150  [57600/70446]
loss: 0.119037  [64000/70446]
loss: 0.159043  [50600/70446]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.145788 

Epoch 35
-------------------------------
loss: 0.129074  [    0/70446]
loss: 0.069475  [ 6400/70446]
loss: 0.111159  [12800/70446]
loss: 0.229951  [19200/70446]
loss: 0.045477  [25600/70446]
loss: 0.162382  [32000/70446]
loss: 0.148757  [38400/70446]
loss: 0.049369  [44800/70446]
loss: 0.107592  [51200/70446]
loss: 0.049567  [57600/70446]
loss: 0.107688  [64000/70446]
loss: 0.092808  [50600/70446]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.140548 

Epoch 36
-------------------------------
loss: 0.120225  [    0/70446]
loss: 0.080115  [ 6400/70446]
loss: 0.138270  [12800/70446]
loss: 0.124798  [19200/70446]
loss: 0.108038  [25600/70446]
loss: 0.113673  [32000/70446]
loss: 0.080189  [38400/70446]
loss: 0.091243  [44800/70446]
loss: 0.174359  [51200/70446]
loss: 0.068781  [57600/70446]
loss: 0.054561  [64000/70446]
loss: 0.078718  [50600/70446]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.142587 

Epoch 37
-------------------------------
loss: 0.060111  [    0/70446]
loss: 0.120424  [ 6400/70446]
loss: 0.082361  [12800/70446]
loss: 0.093623  [19200/70446]
loss: 0.134208  [25600/70446]
loss: 0.088821  [32000/70446]
loss: 0.159459  [38400/70446]
loss: 0.081923  [44800/70446]
loss: 0.114194  [51200/70446]
loss: 0.140386  [57600/70446]
loss: 0.052395  [64000/70446]
loss: 0.085712  [50600/70446]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.145904 

Epoch 38
-------------------------------
loss: 0.126793  [    0/70446]
loss: 0.081128  [ 6400/70446]
loss: 0.123328  [12800/70446]
loss: 0.119758  [19200/70446]
loss: 0.126510  [25600/70446]
loss: 0.061076  [32000/70446]
loss: 0.192193  [38400/70446]
loss: 0.059624  [44800/70446]
loss: 0.054946  [51200/70446]
loss: 0.038008  [57600/70446]
loss: 0.101037  [64000/70446]
loss: 0.049832  [50600/70446]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.142005 

Epoch 39
-------------------------------
loss: 0.103914  [    0/70446]
loss: 0.162848  [ 6400/70446]
loss: 0.161645  [12800/70446]
loss: 0.079373  [19200/70446]
loss: 0.128177  [25600/70446]
loss: 0.072920  [32000/70446]
loss: 0.236242  [38400/70446]
loss: 0.142307  [44800/70446]
loss: 0.065686  [51200/70446]
loss: 0.169542  [57600/70446]
loss: 0.216556  [64000/70446]
loss: 0.061471  [50600/70446]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146254 

Epoch 40
-------------------------------
loss: 0.090424  [    0/70446]
loss: 0.078297  [ 6400/70446]
loss: 0.064906  [12800/70446]
loss: 0.127583  [19200/70446]
loss: 0.141558  [25600/70446]
loss: 0.202415  [32000/70446]
loss: 0.132960  [38400/70446]
loss: 0.077742  [44800/70446]
loss: 0.177147  [51200/70446]
loss: 0.120797  [57600/70446]
loss: 0.067770  [64000/70446]
loss: 0.147743  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.144224 

Epoch 41
-------------------------------
loss: 0.095776  [    0/70446]
loss: 0.128507  [ 6400/70446]
loss: 0.103960  [12800/70446]
loss: 0.064316  [19200/70446]
loss: 0.105931  [25600/70446]
loss: 0.196378  [32000/70446]
loss: 0.141808  [38400/70446]
loss: 0.097846  [44800/70446]
loss: 0.098372  [51200/70446]
loss: 0.107487  [57600/70446]
loss: 0.127766  [64000/70446]
loss: 0.142637  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.138604 

Epoch 42
-------------------------------
loss: 0.063175  [    0/70446]
loss: 0.108728  [ 6400/70446]
loss: 0.032230  [12800/70446]
loss: 0.099469  [19200/70446]
loss: 0.062895  [25600/70446]
loss: 0.069909  [32000/70446]
loss: 0.150402  [38400/70446]
loss: 0.147886  [44800/70446]
loss: 0.087551  [51200/70446]
loss: 0.092486  [57600/70446]
loss: 0.134926  [64000/70446]
loss: 0.176815  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.147109 

Epoch 43
-------------------------------
loss: 0.117833  [    0/70446]
loss: 0.068590  [ 6400/70446]
loss: 0.170185  [12800/70446]
loss: 0.142071  [19200/70446]
loss: 0.074701  [25600/70446]
loss: 0.105285  [32000/70446]
loss: 0.049899  [38400/70446]
loss: 0.142644  [44800/70446]
loss: 0.092242  [51200/70446]
loss: 1.693710  [57600/70446]
loss: 0.093273  [64000/70446]
loss: 0.208051  [50600/70446]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.137404 

Epoch 44
-------------------------------
loss: 0.053046  [    0/70446]
loss: 0.132599  [ 6400/70446]
loss: 0.058819  [12800/70446]
loss: 0.180780  [19200/70446]
loss: 0.062242  [25600/70446]
loss: 0.082424  [32000/70446]
loss: 0.104951  [38400/70446]
loss: 0.209613  [44800/70446]
loss: 0.054642  [51200/70446]
loss: 0.142258  [57600/70446]
loss: 0.157002  [64000/70446]
loss: 0.055658  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.142906 

Epoch 45
-------------------------------
loss: 0.090071  [    0/70446]
loss: 0.100590  [ 6400/70446]
loss: 0.042984  [12800/70446]
loss: 0.076988  [19200/70446]
loss: 0.135391  [25600/70446]
loss: 0.102851  [32000/70446]
loss: 0.060984  [38400/70446]
loss: 0.076436  [38400/71180]
loss: 0.010075  [44800/71180]
loss: 0.111515  [51200/71180]
loss: 0.047041  [57600/71180]
loss: 0.100083  [64000/71180]
loss: 0.028658  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.126529 

Epoch 28
-------------------------------
loss: 0.066630  [    0/71180]
loss: 0.046773  [ 6400/71180]
loss: 0.099071  [12800/71180]
loss: 0.043256  [19200/71180]
loss: 0.132477  [25600/71180]
loss: 0.038593  [32000/71180]
loss: 0.048483  [38400/71180]
loss: 0.040899  [44800/71180]
loss: 0.154952  [51200/71180]
loss: 0.062562  [57600/71180]
loss: 0.059823  [64000/71180]
loss: 0.172265  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.120032 

Epoch 29
-------------------------------
loss: 0.029937  [    0/71180]
loss: 0.026742  [ 6400/71180]
loss: 0.071816  [12800/71180]
loss: 0.056090  [19200/71180]
loss: 0.033779  [25600/71180]
loss: 0.046194  [32000/71180]
loss: 0.096828  [38400/71180]
loss: 0.102380  [44800/71180]
loss: 0.054735  [51200/71180]
loss: 0.115960  [57600/71180]
loss: 0.147735  [64000/71180]
loss: 0.099109  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.122344 

Epoch 30
-------------------------------
loss: 0.100465  [    0/71180]
loss: 0.108022  [ 6400/71180]
loss: 0.061028  [12800/71180]
loss: 0.033152  [19200/71180]
loss: 0.034027  [25600/71180]
loss: 0.075100  [32000/71180]
loss: 0.043898  [38400/71180]
loss: 0.076290  [44800/71180]
loss: 0.051522  [51200/71180]
loss: 0.021964  [57600/71180]
loss: 0.040024  [64000/71180]
loss: 0.058958  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.121539 

Epoch 31
-------------------------------
loss: 0.109299  [    0/71180]
loss: 0.120840  [ 6400/71180]
loss: 0.055865  [12800/71180]
loss: 0.092293  [19200/71180]
loss: 0.073463  [25600/71180]
loss: 0.158315  [32000/71180]
loss: 0.093053  [38400/71180]
loss: 0.037111  [44800/71180]
loss: 0.028873  [51200/71180]
loss: 0.124689  [57600/71180]
loss: 0.128012  [64000/71180]
loss: 0.078837  [70400/71180]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119634 

Epoch 32
-------------------------------
loss: 0.080644  [    0/71180]
loss: 0.063087  [ 6400/71180]
loss: 0.099359  [12800/71180]
loss: 0.094614  [19200/71180]
loss: 0.201743  [25600/71180]
loss: 0.041909  [32000/71180]
loss: 0.035794  [38400/71180]
loss: 0.145435  [44800/71180]
loss: 0.055445  [51200/71180]
loss: 0.026400  [57600/71180]
loss: 0.123315  [64000/71180]
loss: 0.025328  [70400/71180]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.137983 

Epoch 33
-------------------------------
loss: 1.634915  [    0/71180]
loss: 0.035841  [ 6400/71180]
loss: 0.037010  [12800/71180]
loss: 0.083513  [19200/71180]
loss: 0.098287  [25600/71180]
loss: 0.186456  [32000/71180]
loss: 0.060690  [38400/71180]
loss: 1.585318  [44800/71180]
loss: 0.045243  [51200/71180]
loss: 1.682678  [57600/71180]
loss: 0.069674  [64000/71180]
loss: 0.085976  [70400/71180]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119852 

Epoch 34
-------------------------------
loss: 0.020497  [    0/71180]
loss: 0.069857  [ 6400/71180]
loss: 0.048507  [12800/71180]
loss: 0.070046  [19200/71180]
loss: 0.078034  [25600/71180]
loss: 0.050879  [32000/71180]
loss: 0.014802  [38400/71180]
loss: 0.100547  [44800/71180]
loss: 0.137474  [51200/71180]
loss: 0.085299  [57600/71180]
loss: 0.144598  [64000/71180]
loss: 0.055271  [70400/71180]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.134424 

Epoch 35
-------------------------------
loss: 0.124430  [    0/71180]
loss: 0.105241  [ 6400/71180]
loss: 0.132896  [12800/71180]
loss: 0.067699  [19200/71180]
loss: 0.092247  [25600/71180]
loss: 0.072702  [32000/71180]
loss: 0.032734  [38400/71180]
loss: 0.122505  [44800/71180]
loss: 0.066678  [51200/71180]
loss: 0.138202  [57600/71180]
loss: 0.025086  [64000/71180]
loss: 0.073983  [70400/71180]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.137926 

Epoch 36
-------------------------------
loss: 0.039205  [    0/71180]
loss: 0.106871  [ 6400/71180]
loss: 0.045562  [12800/71180]
loss: 0.079489  [19200/71180]
loss: 0.027650  [25600/71180]
loss: 0.161981  [32000/71180]
loss: 0.043104  [38400/71180]
loss: 0.096567  [44800/71180]
loss: 0.050052  [51200/71180]
loss: 0.013283  [57600/71180]
loss: 0.073187  [64000/71180]
loss: 0.018387  [70400/71180]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.133603 

Epoch 37
-------------------------------
loss: 0.055603  [    0/71180]
loss: 0.064672  [ 6400/71180]
loss: 0.062253  [12800/71180]
loss: 0.052193  [19200/71180]
loss: 0.070830  [25600/71180]
loss: 0.068265  [32000/71180]
loss: 0.069579  [38400/71180]
loss: 0.056514  [44800/71180]
loss: 0.092943  [51200/71180]
loss: 0.130613  [57600/71180]
loss: 0.081324  [64000/71180]
loss: 0.090285  [70400/71180]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.125935 

Epoch 38
-------------------------------
loss: 0.077404  [    0/71180]
loss: 0.046447  [ 6400/71180]
loss: 0.160501  [12800/71180]
loss: 0.029905  [19200/71180]
loss: 0.057615  [25600/71180]
loss: 0.016959  [32000/71180]
loss: 0.082314  [38400/71180]
loss: 0.028596  [44800/71180]
loss: 0.157573  [51200/71180]
loss: 0.048756  [57600/71180]
loss: 0.072966  [64000/71180]
loss: 0.082767  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.132498 

Epoch 39
-------------------------------
loss: 0.057998  [    0/71180]
loss: 0.024859  [ 6400/71180]
loss: 0.077932  [12800/71180]
loss: 0.067069  [19200/71180]
loss: 0.061805  [25600/71180]
loss: 0.056071  [32000/71180]
loss: 0.137546  [38400/71180]
loss: 0.071290  [44800/71180]
loss: 0.051555  [51200/71180]
loss: 0.079190  [57600/71180]
loss: 0.031887  [64000/71180]
loss: 0.060507  [70400/71180]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.183861 

Epoch 40
-------------------------------
loss: 0.119823  [    0/71180]
loss: 0.009388  [ 6400/71180]
loss: 0.059636  [12800/71180]
loss: 0.191854  [19200/71180]
loss: 0.096419  [25600/71180]
loss: 0.058929  [32000/71180]
loss: 0.069077  [38400/71180]
loss: 0.039597  [44800/71180]
loss: 0.101647  [51200/71180]
loss: 0.077070  [57600/71180]
loss: 0.044704  [64000/71180]
loss: 1.627847  [70400/71180]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.128923 

Epoch 41
-------------------------------
loss: 0.099486  [    0/71180]
loss: 1.610340  [ 6400/71180]
loss: 0.016815  [12800/71180]
loss: 0.063897  [19200/71180]
loss: 0.073206  [25600/71180]
loss: 0.116340  [32000/71180]
loss: 0.027224  [38400/71180]
loss: 0.096478  [44800/71180]
loss: 0.083047  [51200/71180]
loss: 0.032801  [57600/71180]
loss: 0.003369  [64000/71180]
loss: 0.027582  [70400/71180]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.127787 

Epoch 42
-------------------------------
loss: 0.077473  [    0/71180]
loss: 0.050607  [ 6400/71180]
loss: 0.192783  [12800/71180]
loss: 0.242329  [19200/71180]
loss: 0.042763  [25600/71180]
loss: 0.094240  [32000/71180]
loss: 0.126971  [38400/71180]
loss: 0.069286  [44800/71180]
loss: 0.125635  [51200/71180]
loss: 0.161042  [57600/71180]
loss: 0.078732  [64000/71180]
loss: 0.108136  [70400/71180]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.123057 

Epoch 43
-------------------------------
loss: 0.082443  [    0/71180]
loss: 0.064760  [ 6400/71180]
loss: 0.146143  [12800/71180]
loss: 0.073360  [19200/71180]
loss: 0.036998  [25600/71180]
loss: 0.087038  [32000/71180]
loss: 0.049090  [38400/71180]
loss: 0.114023  [44800/71180]
loss: 0.047124  [51200/71180]
loss: 0.021256  [57600/71180]
loss: 0.069785  [64000/71180]
loss: 0.059819  [70400/71180]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.126693 

Epoch 44
-------------------------------
loss: 0.031116  [    0/71180]
loss: 0.070307  [ 6400/71180]
loss: 0.091784  [12800/71180]
loss: 0.113989  [19200/71180]
loss: 0.021101  [25600/71180]
loss: 0.011095  [32000/71180]
loss: 0.066523  [38400/71180]
loss: 0.044612  [44800/71180]
loss: 0.084721  [51200/71180]
loss: 0.019201  [57600/71180]
loss: 0.223870  [64000/71180]
loss: 0.121249  [70400/71180]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.128913 

Epoch 45
-------------------------------
loss: 0.040053  [    0/71180]
loss: 0.041203  [ 6400/71180]
loss: 0.070531  [12800/71180]
loss: 0.098629  [19200/71180]
loss: 0.069672  [25600/71180]
loss: 0.046322  [32000/71180]
loss: 0.023269  [38400/71180]
loss: 0.039432  [38400/71130]
loss: 0.064813  [44800/71130]
loss: 0.072465  [51200/71130]
loss: 0.020757  [57600/71130]
loss: 0.026749  [64000/71130]
loss: 0.050472  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.071383 

Epoch 28
-------------------------------
loss: 0.035829  [    0/71130]
loss: 0.015182  [ 6400/71130]
loss: 0.127200  [12800/71130]
loss: 0.043322  [19200/71130]
loss: 0.023547  [25600/71130]
loss: 0.054843  [32000/71130]
loss: 0.051172  [38400/71130]
loss: 0.072150  [44800/71130]
loss: 0.051688  [51200/71130]
loss: 0.126608  [57600/71130]
loss: 0.028150  [64000/71130]
loss: 0.055558  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067398 

Epoch 29
-------------------------------
loss: 0.048431  [    0/71130]
loss: 0.056006  [ 6400/71130]
loss: 0.102234  [12800/71130]
loss: 0.047952  [19200/71130]
loss: 0.056982  [25600/71130]
loss: 0.012522  [32000/71130]
loss: 0.011002  [38400/71130]
loss: 0.016438  [44800/71130]
loss: 0.047951  [51200/71130]
loss: 0.015969  [57600/71130]
loss: 0.076166  [64000/71130]
loss: 0.111992  [70400/71130]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075590 

Epoch 30
-------------------------------
loss: 0.166760  [    0/71130]
loss: 0.085895  [ 6400/71130]
loss: 0.012779  [12800/71130]
loss: 0.067057  [19200/71130]
loss: 0.068247  [25600/71130]
loss: 0.087915  [32000/71130]
loss: 0.151283  [38400/71130]
loss: 0.035226  [44800/71130]
loss: 0.014643  [51200/71130]
loss: 0.084199  [57600/71130]
loss: 0.134729  [64000/71130]
loss: 0.019457  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.075005 

Epoch 31
-------------------------------
loss: 0.060892  [    0/71130]
loss: 0.032869  [ 6400/71130]
loss: 0.045058  [12800/71130]
loss: 0.046198  [19200/71130]
loss: 0.009363  [25600/71130]
loss: 0.025057  [32000/71130]
loss: 0.093117  [38400/71130]
loss: 0.029703  [44800/71130]
loss: 0.051120  [51200/71130]
loss: 0.069280  [57600/71130]
loss: 0.082903  [64000/71130]
loss: 0.057978  [70400/71130]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085299 

Epoch 32
-------------------------------
loss: 0.124697  [    0/71130]
loss: 0.040509  [ 6400/71130]
loss: 0.116342  [12800/71130]
loss: 0.045059  [19200/71130]
loss: 0.058611  [25600/71130]
loss: 0.050592  [32000/71130]
loss: 0.339309  [38400/71130]
loss: 0.026779  [44800/71130]
loss: 0.011499  [51200/71130]
loss: 0.155511  [57600/71130]
loss: 0.044374  [64000/71130]
loss: 0.020850  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.074313 

Epoch 33
-------------------------------
loss: 0.143248  [    0/71130]
loss: 0.047631  [ 6400/71130]
loss: 0.020435  [12800/71130]
loss: 0.068506  [19200/71130]
loss: 0.063227  [25600/71130]
loss: 0.117477  [32000/71130]
loss: 0.113468  [38400/71130]
loss: 0.051264  [44800/71130]
loss: 0.058862  [51200/71130]
loss: 0.028783  [57600/71130]
loss: 0.065652  [64000/71130]
loss: 0.018925  [70400/71130]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.076511 

Epoch 34
-------------------------------
loss: 0.106867  [    0/71130]
loss: 0.043367  [ 6400/71130]
loss: 0.116324  [12800/71130]
loss: 0.096703  [19200/71130]
loss: 0.103153  [25600/71130]
loss: 0.026217  [32000/71130]
loss: 0.036644  [38400/71130]
loss: 0.066992  [44800/71130]
loss: 0.083506  [51200/71130]
loss: 0.078272  [57600/71130]
loss: 0.025447  [64000/71130]
loss: 0.062849  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068336 

Epoch 35
-------------------------------
loss: 0.014460  [    0/71130]
loss: 0.034733  [ 6400/71130]
loss: 0.064746  [12800/71130]
loss: 0.035529  [19200/71130]
loss: 0.026405  [25600/71130]
loss: 0.012029  [32000/71130]
loss: 0.032143  [38400/71130]
loss: 0.134195  [44800/71130]
loss: 0.085075  [51200/71130]
loss: 0.028202  [57600/71130]
loss: 0.080254  [64000/71130]
loss: 0.016103  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066690 

Epoch 36
-------------------------------
loss: 0.043025  [    0/71130]
loss: 0.017818  [ 6400/71130]
loss: 0.080746  [12800/71130]
loss: 0.156825  [19200/71130]
loss: 0.018569  [25600/71130]
loss: 0.009459  [32000/71130]
loss: 0.006127  [38400/71130]
loss: 0.053227  [44800/71130]
loss: 0.164211  [51200/71130]
loss: 0.042033  [57600/71130]
loss: 0.062297  [64000/71130]
loss: 0.072574  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067626 

Epoch 37
-------------------------------
loss: 0.028167  [    0/71130]
loss: 0.017212  [ 6400/71130]
loss: 0.007464  [12800/71130]
loss: 0.129749  [19200/71130]
loss: 0.025697  [25600/71130]
loss: 0.035475  [32000/71130]
loss: 0.074950  [38400/71130]
loss: 0.021680  [44800/71130]
loss: 0.091924  [51200/71130]
loss: 0.006726  [57600/71130]
loss: 0.014677  [64000/71130]
loss: 0.009158  [70400/71130]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.072565 

Epoch 38
-------------------------------
loss: 0.036383  [    0/71130]
loss: 0.072041  [ 6400/71130]
loss: 0.072262  [12800/71130]
loss: 0.036740  [19200/71130]
loss: 0.046723  [25600/71130]
loss: 0.044122  [32000/71130]
loss: 0.084063  [38400/71130]
loss: 0.007823  [44800/71130]
loss: 0.074792  [51200/71130]
loss: 0.053662  [57600/71130]
loss: 0.144995  [64000/71130]
loss: 0.105790  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067022 

Epoch 39
-------------------------------
loss: 0.032685  [    0/71130]
loss: 0.014279  [ 6400/71130]
loss: 0.011728  [12800/71130]
loss: 0.031241  [19200/71130]
loss: 0.051812  [25600/71130]
loss: 0.063654  [32000/71130]
loss: 0.091615  [38400/71130]
loss: 0.103432  [44800/71130]
loss: 0.117621  [51200/71130]
loss: 0.009635  [57600/71130]
loss: 0.150505  [64000/71130]
loss: 0.006461  [70400/71130]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.065368 

Epoch 40
-------------------------------
loss: 0.038926  [    0/71130]
loss: 0.122892  [ 6400/71130]
loss: 0.093305  [12800/71130]
loss: 0.042414  [19200/71130]
loss: 0.020514  [25600/71130]
loss: 0.015319  [32000/71130]
loss: 0.017949  [38400/71130]
loss: 0.151108  [44800/71130]
loss: 0.040887  [51200/71130]
loss: 0.133464  [57600/71130]
loss: 0.007343  [64000/71130]
loss: 0.057998  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069805 

Epoch 41
-------------------------------
loss: 0.070767  [    0/71130]
loss: 0.048597  [ 6400/71130]
loss: 0.026452  [12800/71130]
loss: 0.121390  [19200/71130]
loss: 0.080573  [25600/71130]
loss: 0.105656  [32000/71130]
loss: 0.014960  [38400/71130]
loss: 0.127851  [44800/71130]
loss: 0.085512  [51200/71130]
loss: 0.042140  [57600/71130]
loss: 0.073641  [64000/71130]
loss: 0.093662  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068990 

Epoch 42
-------------------------------
loss: 0.015521  [    0/71130]
loss: 0.023061  [ 6400/71130]
loss: 0.014428  [12800/71130]
loss: 0.022363  [19200/71130]
loss: 0.048780  [25600/71130]
loss: 0.054126  [32000/71130]
loss: 0.013038  [38400/71130]
loss: 0.018647  [44800/71130]
loss: 0.023630  [51200/71130]
loss: 0.041684  [57600/71130]
loss: 0.132873  [64000/71130]
loss: 0.063122  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070993 

Epoch 43
-------------------------------
loss: 0.090439  [    0/71130]
loss: 0.040527  [ 6400/71130]
loss: 0.013781  [12800/71130]
loss: 0.043198  [19200/71130]
loss: 0.020351  [25600/71130]
loss: 0.128879  [32000/71130]
loss: 0.093058  [38400/71130]
loss: 0.028674  [44800/71130]
loss: 0.038358  [51200/71130]
loss: 0.050715  [57600/71130]
loss: 0.019091  [64000/71130]
loss: 0.043719  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067772 

Epoch 44
-------------------------------
loss: 0.082753  [    0/71130]
loss: 0.025629  [ 6400/71130]
loss: 0.029107  [12800/71130]
loss: 0.012783  [19200/71130]
loss: 0.002367  [25600/71130]
loss: 0.056380  [32000/71130]
loss: 0.085657  [38400/71130]
loss: 0.130206  [44800/71130]
loss: 0.083266  [51200/71130]
loss: 0.035123  [57600/71130]
loss: 0.026171  [64000/71130]
loss: 0.022195  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.069481 

Epoch 45
-------------------------------
loss: 0.032461  [    0/71130]
loss: 0.082074  [ 6400/71130]
loss: 0.016907  [12800/71130]
loss: 0.019088  [19200/71130]
loss: 0.159710  [25600/71130]
loss: 0.022169  [32000/71130]
loss: 0.037644  [38400/71130]
2022/09/20 15:06:51 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.070694  [19200/70010]
loss: 0.045842  [25600/70010]
loss: 0.183902  [32000/70010]
loss: 0.045372  [38400/70010]
loss: 0.045877  [44800/70010]
loss: 0.073320  [51200/70010]
loss: 0.079765  [57600/70010]
loss: 0.130187  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086874 

Epoch 30
-------------------------------
loss: 0.033711  [    0/70010]
loss: 0.170899  [ 6400/70010]
loss: 0.035154  [12800/70010]
loss: 0.016567  [19200/70010]
loss: 0.075410  [25600/70010]
loss: 0.180604  [32000/70010]
loss: 0.026798  [38400/70010]
loss: 0.080998  [44800/70010]
loss: 0.027736  [51200/70010]
loss: 0.144731  [57600/70010]
loss: 0.037376  [64000/70010]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.088154 

Epoch 31
-------------------------------
loss: 0.020416  [    0/70010]
loss: 0.042852  [ 6400/70010]
loss: 0.063417  [12800/70010]
loss: 0.109169  [19200/70010]
loss: 0.035919  [25600/70010]
loss: 0.090974  [32000/70010]
loss: 0.073334  [38400/70010]
loss: 0.159981  [44800/70010]
loss: 0.032931  [51200/70010]
loss: 0.165690  [57600/70010]
loss: 0.066416  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.089575 

Epoch 32
-------------------------------
loss: 0.071605  [    0/70010]
loss: 0.100944  [ 6400/70010]
loss: 0.025591  [12800/70010]
loss: 0.040275  [19200/70010]
loss: 0.068403  [25600/70010]
loss: 0.052026  [32000/70010]
loss: 0.056197  [38400/70010]
loss: 0.023637  [44800/70010]
loss: 0.057928  [51200/70010]
loss: 0.126292  [57600/70010]
loss: 0.102196  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.090089 

Epoch 33
-------------------------------
loss: 0.092342  [    0/70010]
loss: 0.023224  [ 6400/70010]
loss: 0.043383  [12800/70010]
loss: 0.016677  [19200/70010]
loss: 0.054841  [25600/70010]
loss: 0.043463  [32000/70010]
loss: 0.133244  [38400/70010]
loss: 0.033679  [44800/70010]
loss: 0.030570  [51200/70010]
loss: 0.065298  [57600/70010]
loss: 0.051663  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086665 

Epoch 34
-------------------------------
loss: 0.101423  [    0/70010]
loss: 0.064035  [ 6400/70010]
loss: 0.022960  [12800/70010]
loss: 0.062483  [19200/70010]
loss: 0.066666  [25600/70010]
loss: 0.064636  [32000/70010]
loss: 0.034920  [38400/70010]
loss: 0.044618  [44800/70010]
loss: 0.036038  [51200/70010]
loss: 0.062178  [57600/70010]
loss: 0.179105  [64000/70010]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089692 

Epoch 35
-------------------------------
loss: 0.057568  [    0/70010]
loss: 0.037639  [ 6400/70010]
loss: 0.028361  [12800/70010]
loss: 0.055048  [19200/70010]
loss: 0.053426  [25600/70010]
loss: 0.126420  [32000/70010]
loss: 0.113905  [38400/70010]
loss: 0.016816  [44800/70010]
loss: 0.144533  [51200/70010]
loss: 0.032509  [57600/70010]
loss: 0.140244  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.087793 

Epoch 36
-------------------------------
loss: 0.019716  [    0/70010]
loss: 0.014428  [ 6400/70010]
loss: 0.060015  [12800/70010]
loss: 0.039493  [19200/70010]
loss: 0.078740  [25600/70010]
loss: 0.104748  [32000/70010]
loss: 0.074766  [38400/70010]
loss: 0.076157  [44800/70010]
loss: 0.089142  [51200/70010]
loss: 0.019812  [57600/70010]
loss: 0.045989  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.089238 

Epoch 37
-------------------------------
loss: 0.255258  [    0/70010]
loss: 0.079764  [ 6400/70010]
loss: 0.020822  [12800/70010]
loss: 0.036351  [19200/70010]
loss: 0.026000  [25600/70010]
loss: 0.030517  [32000/70010]
loss: 0.042545  [38400/70010]
loss: 0.047990  [44800/70010]
loss: 0.145353  [51200/70010]
loss: 0.056014  [57600/70010]
loss: 0.104246  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089719 

Epoch 38
-------------------------------
loss: 0.095181  [    0/70010]
loss: 0.061455  [ 6400/70010]
loss: 0.172507  [12800/70010]
loss: 0.079575  [19200/70010]
loss: 0.103742  [25600/70010]
loss: 0.116324  [32000/70010]
loss: 0.026995  [38400/70010]
loss: 0.035248  [44800/70010]
loss: 0.061893  [51200/70010]
loss: 0.130348  [57600/70010]
loss: 0.092249  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086437 

Epoch 39
-------------------------------
loss: 0.098886  [    0/70010]
loss: 0.023636  [ 6400/70010]
loss: 0.094845  [12800/70010]
loss: 0.040804  [19200/70010]
loss: 0.039091  [25600/70010]
loss: 0.099668  [32000/70010]
loss: 0.032329  [38400/70010]
loss: 0.091422  [44800/70010]
loss: 0.083493  [51200/70010]
loss: 0.041547  [57600/70010]
loss: 0.089611  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088673 

Epoch 40
-------------------------------
loss: 0.089068  [    0/70010]
loss: 0.283930  [ 6400/70010]
loss: 0.034610  [12800/70010]
loss: 0.041664  [19200/70010]
loss: 0.105608  [25600/70010]
loss: 0.035358  [32000/70010]
loss: 0.116054  [38400/70010]
loss: 0.135192  [44800/70010]
loss: 0.043241  [51200/70010]
loss: 0.231905  [57600/70010]
loss: 0.062341  [64000/70010]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.093508 

Epoch 41
-------------------------------
loss: 0.053136  [    0/70010]
loss: 0.028350  [ 6400/70010]
loss: 0.074983  [12800/70010]
loss: 0.056190  [19200/70010]
loss: 0.082405  [25600/70010]
loss: 0.092081  [32000/70010]
loss: 0.093484  [38400/70010]
loss: 0.057139  [44800/70010]
loss: 0.212515  [51200/70010]
loss: 0.126240  [57600/70010]
loss: 0.020890  [64000/70010]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.103087 

Epoch 42
-------------------------------
loss: 0.080589  [    0/70010]
loss: 0.080340  [ 6400/70010]
loss: 0.065696  [12800/70010]
loss: 0.112386  [19200/70010]
loss: 0.194305  [25600/70010]
loss: 0.096591  [32000/70010]
loss: 0.063193  [38400/70010]
loss: 0.098023  [44800/70010]
loss: 0.077317  [51200/70010]
loss: 0.064260  [57600/70010]
loss: 0.087542  [64000/70010]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.094071 

Epoch 43
-------------------------------
loss: 0.144568  [    0/70010]
loss: 0.030391  [ 6400/70010]
loss: 0.139731  [12800/70010]
loss: 0.052544  [19200/70010]
loss: 0.038878  [25600/70010]
loss: 0.056525  [32000/70010]
loss: 0.116277  [38400/70010]
loss: 0.097092  [44800/70010]
loss: 0.021022  [51200/70010]
loss: 0.084092  [57600/70010]
loss: 0.031265  [64000/70010]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.092772 

Epoch 44
-------------------------------
loss: 0.109171  [    0/70010]
loss: 0.063913  [ 6400/70010]
loss: 0.077147  [12800/70010]
loss: 0.041208  [19200/70010]
loss: 0.063978  [25600/70010]
loss: 0.031467  [32000/70010]
loss: 0.192718  [38400/70010]
loss: 0.050665  [44800/70010]
loss: 0.086728  [51200/70010]
loss: 0.070546  [57600/70010]
loss: 0.051532  [64000/70010]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.091278 

Epoch 45
-------------------------------
loss: 0.073004  [    0/70010]
loss: 0.081810  [ 6400/70010]
loss: 0.027473  [12800/70010]
loss: 0.102094  [19200/70010]
loss: 0.061265  [25600/70010]
loss: 0.024609  [32000/70010]
loss: 0.098441  [38400/70010]
loss: 0.023667  [44800/70010]
loss: 0.082148  [51200/70010]
loss: 0.100093  [57600/70010]
loss: 0.040948  [64000/70010]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.092347 

Epoch 46
-------------------------------
loss: 0.070616  [    0/70010]
loss: 0.084389  [ 6400/70010]
loss: 0.066496  [12800/70010]
loss: 0.034167  [19200/70010]
loss: 0.051376  [25600/70010]
loss: 0.097033  [32000/70010]
loss: 0.092977  [38400/70010]
loss: 0.065785  [44800/70010]
loss: 0.019294  [51200/70010]
loss: 0.033252  [57600/70010]
loss: 0.070991  [64000/70010]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.105284 

Epoch 47
-------------------------------
loss: 0.048794  [    0/70010]
loss: 0.075648  [ 6400/70010]
loss: 0.065637  [12800/70010]
loss: 0.007185  [19200/70010]
loss: 0.019805  [25600/70010]
loss: 0.117619  [32000/70010]
loss: 0.089739  [38400/70010]
loss: 0.050516  [44800/70010]
loss: 0.094311  [51200/70010]
loss: 0.016619  [57600/70010]
loss: 0.064599  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085698 

Epoch 48
-------------------------------
loss: 0.042612  [    0/70010]
loss: 0.051838  [ 6400/70010]
loss: 0.133708  [12800/70010]
loss: 0.068194  [19200/70010]
loss: 0.195070  [25600/70010]
loss: 0.058539  [32000/70010]
loss: 0.015604  [38400/70010]
loss: 0.079200  [44800/70010]
loss: 0.131474  [38400/70482]
loss: 0.176159  [44800/70482]
loss: 0.208740  [51200/70482]
loss: 0.124972  [57600/70482]
loss: 0.116135  [64000/70482]
loss: 0.103384  [70400/70482]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.137532 

Epoch 28
-------------------------------
loss: 0.106085  [    0/70482]
loss: 0.123204  [ 6400/70482]
loss: 0.107432  [12800/70482]
loss: 0.177103  [19200/70482]
loss: 0.133270  [25600/70482]
loss: 0.087658  [32000/70482]
loss: 0.174777  [38400/70482]
loss: 0.081635  [44800/70482]
loss: 0.029358  [51200/70482]
loss: 0.112303  [57600/70482]
loss: 0.113690  [64000/70482]
loss: 0.154097  [70400/70482]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.157613 

Epoch 29
-------------------------------
loss: 0.069746  [    0/70482]
loss: 0.092347  [ 6400/70482]
loss: 0.138229  [12800/70482]
loss: 0.130449  [19200/70482]
loss: 0.174154  [25600/70482]
loss: 0.065971  [32000/70482]
loss: 0.131000  [38400/70482]
loss: 0.079173  [44800/70482]
loss: 0.096428  [51200/70482]
loss: 0.064303  [57600/70482]
loss: 0.162780  [64000/70482]
loss: 0.088958  [70400/70482]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.143421 

Epoch 30
-------------------------------
loss: 0.047820  [    0/70482]
loss: 0.164150  [ 6400/70482]
loss: 0.206612  [12800/70482]
loss: 0.091486  [19200/70482]
loss: 0.196802  [25600/70482]
loss: 0.120600  [32000/70482]
loss: 0.116635  [38400/70482]
loss: 0.122510  [44800/70482]
loss: 0.096192  [51200/70482]
loss: 0.051663  [57600/70482]
loss: 0.113026  [64000/70482]
loss: 0.143160  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.142328 

Epoch 31
-------------------------------
loss: 0.075067  [    0/70482]
loss: 0.074352  [ 6400/70482]
loss: 0.052779  [12800/70482]
loss: 0.103297  [19200/70482]
loss: 0.244813  [25600/70482]
loss: 0.049036  [32000/70482]
loss: 0.144976  [38400/70482]
loss: 0.068214  [44800/70482]
loss: 0.304389  [51200/70482]
loss: 0.078380  [57600/70482]
loss: 0.054443  [64000/70482]
loss: 0.258701  [70400/70482]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.142953 

Epoch 32
-------------------------------
loss: 0.122877  [    0/70482]
loss: 0.192920  [ 6400/70482]
loss: 0.055005  [12800/70482]
loss: 0.106709  [19200/70482]
loss: 0.228100  [25600/70482]
loss: 0.089057  [32000/70482]
loss: 0.140749  [38400/70482]
loss: 0.057998  [44800/70482]
loss: 0.048222  [51200/70482]
loss: 0.077473  [57600/70482]
loss: 0.166754  [64000/70482]
loss: 0.209834  [70400/70482]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.138129 

Epoch 33
-------------------------------
loss: 0.151873  [    0/70482]
loss: 0.107221  [ 6400/70482]
loss: 0.059512  [12800/70482]
loss: 0.107700  [19200/70482]
loss: 0.073936  [25600/70482]
loss: 0.163952  [32000/70482]
loss: 0.146384  [38400/70482]
loss: 0.084900  [44800/70482]
loss: 0.102991  [51200/70482]
loss: 0.140738  [57600/70482]
loss: 0.015258  [64000/70482]
loss: 0.066686  [70400/70482]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.138493 

Epoch 34
-------------------------------
loss: 0.126575  [    0/70482]
loss: 0.080096  [ 6400/70482]
loss: 0.074362  [12800/70482]
loss: 0.117354  [19200/70482]
loss: 0.099683  [25600/70482]
loss: 0.188200  [32000/70482]
loss: 0.088238  [38400/70482]
loss: 0.107818  [44800/70482]
loss: 0.150359  [51200/70482]
loss: 0.186068  [57600/70482]
loss: 0.160424  [64000/70482]
loss: 0.270926  [70400/70482]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.142121 

Epoch 35
-------------------------------
loss: 0.131497  [    0/70482]
loss: 1.595406  [ 6400/70482]
loss: 0.266580  [12800/70482]
loss: 0.137604  [19200/70482]
loss: 0.049924  [25600/70482]
loss: 0.041576  [32000/70482]
loss: 0.094267  [38400/70482]
loss: 0.274850  [44800/70482]
loss: 0.228950  [51200/70482]
loss: 0.056645  [57600/70482]
loss: 0.117493  [64000/70482]
loss: 0.124644  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.151757 

Epoch 36
-------------------------------
loss: 0.167292  [    0/70482]
loss: 0.118688  [ 6400/70482]
loss: 0.225839  [12800/70482]
loss: 0.202169  [19200/70482]
loss: 0.124798  [25600/70482]
loss: 0.134137  [32000/70482]
loss: 0.089507  [38400/70482]
loss: 0.185046  [44800/70482]
loss: 0.128810  [51200/70482]
loss: 0.028660  [57600/70482]
loss: 0.173223  [64000/70482]
loss: 0.083199  [70400/70482]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146040 

Epoch 37
-------------------------------
loss: 0.156649  [    0/70482]
loss: 0.068789  [ 6400/70482]
loss: 0.069675  [12800/70482]
loss: 0.152534  [19200/70482]
loss: 0.163183  [25600/70482]
loss: 0.057880  [32000/70482]
loss: 0.202475  [38400/70482]
loss: 0.093827  [44800/70482]
loss: 0.255610  [51200/70482]
loss: 0.194509  [57600/70482]
loss: 0.188720  [64000/70482]
loss: 0.065672  [70400/70482]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.147480 

Epoch 38
-------------------------------
loss: 0.265895  [    0/70482]
loss: 0.094428  [ 6400/70482]
loss: 0.144113  [12800/70482]
loss: 0.110778  [19200/70482]
loss: 0.082416  [25600/70482]
loss: 0.105657  [32000/70482]
loss: 0.148927  [38400/70482]
loss: 0.090706  [44800/70482]
loss: 0.130995  [51200/70482]
loss: 0.052476  [57600/70482]
loss: 0.331856  [64000/70482]
loss: 0.202397  [70400/70482]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.144075 

Epoch 39
-------------------------------
loss: 0.055027  [    0/70482]
loss: 0.148211  [ 6400/70482]
loss: 0.134737  [12800/70482]
loss: 0.158331  [19200/70482]
loss: 0.143173  [25600/70482]
loss: 0.059349  [32000/70482]
loss: 0.197650  [38400/70482]
loss: 0.080216  [44800/70482]
loss: 0.135929  [51200/70482]
loss: 0.060945  [57600/70482]
loss: 0.120757  [64000/70482]
loss: 0.121541  [70400/70482]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.145025 

Epoch 40
-------------------------------
loss: 0.037633  [    0/70482]
loss: 0.076726  [ 6400/70482]
loss: 0.143514  [12800/70482]
loss: 0.131035  [19200/70482]
loss: 0.071619  [25600/70482]
loss: 0.140002  [32000/70482]
loss: 0.124601  [38400/70482]
loss: 0.065546  [44800/70482]
loss: 0.026363  [51200/70482]
loss: 0.194769  [57600/70482]
loss: 0.153618  [64000/70482]
loss: 0.078635  [70400/70482]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140362 

Epoch 41
-------------------------------
loss: 0.108226  [    0/70482]
loss: 0.257686  [ 6400/70482]
loss: 0.134576  [12800/70482]
loss: 0.168795  [19200/70482]
loss: 0.111751  [25600/70482]
loss: 0.046107  [32000/70482]
loss: 0.071186  [38400/70482]
loss: 0.053442  [44800/70482]
loss: 0.239580  [51200/70482]
loss: 0.131360  [57600/70482]
loss: 0.148853  [64000/70482]
loss: 0.149953  [70400/70482]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.137204 

Epoch 42
-------------------------------
loss: 0.084513  [    0/70482]
loss: 0.059222  [ 6400/70482]
loss: 0.136550  [12800/70482]
loss: 0.129336  [19200/70482]
loss: 0.114055  [25600/70482]
loss: 0.082718  [32000/70482]
loss: 0.114584  [38400/70482]
loss: 0.127074  [44800/70482]
loss: 0.052204  [51200/70482]
loss: 0.155110  [57600/70482]
loss: 0.128679  [64000/70482]
loss: 0.137484  [70400/70482]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.145915 

Epoch 43
-------------------------------
loss: 0.155973  [    0/70482]
loss: 0.031967  [ 6400/70482]
loss: 0.113748  [12800/70482]
loss: 0.171614  [19200/70482]
loss: 0.109161  [25600/70482]
loss: 0.063932  [32000/70482]
loss: 0.126952  [38400/70482]
loss: 0.067119  [44800/70482]
loss: 1.725099  [51200/70482]
loss: 0.227741  [57600/70482]
loss: 0.069680  [64000/70482]
loss: 0.220509  [70400/70482]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.143135 

Epoch 44
-------------------------------
loss: 0.159352  [    0/70482]
loss: 0.087021  [ 6400/70482]
loss: 0.177873  [12800/70482]
loss: 0.104060  [19200/70482]
loss: 0.120529  [25600/70482]
loss: 0.233785  [32000/70482]
loss: 0.116856  [38400/70482]
loss: 0.196015  [44800/70482]
loss: 0.111169  [51200/70482]
loss: 0.158765  [57600/70482]
loss: 0.132260  [64000/70482]
loss: 0.083061  [70400/70482]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.145928 

Epoch 45
-------------------------------
loss: 0.166353  [    0/70482]
loss: 0.076132  [ 6400/70482]
loss: 0.289296  [12800/70482]
loss: 0.132517  [19200/70482]
loss: 0.128146  [25600/70482]
loss: 0.254811  [32000/70482]
loss: 0.062827  [38400/70482]
2022/09/20 15:07:39 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.061356  [ 6400/69985]
loss: 0.144773  [12800/69985]
loss: 0.071941  [19200/69985]
loss: 0.037213  [25600/69985]
loss: 0.075237  [32000/69985]
loss: 0.187552  [38400/69985]
loss: 0.140753  [44800/69985]
loss: 0.065481  [51200/69985]
loss: 0.043616  [57600/69985]
loss: 0.144819  [64000/69985]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.078253 

Epoch 18
-------------------------------
loss: 0.044525  [    0/69985]
loss: 0.013065  [ 6400/69985]
loss: 0.021087  [12800/69985]
loss: 0.110683  [19200/69985]
loss: 0.073314  [25600/69985]
loss: 0.069467  [32000/69985]
loss: 0.077276  [38400/69985]
loss: 0.041680  [44800/69985]
loss: 0.031006  [51200/69985]
loss: 0.147299  [57600/69985]
loss: 0.100350  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081558 

Epoch 19
-------------------------------
loss: 0.034138  [    0/69985]
loss: 0.053056  [ 6400/69985]
loss: 0.043491  [12800/69985]
loss: 0.030498  [19200/69985]
loss: 0.050903  [25600/69985]
loss: 0.121980  [32000/69985]
loss: 0.078345  [38400/69985]
loss: 0.090640  [44800/69985]
loss: 0.230582  [51200/69985]
loss: 0.077190  [57600/69985]
loss: 0.007921  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086184 

Epoch 20
-------------------------------
loss: 0.030091  [    0/69985]
loss: 0.172880  [ 6400/69985]
loss: 0.020234  [12800/69985]
loss: 0.170942  [19200/69985]
loss: 0.183507  [25600/69985]
loss: 0.024201  [32000/69985]
loss: 0.035921  [38400/69985]
loss: 0.102307  [44800/69985]
loss: 0.077706  [51200/69985]
loss: 0.037375  [57600/69985]
loss: 0.028845  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.078854 

Epoch 21
-------------------------------
loss: 0.177960  [    0/69985]
loss: 0.064165  [ 6400/69985]
loss: 0.088051  [12800/69985]
loss: 0.167113  [19200/69985]
loss: 0.128304  [25600/69985]
loss: 0.046392  [32000/69985]
loss: 0.209542  [38400/69985]
loss: 0.039554  [44800/69985]
loss: 0.021708  [51200/69985]
loss: 0.051098  [57600/69985]
loss: 0.049303  [64000/69985]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.077268 

Epoch 22
-------------------------------
loss: 0.048402  [    0/69985]
loss: 0.056772  [ 6400/69985]
loss: 0.031515  [12800/69985]
loss: 0.090146  [19200/69985]
loss: 0.116477  [25600/69985]
loss: 0.074226  [32000/69985]
loss: 0.067383  [38400/69985]
loss: 0.048382  [44800/69985]
loss: 0.052079  [51200/69985]
loss: 0.056294  [57600/69985]
loss: 0.029228  [64000/69985]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089971 

Epoch 23
-------------------------------
loss: 0.020469  [    0/69985]
loss: 0.057868  [ 6400/69985]
loss: 0.047713  [12800/69985]
loss: 0.024482  [19200/69985]
loss: 0.120997  [25600/69985]
loss: 0.090919  [32000/69985]
loss: 0.037720  [38400/69985]
loss: 0.072932  [44800/69985]
loss: 0.028992  [51200/69985]
loss: 0.070051  [57600/69985]
loss: 0.114080  [64000/69985]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.079786 

Epoch 24
-------------------------------
loss: 0.061660  [    0/69985]
loss: 0.026513  [ 6400/69985]
loss: 0.112353  [12800/69985]
loss: 0.094592  [19200/69985]
loss: 0.118908  [25600/69985]
loss: 0.069225  [32000/69985]
loss: 0.054523  [38400/69985]
loss: 0.061310  [44800/69985]
loss: 0.128572  [51200/69985]
loss: 0.077578  [57600/69985]
loss: 0.029029  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081771 

Epoch 25
-------------------------------
loss: 0.059243  [    0/69985]
loss: 0.017232  [ 6400/69985]
loss: 0.013822  [12800/69985]
loss: 0.117742  [19200/69985]
loss: 0.021666  [25600/69985]
loss: 0.058662  [32000/69985]
loss: 0.076736  [38400/69985]
loss: 0.036613  [44800/69985]
loss: 0.210910  [51200/69985]
loss: 0.064753  [57600/69985]
loss: 0.045680  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080618 

Epoch 26
-------------------------------
loss: 0.044037  [    0/69985]
loss: 0.071083  [ 6400/69985]
loss: 0.047147  [12800/69985]
loss: 0.048633  [19200/69985]
loss: 0.041023  [25600/69985]
loss: 0.171252  [32000/69985]
loss: 0.026016  [38400/69985]
loss: 0.027621  [44800/69985]
loss: 0.074640  [51200/69985]
loss: 0.036192  [57600/69985]
loss: 0.137380  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081032 

Epoch 27
-------------------------------
loss: 0.053478  [    0/69985]
loss: 0.066216  [ 6400/69985]
loss: 0.083896  [12800/69985]
loss: 0.026995  [19200/69985]
loss: 0.122331  [25600/69985]
loss: 0.087575  [32000/69985]
loss: 0.004217  [38400/69985]
loss: 0.318961  [44800/69985]
loss: 0.018406  [51200/69985]
loss: 0.040832  [57600/69985]
loss: 0.090467  [64000/69985]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086536 

Epoch 28
-------------------------------
loss: 0.037367  [    0/69985]
loss: 0.039709  [ 6400/69985]
loss: 0.066162  [12800/69985]
loss: 0.028067  [19200/69985]
loss: 0.159966  [25600/69985]
loss: 0.007798  [32000/69985]
loss: 0.076215  [38400/69985]
loss: 0.065528  [44800/69985]
loss: 0.111012  [51200/69985]
loss: 0.044113  [57600/69985]
loss: 0.038033  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.084794 

Epoch 29
-------------------------------
loss: 0.137271  [    0/69985]
loss: 0.024272  [ 6400/69985]
loss: 0.162433  [12800/69985]
loss: 0.052758  [19200/69985]
loss: 0.034595  [25600/69985]
loss: 0.111391  [32000/69985]
loss: 0.057697  [38400/69985]
loss: 0.088866  [44800/69985]
loss: 0.153930  [51200/69985]
loss: 0.031068  [57600/69985]
loss: 0.090141  [64000/69985]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.080067 

Epoch 30
-------------------------------
loss: 0.054216  [    0/69985]
loss: 0.048187  [ 6400/69985]
loss: 0.020274  [12800/69985]
loss: 0.064726  [19200/69985]
loss: 0.043694  [25600/69985]
loss: 0.078187  [32000/69985]
loss: 0.036112  [38400/69985]
loss: 0.029908  [44800/69985]
loss: 0.083447  [51200/69985]
loss: 0.030762  [57600/69985]
loss: 0.065232  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.077607 

Epoch 31
-------------------------------
loss: 0.033932  [    0/69985]
loss: 0.058630  [ 6400/69985]
loss: 0.029712  [12800/69985]
loss: 0.041592  [19200/69985]
loss: 0.120882  [25600/69985]
loss: 0.055363  [32000/69985]
loss: 0.060500  [38400/69985]
loss: 0.185328  [44800/69985]
loss: 0.082491  [51200/69985]
loss: 0.062329  [57600/69985]
loss: 0.100705  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.079555 

Epoch 32
-------------------------------
loss: 0.104898  [    0/69985]
loss: 0.052285  [ 6400/69985]
loss: 0.050622  [12800/69985]
loss: 0.021557  [19200/69985]
loss: 0.086388  [25600/69985]
loss: 0.051838  [32000/69985]
loss: 0.162695  [38400/69985]
loss: 0.059315  [44800/69985]
loss: 0.335142  [51200/69985]
loss: 0.132981  [57600/69985]
loss: 0.082864  [64000/69985]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077019 

Epoch 33
-------------------------------
loss: 0.070182  [    0/69985]
loss: 0.068109  [ 6400/69985]
loss: 0.043677  [12800/69985]
loss: 0.036998  [19200/69985]
loss: 0.104629  [25600/69985]
loss: 0.027463  [32000/69985]
loss: 0.169058  [38400/69985]
loss: 0.042273  [44800/69985]
loss: 0.046310  [51200/69985]
loss: 0.067321  [57600/69985]
loss: 0.035011  [64000/69985]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.093510 

Epoch 34
-------------------------------
loss: 0.076318  [    0/69985]
loss: 0.032421  [ 6400/69985]
loss: 0.044196  [12800/69985]
loss: 0.056492  [19200/69985]
loss: 0.094846  [25600/69985]
loss: 0.060203  [32000/69985]
loss: 0.029008  [38400/69985]
loss: 0.121256  [44800/69985]
loss: 0.054720  [51200/69985]
loss: 0.097711  [57600/69985]
loss: 0.138033  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.089618 

Epoch 35
-------------------------------
loss: 0.090181  [    0/69985]
loss: 0.127632  [ 6400/69985]
loss: 0.121624  [12800/69985]
loss: 0.044612  [19200/69985]
loss: 0.044539  [25600/69985]
loss: 0.020631  [32000/69985]
loss: 0.032261  [38400/69985]
loss: 0.062979  [44800/69985]
loss: 0.071072  [51200/69985]
loss: 0.079864  [57600/69985]
loss: 0.064439  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082350 

Epoch 36
-------------------------------
loss: 0.194335  [    0/69985]
loss: 0.108090  [ 6400/69985]
loss: 0.076923  [12800/69985]
loss: 0.103400  [19200/69985]
loss: 0.038973  [25600/69985]
loss: 0.069980  [32000/69985]
loss: 0.007274  [19200/69822]
loss: 0.030432  [25600/69822]
loss: 0.050730  [32000/69822]
loss: 0.043674  [38400/69822]
loss: 0.145770  [44800/69822]
loss: 0.072592  [51200/69822]
loss: 0.249979  [57600/69822]
loss: 0.010876  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.074353 

Epoch 30
-------------------------------
loss: 0.037792  [    0/69822]
loss: 0.125520  [ 6400/69822]
loss: 0.069712  [12800/69822]
loss: 0.103814  [19200/69822]
loss: 0.098426  [25600/69822]
loss: 0.031007  [32000/69822]
loss: 0.021020  [38400/69822]
loss: 0.072402  [44800/69822]
loss: 0.017694  [51200/69822]
loss: 0.079933  [57600/69822]
loss: 0.180092  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072472 

Epoch 31
-------------------------------
loss: 0.133303  [    0/69822]
loss: 0.058149  [ 6400/69822]
loss: 0.042041  [12800/69822]
loss: 0.010895  [19200/69822]
loss: 0.013506  [25600/69822]
loss: 0.094312  [32000/69822]
loss: 0.059175  [38400/69822]
loss: 0.101028  [44800/69822]
loss: 0.054288  [51200/69822]
loss: 0.038441  [57600/69822]
loss: 0.185840  [64000/69822]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.085453 

Epoch 32
-------------------------------
loss: 0.024680  [    0/69822]
loss: 0.103526  [ 6400/69822]
loss: 0.042461  [12800/69822]
loss: 0.064908  [19200/69822]
loss: 0.078212  [25600/69822]
loss: 0.039639  [32000/69822]
loss: 0.038636  [38400/69822]
loss: 0.095979  [44800/69822]
loss: 0.111890  [51200/69822]
loss: 0.035292  [57600/69822]
loss: 0.035051  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073321 

Epoch 33
-------------------------------
loss: 0.036041  [    0/69822]
loss: 0.093083  [ 6400/69822]
loss: 0.017766  [12800/69822]
loss: 0.070299  [19200/69822]
loss: 0.052358  [25600/69822]
loss: 0.049140  [32000/69822]
loss: 0.105193  [38400/69822]
loss: 0.028406  [44800/69822]
loss: 0.071756  [51200/69822]
loss: 0.046719  [57600/69822]
loss: 0.020676  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.071225 

Epoch 34
-------------------------------
loss: 0.021866  [    0/69822]
loss: 0.043661  [ 6400/69822]
loss: 0.067501  [12800/69822]
loss: 0.053596  [19200/69822]
loss: 0.106509  [25600/69822]
loss: 0.045095  [32000/69822]
loss: 0.030351  [38400/69822]
loss: 0.039598  [44800/69822]
loss: 0.122579  [51200/69822]
loss: 0.119059  [57600/69822]
loss: 0.089861  [64000/69822]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.068164 

Epoch 35
-------------------------------
loss: 0.103677  [    0/69822]
loss: 0.037895  [ 6400/69822]
loss: 0.064451  [12800/69822]
loss: 0.077487  [19200/69822]
loss: 0.012345  [25600/69822]
loss: 0.096675  [32000/69822]
loss: 0.049514  [38400/69822]
loss: 0.131280  [44800/69822]
loss: 0.033634  [51200/69822]
loss: 0.022411  [57600/69822]
loss: 0.026701  [64000/69822]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073066 

Epoch 36
-------------------------------
loss: 0.044339  [    0/69822]
loss: 0.050006  [ 6400/69822]
loss: 0.101967  [12800/69822]
loss: 0.054408  [19200/69822]
loss: 0.055923  [25600/69822]
loss: 0.057995  [32000/69822]
loss: 0.036493  [38400/69822]
loss: 0.028135  [44800/69822]
loss: 0.063437  [51200/69822]
loss: 0.027595  [57600/69822]
loss: 0.136948  [64000/69822]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.068362 

Epoch 37
-------------------------------
loss: 0.010497  [    0/69822]
loss: 0.071064  [ 6400/69822]
loss: 0.041139  [12800/69822]
loss: 0.109350  [19200/69822]
loss: 0.032367  [25600/69822]
loss: 0.003451  [32000/69822]
loss: 0.038172  [38400/69822]
loss: 0.024626  [44800/69822]
loss: 0.069951  [51200/69822]
loss: 0.024890  [57600/69822]
loss: 0.087993  [64000/69822]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.076489 

Epoch 38
-------------------------------
loss: 0.092366  [    0/69822]
loss: 0.013468  [ 6400/69822]
loss: 0.043862  [12800/69822]
loss: 0.019878  [19200/69822]
loss: 0.042237  [25600/69822]
loss: 0.046123  [32000/69822]
loss: 0.086041  [38400/69822]
loss: 0.026071  [44800/69822]
loss: 0.093116  [51200/69822]
loss: 0.011753  [57600/69822]
loss: 0.008543  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.072908 

Epoch 39
-------------------------------
loss: 0.121377  [    0/69822]
loss: 0.070185  [ 6400/69822]
loss: 0.019499  [12800/69822]
loss: 0.019433  [19200/69822]
loss: 0.028845  [25600/69822]
loss: 0.023905  [32000/69822]
loss: 0.078013  [38400/69822]
loss: 0.051219  [44800/69822]
loss: 0.055379  [51200/69822]
loss: 0.033804  [57600/69822]
loss: 0.067040  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075406 

Epoch 40
-------------------------------
loss: 0.052807  [    0/69822]
loss: 0.120467  [ 6400/69822]
loss: 0.054741  [12800/69822]
loss: 0.026955  [19200/69822]
loss: 0.056693  [25600/69822]
loss: 0.019536  [32000/69822]
loss: 0.086614  [38400/69822]
loss: 0.035067  [44800/69822]
loss: 0.072138  [51200/69822]
loss: 0.155785  [57600/69822]
loss: 0.060564  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.074764 

Epoch 41
-------------------------------
loss: 0.012011  [    0/69822]
loss: 0.114495  [ 6400/69822]
loss: 0.056405  [12800/69822]
loss: 0.075988  [19200/69822]
loss: 0.097061  [25600/69822]
loss: 0.089409  [32000/69822]
loss: 0.028103  [38400/69822]
loss: 0.024547  [44800/69822]
loss: 0.022627  [51200/69822]
loss: 0.044010  [57600/69822]
loss: 0.044908  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072846 

Epoch 42
-------------------------------
loss: 0.046422  [    0/69822]
loss: 0.008125  [ 6400/69822]
loss: 0.045243  [12800/69822]
loss: 0.104831  [19200/69822]
loss: 0.007549  [25600/69822]
loss: 0.023724  [32000/69822]
loss: 0.062516  [38400/69822]
loss: 0.185292  [44800/69822]
loss: 0.037124  [51200/69822]
loss: 0.027401  [57600/69822]
loss: 0.044472  [64000/69822]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.079755 

Epoch 43
-------------------------------
loss: 0.083467  [    0/69822]
loss: 0.034372  [ 6400/69822]
loss: 0.042499  [12800/69822]
loss: 0.015133  [19200/69822]
loss: 0.051104  [25600/69822]
loss: 0.087889  [32000/69822]
loss: 0.039292  [38400/69822]
loss: 0.087850  [44800/69822]
loss: 0.039616  [51200/69822]
loss: 0.104432  [57600/69822]
loss: 0.027364  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075505 

Epoch 44
-------------------------------
loss: 0.029189  [    0/69822]
loss: 0.020796  [ 6400/69822]
loss: 0.048319  [12800/69822]
loss: 0.052093  [19200/69822]
loss: 0.034455  [25600/69822]
loss: 0.055215  [32000/69822]
loss: 0.062227  [38400/69822]
loss: 0.035210  [44800/69822]
loss: 0.030125  [51200/69822]
loss: 0.034243  [57600/69822]
loss: 0.083096  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.072215 

Epoch 45
-------------------------------
loss: 0.009202  [    0/69822]
loss: 0.102732  [ 6400/69822]
loss: 0.063039  [12800/69822]
loss: 0.054817  [19200/69822]
loss: 0.060713  [25600/69822]
loss: 0.063523  [32000/69822]
loss: 0.096474  [38400/69822]
loss: 0.011071  [44800/69822]
loss: 0.003939  [51200/69822]
loss: 0.007251  [57600/69822]
loss: 0.031204  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.075542 

Epoch 46
-------------------------------
loss: 0.056177  [    0/69822]
loss: 0.040778  [ 6400/69822]
loss: 0.064611  [12800/69822]
loss: 0.037864  [19200/69822]
loss: 0.062243  [25600/69822]
loss: 0.031886  [32000/69822]
loss: 0.006185  [38400/69822]
loss: 0.041085  [44800/69822]
loss: 0.093762  [51200/69822]
loss: 0.115745  [57600/69822]
loss: 0.019035  [64000/69822]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.072453 

Epoch 47
-------------------------------
loss: 0.160216  [    0/69822]
loss: 0.032687  [ 6400/69822]
loss: 0.054362  [12800/69822]
loss: 0.027231  [19200/69822]
loss: 0.019749  [25600/69822]
loss: 0.013064  [32000/69822]
loss: 0.077552  [38400/69822]
loss: 0.016845  [44800/69822]
loss: 0.130709  [51200/69822]
loss: 0.116599  [57600/69822]
loss: 0.135212  [64000/69822]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073755 

Epoch 48
-------------------------------
loss: 0.072069  [    0/69822]
loss: 0.027897  [ 6400/69822]
loss: 0.018500  [12800/69822]
loss: 0.060799  [19200/69822]
loss: 0.021436  [25600/69822]
loss: 0.150031  [32000/69822]
loss: 0.053909  [38400/69822]
loss: 0.096991  [44800/69822]
2022/09/20 15:10:47 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.087258  [38400/70555]
loss: 0.037695  [44800/70555]
loss: 0.094679  [51200/70555]
loss: 0.102871  [57600/70555]
loss: 0.118892  [64000/70555]
loss: 0.041693  [70400/70555]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076773 

Epoch 28
-------------------------------
loss: 0.109973  [    0/70555]
loss: 0.080964  [ 6400/70555]
loss: 0.056312  [12800/70555]
loss: 0.010994  [19200/70555]
loss: 0.019308  [25600/70555]
loss: 0.042283  [32000/70555]
loss: 0.053279  [38400/70555]
loss: 0.022055  [44800/70555]
loss: 0.101657  [51200/70555]
loss: 0.149622  [57600/70555]
loss: 0.063248  [64000/70555]
loss: 0.056448  [70400/70555]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078412 

Epoch 29
-------------------------------
loss: 0.061336  [    0/70555]
loss: 0.036423  [ 6400/70555]
loss: 0.089746  [12800/70555]
loss: 0.089539  [19200/70555]
loss: 0.080987  [25600/70555]
loss: 0.019432  [32000/70555]
loss: 0.156205  [38400/70555]
loss: 0.102033  [44800/70555]
loss: 0.071844  [51200/70555]
loss: 0.068171  [57600/70555]
loss: 0.087573  [64000/70555]
loss: 0.121122  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081550 

Epoch 30
-------------------------------
loss: 0.041571  [    0/70555]
loss: 0.026081  [ 6400/70555]
loss: 0.020069  [12800/70555]
loss: 0.029978  [19200/70555]
loss: 0.044853  [25600/70555]
loss: 0.183139  [32000/70555]
loss: 0.063177  [38400/70555]
loss: 0.031559  [44800/70555]
loss: 0.060048  [51200/70555]
loss: 0.062971  [57600/70555]
loss: 0.039536  [64000/70555]
loss: 0.067550  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.083184 

Epoch 31
-------------------------------
loss: 0.014946  [    0/70555]
loss: 0.027092  [ 6400/70555]
loss: 0.072746  [12800/70555]
loss: 0.054393  [19200/70555]
loss: 0.054215  [25600/70555]
loss: 0.077838  [32000/70555]
loss: 0.049597  [38400/70555]
loss: 0.077092  [44800/70555]
loss: 0.119201  [51200/70555]
loss: 0.081397  [57600/70555]
loss: 0.026018  [64000/70555]
loss: 0.084407  [70400/70555]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080350 

Epoch 32
-------------------------------
loss: 0.025661  [    0/70555]
loss: 0.069989  [ 6400/70555]
loss: 0.030042  [12800/70555]
loss: 0.063016  [19200/70555]
loss: 0.080283  [25600/70555]
loss: 0.144207  [32000/70555]
loss: 0.042830  [38400/70555]
loss: 0.091191  [44800/70555]
loss: 0.068128  [51200/70555]
loss: 0.078187  [57600/70555]
loss: 0.073144  [64000/70555]
loss: 0.078425  [70400/70555]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.098178 

Epoch 33
-------------------------------
loss: 0.044477  [    0/70555]
loss: 0.053504  [ 6400/70555]
loss: 0.018914  [12800/70555]
loss: 0.095250  [19200/70555]
loss: 0.062471  [25600/70555]
loss: 0.041035  [32000/70555]
loss: 0.077942  [38400/70555]
loss: 0.082795  [44800/70555]
loss: 0.096349  [51200/70555]
loss: 0.070830  [57600/70555]
loss: 0.134569  [64000/70555]
loss: 0.043956  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086393 

Epoch 34
-------------------------------
loss: 0.050567  [    0/70555]
loss: 0.063358  [ 6400/70555]
loss: 0.044975  [12800/70555]
loss: 0.149964  [19200/70555]
loss: 0.007960  [25600/70555]
loss: 0.114487  [32000/70555]
loss: 0.124678  [38400/70555]
loss: 0.106955  [44800/70555]
loss: 0.139447  [51200/70555]
loss: 0.065602  [57600/70555]
loss: 0.055036  [64000/70555]
loss: 0.122812  [70400/70555]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.091991 

Epoch 35
-------------------------------
loss: 0.131783  [    0/70555]
loss: 0.060713  [ 6400/70555]
loss: 0.111213  [12800/70555]
loss: 0.084586  [19200/70555]
loss: 0.087369  [25600/70555]
loss: 0.071592  [32000/70555]
loss: 0.029562  [38400/70555]
loss: 0.095085  [44800/70555]
loss: 0.071517  [51200/70555]
loss: 0.062661  [57600/70555]
loss: 0.062531  [64000/70555]
loss: 0.100633  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084635 

Epoch 36
-------------------------------
loss: 0.128366  [    0/70555]
loss: 0.046374  [ 6400/70555]
loss: 0.082047  [12800/70555]
loss: 0.023413  [19200/70555]
loss: 0.110168  [25600/70555]
loss: 0.087567  [32000/70555]
loss: 0.126480  [38400/70555]
loss: 0.142956  [44800/70555]
loss: 0.096472  [51200/70555]
loss: 0.073204  [57600/70555]
loss: 0.087412  [64000/70555]
loss: 0.035547  [70400/70555]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.084697 

Epoch 37
-------------------------------
loss: 0.009752  [    0/70555]
loss: 0.063282  [ 6400/70555]
loss: 0.056309  [12800/70555]
loss: 0.061030  [19200/70555]
loss: 0.118007  [25600/70555]
loss: 0.107359  [32000/70555]
loss: 0.052642  [38400/70555]
loss: 0.058699  [44800/70555]
loss: 0.051651  [51200/70555]
loss: 0.028599  [57600/70555]
loss: 0.159632  [64000/70555]
loss: 0.112821  [70400/70555]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.087684 

Epoch 38
-------------------------------
loss: 0.055357  [    0/70555]
loss: 0.062969  [ 6400/70555]
loss: 0.050805  [12800/70555]
loss: 0.049280  [19200/70555]
loss: 0.033170  [25600/70555]
loss: 0.086095  [32000/70555]
loss: 0.047286  [38400/70555]
loss: 0.075708  [44800/70555]
loss: 0.070223  [51200/70555]
loss: 0.081333  [57600/70555]
loss: 0.078560  [64000/70555]
loss: 0.071794  [70400/70555]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089297 

Epoch 39
-------------------------------
loss: 0.014750  [    0/70555]
loss: 0.367665  [ 6400/70555]
loss: 0.047873  [12800/70555]
loss: 0.415986  [19200/70555]
loss: 0.282053  [25600/70555]
loss: 0.020875  [32000/70555]
loss: 0.098865  [38400/70555]
loss: 0.035239  [44800/70555]
loss: 0.081379  [51200/70555]
loss: 0.067788  [57600/70555]
loss: 0.092653  [64000/70555]
loss: 0.033857  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.081861 

Epoch 40
-------------------------------
loss: 0.049463  [    0/70555]
loss: 0.039469  [ 6400/70555]
loss: 0.025788  [12800/70555]
loss: 0.008930  [19200/70555]
loss: 0.029905  [25600/70555]
loss: 0.097316  [32000/70555]
loss: 0.051797  [38400/70555]
loss: 0.019018  [44800/70555]
loss: 0.114456  [51200/70555]
loss: 0.041966  [57600/70555]
loss: 0.082827  [64000/70555]
loss: 0.041977  [70400/70555]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080902 

Epoch 41
-------------------------------
loss: 0.072615  [    0/70555]
loss: 0.047170  [ 6400/70555]
loss: 0.116952  [12800/70555]
loss: 0.080906  [19200/70555]
loss: 0.036983  [25600/70555]
loss: 0.017420  [32000/70555]
loss: 0.079228  [38400/70555]
loss: 0.050782  [44800/70555]
loss: 0.102776  [51200/70555]
loss: 0.017973  [57600/70555]
loss: 0.136774  [64000/70555]
loss: 0.067113  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081907 

Epoch 42
-------------------------------
loss: 0.019972  [    0/70555]
loss: 0.104426  [ 6400/70555]
loss: 0.073643  [12800/70555]
loss: 0.038814  [19200/70555]
loss: 0.055241  [25600/70555]
loss: 0.064289  [32000/70555]
loss: 0.029796  [38400/70555]
loss: 0.083548  [44800/70555]
loss: 0.094638  [51200/70555]
loss: 0.034281  [57600/70555]
loss: 0.077750  [64000/70555]
loss: 0.038292  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.085093 

Epoch 43
-------------------------------
loss: 0.030238  [    0/70555]
loss: 0.018034  [ 6400/70555]
loss: 0.050836  [12800/70555]
loss: 0.083230  [19200/70555]
loss: 0.023054  [25600/70555]
loss: 0.054887  [32000/70555]
loss: 0.083576  [38400/70555]
loss: 0.004773  [44800/70555]
loss: 0.067923  [51200/70555]
loss: 0.191723  [57600/70555]
loss: 0.106756  [64000/70555]
loss: 0.067220  [70400/70555]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.082021 

Epoch 44
-------------------------------
loss: 0.047994  [    0/70555]
loss: 0.026597  [ 6400/70555]
loss: 0.089332  [12800/70555]
loss: 0.074452  [19200/70555]
loss: 0.067551  [25600/70555]
loss: 0.130759  [32000/70555]
loss: 0.017488  [38400/70555]
loss: 0.030794  [44800/70555]
loss: 0.141963  [51200/70555]
loss: 0.022996  [57600/70555]
loss: 0.026136  [64000/70555]
loss: 0.125801  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084551 

Epoch 45
-------------------------------
loss: 0.041308  [    0/70555]
loss: 0.018116  [ 6400/70555]
loss: 0.075228  [12800/70555]
loss: 0.057249  [19200/70555]
loss: 0.077231  [25600/70555]
loss: 0.038415  [32000/70555]
loss: 0.038172  [38400/70555]
loss: 0.112923  [38400/71235]
loss: 0.104709  [44800/71235]
loss: 0.060055  [51200/71235]
loss: 0.051616  [57600/71235]
loss: 0.146778  [64000/71235]
loss: 0.023366  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110404 

Epoch 28
-------------------------------
loss: 0.046057  [    0/71235]
loss: 0.065456  [ 6400/71235]
loss: 0.090258  [12800/71235]
loss: 0.121967  [19200/71235]
loss: 0.088394  [25600/71235]
loss: 0.044846  [32000/71235]
loss: 0.041461  [38400/71235]
loss: 0.103963  [44800/71235]
loss: 1.626536  [51200/71235]
loss: 0.211408  [57600/71235]
loss: 0.022967  [64000/71235]
loss: 0.136367  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.107822 

Epoch 29
-------------------------------
loss: 0.030715  [    0/71235]
loss: 0.075992  [ 6400/71235]
loss: 0.067140  [12800/71235]
loss: 0.007836  [19200/71235]
loss: 0.028908  [25600/71235]
loss: 0.154131  [32000/71235]
loss: 0.078650  [38400/71235]
loss: 0.101057  [44800/71235]
loss: 0.052551  [51200/71235]
loss: 0.078495  [57600/71235]
loss: 0.046909  [64000/71235]
loss: 0.101579  [70400/71235]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.110375 

Epoch 30
-------------------------------
loss: 0.018989  [    0/71235]
loss: 0.044395  [ 6400/71235]
loss: 0.051203  [12800/71235]
loss: 0.077284  [19200/71235]
loss: 0.041705  [25600/71235]
loss: 0.028976  [32000/71235]
loss: 0.094908  [38400/71235]
loss: 0.094786  [44800/71235]
loss: 0.063391  [51200/71235]
loss: 0.021504  [57600/71235]
loss: 0.021691  [64000/71235]
loss: 0.123321  [70400/71235]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.106193 

Epoch 31
-------------------------------
loss: 0.038857  [    0/71235]
loss: 0.066250  [ 6400/71235]
loss: 0.107626  [12800/71235]
loss: 0.048686  [19200/71235]
loss: 0.145140  [25600/71235]
loss: 0.074488  [32000/71235]
loss: 0.063386  [38400/71235]
loss: 0.038025  [44800/71235]
loss: 0.075098  [51200/71235]
loss: 0.102130  [57600/71235]
loss: 0.161221  [64000/71235]
loss: 0.167647  [70400/71235]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.293557 

Epoch 32
-------------------------------
loss: 0.292851  [    0/71235]
loss: 0.043454  [ 6400/71235]
loss: 0.241478  [12800/71235]
loss: 0.014008  [19200/71235]
loss: 0.069311  [25600/71235]
loss: 0.025242  [32000/71235]
loss: 0.080585  [38400/71235]
loss: 0.085792  [44800/71235]
loss: 0.071601  [51200/71235]
loss: 0.040941  [57600/71235]
loss: 0.076924  [64000/71235]
loss: 0.060546  [70400/71235]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.113451 

Epoch 33
-------------------------------
loss: 0.026145  [    0/71235]
loss: 0.059627  [ 6400/71235]
loss: 0.015688  [12800/71235]
loss: 0.071219  [19200/71235]
loss: 0.115025  [25600/71235]
loss: 0.065600  [32000/71235]
loss: 0.022897  [38400/71235]
loss: 0.053361  [44800/71235]
loss: 0.055341  [51200/71235]
loss: 0.018255  [57600/71235]
loss: 0.045859  [64000/71235]
loss: 0.075881  [70400/71235]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.120513 

Epoch 34
-------------------------------
loss: 0.053279  [    0/71235]
loss: 0.086408  [ 6400/71235]
loss: 0.011037  [12800/71235]
loss: 0.084970  [19200/71235]
loss: 0.047956  [25600/71235]
loss: 0.066714  [32000/71235]
loss: 0.052804  [38400/71235]
loss: 0.164153  [44800/71235]
loss: 0.033260  [51200/71235]
loss: 0.048468  [57600/71235]
loss: 0.110080  [64000/71235]
loss: 0.074933  [70400/71235]
Test Error: 
 Accuracy: 83.5%, Avg loss: 0.452388 

Epoch 35
-------------------------------
loss: 0.261507  [    0/71235]
loss: 0.068936  [ 6400/71235]
loss: 0.107861  [12800/71235]
loss: 0.191138  [19200/71235]
loss: 0.055962  [25600/71235]
loss: 0.049673  [32000/71235]
loss: 0.094313  [38400/71235]
loss: 0.062210  [44800/71235]
loss: 0.077446  [51200/71235]
loss: 0.035145  [57600/71235]
loss: 0.068092  [64000/71235]
loss: 0.046029  [70400/71235]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.109669 

Epoch 36
-------------------------------
loss: 0.045194  [    0/71235]
loss: 0.047869  [ 6400/71235]
loss: 0.076025  [12800/71235]
loss: 0.089302  [19200/71235]
loss: 0.025793  [25600/71235]
loss: 0.135690  [32000/71235]
loss: 0.107346  [38400/71235]
loss: 0.018232  [44800/71235]
loss: 0.068031  [51200/71235]
loss: 0.044151  [57600/71235]
loss: 0.145751  [64000/71235]
loss: 0.028008  [70400/71235]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.268562 

Epoch 37
-------------------------------
loss: 0.098365  [    0/71235]
loss: 0.053278  [ 6400/71235]
loss: 0.071180  [12800/71235]
loss: 0.052664  [19200/71235]
loss: 0.058315  [25600/71235]
loss: 0.047572  [32000/71235]
loss: 0.048422  [38400/71235]
loss: 0.091450  [44800/71235]
loss: 0.055196  [51200/71235]
loss: 0.036193  [57600/71235]
loss: 0.090104  [64000/71235]
loss: 0.022897  [70400/71235]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.109306 

Epoch 38
-------------------------------
loss: 0.106444  [    0/71235]
loss: 0.045106  [ 6400/71235]
loss: 0.024621  [12800/71235]
loss: 0.007094  [19200/71235]
loss: 0.060631  [25600/71235]
loss: 0.071469  [32000/71235]
loss: 0.097314  [38400/71235]
loss: 0.081474  [44800/71235]
loss: 0.092328  [51200/71235]
loss: 0.048841  [57600/71235]
loss: 0.068600  [64000/71235]
loss: 0.165122  [70400/71235]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.118511 

Epoch 39
-------------------------------
loss: 0.072317  [    0/71235]
loss: 0.223535  [ 6400/71235]
loss: 0.106503  [12800/71235]
loss: 0.089712  [19200/71235]
loss: 0.100402  [25600/71235]
loss: 0.109278  [32000/71235]
loss: 0.204287  [38400/71235]
loss: 0.041728  [44800/71235]
loss: 0.076359  [51200/71235]
loss: 0.058314  [57600/71235]
loss: 0.043145  [64000/71235]
loss: 0.111165  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110146 

Epoch 40
-------------------------------
loss: 0.051550  [    0/71235]
loss: 0.091639  [ 6400/71235]
loss: 0.047210  [12800/71235]
loss: 0.096559  [19200/71235]
loss: 0.051667  [25600/71235]
loss: 0.031266  [32000/71235]
loss: 0.077581  [38400/71235]
loss: 0.233640  [44800/71235]
loss: 0.069669  [51200/71235]
loss: 0.063711  [57600/71235]
loss: 0.018116  [64000/71235]
loss: 0.055716  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.113818 

Epoch 41
-------------------------------
loss: 0.074355  [    0/71235]
loss: 0.067871  [ 6400/71235]
loss: 0.044116  [12800/71235]
loss: 0.062754  [19200/71235]
loss: 0.043704  [25600/71235]
loss: 0.029413  [32000/71235]
loss: 0.066720  [38400/71235]
loss: 0.106009  [44800/71235]
loss: 0.079575  [51200/71235]
loss: 0.057683  [57600/71235]
loss: 0.052267  [64000/71235]
loss: 0.086747  [70400/71235]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.110203 

Epoch 42
-------------------------------
loss: 0.161736  [    0/71235]
loss: 0.078646  [ 6400/71235]
loss: 0.074958  [12800/71235]
loss: 0.042805  [19200/71235]
loss: 0.243290  [25600/71235]
loss: 0.042115  [32000/71235]
loss: 0.116862  [38400/71235]
loss: 0.172189  [44800/71235]
loss: 0.064254  [51200/71235]
loss: 0.043862  [57600/71235]
loss: 0.153264  [64000/71235]
loss: 0.090557  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.108137 

Epoch 43
-------------------------------
loss: 0.057686  [    0/71235]
loss: 0.059971  [ 6400/71235]
loss: 0.032041  [12800/71235]
loss: 0.044529  [19200/71235]
loss: 0.032729  [25600/71235]
loss: 0.121428  [32000/71235]
loss: 0.118848  [38400/71235]
loss: 0.053571  [44800/71235]
loss: 0.146451  [51200/71235]
loss: 0.026759  [57600/71235]
loss: 0.097100  [64000/71235]
loss: 0.060669  [70400/71235]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.103983 

Epoch 44
-------------------------------
loss: 0.084321  [    0/71235]
loss: 0.080416  [ 6400/71235]
loss: 0.094542  [12800/71235]
loss: 0.041825  [19200/71235]
loss: 0.105351  [25600/71235]
loss: 0.054577  [32000/71235]
loss: 0.094180  [38400/71235]
loss: 0.018120  [44800/71235]
loss: 0.118944  [51200/71235]
loss: 0.039869  [57600/71235]
loss: 0.139417  [64000/71235]
loss: 0.052756  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.106914 

Epoch 45
-------------------------------
loss: 0.013849  [    0/71235]
loss: 0.015159  [ 6400/71235]
loss: 0.118274  [12800/71235]
loss: 0.092974  [19200/71235]
loss: 0.094996  [25600/71235]
loss: 0.096243  [32000/71235]
loss: 0.024044  [38400/71235]
2022/09/20 15:12:46 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:13:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:13:23 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:13:38 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.282367  [16500/70415]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.161187 

Epoch 31
-------------------------------
loss: 0.135844  [    0/70415]
loss: 0.053324  [ 6400/70415]
loss: 0.106929  [12800/70415]
loss: 0.067277  [19200/70415]
loss: 0.050142  [25600/70415]
loss: 0.065720  [32000/70415]
loss: 0.044453  [38400/70415]
loss: 0.085897  [44800/70415]
loss: 0.014838  [51200/70415]
loss: 0.102158  [57600/70415]
loss: 0.080436  [64000/70415]
loss: 0.051332  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.121960 

Epoch 32
-------------------------------
loss: 0.032072  [    0/70415]
loss: 0.051932  [ 6400/70415]
loss: 0.163582  [12800/70415]
loss: 0.093272  [19200/70415]
loss: 0.157258  [25600/70415]
loss: 0.148003  [32000/70415]
loss: 0.102043  [38400/70415]
loss: 0.028103  [44800/70415]
loss: 0.071851  [51200/70415]
loss: 0.043257  [57600/70415]
loss: 0.071526  [64000/70415]
loss: 0.020943  [16500/70415]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.110109 

Epoch 33
-------------------------------
loss: 0.067969  [    0/70415]
loss: 0.088362  [ 6400/70415]
loss: 0.077314  [12800/70415]
loss: 0.110438  [19200/70415]
loss: 0.041524  [25600/70415]
loss: 0.031230  [32000/70415]
loss: 0.091927  [38400/70415]
loss: 0.119334  [44800/70415]
loss: 0.148744  [51200/70415]
loss: 0.049080  [57600/70415]
loss: 0.028124  [64000/70415]
loss: 0.009402  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.128668 

Epoch 34
-------------------------------
loss: 0.138456  [    0/70415]
loss: 0.009680  [ 6400/70415]
loss: 0.038848  [12800/70415]
loss: 0.083816  [19200/70415]
loss: 0.043478  [25600/70415]
loss: 0.047131  [32000/70415]
loss: 0.080328  [38400/70415]
loss: 0.046987  [44800/70415]
loss: 0.077923  [51200/70415]
loss: 0.122395  [57600/70415]
loss: 0.102816  [64000/70415]
loss: 0.000716  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.117678 

Epoch 35
-------------------------------
loss: 0.058395  [    0/70415]
loss: 0.022102  [ 6400/70415]
loss: 0.094937  [12800/70415]
loss: 0.059894  [19200/70415]
loss: 0.110033  [25600/70415]
loss: 0.055773  [32000/70415]
loss: 0.084086  [38400/70415]
loss: 0.139127  [44800/70415]
loss: 0.136709  [51200/70415]
loss: 0.086856  [57600/70415]
loss: 0.143395  [64000/70415]
loss: 0.039777  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112239 

Epoch 36
-------------------------------
loss: 0.118767  [    0/70415]
loss: 0.096373  [ 6400/70415]
loss: 0.052520  [12800/70415]
loss: 0.149568  [19200/70415]
loss: 0.103045  [25600/70415]
loss: 0.054417  [32000/70415]
loss: 0.058941  [38400/70415]
loss: 0.121440  [44800/70415]
loss: 0.195689  [51200/70415]
loss: 0.063801  [57600/70415]
loss: 0.093106  [64000/70415]
loss: 0.029958  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.118577 

Epoch 37
-------------------------------
loss: 0.204423  [    0/70415]
loss: 0.047164  [ 6400/70415]
loss: 0.174796  [12800/70415]
loss: 0.026151  [19200/70415]
loss: 0.038454  [25600/70415]
loss: 0.094539  [32000/70415]
loss: 0.075551  [38400/70415]
loss: 0.183340  [44800/70415]
loss: 0.029167  [51200/70415]
loss: 0.047076  [57600/70415]
loss: 0.058147  [64000/70415]
loss: 0.015414  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.118365 

Epoch 38
-------------------------------
loss: 0.030707  [    0/70415]
loss: 0.091049  [ 6400/70415]
loss: 0.045161  [12800/70415]
loss: 0.038992  [19200/70415]
loss: 0.023481  [25600/70415]
loss: 0.066706  [32000/70415]
loss: 0.034502  [38400/70415]
loss: 0.099720  [44800/70415]
loss: 0.057417  [51200/70415]
loss: 0.061934  [57600/70415]
loss: 0.102351  [64000/70415]
loss: 0.000482  [16500/70415]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.125960 

Epoch 39
-------------------------------
loss: 0.102054  [    0/70415]
loss: 0.108134  [ 6400/70415]
loss: 0.073673  [12800/70415]
loss: 0.061262  [19200/70415]
loss: 0.058959  [25600/70415]
loss: 0.241107  [32000/70415]
loss: 0.148370  [38400/70415]
loss: 0.143539  [44800/70415]
loss: 0.017618  [51200/70415]
loss: 0.043124  [57600/70415]
loss: 0.126485  [64000/70415]
loss: 0.067962  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110065 

Epoch 40
-------------------------------
loss: 0.064252  [    0/70415]
loss: 0.053115  [ 6400/70415]
loss: 0.133516  [12800/70415]
loss: 0.089073  [19200/70415]
loss: 0.123284  [25600/70415]
loss: 0.076157  [32000/70415]
loss: 0.078090  [38400/70415]
loss: 0.012942  [44800/70415]
loss: 0.020266  [51200/70415]
loss: 0.045198  [57600/70415]
loss: 0.057467  [64000/70415]
loss: 0.180449  [16500/70415]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.146505 

Epoch 41
-------------------------------
loss: 0.170957  [    0/70415]
loss: 0.086135  [ 6400/70415]
loss: 0.018495  [12800/70415]
loss: 0.028626  [19200/70415]
loss: 0.081465  [25600/70415]
loss: 0.078329  [32000/70415]
loss: 0.018938  [38400/70415]
loss: 0.048170  [44800/70415]
loss: 0.085231  [51200/70415]
loss: 0.096888  [57600/70415]
loss: 0.079058  [64000/70415]
loss: 0.390575  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.106621 

Epoch 42
-------------------------------
loss: 0.091188  [    0/70415]
loss: 0.086161  [ 6400/70415]
loss: 0.052371  [12800/70415]
loss: 0.054975  [19200/70415]
loss: 0.033322  [25600/70415]
loss: 0.079791  [32000/70415]
loss: 0.128385  [38400/70415]
loss: 0.021762  [44800/70415]
loss: 0.035835  [51200/70415]
loss: 0.047823  [57600/70415]
loss: 0.059970  [64000/70415]
loss: 0.247034  [16500/70415]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.119552 

Epoch 43
-------------------------------
loss: 0.100207  [    0/70415]
loss: 0.025678  [ 6400/70415]
loss: 0.096059  [12800/70415]
loss: 0.018757  [19200/70415]
loss: 0.116587  [25600/70415]
loss: 0.021477  [32000/70415]
loss: 0.030432  [38400/70415]
loss: 0.064614  [44800/70415]
loss: 0.085040  [51200/70415]
loss: 0.082389  [57600/70415]
loss: 0.093244  [64000/70415]
loss: 0.096753  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.112947 

Epoch 44
-------------------------------
loss: 0.065019  [    0/70415]
loss: 0.030949  [ 6400/70415]
loss: 0.169926  [12800/70415]
loss: 0.090237  [19200/70415]
loss: 0.097466  [25600/70415]
loss: 0.044729  [32000/70415]
loss: 0.050680  [38400/70415]
loss: 0.061938  [44800/70415]
loss: 0.065103  [51200/70415]
loss: 0.106970  [57600/70415]
loss: 0.114993  [64000/70415]
loss: 0.088320  [16500/70415]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.122855 

Epoch 45
-------------------------------
loss: 0.156842  [    0/70415]
loss: 0.137810  [ 6400/70415]
loss: 0.046270  [12800/70415]
loss: 0.027771  [19200/70415]
loss: 0.101922  [25600/70415]
loss: 0.093113  [32000/70415]
loss: 0.207730  [38400/70415]
loss: 0.113615  [44800/70415]
loss: 0.184788  [51200/70415]
loss: 0.054982  [57600/70415]
loss: 0.064853  [64000/70415]
loss: 0.001710  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.109902 

Epoch 46
-------------------------------
loss: 0.044241  [    0/70415]
loss: 0.046519  [ 6400/70415]
loss: 0.050764  [12800/70415]
loss: 0.124520  [19200/70415]
loss: 0.038031  [25600/70415]
loss: 0.084496  [32000/70415]
loss: 0.052486  [38400/70415]
loss: 0.108152  [44800/70415]
loss: 0.030097  [51200/70415]
loss: 0.040644  [57600/70415]
loss: 0.052697  [64000/70415]
loss: 0.145199  [16500/70415]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.109459 

Epoch 47
-------------------------------
loss: 0.054987  [    0/70415]
loss: 0.070730  [ 6400/70415]
loss: 0.011069  [12800/70415]
loss: 0.082601  [19200/70415]
loss: 0.079237  [25600/70415]
loss: 0.018260  [32000/70415]
loss: 0.085898  [38400/70415]
loss: 0.052699  [44800/70415]
loss: 0.079076  [51200/70415]
loss: 0.102470  [57600/70415]
loss: 0.103843  [64000/70415]
loss: 0.017381  [16500/70415]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.108460 

Epoch 48
-------------------------------
loss: 0.033907  [    0/70415]
loss: 0.048063  [ 6400/70415]
loss: 0.016965  [12800/70415]
loss: 0.040943  [19200/70415]
loss: 0.053643  [25600/70415]
loss: 0.025706  [32000/70415]
loss: 0.070042  [38400/70415]
loss: 0.078812  [44800/70415]
loss: 0.039713  [51200/70415]
loss: 0.066092  [57600/70415]
loss: 0.037380  [64000/70415]
loss: 0.019331  [16500/70415]
loss: 0.104638  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075967 

Epoch 31
-------------------------------
loss: 0.028394  [    0/72227]
loss: 0.018405  [ 6400/72227]
loss: 0.017449  [12800/72227]
loss: 0.082591  [19200/72227]
loss: 0.078111  [25600/72227]
loss: 0.101476  [32000/72227]
loss: 0.007692  [38400/72227]
loss: 0.005864  [44800/72227]
loss: 0.058657  [51200/72227]
loss: 0.032584  [57600/72227]
loss: 0.082510  [64000/72227]
loss: 0.014445  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.084293 

Epoch 32
-------------------------------
loss: 0.068928  [    0/72227]
loss: 0.033121  [ 6400/72227]
loss: 0.007288  [12800/72227]
loss: 0.005655  [19200/72227]
loss: 0.045213  [25600/72227]
loss: 0.008017  [32000/72227]
loss: 0.026192  [38400/72227]
loss: 0.036199  [44800/72227]
loss: 0.041452  [51200/72227]
loss: 0.011568  [57600/72227]
loss: 0.012914  [64000/72227]
loss: 0.084820  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.090785 

Epoch 33
-------------------------------
loss: 0.034356  [    0/72227]
loss: 0.014198  [ 6400/72227]
loss: 0.025055  [12800/72227]
loss: 0.065797  [19200/72227]
loss: 0.041063  [25600/72227]
loss: 0.070749  [32000/72227]
loss: 0.029517  [38400/72227]
loss: 0.037919  [44800/72227]
loss: 0.042678  [51200/72227]
loss: 0.054085  [57600/72227]
loss: 0.095342  [64000/72227]
loss: 0.076706  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.078858 

Epoch 34
-------------------------------
loss: 0.004878  [    0/72227]
loss: 0.016874  [ 6400/72227]
loss: 0.009531  [12800/72227]
loss: 0.018635  [19200/72227]
loss: 0.007246  [25600/72227]
loss: 0.028728  [32000/72227]
loss: 0.006438  [38400/72227]
loss: 0.052825  [44800/72227]
loss: 0.010208  [51200/72227]
loss: 0.111687  [57600/72227]
loss: 0.084945  [64000/72227]
loss: 0.096355  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080880 

Epoch 35
-------------------------------
loss: 0.008962  [    0/72227]
loss: 0.040372  [ 6400/72227]
loss: 0.031106  [12800/72227]
loss: 0.124311  [19200/72227]
loss: 0.014474  [25600/72227]
loss: 0.016766  [32000/72227]
loss: 0.018456  [38400/72227]
loss: 0.092440  [44800/72227]
loss: 0.005031  [51200/72227]
loss: 0.068640  [57600/72227]
loss: 0.001661  [64000/72227]
loss: 0.130214  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077510 

Epoch 36
-------------------------------
loss: 0.017051  [    0/72227]
loss: 0.011356  [ 6400/72227]
loss: 0.070184  [12800/72227]
loss: 0.012919  [19200/72227]
loss: 0.022453  [25600/72227]
loss: 0.013773  [32000/72227]
loss: 0.051443  [38400/72227]
loss: 0.032512  [44800/72227]
loss: 0.076628  [51200/72227]
loss: 0.025789  [57600/72227]
loss: 0.009592  [64000/72227]
loss: 0.008349  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076353 

Epoch 37
-------------------------------
loss: 0.038683  [    0/72227]
loss: 0.011460  [ 6400/72227]
loss: 0.033882  [12800/72227]
loss: 0.004597  [19200/72227]
loss: 0.008609  [25600/72227]
loss: 0.072937  [32000/72227]
loss: 0.013455  [38400/72227]
loss: 0.032204  [44800/72227]
loss: 0.008298  [51200/72227]
loss: 0.048729  [57600/72227]
loss: 0.048493  [64000/72227]
loss: 0.030129  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.079096 

Epoch 38
-------------------------------
loss: 0.004745  [    0/72227]
loss: 0.063799  [ 6400/72227]
loss: 0.021976  [12800/72227]
loss: 0.055235  [19200/72227]
loss: 0.002947  [25600/72227]
loss: 0.027915  [32000/72227]
loss: 0.063560  [38400/72227]
loss: 0.043925  [44800/72227]
loss: 0.048535  [51200/72227]
loss: 0.082718  [57600/72227]
loss: 0.055662  [64000/72227]
loss: 0.015756  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.086716 

Epoch 39
-------------------------------
loss: 0.029598  [    0/72227]
loss: 0.003967  [ 6400/72227]
loss: 0.018144  [12800/72227]
loss: 0.071520  [19200/72227]
loss: 0.012254  [25600/72227]
loss: 0.001810  [32000/72227]
loss: 0.050464  [38400/72227]
loss: 0.021503  [44800/72227]
loss: 0.052110  [51200/72227]
loss: 0.044893  [57600/72227]
loss: 0.008121  [64000/72227]
loss: 0.006561  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.085218 

Epoch 40
-------------------------------
loss: 0.059816  [    0/72227]
loss: 0.124728  [ 6400/72227]
loss: 0.049953  [12800/72227]
loss: 0.015589  [19200/72227]
loss: 0.112133  [25600/72227]
loss: 0.006503  [32000/72227]
loss: 0.200600  [38400/72227]
loss: 0.017105  [44800/72227]
loss: 0.005460  [51200/72227]
loss: 0.059473  [57600/72227]
loss: 0.069483  [64000/72227]
loss: 0.026751  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.083167 

Epoch 41
-------------------------------
loss: 0.004215  [    0/72227]
loss: 0.077415  [ 6400/72227]
loss: 0.007342  [12800/72227]
loss: 0.029729  [19200/72227]
loss: 0.057174  [25600/72227]
loss: 0.003577  [32000/72227]
loss: 0.026808  [38400/72227]
loss: 0.034724  [44800/72227]
loss: 0.017841  [51200/72227]
loss: 0.063712  [57600/72227]
loss: 0.002908  [64000/72227]
loss: 0.045703  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.082348 

Epoch 42
-------------------------------
loss: 0.031856  [    0/72227]
loss: 0.005757  [ 6400/72227]
loss: 0.034697  [12800/72227]
loss: 0.050739  [19200/72227]
loss: 0.038647  [25600/72227]
loss: 0.019128  [32000/72227]
loss: 0.064290  [38400/72227]
loss: 1.590892  [44800/72227]
loss: 0.091302  [51200/72227]
loss: 0.000421  [57600/72227]
loss: 0.010388  [64000/72227]
loss: 0.016104  [70400/72227]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.103620 

Epoch 43
-------------------------------
loss: 0.005889  [    0/72227]
loss: 0.017753  [ 6400/72227]
loss: 0.017392  [12800/72227]
loss: 0.063244  [19200/72227]
loss: 0.041330  [25600/72227]
loss: 0.068441  [32000/72227]
loss: 0.073418  [38400/72227]
loss: 0.033452  [44800/72227]
loss: 0.022486  [51200/72227]
loss: 0.021150  [57600/72227]
loss: 0.009980  [64000/72227]
loss: 0.046857  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.088210 

Epoch 44
-------------------------------
loss: 0.002687  [    0/72227]
loss: 0.012140  [ 6400/72227]
loss: 0.013196  [12800/72227]
loss: 0.007565  [19200/72227]
loss: 0.008406  [25600/72227]
loss: 0.003708  [32000/72227]
loss: 0.096664  [38400/72227]
loss: 0.006212  [44800/72227]
loss: 0.010309  [51200/72227]
loss: 0.082116  [57600/72227]
loss: 0.011484  [64000/72227]
loss: 0.017652  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.090029 

Epoch 45
-------------------------------
loss: 0.026469  [    0/72227]
loss: 0.016769  [ 6400/72227]
loss: 0.056584  [12800/72227]
loss: 0.062559  [19200/72227]
loss: 0.007120  [25600/72227]
loss: 0.025634  [32000/72227]
loss: 0.061387  [38400/72227]
loss: 0.098877  [44800/72227]
loss: 0.079440  [51200/72227]
loss: 0.005559  [57600/72227]
loss: 0.033369  [64000/72227]
loss: 0.044184  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.092332 

Epoch 46
-------------------------------
loss: 0.057656  [    0/72227]
loss: 0.012141  [ 6400/72227]
loss: 0.043854  [12800/72227]
loss: 0.041977  [19200/72227]
loss: 0.038579  [25600/72227]
loss: 0.078034  [32000/72227]
loss: 0.021141  [38400/72227]
loss: 0.002718  [44800/72227]
loss: 0.020381  [51200/72227]
loss: 0.032020  [57600/72227]
loss: 0.046192  [64000/72227]
loss: 0.056507  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.103260 

Epoch 47
-------------------------------
loss: 0.003132  [    0/72227]
loss: 0.012264  [ 6400/72227]
loss: 0.050064  [12800/72227]
loss: 0.003640  [19200/72227]
loss: 0.023577  [25600/72227]
loss: 0.066431  [32000/72227]
loss: 0.011746  [38400/72227]
loss: 0.025422  [44800/72227]
loss: 0.037516  [51200/72227]
loss: 0.041961  [57600/72227]
loss: 0.013166  [64000/72227]
loss: 0.012270  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.093951 

Epoch 48
-------------------------------
loss: 0.090511  [    0/72227]
loss: 0.007930  [ 6400/72227]
loss: 0.010564  [12800/72227]
loss: 0.044199  [19200/72227]
loss: 0.412546  [25600/72227]
loss: 0.067195  [32000/72227]
loss: 0.058398  [38400/72227]
loss: 0.033898  [44800/72227]
loss: 0.097676  [51200/72227]
loss: 0.015790  [57600/72227]
loss: 0.068665  [64000/72227]
loss: 0.002467  [70400/72227]
2022/09/20 15:15:03 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.070134  [70400/70588]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.132923 

Epoch 31
-------------------------------
loss: 0.088886  [    0/70588]
loss: 0.039882  [ 6400/70588]
loss: 0.112383  [12800/70588]
loss: 0.072036  [19200/70588]
loss: 0.141579  [25600/70588]
loss: 0.045101  [32000/70588]
loss: 0.091495  [38400/70588]
loss: 0.127021  [44800/70588]
loss: 0.043277  [51200/70588]
loss: 0.166600  [57600/70588]
loss: 0.101967  [64000/70588]
loss: 0.121445  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.145781 

Epoch 32
-------------------------------
loss: 0.148078  [    0/70588]
loss: 0.170029  [ 6400/70588]
loss: 0.138047  [12800/70588]
loss: 0.085884  [19200/70588]
loss: 0.059745  [25600/70588]
loss: 0.076195  [32000/70588]
loss: 0.131958  [38400/70588]
loss: 0.176241  [44800/70588]
loss: 0.096677  [51200/70588]
loss: 0.132782  [57600/70588]
loss: 0.061719  [64000/70588]
loss: 0.096863  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.143478 

Epoch 33
-------------------------------
loss: 0.060610  [    0/70588]
loss: 0.305752  [ 6400/70588]
loss: 0.117003  [12800/70588]
loss: 0.045452  [19200/70588]
loss: 0.127559  [25600/70588]
loss: 0.072352  [32000/70588]
loss: 0.156293  [38400/70588]
loss: 0.186000  [44800/70588]
loss: 0.233111  [51200/70588]
loss: 0.227973  [57600/70588]
loss: 0.139988  [64000/70588]
loss: 0.123722  [70400/70588]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.147836 

Epoch 34
-------------------------------
loss: 0.075949  [    0/70588]
loss: 0.059719  [ 6400/70588]
loss: 1.346864  [12800/70588]
loss: 0.027558  [19200/70588]
loss: 0.045003  [25600/70588]
loss: 0.164721  [32000/70588]
loss: 0.118292  [38400/70588]
loss: 0.100991  [44800/70588]
loss: 0.067601  [51200/70588]
loss: 0.208216  [57600/70588]
loss: 0.132196  [64000/70588]
loss: 0.137859  [70400/70588]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.151349 

Epoch 35
-------------------------------
loss: 0.080629  [    0/70588]
loss: 0.064556  [ 6400/70588]
loss: 0.170973  [12800/70588]
loss: 0.126792  [19200/70588]
loss: 0.049637  [25600/70588]
loss: 0.208994  [32000/70588]
loss: 0.222865  [38400/70588]
loss: 0.159030  [44800/70588]
loss: 0.141289  [51200/70588]
loss: 0.051611  [57600/70588]
loss: 0.093184  [64000/70588]
loss: 0.038364  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.144035 

Epoch 36
-------------------------------
loss: 0.125174  [    0/70588]
loss: 0.115291  [ 6400/70588]
loss: 0.156351  [12800/70588]
loss: 0.043111  [19200/70588]
loss: 0.102041  [25600/70588]
loss: 0.120328  [32000/70588]
loss: 0.077258  [38400/70588]
loss: 0.070243  [44800/70588]
loss: 0.059135  [51200/70588]
loss: 0.097766  [57600/70588]
loss: 0.242956  [64000/70588]
loss: 0.142837  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.143718 

Epoch 37
-------------------------------
loss: 0.053908  [    0/70588]
loss: 0.071548  [ 6400/70588]
loss: 0.136352  [12800/70588]
loss: 0.278386  [19200/70588]
loss: 0.108964  [25600/70588]
loss: 0.300963  [32000/70588]
loss: 0.079672  [38400/70588]
loss: 0.072559  [44800/70588]
loss: 0.246068  [51200/70588]
loss: 0.079474  [57600/70588]
loss: 0.053547  [64000/70588]
loss: 0.076655  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.147544 

Epoch 38
-------------------------------
loss: 0.119054  [    0/70588]
loss: 0.123086  [ 6400/70588]
loss: 0.112155  [12800/70588]
loss: 0.115925  [19200/70588]
loss: 0.049584  [25600/70588]
loss: 0.075497  [32000/70588]
loss: 0.094440  [38400/70588]
loss: 0.117851  [44800/70588]
loss: 0.182762  [51200/70588]
loss: 0.144470  [57600/70588]
loss: 0.105125  [64000/70588]
loss: 0.183973  [70400/70588]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.141248 

Epoch 39
-------------------------------
loss: 0.173180  [    0/70588]
loss: 0.055181  [ 6400/70588]
loss: 0.176763  [12800/70588]
loss: 0.036354  [19200/70588]
loss: 0.129952  [25600/70588]
loss: 0.115786  [32000/70588]
loss: 0.234758  [38400/70588]
loss: 0.090631  [44800/70588]
loss: 0.097145  [51200/70588]
loss: 0.126844  [57600/70588]
loss: 0.144729  [64000/70588]
loss: 0.184744  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.138741 

Epoch 40
-------------------------------
loss: 0.184315  [    0/70588]
loss: 0.136960  [ 6400/70588]
loss: 0.127605  [12800/70588]
loss: 0.085736  [19200/70588]
loss: 0.074329  [25600/70588]
loss: 0.129985  [32000/70588]
loss: 0.185194  [38400/70588]
loss: 0.104513  [44800/70588]
loss: 0.088953  [51200/70588]
loss: 0.139521  [57600/70588]
loss: 0.073874  [64000/70588]
loss: 0.105521  [70400/70588]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.142750 

Epoch 41
-------------------------------
loss: 0.075624  [    0/70588]
loss: 0.131862  [ 6400/70588]
loss: 0.068808  [12800/70588]
loss: 0.113347  [19200/70588]
loss: 0.064280  [25600/70588]
loss: 0.152902  [32000/70588]
loss: 0.065171  [38400/70588]
loss: 0.087654  [44800/70588]
loss: 0.039317  [51200/70588]
loss: 0.118604  [57600/70588]
loss: 0.084317  [64000/70588]
loss: 0.081246  [70400/70588]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.142520 

Epoch 42
-------------------------------
loss: 0.141132  [    0/70588]
loss: 0.096506  [ 6400/70588]
loss: 0.173294  [12800/70588]
loss: 0.118485  [19200/70588]
loss: 0.117427  [25600/70588]
loss: 0.061878  [32000/70588]
loss: 0.042279  [38400/70588]
loss: 0.164765  [44800/70588]
loss: 0.069478  [51200/70588]
loss: 0.220442  [57600/70588]
loss: 0.080539  [64000/70588]
loss: 0.029381  [70400/70588]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.146949 

Epoch 43
-------------------------------
loss: 0.036066  [    0/70588]
loss: 0.034343  [ 6400/70588]
loss: 0.098097  [12800/70588]
loss: 0.094930  [19200/70588]
loss: 0.159535  [25600/70588]
loss: 0.187105  [32000/70588]
loss: 0.209859  [38400/70588]
loss: 0.063458  [44800/70588]
loss: 0.091695  [51200/70588]
loss: 0.244232  [57600/70588]
loss: 0.165008  [64000/70588]
loss: 0.069760  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.148966 

Epoch 44
-------------------------------
loss: 0.081659  [    0/70588]
loss: 0.168765  [ 6400/70588]
loss: 0.063939  [12800/70588]
loss: 0.264978  [19200/70588]
loss: 0.105027  [25600/70588]
loss: 0.112282  [32000/70588]
loss: 0.102481  [38400/70588]
loss: 0.088557  [44800/70588]
loss: 0.141264  [51200/70588]
loss: 0.112993  [57600/70588]
loss: 0.247330  [64000/70588]
loss: 0.117716  [70400/70588]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.144115 

Epoch 45
-------------------------------
loss: 0.110365  [    0/70588]
loss: 0.108685  [ 6400/70588]
loss: 0.105661  [12800/70588]
loss: 0.058829  [19200/70588]
loss: 0.091781  [25600/70588]
loss: 0.085943  [32000/70588]
loss: 0.074650  [38400/70588]
loss: 0.033027  [44800/70588]
loss: 0.195100  [51200/70588]
loss: 0.119419  [57600/70588]
loss: 0.207430  [64000/70588]
loss: 0.102773  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.145608 

Epoch 46
-------------------------------
loss: 0.202696  [    0/70588]
loss: 0.150024  [ 6400/70588]
loss: 0.061213  [12800/70588]
loss: 0.100471  [19200/70588]
loss: 0.088981  [25600/70588]
loss: 0.121749  [32000/70588]
loss: 0.059630  [38400/70588]
loss: 0.047499  [44800/70588]
loss: 0.097559  [51200/70588]
loss: 0.119298  [57600/70588]
loss: 0.151674  [64000/70588]
loss: 0.105551  [70400/70588]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.182915 

Epoch 47
-------------------------------
loss: 0.165497  [    0/70588]
loss: 0.091988  [ 6400/70588]
loss: 0.162778  [12800/70588]
loss: 0.128745  [19200/70588]
loss: 0.069743  [25600/70588]
loss: 0.155186  [32000/70588]
loss: 0.082749  [38400/70588]
loss: 0.168458  [44800/70588]
loss: 0.072470  [51200/70588]
loss: 0.097776  [57600/70588]
loss: 0.088496  [64000/70588]
loss: 0.075930  [70400/70588]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146130 

Epoch 48
-------------------------------
loss: 0.126256  [    0/70588]
loss: 0.055943  [ 6400/70588]
loss: 0.060834  [12800/70588]
loss: 0.086222  [19200/70588]
loss: 0.052186  [25600/70588]
loss: 0.089607  [32000/70588]
loss: 0.099129  [38400/70588]
loss: 0.097727  [44800/70588]
loss: 0.189460  [51200/70588]
loss: 0.083125  [57600/70588]
loss: 0.107090  [64000/70588]
loss: 0.086338  [70400/70588]
2022/09/20 15:17:06 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:17:18 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.035795  [19200/69711]
loss: 0.065571  [25600/69711]
loss: 0.036189  [32000/69711]
loss: 0.173910  [38400/69711]
loss: 0.072530  [44800/69711]
loss: 0.026831  [51200/69711]
loss: 0.020552  [57600/69711]
loss: 0.102432  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.071873 

Epoch 30
-------------------------------
loss: 0.095490  [    0/69711]
loss: 0.039069  [ 6400/69711]
loss: 0.033348  [12800/69711]
loss: 0.112692  [19200/69711]
loss: 0.063165  [25600/69711]
loss: 0.007621  [32000/69711]
loss: 0.050402  [38400/69711]
loss: 0.047019  [44800/69711]
loss: 0.042235  [51200/69711]
loss: 0.057279  [57600/69711]
loss: 0.130334  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074455 

Epoch 31
-------------------------------
loss: 0.284531  [    0/69711]
loss: 0.073946  [ 6400/69711]
loss: 0.029397  [12800/69711]
loss: 0.018956  [19200/69711]
loss: 0.069122  [25600/69711]
loss: 0.164044  [32000/69711]
loss: 0.190323  [38400/69711]
loss: 0.089755  [44800/69711]
loss: 0.042355  [51200/69711]
loss: 0.099596  [57600/69711]
loss: 0.048187  [64000/69711]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.069628 

Epoch 32
-------------------------------
loss: 0.028814  [    0/69711]
loss: 0.083998  [ 6400/69711]
loss: 0.038377  [12800/69711]
loss: 0.012478  [19200/69711]
loss: 0.013024  [25600/69711]
loss: 0.088803  [32000/69711]
loss: 0.026916  [38400/69711]
loss: 0.014704  [44800/69711]
loss: 0.074422  [51200/69711]
loss: 0.048361  [57600/69711]
loss: 0.059872  [64000/69711]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.071953 

Epoch 33
-------------------------------
loss: 0.056016  [    0/69711]
loss: 0.058505  [ 6400/69711]
loss: 0.042657  [12800/69711]
loss: 0.012471  [19200/69711]
loss: 0.127425  [25600/69711]
loss: 0.093532  [32000/69711]
loss: 0.041293  [38400/69711]
loss: 0.094749  [44800/69711]
loss: 0.104701  [51200/69711]
loss: 0.069680  [57600/69711]
loss: 0.031346  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075293 

Epoch 34
-------------------------------
loss: 0.037024  [    0/69711]
loss: 0.013570  [ 6400/69711]
loss: 0.012371  [12800/69711]
loss: 0.032208  [19200/69711]
loss: 0.046672  [25600/69711]
loss: 0.051784  [32000/69711]
loss: 0.150495  [38400/69711]
loss: 0.074846  [44800/69711]
loss: 0.039983  [51200/69711]
loss: 0.108310  [57600/69711]
loss: 0.032333  [64000/69711]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.073794 

Epoch 35
-------------------------------
loss: 0.074339  [    0/69711]
loss: 0.028750  [ 6400/69711]
loss: 0.026313  [12800/69711]
loss: 0.023226  [19200/69711]
loss: 0.026304  [25600/69711]
loss: 0.078169  [32000/69711]
loss: 0.114667  [38400/69711]
loss: 0.076933  [44800/69711]
loss: 0.125169  [51200/69711]
loss: 0.059260  [57600/69711]
loss: 0.032050  [64000/69711]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.073952 

Epoch 36
-------------------------------
loss: 0.008763  [    0/69711]
loss: 0.050797  [ 6400/69711]
loss: 0.034767  [12800/69711]
loss: 0.049879  [19200/69711]
loss: 0.042284  [25600/69711]
loss: 0.072673  [32000/69711]
loss: 0.079686  [38400/69711]
loss: 0.039400  [44800/69711]
loss: 0.007083  [51200/69711]
loss: 0.077690  [57600/69711]
loss: 0.032075  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076052 

Epoch 37
-------------------------------
loss: 0.043259  [    0/69711]
loss: 0.076757  [ 6400/69711]
loss: 0.144927  [12800/69711]
loss: 0.071116  [19200/69711]
loss: 0.052224  [25600/69711]
loss: 0.031643  [32000/69711]
loss: 0.091242  [38400/69711]
loss: 0.030374  [44800/69711]
loss: 0.037883  [51200/69711]
loss: 0.180146  [57600/69711]
loss: 0.089657  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.074162 

Epoch 38
-------------------------------
loss: 0.076895  [    0/69711]
loss: 0.013778  [ 6400/69711]
loss: 0.005716  [12800/69711]
loss: 0.059667  [19200/69711]
loss: 0.037937  [25600/69711]
loss: 0.012056  [32000/69711]
loss: 0.033699  [38400/69711]
loss: 0.034002  [44800/69711]
loss: 0.073675  [51200/69711]
loss: 0.041190  [57600/69711]
loss: 0.021185  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.079188 

Epoch 39
-------------------------------
loss: 0.038686  [    0/69711]
loss: 0.060005  [ 6400/69711]
loss: 0.065697  [12800/69711]
loss: 0.287440  [19200/69711]
loss: 0.017027  [25600/69711]
loss: 0.046731  [32000/69711]
loss: 0.014300  [38400/69711]
loss: 0.075955  [44800/69711]
loss: 0.062316  [51200/69711]
loss: 0.048390  [57600/69711]
loss: 0.024352  [64000/69711]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083921 

Epoch 40
-------------------------------
loss: 0.056654  [    0/69711]
loss: 0.104393  [ 6400/69711]
loss: 0.043351  [12800/69711]
loss: 0.106421  [19200/69711]
loss: 0.039928  [25600/69711]
loss: 0.042618  [32000/69711]
loss: 0.024535  [38400/69711]
loss: 0.104662  [44800/69711]
loss: 0.036916  [51200/69711]
loss: 0.041383  [57600/69711]
loss: 0.037593  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080505 

Epoch 41
-------------------------------
loss: 0.123598  [    0/69711]
loss: 0.010442  [ 6400/69711]
loss: 0.068340  [12800/69711]
loss: 0.059278  [19200/69711]
loss: 0.010633  [25600/69711]
loss: 0.032870  [32000/69711]
loss: 0.083692  [38400/69711]
loss: 0.051051  [44800/69711]
loss: 0.017121  [51200/69711]
loss: 0.074652  [57600/69711]
loss: 0.054323  [64000/69711]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.085049 

Epoch 42
-------------------------------
loss: 0.061833  [    0/69711]
loss: 0.042115  [ 6400/69711]
loss: 0.083404  [12800/69711]
loss: 0.048862  [19200/69711]
loss: 0.060602  [25600/69711]
loss: 0.082716  [32000/69711]
loss: 0.068750  [38400/69711]
loss: 0.018437  [44800/69711]
loss: 0.046038  [51200/69711]
loss: 0.013414  [57600/69711]
loss: 0.080253  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077853 

Epoch 43
-------------------------------
loss: 0.219061  [    0/69711]
loss: 0.056457  [ 6400/69711]
loss: 0.016482  [12800/69711]
loss: 0.049771  [19200/69711]
loss: 0.016892  [25600/69711]
loss: 0.066392  [32000/69711]
loss: 0.056931  [38400/69711]
loss: 0.101889  [44800/69711]
loss: 0.022709  [51200/69711]
loss: 0.070564  [57600/69711]
loss: 0.055761  [64000/69711]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.091036 

Epoch 44
-------------------------------
loss: 0.071085  [    0/69711]
loss: 0.043818  [ 6400/69711]
loss: 0.023667  [12800/69711]
loss: 0.051375  [19200/69711]
loss: 0.114809  [25600/69711]
loss: 0.044258  [32000/69711]
loss: 0.024071  [38400/69711]
loss: 0.059287  [44800/69711]
loss: 0.044705  [51200/69711]
loss: 0.013383  [57600/69711]
loss: 0.059964  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.081769 

Epoch 45
-------------------------------
loss: 0.087662  [    0/69711]
loss: 0.039492  [ 6400/69711]
loss: 0.098319  [12800/69711]
loss: 0.093229  [19200/69711]
loss: 0.034323  [25600/69711]
loss: 0.016569  [32000/69711]
loss: 0.067357  [38400/69711]
loss: 0.029145  [44800/69711]
loss: 0.085597  [51200/69711]
loss: 0.036396  [57600/69711]
loss: 0.134803  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080093 

Epoch 46
-------------------------------
loss: 0.062051  [    0/69711]
loss: 0.059783  [ 6400/69711]
loss: 0.045824  [12800/69711]
loss: 0.083791  [19200/69711]
loss: 0.012901  [25600/69711]
loss: 0.395667  [32000/69711]
loss: 0.035406  [38400/69711]
loss: 0.114844  [44800/69711]
loss: 0.073312  [51200/69711]
loss: 0.077445  [57600/69711]
loss: 0.028658  [64000/69711]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.079950 

Epoch 47
-------------------------------
loss: 0.044188  [    0/69711]
loss: 0.053826  [ 6400/69711]
loss: 0.076966  [12800/69711]
loss: 0.043399  [19200/69711]
loss: 0.063182  [25600/69711]
loss: 0.056790  [32000/69711]
loss: 0.088401  [38400/69711]
loss: 0.062209  [44800/69711]
loss: 0.074098  [51200/69711]
loss: 0.060435  [57600/69711]
loss: 0.047983  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.091529 

Epoch 48
-------------------------------
loss: 0.042922  [    0/69711]
loss: 0.032183  [ 6400/69711]
loss: 0.051657  [12800/69711]
loss: 0.112651  [19200/69711]
loss: 0.072832  [25600/69711]
loss: 0.088070  [32000/69711]
loss: 0.089963  [38400/69711]
loss: 0.063605  [44800/69711]
2022/09/20 15:18:54 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.062447  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.076159 

Epoch 31
-------------------------------
loss: 0.066426  [    0/70562]
loss: 0.128327  [ 6400/70562]
loss: 0.044068  [12800/70562]
loss: 0.061033  [19200/70562]
loss: 0.038891  [25600/70562]
loss: 0.067452  [32000/70562]
loss: 0.076848  [38400/70562]
loss: 0.098437  [44800/70562]
loss: 0.026928  [51200/70562]
loss: 0.119861  [57600/70562]
loss: 0.108759  [64000/70562]
loss: 0.071383  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.076040 

Epoch 32
-------------------------------
loss: 0.145584  [    0/70562]
loss: 0.055550  [ 6400/70562]
loss: 0.017137  [12800/70562]
loss: 0.052414  [19200/70562]
loss: 0.102460  [25600/70562]
loss: 0.052797  [32000/70562]
loss: 0.034492  [38400/70562]
loss: 0.048623  [44800/70562]
loss: 0.024871  [51200/70562]
loss: 0.109399  [57600/70562]
loss: 0.043105  [64000/70562]
loss: 0.084927  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.077299 

Epoch 33
-------------------------------
loss: 0.061379  [    0/70562]
loss: 0.024159  [ 6400/70562]
loss: 0.085000  [12800/70562]
loss: 0.065491  [19200/70562]
loss: 0.161201  [25600/70562]
loss: 0.024761  [32000/70562]
loss: 0.067617  [38400/70562]
loss: 0.097809  [44800/70562]
loss: 0.056283  [51200/70562]
loss: 0.065612  [57600/70562]
loss: 0.088570  [64000/70562]
loss: 0.076386  [70400/70562]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.083476 

Epoch 34
-------------------------------
loss: 0.044895  [    0/70562]
loss: 0.037129  [ 6400/70562]
loss: 0.062302  [12800/70562]
loss: 0.045874  [19200/70562]
loss: 0.042079  [25600/70562]
loss: 0.063199  [32000/70562]
loss: 0.024247  [38400/70562]
loss: 0.023370  [44800/70562]
loss: 0.024254  [51200/70562]
loss: 0.059520  [57600/70562]
loss: 0.116555  [64000/70562]
loss: 0.130237  [70400/70562]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.088340 

Epoch 35
-------------------------------
loss: 0.016661  [    0/70562]
loss: 0.006627  [ 6400/70562]
loss: 0.038219  [12800/70562]
loss: 0.064440  [19200/70562]
loss: 0.059044  [25600/70562]
loss: 0.169058  [32000/70562]
loss: 0.065932  [38400/70562]
loss: 0.053577  [44800/70562]
loss: 0.151097  [51200/70562]
loss: 0.013327  [57600/70562]
loss: 0.092951  [64000/70562]
loss: 0.072778  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078967 

Epoch 36
-------------------------------
loss: 0.032516  [    0/70562]
loss: 0.023204  [ 6400/70562]
loss: 0.114552  [12800/70562]
loss: 0.026537  [19200/70562]
loss: 0.071220  [25600/70562]
loss: 0.083045  [32000/70562]
loss: 0.035422  [38400/70562]
loss: 0.129533  [44800/70562]
loss: 0.057240  [51200/70562]
loss: 0.048116  [57600/70562]
loss: 0.044121  [64000/70562]
loss: 0.044044  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.076811 

Epoch 37
-------------------------------
loss: 0.076241  [    0/70562]
loss: 0.064123  [ 6400/70562]
loss: 0.153526  [12800/70562]
loss: 0.081125  [19200/70562]
loss: 0.015841  [25600/70562]
loss: 0.029009  [32000/70562]
loss: 0.057316  [38400/70562]
loss: 0.017381  [44800/70562]
loss: 0.087847  [51200/70562]
loss: 0.086613  [57600/70562]
loss: 0.042700  [64000/70562]
loss: 0.040037  [70400/70562]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.087215 

Epoch 38
-------------------------------
loss: 0.074968  [    0/70562]
loss: 0.109489  [ 6400/70562]
loss: 0.057971  [12800/70562]
loss: 0.065615  [19200/70562]
loss: 0.019352  [25600/70562]
loss: 0.025028  [32000/70562]
loss: 0.062984  [38400/70562]
loss: 0.075104  [44800/70562]
loss: 0.134735  [51200/70562]
loss: 0.077396  [57600/70562]
loss: 0.068530  [64000/70562]
loss: 0.020689  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081421 

Epoch 39
-------------------------------
loss: 0.004639  [    0/70562]
loss: 0.030329  [ 6400/70562]
loss: 0.075953  [12800/70562]
loss: 0.040665  [19200/70562]
loss: 0.053368  [25600/70562]
loss: 0.121768  [32000/70562]
loss: 0.031128  [38400/70562]
loss: 0.111563  [44800/70562]
loss: 0.029105  [51200/70562]
loss: 0.087434  [57600/70562]
loss: 0.005500  [64000/70562]
loss: 0.037168  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078142 

Epoch 40
-------------------------------
loss: 0.027314  [    0/70562]
loss: 0.090843  [ 6400/70562]
loss: 0.219346  [12800/70562]
loss: 0.047019  [19200/70562]
loss: 0.054874  [25600/70562]
loss: 0.055243  [32000/70562]
loss: 0.055650  [38400/70562]
loss: 0.052187  [44800/70562]
loss: 0.069088  [51200/70562]
loss: 0.021888  [57600/70562]
loss: 0.016413  [64000/70562]
loss: 0.043920  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080791 

Epoch 41
-------------------------------
loss: 0.082560  [    0/70562]
loss: 0.025905  [ 6400/70562]
loss: 0.067991  [12800/70562]
loss: 0.012859  [19200/70562]
loss: 0.029820  [25600/70562]
loss: 0.050643  [32000/70562]
loss: 0.021747  [38400/70562]
loss: 0.038451  [44800/70562]
loss: 0.085397  [51200/70562]
loss: 0.070863  [57600/70562]
loss: 0.131513  [64000/70562]
loss: 0.025861  [70400/70562]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.102507 

Epoch 42
-------------------------------
loss: 0.243110  [    0/70562]
loss: 0.012622  [ 6400/70562]
loss: 0.127997  [12800/70562]
loss: 0.031482  [19200/70562]
loss: 0.043180  [25600/70562]
loss: 0.053836  [32000/70562]
loss: 0.047111  [38400/70562]
loss: 0.060939  [44800/70562]
loss: 0.036898  [51200/70562]
loss: 0.055966  [57600/70562]
loss: 0.022627  [64000/70562]
loss: 0.049893  [70400/70562]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.078144 

Epoch 43
-------------------------------
loss: 0.046472  [    0/70562]
loss: 0.051818  [ 6400/70562]
loss: 0.126954  [12800/70562]
loss: 0.020880  [19200/70562]
loss: 0.071416  [25600/70562]
loss: 0.046459  [32000/70562]
loss: 0.045035  [38400/70562]
loss: 0.026238  [44800/70562]
loss: 0.014108  [51200/70562]
loss: 0.058658  [57600/70562]
loss: 0.098926  [64000/70562]
loss: 0.071858  [70400/70562]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.082970 

Epoch 44
-------------------------------
loss: 0.097201  [    0/70562]
loss: 0.045580  [ 6400/70562]
loss: 0.013570  [12800/70562]
loss: 0.040185  [19200/70562]
loss: 0.021879  [25600/70562]
loss: 0.042879  [32000/70562]
loss: 0.071921  [38400/70562]
loss: 0.026922  [44800/70562]
loss: 0.037708  [51200/70562]
loss: 0.082758  [57600/70562]
loss: 0.121983  [64000/70562]
loss: 0.067001  [70400/70562]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.087354 

Epoch 45
-------------------------------
loss: 0.034821  [    0/70562]
loss: 0.043114  [ 6400/70562]
loss: 0.013643  [12800/70562]
loss: 0.031418  [19200/70562]
loss: 0.040926  [25600/70562]
loss: 0.043897  [32000/70562]
loss: 0.054201  [38400/70562]
loss: 0.150987  [44800/70562]
loss: 0.024200  [51200/70562]
loss: 0.025203  [57600/70562]
loss: 0.080253  [64000/70562]
loss: 0.013037  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.076959 

Epoch 46
-------------------------------
loss: 0.102370  [    0/70562]
loss: 0.029559  [ 6400/70562]
loss: 0.076466  [12800/70562]
loss: 0.329206  [19200/70562]
loss: 0.108329  [25600/70562]
loss: 0.077391  [32000/70562]
loss: 0.026863  [38400/70562]
loss: 0.045479  [44800/70562]
loss: 0.115428  [51200/70562]
loss: 0.081698  [57600/70562]
loss: 0.065879  [64000/70562]
loss: 0.046930  [70400/70562]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.092788 

Epoch 47
-------------------------------
loss: 0.039436  [    0/70562]
loss: 0.063062  [ 6400/70562]
loss: 0.168899  [12800/70562]
loss: 0.026048  [19200/70562]
loss: 0.022362  [25600/70562]
loss: 0.069550  [32000/70562]
loss: 0.058719  [38400/70562]
loss: 0.035430  [44800/70562]
loss: 0.027472  [51200/70562]
loss: 0.025989  [57600/70562]
loss: 0.082105  [64000/70562]
loss: 0.093638  [70400/70562]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083460 

Epoch 48
-------------------------------
loss: 0.124464  [    0/70562]
loss: 0.073030  [ 6400/70562]
loss: 0.041297  [12800/70562]
loss: 0.011413  [19200/70562]
loss: 0.082808  [25600/70562]
loss: 0.049125  [32000/70562]
loss: 0.096828  [38400/70562]
loss: 0.149419  [44800/70562]
loss: 0.049608  [51200/70562]
loss: 0.134671  [57600/70562]
loss: 0.079196  [64000/70562]
loss: 0.062845  [70400/70562]
2022/09/20 15:19:14 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:19:18 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:19:20 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:19:40 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:21:34 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 15:22:21 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.148214  [ 6400/70676]
loss: 0.164854  [12800/70676]
loss: 0.080145  [19200/70676]
loss: 0.186225  [25600/70676]
loss: 0.111968  [32000/70676]
loss: 0.088236  [38400/70676]
loss: 0.091628  [44800/70676]
loss: 0.121115  [51200/70676]
loss: 0.113532  [57600/70676]
loss: 0.051201  [64000/70676]
loss: 0.094847  [70400/70676]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.136553 

Epoch 35
-------------------------------
loss: 0.087806  [    0/70676]
loss: 0.066494  [ 6400/70676]
loss: 0.094566  [12800/70676]
loss: 0.050070  [19200/70676]
loss: 0.077878  [25600/70676]
loss: 0.107080  [32000/70676]
loss: 0.184184  [38400/70676]
loss: 0.107923  [44800/70676]
loss: 0.070177  [51200/70676]
loss: 0.102172  [57600/70676]
loss: 0.074948  [64000/70676]
loss: 0.124674  [70400/70676]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.158795 

Epoch 36
-------------------------------
loss: 0.163938  [    0/70676]
loss: 0.047739  [ 6400/70676]
loss: 0.100374  [12800/70676]
loss: 0.148832  [19200/70676]
loss: 0.099665  [25600/70676]
loss: 0.138037  [32000/70676]
loss: 0.061941  [38400/70676]
loss: 0.182484  [44800/70676]
loss: 0.040863  [51200/70676]
loss: 0.169165  [57600/70676]
loss: 0.259502  [64000/70676]
loss: 0.048535  [70400/70676]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.134591 

Epoch 37
-------------------------------
loss: 0.101309  [    0/70676]
loss: 0.038454  [ 6400/70676]
loss: 0.181889  [12800/70676]
loss: 0.116806  [19200/70676]
loss: 0.128003  [25600/70676]
loss: 0.071887  [32000/70676]
loss: 0.136888  [38400/70676]
loss: 0.097808  [44800/70676]
loss: 0.045939  [51200/70676]
loss: 0.172417  [57600/70676]
loss: 0.333322  [64000/70676]
loss: 0.241914  [70400/70676]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147600 

Epoch 38
-------------------------------
loss: 0.048177  [    0/70676]
loss: 0.148553  [ 6400/70676]
loss: 0.063655  [12800/70676]
loss: 0.141976  [19200/70676]
loss: 0.071617  [25600/70676]
loss: 0.084397  [32000/70676]
loss: 0.144946  [38400/70676]
loss: 0.102028  [44800/70676]
loss: 0.130176  [51200/70676]
loss: 0.079325  [57600/70676]
loss: 0.199399  [64000/70676]
loss: 0.047528  [70400/70676]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.148742 

Epoch 39
-------------------------------
loss: 0.022254  [    0/70676]
loss: 0.126092  [ 6400/70676]
loss: 0.069663  [12800/70676]
loss: 0.078611  [19200/70676]
loss: 0.142982  [25600/70676]
loss: 0.081001  [32000/70676]
loss: 0.190062  [38400/70676]
loss: 0.109770  [44800/70676]
loss: 0.040899  [51200/70676]
loss: 0.161162  [57600/70676]
loss: 0.143966  [64000/70676]
loss: 0.146592  [70400/70676]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.141718 

Epoch 40
-------------------------------
loss: 0.070002  [    0/70676]
loss: 0.082694  [ 6400/70676]
loss: 0.060252  [12800/70676]
loss: 0.075409  [19200/70676]
loss: 0.149546  [25600/70676]
loss: 0.062780  [32000/70676]
loss: 0.134831  [38400/70676]
loss: 0.047146  [44800/70676]
loss: 0.067933  [51200/70676]
loss: 0.145599  [57600/70676]
loss: 0.204262  [64000/70676]
loss: 0.197111  [70400/70676]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.132157 

Epoch 41
-------------------------------
loss: 0.169749  [    0/70676]
loss: 0.101166  [ 6400/70676]
loss: 0.073055  [12800/70676]
loss: 0.023545  [19200/70676]
loss: 0.086476  [25600/70676]
loss: 0.060844  [32000/70676]
loss: 0.092390  [38400/70676]
loss: 0.253007  [44800/70676]
loss: 0.214161  [51200/70676]
loss: 0.163872  [57600/70676]
loss: 0.178776  [64000/70676]
loss: 0.099455  [70400/70676]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140937 

Epoch 42
-------------------------------
loss: 0.148168  [    0/70676]
loss: 0.067756  [ 6400/70676]
loss: 0.146849  [12800/70676]
loss: 0.164410  [19200/70676]
loss: 0.214873  [25600/70676]
loss: 0.078215  [32000/70676]
loss: 0.174634  [38400/70676]
loss: 0.114863  [44800/70676]
loss: 0.101192  [51200/70676]
loss: 0.090850  [57600/70676]
loss: 0.150824  [64000/70676]
loss: 0.084385  [70400/70676]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.137700 

Epoch 43
-------------------------------
loss: 0.086075  [    0/70676]
loss: 0.065158  [ 6400/70676]
loss: 0.329448  [12800/70676]
loss: 0.198985  [19200/70676]
loss: 0.135744  [25600/70676]
loss: 0.068043  [32000/70676]
loss: 0.180513  [38400/70676]
loss: 0.160775  [44800/70676]
loss: 0.121394  [51200/70676]
loss: 0.067353  [57600/70676]
loss: 0.062937  [64000/70676]
loss: 0.102046  [70400/70676]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.143092 

Epoch 44
-------------------------------
loss: 0.074812  [    0/70676]
loss: 0.109109  [ 6400/70676]
loss: 0.092254  [12800/70676]
loss: 0.050392  [19200/70676]
loss: 0.100181  [25600/70676]
loss: 0.198022  [32000/70676]
loss: 0.103486  [38400/70676]
loss: 0.113424  [44800/70676]
loss: 0.054912  [51200/70676]
loss: 0.266619  [57600/70676]
loss: 0.068122  [64000/70676]
loss: 0.033266  [70400/70676]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.136610 

Epoch 45
-------------------------------
loss: 0.169995  [    0/70676]
loss: 0.216379  [ 6400/70676]
loss: 0.112575  [12800/70676]
loss: 0.058356  [19200/70676]
loss: 0.212120  [25600/70676]
loss: 0.083217  [32000/70676]
loss: 0.102634  [38400/70676]
loss: 0.131071  [44800/70676]
loss: 0.041703  [51200/70676]
loss: 0.126283  [57600/70676]
loss: 0.150168  [64000/70676]
loss: 0.192763  [70400/70676]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.160992 

Epoch 46
-------------------------------
loss: 0.141848  [    0/70676]
loss: 0.118949  [ 6400/70676]
loss: 0.173922  [12800/70676]
loss: 0.247856  [19200/70676]
loss: 0.089545  [25600/70676]
loss: 0.033021  [32000/70676]
loss: 0.065690  [38400/70676]
loss: 0.079970  [44800/70676]
loss: 0.074999  [51200/70676]
loss: 0.141339  [57600/70676]
loss: 0.190843  [64000/70676]
loss: 0.101422  [70400/70676]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.140340 

Epoch 47
-------------------------------
loss: 0.173083  [    0/70676]
loss: 0.165743  [ 6400/70676]
loss: 0.141988  [12800/70676]
loss: 0.097055  [19200/70676]
loss: 0.108336  [25600/70676]
loss: 0.080723  [32000/70676]
loss: 0.096857  [38400/70676]
loss: 0.239635  [44800/70676]
loss: 0.020168  [51200/70676]
loss: 0.060962  [57600/70676]
loss: 0.064051  [64000/70676]
loss: 0.087752  [70400/70676]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.133508 

Epoch 48
-------------------------------
loss: 0.025305  [    0/70676]
loss: 0.050921  [ 6400/70676]
loss: 0.225403  [12800/70676]
loss: 0.140394  [19200/70676]
loss: 0.112082  [25600/70676]
loss: 0.058803  [32000/70676]
loss: 0.084548  [38400/70676]
loss: 0.098268  [44800/70676]
loss: 0.111825  [51200/70676]
loss: 0.145922  [57600/70676]
loss: 0.080252  [64000/70676]
loss: 0.094737  [70400/70676]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.138327 

Epoch 49
-------------------------------
loss: 0.115445  [    0/70676]
loss: 0.142478  [ 6400/70676]
loss: 0.138907  [12800/70676]
loss: 0.115837  [19200/70676]
loss: 0.199481  [25600/70676]
loss: 0.152392  [32000/70676]
loss: 0.077837  [38400/70676]
loss: 0.109847  [44800/70676]
loss: 0.113550  [51200/70676]
loss: 0.090000  [57600/70676]
loss: 0.083893  [64000/70676]
loss: 0.107175  [70400/70676]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.138366 

Epoch 50
-------------------------------
loss: 0.178829  [    0/70676]
loss: 0.038443  [ 6400/70676]
loss: 0.143057  [12800/70676]
loss: 0.041334  [19200/70676]
loss: 0.096379  [25600/70676]
loss: 0.112990  [32000/70676]
loss: 0.096118  [38400/70676]
loss: 0.177666  [44800/70676]
loss: 0.110776  [51200/70676]
loss: 0.210077  [57600/70676]
loss: 0.086725  [64000/70676]
loss: 0.138400  [70400/70676]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.142873 

Epoch 1
-------------------------------
loss: 0.748634  [    0/72227]
loss: 0.186499  [ 6400/72227]
loss: 0.202025  [12800/72227]
loss: 0.085479  [19200/72227]
loss: 0.050910  [25600/72227]
loss: 0.189539  [32000/72227]
loss: 0.119669  [38400/72227]
loss: 0.055142  [44800/72227]
loss: 0.184493  [51200/72227]
loss: 0.063897  [57600/72227]
loss: 0.062682  [64000/72227]
loss: 0.078579  [70400/72227]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.140432 

Epoch 2
-------------------------------
loss: 0.064670  [    0/72227]
loss: 0.035258  [ 6400/72227]
loss: 0.000057  [44800/72604]
loss: 0.000010  [51200/72604]
loss: 0.042469  [57600/72604]
loss: 0.000030  [64000/72604]
loss: 0.000000  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.080872 

Epoch 46
-------------------------------
loss: 0.001721  [    0/72604]
loss: 0.000012  [ 6400/72604]
loss: 0.000000  [12800/72604]
loss: 0.001842  [19200/72604]
loss: 0.002559  [25600/72604]
loss: 0.000027  [32000/72604]
loss: 0.000008  [38400/72604]
loss: 0.000509  [44800/72604]
loss: 0.001284  [51200/72604]
loss: 0.006236  [57600/72604]
loss: 0.000360  [64000/72604]
loss: 0.000246  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.095312 

Epoch 47
-------------------------------
loss: 0.000885  [    0/72604]
loss: 0.000004  [ 6400/72604]
loss: 0.000199  [12800/72604]
loss: 0.016599  [19200/72604]
loss: 0.000017  [25600/72604]
loss: 0.000002  [32000/72604]
loss: 0.000010  [38400/72604]
loss: 0.000001  [44800/72604]
loss: 0.000116  [51200/72604]
loss: 0.000033  [57600/72604]
loss: 0.000052  [64000/72604]
loss: 0.006227  [70400/72604]
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.094500 

Epoch 48
-------------------------------
loss: 0.000625  [    0/72604]
loss: 0.000819  [ 6400/72604]
loss: 0.007717  [12800/72604]
loss: 0.008685  [19200/72604]
loss: 0.000007  [25600/72604]
loss: 0.000340  [32000/72604]
loss: 0.003195  [38400/72604]
loss: 0.006826  [44800/72604]
loss: 0.002388  [51200/72604]
loss: 0.016286  [57600/72604]
loss: 0.016423  [64000/72604]
loss: 0.000103  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.131235 

Epoch 49
-------------------------------
loss: 0.000971  [    0/72604]
loss: 0.000325  [ 6400/72604]
loss: 0.001692  [12800/72604]
loss: 0.006167  [19200/72604]
loss: 0.000014  [25600/72604]
loss: 0.001914  [32000/72604]
loss: 0.037663  [38400/72604]
loss: 0.000856  [44800/72604]
loss: 0.002183  [51200/72604]
loss: 0.000158  [57600/72604]
loss: 0.000979  [64000/72604]
loss: 0.000000  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.085723 

Epoch 50
-------------------------------
loss: 0.000204  [    0/72604]
loss: 0.000004  [ 6400/72604]
loss: 0.000920  [12800/72604]
loss: 0.000238  [19200/72604]
loss: 0.002299  [25600/72604]
loss: 0.000014  [32000/72604]
loss: 0.043783  [38400/72604]
loss: 0.022061  [44800/72604]
loss: 0.003298  [51200/72604]
loss: 0.031690  [57600/72604]
loss: 0.000000  [64000/72604]
loss: 0.000001  [70400/72604]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.135356 

Epoch 1
-------------------------------
loss: 0.680433  [    0/71616]
loss: 0.232631  [ 6400/71616]
loss: 0.237208  [12800/71616]
loss: 0.181357  [19200/71616]
loss: 0.046214  [25600/71616]
loss: 0.049755  [32000/71616]
loss: 0.158100  [38400/71616]
loss: 0.032733  [44800/71616]
loss: 0.054563  [51200/71616]
loss: 0.038008  [57600/71616]
loss: 0.098511  [64000/71616]
loss: 0.077638  [70400/71616]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.070302 

Epoch 2
-------------------------------
loss: 0.125935  [    0/71616]
loss: 0.037421  [ 6400/71616]
loss: 0.025330  [12800/71616]
loss: 0.097636  [19200/71616]
loss: 0.055656  [25600/71616]
loss: 0.013566  [32000/71616]
loss: 0.040198  [38400/71616]
loss: 0.113584  [44800/71616]
loss: 0.232666  [51200/71616]
loss: 0.053016  [57600/71616]
loss: 0.055967  [64000/71616]
loss: 0.033973  [70400/71616]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.061253 

Epoch 3
-------------------------------
loss: 0.041061  [    0/71616]
loss: 0.014324  [ 6400/71616]
loss: 0.017413  [12800/71616]
loss: 0.102986  [19200/71616]
loss: 0.036823  [25600/71616]
loss: 0.037523  [32000/71616]
loss: 0.046145  [38400/71616]
loss: 0.113277  [44800/71616]
loss: 0.057537  [51200/71616]
loss: 0.015764  [57600/71616]
loss: 0.130531  [64000/71616]
loss: 0.051202  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.056621 

Epoch 4
-------------------------------
loss: 0.096807  [    0/71616]
loss: 0.119024  [ 6400/71616]
loss: 0.048726  [12800/71616]
loss: 0.030481  [19200/71616]
loss: 0.045454  [25600/71616]
loss: 0.041508  [32000/71616]
loss: 0.052225  [38400/71616]
loss: 0.077711  [44800/71616]
loss: 0.080428  [51200/71616]
loss: 0.073794  [57600/71616]
loss: 0.054148  [64000/71616]
loss: 0.107828  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.061558 

Epoch 5
-------------------------------
loss: 0.015731  [    0/71616]
loss: 0.028676  [ 6400/71616]
loss: 0.021635  [12800/71616]
loss: 0.037133  [19200/71616]
loss: 0.029238  [25600/71616]
loss: 0.048613  [32000/71616]
loss: 0.124002  [38400/71616]
loss: 0.026413  [44800/71616]
loss: 0.029659  [51200/71616]
loss: 0.046098  [57600/71616]
loss: 0.061882  [64000/71616]
loss: 0.048696  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.071596 

Epoch 6
-------------------------------
loss: 0.064794  [    0/71616]
loss: 0.058236  [ 6400/71616]
loss: 0.053759  [12800/71616]
loss: 0.017805  [19200/71616]
loss: 0.034956  [25600/71616]
loss: 0.021186  [32000/71616]
loss: 0.042897  [38400/71616]
loss: 0.039217  [44800/71616]
loss: 0.176188  [51200/71616]
loss: 0.087709  [57600/71616]
loss: 0.066024  [64000/71616]
loss: 0.064258  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.067418 

Epoch 7
-------------------------------
loss: 0.028892  [    0/71616]
loss: 0.036058  [ 6400/71616]
loss: 0.120106  [12800/71616]
loss: 0.041228  [19200/71616]
loss: 0.069304  [25600/71616]
loss: 0.005732  [32000/71616]
loss: 0.007092  [38400/71616]
loss: 0.014367  [44800/71616]
loss: 0.023307  [51200/71616]
loss: 0.070276  [57600/71616]
loss: 0.044415  [64000/71616]
loss: 0.079593  [70400/71616]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.063598 

Epoch 8
-------------------------------
loss: 0.032720  [    0/71616]
loss: 0.126166  [ 6400/71616]
loss: 0.040907  [12800/71616]
loss: 0.046372  [19200/71616]
loss: 0.037924  [25600/71616]
loss: 0.067473  [32000/71616]
loss: 0.020418  [38400/71616]
loss: 0.017772  [44800/71616]
loss: 0.003357  [51200/71616]
loss: 0.030351  [57600/71616]
loss: 0.047183  [64000/71616]
loss: 0.016583  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.068788 

Epoch 9
-------------------------------
loss: 0.013660  [    0/71616]
loss: 0.001261  [ 6400/71616]
loss: 0.065370  [12800/71616]
loss: 0.007966  [19200/71616]
loss: 0.017008  [25600/71616]
loss: 0.020424  [32000/71616]
loss: 0.040099  [38400/71616]
loss: 0.211941  [44800/71616]
loss: 0.017562  [51200/71616]
loss: 0.022930  [57600/71616]
loss: 0.050415  [64000/71616]
loss: 0.039271  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066937 

Epoch 10
-------------------------------
loss: 0.100746  [    0/71616]
loss: 0.132406  [ 6400/71616]
loss: 0.001838  [12800/71616]
loss: 0.035089  [19200/71616]
loss: 0.019280  [25600/71616]
loss: 0.033614  [32000/71616]
loss: 0.069706  [38400/71616]
loss: 0.013992  [44800/71616]
loss: 0.098912  [51200/71616]
loss: 0.012748  [57600/71616]
loss: 0.003656  [64000/71616]
loss: 0.110604  [70400/71616]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.063320 

Epoch 11
-------------------------------
loss: 0.020366  [    0/71616]
loss: 0.022107  [ 6400/71616]
loss: 0.047513  [12800/71616]
loss: 0.004607  [19200/71616]
loss: 0.023957  [25600/71616]
loss: 0.013110  [32000/71616]
loss: 0.016928  [38400/71616]
loss: 0.121466  [44800/71616]
loss: 0.089614  [51200/71616]
loss: 0.048476  [57600/71616]
loss: 0.031836  [64000/71616]
loss: 0.028830  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.064962 

Epoch 12
-------------------------------
loss: 0.021610  [    0/71616]
loss: 0.148166  [ 6400/71616]
loss: 0.023474  [12800/71616]
loss: 0.070435  [19200/71616]
loss: 0.011067  [25600/71616]
loss: 0.012927  [32000/71616]
loss: 0.021050  [38400/71616]
loss: 0.072883  [44800/71616]
loss: 0.040984  [51200/71616]
loss: 0.078343  [57600/71616]
loss: 0.013477  [64000/71616]
loss: 0.041136  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067421 

Epoch 13
-------------------------------
loss: 0.014537  [    0/71616]
loss: 0.035985  [ 6400/71616]
loss: 0.034767  [12800/71616]
loss: 0.083080  [19200/71616]
loss: 0.070486  [25600/71616]
loss: 0.034683  [32000/71616]
loss: 0.004104  [38400/71616]
loss: 0.011430  [44800/71616]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088180 

Epoch 33
-------------------------------
loss: 0.100716  [    0/69684]
loss: 0.065683  [ 6400/69684]
loss: 0.075530  [12800/69684]
loss: 0.033605  [19200/69684]
loss: 0.089733  [25600/69684]
loss: 0.094468  [32000/69684]
loss: 0.049070  [38400/69684]
loss: 0.045918  [44800/69684]
loss: 0.109541  [51200/69684]
loss: 0.059327  [57600/69684]
loss: 0.073617  [64000/69684]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090193 

Epoch 34
-------------------------------
loss: 0.097239  [    0/69684]
loss: 0.040467  [ 6400/69684]
loss: 0.010977  [12800/69684]
loss: 0.023894  [19200/69684]
loss: 0.069431  [25600/69684]
loss: 0.021974  [32000/69684]
loss: 0.008659  [38400/69684]
loss: 0.094653  [44800/69684]
loss: 0.079275  [51200/69684]
loss: 0.110534  [57600/69684]
loss: 0.018251  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.086128 

Epoch 35
-------------------------------
loss: 0.081739  [    0/69684]
loss: 0.095689  [ 6400/69684]
loss: 0.048268  [12800/69684]
loss: 0.036516  [19200/69684]
loss: 0.031758  [25600/69684]
loss: 0.072030  [32000/69684]
loss: 0.096255  [38400/69684]
loss: 0.026129  [44800/69684]
loss: 0.032235  [51200/69684]
loss: 0.088720  [57600/69684]
loss: 0.034354  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089485 

Epoch 36
-------------------------------
loss: 0.041715  [    0/69684]
loss: 0.142959  [ 6400/69684]
loss: 0.057658  [12800/69684]
loss: 0.074379  [19200/69684]
loss: 0.101798  [25600/69684]
loss: 0.057561  [32000/69684]
loss: 0.054068  [38400/69684]
loss: 0.069405  [44800/69684]
loss: 0.119759  [51200/69684]
loss: 0.039416  [57600/69684]
loss: 0.125491  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.081784 

Epoch 37
-------------------------------
loss: 0.039499  [    0/69684]
loss: 0.084936  [ 6400/69684]
loss: 0.044074  [12800/69684]
loss: 0.052930  [19200/69684]
loss: 0.066040  [25600/69684]
loss: 0.033598  [32000/69684]
loss: 0.114067  [38400/69684]
loss: 0.105591  [44800/69684]
loss: 0.033711  [51200/69684]
loss: 0.028729  [57600/69684]
loss: 0.072076  [64000/69684]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.085359 

Epoch 38
-------------------------------
loss: 0.056818  [    0/69684]
loss: 0.066399  [ 6400/69684]
loss: 0.063323  [12800/69684]
loss: 0.115572  [19200/69684]
loss: 0.122130  [25600/69684]
loss: 0.069879  [32000/69684]
loss: 0.045248  [38400/69684]
loss: 0.026235  [44800/69684]
loss: 0.063638  [51200/69684]
loss: 0.035493  [57600/69684]
loss: 0.206220  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.088397 

Epoch 39
-------------------------------
loss: 0.153400  [    0/69684]
loss: 0.101921  [ 6400/69684]
loss: 0.079377  [12800/69684]
loss: 0.072471  [19200/69684]
loss: 0.018855  [25600/69684]
loss: 0.093725  [32000/69684]
loss: 0.016307  [38400/69684]
loss: 0.031744  [44800/69684]
loss: 0.050986  [51200/69684]
loss: 0.041328  [57600/69684]
loss: 0.062151  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.082036 

Epoch 40
-------------------------------
loss: 0.033168  [    0/69684]
loss: 0.068571  [ 6400/69684]
loss: 0.094467  [12800/69684]
loss: 0.098639  [19200/69684]
loss: 0.037867  [25600/69684]
loss: 0.050152  [32000/69684]
loss: 0.033734  [38400/69684]
loss: 0.066310  [44800/69684]
loss: 0.076905  [51200/69684]
loss: 0.053527  [57600/69684]
loss: 0.080569  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.089270 

Epoch 41
-------------------------------
loss: 0.125780  [    0/69684]
loss: 0.037517  [ 6400/69684]
loss: 0.176270  [12800/69684]
loss: 0.176193  [19200/69684]
loss: 0.079093  [25600/69684]
loss: 0.056004  [32000/69684]
loss: 0.069202  [38400/69684]
loss: 0.037532  [44800/69684]
loss: 0.097832  [51200/69684]
loss: 0.086711  [57600/69684]
loss: 0.172219  [64000/69684]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.086666 

Epoch 42
-------------------------------
loss: 0.020800  [    0/69684]
loss: 0.041113  [ 6400/69684]
loss: 0.013184  [12800/69684]
loss: 0.039907  [19200/69684]
loss: 0.048828  [25600/69684]
loss: 0.069886  [32000/69684]
loss: 0.057761  [38400/69684]
loss: 0.028422  [44800/69684]
loss: 0.016393  [51200/69684]
loss: 0.081224  [57600/69684]
loss: 0.105119  [64000/69684]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.094179 

Epoch 43
-------------------------------
loss: 0.049245  [    0/69684]
loss: 0.088267  [ 6400/69684]
loss: 0.092813  [12800/69684]
loss: 0.136869  [19200/69684]
loss: 0.177409  [25600/69684]
loss: 0.060092  [32000/69684]
loss: 0.036140  [38400/69684]
loss: 0.082036  [44800/69684]
loss: 0.072848  [51200/69684]
loss: 0.116399  [57600/69684]
loss: 0.024196  [64000/69684]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.094755 

Epoch 44
-------------------------------
loss: 0.148868  [    0/69684]
loss: 0.123151  [ 6400/69684]
loss: 0.058921  [12800/69684]
loss: 0.034568  [19200/69684]
loss: 0.084310  [25600/69684]
loss: 0.085589  [32000/69684]
loss: 0.035500  [38400/69684]
loss: 0.020163  [44800/69684]
loss: 0.130303  [51200/69684]
loss: 0.042990  [57600/69684]
loss: 0.040707  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.087276 

Epoch 45
-------------------------------
loss: 0.062085  [    0/69684]
loss: 0.048084  [ 6400/69684]
loss: 0.022190  [12800/69684]
loss: 0.085071  [19200/69684]
loss: 0.085206  [25600/69684]
loss: 0.018321  [32000/69684]
loss: 0.008713  [38400/69684]
loss: 0.038307  [44800/69684]
loss: 0.110605  [51200/69684]
loss: 0.040982  [57600/69684]
loss: 0.104065  [64000/69684]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084671 

Epoch 46
-------------------------------
loss: 0.048510  [    0/69684]
loss: 0.036264  [ 6400/69684]
loss: 0.025869  [12800/69684]
loss: 0.040277  [19200/69684]
loss: 0.074290  [25600/69684]
loss: 0.021302  [32000/69684]
loss: 0.019957  [38400/69684]
loss: 0.067481  [44800/69684]
loss: 0.072657  [51200/69684]
loss: 0.162086  [57600/69684]
loss: 0.064919  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.085653 

Epoch 47
-------------------------------
loss: 0.072646  [    0/69684]
loss: 0.046409  [ 6400/69684]
loss: 0.045614  [12800/69684]
loss: 0.040706  [19200/69684]
loss: 0.184711  [25600/69684]
loss: 0.074756  [32000/69684]
loss: 0.043005  [38400/69684]
loss: 0.061097  [44800/69684]
loss: 0.007819  [51200/69684]
loss: 0.047025  [57600/69684]
loss: 0.100957  [64000/69684]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.084484 

Epoch 48
-------------------------------
loss: 0.037832  [    0/69684]
loss: 0.036523  [ 6400/69684]
loss: 0.011245  [12800/69684]
loss: 0.127788  [19200/69684]
loss: 0.038613  [25600/69684]
loss: 0.074155  [32000/69684]
loss: 0.059872  [38400/69684]
loss: 0.082407  [44800/69684]
loss: 0.063112  [51200/69684]
loss: 0.130595  [57600/69684]
loss: 0.076466  [64000/69684]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086990 

Epoch 49
-------------------------------
loss: 0.090554  [    0/69684]
loss: 0.064712  [ 6400/69684]
loss: 0.133683  [12800/69684]
loss: 0.071253  [19200/69684]
loss: 0.106363  [25600/69684]
loss: 0.094430  [32000/69684]
loss: 0.075518  [38400/69684]
loss: 0.056291  [44800/69684]
loss: 0.036493  [51200/69684]
loss: 0.068341  [57600/69684]
loss: 0.077166  [64000/69684]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.084533 

Epoch 50
-------------------------------
loss: 0.034176  [    0/69684]
loss: 0.050570  [ 6400/69684]
loss: 0.035648  [12800/69684]
loss: 0.124005  [19200/69684]
loss: 0.026913  [25600/69684]
loss: 0.033747  [32000/69684]
loss: 0.034808  [38400/69684]
loss: 0.028026  [44800/69684]
loss: 0.029429  [51200/69684]
loss: 0.041264  [57600/69684]
loss: 0.055269  [64000/69684]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.093853 

Epoch 1
-------------------------------
loss: 0.651434  [    0/70932]
loss: 0.290715  [ 6400/70932]
loss: 0.268746  [12800/70932]
loss: 0.239189  [19200/70932]
loss: 0.342364  [25600/70932]
loss: 0.232498  [32000/70932]
loss: 0.234771  [38400/70932]
loss: 0.123931  [44800/70932]
loss: 0.156016  [51200/70932]
loss: 0.225087  [57600/70932]
loss: 0.109226  [64000/70932]
loss: 0.188095  [70400/70932]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.211165 

Epoch 2
-------------------------------
loss: 1.830604  [    0/70932]
2022/09/20 15:22:50 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.013099  [44800/71706]
loss: 0.027136  [51200/71706]
loss: 0.057397  [57600/71706]
loss: 0.026666  [64000/71706]
loss: 0.024153  [70400/71706]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.078337 

Epoch 46
-------------------------------
loss: 0.030344  [    0/71706]
loss: 0.036933  [ 6400/71706]
loss: 0.081966  [12800/71706]
loss: 0.085974  [19200/71706]
loss: 0.052231  [25600/71706]
loss: 0.014344  [32000/71706]
loss: 0.095122  [38400/71706]
loss: 0.040522  [44800/71706]
loss: 0.032913  [51200/71706]
loss: 0.100663  [57600/71706]
loss: 0.005806  [64000/71706]
loss: 0.008086  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068217 

Epoch 47
-------------------------------
loss: 0.080638  [    0/71706]
loss: 0.066592  [ 6400/71706]
loss: 0.039285  [12800/71706]
loss: 0.046542  [19200/71706]
loss: 0.012688  [25600/71706]
loss: 0.036753  [32000/71706]
loss: 0.022285  [38400/71706]
loss: 0.098141  [44800/71706]
loss: 0.040520  [51200/71706]
loss: 0.052193  [57600/71706]
loss: 0.015650  [64000/71706]
loss: 0.071809  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068562 

Epoch 48
-------------------------------
loss: 0.108175  [    0/71706]
loss: 0.050401  [ 6400/71706]
loss: 0.026819  [12800/71706]
loss: 0.100461  [19200/71706]
loss: 0.028346  [25600/71706]
loss: 0.010254  [32000/71706]
loss: 0.063931  [38400/71706]
loss: 0.047646  [44800/71706]
loss: 0.039558  [51200/71706]
loss: 0.028021  [57600/71706]
loss: 0.020793  [64000/71706]
loss: 0.133637  [70400/71706]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.071515 

Epoch 49
-------------------------------
loss: 0.040813  [    0/71706]
loss: 0.014518  [ 6400/71706]
loss: 0.053408  [12800/71706]
loss: 0.073358  [19200/71706]
loss: 0.106386  [25600/71706]
loss: 0.010769  [32000/71706]
loss: 0.028593  [38400/71706]
loss: 0.024531  [44800/71706]
loss: 0.050039  [51200/71706]
loss: 0.055520  [57600/71706]
loss: 0.015153  [64000/71706]
loss: 0.006769  [70400/71706]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077318 

Epoch 50
-------------------------------
loss: 0.002516  [    0/71706]
loss: 0.055177  [ 6400/71706]
loss: 0.059156  [12800/71706]
loss: 0.021006  [19200/71706]
loss: 0.059126  [25600/71706]
loss: 0.013911  [32000/71706]
loss: 0.015495  [38400/71706]
loss: 0.114902  [44800/71706]
loss: 0.004674  [51200/71706]
loss: 0.038159  [57600/71706]
loss: 0.080786  [64000/71706]
loss: 0.063168  [70400/71706]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.080745 

Epoch 1
-------------------------------
loss: 0.703657  [    0/69149]
loss: 0.182404  [ 6400/69149]
loss: 0.238180  [12800/69149]
loss: 0.337486  [19200/69149]
loss: 0.151785  [25600/69149]
loss: 0.312269  [32000/69149]
loss: 0.304989  [38400/69149]
loss: 0.164442  [44800/69149]
loss: 0.226767  [51200/69149]
loss: 0.218632  [57600/69149]
loss: 0.073396  [64000/69149]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.172323 

Epoch 2
-------------------------------
loss: 0.236867  [    0/69149]
loss: 0.096627  [ 6400/69149]
loss: 0.163326  [12800/69149]
loss: 0.116467  [19200/69149]
loss: 0.075167  [25600/69149]
loss: 0.092590  [32000/69149]
loss: 0.090162  [38400/69149]
loss: 0.191296  [44800/69149]
loss: 0.194960  [51200/69149]
loss: 0.136981  [57600/69149]
loss: 0.142775  [64000/69149]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.168911 

Epoch 3
-------------------------------
loss: 0.078672  [    0/69149]
loss: 0.139832  [ 6400/69149]
loss: 0.133170  [12800/69149]
loss: 0.207710  [19200/69149]
loss: 0.145193  [25600/69149]
loss: 0.079697  [32000/69149]
loss: 0.166863  [38400/69149]
loss: 0.205164  [44800/69149]
loss: 0.206001  [51200/69149]
loss: 0.207436  [57600/69149]
loss: 0.175540  [64000/69149]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.155529 

Epoch 4
-------------------------------
loss: 0.139713  [    0/69149]
loss: 0.107412  [ 6400/69149]
loss: 0.146468  [12800/69149]
loss: 0.052769  [19200/69149]
loss: 0.098753  [25600/69149]
loss: 0.219093  [32000/69149]
loss: 0.084488  [38400/69149]
loss: 0.093543  [44800/69149]
loss: 0.127130  [51200/69149]
loss: 0.233686  [57600/69149]
loss: 0.063275  [64000/69149]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.156201 

Epoch 5
-------------------------------
loss: 0.140516  [    0/69149]
loss: 0.084883  [ 6400/69149]
loss: 0.173649  [12800/69149]
loss: 0.262492  [19200/69149]
loss: 0.087621  [25600/69149]
loss: 0.255400  [32000/69149]
loss: 0.199307  [38400/69149]
loss: 0.266345  [44800/69149]
loss: 0.113873  [51200/69149]
loss: 0.175967  [57600/69149]
loss: 0.199039  [64000/69149]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.147928 

Epoch 6
-------------------------------
loss: 0.145720  [    0/69149]
loss: 0.063701  [ 6400/69149]
loss: 0.081544  [12800/69149]
loss: 0.060713  [19200/69149]
loss: 0.266685  [25600/69149]
loss: 0.085601  [32000/69149]
loss: 0.162103  [38400/69149]
loss: 0.078098  [44800/69149]
loss: 0.117718  [51200/69149]
loss: 0.313081  [57600/69149]
loss: 0.097325  [64000/69149]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.145604 

Epoch 7
-------------------------------
loss: 0.124935  [    0/69149]
loss: 0.039911  [ 6400/69149]
loss: 0.115935  [12800/69149]
loss: 0.107299  [19200/69149]
loss: 0.107131  [25600/69149]
loss: 0.139570  [32000/69149]
loss: 0.163712  [38400/69149]
loss: 0.097799  [44800/69149]
loss: 0.119570  [51200/69149]
loss: 0.038852  [57600/69149]
loss: 0.181056  [64000/69149]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.131510 

Epoch 8
-------------------------------
loss: 0.069068  [    0/69149]
loss: 0.188907  [ 6400/69149]
loss: 0.137942  [12800/69149]
loss: 0.154095  [19200/69149]
loss: 0.097769  [25600/69149]
loss: 0.068563  [32000/69149]
loss: 0.103317  [38400/69149]
loss: 0.174073  [44800/69149]
loss: 0.154618  [51200/69149]
loss: 0.133197  [57600/69149]
loss: 0.083549  [64000/69149]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.128059 

Epoch 9
-------------------------------
loss: 0.131212  [    0/69149]
loss: 0.108112  [ 6400/69149]
loss: 0.288962  [12800/69149]
loss: 0.076654  [19200/69149]
loss: 0.119408  [25600/69149]
loss: 0.079997  [32000/69149]
loss: 0.102507  [38400/69149]
loss: 0.175030  [44800/69149]
loss: 0.101320  [51200/69149]
loss: 0.141690  [57600/69149]
loss: 0.157257  [64000/69149]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.134145 

Epoch 10
-------------------------------
loss: 0.161379  [    0/69149]
loss: 0.129367  [ 6400/69149]
loss: 0.106008  [12800/69149]
loss: 0.200696  [19200/69149]
loss: 0.145655  [25600/69149]
loss: 0.097427  [32000/69149]
loss: 0.128504  [38400/69149]
loss: 0.201147  [44800/69149]
loss: 0.169101  [51200/69149]
loss: 0.219606  [57600/69149]
loss: 0.176192  [64000/69149]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.137308 

Epoch 11
-------------------------------
loss: 0.114956  [    0/69149]
loss: 0.160662  [ 6400/69149]
loss: 0.075390  [12800/69149]
loss: 0.136077  [19200/69149]
loss: 0.126945  [25600/69149]
loss: 0.038338  [32000/69149]
loss: 0.156556  [38400/69149]
loss: 0.097247  [44800/69149]
loss: 0.159407  [51200/69149]
loss: 0.192893  [57600/69149]
loss: 0.072107  [64000/69149]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.131481 

Epoch 12
-------------------------------
loss: 0.099860  [    0/69149]
loss: 0.105213  [ 6400/69149]
loss: 0.035809  [12800/69149]
loss: 0.093267  [19200/69149]
loss: 0.108760  [25600/69149]
loss: 0.028742  [32000/69149]
loss: 0.115089  [38400/69149]
loss: 0.137145  [44800/69149]
loss: 0.060912  [51200/69149]
loss: 0.084468  [57600/69149]
loss: 0.162452  [64000/69149]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.137564 

Epoch 13
-------------------------------
loss: 0.122522  [    0/69149]
loss: 0.066273  [ 6400/69149]
loss: 0.097501  [12800/69149]
loss: 0.240940  [19200/69149]
loss: 0.160526  [25600/69149]
loss: 0.081642  [32000/69149]
loss: 0.069372  [38400/69149]
loss: 0.132115  [44800/69149]
loss: 0.144272  [51200/69149]
loss: 0.155810  [57600/69149]
loss: 0.082855  [64000/69149]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.130470 

Epoch 14
-------------------------------
loss: 0.073876  [    0/69149]
loss: 0.162989  [ 6400/69149]
loss: 0.121093  [12800/69149]
loss: 0.136388  [19200/69149]
loss: 0.070523  [25600/69149]
loss: 0.182529  [32000/69149]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139722 

Epoch 33
-------------------------------
loss: 0.198839  [    0/70227]
loss: 0.058835  [ 6400/70227]
loss: 0.152299  [12800/70227]
loss: 0.161571  [19200/70227]
loss: 0.090826  [25600/70227]
loss: 0.146834  [32000/70227]
loss: 0.136964  [38400/70227]
loss: 0.133077  [44800/70227]
loss: 0.072502  [51200/70227]
loss: 0.087082  [57600/70227]
loss: 0.096296  [64000/70227]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.185338 

Epoch 34
-------------------------------
loss: 0.158891  [    0/70227]
loss: 0.095978  [ 6400/70227]
loss: 0.154459  [12800/70227]
loss: 0.146762  [19200/70227]
loss: 0.220433  [25600/70227]
loss: 0.247078  [32000/70227]
loss: 0.174200  [38400/70227]
loss: 0.068657  [44800/70227]
loss: 0.169553  [51200/70227]
loss: 0.201534  [57600/70227]
loss: 0.138240  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.137904 

Epoch 35
-------------------------------
loss: 0.075519  [    0/70227]
loss: 0.091039  [ 6400/70227]
loss: 0.110539  [12800/70227]
loss: 0.233830  [19200/70227]
loss: 0.127830  [25600/70227]
loss: 0.108318  [32000/70227]
loss: 0.100856  [38400/70227]
loss: 0.102417  [44800/70227]
loss: 0.109392  [51200/70227]
loss: 0.148518  [57600/70227]
loss: 0.078021  [64000/70227]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.158079 

Epoch 36
-------------------------------
loss: 0.034207  [    0/70227]
loss: 0.180466  [ 6400/70227]
loss: 0.053671  [12800/70227]
loss: 0.150071  [19200/70227]
loss: 0.148141  [25600/70227]
loss: 0.088600  [32000/70227]
loss: 0.196311  [38400/70227]
loss: 0.185775  [44800/70227]
loss: 0.154349  [51200/70227]
loss: 0.236922  [57600/70227]
loss: 0.129759  [64000/70227]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.141581 

Epoch 37
-------------------------------
loss: 0.112744  [    0/70227]
loss: 0.085275  [ 6400/70227]
loss: 0.128743  [12800/70227]
loss: 0.224170  [19200/70227]
loss: 0.069783  [25600/70227]
loss: 0.093605  [32000/70227]
loss: 0.256508  [38400/70227]
loss: 0.139650  [44800/70227]
loss: 0.149299  [51200/70227]
loss: 0.136576  [57600/70227]
loss: 0.103136  [64000/70227]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140275 

Epoch 38
-------------------------------
loss: 0.137392  [    0/70227]
loss: 0.155798  [ 6400/70227]
loss: 0.044832  [12800/70227]
loss: 0.080800  [19200/70227]
loss: 0.199918  [25600/70227]
loss: 0.123620  [32000/70227]
loss: 0.100633  [38400/70227]
loss: 0.037331  [44800/70227]
loss: 0.087989  [51200/70227]
loss: 0.093514  [57600/70227]
loss: 0.147695  [64000/70227]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.138988 

Epoch 39
-------------------------------
loss: 0.118073  [    0/70227]
loss: 0.169905  [ 6400/70227]
loss: 0.163143  [12800/70227]
loss: 0.176282  [19200/70227]
loss: 0.023059  [25600/70227]
loss: 0.195604  [32000/70227]
loss: 0.302019  [38400/70227]
loss: 0.112884  [44800/70227]
loss: 0.118049  [51200/70227]
loss: 0.223500  [57600/70227]
loss: 0.111332  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.141419 

Epoch 40
-------------------------------
loss: 0.043231  [    0/70227]
loss: 0.162500  [ 6400/70227]
loss: 0.090398  [12800/70227]
loss: 0.080037  [19200/70227]
loss: 0.188403  [25600/70227]
loss: 0.199848  [32000/70227]
loss: 0.116624  [38400/70227]
loss: 0.246719  [44800/70227]
loss: 0.154824  [51200/70227]
loss: 0.135215  [57600/70227]
loss: 0.121809  [64000/70227]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170089 

Epoch 41
-------------------------------
loss: 0.234028  [    0/70227]
loss: 0.125565  [ 6400/70227]
loss: 0.146590  [12800/70227]
loss: 0.062481  [19200/70227]
loss: 0.071788  [25600/70227]
loss: 0.242204  [32000/70227]
loss: 0.156106  [38400/70227]
loss: 0.062995  [44800/70227]
loss: 0.039907  [51200/70227]
loss: 0.140518  [57600/70227]
loss: 0.057364  [64000/70227]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.136512 

Epoch 42
-------------------------------
loss: 0.145184  [    0/70227]
loss: 0.120107  [ 6400/70227]
loss: 0.099026  [12800/70227]
loss: 0.169488  [19200/70227]
loss: 0.133232  [25600/70227]
loss: 0.090091  [32000/70227]
loss: 0.168354  [38400/70227]
loss: 0.122771  [44800/70227]
loss: 0.080416  [51200/70227]
loss: 0.145697  [57600/70227]
loss: 0.132435  [64000/70227]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.148671 

Epoch 43
-------------------------------
loss: 0.088794  [    0/70227]
loss: 0.075368  [ 6400/70227]
loss: 0.136730  [12800/70227]
loss: 0.089659  [19200/70227]
loss: 0.075299  [25600/70227]
loss: 0.076154  [32000/70227]
loss: 0.172675  [38400/70227]
loss: 0.053044  [44800/70227]
loss: 0.056893  [51200/70227]
loss: 0.099963  [57600/70227]
loss: 0.175517  [64000/70227]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.143530 

Epoch 44
-------------------------------
loss: 0.066033  [    0/70227]
loss: 0.183022  [ 6400/70227]
loss: 0.191744  [12800/70227]
loss: 0.040482  [19200/70227]
loss: 0.164575  [25600/70227]
loss: 0.142409  [32000/70227]
loss: 0.107519  [38400/70227]
loss: 0.079245  [44800/70227]
loss: 0.147387  [51200/70227]
loss: 0.247856  [57600/70227]
loss: 0.215447  [64000/70227]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.164250 

Epoch 45
-------------------------------
loss: 0.201580  [    0/70227]
loss: 0.113007  [ 6400/70227]
loss: 0.062843  [12800/70227]
loss: 0.152380  [19200/70227]
loss: 0.277264  [25600/70227]
loss: 0.114117  [32000/70227]
loss: 0.183161  [38400/70227]
loss: 0.098603  [44800/70227]
loss: 0.071287  [51200/70227]
loss: 0.106974  [57600/70227]
loss: 0.063660  [64000/70227]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.140581 

Epoch 46
-------------------------------
loss: 0.108716  [    0/70227]
loss: 0.185780  [ 6400/70227]
loss: 0.228987  [12800/70227]
loss: 0.061343  [19200/70227]
loss: 0.182410  [25600/70227]
loss: 0.028248  [32000/70227]
loss: 0.066771  [38400/70227]
loss: 0.250771  [44800/70227]
loss: 0.098825  [51200/70227]
loss: 0.072989  [57600/70227]
loss: 0.179873  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.138480 

Epoch 47
-------------------------------
loss: 0.078802  [    0/70227]
loss: 0.147445  [ 6400/70227]
loss: 0.101771  [12800/70227]
loss: 0.077731  [19200/70227]
loss: 0.142213  [25600/70227]
loss: 0.125974  [32000/70227]
loss: 0.216760  [38400/70227]
loss: 0.119929  [44800/70227]
loss: 0.124074  [51200/70227]
loss: 0.088718  [57600/70227]
loss: 0.154519  [64000/70227]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.152810 

Epoch 48
-------------------------------
loss: 0.203356  [    0/70227]
loss: 0.038573  [ 6400/70227]
loss: 0.081020  [12800/70227]
loss: 0.048802  [19200/70227]
loss: 0.072816  [25600/70227]
loss: 0.086071  [32000/70227]
loss: 0.198495  [38400/70227]
loss: 0.104776  [44800/70227]
loss: 0.128140  [51200/70227]
loss: 0.033937  [57600/70227]
loss: 0.151001  [64000/70227]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.207449 

Epoch 49
-------------------------------
loss: 0.129770  [    0/70227]
loss: 0.105805  [ 6400/70227]
loss: 0.112038  [12800/70227]
loss: 0.109778  [19200/70227]
loss: 0.178830  [25600/70227]
loss: 0.080273  [32000/70227]
loss: 0.191949  [38400/70227]
loss: 0.191422  [44800/70227]
loss: 0.141646  [51200/70227]
loss: 0.160746  [57600/70227]
loss: 0.086621  [64000/70227]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.141023 

Epoch 50
-------------------------------
loss: 0.098666  [    0/70227]
loss: 0.103122  [ 6400/70227]
loss: 0.129662  [12800/70227]
loss: 0.041185  [19200/70227]
loss: 0.171722  [25600/70227]
loss: 0.155782  [32000/70227]
loss: 0.055416  [38400/70227]
loss: 0.087730  [44800/70227]
loss: 0.204685  [51200/70227]
loss: 0.080685  [57600/70227]
loss: 0.109229  [64000/70227]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140278 

Epoch 1
-------------------------------
loss: 0.626494  [    0/70500]
loss: 0.329092  [ 6400/70500]
loss: 1.799587  [12800/70500]
loss: 0.197368  [19200/70500]
loss: 0.317595  [25600/70500]
loss: 0.206640  [32000/70500]
loss: 0.334895  [38400/70500]
loss: 0.223194  [44800/70500]
loss: 0.217061  [51200/70500]
loss: 0.203921  [57600/70500]
loss: 0.146930  [64000/70500]
loss: 0.239293  [70400/70500]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.238609 

Epoch 2
-------------------------------
loss: 1.754846  [    0/70500]
2022/09/20 15:26:37 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110104 

Epoch 49
-------------------------------
loss: 0.074846  [    0/71414]
loss: 0.131764  [ 6400/71414]
loss: 0.118829  [12800/71414]
loss: 0.060516  [19200/71414]
loss: 0.054171  [25600/71414]
loss: 0.112779  [32000/71414]
loss: 0.052402  [38400/71414]
loss: 0.054929  [44800/71414]
loss: 0.031511  [51200/71414]
loss: 0.114573  [57600/71414]
loss: 0.057665  [64000/71414]
loss: 0.110812  [70400/71414]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110967 

Epoch 50
-------------------------------
loss: 0.135262  [    0/71414]
loss: 0.108485  [ 6400/71414]
loss: 0.040128  [12800/71414]
loss: 0.069141  [19200/71414]
loss: 0.078561  [25600/71414]
loss: 0.062850  [32000/71414]
loss: 0.011194  [38400/71414]
loss: 0.102145  [44800/71414]
loss: 0.134872  [51200/71414]
loss: 0.052679  [57600/71414]
loss: 0.144535  [64000/71414]
loss: 0.074217  [70400/71414]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112918 

Epoch 1
-------------------------------
loss: 0.615256  [    0/69807]
loss: 0.251659  [ 6400/69807]
loss: 0.273937  [12800/69807]
loss: 0.360390  [19200/69807]
loss: 0.281988  [25600/69807]
loss: 0.120226  [32000/69807]
loss: 0.225786  [38400/69807]
loss: 0.165496  [44800/69807]
loss: 0.142148  [51200/69807]
loss: 0.206742  [57600/69807]
loss: 0.153447  [64000/69807]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.188968 

Epoch 2
-------------------------------
loss: 0.156438  [    0/69807]
loss: 0.145378  [ 6400/69807]
loss: 0.210648  [12800/69807]
loss: 0.249447  [19200/69807]
loss: 0.171248  [25600/69807]
loss: 0.259676  [32000/69807]
loss: 0.193121  [38400/69807]
loss: 0.167303  [44800/69807]
loss: 0.235357  [51200/69807]
loss: 0.100746  [57600/69807]
loss: 0.242700  [64000/69807]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.173934 

Epoch 3
-------------------------------
loss: 0.225635  [    0/69807]
loss: 0.092681  [ 6400/69807]
loss: 0.205635  [12800/69807]
loss: 0.146482  [19200/69807]
loss: 0.123180  [25600/69807]
loss: 0.250952  [32000/69807]
loss: 0.247308  [38400/69807]
loss: 0.088492  [44800/69807]
loss: 0.057233  [51200/69807]
loss: 0.160582  [57600/69807]
loss: 0.194837  [64000/69807]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.168023 

Epoch 4
-------------------------------
loss: 0.102931  [    0/69807]
loss: 0.204787  [ 6400/69807]
loss: 0.250194  [12800/69807]
loss: 1.663789  [19200/69807]
loss: 0.101268  [25600/69807]
loss: 0.103797  [32000/69807]
loss: 0.264337  [38400/69807]
loss: 0.168709  [44800/69807]
loss: 0.127720  [51200/69807]
loss: 0.185523  [57600/69807]
loss: 0.126079  [64000/69807]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.161575 

Epoch 5
-------------------------------
loss: 0.111730  [    0/69807]
loss: 0.097825  [ 6400/69807]
loss: 0.095605  [12800/69807]
loss: 0.123434  [19200/69807]
loss: 0.120932  [25600/69807]
loss: 0.087669  [32000/69807]
loss: 0.271852  [38400/69807]
loss: 0.161484  [44800/69807]
loss: 0.063129  [51200/69807]
loss: 0.124157  [57600/69807]
loss: 0.158937  [64000/69807]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.170429 

Epoch 6
-------------------------------
loss: 0.041669  [    0/69807]
loss: 0.145462  [ 6400/69807]
loss: 0.226766  [12800/69807]
loss: 0.128598  [19200/69807]
loss: 0.097876  [25600/69807]
loss: 0.090006  [32000/69807]
loss: 0.124510  [38400/69807]
loss: 0.130240  [44800/69807]
loss: 0.147402  [51200/69807]
loss: 0.207291  [57600/69807]
loss: 0.303859  [64000/69807]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.153022 

Epoch 7
-------------------------------
loss: 0.159434  [    0/69807]
loss: 0.190477  [ 6400/69807]
loss: 0.189872  [12800/69807]
loss: 0.267672  [19200/69807]
loss: 0.086060  [25600/69807]
loss: 0.219264  [32000/69807]
loss: 0.091390  [38400/69807]
loss: 0.083867  [44800/69807]
loss: 0.105046  [51200/69807]
loss: 0.116660  [57600/69807]
loss: 0.225711  [64000/69807]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.185568 

Epoch 8
-------------------------------
loss: 0.190281  [    0/69807]
loss: 0.061483  [ 6400/69807]
loss: 0.142004  [12800/69807]
loss: 0.291077  [19200/69807]
loss: 0.069808  [25600/69807]
loss: 0.162000  [32000/69807]
loss: 0.132347  [38400/69807]
loss: 0.091365  [44800/69807]
loss: 0.080672  [51200/69807]
loss: 0.075894  [57600/69807]
loss: 0.108593  [64000/69807]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.155405 

Epoch 9
-------------------------------
loss: 0.193303  [    0/69807]
loss: 0.119044  [ 6400/69807]
loss: 0.134353  [12800/69807]
loss: 0.140657  [19200/69807]
loss: 0.115352  [25600/69807]
loss: 0.121243  [32000/69807]
loss: 0.099928  [38400/69807]
loss: 0.104771  [44800/69807]
loss: 0.067668  [51200/69807]
loss: 0.144353  [57600/69807]
loss: 0.103743  [64000/69807]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.165863 

Epoch 10
-------------------------------
loss: 0.084158  [    0/69807]
loss: 0.065008  [ 6400/69807]
loss: 0.067607  [12800/69807]
loss: 0.101457  [19200/69807]
loss: 0.205350  [25600/69807]
loss: 0.110512  [32000/69807]
loss: 0.109628  [38400/69807]
loss: 0.059329  [44800/69807]
loss: 0.100957  [51200/69807]
loss: 0.161425  [57600/69807]
loss: 0.164367  [64000/69807]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.146427 

Epoch 11
-------------------------------
loss: 0.229731  [    0/69807]
loss: 0.080310  [ 6400/69807]
loss: 0.113121  [12800/69807]
loss: 0.026340  [19200/69807]
loss: 0.122531  [25600/69807]
loss: 0.187053  [32000/69807]
loss: 0.073844  [38400/69807]
loss: 0.195263  [44800/69807]
loss: 0.183443  [51200/69807]
loss: 0.132203  [57600/69807]
loss: 0.124059  [64000/69807]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.150683 

Epoch 12
-------------------------------
loss: 0.165385  [    0/69807]
loss: 0.084040  [ 6400/69807]
loss: 0.158511  [12800/69807]
loss: 0.081949  [19200/69807]
loss: 0.065458  [25600/69807]
loss: 0.132105  [32000/69807]
loss: 0.064167  [38400/69807]
loss: 0.100502  [44800/69807]
loss: 0.089992  [51200/69807]
loss: 0.161367  [57600/69807]
loss: 0.053407  [64000/69807]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.153281 

Epoch 13
-------------------------------
loss: 0.066398  [    0/69807]
loss: 0.133161  [ 6400/69807]
loss: 0.183758  [12800/69807]
loss: 0.203700  [19200/69807]
loss: 0.184317  [25600/69807]
loss: 0.193166  [32000/69807]
loss: 0.189894  [38400/69807]
loss: 0.193116  [44800/69807]
loss: 0.108094  [51200/69807]
loss: 0.153906  [57600/69807]
loss: 0.120276  [64000/69807]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.148114 

Epoch 14
-------------------------------
loss: 0.067757  [    0/69807]
loss: 0.263355  [ 6400/69807]
loss: 0.165336  [12800/69807]
loss: 0.025101  [19200/69807]
loss: 0.139547  [25600/69807]
loss: 0.221200  [32000/69807]
loss: 0.058955  [38400/69807]
loss: 0.172095  [44800/69807]
loss: 0.171822  [51200/69807]
loss: 0.221048  [57600/69807]
loss: 0.125841  [64000/69807]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.147175 

Epoch 15
-------------------------------
loss: 0.129254  [    0/69807]
loss: 0.045090  [ 6400/69807]
loss: 0.158901  [12800/69807]
loss: 0.224705  [19200/69807]
loss: 0.128550  [25600/69807]
loss: 0.213397  [32000/69807]
loss: 0.030341  [38400/69807]
loss: 0.125403  [44800/69807]
loss: 0.197949  [51200/69807]
loss: 0.182180  [57600/69807]
loss: 0.130154  [64000/69807]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.148735 

Epoch 16
-------------------------------
loss: 0.186864  [    0/69807]
loss: 0.275146  [ 6400/69807]
loss: 0.073366  [12800/69807]
loss: 0.043211  [19200/69807]
loss: 0.146648  [25600/69807]
loss: 0.170256  [32000/69807]
loss: 0.057802  [38400/69807]
loss: 0.140929  [44800/69807]
loss: 0.100417  [51200/69807]
loss: 0.137456  [57600/69807]
loss: 0.357157  [64000/69807]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.152143 

Epoch 17
-------------------------------
loss: 0.198211  [    0/69807]
loss: 0.130261  [ 6400/69807]
loss: 0.165282  [12800/69807]
loss: 0.126660  [19200/69807]
loss: 0.256106  [25600/69807]
loss: 0.056728  [32000/69807]
loss: 0.136247  [38400/69807]
loss: 0.259665  [44800/69807]
loss: 0.152184  [51200/69807]
loss: 0.167910  [57600/69807]
loss: 0.177148  [64000/69807]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.188108 

Epoch 18
-------------------------------
loss: 0.351148  [44800/70446]
loss: 0.115788  [51200/70446]
loss: 0.102203  [57600/70446]
loss: 0.076939  [64000/70446]
loss: 0.087622  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.143859 

Epoch 46
-------------------------------
loss: 0.131097  [    0/70446]
loss: 0.030502  [ 6400/70446]
loss: 0.148302  [12800/70446]
loss: 0.177693  [19200/70446]
loss: 0.101950  [25600/70446]
loss: 0.064233  [32000/70446]
loss: 0.096516  [38400/70446]
loss: 0.088708  [44800/70446]
loss: 0.122683  [51200/70446]
loss: 0.100644  [57600/70446]
loss: 0.248368  [64000/70446]
loss: 0.164215  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.153363 

Epoch 47
-------------------------------
loss: 0.172924  [    0/70446]
loss: 0.207538  [ 6400/70446]
loss: 0.063410  [12800/70446]
loss: 0.130184  [19200/70446]
loss: 0.031379  [25600/70446]
loss: 0.178129  [32000/70446]
loss: 0.175677  [38400/70446]
loss: 0.143103  [44800/70446]
loss: 0.037593  [51200/70446]
loss: 0.150579  [57600/70446]
loss: 0.026936  [64000/70446]
loss: 0.195301  [50600/70446]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.138626 

Epoch 48
-------------------------------
loss: 0.097692  [    0/70446]
loss: 0.126988  [ 6400/70446]
loss: 0.104038  [12800/70446]
loss: 0.105885  [19200/70446]
loss: 0.083165  [25600/70446]
loss: 0.082660  [32000/70446]
loss: 0.082636  [38400/70446]
loss: 0.087539  [44800/70446]
loss: 0.138448  [51200/70446]
loss: 0.120473  [57600/70446]
loss: 0.115950  [64000/70446]
loss: 0.158958  [50600/70446]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.143283 

Epoch 49
-------------------------------
loss: 0.040249  [    0/70446]
loss: 0.160277  [ 6400/70446]
loss: 0.113102  [12800/70446]
loss: 0.160809  [19200/70446]
loss: 0.162148  [25600/70446]
loss: 0.120340  [32000/70446]
loss: 0.176994  [38400/70446]
loss: 0.079723  [44800/70446]
loss: 0.083516  [51200/70446]
loss: 0.120464  [57600/70446]
loss: 0.115885  [64000/70446]
loss: 0.082388  [50600/70446]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.144270 

Epoch 50
-------------------------------
loss: 0.218538  [    0/70446]
loss: 0.147350  [ 6400/70446]
loss: 0.077375  [12800/70446]
loss: 0.122963  [19200/70446]
loss: 0.067030  [25600/70446]
loss: 0.152181  [32000/70446]
loss: 0.150697  [38400/70446]
loss: 0.440930  [44800/70446]
loss: 0.124211  [51200/70446]
loss: 0.169875  [57600/70446]
loss: 0.065148  [64000/70446]
loss: 0.101461  [50600/70446]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.146315 

Epoch 1
-------------------------------
loss: 0.658494  [    0/71622]
loss: 0.227859  [ 6400/71622]
loss: 0.308121  [12800/71622]
loss: 1.797303  [19200/71622]
loss: 0.219894  [25600/71622]
loss: 0.073705  [32000/71622]
loss: 0.194686  [38400/71622]
loss: 0.171801  [44800/71622]
loss: 0.179671  [51200/71622]
loss: 0.237036  [57600/71622]
loss: 0.110840  [64000/71622]
loss: 0.076812  [70400/71622]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.167679 

Epoch 2
-------------------------------
loss: 0.046855  [    0/71622]
loss: 0.092650  [ 6400/71622]
loss: 0.124212  [12800/71622]
loss: 0.180864  [19200/71622]
loss: 0.109629  [25600/71622]
loss: 0.306954  [32000/71622]
loss: 0.084043  [38400/71622]
loss: 0.233482  [44800/71622]
loss: 0.062217  [51200/71622]
loss: 0.074967  [57600/71622]
loss: 0.045396  [64000/71622]
loss: 0.243501  [70400/71622]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.166035 

Epoch 3
-------------------------------
loss: 0.211199  [    0/71622]
loss: 0.112956  [ 6400/71622]
loss: 0.049058  [12800/71622]
loss: 0.112410  [19200/71622]
loss: 0.046032  [25600/71622]
loss: 0.023427  [32000/71622]
loss: 0.064884  [38400/71622]
loss: 0.091641  [44800/71622]
loss: 0.044720  [51200/71622]
loss: 0.106459  [57600/71622]
loss: 0.140614  [64000/71622]
loss: 0.059941  [70400/71622]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.159543 

Epoch 4
-------------------------------
loss: 0.100711  [    0/71622]
loss: 0.094082  [ 6400/71622]
loss: 0.022464  [12800/71622]
loss: 0.042366  [19200/71622]
loss: 0.090568  [25600/71622]
loss: 0.063190  [32000/71622]
loss: 0.093175  [38400/71622]
loss: 0.141788  [44800/71622]
loss: 0.198872  [51200/71622]
loss: 1.594819  [57600/71622]
loss: 0.147449  [64000/71622]
loss: 0.081321  [70400/71622]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.147023 

Epoch 5
-------------------------------
loss: 0.132242  [    0/71622]
loss: 0.052603  [ 6400/71622]
loss: 0.173660  [12800/71622]
loss: 0.095232  [19200/71622]
loss: 0.099330  [25600/71622]
loss: 0.104536  [32000/71622]
loss: 0.029606  [38400/71622]
loss: 0.105592  [44800/71622]
loss: 0.052853  [51200/71622]
loss: 0.070114  [57600/71622]
loss: 0.136667  [64000/71622]
loss: 0.054727  [70400/71622]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.150738 

Epoch 6
-------------------------------
loss: 0.139466  [    0/71622]
loss: 0.058006  [ 6400/71622]
loss: 0.067764  [12800/71622]
loss: 0.182221  [19200/71622]
loss: 0.050437  [25600/71622]
loss: 0.105989  [32000/71622]
loss: 0.059809  [38400/71622]
loss: 0.078149  [44800/71622]
loss: 0.017069  [51200/71622]
loss: 0.039856  [57600/71622]
loss: 0.144807  [64000/71622]
loss: 0.104101  [70400/71622]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.144739 

Epoch 7
-------------------------------
loss: 0.052030  [    0/71622]
loss: 0.191059  [ 6400/71622]
loss: 1.672899  [12800/71622]
loss: 0.069318  [19200/71622]
loss: 0.091008  [25600/71622]
loss: 0.070194  [32000/71622]
loss: 0.088718  [38400/71622]
loss: 0.146561  [44800/71622]
loss: 0.051644  [51200/71622]
loss: 0.067661  [57600/71622]
loss: 0.081239  [64000/71622]
loss: 0.150523  [70400/71622]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.143685 

Epoch 8
-------------------------------
loss: 0.157975  [    0/71622]
loss: 0.057815  [ 6400/71622]
loss: 0.098266  [12800/71622]
loss: 0.057740  [19200/71622]
loss: 0.083309  [25600/71622]
loss: 0.091136  [32000/71622]
loss: 0.054327  [38400/71622]
loss: 0.081591  [44800/71622]
loss: 0.248375  [51200/71622]
loss: 0.149402  [57600/71622]
loss: 0.086294  [64000/71622]
loss: 0.072278  [70400/71622]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.149817 

Epoch 9
-------------------------------
loss: 0.070780  [    0/71622]
loss: 0.108772  [ 6400/71622]
loss: 0.068118  [12800/71622]
loss: 0.046489  [19200/71622]
loss: 0.112204  [25600/71622]
loss: 0.061255  [32000/71622]
loss: 0.113636  [38400/71622]
loss: 0.078549  [44800/71622]
loss: 0.042980  [51200/71622]
loss: 0.126581  [57600/71622]
loss: 0.078142  [64000/71622]
loss: 0.101358  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.133574 

Epoch 10
-------------------------------
loss: 0.205404  [    0/71622]
loss: 0.022881  [ 6400/71622]
loss: 0.182564  [12800/71622]
loss: 0.081116  [19200/71622]
loss: 0.158372  [25600/71622]
loss: 0.020153  [32000/71622]
loss: 0.049838  [38400/71622]
loss: 0.055426  [44800/71622]
loss: 0.195698  [51200/71622]
loss: 0.120324  [57600/71622]
loss: 0.045463  [64000/71622]
loss: 0.068360  [70400/71622]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.145456 

Epoch 11
-------------------------------
loss: 0.054783  [    0/71622]
loss: 0.040489  [ 6400/71622]
loss: 0.137106  [12800/71622]
loss: 0.077727  [19200/71622]
loss: 0.164837  [25600/71622]
loss: 0.051879  [32000/71622]
loss: 0.027601  [38400/71622]
loss: 0.201963  [44800/71622]
loss: 0.099189  [51200/71622]
loss: 0.110566  [57600/71622]
loss: 0.042119  [64000/71622]
loss: 0.067188  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.134841 

Epoch 12
-------------------------------
loss: 0.091136  [    0/71622]
loss: 0.092087  [ 6400/71622]
loss: 0.046515  [12800/71622]
loss: 0.076604  [19200/71622]
loss: 0.082278  [25600/71622]
loss: 0.043841  [32000/71622]
loss: 0.078285  [38400/71622]
loss: 0.118270  [44800/71622]
loss: 0.107693  [51200/71622]
loss: 0.054021  [57600/71622]
loss: 0.111195  [64000/71622]
loss: 0.185185  [70400/71622]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.132802 

Epoch 13
-------------------------------
loss: 0.047239  [    0/71622]
loss: 0.057122  [ 6400/71622]
loss: 0.064462  [12800/71622]
loss: 0.124377  [19200/71622]
loss: 0.075365  [25600/71622]
loss: 0.107936  [32000/71622]
loss: 0.017716  [38400/71622]
loss: 0.109613  [44800/71622]
loss: 0.034655  [44800/71130]
loss: 0.195940  [51200/71130]
loss: 0.069650  [57600/71130]
loss: 0.007732  [64000/71130]
loss: 0.064074  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.070171 

Epoch 46
-------------------------------
loss: 0.051699  [    0/71130]
loss: 0.134623  [ 6400/71130]
loss: 0.017974  [12800/71130]
loss: 0.033070  [19200/71130]
loss: 0.057604  [25600/71130]
loss: 0.079777  [32000/71130]
loss: 0.056480  [38400/71130]
loss: 0.199049  [44800/71130]
loss: 0.097961  [51200/71130]
loss: 0.150790  [57600/71130]
loss: 0.052581  [64000/71130]
loss: 0.009681  [70400/71130]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.081117 

Epoch 47
-------------------------------
loss: 0.034991  [    0/71130]
loss: 0.016039  [ 6400/71130]
loss: 0.036597  [12800/71130]
loss: 0.164650  [19200/71130]
loss: 0.012610  [25600/71130]
loss: 0.028334  [32000/71130]
loss: 0.102423  [38400/71130]
loss: 0.014445  [44800/71130]
loss: 0.111543  [51200/71130]
loss: 0.057070  [57600/71130]
loss: 0.062644  [64000/71130]
loss: 0.031125  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073483 

Epoch 48
-------------------------------
loss: 0.024630  [    0/71130]
loss: 0.006655  [ 6400/71130]
loss: 0.030057  [12800/71130]
loss: 0.030163  [19200/71130]
loss: 0.157604  [25600/71130]
loss: 0.064169  [32000/71130]
loss: 0.072738  [38400/71130]
loss: 0.052331  [44800/71130]
loss: 0.048869  [51200/71130]
loss: 0.140195  [57600/71130]
loss: 0.013710  [64000/71130]
loss: 0.126415  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.074109 

Epoch 49
-------------------------------
loss: 0.023232  [    0/71130]
loss: 0.032224  [ 6400/71130]
loss: 0.090143  [12800/71130]
loss: 0.116002  [19200/71130]
loss: 0.047672  [25600/71130]
loss: 0.085481  [32000/71130]
loss: 0.070827  [38400/71130]
loss: 0.065272  [44800/71130]
loss: 0.066867  [51200/71130]
loss: 0.017853  [57600/71130]
loss: 0.070422  [64000/71130]
loss: 0.021369  [70400/71130]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073056 

Epoch 50
-------------------------------
loss: 0.013285  [    0/71130]
loss: 0.043408  [ 6400/71130]
loss: 0.038257  [12800/71130]
loss: 0.036703  [19200/71130]
loss: 0.009725  [25600/71130]
loss: 0.018933  [32000/71130]
loss: 0.008250  [38400/71130]
loss: 0.228069  [44800/71130]
loss: 0.017167  [51200/71130]
loss: 0.124374  [57600/71130]
loss: 0.123277  [64000/71130]
loss: 0.025488  [70400/71130]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071393 

Epoch 1
-------------------------------
loss: 0.650314  [    0/70935]
loss: 0.450963  [ 6400/70935]
loss: 0.221165  [12800/70935]
loss: 0.347324  [19200/70935]
loss: 0.214847  [25600/70935]
loss: 0.220256  [32000/70935]
loss: 0.235224  [38400/70935]
loss: 0.246456  [44800/70935]
loss: 0.238060  [51200/70935]
loss: 0.225054  [57600/70935]
loss: 0.205425  [64000/70935]
loss: 0.243692  [70400/70935]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.213387 

Epoch 2
-------------------------------
loss: 0.191569  [    0/70935]
loss: 0.168759  [ 6400/70935]
loss: 0.136989  [12800/70935]
loss: 0.261832  [19200/70935]
loss: 0.254380  [25600/70935]
loss: 0.278041  [32000/70935]
loss: 0.128149  [38400/70935]
loss: 0.122693  [44800/70935]
loss: 0.079462  [51200/70935]
loss: 0.208384  [57600/70935]
loss: 0.205828  [64000/70935]
loss: 0.230718  [70400/70935]
Test Error: 
 Accuracy: 91.1%, Avg loss: 0.242224 

Epoch 3
-------------------------------
loss: 0.194891  [    0/70935]
loss: 0.246192  [ 6400/70935]
loss: 0.120053  [12800/70935]
loss: 0.237816  [19200/70935]
loss: 0.116125  [25600/70935]
loss: 0.167216  [32000/70935]
loss: 0.199451  [38400/70935]
loss: 0.105863  [44800/70935]
loss: 0.148977  [51200/70935]
loss: 0.143238  [57600/70935]
loss: 0.092161  [64000/70935]
loss: 0.354031  [70400/70935]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.184966 

Epoch 4
-------------------------------
loss: 0.122390  [    0/70935]
loss: 0.180681  [ 6400/70935]
loss: 0.167887  [12800/70935]
loss: 0.259977  [19200/70935]
loss: 0.235732  [25600/70935]
loss: 0.218057  [32000/70935]
loss: 0.130376  [38400/70935]
loss: 0.097282  [44800/70935]
loss: 0.133741  [51200/70935]
loss: 0.131696  [57600/70935]
loss: 0.188452  [64000/70935]
loss: 0.079114  [70400/70935]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.173739 

Epoch 5
-------------------------------
loss: 0.160459  [    0/70935]
loss: 0.120871  [ 6400/70935]
loss: 0.188777  [12800/70935]
loss: 0.133969  [19200/70935]
loss: 0.158001  [25600/70935]
loss: 0.369513  [32000/70935]
loss: 0.191602  [38400/70935]
loss: 0.131878  [44800/70935]
loss: 0.177479  [51200/70935]
loss: 0.152563  [57600/70935]
loss: 0.275963  [64000/70935]
loss: 0.177735  [70400/70935]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.170846 

Epoch 6
-------------------------------
loss: 0.126339  [    0/70935]
loss: 0.128172  [ 6400/70935]
loss: 0.104196  [12800/70935]
loss: 0.163861  [19200/70935]
loss: 0.139667  [25600/70935]
loss: 0.188680  [32000/70935]
loss: 0.131064  [38400/70935]
loss: 0.178094  [44800/70935]
loss: 0.115525  [51200/70935]
loss: 0.205057  [57600/70935]
loss: 0.070835  [64000/70935]
loss: 0.099681  [70400/70935]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.173969 

Epoch 7
-------------------------------
loss: 0.145405  [    0/70935]
loss: 0.266042  [ 6400/70935]
loss: 0.172330  [12800/70935]
loss: 0.346171  [19200/70935]
loss: 0.081321  [25600/70935]
loss: 0.209540  [32000/70935]
loss: 0.166709  [38400/70935]
loss: 0.205070  [44800/70935]
loss: 0.166022  [51200/70935]
loss: 0.130968  [57600/70935]
loss: 0.097380  [64000/70935]
loss: 0.116001  [70400/70935]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.158303 

Epoch 8
-------------------------------
loss: 0.116207  [    0/70935]
loss: 0.127710  [ 6400/70935]
loss: 0.102979  [12800/70935]
loss: 0.118049  [19200/70935]
loss: 0.127137  [25600/70935]
loss: 0.128095  [32000/70935]
loss: 0.139327  [38400/70935]
loss: 0.152928  [44800/70935]
loss: 0.203485  [51200/70935]
loss: 0.201127  [57600/70935]
loss: 0.105390  [64000/70935]
loss: 0.185227  [70400/70935]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.165095 

Epoch 9
-------------------------------
loss: 0.100876  [    0/70935]
loss: 0.210869  [ 6400/70935]
loss: 0.157708  [12800/70935]
loss: 0.171332  [19200/70935]
loss: 0.140224  [25600/70935]
loss: 0.161501  [32000/70935]
loss: 0.131164  [38400/70935]
loss: 0.109827  [44800/70935]
loss: 1.785497  [51200/70935]
loss: 0.112990  [57600/70935]
loss: 0.156550  [64000/70935]
loss: 0.081645  [70400/70935]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.150985 

Epoch 10
-------------------------------
loss: 0.159621  [    0/70935]
loss: 0.173233  [ 6400/70935]
loss: 0.110796  [12800/70935]
loss: 0.283960  [19200/70935]
loss: 0.143484  [25600/70935]
loss: 0.189791  [32000/70935]
loss: 0.132629  [38400/70935]
loss: 0.106511  [44800/70935]
loss: 0.196879  [51200/70935]
loss: 0.224525  [57600/70935]
loss: 0.158389  [64000/70935]
loss: 0.096281  [70400/70935]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.163650 

Epoch 11
-------------------------------
loss: 0.101057  [    0/70935]
loss: 0.091628  [ 6400/70935]
loss: 0.171637  [12800/70935]
loss: 0.174846  [19200/70935]
loss: 0.116361  [25600/70935]
loss: 0.081381  [32000/70935]
loss: 0.164415  [38400/70935]
loss: 0.142597  [44800/70935]
loss: 0.147298  [51200/70935]
loss: 0.142453  [57600/70935]
loss: 0.155063  [64000/70935]
loss: 0.191156  [70400/70935]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.157594 

Epoch 12
-------------------------------
loss: 0.124756  [    0/70935]
loss: 0.107189  [ 6400/70935]
loss: 0.114649  [12800/70935]
loss: 0.193101  [19200/70935]
loss: 0.120617  [25600/70935]
loss: 0.116643  [32000/70935]
loss: 0.158240  [38400/70935]
loss: 0.156156  [44800/70935]
loss: 0.109489  [51200/70935]
loss: 0.236806  [57600/70935]
loss: 0.167040  [64000/70935]
loss: 0.090578  [70400/70935]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.158411 

Epoch 13
-------------------------------
loss: 0.121340  [    0/70935]
loss: 0.132448  [ 6400/70935]
loss: 0.282867  [12800/70935]
loss: 0.190699  [19200/70935]
loss: 0.132211  [25600/70935]
loss: 0.068272  [32000/70935]
loss: 0.138119  [38400/70935]
loss: 0.129162  [44800/70935]
loss: 0.079586  [44800/71180]
loss: 0.012363  [51200/71180]
loss: 0.039166  [57600/71180]
loss: 0.080224  [64000/71180]
loss: 0.033331  [70400/71180]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.133680 

Epoch 46
-------------------------------
loss: 0.079536  [    0/71180]
loss: 0.036731  [ 6400/71180]
loss: 0.083665  [12800/71180]
loss: 0.102292  [19200/71180]
loss: 0.171304  [25600/71180]
loss: 0.150931  [32000/71180]
loss: 0.046049  [38400/71180]
loss: 0.109836  [44800/71180]
loss: 0.237006  [51200/71180]
loss: 0.056026  [57600/71180]
loss: 0.106775  [64000/71180]
loss: 0.097717  [70400/71180]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.125482 

Epoch 47
-------------------------------
loss: 0.063654  [    0/71180]
loss: 0.023591  [ 6400/71180]
loss: 0.014825  [12800/71180]
loss: 0.160682  [19200/71180]
loss: 0.145736  [25600/71180]
loss: 0.040214  [32000/71180]
loss: 0.087045  [38400/71180]
loss: 0.011685  [44800/71180]
loss: 0.020091  [51200/71180]
loss: 0.051632  [57600/71180]
loss: 0.032785  [64000/71180]
loss: 0.094532  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.127546 

Epoch 48
-------------------------------
loss: 0.032356  [    0/71180]
loss: 0.024525  [ 6400/71180]
loss: 0.123258  [12800/71180]
loss: 0.073110  [19200/71180]
loss: 0.120576  [25600/71180]
loss: 0.213158  [32000/71180]
loss: 0.116063  [38400/71180]
loss: 0.035384  [44800/71180]
loss: 0.048927  [51200/71180]
loss: 0.061290  [57600/71180]
loss: 0.065114  [64000/71180]
loss: 0.077929  [70400/71180]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.137289 

Epoch 49
-------------------------------
loss: 0.045973  [    0/71180]
loss: 0.072078  [ 6400/71180]
loss: 0.048352  [12800/71180]
loss: 0.083528  [19200/71180]
loss: 0.035330  [25600/71180]
loss: 0.085545  [32000/71180]
loss: 0.173563  [38400/71180]
loss: 0.295619  [44800/71180]
loss: 0.020799  [51200/71180]
loss: 0.034514  [57600/71180]
loss: 0.048277  [64000/71180]
loss: 0.159332  [70400/71180]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.173305 

Epoch 50
-------------------------------
loss: 0.021740  [    0/71180]
loss: 0.034380  [ 6400/71180]
loss: 0.023727  [12800/71180]
loss: 0.042243  [19200/71180]
loss: 0.032433  [25600/71180]
loss: 0.038632  [32000/71180]
loss: 0.086229  [38400/71180]
loss: 0.056667  [44800/71180]
loss: 0.107066  [51200/71180]
loss: 0.139441  [57600/71180]
loss: 0.059106  [64000/71180]
loss: 0.041688  [70400/71180]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.126798 

Epoch 1
-------------------------------
loss: 0.647011  [    0/69264]
loss: 0.307598  [ 6400/69264]
loss: 0.260843  [12800/69264]
loss: 0.270846  [19200/69264]
loss: 0.250029  [25600/69264]
loss: 0.260030  [32000/69264]
loss: 0.193378  [38400/69264]
loss: 0.219285  [44800/69264]
loss: 0.216955  [51200/69264]
loss: 0.115480  [57600/69264]
loss: 0.260674  [64000/69264]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.203291 

Epoch 2
-------------------------------
loss: 0.279701  [    0/69264]
loss: 0.138572  [ 6400/69264]
loss: 0.067854  [12800/69264]
loss: 0.340163  [19200/69264]
loss: 0.113682  [25600/69264]
loss: 0.102042  [32000/69264]
loss: 0.185317  [38400/69264]
loss: 0.232599  [44800/69264]
loss: 0.132711  [51200/69264]
loss: 0.096636  [57600/69264]
loss: 0.086336  [64000/69264]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.187443 

Epoch 3
-------------------------------
loss: 0.125131  [    0/69264]
loss: 0.223966  [ 6400/69264]
loss: 0.186456  [12800/69264]
loss: 0.161218  [19200/69264]
loss: 0.259453  [25600/69264]
loss: 0.118667  [32000/69264]
loss: 0.215147  [38400/69264]
loss: 0.170552  [44800/69264]
loss: 0.191949  [51200/69264]
loss: 0.122597  [57600/69264]
loss: 0.252429  [64000/69264]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.177967 

Epoch 4
-------------------------------
loss: 0.263321  [    0/69264]
loss: 0.063569  [ 6400/69264]
loss: 0.157253  [12800/69264]
loss: 0.251887  [19200/69264]
loss: 0.159735  [25600/69264]
loss: 0.145414  [32000/69264]
loss: 0.193767  [38400/69264]
loss: 0.226854  [44800/69264]
loss: 0.091868  [51200/69264]
loss: 0.165781  [57600/69264]
loss: 0.097476  [64000/69264]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.160910 

Epoch 5
-------------------------------
loss: 0.226875  [    0/69264]
loss: 0.125196  [ 6400/69264]
loss: 0.203196  [12800/69264]
loss: 0.187355  [19200/69264]
loss: 0.140753  [25600/69264]
loss: 0.130550  [32000/69264]
loss: 0.154729  [38400/69264]
loss: 0.145716  [44800/69264]
loss: 0.080813  [51200/69264]
loss: 0.156899  [57600/69264]
loss: 0.205162  [64000/69264]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.163492 

Epoch 6
-------------------------------
loss: 0.133040  [    0/69264]
loss: 0.133871  [ 6400/69264]
loss: 0.078956  [12800/69264]
loss: 0.130944  [19200/69264]
loss: 0.127585  [25600/69264]
loss: 0.230279  [32000/69264]
loss: 0.152896  [38400/69264]
loss: 0.122904  [44800/69264]
loss: 0.203495  [51200/69264]
loss: 0.161556  [57600/69264]
loss: 0.214338  [64000/69264]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.167280 

Epoch 7
-------------------------------
loss: 0.100910  [    0/69264]
loss: 0.111238  [ 6400/69264]
loss: 0.198158  [12800/69264]
loss: 0.437933  [19200/69264]
loss: 0.097330  [25600/69264]
loss: 0.239948  [32000/69264]
loss: 0.237957  [38400/69264]
loss: 0.196151  [44800/69264]
loss: 0.100304  [51200/69264]
loss: 0.255363  [57600/69264]
loss: 0.228361  [64000/69264]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.168064 

Epoch 8
-------------------------------
loss: 0.203869  [    0/69264]
loss: 0.110541  [ 6400/69264]
loss: 0.182186  [12800/69264]
loss: 0.200950  [19200/69264]
loss: 0.133093  [25600/69264]
loss: 0.149316  [32000/69264]
loss: 0.226845  [38400/69264]
loss: 0.112869  [44800/69264]
loss: 0.145109  [51200/69264]
loss: 0.147413  [57600/69264]
loss: 0.183428  [64000/69264]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.158970 

Epoch 9
-------------------------------
loss: 0.211472  [    0/69264]
loss: 0.237385  [ 6400/69264]
loss: 0.095990  [12800/69264]
loss: 0.135258  [19200/69264]
loss: 0.192795  [25600/69264]
loss: 0.100427  [32000/69264]
loss: 0.149374  [38400/69264]
loss: 0.091292  [44800/69264]
loss: 0.083064  [51200/69264]
loss: 0.182849  [57600/69264]
loss: 0.103097  [64000/69264]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.159584 

Epoch 10
-------------------------------
loss: 0.213572  [    0/69264]
loss: 0.145249  [ 6400/69264]
loss: 0.114112  [12800/69264]
loss: 0.192292  [19200/69264]
loss: 0.129616  [25600/69264]
loss: 0.122595  [32000/69264]
loss: 0.125617  [38400/69264]
loss: 0.193125  [44800/69264]
loss: 0.157352  [51200/69264]
loss: 0.165489  [57600/69264]
loss: 0.082457  [64000/69264]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.160061 

Epoch 11
-------------------------------
loss: 0.296123  [    0/69264]
loss: 0.073465  [ 6400/69264]
loss: 0.228811  [12800/69264]
loss: 0.226782  [19200/69264]
loss: 0.252633  [25600/69264]
loss: 0.147570  [32000/69264]
loss: 0.093979  [38400/69264]
loss: 0.169856  [44800/69264]
loss: 0.175034  [51200/69264]
loss: 0.107712  [57600/69264]
loss: 0.084091  [64000/69264]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.167167 

Epoch 12
-------------------------------
loss: 0.217105  [    0/69264]
loss: 0.217655  [ 6400/69264]
loss: 0.215167  [12800/69264]
loss: 0.160654  [19200/69264]
loss: 0.086276  [25600/69264]
loss: 0.192094  [32000/69264]
loss: 0.245483  [38400/69264]
loss: 0.082388  [44800/69264]
loss: 0.260157  [51200/69264]
loss: 0.206668  [57600/69264]
loss: 0.096784  [64000/69264]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.158177 

Epoch 13
-------------------------------
loss: 0.176644  [    0/69264]
loss: 0.174207  [ 6400/69264]
loss: 0.229009  [12800/69264]
loss: 0.110356  [19200/69264]
loss: 0.115740  [25600/69264]
loss: 0.172536  [32000/69264]
loss: 0.194366  [38400/69264]
loss: 0.318260  [44800/69264]
loss: 0.425875  [51200/69264]
loss: 0.136507  [57600/69264]
loss: 0.194951  [64000/69264]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.164945 

Epoch 14
-------------------------------
loss: 0.081544  [    0/69264]
loss: 0.134260  [ 6400/69264]
loss: 0.138769  [12800/69264]
loss: 0.276874  [19200/69264]
loss: 0.114501  [25600/69264]
loss: 0.154014  [32000/69264]
loss: 0.106989  [51200/70010]
loss: 0.171409  [57600/70010]
loss: 0.119873  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089004 

Epoch 49
-------------------------------
loss: 0.068769  [    0/70010]
loss: 0.037066  [ 6400/70010]
loss: 0.078456  [12800/70010]
loss: 0.082368  [19200/70010]
loss: 0.036447  [25600/70010]
loss: 0.069163  [32000/70010]
loss: 0.120594  [38400/70010]
loss: 0.053245  [44800/70010]
loss: 0.063226  [51200/70010]
loss: 0.152427  [57600/70010]
loss: 0.054468  [64000/70010]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.096501 

Epoch 50
-------------------------------
loss: 0.097728  [    0/70010]
loss: 0.049004  [ 6400/70010]
loss: 0.035690  [12800/70010]
loss: 0.048389  [19200/70010]
loss: 0.046594  [25600/70010]
loss: 0.066598  [32000/70010]
loss: 0.106509  [38400/70010]
loss: 0.095246  [44800/70010]
loss: 0.052311  [51200/70010]
loss: 0.082448  [57600/70010]
loss: 0.100382  [64000/70010]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.097084 

Epoch 1
-------------------------------
loss: 0.676870  [    0/70702]
loss: 0.295327  [ 6400/70702]
loss: 0.236369  [12800/70702]
loss: 0.363354  [19200/70702]
loss: 0.297256  [25600/70702]
loss: 0.264226  [32000/70702]
loss: 0.213972  [38400/70702]
loss: 0.203838  [44800/70702]
loss: 0.243573  [51200/70702]
loss: 0.090014  [57600/70702]
loss: 0.172584  [64000/70702]
loss: 0.104906  [70400/70702]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.228007 

Epoch 2
-------------------------------
loss: 1.695059  [    0/70702]
loss: 0.154104  [ 6400/70702]
loss: 0.249966  [12800/70702]
loss: 0.156499  [19200/70702]
loss: 0.242348  [25600/70702]
loss: 0.126902  [32000/70702]
loss: 0.145217  [38400/70702]
loss: 0.094669  [44800/70702]
loss: 0.218005  [51200/70702]
loss: 0.164056  [57600/70702]
loss: 0.128405  [64000/70702]
loss: 0.154385  [70400/70702]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.189967 

Epoch 3
-------------------------------
loss: 0.175399  [    0/70702]
loss: 0.149085  [ 6400/70702]
loss: 0.309331  [12800/70702]
loss: 0.211770  [19200/70702]
loss: 0.171955  [25600/70702]
loss: 0.200760  [32000/70702]
loss: 0.101974  [38400/70702]
loss: 0.129044  [44800/70702]
loss: 0.145993  [51200/70702]
loss: 0.135541  [57600/70702]
loss: 0.168656  [64000/70702]
loss: 0.270640  [70400/70702]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.189726 

Epoch 4
-------------------------------
loss: 0.225500  [    0/70702]
loss: 0.238165  [ 6400/70702]
loss: 0.187156  [12800/70702]
loss: 0.088316  [19200/70702]
loss: 0.103989  [25600/70702]
loss: 0.212251  [32000/70702]
loss: 0.099269  [38400/70702]
loss: 0.216180  [44800/70702]
loss: 0.086313  [51200/70702]
loss: 0.134086  [57600/70702]
loss: 0.184585  [64000/70702]
loss: 0.134516  [70400/70702]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.172920 

Epoch 5
-------------------------------
loss: 0.149199  [    0/70702]
loss: 0.242445  [ 6400/70702]
loss: 0.087568  [12800/70702]
loss: 0.136170  [19200/70702]
loss: 0.139437  [25600/70702]
loss: 0.163036  [32000/70702]
loss: 0.164615  [38400/70702]
loss: 0.147707  [44800/70702]
loss: 0.132221  [51200/70702]
loss: 0.209737  [57600/70702]
loss: 0.159071  [64000/70702]
loss: 0.137771  [70400/70702]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174567 

Epoch 6
-------------------------------
loss: 0.168754  [    0/70702]
loss: 0.144720  [ 6400/70702]
loss: 0.116517  [12800/70702]
loss: 0.212061  [19200/70702]
loss: 0.131736  [25600/70702]
loss: 0.111390  [32000/70702]
loss: 0.153378  [38400/70702]
loss: 0.182045  [44800/70702]
loss: 0.208639  [51200/70702]
loss: 0.156502  [57600/70702]
loss: 0.200947  [64000/70702]
loss: 0.180102  [70400/70702]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.173298 

Epoch 7
-------------------------------
loss: 0.233736  [    0/70702]
loss: 0.188356  [ 6400/70702]
loss: 0.188395  [12800/70702]
loss: 0.137695  [19200/70702]
loss: 0.121280  [25600/70702]
loss: 0.149165  [32000/70702]
loss: 0.161342  [38400/70702]
loss: 0.190067  [44800/70702]
loss: 0.141824  [51200/70702]
loss: 0.125243  [57600/70702]
loss: 0.088616  [64000/70702]
loss: 0.109123  [70400/70702]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173578 

Epoch 8
-------------------------------
loss: 0.159314  [    0/70702]
loss: 0.053002  [ 6400/70702]
loss: 0.168849  [12800/70702]
loss: 1.702508  [19200/70702]
loss: 0.059356  [25600/70702]
loss: 0.134194  [32000/70702]
loss: 0.119485  [38400/70702]
loss: 0.091136  [44800/70702]
loss: 0.106994  [51200/70702]
loss: 0.159234  [57600/70702]
loss: 0.181037  [64000/70702]
loss: 0.137498  [70400/70702]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174745 

Epoch 9
-------------------------------
loss: 0.143949  [    0/70702]
loss: 0.211808  [ 6400/70702]
loss: 0.100102  [12800/70702]
loss: 0.186857  [19200/70702]
loss: 0.395812  [25600/70702]
loss: 0.142625  [32000/70702]
loss: 0.193046  [38400/70702]
loss: 0.114883  [44800/70702]
loss: 0.198598  [51200/70702]
loss: 0.105950  [57600/70702]
loss: 0.146262  [64000/70702]
loss: 0.110810  [70400/70702]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.170165 

Epoch 10
-------------------------------
loss: 0.165736  [    0/70702]
loss: 0.118008  [ 6400/70702]
loss: 0.116504  [12800/70702]
loss: 0.093616  [19200/70702]
loss: 0.110184  [25600/70702]
loss: 0.102407  [32000/70702]
loss: 0.093801  [38400/70702]
loss: 0.170092  [44800/70702]
loss: 0.210565  [51200/70702]
loss: 0.266608  [57600/70702]
loss: 0.390528  [64000/70702]
loss: 0.181335  [70400/70702]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.181221 

Epoch 11
-------------------------------
loss: 0.178617  [    0/70702]
loss: 0.131279  [ 6400/70702]
loss: 0.029036  [12800/70702]
loss: 0.212376  [19200/70702]
loss: 0.166098  [25600/70702]
loss: 0.179299  [32000/70702]
loss: 0.164361  [38400/70702]
loss: 0.083234  [44800/70702]
loss: 0.068537  [51200/70702]
loss: 0.323334  [57600/70702]
loss: 0.039274  [64000/70702]
loss: 0.120149  [70400/70702]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.172241 

Epoch 12
-------------------------------
loss: 0.076537  [    0/70702]
loss: 0.177497  [ 6400/70702]
loss: 0.258916  [12800/70702]
loss: 0.128406  [19200/70702]
loss: 0.149932  [25600/70702]
loss: 0.117284  [32000/70702]
loss: 0.182622  [38400/70702]
loss: 0.226378  [44800/70702]
loss: 0.081068  [51200/70702]
loss: 0.176448  [57600/70702]
loss: 0.088219  [64000/70702]
loss: 0.113633  [70400/70702]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.176975 

Epoch 13
-------------------------------
loss: 0.229174  [    0/70702]
loss: 0.163420  [ 6400/70702]
loss: 0.167701  [12800/70702]
loss: 0.097298  [19200/70702]
loss: 0.109259  [25600/70702]
loss: 0.085336  [32000/70702]
loss: 0.149543  [38400/70702]
loss: 0.120403  [44800/70702]
loss: 1.664647  [51200/70702]
loss: 0.149331  [57600/70702]
loss: 0.134435  [64000/70702]
loss: 0.215644  [70400/70702]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.174742 

Epoch 14
-------------------------------
loss: 0.125306  [    0/70702]
loss: 0.079800  [ 6400/70702]
loss: 0.145128  [12800/70702]
loss: 0.063711  [19200/70702]
loss: 0.127400  [25600/70702]
loss: 0.122924  [32000/70702]
loss: 0.077078  [38400/70702]
loss: 0.119480  [44800/70702]
loss: 0.216139  [51200/70702]
loss: 0.113519  [57600/70702]
loss: 0.115538  [64000/70702]
loss: 0.162276  [70400/70702]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.168408 

Epoch 15
-------------------------------
loss: 0.127946  [    0/70702]
loss: 0.139171  [ 6400/70702]
loss: 0.029166  [12800/70702]
loss: 0.167581  [19200/70702]
loss: 0.194467  [25600/70702]
loss: 0.139078  [32000/70702]
loss: 0.120776  [38400/70702]
loss: 0.266842  [44800/70702]
loss: 0.097953  [51200/70702]
loss: 0.164715  [57600/70702]
loss: 0.276619  [64000/70702]
loss: 0.082678  [70400/70702]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.161849 

Epoch 16
-------------------------------
loss: 0.154499  [    0/70702]
loss: 0.143379  [ 6400/70702]
loss: 0.099897  [12800/70702]
loss: 0.190760  [19200/70702]
loss: 0.147023  [25600/70702]
loss: 0.111006  [32000/70702]
loss: 0.108190  [38400/70702]
loss: 0.249577  [44800/70702]
loss: 0.155194  [51200/70702]
loss: 0.096872  [57600/70702]
loss: 0.173935  [64000/70702]
loss: 0.072939  [70400/70702]
loss: 0.071365  [44800/70482]
loss: 0.152370  [51200/70482]
loss: 0.160867  [57600/70482]
loss: 0.219434  [64000/70482]
loss: 0.097237  [70400/70482]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.179949 

Epoch 46
-------------------------------
loss: 0.188301  [    0/70482]
loss: 0.123628  [ 6400/70482]
loss: 0.088391  [12800/70482]
loss: 0.120431  [19200/70482]
loss: 0.057240  [25600/70482]
loss: 0.128718  [32000/70482]
loss: 0.162383  [38400/70482]
loss: 0.170278  [44800/70482]
loss: 0.078620  [51200/70482]
loss: 0.068921  [57600/70482]
loss: 0.070240  [64000/70482]
loss: 0.128189  [70400/70482]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.144463 

Epoch 47
-------------------------------
loss: 0.097645  [    0/70482]
loss: 0.103704  [ 6400/70482]
loss: 0.070978  [12800/70482]
loss: 0.089350  [19200/70482]
loss: 0.039784  [25600/70482]
loss: 0.123351  [32000/70482]
loss: 0.127846  [38400/70482]
loss: 0.141916  [44800/70482]
loss: 0.120485  [51200/70482]
loss: 0.062172  [57600/70482]
loss: 0.175468  [64000/70482]
loss: 0.169941  [70400/70482]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.146051 

Epoch 48
-------------------------------
loss: 0.153898  [    0/70482]
loss: 0.108935  [ 6400/70482]
loss: 0.112023  [12800/70482]
loss: 0.090338  [19200/70482]
loss: 0.097445  [25600/70482]
loss: 0.078070  [32000/70482]
loss: 0.067461  [38400/70482]
loss: 0.105848  [44800/70482]
loss: 0.154067  [51200/70482]
loss: 0.108646  [57600/70482]
loss: 0.101742  [64000/70482]
loss: 0.050555  [70400/70482]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.153271 

Epoch 49
-------------------------------
loss: 0.053144  [    0/70482]
loss: 0.166035  [ 6400/70482]
loss: 0.060560  [12800/70482]
loss: 0.066278  [19200/70482]
loss: 0.111292  [25600/70482]
loss: 0.128859  [32000/70482]
loss: 0.117803  [38400/70482]
loss: 0.113036  [44800/70482]
loss: 0.094741  [51200/70482]
loss: 0.163739  [57600/70482]
loss: 0.211121  [64000/70482]
loss: 0.089465  [70400/70482]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.146306 

Epoch 50
-------------------------------
loss: 0.095738  [    0/70482]
loss: 0.075819  [ 6400/70482]
loss: 0.097240  [12800/70482]
loss: 0.110329  [19200/70482]
loss: 0.135365  [25600/70482]
loss: 0.110088  [32000/70482]
loss: 0.102965  [38400/70482]
loss: 0.078994  [44800/70482]
loss: 0.094435  [51200/70482]
loss: 0.076886  [57600/70482]
loss: 0.087052  [64000/70482]
loss: 0.075020  [70400/70482]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.145751 

Epoch 1
-------------------------------
loss: 0.646566  [    0/69635]
loss: 0.184186  [ 6400/69635]
loss: 0.353946  [12800/69635]
loss: 0.210013  [19200/69635]
loss: 0.160462  [25600/69635]
loss: 0.222587  [32000/69635]
loss: 0.244654  [38400/69635]
loss: 0.259238  [44800/69635]
loss: 0.211654  [51200/69635]
loss: 0.206542  [57600/69635]
loss: 0.278739  [64000/69635]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.197532 

Epoch 2
-------------------------------
loss: 0.356806  [    0/69635]
loss: 0.143170  [ 6400/69635]
loss: 0.199976  [12800/69635]
loss: 0.193724  [19200/69635]
loss: 0.155489  [25600/69635]
loss: 0.169021  [32000/69635]
loss: 0.162702  [38400/69635]
loss: 0.137685  [44800/69635]
loss: 0.229494  [51200/69635]
loss: 0.118955  [57600/69635]
loss: 0.167088  [64000/69635]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.186261 

Epoch 3
-------------------------------
loss: 0.158474  [    0/69635]
loss: 0.284485  [ 6400/69635]
loss: 0.083932  [12800/69635]
loss: 0.177549  [19200/69635]
loss: 0.121465  [25600/69635]
loss: 0.205827  [32000/69635]
loss: 0.123202  [38400/69635]
loss: 0.180393  [44800/69635]
loss: 0.159939  [51200/69635]
loss: 0.167203  [57600/69635]
loss: 0.125167  [64000/69635]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171814 

Epoch 4
-------------------------------
loss: 0.154196  [    0/69635]
loss: 0.195974  [ 6400/69635]
loss: 0.228675  [12800/69635]
loss: 0.169218  [19200/69635]
loss: 0.108761  [25600/69635]
loss: 0.251831  [32000/69635]
loss: 0.187546  [38400/69635]
loss: 0.216933  [44800/69635]
loss: 0.153825  [51200/69635]
loss: 0.249721  [57600/69635]
loss: 0.326555  [64000/69635]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.170548 

Epoch 5
-------------------------------
loss: 0.061865  [    0/69635]
loss: 0.075591  [ 6400/69635]
loss: 0.128564  [12800/69635]
loss: 0.235440  [19200/69635]
loss: 0.191714  [25600/69635]
loss: 0.202192  [32000/69635]
loss: 0.151829  [38400/69635]
loss: 0.117353  [44800/69635]
loss: 0.184443  [51200/69635]
loss: 0.153055  [57600/69635]
loss: 0.172811  [64000/69635]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.172438 

Epoch 6
-------------------------------
loss: 0.157431  [    0/69635]
loss: 0.295189  [ 6400/69635]
loss: 0.178559  [12800/69635]
loss: 0.123251  [19200/69635]
loss: 0.044469  [25600/69635]
loss: 0.254440  [32000/69635]
loss: 0.126607  [38400/69635]
loss: 0.300587  [44800/69635]
loss: 0.140597  [51200/69635]
loss: 0.203003  [57600/69635]
loss: 0.111419  [64000/69635]
Test Error: 
 Accuracy: 90.8%, Avg loss: 0.243000 

Epoch 7
-------------------------------
loss: 0.240956  [    0/69635]
loss: 0.188815  [ 6400/69635]
loss: 0.087012  [12800/69635]
loss: 0.222947  [19200/69635]
loss: 0.111478  [25600/69635]
loss: 0.098825  [32000/69635]
loss: 0.096215  [38400/69635]
loss: 0.152737  [44800/69635]
loss: 0.113487  [51200/69635]
loss: 0.168167  [57600/69635]
loss: 0.172898  [64000/69635]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.160329 

Epoch 8
-------------------------------
loss: 0.119350  [    0/69635]
loss: 0.181426  [ 6400/69635]
loss: 0.057120  [12800/69635]
loss: 0.230221  [19200/69635]
loss: 0.063091  [25600/69635]
loss: 0.133673  [32000/69635]
loss: 0.151274  [38400/69635]
loss: 0.158844  [44800/69635]
loss: 0.115659  [51200/69635]
loss: 0.148030  [57600/69635]
loss: 0.172910  [64000/69635]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.171994 

Epoch 9
-------------------------------
loss: 0.214276  [    0/69635]
loss: 0.172858  [ 6400/69635]
loss: 1.926399  [12800/69635]
loss: 0.072594  [19200/69635]
loss: 0.135584  [25600/69635]
loss: 0.153573  [32000/69635]
loss: 0.198729  [38400/69635]
loss: 0.120155  [44800/69635]
loss: 0.231637  [51200/69635]
loss: 0.159694  [57600/69635]
loss: 0.194685  [64000/69635]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.167278 

Epoch 10
-------------------------------
loss: 0.126284  [    0/69635]
loss: 0.132720  [ 6400/69635]
loss: 0.259138  [12800/69635]
loss: 0.192118  [19200/69635]
loss: 0.066277  [25600/69635]
loss: 0.208874  [32000/69635]
loss: 0.097814  [38400/69635]
loss: 0.118040  [44800/69635]
loss: 0.192376  [51200/69635]
loss: 0.238964  [57600/69635]
loss: 0.096740  [64000/69635]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.173181 

Epoch 11
-------------------------------
loss: 0.203276  [    0/69635]
loss: 0.172538  [ 6400/69635]
loss: 0.172227  [12800/69635]
loss: 0.167699  [19200/69635]
loss: 0.238956  [25600/69635]
loss: 0.111767  [32000/69635]
loss: 0.133748  [38400/69635]
loss: 0.159508  [44800/69635]
loss: 0.444102  [51200/69635]
loss: 0.166980  [57600/69635]
loss: 0.147887  [64000/69635]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.163204 

Epoch 12
-------------------------------
loss: 0.079237  [    0/69635]
loss: 0.174303  [ 6400/69635]
loss: 0.101893  [12800/69635]
loss: 0.267016  [19200/69635]
loss: 0.159380  [25600/69635]
loss: 0.170076  [32000/69635]
loss: 0.317001  [38400/69635]
loss: 0.149308  [44800/69635]
loss: 0.129323  [51200/69635]
loss: 0.281131  [57600/69635]
loss: 0.279597  [64000/69635]
Test Error: 
 Accuracy: 86.8%, Avg loss: 0.312977 

Epoch 13
-------------------------------
loss: 0.189120  [    0/69635]
loss: 0.113442  [ 6400/69635]
loss: 0.152041  [12800/69635]
loss: 0.238147  [19200/69635]
loss: 0.101933  [25600/69635]
loss: 0.128816  [32000/69635]
loss: 0.231685  [38400/69635]
loss: 0.256295  [44800/69635]
loss: 0.094058  [51200/69635]
loss: 0.301598  [57600/69635]
loss: 0.186428  [64000/69635]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153698 

Epoch 14
-------------------------------
loss: 0.197815  [    0/69635]
loss: 0.237295  [ 6400/69635]
loss: 0.193683  [12800/69635]
loss: 0.121364  [19200/69635]
loss: 0.186477  [25600/69635]
loss: 0.127106  [32000/69635]
loss: 0.034618  [38400/69985]
loss: 0.041915  [44800/69985]
loss: 0.058136  [51200/69985]
loss: 0.040029  [57600/69985]
loss: 0.049665  [64000/69985]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084734 

Epoch 37
-------------------------------
loss: 0.072326  [    0/69985]
loss: 0.031191  [ 6400/69985]
loss: 0.050510  [12800/69985]
loss: 0.083774  [19200/69985]
loss: 0.055154  [25600/69985]
loss: 0.037877  [32000/69985]
loss: 0.049684  [38400/69985]
loss: 0.104851  [44800/69985]
loss: 0.240232  [51200/69985]
loss: 0.036833  [57600/69985]
loss: 0.042675  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080364 

Epoch 38
-------------------------------
loss: 0.048179  [    0/69985]
loss: 0.033692  [ 6400/69985]
loss: 0.012727  [12800/69985]
loss: 0.103716  [19200/69985]
loss: 0.081407  [25600/69985]
loss: 0.059139  [32000/69985]
loss: 0.015351  [38400/69985]
loss: 0.013256  [44800/69985]
loss: 0.048998  [51200/69985]
loss: 0.124963  [57600/69985]
loss: 0.046177  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.079629 

Epoch 39
-------------------------------
loss: 0.037682  [    0/69985]
loss: 0.021405  [ 6400/69985]
loss: 0.046299  [12800/69985]
loss: 0.019044  [19200/69985]
loss: 0.017130  [25600/69985]
loss: 0.081513  [32000/69985]
loss: 0.024996  [38400/69985]
loss: 0.196562  [44800/69985]
loss: 0.196978  [51200/69985]
loss: 0.022758  [57600/69985]
loss: 0.013995  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.085770 

Epoch 40
-------------------------------
loss: 0.036348  [    0/69985]
loss: 0.063268  [ 6400/69985]
loss: 0.171855  [12800/69985]
loss: 0.039099  [19200/69985]
loss: 0.083136  [25600/69985]
loss: 0.101739  [32000/69985]
loss: 0.077053  [38400/69985]
loss: 0.039411  [44800/69985]
loss: 0.025239  [51200/69985]
loss: 0.022728  [57600/69985]
loss: 0.079196  [64000/69985]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.087226 

Epoch 41
-------------------------------
loss: 0.089877  [    0/69985]
loss: 0.069905  [ 6400/69985]
loss: 0.010074  [12800/69985]
loss: 0.105564  [19200/69985]
loss: 0.076775  [25600/69985]
loss: 0.024307  [32000/69985]
loss: 0.103321  [38400/69985]
loss: 0.117151  [44800/69985]
loss: 0.043563  [51200/69985]
loss: 0.078660  [57600/69985]
loss: 0.023482  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.083449 

Epoch 42
-------------------------------
loss: 0.145482  [    0/69985]
loss: 0.022054  [ 6400/69985]
loss: 0.046159  [12800/69985]
loss: 0.066731  [19200/69985]
loss: 0.060985  [25600/69985]
loss: 0.046068  [32000/69985]
loss: 0.032344  [38400/69985]
loss: 0.026834  [44800/69985]
loss: 0.107463  [51200/69985]
loss: 0.112803  [57600/69985]
loss: 0.020306  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.085152 

Epoch 43
-------------------------------
loss: 0.049951  [    0/69985]
loss: 0.040995  [ 6400/69985]
loss: 0.123527  [12800/69985]
loss: 0.100713  [19200/69985]
loss: 0.031506  [25600/69985]
loss: 0.076324  [32000/69985]
loss: 0.069540  [38400/69985]
loss: 0.070864  [44800/69985]
loss: 0.039101  [51200/69985]
loss: 0.085043  [57600/69985]
loss: 0.049183  [64000/69985]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.093041 

Epoch 44
-------------------------------
loss: 0.035228  [    0/69985]
loss: 0.062635  [ 6400/69985]
loss: 0.036913  [12800/69985]
loss: 0.081289  [19200/69985]
loss: 0.155906  [25600/69985]
loss: 0.071139  [32000/69985]
loss: 0.030003  [38400/69985]
loss: 0.069288  [44800/69985]
loss: 0.074894  [51200/69985]
loss: 0.032143  [57600/69985]
loss: 0.100631  [64000/69985]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.082976 

Epoch 45
-------------------------------
loss: 0.073793  [    0/69985]
loss: 0.072750  [ 6400/69985]
loss: 0.037537  [12800/69985]
loss: 0.030956  [19200/69985]
loss: 0.032368  [25600/69985]
loss: 0.066737  [32000/69985]
loss: 0.025077  [38400/69985]
loss: 0.104892  [44800/69985]
loss: 0.075186  [51200/69985]
loss: 0.042819  [57600/69985]
loss: 0.092286  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.087899 

Epoch 46
-------------------------------
loss: 0.061737  [    0/69985]
loss: 0.055707  [ 6400/69985]
loss: 0.054556  [12800/69985]
loss: 0.045034  [19200/69985]
loss: 0.093311  [25600/69985]
loss: 0.094886  [32000/69985]
loss: 0.051157  [38400/69985]
loss: 0.090542  [44800/69985]
loss: 0.074694  [51200/69985]
loss: 0.064768  [57600/69985]
loss: 0.022390  [64000/69985]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.088621 

Epoch 47
-------------------------------
loss: 0.053433  [    0/69985]
loss: 0.114795  [ 6400/69985]
loss: 0.101901  [12800/69985]
loss: 0.082591  [19200/69985]
loss: 0.050649  [25600/69985]
loss: 0.026318  [32000/69985]
loss: 0.091017  [38400/69985]
loss: 0.030903  [44800/69985]
loss: 0.012754  [51200/69985]
loss: 0.081585  [57600/69985]
loss: 0.012674  [64000/69985]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.082234 

Epoch 48
-------------------------------
loss: 0.023426  [    0/69985]
loss: 0.073500  [ 6400/69985]
loss: 0.097297  [12800/69985]
loss: 0.138483  [19200/69985]
loss: 0.072471  [25600/69985]
loss: 0.096215  [32000/69985]
loss: 0.042330  [38400/69985]
loss: 0.056994  [44800/69985]
loss: 0.090565  [51200/69985]
loss: 0.138494  [57600/69985]
loss: 0.063535  [64000/69985]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.091405 

Epoch 49
-------------------------------
loss: 0.118048  [    0/69985]
loss: 0.079516  [ 6400/69985]
loss: 0.062429  [12800/69985]
loss: 0.103026  [19200/69985]
loss: 0.070765  [25600/69985]
loss: 0.052305  [32000/69985]
loss: 0.039959  [38400/69985]
loss: 0.080364  [44800/69985]
loss: 0.030179  [51200/69985]
loss: 0.110493  [57600/69985]
loss: 0.067016  [64000/69985]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082357 

Epoch 50
-------------------------------
loss: 0.027340  [    0/69985]
loss: 0.064652  [ 6400/69985]
loss: 0.065796  [12800/69985]
loss: 0.061979  [19200/69985]
loss: 0.108577  [25600/69985]
loss: 0.133496  [32000/69985]
loss: 0.021919  [38400/69985]
loss: 0.128267  [44800/69985]
loss: 0.037183  [51200/69985]
loss: 0.021740  [57600/69985]
loss: 0.038640  [64000/69985]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080701 

Epoch 1
-------------------------------
loss: 0.641156  [    0/69548]
loss: 0.322097  [ 6400/69548]
loss: 0.221577  [12800/69548]
loss: 0.303623  [19200/69548]
loss: 0.242259  [25600/69548]
loss: 0.202559  [32000/69548]
loss: 0.291158  [38400/69548]
loss: 0.115047  [44800/69548]
loss: 0.142035  [51200/69548]
loss: 0.171819  [57600/69548]
loss: 0.223159  [64000/69548]
Test Error: 
 Accuracy: 89.9%, Avg loss: 0.247001 

Epoch 2
-------------------------------
loss: 0.159792  [    0/69548]
loss: 0.317326  [ 6400/69548]
loss: 0.197703  [12800/69548]
loss: 0.387066  [19200/69548]
loss: 0.174768  [25600/69548]
loss: 0.237790  [32000/69548]
loss: 0.223475  [38400/69548]
loss: 0.185869  [44800/69548]
loss: 0.335743  [51200/69548]
loss: 0.217391  [57600/69548]
loss: 0.304744  [64000/69548]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.217094 

Epoch 3
-------------------------------
loss: 0.231072  [    0/69548]
loss: 0.135955  [ 6400/69548]
loss: 0.161762  [12800/69548]
loss: 0.294596  [19200/69548]
loss: 0.244450  [25600/69548]
loss: 0.328121  [32000/69548]
loss: 0.262388  [38400/69548]
loss: 0.152268  [44800/69548]
loss: 0.250728  [51200/69548]
loss: 0.130635  [57600/69548]
loss: 0.273390  [64000/69548]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.216411 

Epoch 4
-------------------------------
loss: 0.150814  [    0/69548]
loss: 0.190157  [ 6400/69548]
loss: 0.231440  [12800/69548]
loss: 0.220120  [19200/69548]
loss: 0.173858  [25600/69548]
loss: 0.150417  [32000/69548]
loss: 0.224552  [38400/69548]
loss: 0.273893  [44800/69548]
loss: 0.272374  [51200/69548]
loss: 0.321862  [57600/69548]
loss: 0.208266  [64000/69548]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.213403 

Epoch 5
-------------------------------
loss: 0.105104  [    0/69548]
loss: 0.135931  [ 6400/69548]
loss: 0.262245  [12800/69548]
loss: 0.148226  [19200/69548]
loss: 0.217667  [25600/69548]
loss: 0.261694  [32000/69548]
loss: 0.163174  [38400/69548]
loss: 0.329746  [44800/69548]
loss: 0.117811  [51200/69548]
loss: 0.193248  [57600/69548]
loss: 0.296873  [64000/69548]
loss: 0.007774  [51200/69822]
loss: 0.012234  [57600/69822]
loss: 0.095637  [64000/69822]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.089503 

Epoch 49
-------------------------------
loss: 0.040997  [    0/69822]
loss: 0.054720  [ 6400/69822]
loss: 0.019615  [12800/69822]
loss: 0.184932  [19200/69822]
loss: 0.076341  [25600/69822]
loss: 0.023438  [32000/69822]
loss: 0.020824  [38400/69822]
loss: 0.035186  [44800/69822]
loss: 0.042895  [51200/69822]
loss: 0.124279  [57600/69822]
loss: 0.083032  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076987 

Epoch 50
-------------------------------
loss: 0.142677  [    0/69822]
loss: 0.035415  [ 6400/69822]
loss: 0.033322  [12800/69822]
loss: 0.009377  [19200/69822]
loss: 0.066712  [25600/69822]
loss: 0.061209  [32000/69822]
loss: 0.022380  [38400/69822]
loss: 0.078695  [44800/69822]
loss: 0.008028  [51200/69822]
loss: 0.106171  [57600/69822]
loss: 0.033402  [64000/69822]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075805 

Epoch 1
-------------------------------
loss: 0.624906  [    0/69420]
loss: 0.403601  [ 6400/69420]
loss: 0.298248  [12800/69420]
loss: 0.250510  [19200/69420]
loss: 0.322722  [25600/69420]
loss: 0.290378  [32000/69420]
loss: 0.347214  [38400/69420]
loss: 0.251933  [44800/69420]
loss: 0.259285  [51200/69420]
loss: 0.229858  [57600/69420]
loss: 0.264043  [64000/69420]
Test Error: 
 Accuracy: 89.2%, Avg loss: 0.277759 

Epoch 2
-------------------------------
loss: 0.276944  [    0/69420]
loss: 0.154982  [ 6400/69420]
loss: 0.241207  [12800/69420]
loss: 0.261837  [19200/69420]
loss: 0.205730  [25600/69420]
loss: 0.317817  [32000/69420]
loss: 0.240522  [38400/69420]
loss: 0.167473  [44800/69420]
loss: 0.218179  [51200/69420]
loss: 0.304493  [57600/69420]
loss: 0.280909  [64000/69420]
Test Error: 
 Accuracy: 89.9%, Avg loss: 0.263026 

Epoch 3
-------------------------------
loss: 0.202890  [    0/69420]
loss: 0.292896  [ 6400/69420]
loss: 0.166678  [12800/69420]
loss: 0.318880  [19200/69420]
loss: 0.195074  [25600/69420]
loss: 0.167583  [32000/69420]
loss: 0.315986  [38400/69420]
loss: 0.231746  [44800/69420]
loss: 0.327427  [51200/69420]
loss: 0.167915  [57600/69420]
loss: 0.166164  [64000/69420]
Test Error: 
 Accuracy: 91.1%, Avg loss: 0.244465 

Epoch 4
-------------------------------
loss: 0.232543  [    0/69420]
loss: 0.228771  [ 6400/69420]
loss: 0.298990  [12800/69420]
loss: 0.272315  [19200/69420]
loss: 0.264233  [25600/69420]
loss: 0.228004  [32000/69420]
loss: 0.190125  [38400/69420]
loss: 0.201280  [44800/69420]
loss: 0.266634  [51200/69420]
loss: 0.174555  [57600/69420]
loss: 0.332069  [64000/69420]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.232523 

Epoch 5
-------------------------------
loss: 0.101863  [    0/69420]
loss: 0.215967  [ 6400/69420]
loss: 0.388941  [12800/69420]
loss: 0.124558  [19200/69420]
loss: 0.200425  [25600/69420]
loss: 0.294569  [32000/69420]
loss: 0.192173  [38400/69420]
loss: 0.235837  [44800/69420]
loss: 0.232798  [51200/69420]
loss: 0.155846  [57600/69420]
loss: 0.243170  [64000/69420]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.227939 

Epoch 6
-------------------------------
loss: 0.222189  [    0/69420]
loss: 0.233032  [ 6400/69420]
loss: 0.155390  [12800/69420]
loss: 0.300591  [19200/69420]
loss: 0.196219  [25600/69420]
loss: 0.298455  [32000/69420]
loss: 0.240078  [38400/69420]
loss: 0.203145  [44800/69420]
loss: 0.194487  [51200/69420]
loss: 0.264093  [57600/69420]
loss: 0.293658  [64000/69420]
Test Error: 
 Accuracy: 91.1%, Avg loss: 0.237186 

Epoch 7
-------------------------------
loss: 0.251402  [    0/69420]
loss: 0.145752  [ 6400/69420]
loss: 0.175792  [12800/69420]
loss: 0.173575  [19200/69420]
loss: 0.200528  [25600/69420]
loss: 0.214877  [32000/69420]
loss: 0.236110  [38400/69420]
loss: 0.257335  [44800/69420]
loss: 0.272848  [51200/69420]
loss: 0.253852  [57600/69420]
loss: 0.182452  [64000/69420]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.219405 

Epoch 8
-------------------------------
loss: 0.138291  [    0/69420]
loss: 0.247059  [ 6400/69420]
loss: 0.243176  [12800/69420]
loss: 0.152819  [19200/69420]
loss: 0.325764  [25600/69420]
loss: 0.330177  [32000/69420]
loss: 0.085544  [38400/69420]
loss: 0.181690  [44800/69420]
loss: 0.158977  [51200/69420]
loss: 0.305161  [57600/69420]
loss: 0.264644  [64000/69420]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.210045 

Epoch 9
-------------------------------
loss: 0.296991  [    0/69420]
loss: 0.150505  [ 6400/69420]
loss: 0.230037  [12800/69420]
loss: 0.239799  [19200/69420]
loss: 0.170604  [25600/69420]
loss: 0.231284  [32000/69420]
loss: 0.235086  [38400/69420]
loss: 0.211153  [44800/69420]
loss: 0.148942  [51200/69420]
loss: 0.289798  [57600/69420]
loss: 0.276989  [64000/69420]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.209829 

Epoch 10
-------------------------------
loss: 0.186631  [    0/69420]
loss: 0.264671  [ 6400/69420]
loss: 0.121049  [12800/69420]
loss: 0.236960  [19200/69420]
loss: 0.298705  [25600/69420]
loss: 0.262183  [32000/69420]
loss: 0.278728  [38400/69420]
loss: 0.224212  [44800/69420]
loss: 0.105685  [51200/69420]
loss: 0.246178  [57600/69420]
loss: 0.158106  [64000/69420]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.209928 

Epoch 11
-------------------------------
loss: 0.110355  [    0/69420]
loss: 0.305600  [ 6400/69420]
loss: 0.191189  [12800/69420]
loss: 0.208452  [19200/69420]
loss: 0.192085  [25600/69420]
loss: 0.112285  [32000/69420]
loss: 0.207164  [38400/69420]
loss: 0.153474  [44800/69420]
loss: 0.216259  [51200/69420]
loss: 0.539498  [57600/69420]
loss: 0.166879  [64000/69420]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.211657 

Epoch 12
-------------------------------
loss: 0.224314  [    0/69420]
loss: 0.192389  [ 6400/69420]
loss: 0.172552  [12800/69420]
loss: 0.197566  [19200/69420]
loss: 0.281383  [25600/69420]
loss: 0.182542  [32000/69420]
loss: 0.193106  [38400/69420]
loss: 0.209514  [44800/69420]
loss: 0.223414  [51200/69420]
loss: 0.219387  [57600/69420]
loss: 0.253736  [64000/69420]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.203522 

Epoch 13
-------------------------------
loss: 0.205753  [    0/69420]
loss: 0.162052  [ 6400/69420]
loss: 0.211234  [12800/69420]
loss: 0.162056  [19200/69420]
loss: 0.151551  [25600/69420]
loss: 0.271993  [32000/69420]
loss: 0.190415  [38400/69420]
loss: 0.363448  [44800/69420]
loss: 0.181670  [51200/69420]
loss: 0.142080  [57600/69420]
loss: 0.241151  [64000/69420]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.203076 

Epoch 14
-------------------------------
loss: 0.217288  [    0/69420]
loss: 0.233777  [ 6400/69420]
loss: 0.173786  [12800/69420]
loss: 0.211893  [19200/69420]
loss: 0.183438  [25600/69420]
loss: 0.200910  [32000/69420]
loss: 0.236540  [38400/69420]
loss: 0.331784  [44800/69420]
loss: 0.301691  [51200/69420]
loss: 0.236023  [57600/69420]
loss: 0.131419  [64000/69420]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.211322 

Epoch 15
-------------------------------
loss: 0.241620  [    0/69420]
loss: 0.299409  [ 6400/69420]
loss: 0.239589  [12800/69420]
loss: 0.155062  [19200/69420]
loss: 0.285583  [25600/69420]
loss: 0.202153  [32000/69420]
loss: 0.099127  [38400/69420]
loss: 0.223629  [44800/69420]
loss: 0.185515  [51200/69420]
loss: 0.184065  [57600/69420]
loss: 0.228629  [64000/69420]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.207436 

Epoch 16
-------------------------------
loss: 0.253235  [    0/69420]
loss: 0.276534  [ 6400/69420]
loss: 0.124174  [12800/69420]
loss: 0.163134  [19200/69420]
loss: 0.237497  [25600/69420]
loss: 0.288277  [32000/69420]
loss: 0.259137  [38400/69420]
loss: 0.266368  [44800/69420]
loss: 0.481004  [51200/69420]
loss: 0.150080  [57600/69420]
loss: 0.293637  [64000/69420]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.216275 

Epoch 17
-------------------------------
loss: 0.142890  [    0/69420]
loss: 0.167013  [ 6400/69420]
loss: 0.238638  [12800/69420]
loss: 0.157832  [19200/69420]
loss: 0.169548  [25600/69420]
loss: 0.296169  [32000/69420]
loss: 0.325245  [38400/69420]
loss: 0.187884  [44800/69420]
loss: 0.231670  [51200/69420]
loss: 0.270620  [57600/69420]
loss: 0.304031  [64000/69420]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.210395 

loss: 0.035312  [44800/70555]
loss: 0.012766  [51200/70555]
loss: 0.089685  [57600/70555]
loss: 0.056676  [64000/70555]
loss: 0.038181  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082756 

Epoch 46
-------------------------------
loss: 0.107945  [    0/70555]
loss: 0.028116  [ 6400/70555]
loss: 0.127792  [12800/70555]
loss: 0.075720  [19200/70555]
loss: 0.087587  [25600/70555]
loss: 0.087926  [32000/70555]
loss: 0.063793  [38400/70555]
loss: 0.067033  [44800/70555]
loss: 0.202819  [51200/70555]
loss: 0.036606  [57600/70555]
loss: 0.111578  [64000/70555]
loss: 0.042235  [70400/70555]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.078014 

Epoch 47
-------------------------------
loss: 0.014252  [    0/70555]
loss: 0.033840  [ 6400/70555]
loss: 0.049963  [12800/70555]
loss: 0.142038  [19200/70555]
loss: 0.040091  [25600/70555]
loss: 0.055874  [32000/70555]
loss: 0.026137  [38400/70555]
loss: 0.079031  [44800/70555]
loss: 0.020575  [51200/70555]
loss: 0.146783  [57600/70555]
loss: 0.036255  [64000/70555]
loss: 0.067820  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081271 

Epoch 48
-------------------------------
loss: 0.008841  [    0/70555]
loss: 0.024421  [ 6400/70555]
loss: 0.022226  [12800/70555]
loss: 0.102354  [19200/70555]
loss: 0.026123  [25600/70555]
loss: 0.117480  [32000/70555]
loss: 0.027626  [38400/70555]
loss: 0.052682  [44800/70555]
loss: 0.062188  [51200/70555]
loss: 0.029931  [57600/70555]
loss: 0.082658  [64000/70555]
loss: 0.072310  [70400/70555]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.083873 

Epoch 49
-------------------------------
loss: 0.030039  [    0/70555]
loss: 0.046830  [ 6400/70555]
loss: 0.036582  [12800/70555]
loss: 0.064949  [19200/70555]
loss: 0.056019  [25600/70555]
loss: 0.048435  [32000/70555]
loss: 0.070771  [38400/70555]
loss: 0.015090  [44800/70555]
loss: 0.006810  [51200/70555]
loss: 0.057369  [57600/70555]
loss: 0.019790  [64000/70555]
loss: 0.025008  [70400/70555]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084543 

Epoch 50
-------------------------------
loss: 0.049936  [    0/70555]
loss: 0.149223  [ 6400/70555]
loss: 0.060498  [12800/70555]
loss: 0.025453  [19200/70555]
loss: 0.026604  [25600/70555]
loss: 0.030455  [32000/70555]
loss: 0.081581  [38400/70555]
loss: 0.054594  [44800/70555]
loss: 0.037331  [51200/70555]
loss: 0.079906  [57600/70555]
loss: 0.023761  [64000/70555]
loss: 0.031830  [70400/70555]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082774 

Epoch 1
-------------------------------
loss: 0.649296  [    0/71159]
loss: 0.202259  [ 6400/71159]
loss: 0.250931  [12800/71159]
loss: 0.249941  [19200/71159]
loss: 0.139344  [25600/71159]
loss: 0.210174  [32000/71159]
loss: 0.188380  [38400/71159]
loss: 0.311890  [44800/71159]
loss: 0.241023  [51200/71159]
loss: 0.323780  [57600/71159]
loss: 0.281390  [64000/71159]
loss: 0.174004  [70400/71159]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.182228 

Epoch 2
-------------------------------
loss: 0.172001  [    0/71159]
loss: 0.142080  [ 6400/71159]
loss: 0.155742  [12800/71159]
loss: 0.214474  [19200/71159]
loss: 0.170709  [25600/71159]
loss: 0.081441  [32000/71159]
loss: 0.105244  [38400/71159]
loss: 0.134523  [44800/71159]
loss: 0.153444  [51200/71159]
loss: 0.120451  [57600/71159]
loss: 0.160722  [64000/71159]
loss: 0.174314  [70400/71159]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.164503 

Epoch 3
-------------------------------
loss: 0.136766  [    0/71159]
loss: 0.127219  [ 6400/71159]
loss: 0.076680  [12800/71159]
loss: 0.175727  [19200/71159]
loss: 0.096189  [25600/71159]
loss: 0.187000  [32000/71159]
loss: 0.190737  [38400/71159]
loss: 0.160713  [44800/71159]
loss: 0.196052  [51200/71159]
loss: 0.112123  [57600/71159]
loss: 0.199609  [64000/71159]
loss: 0.079680  [70400/71159]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.162341 

Epoch 4
-------------------------------
loss: 0.372316  [    0/71159]
loss: 0.098888  [ 6400/71159]
loss: 0.209352  [12800/71159]
loss: 0.205089  [19200/71159]
loss: 0.053187  [25600/71159]
loss: 0.071111  [32000/71159]
loss: 0.175459  [38400/71159]
loss: 0.177568  [44800/71159]
loss: 0.144622  [51200/71159]
loss: 0.110661  [57600/71159]
loss: 0.155126  [64000/71159]
loss: 0.198756  [70400/71159]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.157415 

Epoch 5
-------------------------------
loss: 0.188438  [    0/71159]
loss: 0.124036  [ 6400/71159]
loss: 0.249281  [12800/71159]
loss: 0.158263  [19200/71159]
loss: 0.070584  [25600/71159]
loss: 0.103401  [32000/71159]
loss: 0.252414  [38400/71159]
loss: 0.088935  [44800/71159]
loss: 0.069783  [51200/71159]
loss: 0.249432  [57600/71159]
loss: 0.197751  [64000/71159]
loss: 0.133358  [70400/71159]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.155232 

Epoch 6
-------------------------------
loss: 0.172315  [    0/71159]
loss: 0.173681  [ 6400/71159]
loss: 0.129636  [12800/71159]
loss: 0.094890  [19200/71159]
loss: 0.112669  [25600/71159]
loss: 0.140725  [32000/71159]
loss: 0.148245  [38400/71159]
loss: 0.159457  [44800/71159]
loss: 0.171896  [51200/71159]
loss: 0.155744  [57600/71159]
loss: 0.118528  [64000/71159]
loss: 0.142065  [70400/71159]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.151202 

Epoch 7
-------------------------------
loss: 0.198381  [    0/71159]
loss: 0.151290  [ 6400/71159]
loss: 0.226252  [12800/71159]
loss: 0.150849  [19200/71159]
loss: 0.038876  [25600/71159]
loss: 0.243957  [32000/71159]
loss: 0.048169  [38400/71159]
loss: 0.213124  [44800/71159]
loss: 0.047309  [51200/71159]
loss: 0.189675  [57600/71159]
loss: 0.112565  [64000/71159]
loss: 0.163236  [70400/71159]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.151992 

Epoch 8
-------------------------------
loss: 0.104366  [    0/71159]
loss: 0.162076  [ 6400/71159]
loss: 0.116739  [12800/71159]
loss: 0.083055  [19200/71159]
loss: 0.052560  [25600/71159]
loss: 0.141525  [32000/71159]
loss: 0.079506  [38400/71159]
loss: 0.175246  [44800/71159]
loss: 0.073537  [51200/71159]
loss: 0.199601  [57600/71159]
loss: 0.171541  [64000/71159]
loss: 0.242283  [70400/71159]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.147547 

Epoch 9
-------------------------------
loss: 0.182014  [    0/71159]
loss: 0.178743  [ 6400/71159]
loss: 0.155530  [12800/71159]
loss: 0.185007  [19200/71159]
loss: 0.194175  [25600/71159]
loss: 0.333261  [32000/71159]
loss: 0.165745  [38400/71159]
loss: 0.143275  [44800/71159]
loss: 0.068123  [51200/71159]
loss: 0.081045  [57600/71159]
loss: 0.190917  [64000/71159]
loss: 0.127952  [70400/71159]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.159391 

Epoch 10
-------------------------------
loss: 0.161993  [    0/71159]
loss: 0.238148  [ 6400/71159]
loss: 0.096040  [12800/71159]
loss: 0.051045  [19200/71159]
loss: 0.073945  [25600/71159]
loss: 0.182069  [32000/71159]
loss: 0.137432  [38400/71159]
loss: 0.164107  [44800/71159]
loss: 0.068787  [51200/71159]
loss: 0.105287  [57600/71159]
loss: 0.170940  [64000/71159]
loss: 0.086889  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.147892 

Epoch 11
-------------------------------
loss: 0.236833  [    0/71159]
loss: 0.111127  [ 6400/71159]
loss: 0.177172  [12800/71159]
loss: 0.196355  [19200/71159]
loss: 0.130370  [25600/71159]
loss: 0.067962  [32000/71159]
loss: 0.039356  [38400/71159]
loss: 0.106258  [44800/71159]
loss: 0.111730  [51200/71159]
loss: 0.093437  [57600/71159]
loss: 0.137030  [64000/71159]
loss: 0.117861  [70400/71159]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.144597 

Epoch 12
-------------------------------
loss: 0.140515  [    0/71159]
loss: 0.107871  [ 6400/71159]
loss: 0.035206  [12800/71159]
loss: 0.145820  [19200/71159]
loss: 0.040444  [25600/71159]
loss: 0.103504  [32000/71159]
loss: 0.084127  [38400/71159]
loss: 0.059543  [44800/71159]
loss: 0.103842  [51200/71159]
loss: 0.171876  [57600/71159]
loss: 0.242671  [64000/71159]
loss: 0.208911  [70400/71159]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.157817 

Epoch 13
-------------------------------
loss: 0.172736  [    0/71159]
loss: 0.103972  [ 6400/71159]
loss: 0.184297  [12800/71159]
loss: 0.149763  [19200/71159]
loss: 0.146501  [25600/71159]
loss: 0.060046  [32000/71159]
loss: 0.067060  [38400/71159]
loss: 0.099775  [44800/71159]
loss: 0.041021  [44800/71235]
loss: 0.167338  [51200/71235]
loss: 0.090637  [57600/71235]
loss: 0.082004  [64000/71235]
loss: 0.050763  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.114813 

Epoch 46
-------------------------------
loss: 0.037876  [    0/71235]
loss: 0.050628  [ 6400/71235]
loss: 0.078690  [12800/71235]
loss: 0.027685  [19200/71235]
loss: 0.050202  [25600/71235]
loss: 0.051348  [32000/71235]
loss: 0.026335  [38400/71235]
loss: 0.091167  [44800/71235]
loss: 0.044872  [51200/71235]
loss: 0.089668  [57600/71235]
loss: 0.065449  [64000/71235]
loss: 0.037023  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.113141 

Epoch 47
-------------------------------
loss: 0.177006  [    0/71235]
loss: 0.089155  [ 6400/71235]
loss: 0.096265  [12800/71235]
loss: 0.044919  [19200/71235]
loss: 0.060695  [25600/71235]
loss: 0.043179  [32000/71235]
loss: 0.131315  [38400/71235]
loss: 0.085229  [44800/71235]
loss: 0.078459  [51200/71235]
loss: 0.120849  [57600/71235]
loss: 0.081184  [64000/71235]
loss: 0.069571  [70400/71235]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.109478 

Epoch 48
-------------------------------
loss: 0.013126  [    0/71235]
loss: 0.023803  [ 6400/71235]
loss: 0.127267  [12800/71235]
loss: 0.054419  [19200/71235]
loss: 0.054993  [25600/71235]
loss: 0.094041  [32000/71235]
loss: 0.103880  [38400/71235]
loss: 0.036752  [44800/71235]
loss: 0.174451  [51200/71235]
loss: 0.057406  [57600/71235]
loss: 0.030158  [64000/71235]
loss: 0.069810  [70400/71235]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.127559 

Epoch 49
-------------------------------
loss: 0.091479  [    0/71235]
loss: 0.113667  [ 6400/71235]
loss: 0.069389  [12800/71235]
loss: 0.067334  [19200/71235]
loss: 0.017345  [25600/71235]
loss: 0.094325  [32000/71235]
loss: 0.030656  [38400/71235]
loss: 0.049019  [44800/71235]
loss: 0.055021  [51200/71235]
loss: 0.059484  [57600/71235]
loss: 0.042790  [64000/71235]
loss: 0.069797  [70400/71235]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.107201 

Epoch 50
-------------------------------
loss: 0.075873  [    0/71235]
loss: 0.021772  [ 6400/71235]
loss: 0.012204  [12800/71235]
loss: 0.012506  [19200/71235]
loss: 0.085475  [25600/71235]
loss: 0.030053  [32000/71235]
loss: 0.066886  [38400/71235]
loss: 0.054380  [44800/71235]
loss: 0.096767  [51200/71235]
loss: 0.028555  [57600/71235]
loss: 0.033013  [64000/71235]
loss: 0.018846  [70400/71235]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.111707 

Epoch 1
-------------------------------
loss: 0.710644  [    0/70696]
loss: 0.356093  [ 6400/70696]
loss: 2.009956  [12800/70696]
loss: 0.272716  [19200/70696]
loss: 0.390255  [25600/70696]
loss: 0.208672  [32000/70696]
loss: 0.312740  [38400/70696]
loss: 0.295813  [44800/70696]
loss: 0.174504  [51200/70696]
loss: 0.260425  [57600/70696]
loss: 0.317585  [64000/70696]
loss: 1.784416  [70400/70696]
Test Error: 
 Accuracy: 91.2%, Avg loss: 0.243868 

Epoch 2
-------------------------------
loss: 0.160336  [    0/70696]
loss: 0.202621  [ 6400/70696]
loss: 0.255259  [12800/70696]
loss: 0.272257  [19200/70696]
loss: 0.149655  [25600/70696]
loss: 0.231223  [32000/70696]
loss: 0.222867  [38400/70696]
loss: 0.120857  [44800/70696]
loss: 0.256790  [51200/70696]
loss: 1.858230  [57600/70696]
loss: 0.259879  [64000/70696]
loss: 0.306646  [70400/70696]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.220401 

Epoch 3
-------------------------------
loss: 0.176920  [    0/70696]
loss: 0.079901  [ 6400/70696]
loss: 0.132878  [12800/70696]
loss: 0.263665  [19200/70696]
loss: 0.180635  [25600/70696]
loss: 0.236358  [32000/70696]
loss: 0.232616  [38400/70696]
loss: 0.211476  [44800/70696]
loss: 0.178514  [51200/70696]
loss: 0.188991  [57600/70696]
loss: 0.160878  [64000/70696]
loss: 0.135664  [70400/70696]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.204236 

Epoch 4
-------------------------------
loss: 0.199403  [    0/70696]
loss: 0.208347  [ 6400/70696]
loss: 0.224955  [12800/70696]
loss: 0.190968  [19200/70696]
loss: 0.107556  [25600/70696]
loss: 0.287385  [32000/70696]
loss: 0.086999  [38400/70696]
loss: 0.140185  [44800/70696]
loss: 0.114086  [51200/70696]
loss: 0.129053  [57600/70696]
loss: 0.272333  [64000/70696]
loss: 0.231574  [70400/70696]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.205869 

Epoch 5
-------------------------------
loss: 0.293653  [    0/70696]
loss: 0.197549  [ 6400/70696]
loss: 0.119675  [12800/70696]
loss: 0.254749  [19200/70696]
loss: 0.159762  [25600/70696]
loss: 0.252754  [32000/70696]
loss: 0.235777  [38400/70696]
loss: 0.202565  [44800/70696]
loss: 0.242647  [51200/70696]
loss: 0.099195  [57600/70696]
loss: 0.215307  [64000/70696]
loss: 0.171932  [70400/70696]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.199991 

Epoch 6
-------------------------------
loss: 0.142236  [    0/70696]
loss: 0.091258  [ 6400/70696]
loss: 0.218839  [12800/70696]
loss: 0.203834  [19200/70696]
loss: 0.121049  [25600/70696]
loss: 0.158211  [32000/70696]
loss: 0.160943  [38400/70696]
loss: 0.133980  [44800/70696]
loss: 1.717760  [51200/70696]
loss: 0.280086  [57600/70696]
loss: 1.674352  [64000/70696]
loss: 0.293159  [70400/70696]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.188816 

Epoch 7
-------------------------------
loss: 0.119381  [    0/70696]
loss: 0.167836  [ 6400/70696]
loss: 0.136197  [12800/70696]
loss: 0.183362  [19200/70696]
loss: 0.182508  [25600/70696]
loss: 0.133244  [32000/70696]
loss: 0.088997  [38400/70696]
loss: 0.165488  [44800/70696]
loss: 0.077243  [51200/70696]
loss: 0.311176  [57600/70696]
loss: 0.199797  [64000/70696]
loss: 0.245223  [70400/70696]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.190159 

Epoch 8
-------------------------------
loss: 0.099917  [    0/70696]
loss: 0.158888  [ 6400/70696]
loss: 0.233545  [12800/70696]
loss: 0.183335  [19200/70696]
loss: 0.176611  [25600/70696]
loss: 0.112588  [32000/70696]
loss: 0.269101  [38400/70696]
loss: 0.112179  [44800/70696]
loss: 0.200359  [51200/70696]
loss: 1.664145  [57600/70696]
loss: 0.174359  [64000/70696]
loss: 0.173874  [70400/70696]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.193001 

Epoch 9
-------------------------------
loss: 0.089723  [    0/70696]
loss: 0.243961  [ 6400/70696]
loss: 0.318917  [12800/70696]
loss: 0.159502  [19200/70696]
loss: 0.169726  [25600/70696]
loss: 0.188492  [32000/70696]
loss: 0.088488  [38400/70696]
loss: 0.283031  [44800/70696]
loss: 0.221850  [51200/70696]
loss: 0.142685  [57600/70696]
loss: 0.153509  [64000/70696]
loss: 0.103438  [70400/70696]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.168773 

Epoch 10
-------------------------------
loss: 0.156062  [    0/70696]
loss: 0.131491  [ 6400/70696]
loss: 0.138560  [12800/70696]
loss: 0.102762  [19200/70696]
loss: 0.258099  [25600/70696]
loss: 0.135047  [32000/70696]
loss: 0.221767  [38400/70696]
loss: 0.184438  [44800/70696]
loss: 0.138880  [51200/70696]
loss: 0.147596  [57600/70696]
loss: 0.167132  [64000/70696]
loss: 0.101449  [70400/70696]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.163119 

Epoch 11
-------------------------------
loss: 0.182674  [    0/70696]
loss: 0.215082  [ 6400/70696]
loss: 0.180300  [12800/70696]
loss: 0.279211  [19200/70696]
loss: 0.148114  [25600/70696]
loss: 0.135397  [32000/70696]
loss: 0.176179  [38400/70696]
loss: 0.172310  [44800/70696]
loss: 0.146846  [51200/70696]
loss: 0.270532  [57600/70696]
loss: 0.188203  [64000/70696]
loss: 0.207187  [70400/70696]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.162566 

Epoch 12
-------------------------------
loss: 0.139697  [    0/70696]
loss: 0.108698  [ 6400/70696]
loss: 0.217141  [12800/70696]
loss: 0.167423  [19200/70696]
loss: 0.135626  [25600/70696]
loss: 0.183680  [32000/70696]
loss: 0.134162  [38400/70696]
loss: 0.162095  [44800/70696]
loss: 0.242518  [51200/70696]
loss: 0.151549  [57600/70696]
loss: 0.224766  [64000/70696]
loss: 0.139302  [70400/70696]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.177106 

Epoch 13
-------------------------------
loss: 0.158144  [    0/70696]
loss: 0.154104  [ 6400/70696]
loss: 0.239668  [12800/70696]
loss: 0.173150  [19200/70696]
loss: 0.158985  [25600/70696]
loss: 0.082532  [32000/70696]
loss: 0.128783  [38400/70696]
loss: 0.096576  [44800/70696]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.132801 

Epoch 49
-------------------------------
loss: 0.147118  [    0/70588]
loss: 0.097312  [ 6400/70588]
loss: 0.119563  [12800/70588]
loss: 0.109351  [19200/70588]
loss: 0.150817  [25600/70588]
loss: 0.201011  [32000/70588]
loss: 0.140620  [38400/70588]
loss: 0.072609  [44800/70588]
loss: 0.058052  [51200/70588]
loss: 0.101064  [57600/70588]
loss: 0.158229  [64000/70588]
loss: 0.069692  [70400/70588]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.151039 

Epoch 50
-------------------------------
loss: 0.054220  [    0/70588]
loss: 0.052308  [ 6400/70588]
loss: 0.073757  [12800/70588]
loss: 0.155157  [19200/70588]
loss: 0.166832  [25600/70588]
loss: 0.075915  [32000/70588]
loss: 0.252872  [38400/70588]
loss: 0.095195  [44800/70588]
loss: 0.038992  [51200/70588]
loss: 0.055174  [57600/70588]
loss: 0.040359  [64000/70588]
loss: 0.144050  [70400/70588]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.144408 

Epoch 1
-------------------------------
loss: 0.683680  [    0/71502]
loss: 0.258791  [ 6400/71502]
loss: 0.303805  [12800/71502]
loss: 0.161755  [19200/71502]
loss: 0.167892  [25600/71502]
loss: 0.201179  [32000/71502]
loss: 0.296062  [38400/71502]
loss: 0.201766  [44800/71502]
loss: 0.256954  [51200/71502]
loss: 0.242532  [57600/71502]
loss: 0.132950  [64000/71502]
loss: 0.113756  [70400/71502]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.214405 

Epoch 2
-------------------------------
loss: 0.047203  [    0/71502]
loss: 0.156480  [ 6400/71502]
loss: 0.118718  [12800/71502]
loss: 0.145035  [19200/71502]
loss: 0.220000  [25600/71502]
loss: 0.112557  [32000/71502]
loss: 0.131552  [38400/71502]
loss: 0.241986  [44800/71502]
loss: 0.118776  [51200/71502]
loss: 0.085779  [57600/71502]
loss: 0.089388  [64000/71502]
loss: 0.060638  [70400/71502]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.210606 

Epoch 3
-------------------------------
loss: 0.072731  [    0/71502]
loss: 0.079178  [ 6400/71502]
loss: 0.189096  [12800/71502]
loss: 0.063651  [19200/71502]
loss: 0.118961  [25600/71502]
loss: 0.117103  [32000/71502]
loss: 0.281124  [38400/71502]
loss: 0.057211  [44800/71502]
loss: 0.153546  [51200/71502]
loss: 1.781523  [57600/71502]
loss: 0.091463  [64000/71502]
loss: 0.215148  [70400/71502]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.198650 

Epoch 4
-------------------------------
loss: 1.711191  [    0/71502]
loss: 0.038395  [ 6400/71502]
loss: 0.097541  [12800/71502]
loss: 0.212502  [19200/71502]
loss: 0.146437  [25600/71502]
loss: 0.077625  [32000/71502]
loss: 0.189859  [38400/71502]
loss: 0.234957  [44800/71502]
loss: 0.118050  [51200/71502]
loss: 0.040790  [57600/71502]
loss: 0.101526  [64000/71502]
loss: 0.294630  [70400/71502]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.215648 

Epoch 5
-------------------------------
loss: 0.182079  [    0/71502]
loss: 0.095860  [ 6400/71502]
loss: 0.141998  [12800/71502]
loss: 1.599307  [19200/71502]
loss: 0.157072  [25600/71502]
loss: 0.103321  [32000/71502]
loss: 0.148004  [38400/71502]
loss: 0.095646  [44800/71502]
loss: 0.135029  [51200/71502]
loss: 0.180474  [57600/71502]
loss: 0.134944  [64000/71502]
loss: 0.202160  [70400/71502]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.198621 

Epoch 6
-------------------------------
loss: 0.178376  [    0/71502]
loss: 0.042152  [ 6400/71502]
loss: 0.114270  [12800/71502]
loss: 0.092068  [19200/71502]
loss: 1.620700  [25600/71502]
loss: 0.165054  [32000/71502]
loss: 0.151392  [38400/71502]
loss: 0.096840  [44800/71502]
loss: 0.149484  [51200/71502]
loss: 0.206959  [57600/71502]
loss: 0.051510  [64000/71502]
loss: 0.089758  [70400/71502]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.183690 

Epoch 7
-------------------------------
loss: 0.134609  [    0/71502]
loss: 0.073034  [ 6400/71502]
loss: 0.166152  [12800/71502]
loss: 0.081900  [19200/71502]
loss: 0.271511  [25600/71502]
loss: 0.109291  [32000/71502]
loss: 0.038507  [38400/71502]
loss: 0.066393  [44800/71502]
loss: 0.031428  [51200/71502]
loss: 0.082744  [57600/71502]
loss: 0.072630  [64000/71502]
loss: 0.225968  [70400/71502]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.189292 

Epoch 8
-------------------------------
loss: 0.062357  [    0/71502]
loss: 0.112422  [ 6400/71502]
loss: 1.659038  [12800/71502]
loss: 0.130803  [19200/71502]
loss: 0.150623  [25600/71502]
loss: 0.078662  [32000/71502]
loss: 0.059324  [38400/71502]
loss: 0.045549  [44800/71502]
loss: 0.112443  [51200/71502]
loss: 0.039532  [57600/71502]
loss: 0.110392  [64000/71502]
loss: 0.062871  [70400/71502]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.175648 

Epoch 9
-------------------------------
loss: 0.104634  [    0/71502]
loss: 0.096504  [ 6400/71502]
loss: 0.048724  [12800/71502]
loss: 0.058990  [19200/71502]
loss: 0.102529  [25600/71502]
loss: 0.037868  [32000/71502]
loss: 0.080830  [38400/71502]
loss: 0.109790  [44800/71502]
loss: 0.107572  [51200/71502]
loss: 0.052783  [57600/71502]
loss: 0.056018  [64000/71502]
loss: 0.157392  [70400/71502]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.187938 

Epoch 10
-------------------------------
loss: 0.233902  [    0/71502]
loss: 0.092144  [ 6400/71502]
loss: 0.058500  [12800/71502]
loss: 0.042872  [19200/71502]
loss: 0.049498  [25600/71502]
loss: 0.109174  [32000/71502]
loss: 0.098815  [38400/71502]
loss: 0.223629  [44800/71502]
loss: 0.038846  [51200/71502]
loss: 0.018020  [57600/71502]
loss: 0.032288  [64000/71502]
loss: 0.148226  [70400/71502]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.217199 

Epoch 11
-------------------------------
loss: 0.153044  [    0/71502]
loss: 0.040556  [ 6400/71502]
loss: 0.118127  [12800/71502]
loss: 0.094457  [19200/71502]
loss: 0.008394  [25600/71502]
loss: 0.069117  [32000/71502]
loss: 0.011829  [38400/71502]
loss: 0.083491  [44800/71502]
loss: 0.102510  [51200/71502]
loss: 0.069402  [57600/71502]
loss: 0.121188  [64000/71502]
loss: 0.150503  [70400/71502]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.188100 

Epoch 12
-------------------------------
loss: 0.078321  [    0/71502]
loss: 0.056983  [ 6400/71502]
loss: 0.085985  [12800/71502]
loss: 0.071991  [19200/71502]
loss: 0.053645  [25600/71502]
loss: 0.054019  [32000/71502]
loss: 0.067424  [38400/71502]
loss: 0.073815  [44800/71502]
loss: 0.155946  [51200/71502]
loss: 0.063838  [57600/71502]
loss: 0.190437  [64000/71502]
loss: 0.078344  [70400/71502]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.192911 

Epoch 13
-------------------------------
loss: 0.083043  [    0/71502]
loss: 0.168058  [ 6400/71502]
loss: 0.015104  [12800/71502]
loss: 0.029031  [19200/71502]
loss: 0.205438  [25600/71502]
loss: 0.088617  [32000/71502]
loss: 0.142280  [38400/71502]
loss: 0.091910  [44800/71502]
loss: 0.022457  [51200/71502]
loss: 0.106011  [57600/71502]
loss: 0.074195  [64000/71502]
loss: 0.187847  [70400/71502]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.184307 

Epoch 14
-------------------------------
loss: 0.096263  [    0/71502]
loss: 0.033166  [ 6400/71502]
loss: 0.022902  [12800/71502]
loss: 0.089319  [19200/71502]
loss: 0.009430  [25600/71502]
loss: 0.115571  [32000/71502]
loss: 1.647779  [38400/71502]
loss: 0.024376  [44800/71502]
loss: 0.177343  [51200/71502]
loss: 0.070992  [57600/71502]
loss: 0.025548  [64000/71502]
loss: 0.066272  [70400/71502]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.180223 

Epoch 15
-------------------------------
loss: 0.084953  [    0/71502]
loss: 0.059646  [ 6400/71502]
loss: 0.025589  [12800/71502]
loss: 0.248356  [19200/71502]
loss: 0.025334  [25600/71502]
loss: 0.021122  [32000/71502]
loss: 0.078501  [38400/71502]
loss: 0.055494  [44800/71502]
loss: 0.056447  [51200/71502]
loss: 0.149470  [57600/71502]
loss: 0.071717  [64000/71502]
loss: 0.145916  [70400/71502]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.170943 

Epoch 16
-------------------------------
loss: 0.069113  [    0/71502]
loss: 0.181453  [ 6400/71502]
loss: 0.038240  [12800/71502]
loss: 0.084988  [19200/71502]
loss: 0.086366  [25600/71502]
loss: 0.078949  [32000/71502]
loss: 0.037990  [38400/71502]
loss: 0.084350  [44800/71502]
loss: 0.065294  [51200/71502]
loss: 0.120390  [57600/71502]
loss: 0.115373  [64000/71502]
loss: 0.101599  [70400/71502]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.093802 

Epoch 49
-------------------------------
loss: 0.012656  [    0/72227]
loss: 0.004522  [ 6400/72227]
loss: 0.003569  [12800/72227]
loss: 0.070822  [19200/72227]
loss: 0.009913  [25600/72227]
loss: 0.005994  [32000/72227]
loss: 0.048670  [38400/72227]
loss: 0.101900  [44800/72227]
loss: 0.048305  [51200/72227]
loss: 0.016177  [57600/72227]
loss: 0.095751  [64000/72227]
loss: 0.017008  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.102478 

Epoch 50
-------------------------------
loss: 0.028746  [    0/72227]
loss: 0.008924  [ 6400/72227]
loss: 0.029042  [12800/72227]
loss: 0.058342  [19200/72227]
loss: 0.015763  [25600/72227]
loss: 0.010136  [32000/72227]
loss: 0.013667  [38400/72227]
loss: 0.122971  [44800/72227]
loss: 0.012294  [51200/72227]
loss: 0.025428  [57600/72227]
loss: 0.066473  [64000/72227]
loss: 0.137044  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.100571 

Epoch 1
-------------------------------
loss: 0.651589  [    0/70685]
loss: 0.279004  [ 6400/70685]
loss: 0.276560  [12800/70685]
loss: 0.269804  [19200/70685]
loss: 0.182823  [25600/70685]
loss: 0.206772  [32000/70685]
loss: 0.170278  [38400/70685]
loss: 0.169140  [44800/70685]
loss: 0.273125  [51200/70685]
loss: 0.253090  [57600/70685]
loss: 0.195498  [64000/70685]
loss: 0.173665  [70400/70685]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.260505 

Epoch 2
-------------------------------
loss: 0.239762  [    0/70685]
loss: 0.260671  [ 6400/70685]
loss: 0.100912  [12800/70685]
loss: 0.195499  [19200/70685]
loss: 0.149677  [25600/70685]
loss: 0.223399  [32000/70685]
loss: 0.207465  [38400/70685]
loss: 0.164467  [44800/70685]
loss: 0.232750  [51200/70685]
loss: 0.230483  [57600/70685]
loss: 0.167030  [64000/70685]
loss: 0.165261  [70400/70685]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.222518 

Epoch 3
-------------------------------
loss: 0.106764  [    0/70685]
loss: 0.392398  [ 6400/70685]
loss: 0.118403  [12800/70685]
loss: 0.378039  [19200/70685]
loss: 0.166344  [25600/70685]
loss: 0.315555  [32000/70685]
loss: 0.263942  [38400/70685]
loss: 0.335478  [44800/70685]
loss: 0.161009  [51200/70685]
loss: 0.145984  [57600/70685]
loss: 0.204966  [64000/70685]
loss: 0.147913  [70400/70685]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.186193 

Epoch 4
-------------------------------
loss: 0.107630  [    0/70685]
loss: 0.193019  [ 6400/70685]
loss: 0.173014  [12800/70685]
loss: 0.201495  [19200/70685]
loss: 0.223217  [25600/70685]
loss: 0.160336  [32000/70685]
loss: 0.134529  [38400/70685]
loss: 0.208409  [44800/70685]
loss: 0.126334  [51200/70685]
loss: 0.247814  [57600/70685]
loss: 0.180899  [64000/70685]
loss: 0.185863  [70400/70685]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.185481 

Epoch 5
-------------------------------
loss: 0.184194  [    0/70685]
loss: 0.220853  [ 6400/70685]
loss: 0.181322  [12800/70685]
loss: 0.124153  [19200/70685]
loss: 0.224892  [25600/70685]
loss: 0.144728  [32000/70685]
loss: 0.139369  [38400/70685]
loss: 0.258438  [44800/70685]
loss: 0.185152  [51200/70685]
loss: 0.136630  [57600/70685]
loss: 0.087468  [64000/70685]
loss: 0.092004  [70400/70685]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.177594 

Epoch 6
-------------------------------
loss: 0.149160  [    0/70685]
loss: 0.331111  [ 6400/70685]
loss: 0.245843  [12800/70685]
loss: 0.213267  [19200/70685]
loss: 0.159443  [25600/70685]
loss: 0.256084  [32000/70685]
loss: 0.274744  [38400/70685]
loss: 0.296353  [44800/70685]
loss: 0.163165  [51200/70685]
loss: 0.147637  [57600/70685]
loss: 0.175084  [64000/70685]
loss: 0.097442  [70400/70685]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.170631 

Epoch 7
-------------------------------
loss: 0.179446  [    0/70685]
loss: 0.140881  [ 6400/70685]
loss: 0.450420  [12800/70685]
loss: 0.150412  [19200/70685]
loss: 0.122951  [25600/70685]
loss: 0.327790  [32000/70685]
loss: 0.296343  [38400/70685]
loss: 0.117135  [44800/70685]
loss: 0.096943  [51200/70685]
loss: 0.225189  [57600/70685]
loss: 0.151471  [64000/70685]
loss: 0.255218  [70400/70685]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.167588 

Epoch 8
-------------------------------
loss: 0.185710  [    0/70685]
loss: 0.157666  [ 6400/70685]
loss: 0.156904  [12800/70685]
loss: 0.250302  [19200/70685]
loss: 0.128749  [25600/70685]
loss: 0.090149  [32000/70685]
loss: 0.151471  [38400/70685]
loss: 0.123538  [44800/70685]
loss: 0.180700  [51200/70685]
loss: 0.166517  [57600/70685]
loss: 0.218682  [64000/70685]
loss: 0.270477  [70400/70685]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.176351 

Epoch 9
-------------------------------
loss: 0.197295  [    0/70685]
loss: 0.163272  [ 6400/70685]
loss: 0.248097  [12800/70685]
loss: 0.185479  [19200/70685]
loss: 0.131834  [25600/70685]
loss: 0.119549  [32000/70685]
loss: 0.187502  [38400/70685]
loss: 0.248796  [44800/70685]
loss: 0.257460  [51200/70685]
loss: 0.132826  [57600/70685]
loss: 0.244191  [64000/70685]
loss: 0.222159  [70400/70685]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.185217 

Epoch 10
-------------------------------
loss: 0.201138  [    0/70685]
loss: 0.133687  [ 6400/70685]
loss: 0.167621  [12800/70685]
loss: 0.258678  [19200/70685]
loss: 0.157892  [25600/70685]
loss: 0.189866  [32000/70685]
loss: 0.094461  [38400/70685]
loss: 0.126183  [44800/70685]
loss: 0.170268  [51200/70685]
loss: 0.127843  [57600/70685]
loss: 0.113434  [64000/70685]
loss: 0.148514  [70400/70685]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.166348 

Epoch 11
-------------------------------
loss: 0.108001  [    0/70685]
loss: 0.089012  [ 6400/70685]
loss: 0.094508  [12800/70685]
loss: 0.280293  [19200/70685]
loss: 0.169816  [25600/70685]
loss: 0.090648  [32000/70685]
loss: 0.265413  [38400/70685]
loss: 0.219679  [44800/70685]
loss: 0.225087  [51200/70685]
loss: 0.189884  [57600/70685]
loss: 0.161669  [64000/70685]
loss: 0.189573  [70400/70685]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.160644 

Epoch 12
-------------------------------
loss: 0.208910  [    0/70685]
loss: 0.081515  [ 6400/70685]
loss: 0.195907  [12800/70685]
loss: 0.173981  [19200/70685]
loss: 0.126958  [25600/70685]
loss: 0.108054  [32000/70685]
loss: 0.151674  [38400/70685]
loss: 0.184198  [44800/70685]
loss: 0.091107  [51200/70685]
loss: 0.162612  [57600/70685]
loss: 0.095771  [64000/70685]
loss: 0.112920  [70400/70685]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.161483 

Epoch 13
-------------------------------
loss: 0.107388  [    0/70685]
loss: 0.191452  [ 6400/70685]
loss: 0.184399  [12800/70685]
loss: 0.109715  [19200/70685]
loss: 0.110453  [25600/70685]
loss: 0.147097  [32000/70685]
loss: 0.168229  [38400/70685]
loss: 0.134383  [44800/70685]
loss: 0.162926  [51200/70685]
loss: 0.136047  [57600/70685]
loss: 0.178156  [64000/70685]
loss: 0.133018  [70400/70685]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.167162 

Epoch 14
-------------------------------
loss: 0.114090  [    0/70685]
loss: 0.150794  [ 6400/70685]
loss: 0.189128  [12800/70685]
loss: 0.108329  [19200/70685]
loss: 0.218800  [25600/70685]
loss: 0.119568  [32000/70685]
loss: 0.236688  [38400/70685]
loss: 0.139439  [44800/70685]
loss: 0.203249  [51200/70685]
loss: 0.139843  [57600/70685]
loss: 0.245555  [64000/70685]
loss: 0.098257  [70400/70685]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.156992 

Epoch 15
-------------------------------
loss: 0.131714  [    0/70685]
loss: 0.278812  [ 6400/70685]
loss: 0.280912  [12800/70685]
loss: 0.173019  [19200/70685]
loss: 0.230194  [25600/70685]
loss: 0.143530  [32000/70685]
loss: 0.127317  [38400/70685]
loss: 0.136348  [44800/70685]
loss: 0.230106  [51200/70685]
loss: 0.113835  [57600/70685]
loss: 0.127511  [64000/70685]
loss: 0.257133  [70400/70685]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.165552 

Epoch 16
-------------------------------
loss: 0.151038  [    0/70685]
loss: 0.089386  [ 6400/70685]
loss: 0.271275  [12800/70685]
loss: 0.146383  [19200/70685]
loss: 0.166201  [25600/70685]
loss: 0.163952  [32000/70685]
loss: 0.146636  [38400/70685]
loss: 0.233670  [44800/70685]
loss: 0.120475  [51200/70685]
loss: 0.198634  [57600/70685]
loss: 0.214626  [64000/70685]
loss: 0.124815  [70400/70685]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.119631 

Epoch 49
-------------------------------
loss: 0.106272  [    0/70415]
loss: 0.090272  [ 6400/70415]
loss: 0.090616  [12800/70415]
loss: 0.117823  [19200/70415]
loss: 0.033827  [25600/70415]
loss: 0.043294  [32000/70415]
loss: 0.118160  [38400/70415]
loss: 0.073581  [44800/70415]
loss: 0.081711  [51200/70415]
loss: 0.021288  [57600/70415]
loss: 0.097940  [64000/70415]
loss: 0.023305  [16500/70415]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.125034 

Epoch 50
-------------------------------
loss: 0.127024  [    0/70415]
loss: 0.016578  [ 6400/70415]
loss: 0.070996  [12800/70415]
loss: 0.013266  [19200/70415]
loss: 0.121765  [25600/70415]
loss: 0.022841  [32000/70415]
loss: 0.131569  [38400/70415]
loss: 0.192929  [44800/70415]
loss: 0.025998  [51200/70415]
loss: 0.030859  [57600/70415]
loss: 0.162109  [64000/70415]
loss: 0.103503  [16500/70415]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.122675 

Epoch 1
-------------------------------
loss: 0.627379  [    0/69806]
loss: 0.307725  [ 6400/69806]
loss: 0.318805  [12800/69806]
loss: 0.327375  [19200/69806]
loss: 0.360286  [25600/69806]
loss: 0.212731  [32000/69806]
loss: 0.433939  [38400/69806]
loss: 0.242335  [44800/69806]
loss: 0.199006  [51200/69806]
loss: 0.287058  [57600/69806]
loss: 0.240583  [64000/69806]
Test Error: 
 Accuracy: 90.0%, Avg loss: 0.257547 

Epoch 2
-------------------------------
loss: 0.273148  [    0/69806]
loss: 0.195961  [ 6400/69806]
loss: 0.448010  [12800/69806]
loss: 0.379882  [19200/69806]
loss: 0.358944  [25600/69806]
loss: 0.240479  [32000/69806]
loss: 0.308582  [38400/69806]
loss: 0.206002  [44800/69806]
loss: 0.302326  [51200/69806]
loss: 0.463753  [57600/69806]
loss: 0.347701  [64000/69806]
Test Error: 
 Accuracy: 90.8%, Avg loss: 0.242063 

Epoch 3
-------------------------------
loss: 0.136705  [    0/69806]
loss: 0.196154  [ 6400/69806]
loss: 0.173006  [12800/69806]
loss: 0.291280  [19200/69806]
loss: 0.194019  [25600/69806]
loss: 0.258719  [32000/69806]
loss: 0.114554  [38400/69806]
loss: 0.283527  [44800/69806]
loss: 0.285830  [51200/69806]
loss: 0.126411  [57600/69806]
loss: 0.205763  [64000/69806]
Test Error: 
 Accuracy: 89.9%, Avg loss: 0.262587 

Epoch 4
-------------------------------
loss: 0.199851  [    0/69806]
loss: 0.204236  [ 6400/69806]
loss: 0.203671  [12800/69806]
loss: 0.238731  [19200/69806]
loss: 0.153614  [25600/69806]
loss: 0.417071  [32000/69806]
loss: 0.182256  [38400/69806]
loss: 0.182542  [44800/69806]
loss: 0.306762  [51200/69806]
loss: 0.216889  [57600/69806]
loss: 0.448943  [64000/69806]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.223699 

Epoch 5
-------------------------------
loss: 0.188453  [    0/69806]
loss: 0.198543  [ 6400/69806]
loss: 0.459261  [12800/69806]
loss: 0.169109  [19200/69806]
loss: 0.245034  [25600/69806]
loss: 0.246438  [32000/69806]
loss: 0.230416  [38400/69806]
loss: 0.138569  [44800/69806]
loss: 0.223533  [51200/69806]
loss: 0.181326  [57600/69806]
loss: 0.207137  [64000/69806]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.229060 

Epoch 6
-------------------------------
loss: 0.224215  [    0/69806]
loss: 0.127693  [ 6400/69806]
loss: 0.246193  [12800/69806]
loss: 0.294876  [19200/69806]
loss: 0.319050  [25600/69806]
loss: 0.344205  [32000/69806]
loss: 0.256498  [38400/69806]
loss: 0.296981  [44800/69806]
loss: 0.370261  [51200/69806]
loss: 0.226291  [57600/69806]
loss: 0.200926  [64000/69806]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.222824 

Epoch 7
-------------------------------
loss: 0.091997  [    0/69806]
loss: 0.239781  [ 6400/69806]
loss: 0.242262  [12800/69806]
loss: 0.284784  [19200/69806]
loss: 0.201695  [25600/69806]
loss: 0.319257  [32000/69806]
loss: 0.266781  [38400/69806]
loss: 0.255558  [44800/69806]
loss: 0.160081  [51200/69806]
loss: 0.228986  [57600/69806]
loss: 0.226223  [64000/69806]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.211269 

Epoch 8
-------------------------------
loss: 0.164470  [    0/69806]
loss: 0.262788  [ 6400/69806]
loss: 0.288230  [12800/69806]
loss: 0.167400  [19200/69806]
loss: 0.317986  [25600/69806]
loss: 0.195735  [32000/69806]
loss: 0.138383  [38400/69806]
loss: 0.252666  [44800/69806]
loss: 0.182177  [51200/69806]
loss: 0.145285  [57600/69806]
loss: 0.214274  [64000/69806]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.208964 

Epoch 9
-------------------------------
loss: 0.365020  [    0/69806]
loss: 0.195288  [ 6400/69806]
loss: 0.220845  [12800/69806]
loss: 0.093481  [19200/69806]
loss: 0.335111  [25600/69806]
loss: 0.269801  [32000/69806]
loss: 0.249564  [38400/69806]
loss: 0.231558  [44800/69806]
loss: 0.226605  [51200/69806]
loss: 0.330844  [57600/69806]
loss: 0.317621  [64000/69806]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.215714 

Epoch 10
-------------------------------
loss: 0.160711  [    0/69806]
loss: 0.181374  [ 6400/69806]
loss: 0.309685  [12800/69806]
loss: 0.184683  [19200/69806]
loss: 0.085761  [25600/69806]
loss: 0.142969  [32000/69806]
loss: 0.135283  [38400/69806]
loss: 0.169594  [44800/69806]
loss: 0.181691  [51200/69806]
loss: 0.173088  [57600/69806]
loss: 0.200464  [64000/69806]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.214328 

Epoch 11
-------------------------------
loss: 0.180124  [    0/69806]
loss: 0.284362  [ 6400/69806]
loss: 0.114735  [12800/69806]
loss: 0.371003  [19200/69806]
loss: 0.304192  [25600/69806]
loss: 0.237125  [32000/69806]
loss: 0.194745  [38400/69806]
loss: 0.389894  [44800/69806]
loss: 0.236279  [51200/69806]
loss: 0.156091  [57600/69806]
loss: 0.112886  [64000/69806]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.203286 

Epoch 12
-------------------------------
loss: 0.151314  [    0/69806]
loss: 0.180665  [ 6400/69806]
loss: 0.236311  [12800/69806]
loss: 0.123901  [19200/69806]
loss: 0.163227  [25600/69806]
loss: 0.359532  [32000/69806]
loss: 0.224333  [38400/69806]
loss: 0.171720  [44800/69806]
loss: 0.210574  [51200/69806]
loss: 0.390601  [57600/69806]
loss: 0.230382  [64000/69806]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.201169 

Epoch 13
-------------------------------
loss: 0.263315  [    0/69806]
loss: 0.295491  [ 6400/69806]
loss: 0.107767  [12800/69806]
loss: 0.193489  [19200/69806]
loss: 0.228203  [25600/69806]
loss: 0.131258  [32000/69806]
loss: 0.207607  [38400/69806]
loss: 0.206548  [44800/69806]
loss: 0.141240  [51200/69806]
loss: 0.162063  [57600/69806]
loss: 0.154344  [64000/69806]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.211768 

Epoch 14
-------------------------------
loss: 0.206015  [    0/69806]
loss: 0.155157  [ 6400/69806]
loss: 0.087250  [12800/69806]
loss: 0.267274  [19200/69806]
loss: 0.163268  [25600/69806]
loss: 0.161151  [32000/69806]
loss: 0.182293  [38400/69806]
loss: 0.344597  [44800/69806]
loss: 0.265393  [51200/69806]
loss: 0.170316  [57600/69806]
loss: 0.177190  [64000/69806]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.213804 

Epoch 15
-------------------------------
loss: 0.181173  [    0/69806]
loss: 0.235409  [ 6400/69806]
loss: 0.213242  [12800/69806]
loss: 0.229093  [19200/69806]
loss: 0.160704  [25600/69806]
loss: 0.162012  [32000/69806]
loss: 0.160186  [38400/69806]
loss: 0.131384  [44800/69806]
loss: 0.081773  [51200/69806]
loss: 0.242783  [57600/69806]
loss: 0.202294  [64000/69806]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.215511 

Epoch 16
-------------------------------
loss: 0.229747  [    0/69806]
loss: 0.176760  [ 6400/69806]
loss: 0.237149  [12800/69806]
loss: 0.160511  [19200/69806]
loss: 0.252561  [25600/69806]
loss: 0.223150  [32000/69806]
loss: 0.190098  [38400/69806]
loss: 0.226182  [44800/69806]
loss: 0.137748  [51200/69806]
loss: 0.155198  [57600/69806]
loss: 0.180540  [64000/69806]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.206083 

Epoch 17
-------------------------------
loss: 0.096334  [    0/69806]
loss: 0.329675  [ 6400/69806]
loss: 0.122121  [12800/69806]
loss: 0.135146  [19200/69806]
loss: 0.202894  [25600/69806]
loss: 0.335314  [32000/69806]
loss: 0.169325  [38400/69806]
loss: 0.227102  [44800/69806]
loss: 0.218438  [51200/69806]
loss: 0.222088  [57600/69806]
loss: 0.155360  [64000/69806]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.212934 

Epoch 18
-------------------------------
loss: 0.122447  [12800/72227]
loss: 0.151075  [19200/72227]
loss: 0.116391  [25600/72227]
loss: 0.136506  [32000/72227]
loss: 0.062846  [38400/72227]
loss: 0.040688  [44800/72227]
loss: 0.097464  [51200/72227]
loss: 0.058404  [57600/72227]
loss: 0.055225  [64000/72227]
loss: 0.130051  [70400/72227]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.090771 

Epoch 3
-------------------------------
loss: 0.159889  [    0/72227]
loss: 0.084610  [ 6400/72227]
loss: 0.054979  [12800/72227]
loss: 0.064167  [19200/72227]
loss: 0.038925  [25600/72227]
loss: 0.140419  [32000/72227]
loss: 0.163142  [38400/72227]
loss: 0.030011  [44800/72227]
loss: 0.054857  [51200/72227]
loss: 0.026518  [57600/72227]
loss: 0.251456  [64000/72227]
loss: 0.088719  [70400/72227]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089723 

Epoch 4
-------------------------------
loss: 0.105664  [    0/72227]
loss: 0.129626  [ 6400/72227]
loss: 0.041648  [12800/72227]
loss: 0.073341  [19200/72227]
loss: 0.090457  [25600/72227]
loss: 0.060951  [32000/72227]
loss: 0.040011  [38400/72227]
loss: 0.032636  [44800/72227]
loss: 0.087724  [51200/72227]
loss: 0.118940  [57600/72227]
loss: 0.094259  [64000/72227]
loss: 0.026629  [70400/72227]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.082489 

Epoch 5
-------------------------------
loss: 0.112526  [    0/72227]
loss: 0.028069  [ 6400/72227]
loss: 0.072729  [12800/72227]
loss: 0.008168  [19200/72227]
loss: 0.058803  [25600/72227]
loss: 0.011164  [32000/72227]
loss: 0.100776  [38400/72227]
loss: 0.048896  [44800/72227]
loss: 0.026977  [51200/72227]
loss: 0.100639  [57600/72227]
loss: 0.082307  [64000/72227]
loss: 0.097529  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077795 

Epoch 6
-------------------------------
loss: 0.072380  [    0/72227]
loss: 0.029735  [ 6400/72227]
loss: 0.051060  [12800/72227]
loss: 0.111050  [19200/72227]
loss: 0.070740  [25600/72227]
loss: 0.062451  [32000/72227]
loss: 0.089942  [38400/72227]
loss: 0.031948  [44800/72227]
loss: 0.022401  [51200/72227]
loss: 0.107059  [57600/72227]
loss: 0.084336  [64000/72227]
loss: 0.086367  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077899 

Epoch 7
-------------------------------
loss: 0.025278  [    0/72227]
loss: 0.049029  [ 6400/72227]
loss: 0.030766  [12800/72227]
loss: 0.007760  [19200/72227]
loss: 0.026061  [25600/72227]
loss: 0.200753  [32000/72227]
loss: 0.047817  [38400/72227]
loss: 0.047018  [44800/72227]
loss: 0.019735  [51200/72227]
loss: 0.025555  [57600/72227]
loss: 0.141939  [64000/72227]
loss: 0.014585  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082354 

Epoch 8
-------------------------------
loss: 0.064472  [    0/72227]
loss: 0.003843  [ 6400/72227]
loss: 0.033715  [12800/72227]
loss: 0.079232  [19200/72227]
loss: 0.020666  [25600/72227]
loss: 0.094971  [32000/72227]
loss: 0.052594  [38400/72227]
loss: 0.026731  [44800/72227]
loss: 0.094509  [51200/72227]
loss: 0.085084  [57600/72227]
loss: 0.043967  [64000/72227]
loss: 0.083285  [70400/72227]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.091065 

Epoch 9
-------------------------------
loss: 0.048888  [    0/72227]
loss: 0.064107  [ 6400/72227]
loss: 0.103908  [12800/72227]
loss: 0.073827  [19200/72227]
loss: 0.209203  [25600/72227]
loss: 0.026500  [32000/72227]
loss: 0.108798  [38400/72227]
loss: 0.034274  [44800/72227]
loss: 0.100775  [51200/72227]
loss: 0.127855  [57600/72227]
loss: 0.018821  [64000/72227]
loss: 0.086547  [70400/72227]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075215 

Epoch 10
-------------------------------
loss: 0.020185  [    0/72227]
loss: 0.012679  [ 6400/72227]
loss: 0.067120  [12800/72227]
loss: 0.018554  [19200/72227]
loss: 0.003966  [25600/72227]
loss: 0.041047  [32000/72227]
loss: 0.039413  [38400/72227]
loss: 0.040714  [44800/72227]
loss: 0.008637  [51200/72227]
loss: 0.013222  [57600/72227]
loss: 0.006311  [64000/72227]
loss: 0.027188  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075450 

Epoch 11
-------------------------------
loss: 0.013141  [    0/72227]
loss: 0.040573  [ 6400/72227]
loss: 0.006956  [12800/72227]
loss: 0.085733  [19200/72227]
loss: 0.031558  [25600/72227]
loss: 0.017904  [32000/72227]
loss: 0.012577  [38400/72227]
loss: 0.020413  [44800/72227]
loss: 0.103281  [51200/72227]
loss: 0.024687  [57600/72227]
loss: 0.150100  [64000/72227]
loss: 0.035245  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080535 

Epoch 12
-------------------------------
loss: 0.050966  [    0/72227]
loss: 0.090924  [ 6400/72227]
loss: 0.039065  [12800/72227]
loss: 0.004373  [19200/72227]
loss: 0.009244  [25600/72227]
loss: 0.022494  [32000/72227]
loss: 0.080804  [38400/72227]
loss: 0.064611  [44800/72227]
loss: 0.060805  [51200/72227]
loss: 0.019641  [57600/72227]
loss: 0.043697  [64000/72227]
loss: 0.041062  [70400/72227]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082202 

Epoch 13
-------------------------------
loss: 0.026458  [    0/72227]
loss: 0.019912  [ 6400/72227]
loss: 0.076195  [12800/72227]
loss: 0.094298  [19200/72227]
loss: 0.019791  [25600/72227]
loss: 0.041228  [32000/72227]
loss: 0.067422  [38400/72227]
loss: 0.069523  [44800/72227]
loss: 0.072364  [51200/72227]
loss: 0.091579  [57600/72227]
loss: 0.064516  [64000/72227]
loss: 0.043265  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.078036 

Epoch 14
-------------------------------
loss: 0.040520  [    0/72227]
loss: 0.073824  [ 6400/72227]
loss: 0.050920  [12800/72227]
loss: 0.029976  [19200/72227]
loss: 0.069953  [25600/72227]
loss: 0.019737  [32000/72227]
loss: 0.039622  [38400/72227]
loss: 0.041231  [44800/72227]
loss: 0.077825  [51200/72227]
loss: 0.012658  [57600/72227]
loss: 0.079335  [64000/72227]
loss: 0.009235  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072955 

Epoch 15
-------------------------------
loss: 0.023696  [    0/72227]
loss: 0.081164  [ 6400/72227]
loss: 0.039076  [12800/72227]
loss: 0.039367  [19200/72227]
loss: 0.050964  [25600/72227]
loss: 0.008132  [32000/72227]
loss: 0.039604  [38400/72227]
loss: 0.068323  [44800/72227]
loss: 0.052807  [51200/72227]
loss: 0.008299  [57600/72227]
loss: 0.080522  [64000/72227]
loss: 0.004305  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.074996 

Epoch 16
-------------------------------
loss: 0.060982  [    0/72227]
loss: 0.007807  [ 6400/72227]
loss: 0.076006  [12800/72227]
loss: 0.029898  [19200/72227]
loss: 0.018179  [25600/72227]
loss: 0.046998  [32000/72227]
loss: 0.009631  [38400/72227]
loss: 0.013953  [44800/72227]
loss: 0.145624  [51200/72227]
loss: 0.141327  [57600/72227]
loss: 0.039230  [64000/72227]
loss: 0.080735  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.072495 

Epoch 17
-------------------------------
loss: 0.019487  [    0/72227]
loss: 0.078936  [ 6400/72227]
loss: 0.019800  [12800/72227]
loss: 0.035666  [19200/72227]
loss: 0.028502  [25600/72227]
loss: 0.072781  [32000/72227]
loss: 0.027462  [38400/72227]
loss: 0.017835  [44800/72227]
loss: 0.024434  [51200/72227]
loss: 0.033425  [57600/72227]
loss: 0.099535  [64000/72227]
loss: 0.086740  [70400/72227]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072232 

Epoch 18
-------------------------------
loss: 0.056553  [    0/72227]
loss: 0.066182  [ 6400/72227]
loss: 0.072502  [12800/72227]
loss: 0.005956  [19200/72227]
loss: 0.006647  [25600/72227]
loss: 0.048786  [32000/72227]
loss: 0.021135  [38400/72227]
loss: 0.069035  [44800/72227]
loss: 0.087802  [51200/72227]
loss: 0.083117  [57600/72227]
loss: 0.021813  [64000/72227]
loss: 0.059350  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069572 

Epoch 19
-------------------------------
loss: 0.036718  [    0/72227]
loss: 0.049706  [ 6400/72227]
loss: 0.022691  [12800/72227]
loss: 0.018955  [19200/72227]
loss: 0.090039  [25600/72227]
loss: 0.008039  [32000/72227]
loss: 0.025796  [38400/72227]
loss: 0.021408  [44800/72227]
loss: 0.014405  [51200/72227]
loss: 0.071132  [57600/72227]
loss: 0.020953  [64000/72227]
loss: 0.071153  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073387 

Epoch 20
-------------------------------
loss: 0.016109  [    0/72227]
loss: 0.018577  [ 6400/72227]
loss: 0.002155  [12800/72227]
loss: 0.016574  [51200/71616]
loss: 0.020398  [57600/71616]
loss: 0.006248  [64000/71616]
loss: 0.007051  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066460 

Epoch 14
-------------------------------
loss: 0.032253  [    0/71616]
loss: 0.032352  [ 6400/71616]
loss: 0.037869  [12800/71616]
loss: 0.051778  [19200/71616]
loss: 0.080927  [25600/71616]
loss: 0.079258  [32000/71616]
loss: 0.008916  [38400/71616]
loss: 0.011551  [44800/71616]
loss: 0.011858  [51200/71616]
loss: 0.044132  [57600/71616]
loss: 0.020711  [64000/71616]
loss: 0.004341  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070540 

Epoch 15
-------------------------------
loss: 0.034349  [    0/71616]
loss: 0.036337  [ 6400/71616]
loss: 0.048359  [12800/71616]
loss: 0.014683  [19200/71616]
loss: 0.009102  [25600/71616]
loss: 0.033266  [32000/71616]
loss: 0.026793  [38400/71616]
loss: 0.005505  [44800/71616]
loss: 0.017466  [51200/71616]
loss: 0.019473  [57600/71616]
loss: 0.045160  [64000/71616]
loss: 0.079742  [70400/71616]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.065233 

Epoch 16
-------------------------------
loss: 0.043448  [    0/71616]
loss: 0.047710  [ 6400/71616]
loss: 0.005427  [12800/71616]
loss: 0.063045  [19200/71616]
loss: 0.021700  [25600/71616]
loss: 0.001369  [32000/71616]
loss: 0.078739  [38400/71616]
loss: 0.049016  [44800/71616]
loss: 0.004215  [51200/71616]
loss: 0.041164  [57600/71616]
loss: 0.009395  [64000/71616]
loss: 0.054734  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067150 

Epoch 17
-------------------------------
loss: 0.051502  [    0/71616]
loss: 0.014701  [ 6400/71616]
loss: 0.172736  [12800/71616]
loss: 0.031928  [19200/71616]
loss: 0.046801  [25600/71616]
loss: 0.073982  [32000/71616]
loss: 0.039381  [38400/71616]
loss: 0.048720  [44800/71616]
loss: 0.031922  [51200/71616]
loss: 0.201590  [57600/71616]
loss: 0.021322  [64000/71616]
loss: 0.009548  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067805 

Epoch 18
-------------------------------
loss: 0.025737  [    0/71616]
loss: 0.042489  [ 6400/71616]
loss: 0.006818  [12800/71616]
loss: 0.006127  [19200/71616]
loss: 0.063953  [25600/71616]
loss: 0.015512  [32000/71616]
loss: 2.650557  [38400/71616]
loss: 0.022142  [44800/71616]
loss: 0.019258  [51200/71616]
loss: 0.018170  [57600/71616]
loss: 0.071497  [64000/71616]
loss: 0.007265  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.062858 

Epoch 19
-------------------------------
loss: 0.082746  [    0/71616]
loss: 0.049034  [ 6400/71616]
loss: 0.046209  [12800/71616]
loss: 0.089577  [19200/71616]
loss: 0.013591  [25600/71616]
loss: 0.020143  [32000/71616]
loss: 0.034839  [38400/71616]
loss: 0.007927  [44800/71616]
loss: 0.085649  [51200/71616]
loss: 0.031548  [57600/71616]
loss: 0.014490  [64000/71616]
loss: 0.014141  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073716 

Epoch 20
-------------------------------
loss: 0.038978  [    0/71616]
loss: 0.020183  [ 6400/71616]
loss: 0.042619  [12800/71616]
loss: 0.050074  [19200/71616]
loss: 0.053671  [25600/71616]
loss: 0.050754  [32000/71616]
loss: 0.020753  [38400/71616]
loss: 0.003886  [44800/71616]
loss: 0.054348  [51200/71616]
loss: 0.068204  [57600/71616]
loss: 0.015703  [64000/71616]
loss: 0.002603  [70400/71616]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.065310 

Epoch 21
-------------------------------
loss: 0.009647  [    0/71616]
loss: 0.041679  [ 6400/71616]
loss: 0.035063  [12800/71616]
loss: 0.024961  [19200/71616]
loss: 0.072190  [25600/71616]
loss: 0.009857  [32000/71616]
loss: 0.003824  [38400/71616]
loss: 0.001726  [44800/71616]
loss: 0.061508  [51200/71616]
loss: 0.066308  [57600/71616]
loss: 0.004038  [64000/71616]
loss: 0.006796  [70400/71616]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.069630 

Epoch 22
-------------------------------
loss: 0.047061  [    0/71616]
loss: 0.065582  [ 6400/71616]
loss: 0.005252  [12800/71616]
loss: 0.030295  [19200/71616]
loss: 0.020871  [25600/71616]
loss: 0.008865  [32000/71616]
loss: 0.202383  [38400/71616]
loss: 0.045119  [44800/71616]
loss: 0.030873  [51200/71616]
loss: 0.022493  [57600/71616]
loss: 0.085451  [64000/71616]
loss: 0.019068  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077811 

Epoch 23
-------------------------------
loss: 0.040244  [    0/71616]
loss: 0.017421  [ 6400/71616]
loss: 0.003612  [12800/71616]
loss: 0.057122  [19200/71616]
loss: 0.006976  [25600/71616]
loss: 0.028272  [32000/71616]
loss: 0.004908  [38400/71616]
loss: 0.050765  [44800/71616]
loss: 0.049928  [51200/71616]
loss: 0.054775  [57600/71616]
loss: 0.013886  [64000/71616]
loss: 0.007618  [70400/71616]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.068215 

Epoch 24
-------------------------------
loss: 0.062352  [    0/71616]
loss: 0.021149  [ 6400/71616]
loss: 0.179648  [12800/71616]
loss: 0.028136  [19200/71616]
loss: 0.061778  [25600/71616]
loss: 0.035300  [32000/71616]
loss: 0.000659  [38400/71616]
loss: 0.008066  [44800/71616]
loss: 0.010674  [51200/71616]
loss: 0.087413  [57600/71616]
loss: 0.004884  [64000/71616]
loss: 0.042521  [70400/71616]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072005 

Epoch 25
-------------------------------
loss: 0.053148  [    0/71616]
loss: 0.004257  [ 6400/71616]
loss: 0.088278  [12800/71616]
loss: 0.030005  [19200/71616]
loss: 0.047630  [25600/71616]
loss: 0.027478  [32000/71616]
loss: 0.039116  [38400/71616]
loss: 0.016254  [44800/71616]
loss: 0.055741  [51200/71616]
loss: 0.010061  [57600/71616]
loss: 0.020705  [64000/71616]
loss: 0.020187  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.071036 

Epoch 26
-------------------------------
loss: 0.009415  [    0/71616]
loss: 0.030413  [ 6400/71616]
loss: 0.107027  [12800/71616]
loss: 0.148272  [19200/71616]
loss: 0.094301  [25600/71616]
loss: 0.028406  [32000/71616]
loss: 0.007418  [38400/71616]
loss: 0.065433  [44800/71616]
loss: 0.026265  [51200/71616]
loss: 0.037714  [57600/71616]
loss: 0.036392  [64000/71616]
loss: 0.046760  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.072933 

Epoch 27
-------------------------------
loss: 0.014320  [    0/71616]
loss: 0.029030  [ 6400/71616]
loss: 0.027440  [12800/71616]
loss: 0.000562  [19200/71616]
loss: 0.040852  [25600/71616]
loss: 0.124345  [32000/71616]
loss: 0.027337  [38400/71616]
loss: 0.003425  [44800/71616]
loss: 0.014738  [51200/71616]
loss: 0.004375  [57600/71616]
loss: 0.042358  [64000/71616]
loss: 0.003727  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.074146 

Epoch 28
-------------------------------
loss: 0.050983  [    0/71616]
loss: 0.061723  [ 6400/71616]
loss: 0.016083  [12800/71616]
loss: 0.015573  [19200/71616]
loss: 0.081753  [25600/71616]
loss: 0.037688  [32000/71616]
loss: 0.009414  [38400/71616]
loss: 0.097636  [44800/71616]
loss: 0.069673  [51200/71616]
loss: 0.048401  [57600/71616]
loss: 0.071876  [64000/71616]
loss: 0.009725  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070623 

Epoch 29
-------------------------------
loss: 0.032430  [    0/71616]
loss: 0.042009  [ 6400/71616]
loss: 0.062364  [12800/71616]
loss: 0.054485  [19200/71616]
loss: 0.007245  [25600/71616]
loss: 0.011234  [32000/71616]
loss: 0.045889  [38400/71616]
loss: 0.036459  [44800/71616]
loss: 0.024938  [51200/71616]
loss: 0.021514  [57600/71616]
loss: 0.003569  [64000/71616]
loss: 0.024652  [70400/71616]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.076027 

Epoch 30
-------------------------------
loss: 0.036025  [    0/71616]
loss: 0.030930  [ 6400/71616]
loss: 0.029091  [12800/71616]
loss: 0.013208  [19200/71616]
loss: 0.012460  [25600/71616]
loss: 0.001040  [32000/71616]
loss: 0.032847  [38400/71616]
loss: 0.009089  [44800/71616]
loss: 0.010137  [51200/71616]
loss: 0.008525  [57600/71616]
loss: 0.077402  [64000/71616]
loss: 0.018479  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.075423 

Epoch 31
-------------------------------
loss: 0.004019  [    0/71616]
loss: 0.013585  [ 6400/71616]
loss: 0.035232  [12800/71616]
loss: 0.003053  [19200/71616]
loss: 0.025516  [25600/71616]
loss: 0.005187  [32000/71616]
loss: 0.025614  [38400/71616]
loss: 0.003280  [44800/71616]
loss: 0.066507  [51200/71616]
loss: 0.126775  [ 6400/70932]
loss: 0.194307  [12800/70932]
loss: 0.060725  [19200/70932]
loss: 0.195611  [25600/70932]
loss: 0.240494  [32000/70932]
loss: 0.255155  [38400/70932]
loss: 0.210715  [44800/70932]
loss: 0.186903  [51200/70932]
loss: 0.241871  [57600/70932]
loss: 0.245407  [64000/70932]
loss: 0.104940  [70400/70932]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.207879 

Epoch 3
-------------------------------
loss: 0.253347  [    0/70932]
loss: 0.094878  [ 6400/70932]
loss: 0.055796  [12800/70932]
loss: 0.163571  [19200/70932]
loss: 0.173403  [25600/70932]
loss: 0.056195  [32000/70932]
loss: 0.173282  [38400/70932]
loss: 0.096172  [44800/70932]
loss: 0.205243  [51200/70932]
loss: 0.142592  [57600/70932]
loss: 0.137960  [64000/70932]
loss: 0.171697  [70400/70932]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.197022 

Epoch 4
-------------------------------
loss: 0.091371  [    0/70932]
loss: 0.137895  [ 6400/70932]
loss: 0.102920  [12800/70932]
loss: 0.199389  [19200/70932]
loss: 0.134162  [25600/70932]
loss: 0.175799  [32000/70932]
loss: 0.058877  [38400/70932]
loss: 0.141361  [44800/70932]
loss: 0.072886  [51200/70932]
loss: 0.142401  [57600/70932]
loss: 0.150379  [64000/70932]
loss: 0.123092  [70400/70932]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.183447 

Epoch 5
-------------------------------
loss: 0.110194  [    0/70932]
loss: 0.168130  [ 6400/70932]
loss: 0.069650  [12800/70932]
loss: 0.243641  [19200/70932]
loss: 0.221412  [25600/70932]
loss: 0.237765  [32000/70932]
loss: 0.205534  [38400/70932]
loss: 0.220033  [44800/70932]
loss: 0.111939  [51200/70932]
loss: 0.112767  [57600/70932]
loss: 0.155338  [64000/70932]
loss: 0.080927  [70400/70932]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.181054 

Epoch 6
-------------------------------
loss: 0.103010  [    0/70932]
loss: 0.124978  [ 6400/70932]
loss: 0.147503  [12800/70932]
loss: 0.136855  [19200/70932]
loss: 0.149873  [25600/70932]
loss: 0.093028  [32000/70932]
loss: 0.105944  [38400/70932]
loss: 0.118539  [44800/70932]
loss: 0.121458  [51200/70932]
loss: 0.169872  [57600/70932]
loss: 0.481395  [64000/70932]
loss: 0.134090  [70400/70932]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.170387 

Epoch 7
-------------------------------
loss: 0.240059  [    0/70932]
loss: 0.141858  [ 6400/70932]
loss: 0.177716  [12800/70932]
loss: 0.208225  [19200/70932]
loss: 0.107171  [25600/70932]
loss: 0.084467  [32000/70932]
loss: 0.064787  [38400/70932]
loss: 0.235582  [44800/70932]
loss: 0.307102  [51200/70932]
loss: 0.280941  [57600/70932]
loss: 0.139100  [64000/70932]
loss: 0.096251  [70400/70932]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.143677 

Epoch 8
-------------------------------
loss: 0.124524  [    0/70932]
loss: 0.188363  [ 6400/70932]
loss: 0.163283  [12800/70932]
loss: 0.209350  [19200/70932]
loss: 0.097871  [25600/70932]
loss: 0.181839  [32000/70932]
loss: 0.109871  [38400/70932]
loss: 0.171655  [44800/70932]
loss: 0.106840  [51200/70932]
loss: 0.224268  [57600/70932]
loss: 0.070857  [64000/70932]
loss: 0.177689  [70400/70932]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.174671 

Epoch 9
-------------------------------
loss: 0.169605  [    0/70932]
loss: 0.116909  [ 6400/70932]
loss: 0.185682  [12800/70932]
loss: 0.150454  [19200/70932]
loss: 0.086714  [25600/70932]
loss: 0.255990  [32000/70932]
loss: 0.145510  [38400/70932]
loss: 0.081604  [44800/70932]
loss: 0.157084  [51200/70932]
loss: 0.050245  [57600/70932]
loss: 1.669529  [64000/70932]
loss: 0.123279  [70400/70932]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.173287 

Epoch 10
-------------------------------
loss: 0.256175  [    0/70932]
loss: 0.054960  [ 6400/70932]
loss: 0.082155  [12800/70932]
loss: 0.176014  [19200/70932]
loss: 0.144174  [25600/70932]
loss: 0.100320  [32000/70932]
loss: 0.108025  [38400/70932]
loss: 0.064840  [44800/70932]
loss: 0.143157  [51200/70932]
loss: 0.151682  [57600/70932]
loss: 0.076432  [64000/70932]
loss: 0.096556  [70400/70932]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177196 

Epoch 11
-------------------------------
loss: 0.109231  [    0/70932]
loss: 0.170975  [ 6400/70932]
loss: 0.060570  [12800/70932]
loss: 0.158409  [19200/70932]
loss: 0.113932  [25600/70932]
loss: 0.079551  [32000/70932]
loss: 0.222581  [38400/70932]
loss: 0.090007  [44800/70932]
loss: 0.321089  [51200/70932]
loss: 0.228638  [57600/70932]
loss: 0.142524  [64000/70932]
loss: 0.151978  [70400/70932]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.173554 

Epoch 12
-------------------------------
loss: 0.098317  [    0/70932]
loss: 0.155509  [ 6400/70932]
loss: 0.063513  [12800/70932]
loss: 0.230644  [19200/70932]
loss: 0.137982  [25600/70932]
loss: 0.047342  [32000/70932]
loss: 0.203175  [38400/70932]
loss: 0.154010  [44800/70932]
loss: 0.156680  [51200/70932]
loss: 0.079919  [57600/70932]
loss: 0.086090  [64000/70932]
loss: 0.125289  [70400/70932]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.168349 

Epoch 13
-------------------------------
loss: 0.202037  [    0/70932]
loss: 0.109017  [ 6400/70932]
loss: 0.155442  [12800/70932]
loss: 0.181744  [19200/70932]
loss: 0.147365  [25600/70932]
loss: 0.110503  [32000/70932]
loss: 0.335250  [38400/70932]
loss: 0.241247  [44800/70932]
loss: 0.151697  [51200/70932]
loss: 0.229982  [57600/70932]
loss: 0.201476  [64000/70932]
loss: 0.342355  [70400/70932]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.164565 

Epoch 14
-------------------------------
loss: 0.188427  [    0/70932]
loss: 0.121780  [ 6400/70932]
loss: 0.196477  [12800/70932]
loss: 0.176901  [19200/70932]
loss: 0.063127  [25600/70932]
loss: 0.151036  [32000/70932]
loss: 0.118856  [38400/70932]
loss: 0.102693  [44800/70932]
loss: 0.074776  [51200/70932]
loss: 0.041587  [57600/70932]
loss: 0.066209  [64000/70932]
loss: 0.064477  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.159955 

Epoch 15
-------------------------------
loss: 0.139129  [    0/70932]
loss: 0.049488  [ 6400/70932]
loss: 0.110094  [12800/70932]
loss: 0.149511  [19200/70932]
loss: 0.102831  [25600/70932]
loss: 0.072469  [32000/70932]
loss: 0.090427  [38400/70932]
loss: 0.092941  [44800/70932]
loss: 0.151286  [51200/70932]
loss: 0.110894  [57600/70932]
loss: 0.266939  [64000/70932]
loss: 0.084450  [70400/70932]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.166764 

Epoch 16
-------------------------------
loss: 0.115819  [    0/70932]
loss: 0.162860  [ 6400/70932]
loss: 0.188278  [12800/70932]
loss: 0.162535  [19200/70932]
loss: 0.093064  [25600/70932]
loss: 0.077336  [32000/70932]
loss: 0.066865  [38400/70932]
loss: 0.052439  [44800/70932]
loss: 0.161392  [51200/70932]
loss: 0.257301  [57600/70932]
loss: 0.119499  [64000/70932]
loss: 0.239985  [70400/70932]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.161760 

Epoch 17
-------------------------------
loss: 0.109628  [    0/70932]
loss: 0.121654  [ 6400/70932]
loss: 0.100173  [12800/70932]
loss: 0.156341  [19200/70932]
loss: 0.060389  [25600/70932]
loss: 0.102528  [32000/70932]
loss: 0.135723  [38400/70932]
loss: 0.133761  [44800/70932]
loss: 0.065658  [51200/70932]
loss: 0.045612  [57600/70932]
loss: 0.200949  [64000/70932]
loss: 0.190048  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.160250 

Epoch 18
-------------------------------
loss: 0.143320  [    0/70932]
loss: 0.081009  [ 6400/70932]
loss: 0.156620  [12800/70932]
loss: 0.323584  [19200/70932]
loss: 0.158094  [25600/70932]
loss: 0.208968  [32000/70932]
loss: 0.068429  [38400/70932]
loss: 0.121993  [44800/70932]
loss: 0.046808  [51200/70932]
loss: 0.218448  [57600/70932]
loss: 0.104455  [64000/70932]
loss: 0.119689  [70400/70932]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.171079 

Epoch 19
-------------------------------
loss: 0.037147  [    0/70932]
loss: 0.149548  [ 6400/70932]
loss: 0.148672  [12800/70932]
loss: 0.101226  [19200/70932]
loss: 0.133667  [25600/70932]
loss: 0.035211  [32000/70932]
loss: 0.251191  [38400/70932]
loss: 0.137290  [44800/70932]
loss: 0.114393  [51200/70932]
loss: 1.612131  [57600/70932]
loss: 0.059758  [64000/70932]
loss: 0.145610  [70400/70932]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.160093 

Epoch 20
-------------------------------
loss: 0.068807  [    0/70932]
loss: 0.064061  [ 6400/70932]
loss: 0.054416  [51200/69711]
loss: 0.082596  [57600/69711]
loss: 0.047034  [64000/69711]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.085004 

Epoch 49
-------------------------------
loss: 0.093263  [    0/69711]
loss: 0.118772  [ 6400/69711]
loss: 0.031072  [12800/69711]
loss: 0.118361  [19200/69711]
loss: 0.061859  [25600/69711]
loss: 0.021887  [32000/69711]
loss: 0.033470  [38400/69711]
loss: 0.040776  [44800/69711]
loss: 0.055998  [51200/69711]
loss: 0.064784  [57600/69711]
loss: 0.055021  [64000/69711]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.077388 

Epoch 50
-------------------------------
loss: 0.087440  [    0/69711]
loss: 0.055347  [ 6400/69711]
loss: 0.039151  [12800/69711]
loss: 0.164481  [19200/69711]
loss: 0.030955  [25600/69711]
loss: 0.012187  [32000/69711]
loss: 0.021607  [38400/69711]
loss: 0.075268  [44800/69711]
loss: 0.045398  [51200/69711]
loss: 0.068171  [57600/69711]
loss: 0.036840  [64000/69711]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.090967 

Epoch 1
-------------------------------
loss: 0.610422  [    0/71285]
loss: 0.267339  [ 6400/71285]
loss: 0.247154  [12800/71285]
loss: 0.178857  [19200/71285]
loss: 0.256312  [25600/71285]
loss: 0.261284  [32000/71285]
loss: 0.227735  [38400/71285]
loss: 0.228318  [44800/71285]
loss: 0.201312  [51200/71285]
loss: 0.116056  [57600/71285]
loss: 0.218552  [64000/71285]
loss: 0.190709  [70400/71285]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.223983 

Epoch 2
-------------------------------
loss: 0.165443  [    0/71285]
loss: 0.086195  [ 6400/71285]
loss: 0.187373  [12800/71285]
loss: 0.116311  [19200/71285]
loss: 0.095167  [25600/71285]
loss: 0.135179  [32000/71285]
loss: 0.146037  [38400/71285]
loss: 0.166839  [44800/71285]
loss: 0.102645  [51200/71285]
loss: 0.278140  [57600/71285]
loss: 0.255176  [64000/71285]
loss: 0.105798  [70400/71285]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.178826 

Epoch 3
-------------------------------
loss: 0.164475  [    0/71285]
loss: 0.248932  [ 6400/71285]
loss: 0.213770  [12800/71285]
loss: 0.151834  [19200/71285]
loss: 0.108918  [25600/71285]
loss: 0.192364  [32000/71285]
loss: 0.065182  [38400/71285]
loss: 0.153541  [44800/71285]
loss: 0.193521  [51200/71285]
loss: 0.130659  [57600/71285]
loss: 0.165948  [64000/71285]
loss: 0.237820  [70400/71285]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.173369 

Epoch 4
-------------------------------
loss: 0.147626  [    0/71285]
loss: 0.105311  [ 6400/71285]
loss: 0.187261  [12800/71285]
loss: 0.115040  [19200/71285]
loss: 0.402709  [25600/71285]
loss: 0.125313  [32000/71285]
loss: 0.198909  [38400/71285]
loss: 0.247686  [44800/71285]
loss: 0.105468  [51200/71285]
loss: 0.154992  [57600/71285]
loss: 0.066979  [64000/71285]
loss: 0.255023  [70400/71285]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.166871 

Epoch 5
-------------------------------
loss: 0.176807  [    0/71285]
loss: 0.152376  [ 6400/71285]
loss: 0.150436  [12800/71285]
loss: 0.114087  [19200/71285]
loss: 0.096181  [25600/71285]
loss: 0.152375  [32000/71285]
loss: 0.104464  [38400/71285]
loss: 0.130602  [44800/71285]
loss: 0.147157  [51200/71285]
loss: 0.230059  [57600/71285]
loss: 0.169121  [64000/71285]
loss: 0.101081  [70400/71285]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.165737 

Epoch 6
-------------------------------
loss: 0.189854  [    0/71285]
loss: 0.092207  [ 6400/71285]
loss: 0.104917  [12800/71285]
loss: 0.115451  [19200/71285]
loss: 0.091679  [25600/71285]
loss: 0.114894  [32000/71285]
loss: 0.162390  [38400/71285]
loss: 0.082790  [44800/71285]
loss: 0.091321  [51200/71285]
loss: 0.172941  [57600/71285]
loss: 0.156330  [64000/71285]
loss: 0.174270  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.156336 

Epoch 7
-------------------------------
loss: 0.082787  [    0/71285]
loss: 0.045556  [ 6400/71285]
loss: 0.149306  [12800/71285]
loss: 0.088445  [19200/71285]
loss: 0.175829  [25600/71285]
loss: 0.066248  [32000/71285]
loss: 0.103857  [38400/71285]
loss: 0.255544  [44800/71285]
loss: 0.176493  [51200/71285]
loss: 0.072458  [57600/71285]
loss: 0.099336  [64000/71285]
loss: 0.301282  [70400/71285]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.161231 

Epoch 8
-------------------------------
loss: 0.193990  [    0/71285]
loss: 0.165122  [ 6400/71285]
loss: 0.144543  [12800/71285]
loss: 0.157204  [19200/71285]
loss: 0.107881  [25600/71285]
loss: 0.084711  [32000/71285]
loss: 0.099108  [38400/71285]
loss: 0.198888  [44800/71285]
loss: 0.204087  [51200/71285]
loss: 0.076854  [57600/71285]
loss: 0.082679  [64000/71285]
loss: 0.197869  [70400/71285]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.160447 

Epoch 9
-------------------------------
loss: 0.088151  [    0/71285]
loss: 0.105234  [ 6400/71285]
loss: 0.134546  [12800/71285]
loss: 0.180781  [19200/71285]
loss: 0.077702  [25600/71285]
loss: 0.251507  [32000/71285]
loss: 0.264842  [38400/71285]
loss: 0.145842  [44800/71285]
loss: 0.198167  [51200/71285]
loss: 0.166038  [57600/71285]
loss: 0.128617  [64000/71285]
loss: 0.107688  [70400/71285]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.162869 

Epoch 10
-------------------------------
loss: 0.182250  [    0/71285]
loss: 0.182588  [ 6400/71285]
loss: 0.076651  [12800/71285]
loss: 0.130276  [19200/71285]
loss: 0.097132  [25600/71285]
loss: 0.196971  [32000/71285]
loss: 0.093070  [38400/71285]
loss: 0.179996  [44800/71285]
loss: 0.069553  [51200/71285]
loss: 0.251784  [57600/71285]
loss: 0.237997  [64000/71285]
loss: 0.066693  [70400/71285]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.158152 

Epoch 11
-------------------------------
loss: 0.119021  [    0/71285]
loss: 0.088224  [ 6400/71285]
loss: 0.049278  [12800/71285]
loss: 0.133856  [19200/71285]
loss: 0.085375  [25600/71285]
loss: 0.186699  [32000/71285]
loss: 0.272654  [38400/71285]
loss: 0.138083  [44800/71285]
loss: 0.245452  [51200/71285]
loss: 0.074144  [57600/71285]
loss: 0.171381  [64000/71285]
loss: 0.084109  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.153434 

Epoch 12
-------------------------------
loss: 0.125298  [    0/71285]
loss: 0.153376  [ 6400/71285]
loss: 0.070807  [12800/71285]
loss: 0.177803  [19200/71285]
loss: 0.149699  [25600/71285]
loss: 0.176883  [32000/71285]
loss: 0.077977  [38400/71285]
loss: 0.133063  [44800/71285]
loss: 0.083388  [51200/71285]
loss: 0.150922  [57600/71285]
loss: 0.087009  [64000/71285]
loss: 0.165119  [70400/71285]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.163862 

Epoch 13
-------------------------------
loss: 0.164147  [    0/71285]
loss: 0.106430  [ 6400/71285]
loss: 0.077276  [12800/71285]
loss: 0.092216  [19200/71285]
loss: 0.088610  [25600/71285]
loss: 0.169904  [32000/71285]
loss: 0.223859  [38400/71285]
loss: 0.162838  [44800/71285]
loss: 0.176082  [51200/71285]
loss: 0.100869  [57600/71285]
loss: 0.057190  [64000/71285]
loss: 0.187788  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.148176 

Epoch 14
-------------------------------
loss: 0.085691  [    0/71285]
loss: 0.041521  [ 6400/71285]
loss: 0.026127  [12800/71285]
loss: 0.127848  [19200/71285]
loss: 0.158472  [25600/71285]
loss: 0.247026  [32000/71285]
loss: 0.057314  [38400/71285]
loss: 0.105598  [44800/71285]
loss: 0.168968  [51200/71285]
loss: 0.077176  [57600/71285]
loss: 0.101243  [64000/71285]
loss: 0.160917  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.153747 

Epoch 15
-------------------------------
loss: 0.080753  [    0/71285]
loss: 0.136492  [ 6400/71285]
loss: 0.180799  [12800/71285]
loss: 0.110770  [19200/71285]
loss: 0.188013  [25600/71285]
loss: 0.116633  [32000/71285]
loss: 0.156840  [38400/71285]
loss: 0.085739  [44800/71285]
loss: 0.090749  [51200/71285]
loss: 0.139525  [57600/71285]
loss: 0.207628  [64000/71285]
loss: 0.107478  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.150698 

Epoch 16
-------------------------------
loss: 0.125085  [    0/71285]
loss: 0.078146  [ 6400/71285]
loss: 0.156890  [12800/71285]
loss: 0.132641  [19200/71285]
loss: 0.155449  [25600/71285]
loss: 0.086008  [32000/71285]
loss: 0.194292  [38400/71285]
loss: 0.248891  [44800/71285]
loss: 0.220912  [51200/71285]
loss: 0.064740  [57600/71285]
loss: 0.068913  [64000/71285]
loss: 0.151109  [70400/71285]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081499 

Epoch 49
-------------------------------
loss: 0.168700  [    0/70562]
loss: 0.031769  [ 6400/70562]
loss: 0.119003  [12800/70562]
loss: 0.063534  [19200/70562]
loss: 0.119867  [25600/70562]
loss: 0.095494  [32000/70562]
loss: 0.070998  [38400/70562]
loss: 0.092086  [44800/70562]
loss: 0.075938  [51200/70562]
loss: 0.038503  [57600/70562]
loss: 0.173270  [64000/70562]
loss: 0.051871  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.086236 

Epoch 50
-------------------------------
loss: 0.042084  [    0/70562]
loss: 0.043603  [ 6400/70562]
loss: 0.029124  [12800/70562]
loss: 0.072886  [19200/70562]
loss: 0.096472  [25600/70562]
loss: 0.090598  [32000/70562]
loss: 0.058343  [38400/70562]
loss: 0.029364  [44800/70562]
loss: 0.075458  [51200/70562]
loss: 0.057543  [57600/70562]
loss: 0.043600  [64000/70562]
loss: 0.119582  [70400/70562]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.082440 

Epoch 1
-------------------------------
loss: 0.649339  [    0/70872]
loss: 0.359680  [ 6400/70872]
loss: 0.252141  [12800/70872]
loss: 0.239464  [19200/70872]
loss: 0.422231  [25600/70872]
loss: 0.177494  [32000/70872]
loss: 0.242382  [38400/70872]
loss: 0.252781  [44800/70872]
loss: 0.280830  [51200/70872]
loss: 0.117442  [57600/70872]
loss: 0.256131  [64000/70872]
loss: 1.808587  [70400/70872]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.250012 

Epoch 2
-------------------------------
loss: 0.295040  [    0/70872]
loss: 0.220444  [ 6400/70872]
loss: 0.066972  [12800/70872]
loss: 0.275386  [19200/70872]
loss: 0.165463  [25600/70872]
loss: 0.278403  [32000/70872]
loss: 0.171022  [38400/70872]
loss: 0.133781  [44800/70872]
loss: 0.192007  [51200/70872]
loss: 0.297818  [57600/70872]
loss: 0.233987  [64000/70872]
loss: 0.167285  [70400/70872]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.230371 

Epoch 3
-------------------------------
loss: 0.225398  [    0/70872]
loss: 0.232192  [ 6400/70872]
loss: 0.232884  [12800/70872]
loss: 0.317797  [19200/70872]
loss: 0.246514  [25600/70872]
loss: 0.106962  [32000/70872]
loss: 0.209492  [38400/70872]
loss: 0.097363  [44800/70872]
loss: 0.308341  [51200/70872]
loss: 0.132563  [57600/70872]
loss: 0.229709  [64000/70872]
loss: 0.286179  [70400/70872]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.199569 

Epoch 4
-------------------------------
loss: 0.236162  [    0/70872]
loss: 0.135039  [ 6400/70872]
loss: 0.090776  [12800/70872]
loss: 0.188025  [19200/70872]
loss: 0.188547  [25600/70872]
loss: 0.188259  [32000/70872]
loss: 0.125688  [38400/70872]
loss: 0.156917  [44800/70872]
loss: 0.158221  [51200/70872]
loss: 0.169590  [57600/70872]
loss: 0.245768  [64000/70872]
loss: 0.129587  [70400/70872]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.205477 

Epoch 5
-------------------------------
loss: 0.114596  [    0/70872]
loss: 0.225747  [ 6400/70872]
loss: 0.158052  [12800/70872]
loss: 0.154543  [19200/70872]
loss: 0.124808  [25600/70872]
loss: 0.358163  [32000/70872]
loss: 0.119261  [38400/70872]
loss: 0.190955  [44800/70872]
loss: 0.325474  [51200/70872]
loss: 0.190926  [57600/70872]
loss: 0.111058  [64000/70872]
loss: 0.122900  [70400/70872]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.197887 

Epoch 6
-------------------------------
loss: 0.107924  [    0/70872]
loss: 0.207775  [ 6400/70872]
loss: 0.185562  [12800/70872]
loss: 0.260011  [19200/70872]
loss: 0.205091  [25600/70872]
loss: 0.230173  [32000/70872]
loss: 0.308099  [38400/70872]
loss: 0.202871  [44800/70872]
loss: 0.079629  [51200/70872]
loss: 0.227961  [57600/70872]
loss: 0.141342  [64000/70872]
loss: 0.128307  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.186481 

Epoch 7
-------------------------------
loss: 0.134807  [    0/70872]
loss: 0.171023  [ 6400/70872]
loss: 0.162073  [12800/70872]
loss: 0.124671  [19200/70872]
loss: 0.123529  [25600/70872]
loss: 0.301167  [32000/70872]
loss: 0.127054  [38400/70872]
loss: 0.123747  [44800/70872]
loss: 0.197790  [51200/70872]
loss: 0.182933  [57600/70872]
loss: 0.137161  [64000/70872]
loss: 1.779531  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.187175 

Epoch 8
-------------------------------
loss: 0.202580  [    0/70872]
loss: 0.231879  [ 6400/70872]
loss: 0.047487  [12800/70872]
loss: 0.272762  [19200/70872]
loss: 0.136372  [25600/70872]
loss: 0.188354  [32000/70872]
loss: 0.132457  [38400/70872]
loss: 0.182007  [44800/70872]
loss: 0.109941  [51200/70872]
loss: 0.140346  [57600/70872]
loss: 0.244756  [64000/70872]
loss: 0.191522  [70400/70872]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.213243 

Epoch 9
-------------------------------
loss: 0.117372  [    0/70872]
loss: 0.181969  [ 6400/70872]
loss: 0.099135  [12800/70872]
loss: 0.089881  [19200/70872]
loss: 0.231162  [25600/70872]
loss: 0.169655  [32000/70872]
loss: 0.078706  [38400/70872]
loss: 0.206171  [44800/70872]
loss: 0.188614  [51200/70872]
loss: 0.144996  [57600/70872]
loss: 0.304785  [64000/70872]
loss: 0.107868  [70400/70872]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.215710 

Epoch 10
-------------------------------
loss: 0.260579  [    0/70872]
loss: 0.214231  [ 6400/70872]
loss: 0.260463  [12800/70872]
loss: 0.198875  [19200/70872]
loss: 0.154209  [25600/70872]
loss: 0.166573  [32000/70872]
loss: 0.136689  [38400/70872]
loss: 0.205008  [44800/70872]
loss: 0.149218  [51200/70872]
loss: 0.242362  [57600/70872]
loss: 0.167409  [64000/70872]
loss: 0.110267  [70400/70872]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.191313 

Epoch 11
-------------------------------
loss: 0.157551  [    0/70872]
loss: 0.262392  [ 6400/70872]
loss: 0.198362  [12800/70872]
loss: 0.140694  [19200/70872]
loss: 0.100595  [25600/70872]
loss: 0.130285  [32000/70872]
loss: 0.205118  [38400/70872]
loss: 0.195654  [44800/70872]
loss: 0.237084  [51200/70872]
loss: 1.779227  [57600/70872]
loss: 0.222958  [64000/70872]
loss: 0.224028  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.199415 

Epoch 12
-------------------------------
loss: 0.242451  [    0/70872]
loss: 0.097814  [ 6400/70872]
loss: 0.201822  [12800/70872]
loss: 0.223754  [19200/70872]
loss: 0.195808  [25600/70872]
loss: 0.191730  [32000/70872]
loss: 0.081376  [38400/70872]
loss: 0.096625  [44800/70872]
loss: 0.197140  [51200/70872]
loss: 0.094195  [57600/70872]
loss: 0.204701  [64000/70872]
loss: 0.084211  [70400/70872]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.193687 

Epoch 13
-------------------------------
loss: 0.092037  [    0/70872]
loss: 0.120510  [ 6400/70872]
loss: 0.130471  [12800/70872]
loss: 0.123242  [19200/70872]
loss: 0.185001  [25600/70872]
loss: 0.145338  [32000/70872]
loss: 0.238678  [38400/70872]
loss: 0.144297  [44800/70872]
loss: 0.176989  [51200/70872]
loss: 0.162219  [57600/70872]
loss: 0.141777  [64000/70872]
loss: 0.359914  [70400/70872]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.198878 

Epoch 14
-------------------------------
loss: 0.161036  [    0/70872]
loss: 0.105262  [ 6400/70872]
loss: 0.126364  [12800/70872]
loss: 0.156892  [19200/70872]
loss: 0.131407  [25600/70872]
loss: 0.225698  [32000/70872]
loss: 0.164582  [38400/70872]
loss: 0.066512  [44800/70872]
loss: 0.214729  [51200/70872]
loss: 0.133410  [57600/70872]
loss: 0.243924  [64000/70872]
loss: 0.146614  [70400/70872]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.205615 

Epoch 15
-------------------------------
loss: 0.168985  [    0/70872]
loss: 0.081670  [ 6400/70872]
loss: 0.294106  [12800/70872]
loss: 0.100178  [19200/70872]
loss: 0.146998  [25600/70872]
loss: 0.062275  [32000/70872]
loss: 0.134437  [38400/70872]
loss: 0.149688  [44800/70872]
loss: 0.044964  [51200/70872]
loss: 0.141857  [57600/70872]
loss: 0.193789  [64000/70872]
loss: 0.123308  [70400/70872]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.194613 

Epoch 16
-------------------------------
loss: 0.162915  [    0/70872]
loss: 0.212147  [ 6400/70872]
loss: 1.654613  [12800/70872]
loss: 0.251147  [19200/70872]
loss: 0.162710  [25600/70872]
loss: 0.186224  [32000/70872]
loss: 0.169746  [38400/70872]
loss: 0.056113  [44800/70872]
loss: 0.175302  [51200/70872]
loss: 0.069634  [57600/70872]
loss: 0.183382  [64000/70872]
loss: 0.109683  [70400/70872]
loss: 0.229454  [38400/69149]
loss: 0.096301  [44800/69149]
loss: 0.064347  [51200/69149]
loss: 0.258591  [57600/69149]
loss: 0.207215  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.130117 

Epoch 15
-------------------------------
loss: 0.097112  [    0/69149]
loss: 0.043254  [ 6400/69149]
loss: 0.098091  [12800/69149]
loss: 0.055500  [19200/69149]
loss: 0.115833  [25600/69149]
loss: 0.108009  [32000/69149]
loss: 0.160235  [38400/69149]
loss: 0.064930  [44800/69149]
loss: 0.168893  [51200/69149]
loss: 0.067945  [57600/69149]
loss: 1.664195  [64000/69149]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.135140 

Epoch 16
-------------------------------
loss: 0.151732  [    0/69149]
loss: 0.076946  [ 6400/69149]
loss: 0.198473  [12800/69149]
loss: 0.095071  [19200/69149]
loss: 0.042032  [25600/69149]
loss: 0.065154  [32000/69149]
loss: 0.090472  [38400/69149]
loss: 0.175076  [44800/69149]
loss: 0.085384  [51200/69149]
loss: 0.050472  [57600/69149]
loss: 0.115222  [64000/69149]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.140437 

Epoch 17
-------------------------------
loss: 0.207099  [    0/69149]
loss: 0.118550  [ 6400/69149]
loss: 0.108850  [12800/69149]
loss: 0.104250  [19200/69149]
loss: 0.062408  [25600/69149]
loss: 0.084400  [32000/69149]
loss: 0.124570  [38400/69149]
loss: 0.078901  [44800/69149]
loss: 0.266346  [51200/69149]
loss: 0.080988  [57600/69149]
loss: 0.155100  [64000/69149]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.126262 

Epoch 18
-------------------------------
loss: 0.088233  [    0/69149]
loss: 0.133136  [ 6400/69149]
loss: 0.092108  [12800/69149]
loss: 0.176135  [19200/69149]
loss: 0.114188  [25600/69149]
loss: 0.129640  [32000/69149]
loss: 0.082354  [38400/69149]
loss: 0.100828  [44800/69149]
loss: 0.194854  [51200/69149]
loss: 0.062810  [57600/69149]
loss: 0.133825  [64000/69149]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.127833 

Epoch 19
-------------------------------
loss: 0.155195  [    0/69149]
loss: 0.165947  [ 6400/69149]
loss: 0.196384  [12800/69149]
loss: 0.074215  [19200/69149]
loss: 0.078856  [25600/69149]
loss: 0.233144  [32000/69149]
loss: 0.079310  [38400/69149]
loss: 0.081115  [44800/69149]
loss: 0.154907  [51200/69149]
loss: 0.153014  [57600/69149]
loss: 0.093504  [64000/69149]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.126228 

Epoch 20
-------------------------------
loss: 0.338553  [    0/69149]
loss: 0.046346  [ 6400/69149]
loss: 0.035602  [12800/69149]
loss: 0.171475  [19200/69149]
loss: 0.121623  [25600/69149]
loss: 0.084183  [32000/69149]
loss: 0.136000  [38400/69149]
loss: 0.025297  [44800/69149]
loss: 0.165578  [51200/69149]
loss: 0.146331  [57600/69149]
loss: 0.132092  [64000/69149]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.131341 

Epoch 21
-------------------------------
loss: 0.151323  [    0/69149]
loss: 0.074197  [ 6400/69149]
loss: 0.078084  [12800/69149]
loss: 0.035640  [19200/69149]
loss: 0.081459  [25600/69149]
loss: 0.197669  [32000/69149]
loss: 0.068792  [38400/69149]
loss: 0.131632  [44800/69149]
loss: 1.677128  [51200/69149]
loss: 0.122767  [57600/69149]
loss: 0.190875  [64000/69149]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.127196 

Epoch 22
-------------------------------
loss: 0.248377  [    0/69149]
loss: 0.058855  [ 6400/69149]
loss: 0.177094  [12800/69149]
loss: 0.154324  [19200/69149]
loss: 0.096015  [25600/69149]
loss: 0.063436  [32000/69149]
loss: 0.111158  [38400/69149]
loss: 0.069325  [44800/69149]
loss: 0.084509  [51200/69149]
loss: 0.111396  [57600/69149]
loss: 0.159162  [64000/69149]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.127058 

Epoch 23
-------------------------------
loss: 0.119377  [    0/69149]
loss: 0.140124  [ 6400/69149]
loss: 0.063693  [12800/69149]
loss: 0.102566  [19200/69149]
loss: 0.073281  [25600/69149]
loss: 0.125366  [32000/69149]
loss: 0.170540  [38400/69149]
loss: 0.168690  [44800/69149]
loss: 0.075173  [51200/69149]
loss: 0.144260  [57600/69149]
loss: 0.135996  [64000/69149]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.142892 

Epoch 24
-------------------------------
loss: 0.072943  [    0/69149]
loss: 0.085149  [ 6400/69149]
loss: 0.192025  [12800/69149]
loss: 0.083876  [19200/69149]
loss: 0.049649  [25600/69149]
loss: 0.038136  [32000/69149]
loss: 0.070175  [38400/69149]
loss: 0.207723  [44800/69149]
loss: 0.090415  [51200/69149]
loss: 0.265322  [57600/69149]
loss: 0.116740  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.127605 

Epoch 25
-------------------------------
loss: 0.106634  [    0/69149]
loss: 0.039867  [ 6400/69149]
loss: 0.112487  [12800/69149]
loss: 0.146384  [19200/69149]
loss: 0.129292  [25600/69149]
loss: 0.110055  [32000/69149]
loss: 0.154157  [38400/69149]
loss: 0.292504  [44800/69149]
loss: 0.146826  [51200/69149]
loss: 0.104373  [57600/69149]
loss: 0.104103  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.129764 

Epoch 26
-------------------------------
loss: 0.078341  [    0/69149]
loss: 0.079498  [ 6400/69149]
loss: 0.150388  [12800/69149]
loss: 0.203732  [19200/69149]
loss: 0.040192  [25600/69149]
loss: 0.157724  [32000/69149]
loss: 0.069202  [38400/69149]
loss: 0.112517  [44800/69149]
loss: 0.090514  [51200/69149]
loss: 0.111551  [57600/69149]
loss: 0.162071  [64000/69149]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.132026 

Epoch 27
-------------------------------
loss: 0.154359  [    0/69149]
loss: 0.147752  [ 6400/69149]
loss: 0.133053  [12800/69149]
loss: 0.103281  [19200/69149]
loss: 0.043375  [25600/69149]
loss: 0.223339  [32000/69149]
loss: 0.066135  [38400/69149]
loss: 0.219402  [44800/69149]
loss: 0.087881  [51200/69149]
loss: 0.047340  [57600/69149]
loss: 0.152413  [64000/69149]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.146784 

Epoch 28
-------------------------------
loss: 0.090178  [    0/69149]
loss: 0.057024  [ 6400/69149]
loss: 0.056543  [12800/69149]
loss: 0.090149  [19200/69149]
loss: 0.136297  [25600/69149]
loss: 0.123075  [32000/69149]
loss: 0.092507  [38400/69149]
loss: 0.197743  [44800/69149]
loss: 0.081183  [51200/69149]
loss: 0.181595  [57600/69149]
loss: 0.142423  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.137249 

Epoch 29
-------------------------------
loss: 0.075694  [    0/69149]
loss: 0.116243  [ 6400/69149]
loss: 0.185979  [12800/69149]
loss: 0.077954  [19200/69149]
loss: 0.100053  [25600/69149]
loss: 0.101162  [32000/69149]
loss: 0.126078  [38400/69149]
loss: 0.069214  [44800/69149]
loss: 0.200483  [51200/69149]
loss: 0.159563  [57600/69149]
loss: 0.091633  [64000/69149]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.131666 

Epoch 30
-------------------------------
loss: 0.273044  [    0/69149]
loss: 0.069914  [ 6400/69149]
loss: 0.091859  [12800/69149]
loss: 0.128726  [19200/69149]
loss: 0.062636  [25600/69149]
loss: 0.063498  [32000/69149]
loss: 0.122342  [38400/69149]
loss: 0.063618  [44800/69149]
loss: 0.140518  [51200/69149]
loss: 0.104265  [57600/69149]
loss: 0.123806  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.130443 

Epoch 31
-------------------------------
loss: 0.013332  [    0/69149]
loss: 0.053986  [ 6400/69149]
loss: 0.087967  [12800/69149]
loss: 0.066236  [19200/69149]
loss: 0.065926  [25600/69149]
loss: 0.112580  [32000/69149]
loss: 0.174490  [38400/69149]
loss: 0.061708  [44800/69149]
loss: 0.128604  [51200/69149]
loss: 0.113072  [57600/69149]
loss: 0.106682  [64000/69149]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.136835 

Epoch 32
-------------------------------
loss: 0.142445  [    0/69149]
loss: 0.191353  [ 6400/69149]
loss: 0.075224  [12800/69149]
loss: 0.142427  [19200/69149]
loss: 0.242189  [25600/69149]
loss: 0.071464  [32000/69149]
loss: 0.121631  [38400/69149]
loss: 0.183478  [44800/69149]
loss: 0.068736  [51200/69149]
loss: 0.158348  [57600/69149]
loss: 0.150144  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.135341 

Epoch 33
-------------------------------
loss: 0.096458  [    0/69149]
loss: 0.083777  [ 6400/69149]
loss: 0.027404  [12800/69149]
loss: 0.198890  [19200/69149]
loss: 0.067946  [25600/69149]
loss: 0.071034  [32000/69149]
loss: 0.145259  [38400/69149]
loss: 0.080960  [44800/69149]
loss: 0.091747  [51200/69149]
loss: 0.052782  [57600/69149]
loss: 0.167708  [64000/69149]
loss: 0.205529  [ 6400/70500]
loss: 0.101144  [12800/70500]
loss: 0.283189  [19200/70500]
loss: 0.107973  [25600/70500]
loss: 0.240590  [32000/70500]
loss: 0.316063  [38400/70500]
loss: 0.218298  [44800/70500]
loss: 0.195977  [51200/70500]
loss: 0.120086  [57600/70500]
loss: 1.738593  [64000/70500]
loss: 0.117371  [70400/70500]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.195146 

Epoch 3
-------------------------------
loss: 0.283552  [    0/70500]
loss: 0.161798  [ 6400/70500]
loss: 0.214327  [12800/70500]
loss: 0.162777  [19200/70500]
loss: 0.131203  [25600/70500]
loss: 0.177959  [32000/70500]
loss: 0.234426  [38400/70500]
loss: 0.153992  [44800/70500]
loss: 0.161167  [51200/70500]
loss: 0.214198  [57600/70500]
loss: 0.130911  [64000/70500]
loss: 0.169468  [70400/70500]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.193554 

Epoch 4
-------------------------------
loss: 0.073172  [    0/70500]
loss: 0.205825  [ 6400/70500]
loss: 0.204967  [12800/70500]
loss: 0.233132  [19200/70500]
loss: 0.309993  [25600/70500]
loss: 0.434275  [32000/70500]
loss: 0.192920  [38400/70500]
loss: 0.189733  [44800/70500]
loss: 0.139961  [51200/70500]
loss: 0.072648  [57600/70500]
loss: 0.199157  [64000/70500]
loss: 0.101797  [70400/70500]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.188108 

Epoch 5
-------------------------------
loss: 0.197414  [    0/70500]
loss: 0.335289  [ 6400/70500]
loss: 0.223856  [12800/70500]
loss: 0.092613  [19200/70500]
loss: 0.161041  [25600/70500]
loss: 0.147678  [32000/70500]
loss: 0.129766  [38400/70500]
loss: 0.157396  [44800/70500]
loss: 0.078885  [51200/70500]
loss: 0.205468  [57600/70500]
loss: 0.305268  [64000/70500]
loss: 0.162008  [70400/70500]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.187507 

Epoch 6
-------------------------------
loss: 0.148294  [    0/70500]
loss: 0.087016  [ 6400/70500]
loss: 0.090404  [12800/70500]
loss: 0.264566  [19200/70500]
loss: 0.175961  [25600/70500]
loss: 0.088138  [32000/70500]
loss: 0.165895  [38400/70500]
loss: 0.074654  [44800/70500]
loss: 0.241693  [51200/70500]
loss: 0.072531  [57600/70500]
loss: 0.154666  [64000/70500]
loss: 0.103568  [70400/70500]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.190302 

Epoch 7
-------------------------------
loss: 0.193509  [    0/70500]
loss: 0.226403  [ 6400/70500]
loss: 0.166536  [12800/70500]
loss: 0.226667  [19200/70500]
loss: 0.110545  [25600/70500]
loss: 0.147929  [32000/70500]
loss: 0.123635  [38400/70500]
loss: 0.256117  [44800/70500]
loss: 0.116168  [51200/70500]
loss: 0.414505  [57600/70500]
loss: 0.077658  [64000/70500]
loss: 0.150053  [70400/70500]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.196490 

Epoch 8
-------------------------------
loss: 0.195403  [    0/70500]
loss: 0.186506  [ 6400/70500]
loss: 0.399721  [12800/70500]
loss: 0.272432  [19200/70500]
loss: 0.234428  [25600/70500]
loss: 0.093003  [32000/70500]
loss: 0.192589  [38400/70500]
loss: 0.165576  [44800/70500]
loss: 0.219032  [51200/70500]
loss: 0.165545  [57600/70500]
loss: 0.103982  [64000/70500]
loss: 0.157068  [70400/70500]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.185622 

Epoch 9
-------------------------------
loss: 0.143227  [    0/70500]
loss: 0.158248  [ 6400/70500]
loss: 0.126000  [12800/70500]
loss: 0.158443  [19200/70500]
loss: 0.125815  [25600/70500]
loss: 0.067406  [32000/70500]
loss: 0.187663  [38400/70500]
loss: 0.205283  [44800/70500]
loss: 0.167681  [51200/70500]
loss: 0.185591  [57600/70500]
loss: 0.251691  [64000/70500]
loss: 0.165945  [70400/70500]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.178827 

Epoch 10
-------------------------------
loss: 0.136452  [    0/70500]
loss: 0.120263  [ 6400/70500]
loss: 0.156807  [12800/70500]
loss: 0.100488  [19200/70500]
loss: 0.156318  [25600/70500]
loss: 0.081289  [32000/70500]
loss: 0.146529  [38400/70500]
loss: 0.270340  [44800/70500]
loss: 0.077929  [51200/70500]
loss: 0.162799  [57600/70500]
loss: 0.165084  [64000/70500]
loss: 0.253414  [70400/70500]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.180729 

Epoch 11
-------------------------------
loss: 0.168605  [    0/70500]
loss: 0.183794  [ 6400/70500]
loss: 0.103690  [12800/70500]
loss: 0.127195  [19200/70500]
loss: 0.182862  [25600/70500]
loss: 0.049316  [32000/70500]
loss: 0.171292  [38400/70500]
loss: 0.126466  [44800/70500]
loss: 0.152600  [51200/70500]
loss: 0.103046  [57600/70500]
loss: 0.219313  [64000/70500]
loss: 0.223205  [70400/70500]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.179982 

Epoch 12
-------------------------------
loss: 0.080891  [    0/70500]
loss: 0.115641  [ 6400/70500]
loss: 0.261586  [12800/70500]
loss: 0.251301  [19200/70500]
loss: 0.073822  [25600/70500]
loss: 0.186208  [32000/70500]
loss: 0.248395  [38400/70500]
loss: 0.138844  [44800/70500]
loss: 0.153384  [51200/70500]
loss: 0.166035  [57600/70500]
loss: 0.162588  [64000/70500]
loss: 0.157694  [70400/70500]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.175732 

Epoch 13
-------------------------------
loss: 0.224779  [    0/70500]
loss: 0.183557  [ 6400/70500]
loss: 0.137100  [12800/70500]
loss: 0.102242  [19200/70500]
loss: 0.170137  [25600/70500]
loss: 0.101878  [32000/70500]
loss: 0.051442  [38400/70500]
loss: 0.058740  [44800/70500]
loss: 0.119525  [51200/70500]
loss: 0.155312  [57600/70500]
loss: 0.139508  [64000/70500]
loss: 0.182838  [70400/70500]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.180879 

Epoch 14
-------------------------------
loss: 0.095025  [    0/70500]
loss: 0.059979  [ 6400/70500]
loss: 0.104027  [12800/70500]
loss: 0.241721  [19200/70500]
loss: 0.167647  [25600/70500]
loss: 0.103798  [32000/70500]
loss: 0.084461  [38400/70500]
loss: 0.242560  [44800/70500]
loss: 0.058744  [51200/70500]
loss: 0.253891  [57600/70500]
loss: 0.133535  [64000/70500]
loss: 0.156178  [70400/70500]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.187247 

Epoch 15
-------------------------------
loss: 0.100953  [    0/70500]
loss: 0.082657  [ 6400/70500]
loss: 0.145637  [12800/70500]
loss: 0.286379  [19200/70500]
loss: 0.190112  [25600/70500]
loss: 0.144955  [32000/70500]
loss: 0.181907  [38400/70500]
loss: 0.089175  [44800/70500]
loss: 0.205514  [51200/70500]
loss: 0.085107  [57600/70500]
loss: 0.172283  [64000/70500]
loss: 0.206566  [70400/70500]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173492 

Epoch 16
-------------------------------
loss: 0.127744  [    0/70500]
loss: 0.258439  [ 6400/70500]
loss: 0.142287  [12800/70500]
loss: 0.172091  [19200/70500]
loss: 0.143988  [25600/70500]
loss: 0.155671  [32000/70500]
loss: 0.072366  [38400/70500]
loss: 0.144144  [44800/70500]
loss: 0.194303  [51200/70500]
loss: 0.106659  [57600/70500]
loss: 0.179811  [64000/70500]
loss: 0.182792  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.169980 

Epoch 17
-------------------------------
loss: 0.133754  [    0/70500]
loss: 0.078309  [ 6400/70500]
loss: 0.266992  [12800/70500]
loss: 0.159777  [19200/70500]
loss: 0.120418  [25600/70500]
loss: 0.120026  [32000/70500]
loss: 0.090116  [38400/70500]
loss: 0.145959  [44800/70500]
loss: 0.145403  [51200/70500]
loss: 1.617832  [57600/70500]
loss: 0.129175  [64000/70500]
loss: 0.112468  [70400/70500]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.174452 

Epoch 18
-------------------------------
loss: 0.079143  [    0/70500]
loss: 0.110785  [ 6400/70500]
loss: 0.084170  [12800/70500]
loss: 0.206752  [19200/70500]
loss: 0.108011  [25600/70500]
loss: 0.085765  [32000/70500]
loss: 0.103233  [38400/70500]
loss: 0.091932  [44800/70500]
loss: 0.110394  [51200/70500]
loss: 0.208384  [57600/70500]
loss: 0.186372  [64000/70500]
loss: 0.180226  [70400/70500]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.169932 

Epoch 19
-------------------------------
loss: 0.100592  [    0/70500]
loss: 0.148567  [ 6400/70500]
loss: 0.188267  [12800/70500]
loss: 0.114382  [19200/70500]
loss: 0.154594  [25600/70500]
loss: 0.083096  [32000/70500]
loss: 0.149283  [38400/70500]
loss: 0.119423  [44800/70500]
loss: 0.210657  [51200/70500]
loss: 0.346539  [57600/70500]
loss: 0.134210  [64000/70500]
loss: 0.378647  [70400/70500]
Test Error: 
 Accuracy: 90.6%, Avg loss: 0.282806 

Epoch 20
-------------------------------
loss: 0.315125  [    0/70500]
loss: 0.149701  [ 6400/70500]
loss: 0.037533  [51200/71622]
loss: 0.080766  [57600/71622]
loss: 0.069298  [64000/71622]
loss: 0.132319  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.137906 

Epoch 14
-------------------------------
loss: 0.053938  [    0/71622]
loss: 0.138386  [ 6400/71622]
loss: 0.082145  [12800/71622]
loss: 0.059620  [19200/71622]
loss: 0.039046  [25600/71622]
loss: 0.023163  [32000/71622]
loss: 0.072191  [38400/71622]
loss: 0.031910  [44800/71622]
loss: 0.171229  [51200/71622]
loss: 0.179119  [57600/71622]
loss: 0.113861  [64000/71622]
loss: 0.072965  [70400/71622]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.135335 

Epoch 15
-------------------------------
loss: 0.066736  [    0/71622]
loss: 0.041122  [ 6400/71622]
loss: 0.097732  [12800/71622]
loss: 0.051790  [19200/71622]
loss: 0.267553  [25600/71622]
loss: 0.270637  [32000/71622]
loss: 0.174110  [38400/71622]
loss: 0.063599  [44800/71622]
loss: 0.160056  [51200/71622]
loss: 0.074908  [57600/71622]
loss: 0.109138  [64000/71622]
loss: 0.016739  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.134312 

Epoch 16
-------------------------------
loss: 0.051095  [    0/71622]
loss: 0.060717  [ 6400/71622]
loss: 0.043927  [12800/71622]
loss: 0.045390  [19200/71622]
loss: 0.099804  [25600/71622]
loss: 0.054732  [32000/71622]
loss: 0.128549  [38400/71622]
loss: 0.033075  [44800/71622]
loss: 0.090663  [51200/71622]
loss: 0.109352  [57600/71622]
loss: 0.113061  [64000/71622]
loss: 0.090560  [70400/71622]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.142683 

Epoch 17
-------------------------------
loss: 0.276307  [    0/71622]
loss: 0.106127  [ 6400/71622]
loss: 0.103040  [12800/71622]
loss: 0.023177  [19200/71622]
loss: 0.029058  [25600/71622]
loss: 0.031349  [32000/71622]
loss: 0.083671  [38400/71622]
loss: 0.089271  [44800/71622]
loss: 0.014333  [51200/71622]
loss: 0.068046  [57600/71622]
loss: 0.129713  [64000/71622]
loss: 0.039247  [70400/71622]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.135455 

Epoch 18
-------------------------------
loss: 0.037231  [    0/71622]
loss: 0.037341  [ 6400/71622]
loss: 0.025211  [12800/71622]
loss: 0.139929  [19200/71622]
loss: 0.060033  [25600/71622]
loss: 0.085152  [32000/71622]
loss: 0.042645  [38400/71622]
loss: 0.019626  [44800/71622]
loss: 0.050089  [51200/71622]
loss: 0.047247  [57600/71622]
loss: 0.096567  [64000/71622]
loss: 0.138634  [70400/71622]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.140773 

Epoch 19
-------------------------------
loss: 0.091990  [    0/71622]
loss: 0.023718  [ 6400/71622]
loss: 0.072332  [12800/71622]
loss: 0.089472  [19200/71622]
loss: 0.042696  [25600/71622]
loss: 0.099940  [32000/71622]
loss: 0.063792  [38400/71622]
loss: 0.148470  [44800/71622]
loss: 0.136839  [51200/71622]
loss: 0.032758  [57600/71622]
loss: 0.043578  [64000/71622]
loss: 0.177428  [70400/71622]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.164102 

Epoch 20
-------------------------------
loss: 0.065317  [    0/71622]
loss: 0.005133  [ 6400/71622]
loss: 0.098097  [12800/71622]
loss: 0.049238  [19200/71622]
loss: 0.061127  [25600/71622]
loss: 0.017352  [32000/71622]
loss: 0.099067  [38400/71622]
loss: 0.116447  [44800/71622]
loss: 0.215846  [51200/71622]
loss: 0.147862  [57600/71622]
loss: 0.047636  [64000/71622]
loss: 0.031787  [70400/71622]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.139629 

Epoch 21
-------------------------------
loss: 0.082709  [    0/71622]
loss: 0.089898  [ 6400/71622]
loss: 0.037954  [12800/71622]
loss: 0.018273  [19200/71622]
loss: 0.071983  [25600/71622]
loss: 0.139866  [32000/71622]
loss: 0.063835  [38400/71622]
loss: 0.155672  [44800/71622]
loss: 0.142268  [51200/71622]
loss: 0.110209  [57600/71622]
loss: 0.046620  [64000/71622]
loss: 0.030661  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.135652 

Epoch 22
-------------------------------
loss: 0.064279  [    0/71622]
loss: 0.056894  [ 6400/71622]
loss: 0.143257  [12800/71622]
loss: 0.056526  [19200/71622]
loss: 0.145742  [25600/71622]
loss: 0.058421  [32000/71622]
loss: 0.030353  [38400/71622]
loss: 0.111974  [44800/71622]
loss: 0.068783  [51200/71622]
loss: 0.088808  [57600/71622]
loss: 0.022942  [64000/71622]
loss: 0.070556  [70400/71622]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.164926 

Epoch 23
-------------------------------
loss: 0.068169  [    0/71622]
loss: 0.156127  [ 6400/71622]
loss: 0.082884  [12800/71622]
loss: 0.058846  [19200/71622]
loss: 0.013659  [25600/71622]
loss: 0.123261  [32000/71622]
loss: 0.041054  [38400/71622]
loss: 0.045919  [44800/71622]
loss: 0.035987  [51200/71622]
loss: 0.018271  [57600/71622]
loss: 0.053210  [64000/71622]
loss: 0.025178  [70400/71622]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.141313 

Epoch 24
-------------------------------
loss: 0.024366  [    0/71622]
loss: 0.136001  [ 6400/71622]
loss: 0.123360  [12800/71622]
loss: 0.080421  [19200/71622]
loss: 0.132685  [25600/71622]
loss: 0.082975  [32000/71622]
loss: 0.014030  [38400/71622]
loss: 0.081002  [44800/71622]
loss: 0.028185  [51200/71622]
loss: 0.122866  [57600/71622]
loss: 0.079497  [64000/71622]
loss: 0.107972  [70400/71622]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.137745 

Epoch 25
-------------------------------
loss: 0.022194  [    0/71622]
loss: 0.035846  [ 6400/71622]
loss: 0.020996  [12800/71622]
loss: 0.082425  [19200/71622]
loss: 0.033703  [25600/71622]
loss: 0.018752  [32000/71622]
loss: 0.036964  [38400/71622]
loss: 0.042304  [44800/71622]
loss: 0.052866  [51200/71622]
loss: 0.089927  [57600/71622]
loss: 0.079311  [64000/71622]
loss: 0.106679  [70400/71622]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.135372 

Epoch 26
-------------------------------
loss: 0.085090  [    0/71622]
loss: 0.288856  [ 6400/71622]
loss: 0.088365  [12800/71622]
loss: 0.041537  [19200/71622]
loss: 0.096176  [25600/71622]
loss: 0.084993  [32000/71622]
loss: 0.028727  [38400/71622]
loss: 0.042295  [44800/71622]
loss: 0.086810  [51200/71622]
loss: 0.021582  [57600/71622]
loss: 0.074116  [64000/71622]
loss: 0.063452  [70400/71622]
Test Error: 
 Accuracy: 86.9%, Avg loss: 0.521028 

Epoch 27
-------------------------------
loss: 0.529849  [    0/71622]
loss: 0.059248  [ 6400/71622]
loss: 0.096976  [12800/71622]
loss: 0.056626  [19200/71622]
loss: 0.075192  [25600/71622]
loss: 0.156688  [32000/71622]
loss: 0.058920  [38400/71622]
loss: 0.080783  [44800/71622]
loss: 0.049897  [51200/71622]
loss: 0.049732  [57600/71622]
loss: 0.198173  [64000/71622]
loss: 0.068427  [70400/71622]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.139966 

Epoch 28
-------------------------------
loss: 0.113400  [    0/71622]
loss: 0.113200  [ 6400/71622]
loss: 0.139551  [12800/71622]
loss: 0.032138  [19200/71622]
loss: 0.073434  [25600/71622]
loss: 0.055616  [32000/71622]
loss: 0.023623  [38400/71622]
loss: 0.041826  [44800/71622]
loss: 0.069853  [51200/71622]
loss: 0.057373  [57600/71622]
loss: 0.012325  [64000/71622]
loss: 0.061746  [70400/71622]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.146439 

Epoch 29
-------------------------------
loss: 0.097011  [    0/71622]
loss: 0.086227  [ 6400/71622]
loss: 0.043367  [12800/71622]
loss: 0.080467  [19200/71622]
loss: 0.088593  [25600/71622]
loss: 0.112916  [32000/71622]
loss: 0.032129  [38400/71622]
loss: 0.018236  [44800/71622]
loss: 0.009136  [51200/71622]
loss: 0.039311  [57600/71622]
loss: 0.084316  [64000/71622]
loss: 1.620358  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.137421 

Epoch 30
-------------------------------
loss: 0.039330  [    0/71622]
loss: 0.108526  [ 6400/71622]
loss: 1.610771  [12800/71622]
loss: 0.078339  [19200/71622]
loss: 0.073955  [25600/71622]
loss: 0.030122  [32000/71622]
loss: 0.103566  [38400/71622]
loss: 0.136223  [44800/71622]
loss: 1.677501  [51200/71622]
loss: 0.021609  [57600/71622]
loss: 0.065217  [64000/71622]
loss: 0.067886  [70400/71622]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.134648 

Epoch 31
-------------------------------
loss: 0.048113  [    0/71622]
loss: 0.071338  [ 6400/71622]
loss: 0.077373  [12800/71622]
loss: 0.062988  [19200/71622]
loss: 0.049259  [25600/71622]
loss: 0.146446  [32000/71622]
loss: 0.085183  [38400/71622]
loss: 0.182457  [44800/71622]
loss: 0.017323  [51200/71622]
loss: 0.120010  [    0/69807]
loss: 0.205662  [ 6400/69807]
loss: 0.073004  [12800/69807]
loss: 0.124110  [19200/69807]
loss: 0.127362  [25600/69807]
loss: 0.060914  [32000/69807]
loss: 0.135515  [38400/69807]
loss: 0.037638  [44800/69807]
loss: 0.108206  [51200/69807]
loss: 0.128290  [57600/69807]
loss: 0.055655  [64000/69807]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.148959 

Epoch 19
-------------------------------
loss: 0.052322  [    0/69807]
loss: 0.062675  [ 6400/69807]
loss: 0.092284  [12800/69807]
loss: 0.210873  [19200/69807]
loss: 0.102671  [25600/69807]
loss: 0.133421  [32000/69807]
loss: 0.183843  [38400/69807]
loss: 0.225998  [44800/69807]
loss: 0.092031  [51200/69807]
loss: 0.017740  [57600/69807]
loss: 0.204979  [64000/69807]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.152143 

Epoch 20
-------------------------------
loss: 0.076024  [    0/69807]
loss: 0.022858  [ 6400/69807]
loss: 0.136896  [12800/69807]
loss: 0.137404  [19200/69807]
loss: 1.658268  [25600/69807]
loss: 0.108744  [32000/69807]
loss: 0.191321  [38400/69807]
loss: 0.053833  [44800/69807]
loss: 0.113514  [51200/69807]
loss: 0.235399  [57600/69807]
loss: 0.200206  [64000/69807]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.168024 

Epoch 21
-------------------------------
loss: 0.060135  [    0/69807]
loss: 0.113000  [ 6400/69807]
loss: 0.091061  [12800/69807]
loss: 0.101431  [19200/69807]
loss: 0.083931  [25600/69807]
loss: 0.082772  [32000/69807]
loss: 0.215477  [38400/69807]
loss: 0.152830  [44800/69807]
loss: 0.136114  [51200/69807]
loss: 0.170182  [57600/69807]
loss: 0.076725  [64000/69807]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.158548 

Epoch 22
-------------------------------
loss: 0.136607  [    0/69807]
loss: 0.205104  [ 6400/69807]
loss: 0.113087  [12800/69807]
loss: 0.079844  [19200/69807]
loss: 0.153522  [25600/69807]
loss: 0.193598  [32000/69807]
loss: 0.108735  [38400/69807]
loss: 0.102634  [44800/69807]
loss: 0.151296  [51200/69807]
loss: 0.190912  [57600/69807]
loss: 0.140071  [64000/69807]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.156104 

Epoch 23
-------------------------------
loss: 0.060830  [    0/69807]
loss: 0.055293  [ 6400/69807]
loss: 0.074997  [12800/69807]
loss: 0.142223  [19200/69807]
loss: 0.135641  [25600/69807]
loss: 0.047984  [32000/69807]
loss: 0.221866  [38400/69807]
loss: 0.125463  [44800/69807]
loss: 0.087951  [51200/69807]
loss: 0.050108  [57600/69807]
loss: 0.193673  [64000/69807]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.142554 

Epoch 24
-------------------------------
loss: 0.121328  [    0/69807]
loss: 0.092466  [ 6400/69807]
loss: 0.136439  [12800/69807]
loss: 0.228599  [19200/69807]
loss: 0.073451  [25600/69807]
loss: 0.052547  [32000/69807]
loss: 0.141224  [38400/69807]
loss: 0.159749  [44800/69807]
loss: 0.182573  [51200/69807]
loss: 0.086136  [57600/69807]
loss: 0.180822  [64000/69807]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.158992 

Epoch 25
-------------------------------
loss: 0.089705  [    0/69807]
loss: 0.103810  [ 6400/69807]
loss: 0.065884  [12800/69807]
loss: 0.063627  [19200/69807]
loss: 0.139255  [25600/69807]
loss: 0.124898  [32000/69807]
loss: 0.060562  [38400/69807]
loss: 0.169477  [44800/69807]
loss: 0.201133  [51200/69807]
loss: 0.071040  [57600/69807]
loss: 0.167786  [64000/69807]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146292 

Epoch 26
-------------------------------
loss: 0.074488  [    0/69807]
loss: 0.229030  [ 6400/69807]
loss: 0.111687  [12800/69807]
loss: 0.065167  [19200/69807]
loss: 0.140692  [25600/69807]
loss: 0.097395  [32000/69807]
loss: 0.091739  [38400/69807]
loss: 0.227833  [44800/69807]
loss: 0.079732  [51200/69807]
loss: 0.050263  [57600/69807]
loss: 0.070457  [64000/69807]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.151086 

Epoch 27
-------------------------------
loss: 0.133357  [    0/69807]
loss: 0.032166  [ 6400/69807]
loss: 0.158685  [12800/69807]
loss: 0.081611  [19200/69807]
loss: 0.079565  [25600/69807]
loss: 0.126916  [32000/69807]
loss: 0.106060  [38400/69807]
loss: 0.069109  [44800/69807]
loss: 0.171137  [51200/69807]
loss: 0.042243  [57600/69807]
loss: 0.151341  [64000/69807]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.170841 

Epoch 28
-------------------------------
loss: 0.198112  [    0/69807]
loss: 0.039622  [ 6400/69807]
loss: 0.136058  [12800/69807]
loss: 0.070907  [19200/69807]
loss: 0.074191  [25600/69807]
loss: 0.136498  [32000/69807]
loss: 0.115395  [38400/69807]
loss: 0.177732  [44800/69807]
loss: 0.136762  [51200/69807]
loss: 0.079309  [57600/69807]
loss: 0.138745  [64000/69807]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.153126 

Epoch 29
-------------------------------
loss: 0.147974  [    0/69807]
loss: 0.102190  [ 6400/69807]
loss: 0.219443  [12800/69807]
loss: 0.052850  [19200/69807]
loss: 0.121486  [25600/69807]
loss: 0.127381  [32000/69807]
loss: 0.140622  [38400/69807]
loss: 0.240963  [44800/69807]
loss: 0.105694  [51200/69807]
loss: 0.245487  [57600/69807]
loss: 0.202626  [64000/69807]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153432 

Epoch 30
-------------------------------
loss: 0.110795  [    0/69807]
loss: 0.076981  [ 6400/69807]
loss: 0.146821  [12800/69807]
loss: 0.129102  [19200/69807]
loss: 0.043482  [25600/69807]
loss: 0.032653  [32000/69807]
loss: 0.117868  [38400/69807]
loss: 0.109127  [44800/69807]
loss: 0.104890  [51200/69807]
loss: 0.213942  [57600/69807]
loss: 0.097313  [64000/69807]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170963 

Epoch 31
-------------------------------
loss: 0.057913  [    0/69807]
loss: 0.061243  [ 6400/69807]
loss: 0.104803  [12800/69807]
loss: 0.125288  [19200/69807]
loss: 0.086822  [25600/69807]
loss: 0.083782  [32000/69807]
loss: 0.242017  [38400/69807]
loss: 0.108284  [44800/69807]
loss: 0.166872  [51200/69807]
loss: 0.127152  [57600/69807]
loss: 0.152118  [64000/69807]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.145957 

Epoch 32
-------------------------------
loss: 0.102548  [    0/69807]
loss: 0.027959  [ 6400/69807]
loss: 0.105010  [12800/69807]
loss: 0.115276  [19200/69807]
loss: 0.137782  [25600/69807]
loss: 0.201852  [32000/69807]
loss: 0.132517  [38400/69807]
loss: 0.222106  [44800/69807]
loss: 0.097128  [51200/69807]
loss: 0.192492  [57600/69807]
loss: 0.141409  [64000/69807]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.147501 

Epoch 33
-------------------------------
loss: 0.072681  [    0/69807]
loss: 0.158216  [ 6400/69807]
loss: 0.070279  [12800/69807]
loss: 0.056157  [19200/69807]
loss: 0.103357  [25600/69807]
loss: 0.055348  [32000/69807]
loss: 0.059530  [38400/69807]
loss: 0.097620  [44800/69807]
loss: 0.164725  [51200/69807]
loss: 0.143205  [57600/69807]
loss: 0.101311  [64000/69807]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.151974 

Epoch 34
-------------------------------
loss: 0.079310  [    0/69807]
loss: 0.137948  [ 6400/69807]
loss: 0.045311  [12800/69807]
loss: 0.146840  [19200/69807]
loss: 0.068558  [25600/69807]
loss: 0.133891  [32000/69807]
loss: 0.147689  [38400/69807]
loss: 0.085195  [44800/69807]
loss: 0.092044  [51200/69807]
loss: 0.112677  [57600/69807]
loss: 0.097807  [64000/69807]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.165426 

Epoch 35
-------------------------------
loss: 0.135920  [    0/69807]
loss: 0.059160  [ 6400/69807]
loss: 0.129310  [12800/69807]
loss: 0.207847  [19200/69807]
loss: 0.124245  [25600/69807]
loss: 0.117590  [32000/69807]
loss: 0.117197  [38400/69807]
loss: 0.147848  [44800/69807]
loss: 0.128898  [51200/69807]
loss: 0.077323  [57600/69807]
loss: 0.200729  [64000/69807]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.188553 

Epoch 36
-------------------------------
loss: 0.133844  [    0/69807]
loss: 0.120916  [ 6400/69807]
loss: 0.086762  [12800/69807]
loss: 0.107861  [19200/69807]
loss: 0.116078  [25600/69807]
loss: 0.211155  [32000/69807]
loss: 0.062470  [38400/69807]
loss: 0.075901  [44800/69807]
loss: 0.252399  [51200/69807]
loss: 0.111859  [57600/69807]
loss: 0.138490  [64000/69807]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.169123 

Epoch 37
-------------------------------
loss: 0.103071  [    0/69807]
loss: 1.685855  [ 6400/69807]
loss: 0.130675  [12800/69807]
loss: 0.119770  [19200/69807]
loss: 0.029982  [25600/69807]
loss: 0.219356  [38400/69264]
loss: 0.249135  [44800/69264]
loss: 0.120227  [51200/69264]
loss: 0.190277  [57600/69264]
loss: 0.133365  [64000/69264]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.161449 

Epoch 15
-------------------------------
loss: 0.104340  [    0/69264]
loss: 0.155184  [ 6400/69264]
loss: 0.124509  [12800/69264]
loss: 0.084133  [19200/69264]
loss: 0.201006  [25600/69264]
loss: 0.120361  [32000/69264]
loss: 0.229968  [38400/69264]
loss: 0.129009  [44800/69264]
loss: 0.264256  [51200/69264]
loss: 0.191038  [57600/69264]
loss: 0.148903  [64000/69264]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.152459 

Epoch 16
-------------------------------
loss: 0.081778  [    0/69264]
loss: 0.099794  [ 6400/69264]
loss: 0.123418  [12800/69264]
loss: 0.215239  [19200/69264]
loss: 0.106197  [25600/69264]
loss: 0.190274  [32000/69264]
loss: 0.071073  [38400/69264]
loss: 0.129615  [44800/69264]
loss: 0.193269  [51200/69264]
loss: 0.104530  [57600/69264]
loss: 0.175027  [64000/69264]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.184036 

Epoch 17
-------------------------------
loss: 0.111109  [    0/69264]
loss: 0.090637  [ 6400/69264]
loss: 0.121413  [12800/69264]
loss: 0.136833  [19200/69264]
loss: 0.266557  [25600/69264]
loss: 0.219885  [32000/69264]
loss: 0.159608  [38400/69264]
loss: 0.144942  [44800/69264]
loss: 0.095281  [51200/69264]
loss: 0.084440  [57600/69264]
loss: 0.201574  [64000/69264]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.166355 

Epoch 18
-------------------------------
loss: 0.078030  [    0/69264]
loss: 0.108666  [ 6400/69264]
loss: 0.276832  [12800/69264]
loss: 0.200556  [19200/69264]
loss: 0.199562  [25600/69264]
loss: 0.206100  [32000/69264]
loss: 0.270860  [38400/69264]
loss: 0.262267  [44800/69264]
loss: 0.127794  [51200/69264]
loss: 0.136290  [57600/69264]
loss: 0.167381  [64000/69264]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.159110 

Epoch 19
-------------------------------
loss: 0.123477  [    0/69264]
loss: 0.153120  [ 6400/69264]
loss: 0.061980  [12800/69264]
loss: 0.114676  [19200/69264]
loss: 0.117143  [25600/69264]
loss: 0.072614  [32000/69264]
loss: 0.203775  [38400/69264]
loss: 0.208507  [44800/69264]
loss: 0.219810  [51200/69264]
loss: 0.164848  [57600/69264]
loss: 0.084849  [64000/69264]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.171691 

Epoch 20
-------------------------------
loss: 0.267409  [    0/69264]
loss: 0.121249  [ 6400/69264]
loss: 0.286229  [12800/69264]
loss: 0.229034  [19200/69264]
loss: 0.323546  [25600/69264]
loss: 0.121108  [32000/69264]
loss: 0.115206  [38400/69264]
loss: 0.185657  [44800/69264]
loss: 0.203102  [51200/69264]
loss: 0.145690  [57600/69264]
loss: 0.127916  [64000/69264]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.150811 

Epoch 21
-------------------------------
loss: 1.732099  [    0/69264]
loss: 0.174961  [ 6400/69264]
loss: 0.073427  [12800/69264]
loss: 0.144413  [19200/69264]
loss: 0.199441  [25600/69264]
loss: 0.119600  [32000/69264]
loss: 0.119279  [38400/69264]
loss: 0.092600  [44800/69264]
loss: 0.164536  [51200/69264]
loss: 0.109523  [57600/69264]
loss: 0.318712  [64000/69264]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.151204 

Epoch 22
-------------------------------
loss: 0.214278  [    0/69264]
loss: 0.228996  [ 6400/69264]
loss: 0.224008  [12800/69264]
loss: 0.092360  [19200/69264]
loss: 0.090414  [25600/69264]
loss: 0.089321  [32000/69264]
loss: 0.187153  [38400/69264]
loss: 0.204241  [44800/69264]
loss: 0.100941  [51200/69264]
loss: 0.125001  [57600/69264]
loss: 0.124725  [64000/69264]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.183094 

Epoch 23
-------------------------------
loss: 0.131485  [    0/69264]
loss: 0.292449  [ 6400/69264]
loss: 0.220695  [12800/69264]
loss: 0.068769  [19200/69264]
loss: 0.137079  [25600/69264]
loss: 0.075851  [32000/69264]
loss: 0.107623  [38400/69264]
loss: 0.268118  [44800/69264]
loss: 0.138795  [51200/69264]
loss: 0.163701  [57600/69264]
loss: 0.143890  [64000/69264]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.153881 

Epoch 24
-------------------------------
loss: 0.285007  [    0/69264]
loss: 0.122229  [ 6400/69264]
loss: 0.208081  [12800/69264]
loss: 0.233154  [19200/69264]
loss: 0.080678  [25600/69264]
loss: 0.090954  [32000/69264]
loss: 0.119560  [38400/69264]
loss: 0.123932  [44800/69264]
loss: 0.066267  [51200/69264]
loss: 0.311924  [57600/69264]
loss: 0.147597  [64000/69264]
Test Error: 
 Accuracy: 88.6%, Avg loss: 0.254704 

Epoch 25
-------------------------------
loss: 0.322833  [    0/69264]
loss: 0.185012  [ 6400/69264]
loss: 0.149946  [12800/69264]
loss: 0.182891  [19200/69264]
loss: 0.104117  [25600/69264]
loss: 0.114870  [32000/69264]
loss: 0.117269  [38400/69264]
loss: 0.221323  [44800/69264]
loss: 0.170561  [51200/69264]
loss: 0.134638  [57600/69264]
loss: 0.155838  [64000/69264]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.159915 

Epoch 26
-------------------------------
loss: 0.088797  [    0/69264]
loss: 0.152182  [ 6400/69264]
loss: 0.244215  [12800/69264]
loss: 0.236403  [19200/69264]
loss: 0.126430  [25600/69264]
loss: 0.084520  [32000/69264]
loss: 0.135751  [38400/69264]
loss: 0.171721  [44800/69264]
loss: 0.158184  [51200/69264]
loss: 0.159145  [57600/69264]
loss: 0.051932  [64000/69264]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.169654 

Epoch 27
-------------------------------
loss: 0.122865  [    0/69264]
loss: 0.178013  [ 6400/69264]
loss: 0.109819  [12800/69264]
loss: 0.086659  [19200/69264]
loss: 0.154489  [25600/69264]
loss: 0.323453  [32000/69264]
loss: 0.128829  [38400/69264]
loss: 0.156782  [44800/69264]
loss: 0.249322  [51200/69264]
loss: 0.186855  [57600/69264]
loss: 0.233415  [64000/69264]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.183318 

Epoch 28
-------------------------------
loss: 0.158334  [    0/69264]
loss: 0.146324  [ 6400/69264]
loss: 0.249077  [12800/69264]
loss: 0.174845  [19200/69264]
loss: 0.126447  [25600/69264]
loss: 0.165318  [32000/69264]
loss: 0.175966  [38400/69264]
loss: 0.238420  [44800/69264]
loss: 0.224393  [51200/69264]
loss: 0.162669  [57600/69264]
loss: 0.105285  [64000/69264]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.155695 

Epoch 29
-------------------------------
loss: 0.120107  [    0/69264]
loss: 0.088375  [ 6400/69264]
loss: 0.448856  [12800/69264]
loss: 0.132371  [19200/69264]
loss: 0.237622  [25600/69264]
loss: 0.114357  [32000/69264]
loss: 0.163910  [38400/69264]
loss: 0.096876  [44800/69264]
loss: 0.215489  [51200/69264]
loss: 0.153211  [57600/69264]
loss: 0.144488  [64000/69264]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162176 

Epoch 30
-------------------------------
loss: 0.225254  [    0/69264]
loss: 0.126015  [ 6400/69264]
loss: 0.182988  [12800/69264]
loss: 0.079000  [19200/69264]
loss: 0.228726  [25600/69264]
loss: 0.204883  [32000/69264]
loss: 0.018616  [38400/69264]
loss: 0.199711  [44800/69264]
loss: 0.125976  [51200/69264]
loss: 0.174514  [57600/69264]
loss: 0.235615  [64000/69264]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.162253 

Epoch 31
-------------------------------
loss: 0.140983  [    0/69264]
loss: 0.093971  [ 6400/69264]
loss: 0.146793  [12800/69264]
loss: 0.188138  [19200/69264]
loss: 0.125504  [25600/69264]
loss: 0.079586  [32000/69264]
loss: 0.131697  [38400/69264]
loss: 0.087860  [44800/69264]
loss: 0.083761  [51200/69264]
loss: 0.189539  [57600/69264]
loss: 0.090377  [64000/69264]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.160653 

Epoch 32
-------------------------------
loss: 0.166483  [    0/69264]
loss: 0.239947  [ 6400/69264]
loss: 0.141927  [12800/69264]
loss: 0.132014  [19200/69264]
loss: 0.128259  [25600/69264]
loss: 0.203878  [32000/69264]
loss: 0.098916  [38400/69264]
loss: 0.109863  [44800/69264]
loss: 0.292266  [51200/69264]
loss: 0.121278  [57600/69264]
loss: 0.246992  [64000/69264]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.160735 

Epoch 33
-------------------------------
loss: 0.217000  [    0/69264]
loss: 0.118219  [ 6400/69264]
loss: 0.249341  [12800/69264]
loss: 0.114018  [19200/69264]
loss: 0.121486  [25600/69264]
loss: 0.110678  [32000/69264]
loss: 0.097384  [38400/69264]
loss: 0.157273  [44800/69264]
loss: 0.090521  [51200/69264]
loss: 0.156441  [57600/69264]
loss: 0.093878  [64000/69264]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.177117 

Epoch 17
-------------------------------
loss: 0.141695  [    0/70702]
loss: 0.160671  [ 6400/70702]
loss: 0.116578  [12800/70702]
loss: 0.120249  [19200/70702]
loss: 0.191341  [25600/70702]
loss: 0.170138  [32000/70702]
loss: 0.129001  [38400/70702]
loss: 0.155559  [44800/70702]
loss: 0.178982  [51200/70702]
loss: 0.163996  [57600/70702]
loss: 0.169777  [64000/70702]
loss: 0.174166  [70400/70702]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.166338 

Epoch 18
-------------------------------
loss: 0.100218  [    0/70702]
loss: 0.178069  [ 6400/70702]
loss: 0.181200  [12800/70702]
loss: 0.209698  [19200/70702]
loss: 0.131894  [25600/70702]
loss: 0.167133  [32000/70702]
loss: 0.153161  [38400/70702]
loss: 0.119925  [44800/70702]
loss: 0.130475  [51200/70702]
loss: 0.119292  [57600/70702]
loss: 0.190345  [64000/70702]
loss: 0.134973  [70400/70702]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.164331 

Epoch 19
-------------------------------
loss: 0.186275  [    0/70702]
loss: 0.181260  [ 6400/70702]
loss: 0.195445  [12800/70702]
loss: 0.074341  [19200/70702]
loss: 1.630964  [25600/70702]
loss: 0.173043  [32000/70702]
loss: 0.154260  [38400/70702]
loss: 0.174201  [44800/70702]
loss: 0.140720  [51200/70702]
loss: 0.069941  [57600/70702]
loss: 0.173296  [64000/70702]
loss: 0.104986  [70400/70702]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.165169 

Epoch 20
-------------------------------
loss: 0.103573  [    0/70702]
loss: 0.109991  [ 6400/70702]
loss: 0.217374  [12800/70702]
loss: 0.084486  [19200/70702]
loss: 0.127432  [25600/70702]
loss: 0.154776  [32000/70702]
loss: 0.068186  [38400/70702]
loss: 0.128981  [44800/70702]
loss: 0.288053  [51200/70702]
loss: 0.115925  [57600/70702]
loss: 0.136225  [64000/70702]
loss: 0.139312  [70400/70702]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.160106 

Epoch 21
-------------------------------
loss: 0.122520  [    0/70702]
loss: 0.155306  [ 6400/70702]
loss: 0.237738  [12800/70702]
loss: 0.196937  [19200/70702]
loss: 0.090027  [25600/70702]
loss: 0.127434  [32000/70702]
loss: 0.104161  [38400/70702]
loss: 0.169393  [44800/70702]
loss: 0.191060  [51200/70702]
loss: 0.060791  [57600/70702]
loss: 0.152498  [64000/70702]
loss: 0.105330  [70400/70702]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.183869 

Epoch 22
-------------------------------
loss: 0.111261  [    0/70702]
loss: 0.059507  [ 6400/70702]
loss: 0.028404  [12800/70702]
loss: 0.124947  [19200/70702]
loss: 0.164310  [25600/70702]
loss: 0.164063  [32000/70702]
loss: 0.103972  [38400/70702]
loss: 0.235386  [44800/70702]
loss: 0.108396  [51200/70702]
loss: 0.074874  [57600/70702]
loss: 0.144382  [64000/70702]
loss: 0.105549  [70400/70702]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.162377 

Epoch 23
-------------------------------
loss: 0.169453  [    0/70702]
loss: 0.188483  [ 6400/70702]
loss: 0.138692  [12800/70702]
loss: 0.149553  [19200/70702]
loss: 0.071591  [25600/70702]
loss: 0.187863  [32000/70702]
loss: 0.087009  [38400/70702]
loss: 1.706896  [44800/70702]
loss: 0.259717  [51200/70702]
loss: 0.166876  [57600/70702]
loss: 0.068508  [64000/70702]
loss: 0.173981  [70400/70702]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.179597 

Epoch 24
-------------------------------
loss: 0.067119  [    0/70702]
loss: 0.115636  [ 6400/70702]
loss: 0.107536  [12800/70702]
loss: 0.221199  [19200/70702]
loss: 0.154186  [25600/70702]
loss: 0.048561  [32000/70702]
loss: 0.135934  [38400/70702]
loss: 0.139896  [44800/70702]
loss: 0.034882  [51200/70702]
loss: 0.109787  [57600/70702]
loss: 0.176565  [64000/70702]
loss: 0.163673  [70400/70702]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.169363 

Epoch 25
-------------------------------
loss: 0.264769  [    0/70702]
loss: 0.161409  [ 6400/70702]
loss: 0.088408  [12800/70702]
loss: 0.057325  [19200/70702]
loss: 0.113655  [25600/70702]
loss: 0.153427  [32000/70702]
loss: 0.205009  [38400/70702]
loss: 0.095958  [44800/70702]
loss: 0.094352  [51200/70702]
loss: 0.197810  [57600/70702]
loss: 0.084705  [64000/70702]
loss: 0.115765  [70400/70702]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.168410 

Epoch 26
-------------------------------
loss: 0.163791  [    0/70702]
loss: 0.076293  [ 6400/70702]
loss: 0.120511  [12800/70702]
loss: 1.712246  [19200/70702]
loss: 0.102917  [25600/70702]
loss: 0.220141  [32000/70702]
loss: 0.283812  [38400/70702]
loss: 0.117434  [44800/70702]
loss: 0.147765  [51200/70702]
loss: 0.051667  [57600/70702]
loss: 0.123989  [64000/70702]
loss: 0.070734  [70400/70702]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.163368 

Epoch 27
-------------------------------
loss: 0.086993  [    0/70702]
loss: 0.094771  [ 6400/70702]
loss: 0.120730  [12800/70702]
loss: 0.130512  [19200/70702]
loss: 0.030697  [25600/70702]
loss: 0.128033  [32000/70702]
loss: 0.141198  [38400/70702]
loss: 0.100745  [44800/70702]
loss: 0.097481  [51200/70702]
loss: 0.082950  [57600/70702]
loss: 0.117825  [64000/70702]
loss: 0.128381  [70400/70702]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.167358 

Epoch 28
-------------------------------
loss: 0.106509  [    0/70702]
loss: 0.108903  [ 6400/70702]
loss: 0.135573  [12800/70702]
loss: 0.080822  [19200/70702]
loss: 0.188407  [25600/70702]
loss: 0.115802  [32000/70702]
loss: 0.089900  [38400/70702]
loss: 0.104409  [44800/70702]
loss: 0.149155  [51200/70702]
loss: 0.141145  [57600/70702]
loss: 0.148414  [64000/70702]
loss: 0.169227  [70400/70702]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.167246 

Epoch 29
-------------------------------
loss: 0.075983  [    0/70702]
loss: 0.066384  [ 6400/70702]
loss: 0.116512  [12800/70702]
loss: 0.116169  [19200/70702]
loss: 0.091503  [25600/70702]
loss: 0.197098  [32000/70702]
loss: 0.148076  [38400/70702]
loss: 0.090615  [44800/70702]
loss: 0.183397  [51200/70702]
loss: 0.086033  [57600/70702]
loss: 0.113320  [64000/70702]
loss: 0.113680  [70400/70702]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.166155 

Epoch 30
-------------------------------
loss: 0.112939  [    0/70702]
loss: 0.107712  [ 6400/70702]
loss: 0.223682  [12800/70702]
loss: 0.083000  [19200/70702]
loss: 0.284984  [25600/70702]
loss: 0.120545  [32000/70702]
loss: 0.186438  [38400/70702]
loss: 0.194125  [44800/70702]
loss: 0.187022  [51200/70702]
loss: 0.053152  [57600/70702]
loss: 0.196030  [64000/70702]
loss: 0.135325  [70400/70702]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.169611 

Epoch 31
-------------------------------
loss: 0.060461  [    0/70702]
loss: 0.132888  [ 6400/70702]
loss: 0.067694  [12800/70702]
loss: 0.143818  [19200/70702]
loss: 0.120556  [25600/70702]
loss: 0.304392  [32000/70702]
loss: 0.258372  [38400/70702]
loss: 0.113983  [44800/70702]
loss: 0.198980  [51200/70702]
loss: 0.119344  [57600/70702]
loss: 0.161883  [64000/70702]
loss: 0.149335  [70400/70702]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.164721 

Epoch 32
-------------------------------
loss: 0.153250  [    0/70702]
loss: 0.084012  [ 6400/70702]
loss: 0.165473  [12800/70702]
loss: 0.120197  [19200/70702]
loss: 0.120492  [25600/70702]
loss: 0.072934  [32000/70702]
loss: 0.165828  [38400/70702]
loss: 0.114513  [44800/70702]
loss: 0.144165  [51200/70702]
loss: 0.065303  [57600/70702]
loss: 0.154786  [64000/70702]
loss: 0.088732  [70400/70702]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.171049 

Epoch 33
-------------------------------
loss: 0.090455  [    0/70702]
loss: 0.171938  [ 6400/70702]
loss: 0.156278  [12800/70702]
loss: 0.122622  [19200/70702]
loss: 0.052811  [25600/70702]
loss: 0.146956  [32000/70702]
loss: 0.163875  [38400/70702]
loss: 0.075864  [44800/70702]
loss: 0.035495  [51200/70702]
loss: 1.658047  [57600/70702]
loss: 0.181035  [64000/70702]
loss: 0.136745  [70400/70702]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.194674 

Epoch 34
-------------------------------
loss: 0.073559  [    0/70702]
loss: 0.122254  [ 6400/70702]
loss: 0.203656  [12800/70702]
loss: 0.207182  [19200/70702]
loss: 0.104358  [25600/70702]
loss: 0.141957  [32000/70702]
loss: 0.213914  [38400/70702]
loss: 0.091098  [44800/70702]
loss: 0.016516  [51200/70702]
loss: 0.134549  [57600/70702]
loss: 0.111154  [64000/70702]
loss: 0.181915  [70400/70702]
loss: 0.092009  [51200/70935]
loss: 0.122578  [57600/70935]
loss: 0.163232  [64000/70935]
loss: 0.160442  [70400/70935]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.154475 

Epoch 14
-------------------------------
loss: 0.105754  [    0/70935]
loss: 1.750852  [ 6400/70935]
loss: 0.109389  [12800/70935]
loss: 0.230028  [19200/70935]
loss: 0.135650  [25600/70935]
loss: 0.215997  [32000/70935]
loss: 0.114933  [38400/70935]
loss: 0.107078  [44800/70935]
loss: 0.145822  [51200/70935]
loss: 0.133428  [57600/70935]
loss: 0.161566  [64000/70935]
loss: 0.117279  [70400/70935]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.160998 

Epoch 15
-------------------------------
loss: 0.179331  [    0/70935]
loss: 0.126543  [ 6400/70935]
loss: 0.183483  [12800/70935]
loss: 0.069948  [19200/70935]
loss: 0.139203  [25600/70935]
loss: 0.138365  [32000/70935]
loss: 0.222035  [38400/70935]
loss: 0.105000  [44800/70935]
loss: 0.087533  [51200/70935]
loss: 0.093243  [57600/70935]
loss: 0.139408  [64000/70935]
loss: 0.095423  [70400/70935]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.157677 

Epoch 16
-------------------------------
loss: 0.299386  [    0/70935]
loss: 0.064816  [ 6400/70935]
loss: 0.167171  [12800/70935]
loss: 0.102994  [19200/70935]
loss: 0.058393  [25600/70935]
loss: 0.155961  [32000/70935]
loss: 0.285532  [38400/70935]
loss: 0.198415  [44800/70935]
loss: 0.125641  [51200/70935]
loss: 0.122673  [57600/70935]
loss: 0.181879  [64000/70935]
loss: 1.720963  [70400/70935]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.164427 

Epoch 17
-------------------------------
loss: 0.092509  [    0/70935]
loss: 0.060430  [ 6400/70935]
loss: 0.122140  [12800/70935]
loss: 0.174409  [19200/70935]
loss: 0.161508  [25600/70935]
loss: 0.102947  [32000/70935]
loss: 0.130721  [38400/70935]
loss: 0.137354  [44800/70935]
loss: 0.184041  [51200/70935]
loss: 0.095330  [57600/70935]
loss: 0.171736  [64000/70935]
loss: 0.112119  [70400/70935]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.168375 

Epoch 18
-------------------------------
loss: 0.092266  [    0/70935]
loss: 0.099647  [ 6400/70935]
loss: 0.274802  [12800/70935]
loss: 0.100332  [19200/70935]
loss: 0.123704  [25600/70935]
loss: 0.387077  [32000/70935]
loss: 0.057046  [38400/70935]
loss: 0.079080  [44800/70935]
loss: 0.146857  [51200/70935]
loss: 0.164684  [57600/70935]
loss: 0.170170  [64000/70935]
loss: 0.110364  [70400/70935]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.182732 

Epoch 19
-------------------------------
loss: 0.164573  [    0/70935]
loss: 0.102070  [ 6400/70935]
loss: 0.134369  [12800/70935]
loss: 0.115531  [19200/70935]
loss: 0.123612  [25600/70935]
loss: 0.104567  [32000/70935]
loss: 0.058809  [38400/70935]
loss: 0.147898  [44800/70935]
loss: 0.134321  [51200/70935]
loss: 0.108781  [57600/70935]
loss: 0.231675  [64000/70935]
loss: 0.101500  [70400/70935]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.158184 

Epoch 20
-------------------------------
loss: 0.070342  [    0/70935]
loss: 0.069068  [ 6400/70935]
loss: 0.099494  [12800/70935]
loss: 0.178468  [19200/70935]
loss: 0.095424  [25600/70935]
loss: 0.261006  [32000/70935]
loss: 0.141166  [38400/70935]
loss: 0.146101  [44800/70935]
loss: 0.161892  [51200/70935]
loss: 0.129554  [57600/70935]
loss: 0.087441  [64000/70935]
loss: 0.129243  [70400/70935]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.162630 

Epoch 21
-------------------------------
loss: 0.218664  [    0/70935]
loss: 0.130528  [ 6400/70935]
loss: 0.278497  [12800/70935]
loss: 0.167218  [19200/70935]
loss: 0.192760  [25600/70935]
loss: 0.141069  [32000/70935]
loss: 0.151446  [38400/70935]
loss: 0.102768  [44800/70935]
loss: 0.219050  [51200/70935]
loss: 0.118648  [57600/70935]
loss: 0.197527  [64000/70935]
loss: 0.277754  [70400/70935]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.149884 

Epoch 22
-------------------------------
loss: 0.186379  [    0/70935]
loss: 0.070644  [ 6400/70935]
loss: 0.169546  [12800/70935]
loss: 0.228535  [19200/70935]
loss: 0.191878  [25600/70935]
loss: 0.084784  [32000/70935]
loss: 0.122733  [38400/70935]
loss: 0.093120  [44800/70935]
loss: 0.158267  [51200/70935]
loss: 0.190059  [57600/70935]
loss: 0.106979  [64000/70935]
loss: 0.096743  [70400/70935]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.163253 

Epoch 23
-------------------------------
loss: 0.095355  [    0/70935]
loss: 0.079832  [ 6400/70935]
loss: 0.168134  [12800/70935]
loss: 0.084304  [19200/70935]
loss: 0.076589  [25600/70935]
loss: 0.185256  [32000/70935]
loss: 0.073573  [38400/70935]
loss: 0.164762  [44800/70935]
loss: 0.191163  [51200/70935]
loss: 0.094166  [57600/70935]
loss: 0.238619  [64000/70935]
loss: 0.145043  [70400/70935]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.157584 

Epoch 24
-------------------------------
loss: 0.171314  [    0/70935]
loss: 0.131539  [ 6400/70935]
loss: 0.214714  [12800/70935]
loss: 0.230545  [19200/70935]
loss: 0.110961  [25600/70935]
loss: 0.153945  [32000/70935]
loss: 0.152868  [38400/70935]
loss: 0.161731  [44800/70935]
loss: 0.207094  [51200/70935]
loss: 0.215051  [57600/70935]
loss: 0.103363  [64000/70935]
loss: 0.143776  [70400/70935]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.157134 

Epoch 25
-------------------------------
loss: 0.167002  [    0/70935]
loss: 0.098528  [ 6400/70935]
loss: 0.081329  [12800/70935]
loss: 0.194447  [19200/70935]
loss: 0.110652  [25600/70935]
loss: 0.145515  [32000/70935]
loss: 0.140906  [38400/70935]
loss: 0.075806  [44800/70935]
loss: 0.082460  [51200/70935]
loss: 0.158087  [57600/70935]
loss: 0.128381  [64000/70935]
loss: 0.083627  [70400/70935]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.168078 

Epoch 26
-------------------------------
loss: 0.058040  [    0/70935]
loss: 0.175050  [ 6400/70935]
loss: 0.064155  [12800/70935]
loss: 0.128914  [19200/70935]
loss: 0.107215  [25600/70935]
loss: 0.137401  [32000/70935]
loss: 0.131002  [38400/70935]
loss: 0.160236  [44800/70935]
loss: 0.118308  [51200/70935]
loss: 0.240833  [57600/70935]
loss: 0.147645  [64000/70935]
loss: 0.162305  [70400/70935]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.146017 

Epoch 27
-------------------------------
loss: 0.204426  [    0/70935]
loss: 0.145579  [ 6400/70935]
loss: 0.080488  [12800/70935]
loss: 0.114421  [19200/70935]
loss: 0.089271  [25600/70935]
loss: 0.154511  [32000/70935]
loss: 0.297468  [38400/70935]
loss: 0.135193  [44800/70935]
loss: 0.129951  [51200/70935]
loss: 0.224075  [57600/70935]
loss: 0.117451  [64000/70935]
loss: 0.111712  [70400/70935]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.150364 

Epoch 28
-------------------------------
loss: 0.074330  [    0/70935]
loss: 0.221469  [ 6400/70935]
loss: 0.153942  [12800/70935]
loss: 0.181583  [19200/70935]
loss: 0.183172  [25600/70935]
loss: 0.222072  [32000/70935]
loss: 0.343798  [38400/70935]
loss: 0.171199  [44800/70935]
loss: 0.117537  [51200/70935]
loss: 0.034455  [57600/70935]
loss: 0.172947  [64000/70935]
loss: 0.212613  [70400/70935]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.149399 

Epoch 29
-------------------------------
loss: 0.148476  [    0/70935]
loss: 0.070318  [ 6400/70935]
loss: 0.131260  [12800/70935]
loss: 0.110021  [19200/70935]
loss: 0.154402  [25600/70935]
loss: 0.162428  [32000/70935]
loss: 0.066354  [38400/70935]
loss: 0.130860  [44800/70935]
loss: 0.111394  [51200/70935]
loss: 0.230240  [57600/70935]
loss: 0.126819  [64000/70935]
loss: 0.054823  [70400/70935]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.161488 

Epoch 30
-------------------------------
loss: 0.111218  [    0/70935]
loss: 0.132091  [ 6400/70935]
loss: 0.121897  [12800/70935]
loss: 0.167173  [19200/70935]
loss: 0.045738  [25600/70935]
loss: 0.124296  [32000/70935]
loss: 0.125770  [38400/70935]
loss: 0.142559  [44800/70935]
loss: 0.083854  [51200/70935]
loss: 0.204376  [57600/70935]
loss: 0.169558  [64000/70935]
loss: 0.057332  [70400/70935]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.148559 

Epoch 31
-------------------------------
loss: 0.168801  [    0/70935]
loss: 0.044407  [ 6400/70935]
loss: 0.057180  [12800/70935]
loss: 0.079640  [19200/70935]
loss: 0.197610  [25600/70935]
loss: 0.206325  [32000/70935]
loss: 0.108562  [38400/70935]
loss: 0.115747  [44800/70935]
loss: 0.155933  [51200/70935]
loss: 0.053282  [38400/69635]
loss: 0.404480  [44800/69635]
loss: 0.205102  [51200/69635]
loss: 0.206698  [57600/69635]
loss: 0.147431  [64000/69635]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.153597 

Epoch 15
-------------------------------
loss: 0.181638  [    0/69635]
loss: 0.173005  [ 6400/69635]
loss: 0.252043  [12800/69635]
loss: 0.162780  [19200/69635]
loss: 0.232966  [25600/69635]
loss: 0.135111  [32000/69635]
loss: 0.194336  [38400/69635]
loss: 0.201449  [44800/69635]
loss: 0.142960  [51200/69635]
loss: 0.125156  [57600/69635]
loss: 0.216663  [64000/69635]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.178038 

Epoch 16
-------------------------------
loss: 0.368425  [    0/69635]
loss: 0.106147  [ 6400/69635]
loss: 0.175495  [12800/69635]
loss: 0.140054  [19200/69635]
loss: 0.194547  [25600/69635]
loss: 0.178693  [32000/69635]
loss: 0.178189  [38400/69635]
loss: 0.183772  [44800/69635]
loss: 0.345002  [51200/69635]
loss: 0.186921  [57600/69635]
loss: 0.237718  [64000/69635]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.169480 

Epoch 17
-------------------------------
loss: 0.172884  [    0/69635]
loss: 0.207506  [ 6400/69635]
loss: 0.163934  [12800/69635]
loss: 0.142132  [19200/69635]
loss: 0.316816  [25600/69635]
loss: 0.114573  [32000/69635]
loss: 0.158208  [38400/69635]
loss: 0.083562  [44800/69635]
loss: 0.081581  [51200/69635]
loss: 0.081893  [57600/69635]
loss: 1.707315  [64000/69635]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.152915 

Epoch 18
-------------------------------
loss: 0.116255  [    0/69635]
loss: 0.108577  [ 6400/69635]
loss: 0.152438  [12800/69635]
loss: 0.130287  [19200/69635]
loss: 0.112505  [25600/69635]
loss: 0.107034  [32000/69635]
loss: 0.094189  [38400/69635]
loss: 0.191267  [44800/69635]
loss: 0.172525  [51200/69635]
loss: 0.090034  [57600/69635]
loss: 0.243087  [64000/69635]
Test Error: 
 Accuracy: 89.1%, Avg loss: 0.301405 

Epoch 19
-------------------------------
loss: 0.216909  [    0/69635]
loss: 0.212494  [ 6400/69635]
loss: 0.104855  [12800/69635]
loss: 0.095659  [19200/69635]
loss: 0.241485  [25600/69635]
loss: 0.177168  [32000/69635]
loss: 0.338452  [38400/69635]
loss: 0.255899  [44800/69635]
loss: 0.152429  [51200/69635]
loss: 0.132743  [57600/69635]
loss: 0.173711  [64000/69635]
Test Error: 
 Accuracy: 88.5%, Avg loss: 0.279504 

Epoch 20
-------------------------------
loss: 0.130360  [    0/69635]
loss: 0.121706  [ 6400/69635]
loss: 0.094140  [12800/69635]
loss: 0.196532  [19200/69635]
loss: 0.106622  [25600/69635]
loss: 0.175284  [32000/69635]
loss: 0.118479  [38400/69635]
loss: 0.253123  [44800/69635]
loss: 0.302807  [51200/69635]
loss: 0.222272  [57600/69635]
loss: 0.070726  [64000/69635]
Test Error: 
 Accuracy: 89.0%, Avg loss: 0.317537 

Epoch 21
-------------------------------
loss: 0.255814  [    0/69635]
loss: 1.835389  [ 6400/69635]
loss: 0.074660  [12800/69635]
loss: 0.145441  [19200/69635]
loss: 0.108638  [25600/69635]
loss: 0.158335  [32000/69635]
loss: 0.229820  [38400/69635]
loss: 0.106756  [44800/69635]
loss: 0.129229  [51200/69635]
loss: 0.157311  [57600/69635]
loss: 0.159113  [64000/69635]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.152390 

Epoch 22
-------------------------------
loss: 0.119136  [    0/69635]
loss: 0.181997  [ 6400/69635]
loss: 0.113137  [12800/69635]
loss: 0.161638  [19200/69635]
loss: 0.120459  [25600/69635]
loss: 0.164180  [32000/69635]
loss: 0.086328  [38400/69635]
loss: 0.171954  [44800/69635]
loss: 0.127405  [51200/69635]
loss: 0.054716  [57600/69635]
loss: 0.139033  [64000/69635]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.149815 

Epoch 23
-------------------------------
loss: 0.050883  [    0/69635]
loss: 0.182065  [ 6400/69635]
loss: 0.137446  [12800/69635]
loss: 0.178664  [19200/69635]
loss: 0.153950  [25600/69635]
loss: 0.206547  [32000/69635]
loss: 0.148212  [38400/69635]
loss: 0.134219  [44800/69635]
loss: 0.254663  [51200/69635]
loss: 0.075584  [57600/69635]
loss: 0.169294  [64000/69635]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159642 

Epoch 24
-------------------------------
loss: 0.214900  [    0/69635]
loss: 0.083539  [ 6400/69635]
loss: 0.168334  [12800/69635]
loss: 0.216535  [19200/69635]
loss: 0.126489  [25600/69635]
loss: 0.138633  [32000/69635]
loss: 0.137308  [38400/69635]
loss: 0.136072  [44800/69635]
loss: 0.257910  [51200/69635]
loss: 0.177447  [57600/69635]
loss: 0.126497  [64000/69635]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.159620 

Epoch 25
-------------------------------
loss: 0.097251  [    0/69635]
loss: 0.135997  [ 6400/69635]
loss: 0.173629  [12800/69635]
loss: 0.076463  [19200/69635]
loss: 0.227616  [25600/69635]
loss: 0.202321  [32000/69635]
loss: 0.187929  [38400/69635]
loss: 0.172706  [44800/69635]
loss: 0.046024  [51200/69635]
loss: 0.084816  [57600/69635]
loss: 0.123732  [64000/69635]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.154745 

Epoch 26
-------------------------------
loss: 0.127148  [    0/69635]
loss: 0.099777  [ 6400/69635]
loss: 0.152038  [12800/69635]
loss: 0.231894  [19200/69635]
loss: 0.121234  [25600/69635]
loss: 0.113461  [32000/69635]
loss: 0.117768  [38400/69635]
loss: 0.171754  [44800/69635]
loss: 0.201916  [51200/69635]
loss: 0.085652  [57600/69635]
loss: 0.110662  [64000/69635]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.159052 

Epoch 27
-------------------------------
loss: 0.235223  [    0/69635]
loss: 0.181963  [ 6400/69635]
loss: 0.145934  [12800/69635]
loss: 0.171099  [19200/69635]
loss: 0.171020  [25600/69635]
loss: 0.169773  [32000/69635]
loss: 0.089128  [38400/69635]
loss: 0.134437  [44800/69635]
loss: 0.323543  [51200/69635]
loss: 0.128619  [57600/69635]
loss: 0.084762  [64000/69635]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.151980 

Epoch 28
-------------------------------
loss: 0.174509  [    0/69635]
loss: 0.149103  [ 6400/69635]
loss: 0.104833  [12800/69635]
loss: 0.191350  [19200/69635]
loss: 0.121380  [25600/69635]
loss: 0.152018  [32000/69635]
loss: 0.063500  [38400/69635]
loss: 0.222975  [44800/69635]
loss: 0.300949  [51200/69635]
loss: 0.140507  [57600/69635]
loss: 0.228667  [64000/69635]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.168479 

Epoch 29
-------------------------------
loss: 0.103659  [    0/69635]
loss: 0.055308  [ 6400/69635]
loss: 0.189877  [12800/69635]
loss: 0.069344  [19200/69635]
loss: 0.238028  [25600/69635]
loss: 0.094171  [32000/69635]
loss: 0.077429  [38400/69635]
loss: 0.073760  [44800/69635]
loss: 0.074783  [51200/69635]
loss: 0.346517  [57600/69635]
loss: 0.172655  [64000/69635]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.154369 

Epoch 30
-------------------------------
loss: 0.136068  [    0/69635]
loss: 0.160121  [ 6400/69635]
loss: 0.149546  [12800/69635]
loss: 1.673688  [19200/69635]
loss: 0.189636  [25600/69635]
loss: 0.302172  [32000/69635]
loss: 0.193462  [38400/69635]
loss: 0.162961  [44800/69635]
loss: 0.133162  [51200/69635]
loss: 0.104916  [57600/69635]
loss: 0.221496  [64000/69635]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.172913 

Epoch 31
-------------------------------
loss: 0.093632  [    0/69635]
loss: 0.131164  [ 6400/69635]
loss: 0.098958  [12800/69635]
loss: 0.109403  [19200/69635]
loss: 0.163243  [25600/69635]
loss: 0.168047  [32000/69635]
loss: 0.092153  [38400/69635]
loss: 0.115655  [44800/69635]
loss: 0.157531  [51200/69635]
loss: 0.142385  [57600/69635]
loss: 0.172787  [64000/69635]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.157692 

Epoch 32
-------------------------------
loss: 0.139282  [    0/69635]
loss: 0.097167  [ 6400/69635]
loss: 0.071974  [12800/69635]
loss: 0.132782  [19200/69635]
loss: 1.710198  [25600/69635]
loss: 1.696799  [32000/69635]
loss: 0.278138  [38400/69635]
loss: 0.160690  [44800/69635]
loss: 0.258608  [51200/69635]
loss: 0.187380  [57600/69635]
loss: 0.157757  [64000/69635]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.209896 

Epoch 33
-------------------------------
loss: 0.092341  [    0/69635]
loss: 0.182052  [ 6400/69635]
loss: 0.178766  [12800/69635]
loss: 0.073175  [19200/69635]
loss: 0.156612  [25600/69635]
loss: 0.128037  [32000/69635]
loss: 0.081927  [38400/69635]
loss: 0.160804  [44800/69635]
loss: 0.230860  [51200/69635]
loss: 0.122714  [57600/69635]
loss: 0.148683  [64000/69635]
loss: 0.091414  [51200/70696]
loss: 0.185260  [57600/70696]
loss: 0.112894  [64000/70696]
loss: 0.045685  [70400/70696]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169644 

Epoch 14
-------------------------------
loss: 0.191829  [    0/70696]
loss: 0.131997  [ 6400/70696]
loss: 0.104266  [12800/70696]
loss: 0.076564  [19200/70696]
loss: 0.170244  [25600/70696]
loss: 0.066183  [32000/70696]
loss: 0.267294  [38400/70696]
loss: 0.171928  [44800/70696]
loss: 0.147114  [51200/70696]
loss: 0.086603  [57600/70696]
loss: 0.246249  [64000/70696]
loss: 0.159884  [70400/70696]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.176244 

Epoch 15
-------------------------------
loss: 0.160049  [    0/70696]
loss: 0.206255  [ 6400/70696]
loss: 0.239725  [12800/70696]
loss: 0.180840  [19200/70696]
loss: 0.270688  [25600/70696]
loss: 0.070730  [32000/70696]
loss: 0.223533  [38400/70696]
loss: 0.567354  [44800/70696]
loss: 0.136448  [51200/70696]
loss: 0.062659  [57600/70696]
loss: 0.130069  [64000/70696]
loss: 0.358486  [70400/70696]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.179186 

Epoch 16
-------------------------------
loss: 0.196780  [    0/70696]
loss: 0.177472  [ 6400/70696]
loss: 0.210600  [12800/70696]
loss: 0.220405  [19200/70696]
loss: 0.128579  [25600/70696]
loss: 0.144345  [32000/70696]
loss: 0.068267  [38400/70696]
loss: 0.081447  [44800/70696]
loss: 0.125031  [51200/70696]
loss: 0.196860  [57600/70696]
loss: 0.229456  [64000/70696]
loss: 0.148524  [70400/70696]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.172246 

Epoch 17
-------------------------------
loss: 0.133692  [    0/70696]
loss: 0.090449  [ 6400/70696]
loss: 0.228698  [12800/70696]
loss: 0.162690  [19200/70696]
loss: 0.219565  [25600/70696]
loss: 0.161377  [32000/70696]
loss: 0.122923  [38400/70696]
loss: 0.077978  [44800/70696]
loss: 0.149425  [51200/70696]
loss: 0.223306  [57600/70696]
loss: 0.113076  [64000/70696]
loss: 0.189764  [70400/70696]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.166457 

Epoch 18
-------------------------------
loss: 0.121069  [    0/70696]
loss: 0.088986  [ 6400/70696]
loss: 0.126453  [12800/70696]
loss: 0.119232  [19200/70696]
loss: 0.117085  [25600/70696]
loss: 0.359326  [32000/70696]
loss: 0.082549  [38400/70696]
loss: 0.161102  [44800/70696]
loss: 0.247200  [51200/70696]
loss: 0.106814  [57600/70696]
loss: 0.142801  [64000/70696]
loss: 0.100334  [70400/70696]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.167701 

Epoch 19
-------------------------------
loss: 0.071536  [    0/70696]
loss: 0.226252  [ 6400/70696]
loss: 0.137130  [12800/70696]
loss: 0.310263  [19200/70696]
loss: 0.073915  [25600/70696]
loss: 0.123444  [32000/70696]
loss: 0.216259  [38400/70696]
loss: 0.155184  [44800/70696]
loss: 0.125335  [51200/70696]
loss: 0.091944  [57600/70696]
loss: 0.237408  [64000/70696]
loss: 0.091081  [70400/70696]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.163620 

Epoch 20
-------------------------------
loss: 0.162142  [    0/70696]
loss: 0.197902  [ 6400/70696]
loss: 0.168148  [12800/70696]
loss: 0.211936  [19200/70696]
loss: 0.103786  [25600/70696]
loss: 0.123521  [32000/70696]
loss: 0.120415  [38400/70696]
loss: 0.078111  [44800/70696]
loss: 0.112705  [51200/70696]
loss: 0.112676  [57600/70696]
loss: 0.212409  [64000/70696]
loss: 0.226652  [70400/70696]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.164006 

Epoch 21
-------------------------------
loss: 0.240611  [    0/70696]
loss: 0.073364  [ 6400/70696]
loss: 0.111095  [12800/70696]
loss: 0.239022  [19200/70696]
loss: 0.119161  [25600/70696]
loss: 0.139736  [32000/70696]
loss: 0.068307  [38400/70696]
loss: 0.138387  [44800/70696]
loss: 0.085426  [51200/70696]
loss: 0.198703  [57600/70696]
loss: 0.272889  [64000/70696]
loss: 0.135624  [70400/70696]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.168586 

Epoch 22
-------------------------------
loss: 0.195797  [    0/70696]
loss: 0.103900  [ 6400/70696]
loss: 0.140816  [12800/70696]
loss: 0.178646  [19200/70696]
loss: 0.144406  [25600/70696]
loss: 0.100945  [32000/70696]
loss: 0.195458  [38400/70696]
loss: 0.097476  [44800/70696]
loss: 0.130678  [51200/70696]
loss: 0.066674  [57600/70696]
loss: 0.212209  [64000/70696]
loss: 0.114912  [70400/70696]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.190290 

Epoch 23
-------------------------------
loss: 0.092601  [    0/70696]
loss: 0.235309  [ 6400/70696]
loss: 0.072394  [12800/70696]
loss: 0.114653  [19200/70696]
loss: 0.175042  [25600/70696]
loss: 0.077608  [32000/70696]
loss: 0.096845  [38400/70696]
loss: 0.175477  [44800/70696]
loss: 0.168202  [51200/70696]
loss: 0.179025  [57600/70696]
loss: 0.173231  [64000/70696]
loss: 0.061720  [70400/70696]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.177486 

Epoch 24
-------------------------------
loss: 0.150337  [    0/70696]
loss: 0.153265  [ 6400/70696]
loss: 0.115400  [12800/70696]
loss: 0.137760  [19200/70696]
loss: 0.165460  [25600/70696]
loss: 0.149031  [32000/70696]
loss: 0.187734  [38400/70696]
loss: 0.091870  [44800/70696]
loss: 0.156368  [51200/70696]
loss: 0.139101  [57600/70696]
loss: 0.222257  [64000/70696]
loss: 0.061837  [70400/70696]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171384 

Epoch 25
-------------------------------
loss: 0.116723  [    0/70696]
loss: 0.190002  [ 6400/70696]
loss: 0.110831  [12800/70696]
loss: 0.227456  [19200/70696]
loss: 0.114248  [25600/70696]
loss: 0.109278  [32000/70696]
loss: 0.083069  [38400/70696]
loss: 0.140389  [44800/70696]
loss: 0.081896  [51200/70696]
loss: 0.139024  [57600/70696]
loss: 0.186845  [64000/70696]
loss: 0.131999  [70400/70696]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.176363 

Epoch 26
-------------------------------
loss: 0.074378  [    0/70696]
loss: 0.115422  [ 6400/70696]
loss: 0.085137  [12800/70696]
loss: 0.117624  [19200/70696]
loss: 0.202296  [25600/70696]
loss: 0.215701  [32000/70696]
loss: 0.122494  [38400/70696]
loss: 0.146161  [44800/70696]
loss: 0.116203  [51200/70696]
loss: 0.281683  [57600/70696]
loss: 0.161831  [64000/70696]
loss: 0.101659  [70400/70696]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.170640 

Epoch 27
-------------------------------
loss: 0.099132  [    0/70696]
loss: 0.137408  [ 6400/70696]
loss: 0.194806  [12800/70696]
loss: 0.238196  [19200/70696]
loss: 0.114387  [25600/70696]
loss: 0.189099  [32000/70696]
loss: 0.124257  [38400/70696]
loss: 0.149420  [44800/70696]
loss: 0.071103  [51200/70696]
loss: 0.194460  [57600/70696]
loss: 0.093785  [64000/70696]
loss: 0.192187  [70400/70696]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173081 

Epoch 28
-------------------------------
loss: 0.104220  [    0/70696]
loss: 0.208672  [ 6400/70696]
loss: 0.045395  [12800/70696]
loss: 0.089684  [19200/70696]
loss: 0.139293  [25600/70696]
loss: 0.128800  [32000/70696]
loss: 0.149405  [38400/70696]
loss: 0.130239  [44800/70696]
loss: 0.166111  [51200/70696]
loss: 0.208210  [57600/70696]
loss: 0.192013  [64000/70696]
loss: 0.121561  [70400/70696]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.171523 

Epoch 29
-------------------------------
loss: 0.168439  [    0/70696]
loss: 0.151429  [ 6400/70696]
loss: 0.146139  [12800/70696]
loss: 0.081827  [19200/70696]
loss: 0.153299  [25600/70696]
loss: 0.102509  [32000/70696]
loss: 0.113100  [38400/70696]
loss: 0.153292  [44800/70696]
loss: 0.164002  [51200/70696]
loss: 0.209194  [57600/70696]
loss: 0.156781  [64000/70696]
loss: 0.158521  [70400/70696]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.173961 

Epoch 30
-------------------------------
loss: 0.158020  [    0/70696]
loss: 0.015825  [ 6400/70696]
loss: 0.147719  [12800/70696]
loss: 0.146930  [19200/70696]
loss: 0.110813  [25600/70696]
loss: 0.084631  [32000/70696]
loss: 0.207290  [38400/70696]
loss: 0.207434  [44800/70696]
loss: 0.161015  [51200/70696]
loss: 0.100010  [57600/70696]
loss: 0.093059  [64000/70696]
loss: 0.070981  [70400/70696]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.169908 

Epoch 31
-------------------------------
loss: 0.133586  [    0/70696]
loss: 0.135294  [ 6400/70696]
loss: 0.094796  [12800/70696]
loss: 0.147596  [19200/70696]
loss: 0.097389  [25600/70696]
loss: 0.063052  [32000/70696]
loss: 0.215018  [38400/70696]
loss: 0.083972  [44800/70696]
loss: 0.091248  [51200/70696]
loss: 0.118971  [51200/71159]
loss: 0.156693  [57600/71159]
loss: 0.092057  [64000/71159]
loss: 0.080084  [70400/71159]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.146918 

Epoch 14
-------------------------------
loss: 0.084495  [    0/71159]
loss: 0.087386  [ 6400/71159]
loss: 0.090713  [12800/71159]
loss: 0.102818  [19200/71159]
loss: 0.072494  [25600/71159]
loss: 0.149798  [32000/71159]
loss: 0.091444  [38400/71159]
loss: 0.146651  [44800/71159]
loss: 0.170401  [51200/71159]
loss: 0.139300  [57600/71159]
loss: 0.143095  [64000/71159]
loss: 0.069426  [70400/71159]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.147873 

Epoch 15
-------------------------------
loss: 0.087229  [    0/71159]
loss: 0.118368  [ 6400/71159]
loss: 0.076685  [12800/71159]
loss: 0.133968  [19200/71159]
loss: 0.110431  [25600/71159]
loss: 0.098483  [32000/71159]
loss: 0.085006  [38400/71159]
loss: 0.124010  [44800/71159]
loss: 0.097421  [51200/71159]
loss: 0.119821  [57600/71159]
loss: 0.108822  [64000/71159]
loss: 0.044119  [70400/71159]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.140981 

Epoch 16
-------------------------------
loss: 0.124561  [    0/71159]
loss: 0.071680  [ 6400/71159]
loss: 0.043503  [12800/71159]
loss: 0.129589  [19200/71159]
loss: 0.081628  [25600/71159]
loss: 0.208117  [32000/71159]
loss: 0.057991  [38400/71159]
loss: 0.066450  [44800/71159]
loss: 0.112401  [51200/71159]
loss: 0.095589  [57600/71159]
loss: 0.121572  [64000/71159]
loss: 0.075511  [70400/71159]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.137579 

Epoch 17
-------------------------------
loss: 0.190054  [    0/71159]
loss: 0.176271  [ 6400/71159]
loss: 0.074656  [12800/71159]
loss: 0.032569  [19200/71159]
loss: 0.189932  [25600/71159]
loss: 0.173438  [32000/71159]
loss: 0.176281  [38400/71159]
loss: 0.092985  [44800/71159]
loss: 0.178943  [51200/71159]
loss: 0.101069  [57600/71159]
loss: 0.111578  [64000/71159]
loss: 0.201841  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.144293 

Epoch 18
-------------------------------
loss: 0.085419  [    0/71159]
loss: 0.123392  [ 6400/71159]
loss: 0.140140  [12800/71159]
loss: 0.095257  [19200/71159]
loss: 0.151039  [25600/71159]
loss: 0.074550  [32000/71159]
loss: 0.117778  [38400/71159]
loss: 0.068177  [44800/71159]
loss: 0.097737  [51200/71159]
loss: 0.171518  [57600/71159]
loss: 0.044997  [64000/71159]
loss: 0.140696  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.145910 

Epoch 19
-------------------------------
loss: 0.070796  [    0/71159]
loss: 0.139841  [ 6400/71159]
loss: 0.054736  [12800/71159]
loss: 0.105626  [19200/71159]
loss: 0.047613  [25600/71159]
loss: 0.191240  [32000/71159]
loss: 0.049215  [38400/71159]
loss: 0.052425  [44800/71159]
loss: 0.080208  [51200/71159]
loss: 0.021066  [57600/71159]
loss: 0.098246  [64000/71159]
loss: 0.035042  [70400/71159]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.142808 

Epoch 20
-------------------------------
loss: 0.042010  [    0/71159]
loss: 0.085770  [ 6400/71159]
loss: 0.133876  [12800/71159]
loss: 0.241124  [19200/71159]
loss: 0.048397  [25600/71159]
loss: 0.154704  [32000/71159]
loss: 0.109230  [38400/71159]
loss: 0.244870  [44800/71159]
loss: 0.106578  [51200/71159]
loss: 0.124331  [57600/71159]
loss: 0.113961  [64000/71159]
loss: 0.084048  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.144319 

Epoch 21
-------------------------------
loss: 0.118140  [    0/71159]
loss: 0.043359  [ 6400/71159]
loss: 0.022256  [12800/71159]
loss: 0.050877  [19200/71159]
loss: 0.055649  [25600/71159]
loss: 0.048559  [32000/71159]
loss: 0.165211  [38400/71159]
loss: 0.144530  [44800/71159]
loss: 0.262143  [51200/71159]
loss: 0.056135  [57600/71159]
loss: 0.269873  [64000/71159]
loss: 0.083130  [70400/71159]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.142022 

Epoch 22
-------------------------------
loss: 0.110471  [    0/71159]
loss: 0.108350  [ 6400/71159]
loss: 0.102000  [12800/71159]
loss: 0.141080  [19200/71159]
loss: 0.021402  [25600/71159]
loss: 0.178632  [32000/71159]
loss: 0.171906  [38400/71159]
loss: 0.151379  [44800/71159]
loss: 0.150398  [51200/71159]
loss: 0.064539  [57600/71159]
loss: 0.058107  [64000/71159]
loss: 0.092697  [70400/71159]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.145224 

Epoch 23
-------------------------------
loss: 0.138315  [    0/71159]
loss: 0.137829  [ 6400/71159]
loss: 0.206538  [12800/71159]
loss: 0.037423  [19200/71159]
loss: 0.031019  [25600/71159]
loss: 0.072025  [32000/71159]
loss: 0.121482  [38400/71159]
loss: 0.081528  [44800/71159]
loss: 0.123425  [51200/71159]
loss: 0.057842  [57600/71159]
loss: 0.118040  [64000/71159]
loss: 0.100102  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.145552 

Epoch 24
-------------------------------
loss: 0.132021  [    0/71159]
loss: 0.179159  [ 6400/71159]
loss: 0.146093  [12800/71159]
loss: 0.101830  [19200/71159]
loss: 0.209798  [25600/71159]
loss: 0.069158  [32000/71159]
loss: 0.127749  [38400/71159]
loss: 0.073355  [44800/71159]
loss: 0.139110  [51200/71159]
loss: 0.245197  [57600/71159]
loss: 0.258126  [64000/71159]
loss: 0.080798  [70400/71159]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.140353 

Epoch 25
-------------------------------
loss: 0.044509  [    0/71159]
loss: 0.118386  [ 6400/71159]
loss: 0.066998  [12800/71159]
loss: 0.106690  [19200/71159]
loss: 0.034632  [25600/71159]
loss: 0.162443  [32000/71159]
loss: 0.124714  [38400/71159]
loss: 0.046346  [44800/71159]
loss: 0.091545  [51200/71159]
loss: 0.011961  [57600/71159]
loss: 0.152027  [64000/71159]
loss: 0.068450  [70400/71159]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.144643 

Epoch 26
-------------------------------
loss: 0.120355  [    0/71159]
loss: 0.103300  [ 6400/71159]
loss: 0.180611  [12800/71159]
loss: 0.130030  [19200/71159]
loss: 0.066555  [25600/71159]
loss: 0.087573  [32000/71159]
loss: 0.173589  [38400/71159]
loss: 0.085142  [44800/71159]
loss: 0.099763  [51200/71159]
loss: 0.086362  [57600/71159]
loss: 0.077341  [64000/71159]
loss: 0.163446  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.143672 

Epoch 27
-------------------------------
loss: 0.107842  [    0/71159]
loss: 0.072565  [ 6400/71159]
loss: 0.204760  [12800/71159]
loss: 0.214696  [19200/71159]
loss: 0.074343  [25600/71159]
loss: 0.140514  [32000/71159]
loss: 0.090531  [38400/71159]
loss: 0.047957  [44800/71159]
loss: 0.171334  [51200/71159]
loss: 0.118259  [57600/71159]
loss: 0.024791  [64000/71159]
loss: 0.071692  [70400/71159]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.147540 

Epoch 28
-------------------------------
loss: 0.075849  [    0/71159]
loss: 0.129394  [ 6400/71159]
loss: 0.076167  [12800/71159]
loss: 0.065546  [19200/71159]
loss: 0.047519  [25600/71159]
loss: 0.114355  [32000/71159]
loss: 0.135534  [38400/71159]
loss: 0.065984  [44800/71159]
loss: 0.092364  [51200/71159]
loss: 0.114447  [57600/71159]
loss: 0.237519  [64000/71159]
loss: 0.097820  [70400/71159]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.142754 

Epoch 29
-------------------------------
loss: 0.100816  [    0/71159]
loss: 0.128934  [ 6400/71159]
loss: 0.039625  [12800/71159]
loss: 0.117175  [19200/71159]
loss: 0.028523  [25600/71159]
loss: 0.216486  [32000/71159]
loss: 0.138655  [38400/71159]
loss: 0.101881  [44800/71159]
loss: 0.167788  [51200/71159]
loss: 0.076640  [57600/71159]
loss: 0.073796  [64000/71159]
loss: 0.037376  [70400/71159]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.141157 

Epoch 30
-------------------------------
loss: 0.134433  [    0/71159]
loss: 0.138539  [ 6400/71159]
loss: 0.114014  [12800/71159]
loss: 0.096341  [19200/71159]
loss: 0.124159  [25600/71159]
loss: 0.034222  [32000/71159]
loss: 0.099676  [38400/71159]
loss: 0.127048  [44800/71159]
loss: 0.119704  [51200/71159]
loss: 0.080347  [57600/71159]
loss: 0.082684  [64000/71159]
loss: 0.114150  [70400/71159]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.143328 

Epoch 31
-------------------------------
loss: 0.296705  [    0/71159]
loss: 0.150127  [ 6400/71159]
loss: 0.153513  [12800/71159]
loss: 0.153674  [19200/71159]
loss: 0.189851  [25600/71159]
loss: 0.153204  [32000/71159]
loss: 0.055846  [38400/71159]
loss: 0.126765  [44800/71159]
loss: 0.144235  [51200/71159]
Epoch 18
-------------------------------
loss: 1.745202  [    0/69420]
loss: 0.153997  [ 6400/69420]
loss: 0.176779  [12800/69420]
loss: 0.163080  [19200/69420]
loss: 0.231968  [25600/69420]
loss: 0.160606  [32000/69420]
loss: 0.253313  [38400/69420]
loss: 0.125073  [44800/69420]
loss: 0.142838  [51200/69420]
loss: 0.081354  [57600/69420]
loss: 0.204238  [64000/69420]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.204098 

Epoch 19
-------------------------------
loss: 0.178408  [    0/69420]
loss: 0.103390  [ 6400/69420]
loss: 0.206220  [12800/69420]
loss: 0.252527  [19200/69420]
loss: 0.191912  [25600/69420]
loss: 0.217374  [32000/69420]
loss: 0.216688  [38400/69420]
loss: 0.240350  [44800/69420]
loss: 0.180194  [51200/69420]
loss: 0.198497  [57600/69420]
loss: 0.382585  [64000/69420]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.211209 

Epoch 20
-------------------------------
loss: 0.223407  [    0/69420]
loss: 0.176185  [ 6400/69420]
loss: 0.196465  [12800/69420]
loss: 0.192001  [19200/69420]
loss: 0.218764  [25600/69420]
loss: 0.183613  [32000/69420]
loss: 0.225135  [38400/69420]
loss: 0.268611  [44800/69420]
loss: 0.128358  [51200/69420]
loss: 0.218974  [57600/69420]
loss: 0.215035  [64000/69420]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.203086 

Epoch 21
-------------------------------
loss: 0.181358  [    0/69420]
loss: 0.222075  [ 6400/69420]
loss: 0.195500  [12800/69420]
loss: 0.152976  [19200/69420]
loss: 0.256414  [25600/69420]
loss: 0.182080  [32000/69420]
loss: 0.209794  [38400/69420]
loss: 0.218175  [44800/69420]
loss: 0.196882  [51200/69420]
loss: 0.214018  [57600/69420]
loss: 0.206559  [64000/69420]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.199331 

Epoch 22
-------------------------------
loss: 0.267625  [    0/69420]
loss: 0.223012  [ 6400/69420]
loss: 0.246130  [12800/69420]
loss: 0.277667  [19200/69420]
loss: 0.111598  [25600/69420]
loss: 0.176828  [32000/69420]
loss: 0.159940  [38400/69420]
loss: 0.211348  [44800/69420]
loss: 0.279160  [51200/69420]
loss: 0.090732  [57600/69420]
loss: 0.209574  [64000/69420]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.214989 

Epoch 23
-------------------------------
loss: 0.121365  [    0/69420]
loss: 0.190195  [ 6400/69420]
loss: 0.219034  [12800/69420]
loss: 0.125239  [19200/69420]
loss: 0.138453  [25600/69420]
loss: 0.252860  [32000/69420]
loss: 0.117746  [38400/69420]
loss: 0.207899  [44800/69420]
loss: 0.183585  [51200/69420]
loss: 0.126876  [57600/69420]
loss: 0.266961  [64000/69420]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.199520 

Epoch 24
-------------------------------
loss: 0.208717  [    0/69420]
loss: 0.247211  [ 6400/69420]
loss: 0.196221  [12800/69420]
loss: 0.066205  [19200/69420]
loss: 0.131955  [25600/69420]
loss: 0.161409  [32000/69420]
loss: 0.234235  [38400/69420]
loss: 0.218386  [44800/69420]
loss: 0.093009  [51200/69420]
loss: 0.210111  [57600/69420]
loss: 0.333429  [64000/69420]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.230043 

Epoch 25
-------------------------------
loss: 0.203191  [    0/69420]
loss: 0.187099  [ 6400/69420]
loss: 0.335091  [12800/69420]
loss: 0.120828  [19200/69420]
loss: 0.311669  [25600/69420]
loss: 0.203051  [32000/69420]
loss: 0.186295  [38400/69420]
loss: 0.336549  [44800/69420]
loss: 0.211394  [51200/69420]
loss: 0.210252  [57600/69420]
loss: 0.116226  [64000/69420]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.200057 

Epoch 26
-------------------------------
loss: 0.156975  [    0/69420]
loss: 0.192373  [ 6400/69420]
loss: 0.231339  [12800/69420]
loss: 0.118205  [19200/69420]
loss: 0.194461  [25600/69420]
loss: 0.166165  [32000/69420]
loss: 0.152033  [38400/69420]
loss: 0.288368  [44800/69420]
loss: 0.074228  [51200/69420]
loss: 0.123165  [57600/69420]
loss: 0.158061  [64000/69420]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.221343 

Epoch 27
-------------------------------
loss: 0.144799  [    0/69420]
loss: 0.235645  [ 6400/69420]
loss: 0.149651  [12800/69420]
loss: 0.177143  [19200/69420]
loss: 0.250149  [25600/69420]
loss: 0.169992  [32000/69420]
loss: 0.254323  [38400/69420]
loss: 0.283378  [44800/69420]
loss: 0.120333  [51200/69420]
loss: 0.262576  [57600/69420]
loss: 0.145148  [64000/69420]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.201516 

Epoch 28
-------------------------------
loss: 0.240194  [    0/69420]
loss: 0.218398  [ 6400/69420]
loss: 0.289529  [12800/69420]
loss: 0.227460  [19200/69420]
loss: 0.164557  [25600/69420]
loss: 0.116239  [32000/69420]
loss: 0.226388  [38400/69420]
loss: 0.248979  [44800/69420]
loss: 0.213311  [51200/69420]
loss: 0.159015  [57600/69420]
loss: 0.136401  [64000/69420]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.214003 

Epoch 29
-------------------------------
loss: 0.228697  [    0/69420]
loss: 0.235078  [ 6400/69420]
loss: 0.114829  [12800/69420]
loss: 0.202644  [19200/69420]
loss: 0.200701  [25600/69420]
loss: 0.074995  [32000/69420]
loss: 0.221352  [38400/69420]
loss: 0.199222  [44800/69420]
loss: 0.190599  [51200/69420]
loss: 0.183758  [57600/69420]
loss: 0.200847  [64000/69420]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.196630 

Epoch 30
-------------------------------
loss: 0.280642  [    0/69420]
loss: 0.092714  [ 6400/69420]
loss: 0.095799  [12800/69420]
loss: 0.286633  [19200/69420]
loss: 0.197760  [25600/69420]
loss: 0.136951  [32000/69420]
loss: 0.118612  [38400/69420]
loss: 0.195036  [44800/69420]
loss: 0.086686  [51200/69420]
loss: 0.189977  [57600/69420]
loss: 0.260248  [64000/69420]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.195411 

Epoch 31
-------------------------------
loss: 0.286348  [    0/69420]
loss: 0.184673  [ 6400/69420]
loss: 0.251714  [12800/69420]
loss: 0.096355  [19200/69420]
loss: 0.163138  [25600/69420]
loss: 0.347975  [32000/69420]
loss: 0.178630  [38400/69420]
loss: 0.183060  [44800/69420]
loss: 0.393132  [51200/69420]
loss: 0.237634  [57600/69420]
loss: 0.119529  [64000/69420]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.200541 

Epoch 32
-------------------------------
loss: 1.705239  [    0/69420]
loss: 0.262153  [ 6400/69420]
loss: 0.167119  [12800/69420]
loss: 0.201376  [19200/69420]
loss: 0.210524  [25600/69420]
loss: 0.320649  [32000/69420]
loss: 0.205267  [38400/69420]
loss: 0.160465  [44800/69420]
loss: 0.171886  [51200/69420]
loss: 0.245984  [57600/69420]
loss: 0.200655  [64000/69420]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.234749 

Epoch 33
-------------------------------
loss: 0.147433  [    0/69420]
loss: 0.108985  [ 6400/69420]
loss: 0.181215  [12800/69420]
loss: 0.260420  [19200/69420]
loss: 0.252873  [25600/69420]
loss: 0.213030  [32000/69420]
loss: 0.282037  [38400/69420]
loss: 0.167377  [44800/69420]
loss: 0.212379  [51200/69420]
loss: 0.246734  [57600/69420]
loss: 0.201792  [64000/69420]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.205630 

Epoch 34
-------------------------------
loss: 0.282068  [    0/69420]
loss: 0.246166  [ 6400/69420]
loss: 0.312619  [12800/69420]
loss: 0.182540  [19200/69420]
loss: 0.223011  [25600/69420]
loss: 0.181989  [32000/69420]
loss: 0.157202  [38400/69420]
loss: 0.163045  [44800/69420]
loss: 0.361734  [51200/69420]
loss: 0.384456  [57600/69420]
loss: 0.347311  [64000/69420]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.196846 

Epoch 35
-------------------------------
loss: 0.318908  [    0/69420]
loss: 0.215133  [ 6400/69420]
loss: 0.162698  [12800/69420]
loss: 0.223204  [19200/69420]
loss: 0.219096  [25600/69420]
loss: 0.201060  [32000/69420]
loss: 0.181358  [38400/69420]
loss: 0.186349  [44800/69420]
loss: 0.224291  [51200/69420]
loss: 0.182185  [57600/69420]
loss: 0.219411  [64000/69420]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.222156 

Epoch 36
-------------------------------
loss: 0.240669  [    0/69420]
loss: 0.192460  [ 6400/69420]
loss: 0.154414  [12800/69420]
loss: 0.134813  [19200/69420]
loss: 0.159438  [25600/69420]
loss: 0.257480  [32000/69420]
loss: 0.311779  [38400/69420]
loss: 0.206567  [44800/69420]
loss: 0.184263  [51200/69420]
loss: 0.131129  [57600/69420]
loss: 0.171018  [64000/69420]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.198513 

Epoch 37
-------------------------------
loss: 0.157547  [    0/69420]
loss: 0.187005  [ 6400/69420]
loss: 0.154729  [12800/69420]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.200126 

Epoch 6
-------------------------------
loss: 0.293224  [    0/69548]
loss: 0.230838  [ 6400/69548]
loss: 0.175927  [12800/69548]
loss: 0.146701  [19200/69548]
loss: 0.227989  [25600/69548]
loss: 0.391749  [32000/69548]
loss: 0.143663  [38400/69548]
loss: 0.136130  [44800/69548]
loss: 0.229557  [51200/69548]
loss: 0.053723  [57600/69548]
loss: 0.180852  [64000/69548]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.195417 

Epoch 7
-------------------------------
loss: 0.128141  [    0/69548]
loss: 0.101580  [ 6400/69548]
loss: 0.269503  [12800/69548]
loss: 0.304963  [19200/69548]
loss: 0.185069  [25600/69548]
loss: 0.150110  [32000/69548]
loss: 0.221426  [38400/69548]
loss: 0.185180  [44800/69548]
loss: 0.235822  [51200/69548]
loss: 0.208519  [57600/69548]
loss: 0.189315  [64000/69548]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.196452 

Epoch 8
-------------------------------
loss: 0.076123  [    0/69548]
loss: 0.309299  [ 6400/69548]
loss: 0.150430  [12800/69548]
loss: 0.153412  [19200/69548]
loss: 0.150948  [25600/69548]
loss: 0.235150  [32000/69548]
loss: 0.266334  [38400/69548]
loss: 0.130582  [44800/69548]
loss: 0.116076  [51200/69548]
loss: 0.161725  [57600/69548]
loss: 0.174448  [64000/69548]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.198023 

Epoch 9
-------------------------------
loss: 0.184396  [    0/69548]
loss: 0.201265  [ 6400/69548]
loss: 0.141550  [12800/69548]
loss: 0.187054  [19200/69548]
loss: 0.117477  [25600/69548]
loss: 0.097552  [32000/69548]
loss: 0.181685  [38400/69548]
loss: 0.153629  [44800/69548]
loss: 0.177154  [51200/69548]
loss: 0.231108  [57600/69548]
loss: 0.162513  [64000/69548]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.200410 

Epoch 10
-------------------------------
loss: 0.200763  [    0/69548]
loss: 0.214389  [ 6400/69548]
loss: 0.233526  [12800/69548]
loss: 0.193970  [19200/69548]
loss: 0.251756  [25600/69548]
loss: 0.261894  [32000/69548]
loss: 0.202446  [38400/69548]
loss: 0.237036  [44800/69548]
loss: 0.195373  [51200/69548]
loss: 0.124034  [57600/69548]
loss: 0.176809  [64000/69548]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.188965 

Epoch 11
-------------------------------
loss: 0.135315  [    0/69548]
loss: 0.225016  [ 6400/69548]
loss: 0.332934  [12800/69548]
loss: 0.211191  [19200/69548]
loss: 0.149486  [25600/69548]
loss: 0.125309  [32000/69548]
loss: 0.188946  [38400/69548]
loss: 0.173459  [44800/69548]
loss: 0.170514  [51200/69548]
loss: 0.179127  [57600/69548]
loss: 0.082984  [64000/69548]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.184667 

Epoch 12
-------------------------------
loss: 0.165549  [    0/69548]
loss: 0.231504  [ 6400/69548]
loss: 0.185009  [12800/69548]
loss: 0.154825  [19200/69548]
loss: 0.196300  [25600/69548]
loss: 0.289390  [32000/69548]
loss: 0.170785  [38400/69548]
loss: 0.078351  [44800/69548]
loss: 0.167198  [51200/69548]
loss: 0.104537  [57600/69548]
loss: 0.154809  [64000/69548]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.189504 

Epoch 13
-------------------------------
loss: 0.079252  [    0/69548]
loss: 0.084192  [ 6400/69548]
loss: 0.273011  [12800/69548]
loss: 0.139835  [19200/69548]
loss: 0.173435  [25600/69548]
loss: 0.175561  [32000/69548]
loss: 0.161792  [38400/69548]
loss: 0.303040  [44800/69548]
loss: 0.246482  [51200/69548]
loss: 0.147066  [57600/69548]
loss: 0.201432  [64000/69548]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.198573 

Epoch 14
-------------------------------
loss: 0.196171  [    0/69548]
loss: 0.146706  [ 6400/69548]
loss: 0.148540  [12800/69548]
loss: 0.117716  [19200/69548]
loss: 0.214618  [25600/69548]
loss: 0.110406  [32000/69548]
loss: 0.256573  [38400/69548]
loss: 0.348214  [44800/69548]
loss: 0.113859  [51200/69548]
loss: 0.176355  [57600/69548]
loss: 0.121526  [64000/69548]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.187192 

Epoch 15
-------------------------------
loss: 0.057686  [    0/69548]
loss: 0.229600  [ 6400/69548]
loss: 0.202806  [12800/69548]
loss: 0.160305  [19200/69548]
loss: 0.151038  [25600/69548]
loss: 0.186499  [32000/69548]
loss: 0.188926  [38400/69548]
loss: 0.193607  [44800/69548]
loss: 0.140418  [51200/69548]
loss: 0.125309  [57600/69548]
loss: 0.107966  [64000/69548]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.186658 

Epoch 16
-------------------------------
loss: 0.143625  [    0/69548]
loss: 0.171891  [ 6400/69548]
loss: 0.306374  [12800/69548]
loss: 0.119703  [19200/69548]
loss: 0.128564  [25600/69548]
loss: 0.215114  [32000/69548]
loss: 0.124971  [38400/69548]
loss: 0.154608  [44800/69548]
loss: 0.228831  [51200/69548]
loss: 0.116787  [57600/69548]
loss: 0.124238  [64000/69548]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.185089 

Epoch 17
-------------------------------
loss: 0.090631  [    0/69548]
loss: 0.226233  [ 6400/69548]
loss: 0.160538  [12800/69548]
loss: 0.169158  [19200/69548]
loss: 0.191260  [25600/69548]
loss: 0.153484  [32000/69548]
loss: 0.300694  [38400/69548]
loss: 0.191699  [44800/69548]
loss: 0.165929  [51200/69548]
loss: 0.219614  [57600/69548]
loss: 0.167724  [64000/69548]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.185035 

Epoch 18
-------------------------------
loss: 0.195365  [    0/69548]
loss: 0.186135  [ 6400/69548]
loss: 0.305771  [12800/69548]
loss: 0.117001  [19200/69548]
loss: 0.338044  [25600/69548]
loss: 0.244763  [32000/69548]
loss: 0.201176  [38400/69548]
loss: 0.191945  [44800/69548]
loss: 0.204177  [51200/69548]
loss: 0.157669  [57600/69548]
loss: 0.199923  [64000/69548]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.190306 

Epoch 19
-------------------------------
loss: 0.082205  [    0/69548]
loss: 0.144605  [ 6400/69548]
loss: 0.328406  [12800/69548]
loss: 0.203692  [19200/69548]
loss: 0.213366  [25600/69548]
loss: 0.147707  [32000/69548]
loss: 0.226006  [38400/69548]
loss: 0.405001  [44800/69548]
loss: 0.425750  [51200/69548]
loss: 0.275195  [57600/69548]
loss: 0.160402  [64000/69548]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.179761 

Epoch 20
-------------------------------
loss: 0.130401  [    0/69548]
loss: 0.129297  [ 6400/69548]
loss: 0.143960  [12800/69548]
loss: 0.203929  [19200/69548]
loss: 0.160143  [25600/69548]
loss: 0.248854  [32000/69548]
loss: 0.262420  [38400/69548]
loss: 0.104942  [44800/69548]
loss: 0.166843  [51200/69548]
loss: 0.239486  [57600/69548]
loss: 0.221853  [64000/69548]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.188724 

Epoch 21
-------------------------------
loss: 0.048437  [    0/69548]
loss: 0.117003  [ 6400/69548]
loss: 0.171342  [12800/69548]
loss: 0.138605  [19200/69548]
loss: 0.096897  [25600/69548]
loss: 0.352364  [32000/69548]
loss: 0.208933  [38400/69548]
loss: 0.063323  [44800/69548]
loss: 0.143623  [51200/69548]
loss: 0.341674  [57600/69548]
loss: 0.159571  [64000/69548]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.184036 

Epoch 22
-------------------------------
loss: 0.160685  [    0/69548]
loss: 0.120150  [ 6400/69548]
loss: 0.179317  [12800/69548]
loss: 0.155765  [19200/69548]
loss: 0.127228  [25600/69548]
loss: 0.136013  [32000/69548]
loss: 0.089318  [38400/69548]
loss: 0.120570  [44800/69548]
loss: 0.082003  [51200/69548]
loss: 0.190564  [57600/69548]
loss: 0.079883  [64000/69548]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.179803 

Epoch 23
-------------------------------
loss: 0.120327  [    0/69548]
loss: 0.099075  [ 6400/69548]
loss: 0.150445  [12800/69548]
loss: 0.162827  [19200/69548]
loss: 0.075057  [25600/69548]
loss: 0.133610  [32000/69548]
loss: 0.275203  [38400/69548]
loss: 0.298500  [44800/69548]
loss: 0.169149  [51200/69548]
loss: 0.100500  [57600/69548]
loss: 0.353764  [64000/69548]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.184538 

Epoch 24
-------------------------------
loss: 0.146568  [    0/69548]
loss: 0.099888  [ 6400/69548]
loss: 0.158663  [12800/69548]
loss: 0.127306  [19200/69548]
loss: 0.172175  [25600/69548]
loss: 0.121960  [32000/69548]
loss: 0.338276  [38400/69548]
loss: 0.185740  [44800/69548]
loss: 0.100151  [51200/69548]
loss: 0.301616  [57600/69548]
loss: 0.272482  [64000/69548]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.184000 

Epoch 25
-------------------------------
loss: 0.367305  [    0/69548]
loss: 0.184641  [ 6400/69548]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.137381 

Epoch 17
-------------------------------
loss: 0.081226  [    0/71502]
loss: 0.092490  [ 6400/71502]
loss: 0.120778  [12800/71502]
loss: 0.078673  [19200/71502]
loss: 0.267382  [25600/71502]
loss: 0.065004  [32000/71502]
loss: 0.043494  [38400/71502]
loss: 0.186128  [44800/71502]
loss: 0.044448  [51200/71502]
loss: 0.099741  [57600/71502]
loss: 0.123770  [64000/71502]
loss: 0.050482  [70400/71502]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.182680 

Epoch 18
-------------------------------
loss: 0.133303  [    0/71502]
loss: 0.058603  [ 6400/71502]
loss: 0.066919  [12800/71502]
loss: 0.067859  [19200/71502]
loss: 0.020231  [25600/71502]
loss: 0.036110  [32000/71502]
loss: 0.163091  [38400/71502]
loss: 0.083608  [44800/71502]
loss: 0.043183  [51200/71502]
loss: 0.083276  [57600/71502]
loss: 0.013154  [64000/71502]
loss: 0.106780  [70400/71502]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.175905 

Epoch 19
-------------------------------
loss: 0.079630  [    0/71502]
loss: 0.106455  [ 6400/71502]
loss: 0.139779  [12800/71502]
loss: 0.030823  [19200/71502]
loss: 0.053727  [25600/71502]
loss: 0.093068  [32000/71502]
loss: 0.038530  [38400/71502]
loss: 0.046951  [44800/71502]
loss: 1.682113  [51200/71502]
loss: 0.057312  [57600/71502]
loss: 0.070147  [64000/71502]
loss: 0.085266  [70400/71502]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.188224 

Epoch 20
-------------------------------
loss: 0.069406  [    0/71502]
loss: 0.057137  [ 6400/71502]
loss: 0.142177  [12800/71502]
loss: 0.074568  [19200/71502]
loss: 0.163366  [25600/71502]
loss: 0.038531  [32000/71502]
loss: 0.073025  [38400/71502]
loss: 0.020858  [44800/71502]
loss: 0.108564  [51200/71502]
loss: 0.081270  [57600/71502]
loss: 0.032555  [64000/71502]
loss: 0.054136  [70400/71502]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.222338 

Epoch 21
-------------------------------
loss: 0.119998  [    0/71502]
loss: 0.028210  [ 6400/71502]
loss: 0.170081  [12800/71502]
loss: 0.181770  [19200/71502]
loss: 0.098114  [25600/71502]
loss: 0.079068  [32000/71502]
loss: 0.016829  [38400/71502]
loss: 1.588527  [44800/71502]
loss: 0.116251  [51200/71502]
loss: 0.130656  [57600/71502]
loss: 0.158096  [64000/71502]
loss: 0.153321  [70400/71502]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.192367 

Epoch 22
-------------------------------
loss: 0.092098  [    0/71502]
loss: 0.137971  [ 6400/71502]
loss: 0.114356  [12800/71502]
loss: 0.177384  [19200/71502]
loss: 0.065531  [25600/71502]
loss: 0.100921  [32000/71502]
loss: 0.031143  [38400/71502]
loss: 0.094747  [44800/71502]
loss: 0.092523  [51200/71502]
loss: 0.052933  [57600/71502]
loss: 0.044740  [64000/71502]
loss: 0.044542  [70400/71502]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.176806 

Epoch 23
-------------------------------
loss: 0.067350  [    0/71502]
loss: 0.036478  [ 6400/71502]
loss: 0.030088  [12800/71502]
loss: 0.022632  [19200/71502]
loss: 0.183361  [25600/71502]
loss: 0.075174  [32000/71502]
loss: 0.020069  [38400/71502]
loss: 0.108609  [44800/71502]
loss: 0.103826  [51200/71502]
loss: 0.150053  [57600/71502]
loss: 0.038049  [64000/71502]
loss: 0.174834  [70400/71502]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.172378 

Epoch 24
-------------------------------
loss: 0.174081  [    0/71502]
loss: 0.044554  [ 6400/71502]
loss: 0.111521  [12800/71502]
loss: 0.081780  [19200/71502]
loss: 0.078998  [25600/71502]
loss: 0.039395  [32000/71502]
loss: 0.212267  [38400/71502]
loss: 0.087261  [44800/71502]
loss: 0.054181  [51200/71502]
loss: 0.057487  [57600/71502]
loss: 0.037574  [64000/71502]
loss: 0.097787  [70400/71502]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.173956 

Epoch 25
-------------------------------
loss: 0.023142  [    0/71502]
loss: 0.092070  [ 6400/71502]
loss: 0.046146  [12800/71502]
loss: 0.090839  [19200/71502]
loss: 0.268323  [25600/71502]
loss: 0.143846  [32000/71502]
loss: 0.155726  [38400/71502]
loss: 0.073165  [44800/71502]
loss: 0.068202  [51200/71502]
loss: 0.177629  [57600/71502]
loss: 0.078524  [64000/71502]
loss: 0.036666  [70400/71502]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.176855 

Epoch 26
-------------------------------
loss: 0.099535  [    0/71502]
loss: 0.045741  [ 6400/71502]
loss: 0.071295  [12800/71502]
loss: 0.084653  [19200/71502]
loss: 0.210601  [25600/71502]
loss: 0.073042  [32000/71502]
loss: 0.047831  [38400/71502]
loss: 0.028903  [44800/71502]
loss: 0.042954  [51200/71502]
loss: 0.203485  [57600/71502]
loss: 0.091338  [64000/71502]
loss: 0.088406  [70400/71502]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.178638 

Epoch 27
-------------------------------
loss: 0.036565  [    0/71502]
loss: 0.110142  [ 6400/71502]
loss: 0.077410  [12800/71502]
loss: 0.084575  [19200/71502]
loss: 0.065791  [25600/71502]
loss: 0.186159  [32000/71502]
loss: 0.049538  [38400/71502]
loss: 0.032127  [44800/71502]
loss: 0.011857  [51200/71502]
loss: 0.257148  [57600/71502]
loss: 0.099443  [64000/71502]
loss: 0.055026  [70400/71502]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.191944 

Epoch 28
-------------------------------
loss: 0.079774  [    0/71502]
loss: 0.101048  [ 6400/71502]
loss: 0.128205  [12800/71502]
loss: 1.581501  [19200/71502]
loss: 0.068811  [25600/71502]
loss: 0.075479  [32000/71502]
loss: 0.045243  [38400/71502]
loss: 0.061680  [44800/71502]
loss: 0.049224  [51200/71502]
loss: 0.099555  [57600/71502]
loss: 0.074037  [64000/71502]
loss: 0.021654  [70400/71502]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.170114 

Epoch 29
-------------------------------
loss: 0.170501  [    0/71502]
loss: 0.017515  [ 6400/71502]
loss: 0.025460  [12800/71502]
loss: 0.123634  [19200/71502]
loss: 0.115936  [25600/71502]
loss: 0.048112  [32000/71502]
loss: 0.077770  [38400/71502]
loss: 0.119522  [44800/71502]
loss: 0.064667  [51200/71502]
loss: 0.065298  [57600/71502]
loss: 0.048146  [64000/71502]
loss: 0.038042  [70400/71502]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.180625 

Epoch 30
-------------------------------
loss: 0.080208  [    0/71502]
loss: 0.094985  [ 6400/71502]
loss: 0.057336  [12800/71502]
loss: 0.056891  [19200/71502]
loss: 0.159617  [25600/71502]
loss: 0.042272  [32000/71502]
loss: 0.045447  [38400/71502]
loss: 0.091472  [44800/71502]
loss: 0.053487  [51200/71502]
loss: 0.098802  [57600/71502]
loss: 0.008554  [64000/71502]
loss: 0.111290  [70400/71502]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.175343 

Epoch 31
-------------------------------
loss: 0.056425  [    0/71502]
loss: 0.258385  [ 6400/71502]
loss: 0.033375  [12800/71502]
loss: 0.042942  [19200/71502]
loss: 0.150136  [25600/71502]
loss: 0.046209  [32000/71502]
loss: 0.071358  [38400/71502]
loss: 0.090627  [44800/71502]
loss: 0.049928  [51200/71502]
loss: 0.043668  [57600/71502]
loss: 0.085418  [64000/71502]
loss: 0.698357  [70400/71502]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.126759 

Epoch 32
-------------------------------
loss: 0.143994  [    0/71502]
loss: 0.009486  [ 6400/71502]
loss: 0.044240  [12800/71502]
loss: 0.038157  [19200/71502]
loss: 0.120267  [25600/71502]
loss: 0.116771  [32000/71502]
loss: 0.087656  [38400/71502]
loss: 0.018495  [44800/71502]
loss: 0.097105  [51200/71502]
loss: 0.120004  [57600/71502]
loss: 0.031475  [64000/71502]
loss: 0.018476  [70400/71502]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.130655 

Epoch 33
-------------------------------
loss: 0.113170  [    0/71502]
loss: 0.084826  [ 6400/71502]
loss: 0.093353  [12800/71502]
loss: 0.054819  [19200/71502]
loss: 0.059426  [25600/71502]
loss: 0.176024  [32000/71502]
loss: 0.156351  [38400/71502]
loss: 0.042542  [44800/71502]
loss: 0.038586  [51200/71502]
loss: 0.161343  [57600/71502]
loss: 0.060207  [64000/71502]
loss: 0.053843  [70400/71502]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.123500 

Epoch 34
-------------------------------
loss: 0.032238  [    0/71502]
loss: 0.056449  [ 6400/71502]
loss: 0.061400  [12800/71502]
loss: 0.097892  [19200/71502]
loss: 0.080347  [25600/71502]
loss: 0.078425  [32000/71502]
loss: 0.022293  [38400/71502]
loss: 0.025339  [44800/71502]
loss: 0.068686  [51200/71502]
loss: 0.028741  [57600/71502]
loss: 0.049881  [64000/71502]
loss: 0.073351  [70400/71502]
loss: 0.108875  [19200/72227]
loss: 0.111858  [25600/72227]
loss: 0.008290  [32000/72227]
loss: 0.016650  [38400/72227]
loss: 0.066945  [44800/72227]
loss: 0.181218  [51200/72227]
loss: 0.043623  [57600/72227]
loss: 0.145904  [64000/72227]
loss: 0.015035  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.072816 

Epoch 21
-------------------------------
loss: 0.035470  [    0/72227]
loss: 0.014112  [ 6400/72227]
loss: 0.059336  [12800/72227]
loss: 0.039819  [19200/72227]
loss: 0.032422  [25600/72227]
loss: 0.072068  [32000/72227]
loss: 0.026944  [38400/72227]
loss: 0.020802  [44800/72227]
loss: 0.013709  [51200/72227]
loss: 0.025774  [57600/72227]
loss: 0.006050  [64000/72227]
loss: 0.021959  [70400/72227]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076401 

Epoch 22
-------------------------------
loss: 0.048042  [    0/72227]
loss: 0.132677  [ 6400/72227]
loss: 0.007817  [12800/72227]
loss: 0.028872  [19200/72227]
loss: 0.040202  [25600/72227]
loss: 0.009891  [32000/72227]
loss: 0.049172  [38400/72227]
loss: 0.030158  [44800/72227]
loss: 0.012773  [51200/72227]
loss: 0.073174  [57600/72227]
loss: 0.012813  [64000/72227]
loss: 0.081424  [70400/72227]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.070846 

Epoch 23
-------------------------------
loss: 0.067212  [    0/72227]
loss: 0.020252  [ 6400/72227]
loss: 0.110863  [12800/72227]
loss: 0.029364  [19200/72227]
loss: 0.042394  [25600/72227]
loss: 0.036716  [32000/72227]
loss: 0.024415  [38400/72227]
loss: 0.017101  [44800/72227]
loss: 0.030975  [51200/72227]
loss: 0.003729  [57600/72227]
loss: 0.031228  [64000/72227]
loss: 0.048515  [70400/72227]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.074948 

Epoch 24
-------------------------------
loss: 0.013093  [    0/72227]
loss: 0.024508  [ 6400/72227]
loss: 0.081350  [12800/72227]
loss: 0.027751  [19200/72227]
loss: 0.003845  [25600/72227]
loss: 0.043006  [32000/72227]
loss: 0.054395  [38400/72227]
loss: 0.015452  [44800/72227]
loss: 0.023380  [51200/72227]
loss: 0.014066  [57600/72227]
loss: 0.017304  [64000/72227]
loss: 0.034828  [70400/72227]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072708 

Epoch 25
-------------------------------
loss: 0.006621  [    0/72227]
loss: 0.015055  [ 6400/72227]
loss: 0.118979  [12800/72227]
loss: 0.014140  [19200/72227]
loss: 0.037590  [25600/72227]
loss: 0.034855  [32000/72227]
loss: 0.066192  [38400/72227]
loss: 0.080001  [44800/72227]
loss: 0.004499  [51200/72227]
loss: 0.010063  [57600/72227]
loss: 0.107146  [64000/72227]
loss: 0.024308  [70400/72227]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076795 

Epoch 26
-------------------------------
loss: 0.016533  [    0/72227]
loss: 0.029304  [ 6400/72227]
loss: 0.006256  [12800/72227]
loss: 0.044315  [19200/72227]
loss: 0.060566  [25600/72227]
loss: 0.039627  [32000/72227]
loss: 0.010844  [38400/72227]
loss: 0.044467  [44800/72227]
loss: 0.044453  [51200/72227]
loss: 0.075096  [57600/72227]
loss: 0.021732  [64000/72227]
loss: 0.139369  [70400/72227]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.083101 

Epoch 27
-------------------------------
loss: 0.057414  [    0/72227]
loss: 0.004054  [ 6400/72227]
loss: 0.025584  [12800/72227]
loss: 0.001142  [19200/72227]
loss: 0.029981  [25600/72227]
loss: 0.076559  [32000/72227]
loss: 0.066242  [38400/72227]
loss: 0.037260  [44800/72227]
loss: 0.041434  [51200/72227]
loss: 0.049199  [57600/72227]
loss: 0.030340  [64000/72227]
loss: 0.007089  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.096289 

Epoch 28
-------------------------------
loss: 0.011699  [    0/72227]
loss: 0.116142  [ 6400/72227]
loss: 0.063008  [12800/72227]
loss: 0.017423  [19200/72227]
loss: 0.024563  [25600/72227]
loss: 0.050449  [32000/72227]
loss: 0.043513  [38400/72227]
loss: 0.039033  [44800/72227]
loss: 0.052356  [51200/72227]
loss: 0.013476  [57600/72227]
loss: 0.014336  [64000/72227]
loss: 0.087474  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.087308 

Epoch 29
-------------------------------
loss: 0.028636  [    0/72227]
loss: 0.020157  [ 6400/72227]
loss: 0.120536  [12800/72227]
loss: 0.042763  [19200/72227]
loss: 0.068827  [25600/72227]
loss: 0.049522  [32000/72227]
loss: 0.036249  [38400/72227]
loss: 0.021778  [44800/72227]
loss: 0.077577  [51200/72227]
loss: 0.018253  [57600/72227]
loss: 0.106498  [64000/72227]
loss: 0.006623  [70400/72227]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.080273 

Epoch 30
-------------------------------
loss: 0.097627  [    0/72227]
loss: 0.011944  [ 6400/72227]
loss: 0.019637  [12800/72227]
loss: 0.005219  [19200/72227]
loss: 0.024887  [25600/72227]
loss: 0.012160  [32000/72227]
loss: 0.010768  [38400/72227]
loss: 0.018124  [44800/72227]
loss: 0.077623  [51200/72227]
loss: 0.009439  [57600/72227]
loss: 0.001735  [64000/72227]
loss: 0.010074  [70400/72227]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.075022 

Epoch 31
-------------------------------
loss: 0.015689  [    0/72227]
loss: 0.034355  [ 6400/72227]
loss: 0.017150  [12800/72227]
loss: 0.029450  [19200/72227]
loss: 0.006812  [25600/72227]
loss: 0.008622  [32000/72227]
loss: 0.026172  [38400/72227]
loss: 0.027827  [44800/72227]
loss: 0.030520  [51200/72227]
loss: 0.017242  [57600/72227]
loss: 0.026850  [64000/72227]
loss: 0.096761  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.087240 

Epoch 32
-------------------------------
loss: 0.007600  [    0/72227]
loss: 0.055062  [ 6400/72227]
loss: 0.001344  [12800/72227]
loss: 0.005652  [19200/72227]
loss: 0.025108  [25600/72227]
loss: 0.002988  [32000/72227]
loss: 0.018775  [38400/72227]
loss: 0.027455  [44800/72227]
loss: 0.019884  [51200/72227]
loss: 0.294145  [57600/72227]
loss: 0.006070  [64000/72227]
loss: 0.030939  [70400/72227]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.084663 

Epoch 33
-------------------------------
loss: 0.005725  [    0/72227]
loss: 0.020842  [ 6400/72227]
loss: 0.009392  [12800/72227]
loss: 0.013203  [19200/72227]
loss: 0.087427  [25600/72227]
loss: 0.007883  [32000/72227]
loss: 0.024229  [38400/72227]
loss: 0.071215  [44800/72227]
loss: 0.034542  [51200/72227]
loss: 0.054714  [57600/72227]
loss: 0.006352  [64000/72227]
loss: 0.058554  [70400/72227]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.074501 

Epoch 34
-------------------------------
loss: 0.081828  [    0/72227]
loss: 0.135998  [ 6400/72227]
loss: 0.088403  [12800/72227]
loss: 0.111330  [19200/72227]
loss: 0.083880  [25600/72227]
loss: 0.049837  [32000/72227]
loss: 0.024512  [38400/72227]
loss: 0.015071  [44800/72227]
loss: 0.045810  [51200/72227]
loss: 0.051168  [57600/72227]
loss: 0.049172  [64000/72227]
loss: 0.146641  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.082455 

Epoch 35
-------------------------------
loss: 0.023303  [    0/72227]
loss: 0.020822  [ 6400/72227]
loss: 0.002628  [12800/72227]
loss: 0.036222  [19200/72227]
loss: 0.005702  [25600/72227]
loss: 0.041383  [32000/72227]
loss: 0.049029  [38400/72227]
loss: 0.005675  [44800/72227]
loss: 0.052275  [51200/72227]
loss: 0.055365  [57600/72227]
loss: 0.063141  [64000/72227]
loss: 0.016313  [70400/72227]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.086766 

Epoch 36
-------------------------------
loss: 0.008941  [    0/72227]
loss: 0.013643  [ 6400/72227]
loss: 0.125601  [12800/72227]
loss: 0.039663  [19200/72227]
loss: 0.093671  [25600/72227]
loss: 0.012946  [32000/72227]
loss: 0.053295  [38400/72227]
loss: 0.046429  [44800/72227]
loss: 0.005310  [51200/72227]
loss: 0.012655  [57600/72227]
loss: 0.022104  [64000/72227]
loss: 0.013466  [70400/72227]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.092244 

Epoch 37
-------------------------------
loss: 0.042945  [    0/72227]
loss: 0.028814  [ 6400/72227]
loss: 0.014529  [12800/72227]
loss: 0.063471  [19200/72227]
loss: 0.021401  [25600/72227]
loss: 0.023234  [32000/72227]
loss: 0.007301  [38400/72227]
loss: 0.055223  [44800/72227]
loss: 0.057982  [51200/72227]
loss: 0.003323  [57600/72227]
loss: 0.012693  [64000/72227]
loss: 0.047294  [70400/72227]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.076407 

Epoch 38
-------------------------------
loss: 0.021928  [    0/72227]
loss: 0.066572  [ 6400/72227]
loss: 0.008292  [12800/72227]
loss: 0.059659  [19200/72227]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157967 

Epoch 17
-------------------------------
loss: 0.146709  [    0/70685]
loss: 0.119956  [ 6400/70685]
loss: 0.131196  [12800/70685]
loss: 0.153989  [19200/70685]
loss: 0.202631  [25600/70685]
loss: 0.223934  [32000/70685]
loss: 0.201552  [38400/70685]
loss: 0.146501  [44800/70685]
loss: 0.141920  [51200/70685]
loss: 0.240865  [57600/70685]
loss: 0.173872  [64000/70685]
loss: 0.247162  [70400/70685]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.152519 

Epoch 18
-------------------------------
loss: 0.223505  [    0/70685]
loss: 0.132680  [ 6400/70685]
loss: 0.163011  [12800/70685]
loss: 0.094431  [19200/70685]
loss: 0.239503  [25600/70685]
loss: 0.117463  [32000/70685]
loss: 0.136508  [38400/70685]
loss: 1.749817  [44800/70685]
loss: 0.077154  [51200/70685]
loss: 0.106649  [57600/70685]
loss: 0.134815  [64000/70685]
loss: 0.194210  [70400/70685]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153241 

Epoch 19
-------------------------------
loss: 0.141711  [    0/70685]
loss: 0.123288  [ 6400/70685]
loss: 0.109730  [12800/70685]
loss: 0.100444  [19200/70685]
loss: 0.320691  [25600/70685]
loss: 0.228997  [32000/70685]
loss: 0.108706  [38400/70685]
loss: 0.266838  [44800/70685]
loss: 0.111891  [51200/70685]
loss: 0.167807  [57600/70685]
loss: 0.109916  [64000/70685]
loss: 0.247735  [70400/70685]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.164199 

Epoch 20
-------------------------------
loss: 0.145479  [    0/70685]
loss: 0.131678  [ 6400/70685]
loss: 0.081626  [12800/70685]
loss: 0.099440  [19200/70685]
loss: 0.199257  [25600/70685]
loss: 0.160663  [32000/70685]
loss: 0.089565  [38400/70685]
loss: 0.117693  [44800/70685]
loss: 0.094464  [51200/70685]
loss: 0.164985  [57600/70685]
loss: 0.229612  [64000/70685]
loss: 0.149389  [70400/70685]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.163014 

Epoch 21
-------------------------------
loss: 0.175831  [    0/70685]
loss: 0.248698  [ 6400/70685]
loss: 0.088343  [12800/70685]
loss: 0.213874  [19200/70685]
loss: 0.257778  [25600/70685]
loss: 0.169187  [32000/70685]
loss: 0.142265  [38400/70685]
loss: 0.158743  [44800/70685]
loss: 0.086078  [51200/70685]
loss: 0.103253  [57600/70685]
loss: 0.198921  [64000/70685]
loss: 0.128101  [70400/70685]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.156399 

Epoch 22
-------------------------------
loss: 0.161001  [    0/70685]
loss: 0.128700  [ 6400/70685]
loss: 0.089008  [12800/70685]
loss: 0.182241  [19200/70685]
loss: 0.183772  [25600/70685]
loss: 0.199839  [32000/70685]
loss: 0.201730  [38400/70685]
loss: 0.063135  [44800/70685]
loss: 0.312966  [51200/70685]
loss: 0.170082  [57600/70685]
loss: 0.143174  [64000/70685]
loss: 0.169685  [70400/70685]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.157259 

Epoch 23
-------------------------------
loss: 0.092143  [    0/70685]
loss: 0.172166  [ 6400/70685]
loss: 0.086875  [12800/70685]
loss: 0.193228  [19200/70685]
loss: 0.116543  [25600/70685]
loss: 0.174598  [32000/70685]
loss: 0.163241  [38400/70685]
loss: 0.108086  [44800/70685]
loss: 0.047211  [51200/70685]
loss: 0.148661  [57600/70685]
loss: 0.171401  [64000/70685]
loss: 0.149568  [70400/70685]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.167799 

Epoch 24
-------------------------------
loss: 0.172096  [    0/70685]
loss: 0.139652  [ 6400/70685]
loss: 0.216325  [12800/70685]
loss: 0.095582  [19200/70685]
loss: 0.152859  [25600/70685]
loss: 0.048837  [32000/70685]
loss: 0.187311  [38400/70685]
loss: 0.114853  [44800/70685]
loss: 0.172805  [51200/70685]
loss: 0.210924  [57600/70685]
loss: 0.134819  [64000/70685]
loss: 0.100786  [70400/70685]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.158746 

Epoch 25
-------------------------------
loss: 0.187050  [    0/70685]
loss: 0.165570  [ 6400/70685]
loss: 0.153333  [12800/70685]
loss: 0.187079  [19200/70685]
loss: 0.090034  [25600/70685]
loss: 0.302889  [32000/70685]
loss: 0.182270  [38400/70685]
loss: 0.120408  [44800/70685]
loss: 0.168093  [51200/70685]
loss: 0.063366  [57600/70685]
loss: 0.217828  [64000/70685]
loss: 0.220770  [70400/70685]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.154112 

Epoch 26
-------------------------------
loss: 0.121637  [    0/70685]
loss: 0.091906  [ 6400/70685]
loss: 0.124554  [12800/70685]
loss: 0.229731  [19200/70685]
loss: 0.185802  [25600/70685]
loss: 0.108304  [32000/70685]
loss: 0.150465  [38400/70685]
loss: 0.142622  [44800/70685]
loss: 0.115011  [51200/70685]
loss: 0.085858  [57600/70685]
loss: 0.199711  [64000/70685]
loss: 0.188971  [70400/70685]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.158926 

Epoch 27
-------------------------------
loss: 0.150324  [    0/70685]
loss: 0.145855  [ 6400/70685]
loss: 0.059049  [12800/70685]
loss: 0.047859  [19200/70685]
loss: 0.147017  [25600/70685]
loss: 0.084543  [32000/70685]
loss: 0.140794  [38400/70685]
loss: 0.131929  [44800/70685]
loss: 0.172227  [51200/70685]
loss: 0.140431  [57600/70685]
loss: 0.301065  [64000/70685]
loss: 0.179078  [70400/70685]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.156381 

Epoch 28
-------------------------------
loss: 0.109966  [    0/70685]
loss: 0.147989  [ 6400/70685]
loss: 0.069228  [12800/70685]
loss: 0.187080  [19200/70685]
loss: 0.105975  [25600/70685]
loss: 0.223259  [32000/70685]
loss: 0.172586  [38400/70685]
loss: 0.111680  [44800/70685]
loss: 0.168653  [51200/70685]
loss: 0.137012  [57600/70685]
loss: 0.151795  [64000/70685]
loss: 0.118838  [70400/70685]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.185674 

Epoch 29
-------------------------------
loss: 0.196801  [    0/70685]
loss: 0.065033  [ 6400/70685]
loss: 0.127550  [12800/70685]
loss: 0.139661  [19200/70685]
loss: 0.046009  [25600/70685]
loss: 0.098497  [32000/70685]
loss: 0.213316  [38400/70685]
loss: 0.189182  [44800/70685]
loss: 0.173018  [51200/70685]
loss: 0.165482  [57600/70685]
loss: 0.113476  [64000/70685]
loss: 0.300099  [70400/70685]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.168462 

Epoch 30
-------------------------------
loss: 0.128733  [    0/70685]
loss: 0.191511  [ 6400/70685]
loss: 0.118491  [12800/70685]
loss: 0.122346  [19200/70685]
loss: 0.166938  [25600/70685]
loss: 0.201560  [32000/70685]
loss: 0.121459  [38400/70685]
loss: 0.067392  [44800/70685]
loss: 0.122840  [51200/70685]
loss: 0.201547  [57600/70685]
loss: 0.188919  [64000/70685]
loss: 0.149080  [70400/70685]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.166235 

Epoch 31
-------------------------------
loss: 0.130191  [    0/70685]
loss: 0.104047  [ 6400/70685]
loss: 0.240306  [12800/70685]
loss: 0.075972  [19200/70685]
loss: 0.082460  [25600/70685]
loss: 0.263905  [32000/70685]
loss: 0.117998  [38400/70685]
loss: 0.329399  [44800/70685]
loss: 0.046306  [51200/70685]
loss: 0.199033  [57600/70685]
loss: 0.120684  [64000/70685]
loss: 0.128992  [70400/70685]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.158662 

Epoch 32
-------------------------------
loss: 0.186184  [    0/70685]
loss: 0.191779  [ 6400/70685]
loss: 0.132217  [12800/70685]
loss: 0.102826  [19200/70685]
loss: 0.170844  [25600/70685]
loss: 0.237261  [32000/70685]
loss: 0.059579  [38400/70685]
loss: 0.046568  [44800/70685]
loss: 0.083013  [51200/70685]
loss: 0.089347  [57600/70685]
loss: 0.231597  [64000/70685]
loss: 0.072447  [70400/70685]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.162748 

Epoch 33
-------------------------------
loss: 0.080645  [    0/70685]
loss: 0.117939  [ 6400/70685]
loss: 0.202042  [12800/70685]
loss: 0.124523  [19200/70685]
loss: 0.112054  [25600/70685]
loss: 0.102125  [32000/70685]
loss: 0.093377  [38400/70685]
loss: 0.147293  [44800/70685]
loss: 0.146030  [51200/70685]
loss: 0.117849  [57600/70685]
loss: 0.067875  [64000/70685]
loss: 0.261784  [70400/70685]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.152156 

Epoch 34
-------------------------------
loss: 0.091197  [    0/70685]
loss: 0.093755  [ 6400/70685]
loss: 0.076886  [12800/70685]
loss: 0.246488  [19200/70685]
loss: 0.181005  [25600/70685]
loss: 0.197654  [32000/70685]
loss: 0.144867  [38400/70685]
loss: 0.099604  [44800/70685]
loss: 0.167856  [51200/70685]
loss: 0.108279  [57600/70685]
loss: 0.122764  [64000/70685]
loss: 0.346484  [70400/70685]
loss: 0.095268  [57600/71616]
loss: 0.022640  [64000/71616]
loss: 0.002276  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.075749 

Epoch 32
-------------------------------
loss: 0.014456  [    0/71616]
loss: 0.015648  [ 6400/71616]
loss: 0.079833  [12800/71616]
loss: 0.018312  [19200/71616]
loss: 0.020717  [25600/71616]
loss: 0.020538  [32000/71616]
loss: 0.012597  [38400/71616]
loss: 0.232706  [44800/71616]
loss: 0.052334  [51200/71616]
loss: 0.055940  [57600/71616]
loss: 0.030612  [64000/71616]
loss: 0.046579  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071357 

Epoch 33
-------------------------------
loss: 0.020348  [    0/71616]
loss: 0.008223  [ 6400/71616]
loss: 0.007773  [12800/71616]
loss: 0.002160  [19200/71616]
loss: 0.003734  [25600/71616]
loss: 0.009425  [32000/71616]
loss: 0.014791  [38400/71616]
loss: 0.027080  [44800/71616]
loss: 0.013827  [51200/71616]
loss: 0.072047  [57600/71616]
loss: 0.116111  [64000/71616]
loss: 0.049426  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070420 

Epoch 34
-------------------------------
loss: 0.002517  [    0/71616]
loss: 0.015447  [ 6400/71616]
loss: 0.025135  [12800/71616]
loss: 0.015608  [19200/71616]
loss: 0.018825  [25600/71616]
loss: 0.020353  [32000/71616]
loss: 0.005618  [38400/71616]
loss: 0.010006  [44800/71616]
loss: 0.004708  [51200/71616]
loss: 0.071503  [57600/71616]
loss: 0.006177  [64000/71616]
loss: 0.004934  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.060552 

Epoch 35
-------------------------------
loss: 0.026165  [    0/71616]
loss: 0.072666  [ 6400/71616]
loss: 0.003404  [12800/71616]
loss: 0.071173  [19200/71616]
loss: 0.017127  [25600/71616]
loss: 0.000386  [32000/71616]
loss: 0.016416  [38400/71616]
loss: 0.192920  [44800/71616]
loss: 0.004818  [51200/71616]
loss: 0.048674  [57600/71616]
loss: 0.039295  [64000/71616]
loss: 0.034826  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.075850 

Epoch 36
-------------------------------
loss: 0.002929  [    0/71616]
loss: 0.010906  [ 6400/71616]
loss: 0.007035  [12800/71616]
loss: 0.018369  [19200/71616]
loss: 0.030148  [25600/71616]
loss: 0.020271  [32000/71616]
loss: 0.049592  [38400/71616]
loss: 0.035308  [44800/71616]
loss: 0.030257  [51200/71616]
loss: 0.074338  [57600/71616]
loss: 0.075679  [64000/71616]
loss: 0.072448  [70400/71616]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.073496 

Epoch 37
-------------------------------
loss: 0.009167  [    0/71616]
loss: 0.000734  [ 6400/71616]
loss: 0.121621  [12800/71616]
loss: 0.012172  [19200/71616]
loss: 0.004178  [25600/71616]
loss: 0.087622  [32000/71616]
loss: 0.030398  [38400/71616]
loss: 0.040996  [44800/71616]
loss: 0.066766  [51200/71616]
loss: 0.012776  [57600/71616]
loss: 0.141720  [64000/71616]
loss: 0.012367  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073757 

Epoch 38
-------------------------------
loss: 0.015366  [    0/71616]
loss: 0.031758  [ 6400/71616]
loss: 0.025983  [12800/71616]
loss: 0.026646  [19200/71616]
loss: 0.089372  [25600/71616]
loss: 0.020918  [32000/71616]
loss: 0.160562  [38400/71616]
loss: 0.002434  [44800/71616]
loss: 0.102370  [51200/71616]
loss: 0.069436  [57600/71616]
loss: 0.009664  [64000/71616]
loss: 0.024600  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.083502 

Epoch 39
-------------------------------
loss: 0.044821  [    0/71616]
loss: 0.012444  [ 6400/71616]
loss: 0.011192  [12800/71616]
loss: 0.068143  [19200/71616]
loss: 0.009865  [25600/71616]
loss: 0.037295  [32000/71616]
loss: 0.033625  [38400/71616]
loss: 0.004916  [44800/71616]
loss: 0.003064  [51200/71616]
loss: 0.024144  [57600/71616]
loss: 0.025765  [64000/71616]
loss: 0.001163  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.086096 

Epoch 40
-------------------------------
loss: 0.077862  [    0/71616]
loss: 0.006138  [ 6400/71616]
loss: 0.001865  [12800/71616]
loss: 0.032271  [19200/71616]
loss: 0.020037  [25600/71616]
loss: 0.016485  [32000/71616]
loss: 0.004803  [38400/71616]
loss: 0.031791  [44800/71616]
loss: 0.090009  [51200/71616]
loss: 0.068313  [57600/71616]
loss: 0.025978  [64000/71616]
loss: 0.068523  [70400/71616]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.075433 

Epoch 41
-------------------------------
loss: 0.004035  [    0/71616]
loss: 0.023434  [ 6400/71616]
loss: 0.006932  [12800/71616]
loss: 0.011450  [19200/71616]
loss: 0.079342  [25600/71616]
loss: 0.014929  [32000/71616]
loss: 0.018564  [38400/71616]
loss: 0.002212  [44800/71616]
loss: 0.046970  [51200/71616]
loss: 0.007873  [57600/71616]
loss: 0.058957  [64000/71616]
loss: 0.052774  [70400/71616]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.081017 

Epoch 42
-------------------------------
loss: 0.045729  [    0/71616]
loss: 0.019117  [ 6400/71616]
loss: 0.047203  [12800/71616]
loss: 0.056597  [19200/71616]
loss: 0.025287  [25600/71616]
loss: 0.007941  [32000/71616]
loss: 0.010046  [38400/71616]
loss: 0.073882  [44800/71616]
loss: 0.027590  [51200/71616]
loss: 0.005797  [57600/71616]
loss: 0.073257  [64000/71616]
loss: 0.010940  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.075070 

Epoch 43
-------------------------------
loss: 0.027555  [    0/71616]
loss: 0.025990  [ 6400/71616]
loss: 0.020014  [12800/71616]
loss: 0.011617  [19200/71616]
loss: 0.023692  [25600/71616]
loss: 0.063389  [32000/71616]
loss: 0.026167  [38400/71616]
loss: 0.173629  [44800/71616]
loss: 0.026396  [51200/71616]
loss: 0.024808  [57600/71616]
loss: 0.012367  [64000/71616]
loss: 0.129404  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.085076 

Epoch 44
-------------------------------
loss: 0.000819  [    0/71616]
loss: 0.086416  [ 6400/71616]
loss: 0.010481  [12800/71616]
loss: 0.022253  [19200/71616]
loss: 0.046114  [25600/71616]
loss: 0.023673  [32000/71616]
loss: 0.060893  [38400/71616]
loss: 0.059498  [44800/71616]
loss: 0.032121  [51200/71616]
loss: 0.015662  [57600/71616]
loss: 0.077303  [64000/71616]
loss: 0.005625  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.090431 

Epoch 45
-------------------------------
loss: 0.019776  [    0/71616]
loss: 0.054183  [ 6400/71616]
loss: 0.089082  [12800/71616]
loss: 0.043614  [19200/71616]
loss: 0.013344  [25600/71616]
loss: 0.043293  [32000/71616]
loss: 0.052999  [38400/71616]
loss: 0.015657  [44800/71616]
loss: 0.002278  [51200/71616]
loss: 0.087949  [57600/71616]
loss: 0.059292  [64000/71616]
loss: 0.142153  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.079160 

Epoch 46
-------------------------------
loss: 0.052073  [    0/71616]
loss: 0.003594  [ 6400/71616]
loss: 0.019174  [12800/71616]
loss: 0.041062  [19200/71616]
loss: 0.067468  [25600/71616]
loss: 0.041479  [32000/71616]
loss: 0.024980  [38400/71616]
loss: 0.015264  [44800/71616]
loss: 0.002670  [51200/71616]
loss: 0.020605  [57600/71616]
loss: 0.041363  [64000/71616]
loss: 0.004392  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.075756 

Epoch 47
-------------------------------
loss: 0.011357  [    0/71616]
loss: 0.003693  [ 6400/71616]
loss: 0.027850  [12800/71616]
loss: 0.026771  [19200/71616]
loss: 0.062586  [25600/71616]
loss: 0.001044  [32000/71616]
loss: 0.003485  [38400/71616]
loss: 0.004757  [44800/71616]
loss: 0.006531  [51200/71616]
loss: 0.040055  [57600/71616]
loss: 0.009164  [64000/71616]
loss: 0.095994  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076125 

Epoch 48
-------------------------------
loss: 0.010913  [    0/71616]
loss: 0.017167  [ 6400/71616]
loss: 0.018352  [12800/71616]
loss: 0.011923  [19200/71616]
loss: 0.025348  [25600/71616]
loss: 0.008184  [32000/71616]
loss: 0.018559  [38400/71616]
loss: 0.041702  [44800/71616]
loss: 0.057156  [51200/71616]
loss: 0.032466  [57600/71616]
loss: 0.023483  [64000/71616]
loss: 0.032784  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.091959 

Epoch 49
-------------------------------
loss: 0.013366  [    0/71616]
loss: 0.002975  [ 6400/71616]
loss: 0.038412  [12800/71616]
loss: 0.008327  [19200/71616]
loss: 0.001928  [25600/71616]
loss: 0.024309  [32000/71616]
loss: 0.020910  [38400/71616]
loss: 0.030702  [44800/71616]
loss: 0.002274  [51200/71616]
loss: 0.013412  [57600/71616]
loss: 0.212293  [    0/69806]
loss: 0.336146  [ 6400/69806]
loss: 0.254782  [12800/69806]
loss: 0.086708  [19200/69806]
loss: 0.179694  [25600/69806]
loss: 0.295514  [32000/69806]
loss: 0.085890  [38400/69806]
loss: 0.268913  [44800/69806]
loss: 0.129510  [51200/69806]
loss: 0.212262  [57600/69806]
loss: 0.296401  [64000/69806]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.215690 

Epoch 19
-------------------------------
loss: 0.257629  [    0/69806]
loss: 0.273744  [ 6400/69806]
loss: 0.215837  [12800/69806]
loss: 0.154891  [19200/69806]
loss: 0.178502  [25600/69806]
loss: 0.109829  [32000/69806]
loss: 0.145914  [38400/69806]
loss: 0.313000  [44800/69806]
loss: 0.255626  [51200/69806]
loss: 0.175293  [57600/69806]
loss: 0.240523  [64000/69806]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.200946 

Epoch 20
-------------------------------
loss: 0.160213  [    0/69806]
loss: 0.148337  [ 6400/69806]
loss: 0.207629  [12800/69806]
loss: 0.137913  [19200/69806]
loss: 0.176756  [25600/69806]
loss: 0.258165  [32000/69806]
loss: 0.094530  [38400/69806]
loss: 0.069668  [44800/69806]
loss: 0.073197  [51200/69806]
loss: 0.102414  [57600/69806]
loss: 0.250169  [64000/69806]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.194389 

Epoch 21
-------------------------------
loss: 0.142768  [    0/69806]
loss: 0.161013  [ 6400/69806]
loss: 0.134746  [12800/69806]
loss: 0.210001  [19200/69806]
loss: 0.141248  [25600/69806]
loss: 0.417687  [32000/69806]
loss: 0.206081  [38400/69806]
loss: 0.197776  [44800/69806]
loss: 0.150449  [51200/69806]
loss: 0.238619  [57600/69806]
loss: 0.124935  [64000/69806]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.199585 

Epoch 22
-------------------------------
loss: 0.175170  [    0/69806]
loss: 0.214456  [ 6400/69806]
loss: 0.136410  [12800/69806]
loss: 0.152608  [19200/69806]
loss: 0.148281  [25600/69806]
loss: 0.138309  [32000/69806]
loss: 0.256692  [38400/69806]
loss: 0.114774  [44800/69806]
loss: 0.237903  [51200/69806]
loss: 0.233148  [57600/69806]
loss: 0.110385  [64000/69806]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.202436 

Epoch 23
-------------------------------
loss: 0.133846  [    0/69806]
loss: 0.211878  [ 6400/69806]
loss: 0.282428  [12800/69806]
loss: 0.236666  [19200/69806]
loss: 0.184077  [25600/69806]
loss: 0.136570  [32000/69806]
loss: 0.229171  [38400/69806]
loss: 0.291137  [44800/69806]
loss: 0.205566  [51200/69806]
loss: 0.121516  [57600/69806]
loss: 0.168105  [64000/69806]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.203672 

Epoch 24
-------------------------------
loss: 0.119883  [    0/69806]
loss: 0.219309  [ 6400/69806]
loss: 0.097530  [12800/69806]
loss: 0.229532  [19200/69806]
loss: 0.199362  [25600/69806]
loss: 0.151285  [32000/69806]
loss: 0.086797  [38400/69806]
loss: 0.170375  [44800/69806]
loss: 0.128678  [51200/69806]
loss: 0.205861  [57600/69806]
loss: 0.164820  [64000/69806]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.211856 

Epoch 25
-------------------------------
loss: 0.134787  [    0/69806]
loss: 0.181127  [ 6400/69806]
loss: 0.271424  [12800/69806]
loss: 0.123999  [19200/69806]
loss: 0.161784  [25600/69806]
loss: 0.147402  [32000/69806]
loss: 0.141471  [38400/69806]
loss: 0.143856  [44800/69806]
loss: 0.188841  [51200/69806]
loss: 0.190704  [57600/69806]
loss: 0.235409  [64000/69806]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.221969 

Epoch 26
-------------------------------
loss: 0.142420  [    0/69806]
loss: 0.148454  [ 6400/69806]
loss: 0.185506  [12800/69806]
loss: 0.346379  [19200/69806]
loss: 0.151164  [25600/69806]
loss: 0.443562  [32000/69806]
loss: 0.152878  [38400/69806]
loss: 0.186641  [44800/69806]
loss: 0.180276  [51200/69806]
loss: 0.192448  [57600/69806]
loss: 0.209252  [64000/69806]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.199185 

Epoch 27
-------------------------------
loss: 0.151409  [    0/69806]
loss: 0.182049  [ 6400/69806]
loss: 0.103039  [12800/69806]
loss: 0.531702  [19200/69806]
loss: 0.161475  [25600/69806]
loss: 0.238406  [32000/69806]
loss: 0.172327  [38400/69806]
loss: 0.192484  [44800/69806]
loss: 0.117198  [51200/69806]
loss: 0.091557  [57600/69806]
loss: 0.235731  [64000/69806]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.230748 

Epoch 28
-------------------------------
loss: 0.219521  [    0/69806]
loss: 0.192277  [ 6400/69806]
loss: 0.241547  [12800/69806]
loss: 0.184632  [19200/69806]
loss: 0.115640  [25600/69806]
loss: 0.170103  [32000/69806]
loss: 0.140300  [38400/69806]
loss: 0.170009  [44800/69806]
loss: 0.138751  [51200/69806]
loss: 0.177968  [57600/69806]
loss: 0.275742  [64000/69806]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.210647 

Epoch 29
-------------------------------
loss: 0.215593  [    0/69806]
loss: 0.226805  [ 6400/69806]
loss: 0.218745  [12800/69806]
loss: 0.137370  [19200/69806]
loss: 0.184210  [25600/69806]
loss: 0.249411  [32000/69806]
loss: 0.153443  [38400/69806]
loss: 0.133942  [44800/69806]
loss: 0.232786  [51200/69806]
loss: 0.161655  [57600/69806]
loss: 0.280736  [64000/69806]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.194815 

Epoch 30
-------------------------------
loss: 0.254699  [    0/69806]
loss: 0.129933  [ 6400/69806]
loss: 0.156049  [12800/69806]
loss: 0.254654  [19200/69806]
loss: 0.215407  [25600/69806]
loss: 0.148070  [32000/69806]
loss: 0.205293  [38400/69806]
loss: 0.121082  [44800/69806]
loss: 0.148501  [51200/69806]
loss: 0.125766  [57600/69806]
loss: 0.273797  [64000/69806]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.204575 

Epoch 31
-------------------------------
loss: 0.187663  [    0/69806]
loss: 0.138483  [ 6400/69806]
loss: 0.122684  [12800/69806]
loss: 0.159198  [19200/69806]
loss: 0.192827  [25600/69806]
loss: 0.419290  [32000/69806]
loss: 0.255104  [38400/69806]
loss: 0.106757  [44800/69806]
loss: 0.171235  [51200/69806]
loss: 0.129997  [57600/69806]
loss: 0.376975  [64000/69806]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.209137 

Epoch 32
-------------------------------
loss: 0.183395  [    0/69806]
loss: 0.076779  [ 6400/69806]
loss: 0.158167  [12800/69806]
loss: 0.188603  [19200/69806]
loss: 0.108542  [25600/69806]
loss: 0.204699  [32000/69806]
loss: 0.184329  [38400/69806]
loss: 0.132396  [44800/69806]
loss: 0.110362  [51200/69806]
loss: 0.137640  [57600/69806]
loss: 0.141204  [64000/69806]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.196430 

Epoch 33
-------------------------------
loss: 0.180311  [    0/69806]
loss: 0.205451  [ 6400/69806]
loss: 0.194989  [12800/69806]
loss: 0.173024  [19200/69806]
loss: 0.253576  [25600/69806]
loss: 0.195249  [32000/69806]
loss: 0.109167  [38400/69806]
loss: 0.140385  [44800/69806]
loss: 0.194452  [51200/69806]
loss: 0.128541  [57600/69806]
loss: 0.195244  [64000/69806]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.226259 

Epoch 34
-------------------------------
loss: 0.149281  [    0/69806]
loss: 0.149989  [ 6400/69806]
loss: 0.172624  [12800/69806]
loss: 0.149050  [19200/69806]
loss: 0.169623  [25600/69806]
loss: 0.209163  [32000/69806]
loss: 0.174882  [38400/69806]
loss: 0.134645  [44800/69806]
loss: 0.158348  [51200/69806]
loss: 0.248824  [57600/69806]
loss: 0.216941  [64000/69806]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.202194 

Epoch 35
-------------------------------
loss: 0.143748  [    0/69806]
loss: 0.114871  [ 6400/69806]
loss: 0.136591  [12800/69806]
loss: 0.098438  [19200/69806]
loss: 0.154631  [25600/69806]
loss: 0.132489  [32000/69806]
loss: 0.099013  [38400/69806]
loss: 0.153969  [44800/69806]
loss: 0.204121  [51200/69806]
loss: 0.097961  [57600/69806]
loss: 0.331928  [64000/69806]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.206050 

Epoch 36
-------------------------------
loss: 0.180817  [    0/69806]
loss: 0.182847  [ 6400/69806]
loss: 0.290272  [12800/69806]
loss: 0.215473  [19200/69806]
loss: 0.126131  [25600/69806]
loss: 0.246670  [32000/69806]
loss: 0.303984  [38400/69806]
loss: 0.261522  [44800/69806]
loss: 0.123967  [51200/69806]
loss: 0.306149  [57600/69806]
loss: 0.158540  [64000/69806]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.197182 

Epoch 37
-------------------------------
loss: 0.232120  [    0/69806]
loss: 0.142372  [ 6400/69806]
loss: 0.197714  [12800/69806]
loss: 0.073697  [19200/69806]
loss: 0.131107  [25600/69806]
2022/09/20 16:07:07 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.061302  [12800/70932]
loss: 0.087533  [19200/70932]
loss: 0.099458  [25600/70932]
loss: 0.128533  [32000/70932]
loss: 0.138957  [38400/70932]
loss: 0.185366  [44800/70932]
loss: 0.092611  [51200/70932]
loss: 0.159199  [57600/70932]
loss: 0.162061  [64000/70932]
loss: 0.200528  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.159839 

Epoch 21
-------------------------------
loss: 0.112131  [    0/70932]
loss: 0.144896  [ 6400/70932]
loss: 0.222021  [12800/70932]
loss: 0.105770  [19200/70932]
loss: 0.184399  [25600/70932]
loss: 0.159324  [32000/70932]
loss: 0.112842  [38400/70932]
loss: 0.154443  [44800/70932]
loss: 0.103580  [51200/70932]
loss: 0.184088  [57600/70932]
loss: 0.269129  [64000/70932]
loss: 0.113532  [70400/70932]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.181446 

Epoch 22
-------------------------------
loss: 0.110295  [    0/70932]
loss: 0.221471  [ 6400/70932]
loss: 0.074894  [12800/70932]
loss: 0.202465  [19200/70932]
loss: 0.091334  [25600/70932]
loss: 0.076887  [32000/70932]
loss: 0.068851  [38400/70932]
loss: 0.150719  [44800/70932]
loss: 0.164880  [51200/70932]
loss: 0.191954  [57600/70932]
loss: 0.223599  [64000/70932]
loss: 0.060191  [70400/70932]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.158954 

Epoch 23
-------------------------------
loss: 0.133810  [    0/70932]
loss: 0.191180  [ 6400/70932]
loss: 0.098740  [12800/70932]
loss: 0.077996  [19200/70932]
loss: 0.119146  [25600/70932]
loss: 0.134488  [32000/70932]
loss: 0.146742  [38400/70932]
loss: 0.161136  [44800/70932]
loss: 0.114185  [51200/70932]
loss: 0.071061  [57600/70932]
loss: 0.113292  [64000/70932]
loss: 0.145261  [70400/70932]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.156471 

Epoch 24
-------------------------------
loss: 0.131747  [    0/70932]
loss: 0.236804  [ 6400/70932]
loss: 0.102200  [12800/70932]
loss: 0.139307  [19200/70932]
loss: 0.189876  [25600/70932]
loss: 0.120383  [32000/70932]
loss: 0.229745  [38400/70932]
loss: 0.087145  [44800/70932]
loss: 0.220304  [51200/70932]
loss: 0.129781  [57600/70932]
loss: 0.161956  [64000/70932]
loss: 0.087220  [70400/70932]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.165829 

Epoch 25
-------------------------------
loss: 0.150869  [    0/70932]
loss: 0.131462  [ 6400/70932]
loss: 0.304677  [12800/70932]
loss: 0.151499  [19200/70932]
loss: 0.056294  [25600/70932]
loss: 0.272838  [32000/70932]
loss: 0.115582  [38400/70932]
loss: 0.131761  [44800/70932]
loss: 0.083218  [51200/70932]
loss: 0.116023  [57600/70932]
loss: 0.235076  [64000/70932]
loss: 0.088969  [70400/70932]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.180743 

Epoch 26
-------------------------------
loss: 0.147687  [    0/70932]
loss: 0.205542  [ 6400/70932]
loss: 0.128726  [12800/70932]
loss: 0.114779  [19200/70932]
loss: 0.091183  [25600/70932]
loss: 0.205728  [32000/70932]
loss: 0.141995  [38400/70932]
loss: 0.170860  [44800/70932]
loss: 0.100276  [51200/70932]
loss: 0.089467  [57600/70932]
loss: 0.094553  [64000/70932]
loss: 0.166986  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.161741 

Epoch 27
-------------------------------
loss: 0.286924  [    0/70932]
loss: 0.255485  [ 6400/70932]
loss: 0.022358  [12800/70932]
loss: 0.082554  [19200/70932]
loss: 0.135336  [25600/70932]
loss: 0.075787  [32000/70932]
loss: 0.112137  [38400/70932]
loss: 0.087637  [44800/70932]
loss: 0.142652  [51200/70932]
loss: 0.091966  [57600/70932]
loss: 0.098069  [64000/70932]
loss: 0.146921  [70400/70932]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.159752 

Epoch 28
-------------------------------
loss: 0.118211  [    0/70932]
loss: 0.071740  [ 6400/70932]
loss: 0.148498  [12800/70932]
loss: 1.677757  [19200/70932]
loss: 0.155232  [25600/70932]
loss: 0.085388  [32000/70932]
loss: 0.132502  [38400/70932]
loss: 0.051954  [44800/70932]
loss: 0.104793  [51200/70932]
loss: 0.074029  [57600/70932]
loss: 0.235076  [64000/70932]
loss: 0.219470  [70400/70932]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.173698 

Epoch 29
-------------------------------
loss: 0.095808  [    0/70932]
loss: 0.141207  [ 6400/70932]
loss: 0.091407  [12800/70932]
loss: 0.107531  [19200/70932]
loss: 0.254428  [25600/70932]
loss: 0.136792  [32000/70932]
loss: 0.126618  [38400/70932]
loss: 0.041802  [44800/70932]
loss: 0.144679  [51200/70932]
loss: 0.088710  [57600/70932]
loss: 0.099006  [64000/70932]
loss: 0.079341  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.168652 

Epoch 30
-------------------------------
loss: 0.110832  [    0/70932]
loss: 0.136202  [ 6400/70932]
loss: 0.153114  [12800/70932]
loss: 0.144388  [19200/70932]
loss: 0.049663  [25600/70932]
loss: 0.108441  [32000/70932]
loss: 0.094489  [38400/70932]
loss: 0.127423  [44800/70932]
loss: 0.175360  [51200/70932]
loss: 0.128536  [57600/70932]
loss: 0.149445  [64000/70932]
loss: 0.161476  [70400/70932]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.180567 

Epoch 31
-------------------------------
loss: 0.185722  [    0/70932]
loss: 0.187394  [ 6400/70932]
loss: 0.102627  [12800/70932]
loss: 0.199587  [19200/70932]
loss: 0.064577  [25600/70932]
loss: 0.100586  [32000/70932]
loss: 0.310786  [38400/70932]
loss: 0.163122  [44800/70932]
loss: 0.103110  [51200/70932]
loss: 0.081105  [57600/70932]
loss: 0.133224  [64000/70932]
loss: 0.132713  [70400/70932]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.158041 

Epoch 32
-------------------------------
loss: 0.209044  [    0/70932]
loss: 0.069026  [ 6400/70932]
loss: 0.070867  [12800/70932]
loss: 0.021742  [19200/70932]
loss: 0.147222  [25600/70932]
loss: 0.137915  [32000/70932]
loss: 0.213563  [38400/70932]
loss: 0.068777  [44800/70932]
loss: 0.105749  [51200/70932]
loss: 0.354870  [57600/70932]
loss: 0.079493  [64000/70932]
loss: 0.112642  [70400/70932]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.172637 

Epoch 33
-------------------------------
loss: 0.056916  [    0/70932]
loss: 0.076040  [ 6400/70932]
loss: 0.115412  [12800/70932]
loss: 0.106863  [19200/70932]
loss: 0.111226  [25600/70932]
loss: 0.116487  [32000/70932]
loss: 0.124463  [38400/70932]
loss: 0.076903  [44800/70932]
loss: 0.098594  [51200/70932]
loss: 0.158178  [57600/70932]
loss: 0.075678  [64000/70932]
loss: 0.072191  [70400/70932]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.158504 

Epoch 34
-------------------------------
loss: 0.122211  [    0/70932]
loss: 0.178896  [ 6400/70932]
loss: 0.122458  [12800/70932]
loss: 0.061017  [19200/70932]
loss: 0.029766  [25600/70932]
loss: 0.080804  [32000/70932]
loss: 0.182234  [38400/70932]
loss: 0.108481  [44800/70932]
loss: 0.102458  [51200/70932]
loss: 0.143450  [57600/70932]
loss: 0.224434  [64000/70932]
loss: 0.142710  [70400/70932]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.167949 

Epoch 35
-------------------------------
loss: 0.323717  [    0/70932]
loss: 0.130399  [ 6400/70932]
loss: 0.229244  [12800/70932]
loss: 0.056802  [19200/70932]
loss: 0.055117  [25600/70932]
loss: 0.135479  [32000/70932]
loss: 0.166931  [38400/70932]
loss: 0.088818  [44800/70932]
loss: 0.078728  [51200/70932]
loss: 0.203161  [57600/70932]
loss: 0.144908  [64000/70932]
loss: 0.133696  [70400/70932]
Test Error: 
 Accuracy: 90.5%, Avg loss: 0.255693 

Epoch 36
-------------------------------
loss: 0.231652  [    0/70932]
loss: 0.047246  [ 6400/70932]
loss: 0.110270  [12800/70932]
loss: 0.110729  [19200/70932]
loss: 0.108168  [25600/70932]
loss: 0.074927  [32000/70932]
loss: 0.101319  [38400/70932]
loss: 0.172279  [44800/70932]
loss: 0.084815  [51200/70932]
loss: 0.269657  [57600/70932]
loss: 0.076867  [64000/70932]
loss: 0.128780  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.164445 

Epoch 37
-------------------------------
loss: 0.130002  [    0/70932]
loss: 0.094276  [ 6400/70932]
loss: 0.195982  [12800/70932]
loss: 0.057764  [19200/70932]
loss: 0.215249  [25600/70932]
loss: 0.196726  [32000/70932]
loss: 0.181567  [38400/70932]
loss: 0.113984  [44800/70932]
loss: 0.162707  [51200/70932]
loss: 0.183052  [57600/70932]
loss: 0.087858  [64000/70932]
loss: 0.131462  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.168184 

Epoch 38
-------------------------------
loss: 0.147245  [    0/70932]
loss: 0.118353  [ 6400/70932]
loss: 0.171125  [12800/70932]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.150422 

Epoch 17
-------------------------------
loss: 0.102854  [    0/71285]
loss: 0.140552  [ 6400/71285]
loss: 0.090073  [12800/71285]
loss: 0.072398  [19200/71285]
loss: 0.063870  [25600/71285]
loss: 0.084806  [32000/71285]
loss: 0.060390  [38400/71285]
loss: 0.161544  [44800/71285]
loss: 0.200444  [51200/71285]
loss: 0.180023  [57600/71285]
loss: 0.196573  [64000/71285]
loss: 0.139979  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.147860 

Epoch 18
-------------------------------
loss: 0.106966  [    0/71285]
loss: 0.152056  [ 6400/71285]
loss: 0.044912  [12800/71285]
loss: 0.092794  [19200/71285]
loss: 0.074711  [25600/71285]
loss: 0.097701  [32000/71285]
loss: 0.115276  [38400/71285]
loss: 0.063587  [44800/71285]
loss: 0.148363  [51200/71285]
loss: 0.134611  [57600/71285]
loss: 0.133961  [64000/71285]
loss: 0.121591  [70400/71285]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.157075 

Epoch 19
-------------------------------
loss: 0.161934  [    0/71285]
loss: 0.170908  [ 6400/71285]
loss: 0.171069  [12800/71285]
loss: 0.287654  [19200/71285]
loss: 0.126154  [25600/71285]
loss: 0.146901  [32000/71285]
loss: 0.048459  [38400/71285]
loss: 0.146806  [44800/71285]
loss: 0.109207  [51200/71285]
loss: 0.288311  [57600/71285]
loss: 0.194634  [64000/71285]
loss: 0.145857  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.157167 

Epoch 20
-------------------------------
loss: 0.080496  [    0/71285]
loss: 0.058639  [ 6400/71285]
loss: 0.062125  [12800/71285]
loss: 0.182886  [19200/71285]
loss: 0.080178  [25600/71285]
loss: 0.149906  [32000/71285]
loss: 0.267604  [38400/71285]
loss: 0.152388  [44800/71285]
loss: 0.136348  [51200/71285]
loss: 0.354782  [57600/71285]
loss: 0.063171  [64000/71285]
loss: 0.179690  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.146531 

Epoch 21
-------------------------------
loss: 0.144493  [    0/71285]
loss: 0.191474  [ 6400/71285]
loss: 0.119308  [12800/71285]
loss: 0.104632  [19200/71285]
loss: 0.168367  [25600/71285]
loss: 0.110404  [32000/71285]
loss: 0.144322  [38400/71285]
loss: 0.151346  [44800/71285]
loss: 0.087608  [51200/71285]
loss: 0.157958  [57600/71285]
loss: 0.068640  [64000/71285]
loss: 0.174839  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.156512 

Epoch 22
-------------------------------
loss: 0.142867  [    0/71285]
loss: 0.058125  [ 6400/71285]
loss: 0.166883  [12800/71285]
loss: 0.270711  [19200/71285]
loss: 0.275679  [25600/71285]
loss: 0.154111  [32000/71285]
loss: 0.058290  [38400/71285]
loss: 0.171501  [44800/71285]
loss: 0.261297  [51200/71285]
loss: 0.100734  [57600/71285]
loss: 0.112148  [64000/71285]
loss: 0.084434  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.152321 

Epoch 23
-------------------------------
loss: 0.073769  [    0/71285]
loss: 0.162565  [ 6400/71285]
loss: 0.128953  [12800/71285]
loss: 0.097374  [19200/71285]
loss: 0.059451  [25600/71285]
loss: 0.131420  [32000/71285]
loss: 0.166944  [38400/71285]
loss: 0.150535  [44800/71285]
loss: 0.077949  [51200/71285]
loss: 0.303163  [57600/71285]
loss: 0.073446  [64000/71285]
loss: 0.101815  [70400/71285]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.152485 

Epoch 24
-------------------------------
loss: 0.083913  [    0/71285]
loss: 0.071116  [ 6400/71285]
loss: 0.098826  [12800/71285]
loss: 0.215788  [19200/71285]
loss: 0.134053  [25600/71285]
loss: 0.200567  [32000/71285]
loss: 0.065708  [38400/71285]
loss: 0.091118  [44800/71285]
loss: 0.120493  [51200/71285]
loss: 0.077294  [57600/71285]
loss: 0.179291  [64000/71285]
loss: 0.140857  [70400/71285]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.148802 

Epoch 25
-------------------------------
loss: 0.116335  [    0/71285]
loss: 0.133333  [ 6400/71285]
loss: 0.144526  [12800/71285]
loss: 0.152561  [19200/71285]
loss: 0.098676  [25600/71285]
loss: 0.094768  [32000/71285]
loss: 0.138439  [38400/71285]
loss: 0.107782  [44800/71285]
loss: 0.144828  [51200/71285]
loss: 0.091616  [57600/71285]
loss: 0.096903  [64000/71285]
loss: 0.069005  [70400/71285]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.159193 

Epoch 26
-------------------------------
loss: 0.195269  [    0/71285]
loss: 0.123089  [ 6400/71285]
loss: 0.218919  [12800/71285]
loss: 0.197387  [19200/71285]
loss: 0.088982  [25600/71285]
loss: 0.127636  [32000/71285]
loss: 0.117346  [38400/71285]
loss: 0.080147  [44800/71285]
loss: 0.073041  [51200/71285]
loss: 0.089250  [57600/71285]
loss: 0.055378  [64000/71285]
loss: 0.102680  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.150174 

Epoch 27
-------------------------------
loss: 0.265304  [    0/71285]
loss: 0.053345  [ 6400/71285]
loss: 0.092913  [12800/71285]
loss: 0.043461  [19200/71285]
loss: 0.168718  [25600/71285]
loss: 0.157409  [32000/71285]
loss: 0.041529  [38400/71285]
loss: 0.107699  [44800/71285]
loss: 0.186592  [51200/71285]
loss: 0.138880  [57600/71285]
loss: 0.156336  [64000/71285]
loss: 0.160383  [70400/71285]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.163591 

Epoch 28
-------------------------------
loss: 0.103182  [    0/71285]
loss: 0.154237  [ 6400/71285]
loss: 0.097206  [12800/71285]
loss: 0.095536  [19200/71285]
loss: 0.070286  [25600/71285]
loss: 0.174541  [32000/71285]
loss: 0.096539  [38400/71285]
loss: 0.166753  [44800/71285]
loss: 0.139195  [51200/71285]
loss: 0.173915  [57600/71285]
loss: 0.059145  [64000/71285]
loss: 0.097149  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.146959 

Epoch 29
-------------------------------
loss: 0.201695  [    0/71285]
loss: 0.117544  [ 6400/71285]
loss: 0.095137  [12800/71285]
loss: 0.111474  [19200/71285]
loss: 0.130782  [25600/71285]
loss: 0.228917  [32000/71285]
loss: 0.096762  [38400/71285]
loss: 0.138610  [44800/71285]
loss: 0.095149  [51200/71285]
loss: 0.085102  [57600/71285]
loss: 0.193526  [64000/71285]
loss: 0.112722  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.151903 

Epoch 30
-------------------------------
loss: 0.163543  [    0/71285]
loss: 0.162753  [ 6400/71285]
loss: 0.076997  [12800/71285]
loss: 0.050757  [19200/71285]
loss: 0.031194  [25600/71285]
loss: 0.104725  [32000/71285]
loss: 0.113206  [38400/71285]
loss: 0.105133  [44800/71285]
loss: 0.170276  [51200/71285]
loss: 0.126085  [57600/71285]
loss: 0.069622  [64000/71285]
loss: 0.120190  [70400/71285]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.164425 

Epoch 31
-------------------------------
loss: 0.080266  [    0/71285]
loss: 0.171801  [ 6400/71285]
loss: 0.215522  [12800/71285]
loss: 0.113219  [19200/71285]
loss: 0.204364  [25600/71285]
loss: 0.133328  [32000/71285]
loss: 0.093601  [38400/71285]
loss: 0.136764  [44800/71285]
loss: 0.222123  [51200/71285]
loss: 0.151654  [57600/71285]
loss: 0.078229  [64000/71285]
loss: 0.193287  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.147212 

Epoch 32
-------------------------------
loss: 0.085761  [    0/71285]
loss: 0.115597  [ 6400/71285]
loss: 0.192871  [12800/71285]
loss: 0.099328  [19200/71285]
loss: 0.141676  [25600/71285]
loss: 0.117807  [32000/71285]
loss: 0.042523  [38400/71285]
loss: 0.148885  [44800/71285]
loss: 0.194103  [51200/71285]
loss: 0.173920  [57600/71285]
loss: 0.049709  [64000/71285]
loss: 0.162487  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.145462 

Epoch 33
-------------------------------
loss: 0.108842  [    0/71285]
loss: 0.063445  [ 6400/71285]
loss: 0.101696  [12800/71285]
loss: 0.102557  [19200/71285]
loss: 0.129081  [25600/71285]
loss: 0.060098  [32000/71285]
loss: 0.147535  [38400/71285]
loss: 0.166376  [44800/71285]
loss: 0.115949  [51200/71285]
loss: 0.069020  [57600/71285]
loss: 0.089066  [64000/71285]
loss: 0.122605  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.148120 

Epoch 34
-------------------------------
loss: 0.204209  [    0/71285]
loss: 0.037015  [ 6400/71285]
loss: 0.073666  [12800/71285]
loss: 0.170156  [19200/71285]
loss: 0.112457  [25600/71285]
loss: 0.292985  [32000/71285]
loss: 0.179909  [38400/71285]
loss: 0.092194  [44800/71285]
loss: 0.141839  [51200/71285]
loss: 0.072951  [57600/71285]
loss: 0.061986  [64000/71285]
loss: 0.130750  [70400/71285]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.206176 

Epoch 17
-------------------------------
loss: 0.141269  [    0/70872]
loss: 0.170643  [ 6400/70872]
loss: 0.074393  [12800/70872]
loss: 0.151431  [19200/70872]
loss: 0.104362  [25600/70872]
loss: 0.082457  [32000/70872]
loss: 0.226625  [38400/70872]
loss: 0.333507  [44800/70872]
loss: 0.165576  [51200/70872]
loss: 0.076284  [57600/70872]
loss: 0.105930  [64000/70872]
loss: 0.133045  [70400/70872]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.192704 

Epoch 18
-------------------------------
loss: 0.165409  [    0/70872]
loss: 0.129427  [ 6400/70872]
loss: 0.091159  [12800/70872]
loss: 0.078646  [19200/70872]
loss: 0.101801  [25600/70872]
loss: 0.084149  [32000/70872]
loss: 1.747903  [38400/70872]
loss: 0.226617  [44800/70872]
loss: 0.140929  [51200/70872]
loss: 0.053642  [57600/70872]
loss: 1.687705  [64000/70872]
loss: 0.076278  [70400/70872]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.194640 

Epoch 19
-------------------------------
loss: 0.206067  [    0/70872]
loss: 0.164243  [ 6400/70872]
loss: 0.097922  [12800/70872]
loss: 0.235311  [19200/70872]
loss: 1.725724  [25600/70872]
loss: 0.391731  [32000/70872]
loss: 0.107063  [38400/70872]
loss: 0.176581  [44800/70872]
loss: 0.176132  [51200/70872]
loss: 0.072034  [57600/70872]
loss: 0.130504  [64000/70872]
loss: 0.148763  [70400/70872]
Test Error: 
 Accuracy: 83.7%, Avg loss: 0.485454 

Epoch 20
-------------------------------
loss: 0.336714  [    0/70872]
loss: 0.160180  [ 6400/70872]
loss: 0.099233  [12800/70872]
loss: 0.260660  [19200/70872]
loss: 0.270354  [25600/70872]
loss: 0.110672  [32000/70872]
loss: 0.251106  [38400/70872]
loss: 0.077335  [44800/70872]
loss: 0.141146  [51200/70872]
loss: 0.136890  [57600/70872]
loss: 0.133108  [64000/70872]
loss: 0.257894  [70400/70872]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.204582 

Epoch 21
-------------------------------
loss: 0.187168  [    0/70872]
loss: 0.147281  [ 6400/70872]
loss: 0.213426  [12800/70872]
loss: 0.298262  [19200/70872]
loss: 0.148553  [25600/70872]
loss: 0.268566  [32000/70872]
loss: 0.178245  [38400/70872]
loss: 0.199959  [44800/70872]
loss: 0.106179  [51200/70872]
loss: 0.148619  [57600/70872]
loss: 0.170239  [64000/70872]
loss: 0.070177  [70400/70872]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.201171 

Epoch 22
-------------------------------
loss: 0.209513  [    0/70872]
loss: 0.044119  [ 6400/70872]
loss: 0.120046  [12800/70872]
loss: 0.155674  [19200/70872]
loss: 0.100925  [25600/70872]
loss: 0.111490  [32000/70872]
loss: 0.117234  [38400/70872]
loss: 0.212232  [44800/70872]
loss: 0.095372  [51200/70872]
loss: 0.092393  [57600/70872]
loss: 0.139293  [64000/70872]
loss: 0.081728  [70400/70872]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.195501 

Epoch 23
-------------------------------
loss: 0.134754  [    0/70872]
loss: 0.149635  [ 6400/70872]
loss: 0.130191  [12800/70872]
loss: 0.113354  [19200/70872]
loss: 0.070659  [25600/70872]
loss: 0.178358  [32000/70872]
loss: 0.078731  [38400/70872]
loss: 0.110880  [44800/70872]
loss: 0.170317  [51200/70872]
loss: 0.110603  [57600/70872]
loss: 0.152871  [64000/70872]
loss: 0.255529  [70400/70872]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.189519 

Epoch 24
-------------------------------
loss: 0.166210  [    0/70872]
loss: 0.089811  [ 6400/70872]
loss: 0.164048  [12800/70872]
loss: 0.091944  [19200/70872]
loss: 0.252660  [25600/70872]
loss: 0.204291  [32000/70872]
loss: 0.107585  [38400/70872]
loss: 0.180278  [44800/70872]
loss: 0.107601  [51200/70872]
loss: 0.175325  [57600/70872]
loss: 0.278077  [64000/70872]
loss: 0.276807  [70400/70872]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.211911 

Epoch 25
-------------------------------
loss: 0.114822  [    0/70872]
loss: 0.121004  [ 6400/70872]
loss: 0.208041  [12800/70872]
loss: 0.147516  [19200/70872]
loss: 0.127695  [25600/70872]
loss: 0.164852  [32000/70872]
loss: 0.190004  [38400/70872]
loss: 0.138724  [44800/70872]
loss: 0.214757  [51200/70872]
loss: 0.105488  [57600/70872]
loss: 0.153227  [64000/70872]
loss: 0.184000  [70400/70872]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.175829 

Epoch 26
-------------------------------
loss: 0.133705  [    0/70872]
loss: 0.107684  [ 6400/70872]
loss: 0.049850  [12800/70872]
loss: 0.071369  [19200/70872]
loss: 0.101593  [25600/70872]
loss: 0.189910  [32000/70872]
loss: 0.184940  [38400/70872]
loss: 0.127240  [44800/70872]
loss: 0.132160  [51200/70872]
loss: 0.075913  [57600/70872]
loss: 0.155968  [64000/70872]
loss: 0.254250  [70400/70872]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.196800 

Epoch 27
-------------------------------
loss: 0.191501  [    0/70872]
loss: 0.118295  [ 6400/70872]
loss: 0.130508  [12800/70872]
loss: 0.158142  [19200/70872]
loss: 0.130958  [25600/70872]
loss: 0.105777  [32000/70872]
loss: 0.317258  [38400/70872]
loss: 0.085216  [44800/70872]
loss: 0.327928  [51200/70872]
loss: 0.157021  [57600/70872]
loss: 0.201212  [64000/70872]
loss: 0.250311  [70400/70872]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.197229 

Epoch 28
-------------------------------
loss: 0.123555  [    0/70872]
loss: 0.102585  [ 6400/70872]
loss: 0.165316  [12800/70872]
loss: 0.167799  [19200/70872]
loss: 0.173311  [25600/70872]
loss: 0.192673  [32000/70872]
loss: 0.127815  [38400/70872]
loss: 0.262946  [44800/70872]
loss: 0.138997  [51200/70872]
loss: 0.151131  [57600/70872]
loss: 0.128123  [64000/70872]
loss: 0.145986  [70400/70872]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.193053 

Epoch 29
-------------------------------
loss: 0.083924  [    0/70872]
loss: 0.046960  [ 6400/70872]
loss: 0.105896  [12800/70872]
loss: 0.107144  [19200/70872]
loss: 0.233973  [25600/70872]
loss: 0.227960  [32000/70872]
loss: 0.092568  [38400/70872]
loss: 0.262561  [44800/70872]
loss: 0.092472  [51200/70872]
loss: 0.223913  [57600/70872]
loss: 0.100120  [64000/70872]
loss: 0.098104  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.193378 

Epoch 30
-------------------------------
loss: 0.140114  [    0/70872]
loss: 0.116374  [ 6400/70872]
loss: 0.105361  [12800/70872]
loss: 0.106330  [19200/70872]
loss: 0.294552  [25600/70872]
loss: 0.080974  [32000/70872]
loss: 0.223348  [38400/70872]
loss: 0.074214  [44800/70872]
loss: 0.164371  [51200/70872]
loss: 0.139387  [57600/70872]
loss: 0.119720  [64000/70872]
loss: 0.177340  [70400/70872]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.193076 

Epoch 31
-------------------------------
loss: 0.055775  [    0/70872]
loss: 0.077292  [ 6400/70872]
loss: 0.086964  [12800/70872]
loss: 0.175106  [19200/70872]
loss: 0.097172  [25600/70872]
loss: 0.190226  [32000/70872]
loss: 0.115584  [38400/70872]
loss: 0.243091  [44800/70872]
loss: 0.132401  [51200/70872]
loss: 0.147476  [57600/70872]
loss: 0.196890  [64000/70872]
loss: 0.142765  [70400/70872]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.190464 

Epoch 32
-------------------------------
loss: 0.068293  [    0/70872]
loss: 0.159693  [ 6400/70872]
loss: 0.209928  [12800/70872]
loss: 0.185447  [19200/70872]
loss: 0.173981  [25600/70872]
loss: 0.166161  [32000/70872]
loss: 0.210521  [38400/70872]
loss: 0.121988  [44800/70872]
loss: 0.120403  [51200/70872]
loss: 0.092295  [57600/70872]
loss: 0.280084  [64000/70872]
loss: 0.128333  [70400/70872]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.191999 

Epoch 33
-------------------------------
loss: 0.088264  [    0/70872]
loss: 0.065713  [ 6400/70872]
loss: 0.127636  [12800/70872]
loss: 0.206651  [19200/70872]
loss: 0.095290  [25600/70872]
loss: 0.200048  [32000/70872]
loss: 0.227739  [38400/70872]
loss: 0.114154  [44800/70872]
loss: 0.189194  [51200/70872]
loss: 0.203509  [57600/70872]
loss: 0.207741  [64000/70872]
loss: 0.214409  [70400/70872]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.199267 

Epoch 34
-------------------------------
loss: 0.129643  [    0/70872]
loss: 0.223800  [ 6400/70872]
loss: 0.114967  [12800/70872]
loss: 0.153848  [19200/70872]
loss: 0.169947  [25600/70872]
loss: 0.233256  [32000/70872]
loss: 0.091106  [38400/70872]
loss: 0.083435  [44800/70872]
loss: 0.231544  [51200/70872]
loss: 0.205370  [57600/70872]
loss: 0.205964  [64000/70872]
loss: 0.145288  [70400/70872]
2022/09/20 16:08:32 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:10:28 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.284827  [12800/70500]
loss: 0.171633  [19200/70500]
loss: 0.127663  [25600/70500]
loss: 0.178343  [32000/70500]
loss: 0.199418  [38400/70500]
loss: 0.074941  [44800/70500]
loss: 0.229265  [51200/70500]
loss: 0.085230  [57600/70500]
loss: 1.724086  [64000/70500]
loss: 0.123768  [70400/70500]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.172595 

Epoch 21
-------------------------------
loss: 0.047469  [    0/70500]
loss: 0.199936  [ 6400/70500]
loss: 0.177260  [12800/70500]
loss: 0.073195  [19200/70500]
loss: 0.180729  [25600/70500]
loss: 0.083803  [32000/70500]
loss: 0.110684  [38400/70500]
loss: 0.163405  [44800/70500]
loss: 0.227127  [51200/70500]
loss: 0.173294  [57600/70500]
loss: 0.161684  [64000/70500]
loss: 0.243974  [70400/70500]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.166819 

Epoch 22
-------------------------------
loss: 0.084769  [    0/70500]
loss: 0.266286  [ 6400/70500]
loss: 0.186600  [12800/70500]
loss: 0.192362  [19200/70500]
loss: 0.165241  [25600/70500]
loss: 0.122571  [32000/70500]
loss: 0.235210  [38400/70500]
loss: 0.107066  [44800/70500]
loss: 0.193598  [51200/70500]
loss: 0.145546  [57600/70500]
loss: 0.120125  [64000/70500]
loss: 0.082683  [70400/70500]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.178460 

Epoch 23
-------------------------------
loss: 0.108058  [    0/70500]
loss: 0.166362  [ 6400/70500]
loss: 0.082407  [12800/70500]
loss: 1.638009  [19200/70500]
loss: 0.119654  [25600/70500]
loss: 0.197046  [32000/70500]
loss: 0.175903  [38400/70500]
loss: 0.263287  [44800/70500]
loss: 0.124603  [51200/70500]
loss: 0.106229  [57600/70500]
loss: 0.174426  [64000/70500]
loss: 0.220093  [70400/70500]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.171824 

Epoch 24
-------------------------------
loss: 0.181839  [    0/70500]
loss: 0.111064  [ 6400/70500]
loss: 0.153950  [12800/70500]
loss: 0.064157  [19200/70500]
loss: 0.222929  [25600/70500]
loss: 0.096036  [32000/70500]
loss: 0.120605  [38400/70500]
loss: 0.148122  [44800/70500]
loss: 0.182348  [51200/70500]
loss: 0.192716  [57600/70500]
loss: 0.089750  [64000/70500]
loss: 0.101119  [70400/70500]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.178123 

Epoch 25
-------------------------------
loss: 0.207672  [    0/70500]
loss: 0.104538  [ 6400/70500]
loss: 0.177999  [12800/70500]
loss: 1.636447  [19200/70500]
loss: 0.050298  [25600/70500]
loss: 0.144571  [32000/70500]
loss: 0.104605  [38400/70500]
loss: 0.084474  [44800/70500]
loss: 0.142847  [51200/70500]
loss: 0.229893  [57600/70500]
loss: 0.178909  [64000/70500]
loss: 0.287209  [70400/70500]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.187972 

Epoch 26
-------------------------------
loss: 0.239972  [    0/70500]
loss: 0.098182  [ 6400/70500]
loss: 0.086712  [12800/70500]
loss: 0.188570  [19200/70500]
loss: 0.194832  [25600/70500]
loss: 0.043824  [32000/70500]
loss: 0.146941  [38400/70500]
loss: 0.118576  [44800/70500]
loss: 0.114675  [51200/70500]
loss: 0.190678  [57600/70500]
loss: 0.088162  [64000/70500]
loss: 0.184662  [70400/70500]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177663 

Epoch 27
-------------------------------
loss: 0.292152  [    0/70500]
loss: 0.057948  [ 6400/70500]
loss: 0.153716  [12800/70500]
loss: 0.113153  [19200/70500]
loss: 0.150663  [25600/70500]
loss: 0.139394  [32000/70500]
loss: 0.086453  [38400/70500]
loss: 0.159897  [44800/70500]
loss: 0.115413  [51200/70500]
loss: 0.165415  [57600/70500]
loss: 0.152411  [64000/70500]
loss: 0.157763  [70400/70500]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.210380 

Epoch 28
-------------------------------
loss: 0.322190  [    0/70500]
loss: 0.193130  [ 6400/70500]
loss: 0.203422  [12800/70500]
loss: 0.218109  [19200/70500]
loss: 0.088131  [25600/70500]
loss: 0.212112  [32000/70500]
loss: 0.251062  [38400/70500]
loss: 0.099070  [44800/70500]
loss: 0.253798  [51200/70500]
loss: 0.181950  [57600/70500]
loss: 0.318375  [64000/70500]
loss: 0.223040  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.178026 

Epoch 29
-------------------------------
loss: 0.089935  [    0/70500]
loss: 0.066774  [ 6400/70500]
loss: 0.220138  [12800/70500]
loss: 0.166728  [19200/70500]
loss: 0.145678  [25600/70500]
loss: 0.137109  [32000/70500]
loss: 0.053309  [38400/70500]
loss: 0.189875  [44800/70500]
loss: 0.117365  [51200/70500]
loss: 0.138851  [57600/70500]
loss: 0.224544  [64000/70500]
loss: 0.141308  [70400/70500]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.175830 

Epoch 30
-------------------------------
loss: 0.193563  [    0/70500]
loss: 0.156870  [ 6400/70500]
loss: 0.216437  [12800/70500]
loss: 0.107510  [19200/70500]
loss: 0.185848  [25600/70500]
loss: 0.198971  [32000/70500]
loss: 0.095689  [38400/70500]
loss: 0.349155  [44800/70500]
loss: 0.127608  [51200/70500]
loss: 0.095712  [57600/70500]
loss: 0.080894  [64000/70500]
loss: 0.081730  [70400/70500]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.175505 

Epoch 31
-------------------------------
loss: 0.138716  [    0/70500]
loss: 0.129632  [ 6400/70500]
loss: 0.116032  [12800/70500]
loss: 0.142312  [19200/70500]
loss: 0.232002  [25600/70500]
loss: 0.281178  [32000/70500]
loss: 0.126190  [38400/70500]
loss: 0.099382  [44800/70500]
loss: 0.160174  [51200/70500]
loss: 0.081697  [57600/70500]
loss: 0.183169  [64000/70500]
loss: 0.128888  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.178318 

Epoch 32
-------------------------------
loss: 0.173610  [    0/70500]
loss: 1.626572  [ 6400/70500]
loss: 0.036728  [12800/70500]
loss: 0.100255  [19200/70500]
loss: 0.191887  [25600/70500]
loss: 0.158487  [32000/70500]
loss: 0.083691  [38400/70500]
loss: 0.079846  [44800/70500]
loss: 0.094940  [51200/70500]
loss: 0.111461  [57600/70500]
loss: 0.103174  [64000/70500]
loss: 0.097708  [70400/70500]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.187725 

Epoch 33
-------------------------------
loss: 0.200749  [    0/70500]
loss: 0.118905  [ 6400/70500]
loss: 0.055245  [12800/70500]
loss: 0.286843  [19200/70500]
loss: 0.142819  [25600/70500]
loss: 0.042695  [32000/70500]
loss: 0.237145  [38400/70500]
loss: 0.111903  [44800/70500]
loss: 0.063364  [51200/70500]
loss: 0.092962  [57600/70500]
loss: 0.175716  [64000/70500]
loss: 0.089067  [70400/70500]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.174023 

Epoch 34
-------------------------------
loss: 0.147344  [    0/70500]
loss: 0.076696  [ 6400/70500]
loss: 0.228700  [12800/70500]
loss: 0.145707  [19200/70500]
loss: 0.140394  [25600/70500]
loss: 0.155114  [32000/70500]
loss: 0.145309  [38400/70500]
loss: 0.061664  [44800/70500]
loss: 0.191107  [51200/70500]
loss: 0.047913  [57600/70500]
loss: 0.152470  [64000/70500]
loss: 0.272061  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.170043 

Epoch 35
-------------------------------
loss: 0.213380  [    0/70500]
loss: 0.182617  [ 6400/70500]
loss: 0.123162  [12800/70500]
loss: 0.090770  [19200/70500]
loss: 0.192182  [25600/70500]
loss: 0.120030  [32000/70500]
loss: 0.171810  [38400/70500]
loss: 0.137029  [44800/70500]
loss: 0.224144  [51200/70500]
loss: 0.199619  [57600/70500]
loss: 0.112864  [64000/70500]
loss: 0.261440  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.174130 

Epoch 36
-------------------------------
loss: 0.149511  [    0/70500]
loss: 0.072254  [ 6400/70500]
loss: 0.054352  [12800/70500]
loss: 0.084469  [19200/70500]
loss: 0.121089  [25600/70500]
loss: 0.109392  [32000/70500]
loss: 0.123419  [38400/70500]
loss: 0.099739  [44800/70500]
loss: 0.078978  [51200/70500]
loss: 0.121583  [57600/70500]
loss: 0.089253  [64000/70500]
loss: 0.076613  [70400/70500]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.178195 

Epoch 37
-------------------------------
loss: 0.116744  [    0/70500]
loss: 0.059126  [ 6400/70500]
loss: 0.140881  [12800/70500]
loss: 0.192113  [19200/70500]
loss: 0.083344  [25600/70500]
loss: 0.098743  [32000/70500]
loss: 0.116245  [38400/70500]
loss: 0.330223  [44800/70500]
loss: 0.123793  [51200/70500]
loss: 0.194497  [57600/70500]
loss: 0.221969  [64000/70500]
loss: 0.098517  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.174219 

Epoch 38
-------------------------------
loss: 0.106736  [    0/70500]
loss: 0.075629  [ 6400/70500]
loss: 0.169026  [12800/70500]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.136338 

Epoch 34
-------------------------------
loss: 0.097167  [    0/69149]
loss: 0.055280  [ 6400/69149]
loss: 0.205118  [12800/69149]
loss: 0.134858  [19200/69149]
loss: 0.106162  [25600/69149]
loss: 0.036001  [32000/69149]
loss: 0.118349  [38400/69149]
loss: 0.052431  [44800/69149]
loss: 0.146060  [51200/69149]
loss: 0.064024  [57600/69149]
loss: 0.161002  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.129372 

Epoch 35
-------------------------------
loss: 0.050070  [    0/69149]
loss: 0.080497  [ 6400/69149]
loss: 0.147368  [12800/69149]
loss: 0.178702  [19200/69149]
loss: 0.078864  [25600/69149]
loss: 0.104541  [32000/69149]
loss: 0.127399  [38400/69149]
loss: 0.168756  [44800/69149]
loss: 0.129909  [51200/69149]
loss: 0.098437  [57600/69149]
loss: 0.214845  [64000/69149]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.128165 

Epoch 36
-------------------------------
loss: 0.094486  [    0/69149]
loss: 0.087984  [ 6400/69149]
loss: 0.140730  [12800/69149]
loss: 0.199267  [19200/69149]
loss: 0.134341  [25600/69149]
loss: 0.173064  [32000/69149]
loss: 0.162793  [38400/69149]
loss: 0.070849  [44800/69149]
loss: 0.083962  [51200/69149]
loss: 0.037455  [57600/69149]
loss: 0.038084  [64000/69149]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.130758 

Epoch 37
-------------------------------
loss: 0.046145  [    0/69149]
loss: 0.084123  [ 6400/69149]
loss: 0.025145  [12800/69149]
loss: 0.160992  [19200/69149]
loss: 0.073239  [25600/69149]
loss: 0.076347  [32000/69149]
loss: 0.048451  [38400/69149]
loss: 0.031801  [44800/69149]
loss: 0.180349  [51200/69149]
loss: 0.079546  [57600/69149]
loss: 0.114230  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.132752 

Epoch 38
-------------------------------
loss: 0.085547  [    0/69149]
loss: 0.087897  [ 6400/69149]
loss: 0.120174  [12800/69149]
loss: 0.046369  [19200/69149]
loss: 0.045926  [25600/69149]
loss: 0.160552  [32000/69149]
loss: 0.113915  [38400/69149]
loss: 0.045669  [44800/69149]
loss: 0.108974  [51200/69149]
loss: 0.083215  [57600/69149]
loss: 0.159501  [64000/69149]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.131821 

Epoch 39
-------------------------------
loss: 0.100695  [    0/69149]
loss: 0.158115  [ 6400/69149]
loss: 0.035204  [12800/69149]
loss: 0.084915  [19200/69149]
loss: 0.109295  [25600/69149]
loss: 0.094250  [32000/69149]
loss: 0.028290  [38400/69149]
loss: 0.076240  [44800/69149]
loss: 0.120634  [51200/69149]
loss: 0.160155  [57600/69149]
loss: 0.189046  [64000/69149]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.136881 

Epoch 40
-------------------------------
loss: 0.055106  [    0/69149]
loss: 0.155242  [ 6400/69149]
loss: 0.060615  [12800/69149]
loss: 0.105860  [19200/69149]
loss: 0.120094  [25600/69149]
loss: 0.027777  [32000/69149]
loss: 0.100238  [38400/69149]
loss: 0.072741  [44800/69149]
loss: 0.094626  [51200/69149]
loss: 0.156209  [57600/69149]
loss: 0.050121  [64000/69149]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.132652 

Epoch 41
-------------------------------
loss: 0.091153  [    0/69149]
loss: 0.189021  [ 6400/69149]
loss: 0.051534  [12800/69149]
loss: 0.147393  [19200/69149]
loss: 0.166867  [25600/69149]
loss: 0.151662  [32000/69149]
loss: 0.101214  [38400/69149]
loss: 0.171950  [44800/69149]
loss: 0.205534  [51200/69149]
loss: 0.051547  [57600/69149]
loss: 0.055029  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.131152 

Epoch 42
-------------------------------
loss: 0.158881  [    0/69149]
loss: 0.190481  [ 6400/69149]
loss: 0.096839  [12800/69149]
loss: 0.098175  [19200/69149]
loss: 0.072090  [25600/69149]
loss: 0.128444  [32000/69149]
loss: 0.259190  [38400/69149]
loss: 0.096177  [44800/69149]
loss: 0.131832  [51200/69149]
loss: 0.120561  [57600/69149]
loss: 0.119190  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.135149 

Epoch 43
-------------------------------
loss: 0.073262  [    0/69149]
loss: 0.125845  [ 6400/69149]
loss: 0.078100  [12800/69149]
loss: 0.109471  [19200/69149]
loss: 0.242326  [25600/69149]
loss: 0.058534  [32000/69149]
loss: 0.160118  [38400/69149]
loss: 0.112393  [44800/69149]
loss: 0.074721  [51200/69149]
loss: 0.065027  [57600/69149]
loss: 0.156067  [64000/69149]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.144325 

Epoch 44
-------------------------------
loss: 0.149946  [    0/69149]
loss: 0.119982  [ 6400/69149]
loss: 0.075613  [12800/69149]
loss: 0.118625  [19200/69149]
loss: 0.097737  [25600/69149]
loss: 0.133976  [32000/69149]
loss: 0.093276  [38400/69149]
loss: 0.182773  [44800/69149]
loss: 0.068422  [51200/69149]
loss: 0.029903  [57600/69149]
loss: 0.172460  [64000/69149]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.130235 

Epoch 45
-------------------------------
loss: 0.122917  [    0/69149]
loss: 0.187104  [ 6400/69149]
loss: 0.070394  [12800/69149]
loss: 0.087191  [19200/69149]
loss: 0.048287  [25600/69149]
loss: 0.159878  [32000/69149]
loss: 0.119932  [38400/69149]
loss: 0.137546  [44800/69149]
loss: 0.150016  [51200/69149]
loss: 0.135978  [57600/69149]
loss: 0.066621  [64000/69149]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.137599 

Epoch 46
-------------------------------
loss: 0.104198  [    0/69149]
loss: 0.118653  [ 6400/69149]
loss: 0.181905  [12800/69149]
loss: 0.074939  [19200/69149]
loss: 0.070747  [25600/69149]
loss: 0.146695  [32000/69149]
loss: 0.098175  [38400/69149]
loss: 0.072954  [44800/69149]
loss: 0.247227  [51200/69149]
loss: 0.059919  [57600/69149]
loss: 0.236153  [64000/69149]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171092 

Epoch 47
-------------------------------
loss: 0.068217  [    0/69149]
loss: 0.102314  [ 6400/69149]
loss: 0.142817  [12800/69149]
loss: 0.162656  [19200/69149]
loss: 0.117836  [25600/69149]
loss: 0.137738  [32000/69149]
loss: 0.266438  [38400/69149]
loss: 0.062630  [44800/69149]
loss: 0.127492  [51200/69149]
loss: 0.059591  [57600/69149]
loss: 0.227259  [64000/69149]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.133463 

Epoch 48
-------------------------------
loss: 0.078661  [    0/69149]
loss: 0.083810  [ 6400/69149]
loss: 0.086589  [12800/69149]
loss: 0.160606  [19200/69149]
loss: 0.065804  [25600/69149]
loss: 0.091358  [32000/69149]
loss: 0.068217  [38400/69149]
loss: 0.119528  [44800/69149]
loss: 0.084175  [51200/69149]
loss: 0.050592  [57600/69149]
loss: 0.161978  [64000/69149]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.130267 

Epoch 49
-------------------------------
loss: 0.115352  [    0/69149]
loss: 0.093807  [ 6400/69149]
loss: 0.104473  [12800/69149]
loss: 0.147170  [19200/69149]
loss: 0.084423  [25600/69149]
loss: 0.054431  [32000/69149]
loss: 0.054175  [38400/69149]
loss: 0.091847  [44800/69149]
loss: 0.047105  [51200/69149]
loss: 0.113318  [57600/69149]
loss: 0.221443  [64000/69149]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.128608 

Epoch 50
-------------------------------
loss: 0.146394  [    0/69149]
loss: 0.165289  [ 6400/69149]
loss: 0.149490  [12800/69149]
loss: 0.200851  [19200/69149]
loss: 0.076438  [25600/69149]
loss: 0.152792  [32000/69149]
loss: 0.092077  [38400/69149]
loss: 0.088291  [44800/69149]
loss: 0.230377  [51200/69149]
loss: 0.087832  [57600/69149]
loss: 0.111220  [64000/69149]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.133033 

Epoch 1
-------------------------------
loss: 0.691097  [    0/70468]
loss: 0.228767  [ 6400/70468]
loss: 0.306639  [12800/70468]
loss: 0.388855  [19200/70468]
loss: 0.432845  [25600/70468]
loss: 0.166730  [32000/70468]
loss: 0.171568  [38400/70468]
loss: 0.229566  [44800/70468]
loss: 0.145635  [51200/70468]
loss: 0.171058  [57600/70468]
loss: 0.120311  [64000/70468]
loss: 0.217606  [70400/70468]
Test Error: 
 Accuracy: 87.2%, Avg loss: 0.251994 

Epoch 2
-------------------------------
loss: 0.251182  [    0/70468]
loss: 0.161760  [ 6400/70468]
loss: 0.231942  [12800/70468]
loss: 0.178913  [19200/70468]
loss: 0.167640  [25600/70468]
loss: 0.116335  [32000/70468]
loss: 0.204614  [38400/70468]
loss: 0.183107  [44800/70468]
loss: 0.229797  [51200/70468]
loss: 0.200852  [57600/70468]
loss: 0.215826  [64000/70468]
loss: 0.175654  [70400/70468]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.153798 

Epoch 3
-------------------------------
loss: 0.071810  [57600/71622]
loss: 0.211438  [64000/71622]
loss: 0.093212  [70400/71622]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.195809 

Epoch 32
-------------------------------
loss: 0.073072  [    0/71622]
loss: 0.039445  [ 6400/71622]
loss: 0.070298  [12800/71622]
loss: 0.077238  [19200/71622]
loss: 0.042441  [25600/71622]
loss: 0.071103  [32000/71622]
loss: 0.098749  [38400/71622]
loss: 0.034660  [44800/71622]
loss: 0.078143  [51200/71622]
loss: 0.053963  [57600/71622]
loss: 0.068485  [64000/71622]
loss: 0.075041  [70400/71622]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.181027 

Epoch 33
-------------------------------
loss: 1.631431  [    0/71622]
loss: 0.138923  [ 6400/71622]
loss: 0.014906  [12800/71622]
loss: 0.155246  [19200/71622]
loss: 0.084471  [25600/71622]
loss: 0.101239  [32000/71622]
loss: 0.101310  [38400/71622]
loss: 0.183230  [44800/71622]
loss: 0.212717  [51200/71622]
loss: 0.099265  [57600/71622]
loss: 0.103281  [64000/71622]
loss: 0.032080  [70400/71622]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.137081 

Epoch 34
-------------------------------
loss: 0.074904  [    0/71622]
loss: 0.030788  [ 6400/71622]
loss: 0.060696  [12800/71622]
loss: 0.059301  [19200/71622]
loss: 0.068096  [25600/71622]
loss: 0.108798  [32000/71622]
loss: 0.041279  [38400/71622]
loss: 0.079989  [44800/71622]
loss: 0.054955  [51200/71622]
loss: 0.009683  [57600/71622]
loss: 0.042850  [64000/71622]
loss: 0.080441  [70400/71622]
Test Error: 
 Accuracy: 91.0%, Avg loss: 0.262811 

Epoch 35
-------------------------------
loss: 0.309711  [    0/71622]
loss: 0.037840  [ 6400/71622]
loss: 0.039976  [12800/71622]
loss: 0.030095  [19200/71622]
loss: 0.067360  [25600/71622]
loss: 0.119588  [32000/71622]
loss: 0.054365  [38400/71622]
loss: 0.115983  [44800/71622]
loss: 0.036359  [51200/71622]
loss: 0.105757  [57600/71622]
loss: 0.037167  [64000/71622]
loss: 0.030196  [70400/71622]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.139395 

Epoch 36
-------------------------------
loss: 0.085445  [    0/71622]
loss: 0.068011  [ 6400/71622]
loss: 0.080858  [12800/71622]
loss: 0.075247  [19200/71622]
loss: 0.167412  [25600/71622]
loss: 0.038543  [32000/71622]
loss: 0.139963  [38400/71622]
loss: 0.092852  [44800/71622]
loss: 0.016943  [51200/71622]
loss: 0.036060  [57600/71622]
loss: 0.032891  [64000/71622]
loss: 0.046339  [70400/71622]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.133145 

Epoch 37
-------------------------------
loss: 0.042748  [    0/71622]
loss: 0.032223  [ 6400/71622]
loss: 0.050845  [12800/71622]
loss: 0.211390  [19200/71622]
loss: 0.080475  [25600/71622]
loss: 0.081268  [32000/71622]
loss: 0.014775  [38400/71622]
loss: 0.174771  [44800/71622]
loss: 0.087533  [51200/71622]
loss: 0.091475  [57600/71622]
loss: 0.149591  [64000/71622]
loss: 0.042696  [70400/71622]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.136481 

Epoch 38
-------------------------------
loss: 0.019040  [    0/71622]
loss: 0.358751  [ 6400/71622]
loss: 0.064458  [12800/71622]
loss: 0.164233  [19200/71622]
loss: 0.022235  [25600/71622]
loss: 0.049397  [32000/71622]
loss: 0.120221  [38400/71622]
loss: 0.095191  [44800/71622]
loss: 0.126052  [51200/71622]
loss: 0.100585  [57600/71622]
loss: 0.103641  [64000/71622]
loss: 1.632472  [70400/71622]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.158346 

Epoch 39
-------------------------------
loss: 0.171260  [    0/71622]
loss: 0.022145  [ 6400/71622]
loss: 0.062575  [12800/71622]
loss: 1.716346  [19200/71622]
loss: 0.018553  [25600/71622]
loss: 0.088050  [32000/71622]
loss: 0.018793  [38400/71622]
loss: 0.066530  [44800/71622]
loss: 0.100199  [51200/71622]
loss: 0.048810  [57600/71622]
loss: 0.089882  [64000/71622]
loss: 0.026837  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.139402 

Epoch 40
-------------------------------
loss: 0.077817  [    0/71622]
loss: 0.176411  [ 6400/71622]
loss: 0.032811  [12800/71622]
loss: 0.097959  [19200/71622]
loss: 0.074207  [25600/71622]
loss: 0.074382  [32000/71622]
loss: 0.028745  [38400/71622]
loss: 0.166608  [44800/71622]
loss: 0.139138  [51200/71622]
loss: 0.122917  [57600/71622]
loss: 0.032325  [64000/71622]
loss: 0.008055  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.134650 

Epoch 41
-------------------------------
loss: 0.073838  [    0/71622]
loss: 0.115916  [ 6400/71622]
loss: 0.088830  [12800/71622]
loss: 0.076475  [19200/71622]
loss: 0.189751  [25600/71622]
loss: 0.083037  [32000/71622]
loss: 0.029192  [38400/71622]
loss: 0.052022  [44800/71622]
loss: 0.074187  [51200/71622]
loss: 0.082356  [57600/71622]
loss: 0.164495  [64000/71622]
loss: 0.010052  [70400/71622]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.133239 

Epoch 42
-------------------------------
loss: 0.037903  [    0/71622]
loss: 0.267922  [ 6400/71622]
loss: 0.061884  [12800/71622]
loss: 0.119137  [19200/71622]
loss: 0.154084  [25600/71622]
loss: 0.068554  [32000/71622]
loss: 0.055901  [38400/71622]
loss: 0.019886  [44800/71622]
loss: 0.097388  [51200/71622]
loss: 0.042614  [57600/71622]
loss: 0.136989  [64000/71622]
loss: 0.105043  [70400/71622]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.134394 

Epoch 43
-------------------------------
loss: 0.129786  [    0/71622]
loss: 0.078169  [ 6400/71622]
loss: 0.101036  [12800/71622]
loss: 0.011062  [19200/71622]
loss: 0.170036  [25600/71622]
loss: 0.077378  [32000/71622]
loss: 0.094557  [38400/71622]
loss: 0.065476  [44800/71622]
loss: 0.103768  [51200/71622]
loss: 0.034811  [57600/71622]
loss: 0.070393  [64000/71622]
loss: 0.056850  [70400/71622]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.157503 

Epoch 44
-------------------------------
loss: 0.111585  [    0/71622]
loss: 0.052215  [ 6400/71622]
loss: 0.055836  [12800/71622]
loss: 0.112825  [19200/71622]
loss: 0.128128  [25600/71622]
loss: 0.092591  [32000/71622]
loss: 0.075580  [38400/71622]
loss: 0.017630  [44800/71622]
loss: 0.037501  [51200/71622]
loss: 0.179826  [57600/71622]
loss: 0.121649  [64000/71622]
loss: 0.029499  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.137284 

Epoch 45
-------------------------------
loss: 0.052297  [    0/71622]
loss: 0.065823  [ 6400/71622]
loss: 0.100896  [12800/71622]
loss: 0.086008  [19200/71622]
loss: 0.054661  [25600/71622]
loss: 0.054534  [32000/71622]
loss: 0.065566  [38400/71622]
loss: 0.085724  [44800/71622]
loss: 0.110225  [51200/71622]
loss: 0.070478  [57600/71622]
loss: 0.045916  [64000/71622]
loss: 0.149903  [70400/71622]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.152246 

Epoch 46
-------------------------------
loss: 0.017926  [    0/71622]
loss: 0.040844  [ 6400/71622]
loss: 0.036692  [12800/71622]
loss: 0.060379  [19200/71622]
loss: 0.030530  [25600/71622]
loss: 0.072049  [32000/71622]
loss: 0.040238  [38400/71622]
loss: 0.164050  [44800/71622]
loss: 0.087286  [51200/71622]
loss: 0.076280  [57600/71622]
loss: 0.073636  [64000/71622]
loss: 0.019335  [70400/71622]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.131600 

Epoch 47
-------------------------------
loss: 0.030828  [    0/71622]
loss: 0.052192  [ 6400/71622]
loss: 0.021179  [12800/71622]
loss: 0.032935  [19200/71622]
loss: 0.026954  [25600/71622]
loss: 0.078481  [32000/71622]
loss: 0.073282  [38400/71622]
loss: 0.021248  [44800/71622]
loss: 0.097516  [51200/71622]
loss: 0.069630  [57600/71622]
loss: 0.059772  [64000/71622]
loss: 0.054272  [70400/71622]
Test Error: 
 Accuracy: 90.6%, Avg loss: 0.272904 

Epoch 48
-------------------------------
loss: 0.274138  [    0/71622]
loss: 0.046088  [ 6400/71622]
loss: 0.016213  [12800/71622]
loss: 0.087565  [19200/71622]
loss: 0.077233  [25600/71622]
loss: 0.025061  [32000/71622]
loss: 0.094762  [38400/71622]
loss: 0.040577  [44800/71622]
loss: 0.105929  [51200/71622]
loss: 0.102678  [57600/71622]
loss: 0.027882  [64000/71622]
loss: 0.114116  [70400/71622]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.264807 

Epoch 49
-------------------------------
loss: 0.142382  [    0/71622]
loss: 0.049623  [ 6400/71622]
loss: 0.045184  [12800/71622]
loss: 0.056346  [19200/71622]
loss: 0.073836  [25600/71622]
loss: 0.132548  [32000/71622]
loss: 0.153183  [38400/71622]
loss: 0.103113  [44800/71622]
loss: 0.110367  [51200/71622]
loss: 0.125690  [57600/71622]
2022/09/20 16:14:28 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:15:03 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:15:56 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.147918  [57600/70935]
loss: 0.135015  [64000/70935]
loss: 0.175861  [70400/70935]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.158381 

Epoch 32
-------------------------------
loss: 0.071187  [    0/70935]
loss: 0.221201  [ 6400/70935]
loss: 0.105846  [12800/70935]
loss: 0.157068  [19200/70935]
loss: 0.136125  [25600/70935]
loss: 0.151592  [32000/70935]
loss: 0.151991  [38400/70935]
loss: 0.256221  [44800/70935]
loss: 0.169688  [51200/70935]
loss: 0.221737  [57600/70935]
loss: 0.278324  [64000/70935]
loss: 0.123642  [70400/70935]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.151135 

Epoch 33
-------------------------------
loss: 0.106060  [    0/70935]
loss: 0.177057  [ 6400/70935]
loss: 0.095511  [12800/70935]
loss: 0.214873  [19200/70935]
loss: 0.144182  [25600/70935]
loss: 0.159803  [32000/70935]
loss: 0.120363  [38400/70935]
loss: 0.170218  [44800/70935]
loss: 0.121888  [51200/70935]
loss: 0.147326  [57600/70935]
loss: 0.089012  [64000/70935]
loss: 0.259306  [70400/70935]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.156866 

Epoch 34
-------------------------------
loss: 0.060646  [    0/70935]
loss: 0.220969  [ 6400/70935]
loss: 0.070872  [12800/70935]
loss: 0.077098  [19200/70935]
loss: 0.094740  [25600/70935]
loss: 0.097899  [32000/70935]
loss: 0.252518  [38400/70935]
loss: 0.176190  [44800/70935]
loss: 0.162085  [51200/70935]
loss: 0.162651  [57600/70935]
loss: 0.149455  [64000/70935]
loss: 0.129205  [70400/70935]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.148616 

Epoch 35
-------------------------------
loss: 0.149094  [    0/70935]
loss: 0.143633  [ 6400/70935]
loss: 0.092024  [12800/70935]
loss: 0.089248  [19200/70935]
loss: 0.149682  [25600/70935]
loss: 0.126117  [32000/70935]
loss: 0.097008  [38400/70935]
loss: 0.112969  [44800/70935]
loss: 0.092019  [51200/70935]
loss: 0.086421  [57600/70935]
loss: 0.162290  [64000/70935]
loss: 0.090817  [70400/70935]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.168031 

Epoch 36
-------------------------------
loss: 0.118342  [    0/70935]
loss: 0.060481  [ 6400/70935]
loss: 0.042929  [12800/70935]
loss: 0.134149  [19200/70935]
loss: 0.081656  [25600/70935]
loss: 0.120120  [32000/70935]
loss: 0.052494  [38400/70935]
loss: 0.106650  [44800/70935]
loss: 0.109861  [51200/70935]
loss: 0.078406  [57600/70935]
loss: 0.065438  [64000/70935]
loss: 0.156279  [70400/70935]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.161068 

Epoch 37
-------------------------------
loss: 0.078452  [    0/70935]
loss: 0.063877  [ 6400/70935]
loss: 0.098021  [12800/70935]
loss: 1.686489  [19200/70935]
loss: 0.131836  [25600/70935]
loss: 0.065477  [32000/70935]
loss: 0.204106  [38400/70935]
loss: 0.133501  [44800/70935]
loss: 0.113432  [51200/70935]
loss: 0.101527  [57600/70935]
loss: 0.190167  [64000/70935]
loss: 0.130242  [70400/70935]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.162114 

Epoch 38
-------------------------------
loss: 0.290049  [    0/70935]
loss: 0.239399  [ 6400/70935]
loss: 0.209351  [12800/70935]
loss: 1.678110  [19200/70935]
loss: 0.115909  [25600/70935]
loss: 0.148586  [32000/70935]
loss: 0.196064  [38400/70935]
loss: 0.124486  [44800/70935]
loss: 0.193004  [51200/70935]
loss: 0.109489  [57600/70935]
loss: 0.052431  [64000/70935]
loss: 0.147317  [70400/70935]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.190779 

Epoch 39
-------------------------------
loss: 0.094939  [    0/70935]
loss: 0.071380  [ 6400/70935]
loss: 0.071020  [12800/70935]
loss: 0.056300  [19200/70935]
loss: 0.124857  [25600/70935]
loss: 0.176829  [32000/70935]
loss: 0.177146  [38400/70935]
loss: 0.147723  [44800/70935]
loss: 0.062097  [51200/70935]
loss: 0.307001  [57600/70935]
loss: 0.105716  [64000/70935]
loss: 0.154132  [70400/70935]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.173504 

Epoch 40
-------------------------------
loss: 0.287162  [    0/70935]
loss: 0.087694  [ 6400/70935]
loss: 0.138216  [12800/70935]
loss: 0.144561  [19200/70935]
loss: 0.039415  [25600/70935]
loss: 0.133832  [32000/70935]
loss: 0.099616  [38400/70935]
loss: 0.135367  [44800/70935]
loss: 0.108901  [51200/70935]
loss: 0.231423  [57600/70935]
loss: 0.112666  [64000/70935]
loss: 0.077272  [70400/70935]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.172038 

Epoch 41
-------------------------------
loss: 0.159553  [    0/70935]
loss: 0.059432  [ 6400/70935]
loss: 0.077982  [12800/70935]
loss: 0.262141  [19200/70935]
loss: 0.150378  [25600/70935]
loss: 0.070974  [32000/70935]
loss: 0.102225  [38400/70935]
loss: 0.222143  [44800/70935]
loss: 0.089942  [51200/70935]
loss: 0.106580  [57600/70935]
loss: 0.090653  [64000/70935]
loss: 0.204651  [70400/70935]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.183042 

Epoch 42
-------------------------------
loss: 0.125538  [    0/70935]
loss: 0.127493  [ 6400/70935]
loss: 0.157239  [12800/70935]
loss: 0.039310  [19200/70935]
loss: 0.067119  [25600/70935]
loss: 0.029770  [32000/70935]
loss: 0.048588  [38400/70935]
loss: 0.295236  [44800/70935]
loss: 0.047607  [51200/70935]
loss: 0.144428  [57600/70935]
loss: 0.090366  [64000/70935]
loss: 0.068562  [70400/70935]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.153095 

Epoch 43
-------------------------------
loss: 0.060711  [    0/70935]
loss: 0.154385  [ 6400/70935]
loss: 0.125786  [12800/70935]
loss: 0.077360  [19200/70935]
loss: 0.107290  [25600/70935]
loss: 0.073484  [32000/70935]
loss: 0.062520  [38400/70935]
loss: 0.113434  [44800/70935]
loss: 0.150839  [51200/70935]
loss: 0.051705  [57600/70935]
loss: 0.069075  [64000/70935]
loss: 0.117311  [70400/70935]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.156732 

Epoch 44
-------------------------------
loss: 0.186352  [    0/70935]
loss: 0.189329  [ 6400/70935]
loss: 0.127974  [12800/70935]
loss: 0.098371  [19200/70935]
loss: 0.136169  [25600/70935]
loss: 0.034113  [32000/70935]
loss: 0.103734  [38400/70935]
loss: 0.072947  [44800/70935]
loss: 0.188419  [51200/70935]
loss: 0.131055  [57600/70935]
loss: 0.112352  [64000/70935]
loss: 0.083449  [70400/70935]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.168252 

Epoch 45
-------------------------------
loss: 0.183366  [    0/70935]
loss: 0.092292  [ 6400/70935]
loss: 0.065135  [12800/70935]
loss: 0.081203  [19200/70935]
loss: 0.036666  [25600/70935]
loss: 0.209480  [32000/70935]
loss: 0.104162  [38400/70935]
loss: 0.089295  [44800/70935]
loss: 0.093691  [51200/70935]
loss: 0.121954  [57600/70935]
loss: 0.188956  [64000/70935]
loss: 0.181306  [70400/70935]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.151918 

Epoch 46
-------------------------------
loss: 0.106460  [    0/70935]
loss: 0.119583  [ 6400/70935]
loss: 0.176631  [12800/70935]
loss: 0.061713  [19200/70935]
loss: 0.155711  [25600/70935]
loss: 0.181733  [32000/70935]
loss: 0.194011  [38400/70935]
loss: 0.096552  [44800/70935]
loss: 0.069207  [51200/70935]
loss: 0.092810  [57600/70935]
loss: 0.099687  [64000/70935]
loss: 0.098898  [70400/70935]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.159124 

Epoch 47
-------------------------------
loss: 0.140839  [    0/70935]
loss: 0.140248  [ 6400/70935]
loss: 0.211998  [12800/70935]
loss: 0.191733  [19200/70935]
loss: 0.170383  [25600/70935]
loss: 0.112482  [32000/70935]
loss: 0.140828  [38400/70935]
loss: 0.217991  [44800/70935]
loss: 0.086769  [51200/70935]
loss: 0.098021  [57600/70935]
loss: 0.091628  [64000/70935]
loss: 0.116226  [70400/70935]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.159882 

Epoch 48
-------------------------------
loss: 0.109208  [    0/70935]
loss: 0.131947  [ 6400/70935]
loss: 0.119093  [12800/70935]
loss: 0.244317  [19200/70935]
loss: 0.159040  [25600/70935]
loss: 0.054371  [32000/70935]
loss: 0.105916  [38400/70935]
loss: 0.184696  [44800/70935]
loss: 0.183739  [51200/70935]
loss: 0.104793  [57600/70935]
loss: 0.201521  [64000/70935]
loss: 0.077952  [70400/70935]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.154142 

Epoch 49
-------------------------------
loss: 0.137200  [    0/70935]
loss: 0.182716  [ 6400/70935]
loss: 0.133543  [12800/70935]
loss: 0.109514  [19200/70935]
loss: 0.042908  [25600/70935]
loss: 0.116183  [32000/70935]
loss: 0.139142  [38400/70935]
loss: 0.141767  [44800/70935]
loss: 0.090107  [51200/70935]
loss: 0.164898  [57600/70935]
2022/09/20 16:17:31 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:18:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:19:05 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.177753 

Epoch 35
-------------------------------
loss: 0.123567  [    0/70702]
loss: 0.108745  [ 6400/70702]
loss: 0.109156  [12800/70702]
loss: 0.136377  [19200/70702]
loss: 0.099304  [25600/70702]
loss: 0.084402  [32000/70702]
loss: 0.139079  [38400/70702]
loss: 0.165958  [44800/70702]
loss: 0.061042  [51200/70702]
loss: 0.066648  [57600/70702]
loss: 0.122129  [64000/70702]
loss: 0.132080  [70400/70702]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.175491 

Epoch 36
-------------------------------
loss: 0.068039  [    0/70702]
loss: 0.104811  [ 6400/70702]
loss: 0.262332  [12800/70702]
loss: 0.146891  [19200/70702]
loss: 0.093117  [25600/70702]
loss: 0.108379  [32000/70702]
loss: 0.171153  [38400/70702]
loss: 0.120557  [44800/70702]
loss: 0.214386  [51200/70702]
loss: 0.061613  [57600/70702]
loss: 0.145655  [64000/70702]
loss: 0.037029  [70400/70702]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.166546 

Epoch 37
-------------------------------
loss: 0.109486  [    0/70702]
loss: 0.088248  [ 6400/70702]
loss: 0.092168  [12800/70702]
loss: 0.163132  [19200/70702]
loss: 0.104943  [25600/70702]
loss: 0.093204  [32000/70702]
loss: 0.097629  [38400/70702]
loss: 0.118199  [44800/70702]
loss: 0.099109  [51200/70702]
loss: 0.142577  [57600/70702]
loss: 0.095034  [64000/70702]
loss: 0.149121  [70400/70702]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.174794 

Epoch 38
-------------------------------
loss: 0.134759  [    0/70702]
loss: 0.105304  [ 6400/70702]
loss: 0.124353  [12800/70702]
loss: 0.137508  [19200/70702]
loss: 0.142469  [25600/70702]
loss: 0.067501  [32000/70702]
loss: 0.101045  [38400/70702]
loss: 0.078982  [44800/70702]
loss: 0.167224  [51200/70702]
loss: 0.205678  [57600/70702]
loss: 0.069259  [64000/70702]
loss: 0.170276  [70400/70702]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.168219 

Epoch 39
-------------------------------
loss: 0.079346  [    0/70702]
loss: 0.139884  [ 6400/70702]
loss: 0.146024  [12800/70702]
loss: 0.146646  [19200/70702]
loss: 0.068273  [25600/70702]
loss: 0.174292  [32000/70702]
loss: 0.193147  [38400/70702]
loss: 0.082021  [44800/70702]
loss: 0.128344  [51200/70702]
loss: 0.154701  [57600/70702]
loss: 0.158156  [64000/70702]
loss: 0.270343  [70400/70702]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.172476 

Epoch 40
-------------------------------
loss: 0.056074  [    0/70702]
loss: 0.147412  [ 6400/70702]
loss: 0.121518  [12800/70702]
loss: 0.122994  [19200/70702]
loss: 0.126807  [25600/70702]
loss: 0.065378  [32000/70702]
loss: 0.114058  [38400/70702]
loss: 0.205625  [44800/70702]
loss: 0.153007  [51200/70702]
loss: 0.122354  [57600/70702]
loss: 0.149586  [64000/70702]
loss: 0.139211  [70400/70702]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.174382 

Epoch 41
-------------------------------
loss: 0.180022  [    0/70702]
loss: 0.084300  [ 6400/70702]
loss: 0.098775  [12800/70702]
loss: 0.147746  [19200/70702]
loss: 0.105354  [25600/70702]
loss: 0.155142  [32000/70702]
loss: 0.052279  [38400/70702]
loss: 0.117875  [44800/70702]
loss: 0.097285  [51200/70702]
loss: 0.078816  [57600/70702]
loss: 0.164159  [64000/70702]
loss: 1.893293  [70400/70702]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.185164 

Epoch 42
-------------------------------
loss: 0.062793  [    0/70702]
loss: 0.124342  [ 6400/70702]
loss: 0.026617  [12800/70702]
loss: 0.196254  [19200/70702]
loss: 0.236248  [25600/70702]
loss: 0.303455  [32000/70702]
loss: 0.109760  [38400/70702]
loss: 0.148110  [44800/70702]
loss: 0.075441  [51200/70702]
loss: 0.110092  [57600/70702]
loss: 0.062168  [64000/70702]
loss: 0.235748  [70400/70702]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.174798 

Epoch 43
-------------------------------
loss: 0.152637  [    0/70702]
loss: 0.145859  [ 6400/70702]
loss: 0.109618  [12800/70702]
loss: 0.136422  [19200/70702]
loss: 0.051444  [25600/70702]
loss: 0.195158  [32000/70702]
loss: 0.183525  [38400/70702]
loss: 0.090817  [44800/70702]
loss: 0.152934  [51200/70702]
loss: 0.073635  [57600/70702]
loss: 0.069187  [64000/70702]
loss: 0.053990  [70400/70702]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.174561 

Epoch 44
-------------------------------
loss: 0.099765  [    0/70702]
loss: 0.188314  [ 6400/70702]
loss: 0.135895  [12800/70702]
loss: 0.083695  [19200/70702]
loss: 0.141196  [25600/70702]
loss: 0.161756  [32000/70702]
loss: 0.096914  [38400/70702]
loss: 0.138306  [44800/70702]
loss: 0.057984  [51200/70702]
loss: 0.138777  [57600/70702]
loss: 0.095812  [64000/70702]
loss: 0.109734  [70400/70702]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.175151 

Epoch 45
-------------------------------
loss: 0.203360  [    0/70702]
loss: 0.093499  [ 6400/70702]
loss: 0.161868  [12800/70702]
loss: 0.129698  [19200/70702]
loss: 1.729196  [25600/70702]
loss: 0.102399  [32000/70702]
loss: 0.086754  [38400/70702]
loss: 0.164573  [44800/70702]
loss: 0.170548  [51200/70702]
loss: 0.103321  [57600/70702]
loss: 0.307522  [64000/70702]
loss: 0.119681  [70400/70702]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.186579 

Epoch 46
-------------------------------
loss: 0.078870  [    0/70702]
loss: 0.135065  [ 6400/70702]
loss: 0.087869  [12800/70702]
loss: 0.182603  [19200/70702]
loss: 0.163463  [25600/70702]
loss: 0.128474  [32000/70702]
loss: 0.204787  [38400/70702]
loss: 0.162309  [44800/70702]
loss: 0.135602  [51200/70702]
loss: 0.139801  [57600/70702]
loss: 0.098929  [64000/70702]
loss: 0.094686  [70400/70702]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.169844 

Epoch 47
-------------------------------
loss: 0.092167  [    0/70702]
loss: 0.131694  [ 6400/70702]
loss: 0.083116  [12800/70702]
loss: 0.160726  [19200/70702]
loss: 0.133193  [25600/70702]
loss: 0.131371  [32000/70702]
loss: 0.064067  [38400/70702]
loss: 0.117281  [44800/70702]
loss: 0.118136  [51200/70702]
loss: 0.324116  [57600/70702]
loss: 0.092918  [64000/70702]
loss: 0.129629  [70400/70702]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.194764 

Epoch 48
-------------------------------
loss: 0.135903  [    0/70702]
loss: 0.079013  [ 6400/70702]
loss: 0.065718  [12800/70702]
loss: 0.075832  [19200/70702]
loss: 0.047445  [25600/70702]
loss: 0.128291  [32000/70702]
loss: 0.104021  [38400/70702]
loss: 0.102304  [44800/70702]
loss: 0.062089  [51200/70702]
loss: 1.665020  [57600/70702]
loss: 0.150555  [64000/70702]
loss: 0.141224  [70400/70702]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.167986 

Epoch 49
-------------------------------
loss: 0.097598  [    0/70702]
loss: 0.119551  [ 6400/70702]
loss: 0.099338  [12800/70702]
loss: 0.097269  [19200/70702]
loss: 0.101418  [25600/70702]
loss: 0.124031  [32000/70702]
loss: 0.147309  [38400/70702]
loss: 0.103071  [44800/70702]
loss: 0.147735  [51200/70702]
loss: 0.063329  [57600/70702]
loss: 0.137116  [64000/70702]
loss: 0.077270  [70400/70702]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.166705 

Epoch 50
-------------------------------
loss: 0.112320  [    0/70702]
loss: 0.107516  [ 6400/70702]
loss: 0.076435  [12800/70702]
loss: 0.199772  [19200/70702]
loss: 0.105887  [25600/70702]
loss: 0.140630  [32000/70702]
loss: 0.071224  [38400/70702]
loss: 0.061959  [44800/70702]
loss: 0.119678  [51200/70702]
loss: 0.092324  [57600/70702]
loss: 0.140547  [64000/70702]
loss: 0.117818  [70400/70702]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.173934 

Epoch 1
-------------------------------
loss: 0.666650  [    0/69168]
loss: 0.410643  [ 6400/69168]
loss: 0.295386  [12800/69168]
loss: 0.406021  [19200/69168]
loss: 0.341289  [25600/69168]
loss: 0.284188  [32000/69168]
loss: 0.222993  [38400/69168]
loss: 0.273891  [44800/69168]
loss: 0.307570  [51200/69168]
loss: 0.477236  [57600/69168]
loss: 0.229578  [64000/69168]
Test Error: 
 Accuracy: 89.9%, Avg loss: 0.247486 

Epoch 2
-------------------------------
loss: 0.164829  [    0/69168]
loss: 0.318029  [ 6400/69168]
loss: 0.303972  [12800/69168]
loss: 0.284721  [19200/69168]
loss: 0.389945  [25600/69168]
loss: 0.160591  [32000/69168]
loss: 0.177124  [38400/69168]
loss: 0.290135  [44800/69168]
loss: 0.204274  [51200/69168]
loss: 0.076262  [57600/69168]
loss: 0.309415  [64000/69168]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.219066 

Epoch 3
-------------------------------
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.152766 

Epoch 34
-------------------------------
loss: 0.090656  [    0/69264]
loss: 0.137777  [ 6400/69264]
loss: 0.178803  [12800/69264]
loss: 0.128474  [19200/69264]
loss: 0.091672  [25600/69264]
loss: 0.139968  [32000/69264]
loss: 0.168828  [38400/69264]
loss: 0.110420  [44800/69264]
loss: 0.112543  [51200/69264]
loss: 0.105425  [57600/69264]
loss: 0.110999  [64000/69264]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.164923 

Epoch 35
-------------------------------
loss: 0.166499  [    0/69264]
loss: 0.109595  [ 6400/69264]
loss: 0.161909  [12800/69264]
loss: 0.233370  [19200/69264]
loss: 0.362617  [25600/69264]
loss: 0.057687  [32000/69264]
loss: 0.168625  [38400/69264]
loss: 0.130418  [44800/69264]
loss: 0.184766  [51200/69264]
loss: 0.064070  [57600/69264]
loss: 0.145018  [64000/69264]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.157830 

Epoch 36
-------------------------------
loss: 0.147497  [    0/69264]
loss: 0.105075  [ 6400/69264]
loss: 0.106257  [12800/69264]
loss: 0.129414  [19200/69264]
loss: 0.109092  [25600/69264]
loss: 0.182302  [32000/69264]
loss: 0.118385  [38400/69264]
loss: 0.099745  [44800/69264]
loss: 0.146733  [51200/69264]
loss: 0.158125  [57600/69264]
loss: 0.087977  [64000/69264]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.170168 

Epoch 37
-------------------------------
loss: 0.258292  [    0/69264]
loss: 0.229222  [ 6400/69264]
loss: 0.086517  [12800/69264]
loss: 0.169174  [19200/69264]
loss: 0.153383  [25600/69264]
loss: 0.175452  [32000/69264]
loss: 0.131282  [38400/69264]
loss: 0.079180  [44800/69264]
loss: 0.154987  [51200/69264]
loss: 0.331012  [57600/69264]
loss: 0.172230  [64000/69264]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.157643 

Epoch 38
-------------------------------
loss: 0.104334  [    0/69264]
loss: 0.083992  [ 6400/69264]
loss: 0.131109  [12800/69264]
loss: 0.169487  [19200/69264]
loss: 0.098078  [25600/69264]
loss: 0.259424  [32000/69264]
loss: 0.107483  [38400/69264]
loss: 0.170045  [44800/69264]
loss: 0.156375  [51200/69264]
loss: 0.120925  [57600/69264]
loss: 0.108885  [64000/69264]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.186101 

Epoch 39
-------------------------------
loss: 0.265187  [    0/69264]
loss: 0.096143  [ 6400/69264]
loss: 0.194810  [12800/69264]
loss: 0.154874  [19200/69264]
loss: 0.100798  [25600/69264]
loss: 0.143797  [32000/69264]
loss: 0.158280  [38400/69264]
loss: 0.046279  [44800/69264]
loss: 0.152055  [51200/69264]
loss: 0.162679  [57600/69264]
loss: 0.156212  [64000/69264]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.154080 

Epoch 40
-------------------------------
loss: 0.129855  [    0/69264]
loss: 0.134488  [ 6400/69264]
loss: 0.144294  [12800/69264]
loss: 0.180834  [19200/69264]
loss: 0.168414  [25600/69264]
loss: 0.107167  [32000/69264]
loss: 0.137603  [38400/69264]
loss: 0.101000  [44800/69264]
loss: 0.179395  [51200/69264]
loss: 0.102087  [57600/69264]
loss: 0.177736  [64000/69264]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.165642 

Epoch 41
-------------------------------
loss: 0.171740  [    0/69264]
loss: 0.137113  [ 6400/69264]
loss: 0.087287  [12800/69264]
loss: 0.197463  [19200/69264]
loss: 0.151106  [25600/69264]
loss: 0.171077  [32000/69264]
loss: 0.139966  [38400/69264]
loss: 0.171199  [44800/69264]
loss: 0.089249  [51200/69264]
loss: 0.145563  [57600/69264]
loss: 0.116596  [64000/69264]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.166851 

Epoch 42
-------------------------------
loss: 0.093306  [    0/69264]
loss: 0.199318  [ 6400/69264]
loss: 0.119845  [12800/69264]
loss: 0.087615  [19200/69264]
loss: 0.076496  [25600/69264]
loss: 0.193616  [32000/69264]
loss: 0.167688  [38400/69264]
loss: 0.239278  [44800/69264]
loss: 0.100280  [51200/69264]
loss: 0.322700  [57600/69264]
loss: 0.091347  [64000/69264]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.164130 

Epoch 43
-------------------------------
loss: 0.226445  [    0/69264]
loss: 0.151119  [ 6400/69264]
loss: 0.092983  [12800/69264]
loss: 0.228491  [19200/69264]
loss: 0.171245  [25600/69264]
loss: 0.150703  [32000/69264]
loss: 0.146913  [38400/69264]
loss: 0.089454  [44800/69264]
loss: 0.108544  [51200/69264]
loss: 0.101912  [57600/69264]
loss: 0.128121  [64000/69264]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.154233 

Epoch 44
-------------------------------
loss: 1.623294  [    0/69264]
loss: 0.084365  [ 6400/69264]
loss: 0.180281  [12800/69264]
loss: 0.173887  [19200/69264]
loss: 0.177114  [25600/69264]
loss: 0.144566  [32000/69264]
loss: 0.065287  [38400/69264]
loss: 0.104866  [44800/69264]
loss: 0.144434  [51200/69264]
loss: 0.146427  [57600/69264]
loss: 0.255688  [64000/69264]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.159072 

Epoch 45
-------------------------------
loss: 0.207606  [    0/69264]
loss: 0.103428  [ 6400/69264]
loss: 0.127688  [12800/69264]
loss: 0.273937  [19200/69264]
loss: 0.239370  [25600/69264]
loss: 0.107072  [32000/69264]
loss: 0.222799  [38400/69264]
loss: 0.114086  [44800/69264]
loss: 0.082308  [51200/69264]
loss: 0.087178  [57600/69264]
loss: 0.151751  [64000/69264]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.153288 

Epoch 46
-------------------------------
loss: 0.148689  [    0/69264]
loss: 0.258594  [ 6400/69264]
loss: 0.193655  [12800/69264]
loss: 0.198394  [19200/69264]
loss: 0.151238  [25600/69264]
loss: 0.154526  [32000/69264]
loss: 0.108592  [38400/69264]
loss: 0.142825  [44800/69264]
loss: 0.102134  [51200/69264]
loss: 0.089406  [57600/69264]
loss: 0.082608  [64000/69264]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.158818 

Epoch 47
-------------------------------
loss: 0.132966  [    0/69264]
loss: 0.180062  [ 6400/69264]
loss: 0.132871  [12800/69264]
loss: 0.407704  [19200/69264]
loss: 0.177240  [25600/69264]
loss: 0.119858  [32000/69264]
loss: 0.148440  [38400/69264]
loss: 0.208432  [44800/69264]
loss: 0.112230  [51200/69264]
loss: 0.202902  [57600/69264]
loss: 0.243981  [64000/69264]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.161250 

Epoch 48
-------------------------------
loss: 0.096367  [    0/69264]
loss: 0.106999  [ 6400/69264]
loss: 0.185899  [12800/69264]
loss: 0.136910  [19200/69264]
loss: 0.104042  [25600/69264]
loss: 0.099386  [32000/69264]
loss: 0.255395  [38400/69264]
loss: 0.249549  [44800/69264]
loss: 0.126120  [51200/69264]
loss: 0.214585  [57600/69264]
loss: 0.066170  [64000/69264]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.166232 

Epoch 49
-------------------------------
loss: 0.122677  [    0/69264]
loss: 0.111339  [ 6400/69264]
loss: 0.067616  [12800/69264]
loss: 0.203392  [19200/69264]
loss: 0.111213  [25600/69264]
loss: 0.183973  [32000/69264]
loss: 0.102427  [38400/69264]
loss: 0.067943  [44800/69264]
loss: 0.059099  [51200/69264]
loss: 0.438206  [57600/69264]
loss: 0.222603  [64000/69264]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.168547 

Epoch 50
-------------------------------
loss: 0.175971  [    0/69264]
loss: 0.142234  [ 6400/69264]
loss: 0.135595  [12800/69264]
loss: 0.266940  [19200/69264]
loss: 0.283462  [25600/69264]
loss: 0.072247  [32000/69264]
loss: 0.187480  [38400/69264]
loss: 0.100480  [44800/69264]
loss: 0.118973  [51200/69264]
loss: 0.295689  [57600/69264]
loss: 0.157890  [64000/69264]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.149549 

Epoch 1
-------------------------------
loss: 0.675338  [    0/69947]
loss: 0.412505  [ 6400/69947]
loss: 0.189668  [12800/69947]
loss: 0.239182  [19200/69947]
loss: 0.237423  [25600/69947]
loss: 0.260012  [32000/69947]
loss: 0.197781  [38400/69947]
loss: 0.278558  [44800/69947]
loss: 0.140916  [51200/69947]
loss: 0.282456  [57600/69947]
loss: 0.218258  [64000/69947]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.211605 

Epoch 2
-------------------------------
loss: 0.167021  [    0/69947]
loss: 0.152501  [ 6400/69947]
loss: 0.142277  [12800/69947]
loss: 0.186930  [19200/69947]
loss: 0.093021  [25600/69947]
loss: 0.269734  [32000/69947]
loss: 0.156020  [38400/69947]
loss: 0.296624  [44800/69947]
loss: 0.224952  [51200/69947]
loss: 0.095534  [57600/69947]
loss: 0.148439  [64000/69947]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.191221 

Epoch 3
-------------------------------
loss: 0.176317  [    0/69947]
loss: 0.220904  [ 6400/69947]
loss: 0.130874  [57600/70696]
loss: 0.071505  [64000/70696]
loss: 0.168274  [70400/70696]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.179229 

Epoch 32
-------------------------------
loss: 0.123442  [    0/70696]
loss: 0.101022  [ 6400/70696]
loss: 0.205721  [12800/70696]
loss: 0.163893  [19200/70696]
loss: 0.109102  [25600/70696]
loss: 0.309499  [32000/70696]
loss: 0.139309  [38400/70696]
loss: 0.089854  [44800/70696]
loss: 0.195895  [51200/70696]
loss: 0.039611  [57600/70696]
loss: 0.155351  [64000/70696]
loss: 0.159223  [70400/70696]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.168195 

Epoch 33
-------------------------------
loss: 0.201048  [    0/70696]
loss: 0.085556  [ 6400/70696]
loss: 0.213506  [12800/70696]
loss: 0.120904  [19200/70696]
loss: 0.172971  [25600/70696]
loss: 0.156868  [32000/70696]
loss: 0.222787  [38400/70696]
loss: 0.125248  [44800/70696]
loss: 0.161542  [51200/70696]
loss: 0.138154  [57600/70696]
loss: 0.145292  [64000/70696]
loss: 0.219335  [70400/70696]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.195868 

Epoch 34
-------------------------------
loss: 0.140847  [    0/70696]
loss: 0.105839  [ 6400/70696]
loss: 0.114121  [12800/70696]
loss: 0.281742  [19200/70696]
loss: 0.167157  [25600/70696]
loss: 0.165524  [32000/70696]
loss: 0.083157  [38400/70696]
loss: 0.046917  [44800/70696]
loss: 0.097505  [51200/70696]
loss: 0.092402  [57600/70696]
loss: 0.234506  [64000/70696]
loss: 0.123259  [70400/70696]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.170257 

Epoch 35
-------------------------------
loss: 0.121591  [    0/70696]
loss: 0.068083  [ 6400/70696]
loss: 0.192786  [12800/70696]
loss: 0.220856  [19200/70696]
loss: 0.144681  [25600/70696]
loss: 0.096245  [32000/70696]
loss: 0.135838  [38400/70696]
loss: 0.079010  [44800/70696]
loss: 0.097985  [51200/70696]
loss: 0.137002  [57600/70696]
loss: 0.120711  [64000/70696]
loss: 0.102624  [70400/70696]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.169237 

Epoch 36
-------------------------------
loss: 0.074784  [    0/70696]
loss: 0.241295  [ 6400/70696]
loss: 0.113842  [12800/70696]
loss: 0.141144  [19200/70696]
loss: 0.185977  [25600/70696]
loss: 0.095853  [32000/70696]
loss: 0.175537  [38400/70696]
loss: 0.150410  [44800/70696]
loss: 0.088572  [51200/70696]
loss: 0.153316  [57600/70696]
loss: 0.086625  [64000/70696]
loss: 0.192652  [70400/70696]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.178605 

Epoch 37
-------------------------------
loss: 0.073866  [    0/70696]
loss: 0.075057  [ 6400/70696]
loss: 0.209113  [12800/70696]
loss: 0.095960  [19200/70696]
loss: 0.147688  [25600/70696]
loss: 0.113059  [32000/70696]
loss: 0.073542  [38400/70696]
loss: 0.127628  [44800/70696]
loss: 1.754858  [51200/70696]
loss: 0.124021  [57600/70696]
loss: 0.225129  [64000/70696]
loss: 0.153156  [70400/70696]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.170005 

Epoch 38
-------------------------------
loss: 0.271357  [    0/70696]
loss: 0.086577  [ 6400/70696]
loss: 0.094439  [12800/70696]
loss: 0.159263  [19200/70696]
loss: 0.156253  [25600/70696]
loss: 0.115931  [32000/70696]
loss: 0.213073  [38400/70696]
loss: 0.199647  [44800/70696]
loss: 0.118571  [51200/70696]
loss: 0.120383  [57600/70696]
loss: 0.194049  [64000/70696]
loss: 0.110196  [70400/70696]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.171967 

Epoch 39
-------------------------------
loss: 0.120715  [    0/70696]
loss: 0.148038  [ 6400/70696]
loss: 0.125925  [12800/70696]
loss: 0.271092  [19200/70696]
loss: 0.094948  [25600/70696]
loss: 0.104867  [32000/70696]
loss: 0.152899  [38400/70696]
loss: 0.197011  [44800/70696]
loss: 0.108157  [51200/70696]
loss: 0.128364  [57600/70696]
loss: 0.058821  [64000/70696]
loss: 0.193433  [70400/70696]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.178050 

Epoch 40
-------------------------------
loss: 0.097641  [    0/70696]
loss: 0.128683  [ 6400/70696]
loss: 0.079397  [12800/70696]
loss: 0.101941  [19200/70696]
loss: 0.222505  [25600/70696]
loss: 0.209511  [32000/70696]
loss: 0.160440  [38400/70696]
loss: 0.094467  [44800/70696]
loss: 0.071674  [51200/70696]
loss: 0.173670  [57600/70696]
loss: 0.147091  [64000/70696]
loss: 0.181433  [70400/70696]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171039 

Epoch 41
-------------------------------
loss: 0.139030  [    0/70696]
loss: 0.116263  [ 6400/70696]
loss: 0.109303  [12800/70696]
loss: 0.108286  [19200/70696]
loss: 0.195806  [25600/70696]
loss: 0.181340  [32000/70696]
loss: 0.187607  [38400/70696]
loss: 0.157772  [44800/70696]
loss: 0.156953  [51200/70696]
loss: 0.125548  [57600/70696]
loss: 0.207639  [64000/70696]
loss: 0.091660  [70400/70696]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.174804 

Epoch 42
-------------------------------
loss: 0.130702  [    0/70696]
loss: 0.175196  [ 6400/70696]
loss: 0.128162  [12800/70696]
loss: 0.070459  [19200/70696]
loss: 0.168336  [25600/70696]
loss: 0.055746  [32000/70696]
loss: 0.260190  [38400/70696]
loss: 0.199570  [44800/70696]
loss: 0.087186  [51200/70696]
loss: 0.155571  [57600/70696]
loss: 0.115587  [64000/70696]
loss: 0.122294  [70400/70696]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.179890 

Epoch 43
-------------------------------
loss: 0.154852  [    0/70696]
loss: 0.118666  [ 6400/70696]
loss: 0.152144  [12800/70696]
loss: 0.088372  [19200/70696]
loss: 0.079102  [25600/70696]
loss: 0.082616  [32000/70696]
loss: 0.132627  [38400/70696]
loss: 0.231593  [44800/70696]
loss: 0.163772  [51200/70696]
loss: 0.312169  [57600/70696]
loss: 0.120442  [64000/70696]
loss: 0.084863  [70400/70696]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.175324 

Epoch 44
-------------------------------
loss: 0.080340  [    0/70696]
loss: 0.035425  [ 6400/70696]
loss: 0.092744  [12800/70696]
loss: 0.147855  [19200/70696]
loss: 0.095221  [25600/70696]
loss: 0.084337  [32000/70696]
loss: 0.177140  [38400/70696]
loss: 0.066936  [44800/70696]
loss: 0.067250  [51200/70696]
loss: 0.296053  [57600/70696]
loss: 0.261959  [64000/70696]
loss: 0.145535  [70400/70696]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.170372 

Epoch 45
-------------------------------
loss: 0.084013  [    0/70696]
loss: 0.146659  [ 6400/70696]
loss: 0.147605  [12800/70696]
loss: 0.094012  [19200/70696]
loss: 0.085020  [25600/70696]
loss: 0.088817  [32000/70696]
loss: 0.092575  [38400/70696]
loss: 0.158790  [44800/70696]
loss: 0.159354  [51200/70696]
loss: 0.196039  [57600/70696]
loss: 0.172502  [64000/70696]
loss: 0.096982  [70400/70696]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.176008 

Epoch 46
-------------------------------
loss: 0.096141  [    0/70696]
loss: 0.079035  [ 6400/70696]
loss: 0.138381  [12800/70696]
loss: 0.149333  [19200/70696]
loss: 0.105326  [25600/70696]
loss: 0.114893  [32000/70696]
loss: 0.096933  [38400/70696]
loss: 0.112920  [44800/70696]
loss: 0.105592  [51200/70696]
loss: 0.055615  [57600/70696]
loss: 0.102846  [64000/70696]
loss: 0.118165  [70400/70696]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.178654 

Epoch 47
-------------------------------
loss: 0.125492  [    0/70696]
loss: 0.099958  [ 6400/70696]
loss: 0.256736  [12800/70696]
loss: 0.212407  [19200/70696]
loss: 0.114499  [25600/70696]
loss: 0.137595  [32000/70696]
loss: 0.142120  [38400/70696]
loss: 0.151347  [44800/70696]
loss: 0.081929  [51200/70696]
loss: 0.217212  [57600/70696]
loss: 0.166914  [64000/70696]
loss: 0.205099  [70400/70696]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.175928 

Epoch 48
-------------------------------
loss: 0.155778  [    0/70696]
loss: 0.120102  [ 6400/70696]
loss: 0.115355  [12800/70696]
loss: 0.062917  [19200/70696]
loss: 0.290931  [25600/70696]
loss: 0.171272  [32000/70696]
loss: 0.191210  [38400/70696]
loss: 0.183421  [44800/70696]
loss: 0.098609  [51200/70696]
loss: 0.073551  [57600/70696]
loss: 0.174550  [64000/70696]
loss: 0.107869  [70400/70696]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.185346 

Epoch 49
-------------------------------
loss: 0.133441  [    0/70696]
loss: 0.183804  [ 6400/70696]
loss: 0.134312  [12800/70696]
loss: 0.261465  [19200/70696]
loss: 0.190162  [25600/70696]
loss: 0.172931  [32000/70696]
loss: 0.062564  [38400/70696]
loss: 0.097915  [44800/70696]
loss: 0.347573  [51200/70696]
loss: 0.147501  [57600/70696]
loss: 0.057050  [32000/69807]
loss: 0.181277  [38400/69807]
loss: 0.254889  [44800/69807]
loss: 0.131867  [51200/69807]
loss: 0.105481  [57600/69807]
loss: 0.167291  [64000/69807]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.147875 

Epoch 38
-------------------------------
loss: 0.114533  [    0/69807]
loss: 0.172081  [ 6400/69807]
loss: 0.121066  [12800/69807]
loss: 0.103886  [19200/69807]
loss: 0.175756  [25600/69807]
loss: 0.053990  [32000/69807]
loss: 0.143276  [38400/69807]
loss: 0.079492  [44800/69807]
loss: 0.115585  [51200/69807]
loss: 0.125144  [57600/69807]
loss: 0.106198  [64000/69807]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.173032 

Epoch 39
-------------------------------
loss: 0.033030  [    0/69807]
loss: 0.110549  [ 6400/69807]
loss: 0.128728  [12800/69807]
loss: 0.080279  [19200/69807]
loss: 0.048145  [25600/69807]
loss: 0.170385  [32000/69807]
loss: 0.360536  [38400/69807]
loss: 0.158073  [44800/69807]
loss: 0.076465  [51200/69807]
loss: 0.160479  [57600/69807]
loss: 0.105707  [64000/69807]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.151029 

Epoch 40
-------------------------------
loss: 0.144305  [    0/69807]
loss: 0.109731  [ 6400/69807]
loss: 0.109403  [12800/69807]
loss: 0.102815  [19200/69807]
loss: 0.214613  [25600/69807]
loss: 0.112076  [32000/69807]
loss: 0.167609  [38400/69807]
loss: 0.084923  [44800/69807]
loss: 0.142087  [51200/69807]
loss: 0.081203  [57600/69807]
loss: 0.148911  [64000/69807]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.147709 

Epoch 41
-------------------------------
loss: 0.102560  [    0/69807]
loss: 0.144862  [ 6400/69807]
loss: 0.095550  [12800/69807]
loss: 0.082466  [19200/69807]
loss: 0.142829  [25600/69807]
loss: 0.159402  [32000/69807]
loss: 0.063327  [38400/69807]
loss: 0.071146  [44800/69807]
loss: 0.059766  [51200/69807]
loss: 0.184473  [57600/69807]
loss: 0.181871  [64000/69807]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.155838 

Epoch 42
-------------------------------
loss: 0.097363  [    0/69807]
loss: 0.069031  [ 6400/69807]
loss: 0.092663  [12800/69807]
loss: 0.109925  [19200/69807]
loss: 0.109812  [25600/69807]
loss: 0.099517  [32000/69807]
loss: 0.089751  [38400/69807]
loss: 0.086097  [44800/69807]
loss: 0.048592  [51200/69807]
loss: 1.772478  [57600/69807]
loss: 0.134962  [64000/69807]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.160880 

Epoch 43
-------------------------------
loss: 0.207322  [    0/69807]
loss: 0.100183  [ 6400/69807]
loss: 0.070534  [12800/69807]
loss: 0.198115  [19200/69807]
loss: 0.146884  [25600/69807]
loss: 0.116358  [32000/69807]
loss: 0.110734  [38400/69807]
loss: 0.205333  [44800/69807]
loss: 0.125396  [51200/69807]
loss: 0.172676  [57600/69807]
loss: 0.167593  [64000/69807]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.161088 

Epoch 44
-------------------------------
loss: 0.136937  [    0/69807]
loss: 0.100314  [ 6400/69807]
loss: 0.118562  [12800/69807]
loss: 0.066357  [19200/69807]
loss: 0.114277  [25600/69807]
loss: 0.061632  [32000/69807]
loss: 0.156588  [38400/69807]
loss: 0.084164  [44800/69807]
loss: 0.018752  [51200/69807]
loss: 0.183074  [57600/69807]
loss: 0.068565  [64000/69807]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.155458 

Epoch 45
-------------------------------
loss: 0.131807  [    0/69807]
loss: 0.099114  [ 6400/69807]
loss: 0.111135  [12800/69807]
loss: 0.129258  [19200/69807]
loss: 0.165592  [25600/69807]
loss: 0.100999  [32000/69807]
loss: 0.107047  [38400/69807]
loss: 0.091267  [44800/69807]
loss: 0.207826  [51200/69807]
loss: 0.140966  [57600/69807]
loss: 0.192034  [64000/69807]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.153802 

Epoch 46
-------------------------------
loss: 0.071698  [    0/69807]
loss: 0.116654  [ 6400/69807]
loss: 0.173499  [12800/69807]
loss: 0.129446  [19200/69807]
loss: 0.146970  [25600/69807]
loss: 0.122229  [32000/69807]
loss: 1.638534  [38400/69807]
loss: 0.184777  [44800/69807]
loss: 0.101520  [51200/69807]
loss: 0.160401  [57600/69807]
loss: 1.657389  [64000/69807]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.153613 

Epoch 47
-------------------------------
loss: 0.066559  [    0/69807]
loss: 0.178610  [ 6400/69807]
loss: 0.113614  [12800/69807]
loss: 0.080775  [19200/69807]
loss: 0.069439  [25600/69807]
loss: 0.072750  [32000/69807]
loss: 0.112726  [38400/69807]
loss: 0.102038  [44800/69807]
loss: 0.078298  [51200/69807]
loss: 0.031284  [57600/69807]
loss: 0.090289  [64000/69807]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153830 

Epoch 48
-------------------------------
loss: 0.132142  [    0/69807]
loss: 0.129434  [ 6400/69807]
loss: 0.104362  [12800/69807]
loss: 0.068986  [19200/69807]
loss: 0.143463  [25600/69807]
loss: 0.085598  [32000/69807]
loss: 0.115572  [38400/69807]
loss: 0.160285  [44800/69807]
loss: 0.101867  [51200/69807]
loss: 0.136041  [57600/69807]
loss: 0.103058  [64000/69807]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.161262 

Epoch 49
-------------------------------
loss: 0.084670  [    0/69807]
loss: 0.075326  [ 6400/69807]
loss: 0.166859  [12800/69807]
loss: 0.085512  [19200/69807]
loss: 0.038749  [25600/69807]
loss: 0.041126  [32000/69807]
loss: 0.072852  [38400/69807]
loss: 0.139856  [44800/69807]
loss: 0.139178  [51200/69807]
loss: 0.193487  [57600/69807]
loss: 0.128732  [64000/69807]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.148732 

Epoch 50
-------------------------------
loss: 0.119535  [    0/69807]
loss: 0.105906  [ 6400/69807]
loss: 0.176442  [12800/69807]
loss: 0.249948  [19200/69807]
loss: 0.096540  [25600/69807]
loss: 0.023790  [32000/69807]
loss: 0.152315  [38400/69807]
loss: 0.117272  [44800/69807]
loss: 0.218115  [51200/69807]
loss: 0.076124  [57600/69807]
loss: 0.152377  [64000/69807]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.135982 

Epoch 1
-------------------------------
loss: 0.645237  [    0/70080]
loss: 0.267555  [ 6400/70080]
loss: 0.257797  [12800/70080]
loss: 0.149993  [19200/70080]
loss: 0.215905  [25600/70080]
loss: 0.255198  [32000/70080]
loss: 0.203192  [38400/70080]
loss: 0.145428  [44800/70080]
loss: 0.133635  [51200/70080]
loss: 0.097308  [57600/70080]
loss: 0.148129  [64000/70080]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177179 

Epoch 2
-------------------------------
loss: 0.099134  [    0/70080]
loss: 0.240461  [ 6400/70080]
loss: 0.206299  [12800/70080]
loss: 0.221168  [19200/70080]
loss: 0.044942  [25600/70080]
loss: 0.060381  [32000/70080]
loss: 0.300259  [38400/70080]
loss: 0.073628  [44800/70080]
loss: 0.180134  [51200/70080]
loss: 0.230469  [57600/70080]
loss: 0.258737  [64000/70080]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.167219 

Epoch 3
-------------------------------
loss: 0.132409  [    0/70080]
loss: 0.068013  [ 6400/70080]
loss: 0.101679  [12800/70080]
loss: 0.093660  [19200/70080]
loss: 0.097615  [25600/70080]
loss: 0.080651  [32000/70080]
loss: 0.146093  [38400/70080]
loss: 0.119675  [44800/70080]
loss: 0.175833  [51200/70080]
loss: 0.196905  [57600/70080]
loss: 0.167371  [64000/70080]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.151221 

Epoch 4
-------------------------------
loss: 0.139542  [    0/70080]
loss: 0.187608  [ 6400/70080]
loss: 0.175356  [12800/70080]
loss: 0.116501  [19200/70080]
loss: 0.163689  [25600/70080]
loss: 0.175060  [32000/70080]
loss: 0.092959  [38400/70080]
loss: 0.122811  [44800/70080]
loss: 0.072627  [51200/70080]
loss: 0.099838  [57600/70080]
loss: 0.096035  [64000/70080]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.148936 

Epoch 5
-------------------------------
loss: 0.090045  [    0/70080]
loss: 0.156187  [ 6400/70080]
loss: 0.083814  [12800/70080]
loss: 0.165334  [19200/70080]
loss: 0.135033  [25600/70080]
loss: 0.155204  [32000/70080]
loss: 0.141060  [38400/70080]
loss: 0.149586  [44800/70080]
loss: 0.142808  [51200/70080]
loss: 0.211683  [57600/70080]
loss: 0.192222  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.145950 

Epoch 6
-------------------------------
loss: 0.088521  [    0/70080]
loss: 0.082406  [ 6400/70080]
loss: 0.067332  [12800/70080]
loss: 0.058982  [19200/70080]
loss: 0.234548  [25600/70080]
loss: 0.200475  [32000/70080]
loss: 0.093752  [38400/70080]
loss: 0.267463  [44800/70080]
loss: 0.118592  [51200/70080]
loss: 0.201738  [57600/70080]
2022/09/20 16:20:05 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:20:36 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.092383  [57600/71159]
loss: 0.070236  [64000/71159]
loss: 0.200006  [70400/71159]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.142542 

Epoch 32
-------------------------------
loss: 0.156092  [    0/71159]
loss: 0.059487  [ 6400/71159]
loss: 0.152029  [12800/71159]
loss: 0.149111  [19200/71159]
loss: 0.094588  [25600/71159]
loss: 0.078634  [32000/71159]
loss: 0.182222  [38400/71159]
loss: 0.061308  [44800/71159]
loss: 0.101160  [51200/71159]
loss: 0.234439  [57600/71159]
loss: 0.141121  [64000/71159]
loss: 0.151077  [70400/71159]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.145013 

Epoch 33
-------------------------------
loss: 0.084972  [    0/71159]
loss: 0.105965  [ 6400/71159]
loss: 0.159380  [12800/71159]
loss: 0.071851  [19200/71159]
loss: 0.143701  [25600/71159]
loss: 0.055847  [32000/71159]
loss: 0.207027  [38400/71159]
loss: 0.117069  [44800/71159]
loss: 0.100388  [51200/71159]
loss: 0.088397  [57600/71159]
loss: 0.056812  [64000/71159]
loss: 0.112498  [70400/71159]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.141242 

Epoch 34
-------------------------------
loss: 0.074655  [    0/71159]
loss: 0.082005  [ 6400/71159]
loss: 0.084615  [12800/71159]
loss: 0.072121  [19200/71159]
loss: 0.087050  [25600/71159]
loss: 0.118435  [32000/71159]
loss: 0.126802  [38400/71159]
loss: 0.122984  [44800/71159]
loss: 0.150245  [51200/71159]
loss: 0.132259  [57600/71159]
loss: 0.157510  [64000/71159]
loss: 0.209918  [70400/71159]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.138955 

Epoch 35
-------------------------------
loss: 0.114828  [    0/71159]
loss: 0.164277  [ 6400/71159]
loss: 0.069563  [12800/71159]
loss: 0.083259  [19200/71159]
loss: 0.068519  [25600/71159]
loss: 0.119415  [32000/71159]
loss: 0.167680  [38400/71159]
loss: 0.054115  [44800/71159]
loss: 0.054358  [51200/71159]
loss: 0.103665  [57600/71159]
loss: 0.066045  [64000/71159]
loss: 0.117511  [70400/71159]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.152538 

Epoch 36
-------------------------------
loss: 0.107424  [    0/71159]
loss: 0.102471  [ 6400/71159]
loss: 0.065902  [12800/71159]
loss: 0.094820  [19200/71159]
loss: 0.138920  [25600/71159]
loss: 0.047832  [32000/71159]
loss: 0.039872  [38400/71159]
loss: 0.120050  [44800/71159]
loss: 0.146713  [51200/71159]
loss: 0.191878  [57600/71159]
loss: 0.076473  [64000/71159]
loss: 0.045832  [70400/71159]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.147678 

Epoch 37
-------------------------------
loss: 0.105730  [    0/71159]
loss: 0.067083  [ 6400/71159]
loss: 0.060083  [12800/71159]
loss: 0.075360  [19200/71159]
loss: 0.053204  [25600/71159]
loss: 0.156161  [32000/71159]
loss: 0.101799  [38400/71159]
loss: 0.080712  [44800/71159]
loss: 0.139734  [51200/71159]
loss: 0.150329  [57600/71159]
loss: 0.152495  [64000/71159]
loss: 0.149514  [70400/71159]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.141589 

Epoch 38
-------------------------------
loss: 0.058502  [    0/71159]
loss: 0.077625  [ 6400/71159]
loss: 0.035176  [12800/71159]
loss: 0.063762  [19200/71159]
loss: 0.050364  [25600/71159]
loss: 0.139146  [32000/71159]
loss: 0.026830  [38400/71159]
loss: 0.111659  [44800/71159]
loss: 0.064399  [51200/71159]
loss: 0.087622  [57600/71159]
loss: 0.094039  [64000/71159]
loss: 0.220516  [70400/71159]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.142955 

Epoch 39
-------------------------------
loss: 0.192200  [    0/71159]
loss: 0.070546  [ 6400/71159]
loss: 0.112552  [12800/71159]
loss: 0.068113  [19200/71159]
loss: 0.074515  [25600/71159]
loss: 0.206299  [32000/71159]
loss: 0.045529  [38400/71159]
loss: 0.103914  [44800/71159]
loss: 0.112223  [51200/71159]
loss: 0.137807  [57600/71159]
loss: 0.303911  [64000/71159]
loss: 0.137439  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.142984 

Epoch 40
-------------------------------
loss: 0.037696  [    0/71159]
loss: 0.101231  [ 6400/71159]
loss: 0.064377  [12800/71159]
loss: 0.053288  [19200/71159]
loss: 0.119371  [25600/71159]
loss: 0.133183  [32000/71159]
loss: 0.082346  [38400/71159]
loss: 0.054088  [44800/71159]
loss: 0.232634  [51200/71159]
loss: 0.125451  [57600/71159]
loss: 0.129281  [64000/71159]
loss: 0.209622  [70400/71159]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.136778 

Epoch 41
-------------------------------
loss: 0.041241  [    0/71159]
loss: 0.079725  [ 6400/71159]
loss: 0.034719  [12800/71159]
loss: 0.103455  [19200/71159]
loss: 0.065470  [25600/71159]
loss: 0.070300  [32000/71159]
loss: 0.089086  [38400/71159]
loss: 0.110803  [44800/71159]
loss: 0.081102  [51200/71159]
loss: 0.072419  [57600/71159]
loss: 0.109804  [64000/71159]
loss: 0.122905  [70400/71159]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.158168 

Epoch 42
-------------------------------
loss: 0.113147  [    0/71159]
loss: 0.080871  [ 6400/71159]
loss: 0.056970  [12800/71159]
loss: 0.145855  [19200/71159]
loss: 0.192748  [25600/71159]
loss: 0.017976  [32000/71159]
loss: 0.137811  [38400/71159]
loss: 0.089963  [44800/71159]
loss: 0.072223  [51200/71159]
loss: 0.078569  [57600/71159]
loss: 0.152746  [64000/71159]
loss: 0.071120  [70400/71159]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.139483 

Epoch 43
-------------------------------
loss: 0.119175  [    0/71159]
loss: 0.121096  [ 6400/71159]
loss: 0.039259  [12800/71159]
loss: 0.068832  [19200/71159]
loss: 0.082521  [25600/71159]
loss: 0.082694  [32000/71159]
loss: 0.151200  [38400/71159]
loss: 0.099772  [44800/71159]
loss: 0.054625  [51200/71159]
loss: 0.126107  [57600/71159]
loss: 0.077310  [64000/71159]
loss: 0.163693  [70400/71159]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.142122 

Epoch 44
-------------------------------
loss: 0.075041  [    0/71159]
loss: 0.031485  [ 6400/71159]
loss: 0.043796  [12800/71159]
loss: 0.332767  [19200/71159]
loss: 0.070210  [25600/71159]
loss: 0.071441  [32000/71159]
loss: 0.080218  [38400/71159]
loss: 0.108083  [44800/71159]
loss: 0.214464  [51200/71159]
loss: 0.084152  [57600/71159]
loss: 0.073885  [64000/71159]
loss: 0.097347  [70400/71159]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.143039 

Epoch 45
-------------------------------
loss: 0.100234  [    0/71159]
loss: 0.114966  [ 6400/71159]
loss: 0.105135  [12800/71159]
loss: 0.151752  [19200/71159]
loss: 0.115078  [25600/71159]
loss: 0.078070  [32000/71159]
loss: 0.122045  [38400/71159]
loss: 0.029781  [44800/71159]
loss: 0.063663  [51200/71159]
loss: 0.120353  [57600/71159]
loss: 0.136393  [64000/71159]
loss: 0.040937  [70400/71159]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.139111 

Epoch 46
-------------------------------
loss: 0.062925  [    0/71159]
loss: 0.118414  [ 6400/71159]
loss: 0.118571  [12800/71159]
loss: 0.005951  [19200/71159]
loss: 0.084004  [25600/71159]
loss: 0.188424  [32000/71159]
loss: 0.072597  [38400/71159]
loss: 0.123934  [44800/71159]
loss: 0.173475  [51200/71159]
loss: 0.114625  [57600/71159]
loss: 0.026208  [64000/71159]
loss: 0.070176  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.144415 

Epoch 47
-------------------------------
loss: 0.093640  [    0/71159]
loss: 0.161912  [ 6400/71159]
loss: 0.069782  [12800/71159]
loss: 0.049860  [19200/71159]
loss: 0.084873  [25600/71159]
loss: 0.058374  [32000/71159]
loss: 0.120354  [38400/71159]
loss: 0.118649  [44800/71159]
loss: 0.100610  [51200/71159]
loss: 0.072030  [57600/71159]
loss: 0.087349  [64000/71159]
loss: 0.241860  [70400/71159]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.148300 

Epoch 48
-------------------------------
loss: 0.096639  [    0/71159]
loss: 0.171433  [ 6400/71159]
loss: 0.058211  [12800/71159]
loss: 0.095331  [19200/71159]
loss: 0.182010  [25600/71159]
loss: 0.045151  [32000/71159]
loss: 0.086582  [38400/71159]
loss: 0.067208  [44800/71159]
loss: 0.073188  [51200/71159]
loss: 0.074696  [57600/71159]
loss: 0.173760  [64000/71159]
loss: 0.111651  [70400/71159]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.147705 

Epoch 49
-------------------------------
loss: 0.143983  [    0/71159]
loss: 0.082012  [ 6400/71159]
loss: 0.075672  [12800/71159]
loss: 0.099584  [19200/71159]
loss: 0.128070  [25600/71159]
loss: 0.100996  [32000/71159]
loss: 0.171971  [38400/71159]
loss: 0.128539  [44800/71159]
loss: 0.198748  [51200/71159]
loss: 0.158715  [57600/71159]
2022/09/20 16:22:16 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:22:23 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 81.5%, Avg loss: 0.654995 

Epoch 34
-------------------------------
loss: 0.536783  [    0/69635]
loss: 0.109639  [ 6400/69635]
loss: 1.703024  [12800/69635]
loss: 0.221510  [19200/69635]
loss: 0.152763  [25600/69635]
loss: 0.262517  [32000/69635]
loss: 0.163109  [38400/69635]
loss: 0.117195  [44800/69635]
loss: 0.188779  [51200/69635]
loss: 0.090560  [57600/69635]
loss: 0.307006  [64000/69635]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.155450 

Epoch 35
-------------------------------
loss: 0.232031  [    0/69635]
loss: 0.123584  [ 6400/69635]
loss: 0.162173  [12800/69635]
loss: 0.199113  [19200/69635]
loss: 0.255624  [25600/69635]
loss: 0.134895  [32000/69635]
loss: 0.133524  [38400/69635]
loss: 0.166573  [44800/69635]
loss: 0.079895  [51200/69635]
loss: 0.059374  [57600/69635]
loss: 0.202214  [64000/69635]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.173934 

Epoch 36
-------------------------------
loss: 0.088545  [    0/69635]
loss: 0.086177  [ 6400/69635]
loss: 0.135731  [12800/69635]
loss: 0.097711  [19200/69635]
loss: 0.093449  [25600/69635]
loss: 0.126873  [32000/69635]
loss: 0.251272  [38400/69635]
loss: 0.171272  [44800/69635]
loss: 0.254297  [51200/69635]
loss: 0.071148  [57600/69635]
loss: 0.125599  [64000/69635]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.160540 

Epoch 37
-------------------------------
loss: 0.140520  [    0/69635]
loss: 0.166472  [ 6400/69635]
loss: 0.148770  [12800/69635]
loss: 0.201898  [19200/69635]
loss: 0.036725  [25600/69635]
loss: 0.167249  [32000/69635]
loss: 0.106537  [38400/69635]
loss: 0.102221  [44800/69635]
loss: 0.086640  [51200/69635]
loss: 0.158761  [57600/69635]
loss: 0.116539  [64000/69635]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159089 

Epoch 38
-------------------------------
loss: 0.301133  [    0/69635]
loss: 0.195607  [ 6400/69635]
loss: 0.061379  [12800/69635]
loss: 0.223044  [19200/69635]
loss: 0.096433  [25600/69635]
loss: 0.100695  [32000/69635]
loss: 0.156449  [38400/69635]
loss: 0.113569  [44800/69635]
loss: 0.158852  [51200/69635]
loss: 0.206622  [57600/69635]
loss: 0.133001  [64000/69635]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.156837 

Epoch 39
-------------------------------
loss: 0.116708  [    0/69635]
loss: 0.185258  [ 6400/69635]
loss: 0.215837  [12800/69635]
loss: 0.222363  [19200/69635]
loss: 0.122620  [25600/69635]
loss: 0.061755  [32000/69635]
loss: 0.128761  [38400/69635]
loss: 0.174213  [44800/69635]
loss: 0.249475  [51200/69635]
loss: 0.080661  [57600/69635]
loss: 0.074568  [64000/69635]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.149477 

Epoch 40
-------------------------------
loss: 0.186996  [    0/69635]
loss: 0.094129  [ 6400/69635]
loss: 0.139964  [12800/69635]
loss: 0.169455  [19200/69635]
loss: 0.169683  [25600/69635]
loss: 0.161473  [32000/69635]
loss: 0.164822  [38400/69635]
loss: 0.168499  [44800/69635]
loss: 0.181839  [51200/69635]
loss: 0.147468  [57600/69635]
loss: 0.161690  [64000/69635]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.158448 

Epoch 41
-------------------------------
loss: 0.121286  [    0/69635]
loss: 0.105145  [ 6400/69635]
loss: 0.095727  [12800/69635]
loss: 0.116030  [19200/69635]
loss: 0.185965  [25600/69635]
loss: 0.246475  [32000/69635]
loss: 0.129831  [38400/69635]
loss: 0.071518  [44800/69635]
loss: 0.091153  [51200/69635]
loss: 0.126565  [57600/69635]
loss: 0.157611  [64000/69635]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.155818 

Epoch 42
-------------------------------
loss: 0.109095  [    0/69635]
loss: 1.724164  [ 6400/69635]
loss: 0.181596  [12800/69635]
loss: 0.180265  [19200/69635]
loss: 0.209738  [25600/69635]
loss: 0.126006  [32000/69635]
loss: 0.144894  [38400/69635]
loss: 0.361211  [44800/69635]
loss: 0.113745  [51200/69635]
loss: 0.151835  [57600/69635]
loss: 1.673821  [64000/69635]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.203472 

Epoch 43
-------------------------------
loss: 0.125137  [    0/69635]
loss: 0.311427  [ 6400/69635]
loss: 0.127834  [12800/69635]
loss: 0.212306  [19200/69635]
loss: 0.097136  [25600/69635]
loss: 0.169727  [32000/69635]
loss: 0.147085  [38400/69635]
loss: 0.047880  [44800/69635]
loss: 0.127762  [51200/69635]
loss: 0.155500  [57600/69635]
loss: 0.131742  [64000/69635]
Test Error: 
 Accuracy: 82.4%, Avg loss: 0.525125 

Epoch 44
-------------------------------
loss: 0.510626  [    0/69635]
loss: 0.111677  [ 6400/69635]
loss: 0.152043  [12800/69635]
loss: 0.225615  [19200/69635]
loss: 0.045721  [25600/69635]
loss: 0.113493  [32000/69635]
loss: 0.131337  [38400/69635]
loss: 0.080346  [44800/69635]
loss: 0.104541  [51200/69635]
loss: 0.228213  [57600/69635]
loss: 0.163079  [64000/69635]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.167698 

Epoch 45
-------------------------------
loss: 0.127291  [    0/69635]
loss: 0.097581  [ 6400/69635]
loss: 0.059200  [12800/69635]
loss: 0.051685  [19200/69635]
loss: 0.131977  [25600/69635]
loss: 0.110401  [32000/69635]
loss: 0.082212  [38400/69635]
loss: 0.134520  [44800/69635]
loss: 0.137770  [51200/69635]
loss: 0.075823  [57600/69635]
loss: 0.099720  [64000/69635]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.165240 

Epoch 46
-------------------------------
loss: 0.177177  [    0/69635]
loss: 0.221857  [ 6400/69635]
loss: 0.168105  [12800/69635]
loss: 0.106936  [19200/69635]
loss: 0.074185  [25600/69635]
loss: 0.085728  [32000/69635]
loss: 0.194042  [38400/69635]
loss: 0.339911  [44800/69635]
loss: 0.055357  [51200/69635]
loss: 0.132044  [57600/69635]
loss: 0.140123  [64000/69635]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.228767 

Epoch 47
-------------------------------
loss: 0.096898  [    0/69635]
loss: 0.041308  [ 6400/69635]
loss: 0.206308  [12800/69635]
loss: 0.117434  [19200/69635]
loss: 0.120702  [25600/69635]
loss: 0.124042  [32000/69635]
loss: 0.086337  [38400/69635]
loss: 0.243416  [44800/69635]
loss: 0.139172  [51200/69635]
loss: 0.130930  [57600/69635]
loss: 0.081392  [64000/69635]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.198610 

Epoch 48
-------------------------------
loss: 0.138474  [    0/69635]
loss: 0.242740  [ 6400/69635]
loss: 0.073156  [12800/69635]
loss: 0.128200  [19200/69635]
loss: 0.126701  [25600/69635]
loss: 0.142266  [32000/69635]
loss: 0.192229  [38400/69635]
loss: 0.053062  [44800/69635]
loss: 0.072710  [51200/69635]
loss: 0.134715  [57600/69635]
loss: 0.264148  [64000/69635]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.156804 

Epoch 49
-------------------------------
loss: 0.242400  [    0/69635]
loss: 0.106348  [ 6400/69635]
loss: 0.070470  [12800/69635]
loss: 0.101210  [19200/69635]
loss: 0.095108  [25600/69635]
loss: 0.137311  [32000/69635]
loss: 0.122993  [38400/69635]
loss: 0.258269  [44800/69635]
loss: 0.086977  [51200/69635]
loss: 0.165295  [57600/69635]
loss: 0.244488  [64000/69635]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.197001 

Epoch 50
-------------------------------
loss: 0.160880  [    0/69635]
loss: 0.155829  [ 6400/69635]
loss: 0.219933  [12800/69635]
loss: 0.147769  [19200/69635]
loss: 0.106803  [25600/69635]
loss: 0.142494  [32000/69635]
loss: 0.192088  [38400/69635]
loss: 0.109993  [44800/69635]
loss: 0.114217  [51200/69635]
loss: 0.115555  [57600/69635]
loss: 0.115955  [64000/69635]
Test Error: 
 Accuracy: 86.1%, Avg loss: 0.525735 

Epoch 1
-------------------------------
loss: 0.671522  [    0/70414]
loss: 0.288388  [ 6400/70414]
loss: 0.232022  [12800/70414]
loss: 0.275172  [19200/70414]
loss: 0.223069  [25600/70414]
loss: 0.228615  [32000/70414]
loss: 0.135184  [38400/70414]
loss: 0.240972  [44800/70414]
loss: 0.216068  [51200/70414]
loss: 0.226558  [57600/70414]
loss: 0.243317  [64000/70414]
loss: 0.047555  [15400/70414]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.214714 

Epoch 2
-------------------------------
loss: 0.071253  [    0/70414]
loss: 0.092227  [ 6400/70414]
loss: 0.154360  [12800/70414]
loss: 0.197178  [19200/70414]
loss: 0.159575  [25600/70414]
loss: 0.134266  [32000/70414]
loss: 0.123995  [38400/70414]
loss: 0.206591  [44800/70414]
loss: 0.242722  [51200/70414]
loss: 0.262753  [57600/70414]
loss: 0.150971  [64000/70414]
loss: 0.119168  [15400/70414]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.196898 

Epoch 3
-------------------------------
2022/09/20 16:23:06 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:23:42 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.075380  [12800/69548]
loss: 0.169372  [19200/69548]
loss: 0.106209  [25600/69548]
loss: 0.269818  [32000/69548]
loss: 0.204875  [38400/69548]
loss: 0.105513  [44800/69548]
loss: 0.182791  [51200/69548]
loss: 0.189226  [57600/69548]
loss: 0.162638  [64000/69548]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.179375 

Epoch 26
-------------------------------
loss: 0.164267  [    0/69548]
loss: 0.064135  [ 6400/69548]
loss: 0.109685  [12800/69548]
loss: 0.134740  [19200/69548]
loss: 1.756241  [25600/69548]
loss: 0.076321  [32000/69548]
loss: 0.185659  [38400/69548]
loss: 0.176944  [44800/69548]
loss: 0.088573  [51200/69548]
loss: 0.280627  [57600/69548]
loss: 0.127273  [64000/69548]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.187945 

Epoch 27
-------------------------------
loss: 0.064675  [    0/69548]
loss: 0.107372  [ 6400/69548]
loss: 0.229967  [12800/69548]
loss: 0.083763  [19200/69548]
loss: 0.127314  [25600/69548]
loss: 0.182723  [32000/69548]
loss: 0.229375  [38400/69548]
loss: 0.137549  [44800/69548]
loss: 0.089416  [51200/69548]
loss: 0.069312  [57600/69548]
loss: 0.145730  [64000/69548]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.176381 

Epoch 28
-------------------------------
loss: 0.151768  [    0/69548]
loss: 0.176212  [ 6400/69548]
loss: 0.068907  [12800/69548]
loss: 0.208979  [19200/69548]
loss: 0.170038  [25600/69548]
loss: 0.207925  [32000/69548]
loss: 0.128324  [38400/69548]
loss: 0.232222  [44800/69548]
loss: 0.121004  [51200/69548]
loss: 0.262604  [57600/69548]
loss: 0.175037  [64000/69548]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.176345 

Epoch 29
-------------------------------
loss: 0.272773  [    0/69548]
loss: 0.238933  [ 6400/69548]
loss: 0.192177  [12800/69548]
loss: 0.227890  [19200/69548]
loss: 0.118147  [25600/69548]
loss: 0.191552  [32000/69548]
loss: 0.088899  [38400/69548]
loss: 0.137881  [44800/69548]
loss: 0.200211  [51200/69548]
loss: 0.127209  [57600/69548]
loss: 0.239186  [64000/69548]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.176886 

Epoch 30
-------------------------------
loss: 0.229574  [    0/69548]
loss: 0.169854  [ 6400/69548]
loss: 0.062953  [12800/69548]
loss: 0.192062  [19200/69548]
loss: 0.169882  [25600/69548]
loss: 0.296528  [32000/69548]
loss: 0.178943  [38400/69548]
loss: 0.167860  [44800/69548]
loss: 0.083461  [51200/69548]
loss: 0.112753  [57600/69548]
loss: 0.120895  [64000/69548]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.180469 

Epoch 31
-------------------------------
loss: 0.177393  [    0/69548]
loss: 0.036944  [ 6400/69548]
loss: 0.136623  [12800/69548]
loss: 0.131411  [19200/69548]
loss: 0.183769  [25600/69548]
loss: 0.259663  [32000/69548]
loss: 0.176493  [38400/69548]
loss: 0.238659  [44800/69548]
loss: 0.146933  [51200/69548]
loss: 0.338227  [57600/69548]
loss: 0.281556  [64000/69548]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.178582 

Epoch 32
-------------------------------
loss: 0.120377  [    0/69548]
loss: 0.280153  [ 6400/69548]
loss: 0.210533  [12800/69548]
loss: 0.146203  [19200/69548]
loss: 0.317665  [25600/69548]
loss: 0.222544  [32000/69548]
loss: 0.093132  [38400/69548]
loss: 0.107538  [44800/69548]
loss: 0.176730  [51200/69548]
loss: 0.186557  [57600/69548]
loss: 0.165532  [64000/69548]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.170968 

Epoch 33
-------------------------------
loss: 0.139145  [    0/69548]
loss: 0.113247  [ 6400/69548]
loss: 0.168933  [12800/69548]
loss: 0.148697  [19200/69548]
loss: 0.162875  [25600/69548]
loss: 0.121260  [32000/69548]
loss: 0.179644  [38400/69548]
loss: 0.151521  [44800/69548]
loss: 0.165496  [51200/69548]
loss: 0.171236  [57600/69548]
loss: 0.123403  [64000/69548]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.174695 

Epoch 34
-------------------------------
loss: 0.121329  [    0/69548]
loss: 0.168928  [ 6400/69548]
loss: 0.127386  [12800/69548]
loss: 0.096024  [19200/69548]
loss: 0.166855  [25600/69548]
loss: 0.088088  [32000/69548]
loss: 0.145498  [38400/69548]
loss: 0.140074  [44800/69548]
loss: 0.206911  [51200/69548]
loss: 0.306496  [57600/69548]
loss: 0.227321  [64000/69548]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.181218 

Epoch 35
-------------------------------
loss: 0.243427  [    0/69548]
loss: 0.134472  [ 6400/69548]
loss: 0.157531  [12800/69548]
loss: 0.178057  [19200/69548]
loss: 0.129877  [25600/69548]
loss: 0.086315  [32000/69548]
loss: 0.129894  [38400/69548]
loss: 0.088096  [44800/69548]
loss: 0.170056  [51200/69548]
loss: 0.120043  [57600/69548]
loss: 0.180826  [64000/69548]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.185172 

Epoch 36
-------------------------------
loss: 0.238803  [    0/69548]
loss: 0.088126  [ 6400/69548]
loss: 0.206424  [12800/69548]
loss: 0.103529  [19200/69548]
loss: 0.242622  [25600/69548]
loss: 0.175675  [32000/69548]
loss: 0.211444  [38400/69548]
loss: 0.102219  [44800/69548]
loss: 0.247231  [51200/69548]
loss: 0.192438  [57600/69548]
loss: 0.115652  [64000/69548]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.190329 

Epoch 37
-------------------------------
loss: 0.126318  [    0/69548]
loss: 0.120041  [ 6400/69548]
loss: 0.098120  [12800/69548]
loss: 0.236222  [19200/69548]
loss: 0.222852  [25600/69548]
loss: 0.134708  [32000/69548]
loss: 0.163477  [38400/69548]
loss: 0.269396  [44800/69548]
loss: 0.113254  [51200/69548]
loss: 0.171768  [57600/69548]
loss: 0.309848  [64000/69548]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.174240 

Epoch 38
-------------------------------
loss: 0.211432  [    0/69548]
loss: 0.113252  [ 6400/69548]
loss: 0.164580  [12800/69548]
loss: 0.058173  [19200/69548]
loss: 0.170914  [25600/69548]
loss: 0.180644  [32000/69548]
loss: 0.197373  [38400/69548]
loss: 0.270294  [44800/69548]
loss: 0.262888  [51200/69548]
loss: 0.192317  [57600/69548]
loss: 0.162241  [64000/69548]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.181056 

Epoch 39
-------------------------------
loss: 0.122209  [    0/69548]
loss: 0.127799  [ 6400/69548]
loss: 0.278059  [12800/69548]
loss: 0.139736  [19200/69548]
loss: 0.191708  [25600/69548]
loss: 0.177253  [32000/69548]
loss: 0.112198  [38400/69548]
loss: 0.281965  [44800/69548]
loss: 0.181684  [51200/69548]
loss: 0.210422  [57600/69548]
loss: 0.132191  [64000/69548]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.174151 

Epoch 40
-------------------------------
loss: 0.124875  [    0/69548]
loss: 0.171380  [ 6400/69548]
loss: 0.167295  [12800/69548]
loss: 0.118240  [19200/69548]
loss: 0.271156  [25600/69548]
loss: 0.174237  [32000/69548]
loss: 0.118324  [38400/69548]
loss: 0.095758  [44800/69548]
loss: 0.206902  [51200/69548]
loss: 0.304638  [57600/69548]
loss: 0.092296  [64000/69548]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.176856 

Epoch 41
-------------------------------
loss: 0.181983  [    0/69548]
loss: 0.071184  [ 6400/69548]
loss: 0.178270  [12800/69548]
loss: 0.156534  [19200/69548]
loss: 0.198661  [25600/69548]
loss: 0.114824  [32000/69548]
loss: 0.260269  [38400/69548]
loss: 0.236933  [44800/69548]
loss: 0.171689  [51200/69548]
loss: 0.110763  [57600/69548]
loss: 0.119605  [64000/69548]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.174401 

Epoch 42
-------------------------------
loss: 0.137090  [    0/69548]
loss: 0.217576  [ 6400/69548]
loss: 0.245488  [12800/69548]
loss: 0.140662  [19200/69548]
loss: 0.108315  [25600/69548]
loss: 0.213694  [32000/69548]
loss: 0.307840  [38400/69548]
loss: 0.151836  [44800/69548]
loss: 0.089300  [51200/69548]
loss: 0.192863  [57600/69548]
loss: 0.212812  [64000/69548]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.188552 

Epoch 43
-------------------------------
loss: 0.102688  [    0/69548]
loss: 0.332088  [ 6400/69548]
loss: 0.187650  [12800/69548]
loss: 0.101224  [19200/69548]
loss: 0.133395  [25600/69548]
loss: 0.204376  [32000/69548]
loss: 0.180879  [38400/69548]
loss: 0.213292  [44800/69548]
loss: 0.102361  [51200/69548]
loss: 0.314496  [57600/69548]
loss: 0.064565  [64000/69548]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.175701 

Epoch 44
-------------------------------
loss: 0.203074  [    0/69548]
loss: 0.175663  [ 6400/69548]
loss: 0.083661  [12800/69548]
loss: 0.107336  [19200/69548]
loss: 0.129404  [25600/69548]
loss: 0.182025  [32000/69548]
loss: 0.194061  [38400/69548]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.158998 

Epoch 35
-------------------------------
loss: 0.091128  [    0/71502]
loss: 0.092018  [ 6400/71502]
loss: 0.064271  [12800/71502]
loss: 0.107045  [19200/71502]
loss: 0.130137  [25600/71502]
loss: 0.021091  [32000/71502]
loss: 0.048718  [38400/71502]
loss: 0.074336  [44800/71502]
loss: 0.093362  [51200/71502]
loss: 0.062437  [57600/71502]
loss: 0.155549  [64000/71502]
loss: 0.037543  [70400/71502]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.123767 

Epoch 36
-------------------------------
loss: 0.032377  [    0/71502]
loss: 0.081245  [ 6400/71502]
loss: 0.074568  [12800/71502]
loss: 0.106567  [19200/71502]
loss: 0.150807  [25600/71502]
loss: 0.259093  [32000/71502]
loss: 0.054179  [38400/71502]
loss: 0.059098  [44800/71502]
loss: 0.118709  [51200/71502]
loss: 0.059314  [57600/71502]
loss: 1.594139  [64000/71502]
loss: 0.049260  [70400/71502]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.164839 

Epoch 37
-------------------------------
loss: 0.055068  [    0/71502]
loss: 0.017947  [ 6400/71502]
loss: 0.060122  [12800/71502]
loss: 0.069617  [19200/71502]
loss: 0.053632  [25600/71502]
loss: 0.063820  [32000/71502]
loss: 0.065685  [38400/71502]
loss: 0.197852  [44800/71502]
loss: 0.161869  [51200/71502]
loss: 0.036242  [57600/71502]
loss: 0.167745  [64000/71502]
loss: 0.078556  [70400/71502]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.163795 

Epoch 38
-------------------------------
loss: 0.054488  [    0/71502]
loss: 0.031797  [ 6400/71502]
loss: 0.044606  [12800/71502]
loss: 0.047904  [19200/71502]
loss: 0.118109  [25600/71502]
loss: 0.035571  [32000/71502]
loss: 0.069456  [38400/71502]
loss: 0.134141  [44800/71502]
loss: 0.203615  [51200/71502]
loss: 0.171922  [57600/71502]
loss: 0.103435  [64000/71502]
loss: 0.048362  [70400/71502]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.166109 

Epoch 39
-------------------------------
loss: 0.032142  [    0/71502]
loss: 0.108683  [ 6400/71502]
loss: 0.014805  [12800/71502]
loss: 0.246169  [19200/71502]
loss: 0.022991  [25600/71502]
loss: 0.244824  [32000/71502]
loss: 0.076546  [38400/71502]
loss: 0.109242  [44800/71502]
loss: 0.019159  [51200/71502]
loss: 0.117864  [57600/71502]
loss: 0.097238  [64000/71502]
loss: 0.077245  [70400/71502]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.162352 

Epoch 40
-------------------------------
loss: 0.031828  [    0/71502]
loss: 0.073548  [ 6400/71502]
loss: 0.092088  [12800/71502]
loss: 0.025645  [19200/71502]
loss: 0.093278  [25600/71502]
loss: 0.136674  [32000/71502]
loss: 0.252298  [38400/71502]
loss: 0.061855  [44800/71502]
loss: 0.027246  [51200/71502]
loss: 1.635992  [57600/71502]
loss: 0.063118  [64000/71502]
loss: 0.038094  [70400/71502]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.159569 

Epoch 41
-------------------------------
loss: 0.016771  [    0/71502]
loss: 0.123561  [ 6400/71502]
loss: 0.041004  [12800/71502]
loss: 0.018669  [19200/71502]
loss: 0.052063  [25600/71502]
loss: 0.106167  [32000/71502]
loss: 0.088112  [38400/71502]
loss: 0.106344  [44800/71502]
loss: 0.026545  [51200/71502]
loss: 0.126195  [57600/71502]
loss: 0.056845  [64000/71502]
loss: 0.088963  [70400/71502]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.175726 

Epoch 42
-------------------------------
loss: 0.155688  [    0/71502]
loss: 0.055131  [ 6400/71502]
loss: 0.028333  [12800/71502]
loss: 0.040883  [19200/71502]
loss: 0.033258  [25600/71502]
loss: 0.150155  [32000/71502]
loss: 0.159264  [38400/71502]
loss: 0.021966  [44800/71502]
loss: 0.150270  [51200/71502]
loss: 0.034868  [57600/71502]
loss: 0.050906  [64000/71502]
loss: 0.092833  [70400/71502]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.175816 

Epoch 43
-------------------------------
loss: 0.134301  [    0/71502]
loss: 0.084773  [ 6400/71502]
loss: 0.110734  [12800/71502]
loss: 0.069178  [19200/71502]
loss: 0.032090  [25600/71502]
loss: 0.144368  [32000/71502]
loss: 0.146355  [38400/71502]
loss: 0.146360  [44800/71502]
loss: 0.017003  [51200/71502]
loss: 0.064722  [57600/71502]
loss: 0.080468  [64000/71502]
loss: 3.266971  [70400/71502]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.178309 

Epoch 44
-------------------------------
loss: 0.046121  [    0/71502]
loss: 0.017777  [ 6400/71502]
loss: 0.044818  [12800/71502]
loss: 0.154660  [19200/71502]
loss: 0.053581  [25600/71502]
loss: 0.091890  [32000/71502]
loss: 0.084155  [38400/71502]
loss: 0.046727  [44800/71502]
loss: 0.121487  [51200/71502]
loss: 0.090226  [57600/71502]
loss: 0.124163  [64000/71502]
loss: 0.076776  [70400/71502]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.174794 

Epoch 45
-------------------------------
loss: 0.065920  [    0/71502]
loss: 0.140012  [ 6400/71502]
loss: 0.114816  [12800/71502]
loss: 0.174568  [19200/71502]
loss: 0.111313  [25600/71502]
loss: 0.091758  [32000/71502]
loss: 0.051089  [38400/71502]
loss: 0.046813  [44800/71502]
loss: 0.049457  [51200/71502]
loss: 0.049224  [57600/71502]
loss: 0.143628  [64000/71502]
loss: 0.095155  [70400/71502]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.157832 

Epoch 46
-------------------------------
loss: 0.072871  [    0/71502]
loss: 0.056602  [ 6400/71502]
loss: 0.023842  [12800/71502]
loss: 0.053232  [19200/71502]
loss: 0.074152  [25600/71502]
loss: 0.067062  [32000/71502]
loss: 0.166014  [38400/71502]
loss: 0.206837  [44800/71502]
loss: 0.081677  [51200/71502]
loss: 0.030993  [57600/71502]
loss: 0.058578  [64000/71502]
loss: 0.087169  [70400/71502]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.198767 

Epoch 47
-------------------------------
loss: 0.095411  [    0/71502]
loss: 0.052225  [ 6400/71502]
loss: 0.134338  [12800/71502]
loss: 0.045362  [19200/71502]
loss: 0.030552  [25600/71502]
loss: 0.038956  [32000/71502]
loss: 0.046493  [38400/71502]
loss: 0.094313  [44800/71502]
loss: 0.132565  [51200/71502]
loss: 0.147785  [57600/71502]
loss: 0.041029  [64000/71502]
loss: 0.230457  [70400/71502]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.183089 

Epoch 48
-------------------------------
loss: 0.037617  [    0/71502]
loss: 0.020202  [ 6400/71502]
loss: 0.032533  [12800/71502]
loss: 0.012824  [19200/71502]
loss: 0.059785  [25600/71502]
loss: 0.120684  [32000/71502]
loss: 0.061183  [38400/71502]
loss: 0.063423  [44800/71502]
loss: 0.015832  [51200/71502]
loss: 0.048856  [57600/71502]
loss: 0.033533  [64000/71502]
loss: 0.032090  [70400/71502]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.160721 

Epoch 49
-------------------------------
loss: 0.067950  [    0/71502]
loss: 0.208867  [ 6400/71502]
loss: 0.091072  [12800/71502]
loss: 0.045079  [19200/71502]
loss: 0.058690  [25600/71502]
loss: 0.199549  [32000/71502]
loss: 0.128494  [38400/71502]
loss: 0.137852  [44800/71502]
loss: 0.056852  [51200/71502]
loss: 0.071561  [57600/71502]
loss: 0.049790  [64000/71502]
loss: 0.266559  [70400/71502]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.180573 

Epoch 50
-------------------------------
loss: 0.074749  [    0/71502]
loss: 0.023235  [ 6400/71502]
loss: 0.034512  [12800/71502]
loss: 0.053707  [19200/71502]
loss: 0.050882  [25600/71502]
loss: 0.021122  [32000/71502]
loss: 0.054554  [38400/71502]
loss: 0.040070  [44800/71502]
loss: 0.062546  [51200/71502]
loss: 1.607400  [57600/71502]
loss: 0.091249  [64000/71502]
loss: 0.047483  [70400/71502]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.173264 

Epoch 1
-------------------------------
loss: 0.705345  [    0/69810]
loss: 0.202508  [ 6400/69810]
loss: 0.233417  [12800/69810]
loss: 0.227137  [19200/69810]
loss: 0.238568  [25600/69810]
loss: 1.906879  [32000/69810]
loss: 0.196835  [38400/69810]
loss: 0.171684  [44800/69810]
loss: 0.133242  [51200/69810]
loss: 0.188071  [57600/69810]
loss: 0.239889  [64000/69810]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.206705 

Epoch 2
-------------------------------
loss: 0.228804  [    0/69810]
loss: 0.146952  [ 6400/69810]
loss: 0.160586  [12800/69810]
loss: 0.185075  [19200/69810]
loss: 0.128423  [25600/69810]
loss: 0.315461  [32000/69810]
loss: 0.105085  [38400/69810]
loss: 0.222879  [44800/69810]
loss: 0.148254  [51200/69810]
loss: 0.155901  [57600/69810]
loss: 0.190630  [64000/69810]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.186277 

Epoch 3
-------------------------------
2022/09/20 16:26:06 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.120053  [19200/69420]
loss: 0.146696  [25600/69420]
loss: 0.258758  [32000/69420]
loss: 0.254865  [38400/69420]
loss: 0.151125  [44800/69420]
loss: 0.260668  [51200/69420]
loss: 0.230878  [57600/69420]
loss: 0.219646  [64000/69420]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.193709 

Epoch 38
-------------------------------
loss: 0.124235  [    0/69420]
loss: 0.235400  [ 6400/69420]
loss: 0.223004  [12800/69420]
loss: 0.201753  [19200/69420]
loss: 0.086242  [25600/69420]
loss: 0.278960  [32000/69420]
loss: 0.222112  [38400/69420]
loss: 0.127821  [44800/69420]
loss: 0.132679  [51200/69420]
loss: 0.196254  [57600/69420]
loss: 0.149336  [64000/69420]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.201059 

Epoch 39
-------------------------------
loss: 0.233108  [    0/69420]
loss: 0.162519  [ 6400/69420]
loss: 0.176583  [12800/69420]
loss: 0.181188  [19200/69420]
loss: 0.214498  [25600/69420]
loss: 0.411227  [32000/69420]
loss: 0.153276  [38400/69420]
loss: 0.125102  [44800/69420]
loss: 0.294005  [51200/69420]
loss: 0.146069  [57600/69420]
loss: 0.314158  [64000/69420]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.198536 

Epoch 40
-------------------------------
loss: 0.176054  [    0/69420]
loss: 0.147735  [ 6400/69420]
loss: 0.141022  [12800/69420]
loss: 0.153154  [19200/69420]
loss: 0.203282  [25600/69420]
loss: 0.264946  [32000/69420]
loss: 0.181707  [38400/69420]
loss: 0.233833  [44800/69420]
loss: 0.221395  [51200/69420]
loss: 0.196013  [57600/69420]
loss: 0.135246  [64000/69420]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.193657 

Epoch 41
-------------------------------
loss: 0.234066  [    0/69420]
loss: 0.098542  [ 6400/69420]
loss: 0.222817  [12800/69420]
loss: 0.055635  [19200/69420]
loss: 0.207922  [25600/69420]
loss: 0.274294  [32000/69420]
loss: 0.177896  [38400/69420]
loss: 0.211717  [44800/69420]
loss: 0.163795  [51200/69420]
loss: 0.222933  [57600/69420]
loss: 0.194852  [64000/69420]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.226674 

Epoch 42
-------------------------------
loss: 0.117372  [    0/69420]
loss: 0.160730  [ 6400/69420]
loss: 0.212529  [12800/69420]
loss: 0.284716  [19200/69420]
loss: 0.137679  [25600/69420]
loss: 0.102907  [32000/69420]
loss: 0.085094  [38400/69420]
loss: 0.131693  [44800/69420]
loss: 0.165070  [51200/69420]
loss: 0.291471  [57600/69420]
loss: 0.150483  [64000/69420]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.196246 

Epoch 43
-------------------------------
loss: 0.359279  [    0/69420]
loss: 0.226008  [ 6400/69420]
loss: 0.184076  [12800/69420]
loss: 0.185896  [19200/69420]
loss: 0.125423  [25600/69420]
loss: 0.156043  [32000/69420]
loss: 0.253075  [38400/69420]
loss: 0.127109  [44800/69420]
loss: 0.147898  [51200/69420]
loss: 0.198191  [57600/69420]
loss: 0.234201  [64000/69420]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.214765 

Epoch 44
-------------------------------
loss: 0.116460  [    0/69420]
loss: 0.128467  [ 6400/69420]
loss: 0.131621  [12800/69420]
loss: 0.074420  [19200/69420]
loss: 0.185956  [25600/69420]
loss: 0.215461  [32000/69420]
loss: 0.104756  [38400/69420]
loss: 0.237159  [44800/69420]
loss: 0.229615  [51200/69420]
loss: 0.200893  [57600/69420]
loss: 0.293677  [64000/69420]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.207910 

Epoch 45
-------------------------------
loss: 0.190339  [    0/69420]
loss: 0.177613  [ 6400/69420]
loss: 0.223735  [12800/69420]
loss: 0.240202  [19200/69420]
loss: 0.138589  [25600/69420]
loss: 0.120337  [32000/69420]
loss: 0.233226  [38400/69420]
loss: 0.170937  [44800/69420]
loss: 0.236802  [51200/69420]
loss: 0.128337  [57600/69420]
loss: 0.189508  [64000/69420]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.207291 

Epoch 46
-------------------------------
loss: 0.263914  [    0/69420]
loss: 0.260555  [ 6400/69420]
loss: 0.202266  [12800/69420]
loss: 0.181476  [19200/69420]
loss: 0.145259  [25600/69420]
loss: 0.308032  [32000/69420]
loss: 0.237043  [38400/69420]
loss: 0.162172  [44800/69420]
loss: 0.224520  [51200/69420]
loss: 0.202679  [57600/69420]
loss: 0.162942  [64000/69420]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.195778 

Epoch 47
-------------------------------
loss: 0.125269  [    0/69420]
loss: 0.221406  [ 6400/69420]
loss: 0.138795  [12800/69420]
loss: 0.154647  [19200/69420]
loss: 0.155779  [25600/69420]
loss: 0.256308  [32000/69420]
loss: 0.257166  [38400/69420]
loss: 0.179934  [44800/69420]
loss: 0.232687  [51200/69420]
loss: 0.154615  [57600/69420]
loss: 0.111993  [64000/69420]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.198090 

Epoch 48
-------------------------------
loss: 0.215138  [    0/69420]
loss: 0.134498  [ 6400/69420]
loss: 0.227986  [12800/69420]
loss: 0.205126  [19200/69420]
loss: 0.293385  [25600/69420]
loss: 0.128920  [32000/69420]
loss: 0.210458  [38400/69420]
loss: 0.185554  [44800/69420]
loss: 0.287286  [51200/69420]
loss: 0.330443  [57600/69420]
loss: 0.296062  [64000/69420]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.199256 

Epoch 49
-------------------------------
loss: 0.094829  [    0/69420]
loss: 0.218403  [ 6400/69420]
loss: 0.276981  [12800/69420]
loss: 0.196403  [19200/69420]
loss: 0.234347  [25600/69420]
loss: 0.116281  [32000/69420]
loss: 0.167074  [38400/69420]
loss: 0.183231  [44800/69420]
loss: 0.288802  [51200/69420]
loss: 0.219757  [57600/69420]
loss: 0.227860  [64000/69420]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.202203 

Epoch 50
-------------------------------
loss: 0.194998  [    0/69420]
loss: 0.174505  [ 6400/69420]
loss: 0.154395  [12800/69420]
loss: 0.158052  [19200/69420]
loss: 0.180305  [25600/69420]
loss: 0.179504  [32000/69420]
loss: 0.112475  [38400/69420]
loss: 0.146147  [44800/69420]
loss: 0.186508  [51200/69420]
loss: 0.177993  [57600/69420]
loss: 0.101225  [64000/69420]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.206800 

Epoch 1
-------------------------------
loss: 0.660439  [    0/69865]
loss: 0.345377  [ 6400/69865]
loss: 0.273547  [12800/69865]
loss: 0.249148  [19200/69865]
loss: 0.251926  [25600/69865]
loss: 0.160044  [32000/69865]
loss: 0.315006  [38400/69865]
loss: 0.241252  [44800/69865]
loss: 0.341455  [51200/69865]
loss: 0.245821  [57600/69865]
loss: 0.246020  [64000/69865]
Test Error: 
 Accuracy: 89.6%, Avg loss: 0.253856 

Epoch 2
-------------------------------
loss: 0.184915  [    0/69865]
loss: 0.209730  [ 6400/69865]
loss: 0.391213  [12800/69865]
loss: 0.295686  [19200/69865]
loss: 0.310123  [25600/69865]
loss: 0.201305  [32000/69865]
loss: 0.186875  [38400/69865]
loss: 0.242190  [44800/69865]
loss: 0.192836  [51200/69865]
loss: 0.152308  [57600/69865]
loss: 0.234684  [64000/69865]
Test Error: 
 Accuracy: 89.6%, Avg loss: 0.251232 

Epoch 3
-------------------------------
loss: 0.279650  [    0/69865]
loss: 0.212233  [ 6400/69865]
loss: 0.195962  [12800/69865]
loss: 0.240022  [19200/69865]
loss: 0.343525  [25600/69865]
loss: 0.281005  [32000/69865]
loss: 0.360764  [38400/69865]
loss: 0.287330  [44800/69865]
loss: 0.196013  [51200/69865]
loss: 0.181893  [57600/69865]
loss: 0.191384  [64000/69865]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.211743 

Epoch 4
-------------------------------
loss: 0.448092  [    0/69865]
loss: 0.207260  [ 6400/69865]
loss: 0.168223  [12800/69865]
loss: 0.264260  [19200/69865]
loss: 0.220808  [25600/69865]
loss: 0.229880  [32000/69865]
loss: 0.165445  [38400/69865]
loss: 0.134736  [44800/69865]
loss: 0.289320  [51200/69865]
loss: 0.234886  [57600/69865]
loss: 0.205496  [64000/69865]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.214283 

Epoch 5
-------------------------------
loss: 0.237690  [    0/69865]
loss: 0.344781  [ 6400/69865]
loss: 0.226089  [12800/69865]
loss: 0.187064  [19200/69865]
loss: 0.240847  [25600/69865]
loss: 0.256028  [32000/69865]
loss: 0.313178  [38400/69865]
loss: 0.208786  [44800/69865]
loss: 0.142778  [51200/69865]
loss: 0.245595  [57600/69865]
loss: 0.153057  [64000/69865]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.213135 

Epoch 6
-------------------------------
loss: 0.135587  [    0/69865]
loss: 0.186763  [ 6400/69865]
loss: 0.209422  [12800/69865]
loss: 0.267523  [19200/69865]
loss: 0.411236  [25600/69865]
loss: 0.219567  [32000/69865]
loss: 0.249892  [38400/69865]
loss: 0.280160  [44800/69865]
2022/09/20 16:27:01 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.017152  [25600/72227]
loss: 0.009989  [32000/72227]
loss: 0.133941  [38400/72227]
loss: 0.073152  [44800/72227]
loss: 0.018700  [51200/72227]
loss: 0.029790  [57600/72227]
loss: 0.004569  [64000/72227]
loss: 0.044201  [70400/72227]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.088980 

Epoch 39
-------------------------------
loss: 0.009789  [    0/72227]
loss: 0.077567  [ 6400/72227]
loss: 0.021987  [12800/72227]
loss: 0.033097  [19200/72227]
loss: 0.063698  [25600/72227]
loss: 0.075173  [32000/72227]
loss: 0.040331  [38400/72227]
loss: 0.078083  [44800/72227]
loss: 0.020481  [51200/72227]
loss: 0.041044  [57600/72227]
loss: 0.049341  [64000/72227]
loss: 0.095700  [70400/72227]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.084945 

Epoch 40
-------------------------------
loss: 0.033696  [    0/72227]
loss: 0.020798  [ 6400/72227]
loss: 0.019253  [12800/72227]
loss: 0.030793  [19200/72227]
loss: 0.006442  [25600/72227]
loss: 0.055755  [32000/72227]
loss: 0.060872  [38400/72227]
loss: 0.025017  [44800/72227]
loss: 0.028234  [51200/72227]
loss: 0.078963  [57600/72227]
loss: 0.007180  [64000/72227]
loss: 0.041712  [70400/72227]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.072634 

Epoch 41
-------------------------------
loss: 0.003722  [    0/72227]
loss: 0.020639  [ 6400/72227]
loss: 0.076750  [12800/72227]
loss: 0.009179  [19200/72227]
loss: 0.005221  [25600/72227]
loss: 0.027418  [32000/72227]
loss: 0.001465  [38400/72227]
loss: 0.088018  [44800/72227]
loss: 0.025231  [51200/72227]
loss: 0.045354  [57600/72227]
loss: 0.023520  [64000/72227]
loss: 0.035870  [70400/72227]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.085431 

Epoch 42
-------------------------------
loss: 0.068912  [    0/72227]
loss: 0.007908  [ 6400/72227]
loss: 0.034081  [12800/72227]
loss: 0.044924  [19200/72227]
loss: 0.049411  [25600/72227]
loss: 0.010227  [32000/72227]
loss: 0.013937  [38400/72227]
loss: 0.031922  [44800/72227]
loss: 0.004908  [51200/72227]
loss: 0.009205  [57600/72227]
loss: 0.091283  [64000/72227]
loss: 0.003946  [70400/72227]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.084721 

Epoch 43
-------------------------------
loss: 0.016884  [    0/72227]
loss: 0.026502  [ 6400/72227]
loss: 0.098992  [12800/72227]
loss: 0.011575  [19200/72227]
loss: 0.052658  [25600/72227]
loss: 0.017619  [32000/72227]
loss: 0.029384  [38400/72227]
loss: 0.043381  [44800/72227]
loss: 0.009462  [51200/72227]
loss: 0.009302  [57600/72227]
loss: 0.028290  [64000/72227]
loss: 0.030919  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.084388 

Epoch 44
-------------------------------
loss: 0.028415  [    0/72227]
loss: 0.026122  [ 6400/72227]
loss: 0.072995  [12800/72227]
loss: 0.002197  [19200/72227]
loss: 0.097208  [25600/72227]
loss: 0.004168  [32000/72227]
loss: 0.015278  [38400/72227]
loss: 0.124997  [44800/72227]
loss: 0.063087  [51200/72227]
loss: 0.016869  [57600/72227]
loss: 0.055488  [64000/72227]
loss: 0.015342  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.089713 

Epoch 45
-------------------------------
loss: 0.007946  [    0/72227]
loss: 0.004410  [ 6400/72227]
loss: 0.019207  [12800/72227]
loss: 0.004264  [19200/72227]
loss: 0.071555  [25600/72227]
loss: 0.052153  [32000/72227]
loss: 0.016502  [38400/72227]
loss: 0.006222  [44800/72227]
loss: 0.008527  [51200/72227]
loss: 0.086344  [57600/72227]
loss: 0.026815  [64000/72227]
loss: 0.007668  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.073411 

Epoch 46
-------------------------------
loss: 0.021600  [    0/72227]
loss: 0.004049  [ 6400/72227]
loss: 0.020665  [12800/72227]
loss: 0.038209  [19200/72227]
loss: 0.047838  [25600/72227]
loss: 0.001958  [32000/72227]
loss: 0.014519  [38400/72227]
loss: 0.030614  [44800/72227]
loss: 0.009052  [51200/72227]
loss: 0.035525  [57600/72227]
loss: 0.013387  [64000/72227]
loss: 0.033617  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.091134 

Epoch 47
-------------------------------
loss: 0.000769  [    0/72227]
loss: 0.051543  [ 6400/72227]
loss: 0.027326  [12800/72227]
loss: 0.008036  [19200/72227]
loss: 0.006982  [25600/72227]
loss: 0.060757  [32000/72227]
loss: 0.214526  [38400/72227]
loss: 0.074500  [44800/72227]
loss: 0.010015  [51200/72227]
loss: 0.026932  [57600/72227]
loss: 0.056604  [64000/72227]
loss: 0.048189  [70400/72227]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.078250 

Epoch 48
-------------------------------
loss: 0.028896  [    0/72227]
loss: 0.029135  [ 6400/72227]
loss: 0.002298  [12800/72227]
loss: 0.008572  [19200/72227]
loss: 0.000125  [25600/72227]
loss: 0.025944  [32000/72227]
loss: 0.025120  [38400/72227]
loss: 0.030020  [44800/72227]
loss: 0.054709  [51200/72227]
loss: 0.038352  [57600/72227]
loss: 0.045146  [64000/72227]
loss: 0.034181  [70400/72227]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.084343 

Epoch 49
-------------------------------
loss: 0.052459  [    0/72227]
loss: 0.035777  [ 6400/72227]
loss: 0.003866  [12800/72227]
loss: 0.021486  [19200/72227]
loss: 0.065803  [25600/72227]
loss: 0.049746  [32000/72227]
loss: 0.062743  [38400/72227]
loss: 0.009997  [44800/72227]
loss: 0.014834  [51200/72227]
loss: 0.068328  [57600/72227]
loss: 0.046604  [64000/72227]
loss: 0.053789  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.082786 

Epoch 50
-------------------------------
loss: 0.018248  [    0/72227]
loss: 0.014824  [ 6400/72227]
loss: 0.075566  [12800/72227]
loss: 0.019209  [19200/72227]
loss: 0.004876  [25600/72227]
loss: 0.107657  [32000/72227]
loss: 0.006589  [38400/72227]
loss: 0.053984  [44800/72227]
loss: 0.083986  [51200/72227]
loss: 0.008898  [57600/72227]
loss: 0.007581  [64000/72227]
loss: 0.116595  [70400/72227]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.096453 

Epoch 1
-------------------------------
loss: 0.673154  [    0/71429]
loss: 0.120297  [ 6400/71429]
loss: 0.094477  [12800/71429]
loss: 0.391071  [19200/71429]
loss: 0.091295  [25600/71429]
loss: 0.109878  [32000/71429]
loss: 0.106220  [38400/71429]
loss: 0.118883  [44800/71429]
loss: 0.029168  [51200/71429]
loss: 0.091561  [57600/71429]
loss: 0.118894  [64000/71429]
loss: 0.063460  [70400/71429]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.114355 

Epoch 2
-------------------------------
loss: 0.090396  [    0/71429]
loss: 0.128710  [ 6400/71429]
loss: 0.079327  [12800/71429]
loss: 0.081382  [19200/71429]
loss: 0.065094  [25600/71429]
loss: 0.102520  [32000/71429]
loss: 0.100687  [38400/71429]
loss: 0.051620  [44800/71429]
loss: 0.084240  [51200/71429]
loss: 0.040154  [57600/71429]
loss: 0.117817  [64000/71429]
loss: 0.123194  [70400/71429]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.095049 

Epoch 3
-------------------------------
loss: 0.087799  [    0/71429]
loss: 0.057249  [ 6400/71429]
loss: 0.041379  [12800/71429]
loss: 0.104321  [19200/71429]
loss: 0.088904  [25600/71429]
loss: 0.091628  [32000/71429]
loss: 0.108334  [38400/71429]
loss: 0.045476  [44800/71429]
loss: 0.045570  [51200/71429]
loss: 0.076119  [57600/71429]
loss: 0.299229  [64000/71429]
loss: 0.055097  [70400/71429]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.100817 

Epoch 4
-------------------------------
loss: 0.931102  [    0/71429]
loss: 0.070910  [ 6400/71429]
loss: 0.063660  [12800/71429]
loss: 0.089117  [19200/71429]
loss: 0.047176  [25600/71429]
loss: 0.056297  [32000/71429]
loss: 0.011354  [38400/71429]
loss: 0.033499  [44800/71429]
loss: 0.021559  [51200/71429]
loss: 0.048339  [57600/71429]
loss: 0.081590  [64000/71429]
loss: 0.052187  [70400/71429]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.091532 

Epoch 5
-------------------------------
loss: 0.022154  [    0/71429]
loss: 0.043896  [ 6400/71429]
loss: 0.064149  [12800/71429]
loss: 0.010573  [19200/71429]
loss: 0.070198  [25600/71429]
loss: 0.053215  [32000/71429]
loss: 0.018434  [38400/71429]
loss: 0.129244  [44800/71429]
loss: 0.023019  [51200/71429]
loss: 0.065514  [57600/71429]
loss: 0.056373  [64000/71429]
loss: 0.064163  [70400/71429]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.096693 

Epoch 6
-------------------------------
loss: 0.039512  [    0/71429]
loss: 0.116668  [ 6400/71429]
loss: 0.030777  [12800/71429]
loss: 0.117696  [19200/71429]
loss: 0.096703  [25600/71429]
2022/09/20 16:28:48 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 16:28:53 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.015832  [64000/71616]
loss: 0.010716  [70400/71616]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.082703 

Epoch 50
-------------------------------
loss: 0.036444  [    0/71616]
loss: 0.017961  [ 6400/71616]
loss: 0.039398  [12800/71616]
loss: 0.049918  [19200/71616]
loss: 0.004678  [25600/71616]
loss: 0.043929  [32000/71616]
loss: 0.022383  [38400/71616]
loss: 0.018149  [44800/71616]
loss: 0.015817  [51200/71616]
loss: 0.001457  [57600/71616]
loss: 0.053329  [64000/71616]
loss: 0.016563  [70400/71616]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073211 

Epoch 1
-------------------------------
loss: 0.687821  [    0/71476]
loss: 0.251482  [ 6400/71476]
loss: 0.245723  [12800/71476]
loss: 0.117413  [19200/71476]
loss: 0.194101  [25600/71476]
loss: 0.106102  [32000/71476]
loss: 0.098201  [38400/71476]
loss: 0.136429  [44800/71476]
loss: 0.223629  [51200/71476]
loss: 0.052884  [57600/71476]
loss: 0.112532  [64000/71476]
loss: 0.136592  [70400/71476]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.159609 

Epoch 2
-------------------------------
loss: 0.107542  [    0/71476]
loss: 0.070112  [ 6400/71476]
loss: 0.108762  [12800/71476]
loss: 0.090623  [19200/71476]
loss: 0.135963  [25600/71476]
loss: 0.150807  [32000/71476]
loss: 0.108319  [38400/71476]
loss: 0.164813  [44800/71476]
loss: 0.205908  [51200/71476]
loss: 0.180321  [57600/71476]
loss: 0.086288  [64000/71476]
loss: 0.142581  [70400/71476]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.142970 

Epoch 3
-------------------------------
loss: 0.085110  [    0/71476]
loss: 0.155278  [ 6400/71476]
loss: 1.612794  [12800/71476]
loss: 0.202362  [19200/71476]
loss: 0.151483  [25600/71476]
loss: 0.093353  [32000/71476]
loss: 0.137313  [38400/71476]
loss: 1.759737  [44800/71476]
loss: 0.107488  [51200/71476]
loss: 1.730885  [57600/71476]
loss: 0.103164  [64000/71476]
loss: 0.100590  [70400/71476]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.129546 

Epoch 4
-------------------------------
loss: 0.078775  [    0/71476]
loss: 0.137977  [ 6400/71476]
loss: 0.043368  [12800/71476]
loss: 0.084482  [19200/71476]
loss: 0.219151  [25600/71476]
loss: 1.613991  [32000/71476]
loss: 0.095506  [38400/71476]
loss: 0.077432  [44800/71476]
loss: 0.144144  [51200/71476]
loss: 0.073040  [57600/71476]
loss: 0.072509  [64000/71476]
loss: 0.075344  [70400/71476]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.125578 

Epoch 5
-------------------------------
loss: 0.069264  [    0/71476]
loss: 0.110450  [ 6400/71476]
loss: 0.038035  [12800/71476]
loss: 0.040066  [19200/71476]
loss: 0.139229  [25600/71476]
loss: 0.067700  [32000/71476]
loss: 0.020756  [38400/71476]
loss: 0.100385  [44800/71476]
loss: 0.137509  [51200/71476]
loss: 0.053393  [57600/71476]
loss: 0.051224  [64000/71476]
loss: 0.051960  [70400/71476]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.116697 

Epoch 6
-------------------------------
loss: 0.077211  [    0/71476]
loss: 0.123778  [ 6400/71476]
loss: 0.093659  [12800/71476]
loss: 0.108143  [19200/71476]
loss: 0.120810  [25600/71476]
loss: 0.085862  [32000/71476]
loss: 0.081626  [38400/71476]
loss: 0.109066  [44800/71476]
loss: 0.052007  [51200/71476]
loss: 0.050684  [57600/71476]
loss: 0.036636  [64000/71476]
loss: 0.076706  [70400/71476]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.116221 

Epoch 7
-------------------------------
loss: 0.050524  [    0/71476]
loss: 0.063764  [ 6400/71476]
loss: 0.104330  [12800/71476]
loss: 0.311865  [19200/71476]
loss: 0.127093  [25600/71476]
loss: 0.085723  [32000/71476]
loss: 0.079622  [38400/71476]
loss: 0.080529  [44800/71476]
loss: 0.118116  [51200/71476]
loss: 0.306393  [57600/71476]
loss: 0.078465  [64000/71476]
loss: 0.103666  [70400/71476]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.120127 

Epoch 8
-------------------------------
loss: 0.154262  [    0/71476]
loss: 0.119837  [ 6400/71476]
loss: 0.042356  [12800/71476]
loss: 0.050228  [19200/71476]
loss: 0.087592  [25600/71476]
loss: 0.058892  [32000/71476]
loss: 0.202632  [38400/71476]
loss: 0.075414  [44800/71476]
loss: 0.102399  [51200/71476]
loss: 0.136335  [57600/71476]
loss: 0.157628  [64000/71476]
loss: 0.075238  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.111843 

Epoch 9
-------------------------------
loss: 0.192903  [    0/71476]
loss: 0.078078  [ 6400/71476]
loss: 0.035249  [12800/71476]
loss: 0.038971  [19200/71476]
loss: 0.024827  [25600/71476]
loss: 0.093901  [32000/71476]
loss: 0.122312  [38400/71476]
loss: 0.110590  [44800/71476]
loss: 0.032994  [51200/71476]
loss: 0.072072  [57600/71476]
loss: 0.042796  [64000/71476]
loss: 0.031251  [70400/71476]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.109354 

Epoch 10
-------------------------------
loss: 0.014227  [    0/71476]
loss: 0.061995  [ 6400/71476]
loss: 0.065358  [12800/71476]
loss: 0.107185  [19200/71476]
loss: 0.093519  [25600/71476]
loss: 0.023602  [32000/71476]
loss: 0.033491  [38400/71476]
loss: 0.153120  [44800/71476]
loss: 0.047819  [51200/71476]
loss: 0.083841  [57600/71476]
loss: 0.322981  [64000/71476]
loss: 0.016705  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.111126 

Epoch 11
-------------------------------
loss: 0.067966  [    0/71476]
loss: 0.126109  [ 6400/71476]
loss: 0.061390  [12800/71476]
loss: 0.085444  [19200/71476]
loss: 0.031180  [25600/71476]
loss: 0.017238  [32000/71476]
loss: 0.124850  [38400/71476]
loss: 0.181999  [44800/71476]
loss: 0.091028  [51200/71476]
loss: 0.021677  [57600/71476]
loss: 0.070370  [64000/71476]
loss: 0.084354  [70400/71476]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.110535 

Epoch 12
-------------------------------
loss: 0.037458  [    0/71476]
loss: 0.103627  [ 6400/71476]
loss: 0.066628  [12800/71476]
loss: 0.076440  [19200/71476]
loss: 0.206299  [25600/71476]
loss: 0.047314  [32000/71476]
loss: 0.084378  [38400/71476]
loss: 0.210480  [44800/71476]
loss: 0.124004  [51200/71476]
loss: 1.595385  [57600/71476]
loss: 0.063145  [64000/71476]
loss: 0.050161  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.122170 

Epoch 13
-------------------------------
loss: 0.047799  [    0/71476]
loss: 0.031021  [ 6400/71476]
loss: 0.022931  [12800/71476]
loss: 0.107416  [19200/71476]
loss: 0.078196  [25600/71476]
loss: 0.070141  [32000/71476]
loss: 0.061422  [38400/71476]
loss: 0.117884  [44800/71476]
loss: 0.066943  [51200/71476]
loss: 0.061608  [57600/71476]
loss: 0.107266  [64000/71476]
loss: 0.048874  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.122025 

Epoch 14
-------------------------------
loss: 0.039621  [    0/71476]
loss: 0.137157  [ 6400/71476]
loss: 0.186862  [12800/71476]
loss: 0.049188  [19200/71476]
loss: 0.086891  [25600/71476]
loss: 0.052018  [32000/71476]
loss: 0.076806  [38400/71476]
loss: 0.056579  [44800/71476]
loss: 0.079243  [51200/71476]
loss: 0.075764  [57600/71476]
loss: 0.024089  [64000/71476]
loss: 0.046366  [70400/71476]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.124928 

Epoch 15
-------------------------------
loss: 0.105045  [    0/71476]
loss: 0.051642  [ 6400/71476]
loss: 0.037354  [12800/71476]
loss: 0.097161  [19200/71476]
loss: 0.030802  [25600/71476]
loss: 0.027792  [32000/71476]
loss: 1.665212  [38400/71476]
loss: 0.040174  [44800/71476]
loss: 0.108610  [51200/71476]
loss: 0.031344  [57600/71476]
loss: 0.161467  [64000/71476]
loss: 0.027183  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.119068 

Epoch 16
-------------------------------
loss: 0.100101  [    0/71476]
loss: 0.039536  [ 6400/71476]
loss: 0.055042  [12800/71476]
loss: 0.073486  [19200/71476]
loss: 0.089434  [25600/71476]
loss: 0.015179  [32000/71476]
loss: 0.123343  [38400/71476]
loss: 0.069820  [44800/71476]
loss: 0.082572  [51200/71476]
loss: 0.112855  [57600/71476]
loss: 0.104557  [64000/71476]
loss: 0.086608  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.122016 

Epoch 17
-------------------------------
loss: 0.057478  [    0/71476]
loss: 0.125810  [ 6400/71476]
loss: 0.041677  [12800/71476]
loss: 0.052235  [19200/71476]
loss: 0.028046  [25600/71476]
loss: 0.200650  [32000/71476]
loss: 0.024998  [38400/71476]
loss: 0.210867  [44800/71476]
loss: 0.060362  [51200/71476]
loss: 0.044314  [57600/71476]
loss: 0.142633  [64000/71476]
loss: 0.066137  [19200/70932]
loss: 0.280882  [25600/70932]
loss: 0.171444  [32000/70932]
loss: 0.115891  [38400/70932]
loss: 0.029471  [44800/70932]
loss: 0.099471  [51200/70932]
loss: 0.104757  [57600/70932]
loss: 0.182329  [64000/70932]
loss: 0.246351  [70400/70932]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.190009 

Epoch 39
-------------------------------
loss: 0.083849  [    0/70932]
loss: 0.203578  [ 6400/70932]
loss: 0.089089  [12800/70932]
loss: 0.055810  [19200/70932]
loss: 0.056127  [25600/70932]
loss: 0.151255  [32000/70932]
loss: 0.099635  [38400/70932]
loss: 0.066956  [44800/70932]
loss: 0.097118  [51200/70932]
loss: 0.078951  [57600/70932]
loss: 0.190074  [64000/70932]
loss: 0.133655  [70400/70932]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.160326 

Epoch 40
-------------------------------
loss: 0.192068  [    0/70932]
loss: 0.093505  [ 6400/70932]
loss: 0.122536  [12800/70932]
loss: 0.152548  [19200/70932]
loss: 0.034462  [25600/70932]
loss: 0.057576  [32000/70932]
loss: 0.154413  [38400/70932]
loss: 0.072137  [44800/70932]
loss: 0.108635  [51200/70932]
loss: 0.220680  [57600/70932]
loss: 0.140569  [64000/70932]
loss: 0.089084  [70400/70932]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.172218 

Epoch 41
-------------------------------
loss: 0.110731  [    0/70932]
loss: 0.034217  [ 6400/70932]
loss: 0.048664  [12800/70932]
loss: 0.097786  [19200/70932]
loss: 0.161814  [25600/70932]
loss: 0.162745  [32000/70932]
loss: 0.171771  [38400/70932]
loss: 0.122721  [44800/70932]
loss: 0.071704  [51200/70932]
loss: 0.040169  [57600/70932]
loss: 0.070625  [64000/70932]
loss: 0.127693  [70400/70932]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.162095 

Epoch 42
-------------------------------
loss: 0.211273  [    0/70932]
loss: 0.147559  [ 6400/70932]
loss: 0.075146  [12800/70932]
loss: 1.631076  [19200/70932]
loss: 0.123209  [25600/70932]
loss: 0.180016  [32000/70932]
loss: 0.099559  [38400/70932]
loss: 0.099883  [44800/70932]
loss: 0.105027  [51200/70932]
loss: 0.118060  [57600/70932]
loss: 0.191663  [64000/70932]
loss: 0.154887  [70400/70932]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.185500 

Epoch 43
-------------------------------
loss: 0.194574  [    0/70932]
loss: 0.152438  [ 6400/70932]
loss: 0.116320  [12800/70932]
loss: 0.216773  [19200/70932]
loss: 0.154924  [25600/70932]
loss: 0.115366  [32000/70932]
loss: 0.167656  [38400/70932]
loss: 0.063517  [44800/70932]
loss: 0.068950  [51200/70932]
loss: 0.241495  [57600/70932]
loss: 0.251888  [64000/70932]
loss: 0.076102  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.165452 

Epoch 44
-------------------------------
loss: 0.148176  [    0/70932]
loss: 0.189803  [ 6400/70932]
loss: 0.140736  [12800/70932]
loss: 0.086750  [19200/70932]
loss: 0.115700  [25600/70932]
loss: 0.166174  [32000/70932]
loss: 0.123999  [38400/70932]
loss: 0.126723  [44800/70932]
loss: 0.024410  [51200/70932]
loss: 0.283600  [57600/70932]
loss: 0.071034  [64000/70932]
loss: 0.024558  [70400/70932]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.163079 

Epoch 45
-------------------------------
loss: 0.060852  [    0/70932]
loss: 0.134713  [ 6400/70932]
loss: 0.190385  [12800/70932]
loss: 0.177118  [19200/70932]
loss: 0.034560  [25600/70932]
loss: 0.203698  [32000/70932]
loss: 0.107807  [38400/70932]
loss: 0.085023  [44800/70932]
loss: 0.126405  [51200/70932]
loss: 0.156876  [57600/70932]
loss: 0.084658  [64000/70932]
loss: 0.193530  [70400/70932]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.160557 

Epoch 46
-------------------------------
loss: 0.148115  [    0/70932]
loss: 0.055513  [ 6400/70932]
loss: 0.187248  [12800/70932]
loss: 0.196158  [19200/70932]
loss: 0.228342  [25600/70932]
loss: 0.103743  [32000/70932]
loss: 0.044816  [38400/70932]
loss: 0.132482  [44800/70932]
loss: 0.121420  [51200/70932]
loss: 0.096864  [57600/70932]
loss: 0.207284  [64000/70932]
loss: 0.163698  [70400/70932]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.159325 

Epoch 47
-------------------------------
loss: 0.109459  [    0/70932]
loss: 0.056858  [ 6400/70932]
loss: 0.087471  [12800/70932]
loss: 0.133904  [19200/70932]
loss: 0.181378  [25600/70932]
loss: 0.109646  [32000/70932]
loss: 0.124005  [38400/70932]
loss: 0.152513  [44800/70932]
loss: 0.144041  [51200/70932]
loss: 0.135657  [57600/70932]
loss: 0.109526  [64000/70932]
loss: 0.154534  [70400/70932]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.158042 

Epoch 48
-------------------------------
loss: 0.087060  [    0/70932]
loss: 0.071252  [ 6400/70932]
loss: 0.130275  [12800/70932]
loss: 0.075325  [19200/70932]
loss: 0.130641  [25600/70932]
loss: 0.137216  [32000/70932]
loss: 0.136123  [38400/70932]
loss: 0.219653  [44800/70932]
loss: 0.141564  [51200/70932]
loss: 0.169750  [57600/70932]
loss: 0.190754  [64000/70932]
loss: 0.036742  [70400/70932]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.167934 

Epoch 49
-------------------------------
loss: 0.153621  [    0/70932]
loss: 0.086383  [ 6400/70932]
loss: 0.101268  [12800/70932]
loss: 0.061970  [19200/70932]
loss: 0.141539  [25600/70932]
loss: 0.077066  [32000/70932]
loss: 0.065365  [38400/70932]
loss: 0.038158  [44800/70932]
loss: 0.104618  [51200/70932]
loss: 0.055347  [57600/70932]
loss: 0.150000  [64000/70932]
loss: 0.069234  [70400/70932]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.164786 

Epoch 50
-------------------------------
loss: 0.059257  [    0/70932]
loss: 0.240015  [ 6400/70932]
loss: 0.132825  [12800/70932]
loss: 0.091976  [19200/70932]
loss: 0.177005  [25600/70932]
loss: 0.064281  [32000/70932]
loss: 0.115315  [38400/70932]
loss: 0.172903  [44800/70932]
loss: 0.046998  [51200/70932]
loss: 0.165227  [57600/70932]
loss: 0.160104  [64000/70932]
loss: 0.143891  [70400/70932]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.163407 

Epoch 1
-------------------------------
loss: 0.694566  [    0/71041]
loss: 0.269847  [ 6400/71041]
loss: 0.405862  [12800/71041]
loss: 0.415223  [19200/71041]
loss: 0.165508  [25600/71041]
loss: 0.290511  [32000/71041]
loss: 0.167940  [38400/71041]
loss: 0.331710  [44800/71041]
loss: 0.297472  [51200/71041]
loss: 0.215040  [57600/71041]
loss: 0.152745  [64000/71041]
loss: 0.131111  [70400/71041]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.204832 

Epoch 2
-------------------------------
loss: 0.114711  [    0/71041]
loss: 0.117375  [ 6400/71041]
loss: 0.149845  [12800/71041]
loss: 0.246513  [19200/71041]
loss: 0.184670  [25600/71041]
loss: 0.200440  [32000/71041]
loss: 0.113866  [38400/71041]
loss: 0.111226  [44800/71041]
loss: 0.232396  [51200/71041]
loss: 0.168700  [57600/71041]
loss: 0.235337  [64000/71041]
loss: 0.103992  [70400/71041]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.182023 

Epoch 3
-------------------------------
loss: 0.146254  [    0/71041]
loss: 0.139077  [ 6400/71041]
loss: 0.133355  [12800/71041]
loss: 0.039470  [19200/71041]
loss: 0.241841  [25600/71041]
loss: 0.123303  [32000/71041]
loss: 0.066243  [38400/71041]
loss: 0.076993  [44800/71041]
loss: 0.140855  [51200/71041]
loss: 0.206027  [57600/71041]
loss: 0.327638  [64000/71041]
loss: 0.162592  [70400/71041]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.179511 

Epoch 4
-------------------------------
loss: 0.121085  [    0/71041]
loss: 0.055567  [ 6400/71041]
loss: 0.121060  [12800/71041]
loss: 0.062743  [19200/71041]
loss: 0.283893  [25600/71041]
loss: 0.162218  [32000/71041]
loss: 0.225508  [38400/71041]
loss: 0.083225  [44800/71041]
loss: 0.101290  [51200/71041]
loss: 0.056159  [57600/71041]
loss: 0.273012  [64000/71041]
loss: 0.163926  [70400/71041]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.184646 

Epoch 5
-------------------------------
loss: 0.222143  [    0/71041]
loss: 0.125249  [ 6400/71041]
loss: 0.187442  [12800/71041]
loss: 0.170711  [19200/71041]
loss: 0.143036  [25600/71041]
loss: 0.187051  [32000/71041]
loss: 0.120569  [38400/71041]
loss: 0.083422  [44800/71041]
loss: 0.181670  [51200/71041]
loss: 0.192485  [57600/71041]
loss: 0.129077  [64000/71041]
loss: 0.122335  [70400/71041]
Test Error: 
 Accuracy: 89.8%, Avg loss: 0.275925 

Epoch 6
-------------------------------
loss: 0.486542  [    0/71041]
loss: 0.090513  [ 6400/71041]
loss: 0.211618  [12800/71041]
loss: 0.101283  [19200/71041]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.151446 

Epoch 35
-------------------------------
loss: 0.168851  [    0/70685]
loss: 0.065513  [ 6400/70685]
loss: 0.078189  [12800/70685]
loss: 0.145400  [19200/70685]
loss: 0.221178  [25600/70685]
loss: 0.100291  [32000/70685]
loss: 0.091892  [38400/70685]
loss: 0.074674  [44800/70685]
loss: 0.147903  [51200/70685]
loss: 0.146002  [57600/70685]
loss: 0.252003  [64000/70685]
loss: 0.222618  [70400/70685]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169893 

Epoch 36
-------------------------------
loss: 0.131677  [    0/70685]
loss: 0.218677  [ 6400/70685]
loss: 0.250251  [12800/70685]
loss: 0.136370  [19200/70685]
loss: 0.130951  [25600/70685]
loss: 0.064478  [32000/70685]
loss: 0.081513  [38400/70685]
loss: 0.151600  [44800/70685]
loss: 0.109811  [51200/70685]
loss: 0.144875  [57600/70685]
loss: 0.119131  [64000/70685]
loss: 0.212130  [70400/70685]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159661 

Epoch 37
-------------------------------
loss: 0.077017  [    0/70685]
loss: 0.118400  [ 6400/70685]
loss: 0.130473  [12800/70685]
loss: 0.155835  [19200/70685]
loss: 0.164290  [25600/70685]
loss: 0.221072  [32000/70685]
loss: 0.128555  [38400/70685]
loss: 0.150898  [44800/70685]
loss: 0.320146  [51200/70685]
loss: 0.056008  [57600/70685]
loss: 0.063649  [64000/70685]
loss: 0.159685  [70400/70685]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.149708 

Epoch 38
-------------------------------
loss: 0.170251  [    0/70685]
loss: 0.068998  [ 6400/70685]
loss: 0.204462  [12800/70685]
loss: 0.080482  [19200/70685]
loss: 0.077714  [25600/70685]
loss: 0.215991  [32000/70685]
loss: 0.202664  [38400/70685]
loss: 0.109892  [44800/70685]
loss: 0.216119  [51200/70685]
loss: 0.231671  [57600/70685]
loss: 0.230156  [64000/70685]
loss: 0.114207  [70400/70685]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.153656 

Epoch 39
-------------------------------
loss: 0.062139  [    0/70685]
loss: 0.226032  [ 6400/70685]
loss: 0.098470  [12800/70685]
loss: 0.135556  [19200/70685]
loss: 0.121857  [25600/70685]
loss: 0.217521  [32000/70685]
loss: 0.130089  [38400/70685]
loss: 0.162847  [44800/70685]
loss: 0.230975  [51200/70685]
loss: 0.055605  [57600/70685]
loss: 0.273007  [64000/70685]
loss: 0.148928  [70400/70685]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.152574 

Epoch 40
-------------------------------
loss: 0.157998  [    0/70685]
loss: 0.098382  [ 6400/70685]
loss: 0.201229  [12800/70685]
loss: 0.161934  [19200/70685]
loss: 0.164954  [25600/70685]
loss: 0.170196  [32000/70685]
loss: 0.140184  [38400/70685]
loss: 0.256741  [44800/70685]
loss: 0.106345  [51200/70685]
loss: 0.172935  [57600/70685]
loss: 0.128134  [64000/70685]
loss: 0.101673  [70400/70685]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150353 

Epoch 41
-------------------------------
loss: 0.262945  [    0/70685]
loss: 0.204518  [ 6400/70685]
loss: 0.270411  [12800/70685]
loss: 0.125461  [19200/70685]
loss: 0.177326  [25600/70685]
loss: 0.119977  [32000/70685]
loss: 0.136407  [38400/70685]
loss: 0.155867  [44800/70685]
loss: 0.165997  [51200/70685]
loss: 0.197180  [57600/70685]
loss: 0.091528  [64000/70685]
loss: 0.092523  [70400/70685]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.157443 

Epoch 42
-------------------------------
loss: 0.123968  [    0/70685]
loss: 0.071014  [ 6400/70685]
loss: 0.157189  [12800/70685]
loss: 0.100476  [19200/70685]
loss: 0.088318  [25600/70685]
loss: 0.168032  [32000/70685]
loss: 0.157575  [38400/70685]
loss: 0.168562  [44800/70685]
loss: 0.122034  [51200/70685]
loss: 0.054585  [57600/70685]
loss: 0.114284  [64000/70685]
loss: 0.126162  [70400/70685]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150994 

Epoch 43
-------------------------------
loss: 0.130891  [    0/70685]
loss: 0.079047  [ 6400/70685]
loss: 0.159606  [12800/70685]
loss: 0.073239  [19200/70685]
loss: 0.084160  [25600/70685]
loss: 0.213556  [32000/70685]
loss: 0.118900  [38400/70685]
loss: 0.201007  [44800/70685]
loss: 0.254899  [51200/70685]
loss: 0.143022  [57600/70685]
loss: 0.152174  [64000/70685]
loss: 0.139073  [70400/70685]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.154087 

Epoch 44
-------------------------------
loss: 0.134758  [    0/70685]
loss: 0.211793  [ 6400/70685]
loss: 0.133230  [12800/70685]
loss: 0.115568  [19200/70685]
loss: 0.166323  [25600/70685]
loss: 0.144366  [32000/70685]
loss: 0.239470  [38400/70685]
loss: 0.074504  [44800/70685]
loss: 0.110156  [51200/70685]
loss: 0.230901  [57600/70685]
loss: 1.679329  [64000/70685]
loss: 0.110654  [70400/70685]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.152113 

Epoch 45
-------------------------------
loss: 0.216593  [    0/70685]
loss: 0.113892  [ 6400/70685]
loss: 0.145140  [12800/70685]
loss: 0.084321  [19200/70685]
loss: 0.038020  [25600/70685]
loss: 0.134877  [32000/70685]
loss: 0.058438  [38400/70685]
loss: 0.042145  [44800/70685]
loss: 0.095904  [51200/70685]
loss: 0.128501  [57600/70685]
loss: 0.106389  [64000/70685]
loss: 0.069094  [70400/70685]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.153099 

Epoch 46
-------------------------------
loss: 0.109081  [    0/70685]
loss: 0.098789  [ 6400/70685]
loss: 0.141751  [12800/70685]
loss: 0.203424  [19200/70685]
loss: 0.065362  [25600/70685]
loss: 0.093318  [32000/70685]
loss: 0.079337  [38400/70685]
loss: 0.206528  [44800/70685]
loss: 0.148823  [51200/70685]
loss: 0.174509  [57600/70685]
loss: 0.088528  [64000/70685]
loss: 0.195447  [70400/70685]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.166390 

Epoch 47
-------------------------------
loss: 0.135787  [    0/70685]
loss: 0.131654  [ 6400/70685]
loss: 0.133966  [12800/70685]
loss: 0.137227  [19200/70685]
loss: 0.076764  [25600/70685]
loss: 0.098078  [32000/70685]
loss: 0.123083  [38400/70685]
loss: 0.119211  [44800/70685]
loss: 0.183597  [51200/70685]
loss: 0.196773  [57600/70685]
loss: 0.138263  [64000/70685]
loss: 0.112443  [70400/70685]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.155109 

Epoch 48
-------------------------------
loss: 0.096499  [    0/70685]
loss: 0.163743  [ 6400/70685]
loss: 0.260934  [12800/70685]
loss: 0.119112  [19200/70685]
loss: 0.114919  [25600/70685]
loss: 0.156204  [32000/70685]
loss: 0.110128  [38400/70685]
loss: 0.089133  [44800/70685]
loss: 0.176073  [51200/70685]
loss: 0.218730  [57600/70685]
loss: 0.107676  [64000/70685]
loss: 0.139473  [70400/70685]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.164675 

Epoch 49
-------------------------------
loss: 0.298302  [    0/70685]
loss: 0.214238  [ 6400/70685]
loss: 0.264421  [12800/70685]
loss: 0.090505  [19200/70685]
loss: 0.093744  [25600/70685]
loss: 0.210235  [32000/70685]
loss: 0.111135  [38400/70685]
loss: 0.131304  [44800/70685]
loss: 0.130646  [51200/70685]
loss: 0.125324  [57600/70685]
loss: 0.142432  [64000/70685]
loss: 0.166639  [70400/70685]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.149511 

Epoch 50
-------------------------------
loss: 0.146260  [    0/70685]
loss: 0.108301  [ 6400/70685]
loss: 0.233345  [12800/70685]
loss: 0.177706  [19200/70685]
loss: 0.060544  [25600/70685]
loss: 0.151543  [32000/70685]
loss: 0.200016  [38400/70685]
loss: 0.127925  [44800/70685]
loss: 0.349022  [51200/70685]
loss: 0.078667  [57600/70685]
loss: 0.120468  [64000/70685]
loss: 0.178130  [70400/70685]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153651 

Epoch 1
-------------------------------
loss: 0.660383  [    0/69867]
loss: 0.367678  [ 6400/69867]
loss: 0.449535  [12800/69867]
loss: 0.374262  [19200/69867]
loss: 0.184543  [25600/69867]
loss: 0.476873  [32000/69867]
loss: 0.222450  [38400/69867]
loss: 0.281097  [44800/69867]
loss: 0.383860  [51200/69867]
loss: 0.145199  [57600/69867]
loss: 0.346516  [64000/69867]
Test Error: 
 Accuracy: 90.3%, Avg loss: 0.229876 

Epoch 2
-------------------------------
loss: 0.257638  [    0/69867]
loss: 0.186331  [ 6400/69867]
loss: 0.183274  [12800/69867]
loss: 0.200523  [19200/69867]
loss: 0.203205  [25600/69867]
loss: 0.135568  [32000/69867]
loss: 0.228968  [38400/69867]
loss: 0.191896  [44800/69867]
loss: 0.234334  [51200/69867]
loss: 0.257917  [57600/69867]
loss: 0.189637  [64000/69867]
Test Error: 
 Accuracy: 90.2%, Avg loss: 0.225153 

Epoch 3
-------------------------------
2022/09/20 16:32:20 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.163489  [32000/69806]
loss: 0.167724  [38400/69806]
loss: 0.123637  [44800/69806]
loss: 0.169253  [51200/69806]
loss: 0.139844  [57600/69806]
loss: 0.121787  [64000/69806]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.205241 

Epoch 38
-------------------------------
loss: 0.126922  [    0/69806]
loss: 0.191316  [ 6400/69806]
loss: 0.160448  [12800/69806]
loss: 0.317070  [19200/69806]
loss: 0.268284  [25600/69806]
loss: 0.120434  [32000/69806]
loss: 0.219616  [38400/69806]
loss: 0.236598  [44800/69806]
loss: 0.267183  [51200/69806]
loss: 0.256524  [57600/69806]
loss: 0.142859  [64000/69806]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.212763 

Epoch 39
-------------------------------
loss: 0.287248  [    0/69806]
loss: 0.109669  [ 6400/69806]
loss: 0.226199  [12800/69806]
loss: 0.209068  [19200/69806]
loss: 0.180797  [25600/69806]
loss: 0.100238  [32000/69806]
loss: 0.173833  [38400/69806]
loss: 0.268614  [44800/69806]
loss: 0.141912  [51200/69806]
loss: 0.162903  [57600/69806]
loss: 0.274448  [64000/69806]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.198585 

Epoch 40
-------------------------------
loss: 0.109586  [    0/69806]
loss: 0.065339  [ 6400/69806]
loss: 0.195463  [12800/69806]
loss: 0.118389  [19200/69806]
loss: 0.172931  [25600/69806]
loss: 0.138877  [32000/69806]
loss: 0.146281  [38400/69806]
loss: 0.217282  [44800/69806]
loss: 0.108718  [51200/69806]
loss: 0.195277  [57600/69806]
loss: 0.262303  [64000/69806]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.212844 

Epoch 41
-------------------------------
loss: 0.135213  [    0/69806]
loss: 0.182452  [ 6400/69806]
loss: 0.179026  [12800/69806]
loss: 0.137669  [19200/69806]
loss: 0.164127  [25600/69806]
loss: 0.308546  [32000/69806]
loss: 0.181672  [38400/69806]
loss: 0.205519  [44800/69806]
loss: 0.225979  [51200/69806]
loss: 0.170100  [57600/69806]
loss: 0.219648  [64000/69806]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.199715 

Epoch 42
-------------------------------
loss: 0.235904  [    0/69806]
loss: 0.153704  [ 6400/69806]
loss: 0.078513  [12800/69806]
loss: 0.352337  [19200/69806]
loss: 0.166615  [25600/69806]
loss: 0.138510  [32000/69806]
loss: 0.189035  [38400/69806]
loss: 0.164409  [44800/69806]
loss: 0.201075  [51200/69806]
loss: 0.083217  [57600/69806]
loss: 0.186384  [64000/69806]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.195725 

Epoch 43
-------------------------------
loss: 0.127582  [    0/69806]
loss: 0.152084  [ 6400/69806]
loss: 0.203987  [12800/69806]
loss: 0.129314  [19200/69806]
loss: 0.120125  [25600/69806]
loss: 0.381045  [32000/69806]
loss: 0.319613  [38400/69806]
loss: 0.138254  [44800/69806]
loss: 0.177683  [51200/69806]
loss: 0.179468  [57600/69806]
loss: 0.225766  [64000/69806]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.206035 

Epoch 44
-------------------------------
loss: 0.167819  [    0/69806]
loss: 0.121338  [ 6400/69806]
loss: 0.239842  [12800/69806]
loss: 0.190985  [19200/69806]
loss: 0.202931  [25600/69806]
loss: 0.144594  [32000/69806]
loss: 0.160970  [38400/69806]
loss: 0.163715  [44800/69806]
loss: 0.133290  [51200/69806]
loss: 0.118746  [57600/69806]
loss: 0.226514  [64000/69806]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.197827 

Epoch 45
-------------------------------
loss: 0.191206  [    0/69806]
loss: 0.159206  [ 6400/69806]
loss: 0.225706  [12800/69806]
loss: 0.177100  [19200/69806]
loss: 0.072714  [25600/69806]
loss: 0.162723  [32000/69806]
loss: 0.265345  [38400/69806]
loss: 0.389333  [44800/69806]
loss: 0.254498  [51200/69806]
loss: 0.252147  [57600/69806]
loss: 0.320759  [64000/69806]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.214249 

Epoch 46
-------------------------------
loss: 0.179359  [    0/69806]
loss: 0.150099  [ 6400/69806]
loss: 0.203811  [12800/69806]
loss: 0.118620  [19200/69806]
loss: 0.215288  [25600/69806]
loss: 0.109839  [32000/69806]
loss: 0.202781  [38400/69806]
loss: 0.183783  [44800/69806]
loss: 0.183616  [51200/69806]
loss: 0.259947  [57600/69806]
loss: 0.261353  [64000/69806]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.206392 

Epoch 47
-------------------------------
loss: 0.228289  [    0/69806]
loss: 0.368450  [ 6400/69806]
loss: 0.206149  [12800/69806]
loss: 0.277712  [19200/69806]
loss: 0.128365  [25600/69806]
loss: 0.225356  [32000/69806]
loss: 0.252919  [38400/69806]
loss: 0.126075  [44800/69806]
loss: 0.142691  [51200/69806]
loss: 0.182535  [57600/69806]
loss: 0.166016  [64000/69806]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.203496 

Epoch 48
-------------------------------
loss: 0.139910  [    0/69806]
loss: 0.281643  [ 6400/69806]
loss: 0.402225  [12800/69806]
loss: 0.124784  [19200/69806]
loss: 0.232191  [25600/69806]
loss: 0.137437  [32000/69806]
loss: 0.130114  [38400/69806]
loss: 0.185654  [44800/69806]
loss: 0.122723  [51200/69806]
loss: 0.190371  [57600/69806]
loss: 0.159443  [64000/69806]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.204510 

Epoch 49
-------------------------------
loss: 0.102482  [    0/69806]
loss: 0.075869  [ 6400/69806]
loss: 0.232292  [12800/69806]
loss: 0.219888  [19200/69806]
loss: 0.219441  [25600/69806]
loss: 0.138005  [32000/69806]
loss: 0.178171  [38400/69806]
loss: 0.246524  [44800/69806]
loss: 0.357777  [51200/69806]
loss: 0.217120  [57600/69806]
loss: 0.217926  [64000/69806]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.242879 

Epoch 50
-------------------------------
loss: 0.120924  [    0/69806]
loss: 0.227458  [ 6400/69806]
loss: 0.170473  [12800/69806]
loss: 0.182492  [19200/69806]
loss: 0.090922  [25600/69806]
loss: 0.171491  [32000/69806]
loss: 0.142635  [38400/69806]
loss: 0.212166  [44800/69806]
loss: 0.222363  [51200/69806]
loss: 0.196486  [57600/69806]
loss: 0.284533  [64000/69806]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.222971 

Epoch 1
-------------------------------
loss: 0.658969  [    0/69926]
loss: 0.343604  [ 6400/69926]
loss: 0.389770  [12800/69926]
loss: 0.214977  [19200/69926]
loss: 0.247504  [25600/69926]
loss: 0.150228  [32000/69926]
loss: 0.200011  [38400/69926]
loss: 0.209633  [44800/69926]
loss: 0.276793  [51200/69926]
loss: 0.253663  [57600/69926]
loss: 0.118926  [64000/69926]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.215902 

Epoch 2
-------------------------------
loss: 0.219058  [    0/69926]
loss: 0.216516  [ 6400/69926]
loss: 0.169942  [12800/69926]
loss: 0.273755  [19200/69926]
loss: 0.390503  [25600/69926]
loss: 0.208602  [32000/69926]
loss: 0.276674  [38400/69926]
loss: 0.114817  [44800/69926]
loss: 0.410536  [51200/69926]
loss: 0.193561  [57600/69926]
loss: 0.175829  [64000/69926]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.196037 

Epoch 3
-------------------------------
loss: 0.195729  [    0/69926]
loss: 0.089216  [ 6400/69926]
loss: 0.187075  [12800/69926]
loss: 0.134754  [19200/69926]
loss: 0.160531  [25600/69926]
loss: 1.713065  [32000/69926]
loss: 0.088375  [38400/69926]
loss: 0.251598  [44800/69926]
loss: 0.154186  [51200/69926]
loss: 0.127724  [57600/69926]
loss: 0.241506  [64000/69926]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.183986 

Epoch 4
-------------------------------
loss: 0.229405  [    0/69926]
loss: 0.177606  [ 6400/69926]
loss: 0.295799  [12800/69926]
loss: 0.195248  [19200/69926]
loss: 0.101711  [25600/69926]
loss: 0.234438  [32000/69926]
loss: 0.216569  [38400/69926]
loss: 0.242048  [44800/69926]
loss: 0.191701  [51200/69926]
loss: 0.205481  [57600/69926]
loss: 0.087386  [64000/69926]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.176683 

Epoch 5
-------------------------------
loss: 0.170824  [    0/69926]
loss: 0.122004  [ 6400/69926]
loss: 0.152719  [12800/69926]
loss: 0.190631  [19200/69926]
loss: 0.113608  [25600/69926]
loss: 0.180137  [32000/69926]
loss: 0.159145  [38400/69926]
loss: 0.110172  [44800/69926]
loss: 0.218117  [51200/69926]
loss: 0.176359  [57600/69926]
loss: 0.128136  [64000/69926]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.170737 

Epoch 6
-------------------------------
loss: 0.136268  [    0/69926]
loss: 0.193183  [ 6400/69926]
loss: 0.218192  [12800/69926]
loss: 0.163936  [19200/69926]
loss: 0.106823  [25600/69926]
loss: 0.215561  [32000/69926]
loss: 0.218885  [38400/69926]
loss: 0.182401  [44800/69926]
loss: 0.146379  [51200/69926]
loss: 0.162851  [57600/69926]
loss: 0.127616  [    0/70468]
loss: 0.115861  [ 6400/70468]
loss: 0.130574  [12800/70468]
loss: 0.176264  [19200/70468]
loss: 0.237520  [25600/70468]
loss: 0.128708  [32000/70468]
loss: 0.178530  [38400/70468]
loss: 0.110159  [44800/70468]
loss: 0.218613  [51200/70468]
loss: 0.122210  [57600/70468]
loss: 0.090468  [64000/70468]
loss: 0.187532  [70400/70468]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.151797 

Epoch 4
-------------------------------
loss: 0.115679  [    0/70468]
loss: 0.307584  [ 6400/70468]
loss: 0.141348  [12800/70468]
loss: 0.144828  [19200/70468]
loss: 0.091119  [25600/70468]
loss: 0.103106  [32000/70468]
loss: 0.067505  [38400/70468]
loss: 0.123328  [44800/70468]
loss: 0.090243  [51200/70468]
loss: 0.168996  [57600/70468]
loss: 0.205832  [64000/70468]
loss: 0.159893  [70400/70468]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.207550 

Epoch 5
-------------------------------
loss: 0.213682  [    0/70468]
loss: 0.064742  [ 6400/70468]
loss: 0.192752  [12800/70468]
loss: 0.100138  [19200/70468]
loss: 0.105082  [25600/70468]
loss: 0.097899  [32000/70468]
loss: 0.107600  [38400/70468]
loss: 0.059307  [44800/70468]
loss: 0.049612  [51200/70468]
loss: 0.236888  [57600/70468]
loss: 0.156379  [64000/70468]
loss: 0.167301  [70400/70468]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.138139 

Epoch 6
-------------------------------
loss: 0.128729  [    0/70468]
loss: 0.094931  [ 6400/70468]
loss: 0.169183  [12800/70468]
loss: 0.269736  [19200/70468]
loss: 0.086321  [25600/70468]
loss: 0.073508  [32000/70468]
loss: 0.133235  [38400/70468]
loss: 0.123356  [44800/70468]
loss: 0.251890  [51200/70468]
loss: 0.125305  [57600/70468]
loss: 0.152165  [64000/70468]
loss: 0.141678  [70400/70468]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.127941 

Epoch 7
-------------------------------
loss: 0.087166  [    0/70468]
loss: 0.173668  [ 6400/70468]
loss: 0.198414  [12800/70468]
loss: 0.201351  [19200/70468]
loss: 0.181043  [25600/70468]
loss: 0.173105  [32000/70468]
loss: 0.143342  [38400/70468]
loss: 0.174436  [44800/70468]
loss: 0.124520  [51200/70468]
loss: 0.103447  [57600/70468]
loss: 0.174869  [64000/70468]
loss: 0.227879  [70400/70468]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.132150 

Epoch 8
-------------------------------
loss: 0.134644  [    0/70468]
loss: 0.087276  [ 6400/70468]
loss: 0.113015  [12800/70468]
loss: 0.095266  [19200/70468]
loss: 0.081714  [25600/70468]
loss: 0.070167  [32000/70468]
loss: 0.101917  [38400/70468]
loss: 0.190594  [44800/70468]
loss: 0.162819  [51200/70468]
loss: 0.051651  [57600/70468]
loss: 0.184049  [64000/70468]
loss: 0.262011  [70400/70468]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.141863 

Epoch 9
-------------------------------
loss: 0.113824  [    0/70468]
loss: 0.154614  [ 6400/70468]
loss: 0.107793  [12800/70468]
loss: 0.214852  [19200/70468]
loss: 0.185113  [25600/70468]
loss: 0.107738  [32000/70468]
loss: 0.109072  [38400/70468]
loss: 0.149836  [44800/70468]
loss: 0.090054  [51200/70468]
loss: 0.144090  [57600/70468]
loss: 0.131198  [64000/70468]
loss: 0.173948  [70400/70468]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.153693 

Epoch 10
-------------------------------
loss: 0.123907  [    0/70468]
loss: 0.196359  [ 6400/70468]
loss: 0.160209  [12800/70468]
loss: 0.102136  [19200/70468]
loss: 0.214447  [25600/70468]
loss: 0.179319  [32000/70468]
loss: 0.200142  [38400/70468]
loss: 0.163312  [44800/70468]
loss: 0.126747  [51200/70468]
loss: 0.236790  [57600/70468]
loss: 0.058438  [64000/70468]
loss: 0.067878  [70400/70468]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.127391 

Epoch 11
-------------------------------
loss: 0.119345  [    0/70468]
loss: 0.056634  [ 6400/70468]
loss: 0.178054  [12800/70468]
loss: 0.219878  [19200/70468]
loss: 0.098531  [25600/70468]
loss: 0.136837  [32000/70468]
loss: 0.180773  [38400/70468]
loss: 0.177460  [44800/70468]
loss: 0.129626  [51200/70468]
loss: 0.132690  [57600/70468]
loss: 0.144576  [64000/70468]
loss: 0.167574  [70400/70468]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.147819 

Epoch 12
-------------------------------
loss: 0.140296  [    0/70468]
loss: 0.141449  [ 6400/70468]
loss: 0.131977  [12800/70468]
loss: 0.200041  [19200/70468]
loss: 0.099705  [25600/70468]
loss: 0.099746  [32000/70468]
loss: 0.143338  [38400/70468]
loss: 0.103857  [44800/70468]
loss: 0.116310  [51200/70468]
loss: 0.047605  [57600/70468]
loss: 0.083956  [64000/70468]
loss: 0.149331  [70400/70468]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.133458 

Epoch 13
-------------------------------
loss: 0.167948  [    0/70468]
loss: 0.119665  [ 6400/70468]
loss: 0.321964  [12800/70468]
loss: 0.092413  [19200/70468]
loss: 0.100173  [25600/70468]
loss: 0.080311  [32000/70468]
loss: 0.179099  [38400/70468]
loss: 0.156523  [44800/70468]
loss: 0.130615  [51200/70468]
loss: 0.284281  [57600/70468]
loss: 0.064304  [64000/70468]
loss: 0.158311  [70400/70468]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.132949 

Epoch 14
-------------------------------
loss: 0.150325  [    0/70468]
loss: 0.242667  [ 6400/70468]
loss: 0.087169  [12800/70468]
loss: 0.109690  [19200/70468]
loss: 0.117957  [25600/70468]
loss: 0.082800  [32000/70468]
loss: 0.118349  [38400/70468]
loss: 0.145068  [44800/70468]
loss: 0.082540  [51200/70468]
loss: 0.094579  [57600/70468]
loss: 0.107940  [64000/70468]
loss: 0.058773  [70400/70468]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.188495 

Epoch 15
-------------------------------
loss: 0.330811  [    0/70468]
loss: 0.136851  [ 6400/70468]
loss: 0.144697  [12800/70468]
loss: 0.151438  [19200/70468]
loss: 0.133253  [25600/70468]
loss: 0.147819  [32000/70468]
loss: 0.153027  [38400/70468]
loss: 0.117528  [44800/70468]
loss: 0.117823  [51200/70468]
loss: 0.060115  [57600/70468]
loss: 0.071878  [64000/70468]
loss: 0.145638  [70400/70468]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139074 

Epoch 16
-------------------------------
loss: 0.216062  [    0/70468]
loss: 0.179130  [ 6400/70468]
loss: 0.174173  [12800/70468]
loss: 0.086447  [19200/70468]
loss: 0.083833  [25600/70468]
loss: 0.162977  [32000/70468]
loss: 0.164014  [38400/70468]
loss: 0.243740  [44800/70468]
loss: 0.179463  [51200/70468]
loss: 0.199428  [57600/70468]
loss: 0.102852  [64000/70468]
loss: 0.121831  [70400/70468]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.179917 

Epoch 17
-------------------------------
loss: 0.137701  [    0/70468]
loss: 0.121140  [ 6400/70468]
loss: 0.235570  [12800/70468]
loss: 0.204062  [19200/70468]
loss: 0.077040  [25600/70468]
loss: 0.134805  [32000/70468]
loss: 0.048989  [38400/70468]
loss: 0.118837  [44800/70468]
loss: 0.216782  [51200/70468]
loss: 0.207729  [57600/70468]
loss: 0.172787  [64000/70468]
loss: 0.164424  [70400/70468]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.132211 

Epoch 18
-------------------------------
loss: 0.075127  [    0/70468]
loss: 0.145132  [ 6400/70468]
loss: 0.134990  [12800/70468]
loss: 0.180493  [19200/70468]
loss: 0.098837  [25600/70468]
loss: 0.154407  [32000/70468]
loss: 0.091818  [38400/70468]
loss: 0.131074  [44800/70468]
loss: 0.259545  [51200/70468]
loss: 0.063815  [57600/70468]
loss: 0.122256  [64000/70468]
loss: 0.185645  [70400/70468]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.179617 

Epoch 19
-------------------------------
loss: 0.110535  [    0/70468]
loss: 0.137345  [ 6400/70468]
loss: 0.094311  [12800/70468]
loss: 0.152044  [19200/70468]
loss: 0.161407  [25600/70468]
loss: 0.095056  [32000/70468]
loss: 0.102242  [38400/70468]
loss: 0.134342  [44800/70468]
loss: 0.158264  [51200/70468]
loss: 0.124381  [57600/70468]
loss: 0.122268  [64000/70468]
loss: 0.149271  [70400/70468]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.129349 

Epoch 20
-------------------------------
loss: 0.153689  [    0/70468]
loss: 0.160308  [ 6400/70468]
loss: 0.055760  [12800/70468]
loss: 0.226317  [19200/70468]
loss: 0.220284  [25600/70468]
loss: 0.115489  [32000/70468]
loss: 0.114304  [38400/70468]
loss: 0.192007  [44800/70468]
loss: 0.152487  [51200/70468]
loss: 0.076948  [57600/70468]
loss: 0.107166  [64000/70468]
loss: 0.156008  [70400/70468]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.145030 

Epoch 21
-------------------------------
loss: 0.061044  [    0/70468]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.151091 

Epoch 35
-------------------------------
loss: 0.113559  [    0/71285]
loss: 0.070130  [ 6400/71285]
loss: 0.196122  [12800/71285]
loss: 0.099300  [19200/71285]
loss: 0.170340  [25600/71285]
loss: 0.117733  [32000/71285]
loss: 0.066456  [38400/71285]
loss: 0.181880  [44800/71285]
loss: 0.098816  [51200/71285]
loss: 0.164613  [57600/71285]
loss: 0.074575  [64000/71285]
loss: 0.069036  [70400/71285]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.155310 

Epoch 36
-------------------------------
loss: 0.087940  [    0/71285]
loss: 0.243936  [ 6400/71285]
loss: 0.109289  [12800/71285]
loss: 0.197198  [19200/71285]
loss: 0.126161  [25600/71285]
loss: 0.089557  [32000/71285]
loss: 0.048886  [38400/71285]
loss: 0.061822  [44800/71285]
loss: 0.187113  [51200/71285]
loss: 0.130398  [57600/71285]
loss: 0.143062  [64000/71285]
loss: 0.171479  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.148560 

Epoch 37
-------------------------------
loss: 0.164379  [    0/71285]
loss: 0.121526  [ 6400/71285]
loss: 0.157413  [12800/71285]
loss: 0.069636  [19200/71285]
loss: 0.089223  [25600/71285]
loss: 0.081770  [32000/71285]
loss: 0.112788  [38400/71285]
loss: 0.140805  [44800/71285]
loss: 0.090222  [51200/71285]
loss: 0.152896  [57600/71285]
loss: 0.164545  [64000/71285]
loss: 0.090271  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.154907 

Epoch 38
-------------------------------
loss: 0.054506  [    0/71285]
loss: 0.091505  [ 6400/71285]
loss: 0.162324  [12800/71285]
loss: 0.086111  [19200/71285]
loss: 0.277945  [25600/71285]
loss: 0.131455  [32000/71285]
loss: 0.150857  [38400/71285]
loss: 0.074283  [44800/71285]
loss: 0.115772  [51200/71285]
loss: 0.084251  [57600/71285]
loss: 0.198766  [64000/71285]
loss: 0.152850  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.154808 

Epoch 39
-------------------------------
loss: 0.054009  [    0/71285]
loss: 0.092466  [ 6400/71285]
loss: 0.112398  [12800/71285]
loss: 0.036823  [19200/71285]
loss: 0.119111  [25600/71285]
loss: 0.044174  [32000/71285]
loss: 0.119763  [38400/71285]
loss: 0.116839  [44800/71285]
loss: 0.229899  [51200/71285]
loss: 0.117512  [57600/71285]
loss: 0.241588  [64000/71285]
loss: 0.083862  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.155358 

Epoch 40
-------------------------------
loss: 0.155651  [    0/71285]
loss: 0.167538  [ 6400/71285]
loss: 0.176154  [12800/71285]
loss: 0.045000  [19200/71285]
loss: 0.137472  [25600/71285]
loss: 0.059909  [32000/71285]
loss: 0.183378  [38400/71285]
loss: 0.076496  [44800/71285]
loss: 0.176296  [51200/71285]
loss: 3.257926  [57600/71285]
loss: 0.142858  [64000/71285]
loss: 0.079267  [70400/71285]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.145469 

Epoch 41
-------------------------------
loss: 0.058786  [    0/71285]
loss: 0.072428  [ 6400/71285]
loss: 0.132701  [12800/71285]
loss: 0.119467  [19200/71285]
loss: 0.140739  [25600/71285]
loss: 0.080828  [32000/71285]
loss: 0.073997  [38400/71285]
loss: 0.032226  [44800/71285]
loss: 0.087034  [51200/71285]
loss: 0.082368  [57600/71285]
loss: 0.075640  [64000/71285]
loss: 0.128904  [70400/71285]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.159856 

Epoch 42
-------------------------------
loss: 0.227323  [    0/71285]
loss: 0.274509  [ 6400/71285]
loss: 0.209698  [12800/71285]
loss: 0.109014  [19200/71285]
loss: 0.078120  [25600/71285]
loss: 0.139339  [32000/71285]
loss: 0.223189  [38400/71285]
loss: 0.168280  [44800/71285]
loss: 0.129386  [51200/71285]
loss: 0.050784  [57600/71285]
loss: 0.180070  [64000/71285]
loss: 0.106591  [70400/71285]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.153064 

Epoch 43
-------------------------------
loss: 0.121704  [    0/71285]
loss: 0.074913  [ 6400/71285]
loss: 0.198280  [12800/71285]
loss: 0.164186  [19200/71285]
loss: 0.128988  [25600/71285]
loss: 0.125431  [32000/71285]
loss: 0.213152  [38400/71285]
loss: 0.081849  [44800/71285]
loss: 0.100351  [51200/71285]
loss: 0.118323  [57600/71285]
loss: 1.642340  [64000/71285]
loss: 0.077562  [70400/71285]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.155978 

Epoch 44
-------------------------------
loss: 0.072863  [    0/71285]
loss: 0.065837  [ 6400/71285]
loss: 0.162374  [12800/71285]
loss: 0.193569  [19200/71285]
loss: 0.104205  [25600/71285]
loss: 0.105013  [32000/71285]
loss: 0.073934  [38400/71285]
loss: 0.122847  [44800/71285]
loss: 0.197693  [51200/71285]
loss: 0.121184  [57600/71285]
loss: 0.068934  [64000/71285]
loss: 0.150456  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.150453 

Epoch 45
-------------------------------
loss: 0.160420  [    0/71285]
loss: 0.223868  [ 6400/71285]
loss: 0.135137  [12800/71285]
loss: 0.079195  [19200/71285]
loss: 0.126650  [25600/71285]
loss: 0.107990  [32000/71285]
loss: 0.094955  [38400/71285]
loss: 0.202187  [44800/71285]
loss: 0.183048  [51200/71285]
loss: 0.108194  [57600/71285]
loss: 0.198228  [64000/71285]
loss: 0.255260  [70400/71285]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.149676 

Epoch 46
-------------------------------
loss: 0.171089  [    0/71285]
loss: 0.144763  [ 6400/71285]
loss: 0.187888  [12800/71285]
loss: 0.070748  [19200/71285]
loss: 0.053505  [25600/71285]
loss: 0.088668  [32000/71285]
loss: 0.058046  [38400/71285]
loss: 0.091401  [44800/71285]
loss: 0.123302  [51200/71285]
loss: 0.116417  [57600/71285]
loss: 0.162060  [64000/71285]
loss: 0.071204  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.146038 

Epoch 47
-------------------------------
loss: 0.110921  [    0/71285]
loss: 0.058446  [ 6400/71285]
loss: 0.109332  [12800/71285]
loss: 0.035632  [19200/71285]
loss: 0.038471  [25600/71285]
loss: 0.146774  [32000/71285]
loss: 0.133551  [38400/71285]
loss: 0.158836  [44800/71285]
loss: 0.070752  [51200/71285]
loss: 0.073417  [57600/71285]
loss: 0.095656  [64000/71285]
loss: 0.176469  [70400/71285]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.155198 

Epoch 48
-------------------------------
loss: 0.055741  [    0/71285]
loss: 0.170195  [ 6400/71285]
loss: 0.179286  [12800/71285]
loss: 0.122712  [19200/71285]
loss: 0.201025  [25600/71285]
loss: 0.131390  [32000/71285]
loss: 0.092733  [38400/71285]
loss: 0.073473  [44800/71285]
loss: 0.127694  [51200/71285]
loss: 0.040161  [57600/71285]
loss: 0.174182  [64000/71285]
loss: 0.123974  [70400/71285]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.164924 

Epoch 49
-------------------------------
loss: 0.071079  [    0/71285]
loss: 0.191743  [ 6400/71285]
loss: 0.115298  [12800/71285]
loss: 0.063067  [19200/71285]
loss: 0.095938  [25600/71285]
loss: 0.095191  [32000/71285]
loss: 0.120671  [38400/71285]
loss: 0.122898  [44800/71285]
loss: 0.112149  [51200/71285]
loss: 0.110630  [57600/71285]
loss: 0.192503  [64000/71285]
loss: 0.079545  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.146684 

Epoch 50
-------------------------------
loss: 0.142345  [    0/71285]
loss: 0.063913  [ 6400/71285]
loss: 0.087042  [12800/71285]
loss: 0.075711  [19200/71285]
loss: 0.098463  [25600/71285]
loss: 0.207094  [32000/71285]
loss: 0.186077  [38400/71285]
loss: 0.126420  [44800/71285]
loss: 0.195282  [51200/71285]
loss: 0.120320  [57600/71285]
loss: 0.136635  [64000/71285]
loss: 0.229464  [70400/71285]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.150857 

Epoch 1
-------------------------------
loss: 0.697326  [    0/70723]
loss: 0.271127  [ 6400/70723]
loss: 0.322396  [12800/70723]
loss: 0.310856  [19200/70723]
loss: 0.133224  [25600/70723]
loss: 0.163285  [32000/70723]
loss: 0.158862  [38400/70723]
loss: 0.192871  [44800/70723]
loss: 0.187615  [51200/70723]
loss: 0.227057  [57600/70723]
loss: 0.222562  [64000/70723]
loss: 0.148017  [70400/70723]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.173722 

Epoch 2
-------------------------------
loss: 0.263658  [    0/70723]
loss: 0.253473  [ 6400/70723]
loss: 0.181324  [12800/70723]
loss: 0.124871  [19200/70723]
loss: 0.192390  [25600/70723]
loss: 0.204563  [32000/70723]
loss: 0.074846  [38400/70723]
loss: 0.193149  [44800/70723]
loss: 0.318466  [51200/70723]
loss: 0.195318  [57600/70723]
loss: 0.178288  [64000/70723]
loss: 0.223060  [70400/70723]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.209408 

Epoch 35
-------------------------------
loss: 0.066070  [    0/70872]
loss: 0.131653  [ 6400/70872]
loss: 0.255862  [12800/70872]
loss: 0.256097  [19200/70872]
loss: 0.165132  [25600/70872]
loss: 0.288872  [32000/70872]
loss: 0.230876  [38400/70872]
loss: 0.133337  [44800/70872]
loss: 0.074170  [51200/70872]
loss: 0.145020  [57600/70872]
loss: 0.113246  [64000/70872]
loss: 0.140455  [70400/70872]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.195368 

Epoch 36
-------------------------------
loss: 0.049201  [    0/70872]
loss: 0.104486  [ 6400/70872]
loss: 0.114939  [12800/70872]
loss: 0.140374  [19200/70872]
loss: 0.269959  [25600/70872]
loss: 0.162098  [32000/70872]
loss: 0.221174  [38400/70872]
loss: 0.198053  [44800/70872]
loss: 0.223066  [51200/70872]
loss: 0.112031  [57600/70872]
loss: 0.153136  [64000/70872]
loss: 0.098343  [70400/70872]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.203595 

Epoch 37
-------------------------------
loss: 0.331366  [    0/70872]
loss: 0.045531  [ 6400/70872]
loss: 0.232374  [12800/70872]
loss: 0.316413  [19200/70872]
loss: 0.213268  [25600/70872]
loss: 0.043571  [32000/70872]
loss: 0.208656  [38400/70872]
loss: 0.137009  [44800/70872]
loss: 0.078479  [51200/70872]
loss: 0.123100  [57600/70872]
loss: 0.220654  [64000/70872]
loss: 0.179707  [70400/70872]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.208974 

Epoch 38
-------------------------------
loss: 0.216548  [    0/70872]
loss: 0.036936  [ 6400/70872]
loss: 0.158707  [12800/70872]
loss: 0.045927  [19200/70872]
loss: 0.184092  [25600/70872]
loss: 0.134062  [32000/70872]
loss: 0.228969  [38400/70872]
loss: 0.310657  [44800/70872]
loss: 0.143062  [51200/70872]
loss: 0.166455  [57600/70872]
loss: 0.240135  [64000/70872]
loss: 0.141041  [70400/70872]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.200040 

Epoch 39
-------------------------------
loss: 0.216715  [    0/70872]
loss: 0.175190  [ 6400/70872]
loss: 0.136070  [12800/70872]
loss: 0.136878  [19200/70872]
loss: 0.147785  [25600/70872]
loss: 0.124775  [32000/70872]
loss: 0.077779  [38400/70872]
loss: 0.104051  [44800/70872]
loss: 0.046625  [51200/70872]
loss: 0.123077  [57600/70872]
loss: 0.148726  [64000/70872]
loss: 0.150306  [70400/70872]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.192639 

Epoch 40
-------------------------------
loss: 0.138258  [    0/70872]
loss: 0.144478  [ 6400/70872]
loss: 0.200986  [12800/70872]
loss: 0.245542  [19200/70872]
loss: 0.084824  [25600/70872]
loss: 0.089901  [32000/70872]
loss: 0.167385  [38400/70872]
loss: 0.186709  [44800/70872]
loss: 0.166735  [51200/70872]
loss: 0.142079  [57600/70872]
loss: 0.095085  [64000/70872]
loss: 0.183343  [70400/70872]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.217591 

Epoch 41
-------------------------------
loss: 0.165380  [    0/70872]
loss: 0.114200  [ 6400/70872]
loss: 0.143093  [12800/70872]
loss: 0.282091  [19200/70872]
loss: 0.139375  [25600/70872]
loss: 0.139482  [32000/70872]
loss: 0.089191  [38400/70872]
loss: 0.111642  [44800/70872]
loss: 0.118696  [51200/70872]
loss: 0.086089  [57600/70872]
loss: 0.213191  [64000/70872]
loss: 0.167607  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.195421 

Epoch 42
-------------------------------
loss: 0.138912  [    0/70872]
loss: 0.090758  [ 6400/70872]
loss: 0.136121  [12800/70872]
loss: 0.251589  [19200/70872]
loss: 0.162022  [25600/70872]
loss: 0.101626  [32000/70872]
loss: 0.068950  [38400/70872]
loss: 0.164537  [44800/70872]
loss: 0.223242  [51200/70872]
loss: 0.173580  [57600/70872]
loss: 0.176027  [64000/70872]
loss: 0.096217  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.196649 

Epoch 43
-------------------------------
loss: 0.118223  [    0/70872]
loss: 0.097838  [ 6400/70872]
loss: 0.217761  [12800/70872]
loss: 0.162037  [19200/70872]
loss: 0.062328  [25600/70872]
loss: 0.094935  [32000/70872]
loss: 0.120727  [38400/70872]
loss: 0.214099  [44800/70872]
loss: 0.067182  [51200/70872]
loss: 0.198339  [57600/70872]
loss: 0.082507  [64000/70872]
loss: 0.067820  [70400/70872]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.191740 

Epoch 44
-------------------------------
loss: 0.085910  [    0/70872]
loss: 0.205164  [ 6400/70872]
loss: 0.162988  [12800/70872]
loss: 0.086374  [19200/70872]
loss: 0.310577  [25600/70872]
loss: 0.220192  [32000/70872]
loss: 0.280042  [38400/70872]
loss: 0.129241  [44800/70872]
loss: 0.118272  [51200/70872]
loss: 0.142865  [57600/70872]
loss: 0.396034  [64000/70872]
loss: 0.159061  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.200618 

Epoch 45
-------------------------------
loss: 0.208716  [    0/70872]
loss: 0.120618  [ 6400/70872]
loss: 0.070119  [12800/70872]
loss: 0.081399  [19200/70872]
loss: 0.056172  [25600/70872]
loss: 0.197983  [32000/70872]
loss: 0.121148  [38400/70872]
loss: 0.152109  [44800/70872]
loss: 0.167710  [51200/70872]
loss: 0.184237  [57600/70872]
loss: 0.153021  [64000/70872]
loss: 0.112346  [70400/70872]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.197680 

Epoch 46
-------------------------------
loss: 0.153194  [    0/70872]
loss: 0.185048  [ 6400/70872]
loss: 0.169581  [12800/70872]
loss: 0.139151  [19200/70872]
loss: 0.133246  [25600/70872]
loss: 0.209889  [32000/70872]
loss: 0.127999  [38400/70872]
loss: 0.084833  [44800/70872]
loss: 0.203997  [51200/70872]
loss: 0.304563  [57600/70872]
loss: 0.158239  [64000/70872]
loss: 0.220794  [70400/70872]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.192963 

Epoch 47
-------------------------------
loss: 0.134767  [    0/70872]
loss: 0.189968  [ 6400/70872]
loss: 0.120385  [12800/70872]
loss: 0.149154  [19200/70872]
loss: 0.163914  [25600/70872]
loss: 0.225629  [32000/70872]
loss: 0.183809  [38400/70872]
loss: 0.116716  [44800/70872]
loss: 0.200489  [51200/70872]
loss: 0.165520  [57600/70872]
loss: 0.210068  [64000/70872]
loss: 0.097835  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.192197 

Epoch 48
-------------------------------
loss: 0.109319  [    0/70872]
loss: 0.081464  [ 6400/70872]
loss: 0.220095  [12800/70872]
loss: 0.175627  [19200/70872]
loss: 0.174611  [25600/70872]
loss: 0.198728  [32000/70872]
loss: 0.115841  [38400/70872]
loss: 0.101887  [44800/70872]
loss: 0.096372  [51200/70872]
loss: 0.081112  [57600/70872]
loss: 0.215635  [64000/70872]
loss: 0.134030  [70400/70872]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.230350 

Epoch 49
-------------------------------
loss: 0.148016  [    0/70872]
loss: 0.099537  [ 6400/70872]
loss: 0.051028  [12800/70872]
loss: 0.161505  [19200/70872]
loss: 0.199692  [25600/70872]
loss: 0.165260  [32000/70872]
loss: 0.080648  [38400/70872]
loss: 0.124993  [44800/70872]
loss: 0.083074  [51200/70872]
loss: 0.116277  [57600/70872]
loss: 0.158380  [64000/70872]
loss: 0.111825  [70400/70872]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.192965 

Epoch 50
-------------------------------
loss: 0.174756  [    0/70872]
loss: 0.057609  [ 6400/70872]
loss: 0.048274  [12800/70872]
loss: 0.091518  [19200/70872]
loss: 0.103707  [25600/70872]
loss: 0.184648  [32000/70872]
loss: 0.350445  [38400/70872]
loss: 0.106569  [44800/70872]
loss: 0.045811  [51200/70872]
loss: 0.201625  [57600/70872]
loss: 0.167537  [64000/70872]
loss: 0.338418  [70400/70872]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.175627 

Epoch 1
-------------------------------
loss: 0.689016  [    0/70204]
loss: 0.290831  [ 6400/70204]
loss: 0.116230  [12800/70204]
loss: 0.359722  [19200/70204]
loss: 0.246614  [25600/70204]
loss: 0.222911  [32000/70204]
loss: 0.229149  [38400/70204]
loss: 0.383060  [44800/70204]
loss: 0.293156  [51200/70204]
loss: 0.261494  [57600/70204]
loss: 0.156907  [64000/70204]
Test Error: 
 Accuracy: 90.7%, Avg loss: 0.245212 

Epoch 2
-------------------------------
loss: 0.168805  [    0/70204]
loss: 0.284119  [ 6400/70204]
loss: 0.322025  [12800/70204]
loss: 0.208122  [19200/70204]
loss: 0.224762  [25600/70204]
loss: 0.333985  [32000/70204]
loss: 0.109351  [38400/70204]
loss: 0.191114  [44800/70204]
loss: 0.258699  [51200/70204]
loss: 0.287707  [57600/70204]
loss: 0.342763  [64000/70204]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.216158 

Epoch 3
-------------------------------
loss: 0.232763  [19200/70500]
loss: 0.108641  [25600/70500]
loss: 0.111310  [32000/70500]
loss: 0.238740  [38400/70500]
loss: 0.154864  [44800/70500]
loss: 0.147592  [51200/70500]
loss: 0.104467  [57600/70500]
loss: 0.197435  [64000/70500]
loss: 0.106860  [70400/70500]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.180925 

Epoch 39
-------------------------------
loss: 0.123014  [    0/70500]
loss: 0.141443  [ 6400/70500]
loss: 0.162781  [12800/70500]
loss: 0.101019  [19200/70500]
loss: 0.122124  [25600/70500]
loss: 0.184543  [32000/70500]
loss: 0.114935  [38400/70500]
loss: 0.108321  [44800/70500]
loss: 0.132505  [51200/70500]
loss: 0.099319  [57600/70500]
loss: 0.088750  [64000/70500]
loss: 0.090521  [70400/70500]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.168446 

Epoch 40
-------------------------------
loss: 0.105071  [    0/70500]
loss: 0.115180  [ 6400/70500]
loss: 0.145172  [12800/70500]
loss: 0.189595  [19200/70500]
loss: 0.132735  [25600/70500]
loss: 0.116104  [32000/70500]
loss: 0.129205  [38400/70500]
loss: 0.130762  [44800/70500]
loss: 0.136526  [51200/70500]
loss: 0.111235  [57600/70500]
loss: 0.142188  [64000/70500]
loss: 0.152262  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171819 

Epoch 41
-------------------------------
loss: 0.215330  [    0/70500]
loss: 0.095983  [ 6400/70500]
loss: 0.070674  [12800/70500]
loss: 0.205368  [19200/70500]
loss: 0.055847  [25600/70500]
loss: 0.096246  [32000/70500]
loss: 0.112896  [38400/70500]
loss: 0.121370  [44800/70500]
loss: 0.183382  [51200/70500]
loss: 0.065198  [57600/70500]
loss: 0.089838  [64000/70500]
loss: 0.089667  [70400/70500]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.172530 

Epoch 42
-------------------------------
loss: 0.052705  [    0/70500]
loss: 0.092652  [ 6400/70500]
loss: 0.115695  [12800/70500]
loss: 0.300390  [19200/70500]
loss: 0.203420  [25600/70500]
loss: 0.142067  [32000/70500]
loss: 0.129139  [38400/70500]
loss: 0.085342  [44800/70500]
loss: 0.133663  [51200/70500]
loss: 0.122771  [57600/70500]
loss: 0.590069  [64000/70500]
loss: 0.092121  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.168353 

Epoch 43
-------------------------------
loss: 0.103736  [    0/70500]
loss: 0.082092  [ 6400/70500]
loss: 0.187515  [12800/70500]
loss: 0.127958  [19200/70500]
loss: 0.222487  [25600/70500]
loss: 0.130615  [32000/70500]
loss: 0.089832  [38400/70500]
loss: 0.069949  [44800/70500]
loss: 0.077505  [51200/70500]
loss: 0.089365  [57600/70500]
loss: 0.149179  [64000/70500]
loss: 0.183130  [70400/70500]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.183838 

Epoch 44
-------------------------------
loss: 0.192298  [    0/70500]
loss: 0.080920  [ 6400/70500]
loss: 0.133843  [12800/70500]
loss: 0.158156  [19200/70500]
loss: 1.687074  [25600/70500]
loss: 0.363784  [32000/70500]
loss: 0.159710  [38400/70500]
loss: 0.252617  [44800/70500]
loss: 0.098309  [51200/70500]
loss: 0.120273  [57600/70500]
loss: 0.139598  [64000/70500]
loss: 0.161362  [70400/70500]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.165244 

Epoch 45
-------------------------------
loss: 0.191232  [    0/70500]
loss: 0.095598  [ 6400/70500]
loss: 0.202585  [12800/70500]
loss: 0.135947  [19200/70500]
loss: 0.133211  [25600/70500]
loss: 0.052537  [32000/70500]
loss: 0.216673  [38400/70500]
loss: 0.225801  [44800/70500]
loss: 0.106931  [51200/70500]
loss: 0.238203  [57600/70500]
loss: 0.151133  [64000/70500]
loss: 0.190947  [70400/70500]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.180977 

Epoch 46
-------------------------------
loss: 0.058615  [    0/70500]
loss: 0.110184  [ 6400/70500]
loss: 0.089535  [12800/70500]
loss: 0.141661  [19200/70500]
loss: 0.136338  [25600/70500]
loss: 0.171661  [32000/70500]
loss: 0.134962  [38400/70500]
loss: 0.206176  [44800/70500]
loss: 0.175349  [51200/70500]
loss: 0.148464  [57600/70500]
loss: 0.161200  [64000/70500]
loss: 0.086274  [70400/70500]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.185880 

Epoch 47
-------------------------------
loss: 0.151939  [    0/70500]
loss: 0.179547  [ 6400/70500]
loss: 0.088517  [12800/70500]
loss: 0.127302  [19200/70500]
loss: 0.108656  [25600/70500]
loss: 0.099938  [32000/70500]
loss: 0.068554  [38400/70500]
loss: 0.196461  [44800/70500]
loss: 0.143360  [51200/70500]
loss: 0.191452  [57600/70500]
loss: 0.094550  [64000/70500]
loss: 0.035351  [70400/70500]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.179362 

Epoch 48
-------------------------------
loss: 0.156857  [    0/70500]
loss: 0.136939  [ 6400/70500]
loss: 0.071429  [12800/70500]
loss: 0.131348  [19200/70500]
loss: 0.028572  [25600/70500]
loss: 0.061994  [32000/70500]
loss: 0.126809  [38400/70500]
loss: 0.219646  [44800/70500]
loss: 0.121815  [51200/70500]
loss: 0.198659  [57600/70500]
loss: 0.213934  [64000/70500]
loss: 0.134846  [70400/70500]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.179181 

Epoch 49
-------------------------------
loss: 0.086526  [    0/70500]
loss: 0.141765  [ 6400/70500]
loss: 0.167423  [12800/70500]
loss: 0.131893  [19200/70500]
loss: 0.134564  [25600/70500]
loss: 0.242834  [32000/70500]
loss: 0.162415  [38400/70500]
loss: 0.082544  [44800/70500]
loss: 0.151383  [51200/70500]
loss: 0.116508  [57600/70500]
loss: 0.064235  [64000/70500]
loss: 0.103929  [70400/70500]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.178882 

Epoch 50
-------------------------------
loss: 0.216650  [    0/70500]
loss: 0.064872  [ 6400/70500]
loss: 0.063486  [12800/70500]
loss: 0.089146  [19200/70500]
loss: 0.150069  [25600/70500]
loss: 0.373196  [32000/70500]
loss: 0.170061  [38400/70500]
loss: 0.123059  [44800/70500]
loss: 0.097025  [51200/70500]
loss: 0.170994  [57600/70500]
loss: 0.222696  [64000/70500]
loss: 0.230803  [70400/70500]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173525 

Epoch 1
-------------------------------
loss: 0.649056  [    0/70326]
loss: 0.328168  [ 6400/70326]
loss: 0.201364  [12800/70326]
loss: 0.318517  [19200/70326]
loss: 0.169259  [25600/70326]
loss: 0.237342  [32000/70326]
loss: 0.182320  [38400/70326]
loss: 0.245438  [44800/70326]
loss: 0.148023  [51200/70326]
loss: 0.309962  [57600/70326]
loss: 0.180231  [64000/70326]
Test Error: 
 Accuracy: 90.7%, Avg loss: 0.302819 

Epoch 2
-------------------------------
loss: 0.174040  [    0/70326]
loss: 0.177778  [ 6400/70326]
loss: 0.215044  [12800/70326]
loss: 0.426652  [19200/70326]
loss: 0.201620  [25600/70326]
loss: 0.262924  [32000/70326]
loss: 0.243565  [38400/70326]
loss: 0.220408  [44800/70326]
loss: 0.241108  [51200/70326]
loss: 0.163099  [57600/70326]
loss: 0.187668  [64000/70326]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.206565 

Epoch 3
-------------------------------
loss: 0.224738  [    0/70326]
loss: 0.262965  [ 6400/70326]
loss: 0.243167  [12800/70326]
loss: 0.443338  [19200/70326]
loss: 0.195363  [25600/70326]
loss: 0.225795  [32000/70326]
loss: 0.127400  [38400/70326]
loss: 0.188048  [44800/70326]
loss: 0.297017  [51200/70326]
loss: 0.107884  [57600/70326]
loss: 0.154455  [64000/70326]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.214760 

Epoch 4
-------------------------------
loss: 0.130359  [    0/70326]
loss: 0.206290  [ 6400/70326]
loss: 0.137122  [12800/70326]
loss: 0.119785  [19200/70326]
loss: 0.138031  [25600/70326]
loss: 0.093002  [32000/70326]
loss: 0.229042  [38400/70326]
loss: 0.146081  [44800/70326]
loss: 0.172559  [51200/70326]
loss: 0.177054  [57600/70326]
loss: 0.092200  [64000/70326]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.211091 

Epoch 5
-------------------------------
loss: 0.150429  [    0/70326]
loss: 0.053967  [ 6400/70326]
loss: 0.282104  [12800/70326]
loss: 0.179190  [19200/70326]
loss: 0.131067  [25600/70326]
loss: 0.170683  [32000/70326]
loss: 0.283893  [38400/70326]
loss: 0.226552  [44800/70326]
loss: 0.219974  [51200/70326]
loss: 0.120144  [57600/70326]
loss: 0.194093  [64000/70326]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.207865 

Epoch 6
-------------------------------
loss: 0.147964  [    0/70326]
loss: 0.145461  [ 6400/70326]
loss: 0.238180  [12800/70326]
loss: 0.176451  [19200/70326]
loss: 0.122783  [25600/70326]
loss: 0.088535  [32000/70326]
loss: 0.224066  [38400/70326]
loss: 0.167589  [44800/70326]
loss: 0.051419  [51200/70326]
loss: 0.088206  [64000/71622]
loss: 0.062186  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.133953 

Epoch 50
-------------------------------
loss: 0.033865  [    0/71622]
loss: 0.025050  [ 6400/71622]
loss: 0.033016  [12800/71622]
loss: 0.109823  [19200/71622]
loss: 0.026748  [25600/71622]
loss: 0.013679  [32000/71622]
loss: 0.043499  [38400/71622]
loss: 0.053633  [44800/71622]
loss: 0.086644  [51200/71622]
loss: 0.046128  [57600/71622]
loss: 1.604103  [64000/71622]
loss: 0.065732  [70400/71622]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.136605 

Epoch 1
-------------------------------
loss: 0.664038  [    0/69710]
loss: 0.255902  [ 6400/69710]
loss: 0.232572  [12800/69710]
loss: 0.200449  [19200/69710]
loss: 0.174327  [25600/69710]
loss: 0.205830  [32000/69710]
loss: 0.285668  [38400/69710]
loss: 0.070365  [44800/69710]
loss: 0.126378  [51200/69710]
loss: 0.195514  [57600/69710]
loss: 0.124475  [64000/69710]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.191106 

Epoch 2
-------------------------------
loss: 0.115153  [    0/69710]
loss: 0.154121  [ 6400/69710]
loss: 0.339476  [12800/69710]
loss: 0.156893  [19200/69710]
loss: 0.126779  [25600/69710]
loss: 0.104501  [32000/69710]
loss: 0.258494  [38400/69710]
loss: 0.127760  [44800/69710]
loss: 0.266885  [51200/69710]
loss: 0.218920  [57600/69710]
loss: 0.164497  [64000/69710]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.188070 

Epoch 3
-------------------------------
loss: 0.189644  [    0/69710]
loss: 0.094287  [ 6400/69710]
loss: 0.232306  [12800/69710]
loss: 0.230049  [19200/69710]
loss: 0.267051  [25600/69710]
loss: 0.102029  [32000/69710]
loss: 0.315742  [38400/69710]
loss: 0.177209  [44800/69710]
loss: 0.117845  [51200/69710]
loss: 0.089106  [57600/69710]
loss: 0.222374  [64000/69710]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.162805 

Epoch 4
-------------------------------
loss: 0.129214  [    0/69710]
loss: 0.127197  [ 6400/69710]
loss: 0.140619  [12800/69710]
loss: 0.064443  [19200/69710]
loss: 0.156236  [25600/69710]
loss: 0.109916  [32000/69710]
loss: 0.117938  [38400/69710]
loss: 0.197777  [44800/69710]
loss: 0.181990  [51200/69710]
loss: 0.103493  [57600/69710]
loss: 0.086044  [64000/69710]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.173426 

Epoch 5
-------------------------------
loss: 0.147998  [    0/69710]
loss: 0.151252  [ 6400/69710]
loss: 0.244906  [12800/69710]
loss: 1.635854  [19200/69710]
loss: 0.117298  [25600/69710]
loss: 0.148051  [32000/69710]
loss: 0.156095  [38400/69710]
loss: 0.215662  [44800/69710]
loss: 0.164833  [51200/69710]
loss: 0.054268  [57600/69710]
loss: 0.180048  [64000/69710]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.157538 

Epoch 6
-------------------------------
loss: 0.109844  [    0/69710]
loss: 0.144449  [ 6400/69710]
loss: 0.296903  [12800/69710]
loss: 0.163233  [19200/69710]
loss: 0.115840  [25600/69710]
loss: 0.158613  [32000/69710]
loss: 0.146051  [38400/69710]
loss: 0.181585  [44800/69710]
loss: 0.128456  [51200/69710]
loss: 0.085700  [57600/69710]
loss: 0.156846  [64000/69710]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.142217 

Epoch 7
-------------------------------
loss: 0.147965  [    0/69710]
loss: 0.091746  [ 6400/69710]
loss: 0.241148  [12800/69710]
loss: 0.216906  [19200/69710]
loss: 0.148672  [25600/69710]
loss: 0.154223  [32000/69710]
loss: 0.161948  [38400/69710]
loss: 0.087692  [44800/69710]
loss: 0.148752  [51200/69710]
loss: 0.203541  [57600/69710]
loss: 0.118414  [64000/69710]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.149096 

Epoch 8
-------------------------------
loss: 0.073692  [    0/69710]
loss: 0.100444  [ 6400/69710]
loss: 0.212294  [12800/69710]
loss: 0.112652  [19200/69710]
loss: 0.123990  [25600/69710]
loss: 0.180599  [32000/69710]
loss: 0.094203  [38400/69710]
loss: 0.162325  [44800/69710]
loss: 0.078104  [51200/69710]
loss: 0.242846  [57600/69710]
loss: 0.215383  [64000/69710]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.147691 

Epoch 9
-------------------------------
loss: 0.149021  [    0/69710]
loss: 0.177708  [ 6400/69710]
loss: 0.113646  [12800/69710]
loss: 0.127313  [19200/69710]
loss: 0.116447  [25600/69710]
loss: 0.109565  [32000/69710]
loss: 0.151585  [38400/69710]
loss: 0.195204  [44800/69710]
loss: 0.118834  [51200/69710]
loss: 0.096543  [57600/69710]
loss: 0.102891  [64000/69710]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.151164 

Epoch 10
-------------------------------
loss: 1.664538  [    0/69710]
loss: 0.154414  [ 6400/69710]
loss: 0.101003  [12800/69710]
loss: 0.116615  [19200/69710]
loss: 0.156771  [25600/69710]
loss: 0.087896  [32000/69710]
loss: 0.110757  [38400/69710]
loss: 0.110635  [44800/69710]
loss: 0.100571  [51200/69710]
loss: 0.101229  [57600/69710]
loss: 0.140165  [64000/69710]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.141822 

Epoch 11
-------------------------------
loss: 0.113464  [    0/69710]
loss: 0.198492  [ 6400/69710]
loss: 0.095500  [12800/69710]
loss: 0.098006  [19200/69710]
loss: 0.081218  [25600/69710]
loss: 0.095801  [32000/69710]
loss: 0.143934  [38400/69710]
loss: 0.130122  [44800/69710]
loss: 0.090204  [51200/69710]
loss: 0.084949  [57600/69710]
loss: 0.142269  [64000/69710]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.158452 

Epoch 12
-------------------------------
loss: 0.079437  [    0/69710]
loss: 0.103118  [ 6400/69710]
loss: 0.176885  [12800/69710]
loss: 0.267708  [19200/69710]
loss: 0.037752  [25600/69710]
loss: 0.182251  [32000/69710]
loss: 0.084527  [38400/69710]
loss: 0.104121  [44800/69710]
loss: 0.102059  [51200/69710]
loss: 0.170433  [57600/69710]
loss: 0.074078  [64000/69710]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.141347 

Epoch 13
-------------------------------
loss: 0.091598  [    0/69710]
loss: 0.081959  [ 6400/69710]
loss: 0.136569  [12800/69710]
loss: 0.109368  [19200/69710]
loss: 0.101184  [25600/69710]
loss: 0.342618  [32000/69710]
loss: 0.106607  [38400/69710]
loss: 0.160973  [44800/69710]
loss: 0.181770  [51200/69710]
loss: 0.197531  [57600/69710]
loss: 0.297493  [64000/69710]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.163063 

Epoch 14
-------------------------------
loss: 0.132700  [    0/69710]
loss: 0.129626  [ 6400/69710]
loss: 0.185257  [12800/69710]
loss: 0.312814  [19200/69710]
loss: 0.085241  [25600/69710]
loss: 0.081354  [32000/69710]
loss: 0.080357  [38400/69710]
loss: 0.146262  [44800/69710]
loss: 0.075145  [51200/69710]
loss: 0.083481  [57600/69710]
loss: 0.083929  [64000/69710]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.153675 

Epoch 15
-------------------------------
loss: 0.140360  [    0/69710]
loss: 0.213510  [ 6400/69710]
loss: 0.119691  [12800/69710]
loss: 0.060249  [19200/69710]
loss: 0.140869  [25600/69710]
loss: 0.093906  [32000/69710]
loss: 0.184093  [38400/69710]
loss: 0.135403  [44800/69710]
loss: 0.098747  [51200/69710]
loss: 0.103574  [57600/69710]
loss: 0.065570  [64000/69710]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.152632 

Epoch 16
-------------------------------
loss: 0.081717  [    0/69710]
loss: 0.096373  [ 6400/69710]
loss: 0.133367  [12800/69710]
loss: 0.150339  [19200/69710]
loss: 0.127592  [25600/69710]
loss: 0.190590  [32000/69710]
loss: 0.124190  [38400/69710]
loss: 0.047049  [44800/69710]
loss: 0.184601  [51200/69710]
loss: 0.166431  [57600/69710]
loss: 0.097649  [64000/69710]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.147595 

Epoch 17
-------------------------------
loss: 0.126363  [    0/69710]
loss: 0.056093  [ 6400/69710]
loss: 0.104968  [12800/69710]
loss: 0.208604  [19200/69710]
loss: 0.180213  [25600/69710]
loss: 0.113616  [32000/69710]
loss: 0.122229  [38400/69710]
loss: 0.193276  [44800/69710]
loss: 0.170427  [51200/69710]
loss: 0.100803  [57600/69710]
loss: 0.101743  [64000/69710]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.155518 

Epoch 18
-------------------------------
loss: 0.136263  [    0/69710]
loss: 0.104575  [ 6400/69710]
loss: 0.091342  [12800/69710]
loss: 0.187103  [19200/69710]
loss: 0.080364  [25600/69710]
loss: 0.110103  [32000/69710]
loss: 0.166113  [38400/69710]
loss: 0.145677  [44800/69710]
loss: 0.096548  [51200/69710]
loss: 0.185214  [57600/69710]
loss: 0.096612  [64000/69710]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.134157 

loss: 0.064570  [64000/70935]
loss: 0.198666  [70400/70935]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.168351 

Epoch 50
-------------------------------
loss: 0.050148  [    0/70935]
loss: 0.095781  [ 6400/70935]
loss: 0.152260  [12800/70935]
loss: 0.061470  [19200/70935]
loss: 0.047363  [25600/70935]
loss: 0.123156  [32000/70935]
loss: 0.074357  [38400/70935]
loss: 0.248971  [44800/70935]
loss: 0.175496  [51200/70935]
loss: 0.120186  [57600/70935]
loss: 0.062984  [64000/70935]
loss: 0.219593  [70400/70935]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.156300 

Epoch 1
-------------------------------
loss: 0.633865  [    0/69795]
loss: 0.374267  [ 6400/69795]
loss: 0.353348  [12800/69795]
loss: 0.176214  [19200/69795]
loss: 0.245331  [25600/69795]
loss: 0.332604  [32000/69795]
loss: 0.276103  [38400/69795]
loss: 0.271116  [44800/69795]
loss: 0.251671  [51200/69795]
loss: 0.132872  [57600/69795]
loss: 0.204881  [64000/69795]
Test Error: 
 Accuracy: 89.8%, Avg loss: 0.256335 

Epoch 2
-------------------------------
loss: 0.213909  [    0/69795]
loss: 0.195065  [ 6400/69795]
loss: 0.145043  [12800/69795]
loss: 0.211452  [19200/69795]
loss: 0.251408  [25600/69795]
loss: 0.253782  [32000/69795]
loss: 0.307104  [38400/69795]
loss: 0.166747  [44800/69795]
loss: 0.281515  [51200/69795]
loss: 0.253411  [57600/69795]
loss: 0.139558  [64000/69795]
Test Error: 
 Accuracy: 91.2%, Avg loss: 0.220171 

Epoch 3
-------------------------------
loss: 0.175613  [    0/69795]
loss: 0.239228  [ 6400/69795]
loss: 0.139324  [12800/69795]
loss: 0.283090  [19200/69795]
loss: 0.175652  [25600/69795]
loss: 0.205925  [32000/69795]
loss: 0.241450  [38400/69795]
loss: 0.279877  [44800/69795]
loss: 0.243865  [51200/69795]
loss: 0.154020  [57600/69795]
loss: 0.189828  [64000/69795]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.204479 

Epoch 4
-------------------------------
loss: 0.235672  [    0/69795]
loss: 0.100817  [ 6400/69795]
loss: 0.189310  [12800/69795]
loss: 0.161397  [19200/69795]
loss: 0.234548  [25600/69795]
loss: 0.316334  [32000/69795]
loss: 0.150710  [38400/69795]
loss: 0.176706  [44800/69795]
loss: 0.262516  [51200/69795]
loss: 0.157980  [57600/69795]
loss: 0.171354  [64000/69795]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.220061 

Epoch 5
-------------------------------
loss: 0.243782  [    0/69795]
loss: 0.201250  [ 6400/69795]
loss: 0.155677  [12800/69795]
loss: 0.163220  [19200/69795]
loss: 0.222329  [25600/69795]
loss: 0.286034  [32000/69795]
loss: 0.267689  [38400/69795]
loss: 0.257422  [44800/69795]
loss: 0.221675  [51200/69795]
loss: 0.112404  [57600/69795]
loss: 0.169213  [64000/69795]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.202076 

Epoch 6
-------------------------------
loss: 0.189477  [    0/69795]
loss: 0.317414  [ 6400/69795]
loss: 0.311859  [12800/69795]
loss: 0.271430  [19200/69795]
loss: 0.353511  [25600/69795]
loss: 0.307561  [32000/69795]
loss: 0.205302  [38400/69795]
loss: 0.237283  [44800/69795]
loss: 0.159479  [51200/69795]
loss: 0.264785  [57600/69795]
loss: 0.198587  [64000/69795]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.205976 

Epoch 7
-------------------------------
loss: 0.215117  [    0/69795]
loss: 0.145542  [ 6400/69795]
loss: 0.228128  [12800/69795]
loss: 0.207160  [19200/69795]
loss: 0.194875  [25600/69795]
loss: 0.142012  [32000/69795]
loss: 0.248449  [38400/69795]
loss: 0.214650  [44800/69795]
loss: 0.142852  [51200/69795]
loss: 0.324676  [57600/69795]
loss: 0.246861  [64000/69795]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.206443 

Epoch 8
-------------------------------
loss: 0.214485  [    0/69795]
loss: 0.218812  [ 6400/69795]
loss: 0.219695  [12800/69795]
loss: 0.230796  [19200/69795]
loss: 0.269587  [25600/69795]
loss: 0.164887  [32000/69795]
loss: 0.288870  [38400/69795]
loss: 0.312049  [44800/69795]
loss: 0.154544  [51200/69795]
loss: 0.134205  [57600/69795]
loss: 0.213189  [64000/69795]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.198987 

Epoch 9
-------------------------------
loss: 0.183990  [    0/69795]
loss: 0.093433  [ 6400/69795]
loss: 0.252518  [12800/69795]
loss: 0.186368  [19200/69795]
loss: 0.122813  [25600/69795]
loss: 0.294730  [32000/69795]
loss: 0.196530  [38400/69795]
loss: 0.180686  [44800/69795]
loss: 0.135667  [51200/69795]
loss: 0.244774  [57600/69795]
loss: 0.347056  [64000/69795]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.200217 

Epoch 10
-------------------------------
loss: 0.144881  [    0/69795]
loss: 0.192706  [ 6400/69795]
loss: 0.120973  [12800/69795]
loss: 0.238430  [19200/69795]
loss: 0.151615  [25600/69795]
loss: 0.240331  [32000/69795]
loss: 0.184388  [38400/69795]
loss: 0.265445  [44800/69795]
loss: 0.148170  [51200/69795]
loss: 0.404003  [57600/69795]
loss: 0.100619  [64000/69795]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.187707 

Epoch 11
-------------------------------
loss: 0.170769  [    0/69795]
loss: 0.213100  [ 6400/69795]
loss: 0.232599  [12800/69795]
loss: 0.316091  [19200/69795]
loss: 0.193001  [25600/69795]
loss: 0.207415  [32000/69795]
loss: 0.212292  [38400/69795]
loss: 0.149511  [44800/69795]
loss: 0.183353  [51200/69795]
loss: 0.376410  [57600/69795]
loss: 0.184279  [64000/69795]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.192862 

Epoch 12
-------------------------------
loss: 0.353602  [    0/69795]
loss: 0.158910  [ 6400/69795]
loss: 0.264814  [12800/69795]
loss: 0.189313  [19200/69795]
loss: 0.156942  [25600/69795]
loss: 0.295747  [32000/69795]
loss: 0.194566  [38400/69795]
loss: 0.323376  [44800/69795]
loss: 0.095823  [51200/69795]
loss: 0.314569  [57600/69795]
loss: 0.150191  [64000/69795]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.201602 

Epoch 13
-------------------------------
loss: 0.223697  [    0/69795]
loss: 0.123844  [ 6400/69795]
loss: 0.143586  [12800/69795]
loss: 0.060744  [19200/69795]
loss: 0.117752  [25600/69795]
loss: 0.177303  [32000/69795]
loss: 0.230279  [38400/69795]
loss: 0.128227  [44800/69795]
loss: 0.314617  [51200/69795]
loss: 0.195445  [57600/69795]
loss: 0.154951  [64000/69795]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.188562 

Epoch 14
-------------------------------
loss: 0.176719  [    0/69795]
loss: 0.209916  [ 6400/69795]
loss: 0.193848  [12800/69795]
loss: 1.717467  [19200/69795]
loss: 0.147030  [25600/69795]
loss: 0.152592  [32000/69795]
loss: 0.144435  [38400/69795]
loss: 0.248605  [44800/69795]
loss: 0.171491  [51200/69795]
loss: 0.276763  [57600/69795]
loss: 0.226375  [64000/69795]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.187954 

Epoch 15
-------------------------------
loss: 0.161447  [    0/69795]
loss: 0.113212  [ 6400/69795]
loss: 0.209331  [12800/69795]
loss: 0.132498  [19200/69795]
loss: 0.160942  [25600/69795]
loss: 0.202272  [32000/69795]
loss: 0.231437  [38400/69795]
loss: 0.136029  [44800/69795]
loss: 0.221329  [51200/69795]
loss: 0.269395  [57600/69795]
loss: 0.090512  [64000/69795]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.171787 

Epoch 16
-------------------------------
loss: 0.238235  [    0/69795]
loss: 0.137562  [ 6400/69795]
loss: 0.136640  [12800/69795]
loss: 0.240874  [19200/69795]
loss: 0.182159  [25600/69795]
loss: 0.083147  [32000/69795]
loss: 0.367346  [38400/69795]
loss: 0.127157  [44800/69795]
loss: 0.246708  [51200/69795]
loss: 0.221378  [57600/69795]
loss: 0.262501  [64000/69795]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.186185 

Epoch 17
-------------------------------
loss: 0.165973  [    0/69795]
loss: 0.185596  [ 6400/69795]
loss: 0.105911  [12800/69795]
loss: 0.140035  [19200/69795]
loss: 0.250582  [25600/69795]
loss: 0.183203  [32000/69795]
loss: 0.148943  [38400/69795]
loss: 0.111369  [44800/69795]
loss: 0.168839  [51200/69795]
loss: 0.139130  [57600/69795]
loss: 0.340336  [64000/69795]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.187077 

Epoch 18
-------------------------------
loss: 0.160242  [    0/69795]
loss: 0.125108  [ 6400/69795]
loss: 0.205910  [12800/69795]
loss: 0.174381  [19200/69795]
loss: 0.329799  [25600/69795]
loss: 0.141540  [32000/69795]
loss: 0.195752  [38400/69795]
loss: 0.195259  [44800/69795]
loss: 0.153168  [51200/69795]
loss: 0.254357  [57600/69795]
loss: 0.238730  [64000/69795]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.191945 

loss: 0.155933  [12800/69947]
loss: 0.095199  [19200/69947]
loss: 0.090802  [25600/69947]
loss: 0.177191  [32000/69947]
loss: 0.202059  [38400/69947]
loss: 0.163722  [44800/69947]
loss: 0.188358  [51200/69947]
loss: 0.262159  [57600/69947]
loss: 0.163524  [64000/69947]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.185364 

Epoch 4
-------------------------------
loss: 0.159203  [    0/69947]
loss: 0.154189  [ 6400/69947]
loss: 0.120086  [12800/69947]
loss: 0.058520  [19200/69947]
loss: 0.251535  [25600/69947]
loss: 0.094326  [32000/69947]
loss: 0.256627  [38400/69947]
loss: 0.201727  [44800/69947]
loss: 0.054688  [51200/69947]
loss: 0.055556  [57600/69947]
loss: 0.224915  [64000/69947]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.183773 

Epoch 5
-------------------------------
loss: 0.130809  [    0/69947]
loss: 0.197167  [ 6400/69947]
loss: 0.162161  [12800/69947]
loss: 0.111192  [19200/69947]
loss: 0.209386  [25600/69947]
loss: 0.250871  [32000/69947]
loss: 0.133825  [38400/69947]
loss: 0.217719  [44800/69947]
loss: 0.172688  [51200/69947]
loss: 0.276612  [57600/69947]
loss: 0.134474  [64000/69947]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.179923 

Epoch 6
-------------------------------
loss: 0.185690  [    0/69947]
loss: 0.143276  [ 6400/69947]
loss: 0.096262  [12800/69947]
loss: 0.120079  [19200/69947]
loss: 0.214617  [25600/69947]
loss: 0.203753  [32000/69947]
loss: 0.102881  [38400/69947]
loss: 0.193092  [44800/69947]
loss: 0.124853  [51200/69947]
loss: 0.168727  [57600/69947]
loss: 0.291291  [64000/69947]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.176846 

Epoch 7
-------------------------------
loss: 0.141884  [    0/69947]
loss: 0.339390  [ 6400/69947]
loss: 0.084458  [12800/69947]
loss: 0.160493  [19200/69947]
loss: 0.360990  [25600/69947]
loss: 0.103585  [32000/69947]
loss: 0.102469  [38400/69947]
loss: 0.101925  [44800/69947]
loss: 0.138453  [51200/69947]
loss: 0.240377  [57600/69947]
loss: 0.147972  [64000/69947]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.180297 

Epoch 8
-------------------------------
loss: 0.105827  [    0/69947]
loss: 0.176409  [ 6400/69947]
loss: 0.218675  [12800/69947]
loss: 0.153793  [19200/69947]
loss: 0.226543  [25600/69947]
loss: 0.150008  [32000/69947]
loss: 0.168695  [38400/69947]
loss: 0.112883  [44800/69947]
loss: 0.143866  [51200/69947]
loss: 0.154177  [57600/69947]
loss: 0.203191  [64000/69947]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.171638 

Epoch 9
-------------------------------
loss: 0.158349  [    0/69947]
loss: 0.171667  [ 6400/69947]
loss: 0.289565  [12800/69947]
loss: 0.121787  [19200/69947]
loss: 0.133758  [25600/69947]
loss: 0.120690  [32000/69947]
loss: 0.087710  [38400/69947]
loss: 0.093114  [44800/69947]
loss: 0.120640  [51200/69947]
loss: 0.205544  [57600/69947]
loss: 0.262164  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.174054 

Epoch 10
-------------------------------
loss: 0.133112  [    0/69947]
loss: 0.171128  [ 6400/69947]
loss: 0.119083  [12800/69947]
loss: 0.040658  [19200/69947]
loss: 0.265102  [25600/69947]
loss: 0.083552  [32000/69947]
loss: 0.099317  [38400/69947]
loss: 0.033533  [44800/69947]
loss: 0.119715  [51200/69947]
loss: 0.057329  [57600/69947]
loss: 0.092260  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.171605 

Epoch 11
-------------------------------
loss: 0.230725  [    0/69947]
loss: 0.126269  [ 6400/69947]
loss: 0.053757  [12800/69947]
loss: 0.109788  [19200/69947]
loss: 0.149861  [25600/69947]
loss: 0.150099  [32000/69947]
loss: 0.163700  [38400/69947]
loss: 0.111338  [44800/69947]
loss: 0.165689  [51200/69947]
loss: 0.151457  [57600/69947]
loss: 0.167937  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.168289 

Epoch 12
-------------------------------
loss: 0.126790  [    0/69947]
loss: 0.132661  [ 6400/69947]
loss: 0.142181  [12800/69947]
loss: 0.204289  [19200/69947]
loss: 0.258002  [25600/69947]
loss: 0.162817  [32000/69947]
loss: 0.079180  [38400/69947]
loss: 0.225808  [44800/69947]
loss: 0.158334  [51200/69947]
loss: 0.121224  [57600/69947]
loss: 0.078478  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.172497 

Epoch 13
-------------------------------
loss: 0.091965  [    0/69947]
loss: 0.242068  [ 6400/69947]
loss: 0.124388  [12800/69947]
loss: 0.104668  [19200/69947]
loss: 0.251722  [25600/69947]
loss: 0.322101  [32000/69947]
loss: 0.269875  [38400/69947]
loss: 0.109528  [44800/69947]
loss: 0.182534  [51200/69947]
loss: 0.171053  [57600/69947]
loss: 0.056779  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.179641 

Epoch 14
-------------------------------
loss: 0.061101  [    0/69947]
loss: 0.140619  [ 6400/69947]
loss: 0.174145  [12800/69947]
loss: 0.192264  [19200/69947]
loss: 0.181082  [25600/69947]
loss: 0.187051  [32000/69947]
loss: 0.117723  [38400/69947]
loss: 0.057068  [44800/69947]
loss: 0.124045  [51200/69947]
loss: 0.149402  [57600/69947]
loss: 0.174909  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.172398 

Epoch 15
-------------------------------
loss: 0.209424  [    0/69947]
loss: 0.112769  [ 6400/69947]
loss: 0.251521  [12800/69947]
loss: 0.285328  [19200/69947]
loss: 0.094826  [25600/69947]
loss: 0.138238  [32000/69947]
loss: 0.183939  [38400/69947]
loss: 0.181857  [44800/69947]
loss: 0.244494  [51200/69947]
loss: 0.076998  [57600/69947]
loss: 0.108409  [64000/69947]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.175906 

Epoch 16
-------------------------------
loss: 0.127916  [    0/69947]
loss: 0.175093  [ 6400/69947]
loss: 0.186802  [12800/69947]
loss: 0.049905  [19200/69947]
loss: 0.160333  [25600/69947]
loss: 0.151496  [32000/69947]
loss: 0.151845  [38400/69947]
loss: 1.736871  [44800/69947]
loss: 0.206233  [51200/69947]
loss: 0.167313  [57600/69947]
loss: 0.079061  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.175928 

Epoch 17
-------------------------------
loss: 0.122195  [    0/69947]
loss: 0.076193  [ 6400/69947]
loss: 0.136321  [12800/69947]
loss: 0.176341  [19200/69947]
loss: 0.122732  [25600/69947]
loss: 0.190850  [32000/69947]
loss: 0.104441  [38400/69947]
loss: 0.219018  [44800/69947]
loss: 0.149004  [51200/69947]
loss: 0.060189  [57600/69947]
loss: 0.142846  [64000/69947]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.168589 

Epoch 18
-------------------------------
loss: 0.126276  [    0/69947]
loss: 0.214058  [ 6400/69947]
loss: 0.148579  [12800/69947]
loss: 0.074403  [19200/69947]
loss: 0.198634  [25600/69947]
loss: 0.103258  [32000/69947]
loss: 0.108223  [38400/69947]
loss: 0.172293  [44800/69947]
loss: 0.127755  [51200/69947]
loss: 0.163083  [57600/69947]
loss: 0.135237  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.175567 

Epoch 19
-------------------------------
loss: 0.074790  [    0/69947]
loss: 0.045121  [ 6400/69947]
loss: 0.127690  [12800/69947]
loss: 0.196940  [19200/69947]
loss: 0.068857  [25600/69947]
loss: 0.312774  [32000/69947]
loss: 0.084626  [38400/69947]
loss: 0.036019  [44800/69947]
loss: 0.103006  [51200/69947]
loss: 0.237317  [57600/69947]
loss: 0.069215  [64000/69947]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171577 

Epoch 20
-------------------------------
loss: 0.063145  [    0/69947]
loss: 0.214692  [ 6400/69947]
loss: 0.083534  [12800/69947]
loss: 0.165171  [19200/69947]
loss: 0.222423  [25600/69947]
loss: 0.065906  [32000/69947]
loss: 0.269039  [38400/69947]
loss: 0.101278  [44800/69947]
loss: 0.210378  [51200/69947]
loss: 0.162393  [57600/69947]
loss: 0.054408  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.184486 

Epoch 21
-------------------------------
loss: 0.125172  [    0/69947]
loss: 0.214258  [ 6400/69947]
loss: 0.096113  [12800/69947]
loss: 0.138594  [19200/69947]
loss: 0.168760  [25600/69947]
loss: 0.080921  [32000/69947]
loss: 0.219949  [38400/69947]
loss: 0.182450  [44800/69947]
loss: 0.121224  [51200/69947]
loss: 0.188603  [57600/69947]
loss: 0.154793  [64000/69947]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.183801 

Epoch 22
-------------------------------
loss: 0.170446  [    0/69947]
loss: 0.139336  [ 6400/69947]
loss: 0.155384  [12800/69947]
loss: 0.219126  [19200/69947]
loss: 0.210549  [25600/69947]
loss: 0.091598  [32000/69947]
loss: 0.154036  [38400/69947]
loss: 0.177634  [    0/69168]
loss: 0.295944  [ 6400/69168]
loss: 0.262449  [12800/69168]
loss: 0.354201  [19200/69168]
loss: 0.193331  [25600/69168]
loss: 0.278677  [32000/69168]
loss: 0.194163  [38400/69168]
loss: 0.196084  [44800/69168]
loss: 0.256317  [51200/69168]
loss: 0.166836  [57600/69168]
loss: 0.225025  [64000/69168]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.215013 

Epoch 4
-------------------------------
loss: 0.221773  [    0/69168]
loss: 0.191806  [ 6400/69168]
loss: 0.156082  [12800/69168]
loss: 0.200802  [19200/69168]
loss: 0.299076  [25600/69168]
loss: 0.189141  [32000/69168]
loss: 0.229607  [38400/69168]
loss: 0.298147  [44800/69168]
loss: 0.211315  [51200/69168]
loss: 0.164480  [57600/69168]
loss: 0.218784  [64000/69168]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.207818 

Epoch 5
-------------------------------
loss: 0.192138  [    0/69168]
loss: 0.265892  [ 6400/69168]
loss: 0.259231  [12800/69168]
loss: 0.162607  [19200/69168]
loss: 0.157810  [25600/69168]
loss: 0.313945  [32000/69168]
loss: 0.304507  [38400/69168]
loss: 0.247095  [44800/69168]
loss: 0.311470  [51200/69168]
loss: 0.238980  [57600/69168]
loss: 0.144211  [64000/69168]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.191057 

Epoch 6
-------------------------------
loss: 0.141217  [    0/69168]
loss: 0.286966  [ 6400/69168]
loss: 0.266166  [12800/69168]
loss: 0.171586  [19200/69168]
loss: 0.273547  [25600/69168]
loss: 0.233900  [32000/69168]
loss: 0.144711  [38400/69168]
loss: 0.297975  [44800/69168]
loss: 0.213843  [51200/69168]
loss: 0.171364  [57600/69168]
loss: 0.133625  [64000/69168]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.189835 

Epoch 7
-------------------------------
loss: 0.156385  [    0/69168]
loss: 0.210824  [ 6400/69168]
loss: 0.209866  [12800/69168]
loss: 0.156167  [19200/69168]
loss: 0.271057  [25600/69168]
loss: 0.211443  [32000/69168]
loss: 0.182262  [38400/69168]
loss: 0.140808  [44800/69168]
loss: 0.183433  [51200/69168]
loss: 0.183480  [57600/69168]
loss: 0.095095  [64000/69168]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177528 

Epoch 8
-------------------------------
loss: 0.189803  [    0/69168]
loss: 0.210398  [ 6400/69168]
loss: 0.275539  [12800/69168]
loss: 0.269636  [19200/69168]
loss: 0.150236  [25600/69168]
loss: 0.175508  [32000/69168]
loss: 0.122709  [38400/69168]
loss: 0.277149  [44800/69168]
loss: 0.174804  [51200/69168]
loss: 0.260822  [57600/69168]
loss: 0.079507  [64000/69168]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.184973 

Epoch 9
-------------------------------
loss: 0.147148  [    0/69168]
loss: 0.173209  [ 6400/69168]
loss: 0.176182  [12800/69168]
loss: 0.143433  [19200/69168]
loss: 0.166294  [25600/69168]
loss: 0.237776  [32000/69168]
loss: 0.256272  [38400/69168]
loss: 0.105318  [44800/69168]
loss: 0.277905  [51200/69168]
loss: 0.231793  [57600/69168]
loss: 0.202923  [64000/69168]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.179460 

Epoch 10
-------------------------------
loss: 0.215730  [    0/69168]
loss: 0.152923  [ 6400/69168]
loss: 0.212205  [12800/69168]
loss: 0.292063  [19200/69168]
loss: 0.209558  [25600/69168]
loss: 0.256774  [32000/69168]
loss: 0.164108  [38400/69168]
loss: 0.195826  [44800/69168]
loss: 0.168250  [51200/69168]
loss: 0.293157  [57600/69168]
loss: 0.229528  [64000/69168]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.176162 

Epoch 11
-------------------------------
loss: 0.313768  [    0/69168]
loss: 0.190217  [ 6400/69168]
loss: 0.170131  [12800/69168]
loss: 0.090181  [19200/69168]
loss: 0.361989  [25600/69168]
loss: 0.157017  [32000/69168]
loss: 0.243774  [38400/69168]
loss: 0.223446  [44800/69168]
loss: 0.236741  [51200/69168]
loss: 0.239553  [57600/69168]
loss: 0.158496  [64000/69168]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.196961 

Epoch 12
-------------------------------
loss: 0.277164  [    0/69168]
loss: 0.154171  [ 6400/69168]
loss: 0.167160  [12800/69168]
loss: 0.127915  [19200/69168]
loss: 0.220187  [25600/69168]
loss: 0.262273  [32000/69168]
loss: 0.251692  [38400/69168]
loss: 0.206615  [44800/69168]
loss: 0.284299  [51200/69168]
loss: 0.244904  [57600/69168]
loss: 0.207527  [64000/69168]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.189601 

Epoch 13
-------------------------------
loss: 0.163122  [    0/69168]
loss: 0.196851  [ 6400/69168]
loss: 0.127746  [12800/69168]
loss: 0.222540  [19200/69168]
loss: 0.193543  [25600/69168]
loss: 0.312202  [32000/69168]
loss: 0.140551  [38400/69168]
loss: 0.224603  [44800/69168]
loss: 0.130027  [51200/69168]
loss: 0.388523  [57600/69168]
loss: 0.192583  [64000/69168]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.188569 

Epoch 14
-------------------------------
loss: 0.179506  [    0/69168]
loss: 0.124309  [ 6400/69168]
loss: 0.137940  [12800/69168]
loss: 0.233104  [19200/69168]
loss: 0.173687  [25600/69168]
loss: 0.222650  [32000/69168]
loss: 0.152623  [38400/69168]
loss: 0.092384  [44800/69168]
loss: 0.168524  [51200/69168]
loss: 0.163522  [57600/69168]
loss: 0.225680  [64000/69168]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.200164 

Epoch 15
-------------------------------
loss: 0.132953  [    0/69168]
loss: 0.136538  [ 6400/69168]
loss: 0.124563  [12800/69168]
loss: 0.180760  [19200/69168]
loss: 0.122811  [25600/69168]
loss: 0.239271  [32000/69168]
loss: 0.133410  [38400/69168]
loss: 0.192407  [44800/69168]
loss: 0.345099  [51200/69168]
loss: 0.114989  [57600/69168]
loss: 0.172500  [64000/69168]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.174509 

Epoch 16
-------------------------------
loss: 0.156566  [    0/69168]
loss: 0.163578  [ 6400/69168]
loss: 0.157049  [12800/69168]
loss: 0.241096  [19200/69168]
loss: 0.206633  [25600/69168]
loss: 0.292902  [32000/69168]
loss: 0.213686  [38400/69168]
loss: 0.274259  [44800/69168]
loss: 0.145817  [51200/69168]
loss: 0.216873  [57600/69168]
loss: 0.253317  [64000/69168]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.178390 

Epoch 17
-------------------------------
loss: 0.214163  [    0/69168]
loss: 0.215880  [ 6400/69168]
loss: 0.166931  [12800/69168]
loss: 0.174570  [19200/69168]
loss: 0.222389  [25600/69168]
loss: 0.143765  [32000/69168]
loss: 0.267809  [38400/69168]
loss: 0.260449  [44800/69168]
loss: 0.120272  [51200/69168]
loss: 0.135792  [57600/69168]
loss: 0.172758  [64000/69168]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177479 

Epoch 18
-------------------------------
loss: 0.155206  [    0/69168]
loss: 0.116811  [ 6400/69168]
loss: 0.166094  [12800/69168]
loss: 0.169747  [19200/69168]
loss: 0.176399  [25600/69168]
loss: 0.111397  [32000/69168]
loss: 0.172586  [38400/69168]
loss: 0.174915  [44800/69168]
loss: 0.189951  [51200/69168]
loss: 0.159633  [57600/69168]
loss: 0.208994  [64000/69168]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.182602 

Epoch 19
-------------------------------
loss: 0.198010  [    0/69168]
loss: 0.135091  [ 6400/69168]
loss: 0.212091  [12800/69168]
loss: 0.275959  [19200/69168]
loss: 0.243945  [25600/69168]
loss: 0.148117  [32000/69168]
loss: 0.128579  [38400/69168]
loss: 0.233393  [44800/69168]
loss: 0.202902  [51200/69168]
loss: 0.130253  [57600/69168]
loss: 0.201406  [64000/69168]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.180981 

Epoch 20
-------------------------------
loss: 0.111745  [    0/69168]
loss: 0.190023  [ 6400/69168]
loss: 0.143279  [12800/69168]
loss: 0.114609  [19200/69168]
loss: 0.144240  [25600/69168]
loss: 0.082178  [32000/69168]
loss: 0.211709  [38400/69168]
loss: 0.204703  [44800/69168]
loss: 0.319904  [51200/69168]
loss: 0.184201  [57600/69168]
loss: 0.201603  [64000/69168]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.182035 

Epoch 21
-------------------------------
loss: 0.168279  [    0/69168]
loss: 0.147965  [ 6400/69168]
loss: 0.110287  [12800/69168]
loss: 0.201128  [19200/69168]
loss: 0.090546  [25600/69168]
loss: 0.108869  [32000/69168]
loss: 0.139730  [38400/69168]
loss: 0.112376  [44800/69168]
loss: 0.251913  [51200/69168]
loss: 0.181896  [57600/69168]
loss: 0.212838  [64000/69168]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.190977 

Epoch 22
-------------------------------
loss: 0.168303  [    0/69168]
loss: 0.064525  [ 6400/69168]
loss: 0.132067  [12800/69168]
loss: 0.173779  [19200/69168]
loss: 0.191790  [25600/69168]
loss: 0.097593  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.138354 

Epoch 7
-------------------------------
loss: 0.130182  [    0/70080]
loss: 0.115153  [ 6400/70080]
loss: 0.100456  [12800/70080]
loss: 0.150569  [19200/70080]
loss: 0.071116  [25600/70080]
loss: 0.042325  [32000/70080]
loss: 0.125937  [38400/70080]
loss: 0.176527  [44800/70080]
loss: 0.170283  [51200/70080]
loss: 0.154518  [57600/70080]
loss: 0.082859  [64000/70080]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.134393 

Epoch 8
-------------------------------
loss: 0.152415  [    0/70080]
loss: 0.141213  [ 6400/70080]
loss: 0.156010  [12800/70080]
loss: 0.145178  [19200/70080]
loss: 0.120128  [25600/70080]
loss: 0.109693  [32000/70080]
loss: 0.201665  [38400/70080]
loss: 0.136776  [44800/70080]
loss: 0.133003  [51200/70080]
loss: 0.107504  [57600/70080]
loss: 0.091439  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.139782 

Epoch 9
-------------------------------
loss: 0.129969  [    0/70080]
loss: 0.159304  [ 6400/70080]
loss: 0.192619  [12800/70080]
loss: 0.098550  [19200/70080]
loss: 0.185370  [25600/70080]
loss: 0.205097  [32000/70080]
loss: 0.078480  [38400/70080]
loss: 0.137016  [44800/70080]
loss: 0.155196  [51200/70080]
loss: 0.209169  [57600/70080]
loss: 0.126978  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.145514 

Epoch 10
-------------------------------
loss: 0.046343  [    0/70080]
loss: 0.123218  [ 6400/70080]
loss: 0.165113  [12800/70080]
loss: 0.176470  [19200/70080]
loss: 0.048345  [25600/70080]
loss: 0.112988  [32000/70080]
loss: 0.092446  [38400/70080]
loss: 0.103711  [44800/70080]
loss: 0.072917  [51200/70080]
loss: 0.203101  [57600/70080]
loss: 0.093524  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.137192 

Epoch 11
-------------------------------
loss: 0.102892  [    0/70080]
loss: 0.084337  [ 6400/70080]
loss: 0.165624  [12800/70080]
loss: 0.090437  [19200/70080]
loss: 0.133542  [25600/70080]
loss: 0.089243  [32000/70080]
loss: 0.070814  [38400/70080]
loss: 0.134283  [44800/70080]
loss: 0.148928  [51200/70080]
loss: 0.139389  [57600/70080]
loss: 0.096269  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.139650 

Epoch 12
-------------------------------
loss: 0.039651  [    0/70080]
loss: 0.196056  [ 6400/70080]
loss: 0.111719  [12800/70080]
loss: 0.133593  [19200/70080]
loss: 0.063882  [25600/70080]
loss: 0.072792  [32000/70080]
loss: 0.126312  [38400/70080]
loss: 0.065478  [44800/70080]
loss: 0.173503  [51200/70080]
loss: 0.138468  [57600/70080]
loss: 0.081598  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.141483 

Epoch 13
-------------------------------
loss: 0.058037  [    0/70080]
loss: 0.071332  [ 6400/70080]
loss: 0.123052  [12800/70080]
loss: 0.080983  [19200/70080]
loss: 0.067937  [25600/70080]
loss: 0.102508  [32000/70080]
loss: 0.138247  [38400/70080]
loss: 0.213781  [44800/70080]
loss: 0.133919  [51200/70080]
loss: 0.090694  [57600/70080]
loss: 0.161698  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.135175 

Epoch 14
-------------------------------
loss: 0.079961  [    0/70080]
loss: 0.152008  [ 6400/70080]
loss: 0.099750  [12800/70080]
loss: 0.109527  [19200/70080]
loss: 0.106196  [25600/70080]
loss: 0.107921  [32000/70080]
loss: 0.101627  [38400/70080]
loss: 0.100504  [44800/70080]
loss: 0.043155  [51200/70080]
loss: 0.141507  [57600/70080]
loss: 0.214759  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.135381 

Epoch 15
-------------------------------
loss: 0.110535  [    0/70080]
loss: 0.134957  [ 6400/70080]
loss: 0.102291  [12800/70080]
loss: 0.075941  [19200/70080]
loss: 0.123878  [25600/70080]
loss: 0.082964  [32000/70080]
loss: 0.134486  [38400/70080]
loss: 0.133859  [44800/70080]
loss: 0.177568  [51200/70080]
loss: 0.046621  [57600/70080]
loss: 0.058673  [64000/70080]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.132213 

Epoch 16
-------------------------------
loss: 0.044616  [    0/70080]
loss: 0.181881  [ 6400/70080]
loss: 0.192829  [12800/70080]
loss: 0.269340  [19200/70080]
loss: 0.057443  [25600/70080]
loss: 0.241756  [32000/70080]
loss: 0.226799  [38400/70080]
loss: 0.085121  [44800/70080]
loss: 0.090065  [51200/70080]
loss: 0.207249  [57600/70080]
loss: 0.191117  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.138487 

Epoch 17
-------------------------------
loss: 0.065063  [    0/70080]
loss: 0.095457  [ 6400/70080]
loss: 0.113117  [12800/70080]
loss: 0.100795  [19200/70080]
loss: 0.086791  [25600/70080]
loss: 0.101704  [32000/70080]
loss: 0.131537  [38400/70080]
loss: 0.072031  [44800/70080]
loss: 0.165990  [51200/70080]
loss: 0.064314  [57600/70080]
loss: 0.076454  [64000/70080]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.137726 

Epoch 18
-------------------------------
loss: 0.074170  [    0/70080]
loss: 0.163054  [ 6400/70080]
loss: 0.120202  [12800/70080]
loss: 0.128455  [19200/70080]
loss: 0.080916  [25600/70080]
loss: 0.167895  [32000/70080]
loss: 0.319716  [38400/70080]
loss: 0.088489  [44800/70080]
loss: 0.217048  [51200/70080]
loss: 0.050322  [57600/70080]
loss: 0.438371  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.132614 

Epoch 19
-------------------------------
loss: 0.152968  [    0/70080]
loss: 0.021377  [ 6400/70080]
loss: 0.104520  [12800/70080]
loss: 0.059332  [19200/70080]
loss: 0.097657  [25600/70080]
loss: 0.086060  [32000/70080]
loss: 0.102071  [38400/70080]
loss: 0.277213  [44800/70080]
loss: 0.131661  [51200/70080]
loss: 0.118493  [57600/70080]
loss: 0.064326  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.136643 

Epoch 20
-------------------------------
loss: 0.084597  [    0/70080]
loss: 0.108440  [ 6400/70080]
loss: 0.139134  [12800/70080]
loss: 0.136886  [19200/70080]
loss: 0.176308  [25600/70080]
loss: 0.111448  [32000/70080]
loss: 0.165442  [38400/70080]
loss: 0.087325  [44800/70080]
loss: 0.034309  [51200/70080]
loss: 0.185299  [57600/70080]
loss: 0.072173  [64000/70080]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.133540 

Epoch 21
-------------------------------
loss: 0.115414  [    0/70080]
loss: 0.100791  [ 6400/70080]
loss: 0.176481  [12800/70080]
loss: 0.155705  [19200/70080]
loss: 0.083868  [25600/70080]
loss: 0.061130  [32000/70080]
loss: 0.120101  [38400/70080]
loss: 0.151375  [44800/70080]
loss: 0.089453  [51200/70080]
loss: 0.133344  [57600/70080]
loss: 0.026104  [64000/70080]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.141523 

Epoch 22
-------------------------------
loss: 0.052933  [    0/70080]
loss: 0.058606  [ 6400/70080]
loss: 0.059334  [12800/70080]
loss: 0.178353  [19200/70080]
loss: 0.171539  [25600/70080]
loss: 0.236953  [32000/70080]
loss: 0.121938  [38400/70080]
loss: 0.189771  [44800/70080]
loss: 0.132421  [51200/70080]
loss: 0.084906  [57600/70080]
loss: 0.056526  [64000/70080]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.134311 

Epoch 23
-------------------------------
loss: 0.063798  [    0/70080]
loss: 0.068628  [ 6400/70080]
loss: 0.058219  [12800/70080]
loss: 0.039042  [19200/70080]
loss: 0.050181  [25600/70080]
loss: 0.125320  [32000/70080]
loss: 0.110560  [38400/70080]
loss: 0.157628  [44800/70080]
loss: 0.098617  [51200/70080]
loss: 0.051691  [57600/70080]
loss: 0.113544  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140540 

Epoch 24
-------------------------------
loss: 0.105367  [    0/70080]
loss: 0.097662  [ 6400/70080]
loss: 0.106191  [12800/70080]
loss: 0.099472  [19200/70080]
loss: 0.061781  [25600/70080]
loss: 0.119707  [32000/70080]
loss: 0.133166  [38400/70080]
loss: 0.053592  [44800/70080]
loss: 0.158083  [51200/70080]
loss: 0.250980  [57600/70080]
loss: 0.163590  [64000/70080]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.145834 

Epoch 25
-------------------------------
loss: 0.062673  [    0/70080]
loss: 0.060412  [ 6400/70080]
loss: 0.067909  [12800/70080]
loss: 0.103192  [19200/70080]
loss: 0.330981  [25600/70080]
loss: 0.083713  [32000/70080]
loss: 0.128645  [38400/70080]
loss: 0.118926  [44800/70080]
loss: 0.071316  [51200/70080]
loss: 0.276703  [57600/70080]
loss: 0.043395  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.136890 

Epoch 26
-------------------------------
loss: 0.082507  [    0/70080]
loss: 0.269002  [    0/70414]
loss: 0.232272  [ 6400/70414]
loss: 0.110473  [12800/70414]
loss: 0.141079  [19200/70414]
loss: 0.098409  [25600/70414]
loss: 0.204745  [32000/70414]
loss: 0.205860  [38400/70414]
loss: 0.186154  [44800/70414]
loss: 0.186419  [51200/70414]
loss: 0.197242  [57600/70414]
loss: 0.126633  [64000/70414]
loss: 0.071227  [15400/70414]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.194872 

Epoch 4
-------------------------------
loss: 0.104702  [    0/70414]
loss: 0.079697  [ 6400/70414]
loss: 0.079082  [12800/70414]
loss: 0.265587  [19200/70414]
loss: 0.213014  [25600/70414]
loss: 0.111682  [32000/70414]
loss: 0.239869  [38400/70414]
loss: 0.244771  [44800/70414]
loss: 0.156229  [51200/70414]
loss: 0.180198  [57600/70414]
loss: 0.322278  [64000/70414]
loss: 0.069190  [15400/70414]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.182384 

Epoch 5
-------------------------------
loss: 0.082972  [    0/70414]
loss: 0.165941  [ 6400/70414]
loss: 0.124462  [12800/70414]
loss: 0.136576  [19200/70414]
loss: 0.196248  [25600/70414]
loss: 0.276353  [32000/70414]
loss: 0.103820  [38400/70414]
loss: 0.131674  [44800/70414]
loss: 0.082970  [51200/70414]
loss: 0.141739  [57600/70414]
loss: 0.141968  [64000/70414]
loss: 0.119731  [15400/70414]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.183021 

Epoch 6
-------------------------------
loss: 0.262560  [    0/70414]
loss: 0.270033  [ 6400/70414]
loss: 0.152853  [12800/70414]
loss: 0.261197  [19200/70414]
loss: 0.180625  [25600/70414]
loss: 0.174596  [32000/70414]
loss: 0.166725  [38400/70414]
loss: 0.132290  [44800/70414]
loss: 0.156102  [51200/70414]
loss: 0.088406  [57600/70414]
loss: 0.087485  [64000/70414]
loss: 0.211441  [15400/70414]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.209488 

Epoch 7
-------------------------------
loss: 0.093968  [    0/70414]
loss: 0.125953  [ 6400/70414]
loss: 0.187010  [12800/70414]
loss: 0.083433  [19200/70414]
loss: 0.227931  [25600/70414]
loss: 0.102225  [32000/70414]
loss: 1.734026  [38400/70414]
loss: 0.180023  [44800/70414]
loss: 0.109552  [51200/70414]
loss: 0.117765  [57600/70414]
loss: 0.086721  [64000/70414]
loss: 0.027750  [15400/70414]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.178253 

Epoch 8
-------------------------------
loss: 0.180493  [    0/70414]
loss: 0.087037  [ 6400/70414]
loss: 0.131519  [12800/70414]
loss: 0.112597  [19200/70414]
loss: 0.074488  [25600/70414]
loss: 0.156616  [32000/70414]
loss: 0.088402  [38400/70414]
loss: 0.371443  [44800/70414]
loss: 0.165881  [51200/70414]
loss: 0.161557  [57600/70414]
loss: 0.092415  [64000/70414]
loss: 0.041042  [15400/70414]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.196278 

Epoch 9
-------------------------------
loss: 0.213110  [    0/70414]
loss: 0.260977  [ 6400/70414]
loss: 0.090998  [12800/70414]
loss: 0.131451  [19200/70414]
loss: 0.070361  [25600/70414]
loss: 1.697661  [32000/70414]
loss: 0.243430  [38400/70414]
loss: 0.113107  [44800/70414]
loss: 0.163990  [51200/70414]
loss: 0.158975  [57600/70414]
loss: 0.155596  [64000/70414]
loss: 7.414056  [15400/70414]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.196449 

Epoch 10
-------------------------------
loss: 0.080022  [    0/70414]
loss: 0.131078  [ 6400/70414]
loss: 0.100440  [12800/70414]
loss: 0.146221  [19200/70414]
loss: 0.097778  [25600/70414]
loss: 0.125614  [32000/70414]
loss: 0.143682  [38400/70414]
loss: 0.112441  [44800/70414]
loss: 0.132015  [51200/70414]
loss: 0.079696  [57600/70414]
loss: 0.070085  [64000/70414]
loss: 0.052469  [15400/70414]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.180549 

Epoch 11
-------------------------------
loss: 0.186203  [    0/70414]
loss: 0.060471  [ 6400/70414]
loss: 0.245617  [12800/70414]
loss: 0.180175  [19200/70414]
loss: 0.125600  [25600/70414]
loss: 0.233032  [32000/70414]
loss: 0.113368  [38400/70414]
loss: 0.046765  [44800/70414]
loss: 0.153270  [51200/70414]
loss: 0.128560  [57600/70414]
loss: 0.109256  [64000/70414]
loss: 0.070984  [15400/70414]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.174674 

Epoch 12
-------------------------------
loss: 0.159202  [    0/70414]
loss: 0.123533  [ 6400/70414]
loss: 0.183791  [12800/70414]
loss: 0.165164  [19200/70414]
loss: 0.052288  [25600/70414]
loss: 0.084977  [32000/70414]
loss: 0.175773  [38400/70414]
loss: 0.157464  [44800/70414]
loss: 0.155612  [51200/70414]
loss: 1.695166  [57600/70414]
loss: 0.133656  [64000/70414]
loss: 0.265806  [15400/70414]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.186268 

Epoch 13
-------------------------------
loss: 1.701222  [    0/70414]
loss: 0.227633  [ 6400/70414]
loss: 0.112294  [12800/70414]
loss: 0.136750  [19200/70414]
loss: 0.111619  [25600/70414]
loss: 0.130580  [32000/70414]
loss: 0.197245  [38400/70414]
loss: 1.669655  [44800/70414]
loss: 0.105891  [51200/70414]
loss: 0.081824  [57600/70414]
loss: 0.226577  [64000/70414]
loss: 0.077949  [15400/70414]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.174545 

Epoch 14
-------------------------------
loss: 0.118437  [    0/70414]
loss: 0.070455  [ 6400/70414]
loss: 0.114984  [12800/70414]
loss: 0.059604  [19200/70414]
loss: 0.247867  [25600/70414]
loss: 0.145462  [32000/70414]
loss: 0.125036  [38400/70414]
loss: 0.062234  [44800/70414]
loss: 0.125741  [51200/70414]
loss: 0.343881  [57600/70414]
loss: 0.053607  [64000/70414]
loss: 0.114686  [15400/70414]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.185217 

Epoch 15
-------------------------------
loss: 0.280518  [    0/70414]
loss: 0.202268  [ 6400/70414]
loss: 0.221449  [12800/70414]
loss: 0.110328  [19200/70414]
loss: 0.112688  [25600/70414]
loss: 0.166842  [32000/70414]
loss: 0.213125  [38400/70414]
loss: 0.201806  [44800/70414]
loss: 0.149081  [51200/70414]
loss: 0.068524  [57600/70414]
loss: 0.148568  [64000/70414]
loss: 0.065532  [15400/70414]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.179582 

Epoch 16
-------------------------------
loss: 0.127383  [    0/70414]
loss: 0.128239  [ 6400/70414]
loss: 0.283949  [12800/70414]
loss: 0.120047  [19200/70414]
loss: 0.043435  [25600/70414]
loss: 0.149313  [32000/70414]
loss: 0.128129  [38400/70414]
loss: 0.152549  [44800/70414]
loss: 0.291178  [51200/70414]
loss: 0.080380  [57600/70414]
loss: 0.097234  [64000/70414]
loss: 0.156491  [15400/70414]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.180304 

Epoch 17
-------------------------------
loss: 0.169257  [    0/70414]
loss: 0.214853  [ 6400/70414]
loss: 3.407151  [12800/70414]
loss: 0.136947  [19200/70414]
loss: 0.146736  [25600/70414]
loss: 0.057684  [32000/70414]
loss: 0.094553  [38400/70414]
loss: 0.192614  [44800/70414]
loss: 0.117040  [51200/70414]
loss: 0.122193  [57600/70414]
loss: 0.182286  [64000/70414]
loss: 0.008923  [15400/70414]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.177026 

Epoch 18
-------------------------------
loss: 0.069544  [    0/70414]
loss: 0.091565  [ 6400/70414]
loss: 0.168161  [12800/70414]
loss: 0.261115  [19200/70414]
loss: 0.153133  [25600/70414]
loss: 0.074147  [32000/70414]
loss: 0.144836  [38400/70414]
loss: 0.148024  [44800/70414]
loss: 0.075610  [51200/70414]
loss: 0.288591  [57600/70414]
loss: 0.061157  [64000/70414]
loss: 0.572762  [15400/70414]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.232484 

Epoch 19
-------------------------------
loss: 0.177314  [    0/70414]
loss: 0.071787  [ 6400/70414]
loss: 0.205421  [12800/70414]
loss: 0.250723  [19200/70414]
loss: 0.147094  [25600/70414]
loss: 0.026667  [32000/70414]
loss: 0.064819  [38400/70414]
loss: 1.781372  [44800/70414]
loss: 0.146538  [51200/70414]
loss: 0.194322  [57600/70414]
loss: 1.696553  [64000/70414]
loss: 0.033585  [15400/70414]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.173124 

Epoch 20
-------------------------------
loss: 1.784052  [    0/70414]
loss: 0.087918  [ 6400/70414]
loss: 0.082670  [12800/70414]
loss: 0.141423  [19200/70414]
loss: 0.115025  [25600/70414]
loss: 0.045432  [32000/70414]
loss: 0.142058  [38400/70414]
loss: 0.106400  [44800/70414]
loss: 0.210861  [51200/70414]
loss: 1.646007  [57600/70414]
loss: 0.142882  [64000/70414]
loss: 0.107351  [15400/70414]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.174318 

Epoch 21
-------------------------------
loss: 0.151024  [    0/70414]
loss: 0.200841  [64000/71159]
loss: 0.212988  [70400/71159]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.152322 

Epoch 50
-------------------------------
loss: 0.064867  [    0/71159]
loss: 0.098080  [ 6400/71159]
loss: 0.086469  [12800/71159]
loss: 0.024714  [19200/71159]
loss: 0.099364  [25600/71159]
loss: 0.123117  [32000/71159]
loss: 0.058201  [38400/71159]
loss: 0.159573  [44800/71159]
loss: 0.139153  [51200/71159]
loss: 0.053221  [57600/71159]
loss: 0.228935  [64000/71159]
loss: 0.034942  [70400/71159]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.138724 

Epoch 1
-------------------------------
loss: 0.675584  [    0/70495]
loss: 0.206135  [ 6400/70495]
loss: 0.242551  [12800/70495]
loss: 0.057937  [19200/70495]
loss: 0.180144  [25600/70495]
loss: 0.169817  [32000/70495]
loss: 0.111816  [38400/70495]
loss: 0.107959  [44800/70495]
loss: 0.337165  [51200/70495]
loss: 0.115012  [57600/70495]
loss: 0.174114  [64000/70495]
loss: 0.158944  [70400/70495]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.184608 

Epoch 2
-------------------------------
loss: 0.081269  [    0/70495]
loss: 0.171469  [ 6400/70495]
loss: 0.249861  [12800/70495]
loss: 0.046187  [19200/70495]
loss: 0.105137  [25600/70495]
loss: 0.095540  [32000/70495]
loss: 0.075430  [38400/70495]
loss: 0.093723  [44800/70495]
loss: 0.142857  [51200/70495]
loss: 0.108411  [57600/70495]
loss: 0.140045  [64000/70495]
loss: 0.128381  [70400/70495]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.162185 

Epoch 3
-------------------------------
loss: 0.165301  [    0/70495]
loss: 0.122035  [ 6400/70495]
loss: 0.099999  [12800/70495]
loss: 0.112657  [19200/70495]
loss: 0.129337  [25600/70495]
loss: 0.142612  [32000/70495]
loss: 0.057389  [38400/70495]
loss: 0.087129  [44800/70495]
loss: 0.087478  [51200/70495]
loss: 0.174935  [57600/70495]
loss: 0.132517  [64000/70495]
loss: 0.185635  [70400/70495]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.154003 

Epoch 4
-------------------------------
loss: 0.113692  [    0/70495]
loss: 0.130543  [ 6400/70495]
loss: 0.111619  [12800/70495]
loss: 0.104936  [19200/70495]
loss: 0.117957  [25600/70495]
loss: 0.040966  [32000/70495]
loss: 0.093276  [38400/70495]
loss: 0.103547  [44800/70495]
loss: 0.106234  [51200/70495]
loss: 0.097247  [57600/70495]
loss: 0.092340  [64000/70495]
loss: 0.179745  [70400/70495]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.148919 

Epoch 5
-------------------------------
loss: 0.059423  [    0/70495]
loss: 0.160253  [ 6400/70495]
loss: 0.031516  [12800/70495]
loss: 0.143514  [19200/70495]
loss: 0.137292  [25600/70495]
loss: 0.123542  [32000/70495]
loss: 0.158871  [38400/70495]
loss: 0.083218  [44800/70495]
loss: 0.081681  [51200/70495]
loss: 0.097519  [57600/70495]
loss: 0.041342  [64000/70495]
loss: 0.108615  [70400/70495]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.146736 

Epoch 6
-------------------------------
loss: 0.059082  [    0/70495]
loss: 0.120721  [ 6400/70495]
loss: 0.209447  [12800/70495]
loss: 0.076728  [19200/70495]
loss: 0.097068  [25600/70495]
loss: 0.234123  [32000/70495]
loss: 0.073351  [38400/70495]
loss: 0.131714  [44800/70495]
loss: 0.062454  [51200/70495]
loss: 0.111992  [57600/70495]
loss: 0.075110  [64000/70495]
loss: 0.046459  [70400/70495]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.140082 

Epoch 7
-------------------------------
loss: 0.083074  [    0/70495]
loss: 0.144136  [ 6400/70495]
loss: 0.124033  [12800/70495]
loss: 0.230593  [19200/70495]
loss: 0.162635  [25600/70495]
loss: 0.151522  [32000/70495]
loss: 0.088041  [38400/70495]
loss: 0.068295  [44800/70495]
loss: 0.175587  [51200/70495]
loss: 0.129261  [57600/70495]
loss: 0.092590  [64000/70495]
loss: 0.102425  [70400/70495]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.141238 

Epoch 8
-------------------------------
loss: 0.085100  [    0/70495]
loss: 0.027921  [ 6400/70495]
loss: 0.070943  [12800/70495]
loss: 0.034260  [19200/70495]
loss: 0.173209  [25600/70495]
loss: 0.081559  [32000/70495]
loss: 0.111846  [38400/70495]
loss: 0.052878  [44800/70495]
loss: 0.110701  [51200/70495]
loss: 0.150504  [57600/70495]
loss: 0.047257  [64000/70495]
loss: 0.106167  [70400/70495]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.137822 

Epoch 9
-------------------------------
loss: 0.066092  [    0/70495]
loss: 0.117790  [ 6400/70495]
loss: 0.059280  [12800/70495]
loss: 0.159200  [19200/70495]
loss: 0.118668  [25600/70495]
loss: 0.092832  [32000/70495]
loss: 0.134417  [38400/70495]
loss: 0.074539  [44800/70495]
loss: 0.099118  [51200/70495]
loss: 0.128082  [57600/70495]
loss: 0.102943  [64000/70495]
loss: 0.075563  [70400/70495]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.138171 

Epoch 10
-------------------------------
loss: 0.120591  [    0/70495]
loss: 0.196665  [ 6400/70495]
loss: 0.076129  [12800/70495]
loss: 0.069608  [19200/70495]
loss: 0.156230  [25600/70495]
loss: 0.126605  [32000/70495]
loss: 0.125627  [38400/70495]
loss: 0.018616  [44800/70495]
loss: 0.061613  [51200/70495]
loss: 0.102415  [57600/70495]
loss: 0.112048  [64000/70495]
loss: 0.047363  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.133698 

Epoch 11
-------------------------------
loss: 0.096688  [    0/70495]
loss: 0.125759  [ 6400/70495]
loss: 0.101585  [12800/70495]
loss: 0.117604  [19200/70495]
loss: 0.100851  [25600/70495]
loss: 0.080290  [32000/70495]
loss: 0.039753  [38400/70495]
loss: 0.131708  [44800/70495]
loss: 0.049320  [51200/70495]
loss: 0.095604  [57600/70495]
loss: 0.116890  [64000/70495]
loss: 0.076140  [70400/70495]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.145753 

Epoch 12
-------------------------------
loss: 0.044021  [    0/70495]
loss: 0.073736  [ 6400/70495]
loss: 0.043217  [12800/70495]
loss: 0.045156  [19200/70495]
loss: 0.041717  [25600/70495]
loss: 0.093845  [32000/70495]
loss: 0.078433  [38400/70495]
loss: 0.212536  [44800/70495]
loss: 0.045561  [51200/70495]
loss: 0.127418  [57600/70495]
loss: 0.271243  [64000/70495]
loss: 0.179723  [70400/70495]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.136625 

Epoch 13
-------------------------------
loss: 0.158880  [    0/70495]
loss: 0.127438  [ 6400/70495]
loss: 0.076781  [12800/70495]
loss: 0.063106  [19200/70495]
loss: 0.048893  [25600/70495]
loss: 0.044028  [32000/70495]
loss: 0.094396  [38400/70495]
loss: 0.088309  [44800/70495]
loss: 0.164513  [51200/70495]
loss: 0.202205  [57600/70495]
loss: 0.094190  [64000/70495]
loss: 0.073890  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.136885 

Epoch 14
-------------------------------
loss: 0.051724  [    0/70495]
loss: 0.045406  [ 6400/70495]
loss: 0.064379  [12800/70495]
loss: 0.187843  [19200/70495]
loss: 0.082167  [25600/70495]
loss: 0.048395  [32000/70495]
loss: 0.184343  [38400/70495]
loss: 0.153439  [44800/70495]
loss: 0.072505  [51200/70495]
loss: 0.060933  [57600/70495]
loss: 0.198881  [64000/70495]
loss: 0.059394  [70400/70495]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.137204 

Epoch 15
-------------------------------
loss: 0.125491  [    0/70495]
loss: 0.052532  [ 6400/70495]
loss: 0.044437  [12800/70495]
loss: 0.039274  [19200/70495]
loss: 0.207549  [25600/70495]
loss: 0.068852  [32000/70495]
loss: 0.105614  [38400/70495]
loss: 0.178336  [44800/70495]
loss: 0.108976  [51200/70495]
loss: 0.189862  [57600/70495]
loss: 0.073666  [64000/70495]
loss: 0.080975  [70400/70495]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.150746 

Epoch 16
-------------------------------
loss: 0.076205  [    0/70495]
loss: 0.043184  [ 6400/70495]
loss: 0.017333  [12800/70495]
loss: 0.044074  [19200/70495]
loss: 0.080610  [25600/70495]
loss: 0.082698  [32000/70495]
loss: 0.219162  [38400/70495]
loss: 0.094780  [44800/70495]
loss: 0.061333  [51200/70495]
loss: 0.202436  [57600/70495]
loss: 0.131876  [64000/70495]
loss: 0.112074  [70400/70495]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.150711 

Epoch 17
-------------------------------
loss: 0.179073  [    0/70495]
loss: 0.022033  [ 6400/70495]
loss: 0.126917  [12800/70495]
loss: 0.066139  [19200/70495]
loss: 0.106387  [25600/70495]
loss: 0.071499  [32000/70495]
loss: 0.080469  [38400/70495]
loss: 0.070413  [44800/70495]
loss: 0.101140  [51200/70495]
loss: 0.261630  [57600/70495]
loss: 0.094197  [64000/70495]
loss: 0.129523  [64000/70696]
loss: 0.309221  [70400/70696]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.178553 

Epoch 50
-------------------------------
loss: 0.124126  [    0/70696]
loss: 0.203499  [ 6400/70696]
loss: 0.192068  [12800/70696]
loss: 0.242987  [19200/70696]
loss: 0.231455  [25600/70696]
loss: 0.088730  [32000/70696]
loss: 0.107039  [38400/70696]
loss: 0.158224  [44800/70696]
loss: 0.169786  [51200/70696]
loss: 0.162517  [57600/70696]
loss: 0.144254  [64000/70696]
loss: 0.089893  [70400/70696]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.179035 

Epoch 1
-------------------------------
loss: 0.686449  [    0/69728]
loss: 0.374716  [ 6400/69728]
loss: 0.276383  [12800/69728]
loss: 0.328466  [19200/69728]
loss: 0.266990  [25600/69728]
loss: 0.311341  [32000/69728]
loss: 0.215438  [38400/69728]
loss: 0.191978  [44800/69728]
loss: 0.163487  [51200/69728]
loss: 0.147236  [57600/69728]
loss: 0.323716  [64000/69728]
Test Error: 
 Accuracy: 90.4%, Avg loss: 0.269789 

Epoch 2
-------------------------------
loss: 0.220704  [    0/69728]
loss: 0.239734  [ 6400/69728]
loss: 0.141470  [12800/69728]
loss: 0.367960  [19200/69728]
loss: 0.225993  [25600/69728]
loss: 0.152727  [32000/69728]
loss: 0.291903  [38400/69728]
loss: 0.321456  [44800/69728]
loss: 0.210099  [51200/69728]
loss: 0.207289  [57600/69728]
loss: 0.280846  [64000/69728]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.250637 

Epoch 3
-------------------------------
loss: 0.229300  [    0/69728]
loss: 0.093948  [ 6400/69728]
loss: 0.195323  [12800/69728]
loss: 0.279511  [19200/69728]
loss: 0.262529  [25600/69728]
loss: 0.263905  [32000/69728]
loss: 0.230864  [38400/69728]
loss: 0.114417  [44800/69728]
loss: 0.186752  [51200/69728]
loss: 0.374944  [57600/69728]
loss: 0.238882  [64000/69728]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.246883 

Epoch 4
-------------------------------
loss: 0.135348  [    0/69728]
loss: 0.454719  [ 6400/69728]
loss: 0.131388  [12800/69728]
loss: 0.128373  [19200/69728]
loss: 0.271991  [25600/69728]
loss: 0.246605  [32000/69728]
loss: 0.293434  [38400/69728]
loss: 0.185064  [44800/69728]
loss: 0.236222  [51200/69728]
loss: 1.897859  [57600/69728]
loss: 0.162668  [64000/69728]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.235005 

Epoch 5
-------------------------------
loss: 0.190450  [    0/69728]
loss: 0.255300  [ 6400/69728]
loss: 1.695503  [12800/69728]
loss: 0.320955  [19200/69728]
loss: 0.196295  [25600/69728]
loss: 0.173506  [32000/69728]
loss: 0.207540  [38400/69728]
loss: 1.776270  [44800/69728]
loss: 0.115371  [51200/69728]
loss: 0.177571  [57600/69728]
loss: 0.299254  [64000/69728]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.235951 

Epoch 6
-------------------------------
loss: 0.189822  [    0/69728]
loss: 0.288678  [ 6400/69728]
loss: 0.206540  [12800/69728]
loss: 0.145375  [19200/69728]
loss: 0.083215  [25600/69728]
loss: 0.135652  [32000/69728]
loss: 0.132976  [38400/69728]
loss: 0.152039  [44800/69728]
loss: 0.262556  [51200/69728]
loss: 0.187864  [57600/69728]
loss: 0.300423  [64000/69728]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.233009 

Epoch 7
-------------------------------
loss: 0.164609  [    0/69728]
loss: 0.185852  [ 6400/69728]
loss: 0.139942  [12800/69728]
loss: 0.157232  [19200/69728]
loss: 0.198717  [25600/69728]
loss: 0.473295  [32000/69728]
loss: 0.210157  [38400/69728]
loss: 0.077233  [44800/69728]
loss: 0.153135  [51200/69728]
loss: 0.122774  [57600/69728]
loss: 0.197472  [64000/69728]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.236435 

Epoch 8
-------------------------------
loss: 0.105782  [    0/69728]
loss: 0.265510  [ 6400/69728]
loss: 0.120637  [12800/69728]
loss: 0.146007  [19200/69728]
loss: 0.182033  [25600/69728]
loss: 0.194772  [32000/69728]
loss: 0.148883  [38400/69728]
loss: 0.201569  [44800/69728]
loss: 0.205483  [51200/69728]
loss: 0.232537  [57600/69728]
loss: 0.217191  [64000/69728]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.237358 

Epoch 9
-------------------------------
loss: 0.098985  [    0/69728]
loss: 0.178857  [ 6400/69728]
loss: 0.131462  [12800/69728]
loss: 0.237669  [19200/69728]
loss: 0.195068  [25600/69728]
loss: 0.230733  [32000/69728]
loss: 0.251850  [38400/69728]
loss: 0.094180  [44800/69728]
loss: 0.176939  [51200/69728]
loss: 0.196998  [57600/69728]
loss: 0.133902  [64000/69728]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.227387 

Epoch 10
-------------------------------
loss: 0.106079  [    0/69728]
loss: 0.184208  [ 6400/69728]
loss: 0.120310  [12800/69728]
loss: 0.159851  [19200/69728]
loss: 0.141291  [25600/69728]
loss: 0.089117  [32000/69728]
loss: 0.134971  [38400/69728]
loss: 0.102451  [44800/69728]
loss: 0.132258  [51200/69728]
loss: 0.145910  [57600/69728]
loss: 0.396237  [64000/69728]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.219592 

Epoch 11
-------------------------------
loss: 0.217833  [    0/69728]
loss: 0.098216  [ 6400/69728]
loss: 0.255756  [12800/69728]
loss: 0.129378  [19200/69728]
loss: 0.127586  [25600/69728]
loss: 0.152982  [32000/69728]
loss: 0.117785  [38400/69728]
loss: 0.213307  [44800/69728]
loss: 0.196726  [51200/69728]
loss: 0.136701  [57600/69728]
loss: 0.159019  [64000/69728]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.226369 

Epoch 12
-------------------------------
loss: 0.152493  [    0/69728]
loss: 0.168005  [ 6400/69728]
loss: 0.181423  [12800/69728]
loss: 0.198881  [19200/69728]
loss: 0.211938  [25600/69728]
loss: 0.144303  [32000/69728]
loss: 0.137009  [38400/69728]
loss: 0.283449  [44800/69728]
loss: 0.141617  [51200/69728]
loss: 0.226748  [57600/69728]
loss: 0.162979  [64000/69728]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.216489 

Epoch 13
-------------------------------
loss: 0.153180  [    0/69728]
loss: 0.161638  [ 6400/69728]
loss: 0.090215  [12800/69728]
loss: 0.162589  [19200/69728]
loss: 0.190253  [25600/69728]
loss: 0.200452  [32000/69728]
loss: 0.175927  [38400/69728]
loss: 0.230893  [44800/69728]
loss: 0.144165  [51200/69728]
loss: 0.080552  [57600/69728]
loss: 0.153387  [64000/69728]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.221112 

Epoch 14
-------------------------------
loss: 0.142015  [    0/69728]
loss: 0.104673  [ 6400/69728]
loss: 0.265398  [12800/69728]
loss: 0.178505  [19200/69728]
loss: 0.128837  [25600/69728]
loss: 0.164898  [32000/69728]
loss: 0.170720  [38400/69728]
loss: 0.124625  [44800/69728]
loss: 0.156105  [51200/69728]
loss: 0.235143  [57600/69728]
loss: 0.237949  [64000/69728]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.207188 

Epoch 15
-------------------------------
loss: 0.064035  [    0/69728]
loss: 0.151680  [ 6400/69728]
loss: 0.226644  [12800/69728]
loss: 0.201380  [19200/69728]
loss: 0.454199  [25600/69728]
loss: 0.202213  [32000/69728]
loss: 0.132613  [38400/69728]
loss: 0.328331  [44800/69728]
loss: 0.156338  [51200/69728]
loss: 0.142593  [57600/69728]
loss: 0.156865  [64000/69728]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.234768 

Epoch 16
-------------------------------
loss: 0.194820  [    0/69728]
loss: 0.116821  [ 6400/69728]
loss: 0.126663  [12800/69728]
loss: 0.124842  [19200/69728]
loss: 0.260830  [25600/69728]
loss: 0.156019  [32000/69728]
loss: 0.142010  [38400/69728]
loss: 0.137309  [44800/69728]
loss: 0.179851  [51200/69728]
loss: 0.182897  [57600/69728]
loss: 0.183388  [64000/69728]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.203429 

Epoch 17
-------------------------------
loss: 0.111414  [    0/69728]
loss: 0.179099  [ 6400/69728]
loss: 0.250989  [12800/69728]
loss: 0.205371  [19200/69728]
loss: 0.180755  [25600/69728]
loss: 0.076578  [32000/69728]
loss: 0.244312  [38400/69728]
loss: 0.134133  [44800/69728]
loss: 0.168095  [51200/69728]
loss: 0.200038  [57600/69728]
loss: 0.233202  [64000/69728]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.211481 

Epoch 18
-------------------------------
loss: 0.120949  [    0/69728]
loss: 0.186098  [ 6400/69728]
loss: 0.120826  [12800/69728]
loss: 0.196127  [19200/69728]
loss: 0.084621  [25600/69728]
loss: 0.210738  [32000/69728]
loss: 0.125548  [38400/69728]
loss: 0.065605  [44800/69728]
loss: 0.288828  [51200/69728]
loss: 0.112109  [57600/69728]
loss: 0.139080  [64000/69728]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.202687 

loss: 0.144586  [    0/69810]
loss: 0.294611  [ 6400/69810]
loss: 0.300794  [12800/69810]
loss: 0.110729  [19200/69810]
loss: 0.146956  [25600/69810]
loss: 0.162900  [32000/69810]
loss: 0.046188  [38400/69810]
loss: 0.194306  [44800/69810]
loss: 0.108858  [51200/69810]
loss: 0.094829  [57600/69810]
loss: 0.048551  [64000/69810]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.164835 

Epoch 4
-------------------------------
loss: 0.147184  [    0/69810]
loss: 0.099882  [ 6400/69810]
loss: 0.159160  [12800/69810]
loss: 0.182037  [19200/69810]
loss: 0.081112  [25600/69810]
loss: 0.244527  [32000/69810]
loss: 0.078686  [38400/69810]
loss: 0.237727  [44800/69810]
loss: 0.174468  [51200/69810]
loss: 0.096338  [57600/69810]
loss: 0.140372  [64000/69810]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.153830 

Epoch 5
-------------------------------
loss: 0.119633  [    0/69810]
loss: 0.194121  [ 6400/69810]
loss: 0.194814  [12800/69810]
loss: 0.079418  [19200/69810]
loss: 0.114417  [25600/69810]
loss: 0.175689  [32000/69810]
loss: 0.093175  [38400/69810]
loss: 0.033810  [44800/69810]
loss: 0.062972  [51200/69810]
loss: 0.112152  [57600/69810]
loss: 0.065639  [64000/69810]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.151563 

Epoch 6
-------------------------------
loss: 0.074126  [    0/69810]
loss: 0.163452  [ 6400/69810]
loss: 0.159599  [12800/69810]
loss: 0.121226  [19200/69810]
loss: 0.193959  [25600/69810]
loss: 0.184523  [32000/69810]
loss: 0.067876  [38400/69810]
loss: 0.131728  [44800/69810]
loss: 0.059520  [51200/69810]
loss: 0.137568  [57600/69810]
loss: 0.150610  [64000/69810]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.143172 

Epoch 7
-------------------------------
loss: 0.192090  [    0/69810]
loss: 0.104116  [ 6400/69810]
loss: 1.617577  [12800/69810]
loss: 0.143122  [19200/69810]
loss: 0.121655  [25600/69810]
loss: 0.124699  [32000/69810]
loss: 0.216222  [38400/69810]
loss: 0.130508  [44800/69810]
loss: 0.299181  [51200/69810]
loss: 0.139879  [57600/69810]
loss: 0.151146  [64000/69810]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.144023 

Epoch 8
-------------------------------
loss: 0.135560  [    0/69810]
loss: 0.098244  [ 6400/69810]
loss: 0.207023  [12800/69810]
loss: 0.194987  [19200/69810]
loss: 0.101973  [25600/69810]
loss: 0.170201  [32000/69810]
loss: 0.272240  [38400/69810]
loss: 0.106075  [44800/69810]
loss: 0.128090  [51200/69810]
loss: 0.134581  [57600/69810]
loss: 0.158427  [64000/69810]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.148308 

Epoch 9
-------------------------------
loss: 0.160850  [    0/69810]
loss: 0.148404  [ 6400/69810]
loss: 0.056433  [12800/69810]
loss: 0.122767  [19200/69810]
loss: 0.051887  [25600/69810]
loss: 0.101668  [32000/69810]
loss: 0.142375  [38400/69810]
loss: 0.167966  [44800/69810]
loss: 0.104464  [51200/69810]
loss: 1.815333  [57600/69810]
loss: 0.108572  [64000/69810]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.141960 

Epoch 10
-------------------------------
loss: 0.098034  [    0/69810]
loss: 0.049035  [ 6400/69810]
loss: 0.078502  [12800/69810]
loss: 0.047410  [19200/69810]
loss: 0.095381  [25600/69810]
loss: 0.255760  [32000/69810]
loss: 0.066324  [38400/69810]
loss: 0.067008  [44800/69810]
loss: 0.047166  [51200/69810]
loss: 0.078537  [57600/69810]
loss: 0.142030  [64000/69810]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.138229 

Epoch 11
-------------------------------
loss: 0.110173  [    0/69810]
loss: 0.141681  [ 6400/69810]
loss: 0.114729  [12800/69810]
loss: 0.052695  [19200/69810]
loss: 0.050966  [25600/69810]
loss: 0.118036  [32000/69810]
loss: 0.075033  [38400/69810]
loss: 0.138625  [44800/69810]
loss: 0.040121  [51200/69810]
loss: 0.115526  [57600/69810]
loss: 0.128674  [64000/69810]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.134339 

Epoch 12
-------------------------------
loss: 0.151429  [    0/69810]
loss: 0.098498  [ 6400/69810]
loss: 0.094644  [12800/69810]
loss: 0.059846  [19200/69810]
loss: 0.060526  [25600/69810]
loss: 0.130013  [32000/69810]
loss: 0.126428  [38400/69810]
loss: 0.090231  [44800/69810]
loss: 0.059091  [51200/69810]
loss: 0.077873  [57600/69810]
loss: 0.111148  [64000/69810]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.136731 

Epoch 13
-------------------------------
loss: 0.084603  [    0/69810]
loss: 0.069298  [ 6400/69810]
loss: 0.184460  [12800/69810]
loss: 0.110953  [19200/69810]
loss: 0.086904  [25600/69810]
loss: 0.125777  [32000/69810]
loss: 0.149931  [38400/69810]
loss: 0.105571  [44800/69810]
loss: 0.091657  [51200/69810]
loss: 0.105672  [57600/69810]
loss: 0.053668  [64000/69810]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.143781 

Epoch 14
-------------------------------
loss: 0.107794  [    0/69810]
loss: 0.159497  [ 6400/69810]
loss: 0.063335  [12800/69810]
loss: 0.142564  [19200/69810]
loss: 0.133820  [25600/69810]
loss: 0.057420  [32000/69810]
loss: 0.078406  [38400/69810]
loss: 0.114244  [44800/69810]
loss: 0.097900  [51200/69810]
loss: 0.150794  [57600/69810]
loss: 0.180033  [64000/69810]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.145645 

Epoch 15
-------------------------------
loss: 0.115069  [    0/69810]
loss: 0.038704  [ 6400/69810]
loss: 0.173340  [12800/69810]
loss: 0.085378  [19200/69810]
loss: 0.130410  [25600/69810]
loss: 0.053660  [32000/69810]
loss: 0.134760  [38400/69810]
loss: 0.100224  [44800/69810]
loss: 0.112573  [51200/69810]
loss: 0.293467  [57600/69810]
loss: 0.104427  [64000/69810]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.135481 

Epoch 16
-------------------------------
loss: 0.150953  [    0/69810]
loss: 0.066103  [ 6400/69810]
loss: 0.056137  [12800/69810]
loss: 0.124370  [19200/69810]
loss: 0.037125  [25600/69810]
loss: 0.043100  [32000/69810]
loss: 0.126488  [38400/69810]
loss: 0.210088  [44800/69810]
loss: 0.151283  [51200/69810]
loss: 0.062269  [57600/69810]
loss: 0.135853  [64000/69810]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.148187 

Epoch 17
-------------------------------
loss: 0.162495  [    0/69810]
loss: 0.107289  [ 6400/69810]
loss: 0.044589  [12800/69810]
loss: 0.147295  [19200/69810]
loss: 0.073489  [25600/69810]
loss: 0.081537  [32000/69810]
loss: 0.198468  [38400/69810]
loss: 0.109718  [44800/69810]
loss: 0.199624  [51200/69810]
loss: 1.656467  [57600/69810]
loss: 0.131217  [64000/69810]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.143139 

Epoch 18
-------------------------------
loss: 0.130973  [    0/69810]
loss: 0.050434  [ 6400/69810]
loss: 0.108592  [12800/69810]
loss: 0.132093  [19200/69810]
loss: 0.044248  [25600/69810]
loss: 0.329552  [32000/69810]
loss: 0.148229  [38400/69810]
loss: 0.068125  [44800/69810]
loss: 0.061853  [51200/69810]
loss: 0.071748  [57600/69810]
loss: 0.046821  [64000/69810]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.134698 

Epoch 19
-------------------------------
loss: 0.106579  [    0/69810]
loss: 0.089040  [ 6400/69810]
loss: 0.055846  [12800/69810]
loss: 0.182256  [19200/69810]
loss: 0.118025  [25600/69810]
loss: 0.083766  [32000/69810]
loss: 0.161585  [38400/69810]
loss: 0.075886  [44800/69810]
loss: 0.065496  [51200/69810]
loss: 0.105834  [57600/69810]
loss: 0.115398  [64000/69810]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.139262 

Epoch 20
-------------------------------
loss: 0.147391  [    0/69810]
loss: 0.072959  [ 6400/69810]
loss: 0.118158  [12800/69810]
loss: 0.088911  [19200/69810]
loss: 0.140857  [25600/69810]
loss: 0.028420  [32000/69810]
loss: 0.174525  [38400/69810]
loss: 0.120445  [44800/69810]
loss: 0.093211  [51200/69810]
loss: 0.148352  [57600/69810]
loss: 0.138628  [64000/69810]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.135879 

Epoch 21
-------------------------------
loss: 0.078986  [    0/69810]
loss: 0.085135  [ 6400/69810]
loss: 0.116081  [12800/69810]
loss: 0.088203  [19200/69810]
loss: 0.164026  [25600/69810]
loss: 0.093046  [32000/69810]
loss: 0.097529  [38400/69810]
loss: 0.080139  [44800/69810]
loss: 0.172748  [51200/69810]
loss: 0.091565  [57600/69810]
loss: 0.121734  [64000/69810]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.148482 

Epoch 22
-------------------------------
loss: 0.124015  [    0/69810]
loss: 0.075693  [ 6400/69810]
loss: 0.076060  [12800/69810]
loss: 0.078937  [19200/69810]
loss: 0.063453  [25600/69810]
loss: 0.028178  [32000/71429]
loss: 0.145160  [38400/71429]
loss: 0.114376  [44800/71429]
loss: 0.031606  [51200/71429]
loss: 0.016242  [57600/71429]
loss: 0.236598  [64000/71429]
loss: 0.020834  [70400/71429]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.092673 

Epoch 7
-------------------------------
loss: 1.634569  [    0/71429]
loss: 0.056589  [ 6400/71429]
loss: 0.057578  [12800/71429]
loss: 0.090438  [19200/71429]
loss: 0.108385  [25600/71429]
loss: 0.052789  [32000/71429]
loss: 0.028841  [38400/71429]
loss: 0.082755  [44800/71429]
loss: 0.017678  [51200/71429]
loss: 0.048145  [57600/71429]
loss: 0.012103  [64000/71429]
loss: 0.043168  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.082924 

Epoch 8
-------------------------------
loss: 0.073050  [    0/71429]
loss: 0.068409  [ 6400/71429]
loss: 0.011498  [12800/71429]
loss: 0.095332  [19200/71429]
loss: 0.132647  [25600/71429]
loss: 0.111019  [32000/71429]
loss: 0.132691  [38400/71429]
loss: 0.021266  [44800/71429]
loss: 0.071808  [51200/71429]
loss: 0.056782  [57600/71429]
loss: 0.151124  [64000/71429]
loss: 0.116470  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.085019 

Epoch 9
-------------------------------
loss: 0.024947  [    0/71429]
loss: 0.213584  [ 6400/71429]
loss: 0.057648  [12800/71429]
loss: 0.032829  [19200/71429]
loss: 0.010032  [25600/71429]
loss: 0.012575  [32000/71429]
loss: 0.103907  [38400/71429]
loss: 0.028618  [44800/71429]
loss: 0.021116  [51200/71429]
loss: 0.020984  [57600/71429]
loss: 0.064898  [64000/71429]
loss: 0.037406  [70400/71429]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.090715 

Epoch 10
-------------------------------
loss: 0.103440  [    0/71429]
loss: 0.034907  [ 6400/71429]
loss: 0.084135  [12800/71429]
loss: 0.014395  [19200/71429]
loss: 0.065743  [25600/71429]
loss: 0.021691  [32000/71429]
loss: 0.103486  [38400/71429]
loss: 0.019930  [44800/71429]
loss: 0.113220  [51200/71429]
loss: 0.014242  [57600/71429]
loss: 0.051240  [64000/71429]
loss: 1.571197  [70400/71429]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.083230 

Epoch 11
-------------------------------
loss: 0.061681  [    0/71429]
loss: 0.038508  [ 6400/71429]
loss: 0.032537  [12800/71429]
loss: 0.037969  [19200/71429]
loss: 0.008261  [25600/71429]
loss: 0.042556  [32000/71429]
loss: 0.036838  [38400/71429]
loss: 0.120664  [44800/71429]
loss: 0.017107  [51200/71429]
loss: 0.022313  [57600/71429]
loss: 0.024589  [64000/71429]
loss: 0.037335  [70400/71429]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.079960 

Epoch 12
-------------------------------
loss: 0.025093  [    0/71429]
loss: 0.027191  [ 6400/71429]
loss: 0.052635  [12800/71429]
loss: 0.096022  [19200/71429]
loss: 0.067945  [25600/71429]
loss: 0.065297  [32000/71429]
loss: 0.032192  [38400/71429]
loss: 0.046901  [44800/71429]
loss: 0.067961  [51200/71429]
loss: 0.031409  [57600/71429]
loss: 0.027184  [64000/71429]
loss: 0.052604  [70400/71429]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.337723 

Epoch 13
-------------------------------
loss: 0.767883  [    0/71429]
loss: 0.170941  [ 6400/71429]
loss: 0.046522  [12800/71429]
loss: 0.033456  [19200/71429]
loss: 0.019786  [25600/71429]
loss: 0.011959  [32000/71429]
loss: 0.023256  [38400/71429]
loss: 0.021147  [44800/71429]
loss: 0.002202  [51200/71429]
loss: 0.107548  [57600/71429]
loss: 0.050922  [64000/71429]
loss: 0.015790  [70400/71429]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.085983 

Epoch 14
-------------------------------
loss: 0.010354  [    0/71429]
loss: 0.025557  [ 6400/71429]
loss: 0.056798  [12800/71429]
loss: 0.045262  [19200/71429]
loss: 0.031708  [25600/71429]
loss: 0.053146  [32000/71429]
loss: 0.071040  [38400/71429]
loss: 0.032088  [44800/71429]
loss: 0.076721  [51200/71429]
loss: 0.040324  [57600/71429]
loss: 0.054702  [64000/71429]
loss: 0.010978  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.087723 

Epoch 15
-------------------------------
loss: 0.033475  [    0/71429]
loss: 0.065025  [ 6400/71429]
loss: 0.112582  [12800/71429]
loss: 0.006654  [19200/71429]
loss: 0.035446  [25600/71429]
loss: 0.067656  [32000/71429]
loss: 0.028746  [38400/71429]
loss: 0.060990  [44800/71429]
loss: 0.021744  [51200/71429]
loss: 0.106645  [57600/71429]
loss: 0.074382  [64000/71429]
loss: 0.078267  [70400/71429]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.084810 

Epoch 16
-------------------------------
loss: 0.091484  [    0/71429]
loss: 0.072998  [ 6400/71429]
loss: 0.028770  [12800/71429]
loss: 0.017513  [19200/71429]
loss: 0.007648  [25600/71429]
loss: 0.107566  [32000/71429]
loss: 0.014922  [38400/71429]
loss: 0.078320  [44800/71429]
loss: 0.056736  [51200/71429]
loss: 0.047470  [57600/71429]
loss: 0.020800  [64000/71429]
loss: 0.050462  [70400/71429]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.103005 

Epoch 17
-------------------------------
loss: 0.004596  [    0/71429]
loss: 0.038969  [ 6400/71429]
loss: 0.018577  [12800/71429]
loss: 0.066055  [19200/71429]
loss: 0.080041  [25600/71429]
loss: 0.008005  [32000/71429]
loss: 0.049207  [38400/71429]
loss: 0.069327  [44800/71429]
loss: 0.137127  [51200/71429]
loss: 0.010466  [57600/71429]
loss: 0.091162  [64000/71429]
loss: 0.064555  [70400/71429]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.082621 

Epoch 18
-------------------------------
loss: 0.013224  [    0/71429]
loss: 0.008007  [ 6400/71429]
loss: 0.024021  [12800/71429]
loss: 0.017697  [19200/71429]
loss: 1.668935  [25600/71429]
loss: 0.038179  [32000/71429]
loss: 0.046927  [38400/71429]
loss: 0.003323  [44800/71429]
loss: 0.042798  [51200/71429]
loss: 0.101010  [57600/71429]
loss: 0.012268  [64000/71429]
loss: 0.180011  [70400/71429]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.112231 

Epoch 19
-------------------------------
loss: 0.055423  [    0/71429]
loss: 0.019455  [ 6400/71429]
loss: 0.060654  [12800/71429]
loss: 0.035461  [19200/71429]
loss: 0.006299  [25600/71429]
loss: 0.045362  [32000/71429]
loss: 0.004207  [38400/71429]
loss: 0.025892  [44800/71429]
loss: 0.083799  [51200/71429]
loss: 0.065056  [57600/71429]
loss: 0.037814  [64000/71429]
loss: 0.052492  [70400/71429]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.087756 

Epoch 20
-------------------------------
loss: 0.029400  [    0/71429]
loss: 0.060196  [ 6400/71429]
loss: 0.106837  [12800/71429]
loss: 0.002019  [19200/71429]
loss: 0.022889  [25600/71429]
loss: 0.042036  [32000/71429]
loss: 0.031575  [38400/71429]
loss: 0.032341  [44800/71429]
loss: 0.041292  [51200/71429]
loss: 0.012134  [57600/71429]
loss: 0.071288  [64000/71429]
loss: 0.061179  [70400/71429]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.093296 

Epoch 21
-------------------------------
loss: 0.098880  [    0/71429]
loss: 0.036578  [ 6400/71429]
loss: 0.009183  [12800/71429]
loss: 0.003766  [19200/71429]
loss: 0.080568  [25600/71429]
loss: 0.098695  [32000/71429]
loss: 0.012855  [38400/71429]
loss: 0.003613  [44800/71429]
loss: 0.026091  [51200/71429]
loss: 0.043502  [57600/71429]
loss: 0.005972  [64000/71429]
loss: 0.048437  [70400/71429]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.087570 

Epoch 22
-------------------------------
loss: 0.019452  [    0/71429]
loss: 0.023495  [ 6400/71429]
loss: 0.010395  [12800/71429]
loss: 0.072201  [19200/71429]
loss: 0.018314  [25600/71429]
loss: 0.007570  [32000/71429]
loss: 0.028183  [38400/71429]
loss: 0.004128  [44800/71429]
loss: 0.038186  [51200/71429]
loss: 0.038211  [57600/71429]
loss: 0.005412  [64000/71429]
loss: 0.009445  [70400/71429]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.082487 

Epoch 23
-------------------------------
loss: 0.019660  [    0/71429]
loss: 0.115613  [ 6400/71429]
loss: 0.148186  [12800/71429]
loss: 0.022251  [19200/71429]
loss: 0.008446  [25600/71429]
loss: 0.121744  [32000/71429]
loss: 0.059209  [38400/71429]
loss: 0.020757  [44800/71429]
loss: 0.062746  [51200/71429]
loss: 0.039492  [57600/71429]
loss: 0.031094  [64000/71429]
loss: 0.011332  [70400/71429]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.083135 

Epoch 24
-------------------------------
loss: 0.053775  [    0/71429]
loss: 0.006454  [ 6400/71429]
loss: 0.021801  [12800/71429]
loss: 0.019410  [19200/71429]
loss: 0.076743  [25600/71429]
loss: 0.002628  [32000/71429]
loss: 0.271859  [51200/69865]
loss: 0.113825  [57600/69865]
loss: 0.209409  [64000/69865]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.209694 

Epoch 7
-------------------------------
loss: 0.140310  [    0/69865]
loss: 0.145974  [ 6400/69865]
loss: 0.223605  [12800/69865]
loss: 0.176588  [19200/69865]
loss: 0.091428  [25600/69865]
loss: 0.216572  [32000/69865]
loss: 0.334831  [38400/69865]
loss: 0.231248  [44800/69865]
loss: 0.137676  [51200/69865]
loss: 0.154316  [57600/69865]
loss: 0.138101  [64000/69865]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.195615 

Epoch 8
-------------------------------
loss: 0.306641  [    0/69865]
loss: 0.149593  [ 6400/69865]
loss: 0.209516  [12800/69865]
loss: 0.162896  [19200/69865]
loss: 0.125918  [25600/69865]
loss: 0.217348  [32000/69865]
loss: 0.143563  [38400/69865]
loss: 0.196899  [44800/69865]
loss: 0.112397  [51200/69865]
loss: 0.294763  [57600/69865]
loss: 0.183724  [64000/69865]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.227440 

Epoch 9
-------------------------------
loss: 0.293588  [    0/69865]
loss: 0.301503  [ 6400/69865]
loss: 1.774884  [12800/69865]
loss: 0.292320  [19200/69865]
loss: 0.203237  [25600/69865]
loss: 0.132728  [32000/69865]
loss: 0.192907  [38400/69865]
loss: 0.272295  [44800/69865]
loss: 0.197146  [51200/69865]
loss: 0.320462  [57600/69865]
loss: 0.211892  [64000/69865]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.195894 

Epoch 10
-------------------------------
loss: 0.053281  [    0/69865]
loss: 0.282624  [ 6400/69865]
loss: 0.268722  [12800/69865]
loss: 0.296818  [19200/69865]
loss: 0.125023  [25600/69865]
loss: 0.335291  [32000/69865]
loss: 0.242119  [38400/69865]
loss: 0.272969  [44800/69865]
loss: 0.117237  [51200/69865]
loss: 0.233534  [57600/69865]
loss: 0.138013  [64000/69865]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.201812 

Epoch 11
-------------------------------
loss: 0.229622  [    0/69865]
loss: 0.237035  [ 6400/69865]
loss: 0.197509  [12800/69865]
loss: 0.181204  [19200/69865]
loss: 0.291853  [25600/69865]
loss: 0.254545  [32000/69865]
loss: 0.153074  [38400/69865]
loss: 0.247109  [44800/69865]
loss: 0.221887  [51200/69865]
loss: 0.160114  [57600/69865]
loss: 0.164435  [64000/69865]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.188081 

Epoch 12
-------------------------------
loss: 0.292237  [    0/69865]
loss: 1.680817  [ 6400/69865]
loss: 0.261399  [12800/69865]
loss: 0.228678  [19200/69865]
loss: 0.203390  [25600/69865]
loss: 0.207606  [32000/69865]
loss: 0.239822  [38400/69865]
loss: 0.282417  [44800/69865]
loss: 0.360647  [51200/69865]
loss: 0.115108  [57600/69865]
loss: 0.242939  [64000/69865]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.221745 

Epoch 13
-------------------------------
loss: 0.218142  [    0/69865]
loss: 0.307995  [ 6400/69865]
loss: 0.096444  [12800/69865]
loss: 0.174917  [19200/69865]
loss: 0.219733  [25600/69865]
loss: 0.192164  [32000/69865]
loss: 0.181609  [38400/69865]
loss: 0.206918  [44800/69865]
loss: 0.282868  [51200/69865]
loss: 0.069137  [57600/69865]
loss: 0.190797  [64000/69865]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.191845 

Epoch 14
-------------------------------
loss: 0.182568  [    0/69865]
loss: 0.128619  [ 6400/69865]
loss: 0.323770  [12800/69865]
loss: 0.171795  [19200/69865]
loss: 0.313183  [25600/69865]
loss: 0.128616  [32000/69865]
loss: 0.236432  [38400/69865]
loss: 0.153861  [44800/69865]
loss: 0.268921  [51200/69865]
loss: 0.136770  [57600/69865]
loss: 0.139787  [64000/69865]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.192524 

Epoch 15
-------------------------------
loss: 0.118529  [    0/69865]
loss: 0.104561  [ 6400/69865]
loss: 0.217764  [12800/69865]
loss: 0.193496  [19200/69865]
loss: 1.699971  [25600/69865]
loss: 0.151704  [32000/69865]
loss: 0.256767  [38400/69865]
loss: 0.205573  [44800/69865]
loss: 0.261571  [51200/69865]
loss: 0.117893  [57600/69865]
loss: 0.161544  [64000/69865]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.204655 

Epoch 16
-------------------------------
loss: 0.337683  [    0/69865]
loss: 0.142640  [ 6400/69865]
loss: 0.216261  [12800/69865]
loss: 0.145378  [19200/69865]
loss: 0.113305  [25600/69865]
loss: 0.143248  [32000/69865]
loss: 0.199313  [38400/69865]
loss: 0.120748  [44800/69865]
loss: 0.227129  [51200/69865]
loss: 0.228138  [57600/69865]
loss: 0.154923  [64000/69865]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.200524 

Epoch 17
-------------------------------
loss: 0.257476  [    0/69865]
loss: 0.177103  [ 6400/69865]
loss: 0.160500  [12800/69865]
loss: 0.265898  [19200/69865]
loss: 0.176741  [25600/69865]
loss: 0.191030  [32000/69865]
loss: 0.212274  [38400/69865]
loss: 0.246285  [44800/69865]
loss: 0.131800  [51200/69865]
loss: 0.229017  [57600/69865]
loss: 0.154241  [64000/69865]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.199783 

Epoch 18
-------------------------------
loss: 0.157113  [    0/69865]
loss: 0.162508  [ 6400/69865]
loss: 0.267294  [12800/69865]
loss: 0.165077  [19200/69865]
loss: 0.158808  [25600/69865]
loss: 0.140181  [32000/69865]
loss: 0.150646  [38400/69865]
loss: 0.267314  [44800/69865]
loss: 0.248025  [51200/69865]
loss: 0.197109  [57600/69865]
loss: 0.071909  [64000/69865]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.195876 

Epoch 19
-------------------------------
loss: 0.123467  [    0/69865]
loss: 0.134975  [ 6400/69865]
loss: 0.149179  [12800/69865]
loss: 0.208696  [19200/69865]
loss: 0.104389  [25600/69865]
loss: 0.320367  [32000/69865]
loss: 0.126146  [38400/69865]
loss: 0.159940  [44800/69865]
loss: 0.146332  [51200/69865]
loss: 0.253568  [57600/69865]
loss: 0.214828  [64000/69865]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.208916 

Epoch 20
-------------------------------
loss: 0.128414  [    0/69865]
loss: 0.211783  [ 6400/69865]
loss: 0.236793  [12800/69865]
loss: 0.280690  [19200/69865]
loss: 0.178564  [25600/69865]
loss: 0.177463  [32000/69865]
loss: 0.228837  [38400/69865]
loss: 0.149235  [44800/69865]
loss: 0.199216  [51200/69865]
loss: 0.243252  [57600/69865]
loss: 0.120417  [64000/69865]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.206594 

Epoch 21
-------------------------------
loss: 0.242855  [    0/69865]
loss: 0.131777  [ 6400/69865]
loss: 0.174860  [12800/69865]
loss: 0.245165  [19200/69865]
loss: 0.143478  [25600/69865]
loss: 0.131898  [32000/69865]
loss: 0.278334  [38400/69865]
loss: 0.143665  [44800/69865]
loss: 0.222384  [51200/69865]
loss: 0.130353  [57600/69865]
loss: 0.188799  [64000/69865]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.198549 

Epoch 22
-------------------------------
loss: 0.133433  [    0/69865]
loss: 0.219415  [ 6400/69865]
loss: 0.132325  [12800/69865]
loss: 0.179775  [19200/69865]
loss: 0.215245  [25600/69865]
loss: 0.183590  [32000/69865]
loss: 0.116094  [38400/69865]
loss: 0.208574  [44800/69865]
loss: 0.241168  [51200/69865]
loss: 0.199265  [57600/69865]
loss: 0.099639  [64000/69865]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.204249 

Epoch 23
-------------------------------
loss: 0.215042  [    0/69865]
loss: 0.302489  [ 6400/69865]
loss: 1.713568  [12800/69865]
loss: 0.185251  [19200/69865]
loss: 0.206266  [25600/69865]
loss: 0.087214  [32000/69865]
loss: 0.140897  [38400/69865]
loss: 0.197906  [44800/69865]
loss: 0.137189  [51200/69865]
loss: 0.182301  [57600/69865]
loss: 0.112633  [64000/69865]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.212418 

Epoch 24
-------------------------------
loss: 0.280705  [    0/69865]
loss: 0.235870  [ 6400/69865]
loss: 0.126043  [12800/69865]
loss: 0.163668  [19200/69865]
loss: 0.155283  [25600/69865]
loss: 0.252323  [32000/69865]
loss: 0.227034  [38400/69865]
loss: 0.235781  [44800/69865]
loss: 0.180856  [51200/69865]
loss: 0.190473  [57600/69865]
loss: 0.384151  [64000/69865]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.225352 

Epoch 25
-------------------------------
loss: 0.200843  [    0/69865]
loss: 0.165363  [ 6400/69865]
loss: 0.150392  [12800/69865]
loss: 0.305675  [19200/69865]
loss: 0.129988  [25600/69865]
loss: 0.216152  [32000/69865]
loss: 0.189486  [38400/69865]
loss: 0.156390  [44800/69865]
loss: 0.161891  [51200/69865]
loss: 0.168133  [57600/69865]
loss: 0.237877  [64000/69865]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.195613 

loss: 0.294225  [44800/69548]
loss: 0.089068  [51200/69548]
loss: 0.102811  [57600/69548]
loss: 0.304894  [64000/69548]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.177300 

Epoch 45
-------------------------------
loss: 0.098679  [    0/69548]
loss: 0.229194  [ 6400/69548]
loss: 0.209950  [12800/69548]
loss: 0.100360  [19200/69548]
loss: 0.113616  [25600/69548]
loss: 0.083203  [32000/69548]
loss: 0.136039  [38400/69548]
loss: 0.189153  [44800/69548]
loss: 0.235431  [51200/69548]
loss: 0.192157  [57600/69548]
loss: 0.106628  [64000/69548]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.183413 

Epoch 46
-------------------------------
loss: 0.263228  [    0/69548]
loss: 0.222461  [ 6400/69548]
loss: 0.094260  [12800/69548]
loss: 0.250541  [19200/69548]
loss: 0.221256  [25600/69548]
loss: 0.115529  [32000/69548]
loss: 0.211890  [38400/69548]
loss: 0.312179  [44800/69548]
loss: 0.097516  [51200/69548]
loss: 0.136034  [57600/69548]
loss: 0.215660  [64000/69548]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.183370 

Epoch 47
-------------------------------
loss: 0.143807  [    0/69548]
loss: 0.100682  [ 6400/69548]
loss: 0.135822  [12800/69548]
loss: 0.239466  [19200/69548]
loss: 0.172765  [25600/69548]
loss: 0.169856  [32000/69548]
loss: 0.143725  [38400/69548]
loss: 0.139425  [44800/69548]
loss: 0.158562  [51200/69548]
loss: 0.116051  [57600/69548]
loss: 0.132118  [64000/69548]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.180696 

Epoch 48
-------------------------------
loss: 0.141459  [    0/69548]
loss: 0.361497  [ 6400/69548]
loss: 0.156318  [12800/69548]
loss: 0.106027  [19200/69548]
loss: 0.158833  [25600/69548]
loss: 0.127251  [32000/69548]
loss: 0.106519  [38400/69548]
loss: 0.169978  [44800/69548]
loss: 0.194762  [51200/69548]
loss: 0.175985  [57600/69548]
loss: 0.214649  [64000/69548]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.181968 

Epoch 49
-------------------------------
loss: 0.108328  [    0/69548]
loss: 0.109002  [ 6400/69548]
loss: 0.144047  [12800/69548]
loss: 0.097936  [19200/69548]
loss: 0.161107  [25600/69548]
loss: 0.185789  [32000/69548]
loss: 0.072931  [38400/69548]
loss: 0.248541  [44800/69548]
loss: 0.102188  [51200/69548]
loss: 0.206146  [57600/69548]
loss: 0.145285  [64000/69548]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.188911 

Epoch 50
-------------------------------
loss: 0.099771  [    0/69548]
loss: 0.154431  [ 6400/69548]
loss: 0.159430  [12800/69548]
loss: 0.282684  [19200/69548]
loss: 0.107041  [25600/69548]
loss: 0.166877  [32000/69548]
loss: 0.161001  [38400/69548]
loss: 0.164217  [44800/69548]
loss: 0.200935  [51200/69548]
loss: 0.190692  [57600/69548]
loss: 0.232823  [64000/69548]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.181380 

Epoch 1
-------------------------------
loss: 0.653447  [    0/70738]
loss: 0.326260  [ 6400/70738]
loss: 0.137573  [12800/70738]
loss: 0.252791  [19200/70738]
loss: 0.300037  [25600/70738]
loss: 0.259694  [32000/70738]
loss: 0.383185  [38400/70738]
loss: 0.143187  [44800/70738]
loss: 0.128860  [51200/70738]
loss: 0.169714  [57600/70738]
loss: 0.260255  [64000/70738]
loss: 0.306070  [70400/70738]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.227817 

Epoch 2
-------------------------------
loss: 0.245328  [    0/70738]
loss: 0.285927  [ 6400/70738]
loss: 0.144588  [12800/70738]
loss: 0.214337  [19200/70738]
loss: 0.160656  [25600/70738]
loss: 0.255546  [32000/70738]
loss: 0.164384  [38400/70738]
loss: 0.188764  [44800/70738]
loss: 0.261397  [51200/70738]
loss: 0.177731  [57600/70738]
loss: 0.268058  [64000/70738]
loss: 0.226238  [70400/70738]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.215040 

Epoch 3
-------------------------------
loss: 0.111110  [    0/70738]
loss: 0.251106  [ 6400/70738]
loss: 0.154936  [12800/70738]
loss: 0.149323  [19200/70738]
loss: 0.264022  [25600/70738]
loss: 0.177553  [32000/70738]
loss: 0.193137  [38400/70738]
loss: 0.107797  [44800/70738]
loss: 0.201636  [51200/70738]
loss: 0.243692  [57600/70738]
loss: 0.176064  [64000/70738]
loss: 0.165431  [70400/70738]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.218531 

Epoch 4
-------------------------------
loss: 0.261085  [    0/70738]
loss: 0.196869  [ 6400/70738]
loss: 0.115719  [12800/70738]
loss: 0.167037  [19200/70738]
loss: 0.177548  [25600/70738]
loss: 0.207861  [32000/70738]
loss: 1.716679  [38400/70738]
loss: 0.215482  [44800/70738]
loss: 0.083164  [51200/70738]
loss: 0.240675  [57600/70738]
loss: 0.187076  [64000/70738]
loss: 0.181318  [70400/70738]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.198328 

Epoch 5
-------------------------------
loss: 0.149454  [    0/70738]
loss: 0.150181  [ 6400/70738]
loss: 0.178244  [12800/70738]
loss: 0.393056  [19200/70738]
loss: 0.118486  [25600/70738]
loss: 0.087537  [32000/70738]
loss: 0.151461  [38400/70738]
loss: 0.143816  [44800/70738]
loss: 0.108336  [51200/70738]
loss: 0.130195  [57600/70738]
loss: 0.114441  [64000/70738]
loss: 0.186793  [70400/70738]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.203578 

Epoch 6
-------------------------------
loss: 0.144575  [    0/70738]
loss: 0.297693  [ 6400/70738]
loss: 0.121628  [12800/70738]
loss: 0.289158  [19200/70738]
loss: 0.090613  [25600/70738]
loss: 0.094733  [32000/70738]
loss: 0.196594  [38400/70738]
loss: 0.167577  [44800/70738]
loss: 0.190176  [51200/70738]
loss: 0.215687  [57600/70738]
loss: 0.122250  [64000/70738]
loss: 0.125803  [70400/70738]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.196812 

Epoch 7
-------------------------------
loss: 0.207207  [    0/70738]
loss: 0.287967  [ 6400/70738]
loss: 0.091540  [12800/70738]
loss: 0.110190  [19200/70738]
loss: 0.179297  [25600/70738]
loss: 0.198028  [32000/70738]
loss: 0.169857  [38400/70738]
loss: 0.085547  [44800/70738]
loss: 0.116988  [51200/70738]
loss: 0.186761  [57600/70738]
loss: 0.133134  [64000/70738]
loss: 0.148192  [70400/70738]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.201164 

Epoch 8
-------------------------------
loss: 0.136865  [    0/70738]
loss: 0.116283  [ 6400/70738]
loss: 0.062941  [12800/70738]
loss: 0.061059  [19200/70738]
loss: 0.129718  [25600/70738]
loss: 0.304686  [32000/70738]
loss: 0.201458  [38400/70738]
loss: 0.175356  [44800/70738]
loss: 0.137506  [51200/70738]
loss: 0.203228  [57600/70738]
loss: 0.109498  [64000/70738]
loss: 0.216325  [70400/70738]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.189234 

Epoch 9
-------------------------------
loss: 0.191011  [    0/70738]
loss: 0.178424  [ 6400/70738]
loss: 0.151420  [12800/70738]
loss: 0.110210  [19200/70738]
loss: 0.247715  [25600/70738]
loss: 0.113184  [32000/70738]
loss: 0.124930  [38400/70738]
loss: 0.278025  [44800/70738]
loss: 0.188812  [51200/70738]
loss: 0.045994  [57600/70738]
loss: 0.246710  [64000/70738]
loss: 0.090286  [70400/70738]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.205914 

Epoch 10
-------------------------------
loss: 0.110496  [    0/70738]
loss: 0.223532  [ 6400/70738]
loss: 0.343897  [12800/70738]
loss: 0.200176  [19200/70738]
loss: 0.085215  [25600/70738]
loss: 0.168782  [32000/70738]
loss: 0.089530  [38400/70738]
loss: 0.143479  [44800/70738]
loss: 0.109828  [51200/70738]
loss: 0.128004  [57600/70738]
loss: 0.130852  [64000/70738]
loss: 0.130254  [70400/70738]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.185653 

Epoch 11
-------------------------------
loss: 0.131964  [    0/70738]
loss: 0.145660  [ 6400/70738]
loss: 0.214823  [12800/70738]
loss: 0.141014  [19200/70738]
loss: 0.128495  [25600/70738]
loss: 0.097133  [32000/70738]
loss: 0.087918  [38400/70738]
loss: 0.072616  [44800/70738]
loss: 0.390174  [51200/70738]
loss: 0.073077  [57600/70738]
loss: 0.114626  [64000/70738]
loss: 0.164204  [70400/70738]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.192044 

Epoch 12
-------------------------------
loss: 0.252336  [    0/70738]
loss: 0.155894  [ 6400/70738]
loss: 0.093489  [12800/70738]
loss: 0.144704  [19200/70738]
loss: 0.127818  [25600/70738]
loss: 0.234637  [32000/70738]
loss: 0.072145  [38400/70738]
loss: 0.131940  [44800/70738]
loss: 0.239379  [51200/70738]
loss: 0.153482  [57600/70738]
loss: 0.155733  [64000/70738]
loss: 0.110978  [70400/70738]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.199978 

Epoch 13
-------------------------------
loss: 0.045414  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.119530 

Epoch 18
-------------------------------
loss: 0.050919  [    0/71476]
loss: 0.138579  [ 6400/71476]
loss: 0.036352  [12800/71476]
loss: 0.031686  [19200/71476]
loss: 0.073617  [25600/71476]
loss: 0.142425  [32000/71476]
loss: 0.034101  [38400/71476]
loss: 0.109903  [44800/71476]
loss: 0.168007  [51200/71476]
loss: 0.071732  [57600/71476]
loss: 0.161847  [64000/71476]
loss: 0.005563  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.122192 

Epoch 19
-------------------------------
loss: 0.078626  [    0/71476]
loss: 0.113568  [ 6400/71476]
loss: 0.124992  [12800/71476]
loss: 0.073074  [19200/71476]
loss: 0.129261  [25600/71476]
loss: 0.022292  [32000/71476]
loss: 0.067416  [38400/71476]
loss: 0.045100  [44800/71476]
loss: 0.023171  [51200/71476]
loss: 0.020160  [57600/71476]
loss: 0.034640  [64000/71476]
loss: 0.044310  [70400/71476]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.122484 

Epoch 20
-------------------------------
loss: 0.025720  [    0/71476]
loss: 0.042963  [ 6400/71476]
loss: 0.066152  [12800/71476]
loss: 0.097964  [19200/71476]
loss: 0.095629  [25600/71476]
loss: 0.059718  [32000/71476]
loss: 0.024024  [38400/71476]
loss: 0.074300  [44800/71476]
loss: 0.057180  [51200/71476]
loss: 0.082493  [57600/71476]
loss: 0.100723  [64000/71476]
loss: 0.007425  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.126020 

Epoch 21
-------------------------------
loss: 0.036617  [    0/71476]
loss: 0.065693  [ 6400/71476]
loss: 0.061330  [12800/71476]
loss: 0.017430  [19200/71476]
loss: 0.126755  [25600/71476]
loss: 0.147229  [32000/71476]
loss: 0.037624  [38400/71476]
loss: 0.119527  [44800/71476]
loss: 0.100327  [51200/71476]
loss: 0.093071  [57600/71476]
loss: 0.092526  [64000/71476]
loss: 0.082237  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.122146 

Epoch 22
-------------------------------
loss: 0.045826  [    0/71476]
loss: 0.060874  [ 6400/71476]
loss: 0.063856  [12800/71476]
loss: 0.027879  [19200/71476]
loss: 0.085344  [25600/71476]
loss: 0.088400  [32000/71476]
loss: 0.151045  [38400/71476]
loss: 0.025990  [44800/71476]
loss: 0.150111  [51200/71476]
loss: 0.113176  [57600/71476]
loss: 0.097581  [64000/71476]
loss: 0.065896  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.125179 

Epoch 23
-------------------------------
loss: 0.057240  [    0/71476]
loss: 0.044176  [ 6400/71476]
loss: 0.117109  [12800/71476]
loss: 0.059776  [19200/71476]
loss: 0.012287  [25600/71476]
loss: 0.074463  [32000/71476]
loss: 0.032893  [38400/71476]
loss: 0.040207  [44800/71476]
loss: 0.034972  [51200/71476]
loss: 0.030848  [57600/71476]
loss: 0.058653  [64000/71476]
loss: 0.045371  [70400/71476]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.125358 

Epoch 24
-------------------------------
loss: 0.088319  [    0/71476]
loss: 0.029661  [ 6400/71476]
loss: 0.055410  [12800/71476]
loss: 0.014803  [19200/71476]
loss: 0.044331  [25600/71476]
loss: 0.033232  [32000/71476]
loss: 0.066613  [38400/71476]
loss: 0.030290  [44800/71476]
loss: 0.123266  [51200/71476]
loss: 0.050562  [57600/71476]
loss: 0.096325  [64000/71476]
loss: 0.086972  [70400/71476]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.123314 

Epoch 25
-------------------------------
loss: 0.098011  [    0/71476]
loss: 0.030643  [ 6400/71476]
loss: 0.031265  [12800/71476]
loss: 0.007228  [19200/71476]
loss: 0.098111  [25600/71476]
loss: 0.054600  [32000/71476]
loss: 0.019538  [38400/71476]
loss: 0.073745  [44800/71476]
loss: 0.006963  [51200/71476]
loss: 0.081096  [57600/71476]
loss: 0.083096  [64000/71476]
loss: 0.062440  [70400/71476]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.123541 

Epoch 26
-------------------------------
loss: 0.029608  [    0/71476]
loss: 0.025270  [ 6400/71476]
loss: 0.106563  [12800/71476]
loss: 0.023008  [19200/71476]
loss: 0.094567  [25600/71476]
loss: 0.117925  [32000/71476]
loss: 0.083738  [38400/71476]
loss: 0.052718  [44800/71476]
loss: 0.058934  [51200/71476]
loss: 0.025340  [57600/71476]
loss: 0.033631  [64000/71476]
loss: 0.051498  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.122414 

Epoch 27
-------------------------------
loss: 0.049870  [    0/71476]
loss: 0.031289  [ 6400/71476]
loss: 0.096547  [12800/71476]
loss: 0.022530  [19200/71476]
loss: 0.020959  [25600/71476]
loss: 0.070954  [32000/71476]
loss: 0.040972  [38400/71476]
loss: 0.024853  [44800/71476]
loss: 0.055761  [51200/71476]
loss: 0.101206  [57600/71476]
loss: 1.631300  [64000/71476]
loss: 0.097716  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.118369 

Epoch 28
-------------------------------
loss: 0.051686  [    0/71476]
loss: 0.117664  [ 6400/71476]
loss: 0.025513  [12800/71476]
loss: 0.020893  [19200/71476]
loss: 0.052094  [25600/71476]
loss: 0.058274  [32000/71476]
loss: 0.041893  [38400/71476]
loss: 0.122533  [44800/71476]
loss: 0.074397  [51200/71476]
loss: 0.132566  [57600/71476]
loss: 0.063178  [64000/71476]
loss: 0.139861  [70400/71476]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.117390 

Epoch 29
-------------------------------
loss: 0.029345  [    0/71476]
loss: 0.041277  [ 6400/71476]
loss: 0.110666  [12800/71476]
loss: 0.009378  [19200/71476]
loss: 0.038569  [25600/71476]
loss: 0.029074  [32000/71476]
loss: 0.055494  [38400/71476]
loss: 0.072984  [44800/71476]
loss: 0.066381  [51200/71476]
loss: 0.347862  [57600/71476]
loss: 0.076324  [64000/71476]
loss: 0.098665  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.121369 

Epoch 30
-------------------------------
loss: 0.031191  [    0/71476]
loss: 0.013515  [ 6400/71476]
loss: 0.062846  [12800/71476]
loss: 0.134483  [19200/71476]
loss: 0.079596  [25600/71476]
loss: 0.120671  [32000/71476]
loss: 0.066940  [38400/71476]
loss: 0.045768  [44800/71476]
loss: 0.081671  [51200/71476]
loss: 0.058938  [57600/71476]
loss: 0.048740  [64000/71476]
loss: 0.064722  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.121441 

Epoch 31
-------------------------------
loss: 0.103696  [    0/71476]
loss: 0.025642  [ 6400/71476]
loss: 0.136557  [12800/71476]
loss: 0.093142  [19200/71476]
loss: 0.030987  [25600/71476]
loss: 0.004882  [32000/71476]
loss: 0.018229  [38400/71476]
loss: 0.105811  [44800/71476]
loss: 0.012963  [51200/71476]
loss: 0.081390  [57600/71476]
loss: 0.036145  [64000/71476]
loss: 0.017596  [70400/71476]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.122264 

Epoch 32
-------------------------------
loss: 1.611505  [    0/71476]
loss: 0.081844  [ 6400/71476]
loss: 0.058344  [12800/71476]
loss: 0.027105  [19200/71476]
loss: 0.060778  [25600/71476]
loss: 0.023756  [32000/71476]
loss: 0.025287  [38400/71476]
loss: 0.018370  [44800/71476]
loss: 0.120892  [51200/71476]
loss: 0.051654  [57600/71476]
loss: 0.163518  [64000/71476]
loss: 0.073268  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.116887 

Epoch 33
-------------------------------
loss: 0.112285  [    0/71476]
loss: 0.094411  [ 6400/71476]
loss: 0.170218  [12800/71476]
loss: 0.086293  [19200/71476]
loss: 0.078711  [25600/71476]
loss: 0.166852  [32000/71476]
loss: 0.018981  [38400/71476]
loss: 0.122184  [44800/71476]
loss: 0.006475  [51200/71476]
loss: 0.045900  [57600/71476]
loss: 0.020408  [64000/71476]
loss: 0.059048  [70400/71476]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.125720 

Epoch 34
-------------------------------
loss: 0.064953  [    0/71476]
loss: 0.027944  [ 6400/71476]
loss: 0.141987  [12800/71476]
loss: 0.035478  [19200/71476]
loss: 0.028135  [25600/71476]
loss: 0.026361  [32000/71476]
loss: 0.019569  [38400/71476]
loss: 0.068032  [44800/71476]
loss: 0.082020  [51200/71476]
loss: 0.043999  [57600/71476]
loss: 0.038653  [64000/71476]
loss: 0.052324  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.124685 

Epoch 35
-------------------------------
loss: 0.102903  [    0/71476]
loss: 0.030875  [ 6400/71476]
loss: 0.034074  [12800/71476]
loss: 0.160407  [19200/71476]
loss: 0.085215  [25600/71476]
loss: 0.033550  [32000/71476]
loss: 0.047275  [38400/71476]
loss: 0.032318  [44800/71476]
loss: 0.035706  [51200/71476]
loss: 0.009661  [57600/71476]
loss: 0.190852  [64000/71476]
loss: 0.019128  [70400/71476]
loss: 0.106897  [25600/71041]
loss: 0.243353  [32000/71041]
loss: 0.104174  [38400/71041]
loss: 0.203681  [44800/71041]
loss: 0.110579  [51200/71041]
loss: 0.160231  [57600/71041]
loss: 0.152064  [64000/71041]
loss: 0.056778  [70400/71041]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.154587 

Epoch 7
-------------------------------
loss: 0.133536  [    0/71041]
loss: 0.090758  [ 6400/71041]
loss: 0.107588  [12800/71041]
loss: 0.130632  [19200/71041]
loss: 0.289909  [25600/71041]
loss: 0.164723  [32000/71041]
loss: 0.183618  [38400/71041]
loss: 0.153322  [44800/71041]
loss: 0.058140  [51200/71041]
loss: 0.163454  [57600/71041]
loss: 0.116999  [64000/71041]
loss: 0.245410  [70400/71041]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.158864 

Epoch 8
-------------------------------
loss: 0.150503  [    0/71041]
loss: 0.149170  [ 6400/71041]
loss: 0.094098  [12800/71041]
loss: 0.121401  [19200/71041]
loss: 0.141290  [25600/71041]
loss: 0.020436  [32000/71041]
loss: 0.093272  [38400/71041]
loss: 0.218253  [44800/71041]
loss: 0.123048  [51200/71041]
loss: 0.075242  [57600/71041]
loss: 0.194613  [64000/71041]
loss: 0.130295  [70400/71041]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.156059 

Epoch 9
-------------------------------
loss: 0.105148  [    0/71041]
loss: 0.137127  [ 6400/71041]
loss: 0.067660  [12800/71041]
loss: 0.256696  [19200/71041]
loss: 0.115703  [25600/71041]
loss: 0.118093  [32000/71041]
loss: 0.112453  [38400/71041]
loss: 0.076760  [44800/71041]
loss: 0.170308  [51200/71041]
loss: 0.053413  [57600/71041]
loss: 0.100146  [64000/71041]
loss: 0.073761  [70400/71041]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.155361 

Epoch 10
-------------------------------
loss: 0.147368  [    0/71041]
loss: 0.261772  [ 6400/71041]
loss: 0.120990  [12800/71041]
loss: 0.182846  [19200/71041]
loss: 0.043181  [25600/71041]
loss: 0.149474  [32000/71041]
loss: 0.053399  [38400/71041]
loss: 0.135353  [44800/71041]
loss: 0.110625  [51200/71041]
loss: 0.115615  [57600/71041]
loss: 0.146126  [64000/71041]
loss: 0.154400  [70400/71041]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.155961 

Epoch 11
-------------------------------
loss: 0.111336  [    0/71041]
loss: 0.135044  [ 6400/71041]
loss: 0.081536  [12800/71041]
loss: 0.128738  [19200/71041]
loss: 0.109301  [25600/71041]
loss: 0.400285  [32000/71041]
loss: 0.121916  [38400/71041]
loss: 0.064527  [44800/71041]
loss: 0.260703  [51200/71041]
loss: 0.073921  [57600/71041]
loss: 0.180919  [64000/71041]
loss: 0.118766  [70400/71041]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.160305 

Epoch 12
-------------------------------
loss: 0.095746  [    0/71041]
loss: 0.071416  [ 6400/71041]
loss: 0.142366  [12800/71041]
loss: 0.212976  [19200/71041]
loss: 0.079543  [25600/71041]
loss: 0.168372  [32000/71041]
loss: 0.122745  [38400/71041]
loss: 0.160596  [44800/71041]
loss: 0.123624  [51200/71041]
loss: 0.063568  [57600/71041]
loss: 0.085990  [64000/71041]
loss: 0.121354  [70400/71041]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.210538 

Epoch 13
-------------------------------
loss: 0.072060  [    0/71041]
loss: 0.078257  [ 6400/71041]
loss: 0.224323  [12800/71041]
loss: 0.058100  [19200/71041]
loss: 0.072483  [25600/71041]
loss: 0.135149  [32000/71041]
loss: 0.097604  [38400/71041]
loss: 0.110237  [44800/71041]
loss: 0.048267  [51200/71041]
loss: 0.255375  [57600/71041]
loss: 0.223501  [64000/71041]
loss: 0.073230  [70400/71041]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.152100 

Epoch 14
-------------------------------
loss: 0.103560  [    0/71041]
loss: 0.029972  [ 6400/71041]
loss: 0.076125  [12800/71041]
loss: 0.149394  [19200/71041]
loss: 0.194657  [25600/71041]
loss: 0.162666  [32000/71041]
loss: 0.162798  [38400/71041]
loss: 0.031270  [44800/71041]
loss: 0.180967  [51200/71041]
loss: 0.123146  [57600/71041]
loss: 0.261896  [64000/71041]
loss: 0.151523  [70400/71041]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.154961 

Epoch 15
-------------------------------
loss: 0.065186  [    0/71041]
loss: 0.122257  [ 6400/71041]
loss: 0.219150  [12800/71041]
loss: 0.125993  [19200/71041]
loss: 0.161818  [25600/71041]
loss: 0.078315  [32000/71041]
loss: 0.141775  [38400/71041]
loss: 1.602689  [44800/71041]
loss: 0.096927  [51200/71041]
loss: 0.179058  [57600/71041]
loss: 0.141575  [64000/71041]
loss: 0.127056  [70400/71041]
Test Error: 
 Accuracy: 86.9%, Avg loss: 0.389860 

Epoch 16
-------------------------------
loss: 0.424165  [    0/71041]
loss: 0.038761  [ 6400/71041]
loss: 0.116931  [12800/71041]
loss: 0.130659  [19200/71041]
loss: 0.047874  [25600/71041]
loss: 0.080787  [32000/71041]
loss: 0.112308  [38400/71041]
loss: 0.247874  [44800/71041]
loss: 0.058945  [51200/71041]
loss: 0.269693  [57600/71041]
loss: 0.240445  [64000/71041]
loss: 0.073605  [70400/71041]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.155576 

Epoch 17
-------------------------------
loss: 0.104404  [    0/71041]
loss: 0.134429  [ 6400/71041]
loss: 0.202769  [12800/71041]
loss: 0.121030  [19200/71041]
loss: 0.078235  [25600/71041]
loss: 0.180710  [32000/71041]
loss: 0.150495  [38400/71041]
loss: 0.104844  [44800/71041]
loss: 0.183460  [51200/71041]
loss: 0.083803  [57600/71041]
loss: 0.134400  [64000/71041]
loss: 0.042210  [70400/71041]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.153136 

Epoch 18
-------------------------------
loss: 0.098774  [    0/71041]
loss: 0.098243  [ 6400/71041]
loss: 0.115514  [12800/71041]
loss: 0.140325  [19200/71041]
loss: 0.098652  [25600/71041]
loss: 0.074913  [32000/71041]
loss: 0.127211  [38400/71041]
loss: 0.179216  [44800/71041]
loss: 0.016637  [51200/71041]
loss: 0.060031  [57600/71041]
loss: 0.193832  [64000/71041]
loss: 0.104458  [70400/71041]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.153386 

Epoch 19
-------------------------------
loss: 0.059154  [    0/71041]
loss: 0.158826  [ 6400/71041]
loss: 0.063932  [12800/71041]
loss: 0.053924  [19200/71041]
loss: 0.172788  [25600/71041]
loss: 0.139381  [32000/71041]
loss: 0.094463  [38400/71041]
loss: 0.155497  [44800/71041]
loss: 0.089710  [51200/71041]
loss: 0.086444  [57600/71041]
loss: 0.067721  [64000/71041]
loss: 0.123644  [70400/71041]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.148218 

Epoch 20
-------------------------------
loss: 0.074551  [    0/71041]
loss: 0.172436  [ 6400/71041]
loss: 0.113815  [12800/71041]
loss: 0.120361  [19200/71041]
loss: 0.060652  [25600/71041]
loss: 0.202159  [32000/71041]
loss: 0.082927  [38400/71041]
loss: 0.130859  [44800/71041]
loss: 0.140234  [51200/71041]
loss: 0.168721  [57600/71041]
loss: 0.059322  [64000/71041]
loss: 0.147740  [70400/71041]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.148542 

Epoch 21
-------------------------------
loss: 1.595139  [    0/71041]
loss: 0.111637  [ 6400/71041]
loss: 0.043446  [12800/71041]
loss: 0.141047  [19200/71041]
loss: 0.207626  [25600/71041]
loss: 0.351213  [32000/71041]
loss: 0.139344  [38400/71041]
loss: 0.153414  [44800/71041]
loss: 0.127821  [51200/71041]
loss: 0.147789  [57600/71041]
loss: 0.069441  [64000/71041]
loss: 0.079164  [70400/71041]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.155792 

Epoch 22
-------------------------------
loss: 0.047244  [    0/71041]
loss: 0.117341  [ 6400/71041]
loss: 0.032961  [12800/71041]
loss: 0.232391  [19200/71041]
loss: 0.122241  [25600/71041]
loss: 0.097685  [32000/71041]
loss: 0.109896  [38400/71041]
loss: 0.096038  [44800/71041]
loss: 0.139409  [51200/71041]
loss: 0.166955  [57600/71041]
loss: 0.083746  [64000/71041]
loss: 0.129006  [70400/71041]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.145873 

Epoch 23
-------------------------------
loss: 0.095676  [    0/71041]
loss: 0.039654  [ 6400/71041]
loss: 0.138132  [12800/71041]
loss: 0.068181  [19200/71041]
loss: 0.118122  [25600/71041]
loss: 0.052610  [32000/71041]
loss: 0.180833  [38400/71041]
loss: 0.073861  [44800/71041]
loss: 0.172471  [51200/71041]
loss: 0.102315  [57600/71041]
loss: 0.175593  [64000/71041]
loss: 0.147577  [70400/71041]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.151025 

Epoch 24
-------------------------------
loss: 0.179704  [    0/71041]
loss: 0.152815  [ 6400/71041]
loss: 0.112596  [12800/71041]
loss: 0.053845  [19200/71041]
loss: 0.162279  [25600/71041]
loss: 0.084562  [ 6400/70468]
loss: 1.722703  [12800/70468]
loss: 0.100312  [19200/70468]
loss: 0.276666  [25600/70468]
loss: 0.182111  [32000/70468]
loss: 0.087428  [38400/70468]
loss: 0.152946  [44800/70468]
loss: 0.185504  [51200/70468]
loss: 0.137614  [57600/70468]
loss: 0.133120  [64000/70468]
loss: 0.190039  [70400/70468]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.130100 

Epoch 22
-------------------------------
loss: 0.134560  [    0/70468]
loss: 0.055163  [ 6400/70468]
loss: 0.153285  [12800/70468]
loss: 0.149780  [19200/70468]
loss: 0.047623  [25600/70468]
loss: 0.055672  [32000/70468]
loss: 0.090158  [38400/70468]
loss: 0.240480  [44800/70468]
loss: 0.157045  [51200/70468]
loss: 0.073920  [57600/70468]
loss: 0.113731  [64000/70468]
loss: 0.152277  [70400/70468]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.131807 

Epoch 23
-------------------------------
loss: 0.118319  [    0/70468]
loss: 0.085433  [ 6400/70468]
loss: 0.214029  [12800/70468]
loss: 0.099906  [19200/70468]
loss: 0.068349  [25600/70468]
loss: 0.134694  [32000/70468]
loss: 0.116367  [38400/70468]
loss: 0.244714  [44800/70468]
loss: 0.118323  [51200/70468]
loss: 0.264404  [57600/70468]
loss: 0.095285  [64000/70468]
loss: 0.083709  [70400/70468]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.145364 

Epoch 24
-------------------------------
loss: 0.209599  [    0/70468]
loss: 0.200715  [ 6400/70468]
loss: 0.144745  [12800/70468]
loss: 0.122081  [19200/70468]
loss: 0.161820  [25600/70468]
loss: 0.093297  [32000/70468]
loss: 0.128599  [38400/70468]
loss: 0.244861  [44800/70468]
loss: 0.251946  [51200/70468]
loss: 0.100108  [57600/70468]
loss: 0.137712  [64000/70468]
loss: 0.047674  [70400/70468]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.130614 

Epoch 25
-------------------------------
loss: 0.062135  [    0/70468]
loss: 0.231115  [ 6400/70468]
loss: 0.114340  [12800/70468]
loss: 0.080081  [19200/70468]
loss: 0.135061  [25600/70468]
loss: 0.104524  [32000/70468]
loss: 0.150980  [38400/70468]
loss: 0.267068  [44800/70468]
loss: 0.071638  [51200/70468]
loss: 0.249439  [57600/70468]
loss: 0.114347  [64000/70468]
loss: 0.213623  [70400/70468]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.139924 

Epoch 26
-------------------------------
loss: 0.090376  [    0/70468]
loss: 0.083190  [ 6400/70468]
loss: 0.219411  [12800/70468]
loss: 0.154685  [19200/70468]
loss: 0.099692  [25600/70468]
loss: 0.079045  [32000/70468]
loss: 0.118644  [38400/70468]
loss: 0.126734  [44800/70468]
loss: 0.139753  [51200/70468]
loss: 0.067053  [57600/70468]
loss: 0.138496  [64000/70468]
loss: 0.101107  [70400/70468]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.133752 

Epoch 27
-------------------------------
loss: 0.089678  [    0/70468]
loss: 0.168421  [ 6400/70468]
loss: 0.135122  [12800/70468]
loss: 0.128339  [19200/70468]
loss: 0.057227  [25600/70468]
loss: 0.073937  [32000/70468]
loss: 0.142559  [38400/70468]
loss: 0.104077  [44800/70468]
loss: 0.105351  [51200/70468]
loss: 0.225580  [57600/70468]
loss: 0.106472  [64000/70468]
loss: 0.151440  [70400/70468]
Test Error: 
 Accuracy: 91.1%, Avg loss: 0.195439 

Epoch 28
-------------------------------
loss: 0.204497  [    0/70468]
loss: 0.150795  [ 6400/70468]
loss: 0.117709  [12800/70468]
loss: 0.155279  [19200/70468]
loss: 0.175272  [25600/70468]
loss: 0.115151  [32000/70468]
loss: 0.202214  [38400/70468]
loss: 0.061861  [44800/70468]
loss: 0.131574  [51200/70468]
loss: 0.148556  [57600/70468]
loss: 0.145631  [64000/70468]
loss: 0.055085  [70400/70468]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.131233 

Epoch 29
-------------------------------
loss: 0.101200  [    0/70468]
loss: 0.029010  [ 6400/70468]
loss: 0.106597  [12800/70468]
loss: 0.262431  [19200/70468]
loss: 0.181423  [25600/70468]
loss: 0.180676  [32000/70468]
loss: 0.134181  [38400/70468]
loss: 0.192100  [44800/70468]
loss: 0.093853  [51200/70468]
loss: 0.112079  [57600/70468]
loss: 0.116953  [64000/70468]
loss: 0.318529  [70400/70468]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.145783 

Epoch 30
-------------------------------
loss: 0.096318  [    0/70468]
loss: 0.081228  [ 6400/70468]
loss: 0.174556  [12800/70468]
loss: 0.104997  [19200/70468]
loss: 0.071869  [25600/70468]
loss: 0.144495  [32000/70468]
loss: 0.054949  [38400/70468]
loss: 0.063748  [44800/70468]
loss: 0.220829  [51200/70468]
loss: 0.204711  [57600/70468]
loss: 0.127582  [64000/70468]
loss: 0.143640  [70400/70468]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.138493 

Epoch 31
-------------------------------
loss: 0.110960  [    0/70468]
loss: 0.067524  [ 6400/70468]
loss: 0.066031  [12800/70468]
loss: 0.105170  [19200/70468]
loss: 0.066737  [25600/70468]
loss: 0.251793  [32000/70468]
loss: 0.155136  [38400/70468]
loss: 0.135581  [44800/70468]
loss: 0.126824  [51200/70468]
loss: 0.119831  [57600/70468]
loss: 0.226937  [64000/70468]
loss: 0.156689  [70400/70468]
Test Error: 
 Accuracy: 85.5%, Avg loss: 0.368300 

Epoch 32
-------------------------------
loss: 0.307330  [    0/70468]
loss: 0.043244  [ 6400/70468]
loss: 0.126604  [12800/70468]
loss: 0.128998  [19200/70468]
loss: 0.150154  [25600/70468]
loss: 0.108369  [32000/70468]
loss: 0.068093  [38400/70468]
loss: 0.278489  [44800/70468]
loss: 0.167825  [51200/70468]
loss: 0.069187  [57600/70468]
loss: 0.091458  [64000/70468]
loss: 0.134290  [70400/70468]
Test Error: 
 Accuracy: 89.4%, Avg loss: 0.249226 

Epoch 33
-------------------------------
loss: 0.079903  [    0/70468]
loss: 0.163924  [ 6400/70468]
loss: 0.147514  [12800/70468]
loss: 0.163941  [19200/70468]
loss: 0.069971  [25600/70468]
loss: 0.284391  [32000/70468]
loss: 0.182229  [38400/70468]
loss: 0.172270  [44800/70468]
loss: 0.096712  [51200/70468]
loss: 0.071503  [57600/70468]
loss: 0.158485  [64000/70468]
loss: 0.130116  [70400/70468]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.142684 

Epoch 34
-------------------------------
loss: 0.025010  [    0/70468]
loss: 0.048575  [ 6400/70468]
loss: 0.096503  [12800/70468]
loss: 0.166727  [19200/70468]
loss: 0.226992  [25600/70468]
loss: 0.138115  [32000/70468]
loss: 0.115858  [38400/70468]
loss: 0.077893  [44800/70468]
loss: 0.166872  [51200/70468]
loss: 0.184579  [57600/70468]
loss: 0.113897  [64000/70468]
loss: 0.127860  [70400/70468]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.152437 

Epoch 35
-------------------------------
loss: 0.102372  [    0/70468]
loss: 0.102561  [ 6400/70468]
loss: 0.171340  [12800/70468]
loss: 0.155391  [19200/70468]
loss: 0.033438  [25600/70468]
loss: 0.152979  [32000/70468]
loss: 0.078720  [38400/70468]
loss: 0.071840  [44800/70468]
loss: 0.173695  [51200/70468]
loss: 0.135150  [57600/70468]
loss: 0.172026  [64000/70468]
loss: 0.264851  [70400/70468]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.133987 

Epoch 36
-------------------------------
loss: 0.165388  [    0/70468]
loss: 0.298050  [ 6400/70468]
loss: 0.085896  [12800/70468]
loss: 1.621153  [19200/70468]
loss: 0.090142  [25600/70468]
loss: 0.079912  [32000/70468]
loss: 0.171274  [38400/70468]
loss: 0.058232  [44800/70468]
loss: 0.132014  [51200/70468]
loss: 0.116052  [57600/70468]
loss: 0.132738  [64000/70468]
loss: 0.169119  [70400/70468]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.130359 

Epoch 37
-------------------------------
loss: 0.033763  [    0/70468]
loss: 0.078428  [ 6400/70468]
loss: 0.056067  [12800/70468]
loss: 0.073655  [19200/70468]
loss: 0.202084  [25600/70468]
loss: 0.135538  [32000/70468]
loss: 0.213182  [38400/70468]
loss: 0.101173  [44800/70468]
loss: 0.089136  [51200/70468]
loss: 0.136693  [57600/70468]
loss: 0.108564  [64000/70468]
loss: 0.148856  [70400/70468]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.148497 

Epoch 38
-------------------------------
loss: 0.092272  [    0/70468]
loss: 0.087583  [ 6400/70468]
loss: 0.265768  [12800/70468]
loss: 0.107245  [19200/70468]
loss: 0.173247  [25600/70468]
loss: 0.113979  [32000/70468]
loss: 0.106344  [38400/70468]
loss: 0.139835  [44800/70468]
loss: 0.099223  [51200/70468]
loss: 0.141066  [57600/70468]
loss: 0.059260  [64000/70468]
loss: 0.156292  [70400/70468]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.150620 

Epoch 39
-------------------------------
loss: 0.143979  [    0/70468]
loss: 0.084659  [ 6400/70468]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.165476 

Epoch 3
-------------------------------
loss: 0.076249  [    0/70723]
loss: 0.135685  [ 6400/70723]
loss: 0.163112  [12800/70723]
loss: 0.084427  [19200/70723]
loss: 0.117672  [25600/70723]
loss: 0.126912  [32000/70723]
loss: 0.104118  [38400/70723]
loss: 0.113483  [44800/70723]
loss: 0.125080  [51200/70723]
loss: 0.176300  [57600/70723]
loss: 0.137672  [64000/70723]
loss: 0.102508  [70400/70723]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.167568 

Epoch 4
-------------------------------
loss: 0.212291  [    0/70723]
loss: 0.044995  [ 6400/70723]
loss: 0.202086  [12800/70723]
loss: 0.099123  [19200/70723]
loss: 0.100256  [25600/70723]
loss: 0.059106  [32000/70723]
loss: 0.217125  [38400/70723]
loss: 0.077918  [44800/70723]
loss: 0.126089  [51200/70723]
loss: 0.173609  [57600/70723]
loss: 0.049795  [64000/70723]
loss: 0.221276  [70400/70723]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.148604 

Epoch 5
-------------------------------
loss: 0.074724  [    0/70723]
loss: 0.058923  [ 6400/70723]
loss: 0.116230  [12800/70723]
loss: 0.142437  [19200/70723]
loss: 0.192914  [25600/70723]
loss: 0.123291  [32000/70723]
loss: 0.102136  [38400/70723]
loss: 0.080916  [44800/70723]
loss: 0.042555  [51200/70723]
loss: 0.073050  [57600/70723]
loss: 0.211243  [64000/70723]
loss: 0.126405  [70400/70723]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.158608 

Epoch 6
-------------------------------
loss: 0.137334  [    0/70723]
loss: 0.166226  [ 6400/70723]
loss: 0.076281  [12800/70723]
loss: 0.126545  [19200/70723]
loss: 0.130599  [25600/70723]
loss: 0.016463  [32000/70723]
loss: 0.088338  [38400/70723]
loss: 0.042461  [44800/70723]
loss: 0.100629  [51200/70723]
loss: 0.096970  [57600/70723]
loss: 0.140114  [64000/70723]
loss: 0.121932  [70400/70723]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.160718 

Epoch 7
-------------------------------
loss: 0.087884  [    0/70723]
loss: 0.189572  [ 6400/70723]
loss: 0.107090  [12800/70723]
loss: 0.296266  [19200/70723]
loss: 0.142717  [25600/70723]
loss: 0.052090  [32000/70723]
loss: 0.329584  [38400/70723]
loss: 0.235737  [44800/70723]
loss: 0.115439  [51200/70723]
loss: 0.031927  [57600/70723]
loss: 0.089294  [64000/70723]
loss: 0.154664  [70400/70723]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.172285 

Epoch 8
-------------------------------
loss: 0.159302  [    0/70723]
loss: 0.070682  [ 6400/70723]
loss: 0.062987  [12800/70723]
loss: 0.115026  [19200/70723]
loss: 0.128555  [25600/70723]
loss: 0.246685  [32000/70723]
loss: 0.096537  [38400/70723]
loss: 0.153823  [44800/70723]
loss: 0.162825  [51200/70723]
loss: 0.118470  [57600/70723]
loss: 0.260278  [64000/70723]
loss: 0.114318  [70400/70723]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.143739 

Epoch 9
-------------------------------
loss: 0.111916  [    0/70723]
loss: 0.182397  [ 6400/70723]
loss: 0.174540  [12800/70723]
loss: 0.207674  [19200/70723]
loss: 0.130758  [25600/70723]
loss: 0.188460  [32000/70723]
loss: 0.031861  [38400/70723]
loss: 0.082083  [44800/70723]
loss: 0.073267  [51200/70723]
loss: 0.149597  [57600/70723]
loss: 0.079757  [64000/70723]
loss: 0.105128  [70400/70723]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.154545 

Epoch 10
-------------------------------
loss: 0.115820  [    0/70723]
loss: 1.713773  [ 6400/70723]
loss: 0.112764  [12800/70723]
loss: 0.048185  [19200/70723]
loss: 0.166863  [25600/70723]
loss: 0.227721  [32000/70723]
loss: 0.093960  [38400/70723]
loss: 0.136849  [44800/70723]
loss: 0.068575  [51200/70723]
loss: 0.119496  [57600/70723]
loss: 0.097941  [64000/70723]
loss: 0.105751  [70400/70723]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.167527 

Epoch 11
-------------------------------
loss: 0.060314  [    0/70723]
loss: 0.192798  [ 6400/70723]
loss: 0.222391  [12800/70723]
loss: 0.177790  [19200/70723]
loss: 0.071815  [25600/70723]
loss: 0.173306  [32000/70723]
loss: 0.173999  [38400/70723]
loss: 0.201088  [44800/70723]
loss: 0.115631  [51200/70723]
loss: 0.087653  [57600/70723]
loss: 0.169484  [64000/70723]
loss: 0.098119  [70400/70723]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.154167 

Epoch 12
-------------------------------
loss: 0.079678  [    0/70723]
loss: 0.089950  [ 6400/70723]
loss: 0.141694  [12800/70723]
loss: 0.105041  [19200/70723]
loss: 0.091071  [25600/70723]
loss: 0.178639  [32000/70723]
loss: 0.118074  [38400/70723]
loss: 0.056961  [44800/70723]
loss: 0.127135  [51200/70723]
loss: 0.138531  [57600/70723]
loss: 0.071497  [64000/70723]
loss: 0.134184  [70400/70723]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.139102 

Epoch 13
-------------------------------
loss: 0.039059  [    0/70723]
loss: 0.110199  [ 6400/70723]
loss: 0.055991  [12800/70723]
loss: 0.126314  [19200/70723]
loss: 0.100569  [25600/70723]
loss: 0.052249  [32000/70723]
loss: 0.159456  [38400/70723]
loss: 0.184406  [44800/70723]
loss: 0.049215  [51200/70723]
loss: 0.154963  [57600/70723]
loss: 0.087804  [64000/70723]
loss: 0.203191  [70400/70723]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.156180 

Epoch 14
-------------------------------
loss: 0.072180  [    0/70723]
loss: 0.118715  [ 6400/70723]
loss: 0.145410  [12800/70723]
loss: 0.204764  [19200/70723]
loss: 0.256569  [25600/70723]
loss: 0.040544  [32000/70723]
loss: 0.139085  [38400/70723]
loss: 0.079626  [44800/70723]
loss: 0.051151  [51200/70723]
loss: 0.072006  [57600/70723]
loss: 0.036320  [64000/70723]
loss: 0.108766  [70400/70723]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.142297 

Epoch 15
-------------------------------
loss: 0.099625  [    0/70723]
loss: 0.081875  [ 6400/70723]
loss: 0.100778  [12800/70723]
loss: 0.160939  [19200/70723]
loss: 0.069190  [25600/70723]
loss: 0.068453  [32000/70723]
loss: 0.087606  [38400/70723]
loss: 0.274980  [44800/70723]
loss: 0.071297  [51200/70723]
loss: 0.141997  [57600/70723]
loss: 0.094328  [64000/70723]
loss: 0.107774  [70400/70723]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.142046 

Epoch 16
-------------------------------
loss: 0.080655  [    0/70723]
loss: 0.099805  [ 6400/70723]
loss: 0.070010  [12800/70723]
loss: 0.053750  [19200/70723]
loss: 0.083442  [25600/70723]
loss: 0.177885  [32000/70723]
loss: 0.189544  [38400/70723]
loss: 0.107382  [44800/70723]
loss: 0.053895  [51200/70723]
loss: 0.162362  [57600/70723]
loss: 0.156515  [64000/70723]
loss: 0.149840  [70400/70723]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.151544 

Epoch 17
-------------------------------
loss: 0.137892  [    0/70723]
loss: 0.038192  [ 6400/70723]
loss: 0.088934  [12800/70723]
loss: 0.073249  [19200/70723]
loss: 0.146707  [25600/70723]
loss: 0.113389  [32000/70723]
loss: 0.135217  [38400/70723]
loss: 0.176303  [44800/70723]
loss: 0.180569  [51200/70723]
loss: 0.075783  [57600/70723]
loss: 0.063904  [64000/70723]
loss: 0.201275  [70400/70723]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.144138 

Epoch 18
-------------------------------
loss: 0.127241  [    0/70723]
loss: 0.081314  [ 6400/70723]
loss: 0.075631  [12800/70723]
loss: 0.148063  [19200/70723]
loss: 0.080508  [25600/70723]
loss: 0.044208  [32000/70723]
loss: 0.121247  [38400/70723]
loss: 0.038471  [44800/70723]
loss: 0.115572  [51200/70723]
loss: 0.103797  [57600/70723]
loss: 0.208771  [64000/70723]
loss: 1.721923  [70400/70723]
Test Error: 
 Accuracy: 80.7%, Avg loss: 1.276827 

Epoch 19
-------------------------------
loss: 0.550393  [    0/70723]
loss: 0.173247  [ 6400/70723]
loss: 0.056186  [12800/70723]
loss: 0.159599  [19200/70723]
loss: 0.107583  [25600/70723]
loss: 0.035962  [32000/70723]
loss: 0.082115  [38400/70723]
loss: 0.191017  [44800/70723]
loss: 0.069712  [51200/70723]
loss: 0.055669  [57600/70723]
loss: 0.121514  [64000/70723]
loss: 0.042376  [70400/70723]
Test Error: 
 Accuracy: 86.1%, Avg loss: 0.469702 

Epoch 20
-------------------------------
loss: 0.443787  [    0/70723]
loss: 0.116420  [ 6400/70723]
loss: 0.132954  [12800/70723]
loss: 0.070474  [19200/70723]
loss: 0.067659  [25600/70723]
loss: 0.067756  [32000/70723]
loss: 0.104852  [38400/70723]
loss: 0.113850  [44800/70723]
loss: 0.114364  [51200/70723]
loss: 0.123272  [57600/70723]
loss: 0.090970  [64000/70723]
loss: 0.177273  [70400/70723]
loss: 0.252748  [    0/69867]
loss: 0.172550  [ 6400/69867]
loss: 0.356052  [12800/69867]
loss: 0.302609  [19200/69867]
loss: 0.207493  [25600/69867]
loss: 0.235444  [32000/69867]
loss: 0.299577  [38400/69867]
loss: 0.197850  [44800/69867]
loss: 0.216791  [51200/69867]
loss: 0.216231  [57600/69867]
loss: 0.184508  [64000/69867]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.201342 

Epoch 4
-------------------------------
loss: 0.104363  [    0/69867]
loss: 0.170732  [ 6400/69867]
loss: 0.154888  [12800/69867]
loss: 0.282355  [19200/69867]
loss: 0.176186  [25600/69867]
loss: 0.275574  [32000/69867]
loss: 0.201730  [38400/69867]
loss: 0.168592  [44800/69867]
loss: 0.256929  [51200/69867]
loss: 0.137715  [57600/69867]
loss: 0.141520  [64000/69867]
Test Error: 
 Accuracy: 91.2%, Avg loss: 0.217688 

Epoch 5
-------------------------------
loss: 0.192248  [    0/69867]
loss: 0.296410  [ 6400/69867]
loss: 0.254786  [12800/69867]
loss: 0.296884  [19200/69867]
loss: 0.282593  [25600/69867]
loss: 0.195083  [32000/69867]
loss: 0.135522  [38400/69867]
loss: 0.253017  [44800/69867]
loss: 0.167872  [51200/69867]
loss: 0.244327  [57600/69867]
loss: 0.236548  [64000/69867]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.196045 

Epoch 6
-------------------------------
loss: 0.166516  [    0/69867]
loss: 0.237497  [ 6400/69867]
loss: 0.219332  [12800/69867]
loss: 0.193131  [19200/69867]
loss: 0.176415  [25600/69867]
loss: 0.151816  [32000/69867]
loss: 0.098546  [38400/69867]
loss: 0.250247  [44800/69867]
loss: 0.192236  [51200/69867]
loss: 0.138248  [57600/69867]
loss: 0.219708  [64000/69867]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.201970 

Epoch 7
-------------------------------
loss: 0.163769  [    0/69867]
loss: 0.193145  [ 6400/69867]
loss: 0.262326  [12800/69867]
loss: 0.134980  [19200/69867]
loss: 0.112844  [25600/69867]
loss: 0.140707  [32000/69867]
loss: 0.244811  [38400/69867]
loss: 0.131793  [44800/69867]
loss: 0.238124  [51200/69867]
loss: 0.277488  [57600/69867]
loss: 0.175425  [64000/69867]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.184408 

Epoch 8
-------------------------------
loss: 0.207737  [    0/69867]
loss: 0.172269  [ 6400/69867]
loss: 0.181734  [12800/69867]
loss: 0.146763  [19200/69867]
loss: 0.184381  [25600/69867]
loss: 0.194970  [32000/69867]
loss: 0.305267  [38400/69867]
loss: 0.437968  [44800/69867]
loss: 0.249992  [51200/69867]
loss: 0.264923  [57600/69867]
loss: 0.138460  [64000/69867]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.186836 

Epoch 9
-------------------------------
loss: 0.203390  [    0/69867]
loss: 0.303333  [ 6400/69867]
loss: 0.103185  [12800/69867]
loss: 0.153524  [19200/69867]
loss: 0.201939  [25600/69867]
loss: 0.227515  [32000/69867]
loss: 0.197022  [38400/69867]
loss: 0.281598  [44800/69867]
loss: 0.196473  [51200/69867]
loss: 0.175693  [57600/69867]
loss: 0.308129  [64000/69867]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.179127 

Epoch 10
-------------------------------
loss: 0.193432  [    0/69867]
loss: 0.123270  [ 6400/69867]
loss: 0.095569  [12800/69867]
loss: 0.224001  [19200/69867]
loss: 0.163364  [25600/69867]
loss: 0.129493  [32000/69867]
loss: 0.270112  [38400/69867]
loss: 0.281736  [44800/69867]
loss: 0.227466  [51200/69867]
loss: 0.150229  [57600/69867]
loss: 0.198786  [64000/69867]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.199351 

Epoch 11
-------------------------------
loss: 0.192838  [    0/69867]
loss: 0.145727  [ 6400/69867]
loss: 0.139140  [12800/69867]
loss: 0.286960  [19200/69867]
loss: 0.217506  [25600/69867]
loss: 0.229404  [32000/69867]
loss: 0.177089  [38400/69867]
loss: 0.168672  [44800/69867]
loss: 0.159074  [51200/69867]
loss: 0.167868  [57600/69867]
loss: 0.248127  [64000/69867]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.183096 

Epoch 12
-------------------------------
loss: 0.120944  [    0/69867]
loss: 0.231040  [ 6400/69867]
loss: 0.215430  [12800/69867]
loss: 0.198144  [19200/69867]
loss: 0.388611  [25600/69867]
loss: 0.179119  [32000/69867]
loss: 0.207512  [38400/69867]
loss: 0.309611  [44800/69867]
loss: 0.250231  [51200/69867]
loss: 0.158040  [57600/69867]
loss: 0.210381  [64000/69867]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.209427 

Epoch 13
-------------------------------
loss: 0.194721  [    0/69867]
loss: 0.170122  [ 6400/69867]
loss: 0.247587  [12800/69867]
loss: 0.107890  [19200/69867]
loss: 0.286768  [25600/69867]
loss: 0.165669  [32000/69867]
loss: 0.276486  [38400/69867]
loss: 0.170462  [44800/69867]
loss: 0.088702  [51200/69867]
loss: 0.215522  [57600/69867]
loss: 0.155946  [64000/69867]
Test Error: 
 Accuracy: 91.2%, Avg loss: 0.206972 

Epoch 14
-------------------------------
loss: 0.128602  [    0/69867]
loss: 0.219475  [ 6400/69867]
loss: 0.222529  [12800/69867]
loss: 0.293487  [19200/69867]
loss: 0.179817  [25600/69867]
loss: 0.107398  [32000/69867]
loss: 0.172254  [38400/69867]
loss: 0.157059  [44800/69867]
loss: 0.192987  [51200/69867]
loss: 0.099955  [57600/69867]
loss: 0.154954  [64000/69867]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.183193 

Epoch 15
-------------------------------
loss: 0.265961  [    0/69867]
loss: 0.184396  [ 6400/69867]
loss: 0.110926  [12800/69867]
loss: 0.326481  [19200/69867]
loss: 0.114095  [25600/69867]
loss: 0.219894  [32000/69867]
loss: 0.214944  [38400/69867]
loss: 0.221825  [44800/69867]
loss: 0.194553  [51200/69867]
loss: 0.260948  [57600/69867]
loss: 0.132293  [64000/69867]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.178493 

Epoch 16
-------------------------------
loss: 0.192499  [    0/69867]
loss: 0.184571  [ 6400/69867]
loss: 0.216128  [12800/69867]
loss: 0.293078  [19200/69867]
loss: 0.195551  [25600/69867]
loss: 0.146015  [32000/69867]
loss: 0.192077  [38400/69867]
loss: 0.178217  [44800/69867]
loss: 0.393812  [51200/69867]
loss: 0.121315  [57600/69867]
loss: 0.092402  [64000/69867]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.194191 

Epoch 17
-------------------------------
loss: 0.259697  [    0/69867]
loss: 0.197682  [ 6400/69867]
loss: 0.154415  [12800/69867]
loss: 0.153122  [19200/69867]
loss: 0.179931  [25600/69867]
loss: 0.176710  [32000/69867]
loss: 0.204722  [38400/69867]
loss: 0.157965  [44800/69867]
loss: 0.208742  [51200/69867]
loss: 0.251085  [57600/69867]
loss: 0.188397  [64000/69867]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.175603 

Epoch 18
-------------------------------
loss: 0.207541  [    0/69867]
loss: 0.195171  [ 6400/69867]
loss: 0.081304  [12800/69867]
loss: 0.134435  [19200/69867]
loss: 0.147269  [25600/69867]
loss: 0.188467  [32000/69867]
loss: 0.223644  [38400/69867]
loss: 0.207206  [44800/69867]
loss: 0.110331  [51200/69867]
loss: 0.235370  [57600/69867]
loss: 0.195867  [64000/69867]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.207226 

Epoch 19
-------------------------------
loss: 0.157215  [    0/69867]
loss: 0.256826  [ 6400/69867]
loss: 0.155802  [12800/69867]
loss: 0.237281  [19200/69867]
loss: 0.234037  [25600/69867]
loss: 0.097255  [32000/69867]
loss: 0.133842  [38400/69867]
loss: 0.113545  [44800/69867]
loss: 0.256926  [51200/69867]
loss: 0.202001  [57600/69867]
loss: 0.199395  [64000/69867]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.188901 

Epoch 20
-------------------------------
loss: 0.269303  [    0/69867]
loss: 0.225196  [ 6400/69867]
loss: 0.198228  [12800/69867]
loss: 0.244235  [19200/69867]
loss: 0.228637  [25600/69867]
loss: 0.277314  [32000/69867]
loss: 0.103776  [38400/69867]
loss: 0.179414  [44800/69867]
loss: 0.175429  [51200/69867]
loss: 0.148254  [57600/69867]
loss: 0.142756  [64000/69867]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.183437 

Epoch 21
-------------------------------
loss: 0.095299  [    0/69867]
loss: 0.187763  [ 6400/69867]
loss: 0.322339  [12800/69867]
loss: 0.280163  [19200/69867]
loss: 0.196360  [25600/69867]
loss: 0.116959  [32000/69867]
loss: 0.176403  [38400/69867]
loss: 0.280813  [44800/69867]
loss: 0.156295  [51200/69867]
loss: 0.129331  [57600/69867]
loss: 0.272157  [64000/69867]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.198532 

Epoch 22
-------------------------------
loss: 0.243697  [    0/69867]
loss: 0.212656  [ 6400/69867]
loss: 0.093476  [12800/69867]
loss: 0.298228  [19200/69867]
loss: 0.067382  [25600/69867]
loss: 0.264303  [64000/69926]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.174459 

Epoch 7
-------------------------------
loss: 0.141753  [    0/69926]
loss: 0.232117  [ 6400/69926]
loss: 0.129917  [12800/69926]
loss: 1.688230  [19200/69926]
loss: 0.218758  [25600/69926]
loss: 0.214091  [32000/69926]
loss: 0.210215  [38400/69926]
loss: 0.155102  [44800/69926]
loss: 0.136606  [51200/69926]
loss: 0.067568  [57600/69926]
loss: 0.233959  [64000/69926]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.185950 

Epoch 8
-------------------------------
loss: 0.121769  [    0/69926]
loss: 0.170629  [ 6400/69926]
loss: 0.199228  [12800/69926]
loss: 0.257755  [19200/69926]
loss: 1.697683  [25600/69926]
loss: 0.209966  [32000/69926]
loss: 0.238164  [38400/69926]
loss: 0.282123  [44800/69926]
loss: 0.165398  [51200/69926]
loss: 0.115934  [57600/69926]
loss: 0.234385  [64000/69926]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.183537 

Epoch 9
-------------------------------
loss: 0.078837  [    0/69926]
loss: 0.246546  [ 6400/69926]
loss: 0.105120  [12800/69926]
loss: 0.224325  [19200/69926]
loss: 0.144805  [25600/69926]
loss: 0.143234  [32000/69926]
loss: 0.186155  [38400/69926]
loss: 0.145734  [44800/69926]
loss: 0.211491  [51200/69926]
loss: 0.097903  [57600/69926]
loss: 0.095627  [64000/69926]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171103 

Epoch 10
-------------------------------
loss: 0.219922  [    0/69926]
loss: 0.095482  [ 6400/69926]
loss: 0.086712  [12800/69926]
loss: 0.253635  [19200/69926]
loss: 0.182204  [25600/69926]
loss: 0.144988  [32000/69926]
loss: 0.176679  [38400/69926]
loss: 0.214165  [44800/69926]
loss: 0.108898  [51200/69926]
loss: 0.116564  [57600/69926]
loss: 0.230992  [64000/69926]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.172336 

Epoch 11
-------------------------------
loss: 0.228904  [    0/69926]
loss: 0.064616  [ 6400/69926]
loss: 0.232459  [12800/69926]
loss: 0.131376  [19200/69926]
loss: 0.088205  [25600/69926]
loss: 0.152063  [32000/69926]
loss: 0.149820  [38400/69926]
loss: 0.167976  [44800/69926]
loss: 0.130469  [51200/69926]
loss: 0.076768  [57600/69926]
loss: 0.111265  [64000/69926]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173869 

Epoch 12
-------------------------------
loss: 0.179835  [    0/69926]
loss: 0.050025  [ 6400/69926]
loss: 0.099580  [12800/69926]
loss: 0.149282  [19200/69926]
loss: 0.098007  [25600/69926]
loss: 0.132464  [32000/69926]
loss: 0.192160  [38400/69926]
loss: 0.130583  [44800/69926]
loss: 0.163914  [51200/69926]
loss: 0.160787  [57600/69926]
loss: 0.243444  [64000/69926]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.167956 

Epoch 13
-------------------------------
loss: 0.182239  [    0/69926]
loss: 0.199237  [ 6400/69926]
loss: 0.091195  [12800/69926]
loss: 0.103675  [19200/69926]
loss: 0.167767  [25600/69926]
loss: 1.721998  [32000/69926]
loss: 0.141387  [38400/69926]
loss: 0.193263  [44800/69926]
loss: 0.139780  [51200/69926]
loss: 0.090698  [57600/69926]
loss: 0.123992  [64000/69926]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.175391 

Epoch 14
-------------------------------
loss: 0.116614  [    0/69926]
loss: 0.118573  [ 6400/69926]
loss: 0.080585  [12800/69926]
loss: 0.177683  [19200/69926]
loss: 0.135678  [25600/69926]
loss: 0.254954  [32000/69926]
loss: 0.101801  [38400/69926]
loss: 0.158307  [44800/69926]
loss: 0.152127  [51200/69926]
loss: 0.162345  [57600/69926]
loss: 0.091954  [64000/69926]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.172897 

Epoch 15
-------------------------------
loss: 0.069345  [    0/69926]
loss: 0.147663  [ 6400/69926]
loss: 0.137159  [12800/69926]
loss: 0.205463  [19200/69926]
loss: 0.058628  [25600/69926]
loss: 0.090492  [32000/69926]
loss: 0.124052  [38400/69926]
loss: 0.271472  [44800/69926]
loss: 0.094136  [51200/69926]
loss: 0.152928  [57600/69926]
loss: 0.108408  [64000/69926]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.172787 

Epoch 16
-------------------------------
loss: 0.178562  [    0/69926]
loss: 0.202319  [ 6400/69926]
loss: 0.141738  [12800/69926]
loss: 0.174445  [19200/69926]
loss: 0.097936  [25600/69926]
loss: 0.098684  [32000/69926]
loss: 0.081987  [38400/69926]
loss: 0.170401  [44800/69926]
loss: 0.176378  [51200/69926]
loss: 0.322555  [57600/69926]
loss: 0.110755  [64000/69926]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.164090 

Epoch 17
-------------------------------
loss: 0.114866  [    0/69926]
loss: 0.144929  [ 6400/69926]
loss: 0.298819  [12800/69926]
loss: 0.099368  [19200/69926]
loss: 0.274494  [25600/69926]
loss: 0.088838  [32000/69926]
loss: 0.155723  [38400/69926]
loss: 0.216679  [44800/69926]
loss: 0.070758  [51200/69926]
loss: 0.123914  [57600/69926]
loss: 0.100463  [64000/69926]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.161539 

Epoch 18
-------------------------------
loss: 0.199680  [    0/69926]
loss: 0.044298  [ 6400/69926]
loss: 0.069502  [12800/69926]
loss: 0.103462  [19200/69926]
loss: 0.187530  [25600/69926]
loss: 0.102887  [32000/69926]
loss: 0.102297  [38400/69926]
loss: 0.118285  [44800/69926]
loss: 0.247719  [51200/69926]
loss: 0.119864  [57600/69926]
loss: 0.078117  [64000/69926]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.164926 

Epoch 19
-------------------------------
loss: 0.092112  [    0/69926]
loss: 0.090519  [ 6400/69926]
loss: 0.131475  [12800/69926]
loss: 0.248802  [19200/69926]
loss: 0.208249  [25600/69926]
loss: 0.100256  [32000/69926]
loss: 0.132786  [38400/69926]
loss: 0.139131  [44800/69926]
loss: 0.196100  [51200/69926]
loss: 0.107445  [57600/69926]
loss: 0.156150  [64000/69926]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.163215 

Epoch 20
-------------------------------
loss: 0.149707  [    0/69926]
loss: 0.093118  [ 6400/69926]
loss: 0.221497  [12800/69926]
loss: 0.072797  [19200/69926]
loss: 0.125661  [25600/69926]
loss: 0.204280  [32000/69926]
loss: 0.227001  [38400/69926]
loss: 0.111655  [44800/69926]
loss: 0.086743  [51200/69926]
loss: 0.215172  [57600/69926]
loss: 0.178125  [64000/69926]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.163458 

Epoch 21
-------------------------------
loss: 0.100004  [    0/69926]
loss: 0.184150  [ 6400/69926]
loss: 0.190729  [12800/69926]
loss: 0.168797  [19200/69926]
loss: 0.243543  [25600/69926]
loss: 0.144657  [32000/69926]
loss: 0.049794  [38400/69926]
loss: 0.129620  [44800/69926]
loss: 0.162967  [51200/69926]
loss: 0.090903  [57600/69926]
loss: 0.087676  [64000/69926]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.162685 

Epoch 22
-------------------------------
loss: 0.101518  [    0/69926]
loss: 0.143976  [ 6400/69926]
loss: 0.194896  [12800/69926]
loss: 0.103090  [19200/69926]
loss: 0.137881  [25600/69926]
loss: 0.094651  [32000/69926]
loss: 0.179078  [38400/69926]
loss: 0.160861  [44800/69926]
loss: 0.131444  [51200/69926]
loss: 0.140725  [57600/69926]
loss: 0.151821  [64000/69926]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.182464 

Epoch 23
-------------------------------
loss: 0.109200  [    0/69926]
loss: 0.077646  [ 6400/69926]
loss: 0.103597  [12800/69926]
loss: 0.150932  [19200/69926]
loss: 0.085685  [25600/69926]
loss: 0.134757  [32000/69926]
loss: 0.153329  [38400/69926]
loss: 0.083051  [44800/69926]
loss: 0.078049  [51200/69926]
loss: 0.137965  [57600/69926]
loss: 0.158836  [64000/69926]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.171394 

Epoch 24
-------------------------------
loss: 0.127345  [    0/69926]
loss: 0.257831  [ 6400/69926]
loss: 0.087433  [12800/69926]
loss: 0.160828  [19200/69926]
loss: 0.105720  [25600/69926]
loss: 0.182511  [32000/69926]
loss: 0.128702  [38400/69926]
loss: 0.234984  [44800/69926]
loss: 0.077207  [51200/69926]
loss: 0.219060  [57600/69926]
loss: 0.148066  [64000/69926]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.161153 

Epoch 25
-------------------------------
loss: 0.098760  [    0/69926]
loss: 1.669526  [ 6400/69926]
loss: 0.217496  [12800/69926]
loss: 0.222522  [19200/69926]
loss: 1.708011  [25600/69926]
loss: 0.051306  [32000/69926]
loss: 0.148577  [38400/69926]
loss: 1.715570  [44800/69926]
loss: 0.128398  [51200/69926]
loss: 0.170133  [57600/69926]
loss: 0.201090  [64000/69926]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.177601 

Epoch 26
-------------------------------
loss: 0.121630  [    0/69926]
loss: 0.272075  [    0/70204]
loss: 0.132066  [ 6400/70204]
loss: 0.283867  [12800/70204]
loss: 0.167907  [19200/70204]
loss: 0.311245  [25600/70204]
loss: 0.158929  [32000/70204]
loss: 0.130375  [38400/70204]
loss: 0.266342  [44800/70204]
loss: 0.186598  [51200/70204]
loss: 0.226635  [57600/70204]
loss: 0.356017  [64000/70204]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.212897 

Epoch 4
-------------------------------
loss: 0.254437  [    0/70204]
loss: 0.173553  [ 6400/70204]
loss: 0.189490  [12800/70204]
loss: 0.197013  [19200/70204]
loss: 0.145461  [25600/70204]
loss: 0.175338  [32000/70204]
loss: 0.238087  [38400/70204]
loss: 0.282901  [44800/70204]
loss: 0.089132  [51200/70204]
loss: 0.159598  [57600/70204]
loss: 0.193227  [64000/70204]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.213040 

Epoch 5
-------------------------------
loss: 0.305874  [    0/70204]
loss: 0.343663  [ 6400/70204]
loss: 0.264172  [12800/70204]
loss: 0.132814  [19200/70204]
loss: 0.288411  [25600/70204]
loss: 0.195557  [32000/70204]
loss: 0.292192  [38400/70204]
loss: 0.157919  [44800/70204]
loss: 0.221447  [51200/70204]
loss: 0.241969  [57600/70204]
loss: 0.331648  [64000/70204]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.195778 

Epoch 6
-------------------------------
loss: 0.230490  [    0/70204]
loss: 0.113065  [ 6400/70204]
loss: 0.124271  [12800/70204]
loss: 0.244736  [19200/70204]
loss: 0.080003  [25600/70204]
loss: 0.218115  [32000/70204]
loss: 0.310008  [38400/70204]
loss: 0.137050  [44800/70204]
loss: 0.147513  [51200/70204]
loss: 0.184777  [57600/70204]
loss: 0.158819  [64000/70204]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.201815 

Epoch 7
-------------------------------
loss: 0.106964  [    0/70204]
loss: 0.189218  [ 6400/70204]
loss: 0.153670  [12800/70204]
loss: 0.263598  [19200/70204]
loss: 0.134591  [25600/70204]
loss: 0.135105  [32000/70204]
loss: 0.201833  [38400/70204]
loss: 0.107358  [44800/70204]
loss: 0.183583  [51200/70204]
loss: 0.228161  [57600/70204]
loss: 0.131495  [64000/70204]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.183223 

Epoch 8
-------------------------------
loss: 0.241914  [    0/70204]
loss: 0.241536  [ 6400/70204]
loss: 0.178430  [12800/70204]
loss: 0.284449  [19200/70204]
loss: 0.133855  [25600/70204]
loss: 0.317316  [32000/70204]
loss: 0.158283  [38400/70204]
loss: 0.106741  [44800/70204]
loss: 0.138079  [51200/70204]
loss: 0.165291  [57600/70204]
loss: 0.170219  [64000/70204]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.186308 

Epoch 9
-------------------------------
loss: 0.145138  [    0/70204]
loss: 0.169839  [ 6400/70204]
loss: 0.189242  [12800/70204]
loss: 0.172164  [19200/70204]
loss: 0.153210  [25600/70204]
loss: 0.089303  [32000/70204]
loss: 0.180336  [38400/70204]
loss: 0.279289  [44800/70204]
loss: 0.234941  [51200/70204]
loss: 0.084297  [57600/70204]
loss: 0.170992  [64000/70204]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.181314 

Epoch 10
-------------------------------
loss: 0.329493  [    0/70204]
loss: 0.090409  [ 6400/70204]
loss: 0.186686  [12800/70204]
loss: 0.153687  [19200/70204]
loss: 0.218998  [25600/70204]
loss: 0.178764  [32000/70204]
loss: 0.214998  [38400/70204]
loss: 0.061131  [44800/70204]
loss: 0.129991  [51200/70204]
loss: 0.103297  [57600/70204]
loss: 0.340328  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174592 

Epoch 11
-------------------------------
loss: 0.162330  [    0/70204]
loss: 0.078033  [ 6400/70204]
loss: 0.101924  [12800/70204]
loss: 0.102272  [19200/70204]
loss: 0.248237  [25600/70204]
loss: 0.171668  [32000/70204]
loss: 0.109379  [38400/70204]
loss: 0.109641  [44800/70204]
loss: 1.761468  [51200/70204]
loss: 0.264804  [57600/70204]
loss: 0.188102  [64000/70204]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.178536 

Epoch 12
-------------------------------
loss: 0.090848  [    0/70204]
loss: 0.122575  [ 6400/70204]
loss: 0.206849  [12800/70204]
loss: 0.384964  [19200/70204]
loss: 0.120920  [25600/70204]
loss: 0.135319  [32000/70204]
loss: 0.163698  [38400/70204]
loss: 0.318615  [44800/70204]
loss: 0.183910  [51200/70204]
loss: 0.094017  [57600/70204]
loss: 0.111970  [64000/70204]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.177003 

Epoch 13
-------------------------------
loss: 0.153126  [    0/70204]
loss: 0.180936  [ 6400/70204]
loss: 0.268784  [12800/70204]
loss: 0.252283  [19200/70204]
loss: 0.128770  [25600/70204]
loss: 0.183681  [32000/70204]
loss: 0.134858  [38400/70204]
loss: 0.150963  [44800/70204]
loss: 0.096653  [51200/70204]
loss: 0.219073  [57600/70204]
loss: 0.135142  [64000/70204]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.181735 

Epoch 14
-------------------------------
loss: 0.172592  [    0/70204]
loss: 0.257769  [ 6400/70204]
loss: 0.089675  [12800/70204]
loss: 0.130165  [19200/70204]
loss: 0.213356  [25600/70204]
loss: 0.214726  [32000/70204]
loss: 0.182289  [38400/70204]
loss: 0.219571  [44800/70204]
loss: 0.088506  [51200/70204]
loss: 0.101573  [57600/70204]
loss: 0.053273  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.176793 

Epoch 15
-------------------------------
loss: 0.114952  [    0/70204]
loss: 0.181545  [ 6400/70204]
loss: 0.151776  [12800/70204]
loss: 0.106146  [19200/70204]
loss: 0.232350  [25600/70204]
loss: 0.126691  [32000/70204]
loss: 0.185908  [38400/70204]
loss: 0.248460  [44800/70204]
loss: 0.186558  [51200/70204]
loss: 0.106098  [57600/70204]
loss: 0.176695  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.181052 

Epoch 16
-------------------------------
loss: 0.164723  [    0/70204]
loss: 0.180091  [ 6400/70204]
loss: 0.310405  [12800/70204]
loss: 0.112846  [19200/70204]
loss: 0.210275  [25600/70204]
loss: 0.096415  [32000/70204]
loss: 0.161760  [38400/70204]
loss: 0.217199  [44800/70204]
loss: 0.147957  [51200/70204]
loss: 0.167728  [57600/70204]
loss: 0.198591  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.178519 

Epoch 17
-------------------------------
loss: 0.068005  [    0/70204]
loss: 0.326530  [ 6400/70204]
loss: 0.129847  [12800/70204]
loss: 0.075845  [19200/70204]
loss: 0.248233  [25600/70204]
loss: 0.097890  [32000/70204]
loss: 0.088109  [38400/70204]
loss: 0.203286  [44800/70204]
loss: 0.150808  [51200/70204]
loss: 0.150516  [57600/70204]
loss: 0.120487  [64000/70204]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.176356 

Epoch 18
-------------------------------
loss: 0.206929  [    0/70204]
loss: 0.183866  [ 6400/70204]
loss: 0.209658  [12800/70204]
loss: 0.100136  [19200/70204]
loss: 0.179374  [25600/70204]
loss: 0.118895  [32000/70204]
loss: 0.125452  [38400/70204]
loss: 0.197472  [44800/70204]
loss: 0.156521  [51200/70204]
loss: 0.194353  [57600/70204]
loss: 0.271880  [64000/70204]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.183418 

Epoch 19
-------------------------------
loss: 0.346905  [    0/70204]
loss: 0.084223  [ 6400/70204]
loss: 0.157381  [12800/70204]
loss: 0.130778  [19200/70204]
loss: 0.137116  [25600/70204]
loss: 0.106720  [32000/70204]
loss: 0.197954  [38400/70204]
loss: 0.150620  [44800/70204]
loss: 0.194316  [51200/70204]
loss: 0.165554  [57600/70204]
loss: 0.201364  [64000/70204]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.201215 

Epoch 20
-------------------------------
loss: 0.316781  [    0/70204]
loss: 0.265458  [ 6400/70204]
loss: 0.102631  [12800/70204]
loss: 0.184953  [19200/70204]
loss: 0.184202  [25600/70204]
loss: 0.100017  [32000/70204]
loss: 0.240012  [38400/70204]
loss: 0.120184  [44800/70204]
loss: 0.246615  [51200/70204]
loss: 0.307031  [57600/70204]
loss: 0.072612  [64000/70204]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.178942 

Epoch 21
-------------------------------
loss: 0.216430  [    0/70204]
loss: 0.171939  [ 6400/70204]
loss: 0.070451  [12800/70204]
loss: 0.248999  [19200/70204]
loss: 0.068807  [25600/70204]
loss: 0.129611  [32000/70204]
loss: 0.064918  [38400/70204]
loss: 0.165047  [44800/70204]
loss: 0.175881  [51200/70204]
loss: 0.278016  [57600/70204]
loss: 0.168974  [64000/70204]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.174626 

Epoch 22
-------------------------------
loss: 0.082004  [    0/70204]
loss: 0.164490  [ 6400/70204]
loss: 0.151287  [12800/70204]
loss: 0.093828  [19200/70204]
loss: 0.114041  [25600/70204]
loss: 0.136870  [57600/70326]
loss: 0.209895  [64000/70326]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.206554 

Epoch 7
-------------------------------
loss: 0.161897  [    0/70326]
loss: 0.160491  [ 6400/70326]
loss: 0.175676  [12800/70326]
loss: 0.257646  [19200/70326]
loss: 0.135261  [25600/70326]
loss: 0.149978  [32000/70326]
loss: 0.201573  [38400/70326]
loss: 0.126156  [44800/70326]
loss: 0.158518  [51200/70326]
loss: 0.185189  [57600/70326]
loss: 0.208965  [64000/70326]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.207607 

Epoch 8
-------------------------------
loss: 0.146466  [    0/70326]
loss: 1.793823  [ 6400/70326]
loss: 0.234440  [12800/70326]
loss: 0.098034  [19200/70326]
loss: 0.171330  [25600/70326]
loss: 0.090734  [32000/70326]
loss: 0.206801  [38400/70326]
loss: 0.175951  [44800/70326]
loss: 0.133050  [51200/70326]
loss: 0.396610  [57600/70326]
loss: 0.144286  [64000/70326]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.201965 

Epoch 9
-------------------------------
loss: 0.088397  [    0/70326]
loss: 0.132768  [ 6400/70326]
loss: 0.123901  [12800/70326]
loss: 0.105206  [19200/70326]
loss: 0.094551  [25600/70326]
loss: 0.153866  [32000/70326]
loss: 0.175136  [38400/70326]
loss: 0.165297  [44800/70326]
loss: 0.194722  [51200/70326]
loss: 0.160889  [57600/70326]
loss: 0.138218  [64000/70326]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.200051 

Epoch 10
-------------------------------
loss: 0.293487  [    0/70326]
loss: 0.150266  [ 6400/70326]
loss: 0.180616  [12800/70326]
loss: 0.145120  [19200/70326]
loss: 0.100268  [25600/70326]
loss: 0.190959  [32000/70326]
loss: 0.161786  [38400/70326]
loss: 0.156778  [44800/70326]
loss: 0.309105  [51200/70326]
loss: 0.178616  [57600/70326]
loss: 0.169185  [64000/70326]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.203034 

Epoch 11
-------------------------------
loss: 0.143268  [    0/70326]
loss: 0.064811  [ 6400/70326]
loss: 0.180980  [12800/70326]
loss: 0.143011  [19200/70326]
loss: 0.095264  [25600/70326]
loss: 0.207110  [32000/70326]
loss: 0.267871  [38400/70326]
loss: 0.221095  [44800/70326]
loss: 0.263579  [51200/70326]
loss: 1.712203  [57600/70326]
loss: 0.168416  [64000/70326]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.192088 

Epoch 12
-------------------------------
loss: 0.315612  [    0/70326]
loss: 0.076507  [ 6400/70326]
loss: 0.074082  [12800/70326]
loss: 0.084882  [19200/70326]
loss: 1.643911  [25600/70326]
loss: 0.185149  [32000/70326]
loss: 0.105243  [38400/70326]
loss: 0.108779  [44800/70326]
loss: 0.100031  [51200/70326]
loss: 0.041509  [57600/70326]
loss: 0.159505  [64000/70326]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.183876 

Epoch 13
-------------------------------
loss: 0.205948  [    0/70326]
loss: 0.204952  [ 6400/70326]
loss: 0.101107  [12800/70326]
loss: 1.690311  [19200/70326]
loss: 0.207138  [25600/70326]
loss: 0.105816  [32000/70326]
loss: 0.096004  [38400/70326]
loss: 0.193535  [44800/70326]
loss: 0.190778  [51200/70326]
loss: 0.205089  [57600/70326]
loss: 0.195984  [64000/70326]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.185836 

Epoch 14
-------------------------------
loss: 0.120300  [    0/70326]
loss: 0.134491  [ 6400/70326]
loss: 0.236049  [12800/70326]
loss: 0.038933  [19200/70326]
loss: 0.213086  [25600/70326]
loss: 0.134982  [32000/70326]
loss: 0.391269  [38400/70326]
loss: 0.122732  [44800/70326]
loss: 0.145276  [51200/70326]
loss: 0.176356  [57600/70326]
loss: 0.170505  [64000/70326]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.180761 

Epoch 15
-------------------------------
loss: 0.062135  [    0/70326]
loss: 0.099399  [ 6400/70326]
loss: 0.173306  [12800/70326]
loss: 0.051089  [19200/70326]
loss: 0.134603  [25600/70326]
loss: 0.091111  [32000/70326]
loss: 0.178787  [38400/70326]
loss: 0.082306  [44800/70326]
loss: 1.741852  [51200/70326]
loss: 0.138284  [57600/70326]
loss: 0.104779  [64000/70326]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.184128 

Epoch 16
-------------------------------
loss: 0.136662  [    0/70326]
loss: 0.223119  [ 6400/70326]
loss: 0.213004  [12800/70326]
loss: 0.152456  [19200/70326]
loss: 0.166259  [25600/70326]
loss: 0.065104  [32000/70326]
loss: 0.167980  [38400/70326]
loss: 0.231880  [44800/70326]
loss: 0.100219  [51200/70326]
loss: 0.217140  [57600/70326]
loss: 0.178663  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.179377 

Epoch 17
-------------------------------
loss: 0.082440  [    0/70326]
loss: 0.122612  [ 6400/70326]
loss: 0.150049  [12800/70326]
loss: 0.133960  [19200/70326]
loss: 0.126570  [25600/70326]
loss: 0.218550  [32000/70326]
loss: 0.087976  [38400/70326]
loss: 0.141039  [44800/70326]
loss: 0.157734  [51200/70326]
loss: 0.218042  [57600/70326]
loss: 0.120293  [64000/70326]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.186073 

Epoch 18
-------------------------------
loss: 0.076060  [    0/70326]
loss: 0.246573  [ 6400/70326]
loss: 0.174287  [12800/70326]
loss: 0.114792  [19200/70326]
loss: 0.186295  [25600/70326]
loss: 0.252176  [32000/70326]
loss: 0.218485  [38400/70326]
loss: 0.110691  [44800/70326]
loss: 0.185086  [51200/70326]
loss: 0.159231  [57600/70326]
loss: 0.090182  [64000/70326]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.183105 

Epoch 19
-------------------------------
loss: 0.243437  [    0/70326]
loss: 0.137907  [ 6400/70326]
loss: 0.127333  [12800/70326]
loss: 0.123624  [19200/70326]
loss: 0.184657  [25600/70326]
loss: 0.225585  [32000/70326]
loss: 0.169069  [38400/70326]
loss: 0.079159  [44800/70326]
loss: 0.109422  [51200/70326]
loss: 0.114077  [57600/70326]
loss: 0.129329  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.177630 

Epoch 20
-------------------------------
loss: 0.123070  [    0/70326]
loss: 0.141988  [ 6400/70326]
loss: 0.128202  [12800/70326]
loss: 0.110352  [19200/70326]
loss: 0.206482  [25600/70326]
loss: 0.220227  [32000/70326]
loss: 0.161838  [38400/70326]
loss: 0.112340  [44800/70326]
loss: 0.226698  [51200/70326]
loss: 0.315466  [57600/70326]
loss: 0.096367  [64000/70326]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.183582 

Epoch 21
-------------------------------
loss: 0.072537  [    0/70326]
loss: 0.171580  [ 6400/70326]
loss: 0.200984  [12800/70326]
loss: 0.127636  [19200/70326]
loss: 0.128873  [25600/70326]
loss: 0.080173  [32000/70326]
loss: 0.186033  [38400/70326]
loss: 0.216356  [44800/70326]
loss: 0.145634  [51200/70326]
loss: 0.115021  [57600/70326]
loss: 0.073036  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.179219 

Epoch 22
-------------------------------
loss: 0.140153  [    0/70326]
loss: 0.128548  [ 6400/70326]
loss: 0.118608  [12800/70326]
loss: 0.165840  [19200/70326]
loss: 0.063625  [25600/70326]
loss: 0.203653  [32000/70326]
loss: 0.163712  [38400/70326]
loss: 0.143000  [44800/70326]
loss: 0.101286  [51200/70326]
loss: 0.108092  [57600/70326]
loss: 0.131529  [64000/70326]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.180824 

Epoch 23
-------------------------------
loss: 0.117662  [    0/70326]
loss: 0.092255  [ 6400/70326]
loss: 0.119517  [12800/70326]
loss: 0.148305  [19200/70326]
loss: 0.224123  [25600/70326]
loss: 0.225494  [32000/70326]
loss: 0.212267  [38400/70326]
loss: 0.154720  [44800/70326]
loss: 0.112792  [51200/70326]
loss: 0.090029  [57600/70326]
loss: 0.158922  [64000/70326]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.182962 

Epoch 24
-------------------------------
loss: 0.169291  [    0/70326]
loss: 0.188020  [ 6400/70326]
loss: 0.151125  [12800/70326]
loss: 0.197440  [19200/70326]
loss: 0.229309  [25600/70326]
loss: 0.087702  [32000/70326]
loss: 0.137312  [38400/70326]
loss: 0.334087  [44800/70326]
loss: 0.204849  [51200/70326]
loss: 0.197379  [57600/70326]
loss: 0.142251  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.183723 

Epoch 25
-------------------------------
loss: 0.062024  [    0/70326]
loss: 0.074753  [ 6400/70326]
loss: 0.205464  [12800/70326]
loss: 0.144468  [19200/70326]
loss: 0.158915  [25600/70326]
loss: 0.091710  [32000/70326]
loss: 0.160894  [38400/70326]
loss: 0.053886  [44800/70326]
loss: 0.089940  [51200/70326]
loss: 0.293863  [57600/70326]
loss: 0.133946  [64000/70326]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.181535 

Epoch 26
-------------------------------
Epoch 19
-------------------------------
loss: 0.141300  [    0/69710]
loss: 0.153870  [ 6400/69710]
loss: 0.256961  [12800/69710]
loss: 0.115264  [19200/69710]
loss: 0.124335  [25600/69710]
loss: 0.196984  [32000/69710]
loss: 0.098849  [38400/69710]
loss: 0.108675  [44800/69710]
loss: 0.120790  [51200/69710]
loss: 0.065378  [57600/69710]
loss: 0.192026  [64000/69710]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.144804 

Epoch 20
-------------------------------
loss: 0.200321  [    0/69710]
loss: 0.094363  [ 6400/69710]
loss: 0.207425  [12800/69710]
loss: 0.175035  [19200/69710]
loss: 0.077463  [25600/69710]
loss: 0.189964  [32000/69710]
loss: 0.122398  [38400/69710]
loss: 0.077255  [44800/69710]
loss: 0.241768  [51200/69710]
loss: 0.181250  [57600/69710]
loss: 0.107123  [64000/69710]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.142663 

Epoch 21
-------------------------------
loss: 0.105490  [    0/69710]
loss: 0.214709  [ 6400/69710]
loss: 0.162519  [12800/69710]
loss: 0.078268  [19200/69710]
loss: 0.178528  [25600/69710]
loss: 0.051805  [32000/69710]
loss: 0.176752  [38400/69710]
loss: 0.118532  [44800/69710]
loss: 0.120874  [51200/69710]
loss: 0.169247  [57600/69710]
loss: 0.101411  [64000/69710]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.133995 

Epoch 22
-------------------------------
loss: 0.092146  [    0/69710]
loss: 0.308104  [ 6400/69710]
loss: 0.029923  [12800/69710]
loss: 0.098975  [19200/69710]
loss: 0.132657  [25600/69710]
loss: 0.067026  [32000/69710]
loss: 0.158825  [38400/69710]
loss: 0.118059  [44800/69710]
loss: 0.139559  [51200/69710]
loss: 0.080489  [57600/69710]
loss: 0.075207  [64000/69710]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.144687 

Epoch 23
-------------------------------
loss: 0.146036  [    0/69710]
loss: 0.167800  [ 6400/69710]
loss: 0.099631  [12800/69710]
loss: 0.091626  [19200/69710]
loss: 0.397935  [25600/69710]
loss: 0.091704  [32000/69710]
loss: 0.122154  [38400/69710]
loss: 0.056420  [44800/69710]
loss: 0.168462  [51200/69710]
loss: 0.120458  [57600/69710]
loss: 0.147410  [64000/69710]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.144250 

Epoch 24
-------------------------------
loss: 0.060503  [    0/69710]
loss: 0.139562  [ 6400/69710]
loss: 0.095409  [12800/69710]
loss: 0.186454  [19200/69710]
loss: 0.243829  [25600/69710]
loss: 0.148478  [32000/69710]
loss: 0.177834  [38400/69710]
loss: 0.121551  [44800/69710]
loss: 0.023694  [51200/69710]
loss: 0.052743  [57600/69710]
loss: 0.123090  [64000/69710]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.142491 

Epoch 25
-------------------------------
loss: 0.118192  [    0/69710]
loss: 0.147217  [ 6400/69710]
loss: 0.112783  [12800/69710]
loss: 0.111374  [19200/69710]
loss: 0.163763  [25600/69710]
loss: 0.072951  [32000/69710]
loss: 0.071439  [38400/69710]
loss: 0.157693  [44800/69710]
loss: 0.112049  [51200/69710]
loss: 0.144775  [57600/69710]
loss: 0.089004  [64000/69710]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.145217 

Epoch 26
-------------------------------
loss: 0.145657  [    0/69710]
loss: 0.169452  [ 6400/69710]
loss: 0.111891  [12800/69710]
loss: 0.086140  [19200/69710]
loss: 0.070476  [25600/69710]
loss: 0.147622  [32000/69710]
loss: 0.130878  [38400/69710]
loss: 0.127322  [44800/69710]
loss: 0.157650  [51200/69710]
loss: 0.231910  [57600/69710]
loss: 0.114997  [64000/69710]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.138156 

Epoch 27
-------------------------------
loss: 0.178458  [    0/69710]
loss: 0.103405  [ 6400/69710]
loss: 0.128400  [12800/69710]
loss: 0.040358  [19200/69710]
loss: 0.043117  [25600/69710]
loss: 0.176773  [32000/69710]
loss: 0.058285  [38400/69710]
loss: 0.098543  [44800/69710]
loss: 0.108438  [51200/69710]
loss: 0.167721  [57600/69710]
loss: 0.235366  [64000/69710]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.147677 

Epoch 28
-------------------------------
loss: 0.126981  [    0/69710]
loss: 0.106572  [ 6400/69710]
loss: 0.055807  [12800/69710]
loss: 0.093344  [19200/69710]
loss: 0.119537  [25600/69710]
loss: 0.128618  [32000/69710]
loss: 0.149475  [38400/69710]
loss: 0.194682  [44800/69710]
loss: 0.154959  [51200/69710]
loss: 0.092128  [57600/69710]
loss: 0.065514  [64000/69710]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139241 

Epoch 29
-------------------------------
loss: 0.152048  [    0/69710]
loss: 0.140696  [ 6400/69710]
loss: 0.052929  [12800/69710]
loss: 0.056727  [19200/69710]
loss: 0.107827  [25600/69710]
loss: 0.177382  [32000/69710]
loss: 0.114110  [38400/69710]
loss: 0.126605  [44800/69710]
loss: 0.332893  [51200/69710]
loss: 0.110029  [57600/69710]
loss: 0.121573  [64000/69710]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.139951 

Epoch 30
-------------------------------
loss: 0.108068  [    0/69710]
loss: 0.133005  [ 6400/69710]
loss: 0.180870  [12800/69710]
loss: 0.278350  [19200/69710]
loss: 0.148944  [25600/69710]
loss: 0.173876  [32000/69710]
loss: 0.221890  [38400/69710]
loss: 0.073038  [44800/69710]
loss: 0.270502  [51200/69710]
loss: 0.072043  [57600/69710]
loss: 0.133403  [64000/69710]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.137337 

Epoch 31
-------------------------------
loss: 0.121152  [    0/69710]
loss: 0.088667  [ 6400/69710]
loss: 0.076831  [12800/69710]
loss: 0.142410  [19200/69710]
loss: 0.149793  [25600/69710]
loss: 0.117194  [32000/69710]
loss: 0.068598  [38400/69710]
loss: 0.056016  [44800/69710]
loss: 0.165732  [51200/69710]
loss: 0.085357  [57600/69710]
loss: 0.159308  [64000/69710]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.166226 

Epoch 32
-------------------------------
loss: 0.184589  [    0/69710]
loss: 0.136879  [ 6400/69710]
loss: 0.108392  [12800/69710]
loss: 0.087647  [19200/69710]
loss: 0.169738  [25600/69710]
loss: 0.131734  [32000/69710]
loss: 0.112240  [38400/69710]
loss: 0.183643  [44800/69710]
loss: 0.126567  [51200/69710]
loss: 0.096131  [57600/69710]
loss: 0.259308  [64000/69710]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.147476 

Epoch 33
-------------------------------
loss: 0.090751  [    0/69710]
loss: 0.104687  [ 6400/69710]
loss: 0.189712  [12800/69710]
loss: 0.091514  [19200/69710]
loss: 0.112375  [25600/69710]
loss: 0.142062  [32000/69710]
loss: 0.122083  [38400/69710]
loss: 0.057311  [44800/69710]
loss: 0.090327  [51200/69710]
loss: 0.085759  [57600/69710]
loss: 0.181348  [64000/69710]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.139816 

Epoch 34
-------------------------------
loss: 0.082248  [    0/69710]
loss: 0.082683  [ 6400/69710]
loss: 0.055873  [12800/69710]
loss: 0.037217  [19200/69710]
loss: 0.068955  [25600/69710]
loss: 0.145458  [32000/69710]
loss: 0.044688  [38400/69710]
loss: 0.239877  [44800/69710]
loss: 0.173177  [51200/69710]
loss: 0.140293  [57600/69710]
loss: 0.221836  [64000/69710]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.137309 

Epoch 35
-------------------------------
loss: 0.168884  [    0/69710]
loss: 0.109320  [ 6400/69710]
loss: 0.224426  [12800/69710]
loss: 0.058045  [19200/69710]
loss: 0.213090  [25600/69710]
loss: 0.187556  [32000/69710]
loss: 0.113331  [38400/69710]
loss: 0.126257  [44800/69710]
loss: 0.077053  [51200/69710]
loss: 0.161831  [57600/69710]
loss: 0.138492  [64000/69710]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.139569 

Epoch 36
-------------------------------
loss: 0.070716  [    0/69710]
loss: 0.144107  [ 6400/69710]
loss: 0.067133  [12800/69710]
loss: 0.101093  [19200/69710]
loss: 0.079989  [25600/69710]
loss: 0.133391  [32000/69710]
loss: 0.097410  [38400/69710]
loss: 0.125209  [44800/69710]
loss: 0.132310  [51200/69710]
loss: 0.096388  [57600/69710]
loss: 0.049646  [64000/69710]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.187572 

Epoch 37
-------------------------------
loss: 0.232967  [    0/69710]
loss: 0.044188  [ 6400/69710]
loss: 0.135724  [12800/69710]
loss: 0.128003  [19200/69710]
loss: 0.147573  [25600/69710]
loss: 0.215931  [32000/69710]
loss: 0.071181  [38400/69710]
loss: 0.099841  [44800/69710]
loss: 0.080789  [51200/69710]
loss: 0.281968  [57600/69710]
loss: 0.049120  [64000/69710]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.149550 

Epoch 38
-------------------------------
loss: 0.204584  [    0/69710]
loss: 0.077354  [ 6400/69710]
loss: 0.130647  [12800/69710]
Epoch 19
-------------------------------
loss: 0.238270  [    0/69795]
loss: 0.284255  [ 6400/69795]
loss: 0.316774  [12800/69795]
loss: 0.178903  [19200/69795]
loss: 0.122908  [25600/69795]
loss: 0.191477  [32000/69795]
loss: 0.226235  [38400/69795]
loss: 0.148733  [44800/69795]
loss: 0.134828  [51200/69795]
loss: 0.165415  [57600/69795]
loss: 0.296021  [64000/69795]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.182807 

Epoch 20
-------------------------------
loss: 0.189378  [    0/69795]
loss: 0.118836  [ 6400/69795]
loss: 0.132382  [12800/69795]
loss: 0.173127  [19200/69795]
loss: 0.130901  [25600/69795]
loss: 0.119915  [32000/69795]
loss: 0.129227  [38400/69795]
loss: 0.104511  [44800/69795]
loss: 0.139784  [51200/69795]
loss: 0.246901  [57600/69795]
loss: 0.135897  [64000/69795]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.189474 

Epoch 21
-------------------------------
loss: 0.137867  [    0/69795]
loss: 0.170074  [ 6400/69795]
loss: 0.204650  [12800/69795]
loss: 0.246620  [19200/69795]
loss: 0.131844  [25600/69795]
loss: 0.180795  [32000/69795]
loss: 0.180202  [38400/69795]
loss: 0.219518  [44800/69795]
loss: 0.168726  [51200/69795]
loss: 0.235480  [57600/69795]
loss: 0.150980  [64000/69795]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.201966 

Epoch 22
-------------------------------
loss: 0.082614  [    0/69795]
loss: 0.123672  [ 6400/69795]
loss: 0.338150  [12800/69795]
loss: 0.174109  [19200/69795]
loss: 0.096510  [25600/69795]
loss: 0.090594  [32000/69795]
loss: 0.184600  [38400/69795]
loss: 0.232398  [44800/69795]
loss: 0.241754  [51200/69795]
loss: 0.190915  [57600/69795]
loss: 0.248797  [64000/69795]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.201375 

Epoch 23
-------------------------------
loss: 0.172322  [    0/69795]
loss: 0.152638  [ 6400/69795]
loss: 0.241129  [12800/69795]
loss: 0.151505  [19200/69795]
loss: 0.236927  [25600/69795]
loss: 0.153355  [32000/69795]
loss: 0.204333  [38400/69795]
loss: 0.179891  [44800/69795]
loss: 0.084410  [51200/69795]
loss: 0.123858  [57600/69795]
loss: 0.121442  [64000/69795]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.176329 

Epoch 24
-------------------------------
loss: 0.190461  [    0/69795]
loss: 0.173537  [ 6400/69795]
loss: 0.210263  [12800/69795]
loss: 0.246053  [19200/69795]
loss: 0.103142  [25600/69795]
loss: 0.197124  [32000/69795]
loss: 0.183068  [38400/69795]
loss: 0.148446  [44800/69795]
loss: 0.139864  [51200/69795]
loss: 0.093898  [57600/69795]
loss: 0.323063  [64000/69795]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.182665 

Epoch 25
-------------------------------
loss: 0.214628  [    0/69795]
loss: 0.148781  [ 6400/69795]
loss: 0.177154  [12800/69795]
loss: 0.197034  [19200/69795]
loss: 0.231031  [25600/69795]
loss: 0.156173  [32000/69795]
loss: 0.187990  [38400/69795]
loss: 0.079229  [44800/69795]
loss: 0.204975  [51200/69795]
loss: 0.177679  [57600/69795]
loss: 0.106151  [64000/69795]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.183774 

Epoch 26
-------------------------------
loss: 0.140252  [    0/69795]
loss: 0.265436  [ 6400/69795]
loss: 0.166701  [12800/69795]
loss: 0.404084  [19200/69795]
loss: 0.173443  [25600/69795]
loss: 0.187795  [32000/69795]
loss: 0.212353  [38400/69795]
loss: 0.219377  [44800/69795]
loss: 0.171374  [51200/69795]
loss: 0.210989  [57600/69795]
loss: 0.166521  [64000/69795]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.187464 

Epoch 27
-------------------------------
loss: 0.112855  [    0/69795]
loss: 0.107286  [ 6400/69795]
loss: 0.157109  [12800/69795]
loss: 0.118098  [19200/69795]
loss: 0.192784  [25600/69795]
loss: 0.172030  [32000/69795]
loss: 0.282543  [38400/69795]
loss: 0.227700  [44800/69795]
loss: 0.227789  [51200/69795]
loss: 0.191853  [57600/69795]
loss: 0.199295  [64000/69795]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.185955 

Epoch 28
-------------------------------
loss: 0.209715  [    0/69795]
loss: 0.159358  [ 6400/69795]
loss: 0.254739  [12800/69795]
loss: 0.201085  [19200/69795]
loss: 0.141238  [25600/69795]
loss: 0.225307  [32000/69795]
loss: 0.116293  [38400/69795]
loss: 0.142008  [44800/69795]
loss: 0.279796  [51200/69795]
loss: 0.354535  [57600/69795]
loss: 0.225995  [64000/69795]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.177797 

Epoch 29
-------------------------------
loss: 0.174321  [    0/69795]
loss: 0.159031  [ 6400/69795]
loss: 0.058967  [12800/69795]
loss: 0.122647  [19200/69795]
loss: 0.135523  [25600/69795]
loss: 0.193127  [32000/69795]
loss: 0.208666  [38400/69795]
loss: 0.125012  [44800/69795]
loss: 0.134433  [51200/69795]
loss: 0.138495  [57600/69795]
loss: 0.128076  [64000/69795]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.179458 

Epoch 30
-------------------------------
loss: 0.223078  [    0/69795]
loss: 0.096341  [ 6400/69795]
loss: 0.235212  [12800/69795]
loss: 0.167530  [19200/69795]
loss: 0.355610  [25600/69795]
loss: 0.176247  [32000/69795]
loss: 0.147857  [38400/69795]
loss: 0.181742  [44800/69795]
loss: 0.148686  [51200/69795]
loss: 0.167802  [57600/69795]
loss: 0.157255  [64000/69795]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.167494 

Epoch 31
-------------------------------
loss: 0.172912  [    0/69795]
loss: 0.155435  [ 6400/69795]
loss: 0.903056  [12800/69795]
loss: 0.350167  [19200/69795]
loss: 0.129377  [25600/69795]
loss: 0.192352  [32000/69795]
loss: 0.205366  [38400/69795]
loss: 0.147994  [44800/69795]
loss: 0.185841  [51200/69795]
loss: 0.227988  [57600/69795]
loss: 0.130291  [64000/69795]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.177797 

Epoch 32
-------------------------------
loss: 0.163304  [    0/69795]
loss: 0.242894  [ 6400/69795]
loss: 0.155381  [12800/69795]
loss: 0.184095  [19200/69795]
loss: 0.117087  [25600/69795]
loss: 0.296660  [32000/69795]
loss: 0.102502  [38400/69795]
loss: 0.163762  [44800/69795]
loss: 0.149721  [51200/69795]
loss: 0.084305  [57600/69795]
loss: 0.283873  [64000/69795]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.177774 

Epoch 33
-------------------------------
loss: 0.174956  [    0/69795]
loss: 0.218277  [ 6400/69795]
loss: 0.287710  [12800/69795]
loss: 0.060474  [19200/69795]
loss: 0.339627  [25600/69795]
loss: 0.202356  [32000/69795]
loss: 0.115296  [38400/69795]
loss: 0.276413  [44800/69795]
loss: 0.186048  [51200/69795]
loss: 0.200645  [57600/69795]
loss: 0.149677  [64000/69795]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.169692 

Epoch 34
-------------------------------
loss: 0.238022  [    0/69795]
loss: 0.105026  [ 6400/69795]
loss: 0.199755  [12800/69795]
loss: 0.185479  [19200/69795]
loss: 0.367280  [25600/69795]
loss: 0.184075  [32000/69795]
loss: 0.131024  [38400/69795]
loss: 0.240927  [44800/69795]
loss: 0.169699  [51200/69795]
loss: 0.215811  [57600/69795]
loss: 0.189117  [64000/69795]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.175757 

Epoch 35
-------------------------------
loss: 0.069580  [    0/69795]
loss: 0.435691  [ 6400/69795]
loss: 0.213671  [12800/69795]
loss: 0.198649  [19200/69795]
loss: 0.211549  [25600/69795]
loss: 0.118533  [32000/69795]
loss: 0.109161  [38400/69795]
loss: 0.141173  [44800/69795]
loss: 0.241600  [51200/69795]
loss: 0.334577  [57600/69795]
loss: 0.166728  [64000/69795]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.189273 

Epoch 36
-------------------------------
loss: 0.217032  [    0/69795]
loss: 0.232300  [ 6400/69795]
loss: 0.154865  [12800/69795]
loss: 0.419193  [19200/69795]
loss: 0.126636  [25600/69795]
loss: 0.161979  [32000/69795]
loss: 0.198649  [38400/69795]
loss: 0.241595  [44800/69795]
loss: 0.220851  [51200/69795]
loss: 0.131897  [57600/69795]
loss: 0.155531  [64000/69795]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.165108 

Epoch 37
-------------------------------
loss: 0.106196  [    0/69795]
loss: 0.204969  [ 6400/69795]
loss: 0.165394  [12800/69795]
loss: 0.164321  [19200/69795]
loss: 0.152117  [25600/69795]
loss: 0.188873  [32000/69795]
loss: 0.105222  [38400/69795]
loss: 0.163729  [44800/69795]
loss: 0.164081  [51200/69795]
loss: 0.310553  [57600/69795]
loss: 0.067141  [64000/69795]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.190744 

Epoch 38
-------------------------------
loss: 0.231879  [    0/69795]
loss: 0.191749  [ 6400/69795]
loss: 0.257108  [12800/69795]
loss: 0.079961  [44800/69947]
loss: 0.076985  [51200/69947]
loss: 0.118220  [57600/69947]
loss: 0.219175  [64000/69947]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.175517 

Epoch 23
-------------------------------
loss: 0.115410  [    0/69947]
loss: 0.142673  [ 6400/69947]
loss: 0.055360  [12800/69947]
loss: 0.217613  [19200/69947]
loss: 0.281531  [25600/69947]
loss: 0.115815  [32000/69947]
loss: 0.075073  [38400/69947]
loss: 0.140124  [44800/69947]
loss: 0.098022  [51200/69947]
loss: 0.077787  [57600/69947]
loss: 0.086689  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.168696 

Epoch 24
-------------------------------
loss: 0.230524  [    0/69947]
loss: 0.069363  [ 6400/69947]
loss: 0.101515  [12800/69947]
loss: 0.153995  [19200/69947]
loss: 0.264903  [25600/69947]
loss: 0.070392  [32000/69947]
loss: 0.132420  [38400/69947]
loss: 0.236168  [44800/69947]
loss: 0.115285  [51200/69947]
loss: 0.126900  [57600/69947]
loss: 0.168118  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.174807 

Epoch 25
-------------------------------
loss: 0.092421  [    0/69947]
loss: 0.148894  [ 6400/69947]
loss: 0.282496  [12800/69947]
loss: 1.771478  [19200/69947]
loss: 0.159332  [25600/69947]
loss: 0.245591  [32000/69947]
loss: 0.126183  [38400/69947]
loss: 0.084546  [44800/69947]
loss: 0.149660  [51200/69947]
loss: 0.076311  [57600/69947]
loss: 0.201290  [64000/69947]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.167121 

Epoch 26
-------------------------------
loss: 0.073314  [    0/69947]
loss: 0.077330  [ 6400/69947]
loss: 0.128903  [12800/69947]
loss: 0.205634  [19200/69947]
loss: 0.169537  [25600/69947]
loss: 0.138080  [32000/69947]
loss: 0.136714  [38400/69947]
loss: 0.166916  [44800/69947]
loss: 0.160149  [51200/69947]
loss: 0.152988  [57600/69947]
loss: 0.130987  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.171409 

Epoch 27
-------------------------------
loss: 0.164852  [    0/69947]
loss: 0.060033  [ 6400/69947]
loss: 0.060914  [12800/69947]
loss: 0.065071  [19200/69947]
loss: 0.047774  [25600/69947]
loss: 0.101805  [32000/69947]
loss: 0.069966  [38400/69947]
loss: 0.231674  [44800/69947]
loss: 0.161223  [51200/69947]
loss: 0.165663  [57600/69947]
loss: 0.157852  [64000/69947]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.177935 

Epoch 28
-------------------------------
loss: 0.146338  [    0/69947]
loss: 0.235457  [ 6400/69947]
loss: 0.149285  [12800/69947]
loss: 0.137488  [19200/69947]
loss: 0.120900  [25600/69947]
loss: 0.090994  [32000/69947]
loss: 0.114457  [38400/69947]
loss: 0.070129  [44800/69947]
loss: 0.215775  [51200/69947]
loss: 0.096396  [57600/69947]
loss: 0.187698  [64000/69947]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.176701 

Epoch 29
-------------------------------
loss: 0.124003  [    0/69947]
loss: 0.097446  [ 6400/69947]
loss: 0.212173  [12800/69947]
loss: 0.158276  [19200/69947]
loss: 0.147686  [25600/69947]
loss: 0.128509  [32000/69947]
loss: 0.033042  [38400/69947]
loss: 0.200371  [44800/69947]
loss: 0.059374  [51200/69947]
loss: 0.075504  [57600/69947]
loss: 0.070545  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.169772 

Epoch 30
-------------------------------
loss: 0.077914  [    0/69947]
loss: 0.082983  [ 6400/69947]
loss: 0.090056  [12800/69947]
loss: 0.075361  [19200/69947]
loss: 0.074467  [25600/69947]
loss: 1.655083  [32000/69947]
loss: 0.140968  [38400/69947]
loss: 0.065685  [44800/69947]
loss: 0.132252  [51200/69947]
loss: 0.184361  [57600/69947]
loss: 0.069294  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.169355 

Epoch 31
-------------------------------
loss: 0.112842  [    0/69947]
loss: 0.117920  [ 6400/69947]
loss: 0.100532  [12800/69947]
loss: 0.165286  [19200/69947]
loss: 0.142211  [25600/69947]
loss: 0.157864  [32000/69947]
loss: 0.140167  [38400/69947]
loss: 0.107855  [44800/69947]
loss: 0.077318  [51200/69947]
loss: 0.119801  [57600/69947]
loss: 0.054634  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.168262 

Epoch 32
-------------------------------
loss: 0.121429  [    0/69947]
loss: 0.037080  [ 6400/69947]
loss: 0.090107  [12800/69947]
loss: 0.118313  [19200/69947]
loss: 0.144791  [25600/69947]
loss: 0.149849  [32000/69947]
loss: 0.097567  [38400/69947]
loss: 1.771828  [44800/69947]
loss: 0.094850  [51200/69947]
loss: 0.146061  [57600/69947]
loss: 0.099629  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.169896 

Epoch 33
-------------------------------
loss: 0.158991  [    0/69947]
loss: 0.160604  [ 6400/69947]
loss: 0.178208  [12800/69947]
loss: 0.149726  [19200/69947]
loss: 0.101158  [25600/69947]
loss: 0.132434  [32000/69947]
loss: 0.114063  [38400/69947]
loss: 0.194555  [44800/69947]
loss: 0.065112  [51200/69947]
loss: 1.631068  [57600/69947]
loss: 0.121947  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.172304 

Epoch 34
-------------------------------
loss: 0.141121  [    0/69947]
loss: 0.080394  [ 6400/69947]
loss: 0.128188  [12800/69947]
loss: 0.135650  [19200/69947]
loss: 0.103329  [25600/69947]
loss: 0.092502  [32000/69947]
loss: 0.116020  [38400/69947]
loss: 0.277325  [44800/69947]
loss: 0.321491  [51200/69947]
loss: 0.083376  [57600/69947]
loss: 0.146963  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.174910 

Epoch 35
-------------------------------
loss: 0.141351  [    0/69947]
loss: 0.079480  [ 6400/69947]
loss: 0.106326  [12800/69947]
loss: 0.243458  [19200/69947]
loss: 0.129046  [25600/69947]
loss: 0.178668  [32000/69947]
loss: 0.194708  [38400/69947]
loss: 0.113733  [44800/69947]
loss: 0.145251  [51200/69947]
loss: 0.084768  [57600/69947]
loss: 0.064782  [64000/69947]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.175225 

Epoch 36
-------------------------------
loss: 0.086385  [    0/69947]
loss: 0.157862  [ 6400/69947]
loss: 0.143907  [12800/69947]
loss: 0.056710  [19200/69947]
loss: 0.085455  [25600/69947]
loss: 0.102943  [32000/69947]
loss: 0.118966  [38400/69947]
loss: 0.164911  [44800/69947]
loss: 0.064632  [51200/69947]
loss: 0.090754  [57600/69947]
loss: 0.122830  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.168417 

Epoch 37
-------------------------------
loss: 0.131269  [    0/69947]
loss: 0.099527  [ 6400/69947]
loss: 1.626707  [12800/69947]
loss: 1.765818  [19200/69947]
loss: 0.124770  [25600/69947]
loss: 0.164893  [32000/69947]
loss: 0.119053  [38400/69947]
loss: 0.226109  [44800/69947]
loss: 0.172978  [51200/69947]
loss: 0.143749  [57600/69947]
loss: 0.098994  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.171711 

Epoch 38
-------------------------------
loss: 0.065889  [    0/69947]
loss: 0.116932  [ 6400/69947]
loss: 0.091293  [12800/69947]
loss: 0.258617  [19200/69947]
loss: 0.155063  [25600/69947]
loss: 0.223028  [32000/69947]
loss: 0.042551  [38400/69947]
loss: 0.112605  [44800/69947]
loss: 0.074410  [51200/69947]
loss: 0.125020  [57600/69947]
loss: 0.193855  [64000/69947]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.175468 

Epoch 39
-------------------------------
loss: 0.084008  [    0/69947]
loss: 0.243112  [ 6400/69947]
loss: 0.081303  [12800/69947]
loss: 0.168961  [19200/69947]
loss: 0.179247  [25600/69947]
loss: 0.092538  [32000/69947]
loss: 0.100538  [38400/69947]
loss: 0.127923  [44800/69947]
loss: 0.121468  [51200/69947]
loss: 0.187343  [57600/69947]
loss: 0.086132  [64000/69947]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.189215 

Epoch 40
-------------------------------
loss: 0.046528  [    0/69947]
loss: 0.076387  [ 6400/69947]
loss: 0.082102  [12800/69947]
loss: 0.099654  [19200/69947]
loss: 0.147911  [25600/69947]
loss: 0.060379  [32000/69947]
loss: 0.126559  [38400/69947]
loss: 0.158014  [44800/69947]
loss: 0.171047  [51200/69947]
loss: 0.085928  [57600/69947]
loss: 0.107632  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.177446 

Epoch 41
-------------------------------
loss: 0.119154  [    0/69947]
loss: 0.123992  [ 6400/69947]
loss: 0.086216  [12800/69947]
loss: 0.147720  [19200/69947]
loss: 0.064980  [25600/69947]
loss: 0.067641  [32000/69947]
loss: 0.278735  [38400/69947]
loss: 0.223761  [44800/69947]
loss: 0.226034  [51200/69947]
loss: 0.110724  [57600/69947]
loss: 0.073845  [64000/69947]
loss: 0.148419  [32000/69168]
loss: 0.261501  [38400/69168]
loss: 0.197188  [44800/69168]
loss: 0.176443  [51200/69168]
loss: 0.305132  [57600/69168]
loss: 0.166785  [64000/69168]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.176033 

Epoch 23
-------------------------------
loss: 0.163187  [    0/69168]
loss: 0.088838  [ 6400/69168]
loss: 0.180579  [12800/69168]
loss: 0.156366  [19200/69168]
loss: 0.109788  [25600/69168]
loss: 0.235659  [32000/69168]
loss: 0.255450  [38400/69168]
loss: 0.140374  [44800/69168]
loss: 0.263120  [51200/69168]
loss: 0.269993  [57600/69168]
loss: 0.160376  [64000/69168]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.188884 

Epoch 24
-------------------------------
loss: 0.243684  [    0/69168]
loss: 0.164473  [ 6400/69168]
loss: 0.153954  [12800/69168]
loss: 0.297155  [19200/69168]
loss: 0.114504  [25600/69168]
loss: 0.167495  [32000/69168]
loss: 0.321012  [38400/69168]
loss: 0.141477  [44800/69168]
loss: 0.165692  [51200/69168]
loss: 0.161409  [57600/69168]
loss: 0.111541  [64000/69168]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.172002 

Epoch 25
-------------------------------
loss: 0.136724  [    0/69168]
loss: 0.199680  [ 6400/69168]
loss: 0.167902  [12800/69168]
loss: 0.403006  [19200/69168]
loss: 0.218800  [25600/69168]
loss: 0.238812  [32000/69168]
loss: 0.127775  [38400/69168]
loss: 0.287741  [44800/69168]
loss: 0.148435  [51200/69168]
loss: 0.121656  [57600/69168]
loss: 0.222896  [64000/69168]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.175036 

Epoch 26
-------------------------------
loss: 0.246248  [    0/69168]
loss: 0.117735  [ 6400/69168]
loss: 0.231035  [12800/69168]
loss: 0.249417  [19200/69168]
loss: 0.245570  [25600/69168]
loss: 0.167349  [32000/69168]
loss: 0.291699  [38400/69168]
loss: 0.250271  [44800/69168]
loss: 0.155634  [51200/69168]
loss: 0.260366  [57600/69168]
loss: 0.123638  [64000/69168]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.169558 

Epoch 27
-------------------------------
loss: 0.175888  [    0/69168]
loss: 0.271846  [ 6400/69168]
loss: 0.197806  [12800/69168]
loss: 0.335766  [19200/69168]
loss: 0.190251  [25600/69168]
loss: 0.086962  [32000/69168]
loss: 0.196172  [38400/69168]
loss: 0.264450  [44800/69168]
loss: 0.201105  [51200/69168]
loss: 0.219037  [57600/69168]
loss: 0.238441  [64000/69168]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.174205 

Epoch 28
-------------------------------
loss: 0.184778  [    0/69168]
loss: 0.168266  [ 6400/69168]
loss: 0.159620  [12800/69168]
loss: 0.206873  [19200/69168]
loss: 0.215305  [25600/69168]
loss: 0.178132  [32000/69168]
loss: 0.173395  [38400/69168]
loss: 0.309783  [44800/69168]
loss: 0.240129  [51200/69168]
loss: 0.211891  [57600/69168]
loss: 0.190136  [64000/69168]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.195664 

Epoch 29
-------------------------------
loss: 0.150536  [    0/69168]
loss: 0.179875  [ 6400/69168]
loss: 0.158889  [12800/69168]
loss: 0.121070  [19200/69168]
loss: 0.173548  [25600/69168]
loss: 0.247646  [32000/69168]
loss: 0.162993  [38400/69168]
loss: 0.335446  [44800/69168]
loss: 0.113158  [51200/69168]
loss: 0.091412  [57600/69168]
loss: 0.143195  [64000/69168]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.196831 

Epoch 30
-------------------------------
loss: 0.269203  [    0/69168]
loss: 0.181725  [ 6400/69168]
loss: 0.223092  [12800/69168]
loss: 0.209153  [19200/69168]
loss: 0.182078  [25600/69168]
loss: 0.238921  [32000/69168]
loss: 0.209994  [38400/69168]
loss: 0.145462  [44800/69168]
loss: 0.178232  [51200/69168]
loss: 0.119642  [57600/69168]
loss: 0.138268  [64000/69168]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.168031 

Epoch 31
-------------------------------
loss: 0.137602  [    0/69168]
loss: 0.110330  [ 6400/69168]
loss: 0.156440  [12800/69168]
loss: 0.294163  [19200/69168]
loss: 0.295071  [25600/69168]
loss: 0.106470  [32000/69168]
loss: 0.203112  [38400/69168]
loss: 0.156592  [44800/69168]
loss: 0.175398  [51200/69168]
loss: 0.156930  [57600/69168]
loss: 0.127901  [64000/69168]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.177356 

Epoch 32
-------------------------------
loss: 0.150341  [    0/69168]
loss: 0.175463  [ 6400/69168]
loss: 0.215887  [12800/69168]
loss: 0.160347  [19200/69168]
loss: 0.231052  [25600/69168]
loss: 0.245206  [32000/69168]
loss: 0.078981  [38400/69168]
loss: 0.138402  [44800/69168]
loss: 0.114445  [51200/69168]
loss: 0.179802  [57600/69168]
loss: 0.134484  [64000/69168]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.187059 

Epoch 33
-------------------------------
loss: 0.297462  [    0/69168]
loss: 0.212875  [ 6400/69168]
loss: 0.191148  [12800/69168]
loss: 0.163123  [19200/69168]
loss: 0.221800  [25600/69168]
loss: 0.212030  [32000/69168]
loss: 0.286649  [38400/69168]
loss: 0.207123  [44800/69168]
loss: 0.096075  [51200/69168]
loss: 0.194830  [57600/69168]
loss: 0.213088  [64000/69168]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.174902 

Epoch 34
-------------------------------
loss: 0.153249  [    0/69168]
loss: 0.099146  [ 6400/69168]
loss: 0.113342  [12800/69168]
loss: 0.234290  [19200/69168]
loss: 0.131202  [25600/69168]
loss: 0.146756  [32000/69168]
loss: 0.235591  [38400/69168]
loss: 0.143175  [44800/69168]
loss: 0.241590  [51200/69168]
loss: 0.165665  [57600/69168]
loss: 0.242634  [64000/69168]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.170937 

Epoch 35
-------------------------------
loss: 0.188935  [    0/69168]
loss: 0.179296  [ 6400/69168]
loss: 0.206020  [12800/69168]
loss: 0.197586  [19200/69168]
loss: 0.155072  [25600/69168]
loss: 0.216179  [32000/69168]
loss: 0.320390  [38400/69168]
loss: 0.193752  [44800/69168]
loss: 0.135643  [51200/69168]
loss: 0.182679  [57600/69168]
loss: 0.149585  [64000/69168]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.176804 

Epoch 36
-------------------------------
loss: 0.175205  [    0/69168]
loss: 0.303141  [ 6400/69168]
loss: 0.252059  [12800/69168]
loss: 0.085007  [19200/69168]
loss: 0.174738  [25600/69168]
loss: 0.106284  [32000/69168]
loss: 0.172338  [38400/69168]
loss: 0.113262  [44800/69168]
loss: 0.199949  [51200/69168]
loss: 0.084189  [57600/69168]
loss: 0.101812  [64000/69168]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.179561 

Epoch 37
-------------------------------
loss: 0.199718  [    0/69168]
loss: 0.184603  [ 6400/69168]
loss: 0.321236  [12800/69168]
loss: 0.244001  [19200/69168]
loss: 0.144652  [25600/69168]
loss: 0.245981  [32000/69168]
loss: 0.196098  [38400/69168]
loss: 0.188053  [44800/69168]
loss: 0.274353  [51200/69168]
loss: 0.072781  [57600/69168]
loss: 0.198915  [64000/69168]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.176412 

Epoch 38
-------------------------------
loss: 0.170691  [    0/69168]
loss: 0.241665  [ 6400/69168]
loss: 0.146829  [12800/69168]
loss: 0.241064  [19200/69168]
loss: 0.294499  [25600/69168]
loss: 0.289883  [32000/69168]
loss: 0.167261  [38400/69168]
loss: 0.168401  [44800/69168]
loss: 0.147487  [51200/69168]
loss: 0.077078  [57600/69168]
loss: 0.209089  [64000/69168]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.182554 

Epoch 39
-------------------------------
loss: 0.190074  [    0/69168]
loss: 0.252419  [ 6400/69168]
loss: 0.204353  [12800/69168]
loss: 0.235527  [19200/69168]
loss: 0.162814  [25600/69168]
loss: 0.228015  [32000/69168]
loss: 0.268770  [38400/69168]
loss: 0.189693  [44800/69168]
loss: 0.421829  [51200/69168]
loss: 0.266461  [57600/69168]
loss: 0.080646  [64000/69168]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.189538 

Epoch 40
-------------------------------
loss: 0.322593  [    0/69168]
loss: 0.150599  [ 6400/69168]
loss: 0.155794  [12800/69168]
loss: 0.236261  [19200/69168]
loss: 0.235626  [25600/69168]
loss: 0.207397  [32000/69168]
loss: 0.250286  [38400/69168]
loss: 0.223770  [44800/69168]
loss: 0.233039  [51200/69168]
loss: 0.157237  [57600/69168]
loss: 0.101148  [64000/69168]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.176088 

Epoch 41
-------------------------------
loss: 0.269808  [    0/69168]
loss: 0.210874  [ 6400/69168]
loss: 0.193806  [12800/69168]
loss: 0.439402  [19200/69168]
loss: 0.184557  [25600/69168]
loss: 0.153629  [32000/69168]
loss: 0.204403  [38400/69168]
loss: 0.250738  [44800/69168]
loss: 0.363355  [51200/69168]
loss: 0.075217  [57600/69168]
loss: 0.109751  [ 6400/70414]
loss: 0.209040  [12800/70414]
loss: 0.134368  [19200/70414]
loss: 0.135244  [25600/70414]
loss: 0.097655  [32000/70414]
loss: 0.069808  [38400/70414]
loss: 0.126411  [44800/70414]
loss: 0.157980  [51200/70414]
loss: 0.121735  [57600/70414]
loss: 0.124931  [64000/70414]
loss: 0.139232  [15400/70414]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.185621 

Epoch 22
-------------------------------
loss: 0.089362  [    0/70414]
loss: 0.114509  [ 6400/70414]
loss: 0.091303  [12800/70414]
loss: 0.114024  [19200/70414]
loss: 0.098158  [25600/70414]
loss: 0.143942  [32000/70414]
loss: 0.063819  [38400/70414]
loss: 0.103536  [44800/70414]
loss: 0.192400  [51200/70414]
loss: 0.074505  [57600/70414]
loss: 0.109339  [64000/70414]
loss: 7.301450  [15400/70414]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.171360 

Epoch 23
-------------------------------
loss: 0.045741  [    0/70414]
loss: 0.116388  [ 6400/70414]
loss: 0.151506  [12800/70414]
loss: 0.293292  [19200/70414]
loss: 0.121867  [25600/70414]
loss: 0.140241  [32000/70414]
loss: 0.076105  [38400/70414]
loss: 0.188459  [44800/70414]
loss: 0.197061  [51200/70414]
loss: 0.141413  [57600/70414]
loss: 0.103687  [64000/70414]
loss: 0.080287  [15400/70414]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.173968 

Epoch 24
-------------------------------
loss: 0.130391  [    0/70414]
loss: 0.149543  [ 6400/70414]
loss: 0.234592  [12800/70414]
loss: 0.089594  [19200/70414]
loss: 0.159674  [25600/70414]
loss: 0.114585  [32000/70414]
loss: 0.091473  [38400/70414]
loss: 0.118942  [44800/70414]
loss: 0.158949  [51200/70414]
loss: 0.139997  [57600/70414]
loss: 0.028950  [64000/70414]
loss: 0.073426  [15400/70414]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.179084 

Epoch 25
-------------------------------
loss: 0.088920  [    0/70414]
loss: 0.107436  [ 6400/70414]
loss: 0.132189  [12800/70414]
loss: 0.153227  [19200/70414]
loss: 0.126013  [25600/70414]
loss: 0.110010  [32000/70414]
loss: 0.148930  [38400/70414]
loss: 0.049371  [44800/70414]
loss: 0.128725  [51200/70414]
loss: 0.169254  [57600/70414]
loss: 0.137432  [64000/70414]
loss: 0.159210  [15400/70414]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.179045 

Epoch 26
-------------------------------
loss: 0.115585  [    0/70414]
loss: 0.151837  [ 6400/70414]
loss: 0.053049  [12800/70414]
loss: 0.043719  [19200/70414]
loss: 0.122829  [25600/70414]
loss: 0.103267  [32000/70414]
loss: 0.125766  [38400/70414]
loss: 0.073755  [44800/70414]
loss: 0.055470  [51200/70414]
loss: 0.080376  [57600/70414]
loss: 0.152720  [64000/70414]
loss: 0.118385  [15400/70414]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.179542 

Epoch 27
-------------------------------
loss: 0.102422  [    0/70414]
loss: 0.041447  [ 6400/70414]
loss: 0.145572  [12800/70414]
loss: 0.089758  [19200/70414]
loss: 0.041140  [25600/70414]
loss: 0.077457  [32000/70414]
loss: 0.235350  [38400/70414]
loss: 0.271237  [44800/70414]
loss: 0.090381  [51200/70414]
loss: 0.161020  [57600/70414]
loss: 0.181651  [64000/70414]
loss: 0.183069  [15400/70414]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.181273 

Epoch 28
-------------------------------
loss: 0.057098  [    0/70414]
loss: 0.077271  [ 6400/70414]
loss: 0.224933  [12800/70414]
loss: 0.150540  [19200/70414]
loss: 0.099569  [25600/70414]
loss: 0.125951  [32000/70414]
loss: 0.182623  [38400/70414]
loss: 0.088595  [44800/70414]
loss: 0.277762  [51200/70414]
loss: 0.151358  [57600/70414]
loss: 0.159756  [64000/70414]
loss: 0.383781  [15400/70414]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.194506 

Epoch 29
-------------------------------
loss: 0.092639  [    0/70414]
loss: 0.233798  [ 6400/70414]
loss: 0.100738  [12800/70414]
loss: 0.147581  [19200/70414]
loss: 0.172224  [25600/70414]
loss: 0.111502  [32000/70414]
loss: 0.212264  [38400/70414]
loss: 0.162548  [44800/70414]
loss: 1.668522  [51200/70414]
loss: 0.121398  [57600/70414]
loss: 0.070487  [64000/70414]
loss: 0.188154  [15400/70414]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.179391 

Epoch 30
-------------------------------
loss: 0.141426  [    0/70414]
loss: 0.082354  [ 6400/70414]
loss: 0.055745  [12800/70414]
loss: 0.064517  [19200/70414]
loss: 0.270723  [25600/70414]
loss: 0.127084  [32000/70414]
loss: 0.098341  [38400/70414]
loss: 0.175409  [44800/70414]
loss: 0.048964  [51200/70414]
loss: 0.116967  [57600/70414]
loss: 0.138135  [64000/70414]
loss: 0.261980  [15400/70414]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.183046 

Epoch 31
-------------------------------
loss: 0.076897  [    0/70414]
loss: 0.139244  [ 6400/70414]
loss: 0.101326  [12800/70414]
loss: 0.146185  [19200/70414]
loss: 0.151531  [25600/70414]
loss: 0.095437  [32000/70414]
loss: 0.082570  [38400/70414]
loss: 0.106675  [44800/70414]
loss: 0.075979  [51200/70414]
loss: 0.101150  [57600/70414]
loss: 0.092008  [64000/70414]
loss: 0.022240  [15400/70414]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.168807 

Epoch 32
-------------------------------
loss: 0.079106  [    0/70414]
loss: 0.191004  [ 6400/70414]
loss: 0.050800  [12800/70414]
loss: 1.779986  [19200/70414]
loss: 0.121627  [25600/70414]
loss: 0.082679  [32000/70414]
loss: 0.111259  [38400/70414]
loss: 0.087082  [44800/70414]
loss: 0.222766  [51200/70414]
loss: 0.140999  [57600/70414]
loss: 0.102991  [64000/70414]
loss: 0.378660  [15400/70414]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.188427 

Epoch 33
-------------------------------
loss: 0.165325  [    0/70414]
loss: 0.225755  [ 6400/70414]
loss: 0.156566  [12800/70414]
loss: 0.107667  [19200/70414]
loss: 0.124809  [25600/70414]
loss: 0.146541  [32000/70414]
loss: 0.251213  [38400/70414]
loss: 0.138408  [44800/70414]
loss: 0.116041  [51200/70414]
loss: 0.149719  [57600/70414]
loss: 0.196741  [64000/70414]
loss: 0.086125  [15400/70414]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.176377 

Epoch 34
-------------------------------
loss: 0.070946  [    0/70414]
loss: 0.246219  [ 6400/70414]
loss: 0.095765  [12800/70414]
loss: 0.167861  [19200/70414]
loss: 0.177231  [25600/70414]
loss: 0.118278  [32000/70414]
loss: 0.109106  [38400/70414]
loss: 0.206646  [44800/70414]
loss: 0.103766  [51200/70414]
loss: 0.147672  [57600/70414]
loss: 0.053976  [64000/70414]
loss: 0.007332  [15400/70414]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.173215 

Epoch 35
-------------------------------
loss: 0.061291  [    0/70414]
loss: 0.180948  [ 6400/70414]
loss: 0.106405  [12800/70414]
loss: 0.118549  [19200/70414]
loss: 0.192299  [25600/70414]
loss: 0.139507  [32000/70414]
loss: 0.068882  [38400/70414]
loss: 0.089045  [44800/70414]
loss: 0.200047  [51200/70414]
loss: 0.106114  [57600/70414]
loss: 0.097183  [64000/70414]
loss: 0.007974  [15400/70414]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.170420 

Epoch 36
-------------------------------
loss: 0.123558  [    0/70414]
loss: 0.218324  [ 6400/70414]
loss: 0.105887  [12800/70414]
loss: 0.135373  [19200/70414]
loss: 0.136628  [25600/70414]
loss: 0.048118  [32000/70414]
loss: 0.113149  [38400/70414]
loss: 0.104433  [44800/70414]
loss: 0.125412  [51200/70414]
loss: 0.299801  [57600/70414]
loss: 0.197861  [64000/70414]
loss: 0.376496  [15400/70414]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.188103 

Epoch 37
-------------------------------
loss: 0.163242  [    0/70414]
loss: 0.063949  [ 6400/70414]
loss: 0.077245  [12800/70414]
loss: 0.062261  [19200/70414]
loss: 0.234524  [25600/70414]
loss: 0.168910  [32000/70414]
loss: 0.046892  [38400/70414]
loss: 0.148199  [44800/70414]
loss: 0.172247  [51200/70414]
loss: 0.276525  [57600/70414]
loss: 0.140906  [64000/70414]
loss: 0.199686  [15400/70414]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.177197 

Epoch 38
-------------------------------
loss: 0.066276  [    0/70414]
loss: 0.090177  [ 6400/70414]
loss: 0.134342  [12800/70414]
loss: 0.152781  [19200/70414]
loss: 0.077725  [25600/70414]
loss: 0.138797  [32000/70414]
loss: 0.077445  [38400/70414]
loss: 0.132210  [44800/70414]
loss: 0.075586  [51200/70414]
loss: 0.056971  [57600/70414]
loss: 0.183344  [64000/70414]
loss: 0.164810  [15400/70414]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.170268 

Epoch 39
-------------------------------
loss: 0.136515  [    0/70414]
loss: 0.114985  [ 6400/70414]
loss: 0.146767  [70400/70495]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.138600 

Epoch 18
-------------------------------
loss: 0.154775  [    0/70495]
loss: 0.026655  [ 6400/70495]
loss: 0.184609  [12800/70495]
loss: 0.176850  [19200/70495]
loss: 1.785203  [25600/70495]
loss: 0.081562  [32000/70495]
loss: 0.127028  [38400/70495]
loss: 0.038483  [44800/70495]
loss: 0.103759  [51200/70495]
loss: 0.066145  [57600/70495]
loss: 0.075728  [64000/70495]
loss: 0.099308  [70400/70495]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.141382 

Epoch 19
-------------------------------
loss: 0.095333  [    0/70495]
loss: 0.134280  [ 6400/70495]
loss: 0.057562  [12800/70495]
loss: 0.068464  [19200/70495]
loss: 0.149614  [25600/70495]
loss: 0.039406  [32000/70495]
loss: 0.166552  [38400/70495]
loss: 0.027185  [44800/70495]
loss: 0.045728  [51200/70495]
loss: 0.147817  [57600/70495]
loss: 0.177746  [64000/70495]
loss: 0.187178  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.135978 

Epoch 20
-------------------------------
loss: 0.145300  [    0/70495]
loss: 0.046824  [ 6400/70495]
loss: 0.235139  [12800/70495]
loss: 0.086574  [19200/70495]
loss: 0.046891  [25600/70495]
loss: 0.049504  [32000/70495]
loss: 0.029937  [38400/70495]
loss: 0.154671  [44800/70495]
loss: 0.046396  [51200/70495]
loss: 0.046035  [57600/70495]
loss: 0.101773  [64000/70495]
loss: 0.075855  [70400/70495]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.139754 

Epoch 21
-------------------------------
loss: 0.035133  [    0/70495]
loss: 0.077876  [ 6400/70495]
loss: 0.119000  [12800/70495]
loss: 0.179406  [19200/70495]
loss: 0.022182  [25600/70495]
loss: 0.144541  [32000/70495]
loss: 0.136104  [38400/70495]
loss: 0.050148  [44800/70495]
loss: 0.048506  [51200/70495]
loss: 0.028545  [57600/70495]
loss: 0.068185  [64000/70495]
loss: 0.081784  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.136243 

Epoch 22
-------------------------------
loss: 0.073695  [    0/70495]
loss: 0.153604  [ 6400/70495]
loss: 0.053442  [12800/70495]
loss: 0.079096  [19200/70495]
loss: 0.129796  [25600/70495]
loss: 0.046816  [32000/70495]
loss: 0.148190  [38400/70495]
loss: 0.104378  [44800/70495]
loss: 0.012119  [51200/70495]
loss: 0.252811  [57600/70495]
loss: 0.177575  [64000/70495]
loss: 0.080592  [70400/70495]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.139874 

Epoch 23
-------------------------------
loss: 0.030727  [    0/70495]
loss: 0.078916  [ 6400/70495]
loss: 0.078262  [12800/70495]
loss: 0.064877  [19200/70495]
loss: 0.115576  [25600/70495]
loss: 0.033394  [32000/70495]
loss: 0.093840  [38400/70495]
loss: 0.034924  [44800/70495]
loss: 0.065679  [51200/70495]
loss: 0.143122  [57600/70495]
loss: 0.045177  [64000/70495]
loss: 0.072925  [70400/70495]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.151617 

Epoch 24
-------------------------------
loss: 0.139681  [    0/70495]
loss: 0.106990  [ 6400/70495]
loss: 0.032921  [12800/70495]
loss: 0.062905  [19200/70495]
loss: 0.064446  [25600/70495]
loss: 0.127023  [32000/70495]
loss: 0.113770  [38400/70495]
loss: 0.103181  [44800/70495]
loss: 0.038446  [51200/70495]
loss: 0.078974  [57600/70495]
loss: 0.099053  [64000/70495]
loss: 0.147853  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.133251 

Epoch 25
-------------------------------
loss: 0.033558  [    0/70495]
loss: 0.030772  [ 6400/70495]
loss: 0.179766  [12800/70495]
loss: 0.114356  [19200/70495]
loss: 0.126893  [25600/70495]
loss: 0.090386  [32000/70495]
loss: 0.206178  [38400/70495]
loss: 0.108421  [44800/70495]
loss: 0.011163  [51200/70495]
loss: 0.060194  [57600/70495]
loss: 0.090451  [64000/70495]
loss: 0.087487  [70400/70495]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.139453 

Epoch 26
-------------------------------
loss: 0.033455  [    0/70495]
loss: 0.143509  [ 6400/70495]
loss: 0.066443  [12800/70495]
loss: 0.043334  [19200/70495]
loss: 0.079619  [25600/70495]
loss: 0.055480  [32000/70495]
loss: 1.609606  [38400/70495]
loss: 0.038781  [44800/70495]
loss: 0.066559  [51200/70495]
loss: 0.142544  [57600/70495]
loss: 0.090124  [64000/70495]
loss: 0.111882  [70400/70495]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.146693 

Epoch 27
-------------------------------
loss: 0.109206  [    0/70495]
loss: 0.125275  [ 6400/70495]
loss: 0.076510  [12800/70495]
loss: 0.112813  [19200/70495]
loss: 0.037956  [25600/70495]
loss: 0.063508  [32000/70495]
loss: 0.212490  [38400/70495]
loss: 0.108778  [44800/70495]
loss: 0.098565  [51200/70495]
loss: 0.069715  [57600/70495]
loss: 0.170846  [64000/70495]
loss: 0.038372  [70400/70495]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.142321 

Epoch 28
-------------------------------
loss: 0.141261  [    0/70495]
loss: 0.046375  [ 6400/70495]
loss: 0.046155  [12800/70495]
loss: 0.170183  [19200/70495]
loss: 0.052496  [25600/70495]
loss: 0.143125  [32000/70495]
loss: 0.067025  [38400/70495]
loss: 0.046250  [44800/70495]
loss: 0.074445  [51200/70495]
loss: 0.108873  [57600/70495]
loss: 0.061801  [64000/70495]
loss: 0.088334  [70400/70495]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.137854 

Epoch 29
-------------------------------
loss: 0.056226  [    0/70495]
loss: 0.096096  [ 6400/70495]
loss: 0.074608  [12800/70495]
loss: 0.074945  [19200/70495]
loss: 0.032607  [25600/70495]
loss: 0.120128  [32000/70495]
loss: 0.048854  [38400/70495]
loss: 0.063353  [44800/70495]
loss: 0.046475  [51200/70495]
loss: 0.130894  [57600/70495]
loss: 0.117000  [64000/70495]
loss: 0.151162  [70400/70495]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.132687 

Epoch 30
-------------------------------
loss: 0.080673  [    0/70495]
loss: 0.136850  [ 6400/70495]
loss: 0.060080  [12800/70495]
loss: 0.225845  [19200/70495]
loss: 0.289958  [25600/70495]
loss: 0.083221  [32000/70495]
loss: 0.056308  [38400/70495]
loss: 0.121936  [44800/70495]
loss: 0.092903  [51200/70495]
loss: 0.097886  [57600/70495]
loss: 0.046658  [64000/70495]
loss: 0.098949  [70400/70495]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.142894 

Epoch 31
-------------------------------
loss: 0.035387  [    0/70495]
loss: 0.085117  [ 6400/70495]
loss: 0.085101  [12800/70495]
loss: 0.071570  [19200/70495]
loss: 0.107307  [25600/70495]
loss: 0.024346  [32000/70495]
loss: 0.075581  [38400/70495]
loss: 0.204037  [44800/70495]
loss: 0.067410  [51200/70495]
loss: 0.087058  [57600/70495]
loss: 0.141391  [64000/70495]
loss: 0.053295  [70400/70495]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.139970 

Epoch 32
-------------------------------
loss: 0.057292  [    0/70495]
loss: 0.080840  [ 6400/70495]
loss: 0.024412  [12800/70495]
loss: 0.128141  [19200/70495]
loss: 0.069237  [25600/70495]
loss: 0.099595  [32000/70495]
loss: 0.089394  [38400/70495]
loss: 1.601989  [44800/70495]
loss: 0.124828  [51200/70495]
loss: 0.127549  [57600/70495]
loss: 0.208208  [64000/70495]
loss: 0.097943  [70400/70495]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.138978 

Epoch 33
-------------------------------
loss: 0.138433  [    0/70495]
loss: 0.046251  [ 6400/70495]
loss: 0.088038  [12800/70495]
loss: 0.072356  [19200/70495]
loss: 0.276464  [25600/70495]
loss: 0.081615  [32000/70495]
loss: 0.169713  [38400/70495]
loss: 0.046020  [44800/70495]
loss: 0.055114  [51200/70495]
loss: 0.057332  [57600/70495]
loss: 0.080457  [64000/70495]
loss: 0.082648  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.135947 

Epoch 34
-------------------------------
loss: 0.084282  [    0/70495]
loss: 0.105377  [ 6400/70495]
loss: 0.184518  [12800/70495]
loss: 0.069272  [19200/70495]
loss: 0.026564  [25600/70495]
loss: 0.051194  [32000/70495]
loss: 0.055084  [38400/70495]
loss: 0.126905  [44800/70495]
loss: 0.068232  [51200/70495]
loss: 0.138154  [57600/70495]
loss: 0.131063  [64000/70495]
loss: 0.077311  [70400/70495]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.133080 

Epoch 35
-------------------------------
loss: 0.050432  [    0/70495]
loss: 0.130562  [ 6400/70495]
loss: 0.070780  [12800/70495]
loss: 0.192072  [19200/70495]
loss: 0.107744  [25600/70495]
loss: 1.638319  [32000/70495]
loss: 0.071948  [38400/70495]
loss: 0.095646  [44800/70495]
loss: 0.121240  [51200/70495]
loss: 0.168058  [57600/70495]
loss: 0.125317  [64000/70495]
loss: 0.029820  [70400/70495]
loss: 0.071874  [38400/71429]
loss: 0.144569  [44800/71429]
loss: 0.070316  [51200/71429]
loss: 0.053452  [57600/71429]
loss: 0.080978  [64000/71429]
loss: 0.099827  [70400/71429]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.082314 

Epoch 25
-------------------------------
loss: 0.010397  [    0/71429]
loss: 0.066812  [ 6400/71429]
loss: 0.009091  [12800/71429]
loss: 0.087873  [19200/71429]
loss: 0.052061  [25600/71429]
loss: 0.072497  [32000/71429]
loss: 0.015323  [38400/71429]
loss: 0.025223  [44800/71429]
loss: 0.019569  [51200/71429]
loss: 0.087408  [57600/71429]
loss: 0.010183  [64000/71429]
loss: 0.089514  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.090196 

Epoch 26
-------------------------------
loss: 0.013726  [    0/71429]
loss: 0.048068  [ 6400/71429]
loss: 0.041758  [12800/71429]
loss: 0.018742  [19200/71429]
loss: 0.003686  [25600/71429]
loss: 0.013109  [32000/71429]
loss: 0.036624  [38400/71429]
loss: 0.039022  [44800/71429]
loss: 0.057134  [51200/71429]
loss: 0.083773  [57600/71429]
loss: 0.135297  [64000/71429]
loss: 0.047735  [70400/71429]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.097829 

Epoch 27
-------------------------------
loss: 0.052703  [    0/71429]
loss: 0.038982  [ 6400/71429]
loss: 0.018519  [12800/71429]
loss: 0.032414  [19200/71429]
loss: 0.005787  [25600/71429]
loss: 0.014772  [32000/71429]
loss: 0.010773  [38400/71429]
loss: 0.031873  [44800/71429]
loss: 0.036195  [51200/71429]
loss: 0.077278  [57600/71429]
loss: 0.016433  [64000/71429]
loss: 0.228047  [70400/71429]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.105698 

Epoch 28
-------------------------------
loss: 0.102514  [    0/71429]
loss: 0.010888  [ 6400/71429]
loss: 0.015651  [12800/71429]
loss: 0.026445  [19200/71429]
loss: 0.021517  [25600/71429]
loss: 0.077009  [32000/71429]
loss: 0.007358  [38400/71429]
loss: 0.005645  [44800/71429]
loss: 0.010982  [51200/71429]
loss: 0.072346  [57600/71429]
loss: 0.066175  [64000/71429]
loss: 0.114691  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.098813 

Epoch 29
-------------------------------
loss: 0.045497  [    0/71429]
loss: 0.034597  [ 6400/71429]
loss: 0.093189  [12800/71429]
loss: 0.046547  [19200/71429]
loss: 0.024637  [25600/71429]
loss: 0.058594  [32000/71429]
loss: 0.017987  [38400/71429]
loss: 0.143895  [44800/71429]
loss: 0.025359  [51200/71429]
loss: 0.040023  [57600/71429]
loss: 0.056021  [64000/71429]
loss: 0.016943  [70400/71429]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.097164 

Epoch 30
-------------------------------
loss: 0.028070  [    0/71429]
loss: 0.023237  [ 6400/71429]
loss: 0.009875  [12800/71429]
loss: 0.032334  [19200/71429]
loss: 0.014930  [25600/71429]
loss: 0.031285  [32000/71429]
loss: 0.011558  [38400/71429]
loss: 0.018864  [44800/71429]
loss: 0.019754  [51200/71429]
loss: 0.024852  [57600/71429]
loss: 0.033566  [64000/71429]
loss: 0.008972  [70400/71429]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.077998 

Epoch 31
-------------------------------
loss: 0.003779  [    0/71429]
loss: 0.031510  [ 6400/71429]
loss: 0.019743  [12800/71429]
loss: 0.003157  [19200/71429]
loss: 0.051991  [25600/71429]
loss: 0.021792  [32000/71429]
loss: 0.005445  [38400/71429]
loss: 0.089194  [44800/71429]
loss: 0.107718  [51200/71429]
loss: 0.011084  [57600/71429]
loss: 0.117715  [64000/71429]
loss: 0.032046  [70400/71429]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.094670 

Epoch 32
-------------------------------
loss: 0.071017  [    0/71429]
loss: 0.008819  [ 6400/71429]
loss: 0.016727  [12800/71429]
loss: 0.012009  [19200/71429]
loss: 0.018515  [25600/71429]
loss: 0.010763  [32000/71429]
loss: 0.031825  [38400/71429]
loss: 0.084112  [44800/71429]
loss: 0.000425  [51200/71429]
loss: 0.162389  [57600/71429]
loss: 0.007499  [64000/71429]
loss: 0.089931  [70400/71429]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.088664 

Epoch 33
-------------------------------
loss: 0.033139  [    0/71429]
loss: 0.005857  [ 6400/71429]
loss: 0.015810  [12800/71429]
loss: 0.022306  [19200/71429]
loss: 0.078392  [25600/71429]
loss: 0.028489  [32000/71429]
loss: 0.062763  [38400/71429]
loss: 0.027845  [44800/71429]
loss: 0.009494  [51200/71429]
loss: 0.006128  [57600/71429]
loss: 0.011761  [64000/71429]
loss: 0.020944  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.089284 

Epoch 34
-------------------------------
loss: 0.055980  [    0/71429]
loss: 0.029290  [ 6400/71429]
loss: 0.045097  [12800/71429]
loss: 0.042925  [19200/71429]
loss: 0.067572  [25600/71429]
loss: 0.109634  [32000/71429]
loss: 0.016751  [38400/71429]
loss: 0.030025  [44800/71429]
loss: 0.026436  [51200/71429]
loss: 0.063166  [57600/71429]
loss: 0.043801  [64000/71429]
loss: 0.120249  [70400/71429]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.104289 

Epoch 35
-------------------------------
loss: 0.074905  [    0/71429]
loss: 0.075402  [ 6400/71429]
loss: 0.004703  [12800/71429]
loss: 0.024033  [19200/71429]
loss: 0.039092  [25600/71429]
loss: 0.015236  [32000/71429]
loss: 0.051312  [38400/71429]
loss: 0.005357  [44800/71429]
loss: 0.008722  [51200/71429]
loss: 0.234044  [57600/71429]
loss: 0.008550  [64000/71429]
loss: 0.022136  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.092491 

Epoch 36
-------------------------------
loss: 0.038852  [    0/71429]
loss: 0.030239  [ 6400/71429]
loss: 0.076952  [12800/71429]
loss: 0.039052  [19200/71429]
loss: 0.044348  [25600/71429]
loss: 0.007901  [32000/71429]
loss: 0.015012  [38400/71429]
loss: 0.045107  [44800/71429]
loss: 0.037716  [51200/71429]
loss: 0.037162  [57600/71429]
loss: 0.036231  [64000/71429]
loss: 0.028028  [70400/71429]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.097967 

Epoch 37
-------------------------------
loss: 0.017418  [    0/71429]
loss: 0.063393  [ 6400/71429]
loss: 0.048951  [12800/71429]
loss: 0.058220  [19200/71429]
loss: 0.034397  [25600/71429]
loss: 0.068222  [32000/71429]
loss: 0.089768  [38400/71429]
loss: 0.045550  [44800/71429]
loss: 0.084302  [51200/71429]
loss: 0.074655  [57600/71429]
loss: 0.038364  [64000/71429]
loss: 0.009274  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.083501 

Epoch 38
-------------------------------
loss: 0.020162  [    0/71429]
loss: 0.093160  [ 6400/71429]
loss: 0.062603  [12800/71429]
loss: 0.011520  [19200/71429]
loss: 0.008628  [25600/71429]
loss: 0.047819  [32000/71429]
loss: 0.056993  [38400/71429]
loss: 0.018086  [44800/71429]
loss: 0.114973  [51200/71429]
loss: 0.028817  [57600/71429]
loss: 0.053982  [64000/71429]
loss: 0.053906  [70400/71429]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.108297 

Epoch 39
-------------------------------
loss: 0.015853  [    0/71429]
loss: 0.012192  [ 6400/71429]
loss: 0.001722  [12800/71429]
loss: 0.107053  [19200/71429]
loss: 0.017286  [25600/71429]
loss: 0.014126  [32000/71429]
loss: 0.035270  [38400/71429]
loss: 0.038499  [44800/71429]
loss: 0.007041  [51200/71429]
loss: 0.008237  [57600/71429]
loss: 0.011656  [64000/71429]
loss: 0.046945  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.099666 

Epoch 40
-------------------------------
loss: 0.043587  [    0/71429]
loss: 0.020002  [ 6400/71429]
loss: 0.002439  [12800/71429]
loss: 0.103521  [19200/71429]
loss: 0.009877  [25600/71429]
loss: 0.009868  [32000/71429]
loss: 0.004731  [38400/71429]
loss: 0.007170  [44800/71429]
loss: 0.316683  [51200/71429]
loss: 0.013335  [57600/71429]
loss: 0.071630  [64000/71429]
loss: 0.004544  [70400/71429]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.117391 

Epoch 41
-------------------------------
loss: 0.019835  [    0/71429]
loss: 0.016664  [ 6400/71429]
loss: 0.026308  [12800/71429]
loss: 0.017690  [19200/71429]
loss: 0.054754  [25600/71429]
loss: 0.081153  [32000/71429]
loss: 0.031676  [38400/71429]
loss: 0.058845  [44800/71429]
loss: 0.103795  [51200/71429]
loss: 0.023841  [57600/71429]
loss: 0.063485  [64000/71429]
loss: 0.022978  [70400/71429]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.098787 

Epoch 42
-------------------------------
loss: 0.015843  [    0/71429]
loss: 0.003270  [ 6400/71429]
loss: 0.025291  [12800/71429]
loss: 0.007138  [19200/71429]
loss: 0.011328  [25600/71429]
loss: 0.204216  [32000/71429]
loss: 0.015572  [38400/71429]
loss: 1.668296  [32000/69810]
loss: 0.087604  [38400/69810]
loss: 0.166054  [44800/69810]
loss: 0.162778  [51200/69810]
loss: 0.315774  [57600/69810]
loss: 0.053941  [64000/69810]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.134482 

Epoch 23
-------------------------------
loss: 0.101853  [    0/69810]
loss: 0.114746  [ 6400/69810]
loss: 0.120198  [12800/69810]
loss: 0.066378  [19200/69810]
loss: 0.098528  [25600/69810]
loss: 0.166457  [32000/69810]
loss: 0.066471  [38400/69810]
loss: 0.152470  [44800/69810]
loss: 0.212889  [51200/69810]
loss: 0.135031  [57600/69810]
loss: 0.101179  [64000/69810]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.141645 

Epoch 24
-------------------------------
loss: 0.128459  [    0/69810]
loss: 0.080967  [ 6400/69810]
loss: 0.052911  [12800/69810]
loss: 0.217563  [19200/69810]
loss: 0.074736  [25600/69810]
loss: 0.072898  [32000/69810]
loss: 0.067637  [38400/69810]
loss: 0.081172  [44800/69810]
loss: 0.059918  [51200/69810]
loss: 0.137455  [57600/69810]
loss: 0.072019  [64000/69810]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.133198 

Epoch 25
-------------------------------
loss: 0.077495  [    0/69810]
loss: 0.159872  [ 6400/69810]
loss: 0.047333  [12800/69810]
loss: 0.069598  [19200/69810]
loss: 0.050057  [25600/69810]
loss: 0.156840  [32000/69810]
loss: 0.103898  [38400/69810]
loss: 0.143848  [44800/69810]
loss: 0.130647  [51200/69810]
loss: 0.177842  [57600/69810]
loss: 0.273493  [64000/69810]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.134731 

Epoch 26
-------------------------------
loss: 0.044538  [    0/69810]
loss: 0.184111  [ 6400/69810]
loss: 0.167765  [12800/69810]
loss: 0.127303  [19200/69810]
loss: 0.065639  [25600/69810]
loss: 0.022664  [32000/69810]
loss: 0.176039  [38400/69810]
loss: 0.057655  [44800/69810]
loss: 0.108928  [51200/69810]
loss: 0.040587  [57600/69810]
loss: 0.064723  [64000/69810]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.138970 

Epoch 27
-------------------------------
loss: 0.114508  [    0/69810]
loss: 0.136419  [ 6400/69810]
loss: 0.059015  [12800/69810]
loss: 0.078176  [19200/69810]
loss: 0.060499  [25600/69810]
loss: 0.199070  [32000/69810]
loss: 0.090076  [38400/69810]
loss: 0.097340  [44800/69810]
loss: 0.085444  [51200/69810]
loss: 0.080948  [57600/69810]
loss: 0.036593  [64000/69810]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.128306 

Epoch 28
-------------------------------
loss: 0.143839  [    0/69810]
loss: 0.129241  [ 6400/69810]
loss: 0.079306  [12800/69810]
loss: 0.167825  [19200/69810]
loss: 0.085707  [25600/69810]
loss: 0.141138  [32000/69810]
loss: 0.088970  [38400/69810]
loss: 0.100066  [44800/69810]
loss: 0.180951  [51200/69810]
loss: 0.062906  [57600/69810]
loss: 0.083816  [64000/69810]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.133758 

Epoch 29
-------------------------------
loss: 0.097464  [    0/69810]
loss: 0.117336  [ 6400/69810]
loss: 0.181334  [12800/69810]
loss: 0.041067  [19200/69810]
loss: 0.069819  [25600/69810]
loss: 0.055515  [32000/69810]
loss: 0.075993  [38400/69810]
loss: 0.134472  [44800/69810]
loss: 0.173897  [51200/69810]
loss: 0.226878  [57600/69810]
loss: 0.097688  [64000/69810]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.131041 

Epoch 30
-------------------------------
loss: 0.146011  [    0/69810]
loss: 0.235438  [ 6400/69810]
loss: 0.127944  [12800/69810]
loss: 0.098802  [19200/69810]
loss: 0.124332  [25600/69810]
loss: 0.037860  [32000/69810]
loss: 0.121022  [38400/69810]
loss: 0.212956  [44800/69810]
loss: 0.277097  [51200/69810]
loss: 0.024901  [57600/69810]
loss: 0.126825  [64000/69810]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.131610 

Epoch 31
-------------------------------
loss: 0.058563  [    0/69810]
loss: 0.169638  [ 6400/69810]
loss: 0.065160  [12800/69810]
loss: 0.104126  [19200/69810]
loss: 0.161380  [25600/69810]
loss: 0.395767  [32000/69810]
loss: 0.067056  [38400/69810]
loss: 0.029016  [44800/69810]
loss: 0.051262  [51200/69810]
loss: 0.056971  [57600/69810]
loss: 0.168837  [64000/69810]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.129108 

Epoch 32
-------------------------------
loss: 0.121268  [    0/69810]
loss: 0.042205  [ 6400/69810]
loss: 0.084447  [12800/69810]
loss: 0.105119  [19200/69810]
loss: 0.046058  [25600/69810]
loss: 0.119012  [32000/69810]
loss: 0.109070  [38400/69810]
loss: 0.129442  [44800/69810]
loss: 0.037448  [51200/69810]
loss: 0.025178  [57600/69810]
loss: 0.029035  [64000/69810]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.135137 

Epoch 33
-------------------------------
loss: 0.101538  [    0/69810]
loss: 0.049746  [ 6400/69810]
loss: 0.035832  [12800/69810]
loss: 0.077330  [19200/69810]
loss: 0.067989  [25600/69810]
loss: 0.136691  [32000/69810]
loss: 0.147525  [38400/69810]
loss: 0.080066  [44800/69810]
loss: 0.098986  [51200/69810]
loss: 0.135325  [57600/69810]
loss: 0.104222  [64000/69810]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.132225 

Epoch 34
-------------------------------
loss: 0.122149  [    0/69810]
loss: 0.244313  [ 6400/69810]
loss: 0.135063  [12800/69810]
loss: 0.093538  [19200/69810]
loss: 0.166822  [25600/69810]
loss: 0.125356  [32000/69810]
loss: 0.066433  [38400/69810]
loss: 0.069498  [44800/69810]
loss: 0.076190  [51200/69810]
loss: 0.051482  [57600/69810]
loss: 0.080287  [64000/69810]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.130697 

Epoch 35
-------------------------------
loss: 0.046106  [    0/69810]
loss: 0.090425  [ 6400/69810]
loss: 0.087659  [12800/69810]
loss: 0.053127  [19200/69810]
loss: 0.099751  [25600/69810]
loss: 0.055221  [32000/69810]
loss: 0.050165  [38400/69810]
loss: 0.084814  [44800/69810]
loss: 0.056197  [51200/69810]
loss: 0.138462  [57600/69810]
loss: 0.110764  [64000/69810]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.128048 

Epoch 36
-------------------------------
loss: 0.068368  [    0/69810]
loss: 0.063070  [ 6400/69810]
loss: 0.127775  [12800/69810]
loss: 0.093182  [19200/69810]
loss: 0.064742  [25600/69810]
loss: 0.100713  [32000/69810]
loss: 0.056687  [38400/69810]
loss: 0.072499  [44800/69810]
loss: 0.096136  [51200/69810]
loss: 0.164718  [57600/69810]
loss: 0.125875  [64000/69810]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.133534 

Epoch 37
-------------------------------
loss: 0.118315  [    0/69810]
loss: 0.083023  [ 6400/69810]
loss: 0.111722  [12800/69810]
loss: 0.060751  [19200/69810]
loss: 0.147104  [25600/69810]
loss: 0.162725  [32000/69810]
loss: 0.173844  [38400/69810]
loss: 0.091224  [44800/69810]
loss: 0.041772  [51200/69810]
loss: 0.094550  [57600/69810]
loss: 0.143990  [64000/69810]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.145385 

Epoch 38
-------------------------------
loss: 0.143225  [    0/69810]
loss: 0.052214  [ 6400/69810]
loss: 0.075504  [12800/69810]
loss: 0.180796  [19200/69810]
loss: 0.036278  [25600/69810]
loss: 0.082914  [32000/69810]
loss: 0.123210  [38400/69810]
loss: 0.032466  [44800/69810]
loss: 0.099685  [51200/69810]
loss: 0.113451  [57600/69810]
loss: 0.090913  [64000/69810]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.131500 

Epoch 39
-------------------------------
loss: 0.028472  [    0/69810]
loss: 0.315730  [ 6400/69810]
loss: 0.187369  [12800/69810]
loss: 0.100658  [19200/69810]
loss: 0.055134  [25600/69810]
loss: 0.057300  [32000/69810]
loss: 0.055628  [38400/69810]
loss: 0.074210  [44800/69810]
loss: 0.198817  [51200/69810]
loss: 0.170836  [57600/69810]
loss: 0.187927  [64000/69810]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.129571 

Epoch 40
-------------------------------
loss: 0.081184  [    0/69810]
loss: 0.256287  [ 6400/69810]
loss: 0.046471  [12800/69810]
loss: 0.085479  [19200/69810]
loss: 0.146514  [25600/69810]
loss: 0.029348  [32000/69810]
loss: 0.064925  [38400/69810]
loss: 0.045482  [44800/69810]
loss: 0.095028  [51200/69810]
loss: 0.046734  [57600/69810]
loss: 0.281723  [64000/69810]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.128293 

Epoch 41
-------------------------------
loss: 0.061553  [    0/69810]
loss: 0.152747  [ 6400/69810]
loss: 0.100788  [12800/69810]
loss: 0.136402  [19200/69810]
loss: 0.027704  [25600/69810]
loss: 1.637069  [32000/69810]
loss: 0.090600  [38400/69810]
loss: 0.085316  [44800/69810]
loss: 0.063701  [51200/69810]
loss: 0.036570  [57600/69810]
Epoch 19
-------------------------------
loss: 0.209441  [    0/69728]
loss: 0.075085  [ 6400/69728]
loss: 0.106229  [12800/69728]
loss: 0.271763  [19200/69728]
loss: 0.285382  [25600/69728]
loss: 0.153252  [32000/69728]
loss: 0.145609  [38400/69728]
loss: 0.328815  [44800/69728]
loss: 0.147087  [51200/69728]
loss: 0.198414  [57600/69728]
loss: 0.199268  [64000/69728]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.295610 

Epoch 20
-------------------------------
loss: 0.227013  [    0/69728]
loss: 0.190182  [ 6400/69728]
loss: 0.094111  [12800/69728]
loss: 0.139052  [19200/69728]
loss: 0.250082  [25600/69728]
loss: 0.214585  [32000/69728]
loss: 0.131425  [38400/69728]
loss: 0.138995  [44800/69728]
loss: 0.230360  [51200/69728]
loss: 0.228435  [57600/69728]
loss: 0.150379  [64000/69728]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.204188 

Epoch 21
-------------------------------
loss: 0.160228  [    0/69728]
loss: 0.155035  [ 6400/69728]
loss: 0.252146  [12800/69728]
loss: 0.160645  [19200/69728]
loss: 0.200724  [25600/69728]
loss: 0.109826  [32000/69728]
loss: 0.188258  [38400/69728]
loss: 0.174651  [44800/69728]
loss: 0.241439  [51200/69728]
loss: 0.168836  [57600/69728]
loss: 0.076968  [64000/69728]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.203714 

Epoch 22
-------------------------------
loss: 0.092769  [    0/69728]
loss: 0.138686  [ 6400/69728]
loss: 0.181484  [12800/69728]
loss: 0.101779  [19200/69728]
loss: 0.139965  [25600/69728]
loss: 0.125657  [32000/69728]
loss: 0.142220  [38400/69728]
loss: 0.182025  [44800/69728]
loss: 0.196014  [51200/69728]
loss: 0.182550  [57600/69728]
loss: 0.074550  [64000/69728]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.215610 

Epoch 23
-------------------------------
loss: 0.161280  [    0/69728]
loss: 0.270098  [ 6400/69728]
loss: 0.120656  [12800/69728]
loss: 0.109067  [19200/69728]
loss: 0.265928  [25600/69728]
loss: 0.128159  [32000/69728]
loss: 0.206844  [38400/69728]
loss: 0.314831  [44800/69728]
loss: 0.268643  [51200/69728]
loss: 0.184280  [57600/69728]
loss: 0.204277  [64000/69728]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.215388 

Epoch 24
-------------------------------
loss: 0.169131  [    0/69728]
loss: 0.095008  [ 6400/69728]
loss: 0.119418  [12800/69728]
loss: 0.084063  [19200/69728]
loss: 0.116109  [25600/69728]
loss: 0.123399  [32000/69728]
loss: 0.131756  [38400/69728]
loss: 0.205383  [44800/69728]
loss: 0.249512  [51200/69728]
loss: 0.092874  [57600/69728]
loss: 0.197306  [64000/69728]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.200331 

Epoch 25
-------------------------------
loss: 0.119577  [    0/69728]
loss: 1.819434  [ 6400/69728]
loss: 0.228289  [12800/69728]
loss: 0.129722  [19200/69728]
loss: 0.153673  [25600/69728]
loss: 0.154363  [32000/69728]
loss: 0.249548  [38400/69728]
loss: 0.137432  [44800/69728]
loss: 0.108106  [51200/69728]
loss: 0.158175  [57600/69728]
loss: 0.050468  [64000/69728]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.205189 

Epoch 26
-------------------------------
loss: 0.108746  [    0/69728]
loss: 0.202992  [ 6400/69728]
loss: 0.161795  [12800/69728]
loss: 0.082870  [19200/69728]
loss: 0.131493  [25600/69728]
loss: 0.208238  [32000/69728]
loss: 3.417479  [38400/69728]
loss: 0.124824  [44800/69728]
loss: 0.163425  [51200/69728]
loss: 0.105768  [57600/69728]
loss: 0.158332  [64000/69728]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.207212 

Epoch 27
-------------------------------
loss: 0.152670  [    0/69728]
loss: 0.105607  [ 6400/69728]
loss: 0.268420  [12800/69728]
loss: 0.141498  [19200/69728]
loss: 0.311752  [25600/69728]
loss: 0.224661  [32000/69728]
loss: 0.288350  [38400/69728]
loss: 0.167607  [44800/69728]
loss: 0.169618  [51200/69728]
loss: 0.241350  [57600/69728]
loss: 0.099352  [64000/69728]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.207359 

Epoch 28
-------------------------------
loss: 0.165557  [    0/69728]
loss: 0.223120  [ 6400/69728]
loss: 0.224024  [12800/69728]
loss: 0.175981  [19200/69728]
loss: 0.108025  [25600/69728]
loss: 0.227524  [32000/69728]
loss: 0.214279  [38400/69728]
loss: 0.088470  [44800/69728]
loss: 0.264201  [51200/69728]
loss: 0.136193  [57600/69728]
loss: 0.056193  [64000/69728]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.198289 

Epoch 29
-------------------------------
loss: 0.190503  [    0/69728]
loss: 0.092040  [ 6400/69728]
loss: 0.202501  [12800/69728]
loss: 0.199380  [19200/69728]
loss: 0.104543  [25600/69728]
loss: 0.086877  [32000/69728]
loss: 0.186414  [38400/69728]
loss: 0.115613  [44800/69728]
loss: 0.227547  [51200/69728]
loss: 0.061635  [57600/69728]
loss: 0.179842  [64000/69728]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.200685 

Epoch 30
-------------------------------
loss: 0.110861  [    0/69728]
loss: 0.112986  [ 6400/69728]
loss: 0.107752  [12800/69728]
loss: 1.622944  [19200/69728]
loss: 0.145134  [25600/69728]
loss: 0.122320  [32000/69728]
loss: 0.169922  [38400/69728]
loss: 0.114990  [44800/69728]
loss: 0.081529  [51200/69728]
loss: 0.229722  [57600/69728]
loss: 0.123020  [64000/69728]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.198400 

Epoch 31
-------------------------------
loss: 0.109454  [    0/69728]
loss: 0.099545  [ 6400/69728]
loss: 0.189900  [12800/69728]
loss: 0.097361  [19200/69728]
loss: 0.194221  [25600/69728]
loss: 0.308541  [32000/69728]
loss: 0.248246  [38400/69728]
loss: 0.177971  [44800/69728]
loss: 0.252898  [51200/69728]
loss: 0.194663  [57600/69728]
loss: 0.176045  [64000/69728]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.207832 

Epoch 32
-------------------------------
loss: 0.088366  [    0/69728]
loss: 0.167200  [ 6400/69728]
loss: 0.162165  [12800/69728]
loss: 0.214323  [19200/69728]
loss: 0.155813  [25600/69728]
loss: 0.119961  [32000/69728]
loss: 0.136003  [38400/69728]
loss: 0.208346  [44800/69728]
loss: 0.113769  [51200/69728]
loss: 0.056429  [57600/69728]
loss: 0.141989  [64000/69728]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.228699 

Epoch 33
-------------------------------
loss: 0.288901  [    0/69728]
loss: 0.081698  [ 6400/69728]
loss: 0.196575  [12800/69728]
loss: 0.142753  [19200/69728]
loss: 0.099511  [25600/69728]
loss: 0.170599  [32000/69728]
loss: 0.273296  [38400/69728]
loss: 0.212820  [44800/69728]
loss: 0.147150  [51200/69728]
loss: 0.246526  [57600/69728]
loss: 0.164131  [64000/69728]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.203944 

Epoch 34
-------------------------------
loss: 0.081236  [    0/69728]
loss: 0.274414  [ 6400/69728]
loss: 0.168898  [12800/69728]
loss: 0.268392  [19200/69728]
loss: 0.119263  [25600/69728]
loss: 0.090406  [32000/69728]
loss: 0.254624  [38400/69728]
loss: 0.207489  [44800/69728]
loss: 0.172099  [51200/69728]
loss: 0.264934  [57600/69728]
loss: 0.203259  [64000/69728]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.201642 

Epoch 35
-------------------------------
loss: 0.096538  [    0/69728]
loss: 0.210361  [ 6400/69728]
loss: 0.141744  [12800/69728]
loss: 0.073687  [19200/69728]
loss: 0.124143  [25600/69728]
loss: 0.092393  [32000/69728]
loss: 0.478739  [38400/69728]
loss: 0.170056  [44800/69728]
loss: 0.218568  [51200/69728]
loss: 0.081176  [57600/69728]
loss: 0.099864  [64000/69728]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.198022 

Epoch 36
-------------------------------
loss: 0.147623  [    0/69728]
loss: 0.096164  [ 6400/69728]
loss: 0.116101  [12800/69728]
loss: 0.138193  [19200/69728]
loss: 0.212947  [25600/69728]
loss: 0.237554  [32000/69728]
loss: 0.189385  [38400/69728]
loss: 0.138769  [44800/69728]
loss: 0.223331  [51200/69728]
loss: 0.225179  [57600/69728]
loss: 0.225600  [64000/69728]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.196589 

Epoch 37
-------------------------------
loss: 0.206280  [    0/69728]
loss: 0.184921  [ 6400/69728]
loss: 0.113572  [12800/69728]
loss: 0.075530  [19200/69728]
loss: 0.086890  [25600/69728]
loss: 0.063591  [32000/69728]
loss: 0.108578  [38400/69728]
loss: 0.164187  [44800/69728]
loss: 0.307033  [51200/69728]
loss: 0.094981  [57600/69728]
loss: 0.140279  [64000/69728]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.203800 

Epoch 38
-------------------------------
loss: 1.667962  [    0/69728]
loss: 0.112345  [ 6400/69728]
loss: 0.171374  [12800/69728]
2022/09/20 17:10:33 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:10:35 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.100478  [ 6400/70080]
loss: 0.135727  [12800/70080]
loss: 0.067336  [19200/70080]
loss: 0.121822  [25600/70080]
loss: 0.063239  [32000/70080]
loss: 0.144035  [38400/70080]
loss: 0.110641  [44800/70080]
loss: 0.134437  [51200/70080]
loss: 0.063123  [57600/70080]
loss: 0.089938  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140559 

Epoch 27
-------------------------------
loss: 0.126892  [    0/70080]
loss: 0.140754  [ 6400/70080]
loss: 0.094190  [12800/70080]
loss: 0.252574  [19200/70080]
loss: 0.123125  [25600/70080]
loss: 0.172077  [32000/70080]
loss: 0.191660  [38400/70080]
loss: 0.085143  [44800/70080]
loss: 0.138686  [51200/70080]
loss: 0.061909  [57600/70080]
loss: 0.081099  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140715 

Epoch 28
-------------------------------
loss: 0.120358  [    0/70080]
loss: 0.177934  [ 6400/70080]
loss: 0.070777  [12800/70080]
loss: 0.050140  [19200/70080]
loss: 0.115454  [25600/70080]
loss: 0.078441  [32000/70080]
loss: 0.167169  [38400/70080]
loss: 0.094597  [44800/70080]
loss: 0.171321  [51200/70080]
loss: 0.202083  [57600/70080]
loss: 0.129983  [64000/70080]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.136614 

Epoch 29
-------------------------------
loss: 0.082926  [    0/70080]
loss: 0.074876  [ 6400/70080]
loss: 0.153040  [12800/70080]
loss: 0.195142  [19200/70080]
loss: 0.123422  [25600/70080]
loss: 0.204917  [32000/70080]
loss: 0.135495  [38400/70080]
loss: 0.041609  [44800/70080]
loss: 0.108522  [51200/70080]
loss: 0.095283  [57600/70080]
loss: 0.025085  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.142977 

Epoch 30
-------------------------------
loss: 0.110604  [    0/70080]
loss: 0.206180  [ 6400/70080]
loss: 0.037049  [12800/70080]
loss: 0.122117  [19200/70080]
loss: 0.118418  [25600/70080]
loss: 0.150726  [32000/70080]
loss: 0.162777  [38400/70080]
loss: 0.148305  [44800/70080]
loss: 0.102132  [51200/70080]
loss: 0.250415  [57600/70080]
loss: 0.113809  [64000/70080]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.137124 

Epoch 31
-------------------------------
loss: 0.090954  [    0/70080]
loss: 0.159685  [ 6400/70080]
loss: 0.066103  [12800/70080]
loss: 0.080087  [19200/70080]
loss: 0.101200  [25600/70080]
loss: 0.275545  [32000/70080]
loss: 0.066650  [38400/70080]
loss: 0.153390  [44800/70080]
loss: 0.166710  [51200/70080]
loss: 0.067263  [57600/70080]
loss: 0.200678  [64000/70080]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.130151 

Epoch 32
-------------------------------
loss: 0.121281  [    0/70080]
loss: 0.121149  [ 6400/70080]
loss: 0.207112  [12800/70080]
loss: 0.230911  [19200/70080]
loss: 0.086575  [25600/70080]
loss: 0.091366  [32000/70080]
loss: 0.054478  [38400/70080]
loss: 0.082200  [44800/70080]
loss: 0.131863  [51200/70080]
loss: 0.063951  [57600/70080]
loss: 0.051119  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.145308 

Epoch 33
-------------------------------
loss: 0.061543  [    0/70080]
loss: 0.091697  [ 6400/70080]
loss: 0.161988  [12800/70080]
loss: 0.039316  [19200/70080]
loss: 0.142072  [25600/70080]
loss: 0.161800  [32000/70080]
loss: 0.178195  [38400/70080]
loss: 0.066141  [44800/70080]
loss: 0.286426  [51200/70080]
loss: 0.046063  [57600/70080]
loss: 0.243019  [64000/70080]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.146612 

Epoch 34
-------------------------------
loss: 0.074349  [    0/70080]
loss: 0.061652  [ 6400/70080]
loss: 0.055198  [12800/70080]
loss: 0.151668  [19200/70080]
loss: 0.056803  [25600/70080]
loss: 0.173648  [32000/70080]
loss: 0.058114  [38400/70080]
loss: 0.074987  [44800/70080]
loss: 0.240899  [51200/70080]
loss: 0.113711  [57600/70080]
loss: 0.243006  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.132759 

Epoch 35
-------------------------------
loss: 0.115041  [    0/70080]
loss: 0.109321  [ 6400/70080]
loss: 0.073765  [12800/70080]
loss: 0.186005  [19200/70080]
loss: 0.079853  [25600/70080]
loss: 0.149494  [32000/70080]
loss: 0.130292  [38400/70080]
loss: 0.101277  [44800/70080]
loss: 0.154708  [51200/70080]
loss: 0.098486  [57600/70080]
loss: 0.136645  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.141021 

Epoch 36
-------------------------------
loss: 0.078311  [    0/70080]
loss: 0.147046  [ 6400/70080]
loss: 0.075710  [12800/70080]
loss: 0.090283  [19200/70080]
loss: 0.017610  [25600/70080]
loss: 0.019999  [32000/70080]
loss: 0.133411  [38400/70080]
loss: 0.091518  [44800/70080]
loss: 1.618769  [51200/70080]
loss: 0.198490  [57600/70080]
loss: 0.118005  [64000/70080]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.130435 

Epoch 37
-------------------------------
loss: 0.080810  [    0/70080]
loss: 0.050347  [ 6400/70080]
loss: 0.083089  [12800/70080]
loss: 0.075687  [19200/70080]
loss: 0.093591  [25600/70080]
loss: 0.098807  [32000/70080]
loss: 0.121036  [38400/70080]
loss: 0.071505  [44800/70080]
loss: 0.134984  [51200/70080]
loss: 0.099326  [57600/70080]
loss: 0.102566  [64000/70080]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.138801 

Epoch 38
-------------------------------
loss: 0.070020  [    0/70080]
loss: 0.167497  [ 6400/70080]
loss: 0.052874  [12800/70080]
loss: 0.072991  [19200/70080]
loss: 0.110619  [25600/70080]
loss: 0.061381  [32000/70080]
loss: 0.116981  [38400/70080]
loss: 0.088502  [44800/70080]
loss: 0.193821  [51200/70080]
loss: 0.112511  [57600/70080]
loss: 0.093731  [64000/70080]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.131919 

Epoch 39
-------------------------------
loss: 0.038220  [    0/70080]
loss: 0.031592  [ 6400/70080]
loss: 0.066502  [12800/70080]
loss: 0.052897  [19200/70080]
loss: 0.129841  [25600/70080]
loss: 0.078242  [32000/70080]
loss: 0.063877  [38400/70080]
loss: 0.032324  [44800/70080]
loss: 0.106341  [51200/70080]
loss: 0.178266  [57600/70080]
loss: 0.068749  [64000/70080]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.137535 

Epoch 40
-------------------------------
loss: 0.016266  [    0/70080]
loss: 0.085137  [ 6400/70080]
loss: 0.049324  [12800/70080]
loss: 0.069426  [19200/70080]
loss: 0.144431  [25600/70080]
loss: 0.082162  [32000/70080]
loss: 0.110074  [38400/70080]
loss: 0.048024  [44800/70080]
loss: 0.045663  [51200/70080]
loss: 0.159842  [57600/70080]
loss: 0.062760  [64000/70080]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.141998 

Epoch 41
-------------------------------
loss: 0.036439  [    0/70080]
loss: 0.069671  [ 6400/70080]
loss: 0.087985  [12800/70080]
loss: 0.096612  [19200/70080]
loss: 0.059708  [25600/70080]
loss: 0.138615  [32000/70080]
loss: 0.084031  [38400/70080]
loss: 0.061059  [44800/70080]
loss: 0.103642  [51200/70080]
loss: 0.022482  [57600/70080]
loss: 0.129674  [64000/70080]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.142328 

Epoch 42
-------------------------------
loss: 0.036019  [    0/70080]
loss: 0.197498  [ 6400/70080]
loss: 0.094501  [12800/70080]
loss: 0.044409  [19200/70080]
loss: 0.075065  [25600/70080]
loss: 0.267960  [32000/70080]
loss: 0.244911  [38400/70080]
loss: 0.120471  [44800/70080]
loss: 0.104350  [51200/70080]
loss: 0.205359  [57600/70080]
loss: 0.074729  [64000/70080]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.142763 

Epoch 43
-------------------------------
loss: 0.033850  [    0/70080]
loss: 0.280609  [ 6400/70080]
loss: 0.083754  [12800/70080]
loss: 0.040760  [19200/70080]
loss: 0.103810  [25600/70080]
loss: 0.237316  [32000/70080]
loss: 0.091394  [38400/70080]
loss: 0.056535  [44800/70080]
loss: 0.144054  [51200/70080]
loss: 0.097455  [57600/70080]
loss: 0.159862  [64000/70080]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.143561 

Epoch 44
-------------------------------
loss: 0.138714  [    0/70080]
loss: 0.072817  [ 6400/70080]
loss: 0.081305  [12800/70080]
loss: 0.041632  [19200/70080]
loss: 0.110190  [25600/70080]
loss: 0.103305  [32000/70080]
loss: 0.102085  [38400/70080]
loss: 0.143164  [44800/70080]
loss: 0.083818  [51200/70080]
loss: 0.099616  [57600/70080]
loss: 0.057265  [64000/70080]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.136337 

Epoch 45
-------------------------------
loss: 0.096066  [    0/70080]
loss: 0.051203  [ 6400/70080]
loss: 0.093707  [12800/70080]
loss: 0.071930  [19200/70080]
loss: 0.054715  [25600/70080]
loss: 0.093664  [32000/70080]
Epoch 26
-------------------------------
loss: 0.075637  [    0/69865]
loss: 0.233962  [ 6400/69865]
loss: 0.197747  [12800/69865]
loss: 0.155905  [19200/69865]
loss: 0.137788  [25600/69865]
loss: 0.083917  [32000/69865]
loss: 0.173778  [38400/69865]
loss: 0.213905  [44800/69865]
loss: 0.228735  [51200/69865]
loss: 0.181791  [57600/69865]
loss: 0.123970  [64000/69865]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.199359 

Epoch 27
-------------------------------
loss: 0.098685  [    0/69865]
loss: 0.197827  [ 6400/69865]
loss: 0.119727  [12800/69865]
loss: 0.211758  [19200/69865]
loss: 0.143650  [25600/69865]
loss: 0.232717  [32000/69865]
loss: 0.183536  [38400/69865]
loss: 0.119027  [44800/69865]
loss: 0.171350  [51200/69865]
loss: 0.188200  [57600/69865]
loss: 0.139917  [64000/69865]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.197192 

Epoch 28
-------------------------------
loss: 0.191341  [    0/69865]
loss: 0.267796  [ 6400/69865]
loss: 0.167825  [12800/69865]
loss: 0.221734  [19200/69865]
loss: 0.150245  [25600/69865]
loss: 0.127397  [32000/69865]
loss: 0.358071  [38400/69865]
loss: 0.164976  [44800/69865]
loss: 0.217121  [51200/69865]
loss: 0.095424  [57600/69865]
loss: 0.180830  [64000/69865]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.188706 

Epoch 29
-------------------------------
loss: 0.136063  [    0/69865]
loss: 0.172556  [ 6400/69865]
loss: 0.160434  [12800/69865]
loss: 0.251500  [19200/69865]
loss: 0.184292  [25600/69865]
loss: 0.390039  [32000/69865]
loss: 0.159779  [38400/69865]
loss: 0.097365  [44800/69865]
loss: 0.182483  [51200/69865]
loss: 0.310415  [57600/69865]
loss: 0.206491  [64000/69865]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.215591 

Epoch 30
-------------------------------
loss: 0.201628  [    0/69865]
loss: 0.088358  [ 6400/69865]
loss: 0.113305  [12800/69865]
loss: 0.096812  [19200/69865]
loss: 0.277524  [25600/69865]
loss: 0.176986  [32000/69865]
loss: 0.159105  [38400/69865]
loss: 0.121697  [44800/69865]
loss: 0.318967  [51200/69865]
loss: 0.252758  [57600/69865]
loss: 0.127598  [64000/69865]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.198345 

Epoch 31
-------------------------------
loss: 0.164194  [    0/69865]
loss: 0.191487  [ 6400/69865]
loss: 0.241199  [12800/69865]
loss: 0.127384  [19200/69865]
loss: 0.144536  [25600/69865]
loss: 0.208396  [32000/69865]
loss: 0.134796  [38400/69865]
loss: 0.125167  [44800/69865]
loss: 0.131264  [51200/69865]
loss: 0.198164  [57600/69865]
loss: 0.202267  [64000/69865]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.195002 

Epoch 32
-------------------------------
loss: 0.183754  [    0/69865]
loss: 0.122946  [ 6400/69865]
loss: 0.175746  [12800/69865]
loss: 0.200976  [19200/69865]
loss: 0.186644  [25600/69865]
loss: 0.239955  [32000/69865]
loss: 0.142580  [38400/69865]
loss: 0.188549  [44800/69865]
loss: 0.218206  [51200/69865]
loss: 0.212329  [57600/69865]
loss: 0.365803  [64000/69865]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.197792 

Epoch 33
-------------------------------
loss: 0.142591  [    0/69865]
loss: 0.181111  [ 6400/69865]
loss: 0.138281  [12800/69865]
loss: 0.122913  [19200/69865]
loss: 0.113017  [25600/69865]
loss: 0.127610  [32000/69865]
loss: 0.202503  [38400/69865]
loss: 0.162838  [44800/69865]
loss: 0.219533  [51200/69865]
loss: 0.208574  [57600/69865]
loss: 0.178235  [64000/69865]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.198494 

Epoch 34
-------------------------------
loss: 0.127907  [    0/69865]
loss: 0.292536  [ 6400/69865]
loss: 0.183536  [12800/69865]
loss: 0.170876  [19200/69865]
loss: 0.229201  [25600/69865]
loss: 0.181912  [32000/69865]
loss: 0.151222  [38400/69865]
loss: 0.248323  [44800/69865]
loss: 0.161094  [51200/69865]
loss: 0.097286  [57600/69865]
loss: 0.145715  [64000/69865]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.201563 

Epoch 35
-------------------------------
loss: 1.688322  [    0/69865]
loss: 0.196465  [ 6400/69865]
loss: 0.109500  [12800/69865]
loss: 0.165468  [19200/69865]
loss: 0.197263  [25600/69865]
loss: 0.543915  [32000/69865]
loss: 0.110761  [38400/69865]
loss: 0.123057  [44800/69865]
loss: 0.254144  [51200/69865]
loss: 0.117164  [57600/69865]
loss: 0.182310  [64000/69865]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.191273 

Epoch 36
-------------------------------
loss: 0.152454  [    0/69865]
loss: 0.194712  [ 6400/69865]
loss: 0.362326  [12800/69865]
loss: 0.258517  [19200/69865]
loss: 0.242168  [25600/69865]
loss: 0.184681  [32000/69865]
loss: 0.244836  [38400/69865]
loss: 0.187545  [44800/69865]
loss: 0.145876  [51200/69865]
loss: 0.169257  [57600/69865]
loss: 0.265174  [64000/69865]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.194174 

Epoch 37
-------------------------------
loss: 0.153395  [    0/69865]
loss: 0.142504  [ 6400/69865]
loss: 0.155526  [12800/69865]
loss: 0.143859  [19200/69865]
loss: 0.147410  [25600/69865]
loss: 0.165292  [32000/69865]
loss: 0.091845  [38400/69865]
loss: 0.126531  [44800/69865]
loss: 0.195196  [51200/69865]
loss: 0.154465  [57600/69865]
loss: 0.228155  [64000/69865]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.180360 

Epoch 38
-------------------------------
loss: 0.084796  [    0/69865]
loss: 0.121422  [ 6400/69865]
loss: 0.087227  [12800/69865]
loss: 0.174830  [19200/69865]
loss: 0.180282  [25600/69865]
loss: 0.265647  [32000/69865]
loss: 0.204586  [38400/69865]
loss: 0.115808  [44800/69865]
loss: 0.198107  [51200/69865]
loss: 0.165574  [57600/69865]
loss: 0.126840  [64000/69865]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.193437 

Epoch 39
-------------------------------
loss: 0.243541  [    0/69865]
loss: 0.136435  [ 6400/69865]
loss: 0.228716  [12800/69865]
loss: 0.212473  [19200/69865]
loss: 0.200632  [25600/69865]
loss: 0.157913  [32000/69865]
loss: 0.166788  [38400/69865]
loss: 0.088697  [44800/69865]
loss: 0.249975  [51200/69865]
loss: 0.126465  [57600/69865]
loss: 0.249431  [64000/69865]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.192371 

Epoch 40
-------------------------------
loss: 0.108902  [    0/69865]
loss: 0.175280  [ 6400/69865]
loss: 0.114417  [12800/69865]
loss: 0.312921  [19200/69865]
loss: 0.221873  [25600/69865]
loss: 0.211972  [32000/69865]
loss: 0.116233  [38400/69865]
loss: 0.163395  [44800/69865]
loss: 0.134504  [51200/69865]
loss: 0.154943  [57600/69865]
loss: 0.178230  [64000/69865]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.198835 

Epoch 41
-------------------------------
loss: 0.204720  [    0/69865]
loss: 0.162579  [ 6400/69865]
loss: 0.159621  [12800/69865]
loss: 0.211081  [19200/69865]
loss: 0.148987  [25600/69865]
loss: 0.077234  [32000/69865]
loss: 0.194319  [38400/69865]
loss: 0.211994  [44800/69865]
loss: 0.077387  [51200/69865]
loss: 0.220241  [57600/69865]
loss: 0.117303  [64000/69865]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.206989 

Epoch 42
-------------------------------
loss: 0.169706  [    0/69865]
loss: 0.094693  [ 6400/69865]
loss: 0.204365  [12800/69865]
loss: 0.156543  [19200/69865]
loss: 0.178745  [25600/69865]
loss: 0.234578  [32000/69865]
loss: 0.202854  [38400/69865]
loss: 0.148679  [44800/69865]
loss: 0.183108  [51200/69865]
loss: 0.083014  [57600/69865]
loss: 0.134626  [64000/69865]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.194422 

Epoch 43
-------------------------------
loss: 0.082184  [    0/69865]
loss: 0.228856  [ 6400/69865]
loss: 0.152495  [12800/69865]
loss: 0.154701  [19200/69865]
loss: 0.332695  [25600/69865]
loss: 0.131344  [32000/69865]
loss: 0.118027  [38400/69865]
loss: 0.171678  [44800/69865]
loss: 0.094519  [51200/69865]
loss: 0.170675  [57600/69865]
loss: 0.195847  [64000/69865]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.202876 

Epoch 44
-------------------------------
loss: 0.214257  [    0/69865]
loss: 0.294696  [ 6400/69865]
loss: 0.124837  [12800/69865]
loss: 0.064318  [19200/69865]
loss: 0.114983  [25600/69865]
loss: 0.156317  [32000/69865]
loss: 0.232874  [38400/69865]
loss: 0.110764  [44800/69865]
loss: 0.089451  [51200/69865]
loss: 0.170498  [57600/69865]
loss: 0.217393  [64000/69865]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.195217 

Epoch 45
-------------------------------
loss: 0.174343  [    0/69865]
loss: 0.108940  [ 6400/69865]
loss: 0.156655  [12800/69865]
loss: 0.109359  [    0/70738]
loss: 0.122269  [ 6400/70738]
loss: 0.159723  [12800/70738]
loss: 0.096053  [19200/70738]
loss: 0.158083  [25600/70738]
loss: 0.102431  [32000/70738]
loss: 0.239813  [38400/70738]
loss: 0.115700  [44800/70738]
loss: 0.174328  [51200/70738]
loss: 0.211481  [57600/70738]
loss: 0.179714  [64000/70738]
loss: 0.172421  [70400/70738]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.195354 

Epoch 14
-------------------------------
loss: 0.128150  [    0/70738]
loss: 0.136858  [ 6400/70738]
loss: 0.186574  [12800/70738]
loss: 0.099187  [19200/70738]
loss: 0.108806  [25600/70738]
loss: 0.065358  [32000/70738]
loss: 0.117122  [38400/70738]
loss: 0.075744  [44800/70738]
loss: 0.141034  [51200/70738]
loss: 0.074325  [57600/70738]
loss: 0.191264  [64000/70738]
loss: 1.697426  [70400/70738]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.191551 

Epoch 15
-------------------------------
loss: 0.072626  [    0/70738]
loss: 0.223058  [ 6400/70738]
loss: 0.167217  [12800/70738]
loss: 0.120533  [19200/70738]
loss: 0.265367  [25600/70738]
loss: 0.052432  [32000/70738]
loss: 0.189250  [38400/70738]
loss: 0.087694  [44800/70738]
loss: 0.170870  [51200/70738]
loss: 0.168606  [57600/70738]
loss: 0.097164  [64000/70738]
loss: 0.382394  [70400/70738]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.190506 

Epoch 16
-------------------------------
loss: 0.166528  [    0/70738]
loss: 0.171801  [ 6400/70738]
loss: 0.104214  [12800/70738]
loss: 0.148570  [19200/70738]
loss: 0.124313  [25600/70738]
loss: 0.251100  [32000/70738]
loss: 0.139606  [38400/70738]
loss: 0.170894  [44800/70738]
loss: 0.214702  [51200/70738]
loss: 0.236053  [57600/70738]
loss: 0.284671  [64000/70738]
loss: 0.091554  [70400/70738]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.186118 

Epoch 17
-------------------------------
loss: 0.211328  [    0/70738]
loss: 0.191844  [ 6400/70738]
loss: 0.224844  [12800/70738]
loss: 0.296914  [19200/70738]
loss: 0.123030  [25600/70738]
loss: 0.180330  [32000/70738]
loss: 0.212116  [38400/70738]
loss: 0.221530  [44800/70738]
loss: 0.230606  [51200/70738]
loss: 0.145169  [57600/70738]
loss: 0.122576  [64000/70738]
loss: 0.160876  [70400/70738]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.201140 

Epoch 18
-------------------------------
loss: 0.307202  [    0/70738]
loss: 0.148242  [ 6400/70738]
loss: 0.081885  [12800/70738]
loss: 0.152395  [19200/70738]
loss: 0.089799  [25600/70738]
loss: 0.137870  [32000/70738]
loss: 0.240708  [38400/70738]
loss: 0.125791  [44800/70738]
loss: 0.184145  [51200/70738]
loss: 0.151904  [57600/70738]
loss: 0.121179  [64000/70738]
loss: 0.124375  [70400/70738]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.183258 

Epoch 19
-------------------------------
loss: 0.116411  [    0/70738]
loss: 0.159833  [ 6400/70738]
loss: 0.089588  [12800/70738]
loss: 0.167677  [19200/70738]
loss: 0.088649  [25600/70738]
loss: 1.688425  [32000/70738]
loss: 0.195718  [38400/70738]
loss: 0.254747  [44800/70738]
loss: 0.108351  [51200/70738]
loss: 0.193565  [57600/70738]
loss: 0.139429  [64000/70738]
loss: 0.201720  [70400/70738]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.216667 

Epoch 20
-------------------------------
loss: 0.102730  [    0/70738]
loss: 0.077407  [ 6400/70738]
loss: 0.140716  [12800/70738]
loss: 0.062044  [19200/70738]
loss: 0.128069  [25600/70738]
loss: 0.060569  [32000/70738]
loss: 0.083213  [38400/70738]
loss: 0.254409  [44800/70738]
loss: 0.117693  [51200/70738]
loss: 0.178078  [57600/70738]
loss: 0.209062  [64000/70738]
loss: 0.176206  [70400/70738]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.231904 

Epoch 21
-------------------------------
loss: 0.129566  [    0/70738]
loss: 0.128353  [ 6400/70738]
loss: 0.140577  [12800/70738]
loss: 1.628863  [19200/70738]
loss: 0.123446  [25600/70738]
loss: 0.106238  [32000/70738]
loss: 0.076282  [38400/70738]
loss: 0.320049  [44800/70738]
loss: 0.111383  [51200/70738]
loss: 0.148118  [57600/70738]
loss: 0.144852  [64000/70738]
loss: 0.160040  [70400/70738]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.190916 

Epoch 22
-------------------------------
loss: 0.175844  [    0/70738]
loss: 0.115681  [ 6400/70738]
loss: 0.154022  [12800/70738]
loss: 0.155166  [19200/70738]
loss: 0.076727  [25600/70738]
loss: 0.091198  [32000/70738]
loss: 0.169324  [38400/70738]
loss: 0.199876  [44800/70738]
loss: 0.037474  [51200/70738]
loss: 0.174091  [57600/70738]
loss: 0.167544  [64000/70738]
loss: 0.133671  [70400/70738]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.189973 

Epoch 23
-------------------------------
loss: 0.208809  [    0/70738]
loss: 0.213676  [ 6400/70738]
loss: 1.724526  [12800/70738]
loss: 0.119531  [19200/70738]
loss: 0.138557  [25600/70738]
loss: 0.072724  [32000/70738]
loss: 0.104791  [38400/70738]
loss: 0.098270  [44800/70738]
loss: 0.127104  [51200/70738]
loss: 0.098271  [57600/70738]
loss: 0.162987  [64000/70738]
loss: 0.147184  [70400/70738]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.196431 

Epoch 24
-------------------------------
loss: 0.132412  [    0/70738]
loss: 0.193945  [ 6400/70738]
loss: 0.070587  [12800/70738]
loss: 0.061128  [19200/70738]
loss: 0.167010  [25600/70738]
loss: 0.185377  [32000/70738]
loss: 0.090254  [38400/70738]
loss: 0.114705  [44800/70738]
loss: 0.134180  [51200/70738]
loss: 0.147411  [57600/70738]
loss: 0.079473  [64000/70738]
loss: 0.390614  [70400/70738]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.182586 

Epoch 25
-------------------------------
loss: 0.096490  [    0/70738]
loss: 0.109564  [ 6400/70738]
loss: 0.111226  [12800/70738]
loss: 0.158392  [19200/70738]
loss: 0.047288  [25600/70738]
loss: 0.121822  [32000/70738]
loss: 0.155565  [38400/70738]
loss: 0.117738  [44800/70738]
loss: 0.212919  [51200/70738]
loss: 0.229533  [57600/70738]
loss: 0.193436  [64000/70738]
loss: 0.069634  [70400/70738]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.182419 

Epoch 26
-------------------------------
loss: 0.162878  [    0/70738]
loss: 0.113744  [ 6400/70738]
loss: 0.198579  [12800/70738]
loss: 0.101438  [19200/70738]
loss: 0.107000  [25600/70738]
loss: 0.113193  [32000/70738]
loss: 0.045795  [38400/70738]
loss: 0.197254  [44800/70738]
loss: 0.107716  [51200/70738]
loss: 1.809117  [57600/70738]
loss: 0.116900  [64000/70738]
loss: 0.107884  [70400/70738]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.178730 

Epoch 27
-------------------------------
loss: 0.107943  [    0/70738]
loss: 0.167590  [ 6400/70738]
loss: 0.229727  [12800/70738]
loss: 0.124938  [19200/70738]
loss: 0.180766  [25600/70738]
loss: 0.194821  [32000/70738]
loss: 0.118970  [38400/70738]
loss: 1.743769  [44800/70738]
loss: 0.140409  [51200/70738]
loss: 0.182658  [57600/70738]
loss: 1.887932  [64000/70738]
loss: 0.184317  [70400/70738]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.197595 

Epoch 28
-------------------------------
loss: 0.103556  [    0/70738]
loss: 0.153753  [ 6400/70738]
loss: 0.125783  [12800/70738]
loss: 0.220194  [19200/70738]
loss: 0.132608  [25600/70738]
loss: 0.213847  [32000/70738]
loss: 0.175639  [38400/70738]
loss: 0.083797  [44800/70738]
loss: 0.173074  [51200/70738]
loss: 0.110138  [57600/70738]
loss: 0.058097  [64000/70738]
loss: 0.193742  [70400/70738]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.199941 

Epoch 29
-------------------------------
loss: 0.225795  [    0/70738]
loss: 0.124409  [ 6400/70738]
loss: 0.107104  [12800/70738]
loss: 0.245140  [19200/70738]
loss: 0.090396  [25600/70738]
loss: 0.199642  [32000/70738]
loss: 0.103732  [38400/70738]
loss: 0.162692  [44800/70738]
loss: 0.104801  [51200/70738]
loss: 0.092848  [57600/70738]
loss: 0.074619  [64000/70738]
loss: 0.170632  [70400/70738]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.182163 

Epoch 30
-------------------------------
loss: 0.095344  [    0/70738]
loss: 0.193542  [ 6400/70738]
loss: 0.055049  [12800/70738]
loss: 0.108086  [19200/70738]
loss: 0.175435  [25600/70738]
loss: 0.173890  [32000/70738]
loss: 1.788586  [38400/70738]
loss: 0.056049  [44800/70738]
loss: 0.055620  [51200/70738]
loss: 0.106111  [57600/70738]
loss: 0.202548  [64000/70738]
loss: 1.652596  [70400/70738]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.197031 

Epoch 31
-------------------------------
loss: 0.186385  [    0/70738]
loss: 0.134225  [32000/71041]
loss: 0.096465  [38400/71041]
loss: 0.151939  [44800/71041]
loss: 0.051454  [51200/71041]
loss: 0.142748  [57600/71041]
loss: 0.205252  [64000/71041]
loss: 0.032073  [70400/71041]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.147655 

Epoch 25
-------------------------------
loss: 0.073379  [    0/71041]
loss: 0.079924  [ 6400/71041]
loss: 0.130981  [12800/71041]
loss: 0.123353  [19200/71041]
loss: 0.069693  [25600/71041]
loss: 0.095820  [32000/71041]
loss: 0.135537  [38400/71041]
loss: 0.047097  [44800/71041]
loss: 0.063687  [51200/71041]
loss: 0.138731  [57600/71041]
loss: 0.064413  [64000/71041]
loss: 0.067111  [70400/71041]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.148746 

Epoch 26
-------------------------------
loss: 0.090821  [    0/71041]
loss: 0.081276  [ 6400/71041]
loss: 0.169513  [12800/71041]
loss: 0.086982  [19200/71041]
loss: 0.080854  [25600/71041]
loss: 0.080733  [32000/71041]
loss: 0.119037  [38400/71041]
loss: 0.133268  [44800/71041]
loss: 0.128329  [51200/71041]
loss: 0.135464  [57600/71041]
loss: 0.031740  [64000/71041]
loss: 0.075056  [70400/71041]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.153580 

Epoch 27
-------------------------------
loss: 0.103687  [    0/71041]
loss: 0.157967  [ 6400/71041]
loss: 0.061604  [12800/71041]
loss: 0.096447  [19200/71041]
loss: 0.179659  [25600/71041]
loss: 0.081076  [32000/71041]
loss: 0.040396  [38400/71041]
loss: 0.103852  [44800/71041]
loss: 0.032588  [51200/71041]
loss: 0.114691  [57600/71041]
loss: 0.058250  [64000/71041]
loss: 0.123962  [70400/71041]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.150324 

Epoch 28
-------------------------------
loss: 0.111371  [    0/71041]
loss: 0.051273  [ 6400/71041]
loss: 0.061874  [12800/71041]
loss: 0.099623  [19200/71041]
loss: 0.168004  [25600/71041]
loss: 0.015684  [32000/71041]
loss: 0.083476  [38400/71041]
loss: 0.085802  [44800/71041]
loss: 0.173271  [51200/71041]
loss: 0.053830  [57600/71041]
loss: 0.156304  [64000/71041]
loss: 0.118439  [70400/71041]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.146213 

Epoch 29
-------------------------------
loss: 0.037373  [    0/71041]
loss: 0.127306  [ 6400/71041]
loss: 0.024421  [12800/71041]
loss: 0.157986  [19200/71041]
loss: 0.087028  [25600/71041]
loss: 0.125403  [32000/71041]
loss: 0.141308  [38400/71041]
loss: 0.157902  [44800/71041]
loss: 0.040260  [51200/71041]
loss: 0.064253  [57600/71041]
loss: 1.646314  [64000/71041]
loss: 0.076375  [70400/71041]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.148065 

Epoch 30
-------------------------------
loss: 0.147111  [    0/71041]
loss: 0.112045  [ 6400/71041]
loss: 0.111823  [12800/71041]
loss: 0.141840  [19200/71041]
loss: 0.084679  [25600/71041]
loss: 0.075467  [32000/71041]
loss: 0.060984  [38400/71041]
loss: 0.049648  [44800/71041]
loss: 0.103459  [51200/71041]
loss: 0.126889  [57600/71041]
loss: 0.131242  [64000/71041]
loss: 0.082536  [70400/71041]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.151274 

Epoch 31
-------------------------------
loss: 0.054323  [    0/71041]
loss: 0.161102  [ 6400/71041]
loss: 0.092811  [12800/71041]
loss: 0.171498  [19200/71041]
loss: 0.094775  [25600/71041]
loss: 0.084270  [32000/71041]
loss: 0.077011  [38400/71041]
loss: 0.085552  [44800/71041]
loss: 0.136765  [51200/71041]
loss: 0.045820  [57600/71041]
loss: 0.096764  [64000/71041]
loss: 0.296635  [70400/71041]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.144226 

Epoch 32
-------------------------------
loss: 0.042494  [    0/71041]
loss: 0.088162  [ 6400/71041]
loss: 0.066469  [12800/71041]
loss: 0.072467  [19200/71041]
loss: 0.196010  [25600/71041]
loss: 0.076622  [32000/71041]
loss: 0.164427  [38400/71041]
loss: 0.123172  [44800/71041]
loss: 0.303669  [51200/71041]
loss: 0.135970  [57600/71041]
loss: 0.095559  [64000/71041]
loss: 0.095767  [70400/71041]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.149185 

Epoch 33
-------------------------------
loss: 0.247059  [    0/71041]
loss: 0.153573  [ 6400/71041]
loss: 0.114678  [12800/71041]
loss: 0.105327  [19200/71041]
loss: 0.251406  [25600/71041]
loss: 0.119238  [32000/71041]
loss: 0.164965  [38400/71041]
loss: 0.088577  [44800/71041]
loss: 0.096514  [51200/71041]
loss: 0.019925  [57600/71041]
loss: 0.389004  [64000/71041]
loss: 0.053553  [70400/71041]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.148811 

Epoch 34
-------------------------------
loss: 0.150655  [    0/71041]
loss: 0.226666  [ 6400/71041]
loss: 0.091579  [12800/71041]
loss: 0.107216  [19200/71041]
loss: 0.156979  [25600/71041]
loss: 0.086295  [32000/71041]
loss: 0.091901  [38400/71041]
loss: 0.081248  [44800/71041]
loss: 0.082167  [51200/71041]
loss: 0.112543  [57600/71041]
loss: 0.090155  [64000/71041]
loss: 0.190387  [70400/71041]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.160212 

Epoch 35
-------------------------------
loss: 0.142899  [    0/71041]
loss: 0.080524  [ 6400/71041]
loss: 0.069558  [12800/71041]
loss: 0.020352  [19200/71041]
loss: 0.164275  [25600/71041]
loss: 0.064633  [32000/71041]
loss: 0.088877  [38400/71041]
loss: 0.212619  [44800/71041]
loss: 0.119879  [51200/71041]
loss: 0.074116  [57600/71041]
loss: 0.031515  [64000/71041]
loss: 0.120818  [70400/71041]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.148925 

Epoch 36
-------------------------------
loss: 0.076085  [    0/71041]
loss: 0.260091  [ 6400/71041]
loss: 0.191344  [12800/71041]
loss: 0.056025  [19200/71041]
loss: 0.065326  [25600/71041]
loss: 0.133923  [32000/71041]
loss: 0.153659  [38400/71041]
loss: 0.022056  [44800/71041]
loss: 0.071205  [51200/71041]
loss: 0.152722  [57600/71041]
loss: 0.156885  [64000/71041]
loss: 0.070876  [70400/71041]
Test Error: 
 Accuracy: 80.8%, Avg loss: 1.566285 

Epoch 37
-------------------------------
loss: 1.407867  [    0/71041]
loss: 0.087496  [ 6400/71041]
loss: 0.039620  [12800/71041]
loss: 0.077564  [19200/71041]
loss: 0.114862  [25600/71041]
loss: 0.102996  [32000/71041]
loss: 0.066962  [38400/71041]
loss: 0.156967  [44800/71041]
loss: 0.073763  [51200/71041]
loss: 0.170347  [57600/71041]
loss: 0.149864  [64000/71041]
loss: 0.165800  [70400/71041]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.150984 

Epoch 38
-------------------------------
loss: 0.106784  [    0/71041]
loss: 0.163699  [ 6400/71041]
loss: 0.084317  [12800/71041]
loss: 0.050434  [19200/71041]
loss: 0.060174  [25600/71041]
loss: 0.120654  [32000/71041]
loss: 0.138119  [38400/71041]
loss: 0.092303  [44800/71041]
loss: 0.059556  [51200/71041]
loss: 0.154854  [57600/71041]
loss: 0.072980  [64000/71041]
loss: 1.629307  [70400/71041]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.146973 

Epoch 39
-------------------------------
loss: 0.156480  [    0/71041]
loss: 0.139591  [ 6400/71041]
loss: 0.039075  [12800/71041]
loss: 0.113962  [19200/71041]
loss: 0.098134  [25600/71041]
loss: 0.089028  [32000/71041]
loss: 0.075017  [38400/71041]
loss: 0.070700  [44800/71041]
loss: 0.067502  [51200/71041]
loss: 0.127332  [57600/71041]
loss: 0.194518  [64000/71041]
loss: 0.135890  [70400/71041]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.358647 

Epoch 40
-------------------------------
loss: 0.366753  [    0/71041]
loss: 0.057015  [ 6400/71041]
loss: 0.053556  [12800/71041]
loss: 0.145849  [19200/71041]
loss: 0.046506  [25600/71041]
loss: 0.185353  [32000/71041]
loss: 0.093993  [38400/71041]
loss: 0.110029  [44800/71041]
loss: 0.026077  [51200/71041]
loss: 0.132312  [57600/71041]
loss: 0.166517  [64000/71041]
loss: 0.148914  [70400/71041]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.151884 

Epoch 41
-------------------------------
loss: 0.124207  [    0/71041]
loss: 0.093118  [ 6400/71041]
loss: 0.104910  [12800/71041]
loss: 0.079931  [19200/71041]
loss: 0.056567  [25600/71041]
loss: 0.180009  [32000/71041]
loss: 0.143954  [38400/71041]
loss: 0.253439  [44800/71041]
loss: 0.125884  [51200/71041]
loss: 0.080259  [57600/71041]
loss: 0.067885  [64000/71041]
loss: 0.135303  [70400/71041]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.206772 

Epoch 42
-------------------------------
loss: 0.099853  [    0/71041]
loss: 0.156359  [ 6400/71041]
loss: 0.032829  [12800/71041]
loss: 0.106301  [19200/71041]
loss: 0.108636  [25600/71041]
loss: 0.153514  [32000/71041]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.128460 

Epoch 36
-------------------------------
loss: 0.071781  [    0/71476]
loss: 0.077086  [ 6400/71476]
loss: 0.081687  [12800/71476]
loss: 0.014043  [19200/71476]
loss: 0.023081  [25600/71476]
loss: 0.120672  [32000/71476]
loss: 0.061659  [38400/71476]
loss: 0.026574  [44800/71476]
loss: 0.088454  [51200/71476]
loss: 0.151058  [57600/71476]
loss: 0.039800  [64000/71476]
loss: 0.025845  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.127274 

Epoch 37
-------------------------------
loss: 0.027646  [    0/71476]
loss: 0.128402  [ 6400/71476]
loss: 0.053170  [12800/71476]
loss: 0.033715  [19200/71476]
loss: 0.029698  [25600/71476]
loss: 0.137048  [32000/71476]
loss: 0.056189  [38400/71476]
loss: 0.055805  [44800/71476]
loss: 0.046555  [51200/71476]
loss: 0.087807  [57600/71476]
loss: 0.008928  [64000/71476]
loss: 0.059716  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.123586 

Epoch 38
-------------------------------
loss: 0.020929  [    0/71476]
loss: 0.055166  [ 6400/71476]
loss: 0.110266  [12800/71476]
loss: 0.024714  [19200/71476]
loss: 0.026212  [25600/71476]
loss: 0.054864  [32000/71476]
loss: 0.162073  [38400/71476]
loss: 0.026707  [44800/71476]
loss: 0.128174  [51200/71476]
loss: 0.136019  [57600/71476]
loss: 0.045905  [64000/71476]
loss: 0.011814  [70400/71476]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.133837 

Epoch 39
-------------------------------
loss: 0.019851  [    0/71476]
loss: 0.218611  [ 6400/71476]
loss: 0.021348  [12800/71476]
loss: 0.141810  [19200/71476]
loss: 0.081573  [25600/71476]
loss: 0.190720  [32000/71476]
loss: 0.042196  [38400/71476]
loss: 0.144074  [44800/71476]
loss: 0.036937  [51200/71476]
loss: 0.018622  [57600/71476]
loss: 0.064450  [64000/71476]
loss: 0.015376  [70400/71476]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.117862 

Epoch 40
-------------------------------
loss: 0.150048  [    0/71476]
loss: 0.086493  [ 6400/71476]
loss: 1.711900  [12800/71476]
loss: 0.022870  [19200/71476]
loss: 0.034841  [25600/71476]
loss: 0.091717  [32000/71476]
loss: 0.054810  [38400/71476]
loss: 0.033346  [44800/71476]
loss: 0.036337  [51200/71476]
loss: 1.646149  [57600/71476]
loss: 0.011793  [64000/71476]
loss: 0.036299  [70400/71476]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.130529 

Epoch 41
-------------------------------
loss: 0.041862  [    0/71476]
loss: 0.096581  [ 6400/71476]
loss: 0.082874  [12800/71476]
loss: 0.011456  [19200/71476]
loss: 0.016762  [25600/71476]
loss: 0.071535  [32000/71476]
loss: 0.067903  [38400/71476]
loss: 0.036852  [44800/71476]
loss: 0.046029  [51200/71476]
loss: 0.062745  [57600/71476]
loss: 0.177618  [64000/71476]
loss: 0.027148  [70400/71476]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.137459 

Epoch 42
-------------------------------
loss: 0.009514  [    0/71476]
loss: 0.005556  [ 6400/71476]
loss: 0.004928  [12800/71476]
loss: 0.033503  [19200/71476]
loss: 0.121565  [25600/71476]
loss: 0.009434  [32000/71476]
loss: 0.071700  [38400/71476]
loss: 0.036636  [44800/71476]
loss: 0.019596  [51200/71476]
loss: 0.080949  [57600/71476]
loss: 0.022110  [64000/71476]
loss: 1.657801  [70400/71476]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.126410 

Epoch 43
-------------------------------
loss: 0.051421  [    0/71476]
loss: 0.055818  [ 6400/71476]
loss: 0.022876  [12800/71476]
loss: 0.057331  [19200/71476]
loss: 0.089150  [25600/71476]
loss: 0.026826  [32000/71476]
loss: 0.017187  [38400/71476]
loss: 0.025368  [44800/71476]
loss: 0.073764  [51200/71476]
loss: 0.078326  [57600/71476]
loss: 0.153701  [64000/71476]
loss: 0.077496  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.132143 

Epoch 44
-------------------------------
loss: 0.074632  [    0/71476]
loss: 0.099102  [ 6400/71476]
loss: 0.054758  [12800/71476]
loss: 0.215889  [19200/71476]
loss: 0.047311  [25600/71476]
loss: 0.061867  [32000/71476]
loss: 0.020821  [38400/71476]
loss: 0.041473  [44800/71476]
loss: 0.038806  [51200/71476]
loss: 0.010926  [57600/71476]
loss: 0.017607  [64000/71476]
loss: 0.073953  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.125173 

Epoch 45
-------------------------------
loss: 0.042560  [    0/71476]
loss: 0.021624  [ 6400/71476]
loss: 0.130277  [12800/71476]
loss: 0.035923  [19200/71476]
loss: 0.062268  [25600/71476]
loss: 0.051308  [32000/71476]
loss: 0.077780  [38400/71476]
loss: 0.032004  [44800/71476]
loss: 0.137770  [51200/71476]
loss: 0.033928  [57600/71476]
loss: 0.031477  [64000/71476]
loss: 0.036902  [70400/71476]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.119748 

Epoch 46
-------------------------------
loss: 0.043470  [    0/71476]
loss: 0.031966  [ 6400/71476]
loss: 0.127318  [12800/71476]
loss: 0.118291  [19200/71476]
loss: 0.061451  [25600/71476]
loss: 0.025853  [32000/71476]
loss: 0.064087  [38400/71476]
loss: 0.035743  [44800/71476]
loss: 0.023647  [51200/71476]
loss: 0.025606  [57600/71476]
loss: 0.022065  [64000/71476]
loss: 0.079694  [70400/71476]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.122959 

Epoch 47
-------------------------------
loss: 0.120373  [    0/71476]
loss: 0.049073  [ 6400/71476]
loss: 0.049490  [12800/71476]
loss: 0.079240  [19200/71476]
loss: 0.030829  [25600/71476]
loss: 0.099877  [32000/71476]
loss: 0.103961  [38400/71476]
loss: 0.058558  [44800/71476]
loss: 0.028224  [51200/71476]
loss: 0.068221  [57600/71476]
loss: 0.021905  [64000/71476]
loss: 0.023216  [70400/71476]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.122513 

Epoch 48
-------------------------------
loss: 0.042652  [    0/71476]
loss: 0.039028  [ 6400/71476]
loss: 0.023732  [12800/71476]
loss: 0.079491  [19200/71476]
loss: 0.016646  [25600/71476]
loss: 0.027448  [32000/71476]
loss: 0.067706  [38400/71476]
loss: 0.055285  [44800/71476]
loss: 0.136810  [51200/71476]
loss: 0.057319  [57600/71476]
loss: 0.010460  [64000/71476]
loss: 0.020120  [70400/71476]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.125159 

Epoch 49
-------------------------------
loss: 0.073233  [    0/71476]
loss: 0.058870  [ 6400/71476]
loss: 0.033621  [12800/71476]
loss: 0.119247  [19200/71476]
loss: 0.026396  [25600/71476]
loss: 0.066122  [32000/71476]
loss: 0.205444  [38400/71476]
loss: 0.071140  [44800/71476]
loss: 0.034585  [51200/71476]
loss: 0.094672  [57600/71476]
loss: 0.186786  [64000/71476]
loss: 1.629603  [70400/71476]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.121868 

Epoch 50
-------------------------------
loss: 0.069007  [    0/71476]
loss: 0.024835  [ 6400/71476]
loss: 0.041756  [12800/71476]
loss: 0.015447  [19200/71476]
loss: 0.036831  [25600/71476]
loss: 0.053218  [32000/71476]
loss: 0.095555  [38400/71476]
loss: 0.044618  [44800/71476]
loss: 0.067433  [51200/71476]
loss: 0.032878  [57600/71476]
loss: 0.037990  [64000/71476]
loss: 0.190490  [70400/71476]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.126783 

Epoch 1
-------------------------------
loss: 0.717056  [    0/71783]
loss: 0.199669  [ 6400/71783]
loss: 0.183555  [12800/71783]
loss: 0.162796  [19200/71783]
loss: 0.058174  [25600/71783]
loss: 0.091599  [32000/71783]
loss: 0.129394  [38400/71783]
loss: 0.068194  [44800/71783]
loss: 0.119993  [51200/71783]
loss: 0.034911  [57600/71783]
loss: 0.093541  [64000/71783]
loss: 0.038913  [70400/71783]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085563 

Epoch 2
-------------------------------
loss: 0.113869  [    0/71783]
loss: 0.086834  [ 6400/71783]
loss: 0.026665  [12800/71783]
loss: 0.262313  [19200/71783]
loss: 0.085953  [25600/71783]
loss: 0.041198  [32000/71783]
loss: 0.159067  [38400/71783]
loss: 0.110203  [44800/71783]
loss: 0.039250  [51200/71783]
loss: 0.149715  [57600/71783]
loss: 0.056838  [64000/71783]
loss: 0.034990  [70400/71783]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.076883 

Epoch 3
-------------------------------
loss: 0.038804  [    0/71783]
loss: 0.018716  [ 6400/71783]
loss: 0.073548  [12800/71783]
loss: 0.116994  [19200/71783]
loss: 0.092700  [25600/71783]
loss: 0.029506  [32000/71783]
loss: 0.145056  [38400/71783]
loss: 0.072712  [44800/71783]
loss: 0.035493  [51200/71783]
loss: 0.163325  [57600/71783]
loss: 0.061290  [64000/71783]
loss: 0.037533  [70400/71783]
2022/09/20 17:17:41 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:18:18 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:18:31 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:19:12 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.228912 

Epoch 21
-------------------------------
loss: 0.107386  [    0/70723]
loss: 0.101621  [ 6400/70723]
loss: 0.096247  [12800/70723]
loss: 0.098550  [19200/70723]
loss: 0.028602  [25600/70723]
loss: 0.062729  [32000/70723]
loss: 0.042117  [38400/70723]
loss: 0.223815  [44800/70723]
loss: 0.152054  [51200/70723]
loss: 0.053635  [57600/70723]
loss: 0.134462  [64000/70723]
loss: 0.113452  [70400/70723]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.143810 

Epoch 22
-------------------------------
loss: 0.066071  [    0/70723]
loss: 0.107833  [ 6400/70723]
loss: 0.093903  [12800/70723]
loss: 0.135263  [19200/70723]
loss: 0.088194  [25600/70723]
loss: 0.097971  [32000/70723]
loss: 0.173666  [38400/70723]
loss: 0.091568  [44800/70723]
loss: 0.207779  [51200/70723]
loss: 0.068826  [57600/70723]
loss: 0.090272  [64000/70723]
loss: 0.127810  [70400/70723]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.139114 

Epoch 23
-------------------------------
loss: 0.184229  [    0/70723]
loss: 0.106544  [ 6400/70723]
loss: 0.205039  [12800/70723]
loss: 0.044789  [19200/70723]
loss: 0.162511  [25600/70723]
loss: 0.142056  [32000/70723]
loss: 0.073583  [38400/70723]
loss: 0.121389  [44800/70723]
loss: 0.057510  [51200/70723]
loss: 0.230983  [57600/70723]
loss: 0.138600  [64000/70723]
loss: 0.149277  [70400/70723]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.182398 

Epoch 24
-------------------------------
loss: 0.218127  [    0/70723]
loss: 0.096188  [ 6400/70723]
loss: 0.056930  [12800/70723]
loss: 0.080463  [19200/70723]
loss: 0.139702  [25600/70723]
loss: 0.145515  [32000/70723]
loss: 0.075426  [38400/70723]
loss: 0.168915  [44800/70723]
loss: 0.102685  [51200/70723]
loss: 0.051196  [57600/70723]
loss: 0.216574  [64000/70723]
loss: 0.078941  [70400/70723]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.135917 

Epoch 25
-------------------------------
loss: 0.056944  [    0/70723]
loss: 0.108152  [ 6400/70723]
loss: 0.037742  [12800/70723]
loss: 0.064005  [19200/70723]
loss: 0.054872  [25600/70723]
loss: 0.124052  [32000/70723]
loss: 0.149739  [38400/70723]
loss: 0.080580  [44800/70723]
loss: 0.189822  [51200/70723]
loss: 0.221892  [57600/70723]
loss: 0.104520  [64000/70723]
loss: 0.134147  [70400/70723]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.139780 

Epoch 26
-------------------------------
loss: 0.112159  [    0/70723]
loss: 0.153122  [ 6400/70723]
loss: 0.060091  [12800/70723]
loss: 0.052398  [19200/70723]
loss: 0.048042  [25600/70723]
loss: 0.039602  [32000/70723]
loss: 0.053215  [38400/70723]
loss: 0.152252  [44800/70723]
loss: 0.083821  [51200/70723]
loss: 0.211046  [57600/70723]
loss: 0.035301  [64000/70723]
loss: 0.063141  [70400/70723]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.139152 

Epoch 27
-------------------------------
loss: 0.058924  [    0/70723]
loss: 0.108878  [ 6400/70723]
loss: 0.150970  [12800/70723]
loss: 0.219171  [19200/70723]
loss: 0.062775  [25600/70723]
loss: 0.076081  [32000/70723]
loss: 0.065978  [38400/70723]
loss: 0.130279  [44800/70723]
loss: 0.162020  [51200/70723]
loss: 0.110589  [57600/70723]
loss: 0.285500  [64000/70723]
loss: 0.138092  [70400/70723]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.138789 

Epoch 28
-------------------------------
loss: 0.135768  [    0/70723]
loss: 0.113554  [ 6400/70723]
loss: 0.058377  [12800/70723]
loss: 0.181528  [19200/70723]
loss: 0.070440  [25600/70723]
loss: 0.024468  [32000/70723]
loss: 0.103848  [38400/70723]
loss: 0.032060  [44800/70723]
loss: 0.048634  [51200/70723]
loss: 0.097618  [57600/70723]
loss: 0.050607  [64000/70723]
loss: 0.104799  [70400/70723]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.133784 

Epoch 29
-------------------------------
loss: 0.089591  [    0/70723]
loss: 1.590247  [ 6400/70723]
loss: 0.249794  [12800/70723]
loss: 0.071101  [19200/70723]
loss: 0.077296  [25600/70723]
loss: 0.111555  [32000/70723]
loss: 0.082372  [38400/70723]
loss: 0.085436  [44800/70723]
loss: 0.107717  [51200/70723]
loss: 0.173263  [57600/70723]
loss: 0.105455  [64000/70723]
loss: 0.068451  [70400/70723]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.135078 

Epoch 30
-------------------------------
loss: 0.061524  [    0/70723]
loss: 0.051923  [ 6400/70723]
loss: 0.090665  [12800/70723]
loss: 0.144142  [19200/70723]
loss: 0.081803  [25600/70723]
loss: 0.194542  [32000/70723]
loss: 0.162622  [38400/70723]
loss: 0.046492  [44800/70723]
loss: 0.046686  [51200/70723]
loss: 0.149363  [57600/70723]
loss: 0.077214  [64000/70723]
loss: 0.177941  [70400/70723]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.142390 

Epoch 31
-------------------------------
loss: 0.089374  [    0/70723]
loss: 0.063741  [ 6400/70723]
loss: 0.110630  [12800/70723]
loss: 0.155634  [19200/70723]
loss: 0.094980  [25600/70723]
loss: 0.152260  [32000/70723]
loss: 0.193585  [38400/70723]
loss: 0.055564  [44800/70723]
loss: 0.073861  [51200/70723]
loss: 0.097292  [57600/70723]
loss: 0.149923  [64000/70723]
loss: 0.056939  [70400/70723]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.140617 

Epoch 32
-------------------------------
loss: 0.073780  [    0/70723]
loss: 0.135880  [ 6400/70723]
loss: 0.075333  [12800/70723]
loss: 0.087086  [19200/70723]
loss: 0.172284  [25600/70723]
loss: 0.158792  [32000/70723]
loss: 0.055289  [38400/70723]
loss: 0.078160  [44800/70723]
loss: 0.092864  [51200/70723]
loss: 0.081120  [57600/70723]
loss: 0.149402  [64000/70723]
loss: 0.048656  [70400/70723]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.136662 

Epoch 33
-------------------------------
loss: 0.080636  [    0/70723]
loss: 0.051591  [ 6400/70723]
loss: 0.085128  [12800/70723]
loss: 0.099959  [19200/70723]
loss: 0.061460  [25600/70723]
loss: 0.065759  [32000/70723]
loss: 0.120208  [38400/70723]
loss: 0.076170  [44800/70723]
loss: 0.044404  [51200/70723]
loss: 0.087949  [57600/70723]
loss: 0.093051  [64000/70723]
loss: 0.148055  [70400/70723]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.165503 

Epoch 34
-------------------------------
loss: 0.057579  [    0/70723]
loss: 0.049200  [ 6400/70723]
loss: 0.093513  [12800/70723]
loss: 0.143360  [19200/70723]
loss: 0.129876  [25600/70723]
loss: 0.089727  [32000/70723]
loss: 0.152986  [38400/70723]
loss: 0.063843  [44800/70723]
loss: 0.150728  [51200/70723]
loss: 0.119089  [57600/70723]
loss: 0.061855  [64000/70723]
loss: 0.123502  [70400/70723]
Test Error: 
 Accuracy: 87.5%, Avg loss: 0.353293 

Epoch 35
-------------------------------
loss: 0.333740  [    0/70723]
loss: 0.107998  [ 6400/70723]
loss: 0.098497  [12800/70723]
loss: 0.088509  [19200/70723]
loss: 0.163866  [25600/70723]
loss: 0.045864  [32000/70723]
loss: 0.123451  [38400/70723]
loss: 0.087913  [44800/70723]
loss: 0.075118  [51200/70723]
loss: 0.059498  [57600/70723]
loss: 0.062026  [64000/70723]
loss: 0.073765  [70400/70723]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.147917 

Epoch 36
-------------------------------
loss: 0.091580  [    0/70723]
loss: 0.088971  [ 6400/70723]
loss: 0.148330  [12800/70723]
loss: 0.114504  [19200/70723]
loss: 0.168644  [25600/70723]
loss: 0.140876  [32000/70723]
loss: 0.114878  [38400/70723]
loss: 0.217266  [44800/70723]
loss: 0.102126  [51200/70723]
loss: 0.059001  [57600/70723]
loss: 0.107277  [64000/70723]
loss: 0.058268  [70400/70723]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.136042 

Epoch 37
-------------------------------
loss: 0.071390  [    0/70723]
loss: 0.136881  [ 6400/70723]
loss: 0.106928  [12800/70723]
loss: 0.134123  [19200/70723]
loss: 0.167677  [25600/70723]
loss: 0.106567  [32000/70723]
loss: 0.034467  [38400/70723]
loss: 0.130358  [44800/70723]
loss: 0.158527  [51200/70723]
loss: 0.092247  [57600/70723]
loss: 0.066545  [64000/70723]
loss: 0.230565  [70400/70723]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.136695 

Epoch 38
-------------------------------
loss: 0.176086  [    0/70723]
loss: 0.216309  [ 6400/70723]
loss: 0.140346  [12800/70723]
loss: 0.122676  [19200/70723]
loss: 0.078639  [25600/70723]
loss: 0.050464  [32000/70723]
loss: 0.075764  [38400/70723]
loss: 0.129354  [44800/70723]
loss: 0.198368  [51200/70723]
loss: 0.070279  [57600/70723]
loss: 0.050293  [64000/70723]
loss: 0.073380  [70400/70723]
2022/09/20 17:19:33 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.130758  [12800/70468]
loss: 0.098029  [19200/70468]
loss: 0.079254  [25600/70468]
loss: 0.118464  [32000/70468]
loss: 0.074104  [38400/70468]
loss: 0.159259  [44800/70468]
loss: 0.117421  [51200/70468]
loss: 0.132537  [57600/70468]
loss: 0.125005  [64000/70468]
loss: 0.092290  [70400/70468]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.161163 

Epoch 40
-------------------------------
loss: 0.193840  [    0/70468]
loss: 0.059591  [ 6400/70468]
loss: 0.130168  [12800/70468]
loss: 0.149175  [19200/70468]
loss: 0.052086  [25600/70468]
loss: 0.199942  [32000/70468]
loss: 0.050985  [38400/70468]
loss: 0.143867  [44800/70468]
loss: 0.167944  [51200/70468]
loss: 0.154190  [57600/70468]
loss: 0.105476  [64000/70468]
loss: 0.216253  [70400/70468]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.157034 

Epoch 41
-------------------------------
loss: 0.053063  [    0/70468]
loss: 0.100744  [ 6400/70468]
loss: 0.235909  [12800/70468]
loss: 0.169422  [19200/70468]
loss: 0.146503  [25600/70468]
loss: 1.735628  [32000/70468]
loss: 0.058212  [38400/70468]
loss: 0.350578  [44800/70468]
loss: 0.157256  [51200/70468]
loss: 0.188015  [57600/70468]
loss: 0.168054  [64000/70468]
loss: 0.103596  [70400/70468]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.149180 

Epoch 42
-------------------------------
loss: 0.163782  [    0/70468]
loss: 0.188686  [ 6400/70468]
loss: 0.140225  [12800/70468]
loss: 0.119006  [19200/70468]
loss: 0.056147  [25600/70468]
loss: 0.150593  [32000/70468]
loss: 0.121056  [38400/70468]
loss: 0.119569  [44800/70468]
loss: 0.165509  [51200/70468]
loss: 0.148268  [57600/70468]
loss: 0.071018  [64000/70468]
loss: 0.221131  [70400/70468]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.162071 

Epoch 43
-------------------------------
loss: 0.128977  [    0/70468]
loss: 0.094820  [ 6400/70468]
loss: 0.178396  [12800/70468]
loss: 0.071275  [19200/70468]
loss: 0.204823  [25600/70468]
loss: 0.230217  [32000/70468]
loss: 0.180129  [38400/70468]
loss: 0.150851  [44800/70468]
loss: 0.191266  [51200/70468]
loss: 0.148488  [57600/70468]
loss: 0.087263  [64000/70468]
loss: 0.093828  [70400/70468]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.147948 

Epoch 44
-------------------------------
loss: 0.232457  [    0/70468]
loss: 0.133709  [ 6400/70468]
loss: 0.189551  [12800/70468]
loss: 0.146044  [19200/70468]
loss: 0.035156  [25600/70468]
loss: 0.122259  [32000/70468]
loss: 0.118085  [38400/70468]
loss: 0.155603  [44800/70468]
loss: 0.177587  [51200/70468]
loss: 0.058764  [57600/70468]
loss: 0.086636  [64000/70468]
loss: 0.074334  [70400/70468]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.153704 

Epoch 45
-------------------------------
loss: 0.070314  [    0/70468]
loss: 0.090147  [ 6400/70468]
loss: 0.161598  [12800/70468]
loss: 0.106255  [19200/70468]
loss: 0.058005  [25600/70468]
loss: 0.078219  [32000/70468]
loss: 0.108142  [38400/70468]
loss: 0.108886  [44800/70468]
loss: 0.047030  [51200/70468]
loss: 0.172774  [57600/70468]
loss: 0.134915  [64000/70468]
loss: 0.141046  [70400/70468]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.239729 

Epoch 46
-------------------------------
loss: 0.232857  [    0/70468]
loss: 0.103892  [ 6400/70468]
loss: 0.048702  [12800/70468]
loss: 0.087691  [19200/70468]
loss: 0.167969  [25600/70468]
loss: 0.244677  [32000/70468]
loss: 0.248519  [38400/70468]
loss: 0.159467  [44800/70468]
loss: 0.134342  [51200/70468]
loss: 0.098373  [57600/70468]
loss: 0.095389  [64000/70468]
loss: 0.063033  [70400/70468]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.171247 

Epoch 47
-------------------------------
loss: 0.118017  [    0/70468]
loss: 0.184006  [ 6400/70468]
loss: 0.161924  [12800/70468]
loss: 0.239399  [19200/70468]
loss: 0.132597  [25600/70468]
loss: 0.117668  [32000/70468]
loss: 0.083040  [38400/70468]
loss: 0.128687  [44800/70468]
loss: 0.149471  [51200/70468]
loss: 0.107409  [57600/70468]
loss: 0.118166  [64000/70468]
loss: 0.151163  [70400/70468]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.160067 

Epoch 48
-------------------------------
loss: 0.089156  [    0/70468]
loss: 0.105769  [ 6400/70468]
loss: 0.099739  [12800/70468]
loss: 0.146281  [19200/70468]
loss: 0.143092  [25600/70468]
loss: 0.205039  [32000/70468]
loss: 0.148238  [38400/70468]
loss: 0.170675  [44800/70468]
loss: 0.172803  [51200/70468]
loss: 0.090563  [57600/70468]
loss: 0.073139  [64000/70468]
loss: 0.233132  [70400/70468]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.166047 

Epoch 49
-------------------------------
loss: 0.117096  [    0/70468]
loss: 0.086871  [ 6400/70468]
loss: 0.115565  [12800/70468]
loss: 0.108115  [19200/70468]
loss: 0.025712  [25600/70468]
loss: 0.065769  [32000/70468]
loss: 0.118864  [38400/70468]
loss: 0.103330  [44800/70468]
loss: 0.391182  [51200/70468]
loss: 0.085640  [57600/70468]
loss: 0.120436  [64000/70468]
loss: 0.205255  [70400/70468]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.149867 

Epoch 50
-------------------------------
loss: 0.061838  [    0/70468]
loss: 0.307677  [ 6400/70468]
loss: 0.111837  [12800/70468]
loss: 0.097521  [19200/70468]
loss: 0.177994  [25600/70468]
loss: 0.216675  [32000/70468]
loss: 0.199437  [38400/70468]
loss: 0.048078  [44800/70468]
loss: 0.106749  [51200/70468]
loss: 0.098613  [57600/70468]
loss: 0.165858  [64000/70468]
loss: 0.077965  [70400/70468]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.152189 

Epoch 1
-------------------------------
loss: 0.725952  [    0/70487]
loss: 0.286889  [ 6400/70487]
loss: 0.308661  [12800/70487]
loss: 0.232149  [19200/70487]
loss: 0.384761  [25600/70487]
loss: 0.272806  [32000/70487]
loss: 0.383773  [38400/70487]
loss: 0.397063  [44800/70487]
loss: 0.204744  [51200/70487]
loss: 0.182683  [57600/70487]
loss: 0.533103  [64000/70487]
loss: 0.294402  [70400/70487]
Test Error: 
 Accuracy: 91.1%, Avg loss: 0.264834 

Epoch 2
-------------------------------
loss: 0.172538  [    0/70487]
loss: 0.271964  [ 6400/70487]
loss: 1.770925  [12800/70487]
loss: 0.255730  [19200/70487]
loss: 0.293710  [25600/70487]
loss: 0.181641  [32000/70487]
loss: 0.212883  [38400/70487]
loss: 0.362607  [44800/70487]
loss: 0.236168  [51200/70487]
loss: 0.356232  [57600/70487]
loss: 0.273339  [64000/70487]
loss: 0.189157  [70400/70487]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.228284 

Epoch 3
-------------------------------
loss: 0.221761  [    0/70487]
loss: 0.148730  [ 6400/70487]
loss: 0.144533  [12800/70487]
loss: 0.171284  [19200/70487]
loss: 0.243864  [25600/70487]
loss: 0.165069  [32000/70487]
loss: 0.220303  [38400/70487]
loss: 0.216851  [44800/70487]
loss: 0.217419  [51200/70487]
loss: 0.300385  [57600/70487]
loss: 0.250390  [64000/70487]
loss: 0.165207  [70400/70487]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.245981 

Epoch 4
-------------------------------
loss: 0.152444  [    0/70487]
loss: 0.123080  [ 6400/70487]
loss: 0.244991  [12800/70487]
loss: 0.283662  [19200/70487]
loss: 0.183070  [25600/70487]
loss: 0.162081  [32000/70487]
loss: 0.224687  [38400/70487]
loss: 0.249076  [44800/70487]
loss: 0.127896  [51200/70487]
loss: 1.724149  [57600/70487]
loss: 0.256826  [64000/70487]
loss: 0.210648  [70400/70487]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.203579 

Epoch 5
-------------------------------
loss: 0.159680  [    0/70487]
loss: 0.249855  [ 6400/70487]
loss: 1.722368  [12800/70487]
loss: 0.126781  [19200/70487]
loss: 0.178790  [25600/70487]
loss: 0.201501  [32000/70487]
loss: 0.248311  [38400/70487]
loss: 0.162086  [44800/70487]
loss: 1.662139  [51200/70487]
loss: 0.181412  [57600/70487]
loss: 0.180999  [64000/70487]
loss: 1.769427  [70400/70487]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.217710 

Epoch 6
-------------------------------
loss: 0.124141  [    0/70487]
loss: 0.306976  [ 6400/70487]
loss: 0.178266  [12800/70487]
loss: 0.316798  [19200/70487]
loss: 0.235118  [25600/70487]
loss: 0.114848  [32000/70487]
loss: 0.180170  [38400/70487]
loss: 0.365589  [44800/70487]
loss: 0.239061  [51200/70487]
loss: 0.167958  [57600/70487]
loss: 0.123952  [64000/70487]
loss: 0.089437  [70400/70487]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.204590 

Epoch 7
-------------------------------
loss: 0.166539  [    0/70487]
loss: 0.235740  [ 6400/70487]
loss: 0.191328  [12800/70487]
2022/09/20 17:20:26 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.100286  [ 6400/69926]
loss: 0.174008  [12800/69926]
loss: 0.078356  [19200/69926]
loss: 0.141182  [25600/69926]
loss: 0.095823  [32000/69926]
loss: 0.259900  [38400/69926]
loss: 0.105196  [44800/69926]
loss: 0.122578  [51200/69926]
loss: 0.127914  [57600/69926]
loss: 0.179870  [64000/69926]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.178116 

Epoch 27
-------------------------------
loss: 0.188557  [    0/69926]
loss: 0.117425  [ 6400/69926]
loss: 0.113876  [12800/69926]
loss: 0.097245  [19200/69926]
loss: 0.128979  [25600/69926]
loss: 0.209549  [32000/69926]
loss: 0.126015  [38400/69926]
loss: 0.139488  [44800/69926]
loss: 0.181784  [51200/69926]
loss: 0.208567  [57600/69926]
loss: 0.066632  [64000/69926]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.179068 

Epoch 28
-------------------------------
loss: 0.128262  [    0/69926]
loss: 0.171884  [ 6400/69926]
loss: 0.122334  [12800/69926]
loss: 0.167555  [19200/69926]
loss: 0.155694  [25600/69926]
loss: 1.701120  [32000/69926]
loss: 0.050790  [38400/69926]
loss: 0.146371  [44800/69926]
loss: 0.154061  [51200/69926]
loss: 0.088964  [57600/69926]
loss: 0.174300  [64000/69926]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.169577 

Epoch 29
-------------------------------
loss: 0.136342  [    0/69926]
loss: 0.155864  [ 6400/69926]
loss: 0.125464  [12800/69926]
loss: 0.190448  [19200/69926]
loss: 0.160626  [25600/69926]
loss: 0.208207  [32000/69926]
loss: 0.085589  [38400/69926]
loss: 0.146575  [44800/69926]
loss: 0.071680  [51200/69926]
loss: 0.084081  [57600/69926]
loss: 0.152015  [64000/69926]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.175526 

Epoch 30
-------------------------------
loss: 0.091840  [    0/69926]
loss: 0.107388  [ 6400/69926]
loss: 0.121846  [12800/69926]
loss: 0.124096  [19200/69926]
loss: 0.136862  [25600/69926]
loss: 0.106234  [32000/69926]
loss: 0.197169  [38400/69926]
loss: 0.121219  [44800/69926]
loss: 0.065887  [51200/69926]
loss: 0.196559  [57600/69926]
loss: 0.152758  [64000/69926]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.173546 

Epoch 31
-------------------------------
loss: 0.343172  [    0/69926]
loss: 0.131864  [ 6400/69926]
loss: 0.096984  [12800/69926]
loss: 0.078387  [19200/69926]
loss: 0.125308  [25600/69926]
loss: 0.036595  [32000/69926]
loss: 0.181904  [38400/69926]
loss: 0.172216  [44800/69926]
loss: 0.176981  [51200/69926]
loss: 0.119203  [57600/69926]
loss: 0.218574  [64000/69926]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.160082 

Epoch 32
-------------------------------
loss: 0.178445  [    0/69926]
loss: 0.227648  [ 6400/69926]
loss: 0.118730  [12800/69926]
loss: 0.127022  [19200/69926]
loss: 0.160118  [25600/69926]
loss: 0.229108  [32000/69926]
loss: 0.184922  [38400/69926]
loss: 0.215050  [44800/69926]
loss: 0.119239  [51200/69926]
loss: 0.195382  [57600/69926]
loss: 0.118889  [64000/69926]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.158870 

Epoch 33
-------------------------------
loss: 0.120836  [    0/69926]
loss: 0.159298  [ 6400/69926]
loss: 0.176167  [12800/69926]
loss: 0.162493  [19200/69926]
loss: 0.114007  [25600/69926]
loss: 0.069907  [32000/69926]
loss: 0.146806  [38400/69926]
loss: 0.105865  [44800/69926]
loss: 0.236882  [51200/69926]
loss: 0.210654  [57600/69926]
loss: 0.255842  [64000/69926]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.165782 

Epoch 34
-------------------------------
loss: 0.138908  [    0/69926]
loss: 0.168604  [ 6400/69926]
loss: 0.117682  [12800/69926]
loss: 0.102752  [19200/69926]
loss: 0.142931  [25600/69926]
loss: 0.167714  [32000/69926]
loss: 0.151669  [38400/69926]
loss: 0.161866  [44800/69926]
loss: 0.112752  [51200/69926]
loss: 0.245385  [57600/69926]
loss: 0.192650  [64000/69926]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.173964 

Epoch 35
-------------------------------
loss: 0.102604  [    0/69926]
loss: 0.041543  [ 6400/69926]
loss: 0.268671  [12800/69926]
loss: 0.200201  [19200/69926]
loss: 0.232957  [25600/69926]
loss: 0.182929  [32000/69926]
loss: 0.079534  [38400/69926]
loss: 0.164556  [44800/69926]
loss: 0.121956  [51200/69926]
loss: 0.201754  [57600/69926]
loss: 0.112711  [64000/69926]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.161422 

Epoch 36
-------------------------------
loss: 0.105606  [    0/69926]
loss: 0.073826  [ 6400/69926]
loss: 0.125542  [12800/69926]
loss: 0.055245  [19200/69926]
loss: 0.152695  [25600/69926]
loss: 0.139691  [32000/69926]
loss: 0.104858  [38400/69926]
loss: 0.103285  [44800/69926]
loss: 0.192441  [51200/69926]
loss: 0.138164  [57600/69926]
loss: 0.210209  [64000/69926]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.163145 

Epoch 37
-------------------------------
loss: 0.121459  [    0/69926]
loss: 0.057391  [ 6400/69926]
loss: 0.170709  [12800/69926]
loss: 0.115180  [19200/69926]
loss: 0.069054  [25600/69926]
loss: 0.137679  [32000/69926]
loss: 0.196023  [38400/69926]
loss: 0.128625  [44800/69926]
loss: 0.065755  [51200/69926]
loss: 0.180305  [57600/69926]
loss: 0.266656  [64000/69926]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.158899 

Epoch 38
-------------------------------
loss: 0.089917  [    0/69926]
loss: 0.269879  [ 6400/69926]
loss: 0.160058  [12800/69926]
loss: 1.633939  [19200/69926]
loss: 0.147090  [25600/69926]
loss: 0.189325  [32000/69926]
loss: 0.144254  [38400/69926]
loss: 0.124911  [44800/69926]
loss: 0.128321  [51200/69926]
loss: 0.200351  [57600/69926]
loss: 0.105994  [64000/69926]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.177094 

Epoch 39
-------------------------------
loss: 0.109234  [    0/69926]
loss: 0.096178  [ 6400/69926]
loss: 0.159207  [12800/69926]
loss: 0.094379  [19200/69926]
loss: 0.090491  [25600/69926]
loss: 0.245565  [32000/69926]
loss: 0.142933  [38400/69926]
loss: 0.051555  [44800/69926]
loss: 0.189460  [51200/69926]
loss: 0.160649  [57600/69926]
loss: 0.101991  [64000/69926]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.178011 

Epoch 40
-------------------------------
loss: 0.077678  [    0/69926]
loss: 0.212276  [ 6400/69926]
loss: 0.109089  [12800/69926]
loss: 0.072717  [19200/69926]
loss: 0.100975  [25600/69926]
loss: 0.218186  [32000/69926]
loss: 0.169517  [38400/69926]
loss: 0.135946  [44800/69926]
loss: 0.159643  [51200/69926]
loss: 0.122780  [57600/69926]
loss: 0.153053  [64000/69926]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.159866 

Epoch 41
-------------------------------
loss: 0.075451  [    0/69926]
loss: 0.213889  [ 6400/69926]
loss: 0.076596  [12800/69926]
loss: 0.158911  [19200/69926]
loss: 0.206903  [25600/69926]
loss: 0.117831  [32000/69926]
loss: 0.109643  [38400/69926]
loss: 0.154878  [44800/69926]
loss: 0.259675  [51200/69926]
loss: 0.104165  [57600/69926]
loss: 0.216309  [64000/69926]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.164939 

Epoch 42
-------------------------------
loss: 0.112069  [    0/69926]
loss: 0.243099  [ 6400/69926]
loss: 0.147209  [12800/69926]
loss: 0.082027  [19200/69926]
loss: 0.073226  [25600/69926]
loss: 0.172383  [32000/69926]
loss: 0.200975  [38400/69926]
loss: 0.138863  [44800/69926]
loss: 0.167452  [51200/69926]
loss: 0.215433  [57600/69926]
loss: 0.167666  [64000/69926]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.163668 

Epoch 43
-------------------------------
loss: 0.183585  [    0/69926]
loss: 0.115956  [ 6400/69926]
loss: 0.223775  [12800/69926]
loss: 0.122598  [19200/69926]
loss: 0.287323  [25600/69926]
loss: 0.096207  [32000/69926]
loss: 0.063934  [38400/69926]
loss: 0.125452  [44800/69926]
loss: 0.209620  [51200/69926]
loss: 0.199421  [57600/69926]
loss: 0.207965  [64000/69926]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.156892 

Epoch 44
-------------------------------
loss: 0.161675  [    0/69926]
loss: 0.139780  [ 6400/69926]
loss: 0.132571  [12800/69926]
loss: 0.177135  [19200/69926]
loss: 0.223669  [25600/69926]
loss: 0.101442  [32000/69926]
loss: 0.117602  [38400/69926]
loss: 0.057296  [44800/69926]
loss: 0.165314  [51200/69926]
loss: 0.082737  [57600/69926]
loss: 0.093014  [64000/69926]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.160931 

Epoch 45
-------------------------------
loss: 0.092331  [    0/69926]
loss: 0.157579  [ 6400/69926]
loss: 0.119724  [12800/69926]
loss: 0.111554  [19200/69926]
loss: 0.196951  [25600/69926]
loss: 0.094366  [32000/69926]
loss: 0.073066  [32000/69867]
loss: 0.173533  [38400/69867]
loss: 0.144878  [44800/69867]
loss: 0.182092  [51200/69867]
loss: 0.151703  [57600/69867]
loss: 0.160361  [64000/69867]
Test Error: 
 Accuracy: 90.9%, Avg loss: 0.220390 

Epoch 23
-------------------------------
loss: 0.303133  [    0/69867]
loss: 0.153413  [ 6400/69867]
loss: 0.221862  [12800/69867]
loss: 0.153756  [19200/69867]
loss: 0.084968  [25600/69867]
loss: 0.145603  [32000/69867]
loss: 0.201715  [38400/69867]
loss: 0.133986  [44800/69867]
loss: 0.171531  [51200/69867]
loss: 0.198949  [57600/69867]
loss: 0.171124  [64000/69867]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.176516 

Epoch 24
-------------------------------
loss: 0.138198  [    0/69867]
loss: 0.356429  [ 6400/69867]
loss: 0.281890  [12800/69867]
loss: 0.119579  [19200/69867]
loss: 0.224623  [25600/69867]
loss: 0.126345  [32000/69867]
loss: 0.267882  [38400/69867]
loss: 0.183816  [44800/69867]
loss: 0.162711  [51200/69867]
loss: 0.158466  [57600/69867]
loss: 0.200278  [64000/69867]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.190345 

Epoch 25
-------------------------------
loss: 0.101989  [    0/69867]
loss: 0.110053  [ 6400/69867]
loss: 0.210043  [12800/69867]
loss: 0.200654  [19200/69867]
loss: 0.164581  [25600/69867]
loss: 0.140774  [32000/69867]
loss: 0.100493  [38400/69867]
loss: 0.120934  [44800/69867]
loss: 0.338214  [51200/69867]
loss: 0.289452  [57600/69867]
loss: 0.126703  [64000/69867]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.180020 

Epoch 26
-------------------------------
loss: 0.320135  [    0/69867]
loss: 0.104412  [ 6400/69867]
loss: 0.130372  [12800/69867]
loss: 0.094156  [19200/69867]
loss: 0.142318  [25600/69867]
loss: 0.297614  [32000/69867]
loss: 0.193128  [38400/69867]
loss: 0.135165  [44800/69867]
loss: 0.138055  [51200/69867]
loss: 0.153263  [57600/69867]
loss: 0.197808  [64000/69867]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.178068 

Epoch 27
-------------------------------
loss: 0.146529  [    0/69867]
loss: 0.143024  [ 6400/69867]
loss: 0.191636  [12800/69867]
loss: 0.091434  [19200/69867]
loss: 0.090721  [25600/69867]
loss: 0.138971  [32000/69867]
loss: 0.149538  [38400/69867]
loss: 0.236647  [44800/69867]
loss: 0.081676  [51200/69867]
loss: 0.261657  [57600/69867]
loss: 0.188410  [64000/69867]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.171123 

Epoch 28
-------------------------------
loss: 0.193195  [    0/69867]
loss: 0.228247  [ 6400/69867]
loss: 0.206909  [12800/69867]
loss: 0.126890  [19200/69867]
loss: 0.108910  [25600/69867]
loss: 0.165738  [32000/69867]
loss: 0.228280  [38400/69867]
loss: 0.224177  [44800/69867]
loss: 0.191625  [51200/69867]
loss: 0.094741  [57600/69867]
loss: 0.123264  [64000/69867]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.191479 

Epoch 29
-------------------------------
loss: 0.226427  [    0/69867]
loss: 0.131372  [ 6400/69867]
loss: 0.082578  [12800/69867]
loss: 0.240116  [19200/69867]
loss: 0.125382  [25600/69867]
loss: 0.248396  [32000/69867]
loss: 0.143139  [38400/69867]
loss: 0.089257  [44800/69867]
loss: 0.236584  [51200/69867]
loss: 0.155981  [57600/69867]
loss: 0.132225  [64000/69867]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.176058 

Epoch 30
-------------------------------
loss: 0.218704  [    0/69867]
loss: 0.175532  [ 6400/69867]
loss: 0.193668  [12800/69867]
loss: 0.144538  [19200/69867]
loss: 0.168317  [25600/69867]
loss: 0.203951  [32000/69867]
loss: 0.175809  [38400/69867]
loss: 0.182756  [44800/69867]
loss: 0.100606  [51200/69867]
loss: 0.229122  [57600/69867]
loss: 0.127528  [64000/69867]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.173888 

Epoch 31
-------------------------------
loss: 0.125965  [    0/69867]
loss: 0.215386  [ 6400/69867]
loss: 0.092501  [12800/69867]
loss: 0.176041  [19200/69867]
loss: 0.150083  [25600/69867]
loss: 0.137642  [32000/69867]
loss: 0.256035  [38400/69867]
loss: 0.212523  [44800/69867]
loss: 0.200056  [51200/69867]
loss: 0.242654  [57600/69867]
loss: 0.245845  [64000/69867]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.187333 

Epoch 32
-------------------------------
loss: 0.209737  [    0/69867]
loss: 0.176875  [ 6400/69867]
loss: 0.213593  [12800/69867]
loss: 0.080741  [19200/69867]
loss: 0.201251  [25600/69867]
loss: 0.282779  [32000/69867]
loss: 0.151505  [38400/69867]
loss: 0.201473  [44800/69867]
loss: 0.371266  [51200/69867]
loss: 0.143654  [57600/69867]
loss: 0.286630  [64000/69867]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.175714 

Epoch 33
-------------------------------
loss: 0.151449  [    0/69867]
loss: 0.169633  [ 6400/69867]
loss: 0.148312  [12800/69867]
loss: 0.148866  [19200/69867]
loss: 0.127321  [25600/69867]
loss: 0.140171  [32000/69867]
loss: 0.150701  [38400/69867]
loss: 0.250578  [44800/69867]
loss: 0.188919  [51200/69867]
loss: 0.234964  [57600/69867]
loss: 0.138233  [64000/69867]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.173969 

Epoch 34
-------------------------------
loss: 0.117472  [    0/69867]
loss: 0.244334  [ 6400/69867]
loss: 0.214062  [12800/69867]
loss: 0.193182  [19200/69867]
loss: 0.128916  [25600/69867]
loss: 0.156041  [32000/69867]
loss: 0.110486  [38400/69867]
loss: 0.282544  [44800/69867]
loss: 0.183159  [51200/69867]
loss: 0.239841  [57600/69867]
loss: 0.184594  [64000/69867]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.187149 

Epoch 35
-------------------------------
loss: 0.166828  [    0/69867]
loss: 0.166615  [ 6400/69867]
loss: 0.239972  [12800/69867]
loss: 0.182702  [19200/69867]
loss: 0.425584  [25600/69867]
loss: 0.248672  [32000/69867]
loss: 0.168414  [38400/69867]
loss: 0.116168  [44800/69867]
loss: 0.258932  [51200/69867]
loss: 0.144107  [57600/69867]
loss: 0.317451  [64000/69867]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.179322 

Epoch 36
-------------------------------
loss: 0.154387  [    0/69867]
loss: 0.198007  [ 6400/69867]
loss: 0.137739  [12800/69867]
loss: 0.115379  [19200/69867]
loss: 0.136250  [25600/69867]
loss: 0.149234  [32000/69867]
loss: 0.184334  [38400/69867]
loss: 0.186281  [44800/69867]
loss: 0.140043  [51200/69867]
loss: 0.181084  [57600/69867]
loss: 0.146731  [64000/69867]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.177522 

Epoch 37
-------------------------------
loss: 0.070034  [    0/69867]
loss: 0.203055  [ 6400/69867]
loss: 0.138677  [12800/69867]
loss: 0.238798  [19200/69867]
loss: 0.121745  [25600/69867]
loss: 0.167189  [32000/69867]
loss: 0.171032  [38400/69867]
loss: 0.209002  [44800/69867]
loss: 0.197083  [51200/69867]
loss: 0.253891  [57600/69867]
loss: 0.150404  [64000/69867]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.187779 

Epoch 38
-------------------------------
loss: 0.083560  [    0/69867]
loss: 0.112816  [ 6400/69867]
loss: 0.160558  [12800/69867]
loss: 0.122991  [19200/69867]
loss: 0.177350  [25600/69867]
loss: 0.140212  [32000/69867]
loss: 0.151874  [38400/69867]
loss: 0.198115  [44800/69867]
loss: 0.295465  [51200/69867]
loss: 0.120444  [57600/69867]
loss: 0.209447  [64000/69867]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.177845 

Epoch 39
-------------------------------
loss: 0.239106  [    0/69867]
loss: 0.157238  [ 6400/69867]
loss: 0.158399  [12800/69867]
loss: 0.201796  [19200/69867]
loss: 0.248410  [25600/69867]
loss: 0.325295  [32000/69867]
loss: 0.146532  [38400/69867]
loss: 0.127353  [44800/69867]
loss: 0.182655  [51200/69867]
loss: 0.227868  [57600/69867]
loss: 0.148306  [64000/69867]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.181768 

Epoch 40
-------------------------------
loss: 0.155503  [    0/69867]
loss: 0.145836  [ 6400/69867]
loss: 0.131626  [12800/69867]
loss: 0.152484  [19200/69867]
loss: 0.125658  [25600/69867]
loss: 0.078626  [32000/69867]
loss: 0.181490  [38400/69867]
loss: 0.154935  [44800/69867]
loss: 0.245722  [51200/69867]
loss: 0.189888  [57600/69867]
loss: 0.239542  [64000/69867]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.168080 

Epoch 41
-------------------------------
loss: 0.143740  [    0/69867]
loss: 0.099100  [ 6400/69867]
loss: 0.215212  [12800/69867]
loss: 0.152177  [19200/69867]
loss: 0.235593  [25600/69867]
loss: 0.098355  [32000/69867]
loss: 0.115916  [38400/69867]
loss: 0.170428  [44800/69867]
loss: 0.226427  [51200/69867]
loss: 0.083725  [57600/69867]
2022/09/20 17:21:22 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:21:40 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:22:25 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.327067  [32000/70204]
loss: 0.231142  [38400/70204]
loss: 0.149251  [44800/70204]
loss: 0.180093  [51200/70204]
loss: 0.220740  [57600/70204]
loss: 0.209753  [64000/70204]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.176404 

Epoch 23
-------------------------------
loss: 0.150695  [    0/70204]
loss: 0.150278  [ 6400/70204]
loss: 0.082049  [12800/70204]
loss: 0.190438  [19200/70204]
loss: 0.067015  [25600/70204]
loss: 0.069691  [32000/70204]
loss: 0.149092  [38400/70204]
loss: 0.167533  [44800/70204]
loss: 0.130619  [51200/70204]
loss: 0.149848  [57600/70204]
loss: 0.232743  [64000/70204]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.173000 

Epoch 24
-------------------------------
loss: 0.218286  [    0/70204]
loss: 0.054465  [ 6400/70204]
loss: 0.103902  [12800/70204]
loss: 0.127333  [19200/70204]
loss: 0.071430  [25600/70204]
loss: 0.149561  [32000/70204]
loss: 0.229022  [38400/70204]
loss: 0.094764  [44800/70204]
loss: 0.149730  [51200/70204]
loss: 0.119173  [57600/70204]
loss: 0.210966  [64000/70204]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.184919 

Epoch 25
-------------------------------
loss: 0.180496  [    0/70204]
loss: 0.119826  [ 6400/70204]
loss: 0.097582  [12800/70204]
loss: 0.139824  [19200/70204]
loss: 0.224929  [25600/70204]
loss: 0.135253  [32000/70204]
loss: 0.167262  [38400/70204]
loss: 0.221015  [44800/70204]
loss: 0.227683  [51200/70204]
loss: 0.109666  [57600/70204]
loss: 0.121897  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.170013 

Epoch 26
-------------------------------
loss: 0.157964  [    0/70204]
loss: 0.124981  [ 6400/70204]
loss: 0.102471  [12800/70204]
loss: 0.104753  [19200/70204]
loss: 0.208295  [25600/70204]
loss: 0.108684  [32000/70204]
loss: 0.207449  [38400/70204]
loss: 0.108297  [44800/70204]
loss: 0.144932  [51200/70204]
loss: 0.217186  [57600/70204]
loss: 0.129278  [64000/70204]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.179905 

Epoch 27
-------------------------------
loss: 0.095913  [    0/70204]
loss: 0.230810  [ 6400/70204]
loss: 0.176437  [12800/70204]
loss: 0.139973  [19200/70204]
loss: 0.293266  [25600/70204]
loss: 0.110004  [32000/70204]
loss: 0.121058  [38400/70204]
loss: 0.202939  [44800/70204]
loss: 0.186111  [51200/70204]
loss: 0.225126  [57600/70204]
loss: 0.299570  [64000/70204]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.169277 

Epoch 28
-------------------------------
loss: 0.199779  [    0/70204]
loss: 0.122634  [ 6400/70204]
loss: 0.150470  [12800/70204]
loss: 0.304772  [19200/70204]
loss: 0.143356  [25600/70204]
loss: 0.201585  [32000/70204]
loss: 0.078559  [38400/70204]
loss: 0.150082  [44800/70204]
loss: 0.175159  [51200/70204]
loss: 0.207969  [57600/70204]
loss: 0.201469  [64000/70204]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.170042 

Epoch 29
-------------------------------
loss: 0.214116  [    0/70204]
loss: 0.188503  [ 6400/70204]
loss: 0.142414  [12800/70204]
loss: 0.210537  [19200/70204]
loss: 0.181072  [25600/70204]
loss: 0.164342  [32000/70204]
loss: 0.090767  [38400/70204]
loss: 0.107024  [44800/70204]
loss: 0.146592  [51200/70204]
loss: 0.216059  [57600/70204]
loss: 0.087648  [64000/70204]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.172355 

Epoch 30
-------------------------------
loss: 0.177360  [    0/70204]
loss: 0.163371  [ 6400/70204]
loss: 0.159996  [12800/70204]
loss: 0.118966  [19200/70204]
loss: 0.215857  [25600/70204]
loss: 0.269688  [32000/70204]
loss: 0.115139  [38400/70204]
loss: 0.358519  [44800/70204]
loss: 0.222083  [51200/70204]
loss: 0.118069  [57600/70204]
loss: 0.083201  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.173245 

Epoch 31
-------------------------------
loss: 0.149651  [    0/70204]
loss: 0.168274  [ 6400/70204]
loss: 0.169217  [12800/70204]
loss: 0.109508  [19200/70204]
loss: 0.238359  [25600/70204]
loss: 0.300829  [32000/70204]
loss: 0.348686  [38400/70204]
loss: 0.143245  [44800/70204]
loss: 0.098798  [51200/70204]
loss: 0.167248  [57600/70204]
loss: 0.114528  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.178209 

Epoch 32
-------------------------------
loss: 0.150230  [    0/70204]
loss: 0.148998  [ 6400/70204]
loss: 0.166499  [12800/70204]
loss: 0.259602  [19200/70204]
loss: 0.157899  [25600/70204]
loss: 0.147333  [32000/70204]
loss: 0.117931  [38400/70204]
loss: 0.248799  [44800/70204]
loss: 0.157703  [51200/70204]
loss: 0.160138  [57600/70204]
loss: 0.135768  [64000/70204]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.169208 

Epoch 33
-------------------------------
loss: 0.099184  [    0/70204]
loss: 0.243773  [ 6400/70204]
loss: 0.108409  [12800/70204]
loss: 0.256832  [19200/70204]
loss: 0.210874  [25600/70204]
loss: 0.227409  [32000/70204]
loss: 0.197420  [38400/70204]
loss: 0.141281  [44800/70204]
loss: 0.186358  [51200/70204]
loss: 0.142295  [57600/70204]
loss: 0.271398  [64000/70204]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.186806 

Epoch 34
-------------------------------
loss: 0.169946  [    0/70204]
loss: 0.217653  [ 6400/70204]
loss: 0.207266  [12800/70204]
loss: 0.089318  [19200/70204]
loss: 0.169256  [25600/70204]
loss: 0.091120  [32000/70204]
loss: 0.069470  [38400/70204]
loss: 0.199107  [44800/70204]
loss: 0.112859  [51200/70204]
loss: 0.091478  [57600/70204]
loss: 0.130752  [64000/70204]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.175355 

Epoch 35
-------------------------------
loss: 0.081551  [    0/70204]
loss: 0.118201  [ 6400/70204]
loss: 0.111178  [12800/70204]
loss: 0.156838  [19200/70204]
loss: 0.183150  [25600/70204]
loss: 0.187183  [32000/70204]
loss: 0.099845  [38400/70204]
loss: 0.265661  [44800/70204]
loss: 0.134946  [51200/70204]
loss: 0.211265  [57600/70204]
loss: 0.162084  [64000/70204]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171826 

Epoch 36
-------------------------------
loss: 0.261414  [    0/70204]
loss: 0.136783  [ 6400/70204]
loss: 0.128196  [12800/70204]
loss: 0.094103  [19200/70204]
loss: 0.190084  [25600/70204]
loss: 0.192201  [32000/70204]
loss: 0.123196  [38400/70204]
loss: 1.622444  [44800/70204]
loss: 0.141056  [51200/70204]
loss: 0.100487  [57600/70204]
loss: 0.116937  [64000/70204]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.187919 

Epoch 37
-------------------------------
loss: 0.191965  [    0/70204]
loss: 0.293136  [ 6400/70204]
loss: 0.097489  [12800/70204]
loss: 0.143686  [19200/70204]
loss: 0.276750  [25600/70204]
loss: 0.270206  [32000/70204]
loss: 0.126122  [38400/70204]
loss: 0.270844  [44800/70204]
loss: 0.173833  [51200/70204]
loss: 0.357688  [57600/70204]
loss: 0.111504  [64000/70204]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169336 

Epoch 38
-------------------------------
loss: 0.365827  [    0/70204]
loss: 0.116083  [ 6400/70204]
loss: 0.111764  [12800/70204]
loss: 0.222901  [19200/70204]
loss: 0.173388  [25600/70204]
loss: 0.246921  [32000/70204]
loss: 0.160595  [38400/70204]
loss: 0.257010  [44800/70204]
loss: 0.117163  [51200/70204]
loss: 0.105391  [57600/70204]
loss: 0.109980  [64000/70204]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.172813 

Epoch 39
-------------------------------
loss: 0.202177  [    0/70204]
loss: 0.065383  [ 6400/70204]
loss: 0.090832  [12800/70204]
loss: 0.153163  [19200/70204]
loss: 0.213937  [25600/70204]
loss: 0.094728  [32000/70204]
loss: 0.120888  [38400/70204]
loss: 0.082179  [44800/70204]
loss: 0.093970  [51200/70204]
loss: 0.101406  [57600/70204]
loss: 0.109722  [64000/70204]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.168302 

Epoch 40
-------------------------------
loss: 0.145650  [    0/70204]
loss: 0.100290  [ 6400/70204]
loss: 0.194461  [12800/70204]
loss: 0.049563  [19200/70204]
loss: 0.224211  [25600/70204]
loss: 0.127097  [32000/70204]
loss: 0.127104  [38400/70204]
loss: 0.266907  [44800/70204]
loss: 0.100404  [51200/70204]
loss: 0.217172  [57600/70204]
loss: 0.224696  [64000/70204]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.167140 

Epoch 41
-------------------------------
loss: 0.129064  [    0/70204]
loss: 0.125980  [ 6400/70204]
loss: 0.084776  [12800/70204]
loss: 0.256874  [19200/70204]
loss: 0.181350  [25600/70204]
loss: 0.223741  [32000/70204]
loss: 0.137484  [38400/70204]
loss: 0.121843  [44800/70204]
loss: 0.136693  [51200/70204]
loss: 0.138905  [57600/70204]
loss: 0.113483  [    0/70326]
loss: 0.258671  [ 6400/70326]
loss: 0.140974  [12800/70326]
loss: 0.080811  [19200/70326]
loss: 0.102473  [25600/70326]
loss: 0.131970  [32000/70326]
loss: 0.131413  [38400/70326]
loss: 0.133870  [44800/70326]
loss: 0.154318  [51200/70326]
loss: 0.058819  [57600/70326]
loss: 0.190903  [64000/70326]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.182828 

Epoch 27
-------------------------------
loss: 0.274414  [    0/70326]
loss: 1.682702  [ 6400/70326]
loss: 0.128690  [12800/70326]
loss: 0.063460  [19200/70326]
loss: 0.177481  [25600/70326]
loss: 0.142415  [32000/70326]
loss: 0.091794  [38400/70326]
loss: 0.184932  [44800/70326]
loss: 0.089786  [51200/70326]
loss: 0.076961  [57600/70326]
loss: 0.250358  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173960 

Epoch 28
-------------------------------
loss: 0.142954  [    0/70326]
loss: 0.193073  [ 6400/70326]
loss: 0.196522  [12800/70326]
loss: 0.205255  [19200/70326]
loss: 0.167689  [25600/70326]
loss: 0.213507  [32000/70326]
loss: 0.121174  [38400/70326]
loss: 0.058529  [44800/70326]
loss: 0.099237  [51200/70326]
loss: 0.233883  [57600/70326]
loss: 0.092135  [64000/70326]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.184348 

Epoch 29
-------------------------------
loss: 0.118557  [    0/70326]
loss: 0.127218  [ 6400/70326]
loss: 0.107073  [12800/70326]
loss: 0.119259  [19200/70326]
loss: 0.260181  [25600/70326]
loss: 0.193885  [32000/70326]
loss: 0.066409  [38400/70326]
loss: 0.247625  [44800/70326]
loss: 0.128457  [51200/70326]
loss: 0.151560  [57600/70326]
loss: 0.089044  [64000/70326]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171405 

Epoch 30
-------------------------------
loss: 0.100412  [    0/70326]
loss: 0.040279  [ 6400/70326]
loss: 0.165709  [12800/70326]
loss: 0.184178  [19200/70326]
loss: 0.242889  [25600/70326]
loss: 0.122264  [32000/70326]
loss: 0.131305  [38400/70326]
loss: 0.136306  [44800/70326]
loss: 0.155282  [51200/70326]
loss: 0.219027  [57600/70326]
loss: 0.109408  [64000/70326]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.173118 

Epoch 31
-------------------------------
loss: 0.067876  [    0/70326]
loss: 0.068557  [ 6400/70326]
loss: 0.236823  [12800/70326]
loss: 0.180778  [19200/70326]
loss: 0.105275  [25600/70326]
loss: 0.122274  [32000/70326]
loss: 0.182452  [38400/70326]
loss: 0.129342  [44800/70326]
loss: 0.151253  [51200/70326]
loss: 0.163827  [57600/70326]
loss: 0.105153  [64000/70326]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.168771 

Epoch 32
-------------------------------
loss: 0.133870  [    0/70326]
loss: 0.129580  [ 6400/70326]
loss: 0.037680  [12800/70326]
loss: 0.056409  [19200/70326]
loss: 0.123342  [25600/70326]
loss: 0.206786  [32000/70326]
loss: 0.218429  [38400/70326]
loss: 0.284386  [44800/70326]
loss: 0.052153  [51200/70326]
loss: 0.110797  [57600/70326]
loss: 0.073945  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174616 

Epoch 33
-------------------------------
loss: 0.287332  [    0/70326]
loss: 0.236991  [ 6400/70326]
loss: 0.254155  [12800/70326]
loss: 0.164606  [19200/70326]
loss: 0.114081  [25600/70326]
loss: 0.153667  [32000/70326]
loss: 0.120826  [38400/70326]
loss: 0.122946  [44800/70326]
loss: 0.252514  [51200/70326]
loss: 0.340633  [57600/70326]
loss: 0.133363  [64000/70326]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.179737 

Epoch 34
-------------------------------
loss: 0.138426  [    0/70326]
loss: 0.232363  [ 6400/70326]
loss: 0.101517  [12800/70326]
loss: 0.147721  [19200/70326]
loss: 0.148756  [25600/70326]
loss: 0.184521  [32000/70326]
loss: 0.139502  [38400/70326]
loss: 0.083932  [44800/70326]
loss: 0.093845  [51200/70326]
loss: 0.158796  [57600/70326]
loss: 0.113690  [64000/70326]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.176641 

Epoch 35
-------------------------------
loss: 0.266581  [    0/70326]
loss: 0.164458  [ 6400/70326]
loss: 0.145232  [12800/70326]
loss: 0.172332  [19200/70326]
loss: 0.108728  [25600/70326]
loss: 0.147394  [32000/70326]
loss: 0.127685  [38400/70326]
loss: 0.245990  [44800/70326]
loss: 0.077686  [51200/70326]
loss: 0.130822  [57600/70326]
loss: 0.109556  [64000/70326]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171018 

Epoch 36
-------------------------------
loss: 0.174996  [    0/70326]
loss: 0.187338  [ 6400/70326]
loss: 0.087413  [12800/70326]
loss: 0.057979  [19200/70326]
loss: 0.314602  [25600/70326]
loss: 0.162684  [32000/70326]
loss: 0.115882  [38400/70326]
loss: 0.098321  [44800/70326]
loss: 0.134773  [51200/70326]
loss: 0.167442  [57600/70326]
loss: 0.156355  [64000/70326]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.168867 

Epoch 37
-------------------------------
loss: 0.199313  [    0/70326]
loss: 0.170910  [ 6400/70326]
loss: 0.101505  [12800/70326]
loss: 0.118358  [19200/70326]
loss: 0.104764  [25600/70326]
loss: 0.173499  [32000/70326]
loss: 0.171697  [38400/70326]
loss: 0.181515  [44800/70326]
loss: 0.127290  [51200/70326]
loss: 0.085837  [57600/70326]
loss: 0.211896  [64000/70326]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.169522 

Epoch 38
-------------------------------
loss: 0.093635  [    0/70326]
loss: 0.082962  [ 6400/70326]
loss: 0.264638  [12800/70326]
loss: 0.082994  [19200/70326]
loss: 0.131153  [25600/70326]
loss: 0.157023  [32000/70326]
loss: 0.191051  [38400/70326]
loss: 0.199841  [44800/70326]
loss: 0.075654  [51200/70326]
loss: 0.104287  [57600/70326]
loss: 0.058075  [64000/70326]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.178046 

Epoch 39
-------------------------------
loss: 0.152273  [    0/70326]
loss: 0.115186  [ 6400/70326]
loss: 0.167801  [12800/70326]
loss: 0.177040  [19200/70326]
loss: 0.093800  [25600/70326]
loss: 0.182805  [32000/70326]
loss: 0.112166  [38400/70326]
loss: 0.190468  [44800/70326]
loss: 0.242482  [51200/70326]
loss: 0.173567  [57600/70326]
loss: 0.112800  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173711 

Epoch 40
-------------------------------
loss: 0.157337  [    0/70326]
loss: 0.078957  [ 6400/70326]
loss: 0.195868  [12800/70326]
loss: 0.161793  [19200/70326]
loss: 0.133940  [25600/70326]
loss: 0.292699  [32000/70326]
loss: 0.062561  [38400/70326]
loss: 0.181498  [44800/70326]
loss: 0.229684  [51200/70326]
loss: 0.105355  [57600/70326]
loss: 0.131657  [64000/70326]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.166409 

Epoch 41
-------------------------------
loss: 0.071024  [    0/70326]
loss: 0.262125  [ 6400/70326]
loss: 0.137725  [12800/70326]
loss: 0.233119  [19200/70326]
loss: 0.099856  [25600/70326]
loss: 0.185650  [32000/70326]
loss: 0.172708  [38400/70326]
loss: 0.132322  [44800/70326]
loss: 0.157300  [51200/70326]
loss: 0.074548  [57600/70326]
loss: 0.106700  [64000/70326]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.172226 

Epoch 42
-------------------------------
loss: 0.140729  [    0/70326]
loss: 0.152747  [ 6400/70326]
loss: 0.065387  [12800/70326]
loss: 0.141522  [19200/70326]
loss: 0.107908  [25600/70326]
loss: 0.128540  [32000/70326]
loss: 0.158249  [38400/70326]
loss: 0.169922  [44800/70326]
loss: 0.157476  [51200/70326]
loss: 0.128185  [57600/70326]
loss: 0.103484  [64000/70326]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.179568 

Epoch 43
-------------------------------
loss: 0.118361  [    0/70326]
loss: 0.130520  [ 6400/70326]
loss: 0.241842  [12800/70326]
loss: 0.086989  [19200/70326]
loss: 0.096989  [25600/70326]
loss: 0.054118  [32000/70326]
loss: 0.134215  [38400/70326]
loss: 0.095676  [44800/70326]
loss: 0.128848  [51200/70326]
loss: 0.085503  [57600/70326]
loss: 0.134457  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.177028 

Epoch 44
-------------------------------
loss: 1.761405  [    0/70326]
loss: 0.067749  [ 6400/70326]
loss: 0.130281  [12800/70326]
loss: 0.094003  [19200/70326]
loss: 0.156833  [25600/70326]
loss: 0.063172  [32000/70326]
loss: 0.109678  [38400/70326]
loss: 0.150719  [44800/70326]
loss: 0.109681  [51200/70326]
loss: 0.263255  [57600/70326]
loss: 0.168910  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174238 

Epoch 45
-------------------------------
loss: 0.245190  [    0/70326]
loss: 0.125794  [ 6400/70326]
loss: 0.125565  [12800/70326]
loss: 0.252580  [19200/70326]
loss: 0.158317  [25600/70326]
2022/09/20 17:24:20 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:26:00 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:26:39 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.073738  [19200/69710]
loss: 0.062630  [25600/69710]
loss: 0.203932  [32000/69710]
loss: 0.145312  [38400/69710]
loss: 0.165538  [44800/69710]
loss: 0.131531  [51200/69710]
loss: 0.103776  [57600/69710]
loss: 0.254342  [64000/69710]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.156940 

Epoch 39
-------------------------------
loss: 0.243587  [    0/69710]
loss: 0.129072  [ 6400/69710]
loss: 0.115810  [12800/69710]
loss: 0.088912  [19200/69710]
loss: 0.154528  [25600/69710]
loss: 0.111300  [32000/69710]
loss: 0.101733  [38400/69710]
loss: 0.158751  [44800/69710]
loss: 0.140658  [51200/69710]
loss: 0.102688  [57600/69710]
loss: 0.129300  [64000/69710]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.141058 

Epoch 40
-------------------------------
loss: 0.108014  [    0/69710]
loss: 0.140022  [ 6400/69710]
loss: 0.090876  [12800/69710]
loss: 0.211145  [19200/69710]
loss: 0.147388  [25600/69710]
loss: 0.197282  [32000/69710]
loss: 0.063123  [38400/69710]
loss: 0.153928  [44800/69710]
loss: 0.078447  [51200/69710]
loss: 0.215448  [57600/69710]
loss: 0.157905  [64000/69710]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.143304 

Epoch 41
-------------------------------
loss: 0.160180  [    0/69710]
loss: 0.195461  [ 6400/69710]
loss: 0.104986  [12800/69710]
loss: 0.143662  [19200/69710]
loss: 0.135471  [25600/69710]
loss: 0.177287  [32000/69710]
loss: 0.212545  [38400/69710]
loss: 0.171099  [44800/69710]
loss: 0.190965  [51200/69710]
loss: 0.159826  [57600/69710]
loss: 0.262986  [64000/69710]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.147853 

Epoch 42
-------------------------------
loss: 0.057759  [    0/69710]
loss: 0.215241  [ 6400/69710]
loss: 0.200278  [12800/69710]
loss: 0.091935  [19200/69710]
loss: 0.154641  [25600/69710]
loss: 0.105092  [32000/69710]
loss: 0.153703  [38400/69710]
loss: 0.196527  [44800/69710]
loss: 0.167586  [51200/69710]
loss: 0.120374  [57600/69710]
loss: 0.136810  [64000/69710]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.150448 

Epoch 43
-------------------------------
loss: 0.185481  [    0/69710]
loss: 0.110793  [ 6400/69710]
loss: 0.230256  [12800/69710]
loss: 0.081124  [19200/69710]
loss: 0.128801  [25600/69710]
loss: 0.078556  [32000/69710]
loss: 0.101560  [38400/69710]
loss: 0.193297  [44800/69710]
loss: 0.130858  [51200/69710]
loss: 0.064360  [57600/69710]
loss: 0.025995  [64000/69710]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.143325 

Epoch 44
-------------------------------
loss: 0.179606  [    0/69710]
loss: 0.183426  [ 6400/69710]
loss: 0.171355  [12800/69710]
loss: 0.163633  [19200/69710]
loss: 0.136712  [25600/69710]
loss: 0.272517  [32000/69710]
loss: 0.274807  [38400/69710]
loss: 0.102148  [44800/69710]
loss: 0.128620  [51200/69710]
loss: 0.214985  [57600/69710]
loss: 0.092963  [64000/69710]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.137942 

Epoch 45
-------------------------------
loss: 0.102056  [    0/69710]
loss: 0.083592  [ 6400/69710]
loss: 0.147132  [12800/69710]
loss: 0.066464  [19200/69710]
loss: 0.123733  [25600/69710]
loss: 0.062409  [32000/69710]
loss: 0.093857  [38400/69710]
loss: 0.236549  [44800/69710]
loss: 0.171158  [51200/69710]
loss: 0.204110  [57600/69710]
loss: 0.053446  [64000/69710]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.143403 

Epoch 46
-------------------------------
loss: 0.096898  [    0/69710]
loss: 0.231428  [ 6400/69710]
loss: 0.119249  [12800/69710]
loss: 0.157302  [19200/69710]
loss: 0.130829  [25600/69710]
loss: 0.301904  [32000/69710]
loss: 0.223518  [38400/69710]
loss: 0.189922  [44800/69710]
loss: 0.086597  [51200/69710]
loss: 0.178479  [57600/69710]
loss: 0.164230  [64000/69710]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.141759 

Epoch 47
-------------------------------
loss: 0.114973  [    0/69710]
loss: 0.167766  [ 6400/69710]
loss: 0.171174  [12800/69710]
loss: 0.040963  [19200/69710]
loss: 0.100827  [25600/69710]
loss: 0.138290  [32000/69710]
loss: 0.133355  [38400/69710]
loss: 0.145473  [44800/69710]
loss: 0.086494  [51200/69710]
loss: 0.153226  [57600/69710]
loss: 0.067981  [64000/69710]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.151857 

Epoch 48
-------------------------------
loss: 0.020557  [    0/69710]
loss: 0.182531  [ 6400/69710]
loss: 0.062323  [12800/69710]
loss: 0.197888  [19200/69710]
loss: 0.050777  [25600/69710]
loss: 0.216104  [32000/69710]
loss: 0.065813  [38400/69710]
loss: 0.113407  [44800/69710]
loss: 0.192429  [51200/69710]
loss: 0.125820  [57600/69710]
loss: 0.083986  [64000/69710]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.140358 

Epoch 49
-------------------------------
loss: 0.192022  [    0/69710]
loss: 0.104402  [ 6400/69710]
loss: 0.068836  [12800/69710]
loss: 0.199106  [19200/69710]
loss: 0.136525  [25600/69710]
loss: 0.254800  [32000/69710]
loss: 0.104453  [38400/69710]
loss: 0.110249  [44800/69710]
loss: 0.155123  [51200/69710]
loss: 0.164426  [57600/69710]
loss: 0.101383  [64000/69710]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.138255 

Epoch 50
-------------------------------
loss: 0.039389  [    0/69710]
loss: 0.116592  [ 6400/69710]
loss: 0.071554  [12800/69710]
loss: 0.187486  [19200/69710]
loss: 0.289286  [25600/69710]
loss: 0.131013  [32000/69710]
loss: 0.088675  [38400/69710]
loss: 0.142898  [44800/69710]
loss: 0.113231  [51200/69710]
loss: 0.136750  [57600/69710]
loss: 0.126673  [64000/69710]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.144031 

Epoch 1
-------------------------------
loss: 0.745268  [    0/70717]
loss: 0.300048  [ 6400/70717]
loss: 0.254944  [12800/70717]
loss: 0.225506  [19200/70717]
loss: 0.299390  [25600/70717]
loss: 0.178553  [32000/70717]
loss: 0.243655  [38400/70717]
loss: 0.153834  [44800/70717]
loss: 0.203614  [51200/70717]
loss: 0.094030  [57600/70717]
loss: 0.196694  [64000/70717]
loss: 0.201075  [70400/70717]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.158633 

Epoch 2
-------------------------------
loss: 0.197755  [    0/70717]
loss: 0.121324  [ 6400/70717]
loss: 0.107531  [12800/70717]
loss: 0.214336  [19200/70717]
loss: 0.135018  [25600/70717]
loss: 0.240394  [32000/70717]
loss: 0.207770  [38400/70717]
loss: 0.081922  [44800/70717]
loss: 0.097525  [51200/70717]
loss: 0.162010  [57600/70717]
loss: 0.147669  [64000/70717]
loss: 0.149231  [70400/70717]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.142223 

Epoch 3
-------------------------------
loss: 0.055535  [    0/70717]
loss: 0.110744  [ 6400/70717]
loss: 0.264857  [12800/70717]
loss: 0.205746  [19200/70717]
loss: 0.214100  [25600/70717]
loss: 0.188121  [32000/70717]
loss: 0.056387  [38400/70717]
loss: 0.183031  [44800/70717]
loss: 0.212046  [51200/70717]
loss: 0.068536  [57600/70717]
loss: 0.085654  [64000/70717]
loss: 0.210903  [70400/70717]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.138753 

Epoch 4
-------------------------------
loss: 0.076577  [    0/70717]
loss: 0.094129  [ 6400/70717]
loss: 0.102045  [12800/70717]
loss: 0.118682  [19200/70717]
loss: 0.090352  [25600/70717]
loss: 0.147274  [32000/70717]
loss: 0.045312  [38400/70717]
loss: 0.336351  [44800/70717]
loss: 0.097230  [51200/70717]
loss: 0.212019  [57600/70717]
loss: 0.084641  [64000/70717]
loss: 0.135806  [70400/70717]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.136001 

Epoch 5
-------------------------------
loss: 0.080587  [    0/70717]
loss: 0.088932  [ 6400/70717]
loss: 0.054742  [12800/70717]
loss: 0.079003  [19200/70717]
loss: 0.144036  [25600/70717]
loss: 0.119390  [32000/70717]
loss: 0.209829  [38400/70717]
loss: 0.123926  [44800/70717]
loss: 0.119420  [51200/70717]
loss: 0.099913  [57600/70717]
loss: 0.092910  [64000/70717]
loss: 0.123066  [70400/70717]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.131137 

Epoch 6
-------------------------------
loss: 0.092735  [    0/70717]
loss: 0.140820  [ 6400/70717]
loss: 0.167614  [12800/70717]
loss: 0.137730  [19200/70717]
loss: 0.164131  [25600/70717]
loss: 0.111451  [32000/70717]
loss: 0.118637  [38400/70717]
loss: 0.147918  [44800/70717]
loss: 0.127922  [51200/70717]
loss: 0.084364  [57600/70717]
loss: 0.112889  [64000/70717]
loss: 0.019924  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.120679 

Epoch 7
-------------------------------
loss: 1.574866  [    0/70717]
loss: 0.114035  [ 6400/70717]
2022/09/20 17:28:41 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.178674  [19200/69795]
loss: 0.192946  [25600/69795]
loss: 0.235890  [32000/69795]
loss: 0.259083  [38400/69795]
loss: 0.294623  [44800/69795]
loss: 0.135139  [51200/69795]
loss: 0.132739  [57600/69795]
loss: 0.230264  [64000/69795]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.175882 

Epoch 39
-------------------------------
loss: 0.114071  [    0/69795]
loss: 0.177753  [ 6400/69795]
loss: 0.156769  [12800/69795]
loss: 0.191534  [19200/69795]
loss: 0.091138  [25600/69795]
loss: 0.120277  [32000/69795]
loss: 0.117125  [38400/69795]
loss: 0.290547  [44800/69795]
loss: 0.083334  [51200/69795]
loss: 0.146993  [57600/69795]
loss: 0.186103  [64000/69795]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.172039 

Epoch 40
-------------------------------
loss: 0.172482  [    0/69795]
loss: 0.159730  [ 6400/69795]
loss: 0.131380  [12800/69795]
loss: 0.161880  [19200/69795]
loss: 0.122116  [25600/69795]
loss: 0.176138  [32000/69795]
loss: 0.143560  [38400/69795]
loss: 0.200556  [44800/69795]
loss: 0.217067  [51200/69795]
loss: 0.149352  [57600/69795]
loss: 0.150398  [64000/69795]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.182394 

Epoch 41
-------------------------------
loss: 0.107313  [    0/69795]
loss: 0.159153  [ 6400/69795]
loss: 0.201489  [12800/69795]
loss: 0.159517  [19200/69795]
loss: 0.274278  [25600/69795]
loss: 0.134648  [32000/69795]
loss: 0.206635  [38400/69795]
loss: 0.182876  [44800/69795]
loss: 0.136447  [51200/69795]
loss: 0.303728  [57600/69795]
loss: 0.148068  [64000/69795]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.196671 

Epoch 42
-------------------------------
loss: 0.191259  [    0/69795]
loss: 0.232486  [ 6400/69795]
loss: 0.200687  [12800/69795]
loss: 0.188966  [19200/69795]
loss: 0.311805  [25600/69795]
loss: 0.168684  [32000/69795]
loss: 0.128932  [38400/69795]
loss: 0.167961  [44800/69795]
loss: 0.065944  [51200/69795]
loss: 0.217246  [57600/69795]
loss: 0.086112  [64000/69795]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.186060 

Epoch 43
-------------------------------
loss: 0.306828  [    0/69795]
loss: 0.183761  [ 6400/69795]
loss: 0.134572  [12800/69795]
loss: 0.204088  [19200/69795]
loss: 0.215371  [25600/69795]
loss: 0.194566  [32000/69795]
loss: 0.260156  [38400/69795]
loss: 0.166049  [44800/69795]
loss: 0.237645  [51200/69795]
loss: 0.155872  [57600/69795]
loss: 0.222885  [64000/69795]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.180719 

Epoch 44
-------------------------------
loss: 0.246237  [    0/69795]
loss: 0.142755  [ 6400/69795]
loss: 0.127414  [12800/69795]
loss: 0.190621  [19200/69795]
loss: 0.107839  [25600/69795]
loss: 0.182520  [32000/69795]
loss: 0.138194  [38400/69795]
loss: 0.187468  [44800/69795]
loss: 0.223143  [51200/69795]
loss: 0.236873  [57600/69795]
loss: 0.100618  [64000/69795]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.172381 

Epoch 45
-------------------------------
loss: 0.163266  [    0/69795]
loss: 0.293566  [ 6400/69795]
loss: 0.170025  [12800/69795]
loss: 0.160700  [19200/69795]
loss: 0.180333  [25600/69795]
loss: 0.183277  [32000/69795]
loss: 0.244282  [38400/69795]
loss: 0.152132  [44800/69795]
loss: 0.284393  [51200/69795]
loss: 0.228824  [57600/69795]
loss: 0.236247  [64000/69795]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.194488 

Epoch 46
-------------------------------
loss: 0.231739  [    0/69795]
loss: 0.198939  [ 6400/69795]
loss: 0.210416  [12800/69795]
loss: 0.384333  [19200/69795]
loss: 0.100931  [25600/69795]
loss: 0.162933  [32000/69795]
loss: 0.104536  [38400/69795]
loss: 0.121663  [44800/69795]
loss: 0.132093  [51200/69795]
loss: 0.178291  [57600/69795]
loss: 0.189132  [64000/69795]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.181395 

Epoch 47
-------------------------------
loss: 0.249122  [    0/69795]
loss: 0.188646  [ 6400/69795]
loss: 0.294307  [12800/69795]
loss: 0.207156  [19200/69795]
loss: 0.150090  [25600/69795]
loss: 0.103850  [32000/69795]
loss: 0.218313  [38400/69795]
loss: 0.183021  [44800/69795]
loss: 0.214454  [51200/69795]
loss: 0.165382  [57600/69795]
loss: 0.119346  [64000/69795]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.177648 

Epoch 48
-------------------------------
loss: 0.167753  [    0/69795]
loss: 0.131077  [ 6400/69795]
loss: 0.179185  [12800/69795]
loss: 0.262356  [19200/69795]
loss: 0.133996  [25600/69795]
loss: 0.250128  [32000/69795]
loss: 0.219205  [38400/69795]
loss: 0.161137  [44800/69795]
loss: 0.105050  [51200/69795]
loss: 0.135494  [57600/69795]
loss: 0.261938  [64000/69795]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.179044 

Epoch 49
-------------------------------
loss: 0.240063  [    0/69795]
loss: 0.112841  [ 6400/69795]
loss: 0.155295  [12800/69795]
loss: 0.147179  [19200/69795]
loss: 0.137416  [25600/69795]
loss: 0.166163  [32000/69795]
loss: 0.112957  [38400/69795]
loss: 0.217145  [44800/69795]
loss: 0.158337  [51200/69795]
loss: 0.111314  [57600/69795]
loss: 0.065079  [64000/69795]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.189905 

Epoch 50
-------------------------------
loss: 0.183335  [    0/69795]
loss: 0.120005  [ 6400/69795]
loss: 0.159873  [12800/69795]
loss: 0.230150  [19200/69795]
loss: 0.234660  [25600/69795]
loss: 0.215093  [32000/69795]
loss: 0.207336  [38400/69795]
loss: 0.134424  [44800/69795]
loss: 0.190354  [51200/69795]
loss: 0.234194  [57600/69795]
loss: 0.135411  [64000/69795]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.185641 

Epoch 1
-------------------------------
loss: 0.737066  [    0/70523]
loss: 0.340464  [ 6400/70523]
loss: 0.283413  [12800/70523]
loss: 0.249286  [19200/70523]
loss: 0.240407  [25600/70523]
loss: 0.297289  [32000/70523]
loss: 0.202275  [38400/70523]
loss: 0.410085  [44800/70523]
loss: 0.429003  [51200/70523]
loss: 0.306814  [57600/70523]
loss: 0.195354  [64000/70523]
loss: 0.219740  [70400/70523]
Test Error: 
 Accuracy: 90.7%, Avg loss: 0.243057 

Epoch 2
-------------------------------
loss: 0.183278  [    0/70523]
loss: 0.282263  [ 6400/70523]
loss: 0.178478  [12800/70523]
loss: 0.280496  [19200/70523]
loss: 0.255406  [25600/70523]
loss: 0.243864  [32000/70523]
loss: 0.352564  [38400/70523]
loss: 0.296795  [44800/70523]
loss: 0.178580  [51200/70523]
loss: 0.227777  [57600/70523]
loss: 0.168183  [64000/70523]
loss: 0.294767  [70400/70523]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.228931 

Epoch 3
-------------------------------
loss: 0.173365  [    0/70523]
loss: 0.273765  [ 6400/70523]
loss: 0.201227  [12800/70523]
loss: 0.127757  [19200/70523]
loss: 0.230538  [25600/70523]
loss: 0.197863  [32000/70523]
loss: 0.236801  [38400/70523]
loss: 0.182434  [44800/70523]
loss: 0.183375  [51200/70523]
loss: 0.311197  [57600/70523]
loss: 0.088781  [64000/70523]
loss: 0.268507  [70400/70523]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.203695 

Epoch 4
-------------------------------
loss: 0.125042  [    0/70523]
loss: 0.190869  [ 6400/70523]
loss: 0.271970  [12800/70523]
loss: 0.230046  [19200/70523]
loss: 0.201166  [25600/70523]
loss: 0.263730  [32000/70523]
loss: 0.140988  [38400/70523]
loss: 0.137547  [44800/70523]
loss: 0.150355  [51200/70523]
loss: 0.184723  [57600/70523]
loss: 0.145496  [64000/70523]
loss: 0.137850  [70400/70523]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.193318 

Epoch 5
-------------------------------
loss: 0.142472  [    0/70523]
loss: 0.161584  [ 6400/70523]
loss: 0.183725  [12800/70523]
loss: 0.222802  [19200/70523]
loss: 0.152336  [25600/70523]
loss: 0.189771  [32000/70523]
loss: 0.253988  [38400/70523]
loss: 0.251571  [44800/70523]
loss: 0.174553  [51200/70523]
loss: 0.173264  [57600/70523]
loss: 0.165107  [64000/70523]
loss: 0.115178  [70400/70523]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.190883 

Epoch 6
-------------------------------
loss: 0.152727  [    0/70523]
loss: 0.211474  [ 6400/70523]
loss: 0.213318  [12800/70523]
loss: 0.211174  [19200/70523]
loss: 0.169144  [25600/70523]
loss: 0.205968  [32000/70523]
loss: 0.163806  [38400/70523]
loss: 0.148204  [44800/70523]
loss: 0.312960  [51200/70523]
loss: 0.114719  [57600/70523]
loss: 0.111698  [64000/70523]
loss: 0.135757  [70400/70523]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.187739 

Epoch 7
-------------------------------
loss: 0.085092  [    0/70523]
loss: 0.202857  [ 6400/70523]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.179013 

Epoch 42
-------------------------------
loss: 0.130913  [    0/69947]
loss: 0.092918  [ 6400/69947]
loss: 0.116550  [12800/69947]
loss: 0.126849  [19200/69947]
loss: 0.068787  [25600/69947]
loss: 0.142603  [32000/69947]
loss: 0.084770  [38400/69947]
loss: 0.099614  [44800/69947]
loss: 0.068484  [51200/69947]
loss: 0.167926  [57600/69947]
loss: 0.145928  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.177727 

Epoch 43
-------------------------------
loss: 0.141461  [    0/69947]
loss: 0.128650  [ 6400/69947]
loss: 0.146030  [12800/69947]
loss: 0.120704  [19200/69947]
loss: 0.088616  [25600/69947]
loss: 0.129777  [32000/69947]
loss: 0.032742  [38400/69947]
loss: 0.189181  [44800/69947]
loss: 0.106293  [51200/69947]
loss: 0.074928  [57600/69947]
loss: 0.106476  [64000/69947]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.180464 

Epoch 44
-------------------------------
loss: 0.112607  [    0/69947]
loss: 0.130913  [ 6400/69947]
loss: 0.313683  [12800/69947]
loss: 0.093904  [19200/69947]
loss: 0.261504  [25600/69947]
loss: 0.239114  [32000/69947]
loss: 0.148810  [38400/69947]
loss: 0.098813  [44800/69947]
loss: 0.130045  [51200/69947]
loss: 0.157312  [57600/69947]
loss: 0.179275  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.178240 

Epoch 45
-------------------------------
loss: 0.135008  [    0/69947]
loss: 0.122012  [ 6400/69947]
loss: 0.095388  [12800/69947]
loss: 0.176264  [19200/69947]
loss: 0.079637  [25600/69947]
loss: 0.199424  [32000/69947]
loss: 0.238710  [38400/69947]
loss: 0.207346  [44800/69947]
loss: 0.064546  [51200/69947]
loss: 0.138277  [57600/69947]
loss: 0.280752  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.170611 

Epoch 46
-------------------------------
loss: 0.069807  [    0/69947]
loss: 0.131953  [ 6400/69947]
loss: 0.154803  [12800/69947]
loss: 0.093653  [19200/69947]
loss: 0.209347  [25600/69947]
loss: 0.061204  [32000/69947]
loss: 0.158892  [38400/69947]
loss: 0.115724  [44800/69947]
loss: 0.171818  [51200/69947]
loss: 0.018347  [57600/69947]
loss: 0.254540  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.173008 

Epoch 47
-------------------------------
loss: 0.055909  [    0/69947]
loss: 0.114361  [ 6400/69947]
loss: 0.144837  [12800/69947]
loss: 0.086100  [19200/69947]
loss: 0.158458  [25600/69947]
loss: 0.191375  [32000/69947]
loss: 0.144876  [38400/69947]
loss: 0.164486  [44800/69947]
loss: 0.200620  [51200/69947]
loss: 0.065296  [57600/69947]
loss: 0.083284  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.182578 

Epoch 48
-------------------------------
loss: 0.156449  [    0/69947]
loss: 0.169485  [ 6400/69947]
loss: 0.084834  [12800/69947]
loss: 0.102429  [19200/69947]
loss: 0.091680  [25600/69947]
loss: 0.153917  [32000/69947]
loss: 0.056264  [38400/69947]
loss: 0.112304  [44800/69947]
loss: 0.121531  [51200/69947]
loss: 0.158409  [57600/69947]
loss: 0.100852  [64000/69947]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.167207 

Epoch 49
-------------------------------
loss: 0.111531  [    0/69947]
loss: 0.057537  [ 6400/69947]
loss: 0.270655  [12800/69947]
loss: 0.109437  [19200/69947]
loss: 0.053940  [25600/69947]
loss: 0.136849  [32000/69947]
loss: 0.290498  [38400/69947]
loss: 0.171133  [44800/69947]
loss: 0.060070  [51200/69947]
loss: 0.150975  [57600/69947]
loss: 0.206289  [64000/69947]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.173798 

Epoch 50
-------------------------------
loss: 0.109391  [    0/69947]
loss: 0.174884  [ 6400/69947]
loss: 0.132238  [12800/69947]
loss: 0.114014  [19200/69947]
loss: 0.122015  [25600/69947]
loss: 0.129164  [32000/69947]
loss: 0.163073  [38400/69947]
loss: 0.193654  [44800/69947]
loss: 0.074118  [51200/69947]
loss: 0.105453  [57600/69947]
loss: 0.087949  [64000/69947]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.179849 

Epoch 1
-------------------------------
loss: 0.747017  [    0/70677]
loss: 0.379683  [ 6400/70677]
loss: 0.358393  [12800/70677]
loss: 0.235933  [19200/70677]
loss: 0.181326  [25600/70677]
loss: 0.221936  [32000/70677]
loss: 0.274928  [38400/70677]
loss: 0.199319  [44800/70677]
loss: 0.263660  [51200/70677]
loss: 0.232474  [57600/70677]
loss: 0.157064  [64000/70677]
loss: 0.154447  [70400/70677]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.256503 

Epoch 2
-------------------------------
loss: 0.226646  [    0/70677]
loss: 0.224614  [ 6400/70677]
loss: 0.246821  [12800/70677]
loss: 0.235533  [19200/70677]
loss: 0.347548  [25600/70677]
loss: 0.278229  [32000/70677]
loss: 0.331325  [38400/70677]
loss: 0.127950  [44800/70677]
loss: 0.208097  [51200/70677]
loss: 0.342731  [57600/70677]
loss: 0.170312  [64000/70677]
loss: 0.201278  [70400/70677]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.237125 

Epoch 3
-------------------------------
loss: 0.221780  [    0/70677]
loss: 0.177632  [ 6400/70677]
loss: 0.167270  [12800/70677]
loss: 0.275923  [19200/70677]
loss: 0.106394  [25600/70677]
loss: 0.114705  [32000/70677]
loss: 0.147406  [38400/70677]
loss: 0.245284  [44800/70677]
loss: 0.151189  [51200/70677]
loss: 0.168459  [57600/70677]
loss: 0.172642  [64000/70677]
loss: 0.128113  [70400/70677]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.235227 

Epoch 4
-------------------------------
loss: 0.295197  [    0/70677]
loss: 0.170585  [ 6400/70677]
loss: 0.207651  [12800/70677]
loss: 0.177873  [19200/70677]
loss: 0.145699  [25600/70677]
loss: 0.296917  [32000/70677]
loss: 0.199652  [38400/70677]
loss: 0.277613  [44800/70677]
loss: 0.199973  [51200/70677]
loss: 0.205532  [57600/70677]
loss: 0.262272  [64000/70677]
loss: 0.061539  [70400/70677]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.237326 

Epoch 5
-------------------------------
loss: 0.153986  [    0/70677]
loss: 0.189422  [ 6400/70677]
loss: 0.161618  [12800/70677]
loss: 0.235243  [19200/70677]
loss: 0.162352  [25600/70677]
loss: 0.159726  [32000/70677]
loss: 0.099546  [38400/70677]
loss: 0.087640  [44800/70677]
loss: 0.246579  [51200/70677]
loss: 0.231521  [57600/70677]
loss: 0.225778  [64000/70677]
loss: 0.118413  [70400/70677]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.232494 

Epoch 6
-------------------------------
loss: 0.127821  [    0/70677]
loss: 0.225290  [ 6400/70677]
loss: 0.199442  [12800/70677]
loss: 0.218332  [19200/70677]
loss: 0.088490  [25600/70677]
loss: 0.186407  [32000/70677]
loss: 1.739058  [38400/70677]
loss: 0.216006  [44800/70677]
loss: 0.243172  [51200/70677]
loss: 0.247550  [57600/70677]
loss: 0.205032  [64000/70677]
loss: 0.163901  [70400/70677]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.230851 

Epoch 7
-------------------------------
loss: 0.233705  [    0/70677]
loss: 0.155734  [ 6400/70677]
loss: 0.152244  [12800/70677]
loss: 0.146977  [19200/70677]
loss: 0.120539  [25600/70677]
loss: 0.112339  [32000/70677]
loss: 0.214409  [38400/70677]
loss: 0.121741  [44800/70677]
loss: 0.124303  [51200/70677]
loss: 0.140992  [57600/70677]
loss: 0.063958  [64000/70677]
loss: 0.087099  [70400/70677]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.240829 

Epoch 8
-------------------------------
loss: 0.068339  [    0/70677]
loss: 0.104072  [ 6400/70677]
loss: 0.098229  [12800/70677]
loss: 0.198936  [19200/70677]
loss: 0.113978  [25600/70677]
loss: 0.186246  [32000/70677]
loss: 0.119890  [38400/70677]
loss: 0.279190  [44800/70677]
loss: 1.779981  [51200/70677]
loss: 0.092337  [57600/70677]
loss: 0.235102  [64000/70677]
loss: 0.135587  [70400/70677]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.233316 

Epoch 9
-------------------------------
loss: 0.123686  [    0/70677]
loss: 0.086159  [ 6400/70677]
loss: 0.166895  [12800/70677]
loss: 0.302899  [19200/70677]
loss: 0.172887  [25600/70677]
loss: 0.104915  [32000/70677]
loss: 0.108778  [38400/70677]
loss: 0.239079  [44800/70677]
loss: 0.177072  [51200/70677]
loss: 0.268665  [57600/70677]
loss: 0.214789  [64000/70677]
loss: 0.162417  [70400/70677]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.224964 

Epoch 10
-------------------------------
loss: 0.179976  [    0/70677]
loss: 0.103784  [ 6400/70677]
loss: 0.242304  [12800/70677]
loss: 0.123720  [19200/70677]
loss: 0.127828  [25600/70677]
loss: 0.180062  [32000/70677]
loss: 0.137398  [38400/70677]
2022/09/20 17:31:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.225421  [64000/69168]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.176626 

Epoch 42
-------------------------------
loss: 0.134179  [    0/69168]
loss: 0.100263  [ 6400/69168]
loss: 0.272815  [12800/69168]
loss: 0.175094  [19200/69168]
loss: 0.143432  [25600/69168]
loss: 0.298293  [32000/69168]
loss: 0.234677  [38400/69168]
loss: 0.141212  [44800/69168]
loss: 0.233018  [51200/69168]
loss: 0.217429  [57600/69168]
loss: 0.224269  [64000/69168]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.173969 

Epoch 43
-------------------------------
loss: 0.203741  [    0/69168]
loss: 0.248217  [ 6400/69168]
loss: 0.094728  [12800/69168]
loss: 0.148140  [19200/69168]
loss: 0.200839  [25600/69168]
loss: 0.138396  [32000/69168]
loss: 0.241333  [38400/69168]
loss: 0.122879  [44800/69168]
loss: 0.124686  [51200/69168]
loss: 0.247705  [57600/69168]
loss: 0.244738  [64000/69168]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.174551 

Epoch 44
-------------------------------
loss: 0.087273  [    0/69168]
loss: 0.252990  [ 6400/69168]
loss: 0.223799  [12800/69168]
loss: 0.135171  [19200/69168]
loss: 0.135951  [25600/69168]
loss: 0.238817  [32000/69168]
loss: 0.341006  [38400/69168]
loss: 0.230047  [44800/69168]
loss: 0.192636  [51200/69168]
loss: 0.181412  [57600/69168]
loss: 0.155862  [64000/69168]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.165967 

Epoch 45
-------------------------------
loss: 0.314477  [    0/69168]
loss: 0.302091  [ 6400/69168]
loss: 0.262546  [12800/69168]
loss: 0.235118  [19200/69168]
loss: 0.243986  [25600/69168]
loss: 0.079584  [32000/69168]
loss: 0.123136  [38400/69168]
loss: 0.217430  [44800/69168]
loss: 0.141916  [51200/69168]
loss: 0.338380  [57600/69168]
loss: 0.248832  [64000/69168]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.171311 

Epoch 46
-------------------------------
loss: 0.114317  [    0/69168]
loss: 0.213564  [ 6400/69168]
loss: 0.206377  [12800/69168]
loss: 0.178410  [19200/69168]
loss: 0.143251  [25600/69168]
loss: 0.217087  [32000/69168]
loss: 0.199255  [38400/69168]
loss: 0.235079  [44800/69168]
loss: 0.209574  [51200/69168]
loss: 0.235143  [57600/69168]
loss: 0.232663  [64000/69168]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.193777 

Epoch 47
-------------------------------
loss: 0.255674  [    0/69168]
loss: 0.207068  [ 6400/69168]
loss: 0.168323  [12800/69168]
loss: 0.298856  [19200/69168]
loss: 0.153945  [25600/69168]
loss: 0.179205  [32000/69168]
loss: 0.170329  [38400/69168]
loss: 0.147089  [44800/69168]
loss: 0.196134  [51200/69168]
loss: 0.143900  [57600/69168]
loss: 0.226104  [64000/69168]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.185323 

Epoch 48
-------------------------------
loss: 0.301581  [    0/69168]
loss: 0.100302  [ 6400/69168]
loss: 0.247771  [12800/69168]
loss: 0.299435  [19200/69168]
loss: 0.150962  [25600/69168]
loss: 0.126701  [32000/69168]
loss: 0.163834  [38400/69168]
loss: 0.059390  [44800/69168]
loss: 0.208625  [51200/69168]
loss: 0.100268  [57600/69168]
loss: 0.140761  [64000/69168]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.191076 

Epoch 49
-------------------------------
loss: 0.118933  [    0/69168]
loss: 0.158687  [ 6400/69168]
loss: 0.133857  [12800/69168]
loss: 0.233099  [19200/69168]
loss: 0.206158  [25600/69168]
loss: 0.246209  [32000/69168]
loss: 0.205499  [38400/69168]
loss: 0.145817  [44800/69168]
loss: 0.120406  [51200/69168]
loss: 0.235674  [57600/69168]
loss: 0.123263  [64000/69168]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.178088 

Epoch 50
-------------------------------
loss: 0.239082  [    0/69168]
loss: 0.138863  [ 6400/69168]
loss: 0.183100  [12800/69168]
loss: 0.139868  [19200/69168]
loss: 0.228730  [25600/69168]
loss: 0.319659  [32000/69168]
loss: 0.244643  [38400/69168]
loss: 0.100077  [44800/69168]
loss: 0.330136  [51200/69168]
loss: 0.308254  [57600/69168]
loss: 0.191220  [64000/69168]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.171884 

Epoch 1
-------------------------------
loss: 0.740408  [    0/71095]
loss: 0.300287  [ 6400/71095]
loss: 0.247885  [12800/71095]
loss: 0.166388  [19200/71095]
loss: 0.218547  [25600/71095]
loss: 0.044642  [32000/71095]
loss: 0.226161  [38400/71095]
loss: 0.118443  [44800/71095]
loss: 0.082564  [51200/71095]
loss: 0.102820  [57600/71095]
loss: 0.148374  [64000/71095]
loss: 0.074095  [70400/71095]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.197777 

Epoch 2
-------------------------------
loss: 0.119849  [    0/71095]
loss: 0.086495  [ 6400/71095]
loss: 0.107582  [12800/71095]
loss: 0.114946  [19200/71095]
loss: 0.085485  [25600/71095]
loss: 0.112169  [32000/71095]
loss: 0.037430  [38400/71095]
loss: 0.099562  [44800/71095]
loss: 0.068168  [51200/71095]
loss: 0.105155  [57600/71095]
loss: 0.197406  [64000/71095]
loss: 0.127974  [70400/71095]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.180522 

Epoch 3
-------------------------------
loss: 0.224995  [    0/71095]
loss: 0.123900  [ 6400/71095]
loss: 0.132780  [12800/71095]
loss: 0.241965  [19200/71095]
loss: 0.156893  [25600/71095]
loss: 0.262216  [32000/71095]
loss: 0.076442  [38400/71095]
loss: 0.182232  [44800/71095]
loss: 0.201133  [51200/71095]
loss: 1.743694  [57600/71095]
loss: 0.135740  [64000/71095]
loss: 0.069218  [70400/71095]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.171877 

Epoch 4
-------------------------------
loss: 0.118081  [    0/71095]
loss: 0.115966  [ 6400/71095]
loss: 0.167013  [12800/71095]
loss: 0.187791  [19200/71095]
loss: 0.043607  [25600/71095]
loss: 0.107120  [32000/71095]
loss: 1.668214  [38400/71095]
loss: 0.108966  [44800/71095]
loss: 0.188530  [51200/71095]
loss: 0.073719  [57600/71095]
loss: 0.114038  [64000/71095]
loss: 0.067198  [70400/71095]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.168402 

Epoch 5
-------------------------------
loss: 0.118510  [    0/71095]
loss: 0.050363  [ 6400/71095]
loss: 0.068594  [12800/71095]
loss: 0.164126  [19200/71095]
loss: 0.230496  [25600/71095]
loss: 0.085517  [32000/71095]
loss: 0.112387  [38400/71095]
loss: 1.605164  [44800/71095]
loss: 0.153796  [51200/71095]
loss: 0.056652  [57600/71095]
loss: 0.190293  [64000/71095]
loss: 0.218272  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.161443 

Epoch 6
-------------------------------
loss: 0.103565  [    0/71095]
loss: 0.053027  [ 6400/71095]
loss: 0.028448  [12800/71095]
loss: 0.064742  [19200/71095]
loss: 0.183729  [25600/71095]
loss: 0.139725  [32000/71095]
loss: 0.051692  [38400/71095]
loss: 0.121666  [44800/71095]
loss: 0.191835  [51200/71095]
loss: 0.115885  [57600/71095]
loss: 0.165700  [64000/71095]
loss: 0.123982  [70400/71095]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.167920 

Epoch 7
-------------------------------
loss: 0.069284  [    0/71095]
loss: 0.038481  [ 6400/71095]
loss: 0.091256  [12800/71095]
loss: 0.069943  [19200/71095]
loss: 0.035503  [25600/71095]
loss: 0.086759  [32000/71095]
loss: 0.092448  [38400/71095]
loss: 0.153418  [44800/71095]
loss: 0.086838  [51200/71095]
loss: 0.060062  [57600/71095]
loss: 0.218420  [64000/71095]
loss: 0.176333  [70400/71095]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.161096 

Epoch 8
-------------------------------
loss: 0.077695  [    0/71095]
loss: 0.135655  [ 6400/71095]
loss: 0.068613  [12800/71095]
loss: 0.070478  [19200/71095]
loss: 0.022228  [25600/71095]
loss: 0.186602  [32000/71095]
loss: 0.142231  [38400/71095]
loss: 0.123711  [44800/71095]
loss: 0.167384  [51200/71095]
loss: 0.065823  [57600/71095]
loss: 0.082690  [64000/71095]
loss: 0.082615  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.155099 

Epoch 9
-------------------------------
loss: 0.072947  [    0/71095]
loss: 0.169878  [ 6400/71095]
loss: 0.099260  [12800/71095]
loss: 0.122644  [19200/71095]
loss: 0.140236  [25600/71095]
loss: 1.612400  [32000/71095]
loss: 0.128237  [38400/71095]
loss: 0.133087  [44800/71095]
loss: 0.153140  [51200/71095]
loss: 0.147103  [57600/71095]
loss: 0.037524  [64000/71095]
loss: 0.084734  [70400/71095]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.158996 

Epoch 10
-------------------------------
loss: 0.162636  [    0/71095]
loss: 0.095343  [ 6400/71095]
loss: 0.110698  [12800/71095]
loss: 0.040148  [19200/71095]
loss: 0.086622  [25600/71095]
loss: 1.625785  [32000/71095]
loss: 0.015080  [44800/71429]
loss: 0.138508  [51200/71429]
loss: 0.039446  [57600/71429]
loss: 0.009607  [64000/71429]
loss: 0.011847  [70400/71429]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.108116 

Epoch 43
-------------------------------
loss: 0.078797  [    0/71429]
loss: 0.018091  [ 6400/71429]
loss: 0.029395  [12800/71429]
loss: 0.018620  [19200/71429]
loss: 0.059134  [25600/71429]
loss: 0.010900  [32000/71429]
loss: 0.020471  [38400/71429]
loss: 0.006763  [44800/71429]
loss: 0.055174  [51200/71429]
loss: 0.031207  [57600/71429]
loss: 0.014163  [64000/71429]
loss: 0.023520  [70400/71429]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.101501 

Epoch 44
-------------------------------
loss: 0.068994  [    0/71429]
loss: 0.013181  [ 6400/71429]
loss: 0.070420  [12800/71429]
loss: 0.014208  [19200/71429]
loss: 0.007199  [25600/71429]
loss: 0.027281  [32000/71429]
loss: 0.023261  [38400/71429]
loss: 0.042155  [44800/71429]
loss: 0.060707  [51200/71429]
loss: 0.036780  [57600/71429]
loss: 0.048449  [64000/71429]
loss: 0.017863  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.104266 

Epoch 45
-------------------------------
loss: 0.004594  [    0/71429]
loss: 0.013507  [ 6400/71429]
loss: 0.034475  [12800/71429]
loss: 0.030735  [19200/71429]
loss: 0.041986  [25600/71429]
loss: 0.197147  [32000/71429]
loss: 0.074041  [38400/71429]
loss: 0.086575  [44800/71429]
loss: 0.015166  [51200/71429]
loss: 0.007445  [57600/71429]
loss: 0.009991  [64000/71429]
loss: 0.005371  [70400/71429]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.160299 

Epoch 46
-------------------------------
loss: 0.074743  [    0/71429]
loss: 0.014520  [ 6400/71429]
loss: 0.000935  [12800/71429]
loss: 1.588302  [19200/71429]
loss: 0.113614  [25600/71429]
loss: 0.030028  [32000/71429]
loss: 0.022902  [38400/71429]
loss: 0.014299  [44800/71429]
loss: 0.034173  [51200/71429]
loss: 0.033246  [57600/71429]
loss: 0.081958  [64000/71429]
loss: 0.026666  [70400/71429]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.255919 

Epoch 47
-------------------------------
loss: 0.171868  [    0/71429]
loss: 0.012339  [ 6400/71429]
loss: 0.020660  [12800/71429]
loss: 0.059467  [19200/71429]
loss: 0.008693  [25600/71429]
loss: 0.140114  [32000/71429]
loss: 0.004833  [38400/71429]
loss: 0.001427  [44800/71429]
loss: 0.011501  [51200/71429]
loss: 0.025360  [57600/71429]
loss: 0.019010  [64000/71429]
loss: 0.113865  [70400/71429]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.102600 

Epoch 48
-------------------------------
loss: 0.035916  [    0/71429]
loss: 0.021260  [ 6400/71429]
loss: 0.054383  [12800/71429]
loss: 0.002811  [19200/71429]
loss: 0.042297  [25600/71429]
loss: 0.027439  [32000/71429]
loss: 0.016457  [38400/71429]
loss: 0.026291  [44800/71429]
loss: 0.102395  [51200/71429]
loss: 0.012643  [57600/71429]
loss: 0.021891  [64000/71429]
loss: 1.738529  [70400/71429]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.110442 

Epoch 49
-------------------------------
loss: 0.036573  [    0/71429]
loss: 0.077841  [ 6400/71429]
loss: 0.068472  [12800/71429]
loss: 0.022678  [19200/71429]
loss: 0.042059  [25600/71429]
loss: 0.049560  [32000/71429]
loss: 0.028109  [38400/71429]
loss: 0.026370  [44800/71429]
loss: 0.015995  [51200/71429]
loss: 0.014708  [57600/71429]
loss: 0.242251  [64000/71429]
loss: 0.034383  [70400/71429]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.102181 

Epoch 50
-------------------------------
loss: 0.047487  [    0/71429]
loss: 0.030714  [ 6400/71429]
loss: 0.005602  [12800/71429]
loss: 0.031387  [19200/71429]
loss: 0.146422  [25600/71429]
loss: 0.202440  [32000/71429]
loss: 0.014542  [38400/71429]
loss: 0.011105  [44800/71429]
loss: 0.049743  [51200/71429]
loss: 0.015762  [57600/71429]
loss: 0.006260  [64000/71429]
loss: 0.011076  [70400/71429]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.157706 

Epoch 1
-------------------------------
loss: 0.714538  [    0/70391]
loss: 0.227218  [ 6400/70391]
loss: 0.185290  [12800/70391]
loss: 0.174293  [19200/70391]
loss: 0.137518  [25600/70391]
loss: 0.405491  [32000/70391]
loss: 0.230010  [38400/70391]
loss: 0.205533  [44800/70391]
loss: 0.090647  [51200/70391]
loss: 0.126706  [57600/70391]
loss: 0.132895  [64000/70391]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.190081 

Epoch 2
-------------------------------
loss: 1.742570  [    0/70391]
loss: 0.081516  [ 6400/70391]
loss: 0.093265  [12800/70391]
loss: 0.154009  [19200/70391]
loss: 0.174867  [25600/70391]
loss: 0.123798  [32000/70391]
loss: 0.225222  [38400/70391]
loss: 0.213526  [44800/70391]
loss: 0.158934  [51200/70391]
loss: 0.140386  [57600/70391]
loss: 0.163420  [64000/70391]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.175164 

Epoch 3
-------------------------------
loss: 0.179348  [    0/70391]
loss: 0.174763  [ 6400/70391]
loss: 0.102204  [12800/70391]
loss: 0.145372  [19200/70391]
loss: 0.153995  [25600/70391]
loss: 0.066640  [32000/70391]
loss: 0.037994  [38400/70391]
loss: 0.155835  [44800/70391]
loss: 0.112473  [51200/70391]
loss: 0.130578  [57600/70391]
loss: 0.099871  [64000/70391]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.172114 

Epoch 4
-------------------------------
loss: 0.103022  [    0/70391]
loss: 0.157566  [ 6400/70391]
loss: 0.169521  [12800/70391]
loss: 0.116498  [19200/70391]
loss: 0.105970  [25600/70391]
loss: 0.111207  [32000/70391]
loss: 0.077556  [38400/70391]
loss: 0.091950  [44800/70391]
loss: 0.094339  [51200/70391]
loss: 0.096063  [57600/70391]
loss: 0.077370  [64000/70391]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.166425 

Epoch 5
-------------------------------
loss: 0.097992  [    0/70391]
loss: 0.172694  [ 6400/70391]
loss: 0.108815  [12800/70391]
loss: 0.033952  [19200/70391]
loss: 0.028566  [25600/70391]
loss: 0.147405  [32000/70391]
loss: 0.141772  [38400/70391]
loss: 0.087574  [44800/70391]
loss: 0.314410  [51200/70391]
loss: 0.109173  [57600/70391]
loss: 0.073987  [64000/70391]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.163180 

Epoch 6
-------------------------------
loss: 0.109078  [    0/70391]
loss: 0.144730  [ 6400/70391]
loss: 0.056621  [12800/70391]
loss: 0.111696  [19200/70391]
loss: 0.122686  [25600/70391]
loss: 0.106255  [32000/70391]
loss: 0.095002  [38400/70391]
loss: 0.188449  [44800/70391]
loss: 0.119979  [51200/70391]
loss: 0.043929  [57600/70391]
loss: 0.192892  [64000/70391]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.158638 

Epoch 7
-------------------------------
loss: 0.063355  [    0/70391]
loss: 0.101807  [ 6400/70391]
loss: 0.046735  [12800/70391]
loss: 0.128161  [19200/70391]
loss: 0.077500  [25600/70391]
loss: 0.065630  [32000/70391]
loss: 0.105714  [38400/70391]
loss: 0.111699  [44800/70391]
loss: 0.030608  [51200/70391]
loss: 0.065199  [57600/70391]
loss: 0.150061  [64000/70391]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.160080 

Epoch 8
-------------------------------
loss: 0.141862  [    0/70391]
loss: 0.144589  [ 6400/70391]
loss: 0.101502  [12800/70391]
loss: 0.059860  [19200/70391]
loss: 0.074382  [25600/70391]
loss: 0.067594  [32000/70391]
loss: 0.048059  [38400/70391]
loss: 0.122177  [44800/70391]
loss: 0.123597  [51200/70391]
loss: 0.128407  [57600/70391]
loss: 0.117036  [64000/70391]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.159960 

Epoch 9
-------------------------------
loss: 0.138764  [    0/70391]
loss: 0.228036  [ 6400/70391]
loss: 0.152636  [12800/70391]
loss: 0.146376  [19200/70391]
loss: 0.232474  [25600/70391]
loss: 0.096345  [32000/70391]
loss: 0.072011  [38400/70391]
loss: 0.191223  [44800/70391]
loss: 0.139225  [51200/70391]
loss: 0.153237  [57600/70391]
loss: 0.125518  [64000/70391]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.152511 

Epoch 10
-------------------------------
loss: 0.136745  [    0/70391]
loss: 0.054965  [ 6400/70391]
loss: 0.094756  [12800/70391]
loss: 0.077304  [19200/70391]
loss: 0.107778  [25600/70391]
loss: 0.081526  [32000/70391]
loss: 0.206267  [38400/70391]
loss: 0.101319  [44800/70391]
loss: 0.166962  [51200/70391]
loss: 0.121773  [57600/70391]
loss: 0.098351  [64000/70391]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.157766 

Epoch 11
-------------------------------
loss: 0.021804  [    0/70391]
loss: 0.360183  [ 6400/70391]
loss: 0.040398  [12800/70391]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.137112 

Epoch 36
-------------------------------
loss: 0.055910  [    0/70495]
loss: 0.057800  [ 6400/70495]
loss: 0.064950  [12800/70495]
loss: 0.060261  [19200/70495]
loss: 0.102256  [25600/70495]
loss: 0.061857  [32000/70495]
loss: 0.054919  [38400/70495]
loss: 0.083740  [44800/70495]
loss: 0.132124  [51200/70495]
loss: 0.099466  [57600/70495]
loss: 0.052540  [64000/70495]
loss: 0.185080  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.134694 

Epoch 37
-------------------------------
loss: 0.072945  [    0/70495]
loss: 0.170236  [ 6400/70495]
loss: 0.116537  [12800/70495]
loss: 0.102496  [19200/70495]
loss: 0.100100  [25600/70495]
loss: 0.076859  [32000/70495]
loss: 0.111342  [38400/70495]
loss: 0.054080  [44800/70495]
loss: 0.038783  [51200/70495]
loss: 0.067057  [57600/70495]
loss: 0.289444  [64000/70495]
loss: 0.027721  [70400/70495]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.143438 

Epoch 38
-------------------------------
loss: 0.050373  [    0/70495]
loss: 0.032093  [ 6400/70495]
loss: 0.121128  [12800/70495]
loss: 0.044286  [19200/70495]
loss: 0.103799  [25600/70495]
loss: 0.069249  [32000/70495]
loss: 0.117816  [38400/70495]
loss: 0.028173  [44800/70495]
loss: 0.055851  [51200/70495]
loss: 0.174098  [57600/70495]
loss: 0.068227  [64000/70495]
loss: 0.236166  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.136369 

Epoch 39
-------------------------------
loss: 0.116969  [    0/70495]
loss: 0.075397  [ 6400/70495]
loss: 0.138114  [12800/70495]
loss: 0.070511  [19200/70495]
loss: 0.141388  [25600/70495]
loss: 0.121847  [32000/70495]
loss: 0.049358  [38400/70495]
loss: 0.132756  [44800/70495]
loss: 0.079363  [51200/70495]
loss: 0.098782  [57600/70495]
loss: 0.074091  [64000/70495]
loss: 0.055609  [70400/70495]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.146139 

Epoch 40
-------------------------------
loss: 0.114991  [    0/70495]
loss: 0.056165  [ 6400/70495]
loss: 0.097064  [12800/70495]
loss: 0.051526  [19200/70495]
loss: 0.102381  [25600/70495]
loss: 0.108423  [32000/70495]
loss: 0.039749  [38400/70495]
loss: 0.078845  [44800/70495]
loss: 0.079154  [51200/70495]
loss: 0.049774  [57600/70495]
loss: 0.198252  [64000/70495]
loss: 0.055663  [70400/70495]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.143671 

Epoch 41
-------------------------------
loss: 0.111127  [    0/70495]
loss: 0.068342  [ 6400/70495]
loss: 0.186585  [12800/70495]
loss: 0.114654  [19200/70495]
loss: 0.039511  [25600/70495]
loss: 0.105771  [32000/70495]
loss: 0.143467  [38400/70495]
loss: 0.079542  [44800/70495]
loss: 0.080888  [51200/70495]
loss: 0.093784  [57600/70495]
loss: 0.073203  [64000/70495]
loss: 0.029304  [70400/70495]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.142781 

Epoch 42
-------------------------------
loss: 0.027559  [    0/70495]
loss: 0.071820  [ 6400/70495]
loss: 0.157725  [12800/70495]
loss: 0.061374  [19200/70495]
loss: 0.060208  [25600/70495]
loss: 0.043057  [32000/70495]
loss: 0.063956  [38400/70495]
loss: 0.142801  [44800/70495]
loss: 0.080883  [51200/70495]
loss: 0.156182  [57600/70495]
loss: 0.141121  [64000/70495]
loss: 0.073566  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.136346 

Epoch 43
-------------------------------
loss: 0.069176  [    0/70495]
loss: 0.123864  [ 6400/70495]
loss: 0.147875  [12800/70495]
loss: 0.063380  [19200/70495]
loss: 0.197282  [25600/70495]
loss: 0.089837  [32000/70495]
loss: 0.101757  [38400/70495]
loss: 0.159098  [44800/70495]
loss: 0.099292  [51200/70495]
loss: 0.067162  [57600/70495]
loss: 0.117920  [64000/70495]
loss: 0.047319  [70400/70495]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.145571 

Epoch 44
-------------------------------
loss: 0.057296  [    0/70495]
loss: 0.069618  [ 6400/70495]
loss: 0.126611  [12800/70495]
loss: 0.089009  [19200/70495]
loss: 0.037539  [25600/70495]
loss: 0.069127  [32000/70495]
loss: 0.145217  [38400/70495]
loss: 0.150104  [44800/70495]
loss: 0.082633  [51200/70495]
loss: 0.124984  [57600/70495]
loss: 0.078432  [64000/70495]
loss: 0.034441  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.137806 

Epoch 45
-------------------------------
loss: 0.158801  [    0/70495]
loss: 0.067915  [ 6400/70495]
loss: 0.098319  [12800/70495]
loss: 0.061554  [19200/70495]
loss: 0.173590  [25600/70495]
loss: 0.073424  [32000/70495]
loss: 0.178607  [38400/70495]
loss: 0.046777  [44800/70495]
loss: 0.073275  [51200/70495]
loss: 0.151650  [57600/70495]
loss: 0.027346  [64000/70495]
loss: 0.052364  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.135864 

Epoch 46
-------------------------------
loss: 0.125514  [    0/70495]
loss: 0.074602  [ 6400/70495]
loss: 0.028013  [12800/70495]
loss: 0.077162  [19200/70495]
loss: 0.015488  [25600/70495]
loss: 0.045497  [32000/70495]
loss: 0.076911  [38400/70495]
loss: 0.031625  [44800/70495]
loss: 0.051051  [51200/70495]
loss: 0.174498  [57600/70495]
loss: 0.052991  [64000/70495]
loss: 0.059246  [70400/70495]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.136147 

Epoch 47
-------------------------------
loss: 0.026060  [    0/70495]
loss: 0.096209  [ 6400/70495]
loss: 0.066483  [12800/70495]
loss: 0.038084  [19200/70495]
loss: 0.091892  [25600/70495]
loss: 0.064469  [32000/70495]
loss: 0.097687  [38400/70495]
loss: 0.129854  [44800/70495]
loss: 0.225585  [51200/70495]
loss: 0.074226  [57600/70495]
loss: 0.108322  [64000/70495]
loss: 0.121552  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.141682 

Epoch 48
-------------------------------
loss: 0.046149  [    0/70495]
loss: 0.074142  [ 6400/70495]
loss: 0.071926  [12800/70495]
loss: 0.024485  [19200/70495]
loss: 0.029836  [25600/70495]
loss: 0.131810  [32000/70495]
loss: 0.098248  [38400/70495]
loss: 0.101733  [44800/70495]
loss: 0.050779  [51200/70495]
loss: 0.054827  [57600/70495]
loss: 0.048985  [64000/70495]
loss: 0.035282  [70400/70495]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.135587 

Epoch 49
-------------------------------
loss: 0.074574  [    0/70495]
loss: 0.191826  [ 6400/70495]
loss: 0.167155  [12800/70495]
loss: 0.047320  [19200/70495]
loss: 0.084961  [25600/70495]
loss: 0.027257  [32000/70495]
loss: 0.087211  [38400/70495]
loss: 0.099640  [44800/70495]
loss: 0.124764  [51200/70495]
loss: 0.073622  [57600/70495]
loss: 0.086396  [64000/70495]
loss: 0.070365  [70400/70495]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.140386 

Epoch 50
-------------------------------
loss: 0.025056  [    0/70495]
loss: 0.044947  [ 6400/70495]
loss: 0.041829  [12800/70495]
loss: 0.157748  [19200/70495]
loss: 0.098931  [25600/70495]
loss: 0.078308  [32000/70495]
loss: 0.107450  [38400/70495]
loss: 0.078864  [44800/70495]
loss: 0.011177  [51200/70495]
loss: 0.069914  [57600/70495]
loss: 0.128215  [64000/70495]
loss: 0.052931  [70400/70495]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.150349 

Epoch 1
-------------------------------
loss: 0.746397  [    0/70549]
loss: 0.270284  [ 6400/70549]
loss: 1.775323  [12800/70549]
loss: 0.276092  [19200/70549]
loss: 0.550256  [25600/70549]
loss: 0.300826  [32000/70549]
loss: 0.217233  [38400/70549]
loss: 0.156216  [44800/70549]
loss: 0.293653  [51200/70549]
loss: 0.207224  [57600/70549]
loss: 0.247931  [64000/70549]
loss: 0.250015  [70400/70549]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.196897 

Epoch 2
-------------------------------
loss: 0.100428  [    0/70549]
loss: 0.112048  [ 6400/70549]
loss: 0.166569  [12800/70549]
loss: 0.103998  [19200/70549]
loss: 0.059490  [25600/70549]
loss: 0.200367  [32000/70549]
loss: 0.133708  [38400/70549]
loss: 0.168639  [44800/70549]
loss: 0.170601  [51200/70549]
loss: 0.103885  [57600/70549]
loss: 0.236020  [64000/70549]
loss: 0.128853  [70400/70549]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.181035 

Epoch 3
-------------------------------
loss: 0.183880  [    0/70549]
loss: 0.127488  [ 6400/70549]
loss: 0.144860  [12800/70549]
loss: 0.129331  [19200/70549]
loss: 0.300536  [25600/70549]
loss: 0.216963  [32000/70549]
loss: 0.077045  [38400/70549]
loss: 0.068168  [44800/70549]
loss: 0.152634  [51200/70549]
loss: 0.166849  [57600/70549]
loss: 0.199988  [64000/70549]
loss: 0.118533  [70400/70549]
loss: 0.186847  [12800/70414]
loss: 0.093857  [19200/70414]
loss: 0.108662  [25600/70414]
loss: 0.085218  [32000/70414]
loss: 0.135234  [38400/70414]
loss: 0.169950  [44800/70414]
loss: 0.085852  [51200/70414]
loss: 0.751988  [57600/70414]
loss: 0.150744  [64000/70414]
loss: 0.473668  [15400/70414]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.169810 

Epoch 40
-------------------------------
loss: 0.132917  [    0/70414]
loss: 0.191570  [ 6400/70414]
loss: 0.091041  [12800/70414]
loss: 0.054028  [19200/70414]
loss: 0.117716  [25600/70414]
loss: 0.037578  [32000/70414]
loss: 0.198396  [38400/70414]
loss: 0.186111  [44800/70414]
loss: 0.093120  [51200/70414]
loss: 0.091521  [57600/70414]
loss: 0.274196  [64000/70414]
loss: 0.170059  [15400/70414]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.156463 

Epoch 41
-------------------------------
loss: 0.170586  [    0/70414]
loss: 0.155423  [ 6400/70414]
loss: 0.149870  [12800/70414]
loss: 0.094837  [19200/70414]
loss: 0.225614  [25600/70414]
loss: 0.333446  [32000/70414]
loss: 0.217569  [38400/70414]
loss: 0.047032  [44800/70414]
loss: 0.130148  [51200/70414]
loss: 0.121952  [57600/70414]
loss: 0.109960  [64000/70414]
loss: 0.018625  [15400/70414]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.144807 

Epoch 42
-------------------------------
loss: 0.087817  [    0/70414]
loss: 0.075330  [ 6400/70414]
loss: 0.235908  [12800/70414]
loss: 0.144944  [19200/70414]
loss: 0.189543  [25600/70414]
loss: 0.172418  [32000/70414]
loss: 0.106587  [38400/70414]
loss: 0.053760  [44800/70414]
loss: 0.135860  [51200/70414]
loss: 0.109890  [57600/70414]
loss: 0.196969  [64000/70414]
loss: 0.065530  [15400/70414]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.140110 

Epoch 43
-------------------------------
loss: 0.107283  [    0/70414]
loss: 0.032889  [ 6400/70414]
loss: 0.131174  [12800/70414]
loss: 0.039124  [19200/70414]
loss: 0.145277  [25600/70414]
loss: 0.262620  [32000/70414]
loss: 0.104279  [38400/70414]
loss: 0.150330  [44800/70414]
loss: 0.061878  [51200/70414]
loss: 0.055524  [57600/70414]
loss: 0.060047  [64000/70414]
loss: 0.069797  [15400/70414]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.172068 

Epoch 44
-------------------------------
loss: 0.086804  [    0/70414]
loss: 0.146925  [ 6400/70414]
loss: 0.149486  [12800/70414]
loss: 0.372527  [19200/70414]
loss: 0.053699  [25600/70414]
loss: 0.135693  [32000/70414]
loss: 0.140370  [38400/70414]
loss: 0.058332  [44800/70414]
loss: 0.168089  [51200/70414]
loss: 0.111511  [57600/70414]
loss: 0.078549  [64000/70414]
loss: 0.091617  [15400/70414]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.147495 

Epoch 45
-------------------------------
loss: 0.076208  [    0/70414]
loss: 0.131984  [ 6400/70414]
loss: 0.097193  [12800/70414]
loss: 0.058353  [19200/70414]
loss: 0.478118  [25600/70414]
loss: 0.254196  [32000/70414]
loss: 0.059825  [38400/70414]
loss: 0.118579  [44800/70414]
loss: 0.161666  [51200/70414]
loss: 0.130781  [57600/70414]
loss: 0.177114  [64000/70414]
loss: 0.039717  [15400/70414]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.170371 

Epoch 46
-------------------------------
loss: 0.039251  [    0/70414]
loss: 0.134188  [ 6400/70414]
loss: 0.234802  [12800/70414]
loss: 0.211321  [19200/70414]
loss: 0.122635  [25600/70414]
loss: 0.195080  [32000/70414]
loss: 0.141714  [38400/70414]
loss: 0.102131  [44800/70414]
loss: 0.135480  [51200/70414]
loss: 0.076255  [57600/70414]
loss: 0.139547  [64000/70414]
loss: 0.188187  [15400/70414]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150142 

Epoch 47
-------------------------------
loss: 0.150057  [    0/70414]
loss: 0.054373  [ 6400/70414]
loss: 0.126511  [12800/70414]
loss: 0.155580  [19200/70414]
loss: 0.063283  [25600/70414]
loss: 0.218208  [32000/70414]
loss: 0.040264  [38400/70414]
loss: 0.130769  [44800/70414]
loss: 0.065818  [51200/70414]
loss: 0.088438  [57600/70414]
loss: 0.080667  [64000/70414]
loss: 0.048385  [15400/70414]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.147139 

Epoch 48
-------------------------------
loss: 0.070872  [    0/70414]
loss: 0.163699  [ 6400/70414]
loss: 0.073188  [12800/70414]
loss: 0.163527  [19200/70414]
loss: 0.089849  [25600/70414]
loss: 0.043674  [32000/70414]
loss: 0.110367  [38400/70414]
loss: 0.256083  [44800/70414]
loss: 0.246601  [51200/70414]
loss: 0.102229  [57600/70414]
loss: 0.197702  [64000/70414]
loss: 0.259911  [15400/70414]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.154885 

Epoch 49
-------------------------------
loss: 0.073010  [    0/70414]
loss: 0.152939  [ 6400/70414]
loss: 0.344312  [12800/70414]
loss: 0.129597  [19200/70414]
loss: 0.262025  [25600/70414]
loss: 0.155719  [32000/70414]
loss: 0.078396  [38400/70414]
loss: 0.186553  [44800/70414]
loss: 0.225226  [51200/70414]
loss: 0.160341  [57600/70414]
loss: 0.101794  [64000/70414]
loss: 0.018255  [15400/70414]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.145256 

Epoch 50
-------------------------------
loss: 0.122858  [    0/70414]
loss: 0.213768  [ 6400/70414]
loss: 0.077397  [12800/70414]
loss: 0.076101  [19200/70414]
loss: 0.121837  [25600/70414]
loss: 0.294000  [32000/70414]
loss: 0.076181  [38400/70414]
loss: 0.094207  [44800/70414]
loss: 0.068287  [51200/70414]
loss: 0.153093  [57600/70414]
loss: 0.110649  [64000/70414]
loss: 0.269307  [15400/70414]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.162623 

Epoch 1
-------------------------------
loss: 0.792851  [    0/69530]
loss: 0.452867  [ 6400/69530]
loss: 0.345699  [12800/69530]
loss: 0.260040  [19200/69530]
loss: 0.186879  [25600/69530]
loss: 0.140763  [32000/69530]
loss: 0.286347  [38400/69530]
loss: 0.279791  [44800/69530]
loss: 0.277309  [51200/69530]
loss: 0.211829  [57600/69530]
loss: 0.330428  [64000/69530]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.220592 

Epoch 2
-------------------------------
loss: 0.257850  [    0/69530]
loss: 0.158145  [ 6400/69530]
loss: 0.239510  [12800/69530]
loss: 0.252304  [19200/69530]
loss: 0.128610  [25600/69530]
loss: 0.176092  [32000/69530]
loss: 0.146962  [38400/69530]
loss: 0.246592  [44800/69530]
loss: 0.123223  [51200/69530]
loss: 0.194809  [57600/69530]
loss: 0.193977  [64000/69530]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.195970 

Epoch 3
-------------------------------
loss: 0.159483  [    0/69530]
loss: 0.239754  [ 6400/69530]
loss: 0.129968  [12800/69530]
loss: 0.169904  [19200/69530]
loss: 0.163420  [25600/69530]
loss: 0.171239  [32000/69530]
loss: 0.242891  [38400/69530]
loss: 0.184183  [44800/69530]
loss: 0.201117  [51200/69530]
loss: 0.158570  [57600/69530]
loss: 0.095852  [64000/69530]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.217155 

Epoch 4
-------------------------------
loss: 0.102466  [    0/69530]
loss: 0.112125  [ 6400/69530]
loss: 0.169935  [12800/69530]
loss: 0.133980  [19200/69530]
loss: 0.181995  [25600/69530]
loss: 0.224535  [32000/69530]
loss: 0.160760  [38400/69530]
loss: 0.215504  [44800/69530]
loss: 0.218914  [51200/69530]
loss: 0.205882  [57600/69530]
loss: 0.138707  [64000/69530]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.182199 

Epoch 5
-------------------------------
loss: 0.165372  [    0/69530]
loss: 0.176412  [ 6400/69530]
loss: 0.198268  [12800/69530]
loss: 0.249849  [19200/69530]
loss: 0.296727  [25600/69530]
loss: 0.259606  [32000/69530]
loss: 0.309865  [38400/69530]
loss: 0.246899  [44800/69530]
loss: 0.106221  [51200/69530]
loss: 0.200918  [57600/69530]
loss: 0.107357  [64000/69530]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.197673 

Epoch 6
-------------------------------
loss: 0.154865  [    0/69530]
loss: 0.086521  [ 6400/69530]
loss: 0.137879  [12800/69530]
loss: 0.144746  [19200/69530]
loss: 0.210479  [25600/69530]
loss: 0.119693  [32000/69530]
loss: 0.284406  [38400/69530]
loss: 0.074701  [44800/69530]
loss: 0.112722  [51200/69530]
loss: 0.218767  [57600/69530]
loss: 0.172872  [64000/69530]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.186790 

Epoch 7
-------------------------------
loss: 0.151361  [    0/69530]
loss: 0.278715  [ 6400/69530]
loss: 0.261159  [12800/69530]
loss: 0.255288  [19200/69530]
loss: 0.289998  [25600/69530]
loss: 0.137855  [32000/69530]
loss: 0.228223  [38400/69530]
loss: 0.122517  [44800/69530]
loss: 0.265187  [51200/69530]
2022/09/20 17:34:16 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 17:34:41 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.294968  [64000/69810]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.136092 

Epoch 42
-------------------------------
loss: 0.151249  [    0/69810]
loss: 0.074529  [ 6400/69810]
loss: 0.108188  [12800/69810]
loss: 0.061783  [19200/69810]
loss: 0.104553  [25600/69810]
loss: 0.092798  [32000/69810]
loss: 0.181651  [38400/69810]
loss: 0.102151  [44800/69810]
loss: 0.023490  [51200/69810]
loss: 0.136670  [57600/69810]
loss: 0.223260  [64000/69810]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.132809 

Epoch 43
-------------------------------
loss: 0.083476  [    0/69810]
loss: 0.042552  [ 6400/69810]
loss: 0.181773  [12800/69810]
loss: 0.055405  [19200/69810]
loss: 0.037119  [25600/69810]
loss: 0.109532  [32000/69810]
loss: 0.065440  [38400/69810]
loss: 0.044899  [44800/69810]
loss: 0.142886  [51200/69810]
loss: 0.091063  [57600/69810]
loss: 0.040711  [64000/69810]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.128982 

Epoch 44
-------------------------------
loss: 0.097330  [    0/69810]
loss: 0.114783  [ 6400/69810]
loss: 0.039495  [12800/69810]
loss: 0.027418  [19200/69810]
loss: 0.150588  [25600/69810]
loss: 0.120695  [32000/69810]
loss: 0.075908  [38400/69810]
loss: 0.170555  [44800/69810]
loss: 0.145792  [51200/69810]
loss: 0.070981  [57600/69810]
loss: 0.082776  [64000/69810]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.127159 

Epoch 45
-------------------------------
loss: 0.168364  [    0/69810]
loss: 0.122137  [ 6400/69810]
loss: 0.049321  [12800/69810]
loss: 0.079162  [19200/69810]
loss: 0.074345  [25600/69810]
loss: 0.058843  [32000/69810]
loss: 0.103402  [38400/69810]
loss: 0.088149  [44800/69810]
loss: 0.117063  [51200/69810]
loss: 0.044964  [57600/69810]
loss: 0.029742  [64000/69810]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.140048 

Epoch 46
-------------------------------
loss: 0.107166  [    0/69810]
loss: 0.041632  [ 6400/69810]
loss: 0.097839  [12800/69810]
loss: 0.080579  [19200/69810]
loss: 0.161321  [25600/69810]
loss: 0.058987  [32000/69810]
loss: 0.201918  [38400/69810]
loss: 0.087389  [44800/69810]
loss: 0.135581  [51200/69810]
loss: 0.095654  [57600/69810]
loss: 0.131143  [64000/69810]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.141463 

Epoch 47
-------------------------------
loss: 0.125954  [    0/69810]
loss: 0.046381  [ 6400/69810]
loss: 0.061444  [12800/69810]
loss: 0.122905  [19200/69810]
loss: 0.033535  [25600/69810]
loss: 0.104193  [32000/69810]
loss: 0.172025  [38400/69810]
loss: 0.183348  [44800/69810]
loss: 0.082790  [51200/69810]
loss: 0.065600  [57600/69810]
loss: 0.058005  [64000/69810]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.131343 

Epoch 48
-------------------------------
loss: 0.053996  [    0/69810]
loss: 0.097467  [ 6400/69810]
loss: 0.067736  [12800/69810]
loss: 0.111992  [19200/69810]
loss: 0.212706  [25600/69810]
loss: 0.088727  [32000/69810]
loss: 0.141452  [38400/69810]
loss: 0.193632  [44800/69810]
loss: 0.058315  [51200/69810]
loss: 0.113253  [57600/69810]
loss: 0.083674  [64000/69810]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.133727 

Epoch 49
-------------------------------
loss: 0.060050  [    0/69810]
loss: 0.082813  [ 6400/69810]
loss: 0.098350  [12800/69810]
loss: 0.246413  [19200/69810]
loss: 0.081207  [25600/69810]
loss: 0.079602  [32000/69810]
loss: 0.124519  [38400/69810]
loss: 0.103553  [44800/69810]
loss: 0.041833  [51200/69810]
loss: 0.088960  [57600/69810]
loss: 0.083105  [64000/69810]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.134050 

Epoch 50
-------------------------------
loss: 0.033946  [    0/69810]
loss: 0.071563  [ 6400/69810]
loss: 0.078485  [12800/69810]
loss: 0.093807  [19200/69810]
loss: 0.026388  [25600/69810]
loss: 0.143303  [32000/69810]
loss: 0.069079  [38400/69810]
loss: 0.032321  [44800/69810]
loss: 0.101136  [51200/69810]
loss: 0.077579  [57600/69810]
loss: 0.164826  [64000/69810]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.129845 

Epoch 1
-------------------------------
loss: 0.751234  [    0/71653]
loss: 0.211270  [ 6400/71653]
loss: 0.211835  [12800/71653]
loss: 0.151743  [19200/71653]
loss: 0.098241  [25600/71653]
loss: 0.104897  [32000/71653]
loss: 0.112658  [38400/71653]
loss: 0.302954  [44800/71653]
loss: 0.120833  [51200/71653]
loss: 0.167666  [57600/71653]
loss: 0.184597  [64000/71653]
loss: 0.169604  [70400/71653]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.169453 

Epoch 2
-------------------------------
loss: 1.729117  [    0/71653]
loss: 0.095610  [ 6400/71653]
loss: 0.226056  [12800/71653]
loss: 0.120604  [19200/71653]
loss: 0.253724  [25600/71653]
loss: 0.106943  [32000/71653]
loss: 0.207278  [38400/71653]
loss: 0.063294  [44800/71653]
loss: 0.061575  [51200/71653]
loss: 0.236185  [57600/71653]
loss: 0.145726  [64000/71653]
loss: 0.100741  [70400/71653]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.145334 

Epoch 3
-------------------------------
loss: 0.179170  [    0/71653]
loss: 0.109825  [ 6400/71653]
loss: 0.173757  [12800/71653]
loss: 0.085164  [19200/71653]
loss: 0.136215  [25600/71653]
loss: 0.156864  [32000/71653]
loss: 0.076922  [38400/71653]
loss: 0.141765  [44800/71653]
loss: 0.129924  [51200/71653]
loss: 0.126822  [57600/71653]
loss: 0.195773  [64000/71653]
loss: 0.028607  [70400/71653]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.138533 

Epoch 4
-------------------------------
loss: 0.132151  [    0/71653]
loss: 0.089746  [ 6400/71653]
loss: 0.082821  [12800/71653]
loss: 0.094932  [19200/71653]
loss: 0.117141  [25600/71653]
loss: 0.142255  [32000/71653]
loss: 0.115949  [38400/71653]
loss: 0.037189  [44800/71653]
loss: 0.097170  [51200/71653]
loss: 0.125216  [57600/71653]
loss: 0.088145  [64000/71653]
loss: 0.181950  [70400/71653]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.125965 

Epoch 5
-------------------------------
loss: 0.084732  [    0/71653]
loss: 0.105220  [ 6400/71653]
loss: 0.040581  [12800/71653]
loss: 0.146591  [19200/71653]
loss: 0.121468  [25600/71653]
loss: 0.070442  [32000/71653]
loss: 0.077736  [38400/71653]
loss: 0.089350  [44800/71653]
loss: 0.166991  [51200/71653]
loss: 0.156808  [57600/71653]
loss: 0.081843  [64000/71653]
loss: 0.163300  [70400/71653]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.127320 

Epoch 6
-------------------------------
loss: 0.083599  [    0/71653]
loss: 0.105720  [ 6400/71653]
loss: 0.213054  [12800/71653]
loss: 0.175173  [19200/71653]
loss: 0.065720  [25600/71653]
loss: 0.109649  [32000/71653]
loss: 0.128134  [38400/71653]
loss: 0.134665  [44800/71653]
loss: 0.122656  [51200/71653]
loss: 0.287182  [57600/71653]
loss: 0.027749  [64000/71653]
loss: 0.063417  [70400/71653]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.123547 

Epoch 7
-------------------------------
loss: 0.074810  [    0/71653]
loss: 0.188692  [ 6400/71653]
loss: 0.126111  [12800/71653]
loss: 0.066579  [19200/71653]
loss: 0.260397  [25600/71653]
loss: 0.023194  [32000/71653]
loss: 0.047764  [38400/71653]
loss: 0.061883  [44800/71653]
loss: 0.049792  [51200/71653]
loss: 0.145615  [57600/71653]
loss: 0.076357  [64000/71653]
loss: 0.107130  [70400/71653]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.125395 

Epoch 8
-------------------------------
loss: 0.098331  [    0/71653]
loss: 0.049361  [ 6400/71653]
loss: 0.104432  [12800/71653]
loss: 0.090346  [19200/71653]
loss: 0.091411  [25600/71653]
loss: 0.077710  [32000/71653]
loss: 0.149632  [38400/71653]
loss: 0.069369  [44800/71653]
loss: 0.089938  [51200/71653]
loss: 0.044315  [57600/71653]
loss: 0.183519  [64000/71653]
loss: 0.136089  [70400/71653]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.126089 

Epoch 9
-------------------------------
loss: 0.053715  [    0/71653]
loss: 0.080695  [ 6400/71653]
loss: 0.094721  [12800/71653]
loss: 0.099811  [19200/71653]
loss: 0.104697  [25600/71653]
loss: 0.086868  [32000/71653]
loss: 0.173389  [38400/71653]
loss: 0.109834  [44800/71653]
loss: 0.102418  [51200/71653]
loss: 0.115416  [57600/71653]
loss: 0.199280  [64000/71653]
loss: 0.183228  [70400/71653]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.120410 

Epoch 10
-------------------------------
loss: 0.027981  [    0/71653]
loss: 0.093953  [ 6400/71653]
loss: 0.055815  [12800/71653]
loss: 0.035003  [19200/71653]
loss: 0.142832  [25600/71653]
loss: 0.043223  [32000/71653]
2022/09/20 17:35:12 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.126501  [19200/69728]
loss: 0.094582  [25600/69728]
loss: 0.284492  [32000/69728]
loss: 0.195213  [38400/69728]
loss: 0.126845  [44800/69728]
loss: 0.180636  [51200/69728]
loss: 0.141627  [57600/69728]
loss: 0.277489  [64000/69728]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.198858 

Epoch 39
-------------------------------
loss: 0.193886  [    0/69728]
loss: 0.171750  [ 6400/69728]
loss: 0.088835  [12800/69728]
loss: 0.293503  [19200/69728]
loss: 0.186828  [25600/69728]
loss: 0.181366  [32000/69728]
loss: 0.196278  [38400/69728]
loss: 0.082719  [44800/69728]
loss: 0.218767  [51200/69728]
loss: 0.090403  [57600/69728]
loss: 0.163748  [64000/69728]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.211876 

Epoch 40
-------------------------------
loss: 0.157902  [    0/69728]
loss: 0.159184  [ 6400/69728]
loss: 0.166845  [12800/69728]
loss: 0.178372  [19200/69728]
loss: 0.137884  [25600/69728]
loss: 0.279974  [32000/69728]
loss: 0.214113  [38400/69728]
loss: 0.091299  [44800/69728]
loss: 0.162668  [51200/69728]
loss: 0.259399  [57600/69728]
loss: 0.170500  [64000/69728]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.203079 

Epoch 41
-------------------------------
loss: 0.132462  [    0/69728]
loss: 0.065498  [ 6400/69728]
loss: 0.321664  [12800/69728]
loss: 0.259916  [19200/69728]
loss: 0.121884  [25600/69728]
loss: 0.309865  [32000/69728]
loss: 0.163758  [38400/69728]
loss: 1.706393  [44800/69728]
loss: 0.209210  [51200/69728]
loss: 0.187213  [57600/69728]
loss: 0.140543  [64000/69728]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.198533 

Epoch 42
-------------------------------
loss: 0.116461  [    0/69728]
loss: 0.145811  [ 6400/69728]
loss: 0.193400  [12800/69728]
loss: 0.172216  [19200/69728]
loss: 0.183275  [25600/69728]
loss: 0.078001  [32000/69728]
loss: 0.110969  [38400/69728]
loss: 0.105582  [44800/69728]
loss: 0.240723  [51200/69728]
loss: 0.242086  [57600/69728]
loss: 0.142333  [64000/69728]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.202759 

Epoch 43
-------------------------------
loss: 0.195672  [    0/69728]
loss: 0.096696  [ 6400/69728]
loss: 0.151094  [12800/69728]
loss: 0.138765  [19200/69728]
loss: 0.178857  [25600/69728]
loss: 0.124817  [32000/69728]
loss: 0.118869  [38400/69728]
loss: 0.094381  [44800/69728]
loss: 0.141145  [51200/69728]
loss: 0.103481  [57600/69728]
loss: 0.122014  [64000/69728]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.198230 

Epoch 44
-------------------------------
loss: 0.083012  [    0/69728]
loss: 0.165386  [ 6400/69728]
loss: 0.219305  [12800/69728]
loss: 0.107281  [19200/69728]
loss: 0.101262  [25600/69728]
loss: 0.054919  [32000/69728]
loss: 0.130699  [38400/69728]
loss: 0.100442  [44800/69728]
loss: 0.192975  [51200/69728]
loss: 0.133510  [57600/69728]
loss: 0.140869  [64000/69728]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.200861 

Epoch 45
-------------------------------
loss: 0.182332  [    0/69728]
loss: 0.163159  [ 6400/69728]
loss: 0.138943  [12800/69728]
loss: 0.062187  [19200/69728]
loss: 0.114700  [25600/69728]
loss: 0.128685  [32000/69728]
loss: 0.216015  [38400/69728]
loss: 0.252823  [44800/69728]
loss: 0.164223  [51200/69728]
loss: 0.191395  [57600/69728]
loss: 0.234874  [64000/69728]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.211092 

Epoch 46
-------------------------------
loss: 0.090918  [    0/69728]
loss: 0.203567  [ 6400/69728]
loss: 0.166304  [12800/69728]
loss: 0.119396  [19200/69728]
loss: 0.183997  [25600/69728]
loss: 0.090957  [32000/69728]
loss: 0.245938  [38400/69728]
loss: 0.126749  [44800/69728]
loss: 1.672526  [51200/69728]
loss: 0.139684  [57600/69728]
loss: 0.120498  [64000/69728]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.193236 

Epoch 47
-------------------------------
loss: 0.127756  [    0/69728]
loss: 0.133119  [ 6400/69728]
loss: 0.073952  [12800/69728]
loss: 0.060039  [19200/69728]
loss: 0.277608  [25600/69728]
loss: 0.056045  [32000/69728]
loss: 0.169871  [38400/69728]
loss: 0.186611  [44800/69728]
loss: 0.131010  [51200/69728]
loss: 0.080749  [57600/69728]
loss: 0.148825  [64000/69728]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.195234 

Epoch 48
-------------------------------
loss: 0.097434  [    0/69728]
loss: 1.661145  [ 6400/69728]
loss: 0.203365  [12800/69728]
loss: 0.119388  [19200/69728]
loss: 0.115307  [25600/69728]
loss: 0.127072  [32000/69728]
loss: 0.126395  [38400/69728]
loss: 0.146813  [44800/69728]
loss: 0.095606  [51200/69728]
loss: 0.102308  [57600/69728]
loss: 0.151550  [64000/69728]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.202573 

Epoch 49
-------------------------------
loss: 0.141351  [    0/69728]
loss: 0.164899  [ 6400/69728]
loss: 0.199744  [12800/69728]
loss: 0.124606  [19200/69728]
loss: 0.297659  [25600/69728]
loss: 0.158290  [32000/69728]
loss: 0.113849  [38400/69728]
loss: 0.126883  [44800/69728]
loss: 0.311540  [51200/69728]
loss: 0.130129  [57600/69728]
loss: 0.135703  [64000/69728]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.193959 

Epoch 50
-------------------------------
loss: 0.169635  [    0/69728]
loss: 0.122457  [ 6400/69728]
loss: 0.160533  [12800/69728]
loss: 0.131632  [19200/69728]
loss: 0.165923  [25600/69728]
loss: 0.209218  [32000/69728]
loss: 1.700207  [38400/69728]
loss: 0.193739  [44800/69728]
loss: 0.137133  [51200/69728]
loss: 0.150729  [57600/69728]
loss: 0.116919  [64000/69728]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.191565 

Epoch 1
-------------------------------
loss: 0.757876  [    0/69274]
loss: 0.308883  [ 6400/69274]
loss: 0.361722  [12800/69274]
loss: 0.268509  [19200/69274]
loss: 0.225527  [25600/69274]
loss: 1.823955  [32000/69274]
loss: 0.117368  [38400/69274]
loss: 0.162489  [44800/69274]
loss: 0.200333  [51200/69274]
loss: 0.159187  [57600/69274]
loss: 0.176384  [64000/69274]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.223718 

Epoch 2
-------------------------------
loss: 0.234979  [    0/69274]
loss: 0.327712  [ 6400/69274]
loss: 0.154350  [12800/69274]
loss: 0.149386  [19200/69274]
loss: 0.294958  [25600/69274]
loss: 0.201746  [32000/69274]
loss: 0.156182  [38400/69274]
loss: 0.265814  [44800/69274]
loss: 0.228020  [51200/69274]
loss: 0.222032  [57600/69274]
loss: 0.182457  [64000/69274]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.207353 

Epoch 3
-------------------------------
loss: 0.219643  [    0/69274]
loss: 0.198256  [ 6400/69274]
loss: 0.192476  [12800/69274]
loss: 0.145615  [19200/69274]
loss: 0.160006  [25600/69274]
loss: 0.234345  [32000/69274]
loss: 0.141527  [38400/69274]
loss: 0.138647  [44800/69274]
loss: 0.130694  [51200/69274]
loss: 0.166796  [57600/69274]
loss: 0.156340  [64000/69274]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.208275 

Epoch 4
-------------------------------
loss: 0.237344  [    0/69274]
loss: 0.091574  [ 6400/69274]
loss: 1.650403  [12800/69274]
loss: 0.166812  [19200/69274]
loss: 0.111829  [25600/69274]
loss: 0.209835  [32000/69274]
loss: 0.279407  [38400/69274]
loss: 0.112266  [44800/69274]
loss: 0.135491  [51200/69274]
loss: 0.341427  [57600/69274]
loss: 0.169537  [64000/69274]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.204588 

Epoch 5
-------------------------------
loss: 0.309923  [    0/69274]
loss: 0.226880  [ 6400/69274]
loss: 0.281552  [12800/69274]
loss: 0.129043  [19200/69274]
loss: 0.140932  [25600/69274]
loss: 0.080098  [32000/69274]
loss: 0.140490  [38400/69274]
loss: 0.255146  [44800/69274]
loss: 0.115649  [51200/69274]
loss: 0.159000  [57600/69274]
loss: 0.136371  [64000/69274]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.203108 

Epoch 6
-------------------------------
loss: 0.130917  [    0/69274]
loss: 0.177724  [ 6400/69274]
loss: 0.202147  [12800/69274]
loss: 0.086574  [19200/69274]
loss: 0.178557  [25600/69274]
loss: 0.118254  [32000/69274]
loss: 0.260933  [38400/69274]
loss: 0.212890  [44800/69274]
loss: 0.260363  [51200/69274]
loss: 0.278878  [57600/69274]
loss: 0.205078  [64000/69274]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.187821 

Epoch 7
-------------------------------
loss: 0.086873  [    0/69274]
loss: 0.191500  [ 6400/69274]
loss: 0.135471  [12800/69274]
loss: 0.191960  [19200/69274]
loss: 0.133708  [25600/69274]
loss: 0.125721  [32000/69274]
loss: 0.261398  [38400/69274]
loss: 0.372318  [44800/69274]
loss: 0.190362  [ 6400/70738]
loss: 1.659211  [12800/70738]
loss: 0.151317  [19200/70738]
loss: 0.284945  [25600/70738]
loss: 0.102702  [32000/70738]
loss: 0.157414  [38400/70738]
loss: 0.125602  [44800/70738]
loss: 0.124876  [51200/70738]
loss: 0.112168  [57600/70738]
loss: 0.127715  [64000/70738]
loss: 0.113840  [70400/70738]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.185576 

Epoch 32
-------------------------------
loss: 0.112514  [    0/70738]
loss: 0.075655  [ 6400/70738]
loss: 0.087792  [12800/70738]
loss: 0.119971  [19200/70738]
loss: 0.101211  [25600/70738]
loss: 0.241931  [32000/70738]
loss: 0.077674  [38400/70738]
loss: 0.268703  [44800/70738]
loss: 0.088372  [51200/70738]
loss: 0.271031  [57600/70738]
loss: 0.103097  [64000/70738]
loss: 0.151028  [70400/70738]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.192879 

Epoch 33
-------------------------------
loss: 0.064021  [    0/70738]
loss: 0.118234  [ 6400/70738]
loss: 0.124108  [12800/70738]
loss: 0.140778  [19200/70738]
loss: 0.299098  [25600/70738]
loss: 0.182374  [32000/70738]
loss: 0.178208  [38400/70738]
loss: 0.064176  [44800/70738]
loss: 0.113819  [51200/70738]
loss: 0.054800  [57600/70738]
loss: 0.194184  [64000/70738]
loss: 0.108742  [70400/70738]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.169049 

Epoch 34
-------------------------------
loss: 0.119655  [    0/70738]
loss: 0.074834  [ 6400/70738]
loss: 0.109998  [12800/70738]
loss: 0.215104  [19200/70738]
loss: 0.261957  [25600/70738]
loss: 0.155709  [32000/70738]
loss: 0.074190  [38400/70738]
loss: 0.122934  [44800/70738]
loss: 0.118410  [51200/70738]
loss: 0.188295  [57600/70738]
loss: 0.153375  [64000/70738]
loss: 0.103904  [70400/70738]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.171143 

Epoch 35
-------------------------------
loss: 0.106436  [    0/70738]
loss: 0.182486  [ 6400/70738]
loss: 0.079858  [12800/70738]
loss: 0.169789  [19200/70738]
loss: 0.082431  [25600/70738]
loss: 0.091875  [32000/70738]
loss: 0.129914  [38400/70738]
loss: 0.052014  [44800/70738]
loss: 0.063032  [51200/70738]
loss: 0.114859  [57600/70738]
loss: 0.194688  [64000/70738]
loss: 0.138161  [70400/70738]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180616 

Epoch 36
-------------------------------
loss: 0.128664  [    0/70738]
loss: 0.115572  [ 6400/70738]
loss: 0.146696  [12800/70738]
loss: 0.149503  [19200/70738]
loss: 0.073407  [25600/70738]
loss: 0.108844  [32000/70738]
loss: 0.118415  [38400/70738]
loss: 0.113892  [44800/70738]
loss: 0.117194  [51200/70738]
loss: 0.092217  [57600/70738]
loss: 0.125655  [64000/70738]
loss: 0.185800  [70400/70738]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.171550 

Epoch 37
-------------------------------
loss: 0.086313  [    0/70738]
loss: 0.181250  [ 6400/70738]
loss: 0.223146  [12800/70738]
loss: 0.243487  [19200/70738]
loss: 0.212142  [25600/70738]
loss: 0.060141  [32000/70738]
loss: 0.145425  [38400/70738]
loss: 0.113567  [44800/70738]
loss: 0.236123  [51200/70738]
loss: 0.083212  [57600/70738]
loss: 0.092244  [64000/70738]
loss: 0.124431  [70400/70738]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.158144 

Epoch 38
-------------------------------
loss: 0.095557  [    0/70738]
loss: 0.096073  [ 6400/70738]
loss: 0.086826  [12800/70738]
loss: 0.163819  [19200/70738]
loss: 0.161001  [25600/70738]
loss: 0.146536  [32000/70738]
loss: 0.108377  [38400/70738]
loss: 0.173339  [44800/70738]
loss: 0.107379  [51200/70738]
loss: 0.117492  [57600/70738]
loss: 0.163303  [64000/70738]
loss: 0.141445  [70400/70738]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.160720 

Epoch 39
-------------------------------
loss: 0.054021  [    0/70738]
loss: 0.093925  [ 6400/70738]
loss: 0.237182  [12800/70738]
loss: 0.542004  [19200/70738]
loss: 0.102441  [25600/70738]
loss: 0.110027  [32000/70738]
loss: 0.115816  [38400/70738]
loss: 0.061058  [44800/70738]
loss: 0.202450  [51200/70738]
loss: 0.090028  [57600/70738]
loss: 0.108517  [64000/70738]
loss: 0.298262  [70400/70738]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.165582 

Epoch 40
-------------------------------
loss: 0.074855  [    0/70738]
loss: 0.187919  [ 6400/70738]
loss: 0.085610  [12800/70738]
loss: 0.303051  [19200/70738]
loss: 0.186608  [25600/70738]
loss: 0.171380  [32000/70738]
loss: 0.152814  [38400/70738]
loss: 0.164507  [44800/70738]
loss: 0.181788  [51200/70738]
loss: 0.104519  [57600/70738]
loss: 0.040635  [64000/70738]
loss: 0.105007  [70400/70738]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.172441 

Epoch 41
-------------------------------
loss: 0.124485  [    0/70738]
loss: 0.136881  [ 6400/70738]
loss: 0.115318  [12800/70738]
loss: 0.114386  [19200/70738]
loss: 0.104413  [25600/70738]
loss: 0.313094  [32000/70738]
loss: 0.246443  [38400/70738]
loss: 0.145183  [44800/70738]
loss: 0.078054  [51200/70738]
loss: 0.244508  [57600/70738]
loss: 0.169621  [64000/70738]
loss: 0.092567  [70400/70738]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.168112 

Epoch 42
-------------------------------
loss: 0.063552  [    0/70738]
loss: 0.119400  [ 6400/70738]
loss: 0.125779  [12800/70738]
loss: 0.086951  [19200/70738]
loss: 0.117675  [25600/70738]
loss: 0.252775  [32000/70738]
loss: 0.135221  [38400/70738]
loss: 0.095531  [44800/70738]
loss: 0.064037  [51200/70738]
loss: 0.275987  [57600/70738]
loss: 0.207705  [64000/70738]
loss: 0.078085  [70400/70738]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.173356 

Epoch 43
-------------------------------
loss: 0.183529  [    0/70738]
loss: 0.134517  [ 6400/70738]
loss: 0.077431  [12800/70738]
loss: 0.119597  [19200/70738]
loss: 0.134331  [25600/70738]
loss: 0.122590  [32000/70738]
loss: 0.142549  [38400/70738]
loss: 0.110674  [44800/70738]
loss: 0.072671  [51200/70738]
loss: 0.190245  [57600/70738]
loss: 0.085158  [64000/70738]
loss: 0.183649  [70400/70738]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.183079 

Epoch 44
-------------------------------
loss: 0.234313  [    0/70738]
loss: 0.172979  [ 6400/70738]
loss: 0.116068  [12800/70738]
loss: 0.138514  [19200/70738]
loss: 0.066993  [25600/70738]
loss: 0.116364  [32000/70738]
loss: 0.098203  [38400/70738]
loss: 0.128306  [44800/70738]
loss: 0.215174  [51200/70738]
loss: 0.131930  [57600/70738]
loss: 0.130176  [64000/70738]
loss: 0.158160  [70400/70738]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.162331 

Epoch 45
-------------------------------
loss: 0.120400  [    0/70738]
loss: 0.081902  [ 6400/70738]
loss: 0.128679  [12800/70738]
loss: 0.082592  [19200/70738]
loss: 0.057185  [25600/70738]
loss: 0.111616  [32000/70738]
loss: 0.208740  [38400/70738]
loss: 0.160244  [44800/70738]
loss: 0.126003  [51200/70738]
loss: 0.071973  [57600/70738]
loss: 0.094641  [64000/70738]
loss: 0.162141  [70400/70738]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.163660 

Epoch 46
-------------------------------
loss: 0.130566  [    0/70738]
loss: 0.136337  [ 6400/70738]
loss: 0.094684  [12800/70738]
loss: 0.220698  [19200/70738]
loss: 0.159704  [25600/70738]
loss: 0.133710  [32000/70738]
loss: 0.134744  [38400/70738]
loss: 0.296299  [44800/70738]
loss: 0.071898  [51200/70738]
loss: 0.040378  [57600/70738]
loss: 0.131923  [64000/70738]
loss: 0.232779  [70400/70738]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177045 

Epoch 47
-------------------------------
loss: 1.643855  [    0/70738]
loss: 0.121919  [ 6400/70738]
loss: 0.141919  [12800/70738]
loss: 0.125085  [19200/70738]
loss: 0.152425  [25600/70738]
loss: 0.123284  [32000/70738]
loss: 0.175222  [38400/70738]
loss: 0.076545  [44800/70738]
loss: 0.106368  [51200/70738]
loss: 0.128749  [57600/70738]
loss: 0.075723  [64000/70738]
loss: 0.077985  [70400/70738]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.175292 

Epoch 48
-------------------------------
loss: 0.112328  [    0/70738]
loss: 0.176545  [ 6400/70738]
loss: 0.095920  [12800/70738]
loss: 0.158587  [19200/70738]
loss: 0.109724  [25600/70738]
loss: 0.163259  [32000/70738]
loss: 0.192558  [38400/70738]
loss: 0.250038  [44800/70738]
loss: 0.117644  [51200/70738]
loss: 0.039553  [57600/70738]
loss: 0.054039  [64000/70738]
loss: 0.144811  [70400/70738]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.164226 

Epoch 49
-------------------------------
loss: 0.066709  [    0/70738]
loss: 0.117023  [ 6400/70738]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.074206 

Epoch 4
-------------------------------
loss: 0.048374  [    0/71783]
loss: 0.182328  [ 6400/71783]
loss: 0.058866  [12800/71783]
loss: 0.039216  [19200/71783]
loss: 0.081988  [25600/71783]
loss: 0.072321  [32000/71783]
loss: 0.071796  [38400/71783]
loss: 0.038856  [44800/71783]
loss: 0.077468  [51200/71783]
loss: 0.049397  [57600/71783]
loss: 0.062551  [64000/71783]
loss: 0.059146  [70400/71783]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.081914 

Epoch 5
-------------------------------
loss: 0.060616  [    0/71783]
loss: 0.024965  [ 6400/71783]
loss: 0.031421  [12800/71783]
loss: 0.041621  [19200/71783]
loss: 0.129800  [25600/71783]
loss: 0.042246  [32000/71783]
loss: 0.025969  [38400/71783]
loss: 0.041453  [44800/71783]
loss: 0.103275  [51200/71783]
loss: 0.016142  [57600/71783]
loss: 0.146310  [64000/71783]
loss: 0.056701  [70400/71783]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.068947 

Epoch 6
-------------------------------
loss: 0.028639  [    0/71783]
loss: 1.599067  [ 6400/71783]
loss: 0.064410  [12800/71783]
loss: 0.013842  [19200/71783]
loss: 0.008872  [25600/71783]
loss: 0.028080  [32000/71783]
loss: 0.007481  [38400/71783]
loss: 0.074177  [44800/71783]
loss: 0.069967  [51200/71783]
loss: 0.064001  [57600/71783]
loss: 0.051603  [64000/71783]
loss: 0.081439  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.068117 

Epoch 7
-------------------------------
loss: 0.005074  [    0/71783]
loss: 0.098865  [ 6400/71783]
loss: 0.064665  [12800/71783]
loss: 0.166022  [19200/71783]
loss: 0.046376  [25600/71783]
loss: 0.042204  [32000/71783]
loss: 0.053472  [38400/71783]
loss: 0.071509  [44800/71783]
loss: 0.053260  [51200/71783]
loss: 0.114098  [57600/71783]
loss: 0.149734  [64000/71783]
loss: 0.048486  [70400/71783]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.071620 

Epoch 8
-------------------------------
loss: 0.021237  [    0/71783]
loss: 0.064308  [ 6400/71783]
loss: 0.169155  [12800/71783]
loss: 0.009186  [19200/71783]
loss: 0.058599  [25600/71783]
loss: 0.085915  [32000/71783]
loss: 0.032500  [38400/71783]
loss: 0.069557  [44800/71783]
loss: 0.078214  [51200/71783]
loss: 0.013830  [57600/71783]
loss: 0.009714  [64000/71783]
loss: 0.021821  [70400/71783]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.073721 

Epoch 9
-------------------------------
loss: 0.033682  [    0/71783]
loss: 0.064613  [ 6400/71783]
loss: 0.025294  [12800/71783]
loss: 0.045804  [19200/71783]
loss: 0.031450  [25600/71783]
loss: 0.130332  [32000/71783]
loss: 0.026288  [38400/71783]
loss: 0.116634  [44800/71783]
loss: 0.164107  [51200/71783]
loss: 0.079916  [57600/71783]
loss: 0.080241  [64000/71783]
loss: 0.053759  [70400/71783]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.079691 

Epoch 10
-------------------------------
loss: 0.030403  [    0/71783]
loss: 0.088509  [ 6400/71783]
loss: 0.091305  [12800/71783]
loss: 0.034298  [19200/71783]
loss: 0.021943  [25600/71783]
loss: 0.136112  [32000/71783]
loss: 0.057581  [38400/71783]
loss: 0.060947  [44800/71783]
loss: 0.080062  [51200/71783]
loss: 0.071759  [57600/71783]
loss: 0.057721  [64000/71783]
loss: 0.016042  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.078216 

Epoch 11
-------------------------------
loss: 0.106320  [    0/71783]
loss: 0.045294  [ 6400/71783]
loss: 0.013600  [12800/71783]
loss: 0.027907  [19200/71783]
loss: 0.051706  [25600/71783]
loss: 0.037003  [32000/71783]
loss: 0.106326  [38400/71783]
loss: 0.014201  [44800/71783]
loss: 0.100067  [51200/71783]
loss: 0.063835  [57600/71783]
loss: 0.053502  [64000/71783]
loss: 0.037870  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.080275 

Epoch 12
-------------------------------
loss: 0.003841  [    0/71783]
loss: 0.065245  [ 6400/71783]
loss: 0.085927  [12800/71783]
loss: 0.023127  [19200/71783]
loss: 0.035082  [25600/71783]
loss: 0.044909  [32000/71783]
loss: 0.020430  [38400/71783]
loss: 0.110398  [44800/71783]
loss: 0.043385  [51200/71783]
loss: 0.039687  [57600/71783]
loss: 0.048479  [64000/71783]
loss: 0.113703  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.083645 

Epoch 13
-------------------------------
loss: 0.024430  [    0/71783]
loss: 0.008083  [ 6400/71783]
loss: 0.048074  [12800/71783]
loss: 0.043103  [19200/71783]
loss: 0.141903  [25600/71783]
loss: 0.017486  [32000/71783]
loss: 0.031128  [38400/71783]
loss: 0.014847  [44800/71783]
loss: 0.021182  [51200/71783]
loss: 0.009402  [57600/71783]
loss: 0.174247  [64000/71783]
loss: 0.041773  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074922 

Epoch 14
-------------------------------
loss: 0.058816  [    0/71783]
loss: 0.035119  [ 6400/71783]
loss: 0.054259  [12800/71783]
loss: 0.079359  [19200/71783]
loss: 0.086947  [25600/71783]
loss: 0.065232  [32000/71783]
loss: 0.090807  [38400/71783]
loss: 0.041525  [44800/71783]
loss: 0.121680  [51200/71783]
loss: 0.043399  [57600/71783]
loss: 0.110993  [64000/71783]
loss: 0.038267  [70400/71783]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.082623 

Epoch 15
-------------------------------
loss: 0.052923  [    0/71783]
loss: 0.063733  [ 6400/71783]
loss: 0.037802  [12800/71783]
loss: 0.015674  [19200/71783]
loss: 0.040194  [25600/71783]
loss: 0.027183  [32000/71783]
loss: 0.055798  [38400/71783]
loss: 0.023104  [44800/71783]
loss: 0.142421  [51200/71783]
loss: 0.083624  [57600/71783]
loss: 0.159016  [64000/71783]
loss: 0.057667  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.082197 

Epoch 16
-------------------------------
loss: 0.091380  [    0/71783]
loss: 0.018508  [ 6400/71783]
loss: 0.016268  [12800/71783]
loss: 0.084831  [19200/71783]
loss: 0.080447  [25600/71783]
loss: 0.095440  [32000/71783]
loss: 0.032971  [38400/71783]
loss: 0.029966  [44800/71783]
loss: 0.013002  [51200/71783]
loss: 0.033238  [57600/71783]
loss: 0.139255  [64000/71783]
loss: 0.015749  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.092598 

Epoch 17
-------------------------------
loss: 0.010113  [    0/71783]
loss: 0.035175  [ 6400/71783]
loss: 0.004041  [12800/71783]
loss: 0.015969  [19200/71783]
loss: 0.060233  [25600/71783]
loss: 0.026431  [32000/71783]
loss: 0.002034  [38400/71783]
loss: 1.655202  [44800/71783]
loss: 0.009170  [51200/71783]
loss: 0.093660  [57600/71783]
loss: 0.101476  [64000/71783]
loss: 0.028135  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.078974 

Epoch 18
-------------------------------
loss: 0.032462  [    0/71783]
loss: 0.022807  [ 6400/71783]
loss: 0.002743  [12800/71783]
loss: 0.163247  [19200/71783]
loss: 0.017092  [25600/71783]
loss: 0.051330  [32000/71783]
loss: 0.022681  [38400/71783]
loss: 0.082428  [44800/71783]
loss: 0.027933  [51200/71783]
loss: 0.045186  [57600/71783]
loss: 0.060351  [64000/71783]
loss: 0.047699  [70400/71783]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.080738 

Epoch 19
-------------------------------
loss: 0.022095  [    0/71783]
loss: 0.033007  [ 6400/71783]
loss: 0.018217  [12800/71783]
loss: 0.048516  [19200/71783]
loss: 0.126883  [25600/71783]
loss: 0.019484  [32000/71783]
loss: 0.058571  [38400/71783]
loss: 0.033464  [44800/71783]
loss: 0.038129  [51200/71783]
loss: 0.084985  [57600/71783]
loss: 0.057510  [64000/71783]
loss: 0.011883  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.092047 

Epoch 20
-------------------------------
loss: 0.041016  [    0/71783]
loss: 0.018591  [ 6400/71783]
loss: 0.043239  [12800/71783]
loss: 0.010105  [19200/71783]
loss: 0.069926  [25600/71783]
loss: 0.008039  [32000/71783]
loss: 0.029396  [38400/71783]
loss: 0.056266  [44800/71783]
loss: 0.075133  [51200/71783]
loss: 0.007891  [57600/71783]
loss: 0.028200  [64000/71783]
loss: 0.041492  [70400/71783]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.089164 

Epoch 21
-------------------------------
loss: 0.022532  [    0/71783]
loss: 0.045512  [ 6400/71783]
loss: 0.044550  [12800/71783]
loss: 0.009750  [19200/71783]
loss: 0.039414  [25600/71783]
loss: 0.103046  [32000/71783]
loss: 0.085936  [38400/71783]
loss: 0.014863  [44800/71783]
loss: 0.035948  [51200/71783]
loss: 0.016613  [57600/71783]
loss: 0.112315  [64000/71783]
loss: 0.060427  [70400/71783]
loss: 0.107948  [38400/70080]
loss: 0.081647  [44800/70080]
loss: 0.214905  [51200/70080]
loss: 0.091979  [57600/70080]
loss: 0.154816  [64000/70080]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.143585 

Epoch 46
-------------------------------
loss: 0.079812  [    0/70080]
loss: 0.090650  [ 6400/70080]
loss: 0.091629  [12800/70080]
loss: 0.078738  [19200/70080]
loss: 0.117143  [25600/70080]
loss: 0.107113  [32000/70080]
loss: 0.120447  [38400/70080]
loss: 0.057902  [44800/70080]
loss: 0.078426  [51200/70080]
loss: 0.352733  [57600/70080]
loss: 0.074052  [64000/70080]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.138688 

Epoch 47
-------------------------------
loss: 0.124691  [    0/70080]
loss: 0.040725  [ 6400/70080]
loss: 0.106412  [12800/70080]
loss: 0.084295  [19200/70080]
loss: 0.125355  [25600/70080]
loss: 0.068391  [32000/70080]
loss: 0.084632  [38400/70080]
loss: 0.069889  [44800/70080]
loss: 0.151088  [51200/70080]
loss: 0.102882  [57600/70080]
loss: 0.109255  [64000/70080]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.134371 

Epoch 48
-------------------------------
loss: 0.053717  [    0/70080]
loss: 0.053025  [ 6400/70080]
loss: 0.054538  [12800/70080]
loss: 0.059354  [19200/70080]
loss: 0.174669  [25600/70080]
loss: 0.160799  [32000/70080]
loss: 0.102465  [38400/70080]
loss: 0.141956  [44800/70080]
loss: 0.050705  [51200/70080]
loss: 0.076070  [57600/70080]
loss: 0.128069  [64000/70080]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.139139 

Epoch 49
-------------------------------
loss: 0.138473  [    0/70080]
loss: 0.073044  [ 6400/70080]
loss: 0.152241  [12800/70080]
loss: 0.087052  [19200/70080]
loss: 0.063373  [25600/70080]
loss: 0.122363  [32000/70080]
loss: 0.081329  [38400/70080]
loss: 0.038421  [44800/70080]
loss: 0.115558  [51200/70080]
loss: 0.104734  [57600/70080]
loss: 0.121297  [64000/70080]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.132197 

Epoch 50
-------------------------------
loss: 0.107193  [    0/70080]
loss: 0.036748  [ 6400/70080]
loss: 0.045914  [12800/70080]
loss: 0.052574  [19200/70080]
loss: 0.100871  [25600/70080]
loss: 0.107498  [32000/70080]
loss: 0.104409  [38400/70080]
loss: 0.111210  [44800/70080]
loss: 0.111436  [51200/70080]
loss: 0.057733  [57600/70080]
loss: 0.114455  [64000/70080]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.134210 

Epoch 1
-------------------------------
loss: 0.695896  [    0/69641]
loss: 0.215537  [ 6400/69641]
loss: 0.162842  [12800/69641]
loss: 0.249480  [19200/69641]
loss: 0.385773  [25600/69641]
loss: 0.136559  [32000/69641]
loss: 0.134383  [38400/69641]
loss: 0.146433  [44800/69641]
loss: 0.104792  [51200/69641]
loss: 0.193897  [57600/69641]
loss: 0.180980  [64000/69641]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.191111 

Epoch 2
-------------------------------
loss: 0.097537  [    0/69641]
loss: 0.198080  [ 6400/69641]
loss: 0.118716  [12800/69641]
loss: 0.214498  [19200/69641]
loss: 0.141512  [25600/69641]
loss: 0.233414  [32000/69641]
loss: 0.171659  [38400/69641]
loss: 0.057447  [44800/69641]
loss: 0.214748  [51200/69641]
loss: 0.116795  [57600/69641]
loss: 0.204223  [64000/69641]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.158295 

Epoch 3
-------------------------------
loss: 0.096370  [    0/69641]
loss: 0.222154  [ 6400/69641]
loss: 0.154023  [12800/69641]
loss: 0.186656  [19200/69641]
loss: 0.075884  [25600/69641]
loss: 0.064118  [32000/69641]
loss: 0.125324  [38400/69641]
loss: 0.095970  [44800/69641]
loss: 0.170204  [51200/69641]
loss: 0.153981  [57600/69641]
loss: 0.185688  [64000/69641]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.145997 

Epoch 4
-------------------------------
loss: 0.149718  [    0/69641]
loss: 0.217668  [ 6400/69641]
loss: 0.092734  [12800/69641]
loss: 0.286579  [19200/69641]
loss: 0.243724  [25600/69641]
loss: 0.096457  [32000/69641]
loss: 0.126816  [38400/69641]
loss: 0.159302  [44800/69641]
loss: 0.109872  [51200/69641]
loss: 0.121397  [57600/69641]
loss: 0.064183  [64000/69641]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.140811 

Epoch 5
-------------------------------
loss: 0.173263  [    0/69641]
loss: 0.116725  [ 6400/69641]
loss: 0.229563  [12800/69641]
loss: 0.072253  [19200/69641]
loss: 0.165871  [25600/69641]
loss: 0.203701  [32000/69641]
loss: 0.079608  [38400/69641]
loss: 0.049222  [44800/69641]
loss: 0.125899  [51200/69641]
loss: 0.168307  [57600/69641]
loss: 0.069166  [64000/69641]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.136244 

Epoch 6
-------------------------------
loss: 0.116205  [    0/69641]
loss: 0.120028  [ 6400/69641]
loss: 0.092970  [12800/69641]
loss: 0.084650  [19200/69641]
loss: 1.847685  [25600/69641]
loss: 0.091340  [32000/69641]
loss: 0.092766  [38400/69641]
loss: 0.110758  [44800/69641]
loss: 0.053324  [51200/69641]
loss: 0.146720  [57600/69641]
loss: 0.117840  [64000/69641]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.152651 

Epoch 7
-------------------------------
loss: 0.139232  [    0/69641]
loss: 0.095607  [ 6400/69641]
loss: 0.069166  [12800/69641]
loss: 0.222798  [19200/69641]
loss: 0.125676  [25600/69641]
loss: 0.219906  [32000/69641]
loss: 0.129357  [38400/69641]
loss: 0.067658  [44800/69641]
loss: 0.090310  [51200/69641]
loss: 0.168125  [57600/69641]
loss: 0.162040  [64000/69641]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.130489 

Epoch 8
-------------------------------
loss: 0.075594  [    0/69641]
loss: 0.173817  [ 6400/69641]
loss: 0.164201  [12800/69641]
loss: 0.095299  [19200/69641]
loss: 0.099553  [25600/69641]
loss: 0.083401  [32000/69641]
loss: 0.112460  [38400/69641]
loss: 0.096684  [44800/69641]
loss: 0.122252  [51200/69641]
loss: 0.097294  [57600/69641]
loss: 0.084037  [64000/69641]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.136798 

Epoch 9
-------------------------------
loss: 0.350000  [    0/69641]
loss: 0.092487  [ 6400/69641]
loss: 0.146624  [12800/69641]
loss: 0.095898  [19200/69641]
loss: 0.104975  [25600/69641]
loss: 0.175033  [32000/69641]
loss: 0.076898  [38400/69641]
loss: 0.168378  [44800/69641]
loss: 0.120654  [51200/69641]
loss: 0.050279  [57600/69641]
loss: 0.128412  [64000/69641]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.124727 

Epoch 10
-------------------------------
loss: 0.060372  [    0/69641]
loss: 0.219784  [ 6400/69641]
loss: 0.159409  [12800/69641]
loss: 0.130086  [19200/69641]
loss: 0.105382  [25600/69641]
loss: 0.091334  [32000/69641]
loss: 0.040874  [38400/69641]
loss: 0.293337  [44800/69641]
loss: 0.056047  [51200/69641]
loss: 0.097814  [57600/69641]
loss: 0.106145  [64000/69641]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.110718 

Epoch 11
-------------------------------
loss: 0.027333  [    0/69641]
loss: 0.085531  [ 6400/69641]
loss: 0.047049  [12800/69641]
loss: 0.144310  [19200/69641]
loss: 0.076649  [25600/69641]
loss: 0.166695  [32000/69641]
loss: 0.214415  [38400/69641]
loss: 0.084025  [44800/69641]
loss: 0.190352  [51200/69641]
loss: 0.074818  [57600/69641]
loss: 0.078173  [64000/69641]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.115360 

Epoch 12
-------------------------------
loss: 0.060017  [    0/69641]
loss: 0.049219  [ 6400/69641]
loss: 0.048268  [12800/69641]
loss: 0.106481  [19200/69641]
loss: 0.092327  [25600/69641]
loss: 0.073453  [32000/69641]
loss: 0.098814  [38400/69641]
loss: 0.160105  [44800/69641]
loss: 0.197121  [51200/69641]
loss: 0.102812  [57600/69641]
loss: 0.136133  [64000/69641]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.115934 

Epoch 13
-------------------------------
loss: 0.047993  [    0/69641]
loss: 0.114089  [ 6400/69641]
loss: 0.110498  [12800/69641]
loss: 0.102768  [19200/69641]
loss: 0.223973  [25600/69641]
loss: 0.089523  [32000/69641]
loss: 0.110554  [38400/69641]
loss: 0.168944  [44800/69641]
loss: 0.142526  [51200/69641]
loss: 0.107130  [57600/69641]
loss: 0.066080  [64000/69641]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.116810 

Epoch 14
-------------------------------
loss: 0.145482  [    0/69641]
loss: 0.162880  [ 6400/69641]
loss: 0.089085  [12800/69641]
loss: 0.109983  [19200/69641]
loss: 0.083286  [25600/69641]
loss: 0.104019  [32000/69641]
loss: 0.146772  [38400/69641]
loss: 0.105916  [44800/69641]
loss: 0.170515  [51200/69641]
loss: 0.138122  [57600/69641]
loss: 0.065717  [64000/69641]
loss: 0.152672  [19200/69865]
loss: 0.132020  [25600/69865]
loss: 0.184432  [32000/69865]
loss: 0.231813  [38400/69865]
loss: 0.125266  [44800/69865]
loss: 0.064339  [51200/69865]
loss: 0.194125  [57600/69865]
loss: 0.266194  [64000/69865]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.185069 

Epoch 46
-------------------------------
loss: 0.164211  [    0/69865]
loss: 0.097921  [ 6400/69865]
loss: 0.221693  [12800/69865]
loss: 0.138729  [19200/69865]
loss: 0.105010  [25600/69865]
loss: 0.237645  [32000/69865]
loss: 0.207751  [38400/69865]
loss: 0.213814  [44800/69865]
loss: 0.262519  [51200/69865]
loss: 0.251429  [57600/69865]
loss: 0.210418  [64000/69865]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.202432 

Epoch 47
-------------------------------
loss: 0.129573  [    0/69865]
loss: 0.123128  [ 6400/69865]
loss: 0.303908  [12800/69865]
loss: 0.210459  [19200/69865]
loss: 0.124615  [25600/69865]
loss: 0.238524  [32000/69865]
loss: 0.080386  [38400/69865]
loss: 0.058166  [44800/69865]
loss: 0.204687  [51200/69865]
loss: 0.188212  [57600/69865]
loss: 0.170338  [64000/69865]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.189793 

Epoch 48
-------------------------------
loss: 0.245849  [    0/69865]
loss: 0.163129  [ 6400/69865]
loss: 0.257253  [12800/69865]
loss: 0.164817  [19200/69865]
loss: 0.266852  [25600/69865]
loss: 0.141968  [32000/69865]
loss: 0.221687  [38400/69865]
loss: 0.096688  [44800/69865]
loss: 0.100490  [51200/69865]
loss: 0.118487  [57600/69865]
loss: 0.171729  [64000/69865]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.213800 

Epoch 49
-------------------------------
loss: 0.171856  [    0/69865]
loss: 0.161842  [ 6400/69865]
loss: 0.146278  [12800/69865]
loss: 0.083918  [19200/69865]
loss: 0.137040  [25600/69865]
loss: 0.119431  [32000/69865]
loss: 0.187013  [38400/69865]
loss: 0.170691  [44800/69865]
loss: 0.148533  [51200/69865]
loss: 0.268729  [57600/69865]
loss: 0.309826  [64000/69865]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.193373 

Epoch 50
-------------------------------
loss: 0.282865  [    0/69865]
loss: 0.155251  [ 6400/69865]
loss: 0.140811  [12800/69865]
loss: 0.168768  [19200/69865]
loss: 0.205971  [25600/69865]
loss: 0.116957  [32000/69865]
loss: 0.185703  [38400/69865]
loss: 0.185073  [44800/69865]
loss: 0.206654  [51200/69865]
loss: 0.282985  [57600/69865]
loss: 0.099549  [64000/69865]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.187495 

Epoch 1
-------------------------------
loss: 0.797622  [    0/70852]
loss: 0.209702  [ 6400/70852]
loss: 0.279737  [12800/70852]
loss: 0.106405  [19200/70852]
loss: 0.115129  [25600/70852]
loss: 0.159009  [32000/70852]
loss: 0.194192  [38400/70852]
loss: 0.113048  [44800/70852]
loss: 0.172938  [51200/70852]
loss: 0.155997  [57600/70852]
loss: 0.223896  [64000/70852]
loss: 0.105055  [70400/70852]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.205671 

Epoch 2
-------------------------------
loss: 0.157068  [    0/70852]
loss: 0.171247  [ 6400/70852]
loss: 0.217157  [12800/70852]
loss: 0.073171  [19200/70852]
loss: 0.225411  [25600/70852]
loss: 0.176239  [32000/70852]
loss: 0.212811  [38400/70852]
loss: 0.159114  [44800/70852]
loss: 0.166055  [51200/70852]
loss: 0.092272  [57600/70852]
loss: 0.056675  [64000/70852]
loss: 0.138102  [70400/70852]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.193572 

Epoch 3
-------------------------------
loss: 0.167409  [    0/70852]
loss: 0.125089  [ 6400/70852]
loss: 0.088072  [12800/70852]
loss: 0.208210  [19200/70852]
loss: 0.094866  [25600/70852]
loss: 0.176585  [32000/70852]
loss: 0.164078  [38400/70852]
loss: 0.205522  [44800/70852]
loss: 0.152607  [51200/70852]
loss: 0.087172  [57600/70852]
loss: 0.150610  [64000/70852]
loss: 0.126541  [70400/70852]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.169593 

Epoch 4
-------------------------------
loss: 0.115923  [    0/70852]
loss: 0.145576  [ 6400/70852]
loss: 0.128271  [12800/70852]
loss: 0.047406  [19200/70852]
loss: 0.084784  [25600/70852]
loss: 0.129979  [32000/70852]
loss: 0.099439  [38400/70852]
loss: 0.207023  [44800/70852]
loss: 0.170107  [51200/70852]
loss: 0.163385  [57600/70852]
loss: 0.255030  [64000/70852]
loss: 0.121282  [70400/70852]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.178881 

Epoch 5
-------------------------------
loss: 0.055721  [    0/70852]
loss: 0.185099  [ 6400/70852]
loss: 0.099790  [12800/70852]
loss: 0.100482  [19200/70852]
loss: 0.109743  [25600/70852]
loss: 0.150146  [32000/70852]
loss: 0.125714  [38400/70852]
loss: 0.159861  [44800/70852]
loss: 0.177465  [51200/70852]
loss: 0.166982  [57600/70852]
loss: 0.207474  [64000/70852]
loss: 0.170505  [70400/70852]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.206819 

Epoch 6
-------------------------------
loss: 0.086746  [    0/70852]
loss: 0.085667  [ 6400/70852]
loss: 0.170402  [12800/70852]
loss: 0.348964  [19200/70852]
loss: 0.076549  [25600/70852]
loss: 0.095798  [32000/70852]
loss: 0.182183  [38400/70852]
loss: 0.121379  [44800/70852]
loss: 0.105832  [51200/70852]
loss: 0.075785  [57600/70852]
loss: 0.093423  [64000/70852]
loss: 0.167960  [70400/70852]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.184945 

Epoch 7
-------------------------------
loss: 0.047313  [    0/70852]
loss: 0.081980  [ 6400/70852]
loss: 0.111635  [12800/70852]
loss: 0.232845  [19200/70852]
loss: 0.207962  [25600/70852]
loss: 0.100948  [32000/70852]
loss: 0.188050  [38400/70852]
loss: 0.157692  [44800/70852]
loss: 0.234516  [51200/70852]
loss: 0.114674  [57600/70852]
loss: 0.052165  [64000/70852]
loss: 0.084459  [70400/70852]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.200193 

Epoch 8
-------------------------------
loss: 0.151203  [    0/70852]
loss: 0.117842  [ 6400/70852]
loss: 0.111160  [12800/70852]
loss: 0.246856  [19200/70852]
loss: 0.164545  [25600/70852]
loss: 0.074320  [32000/70852]
loss: 0.170086  [38400/70852]
loss: 0.175714  [44800/70852]
loss: 0.189266  [51200/70852]
loss: 0.061652  [57600/70852]
loss: 0.116631  [64000/70852]
loss: 0.152809  [70400/70852]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.177035 

Epoch 9
-------------------------------
loss: 0.275974  [    0/70852]
loss: 0.142491  [ 6400/70852]
loss: 0.152367  [12800/70852]
loss: 0.118063  [19200/70852]
loss: 0.186772  [25600/70852]
loss: 0.237088  [32000/70852]
loss: 0.186601  [38400/70852]
loss: 0.074671  [44800/70852]
loss: 0.050064  [51200/70852]
loss: 0.159945  [57600/70852]
loss: 0.145320  [64000/70852]
loss: 0.145968  [70400/70852]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.177991 

Epoch 10
-------------------------------
loss: 0.235678  [    0/70852]
loss: 0.133943  [ 6400/70852]
loss: 0.040579  [12800/70852]
loss: 0.108749  [19200/70852]
loss: 0.248715  [25600/70852]
loss: 0.177769  [32000/70852]
loss: 0.078117  [38400/70852]
loss: 0.162065  [44800/70852]
loss: 0.086232  [51200/70852]
loss: 0.107404  [57600/70852]
loss: 0.242926  [64000/70852]
loss: 0.245447  [70400/70852]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.169940 

Epoch 11
-------------------------------
loss: 0.057175  [    0/70852]
loss: 0.042439  [ 6400/70852]
loss: 0.203159  [12800/70852]
loss: 0.140604  [19200/70852]
loss: 0.198956  [25600/70852]
loss: 0.064867  [32000/70852]
loss: 0.116036  [38400/70852]
loss: 0.142788  [44800/70852]
loss: 1.763442  [51200/70852]
loss: 0.171101  [57600/70852]
loss: 0.067123  [64000/70852]
loss: 0.186540  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.166499 

Epoch 12
-------------------------------
loss: 0.101363  [    0/70852]
loss: 0.139226  [ 6400/70852]
loss: 0.189404  [12800/70852]
loss: 0.051205  [19200/70852]
loss: 0.171556  [25600/70852]
loss: 0.116744  [32000/70852]
loss: 0.057438  [38400/70852]
loss: 0.117450  [44800/70852]
loss: 0.139859  [51200/70852]
loss: 0.083635  [57600/70852]
loss: 0.046136  [64000/70852]
loss: 0.276253  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.166293 

Epoch 13
-------------------------------
loss: 0.069485  [    0/70852]
loss: 0.172731  [ 6400/70852]
loss: 0.058503  [12800/70852]
loss: 0.117734  [19200/70852]
loss: 0.184935  [25600/70852]
loss: 0.118539  [32000/70852]
loss: 0.128120  [38400/70852]
loss: 0.080893  [44800/70852]
loss: 0.212501  [51200/70852]
loss: 0.186023  [57600/70852]
loss: 0.095675  [38400/71041]
loss: 0.189413  [44800/71041]
loss: 0.245354  [51200/71041]
loss: 0.105538  [57600/71041]
loss: 0.173552  [64000/71041]
loss: 0.183297  [70400/71041]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.156950 

Epoch 43
-------------------------------
loss: 0.113043  [    0/71041]
loss: 3.314246  [ 6400/71041]
loss: 0.129409  [12800/71041]
loss: 0.028593  [19200/71041]
loss: 0.038329  [25600/71041]
loss: 0.065205  [32000/71041]
loss: 0.108296  [38400/71041]
loss: 0.072837  [44800/71041]
loss: 0.073866  [51200/71041]
loss: 0.120156  [57600/71041]
loss: 0.110859  [64000/71041]
loss: 0.160550  [70400/71041]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.147181 

Epoch 44
-------------------------------
loss: 0.120899  [    0/71041]
loss: 0.049289  [ 6400/71041]
loss: 0.093919  [12800/71041]
loss: 0.118741  [19200/71041]
loss: 0.088066  [25600/71041]
loss: 0.218119  [32000/71041]
loss: 0.141700  [38400/71041]
loss: 0.135305  [44800/71041]
loss: 0.136738  [51200/71041]
loss: 0.137471  [57600/71041]
loss: 0.106971  [64000/71041]
loss: 0.205807  [70400/71041]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.191469 

Epoch 45
-------------------------------
loss: 0.146707  [    0/71041]
loss: 0.165478  [ 6400/71041]
loss: 0.039250  [12800/71041]
loss: 0.076156  [19200/71041]
loss: 0.039826  [25600/71041]
loss: 0.377871  [32000/71041]
loss: 0.132361  [38400/71041]
loss: 0.197582  [44800/71041]
loss: 0.061145  [51200/71041]
loss: 0.067009  [57600/71041]
loss: 0.074169  [64000/71041]
loss: 0.066613  [70400/71041]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.151869 

Epoch 46
-------------------------------
loss: 0.053752  [    0/71041]
loss: 0.085168  [ 6400/71041]
loss: 0.129837  [12800/71041]
loss: 0.067939  [19200/71041]
loss: 0.075104  [25600/71041]
loss: 0.171735  [32000/71041]
loss: 0.104296  [38400/71041]
loss: 0.047016  [44800/71041]
loss: 0.063049  [51200/71041]
loss: 0.259002  [57600/71041]
loss: 0.067188  [64000/71041]
loss: 0.101662  [70400/71041]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.148117 

Epoch 47
-------------------------------
loss: 0.043401  [    0/71041]
loss: 0.052907  [ 6400/71041]
loss: 0.085780  [12800/71041]
loss: 0.053133  [19200/71041]
loss: 0.137329  [25600/71041]
loss: 0.079486  [32000/71041]
loss: 0.065800  [38400/71041]
loss: 0.126104  [44800/71041]
loss: 1.851589  [51200/71041]
loss: 0.118101  [57600/71041]
loss: 0.105996  [64000/71041]
loss: 0.033475  [70400/71041]
Test Error: 
 Accuracy: 90.0%, Avg loss: 0.715953 

Epoch 48
-------------------------------
loss: 0.383462  [    0/71041]
loss: 0.121512  [ 6400/71041]
loss: 0.013809  [12800/71041]
loss: 0.124535  [19200/71041]
loss: 0.132430  [25600/71041]
loss: 0.052027  [32000/71041]
loss: 0.085821  [38400/71041]
loss: 0.019202  [44800/71041]
loss: 0.141421  [51200/71041]
loss: 0.119468  [57600/71041]
loss: 0.101543  [64000/71041]
loss: 0.051640  [70400/71041]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.212445 

Epoch 49
-------------------------------
loss: 0.124316  [    0/71041]
loss: 0.061738  [ 6400/71041]
loss: 0.075402  [12800/71041]
loss: 0.088915  [19200/71041]
loss: 0.056998  [25600/71041]
loss: 0.266958  [32000/71041]
loss: 0.112712  [38400/71041]
loss: 0.045979  [44800/71041]
loss: 0.103677  [51200/71041]
loss: 0.051564  [57600/71041]
loss: 0.082296  [64000/71041]
loss: 0.064077  [70400/71041]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.148686 

Epoch 50
-------------------------------
loss: 0.126202  [    0/71041]
loss: 0.075101  [ 6400/71041]
loss: 0.037863  [12800/71041]
loss: 0.239728  [19200/71041]
loss: 0.155259  [25600/71041]
loss: 0.059790  [32000/71041]
loss: 0.071781  [38400/71041]
loss: 0.121649  [44800/71041]
loss: 0.204526  [51200/71041]
loss: 0.037756  [57600/71041]
loss: 0.073943  [64000/71041]
loss: 0.104081  [70400/71041]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.153572 

Epoch 1
-------------------------------
loss: 0.751487  [    0/69949]
loss: 0.328382  [ 6400/69949]
loss: 0.325958  [12800/69949]
loss: 0.345153  [19200/69949]
loss: 0.098637  [25600/69949]
loss: 0.247207  [32000/69949]
loss: 0.159773  [38400/69949]
loss: 0.303539  [44800/69949]
loss: 0.217881  [51200/69949]
loss: 0.336352  [57600/69949]
loss: 0.153800  [64000/69949]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.207422 

Epoch 2
-------------------------------
loss: 0.373632  [    0/69949]
loss: 0.314117  [ 6400/69949]
loss: 0.160417  [12800/69949]
loss: 0.111901  [19200/69949]
loss: 0.213920  [25600/69949]
loss: 0.141224  [32000/69949]
loss: 0.164675  [38400/69949]
loss: 0.159676  [44800/69949]
loss: 0.327246  [51200/69949]
loss: 0.214993  [57600/69949]
loss: 0.167090  [64000/69949]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.187721 

Epoch 3
-------------------------------
loss: 0.221624  [    0/69949]
loss: 0.198953  [ 6400/69949]
loss: 0.088035  [12800/69949]
loss: 0.215002  [19200/69949]
loss: 0.090425  [25600/69949]
loss: 0.130129  [32000/69949]
loss: 0.182983  [38400/69949]
loss: 0.168823  [44800/69949]
loss: 0.231212  [51200/69949]
loss: 0.205519  [57600/69949]
loss: 0.076843  [64000/69949]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.183843 

Epoch 4
-------------------------------
loss: 0.248879  [    0/69949]
loss: 0.189296  [ 6400/69949]
loss: 0.136451  [12800/69949]
loss: 0.193647  [19200/69949]
loss: 0.172057  [25600/69949]
loss: 0.162610  [32000/69949]
loss: 0.175735  [38400/69949]
loss: 0.145134  [44800/69949]
loss: 0.128784  [51200/69949]
loss: 0.172096  [57600/69949]
loss: 0.172657  [64000/69949]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.174449 

Epoch 5
-------------------------------
loss: 0.261861  [    0/69949]
loss: 0.261045  [ 6400/69949]
loss: 0.155204  [12800/69949]
loss: 0.244185  [19200/69949]
loss: 0.087627  [25600/69949]
loss: 0.097041  [32000/69949]
loss: 0.231257  [38400/69949]
loss: 0.202785  [44800/69949]
loss: 0.056275  [51200/69949]
loss: 0.113103  [57600/69949]
loss: 0.190651  [64000/69949]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.162235 

Epoch 6
-------------------------------
loss: 0.216856  [    0/69949]
loss: 0.128555  [ 6400/69949]
loss: 0.096510  [12800/69949]
loss: 0.082956  [19200/69949]
loss: 0.225511  [25600/69949]
loss: 0.108542  [32000/69949]
loss: 0.194063  [38400/69949]
loss: 0.099082  [44800/69949]
loss: 0.298445  [51200/69949]
loss: 0.223015  [57600/69949]
loss: 0.221624  [64000/69949]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.162959 

Epoch 7
-------------------------------
loss: 0.075387  [    0/69949]
loss: 0.068753  [ 6400/69949]
loss: 0.155489  [12800/69949]
loss: 0.193602  [19200/69949]
loss: 0.209575  [25600/69949]
loss: 0.095501  [32000/69949]
loss: 0.111793  [38400/69949]
loss: 0.257338  [44800/69949]
loss: 0.078511  [51200/69949]
loss: 0.143332  [57600/69949]
loss: 0.100165  [64000/69949]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.163375 

Epoch 8
-------------------------------
loss: 0.097926  [    0/69949]
loss: 0.095330  [ 6400/69949]
loss: 0.113792  [12800/69949]
loss: 0.054647  [19200/69949]
loss: 0.138133  [25600/69949]
loss: 0.220469  [32000/69949]
loss: 0.146285  [38400/69949]
loss: 0.111600  [44800/69949]
loss: 0.157354  [51200/69949]
loss: 0.273956  [57600/69949]
loss: 0.172535  [64000/69949]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.164617 

Epoch 9
-------------------------------
loss: 0.182665  [    0/69949]
loss: 0.091489  [ 6400/69949]
loss: 0.097492  [12800/69949]
loss: 0.252176  [19200/69949]
loss: 0.190454  [25600/69949]
loss: 0.103867  [32000/69949]
loss: 0.167955  [38400/69949]
loss: 0.128834  [44800/69949]
loss: 0.229845  [51200/69949]
loss: 0.163825  [57600/69949]
loss: 0.129822  [64000/69949]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.158316 

Epoch 10
-------------------------------
loss: 0.208967  [    0/69949]
loss: 0.129466  [ 6400/69949]
loss: 0.232593  [12800/69949]
loss: 0.152910  [19200/69949]
loss: 0.097699  [25600/69949]
loss: 0.125993  [32000/69949]
loss: 0.087105  [38400/69949]
loss: 0.116164  [44800/69949]
loss: 0.178783  [51200/69949]
loss: 0.166015  [57600/69949]
loss: 0.141620  [64000/69949]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.176348 

Epoch 11
-------------------------------
loss: 0.239686  [    0/69949]
loss: 0.044284  [ 6400/69949]
2022/09/20 17:39:35 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.173553  [19200/70487]
loss: 0.121814  [25600/70487]
loss: 0.098519  [32000/70487]
loss: 0.070024  [38400/70487]
loss: 0.301014  [44800/70487]
loss: 0.124370  [51200/70487]
loss: 0.151525  [57600/70487]
loss: 0.075682  [64000/70487]
loss: 0.162689  [70400/70487]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.198768 

Epoch 8
-------------------------------
loss: 0.179645  [    0/70487]
loss: 0.242250  [ 6400/70487]
loss: 0.173887  [12800/70487]
loss: 0.135294  [19200/70487]
loss: 0.140114  [25600/70487]
loss: 0.126944  [32000/70487]
loss: 0.258632  [38400/70487]
loss: 0.158472  [44800/70487]
loss: 0.100249  [51200/70487]
loss: 0.146921  [57600/70487]
loss: 0.165188  [64000/70487]
loss: 0.139568  [70400/70487]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.209191 

Epoch 9
-------------------------------
loss: 1.713705  [    0/70487]
loss: 0.135966  [ 6400/70487]
loss: 0.114946  [12800/70487]
loss: 0.196626  [19200/70487]
loss: 0.231645  [25600/70487]
loss: 0.200920  [32000/70487]
loss: 0.246356  [38400/70487]
loss: 1.811829  [44800/70487]
loss: 0.108235  [51200/70487]
loss: 0.251163  [57600/70487]
loss: 0.212997  [64000/70487]
loss: 0.154571  [70400/70487]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.205291 

Epoch 10
-------------------------------
loss: 0.153811  [    0/70487]
loss: 1.756702  [ 6400/70487]
loss: 0.237133  [12800/70487]
loss: 0.135505  [19200/70487]
loss: 0.078756  [25600/70487]
loss: 0.219491  [32000/70487]
loss: 0.113101  [38400/70487]
loss: 0.075778  [44800/70487]
loss: 0.135730  [51200/70487]
loss: 0.193887  [57600/70487]
loss: 0.184273  [64000/70487]
loss: 0.145115  [70400/70487]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.190146 

Epoch 11
-------------------------------
loss: 0.054921  [    0/70487]
loss: 0.163363  [ 6400/70487]
loss: 0.220300  [12800/70487]
loss: 0.103737  [19200/70487]
loss: 0.165403  [25600/70487]
loss: 0.210307  [32000/70487]
loss: 0.189305  [38400/70487]
loss: 0.093295  [44800/70487]
loss: 0.164893  [51200/70487]
loss: 0.288068  [57600/70487]
loss: 0.160712  [64000/70487]
loss: 0.204929  [70400/70487]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.208029 

Epoch 12
-------------------------------
loss: 0.119405  [    0/70487]
loss: 0.205877  [ 6400/70487]
loss: 0.116821  [12800/70487]
loss: 0.155905  [19200/70487]
loss: 0.101752  [25600/70487]
loss: 1.743959  [32000/70487]
loss: 0.176224  [38400/70487]
loss: 0.341475  [44800/70487]
loss: 0.098620  [51200/70487]
loss: 0.140811  [57600/70487]
loss: 0.165360  [64000/70487]
loss: 0.150111  [70400/70487]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.204675 

Epoch 13
-------------------------------
loss: 0.066742  [    0/70487]
loss: 0.184549  [ 6400/70487]
loss: 0.224157  [12800/70487]
loss: 0.236982  [19200/70487]
loss: 0.127911  [25600/70487]
loss: 0.172511  [32000/70487]
loss: 0.132665  [38400/70487]
loss: 0.087007  [44800/70487]
loss: 0.183895  [51200/70487]
loss: 0.193915  [57600/70487]
loss: 0.086238  [64000/70487]
loss: 0.067462  [70400/70487]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.191524 

Epoch 14
-------------------------------
loss: 0.119000  [    0/70487]
loss: 0.155093  [ 6400/70487]
loss: 0.116991  [12800/70487]
loss: 0.075637  [19200/70487]
loss: 0.057277  [25600/70487]
loss: 0.128916  [32000/70487]
loss: 0.081823  [38400/70487]
loss: 0.088660  [44800/70487]
loss: 0.171429  [51200/70487]
loss: 0.188072  [57600/70487]
loss: 1.822527  [64000/70487]
loss: 0.207816  [70400/70487]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.191029 

Epoch 15
-------------------------------
loss: 0.126519  [    0/70487]
loss: 0.192174  [ 6400/70487]
loss: 0.177429  [12800/70487]
loss: 0.193974  [19200/70487]
loss: 0.116262  [25600/70487]
loss: 0.145496  [32000/70487]
loss: 0.109784  [38400/70487]
loss: 1.733026  [44800/70487]
loss: 1.693140  [51200/70487]
loss: 0.244325  [57600/70487]
loss: 0.258938  [64000/70487]
loss: 0.115639  [70400/70487]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.190101 

Epoch 16
-------------------------------
loss: 0.145682  [    0/70487]
loss: 0.173191  [ 6400/70487]
loss: 0.193985  [12800/70487]
loss: 0.256904  [19200/70487]
loss: 0.169020  [25600/70487]
loss: 0.156884  [32000/70487]
loss: 0.191311  [38400/70487]
loss: 0.154430  [44800/70487]
loss: 0.231095  [51200/70487]
loss: 0.245111  [57600/70487]
loss: 0.157824  [64000/70487]
loss: 0.152930  [70400/70487]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.209986 

Epoch 17
-------------------------------
loss: 0.120020  [    0/70487]
loss: 0.119844  [ 6400/70487]
loss: 0.173205  [12800/70487]
loss: 0.165414  [19200/70487]
loss: 0.202357  [25600/70487]
loss: 0.150974  [32000/70487]
loss: 0.391521  [38400/70487]
loss: 0.275299  [44800/70487]
loss: 0.220348  [51200/70487]
loss: 0.164538  [57600/70487]
loss: 0.109163  [64000/70487]
loss: 0.118215  [70400/70487]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.199120 

Epoch 18
-------------------------------
loss: 0.104588  [    0/70487]
loss: 0.196033  [ 6400/70487]
loss: 0.141835  [12800/70487]
loss: 0.203362  [19200/70487]
loss: 0.088186  [25600/70487]
loss: 0.105411  [32000/70487]
loss: 0.126423  [38400/70487]
loss: 0.141083  [44800/70487]
loss: 0.097262  [51200/70487]
loss: 0.131497  [57600/70487]
loss: 0.198741  [64000/70487]
loss: 0.175447  [70400/70487]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.195335 

Epoch 19
-------------------------------
loss: 0.292284  [    0/70487]
loss: 0.096389  [ 6400/70487]
loss: 0.097072  [12800/70487]
loss: 0.195980  [19200/70487]
loss: 0.162482  [25600/70487]
loss: 0.164121  [32000/70487]
loss: 0.156808  [38400/70487]
loss: 0.150383  [44800/70487]
loss: 0.114068  [51200/70487]
loss: 0.183985  [57600/70487]
loss: 0.304434  [64000/70487]
loss: 0.269485  [70400/70487]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.190879 

Epoch 20
-------------------------------
loss: 0.169135  [    0/70487]
loss: 0.057038  [ 6400/70487]
loss: 0.102783  [12800/70487]
loss: 0.197463  [19200/70487]
loss: 0.222762  [25600/70487]
loss: 0.150629  [32000/70487]
loss: 0.133465  [38400/70487]
loss: 0.146991  [44800/70487]
loss: 0.208319  [51200/70487]
loss: 0.065099  [57600/70487]
loss: 0.180094  [64000/70487]
loss: 0.246089  [70400/70487]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.190756 

Epoch 21
-------------------------------
loss: 0.102347  [    0/70487]
loss: 0.283438  [ 6400/70487]
loss: 0.105778  [12800/70487]
loss: 0.158954  [19200/70487]
loss: 0.205271  [25600/70487]
loss: 0.187877  [32000/70487]
loss: 0.123423  [38400/70487]
loss: 0.096541  [44800/70487]
loss: 0.061547  [51200/70487]
loss: 0.173352  [57600/70487]
loss: 0.202877  [64000/70487]
loss: 0.178701  [70400/70487]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.183312 

Epoch 22
-------------------------------
loss: 0.147348  [    0/70487]
loss: 0.287351  [ 6400/70487]
loss: 0.088298  [12800/70487]
loss: 0.383189  [19200/70487]
loss: 0.087465  [25600/70487]
loss: 0.147380  [32000/70487]
loss: 0.214884  [38400/70487]
loss: 0.065521  [44800/70487]
loss: 0.246248  [51200/70487]
loss: 0.102677  [57600/70487]
loss: 0.105544  [64000/70487]
loss: 0.320208  [70400/70487]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.198334 

Epoch 23
-------------------------------
loss: 0.145252  [    0/70487]
loss: 0.184333  [ 6400/70487]
loss: 0.213153  [12800/70487]
loss: 0.286601  [19200/70487]
loss: 0.336454  [25600/70487]
loss: 0.100838  [32000/70487]
loss: 0.118688  [38400/70487]
loss: 0.104350  [44800/70487]
loss: 0.263899  [51200/70487]
loss: 0.180787  [57600/70487]
loss: 0.121528  [64000/70487]
loss: 0.071539  [70400/70487]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.182689 

Epoch 24
-------------------------------
loss: 0.061656  [    0/70487]
loss: 0.209362  [ 6400/70487]
loss: 0.070117  [12800/70487]
loss: 0.186508  [19200/70487]
loss: 0.138800  [25600/70487]
loss: 0.135449  [32000/70487]
loss: 0.142203  [38400/70487]
loss: 0.037854  [44800/70487]
loss: 0.199243  [51200/70487]
loss: 0.230342  [57600/70487]
loss: 0.133674  [64000/70487]
loss: 0.146261  [70400/70487]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.193331 

Epoch 25
-------------------------------
loss: 0.138953  [    0/70487]
loss: 0.247781  [ 6400/70487]
loss: 0.156405  [12800/70487]
loss: 0.177815  [19200/70487]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.138543 

Epoch 39
-------------------------------
loss: 0.173669  [    0/70723]
loss: 0.138466  [ 6400/70723]
loss: 0.080173  [12800/70723]
loss: 0.054158  [19200/70723]
loss: 0.182648  [25600/70723]
loss: 0.153624  [32000/70723]
loss: 0.076281  [38400/70723]
loss: 0.142114  [44800/70723]
loss: 0.081242  [51200/70723]
loss: 0.085994  [57600/70723]
loss: 0.040807  [64000/70723]
loss: 0.213344  [70400/70723]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.157928 

Epoch 40
-------------------------------
loss: 0.162980  [    0/70723]
loss: 0.130353  [ 6400/70723]
loss: 0.035375  [12800/70723]
loss: 0.122189  [19200/70723]
loss: 0.129879  [25600/70723]
loss: 0.129417  [32000/70723]
loss: 0.074296  [38400/70723]
loss: 0.080987  [44800/70723]
loss: 0.168928  [51200/70723]
loss: 0.089433  [57600/70723]
loss: 0.061946  [64000/70723]
loss: 0.083861  [70400/70723]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.140581 

Epoch 41
-------------------------------
loss: 0.114619  [    0/70723]
loss: 0.101707  [ 6400/70723]
loss: 0.037610  [12800/70723]
loss: 0.076749  [19200/70723]
loss: 0.035548  [25600/70723]
loss: 0.203166  [32000/70723]
loss: 0.094792  [38400/70723]
loss: 0.099296  [44800/70723]
loss: 0.185840  [51200/70723]
loss: 0.098916  [57600/70723]
loss: 0.070509  [64000/70723]
loss: 0.039802  [70400/70723]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.141664 

Epoch 42
-------------------------------
loss: 0.090557  [    0/70723]
loss: 0.187259  [ 6400/70723]
loss: 0.101243  [12800/70723]
loss: 0.063987  [19200/70723]
loss: 0.113508  [25600/70723]
loss: 0.156047  [32000/70723]
loss: 0.212678  [38400/70723]
loss: 0.057847  [44800/70723]
loss: 0.021143  [51200/70723]
loss: 0.089467  [57600/70723]
loss: 0.185711  [64000/70723]
loss: 0.254324  [70400/70723]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.139822 

Epoch 43
-------------------------------
loss: 0.097380  [    0/70723]
loss: 0.097625  [ 6400/70723]
loss: 0.130287  [12800/70723]
loss: 0.060252  [19200/70723]
loss: 0.076695  [25600/70723]
loss: 0.122445  [32000/70723]
loss: 0.049722  [38400/70723]
loss: 0.096118  [44800/70723]
loss: 0.106525  [51200/70723]
loss: 0.101978  [57600/70723]
loss: 0.201791  [64000/70723]
loss: 0.103075  [70400/70723]
Test Error: 
 Accuracy: 89.1%, Avg loss: 0.289496 

Epoch 44
-------------------------------
loss: 0.332124  [    0/70723]
loss: 0.150653  [ 6400/70723]
loss: 0.057659  [12800/70723]
loss: 0.063583  [19200/70723]
loss: 0.072752  [25600/70723]
loss: 0.041706  [32000/70723]
loss: 0.040197  [38400/70723]
loss: 0.071771  [44800/70723]
loss: 0.158373  [51200/70723]
loss: 0.078918  [57600/70723]
loss: 0.057131  [64000/70723]
loss: 0.034326  [70400/70723]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.142397 

Epoch 45
-------------------------------
loss: 0.120402  [    0/70723]
loss: 0.100261  [ 6400/70723]
loss: 0.056366  [12800/70723]
loss: 0.045687  [19200/70723]
loss: 0.051047  [25600/70723]
loss: 0.125352  [32000/70723]
loss: 0.063352  [38400/70723]
loss: 0.124602  [44800/70723]
loss: 0.094903  [51200/70723]
loss: 0.149649  [57600/70723]
loss: 0.161043  [64000/70723]
loss: 0.050981  [70400/70723]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.140725 

Epoch 46
-------------------------------
loss: 0.100867  [    0/70723]
loss: 0.076800  [ 6400/70723]
loss: 0.159689  [12800/70723]
loss: 0.051669  [19200/70723]
loss: 0.122642  [25600/70723]
loss: 0.067468  [32000/70723]
loss: 0.135252  [38400/70723]
loss: 0.138451  [44800/70723]
loss: 0.060155  [51200/70723]
loss: 0.041240  [57600/70723]
loss: 0.119763  [64000/70723]
loss: 0.058891  [70400/70723]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.145256 

Epoch 47
-------------------------------
loss: 0.061048  [    0/70723]
loss: 0.203508  [ 6400/70723]
loss: 0.070703  [12800/70723]
loss: 0.114487  [19200/70723]
loss: 0.150776  [25600/70723]
loss: 0.082544  [32000/70723]
loss: 0.061608  [38400/70723]
loss: 0.145581  [44800/70723]
loss: 0.083607  [51200/70723]
loss: 0.127986  [57600/70723]
loss: 0.070867  [64000/70723]
loss: 0.035391  [70400/70723]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.143021 

Epoch 48
-------------------------------
loss: 0.091416  [    0/70723]
loss: 0.068867  [ 6400/70723]
loss: 0.041413  [12800/70723]
loss: 0.184405  [19200/70723]
loss: 0.161101  [25600/70723]
loss: 0.214239  [32000/70723]
loss: 0.126939  [38400/70723]
loss: 0.104914  [44800/70723]
loss: 0.067571  [51200/70723]
loss: 1.718676  [57600/70723]
loss: 0.105737  [64000/70723]
loss: 0.099609  [70400/70723]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.134425 

Epoch 49
-------------------------------
loss: 0.045547  [    0/70723]
loss: 0.142848  [ 6400/70723]
loss: 0.117125  [12800/70723]
loss: 0.186011  [19200/70723]
loss: 0.127472  [25600/70723]
loss: 0.092643  [32000/70723]
loss: 0.065366  [38400/70723]
loss: 0.044478  [44800/70723]
loss: 0.171517  [51200/70723]
loss: 0.149108  [57600/70723]
loss: 0.057196  [64000/70723]
loss: 0.121291  [70400/70723]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.149399 

Epoch 50
-------------------------------
loss: 0.107500  [    0/70723]
loss: 0.102076  [ 6400/70723]
loss: 0.113240  [12800/70723]
loss: 0.052277  [19200/70723]
loss: 0.096202  [25600/70723]
loss: 0.085187  [32000/70723]
loss: 0.107514  [38400/70723]
loss: 0.149385  [44800/70723]
loss: 0.153297  [51200/70723]
loss: 0.072647  [57600/70723]
loss: 0.235968  [64000/70723]
loss: 0.100539  [70400/70723]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.135898 

Epoch 1
-------------------------------
loss: 0.764875  [    0/70533]
loss: 0.266016  [ 6400/70533]
loss: 0.188361  [12800/70533]
loss: 0.194099  [19200/70533]
loss: 0.130302  [25600/70533]
loss: 0.161617  [32000/70533]
loss: 0.223972  [38400/70533]
loss: 0.211570  [44800/70533]
loss: 0.187946  [51200/70533]
loss: 0.221535  [57600/70533]
loss: 1.881475  [64000/70533]
loss: 0.113124  [70400/70533]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.304759 

Epoch 2
-------------------------------
loss: 0.123045  [    0/70533]
loss: 0.229302  [ 6400/70533]
loss: 0.241619  [12800/70533]
loss: 0.109497  [19200/70533]
loss: 0.242437  [25600/70533]
loss: 0.229377  [32000/70533]
loss: 0.212091  [38400/70533]
loss: 0.165730  [44800/70533]
loss: 0.117735  [51200/70533]
loss: 0.104187  [57600/70533]
loss: 0.103122  [64000/70533]
loss: 1.757650  [70400/70533]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.289751 

Epoch 3
-------------------------------
loss: 0.174895  [    0/70533]
loss: 0.301725  [ 6400/70533]
loss: 0.155649  [12800/70533]
loss: 0.150284  [19200/70533]
loss: 0.190581  [25600/70533]
loss: 0.263030  [32000/70533]
loss: 0.119210  [38400/70533]
loss: 0.212634  [44800/70533]
loss: 0.229814  [51200/70533]
loss: 0.208996  [57600/70533]
loss: 0.183292  [64000/70533]
loss: 0.201714  [70400/70533]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.279643 

Epoch 4
-------------------------------
loss: 0.174993  [    0/70533]
loss: 0.146872  [ 6400/70533]
loss: 0.108461  [12800/70533]
loss: 0.198270  [19200/70533]
loss: 0.172152  [25600/70533]
loss: 0.131587  [32000/70533]
loss: 0.148618  [38400/70533]
loss: 0.155782  [44800/70533]
loss: 0.149627  [51200/70533]
loss: 0.176267  [57600/70533]
loss: 0.272007  [64000/70533]
loss: 0.108154  [70400/70533]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.181960 

Epoch 5
-------------------------------
loss: 0.125827  [    0/70533]
loss: 0.138888  [ 6400/70533]
loss: 0.140562  [12800/70533]
loss: 0.071781  [19200/70533]
loss: 0.140191  [25600/70533]
loss: 0.186514  [32000/70533]
loss: 0.144739  [38400/70533]
loss: 0.115018  [44800/70533]
loss: 0.112429  [51200/70533]
loss: 0.083201  [57600/70533]
loss: 0.204067  [64000/70533]
loss: 0.264637  [70400/70533]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.204112 

Epoch 6
-------------------------------
loss: 0.184515  [    0/70533]
loss: 0.142418  [ 6400/70533]
loss: 0.075072  [12800/70533]
loss: 0.114079  [19200/70533]
loss: 0.247017  [25600/70533]
loss: 1.699880  [32000/70533]
loss: 0.121261  [38400/70533]
loss: 0.192655  [44800/70533]
loss: 0.239206  [51200/70533]
loss: 0.205124  [57600/70533]
loss: 0.277320  [64000/70533]
loss: 0.121966  [70400/70533]
loss: 0.161759  [12800/70717]
loss: 0.171585  [19200/70717]
loss: 0.075506  [25600/70717]
loss: 0.079659  [32000/70717]
loss: 0.074137  [38400/70717]
loss: 0.088782  [44800/70717]
loss: 0.094689  [51200/70717]
loss: 0.133617  [57600/70717]
loss: 0.149683  [64000/70717]
loss: 0.154074  [70400/70717]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.129221 

Epoch 8
-------------------------------
loss: 0.091559  [    0/70717]
loss: 0.156438  [ 6400/70717]
loss: 0.066431  [12800/70717]
loss: 0.027726  [19200/70717]
loss: 0.041918  [25600/70717]
loss: 0.137484  [32000/70717]
loss: 0.081675  [38400/70717]
loss: 0.078009  [44800/70717]
loss: 0.075363  [51200/70717]
loss: 0.117995  [57600/70717]
loss: 0.140349  [64000/70717]
loss: 0.033774  [70400/70717]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.130193 

Epoch 9
-------------------------------
loss: 0.087692  [    0/70717]
loss: 0.090735  [ 6400/70717]
loss: 0.117309  [12800/70717]
loss: 0.178667  [19200/70717]
loss: 0.074150  [25600/70717]
loss: 0.124869  [32000/70717]
loss: 0.080221  [38400/70717]
loss: 0.059376  [44800/70717]
loss: 0.116778  [51200/70717]
loss: 0.207320  [57600/70717]
loss: 0.105998  [64000/70717]
loss: 0.099382  [70400/70717]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.134646 

Epoch 10
-------------------------------
loss: 0.039371  [    0/70717]
loss: 0.138287  [ 6400/70717]
loss: 0.039516  [12800/70717]
loss: 0.081404  [19200/70717]
loss: 0.084624  [25600/70717]
loss: 0.207568  [32000/70717]
loss: 0.105258  [38400/70717]
loss: 0.090951  [44800/70717]
loss: 0.225125  [51200/70717]
loss: 0.147299  [57600/70717]
loss: 0.050033  [64000/70717]
loss: 0.041439  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.122463 

Epoch 11
-------------------------------
loss: 0.093900  [    0/70717]
loss: 0.074106  [ 6400/70717]
loss: 0.084876  [12800/70717]
loss: 0.120451  [19200/70717]
loss: 0.099402  [25600/70717]
loss: 0.051370  [32000/70717]
loss: 0.077314  [38400/70717]
loss: 0.116154  [44800/70717]
loss: 0.105744  [51200/70717]
loss: 0.067616  [57600/70717]
loss: 0.049165  [64000/70717]
loss: 0.142782  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.123465 

Epoch 12
-------------------------------
loss: 0.052189  [    0/70717]
loss: 0.047555  [ 6400/70717]
loss: 0.070990  [12800/70717]
loss: 0.063126  [19200/70717]
loss: 0.030633  [25600/70717]
loss: 0.133103  [32000/70717]
loss: 0.089284  [38400/70717]
loss: 0.123590  [44800/70717]
loss: 0.097702  [51200/70717]
loss: 0.168494  [57600/70717]
loss: 0.076405  [64000/70717]
loss: 0.212108  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.125387 

Epoch 13
-------------------------------
loss: 0.092359  [    0/70717]
loss: 0.023555  [ 6400/70717]
loss: 0.119387  [12800/70717]
loss: 0.093913  [19200/70717]
loss: 0.105912  [25600/70717]
loss: 0.055291  [32000/70717]
loss: 0.106981  [38400/70717]
loss: 0.139602  [44800/70717]
loss: 0.059954  [51200/70717]
loss: 0.129542  [57600/70717]
loss: 0.068416  [64000/70717]
loss: 0.049202  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.118701 

Epoch 14
-------------------------------
loss: 0.097776  [    0/70717]
loss: 0.058341  [ 6400/70717]
loss: 0.118772  [12800/70717]
loss: 0.127251  [19200/70717]
loss: 0.145912  [25600/70717]
loss: 0.081271  [32000/70717]
loss: 0.028552  [38400/70717]
loss: 0.193807  [44800/70717]
loss: 0.100401  [51200/70717]
loss: 0.036164  [57600/70717]
loss: 0.065415  [64000/70717]
loss: 0.082154  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.126993 

Epoch 15
-------------------------------
loss: 0.070823  [    0/70717]
loss: 0.092435  [ 6400/70717]
loss: 0.198277  [12800/70717]
loss: 0.048329  [19200/70717]
loss: 0.051029  [25600/70717]
loss: 0.100529  [32000/70717]
loss: 0.060281  [38400/70717]
loss: 0.109812  [44800/70717]
loss: 0.067523  [51200/70717]
loss: 0.158196  [57600/70717]
loss: 0.090682  [64000/70717]
loss: 0.119816  [70400/70717]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.133776 

Epoch 16
-------------------------------
loss: 0.170471  [    0/70717]
loss: 0.092860  [ 6400/70717]
loss: 0.105536  [12800/70717]
loss: 0.030535  [19200/70717]
loss: 0.064229  [25600/70717]
loss: 0.195915  [32000/70717]
loss: 0.103210  [38400/70717]
loss: 0.096088  [44800/70717]
loss: 0.035773  [51200/70717]
loss: 0.093787  [57600/70717]
loss: 0.064902  [64000/70717]
loss: 0.047114  [70400/70717]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.126402 

Epoch 17
-------------------------------
loss: 0.183077  [    0/70717]
loss: 0.053257  [ 6400/70717]
loss: 0.098141  [12800/70717]
loss: 0.127314  [19200/70717]
loss: 0.074546  [25600/70717]
loss: 0.061456  [32000/70717]
loss: 0.092042  [38400/70717]
loss: 0.048019  [44800/70717]
loss: 0.057090  [51200/70717]
loss: 0.054426  [57600/70717]
loss: 0.035420  [64000/70717]
loss: 0.111402  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.129114 

Epoch 18
-------------------------------
loss: 0.136292  [    0/70717]
loss: 0.080472  [ 6400/70717]
loss: 0.061118  [12800/70717]
loss: 0.097094  [19200/70717]
loss: 0.070714  [25600/70717]
loss: 0.090831  [32000/70717]
loss: 0.057782  [38400/70717]
loss: 0.057863  [44800/70717]
loss: 0.090693  [51200/70717]
loss: 0.077663  [57600/70717]
loss: 0.086971  [64000/70717]
loss: 0.069520  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.120104 

Epoch 19
-------------------------------
loss: 0.124228  [    0/70717]
loss: 0.057990  [ 6400/70717]
loss: 0.064490  [12800/70717]
loss: 0.132696  [19200/70717]
loss: 0.058682  [25600/70717]
loss: 0.130000  [32000/70717]
loss: 0.113741  [38400/70717]
loss: 0.169427  [44800/70717]
loss: 0.081586  [51200/70717]
loss: 0.104813  [57600/70717]
loss: 0.023578  [64000/70717]
loss: 0.055527  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.118892 

Epoch 20
-------------------------------
loss: 0.056106  [    0/70717]
loss: 0.021752  [ 6400/70717]
loss: 0.184722  [12800/70717]
loss: 0.088468  [19200/70717]
loss: 0.119044  [25600/70717]
loss: 0.050129  [32000/70717]
loss: 0.097787  [38400/70717]
loss: 0.043339  [44800/70717]
loss: 0.216806  [51200/70717]
loss: 0.149369  [57600/70717]
loss: 0.349218  [64000/70717]
loss: 0.150012  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.124577 

Epoch 21
-------------------------------
loss: 0.073134  [    0/70717]
loss: 0.040052  [ 6400/70717]
loss: 0.118858  [12800/70717]
loss: 0.062126  [19200/70717]
loss: 0.057527  [25600/70717]
loss: 0.183968  [32000/70717]
loss: 0.089604  [38400/70717]
loss: 0.058682  [44800/70717]
loss: 0.147323  [51200/70717]
loss: 0.172993  [57600/70717]
loss: 0.149341  [64000/70717]
loss: 0.181398  [70400/70717]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.126525 

Epoch 22
-------------------------------
loss: 0.198422  [    0/70717]
loss: 0.176276  [ 6400/70717]
loss: 0.032853  [12800/70717]
loss: 0.114380  [19200/70717]
loss: 0.090992  [25600/70717]
loss: 0.051720  [32000/70717]
loss: 0.098692  [38400/70717]
loss: 0.033285  [44800/70717]
loss: 0.168629  [51200/70717]
loss: 0.174197  [57600/70717]
loss: 0.077134  [64000/70717]
loss: 0.124755  [70400/70717]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.134162 

Epoch 23
-------------------------------
loss: 0.023918  [    0/70717]
loss: 0.051512  [ 6400/70717]
loss: 0.075172  [12800/70717]
loss: 0.081370  [19200/70717]
loss: 0.053859  [25600/70717]
loss: 0.081985  [32000/70717]
loss: 0.110909  [38400/70717]
loss: 0.109720  [44800/70717]
loss: 0.028827  [51200/70717]
loss: 0.068342  [57600/70717]
loss: 0.062946  [64000/70717]
loss: 0.069406  [70400/70717]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.130804 

Epoch 24
-------------------------------
loss: 0.039665  [    0/70717]
loss: 0.139602  [ 6400/70717]
loss: 0.204410  [12800/70717]
loss: 0.159883  [19200/70717]
loss: 0.169339  [25600/70717]
loss: 0.073579  [32000/70717]
loss: 0.076111  [38400/70717]
loss: 0.125810  [44800/70717]
loss: 0.122715  [51200/70717]
loss: 0.202690  [57600/70717]
loss: 0.108744  [64000/70717]
loss: 0.055881  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.129134 

Epoch 25
-------------------------------
loss: 0.078243  [    0/70717]
loss: 0.087677  [ 6400/70717]
loss: 0.050619  [12800/70717]
loss: 0.154624  [38400/69926]
loss: 0.211384  [44800/69926]
loss: 0.139865  [51200/69926]
loss: 0.060705  [57600/69926]
loss: 0.179285  [64000/69926]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.184907 

Epoch 46
-------------------------------
loss: 0.311300  [    0/69926]
loss: 0.187679  [ 6400/69926]
loss: 0.070520  [12800/69926]
loss: 0.194968  [19200/69926]
loss: 0.100498  [25600/69926]
loss: 0.087906  [32000/69926]
loss: 0.210197  [38400/69926]
loss: 0.073904  [44800/69926]
loss: 0.174988  [51200/69926]
loss: 0.044894  [57600/69926]
loss: 0.121341  [64000/69926]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.169079 

Epoch 47
-------------------------------
loss: 0.098529  [    0/69926]
loss: 0.195494  [ 6400/69926]
loss: 0.097521  [12800/69926]
loss: 0.135872  [19200/69926]
loss: 0.046548  [25600/69926]
loss: 0.192076  [32000/69926]
loss: 0.165792  [38400/69926]
loss: 0.134069  [44800/69926]
loss: 0.203575  [51200/69926]
loss: 0.091339  [57600/69926]
loss: 0.128551  [64000/69926]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.155841 

Epoch 48
-------------------------------
loss: 0.062391  [    0/69926]
loss: 0.119455  [ 6400/69926]
loss: 0.169158  [12800/69926]
loss: 0.193695  [19200/69926]
loss: 0.307556  [25600/69926]
loss: 0.045249  [32000/69926]
loss: 0.270921  [38400/69926]
loss: 0.220295  [44800/69926]
loss: 0.082134  [51200/69926]
loss: 0.075710  [57600/69926]
loss: 0.121423  [64000/69926]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.166045 

Epoch 49
-------------------------------
loss: 0.218305  [    0/69926]
loss: 0.180231  [ 6400/69926]
loss: 0.092838  [12800/69926]
loss: 0.103810  [19200/69926]
loss: 0.082876  [25600/69926]
loss: 0.199732  [32000/69926]
loss: 0.123388  [38400/69926]
loss: 0.151154  [44800/69926]
loss: 0.181691  [51200/69926]
loss: 0.247939  [57600/69926]
loss: 0.086678  [64000/69926]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.159801 

Epoch 50
-------------------------------
loss: 0.162696  [    0/69926]
loss: 0.177676  [ 6400/69926]
loss: 0.186069  [12800/69926]
loss: 0.151768  [19200/69926]
loss: 0.126384  [25600/69926]
loss: 0.194441  [32000/69926]
loss: 0.231974  [38400/69926]
loss: 0.214677  [44800/69926]
loss: 0.094668  [51200/69926]
loss: 0.142418  [57600/69926]
loss: 0.088691  [64000/69926]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.162173 

Epoch 1
-------------------------------
loss: 0.758440  [    0/70070]
loss: 0.381172  [ 6400/70070]
loss: 0.356644  [12800/70070]
loss: 0.289154  [19200/70070]
loss: 0.391799  [25600/70070]
loss: 0.190748  [32000/70070]
loss: 0.370333  [38400/70070]
loss: 0.195662  [44800/70070]
loss: 0.191492  [51200/70070]
loss: 0.243154  [57600/70070]
loss: 0.226078  [64000/70070]
Test Error: 
 Accuracy: 90.9%, Avg loss: 0.223801 

Epoch 2
-------------------------------
loss: 0.151926  [    0/70070]
loss: 0.206311  [ 6400/70070]
loss: 0.302459  [12800/70070]
loss: 0.256273  [19200/70070]
loss: 0.192926  [25600/70070]
loss: 0.260448  [32000/70070]
loss: 0.168724  [38400/70070]
loss: 0.188305  [44800/70070]
loss: 0.198869  [51200/70070]
loss: 0.152605  [57600/70070]
loss: 0.227462  [64000/70070]
Test Error: 
 Accuracy: 91.0%, Avg loss: 0.215965 

Epoch 3
-------------------------------
loss: 0.199748  [    0/70070]
loss: 0.151201  [ 6400/70070]
loss: 0.240141  [12800/70070]
loss: 0.189554  [19200/70070]
loss: 0.115568  [25600/70070]
loss: 0.090685  [32000/70070]
loss: 0.113607  [38400/70070]
loss: 0.176437  [44800/70070]
loss: 0.164890  [51200/70070]
loss: 0.172762  [57600/70070]
loss: 0.236744  [64000/70070]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.191039 

Epoch 4
-------------------------------
loss: 0.253342  [    0/70070]
loss: 0.272255  [ 6400/70070]
loss: 0.267207  [12800/70070]
loss: 0.141326  [19200/70070]
loss: 0.240381  [25600/70070]
loss: 0.246691  [32000/70070]
loss: 0.222037  [38400/70070]
loss: 0.255074  [44800/70070]
loss: 0.393083  [51200/70070]
loss: 0.196152  [57600/70070]
loss: 0.243110  [64000/70070]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.196750 

Epoch 5
-------------------------------
loss: 0.169066  [    0/70070]
loss: 0.075995  [ 6400/70070]
loss: 0.100735  [12800/70070]
loss: 0.198242  [19200/70070]
loss: 0.258397  [25600/70070]
loss: 0.195799  [32000/70070]
loss: 0.219571  [38400/70070]
loss: 0.150671  [44800/70070]
loss: 0.257805  [51200/70070]
loss: 0.241304  [57600/70070]
loss: 0.321467  [64000/70070]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.188982 

Epoch 6
-------------------------------
loss: 0.315271  [    0/70070]
loss: 0.187947  [ 6400/70070]
loss: 0.227543  [12800/70070]
loss: 0.201702  [19200/70070]
loss: 0.197658  [25600/70070]
loss: 0.232472  [32000/70070]
loss: 0.205288  [38400/70070]
loss: 0.096934  [44800/70070]
loss: 0.192902  [51200/70070]
loss: 0.260631  [57600/70070]
loss: 0.212630  [64000/70070]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.186959 

Epoch 7
-------------------------------
loss: 0.120629  [    0/70070]
loss: 0.131841  [ 6400/70070]
loss: 0.199104  [12800/70070]
loss: 0.161556  [19200/70070]
loss: 0.094690  [25600/70070]
loss: 0.218160  [32000/70070]
loss: 0.221065  [38400/70070]
loss: 0.164296  [44800/70070]
loss: 0.218125  [51200/70070]
loss: 0.209007  [57600/70070]
loss: 0.254557  [64000/70070]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.201921 

Epoch 8
-------------------------------
loss: 0.142879  [    0/70070]
loss: 0.297494  [ 6400/70070]
loss: 0.261565  [12800/70070]
loss: 0.400849  [19200/70070]
loss: 0.129344  [25600/70070]
loss: 0.291740  [32000/70070]
loss: 0.170407  [38400/70070]
loss: 0.377444  [44800/70070]
loss: 0.237732  [51200/70070]
loss: 0.117050  [57600/70070]
loss: 0.134949  [64000/70070]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.200565 

Epoch 9
-------------------------------
loss: 0.235968  [    0/70070]
loss: 0.359260  [ 6400/70070]
loss: 0.141225  [12800/70070]
loss: 0.205630  [19200/70070]
loss: 0.174716  [25600/70070]
loss: 0.266834  [32000/70070]
loss: 0.089560  [38400/70070]
loss: 0.147256  [44800/70070]
loss: 0.203159  [51200/70070]
loss: 0.129963  [57600/70070]
loss: 0.086786  [64000/70070]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.179128 

Epoch 10
-------------------------------
loss: 0.161926  [    0/70070]
loss: 0.275601  [ 6400/70070]
loss: 0.172734  [12800/70070]
loss: 0.139087  [19200/70070]
loss: 0.100904  [25600/70070]
loss: 0.207543  [32000/70070]
loss: 0.203922  [38400/70070]
loss: 0.163914  [44800/70070]
loss: 0.159382  [51200/70070]
loss: 0.227108  [57600/70070]
loss: 0.191651  [64000/70070]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.175009 

Epoch 11
-------------------------------
loss: 0.175091  [    0/70070]
loss: 0.114707  [ 6400/70070]
loss: 0.195750  [12800/70070]
loss: 0.119268  [19200/70070]
loss: 0.219747  [25600/70070]
loss: 0.178187  [32000/70070]
loss: 0.259615  [38400/70070]
loss: 0.141173  [44800/70070]
loss: 0.147562  [51200/70070]
loss: 0.165029  [57600/70070]
loss: 0.185506  [64000/70070]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.190957 

Epoch 12
-------------------------------
loss: 0.166809  [    0/70070]
loss: 0.155977  [ 6400/70070]
loss: 0.238435  [12800/70070]
loss: 0.205983  [19200/70070]
loss: 0.186795  [25600/70070]
loss: 0.154550  [32000/70070]
loss: 0.203640  [38400/70070]
loss: 0.125560  [44800/70070]
loss: 0.179625  [51200/70070]
loss: 0.220242  [57600/70070]
loss: 0.127480  [64000/70070]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.190265 

Epoch 13
-------------------------------
loss: 0.143294  [    0/70070]
loss: 0.139729  [ 6400/70070]
loss: 0.189552  [12800/70070]
loss: 0.138578  [19200/70070]
loss: 0.151797  [25600/70070]
loss: 0.196261  [32000/70070]
loss: 0.232535  [38400/70070]
loss: 0.159508  [44800/70070]
loss: 0.151271  [51200/70070]
loss: 0.236019  [57600/70070]
loss: 0.145526  [64000/70070]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.188598 

Epoch 14
-------------------------------
loss: 0.132562  [    0/70070]
loss: 0.115327  [ 6400/70070]
loss: 0.186896  [12800/70070]
loss: 0.182154  [19200/70070]
loss: 0.186376  [25600/70070]
loss: 0.122051  [32000/70070]
loss: 0.235525  [38400/70070]
loss: 0.229439  [44800/70070]
loss: 0.127528  [51200/70070]
loss: 0.341592  [57600/70070]
loss: 0.173181  [64000/70070]
loss: 0.140472  [64000/69867]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.187009 

Epoch 42
-------------------------------
loss: 0.161492  [    0/69867]
loss: 0.210186  [ 6400/69867]
loss: 0.148545  [12800/69867]
loss: 0.111125  [19200/69867]
loss: 0.141889  [25600/69867]
loss: 0.149845  [32000/69867]
loss: 0.145903  [38400/69867]
loss: 0.310605  [44800/69867]
loss: 0.095667  [51200/69867]
loss: 0.254940  [57600/69867]
loss: 0.300369  [64000/69867]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.176840 

Epoch 43
-------------------------------
loss: 0.100259  [    0/69867]
loss: 0.124243  [ 6400/69867]
loss: 0.237820  [12800/69867]
loss: 0.204317  [19200/69867]
loss: 0.126915  [25600/69867]
loss: 0.165819  [32000/69867]
loss: 0.195878  [38400/69867]
loss: 0.120410  [44800/69867]
loss: 0.237830  [51200/69867]
loss: 0.172477  [57600/69867]
loss: 0.195510  [64000/69867]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.179866 

Epoch 44
-------------------------------
loss: 0.196886  [    0/69867]
loss: 0.116038  [ 6400/69867]
loss: 0.202610  [12800/69867]
loss: 0.182047  [19200/69867]
loss: 0.194591  [25600/69867]
loss: 0.208688  [32000/69867]
loss: 0.147004  [38400/69867]
loss: 0.131175  [44800/69867]
loss: 0.277171  [51200/69867]
loss: 1.656288  [57600/69867]
loss: 0.176952  [64000/69867]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.169944 

Epoch 45
-------------------------------
loss: 0.163071  [    0/69867]
loss: 0.284398  [ 6400/69867]
loss: 0.227724  [12800/69867]
loss: 0.104507  [19200/69867]
loss: 0.086630  [25600/69867]
loss: 0.199035  [32000/69867]
loss: 0.260236  [38400/69867]
loss: 0.200652  [44800/69867]
loss: 0.324012  [51200/69867]
loss: 0.240230  [57600/69867]
loss: 0.125607  [64000/69867]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.175760 

Epoch 46
-------------------------------
loss: 0.253252  [    0/69867]
loss: 0.170944  [ 6400/69867]
loss: 0.266195  [12800/69867]
loss: 0.189262  [19200/69867]
loss: 0.198480  [25600/69867]
loss: 0.185752  [32000/69867]
loss: 0.152656  [38400/69867]
loss: 0.104660  [44800/69867]
loss: 0.146270  [51200/69867]
loss: 0.139624  [57600/69867]
loss: 0.194098  [64000/69867]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.180106 

Epoch 47
-------------------------------
loss: 0.288689  [    0/69867]
loss: 0.199304  [ 6400/69867]
loss: 0.196532  [12800/69867]
loss: 0.169571  [19200/69867]
loss: 0.092379  [25600/69867]
loss: 0.063045  [32000/69867]
loss: 0.155841  [38400/69867]
loss: 0.219906  [44800/69867]
loss: 0.106829  [51200/69867]
loss: 0.083205  [57600/69867]
loss: 0.126410  [64000/69867]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.201031 

Epoch 48
-------------------------------
loss: 0.268719  [    0/69867]
loss: 0.063701  [ 6400/69867]
loss: 0.224134  [12800/69867]
loss: 0.112037  [19200/69867]
loss: 0.122529  [25600/69867]
loss: 0.214363  [32000/69867]
loss: 0.072911  [38400/69867]
loss: 0.275406  [44800/69867]
loss: 0.147707  [51200/69867]
loss: 0.406488  [57600/69867]
loss: 0.277020  [64000/69867]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.191572 

Epoch 49
-------------------------------
loss: 0.198260  [    0/69867]
loss: 0.084985  [ 6400/69867]
loss: 0.170590  [12800/69867]
loss: 0.289478  [19200/69867]
loss: 0.149099  [25600/69867]
loss: 0.242768  [32000/69867]
loss: 0.148095  [38400/69867]
loss: 0.075381  [44800/69867]
loss: 0.223543  [51200/69867]
loss: 0.176398  [57600/69867]
loss: 0.188765  [64000/69867]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.211810 

Epoch 50
-------------------------------
loss: 0.188705  [    0/69867]
loss: 0.243205  [ 6400/69867]
loss: 0.058615  [12800/69867]
loss: 0.193318  [19200/69867]
loss: 0.148256  [25600/69867]
loss: 0.225510  [32000/69867]
loss: 0.200304  [38400/69867]
loss: 0.103497  [44800/69867]
loss: 0.130710  [51200/69867]
loss: 0.351764  [57600/69867]
loss: 0.098403  [64000/69867]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.171289 

Epoch 1
-------------------------------
loss: 0.780622  [    0/70245]
loss: 0.329910  [ 6400/70245]
loss: 0.435636  [12800/70245]
loss: 0.228411  [19200/70245]
loss: 0.267126  [25600/70245]
loss: 0.310022  [32000/70245]
loss: 0.225491  [38400/70245]
loss: 0.290553  [44800/70245]
loss: 0.179816  [51200/70245]
loss: 0.147162  [57600/70245]
loss: 0.242344  [64000/70245]
Test Error: 
 Accuracy: 89.9%, Avg loss: 0.249414 

Epoch 2
-------------------------------
loss: 0.223781  [    0/70245]
loss: 0.235030  [ 6400/70245]
loss: 0.215321  [12800/70245]
loss: 0.183156  [19200/70245]
loss: 0.187872  [25600/70245]
loss: 0.236168  [32000/70245]
loss: 0.198042  [38400/70245]
loss: 0.386161  [44800/70245]
loss: 0.217505  [51200/70245]
loss: 0.256032  [57600/70245]
loss: 0.309507  [64000/70245]
Test Error: 
 Accuracy: 91.2%, Avg loss: 0.219444 

Epoch 3
-------------------------------
loss: 0.190505  [    0/70245]
loss: 0.123486  [ 6400/70245]
loss: 0.200760  [12800/70245]
loss: 0.197202  [19200/70245]
loss: 0.367212  [25600/70245]
loss: 0.125598  [32000/70245]
loss: 0.327563  [38400/70245]
loss: 0.210365  [44800/70245]
loss: 0.208956  [51200/70245]
loss: 0.175463  [57600/70245]
loss: 0.173551  [64000/70245]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.219235 

Epoch 4
-------------------------------
loss: 0.117000  [    0/70245]
loss: 0.317692  [ 6400/70245]
loss: 0.213332  [12800/70245]
loss: 0.250924  [19200/70245]
loss: 0.159240  [25600/70245]
loss: 0.202175  [32000/70245]
loss: 0.142842  [38400/70245]
loss: 0.272866  [44800/70245]
loss: 0.183649  [51200/70245]
loss: 0.282948  [57600/70245]
loss: 0.170333  [64000/70245]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.200943 

Epoch 5
-------------------------------
loss: 0.250248  [    0/70245]
loss: 0.125693  [ 6400/70245]
loss: 0.333568  [12800/70245]
loss: 0.357302  [19200/70245]
loss: 0.210883  [25600/70245]
loss: 0.289054  [32000/70245]
loss: 0.245275  [38400/70245]
loss: 0.265683  [44800/70245]
loss: 0.278396  [51200/70245]
loss: 0.149451  [57600/70245]
loss: 0.121924  [64000/70245]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.201810 

Epoch 6
-------------------------------
loss: 0.156235  [    0/70245]
loss: 0.195057  [ 6400/70245]
loss: 0.200582  [12800/70245]
loss: 0.157614  [19200/70245]
loss: 0.171304  [25600/70245]
loss: 0.186397  [32000/70245]
loss: 0.187433  [38400/70245]
loss: 0.227135  [44800/70245]
loss: 0.195528  [51200/70245]
loss: 0.168685  [57600/70245]
loss: 0.215942  [64000/70245]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.208608 

Epoch 7
-------------------------------
loss: 0.190840  [    0/70245]
loss: 0.251649  [ 6400/70245]
loss: 0.121851  [12800/70245]
loss: 0.126761  [19200/70245]
loss: 0.217134  [25600/70245]
loss: 0.175804  [32000/70245]
loss: 0.172788  [38400/70245]
loss: 0.176362  [44800/70245]
loss: 0.354813  [51200/70245]
loss: 0.140632  [57600/70245]
loss: 0.153970  [64000/70245]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.182965 

Epoch 8
-------------------------------
loss: 0.081630  [    0/70245]
loss: 0.311288  [ 6400/70245]
loss: 0.128866  [12800/70245]
loss: 0.177423  [19200/70245]
loss: 0.339549  [25600/70245]
loss: 0.161472  [32000/70245]
loss: 0.284543  [38400/70245]
loss: 0.212371  [44800/70245]
loss: 0.076534  [51200/70245]
loss: 0.209400  [57600/70245]
loss: 0.267874  [64000/70245]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.200472 

Epoch 9
-------------------------------
loss: 0.182927  [    0/70245]
loss: 0.098545  [ 6400/70245]
loss: 0.159605  [12800/70245]
loss: 0.166871  [19200/70245]
loss: 0.155297  [25600/70245]
loss: 0.123332  [32000/70245]
loss: 0.173287  [38400/70245]
loss: 0.212256  [44800/70245]
loss: 0.130564  [51200/70245]
loss: 0.236364  [57600/70245]
loss: 0.177434  [64000/70245]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.177213 

Epoch 10
-------------------------------
loss: 0.200489  [    0/70245]
loss: 0.211812  [ 6400/70245]
loss: 0.125148  [12800/70245]
loss: 0.291350  [19200/70245]
loss: 0.190065  [25600/70245]
loss: 0.190284  [32000/70245]
loss: 0.116696  [38400/70245]
loss: 0.375260  [44800/70245]
loss: 0.160924  [51200/70245]
loss: 0.274485  [57600/70245]
loss: 0.190220  [64000/70245]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.179890 

Epoch 11
-------------------------------
loss: 0.103160  [    0/70245]
loss: 0.297733  [64000/70204]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.174636 

Epoch 42
-------------------------------
loss: 0.092756  [    0/70204]
loss: 0.170844  [ 6400/70204]
loss: 0.109593  [12800/70204]
loss: 0.046782  [19200/70204]
loss: 0.200851  [25600/70204]
loss: 0.220815  [32000/70204]
loss: 0.124854  [38400/70204]
loss: 0.129371  [44800/70204]
loss: 0.236342  [51200/70204]
loss: 0.144932  [57600/70204]
loss: 0.251355  [64000/70204]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170895 

Epoch 43
-------------------------------
loss: 1.708945  [    0/70204]
loss: 0.126174  [ 6400/70204]
loss: 0.173838  [12800/70204]
loss: 0.092460  [19200/70204]
loss: 0.175004  [25600/70204]
loss: 0.161392  [32000/70204]
loss: 0.109400  [38400/70204]
loss: 0.155900  [44800/70204]
loss: 0.110567  [51200/70204]
loss: 0.153940  [57600/70204]
loss: 0.049489  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174552 

Epoch 44
-------------------------------
loss: 0.093827  [    0/70204]
loss: 0.204017  [ 6400/70204]
loss: 0.184417  [12800/70204]
loss: 0.196376  [19200/70204]
loss: 0.133665  [25600/70204]
loss: 0.115304  [32000/70204]
loss: 0.165157  [38400/70204]
loss: 0.081118  [44800/70204]
loss: 0.258745  [51200/70204]
loss: 0.231474  [57600/70204]
loss: 0.139994  [64000/70204]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.192878 

Epoch 45
-------------------------------
loss: 0.239113  [    0/70204]
loss: 0.183522  [ 6400/70204]
loss: 0.087820  [12800/70204]
loss: 0.211223  [19200/70204]
loss: 0.091744  [25600/70204]
loss: 0.078025  [32000/70204]
loss: 0.149788  [38400/70204]
loss: 0.114898  [44800/70204]
loss: 0.112679  [51200/70204]
loss: 0.113857  [57600/70204]
loss: 0.203366  [64000/70204]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.179902 

Epoch 46
-------------------------------
loss: 0.049511  [    0/70204]
loss: 0.108680  [ 6400/70204]
loss: 0.218963  [12800/70204]
loss: 0.264018  [19200/70204]
loss: 0.157724  [25600/70204]
loss: 0.105442  [32000/70204]
loss: 0.179893  [38400/70204]
loss: 0.194816  [44800/70204]
loss: 0.075868  [51200/70204]
loss: 0.113284  [57600/70204]
loss: 0.178403  [64000/70204]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.180588 

Epoch 47
-------------------------------
loss: 0.116449  [    0/70204]
loss: 0.080100  [ 6400/70204]
loss: 0.113581  [12800/70204]
loss: 0.147091  [19200/70204]
loss: 0.165669  [25600/70204]
loss: 0.209390  [32000/70204]
loss: 0.297396  [38400/70204]
loss: 0.202251  [44800/70204]
loss: 0.213165  [51200/70204]
loss: 0.124229  [57600/70204]
loss: 0.164298  [64000/70204]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.172499 

Epoch 48
-------------------------------
loss: 0.264501  [    0/70204]
loss: 0.157581  [ 6400/70204]
loss: 0.152044  [12800/70204]
loss: 0.068138  [19200/70204]
loss: 0.167604  [25600/70204]
loss: 0.110391  [32000/70204]
loss: 0.200185  [38400/70204]
loss: 0.162275  [44800/70204]
loss: 0.142755  [51200/70204]
loss: 0.128638  [57600/70204]
loss: 0.224523  [64000/70204]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.176957 

Epoch 49
-------------------------------
loss: 0.133164  [    0/70204]
loss: 0.157136  [ 6400/70204]
loss: 0.167638  [12800/70204]
loss: 0.165204  [19200/70204]
loss: 0.143150  [25600/70204]
loss: 0.173524  [32000/70204]
loss: 0.109018  [38400/70204]
loss: 0.230819  [44800/70204]
loss: 0.141086  [51200/70204]
loss: 0.156750  [57600/70204]
loss: 0.204754  [64000/70204]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.170904 

Epoch 50
-------------------------------
loss: 0.163307  [    0/70204]
loss: 0.078766  [ 6400/70204]
loss: 0.045539  [12800/70204]
loss: 0.158955  [19200/70204]
loss: 0.205799  [25600/70204]
loss: 0.221259  [32000/70204]
loss: 0.063886  [38400/70204]
loss: 0.173742  [44800/70204]
loss: 0.267686  [51200/70204]
loss: 0.105867  [57600/70204]
loss: 0.122416  [64000/70204]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180135 

Epoch 1
-------------------------------
loss: 0.742971  [    0/69698]
loss: 0.364987  [ 6400/69698]
loss: 0.333079  [12800/69698]
loss: 0.245626  [19200/69698]
loss: 0.169986  [25600/69698]
loss: 0.266065  [32000/69698]
loss: 0.224901  [38400/69698]
loss: 0.080012  [44800/69698]
loss: 0.161980  [51200/69698]
loss: 0.161518  [57600/69698]
loss: 1.763589  [64000/69698]
Test Error: 
 Accuracy: 91.1%, Avg loss: 0.227906 

Epoch 2
-------------------------------
loss: 0.206589  [    0/69698]
loss: 0.152831  [ 6400/69698]
loss: 0.234164  [12800/69698]
loss: 0.112397  [19200/69698]
loss: 0.218430  [25600/69698]
loss: 0.219412  [32000/69698]
loss: 0.116408  [38400/69698]
loss: 0.303348  [44800/69698]
loss: 0.177991  [51200/69698]
loss: 0.172284  [57600/69698]
loss: 0.125280  [64000/69698]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.206191 

Epoch 3
-------------------------------
loss: 0.120293  [    0/69698]
loss: 0.147121  [ 6400/69698]
loss: 0.249542  [12800/69698]
loss: 0.169986  [19200/69698]
loss: 0.152453  [25600/69698]
loss: 0.247955  [32000/69698]
loss: 0.191466  [38400/69698]
loss: 0.145540  [44800/69698]
loss: 0.175536  [51200/69698]
loss: 0.217305  [57600/69698]
loss: 0.106796  [64000/69698]
Test Error: 
 Accuracy: 90.6%, Avg loss: 0.235436 

Epoch 4
-------------------------------
loss: 0.235166  [    0/69698]
loss: 0.161109  [ 6400/69698]
loss: 0.194828  [12800/69698]
loss: 0.342065  [19200/69698]
loss: 0.296245  [25600/69698]
loss: 0.110712  [32000/69698]
loss: 0.230148  [38400/69698]
loss: 0.182163  [44800/69698]
loss: 0.171359  [51200/69698]
loss: 0.207941  [57600/69698]
loss: 0.135150  [64000/69698]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.199188 

Epoch 5
-------------------------------
loss: 0.171327  [    0/69698]
loss: 0.179279  [ 6400/69698]
loss: 0.204888  [12800/69698]
loss: 0.077580  [19200/69698]
loss: 0.137101  [25600/69698]
loss: 0.263840  [32000/69698]
loss: 0.261087  [38400/69698]
loss: 0.125019  [44800/69698]
loss: 0.095498  [51200/69698]
loss: 0.078186  [57600/69698]
loss: 0.197732  [64000/69698]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.192824 

Epoch 6
-------------------------------
loss: 0.255131  [    0/69698]
loss: 0.167073  [ 6400/69698]
loss: 0.133028  [12800/69698]
loss: 0.154875  [19200/69698]
loss: 0.228939  [25600/69698]
loss: 0.196425  [32000/69698]
loss: 0.281086  [38400/69698]
loss: 0.226799  [44800/69698]
loss: 0.152418  [51200/69698]
loss: 0.155418  [57600/69698]
loss: 0.189869  [64000/69698]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.183168 

Epoch 7
-------------------------------
loss: 0.156468  [    0/69698]
loss: 0.119968  [ 6400/69698]
loss: 0.146664  [12800/69698]
loss: 0.098974  [19200/69698]
loss: 0.147523  [25600/69698]
loss: 0.205322  [32000/69698]
loss: 0.130578  [38400/69698]
loss: 0.143014  [44800/69698]
loss: 0.327209  [51200/69698]
loss: 0.099293  [57600/69698]
loss: 0.230335  [64000/69698]
Test Error: 
 Accuracy: 84.9%, Avg loss: 0.380652 

Epoch 8
-------------------------------
loss: 0.594086  [    0/69698]
loss: 0.059897  [ 6400/69698]
loss: 0.205046  [12800/69698]
loss: 0.133791  [19200/69698]
loss: 0.155179  [25600/69698]
loss: 0.112069  [32000/69698]
loss: 0.313067  [38400/69698]
loss: 0.168378  [44800/69698]
loss: 0.317424  [51200/69698]
loss: 0.178307  [57600/69698]
loss: 0.163857  [64000/69698]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.197743 

Epoch 9
-------------------------------
loss: 0.343185  [    0/69698]
loss: 0.144875  [ 6400/69698]
loss: 0.155825  [12800/69698]
loss: 0.147182  [19200/69698]
loss: 0.044806  [25600/69698]
loss: 0.090908  [32000/69698]
loss: 0.090688  [38400/69698]
loss: 0.108840  [44800/69698]
loss: 0.255558  [51200/69698]
loss: 0.268408  [57600/69698]
loss: 0.167600  [64000/69698]
Test Error: 
 Accuracy: 86.6%, Avg loss: 0.373096 

Epoch 10
-------------------------------
loss: 0.666377  [    0/69698]
loss: 0.144280  [ 6400/69698]
loss: 0.199785  [12800/69698]
loss: 0.091399  [19200/69698]
loss: 0.136888  [25600/69698]
loss: 0.079302  [32000/69698]
loss: 0.229071  [38400/69698]
loss: 0.122859  [44800/69698]
loss: 0.173530  [51200/69698]
loss: 0.260414  [57600/69698]
loss: 0.094837  [64000/69698]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.187035 

Epoch 11
-------------------------------
loss: 0.135032  [    0/69698]
loss: 0.106791  [32000/70326]
loss: 0.106752  [38400/70326]
loss: 0.087509  [44800/70326]
loss: 0.178786  [51200/70326]
loss: 0.163261  [57600/70326]
loss: 0.064823  [64000/70326]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.170291 

Epoch 46
-------------------------------
loss: 0.162911  [    0/70326]
loss: 0.179075  [ 6400/70326]
loss: 0.080773  [12800/70326]
loss: 0.085097  [19200/70326]
loss: 0.207693  [25600/70326]
loss: 0.152462  [32000/70326]
loss: 0.182759  [38400/70326]
loss: 0.135730  [44800/70326]
loss: 0.130948  [51200/70326]
loss: 0.152319  [57600/70326]
loss: 0.125738  [64000/70326]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.171841 

Epoch 47
-------------------------------
loss: 0.086582  [    0/70326]
loss: 0.089763  [ 6400/70326]
loss: 0.175446  [12800/70326]
loss: 0.060620  [19200/70326]
loss: 0.156954  [25600/70326]
loss: 0.071142  [32000/70326]
loss: 0.105304  [38400/70326]
loss: 0.114849  [44800/70326]
loss: 0.104696  [51200/70326]
loss: 0.194395  [57600/70326]
loss: 0.097094  [64000/70326]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.179116 

Epoch 48
-------------------------------
loss: 0.137496  [    0/70326]
loss: 0.178898  [ 6400/70326]
loss: 0.126198  [12800/70326]
loss: 0.119763  [19200/70326]
loss: 0.130970  [25600/70326]
loss: 0.120813  [32000/70326]
loss: 0.215255  [38400/70326]
loss: 0.105479  [44800/70326]
loss: 0.112796  [51200/70326]
loss: 0.122000  [57600/70326]
loss: 0.149606  [64000/70326]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.186838 

Epoch 49
-------------------------------
loss: 0.184241  [    0/70326]
loss: 0.102076  [ 6400/70326]
loss: 0.101670  [12800/70326]
loss: 0.187533  [19200/70326]
loss: 0.098138  [25600/70326]
loss: 0.135438  [32000/70326]
loss: 0.181684  [38400/70326]
loss: 0.185957  [44800/70326]
loss: 0.128169  [51200/70326]
loss: 0.191959  [57600/70326]
loss: 0.092251  [64000/70326]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.172124 

Epoch 50
-------------------------------
loss: 0.126699  [    0/70326]
loss: 0.097189  [ 6400/70326]
loss: 0.053299  [12800/70326]
loss: 0.038952  [19200/70326]
loss: 0.270517  [25600/70326]
loss: 0.239302  [32000/70326]
loss: 0.116625  [38400/70326]
loss: 0.191132  [44800/70326]
loss: 0.094315  [51200/70326]
loss: 0.100119  [57600/70326]
loss: 0.166276  [64000/70326]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.171632 

Epoch 1
-------------------------------
loss: 0.753519  [    0/69473]
loss: 0.234388  [ 6400/69473]
loss: 0.261455  [12800/69473]
loss: 0.143670  [19200/69473]
loss: 0.265465  [25600/69473]
loss: 0.320995  [32000/69473]
loss: 0.154746  [38400/69473]
loss: 0.185050  [44800/69473]
loss: 0.276541  [51200/69473]
loss: 0.108619  [57600/69473]
loss: 0.207209  [64000/69473]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.214006 

Epoch 2
-------------------------------
loss: 0.097339  [    0/69473]
loss: 0.250508  [ 6400/69473]
loss: 0.177447  [12800/69473]
loss: 0.192832  [19200/69473]
loss: 0.177528  [25600/69473]
loss: 0.091634  [32000/69473]
loss: 0.259216  [38400/69473]
loss: 0.147586  [44800/69473]
loss: 0.212469  [51200/69473]
loss: 0.071654  [57600/69473]
loss: 0.269913  [64000/69473]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.199577 

Epoch 3
-------------------------------
loss: 0.166652  [    0/69473]
loss: 0.149838  [ 6400/69473]
loss: 0.165196  [12800/69473]
loss: 0.144570  [19200/69473]
loss: 0.242430  [25600/69473]
loss: 0.180905  [32000/69473]
loss: 0.146546  [38400/69473]
loss: 0.072484  [44800/69473]
loss: 0.171309  [51200/69473]
loss: 0.201845  [57600/69473]
loss: 0.169549  [64000/69473]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.184233 

Epoch 4
-------------------------------
loss: 0.145901  [    0/69473]
loss: 0.281353  [ 6400/69473]
loss: 0.141659  [12800/69473]
loss: 0.198838  [19200/69473]
loss: 0.185254  [25600/69473]
loss: 0.225726  [32000/69473]
loss: 0.112426  [38400/69473]
loss: 0.103912  [44800/69473]
loss: 0.155508  [51200/69473]
loss: 0.170813  [57600/69473]
loss: 0.301503  [64000/69473]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.180101 

Epoch 5
-------------------------------
loss: 0.177711  [    0/69473]
loss: 0.077774  [ 6400/69473]
loss: 0.223891  [12800/69473]
loss: 0.152893  [19200/69473]
loss: 0.090074  [25600/69473]
loss: 0.187895  [32000/69473]
loss: 0.153307  [38400/69473]
loss: 0.072837  [44800/69473]
loss: 0.140501  [51200/69473]
loss: 0.125620  [57600/69473]
loss: 0.096692  [64000/69473]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.170311 

Epoch 6
-------------------------------
loss: 0.146085  [    0/69473]
loss: 0.172099  [ 6400/69473]
loss: 0.118481  [12800/69473]
loss: 0.141453  [19200/69473]
loss: 0.134526  [25600/69473]
loss: 0.222805  [32000/69473]
loss: 0.217854  [38400/69473]
loss: 0.103432  [44800/69473]
loss: 0.145217  [51200/69473]
loss: 0.217883  [57600/69473]
loss: 0.111886  [64000/69473]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.194621 

Epoch 7
-------------------------------
loss: 0.224927  [    0/69473]
loss: 0.180736  [ 6400/69473]
loss: 0.192890  [12800/69473]
loss: 0.268699  [19200/69473]
loss: 0.145716  [25600/69473]
loss: 0.128846  [32000/69473]
loss: 0.252669  [38400/69473]
loss: 0.128788  [44800/69473]
loss: 0.073272  [51200/69473]
loss: 0.216447  [57600/69473]
loss: 0.099629  [64000/69473]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171541 

Epoch 8
-------------------------------
loss: 0.086889  [    0/69473]
loss: 0.034139  [ 6400/69473]
loss: 0.114847  [12800/69473]
loss: 0.306671  [19200/69473]
loss: 0.162891  [25600/69473]
loss: 0.198405  [32000/69473]
loss: 0.130124  [38400/69473]
loss: 0.398467  [44800/69473]
loss: 0.087543  [51200/69473]
loss: 0.150750  [57600/69473]
loss: 0.231182  [64000/69473]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.175235 

Epoch 9
-------------------------------
loss: 0.095809  [    0/69473]
loss: 0.091179  [ 6400/69473]
loss: 0.102216  [12800/69473]
loss: 0.084469  [19200/69473]
loss: 0.211148  [25600/69473]
loss: 0.238917  [32000/69473]
loss: 0.115380  [38400/69473]
loss: 0.112417  [44800/69473]
loss: 0.195820  [51200/69473]
loss: 0.157011  [57600/69473]
loss: 0.107416  [64000/69473]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.168790 

Epoch 10
-------------------------------
loss: 0.173016  [    0/69473]
loss: 0.085371  [ 6400/69473]
loss: 0.222494  [12800/69473]
loss: 0.155855  [19200/69473]
loss: 0.231407  [25600/69473]
loss: 0.143048  [32000/69473]
loss: 0.126994  [38400/69473]
loss: 0.175546  [44800/69473]
loss: 0.169810  [51200/69473]
loss: 0.114137  [57600/69473]
loss: 0.147473  [64000/69473]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174503 

Epoch 11
-------------------------------
loss: 0.191419  [    0/69473]
loss: 0.099558  [ 6400/69473]
loss: 0.186649  [12800/69473]
loss: 0.069694  [19200/69473]
loss: 0.149384  [25600/69473]
loss: 0.163207  [32000/69473]
loss: 0.130554  [38400/69473]
loss: 0.128330  [44800/69473]
loss: 0.085544  [51200/69473]
loss: 0.201440  [57600/69473]
loss: 0.166918  [64000/69473]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.172340 

Epoch 12
-------------------------------
loss: 0.102345  [    0/69473]
loss: 0.159641  [ 6400/69473]
loss: 0.128582  [12800/69473]
loss: 0.217965  [19200/69473]
loss: 0.025297  [25600/69473]
loss: 0.148268  [32000/69473]
loss: 0.219273  [38400/69473]
loss: 0.185333  [44800/69473]
loss: 0.054179  [51200/69473]
loss: 0.145207  [57600/69473]
loss: 0.097041  [64000/69473]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.169719 

Epoch 13
-------------------------------
loss: 0.116861  [    0/69473]
loss: 0.163159  [ 6400/69473]
loss: 0.042914  [12800/69473]
loss: 0.082647  [19200/69473]
loss: 0.092371  [25600/69473]
loss: 0.105186  [32000/69473]
loss: 0.146164  [38400/69473]
loss: 0.068652  [44800/69473]
loss: 0.164953  [51200/69473]
loss: 0.119872  [57600/69473]
loss: 0.255294  [64000/69473]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180009 

Epoch 14
-------------------------------
loss: 0.198043  [    0/69473]
loss: 0.181012  [ 6400/69473]
loss: 0.068746  [12800/69473]
loss: 0.080243  [19200/69473]
loss: 0.234261  [25600/69473]
loss: 0.235772  [32000/69473]
loss: 0.235781  [38400/69473]
loss: 0.190679  [44800/69473]
loss: 0.087720  [51200/69473]
loss: 0.062557  [57600/69473]
loss: 0.078188  [44800/70677]
loss: 0.250719  [51200/70677]
loss: 0.205472  [57600/70677]
loss: 0.156236  [64000/70677]
loss: 0.196466  [70400/70677]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.226412 

Epoch 11
-------------------------------
loss: 0.135542  [    0/70677]
loss: 0.233873  [ 6400/70677]
loss: 0.185089  [12800/70677]
loss: 0.152864  [19200/70677]
loss: 0.175131  [25600/70677]
loss: 0.083420  [32000/70677]
loss: 0.081701  [38400/70677]
loss: 0.255242  [44800/70677]
loss: 0.115723  [51200/70677]
loss: 0.226229  [57600/70677]
loss: 0.323956  [64000/70677]
loss: 0.072043  [70400/70677]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.227132 

Epoch 12
-------------------------------
loss: 0.084288  [    0/70677]
loss: 0.143548  [ 6400/70677]
loss: 0.194432  [12800/70677]
loss: 0.079024  [19200/70677]
loss: 0.082905  [25600/70677]
loss: 0.158944  [32000/70677]
loss: 0.126336  [38400/70677]
loss: 0.187365  [44800/70677]
loss: 0.177924  [51200/70677]
loss: 0.208508  [57600/70677]
loss: 0.220811  [64000/70677]
loss: 0.094325  [70400/70677]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.228857 

Epoch 13
-------------------------------
loss: 0.122151  [    0/70677]
loss: 0.128214  [ 6400/70677]
loss: 0.273286  [12800/70677]
loss: 0.187827  [19200/70677]
loss: 0.139658  [25600/70677]
loss: 0.126615  [32000/70677]
loss: 0.179526  [38400/70677]
loss: 0.061429  [44800/70677]
loss: 0.143651  [51200/70677]
loss: 0.142227  [57600/70677]
loss: 0.157211  [64000/70677]
loss: 0.168103  [70400/70677]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.246756 

Epoch 14
-------------------------------
loss: 0.450083  [    0/70677]
loss: 0.189942  [ 6400/70677]
loss: 0.198375  [12800/70677]
loss: 0.113431  [19200/70677]
loss: 0.222364  [25600/70677]
loss: 0.157091  [32000/70677]
loss: 0.066895  [38400/70677]
loss: 0.151226  [44800/70677]
loss: 0.225709  [51200/70677]
loss: 0.208869  [57600/70677]
loss: 0.119546  [64000/70677]
loss: 0.216451  [70400/70677]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.240322 

Epoch 15
-------------------------------
loss: 0.114855  [    0/70677]
loss: 0.129744  [ 6400/70677]
loss: 0.064107  [12800/70677]
loss: 0.136636  [19200/70677]
loss: 0.102462  [25600/70677]
loss: 0.165774  [32000/70677]
loss: 0.282851  [38400/70677]
loss: 0.093032  [44800/70677]
loss: 0.163695  [51200/70677]
loss: 0.254377  [57600/70677]
loss: 0.274934  [64000/70677]
loss: 0.238356  [70400/70677]
Test Error: 
 Accuracy: 90.0%, Avg loss: 0.283544 

Epoch 16
-------------------------------
loss: 0.133209  [    0/70677]
loss: 0.152389  [ 6400/70677]
loss: 0.171696  [12800/70677]
loss: 0.175865  [19200/70677]
loss: 0.126374  [25600/70677]
loss: 0.126020  [32000/70677]
loss: 0.176552  [38400/70677]
loss: 0.178643  [44800/70677]
loss: 0.133749  [51200/70677]
loss: 0.142336  [57600/70677]
loss: 0.178836  [64000/70677]
loss: 0.084258  [70400/70677]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.221305 

Epoch 17
-------------------------------
loss: 0.111512  [    0/70677]
loss: 0.161486  [ 6400/70677]
loss: 0.225054  [12800/70677]
loss: 0.157472  [19200/70677]
loss: 0.085293  [25600/70677]
loss: 0.086892  [32000/70677]
loss: 0.066557  [38400/70677]
loss: 0.213151  [44800/70677]
loss: 0.105851  [51200/70677]
loss: 0.134572  [57600/70677]
loss: 0.339298  [64000/70677]
loss: 0.093852  [70400/70677]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.224389 

Epoch 18
-------------------------------
loss: 0.162637  [    0/70677]
loss: 0.162480  [ 6400/70677]
loss: 0.139177  [12800/70677]
loss: 0.060826  [19200/70677]
loss: 0.115978  [25600/70677]
loss: 0.149527  [32000/70677]
loss: 0.155430  [38400/70677]
loss: 0.329907  [44800/70677]
loss: 0.153382  [51200/70677]
loss: 0.106912  [57600/70677]
loss: 0.095869  [64000/70677]
loss: 0.100011  [70400/70677]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.232756 

Epoch 19
-------------------------------
loss: 0.180621  [    0/70677]
loss: 0.189215  [ 6400/70677]
loss: 0.206457  [12800/70677]
loss: 0.176317  [19200/70677]
loss: 0.137168  [25600/70677]
loss: 0.171339  [32000/70677]
loss: 0.127064  [38400/70677]
loss: 0.244694  [44800/70677]
loss: 0.091451  [51200/70677]
loss: 0.176358  [57600/70677]
loss: 0.104098  [64000/70677]
loss: 0.296660  [70400/70677]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.221134 

Epoch 20
-------------------------------
loss: 0.200175  [    0/70677]
loss: 0.238314  [ 6400/70677]
loss: 0.347686  [12800/70677]
loss: 0.165386  [19200/70677]
loss: 0.322878  [25600/70677]
loss: 0.056027  [32000/70677]
loss: 0.124011  [38400/70677]
loss: 1.676100  [44800/70677]
loss: 0.126244  [51200/70677]
loss: 0.207765  [57600/70677]
loss: 0.160174  [64000/70677]
loss: 0.109690  [70400/70677]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.223856 

Epoch 21
-------------------------------
loss: 0.229770  [    0/70677]
loss: 0.185031  [ 6400/70677]
loss: 0.140407  [12800/70677]
loss: 0.162460  [19200/70677]
loss: 0.102013  [25600/70677]
loss: 0.184632  [32000/70677]
loss: 0.125109  [38400/70677]
loss: 0.343391  [44800/70677]
loss: 0.220130  [51200/70677]
loss: 0.163907  [57600/70677]
loss: 0.207519  [64000/70677]
loss: 0.107435  [70400/70677]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.239473 

Epoch 22
-------------------------------
loss: 0.281067  [    0/70677]
loss: 0.146914  [ 6400/70677]
loss: 0.109717  [12800/70677]
loss: 0.247337  [19200/70677]
loss: 0.162551  [25600/70677]
loss: 0.219846  [32000/70677]
loss: 0.107950  [38400/70677]
loss: 0.158800  [44800/70677]
loss: 0.075118  [51200/70677]
loss: 0.185380  [57600/70677]
loss: 0.150522  [64000/70677]
loss: 0.215450  [70400/70677]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.223714 

Epoch 23
-------------------------------
loss: 0.142748  [    0/70677]
loss: 0.094774  [ 6400/70677]
loss: 0.110678  [12800/70677]
loss: 0.281373  [19200/70677]
loss: 0.210286  [25600/70677]
loss: 0.199695  [32000/70677]
loss: 0.192163  [38400/70677]
loss: 0.243689  [44800/70677]
loss: 0.164002  [51200/70677]
loss: 0.111143  [57600/70677]
loss: 0.109831  [64000/70677]
loss: 0.098537  [70400/70677]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.229285 

Epoch 24
-------------------------------
loss: 0.152452  [    0/70677]
loss: 0.085321  [ 6400/70677]
loss: 0.404444  [12800/70677]
loss: 0.088015  [19200/70677]
loss: 0.265121  [25600/70677]
loss: 0.123172  [32000/70677]
loss: 0.064403  [38400/70677]
loss: 0.203073  [44800/70677]
loss: 0.116206  [51200/70677]
loss: 0.240427  [57600/70677]
loss: 0.097362  [64000/70677]
loss: 0.162296  [70400/70677]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.223809 

Epoch 25
-------------------------------
loss: 0.153922  [    0/70677]
loss: 0.076072  [ 6400/70677]
loss: 0.125795  [12800/70677]
loss: 0.141545  [19200/70677]
loss: 0.141057  [25600/70677]
loss: 0.133794  [32000/70677]
loss: 0.229402  [38400/70677]
loss: 0.057356  [44800/70677]
loss: 0.066863  [51200/70677]
loss: 0.141513  [57600/70677]
loss: 0.078869  [64000/70677]
loss: 0.155456  [70400/70677]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.219479 

Epoch 26
-------------------------------
loss: 0.066974  [    0/70677]
loss: 0.154314  [ 6400/70677]
loss: 0.069677  [12800/70677]
loss: 0.144604  [19200/70677]
loss: 0.128005  [25600/70677]
loss: 0.188047  [32000/70677]
loss: 0.291186  [38400/70677]
loss: 0.182731  [44800/70677]
loss: 0.316974  [51200/70677]
loss: 0.126451  [57600/70677]
loss: 1.664026  [64000/70677]
loss: 0.149195  [70400/70677]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.214464 

Epoch 27
-------------------------------
loss: 0.079584  [    0/70677]
loss: 0.157607  [ 6400/70677]
loss: 0.140774  [12800/70677]
loss: 1.746559  [19200/70677]
loss: 0.170462  [25600/70677]
loss: 0.239898  [32000/70677]
loss: 0.164806  [38400/70677]
loss: 0.135557  [44800/70677]
loss: 0.153231  [51200/70677]
loss: 0.258105  [57600/70677]
loss: 0.140046  [64000/70677]
loss: 0.177810  [70400/70677]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.220992 

Epoch 28
-------------------------------
loss: 0.083982  [    0/70677]
loss: 0.168779  [ 6400/70677]
loss: 0.066620  [12800/70677]
loss: 0.125516  [19200/70677]
loss: 0.168430  [25600/70677]
loss: 0.319194  [32000/70677]
loss: 0.227434  [38400/70677]
loss: 0.159956  [44800/70677]
loss: 0.147576  [12800/70523]
loss: 0.073865  [19200/70523]
loss: 0.323494  [25600/70523]
loss: 0.184475  [32000/70523]
loss: 0.188918  [38400/70523]
loss: 0.163399  [44800/70523]
loss: 0.109140  [51200/70523]
loss: 0.110516  [57600/70523]
loss: 0.123123  [64000/70523]
loss: 0.134357  [70400/70523]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.183088 

Epoch 8
-------------------------------
loss: 0.128150  [    0/70523]
loss: 0.148134  [ 6400/70523]
loss: 0.121211  [12800/70523]
loss: 0.163375  [19200/70523]
loss: 0.124079  [25600/70523]
loss: 0.276595  [32000/70523]
loss: 0.296494  [38400/70523]
loss: 0.217393  [44800/70523]
loss: 0.232989  [51200/70523]
loss: 0.126955  [57600/70523]
loss: 0.264196  [64000/70523]
loss: 0.254238  [70400/70523]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.185443 

Epoch 9
-------------------------------
loss: 0.088113  [    0/70523]
loss: 0.245670  [ 6400/70523]
loss: 0.231844  [12800/70523]
loss: 0.147555  [19200/70523]
loss: 0.136076  [25600/70523]
loss: 0.191542  [32000/70523]
loss: 0.094642  [38400/70523]
loss: 0.155600  [44800/70523]
loss: 0.250700  [51200/70523]
loss: 0.095356  [57600/70523]
loss: 0.147168  [64000/70523]
loss: 0.208760  [70400/70523]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.184145 

Epoch 10
-------------------------------
loss: 0.174430  [    0/70523]
loss: 0.156123  [ 6400/70523]
loss: 0.153211  [12800/70523]
loss: 0.110870  [19200/70523]
loss: 0.211691  [25600/70523]
loss: 0.099131  [32000/70523]
loss: 0.320095  [38400/70523]
loss: 0.204445  [44800/70523]
loss: 0.300349  [51200/70523]
loss: 0.166910  [57600/70523]
loss: 0.152624  [64000/70523]
loss: 0.299407  [70400/70523]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.185221 

Epoch 11
-------------------------------
loss: 0.145850  [    0/70523]
loss: 0.116326  [ 6400/70523]
loss: 0.234365  [12800/70523]
loss: 0.258907  [19200/70523]
loss: 0.090204  [25600/70523]
loss: 0.152823  [32000/70523]
loss: 0.130977  [38400/70523]
loss: 0.158724  [44800/70523]
loss: 0.254264  [51200/70523]
loss: 0.168441  [57600/70523]
loss: 0.180403  [64000/70523]
loss: 0.095848  [70400/70523]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174026 

Epoch 12
-------------------------------
loss: 1.675614  [    0/70523]
loss: 0.111839  [ 6400/70523]
loss: 0.140975  [12800/70523]
loss: 0.087611  [19200/70523]
loss: 0.105054  [25600/70523]
loss: 0.161106  [32000/70523]
loss: 0.087343  [38400/70523]
loss: 0.134935  [44800/70523]
loss: 0.090403  [51200/70523]
loss: 0.096057  [57600/70523]
loss: 0.097062  [64000/70523]
loss: 0.181817  [70400/70523]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.192041 

Epoch 13
-------------------------------
loss: 0.158280  [    0/70523]
loss: 0.143687  [ 6400/70523]
loss: 0.193246  [12800/70523]
loss: 0.219765  [19200/70523]
loss: 0.217810  [25600/70523]
loss: 0.164830  [32000/70523]
loss: 0.162993  [38400/70523]
loss: 0.187134  [44800/70523]
loss: 0.116042  [51200/70523]
loss: 0.197300  [57600/70523]
loss: 0.206828  [64000/70523]
loss: 0.303149  [70400/70523]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177191 

Epoch 14
-------------------------------
loss: 0.180993  [    0/70523]
loss: 0.146750  [ 6400/70523]
loss: 0.098671  [12800/70523]
loss: 0.324852  [19200/70523]
loss: 0.114417  [25600/70523]
loss: 0.241224  [32000/70523]
loss: 0.108417  [38400/70523]
loss: 0.187121  [44800/70523]
loss: 0.127475  [51200/70523]
loss: 0.152671  [57600/70523]
loss: 0.195964  [64000/70523]
loss: 0.055940  [70400/70523]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.179958 

Epoch 15
-------------------------------
loss: 0.112564  [    0/70523]
loss: 0.183322  [ 6400/70523]
loss: 0.186489  [12800/70523]
loss: 0.178870  [19200/70523]
loss: 0.319875  [25600/70523]
loss: 0.087167  [32000/70523]
loss: 0.069783  [38400/70523]
loss: 0.166637  [44800/70523]
loss: 0.293325  [51200/70523]
loss: 0.141853  [57600/70523]
loss: 0.098344  [64000/70523]
loss: 0.200721  [70400/70523]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.178769 

Epoch 16
-------------------------------
loss: 0.102429  [    0/70523]
loss: 0.094094  [ 6400/70523]
loss: 0.172096  [12800/70523]
loss: 0.291222  [19200/70523]
loss: 0.141722  [25600/70523]
loss: 0.153069  [32000/70523]
loss: 0.214685  [38400/70523]
loss: 0.175286  [44800/70523]
loss: 0.087592  [51200/70523]
loss: 0.069366  [57600/70523]
loss: 0.161278  [64000/70523]
loss: 0.079420  [70400/70523]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.176919 

Epoch 17
-------------------------------
loss: 0.168862  [    0/70523]
loss: 0.123860  [ 6400/70523]
loss: 0.184165  [12800/70523]
loss: 0.141424  [19200/70523]
loss: 0.135933  [25600/70523]
loss: 0.199961  [32000/70523]
loss: 0.081219  [38400/70523]
loss: 0.222005  [44800/70523]
loss: 0.143386  [51200/70523]
loss: 0.126743  [57600/70523]
loss: 0.174961  [64000/70523]
loss: 0.217074  [70400/70523]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.184725 

Epoch 18
-------------------------------
loss: 0.154235  [    0/70523]
loss: 0.119227  [ 6400/70523]
loss: 0.250572  [12800/70523]
loss: 0.107349  [19200/70523]
loss: 0.173930  [25600/70523]
loss: 0.184641  [32000/70523]
loss: 0.175923  [38400/70523]
loss: 0.228300  [44800/70523]
loss: 0.138387  [51200/70523]
loss: 0.090641  [57600/70523]
loss: 0.233871  [64000/70523]
loss: 0.151133  [70400/70523]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.177523 

Epoch 19
-------------------------------
loss: 0.183770  [    0/70523]
loss: 0.138947  [ 6400/70523]
loss: 0.143463  [12800/70523]
loss: 0.280795  [19200/70523]
loss: 0.156265  [25600/70523]
loss: 0.223154  [32000/70523]
loss: 0.103731  [38400/70523]
loss: 0.177799  [44800/70523]
loss: 0.169027  [51200/70523]
loss: 0.256685  [57600/70523]
loss: 0.156628  [64000/70523]
loss: 0.207564  [70400/70523]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.172101 

Epoch 20
-------------------------------
loss: 0.092800  [    0/70523]
loss: 0.146196  [ 6400/70523]
loss: 0.070993  [12800/70523]
loss: 0.190667  [19200/70523]
loss: 0.105693  [25600/70523]
loss: 0.087486  [32000/70523]
loss: 0.142111  [38400/70523]
loss: 0.159131  [44800/70523]
loss: 0.219691  [51200/70523]
loss: 0.155938  [57600/70523]
loss: 0.161456  [64000/70523]
loss: 0.360406  [70400/70523]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.172119 

Epoch 21
-------------------------------
loss: 0.132338  [    0/70523]
loss: 0.114862  [ 6400/70523]
loss: 0.188793  [12800/70523]
loss: 0.172292  [19200/70523]
loss: 0.091272  [25600/70523]
loss: 0.161639  [32000/70523]
loss: 0.166223  [38400/70523]
loss: 0.143690  [44800/70523]
loss: 0.084780  [51200/70523]
loss: 0.326484  [57600/70523]
loss: 0.128985  [64000/70523]
loss: 0.124180  [70400/70523]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.172953 

Epoch 22
-------------------------------
loss: 0.231434  [    0/70523]
loss: 0.068954  [ 6400/70523]
loss: 0.112073  [12800/70523]
loss: 0.115142  [19200/70523]
loss: 0.227410  [25600/70523]
loss: 0.104476  [32000/70523]
loss: 0.121431  [38400/70523]
loss: 0.196285  [44800/70523]
loss: 0.194418  [51200/70523]
loss: 0.222083  [57600/70523]
loss: 0.188987  [64000/70523]
loss: 0.113003  [70400/70523]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.173106 

Epoch 23
-------------------------------
loss: 0.151695  [    0/70523]
loss: 0.114004  [ 6400/70523]
loss: 0.073140  [12800/70523]
loss: 0.153542  [19200/70523]
loss: 0.130782  [25600/70523]
loss: 0.226182  [32000/70523]
loss: 0.222500  [38400/70523]
loss: 0.150545  [44800/70523]
loss: 0.242217  [51200/70523]
loss: 0.193743  [57600/70523]
loss: 0.246758  [64000/70523]
loss: 0.185562  [70400/70523]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.169805 

Epoch 24
-------------------------------
loss: 0.156587  [    0/70523]
loss: 0.075292  [ 6400/70523]
loss: 0.113588  [12800/70523]
loss: 0.158799  [19200/70523]
loss: 0.241404  [25600/70523]
loss: 0.145954  [32000/70523]
loss: 1.724191  [38400/70523]
loss: 0.180188  [44800/70523]
loss: 0.196081  [51200/70523]
loss: 0.156465  [57600/70523]
loss: 0.126441  [64000/70523]
loss: 0.112653  [70400/70523]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.176886 

Epoch 25
-------------------------------
loss: 0.136279  [    0/70523]
loss: 0.108288  [ 6400/70523]
loss: 0.074572  [12800/70523]
loss: 0.098532  [38400/71095]
loss: 0.108204  [44800/71095]
loss: 0.094274  [51200/71095]
loss: 0.173185  [57600/71095]
loss: 0.077080  [64000/71095]
loss: 0.133657  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.159142 

Epoch 11
-------------------------------
loss: 1.615457  [    0/71095]
loss: 1.691342  [ 6400/71095]
loss: 0.203052  [12800/71095]
loss: 0.022211  [19200/71095]
loss: 0.149016  [25600/71095]
loss: 0.112159  [32000/71095]
loss: 0.069658  [38400/71095]
loss: 0.127568  [44800/71095]
loss: 0.079073  [51200/71095]
loss: 0.108459  [57600/71095]
loss: 0.102204  [64000/71095]
loss: 0.080121  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.157523 

Epoch 12
-------------------------------
loss: 0.037559  [    0/71095]
loss: 0.085105  [ 6400/71095]
loss: 0.047355  [12800/71095]
loss: 0.072099  [19200/71095]
loss: 0.050683  [25600/71095]
loss: 0.116687  [32000/71095]
loss: 0.135749  [38400/71095]
loss: 0.094233  [44800/71095]
loss: 0.159148  [51200/71095]
loss: 0.165569  [57600/71095]
loss: 0.035443  [64000/71095]
loss: 0.107880  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.156550 

Epoch 13
-------------------------------
loss: 0.039186  [    0/71095]
loss: 0.123852  [ 6400/71095]
loss: 0.168043  [12800/71095]
loss: 0.089503  [19200/71095]
loss: 0.083562  [25600/71095]
loss: 0.164645  [32000/71095]
loss: 0.055069  [38400/71095]
loss: 0.198943  [44800/71095]
loss: 0.077227  [51200/71095]
loss: 0.090320  [57600/71095]
loss: 0.074050  [64000/71095]
loss: 0.088304  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.153294 

Epoch 14
-------------------------------
loss: 0.118096  [    0/71095]
loss: 0.086772  [ 6400/71095]
loss: 0.059979  [12800/71095]
loss: 0.178576  [19200/71095]
loss: 0.059766  [25600/71095]
loss: 0.092280  [32000/71095]
loss: 0.240258  [38400/71095]
loss: 0.209743  [44800/71095]
loss: 0.121352  [51200/71095]
loss: 0.060942  [57600/71095]
loss: 0.090406  [64000/71095]
loss: 0.048463  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.151332 

Epoch 15
-------------------------------
loss: 0.072915  [    0/71095]
loss: 0.128179  [ 6400/71095]
loss: 0.075085  [12800/71095]
loss: 0.087267  [19200/71095]
loss: 0.126057  [25600/71095]
loss: 0.070178  [32000/71095]
loss: 0.056445  [38400/71095]
loss: 0.278359  [44800/71095]
loss: 0.140819  [51200/71095]
loss: 0.058288  [57600/71095]
loss: 1.671219  [64000/71095]
loss: 0.152185  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.153474 

Epoch 16
-------------------------------
loss: 0.028938  [    0/71095]
loss: 0.128552  [ 6400/71095]
loss: 0.102068  [12800/71095]
loss: 0.055971  [19200/71095]
loss: 0.090609  [25600/71095]
loss: 1.688318  [32000/71095]
loss: 0.065821  [38400/71095]
loss: 0.125750  [44800/71095]
loss: 0.155691  [51200/71095]
loss: 0.169282  [57600/71095]
loss: 0.110023  [64000/71095]
loss: 0.111660  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.154486 

Epoch 17
-------------------------------
loss: 0.062351  [    0/71095]
loss: 0.190631  [ 6400/71095]
loss: 0.098349  [12800/71095]
loss: 0.093833  [19200/71095]
loss: 0.090951  [25600/71095]
loss: 0.128823  [32000/71095]
loss: 0.061236  [38400/71095]
loss: 0.087813  [44800/71095]
loss: 0.057634  [51200/71095]
loss: 0.026216  [57600/71095]
loss: 0.092677  [64000/71095]
loss: 0.106004  [70400/71095]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.152580 

Epoch 18
-------------------------------
loss: 0.152881  [    0/71095]
loss: 0.053894  [ 6400/71095]
loss: 0.087848  [12800/71095]
loss: 0.070273  [19200/71095]
loss: 0.102256  [25600/71095]
loss: 0.090378  [32000/71095]
loss: 0.058726  [38400/71095]
loss: 0.105130  [44800/71095]
loss: 0.071114  [51200/71095]
loss: 0.030242  [57600/71095]
loss: 0.152977  [64000/71095]
loss: 0.046710  [70400/71095]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.152671 

Epoch 19
-------------------------------
loss: 0.040503  [    0/71095]
loss: 0.048263  [ 6400/71095]
loss: 0.062699  [12800/71095]
loss: 0.105872  [19200/71095]
loss: 0.083985  [25600/71095]
loss: 0.116571  [32000/71095]
loss: 0.055696  [38400/71095]
loss: 0.149520  [44800/71095]
loss: 0.077242  [51200/71095]
loss: 0.064316  [57600/71095]
loss: 0.052661  [64000/71095]
loss: 0.075288  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.159304 

Epoch 20
-------------------------------
loss: 0.120972  [    0/71095]
loss: 0.104016  [ 6400/71095]
loss: 0.070171  [12800/71095]
loss: 0.067537  [19200/71095]
loss: 0.101151  [25600/71095]
loss: 0.094860  [32000/71095]
loss: 0.219828  [38400/71095]
loss: 0.325906  [44800/71095]
loss: 0.081287  [51200/71095]
loss: 0.076312  [57600/71095]
loss: 0.170982  [64000/71095]
loss: 0.215036  [70400/71095]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.159041 

Epoch 21
-------------------------------
loss: 0.047702  [    0/71095]
loss: 0.067180  [ 6400/71095]
loss: 0.103008  [12800/71095]
loss: 0.104711  [19200/71095]
loss: 0.066150  [25600/71095]
loss: 0.234324  [32000/71095]
loss: 0.119729  [38400/71095]
loss: 0.066292  [44800/71095]
loss: 0.032256  [51200/71095]
loss: 0.105872  [57600/71095]
loss: 0.134250  [64000/71095]
loss: 0.108149  [70400/71095]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.152431 

Epoch 22
-------------------------------
loss: 0.107894  [    0/71095]
loss: 0.157602  [ 6400/71095]
loss: 0.171440  [12800/71095]
loss: 0.193418  [19200/71095]
loss: 0.076170  [25600/71095]
loss: 0.210826  [32000/71095]
loss: 0.048194  [38400/71095]
loss: 0.099486  [44800/71095]
loss: 0.070312  [51200/71095]
loss: 0.034063  [57600/71095]
loss: 0.062816  [64000/71095]
loss: 0.083415  [70400/71095]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.161027 

Epoch 23
-------------------------------
loss: 0.061474  [    0/71095]
loss: 0.216586  [ 6400/71095]
loss: 0.073628  [12800/71095]
loss: 0.039926  [19200/71095]
loss: 0.138177  [25600/71095]
loss: 0.052250  [32000/71095]
loss: 0.090764  [38400/71095]
loss: 0.187925  [44800/71095]
loss: 0.088828  [51200/71095]
loss: 0.174050  [57600/71095]
loss: 0.082951  [64000/71095]
loss: 0.144169  [70400/71095]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.150673 

Epoch 24
-------------------------------
loss: 0.073165  [    0/71095]
loss: 0.131311  [ 6400/71095]
loss: 0.061974  [12800/71095]
loss: 0.083691  [19200/71095]
loss: 0.091448  [25600/71095]
loss: 0.079766  [32000/71095]
loss: 0.082692  [38400/71095]
loss: 0.019870  [44800/71095]
loss: 0.160869  [51200/71095]
loss: 0.114937  [57600/71095]
loss: 0.046018  [64000/71095]
loss: 0.075277  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.157487 

Epoch 25
-------------------------------
loss: 0.086507  [    0/71095]
loss: 0.091988  [ 6400/71095]
loss: 0.178864  [12800/71095]
loss: 0.220067  [19200/71095]
loss: 0.047384  [25600/71095]
loss: 0.082444  [32000/71095]
loss: 0.163877  [38400/71095]
loss: 0.063095  [44800/71095]
loss: 0.079356  [51200/71095]
loss: 0.097808  [57600/71095]
loss: 0.111203  [64000/71095]
loss: 0.031611  [70400/71095]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.168719 

Epoch 26
-------------------------------
loss: 0.101860  [    0/71095]
loss: 0.036241  [ 6400/71095]
loss: 0.103927  [12800/71095]
loss: 0.148339  [19200/71095]
loss: 0.185928  [25600/71095]
loss: 0.052198  [32000/71095]
loss: 0.051912  [38400/71095]
loss: 0.064529  [44800/71095]
loss: 0.037443  [51200/71095]
loss: 0.063496  [57600/71095]
loss: 0.097998  [64000/71095]
loss: 0.074720  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.152551 

Epoch 27
-------------------------------
loss: 1.705212  [    0/71095]
loss: 0.047093  [ 6400/71095]
loss: 0.047514  [12800/71095]
loss: 0.148573  [19200/71095]
loss: 0.064765  [25600/71095]
loss: 0.043438  [32000/71095]
loss: 0.104824  [38400/71095]
loss: 0.064745  [44800/71095]
loss: 0.167880  [51200/71095]
loss: 0.075798  [57600/71095]
loss: 0.095398  [64000/71095]
loss: 0.186151  [70400/71095]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.170286 

Epoch 28
-------------------------------
loss: 0.140181  [    0/71095]
loss: 0.075347  [ 6400/71095]
loss: 0.151141  [12800/71095]
loss: 0.134873  [19200/71095]
loss: 0.095630  [25600/71095]
loss: 0.148990  [32000/71095]
loss: 0.096795  [38400/71095]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.166307 

Epoch 4
-------------------------------
loss: 0.234053  [    0/70549]
loss: 0.195758  [ 6400/70549]
loss: 0.130712  [12800/70549]
loss: 0.135580  [19200/70549]
loss: 0.102111  [25600/70549]
loss: 0.220981  [32000/70549]
loss: 0.158523  [38400/70549]
loss: 0.177271  [44800/70549]
loss: 0.090834  [51200/70549]
loss: 0.220763  [57600/70549]
loss: 0.174148  [64000/70549]
loss: 0.263965  [70400/70549]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.164871 

Epoch 5
-------------------------------
loss: 0.135883  [    0/70549]
loss: 0.083498  [ 6400/70549]
loss: 0.279248  [12800/70549]
loss: 0.087680  [19200/70549]
loss: 0.109190  [25600/70549]
loss: 0.232183  [32000/70549]
loss: 0.084305  [38400/70549]
loss: 0.133882  [44800/70549]
loss: 0.106599  [51200/70549]
loss: 0.197434  [57600/70549]
loss: 0.182930  [64000/70549]
loss: 0.134532  [70400/70549]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.178208 

Epoch 6
-------------------------------
loss: 0.173583  [    0/70549]
loss: 0.097045  [ 6400/70549]
loss: 0.167242  [12800/70549]
loss: 0.253321  [19200/70549]
loss: 0.151446  [25600/70549]
loss: 0.175759  [32000/70549]
loss: 0.062858  [38400/70549]
loss: 0.124828  [44800/70549]
loss: 1.660056  [51200/70549]
loss: 0.143922  [57600/70549]
loss: 0.298398  [64000/70549]
loss: 0.267420  [70400/70549]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.179830 

Epoch 7
-------------------------------
loss: 0.045144  [    0/70549]
loss: 0.088088  [ 6400/70549]
loss: 0.158243  [12800/70549]
loss: 0.125262  [19200/70549]
loss: 0.064554  [25600/70549]
loss: 0.135635  [32000/70549]
loss: 0.117017  [38400/70549]
loss: 0.131227  [44800/70549]
loss: 0.210905  [51200/70549]
loss: 0.188609  [57600/70549]
loss: 0.194421  [64000/70549]
loss: 0.178552  [70400/70549]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.150297 

Epoch 8
-------------------------------
loss: 0.055623  [    0/70549]
loss: 0.064262  [ 6400/70549]
loss: 0.161934  [12800/70549]
loss: 0.103857  [19200/70549]
loss: 0.150406  [25600/70549]
loss: 0.078478  [32000/70549]
loss: 0.076773  [38400/70549]
loss: 0.204648  [44800/70549]
loss: 0.059534  [51200/70549]
loss: 0.265772  [57600/70549]
loss: 0.099304  [64000/70549]
loss: 0.177932  [70400/70549]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.153012 

Epoch 9
-------------------------------
loss: 0.216777  [    0/70549]
loss: 0.057590  [ 6400/70549]
loss: 0.160635  [12800/70549]
loss: 0.105479  [19200/70549]
loss: 0.172187  [25600/70549]
loss: 0.069244  [32000/70549]
loss: 0.086624  [38400/70549]
loss: 0.168075  [44800/70549]
loss: 0.123103  [51200/70549]
loss: 0.113606  [57600/70549]
loss: 0.189704  [64000/70549]
loss: 0.118400  [70400/70549]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146361 

Epoch 10
-------------------------------
loss: 0.106641  [    0/70549]
loss: 0.116047  [ 6400/70549]
loss: 0.059857  [12800/70549]
loss: 1.630019  [19200/70549]
loss: 0.083283  [25600/70549]
loss: 0.157942  [32000/70549]
loss: 0.219562  [38400/70549]
loss: 1.740829  [44800/70549]
loss: 0.132762  [51200/70549]
loss: 0.033253  [57600/70549]
loss: 0.155840  [64000/70549]
loss: 0.187911  [70400/70549]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.153103 

Epoch 11
-------------------------------
loss: 0.066911  [    0/70549]
loss: 0.108378  [ 6400/70549]
loss: 0.075615  [12800/70549]
loss: 0.082376  [19200/70549]
loss: 0.065924  [25600/70549]
loss: 0.093356  [32000/70549]
loss: 0.160606  [38400/70549]
loss: 0.121124  [44800/70549]
loss: 0.107508  [51200/70549]
loss: 0.137330  [57600/70549]
loss: 0.323315  [64000/70549]
loss: 0.127225  [70400/70549]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.152656 

Epoch 12
-------------------------------
loss: 0.137525  [    0/70549]
loss: 0.102208  [ 6400/70549]
loss: 0.187546  [12800/70549]
loss: 0.172623  [19200/70549]
loss: 0.156756  [25600/70549]
loss: 0.038639  [32000/70549]
loss: 0.044843  [38400/70549]
loss: 0.050730  [44800/70549]
loss: 0.211091  [51200/70549]
loss: 0.117825  [57600/70549]
loss: 0.058445  [64000/70549]
loss: 0.054925  [70400/70549]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.143644 

Epoch 13
-------------------------------
loss: 0.124829  [    0/70549]
loss: 0.088225  [ 6400/70549]
loss: 0.027327  [12800/70549]
loss: 0.160906  [19200/70549]
loss: 0.171881  [25600/70549]
loss: 0.171664  [32000/70549]
loss: 0.064340  [38400/70549]
loss: 0.078147  [44800/70549]
loss: 0.135458  [51200/70549]
loss: 0.158133  [57600/70549]
loss: 0.033946  [64000/70549]
loss: 0.042352  [70400/70549]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.161361 

Epoch 14
-------------------------------
loss: 0.035292  [    0/70549]
loss: 0.167496  [ 6400/70549]
loss: 0.066885  [12800/70549]
loss: 0.057857  [19200/70549]
loss: 0.151790  [25600/70549]
loss: 0.087175  [32000/70549]
loss: 0.207039  [38400/70549]
loss: 0.135597  [44800/70549]
loss: 0.065909  [51200/70549]
loss: 0.115235  [57600/70549]
loss: 0.136429  [64000/70549]
loss: 0.368229  [70400/70549]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.137835 

Epoch 15
-------------------------------
loss: 0.176225  [    0/70549]
loss: 0.195785  [ 6400/70549]
loss: 0.088065  [12800/70549]
loss: 0.054011  [19200/70549]
loss: 0.169874  [25600/70549]
loss: 0.212432  [32000/70549]
loss: 0.071039  [38400/70549]
loss: 0.077667  [44800/70549]
loss: 0.053329  [51200/70549]
loss: 0.087957  [57600/70549]
loss: 0.182504  [64000/70549]
loss: 0.044345  [70400/70549]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.136578 

Epoch 16
-------------------------------
loss: 0.085931  [    0/70549]
loss: 0.051536  [ 6400/70549]
loss: 0.092100  [12800/70549]
loss: 0.090053  [19200/70549]
loss: 0.048301  [25600/70549]
loss: 0.104737  [32000/70549]
loss: 0.095368  [38400/70549]
loss: 0.062770  [44800/70549]
loss: 0.172032  [51200/70549]
loss: 0.109761  [57600/70549]
loss: 0.136914  [64000/70549]
loss: 0.106180  [70400/70549]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.133366 

Epoch 17
-------------------------------
loss: 0.110532  [    0/70549]
loss: 0.079049  [ 6400/70549]
loss: 0.079436  [12800/70549]
loss: 1.613934  [19200/70549]
loss: 0.116496  [25600/70549]
loss: 0.186321  [32000/70549]
loss: 0.162709  [38400/70549]
loss: 0.171120  [44800/70549]
loss: 0.108169  [51200/70549]
loss: 0.091215  [57600/70549]
loss: 0.104567  [64000/70549]
loss: 0.072906  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.124504 

Epoch 18
-------------------------------
loss: 0.034461  [    0/70549]
loss: 0.077072  [ 6400/70549]
loss: 0.119537  [12800/70549]
loss: 0.238077  [19200/70549]
loss: 0.096409  [25600/70549]
loss: 0.184082  [32000/70549]
loss: 0.200088  [38400/70549]
loss: 0.102266  [44800/70549]
loss: 0.140706  [51200/70549]
loss: 0.116670  [57600/70549]
loss: 0.130948  [64000/70549]
loss: 0.080820  [70400/70549]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.153669 

Epoch 19
-------------------------------
loss: 0.108828  [    0/70549]
loss: 0.106249  [ 6400/70549]
loss: 0.060851  [12800/70549]
loss: 0.066310  [19200/70549]
loss: 0.106379  [25600/70549]
loss: 0.264695  [32000/70549]
loss: 0.065179  [38400/70549]
loss: 0.064699  [44800/70549]
loss: 0.119535  [51200/70549]
loss: 0.131182  [57600/70549]
loss: 0.110857  [64000/70549]
loss: 0.066475  [70400/70549]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.125215 

Epoch 20
-------------------------------
loss: 0.079644  [    0/70549]
loss: 0.148998  [ 6400/70549]
loss: 0.131680  [12800/70549]
loss: 0.128645  [19200/70549]
loss: 0.136981  [25600/70549]
loss: 0.153955  [32000/70549]
loss: 0.171745  [38400/70549]
loss: 0.160269  [44800/70549]
loss: 0.128375  [51200/70549]
loss: 0.120847  [57600/70549]
loss: 0.138077  [64000/70549]
loss: 0.071822  [70400/70549]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.131063 

Epoch 21
-------------------------------
loss: 0.162946  [    0/70549]
loss: 0.125576  [ 6400/70549]
loss: 0.038507  [12800/70549]
loss: 0.131526  [19200/70549]
loss: 0.115773  [25600/70549]
loss: 0.047384  [32000/70549]
loss: 0.051150  [38400/70549]
loss: 0.119219  [44800/70549]
loss: 0.150650  [51200/70549]
loss: 0.039605  [57600/70549]
loss: 0.032611  [64000/70549]
loss: 0.173565  [70400/70549]
loss: 0.081289  [19200/70391]
loss: 0.054935  [25600/70391]
loss: 0.134981  [32000/70391]
loss: 0.118296  [38400/70391]
loss: 0.104456  [44800/70391]
loss: 0.102588  [51200/70391]
loss: 0.071004  [57600/70391]
loss: 0.184781  [64000/70391]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.152326 

Epoch 12
-------------------------------
loss: 0.052367  [    0/70391]
loss: 0.098269  [ 6400/70391]
loss: 0.090174  [12800/70391]
loss: 0.096697  [19200/70391]
loss: 0.049161  [25600/70391]
loss: 0.182493  [32000/70391]
loss: 0.191546  [38400/70391]
loss: 0.077765  [44800/70391]
loss: 0.086662  [51200/70391]
loss: 0.138334  [57600/70391]
loss: 0.057562  [64000/70391]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.156706 

Epoch 13
-------------------------------
loss: 0.051581  [    0/70391]
loss: 0.090199  [ 6400/70391]
loss: 1.589741  [12800/70391]
loss: 0.030962  [19200/70391]
loss: 0.170397  [25600/70391]
loss: 0.053317  [32000/70391]
loss: 0.090367  [38400/70391]
loss: 0.051666  [44800/70391]
loss: 0.024218  [51200/70391]
loss: 0.051255  [57600/70391]
loss: 0.078571  [64000/70391]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.153006 

Epoch 14
-------------------------------
loss: 0.045483  [    0/70391]
loss: 0.060760  [ 6400/70391]
loss: 0.036125  [12800/70391]
loss: 0.027444  [19200/70391]
loss: 0.056551  [25600/70391]
loss: 0.113224  [32000/70391]
loss: 0.036740  [38400/70391]
loss: 0.118229  [44800/70391]
loss: 0.124384  [51200/70391]
loss: 0.073199  [57600/70391]
loss: 0.067765  [64000/70391]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.157527 

Epoch 15
-------------------------------
loss: 0.065652  [    0/70391]
loss: 0.096119  [ 6400/70391]
loss: 0.034948  [12800/70391]
loss: 0.103226  [19200/70391]
loss: 0.055337  [25600/70391]
loss: 0.142768  [32000/70391]
loss: 0.106082  [38400/70391]
loss: 0.112279  [44800/70391]
loss: 0.116249  [51200/70391]
loss: 0.078632  [57600/70391]
loss: 0.018937  [64000/70391]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.157458 

Epoch 16
-------------------------------
loss: 0.066744  [    0/70391]
loss: 0.058438  [ 6400/70391]
loss: 0.032234  [12800/70391]
loss: 0.058640  [19200/70391]
loss: 0.197519  [25600/70391]
loss: 0.078732  [32000/70391]
loss: 0.030747  [38400/70391]
loss: 0.115328  [44800/70391]
loss: 0.023194  [51200/70391]
loss: 0.036167  [57600/70391]
loss: 0.116725  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.146187 

Epoch 17
-------------------------------
loss: 0.196040  [    0/70391]
loss: 0.097969  [ 6400/70391]
loss: 0.067423  [12800/70391]
loss: 0.047863  [19200/70391]
loss: 0.149537  [25600/70391]
loss: 0.158896  [32000/70391]
loss: 0.029693  [38400/70391]
loss: 1.709859  [44800/70391]
loss: 1.602660  [51200/70391]
loss: 0.090320  [57600/70391]
loss: 0.034119  [64000/70391]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.155838 

Epoch 18
-------------------------------
loss: 0.044404  [    0/70391]
loss: 0.118277  [ 6400/70391]
loss: 0.162461  [12800/70391]
loss: 0.023117  [19200/70391]
loss: 0.098233  [25600/70391]
loss: 0.129454  [32000/70391]
loss: 0.248249  [38400/70391]
loss: 0.127095  [44800/70391]
loss: 0.040975  [51200/70391]
loss: 0.098752  [57600/70391]
loss: 0.045731  [64000/70391]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.146426 

Epoch 19
-------------------------------
loss: 0.021302  [    0/70391]
loss: 0.174214  [ 6400/70391]
loss: 0.114072  [12800/70391]
loss: 0.154421  [19200/70391]
loss: 0.033977  [25600/70391]
loss: 0.038671  [32000/70391]
loss: 0.106973  [38400/70391]
loss: 0.075085  [44800/70391]
loss: 0.050188  [51200/70391]
loss: 0.182913  [57600/70391]
loss: 0.120203  [64000/70391]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.150069 

Epoch 20
-------------------------------
loss: 0.035483  [    0/70391]
loss: 0.148617  [ 6400/70391]
loss: 0.053615  [12800/70391]
loss: 0.027818  [19200/70391]
loss: 0.039780  [25600/70391]
loss: 0.124220  [32000/70391]
loss: 0.091379  [38400/70391]
loss: 0.094043  [44800/70391]
loss: 0.217684  [51200/70391]
loss: 0.136909  [57600/70391]
loss: 0.092380  [64000/70391]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.149969 

Epoch 21
-------------------------------
loss: 0.190759  [    0/70391]
loss: 0.149175  [ 6400/70391]
loss: 0.045574  [12800/70391]
loss: 0.203361  [19200/70391]
loss: 0.101003  [25600/70391]
loss: 0.139256  [32000/70391]
loss: 0.151379  [38400/70391]
loss: 0.049650  [44800/70391]
loss: 0.080056  [51200/70391]
loss: 0.008274  [57600/70391]
loss: 0.088340  [64000/70391]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.153143 

Epoch 22
-------------------------------
loss: 0.043493  [    0/70391]
loss: 0.092294  [ 6400/70391]
loss: 0.143325  [12800/70391]
loss: 0.120110  [19200/70391]
loss: 0.073318  [25600/70391]
loss: 0.025095  [32000/70391]
loss: 0.097796  [38400/70391]
loss: 0.110676  [44800/70391]
loss: 0.055305  [51200/70391]
loss: 0.159073  [57600/70391]
loss: 0.018393  [64000/70391]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.155536 

Epoch 23
-------------------------------
loss: 1.582372  [    0/70391]
loss: 0.048121  [ 6400/70391]
loss: 0.146163  [12800/70391]
loss: 0.048388  [19200/70391]
loss: 0.089236  [25600/70391]
loss: 0.038257  [32000/70391]
loss: 0.044305  [38400/70391]
loss: 0.038246  [44800/70391]
loss: 0.136684  [51200/70391]
loss: 0.134804  [57600/70391]
loss: 0.077308  [64000/70391]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.154129 

Epoch 24
-------------------------------
loss: 0.056465  [    0/70391]
loss: 0.054920  [ 6400/70391]
loss: 0.038098  [12800/70391]
loss: 0.054782  [19200/70391]
loss: 0.044548  [25600/70391]
loss: 0.167479  [32000/70391]
loss: 0.114431  [38400/70391]
loss: 0.139757  [44800/70391]
loss: 0.100097  [51200/70391]
loss: 0.016652  [57600/70391]
loss: 0.134507  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.145600 

Epoch 25
-------------------------------
loss: 0.018816  [    0/70391]
loss: 0.081299  [ 6400/70391]
loss: 0.033666  [12800/70391]
loss: 0.123785  [19200/70391]
loss: 0.105007  [25600/70391]
loss: 0.030247  [32000/70391]
loss: 0.262098  [38400/70391]
loss: 0.140783  [44800/70391]
loss: 0.162555  [51200/70391]
loss: 0.086809  [57600/70391]
loss: 0.110671  [64000/70391]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.149640 

Epoch 26
-------------------------------
loss: 0.056326  [    0/70391]
loss: 0.069568  [ 6400/70391]
loss: 0.096311  [12800/70391]
loss: 0.087271  [19200/70391]
loss: 0.131530  [25600/70391]
loss: 0.057863  [32000/70391]
loss: 0.100593  [38400/70391]
loss: 0.063290  [44800/70391]
loss: 0.015282  [51200/70391]
loss: 0.117277  [57600/70391]
loss: 0.165770  [64000/70391]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.152159 

Epoch 27
-------------------------------
loss: 0.147346  [    0/70391]
loss: 0.102832  [ 6400/70391]
loss: 0.047009  [12800/70391]
loss: 0.030064  [19200/70391]
loss: 0.105548  [25600/70391]
loss: 0.062324  [32000/70391]
loss: 0.075449  [38400/70391]
loss: 0.044535  [44800/70391]
loss: 0.047499  [51200/70391]
loss: 0.184645  [57600/70391]
loss: 0.022148  [64000/70391]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.152394 

Epoch 28
-------------------------------
loss: 0.066197  [    0/70391]
loss: 0.159314  [ 6400/70391]
loss: 0.145457  [12800/70391]
loss: 0.024390  [19200/70391]
loss: 0.036835  [25600/70391]
loss: 0.094001  [32000/70391]
loss: 0.139899  [38400/70391]
loss: 0.042342  [44800/70391]
loss: 0.050051  [51200/70391]
loss: 0.099219  [57600/70391]
loss: 0.108897  [64000/70391]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.152752 

Epoch 29
-------------------------------
loss: 0.036016  [    0/70391]
loss: 0.206920  [ 6400/70391]
loss: 0.096202  [12800/70391]
loss: 0.023658  [19200/70391]
loss: 0.041769  [25600/70391]
loss: 0.059062  [32000/70391]
loss: 0.025157  [38400/70391]
loss: 0.042673  [44800/70391]
loss: 0.168084  [51200/70391]
loss: 0.058094  [57600/70391]
loss: 0.114890  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.147475 

Epoch 30
-------------------------------
loss: 1.652435  [    0/70391]
loss: 0.050036  [ 6400/70391]
loss: 0.044584  [12800/70391]
loss: 0.057530  [19200/70391]
loss: 0.046995  [25600/70391]
loss: 0.070145  [32000/70391]
loss: 0.085428  [38400/70391]
loss: 0.106150  [44800/70391]
loss: 0.225669  [57600/69530]
loss: 0.129731  [64000/69530]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.189559 

Epoch 8
-------------------------------
loss: 0.207276  [    0/69530]
loss: 0.149198  [ 6400/69530]
loss: 0.198809  [12800/69530]
loss: 0.072898  [19200/69530]
loss: 0.223048  [25600/69530]
loss: 0.210540  [32000/69530]
loss: 0.154364  [38400/69530]
loss: 0.277551  [44800/69530]
loss: 0.182319  [51200/69530]
loss: 0.220883  [57600/69530]
loss: 0.090077  [64000/69530]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177381 

Epoch 9
-------------------------------
loss: 0.184903  [    0/69530]
loss: 0.145629  [ 6400/69530]
loss: 0.194156  [12800/69530]
loss: 0.152701  [19200/69530]
loss: 0.128102  [25600/69530]
loss: 0.228462  [32000/69530]
loss: 0.090956  [38400/69530]
loss: 0.194227  [44800/69530]
loss: 0.110338  [51200/69530]
loss: 0.176379  [57600/69530]
loss: 0.137084  [64000/69530]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.182105 

Epoch 10
-------------------------------
loss: 0.052130  [    0/69530]
loss: 0.125475  [ 6400/69530]
loss: 0.109862  [12800/69530]
loss: 0.237108  [19200/69530]
loss: 0.145266  [25600/69530]
loss: 0.237909  [32000/69530]
loss: 0.249596  [38400/69530]
loss: 0.158584  [44800/69530]
loss: 0.143378  [51200/69530]
loss: 0.090085  [57600/69530]
loss: 0.209457  [64000/69530]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.189441 

Epoch 11
-------------------------------
loss: 0.262934  [    0/69530]
loss: 0.137667  [ 6400/69530]
loss: 0.214471  [12800/69530]
loss: 0.179450  [19200/69530]
loss: 0.103047  [25600/69530]
loss: 0.177124  [32000/69530]
loss: 0.193937  [38400/69530]
loss: 0.259224  [44800/69530]
loss: 0.184103  [51200/69530]
loss: 0.267063  [57600/69530]
loss: 0.284203  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.173598 

Epoch 12
-------------------------------
loss: 0.127779  [    0/69530]
loss: 0.053696  [ 6400/69530]
loss: 0.215722  [12800/69530]
loss: 0.077421  [19200/69530]
loss: 0.190006  [25600/69530]
loss: 0.188043  [32000/69530]
loss: 0.106925  [38400/69530]
loss: 0.248492  [44800/69530]
loss: 0.167642  [51200/69530]
loss: 0.245672  [57600/69530]
loss: 0.126033  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.173057 

Epoch 13
-------------------------------
loss: 0.243652  [    0/69530]
loss: 0.161894  [ 6400/69530]
loss: 0.074952  [12800/69530]
loss: 0.237039  [19200/69530]
loss: 0.274258  [25600/69530]
loss: 0.141715  [32000/69530]
loss: 0.091559  [38400/69530]
loss: 0.098053  [44800/69530]
loss: 0.135045  [51200/69530]
loss: 0.188387  [57600/69530]
loss: 0.123773  [64000/69530]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.207974 

Epoch 14
-------------------------------
loss: 0.188658  [    0/69530]
loss: 0.122606  [ 6400/69530]
loss: 0.137349  [12800/69530]
loss: 0.240620  [19200/69530]
loss: 0.165338  [25600/69530]
loss: 0.095171  [32000/69530]
loss: 0.299869  [38400/69530]
loss: 0.348628  [44800/69530]
loss: 0.127959  [51200/69530]
loss: 0.118656  [57600/69530]
loss: 0.103181  [64000/69530]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.170455 

Epoch 15
-------------------------------
loss: 0.170114  [    0/69530]
loss: 0.108470  [ 6400/69530]
loss: 0.111733  [12800/69530]
loss: 0.155862  [19200/69530]
loss: 0.246843  [25600/69530]
loss: 0.233031  [32000/69530]
loss: 0.220027  [38400/69530]
loss: 0.098413  [44800/69530]
loss: 0.137228  [51200/69530]
loss: 0.192808  [57600/69530]
loss: 0.155135  [64000/69530]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.182660 

Epoch 16
-------------------------------
loss: 0.079913  [    0/69530]
loss: 0.091605  [ 6400/69530]
loss: 0.143674  [12800/69530]
loss: 0.214627  [19200/69530]
loss: 0.090589  [25600/69530]
loss: 0.191592  [32000/69530]
loss: 0.118164  [38400/69530]
loss: 0.141644  [44800/69530]
loss: 0.197678  [51200/69530]
loss: 0.165492  [57600/69530]
loss: 0.161762  [64000/69530]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.200948 

Epoch 17
-------------------------------
loss: 0.344550  [    0/69530]
loss: 1.721664  [ 6400/69530]
loss: 0.144465  [12800/69530]
loss: 0.171102  [19200/69530]
loss: 0.216414  [25600/69530]
loss: 0.172627  [32000/69530]
loss: 0.141753  [38400/69530]
loss: 0.149276  [44800/69530]
loss: 0.099893  [51200/69530]
loss: 0.221573  [57600/69530]
loss: 0.468782  [64000/69530]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.179392 

Epoch 18
-------------------------------
loss: 0.311310  [    0/69530]
loss: 0.317055  [ 6400/69530]
loss: 0.191667  [12800/69530]
loss: 0.180341  [19200/69530]
loss: 0.138548  [25600/69530]
loss: 0.109056  [32000/69530]
loss: 0.201983  [38400/69530]
loss: 0.155732  [44800/69530]
loss: 0.170670  [51200/69530]
loss: 0.193840  [57600/69530]
loss: 0.118678  [64000/69530]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.198793 

Epoch 19
-------------------------------
loss: 0.204335  [    0/69530]
loss: 0.184624  [ 6400/69530]
loss: 0.311260  [12800/69530]
loss: 0.200074  [19200/69530]
loss: 0.113380  [25600/69530]
loss: 0.101272  [32000/69530]
loss: 0.334289  [38400/69530]
loss: 0.127004  [44800/69530]
loss: 0.186586  [51200/69530]
loss: 0.173858  [57600/69530]
loss: 0.078580  [64000/69530]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174764 

Epoch 20
-------------------------------
loss: 0.138079  [    0/69530]
loss: 0.102248  [ 6400/69530]
loss: 0.164113  [12800/69530]
loss: 0.111753  [19200/69530]
loss: 0.179062  [25600/69530]
loss: 0.117310  [32000/69530]
loss: 0.179185  [38400/69530]
loss: 0.059467  [44800/69530]
loss: 0.188448  [51200/69530]
loss: 0.128078  [57600/69530]
loss: 0.219291  [64000/69530]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.185992 

Epoch 21
-------------------------------
loss: 0.154151  [    0/69530]
loss: 0.268253  [ 6400/69530]
loss: 0.163833  [12800/69530]
loss: 0.154781  [19200/69530]
loss: 0.134664  [25600/69530]
loss: 0.150597  [32000/69530]
loss: 0.142961  [38400/69530]
loss: 0.101930  [44800/69530]
loss: 1.746397  [51200/69530]
loss: 0.060252  [57600/69530]
loss: 0.251045  [64000/69530]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.175564 

Epoch 22
-------------------------------
loss: 0.145137  [    0/69530]
loss: 0.135749  [ 6400/69530]
loss: 0.159253  [12800/69530]
loss: 0.197771  [19200/69530]
loss: 0.230582  [25600/69530]
loss: 0.191479  [32000/69530]
loss: 0.089047  [38400/69530]
loss: 0.120674  [44800/69530]
loss: 0.114128  [51200/69530]
loss: 0.200501  [57600/69530]
loss: 0.247483  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.173891 

Epoch 23
-------------------------------
loss: 0.262444  [    0/69530]
loss: 0.144802  [ 6400/69530]
loss: 0.168707  [12800/69530]
loss: 0.150519  [19200/69530]
loss: 0.101803  [25600/69530]
loss: 0.187793  [32000/69530]
loss: 0.067937  [38400/69530]
loss: 0.205758  [44800/69530]
loss: 0.179500  [51200/69530]
loss: 0.134372  [57600/69530]
loss: 0.259765  [64000/69530]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.178534 

Epoch 24
-------------------------------
loss: 0.078031  [    0/69530]
loss: 0.086156  [ 6400/69530]
loss: 0.075505  [12800/69530]
loss: 0.222400  [19200/69530]
loss: 0.193322  [25600/69530]
loss: 0.045540  [32000/69530]
loss: 0.293936  [38400/69530]
loss: 0.086206  [44800/69530]
loss: 0.149742  [51200/69530]
loss: 0.111451  [57600/69530]
loss: 0.117545  [64000/69530]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.208144 

Epoch 25
-------------------------------
loss: 0.304297  [    0/69530]
loss: 0.136059  [ 6400/69530]
loss: 0.146799  [12800/69530]
loss: 0.128732  [19200/69530]
loss: 0.171473  [25600/69530]
loss: 0.244438  [32000/69530]
loss: 0.137127  [38400/69530]
loss: 0.109770  [44800/69530]
loss: 0.128078  [51200/69530]
loss: 0.072211  [57600/69530]
loss: 0.136722  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171771 

Epoch 26
-------------------------------
loss: 0.069713  [    0/69530]
loss: 0.157439  [ 6400/69530]
loss: 0.076648  [12800/69530]
loss: 0.147036  [19200/69530]
loss: 0.095748  [25600/69530]
loss: 0.168820  [32000/69530]
loss: 0.177481  [38400/69530]
loss: 0.105384  [44800/69530]
loss: 0.127853  [51200/69530]
loss: 0.254399  [57600/69530]
loss: 0.222391  [64000/69530]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.181204 

Epoch 27
-------------------------------
loss: 0.225037  [38400/71653]
loss: 0.182401  [44800/71653]
loss: 0.068395  [51200/71653]
loss: 0.069434  [57600/71653]
loss: 0.135182  [64000/71653]
loss: 0.131660  [70400/71653]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.120331 

Epoch 11
-------------------------------
loss: 0.013823  [    0/71653]
loss: 0.045374  [ 6400/71653]
loss: 0.078041  [12800/71653]
loss: 0.048992  [19200/71653]
loss: 0.040927  [25600/71653]
loss: 0.167225  [32000/71653]
loss: 0.104165  [38400/71653]
loss: 0.050768  [44800/71653]
loss: 0.070718  [51200/71653]
loss: 0.049216  [57600/71653]
loss: 0.115137  [64000/71653]
loss: 0.081763  [70400/71653]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.121424 

Epoch 12
-------------------------------
loss: 0.105257  [    0/71653]
loss: 0.148992  [ 6400/71653]
loss: 0.112794  [12800/71653]
loss: 0.111768  [19200/71653]
loss: 0.040677  [25600/71653]
loss: 0.037849  [32000/71653]
loss: 0.035135  [38400/71653]
loss: 0.114678  [44800/71653]
loss: 0.229084  [51200/71653]
loss: 0.114275  [57600/71653]
loss: 0.078169  [64000/71653]
loss: 0.019150  [70400/71653]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.129353 

Epoch 13
-------------------------------
loss: 0.081015  [    0/71653]
loss: 0.068590  [ 6400/71653]
loss: 0.093696  [12800/71653]
loss: 0.044851  [19200/71653]
loss: 0.094965  [25600/71653]
loss: 0.054172  [32000/71653]
loss: 1.771460  [38400/71653]
loss: 0.048467  [44800/71653]
loss: 0.088188  [51200/71653]
loss: 0.055309  [57600/71653]
loss: 0.118297  [64000/71653]
loss: 0.237584  [70400/71653]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119280 

Epoch 14
-------------------------------
loss: 0.114128  [    0/71653]
loss: 0.131885  [ 6400/71653]
loss: 0.046914  [12800/71653]
loss: 0.105904  [19200/71653]
loss: 0.090420  [25600/71653]
loss: 0.035488  [32000/71653]
loss: 0.048322  [38400/71653]
loss: 0.081943  [44800/71653]
loss: 0.059730  [51200/71653]
loss: 0.062021  [57600/71653]
loss: 0.063862  [64000/71653]
loss: 0.142140  [70400/71653]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.117723 

Epoch 15
-------------------------------
loss: 0.143898  [    0/71653]
loss: 0.131197  [ 6400/71653]
loss: 1.617441  [12800/71653]
loss: 0.082561  [19200/71653]
loss: 0.071331  [25600/71653]
loss: 0.078289  [32000/71653]
loss: 0.092151  [38400/71653]
loss: 0.051720  [44800/71653]
loss: 0.174725  [51200/71653]
loss: 0.076716  [57600/71653]
loss: 0.032908  [64000/71653]
loss: 0.011719  [70400/71653]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.117290 

Epoch 16
-------------------------------
loss: 0.046686  [    0/71653]
loss: 0.044536  [ 6400/71653]
loss: 0.083606  [12800/71653]
loss: 0.061171  [19200/71653]
loss: 0.046539  [25600/71653]
loss: 0.065443  [32000/71653]
loss: 0.221827  [38400/71653]
loss: 0.181594  [44800/71653]
loss: 0.023888  [51200/71653]
loss: 0.065715  [57600/71653]
loss: 0.019001  [64000/71653]
loss: 0.120111  [70400/71653]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.114920 

Epoch 17
-------------------------------
loss: 0.051410  [    0/71653]
loss: 0.074463  [ 6400/71653]
loss: 0.092409  [12800/71653]
loss: 0.065957  [19200/71653]
loss: 0.114387  [25600/71653]
loss: 0.065287  [32000/71653]
loss: 0.094098  [38400/71653]
loss: 0.112837  [44800/71653]
loss: 0.125353  [51200/71653]
loss: 0.043357  [57600/71653]
loss: 0.059530  [64000/71653]
loss: 0.125411  [70400/71653]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.119638 

Epoch 18
-------------------------------
loss: 0.045523  [    0/71653]
loss: 0.236850  [ 6400/71653]
loss: 0.073897  [12800/71653]
loss: 0.132813  [19200/71653]
loss: 0.120993  [25600/71653]
loss: 0.137188  [32000/71653]
loss: 0.057830  [38400/71653]
loss: 0.197451  [44800/71653]
loss: 0.151126  [51200/71653]
loss: 0.167986  [57600/71653]
loss: 0.120569  [64000/71653]
loss: 0.140826  [70400/71653]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.110781 

Epoch 19
-------------------------------
loss: 0.075397  [    0/71653]
loss: 0.166836  [ 6400/71653]
loss: 0.146142  [12800/71653]
loss: 0.096302  [19200/71653]
loss: 0.053130  [25600/71653]
loss: 0.057318  [32000/71653]
loss: 0.079385  [38400/71653]
loss: 0.046341  [44800/71653]
loss: 0.029421  [51200/71653]
loss: 0.054704  [57600/71653]
loss: 0.037316  [64000/71653]
loss: 0.039115  [70400/71653]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.113188 

Epoch 20
-------------------------------
loss: 0.059028  [    0/71653]
loss: 0.074111  [ 6400/71653]
loss: 0.038139  [12800/71653]
loss: 0.145481  [19200/71653]
loss: 0.046742  [25600/71653]
loss: 0.076941  [32000/71653]
loss: 0.066046  [38400/71653]
loss: 0.091020  [44800/71653]
loss: 0.075886  [51200/71653]
loss: 0.065714  [57600/71653]
loss: 0.098725  [64000/71653]
loss: 0.195876  [70400/71653]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.130875 

Epoch 21
-------------------------------
loss: 0.042406  [    0/71653]
loss: 0.057644  [ 6400/71653]
loss: 0.113512  [12800/71653]
loss: 0.089479  [19200/71653]
loss: 0.094037  [25600/71653]
loss: 0.112599  [32000/71653]
loss: 0.161664  [38400/71653]
loss: 0.023703  [44800/71653]
loss: 0.039953  [51200/71653]
loss: 0.105673  [57600/71653]
loss: 0.062685  [64000/71653]
loss: 0.044004  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.108061 

Epoch 22
-------------------------------
loss: 0.099880  [    0/71653]
loss: 0.123480  [ 6400/71653]
loss: 0.070704  [12800/71653]
loss: 0.066791  [19200/71653]
loss: 0.116635  [25600/71653]
loss: 0.066346  [32000/71653]
loss: 0.177091  [38400/71653]
loss: 0.144298  [44800/71653]
loss: 0.059982  [51200/71653]
loss: 0.053551  [57600/71653]
loss: 0.165576  [64000/71653]
loss: 0.187123  [70400/71653]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.124774 

Epoch 23
-------------------------------
loss: 0.085651  [    0/71653]
loss: 0.093933  [ 6400/71653]
loss: 0.145032  [12800/71653]
loss: 0.024700  [19200/71653]
loss: 0.182467  [25600/71653]
loss: 0.076767  [32000/71653]
loss: 0.061458  [38400/71653]
loss: 0.027326  [44800/71653]
loss: 0.048004  [51200/71653]
loss: 0.084116  [57600/71653]
loss: 0.195845  [64000/71653]
loss: 0.177149  [70400/71653]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.113032 

Epoch 24
-------------------------------
loss: 0.194201  [    0/71653]
loss: 0.032342  [ 6400/71653]
loss: 0.097310  [12800/71653]
loss: 0.084117  [19200/71653]
loss: 0.126790  [25600/71653]
loss: 0.046313  [32000/71653]
loss: 0.110294  [38400/71653]
loss: 0.111084  [44800/71653]
loss: 0.153092  [51200/71653]
loss: 0.043813  [57600/71653]
loss: 0.103145  [64000/71653]
loss: 0.117169  [70400/71653]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.109072 

Epoch 25
-------------------------------
loss: 0.072605  [    0/71653]
loss: 0.047526  [ 6400/71653]
loss: 0.038400  [12800/71653]
loss: 0.025906  [19200/71653]
loss: 0.039337  [25600/71653]
loss: 0.026812  [32000/71653]
loss: 0.170612  [38400/71653]
loss: 0.083011  [44800/71653]
loss: 0.063421  [51200/71653]
loss: 0.038028  [57600/71653]
loss: 0.196006  [64000/71653]
loss: 0.159509  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.110767 

Epoch 26
-------------------------------
loss: 0.087230  [    0/71653]
loss: 0.085076  [ 6400/71653]
loss: 0.150620  [12800/71653]
loss: 0.040112  [19200/71653]
loss: 0.035849  [25600/71653]
loss: 0.089240  [32000/71653]
loss: 0.042353  [38400/71653]
loss: 0.028421  [44800/71653]
loss: 0.070783  [51200/71653]
loss: 0.052634  [57600/71653]
loss: 0.111911  [64000/71653]
loss: 0.082292  [70400/71653]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.117001 

Epoch 27
-------------------------------
loss: 0.057861  [    0/71653]
loss: 0.082796  [ 6400/71653]
loss: 0.060323  [12800/71653]
loss: 0.063022  [19200/71653]
loss: 0.082104  [25600/71653]
loss: 0.260882  [32000/71653]
loss: 0.014122  [38400/71653]
loss: 0.053026  [44800/71653]
loss: 0.042109  [51200/71653]
loss: 0.118001  [57600/71653]
loss: 0.049202  [64000/71653]
loss: 0.043963  [70400/71653]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.106972 

Epoch 28
-------------------------------
loss: 0.042041  [    0/71653]
loss: 0.063971  [ 6400/71653]
loss: 0.111151  [12800/71653]
loss: 0.057033  [19200/71653]
loss: 0.083300  [25600/71653]
loss: 0.074383  [32000/71653]
loss: 0.082012  [38400/71653]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085926 

Epoch 22
-------------------------------
loss: 0.063413  [    0/71783]
loss: 0.010952  [ 6400/71783]
loss: 0.033816  [12800/71783]
loss: 0.046439  [19200/71783]
loss: 0.009405  [25600/71783]
loss: 0.057434  [32000/71783]
loss: 0.037354  [38400/71783]
loss: 0.015673  [44800/71783]
loss: 0.030561  [51200/71783]
loss: 0.074424  [57600/71783]
loss: 0.068817  [64000/71783]
loss: 0.068154  [70400/71783]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.078834 

Epoch 23
-------------------------------
loss: 0.010986  [    0/71783]
loss: 0.012941  [ 6400/71783]
loss: 0.042292  [12800/71783]
loss: 0.061903  [19200/71783]
loss: 0.017500  [25600/71783]
loss: 0.067105  [32000/71783]
loss: 0.067330  [38400/71783]
loss: 0.020285  [44800/71783]
loss: 0.021133  [51200/71783]
loss: 0.020132  [57600/71783]
loss: 0.022256  [64000/71783]
loss: 0.111568  [70400/71783]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.089704 

Epoch 24
-------------------------------
loss: 0.011878  [    0/71783]
loss: 0.006883  [ 6400/71783]
loss: 0.014195  [12800/71783]
loss: 0.124194  [19200/71783]
loss: 0.015600  [25600/71783]
loss: 0.026887  [32000/71783]
loss: 0.053519  [38400/71783]
loss: 0.047018  [44800/71783]
loss: 0.021193  [51200/71783]
loss: 0.045426  [57600/71783]
loss: 0.049514  [64000/71783]
loss: 0.056278  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.096394 

Epoch 25
-------------------------------
loss: 0.028562  [    0/71783]
loss: 0.124850  [ 6400/71783]
loss: 0.024201  [12800/71783]
loss: 0.178754  [19200/71783]
loss: 0.024333  [25600/71783]
loss: 0.009759  [32000/71783]
loss: 0.067180  [38400/71783]
loss: 0.041531  [44800/71783]
loss: 0.033643  [51200/71783]
loss: 0.032770  [57600/71783]
loss: 0.003678  [64000/71783]
loss: 0.016647  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.090030 

Epoch 26
-------------------------------
loss: 0.016630  [    0/71783]
loss: 0.004060  [ 6400/71783]
loss: 0.049615  [12800/71783]
loss: 0.007108  [19200/71783]
loss: 0.061795  [25600/71783]
loss: 0.032480  [32000/71783]
loss: 0.015902  [38400/71783]
loss: 0.020554  [44800/71783]
loss: 0.037331  [51200/71783]
loss: 0.146602  [57600/71783]
loss: 1.628968  [64000/71783]
loss: 0.078422  [70400/71783]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.089443 

Epoch 27
-------------------------------
loss: 0.027342  [    0/71783]
loss: 0.004653  [ 6400/71783]
loss: 0.024306  [12800/71783]
loss: 0.012831  [19200/71783]
loss: 0.028179  [25600/71783]
loss: 0.036614  [32000/71783]
loss: 0.024684  [38400/71783]
loss: 0.063309  [44800/71783]
loss: 0.004023  [51200/71783]
loss: 0.019376  [57600/71783]
loss: 0.087023  [64000/71783]
loss: 0.018931  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.091413 

Epoch 28
-------------------------------
loss: 0.042413  [    0/71783]
loss: 0.054869  [ 6400/71783]
loss: 0.013331  [12800/71783]
loss: 0.041935  [19200/71783]
loss: 0.018189  [25600/71783]
loss: 0.007672  [32000/71783]
loss: 0.025684  [38400/71783]
loss: 0.008500  [44800/71783]
loss: 0.068787  [51200/71783]
loss: 0.004884  [57600/71783]
loss: 0.021328  [64000/71783]
loss: 0.097632  [70400/71783]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.091269 

Epoch 29
-------------------------------
loss: 0.040005  [    0/71783]
loss: 0.023369  [ 6400/71783]
loss: 0.006826  [12800/71783]
loss: 0.012826  [19200/71783]
loss: 0.053732  [25600/71783]
loss: 0.078446  [32000/71783]
loss: 0.014342  [38400/71783]
loss: 0.096512  [44800/71783]
loss: 0.177973  [51200/71783]
loss: 0.009751  [57600/71783]
loss: 0.038668  [64000/71783]
loss: 0.029419  [70400/71783]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.088013 

Epoch 30
-------------------------------
loss: 0.054753  [    0/71783]
loss: 0.007028  [ 6400/71783]
loss: 0.019150  [12800/71783]
loss: 0.039192  [19200/71783]
loss: 0.082003  [25600/71783]
loss: 0.024045  [32000/71783]
loss: 0.029480  [38400/71783]
loss: 0.014485  [44800/71783]
loss: 0.020776  [51200/71783]
loss: 0.034240  [57600/71783]
loss: 0.015481  [64000/71783]
loss: 0.020311  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.092226 

Epoch 31
-------------------------------
loss: 0.067387  [    0/71783]
loss: 0.078828  [ 6400/71783]
loss: 0.062211  [12800/71783]
loss: 0.004887  [19200/71783]
loss: 0.012698  [25600/71783]
loss: 0.005023  [32000/71783]
loss: 0.011742  [38400/71783]
loss: 0.107949  [44800/71783]
loss: 0.027920  [51200/71783]
loss: 0.009922  [57600/71783]
loss: 0.087728  [64000/71783]
loss: 0.008588  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.097314 

Epoch 32
-------------------------------
loss: 0.013290  [    0/71783]
loss: 0.007091  [ 6400/71783]
loss: 0.002709  [12800/71783]
loss: 0.057196  [19200/71783]
loss: 0.031148  [25600/71783]
loss: 0.032727  [32000/71783]
loss: 0.086863  [38400/71783]
loss: 1.640224  [44800/71783]
loss: 0.064845  [51200/71783]
loss: 0.020338  [57600/71783]
loss: 0.038622  [64000/71783]
loss: 0.038072  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.108166 

Epoch 33
-------------------------------
loss: 0.040146  [    0/71783]
loss: 0.110531  [ 6400/71783]
loss: 0.027532  [12800/71783]
loss: 0.012775  [19200/71783]
loss: 0.015554  [25600/71783]
loss: 0.005907  [32000/71783]
loss: 0.037947  [38400/71783]
loss: 0.029343  [44800/71783]
loss: 0.064344  [51200/71783]
loss: 0.006393  [57600/71783]
loss: 0.006136  [64000/71783]
loss: 0.072164  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.093742 

Epoch 34
-------------------------------
loss: 0.058428  [    0/71783]
loss: 0.050963  [ 6400/71783]
loss: 0.037541  [12800/71783]
loss: 0.141383  [19200/71783]
loss: 0.022237  [25600/71783]
loss: 0.037587  [32000/71783]
loss: 0.075685  [38400/71783]
loss: 0.048286  [44800/71783]
loss: 0.047969  [51200/71783]
loss: 0.100023  [57600/71783]
loss: 0.021685  [64000/71783]
loss: 0.021259  [70400/71783]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.099771 

Epoch 35
-------------------------------
loss: 0.068262  [    0/71783]
loss: 0.002462  [ 6400/71783]
loss: 0.044774  [12800/71783]
loss: 0.064476  [19200/71783]
loss: 0.016256  [25600/71783]
loss: 0.101459  [32000/71783]
loss: 0.114190  [38400/71783]
loss: 0.030773  [44800/71783]
loss: 0.020532  [51200/71783]
loss: 0.047362  [57600/71783]
loss: 0.004296  [64000/71783]
loss: 0.062085  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.087234 

Epoch 36
-------------------------------
loss: 0.029989  [    0/71783]
loss: 0.015416  [ 6400/71783]
loss: 0.008919  [12800/71783]
loss: 0.013973  [19200/71783]
loss: 0.023352  [25600/71783]
loss: 0.061051  [32000/71783]
loss: 0.010144  [38400/71783]
loss: 0.021819  [44800/71783]
loss: 0.022313  [51200/71783]
loss: 0.003650  [57600/71783]
loss: 0.124078  [64000/71783]
loss: 0.103484  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.085090 

Epoch 37
-------------------------------
loss: 0.027772  [    0/71783]
loss: 0.079438  [ 6400/71783]
loss: 0.047270  [12800/71783]
loss: 0.064495  [19200/71783]
loss: 0.015769  [25600/71783]
loss: 0.007912  [32000/71783]
loss: 0.166390  [38400/71783]
loss: 0.044027  [44800/71783]
loss: 0.009638  [51200/71783]
loss: 0.034192  [57600/71783]
loss: 0.175838  [64000/71783]
loss: 0.082157  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.097773 

Epoch 38
-------------------------------
loss: 0.015205  [    0/71783]
loss: 0.032261  [ 6400/71783]
loss: 0.007144  [12800/71783]
loss: 0.024529  [19200/71783]
loss: 0.032446  [25600/71783]
loss: 1.566605  [32000/71783]
loss: 0.051877  [38400/71783]
loss: 0.024409  [44800/71783]
loss: 0.054752  [51200/71783]
loss: 0.032359  [57600/71783]
loss: 0.041296  [64000/71783]
loss: 0.047943  [70400/71783]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.105511 

Epoch 39
-------------------------------
loss: 0.081966  [    0/71783]
loss: 0.039978  [ 6400/71783]
loss: 0.010780  [12800/71783]
loss: 0.004118  [19200/71783]
loss: 0.228310  [25600/71783]
loss: 0.004281  [32000/71783]
loss: 0.012625  [38400/71783]
loss: 0.041722  [44800/71783]
loss: 0.007606  [51200/71783]
loss: 0.039822  [57600/71783]
loss: 0.027207  [64000/71783]
loss: 0.081885  [70400/71783]
loss: 0.189463  [51200/69274]
loss: 0.377178  [57600/69274]
loss: 0.220212  [64000/69274]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.196910 

Epoch 8
-------------------------------
loss: 0.152668  [    0/69274]
loss: 0.246787  [ 6400/69274]
loss: 0.201114  [12800/69274]
loss: 0.186445  [19200/69274]
loss: 0.121590  [25600/69274]
loss: 0.300575  [32000/69274]
loss: 0.220227  [38400/69274]
loss: 0.254333  [44800/69274]
loss: 0.246275  [51200/69274]
loss: 0.130529  [57600/69274]
loss: 0.147047  [64000/69274]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.192697 

Epoch 9
-------------------------------
loss: 0.092683  [    0/69274]
loss: 0.262768  [ 6400/69274]
loss: 0.118024  [12800/69274]
loss: 0.145230  [19200/69274]
loss: 0.188482  [25600/69274]
loss: 0.069874  [32000/69274]
loss: 0.235433  [38400/69274]
loss: 0.155384  [44800/69274]
loss: 1.749470  [51200/69274]
loss: 0.257579  [57600/69274]
loss: 0.185859  [64000/69274]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.192575 

Epoch 10
-------------------------------
loss: 0.225815  [    0/69274]
loss: 0.099179  [ 6400/69274]
loss: 0.098262  [12800/69274]
loss: 0.167166  [19200/69274]
loss: 0.168306  [25600/69274]
loss: 0.221530  [32000/69274]
loss: 0.125523  [38400/69274]
loss: 0.175232  [44800/69274]
loss: 0.104605  [51200/69274]
loss: 0.110446  [57600/69274]
loss: 0.143940  [64000/69274]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180058 

Epoch 11
-------------------------------
loss: 0.215736  [    0/69274]
loss: 0.221043  [ 6400/69274]
loss: 0.166833  [12800/69274]
loss: 0.198325  [19200/69274]
loss: 1.702644  [25600/69274]
loss: 0.146585  [32000/69274]
loss: 0.116796  [38400/69274]
loss: 0.163837  [44800/69274]
loss: 0.252589  [51200/69274]
loss: 0.142819  [57600/69274]
loss: 1.788264  [64000/69274]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.184014 

Epoch 12
-------------------------------
loss: 0.153796  [    0/69274]
loss: 0.130650  [ 6400/69274]
loss: 0.223524  [12800/69274]
loss: 0.125292  [19200/69274]
loss: 0.189250  [25600/69274]
loss: 0.108470  [32000/69274]
loss: 0.201690  [38400/69274]
loss: 0.204298  [44800/69274]
loss: 0.207822  [51200/69274]
loss: 1.740097  [57600/69274]
loss: 0.215351  [64000/69274]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.184058 

Epoch 13
-------------------------------
loss: 0.101585  [    0/69274]
loss: 0.109723  [ 6400/69274]
loss: 0.122972  [12800/69274]
loss: 0.104952  [19200/69274]
loss: 0.070189  [25600/69274]
loss: 0.098304  [32000/69274]
loss: 0.182827  [38400/69274]
loss: 0.344612  [44800/69274]
loss: 0.139236  [51200/69274]
loss: 0.081886  [57600/69274]
loss: 0.109127  [64000/69274]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.181089 

Epoch 14
-------------------------------
loss: 0.153653  [    0/69274]
loss: 0.403128  [ 6400/69274]
loss: 0.165229  [12800/69274]
loss: 0.049355  [19200/69274]
loss: 0.179767  [25600/69274]
loss: 0.271569  [32000/69274]
loss: 0.133448  [38400/69274]
loss: 0.172447  [44800/69274]
loss: 0.109934  [51200/69274]
loss: 0.166362  [57600/69274]
loss: 0.091562  [64000/69274]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.177445 

Epoch 15
-------------------------------
loss: 0.243022  [    0/69274]
loss: 0.131580  [ 6400/69274]
loss: 1.775043  [12800/69274]
loss: 0.134099  [19200/69274]
loss: 0.236992  [25600/69274]
loss: 0.162240  [32000/69274]
loss: 0.081941  [38400/69274]
loss: 0.096139  [44800/69274]
loss: 0.067503  [51200/69274]
loss: 0.105302  [57600/69274]
loss: 0.131294  [64000/69274]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.186377 

Epoch 16
-------------------------------
loss: 0.183644  [    0/69274]
loss: 0.214038  [ 6400/69274]
loss: 0.149505  [12800/69274]
loss: 0.155188  [19200/69274]
loss: 0.058346  [25600/69274]
loss: 0.184302  [32000/69274]
loss: 0.049664  [38400/69274]
loss: 0.222327  [44800/69274]
loss: 0.332036  [51200/69274]
loss: 0.234086  [57600/69274]
loss: 0.160820  [64000/69274]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.201411 

Epoch 17
-------------------------------
loss: 0.133988  [    0/69274]
loss: 0.185161  [ 6400/69274]
loss: 0.196071  [12800/69274]
loss: 0.082604  [19200/69274]
loss: 0.085337  [25600/69274]
loss: 0.216401  [32000/69274]
loss: 0.096960  [38400/69274]
loss: 0.097336  [44800/69274]
loss: 0.174522  [51200/69274]
loss: 0.122093  [57600/69274]
loss: 0.119600  [64000/69274]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.182136 

Epoch 18
-------------------------------
loss: 0.183727  [    0/69274]
loss: 0.112838  [ 6400/69274]
loss: 0.121828  [12800/69274]
loss: 0.276744  [19200/69274]
loss: 0.173381  [25600/69274]
loss: 0.116103  [32000/69274]
loss: 0.131189  [38400/69274]
loss: 0.090584  [44800/69274]
loss: 0.238563  [51200/69274]
loss: 0.110221  [57600/69274]
loss: 0.123530  [64000/69274]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.180001 

Epoch 19
-------------------------------
loss: 0.136820  [    0/69274]
loss: 0.183855  [ 6400/69274]
loss: 0.089414  [12800/69274]
loss: 0.158692  [19200/69274]
loss: 0.154862  [25600/69274]
loss: 0.062370  [32000/69274]
loss: 0.086163  [38400/69274]
loss: 0.200905  [44800/69274]
loss: 0.085345  [51200/69274]
loss: 0.188618  [57600/69274]
loss: 0.262317  [64000/69274]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.181625 

Epoch 20
-------------------------------
loss: 0.114714  [    0/69274]
loss: 0.224910  [ 6400/69274]
loss: 0.182925  [12800/69274]
loss: 0.152026  [19200/69274]
loss: 0.109671  [25600/69274]
loss: 0.153557  [32000/69274]
loss: 0.068823  [38400/69274]
loss: 0.219937  [44800/69274]
loss: 0.101863  [51200/69274]
loss: 0.125418  [57600/69274]
loss: 0.104612  [64000/69274]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.181889 

Epoch 21
-------------------------------
loss: 0.148519  [    0/69274]
loss: 0.176109  [ 6400/69274]
loss: 0.183500  [12800/69274]
loss: 0.142607  [19200/69274]
loss: 0.135393  [25600/69274]
loss: 0.158669  [32000/69274]
loss: 0.407145  [38400/69274]
loss: 0.167868  [44800/69274]
loss: 0.160614  [51200/69274]
loss: 0.108122  [57600/69274]
loss: 0.116494  [64000/69274]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.174105 

Epoch 22
-------------------------------
loss: 0.211514  [    0/69274]
loss: 0.318969  [ 6400/69274]
loss: 0.164135  [12800/69274]
loss: 0.068672  [19200/69274]
loss: 0.106248  [25600/69274]
loss: 0.058768  [32000/69274]
loss: 0.162435  [38400/69274]
loss: 0.189210  [44800/69274]
loss: 0.131052  [51200/69274]
loss: 0.221055  [57600/69274]
loss: 0.207036  [64000/69274]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.173157 

Epoch 23
-------------------------------
loss: 0.106716  [    0/69274]
loss: 0.159571  [ 6400/69274]
loss: 0.248528  [12800/69274]
loss: 0.078129  [19200/69274]
loss: 0.156549  [25600/69274]
loss: 0.160171  [32000/69274]
loss: 0.131842  [38400/69274]
loss: 0.136328  [44800/69274]
loss: 0.122832  [51200/69274]
loss: 0.122718  [57600/69274]
loss: 0.089974  [64000/69274]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.173397 

Epoch 24
-------------------------------
loss: 0.084910  [    0/69274]
loss: 0.208645  [ 6400/69274]
loss: 0.161469  [12800/69274]
loss: 0.137392  [19200/69274]
loss: 0.074356  [25600/69274]
loss: 0.139093  [32000/69274]
loss: 0.077402  [38400/69274]
loss: 0.123288  [44800/69274]
loss: 0.275432  [51200/69274]
loss: 0.092094  [57600/69274]
loss: 0.152280  [64000/69274]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.170512 

Epoch 25
-------------------------------
loss: 0.215459  [    0/69274]
loss: 0.229845  [ 6400/69274]
loss: 1.663191  [12800/69274]
loss: 0.136608  [19200/69274]
loss: 0.155819  [25600/69274]
loss: 0.122683  [32000/69274]
loss: 0.271931  [38400/69274]
loss: 0.075837  [44800/69274]
loss: 0.081017  [51200/69274]
loss: 0.141597  [57600/69274]
loss: 0.160792  [64000/69274]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.194077 

Epoch 26
-------------------------------
loss: 0.141293  [    0/69274]
loss: 0.090538  [ 6400/69274]
loss: 0.106915  [12800/69274]
loss: 0.133260  [19200/69274]
loss: 0.110440  [25600/69274]
loss: 0.157824  [32000/69274]
loss: 1.720299  [38400/69274]
loss: 0.136277  [44800/69274]
loss: 0.064381  [51200/69274]
loss: 0.090865  [57600/69274]
loss: 0.046299  [64000/69274]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.181642 

Test Error: 
 Accuracy: 96.0%, Avg loss: 0.129251 

Epoch 15
-------------------------------
loss: 0.142572  [    0/69641]
loss: 0.150228  [ 6400/69641]
loss: 0.135148  [12800/69641]
loss: 0.068516  [19200/69641]
loss: 0.065330  [25600/69641]
loss: 0.092962  [32000/69641]
loss: 0.124062  [38400/69641]
loss: 0.157831  [44800/69641]
loss: 0.156411  [51200/69641]
loss: 0.061849  [57600/69641]
loss: 0.187536  [64000/69641]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.120093 

Epoch 16
-------------------------------
loss: 0.047355  [    0/69641]
loss: 0.086263  [ 6400/69641]
loss: 0.160570  [12800/69641]
loss: 0.034662  [19200/69641]
loss: 0.206704  [25600/69641]
loss: 0.098016  [32000/69641]
loss: 0.110654  [38400/69641]
loss: 0.143442  [44800/69641]
loss: 0.096623  [51200/69641]
loss: 0.086330  [57600/69641]
loss: 0.079731  [64000/69641]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.145367 

Epoch 17
-------------------------------
loss: 0.086726  [    0/69641]
loss: 0.095047  [ 6400/69641]
loss: 0.068759  [12800/69641]
loss: 0.111403  [19200/69641]
loss: 0.142224  [25600/69641]
loss: 0.214826  [32000/69641]
loss: 0.128453  [38400/69641]
loss: 0.045656  [44800/69641]
loss: 0.080172  [51200/69641]
loss: 0.089032  [57600/69641]
loss: 0.106566  [64000/69641]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.113322 

Epoch 18
-------------------------------
loss: 0.061640  [    0/69641]
loss: 0.050725  [ 6400/69641]
loss: 0.055139  [12800/69641]
loss: 0.277852  [19200/69641]
loss: 0.080307  [25600/69641]
loss: 0.121677  [32000/69641]
loss: 0.081815  [38400/69641]
loss: 0.133975  [44800/69641]
loss: 0.100711  [51200/69641]
loss: 0.055019  [57600/69641]
loss: 0.155721  [64000/69641]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.142256 

Epoch 19
-------------------------------
loss: 0.175309  [    0/69641]
loss: 0.078624  [ 6400/69641]
loss: 0.096880  [12800/69641]
loss: 0.100773  [19200/69641]
loss: 0.092405  [25600/69641]
loss: 0.069544  [32000/69641]
loss: 0.065479  [38400/69641]
loss: 0.183042  [44800/69641]
loss: 0.120850  [51200/69641]
loss: 0.075575  [57600/69641]
loss: 0.096309  [64000/69641]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.112347 

Epoch 20
-------------------------------
loss: 0.037844  [    0/69641]
loss: 0.080514  [ 6400/69641]
loss: 0.021680  [12800/69641]
loss: 0.069759  [19200/69641]
loss: 0.073695  [25600/69641]
loss: 0.071467  [32000/69641]
loss: 0.173325  [38400/69641]
loss: 0.105895  [44800/69641]
loss: 0.056413  [51200/69641]
loss: 0.152955  [57600/69641]
loss: 0.092613  [64000/69641]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.120463 

Epoch 21
-------------------------------
loss: 0.165207  [    0/69641]
loss: 0.166015  [ 6400/69641]
loss: 0.054580  [12800/69641]
loss: 0.150924  [19200/69641]
loss: 0.108054  [25600/69641]
loss: 0.060736  [32000/69641]
loss: 0.088612  [38400/69641]
loss: 0.084877  [44800/69641]
loss: 0.072147  [51200/69641]
loss: 0.097151  [57600/69641]
loss: 0.152464  [64000/69641]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.129226 

Epoch 22
-------------------------------
loss: 0.105298  [    0/69641]
loss: 0.031464  [ 6400/69641]
loss: 0.147905  [12800/69641]
loss: 0.036238  [19200/69641]
loss: 0.161612  [25600/69641]
loss: 0.097246  [32000/69641]
loss: 0.094826  [38400/69641]
loss: 0.053952  [44800/69641]
loss: 0.242283  [51200/69641]
loss: 0.170873  [57600/69641]
loss: 0.048636  [64000/69641]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.111831 

Epoch 23
-------------------------------
loss: 0.065328  [    0/69641]
loss: 0.169523  [ 6400/69641]
loss: 0.056959  [12800/69641]
loss: 0.143642  [19200/69641]
loss: 0.048556  [25600/69641]
loss: 0.168903  [32000/69641]
loss: 0.105401  [38400/69641]
loss: 0.118173  [44800/69641]
loss: 0.058001  [51200/69641]
loss: 0.103994  [57600/69641]
loss: 0.088906  [64000/69641]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.217225 

Epoch 24
-------------------------------
loss: 0.229984  [    0/69641]
loss: 0.066209  [ 6400/69641]
loss: 0.105166  [12800/69641]
loss: 0.165833  [19200/69641]
loss: 0.076390  [25600/69641]
loss: 0.028457  [32000/69641]
loss: 0.114599  [38400/69641]
loss: 0.102350  [44800/69641]
loss: 0.178575  [51200/69641]
loss: 0.028020  [57600/69641]
loss: 0.110182  [64000/69641]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.113518 

Epoch 25
-------------------------------
loss: 0.075931  [    0/69641]
loss: 0.171986  [ 6400/69641]
loss: 0.056973  [12800/69641]
loss: 0.077809  [19200/69641]
loss: 0.070278  [25600/69641]
loss: 0.150323  [32000/69641]
loss: 0.042439  [38400/69641]
loss: 0.016194  [44800/69641]
loss: 0.105511  [51200/69641]
loss: 0.075301  [57600/69641]
loss: 0.067719  [64000/69641]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.155557 

Epoch 26
-------------------------------
loss: 0.111160  [    0/69641]
loss: 0.068596  [ 6400/69641]
loss: 0.055126  [12800/69641]
loss: 0.028691  [19200/69641]
loss: 0.101909  [25600/69641]
loss: 0.115231  [32000/69641]
loss: 0.108750  [38400/69641]
loss: 0.057846  [44800/69641]
loss: 0.069078  [51200/69641]
loss: 0.190939  [57600/69641]
loss: 0.153541  [64000/69641]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.109903 

Epoch 27
-------------------------------
loss: 0.068205  [    0/69641]
loss: 0.139340  [ 6400/69641]
loss: 0.108558  [12800/69641]
loss: 0.082511  [19200/69641]
loss: 0.070675  [25600/69641]
loss: 0.054281  [32000/69641]
loss: 0.077003  [38400/69641]
loss: 0.056638  [44800/69641]
loss: 0.063797  [51200/69641]
loss: 0.050674  [57600/69641]
loss: 0.059716  [64000/69641]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.104410 

Epoch 28
-------------------------------
loss: 0.077595  [    0/69641]
loss: 0.116308  [ 6400/69641]
loss: 0.130178  [12800/69641]
loss: 0.070194  [19200/69641]
loss: 0.096334  [25600/69641]
loss: 0.204062  [32000/69641]
loss: 0.058953  [38400/69641]
loss: 0.117434  [44800/69641]
loss: 0.017788  [51200/69641]
loss: 0.051121  [57600/69641]
loss: 0.127267  [64000/69641]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.136416 

Epoch 29
-------------------------------
loss: 0.083221  [    0/69641]
loss: 0.125485  [ 6400/69641]
loss: 0.089945  [12800/69641]
loss: 0.130906  [19200/69641]
loss: 0.091331  [25600/69641]
loss: 0.023545  [32000/69641]
loss: 0.183409  [38400/69641]
loss: 0.166008  [44800/69641]
loss: 0.102130  [51200/69641]
loss: 0.100781  [57600/69641]
loss: 0.103854  [64000/69641]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.122575 

Epoch 30
-------------------------------
loss: 0.040999  [    0/69641]
loss: 0.189328  [ 6400/69641]
loss: 0.175528  [12800/69641]
loss: 0.106165  [19200/69641]
loss: 0.089797  [25600/69641]
loss: 0.133511  [32000/69641]
loss: 0.076302  [38400/69641]
loss: 0.085230  [44800/69641]
loss: 0.052041  [51200/69641]
loss: 0.126362  [57600/69641]
loss: 0.195794  [64000/69641]
Test Error: 
 Accuracy: 89.7%, Avg loss: 0.216403 

Epoch 31
-------------------------------
loss: 0.161491  [    0/69641]
loss: 0.082496  [ 6400/69641]
loss: 0.202392  [12800/69641]
loss: 0.075812  [19200/69641]
loss: 0.064909  [25600/69641]
loss: 0.075474  [32000/69641]
loss: 0.074410  [38400/69641]
loss: 0.040983  [44800/69641]
loss: 0.087828  [51200/69641]
loss: 0.133795  [57600/69641]
loss: 0.054230  [64000/69641]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.121124 

Epoch 32
-------------------------------
loss: 0.109053  [    0/69641]
loss: 0.105116  [ 6400/69641]
loss: 0.103336  [12800/69641]
loss: 0.042137  [19200/69641]
loss: 0.042884  [25600/69641]
loss: 0.085460  [32000/69641]
loss: 0.172589  [38400/69641]
loss: 0.044211  [44800/69641]
loss: 0.110081  [51200/69641]
loss: 0.218927  [57600/69641]
loss: 0.130707  [64000/69641]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.108226 

Epoch 33
-------------------------------
loss: 0.025044  [    0/69641]
loss: 0.058489  [ 6400/69641]
loss: 0.067336  [12800/69641]
loss: 0.102492  [19200/69641]
loss: 0.186155  [25600/69641]
loss: 0.166158  [32000/69641]
loss: 0.069850  [38400/69641]
loss: 0.046178  [44800/69641]
loss: 0.049648  [51200/69641]
loss: 0.066625  [57600/69641]
loss: 0.287969  [64000/69641]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.132524 

Epoch 34
-------------------------------
loss: 0.137066  [    0/69641]
loss: 0.178382  [ 6400/69641]
loss: 0.118810  [64000/70852]
loss: 0.108229  [70400/70852]
Test Error: 
 Accuracy: 91.2%, Avg loss: 0.295088 

Epoch 14
-------------------------------
loss: 0.158925  [    0/70852]
loss: 0.065870  [ 6400/70852]
loss: 0.073913  [12800/70852]
loss: 0.143286  [19200/70852]
loss: 0.051228  [25600/70852]
loss: 0.140514  [32000/70852]
loss: 0.115659  [38400/70852]
loss: 0.208608  [44800/70852]
loss: 0.083854  [51200/70852]
loss: 0.105278  [57600/70852]
loss: 0.042496  [64000/70852]
loss: 0.092471  [70400/70852]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.217216 

Epoch 15
-------------------------------
loss: 0.220578  [    0/70852]
loss: 0.165710  [ 6400/70852]
loss: 0.184960  [12800/70852]
loss: 0.113814  [19200/70852]
loss: 0.193366  [25600/70852]
loss: 0.086690  [32000/70852]
loss: 0.100542  [38400/70852]
loss: 0.194426  [44800/70852]
loss: 0.172172  [51200/70852]
loss: 0.063170  [57600/70852]
loss: 0.064259  [64000/70852]
loss: 0.156955  [70400/70852]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.197906 

Epoch 16
-------------------------------
loss: 0.144815  [    0/70852]
loss: 0.117060  [ 6400/70852]
loss: 0.210757  [12800/70852]
loss: 0.129170  [19200/70852]
loss: 0.120497  [25600/70852]
loss: 0.141260  [32000/70852]
loss: 0.082895  [38400/70852]
loss: 0.162192  [44800/70852]
loss: 0.119342  [51200/70852]
loss: 0.150806  [57600/70852]
loss: 0.070166  [64000/70852]
loss: 0.115273  [70400/70852]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.187313 

Epoch 17
-------------------------------
loss: 0.165656  [    0/70852]
loss: 0.036651  [ 6400/70852]
loss: 0.077641  [12800/70852]
loss: 0.054459  [19200/70852]
loss: 0.105335  [25600/70852]
loss: 0.180781  [32000/70852]
loss: 0.064784  [38400/70852]
loss: 0.092708  [44800/70852]
loss: 0.092485  [51200/70852]
loss: 0.079750  [57600/70852]
loss: 0.126329  [64000/70852]
loss: 0.164088  [70400/70852]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.176460 

Epoch 18
-------------------------------
loss: 0.083465  [    0/70852]
loss: 0.087565  [ 6400/70852]
loss: 0.072607  [12800/70852]
loss: 0.035114  [19200/70852]
loss: 0.125167  [25600/70852]
loss: 0.179144  [32000/70852]
loss: 0.260342  [38400/70852]
loss: 1.711049  [44800/70852]
loss: 0.106654  [51200/70852]
loss: 1.764034  [57600/70852]
loss: 0.102867  [64000/70852]
loss: 0.112247  [70400/70852]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.279369 

Epoch 19
-------------------------------
loss: 0.050035  [    0/70852]
loss: 0.069097  [ 6400/70852]
loss: 0.152615  [12800/70852]
loss: 0.107023  [19200/70852]
loss: 0.109979  [25600/70852]
loss: 0.156818  [32000/70852]
loss: 0.118070  [38400/70852]
loss: 0.159979  [44800/70852]
loss: 0.118394  [51200/70852]
loss: 0.118067  [57600/70852]
loss: 0.060611  [64000/70852]
loss: 0.225483  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.162637 

Epoch 20
-------------------------------
loss: 0.171446  [    0/70852]
loss: 0.111949  [ 6400/70852]
loss: 0.149614  [12800/70852]
loss: 0.121901  [19200/70852]
loss: 0.119243  [25600/70852]
loss: 0.040413  [32000/70852]
loss: 0.154466  [38400/70852]
loss: 0.206903  [44800/70852]
loss: 0.154693  [51200/70852]
loss: 0.130930  [57600/70852]
loss: 0.132119  [64000/70852]
loss: 0.072567  [70400/70852]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.170445 

Epoch 21
-------------------------------
loss: 0.058706  [    0/70852]
loss: 0.122949  [ 6400/70852]
loss: 0.121857  [12800/70852]
loss: 0.154391  [19200/70852]
loss: 0.117649  [25600/70852]
loss: 0.109452  [32000/70852]
loss: 0.076159  [38400/70852]
loss: 0.079892  [44800/70852]
loss: 0.094634  [51200/70852]
loss: 0.076489  [57600/70852]
loss: 0.122202  [64000/70852]
loss: 0.082693  [70400/70852]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.186301 

Epoch 22
-------------------------------
loss: 0.230871  [    0/70852]
loss: 0.079006  [ 6400/70852]
loss: 0.059910  [12800/70852]
loss: 0.123734  [19200/70852]
loss: 0.064645  [25600/70852]
loss: 0.066051  [32000/70852]
loss: 0.200106  [38400/70852]
loss: 0.041176  [44800/70852]
loss: 0.090466  [51200/70852]
loss: 0.120133  [57600/70852]
loss: 0.135962  [64000/70852]
loss: 1.650138  [70400/70852]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.163204 

Epoch 23
-------------------------------
loss: 0.074474  [    0/70852]
loss: 0.104279  [ 6400/70852]
loss: 0.228368  [12800/70852]
loss: 0.070597  [19200/70852]
loss: 0.047741  [25600/70852]
loss: 0.130802  [32000/70852]
loss: 0.079923  [38400/70852]
loss: 0.065639  [44800/70852]
loss: 0.117180  [51200/70852]
loss: 0.199041  [57600/70852]
loss: 0.061601  [64000/70852]
loss: 0.084698  [70400/70852]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.168685 

Epoch 24
-------------------------------
loss: 0.087533  [    0/70852]
loss: 0.096323  [ 6400/70852]
loss: 0.110958  [12800/70852]
loss: 0.109587  [19200/70852]
loss: 0.068353  [25600/70852]
loss: 0.064981  [32000/70852]
loss: 0.173908  [38400/70852]
loss: 1.622366  [44800/70852]
loss: 0.128401  [51200/70852]
loss: 0.124125  [57600/70852]
loss: 0.213950  [64000/70852]
loss: 0.141176  [70400/70852]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.194586 

Epoch 25
-------------------------------
loss: 0.077543  [    0/70852]
loss: 0.064505  [ 6400/70852]
loss: 0.173987  [12800/70852]
loss: 0.118464  [19200/70852]
loss: 0.114990  [25600/70852]
loss: 0.060407  [32000/70852]
loss: 0.088012  [38400/70852]
loss: 0.106133  [44800/70852]
loss: 0.084279  [51200/70852]
loss: 0.187271  [57600/70852]
loss: 0.100812  [64000/70852]
loss: 0.086658  [70400/70852]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.162508 

Epoch 26
-------------------------------
loss: 0.056231  [    0/70852]
loss: 0.178639  [ 6400/70852]
loss: 0.103961  [12800/70852]
loss: 0.105131  [19200/70852]
loss: 0.139176  [25600/70852]
loss: 0.230419  [32000/70852]
loss: 0.120288  [38400/70852]
loss: 0.115848  [44800/70852]
loss: 0.184764  [51200/70852]
loss: 0.152505  [57600/70852]
loss: 0.146627  [64000/70852]
loss: 0.149014  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.166211 

Epoch 27
-------------------------------
loss: 0.094552  [    0/70852]
loss: 0.129903  [ 6400/70852]
loss: 0.126084  [12800/70852]
loss: 0.114184  [19200/70852]
loss: 0.146360  [25600/70852]
loss: 0.071632  [32000/70852]
loss: 0.092158  [38400/70852]
loss: 0.103559  [44800/70852]
loss: 0.239445  [51200/70852]
loss: 0.195138  [57600/70852]
loss: 0.091751  [64000/70852]
loss: 0.075559  [70400/70852]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.162734 

Epoch 28
-------------------------------
loss: 0.101496  [    0/70852]
loss: 0.107306  [ 6400/70852]
loss: 0.091305  [12800/70852]
loss: 0.061448  [19200/70852]
loss: 0.116815  [25600/70852]
loss: 0.135579  [32000/70852]
loss: 0.111548  [38400/70852]
loss: 0.026492  [44800/70852]
loss: 0.173025  [51200/70852]
loss: 0.126889  [57600/70852]
loss: 0.246746  [64000/70852]
loss: 0.133258  [70400/70852]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.184724 

Epoch 29
-------------------------------
loss: 0.102378  [    0/70852]
loss: 0.248045  [ 6400/70852]
loss: 0.171374  [12800/70852]
loss: 0.075279  [19200/70852]
loss: 0.049260  [25600/70852]
loss: 0.078467  [32000/70852]
loss: 0.085663  [38400/70852]
loss: 0.131447  [44800/70852]
loss: 0.060513  [51200/70852]
loss: 0.090398  [57600/70852]
loss: 0.107776  [64000/70852]
loss: 0.108939  [70400/70852]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.167497 

Epoch 30
-------------------------------
loss: 0.094704  [    0/70852]
loss: 0.135051  [ 6400/70852]
loss: 0.093911  [12800/70852]
loss: 0.143667  [19200/70852]
loss: 0.057454  [25600/70852]
loss: 1.641012  [32000/70852]
loss: 0.089754  [38400/70852]
loss: 0.101862  [44800/70852]
loss: 0.154268  [51200/70852]
loss: 0.030913  [57600/70852]
loss: 0.129595  [64000/70852]
loss: 0.040661  [70400/70852]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.165887 

Epoch 31
-------------------------------
loss: 0.013936  [    0/70852]
loss: 0.155602  [ 6400/70852]
loss: 0.181238  [12800/70852]
loss: 0.034450  [19200/70852]
loss: 0.107426  [25600/70852]
loss: 0.092245  [32000/70852]
loss: 0.057303  [38400/70852]
loss: 0.063890  [44800/70852]
loss: 0.165567  [51200/70852]
loss: 0.097237  [57600/70852]
loss: 0.084501  [64000/70852]
loss: 0.103544  [12800/69949]
loss: 0.058622  [19200/69949]
loss: 0.203690  [25600/69949]
loss: 0.092066  [32000/69949]
loss: 0.126817  [38400/69949]
loss: 0.129885  [44800/69949]
loss: 0.084332  [51200/69949]
loss: 0.209220  [57600/69949]
loss: 0.136140  [64000/69949]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.156481 

Epoch 12
-------------------------------
loss: 0.200122  [    0/69949]
loss: 0.102391  [ 6400/69949]
loss: 0.106743  [12800/69949]
loss: 0.186855  [19200/69949]
loss: 0.107318  [25600/69949]
loss: 0.107221  [32000/69949]
loss: 0.074261  [38400/69949]
loss: 0.132599  [44800/69949]
loss: 0.099543  [51200/69949]
loss: 0.165283  [57600/69949]
loss: 0.188184  [64000/69949]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.155967 

Epoch 13
-------------------------------
loss: 0.117571  [    0/69949]
loss: 0.124368  [ 6400/69949]
loss: 0.102211  [12800/69949]
loss: 0.083653  [19200/69949]
loss: 0.069406  [25600/69949]
loss: 0.150059  [32000/69949]
loss: 0.121743  [38400/69949]
loss: 0.153608  [44800/69949]
loss: 0.120615  [51200/69949]
loss: 0.127291  [57600/69949]
loss: 0.112724  [64000/69949]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.155221 

Epoch 14
-------------------------------
loss: 0.102083  [    0/69949]
loss: 0.095957  [ 6400/69949]
loss: 0.103623  [12800/69949]
loss: 0.121875  [19200/69949]
loss: 0.179762  [25600/69949]
loss: 0.061796  [32000/69949]
loss: 0.160927  [38400/69949]
loss: 0.110498  [44800/69949]
loss: 0.107486  [51200/69949]
loss: 0.104511  [57600/69949]
loss: 0.181700  [64000/69949]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.164256 

Epoch 15
-------------------------------
loss: 0.100556  [    0/69949]
loss: 0.119095  [ 6400/69949]
loss: 0.125143  [12800/69949]
loss: 0.170838  [19200/69949]
loss: 0.133740  [25600/69949]
loss: 0.272312  [32000/69949]
loss: 0.166492  [38400/69949]
loss: 0.178210  [44800/69949]
loss: 0.161886  [51200/69949]
loss: 0.091444  [57600/69949]
loss: 0.083759  [64000/69949]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.151038 

Epoch 16
-------------------------------
loss: 0.121541  [    0/69949]
loss: 0.187029  [ 6400/69949]
loss: 0.101560  [12800/69949]
loss: 0.065412  [19200/69949]
loss: 0.228115  [25600/69949]
loss: 0.078456  [32000/69949]
loss: 0.095530  [38400/69949]
loss: 0.138329  [44800/69949]
loss: 0.209748  [51200/69949]
loss: 0.188243  [57600/69949]
loss: 0.165797  [64000/69949]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.154212 

Epoch 17
-------------------------------
loss: 0.173185  [    0/69949]
loss: 0.087055  [ 6400/69949]
loss: 0.147384  [12800/69949]
loss: 0.179920  [19200/69949]
loss: 0.198673  [25600/69949]
loss: 0.170645  [32000/69949]
loss: 0.153581  [38400/69949]
loss: 0.297576  [44800/69949]
loss: 0.146561  [51200/69949]
loss: 0.188661  [57600/69949]
loss: 0.065516  [64000/69949]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.149105 

Epoch 18
-------------------------------
loss: 0.167859  [    0/69949]
loss: 0.149541  [ 6400/69949]
loss: 0.158379  [12800/69949]
loss: 0.167240  [19200/69949]
loss: 0.126566  [25600/69949]
loss: 0.168134  [32000/69949]
loss: 0.114506  [38400/69949]
loss: 0.166613  [44800/69949]
loss: 0.141195  [51200/69949]
loss: 0.220776  [57600/69949]
loss: 0.145010  [64000/69949]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.158877 

Epoch 19
-------------------------------
loss: 0.117539  [    0/69949]
loss: 0.118307  [ 6400/69949]
loss: 0.341878  [12800/69949]
loss: 0.118917  [19200/69949]
loss: 0.177954  [25600/69949]
loss: 0.231339  [32000/69949]
loss: 0.109132  [38400/69949]
loss: 0.139248  [44800/69949]
loss: 0.190397  [51200/69949]
loss: 0.172145  [57600/69949]
loss: 0.113344  [64000/69949]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.150123 

Epoch 20
-------------------------------
loss: 0.094392  [    0/69949]
loss: 0.220001  [ 6400/69949]
loss: 0.105855  [12800/69949]
loss: 0.117289  [19200/69949]
loss: 0.133179  [25600/69949]
loss: 0.110419  [32000/69949]
loss: 0.100367  [38400/69949]
loss: 0.190173  [44800/69949]
loss: 0.237471  [51200/69949]
loss: 0.186355  [57600/69949]
loss: 0.139118  [64000/69949]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.149143 

Epoch 21
-------------------------------
loss: 0.033524  [    0/69949]
loss: 0.160847  [ 6400/69949]
loss: 0.099742  [12800/69949]
loss: 1.718070  [19200/69949]
loss: 0.177191  [25600/69949]
loss: 0.218054  [32000/69949]
loss: 0.222762  [38400/69949]
loss: 0.171132  [44800/69949]
loss: 0.105811  [51200/69949]
loss: 0.093425  [57600/69949]
loss: 0.030519  [64000/69949]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.150094 

Epoch 22
-------------------------------
loss: 0.209846  [    0/69949]
loss: 0.187471  [ 6400/69949]
loss: 0.169701  [12800/69949]
loss: 0.120725  [19200/69949]
loss: 0.115921  [25600/69949]
loss: 0.116632  [32000/69949]
loss: 0.040694  [38400/69949]
loss: 0.232496  [44800/69949]
loss: 0.308256  [51200/69949]
loss: 0.101306  [57600/69949]
loss: 0.040879  [64000/69949]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.149763 

Epoch 23
-------------------------------
loss: 0.097498  [    0/69949]
loss: 0.099452  [ 6400/69949]
loss: 0.137059  [12800/69949]
loss: 0.145170  [19200/69949]
loss: 0.144177  [25600/69949]
loss: 0.117754  [32000/69949]
loss: 0.158486  [38400/69949]
loss: 0.103479  [44800/69949]
loss: 0.073544  [51200/69949]
loss: 0.117931  [57600/69949]
loss: 0.106142  [64000/69949]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.145053 

Epoch 24
-------------------------------
loss: 0.139673  [    0/69949]
loss: 0.075686  [ 6400/69949]
loss: 0.124918  [12800/69949]
loss: 0.146575  [19200/69949]
loss: 0.115904  [25600/69949]
loss: 0.224133  [32000/69949]
loss: 0.108288  [38400/69949]
loss: 0.293715  [44800/69949]
loss: 0.123310  [51200/69949]
loss: 0.196877  [57600/69949]
loss: 0.281172  [64000/69949]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160041 

Epoch 25
-------------------------------
loss: 0.131462  [    0/69949]
loss: 0.138056  [ 6400/69949]
loss: 0.086928  [12800/69949]
loss: 0.114221  [19200/69949]
loss: 0.165714  [25600/69949]
loss: 0.061295  [32000/69949]
loss: 0.049874  [38400/69949]
loss: 0.079522  [44800/69949]
loss: 0.078865  [51200/69949]
loss: 0.146132  [57600/69949]
loss: 0.110465  [64000/69949]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.154000 

Epoch 26
-------------------------------
loss: 0.183895  [    0/69949]
loss: 0.259347  [ 6400/69949]
loss: 0.065069  [12800/69949]
loss: 0.117818  [19200/69949]
loss: 0.068521  [25600/69949]
loss: 0.087048  [32000/69949]
loss: 0.112583  [38400/69949]
loss: 0.157334  [44800/69949]
loss: 0.143156  [51200/69949]
loss: 0.091472  [57600/69949]
loss: 0.098984  [64000/69949]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.147523 

Epoch 27
-------------------------------
loss: 0.174078  [    0/69949]
loss: 0.084713  [ 6400/69949]
loss: 0.218483  [12800/69949]
loss: 0.128140  [19200/69949]
loss: 0.100938  [25600/69949]
loss: 0.200297  [32000/69949]
loss: 0.113255  [38400/69949]
loss: 0.154075  [44800/69949]
loss: 0.124363  [51200/69949]
loss: 0.108222  [57600/69949]
loss: 0.085571  [64000/69949]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146817 

Epoch 28
-------------------------------
loss: 0.174658  [    0/69949]
loss: 0.112827  [ 6400/69949]
loss: 0.074606  [12800/69949]
loss: 0.073288  [19200/69949]
loss: 0.203468  [25600/69949]
loss: 0.178562  [32000/69949]
loss: 0.073545  [38400/69949]
loss: 0.090911  [44800/69949]
loss: 0.101887  [51200/69949]
loss: 0.059828  [57600/69949]
loss: 0.103770  [64000/69949]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.156370 

Epoch 29
-------------------------------
loss: 0.107438  [    0/69949]
loss: 0.159931  [ 6400/69949]
loss: 0.113553  [12800/69949]
loss: 0.116705  [19200/69949]
loss: 0.115012  [25600/69949]
loss: 0.112695  [32000/69949]
loss: 0.045408  [38400/69949]
loss: 0.141476  [44800/69949]
loss: 0.088329  [51200/69949]
loss: 0.130948  [57600/69949]
loss: 0.076313  [64000/69949]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.155270 

Epoch 30
-------------------------------
loss: 0.050904  [    0/69949]
loss: 0.178608  [ 6400/69949]
loss: 0.103225  [12800/69949]
loss: 0.134687  [19200/69949]
loss: 0.074606  [25600/69949]
loss: 0.138415  [32000/69949]
loss: 0.032932  [38400/69949]
loss: 0.102260  [25600/70487]
loss: 0.151320  [32000/70487]
loss: 0.127085  [38400/70487]
loss: 1.812457  [44800/70487]
loss: 0.104018  [51200/70487]
loss: 0.210478  [57600/70487]
loss: 0.222088  [64000/70487]
loss: 0.183271  [70400/70487]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.188433 

Epoch 26
-------------------------------
loss: 0.113973  [    0/70487]
loss: 0.059716  [ 6400/70487]
loss: 0.096632  [12800/70487]
loss: 0.200566  [19200/70487]
loss: 1.744529  [25600/70487]
loss: 0.263731  [32000/70487]
loss: 0.087731  [38400/70487]
loss: 0.270436  [44800/70487]
loss: 0.177950  [51200/70487]
loss: 0.331113  [57600/70487]
loss: 0.133196  [64000/70487]
loss: 0.191895  [70400/70487]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.201101 

Epoch 27
-------------------------------
loss: 0.242233  [    0/70487]
loss: 0.223489  [ 6400/70487]
loss: 0.043350  [12800/70487]
loss: 0.151329  [19200/70487]
loss: 0.113150  [25600/70487]
loss: 0.381138  [32000/70487]
loss: 0.159778  [38400/70487]
loss: 0.093034  [44800/70487]
loss: 0.066635  [51200/70487]
loss: 0.233502  [57600/70487]
loss: 0.222303  [64000/70487]
loss: 0.098203  [70400/70487]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.185228 

Epoch 28
-------------------------------
loss: 0.152075  [    0/70487]
loss: 0.138832  [ 6400/70487]
loss: 0.214778  [12800/70487]
loss: 0.099369  [19200/70487]
loss: 0.169818  [25600/70487]
loss: 0.226883  [32000/70487]
loss: 0.181206  [38400/70487]
loss: 0.191586  [44800/70487]
loss: 0.194528  [51200/70487]
loss: 0.217905  [57600/70487]
loss: 0.135497  [64000/70487]
loss: 0.231826  [70400/70487]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.187395 

Epoch 29
-------------------------------
loss: 0.213762  [    0/70487]
loss: 0.215575  [ 6400/70487]
loss: 0.325989  [12800/70487]
loss: 0.132926  [19200/70487]
loss: 0.052739  [25600/70487]
loss: 0.189030  [32000/70487]
loss: 0.082200  [38400/70487]
loss: 0.164621  [44800/70487]
loss: 0.150868  [51200/70487]
loss: 0.129146  [57600/70487]
loss: 1.696646  [64000/70487]
loss: 0.163269  [70400/70487]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.207134 

Epoch 30
-------------------------------
loss: 0.165830  [    0/70487]
loss: 0.104232  [ 6400/70487]
loss: 0.105449  [12800/70487]
loss: 0.134053  [19200/70487]
loss: 0.211155  [25600/70487]
loss: 0.232802  [32000/70487]
loss: 0.256920  [38400/70487]
loss: 0.161926  [44800/70487]
loss: 0.259969  [51200/70487]
loss: 0.093961  [57600/70487]
loss: 0.037400  [64000/70487]
loss: 0.338891  [70400/70487]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.217672 

Epoch 31
-------------------------------
loss: 0.180870  [    0/70487]
loss: 0.177172  [ 6400/70487]
loss: 0.187880  [12800/70487]
loss: 0.114341  [19200/70487]
loss: 0.139957  [25600/70487]
loss: 0.055246  [32000/70487]
loss: 0.198740  [38400/70487]
loss: 0.069504  [44800/70487]
loss: 0.144412  [51200/70487]
loss: 0.149944  [57600/70487]
loss: 0.080591  [64000/70487]
loss: 0.182293  [70400/70487]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.182881 

Epoch 32
-------------------------------
loss: 0.081749  [    0/70487]
loss: 0.197226  [ 6400/70487]
loss: 0.293769  [12800/70487]
loss: 0.139773  [19200/70487]
loss: 0.216071  [25600/70487]
loss: 0.058269  [32000/70487]
loss: 0.247895  [38400/70487]
loss: 0.140171  [44800/70487]
loss: 0.104514  [51200/70487]
loss: 0.275646  [57600/70487]
loss: 0.166349  [64000/70487]
loss: 1.709996  [70400/70487]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.194703 

Epoch 33
-------------------------------
loss: 0.250797  [    0/70487]
loss: 0.163291  [ 6400/70487]
loss: 0.120806  [12800/70487]
loss: 0.220691  [19200/70487]
loss: 0.131330  [25600/70487]
loss: 0.219092  [32000/70487]
loss: 0.033225  [38400/70487]
loss: 0.111204  [44800/70487]
loss: 0.161367  [51200/70487]
loss: 0.101043  [57600/70487]
loss: 0.143003  [64000/70487]
loss: 0.127970  [70400/70487]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.186459 

Epoch 34
-------------------------------
loss: 0.103857  [    0/70487]
loss: 0.104528  [ 6400/70487]
loss: 0.112424  [12800/70487]
loss: 0.207253  [19200/70487]
loss: 0.199489  [25600/70487]
loss: 0.114423  [32000/70487]
loss: 0.154931  [38400/70487]
loss: 0.230002  [44800/70487]
loss: 0.298221  [51200/70487]
loss: 0.191332  [57600/70487]
loss: 0.102597  [64000/70487]
loss: 0.210822  [70400/70487]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.236479 

Epoch 35
-------------------------------
loss: 0.091126  [    0/70487]
loss: 0.173212  [ 6400/70487]
loss: 0.143348  [12800/70487]
loss: 0.351944  [19200/70487]
loss: 0.267552  [25600/70487]
loss: 0.172967  [32000/70487]
loss: 0.230047  [38400/70487]
loss: 0.175537  [44800/70487]
loss: 0.245130  [51200/70487]
loss: 0.212432  [57600/70487]
loss: 0.123057  [64000/70487]
loss: 0.204070  [70400/70487]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.194550 

Epoch 36
-------------------------------
loss: 0.226304  [    0/70487]
loss: 0.132282  [ 6400/70487]
loss: 0.157265  [12800/70487]
loss: 0.113822  [19200/70487]
loss: 0.121648  [25600/70487]
loss: 0.215120  [32000/70487]
loss: 0.163704  [38400/70487]
loss: 0.069738  [44800/70487]
loss: 0.083424  [51200/70487]
loss: 0.236578  [57600/70487]
loss: 0.157778  [64000/70487]
loss: 0.185746  [70400/70487]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.227476 

Epoch 37
-------------------------------
loss: 0.074332  [    0/70487]
loss: 0.241211  [ 6400/70487]
loss: 0.284991  [12800/70487]
loss: 0.048117  [19200/70487]
loss: 0.147872  [25600/70487]
loss: 0.147800  [32000/70487]
loss: 0.062120  [38400/70487]
loss: 0.187410  [44800/70487]
loss: 0.209481  [51200/70487]
loss: 0.214621  [57600/70487]
loss: 0.260290  [64000/70487]
loss: 0.160640  [70400/70487]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.196727 

Epoch 38
-------------------------------
loss: 0.102307  [    0/70487]
loss: 0.243347  [ 6400/70487]
loss: 0.128554  [12800/70487]
loss: 0.073214  [19200/70487]
loss: 0.191491  [25600/70487]
loss: 0.176940  [32000/70487]
loss: 0.172967  [38400/70487]
loss: 0.199784  [44800/70487]
loss: 0.276361  [51200/70487]
loss: 0.180346  [57600/70487]
loss: 0.161005  [64000/70487]
loss: 0.203108  [70400/70487]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.191345 

Epoch 39
-------------------------------
loss: 0.101663  [    0/70487]
loss: 0.131975  [ 6400/70487]
loss: 3.229653  [12800/70487]
loss: 0.198345  [19200/70487]
loss: 0.174293  [25600/70487]
loss: 1.708344  [32000/70487]
loss: 0.120477  [38400/70487]
loss: 0.157660  [44800/70487]
loss: 0.140146  [51200/70487]
loss: 0.097035  [57600/70487]
loss: 0.201601  [64000/70487]
loss: 0.239474  [70400/70487]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.204896 

Epoch 40
-------------------------------
loss: 0.269098  [    0/70487]
loss: 0.240464  [ 6400/70487]
loss: 0.142985  [12800/70487]
loss: 0.184170  [19200/70487]
loss: 0.080079  [25600/70487]
loss: 1.732735  [32000/70487]
loss: 0.196627  [38400/70487]
loss: 0.095670  [44800/70487]
loss: 1.656978  [51200/70487]
loss: 0.074481  [57600/70487]
loss: 0.274135  [64000/70487]
loss: 0.162343  [70400/70487]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.200091 

Epoch 41
-------------------------------
loss: 0.291167  [    0/70487]
loss: 0.178378  [ 6400/70487]
loss: 0.039565  [12800/70487]
loss: 0.141419  [19200/70487]
loss: 0.140842  [25600/70487]
loss: 0.154445  [32000/70487]
loss: 0.059330  [38400/70487]
loss: 0.213597  [44800/70487]
loss: 0.163265  [51200/70487]
loss: 0.166226  [57600/70487]
loss: 0.219626  [64000/70487]
loss: 0.114592  [70400/70487]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.194462 

Epoch 42
-------------------------------
loss: 1.742589  [    0/70487]
loss: 0.247913  [ 6400/70487]
loss: 0.211619  [12800/70487]
loss: 0.221604  [19200/70487]
loss: 0.121764  [25600/70487]
loss: 0.154947  [32000/70487]
loss: 0.181600  [38400/70487]
loss: 0.172054  [44800/70487]
loss: 0.076399  [51200/70487]
loss: 0.183216  [57600/70487]
loss: 0.187318  [64000/70487]
loss: 0.131198  [70400/70487]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.185696 

Epoch 43
-------------------------------
loss: 0.113986  [    0/70487]
loss: 0.157388  [ 6400/70487]
loss: 0.067626  [12800/70487]
loss: 0.122337  [19200/70487]
loss: 0.106622  [25600/70487]
loss: 0.237474  [12800/70738]
loss: 0.140668  [19200/70738]
loss: 0.133928  [25600/70738]
loss: 0.071388  [32000/70738]
loss: 0.164463  [38400/70738]
loss: 0.256443  [44800/70738]
loss: 0.323978  [51200/70738]
loss: 0.224611  [57600/70738]
loss: 0.101286  [64000/70738]
loss: 0.093217  [70400/70738]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.167107 

Epoch 50
-------------------------------
loss: 0.100002  [    0/70738]
loss: 0.114420  [ 6400/70738]
loss: 0.156473  [12800/70738]
loss: 0.125508  [19200/70738]
loss: 0.158727  [25600/70738]
loss: 0.164265  [32000/70738]
loss: 0.052709  [38400/70738]
loss: 0.183340  [44800/70738]
loss: 0.206685  [51200/70738]
loss: 0.115702  [57600/70738]
loss: 0.056477  [64000/70738]
loss: 0.205006  [70400/70738]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.161999 

Epoch 1
-------------------------------
loss: 0.771078  [    0/70480]
loss: 0.353933  [ 6400/70480]
loss: 0.372604  [12800/70480]
loss: 0.287060  [19200/70480]
loss: 0.238643  [25600/70480]
loss: 0.134277  [32000/70480]
loss: 0.325750  [38400/70480]
loss: 0.140096  [44800/70480]
loss: 0.243750  [51200/70480]
loss: 0.385829  [57600/70480]
loss: 0.417182  [64000/70480]
loss: 0.225414  [70400/70480]
Test Error: 
 Accuracy: 90.9%, Avg loss: 0.234298 

Epoch 2
-------------------------------
loss: 0.265264  [    0/70480]
loss: 0.330586  [ 6400/70480]
loss: 0.186284  [12800/70480]
loss: 0.404443  [19200/70480]
loss: 0.185629  [25600/70480]
loss: 0.112125  [32000/70480]
loss: 0.157471  [38400/70480]
loss: 0.157234  [44800/70480]
loss: 0.235291  [51200/70480]
loss: 0.221319  [57600/70480]
loss: 0.301113  [64000/70480]
loss: 0.233114  [70400/70480]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.210800 

Epoch 3
-------------------------------
loss: 0.164244  [    0/70480]
loss: 0.286067  [ 6400/70480]
loss: 0.371495  [12800/70480]
loss: 0.156930  [19200/70480]
loss: 0.107683  [25600/70480]
loss: 0.224515  [32000/70480]
loss: 0.139897  [38400/70480]
loss: 0.224151  [44800/70480]
loss: 0.346379  [51200/70480]
loss: 0.365633  [57600/70480]
loss: 0.322138  [64000/70480]
loss: 0.190828  [70400/70480]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.218049 

Epoch 4
-------------------------------
loss: 0.388688  [    0/70480]
loss: 0.245487  [ 6400/70480]
loss: 0.225989  [12800/70480]
loss: 0.114742  [19200/70480]
loss: 0.144813  [25600/70480]
loss: 0.141063  [32000/70480]
loss: 0.303949  [38400/70480]
loss: 0.176353  [44800/70480]
loss: 0.215057  [51200/70480]
loss: 0.216568  [57600/70480]
loss: 0.105160  [64000/70480]
loss: 0.302366  [70400/70480]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.202347 

Epoch 5
-------------------------------
loss: 0.212264  [    0/70480]
loss: 0.181420  [ 6400/70480]
loss: 0.186911  [12800/70480]
loss: 0.222532  [19200/70480]
loss: 0.163303  [25600/70480]
loss: 0.381677  [32000/70480]
loss: 0.085666  [38400/70480]
loss: 0.300423  [44800/70480]
loss: 0.228385  [51200/70480]
loss: 0.079324  [57600/70480]
loss: 0.194337  [64000/70480]
loss: 0.142092  [70400/70480]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.196152 

Epoch 6
-------------------------------
loss: 0.140785  [    0/70480]
loss: 0.212935  [ 6400/70480]
loss: 0.134316  [12800/70480]
loss: 0.101621  [19200/70480]
loss: 0.092130  [25600/70480]
loss: 0.349197  [32000/70480]
loss: 0.206354  [38400/70480]
loss: 0.138403  [44800/70480]
loss: 0.163493  [51200/70480]
loss: 0.210901  [57600/70480]
loss: 0.266040  [64000/70480]
loss: 0.189397  [70400/70480]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.187736 

Epoch 7
-------------------------------
loss: 0.073262  [    0/70480]
loss: 0.213752  [ 6400/70480]
loss: 0.221687  [12800/70480]
loss: 0.264797  [19200/70480]
loss: 0.256809  [25600/70480]
loss: 0.157014  [32000/70480]
loss: 0.218367  [38400/70480]
loss: 0.218284  [44800/70480]
loss: 0.101725  [51200/70480]
loss: 0.116472  [57600/70480]
loss: 0.191288  [64000/70480]
loss: 0.089241  [70400/70480]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.204313 

Epoch 8
-------------------------------
loss: 0.284496  [    0/70480]
loss: 0.106260  [ 6400/70480]
loss: 0.143192  [12800/70480]
loss: 0.249758  [19200/70480]
loss: 0.140412  [25600/70480]
loss: 0.182441  [32000/70480]
loss: 0.162033  [38400/70480]
loss: 0.116760  [44800/70480]
loss: 0.199186  [51200/70480]
loss: 0.219404  [57600/70480]
loss: 0.151084  [64000/70480]
loss: 0.138192  [70400/70480]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.211267 

Epoch 9
-------------------------------
loss: 0.122281  [    0/70480]
loss: 0.135743  [ 6400/70480]
loss: 0.220187  [12800/70480]
loss: 0.228858  [19200/70480]
loss: 0.098754  [25600/70480]
loss: 0.102506  [32000/70480]
loss: 0.172417  [38400/70480]
loss: 0.384346  [44800/70480]
loss: 0.184167  [51200/70480]
loss: 0.224121  [57600/70480]
loss: 0.175083  [64000/70480]
loss: 0.156526  [70400/70480]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.198255 

Epoch 10
-------------------------------
loss: 0.110969  [    0/70480]
loss: 0.103049  [ 6400/70480]
loss: 0.213043  [12800/70480]
loss: 0.087101  [19200/70480]
loss: 0.095680  [25600/70480]
loss: 0.236634  [32000/70480]
loss: 0.197076  [38400/70480]
loss: 0.186396  [44800/70480]
loss: 0.219635  [51200/70480]
loss: 0.109106  [57600/70480]
loss: 0.157071  [64000/70480]
loss: 0.179182  [70400/70480]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.184327 

Epoch 11
-------------------------------
loss: 0.236702  [    0/70480]
loss: 0.142166  [ 6400/70480]
loss: 0.134287  [12800/70480]
loss: 0.325315  [19200/70480]
loss: 0.211017  [25600/70480]
loss: 0.156024  [32000/70480]
loss: 0.086510  [38400/70480]
loss: 0.183542  [44800/70480]
loss: 0.177550  [51200/70480]
loss: 0.133535  [57600/70480]
loss: 0.203889  [64000/70480]
loss: 0.070787  [70400/70480]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.204847 

Epoch 12
-------------------------------
loss: 0.117806  [    0/70480]
loss: 0.132506  [ 6400/70480]
loss: 0.101387  [12800/70480]
loss: 0.200423  [19200/70480]
loss: 0.151314  [25600/70480]
loss: 0.190134  [32000/70480]
loss: 0.143884  [38400/70480]
loss: 0.096258  [44800/70480]
loss: 0.155747  [51200/70480]
loss: 1.709541  [57600/70480]
loss: 0.176411  [64000/70480]
loss: 0.155702  [70400/70480]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.180853 

Epoch 13
-------------------------------
loss: 0.172310  [    0/70480]
loss: 0.101415  [ 6400/70480]
loss: 0.175591  [12800/70480]
loss: 0.123833  [19200/70480]
loss: 0.204815  [25600/70480]
loss: 0.125660  [32000/70480]
loss: 0.127163  [38400/70480]
loss: 0.200673  [44800/70480]
loss: 0.113520  [51200/70480]
loss: 0.206651  [57600/70480]
loss: 0.111610  [64000/70480]
loss: 0.180381  [70400/70480]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.188056 

Epoch 14
-------------------------------
loss: 0.151243  [    0/70480]
loss: 1.660985  [ 6400/70480]
loss: 0.210392  [12800/70480]
loss: 0.099654  [19200/70480]
loss: 0.227472  [25600/70480]
loss: 0.103163  [32000/70480]
loss: 0.122807  [38400/70480]
loss: 0.122595  [44800/70480]
loss: 0.146726  [51200/70480]
loss: 0.215159  [57600/70480]
loss: 0.108329  [64000/70480]
loss: 0.172489  [70400/70480]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.176060 

Epoch 15
-------------------------------
loss: 0.122532  [    0/70480]
loss: 0.174400  [ 6400/70480]
loss: 0.226943  [12800/70480]
loss: 0.157399  [19200/70480]
loss: 0.141017  [25600/70480]
loss: 0.172783  [32000/70480]
loss: 0.115917  [38400/70480]
loss: 0.157407  [44800/70480]
loss: 0.199257  [51200/70480]
loss: 0.096484  [57600/70480]
loss: 0.228544  [64000/70480]
loss: 0.074454  [70400/70480]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.182913 

Epoch 16
-------------------------------
loss: 0.131100  [    0/70480]
loss: 0.113840  [ 6400/70480]
loss: 0.097937  [12800/70480]
loss: 0.122231  [19200/70480]
loss: 0.105324  [25600/70480]
loss: 0.069827  [32000/70480]
loss: 0.208627  [38400/70480]
loss: 0.166695  [44800/70480]
loss: 0.126097  [51200/70480]
loss: 0.205335  [57600/70480]
loss: 0.122461  [64000/70480]
loss: 0.099308  [70400/70480]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.180672 

Epoch 17
-------------------------------
loss: 0.146014  [    0/70480]
loss: 0.150370  [ 6400/70480]
loss: 0.178164  [12800/70480]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.227924 

Epoch 7
-------------------------------
loss: 0.123821  [    0/70533]
loss: 0.116510  [ 6400/70533]
loss: 0.214915  [12800/70533]
loss: 0.101265  [19200/70533]
loss: 0.132393  [25600/70533]
loss: 0.132757  [32000/70533]
loss: 0.255467  [38400/70533]
loss: 0.042304  [44800/70533]
loss: 0.129336  [51200/70533]
loss: 0.175635  [57600/70533]
loss: 0.208936  [64000/70533]
loss: 0.112111  [70400/70533]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.218141 

Epoch 8
-------------------------------
loss: 0.070100  [    0/70533]
loss: 0.071644  [ 6400/70533]
loss: 0.269174  [12800/70533]
loss: 0.221783  [19200/70533]
loss: 0.281088  [25600/70533]
loss: 0.192143  [32000/70533]
loss: 0.284402  [38400/70533]
loss: 0.301527  [44800/70533]
loss: 0.174465  [51200/70533]
loss: 0.189659  [57600/70533]
loss: 0.433328  [64000/70533]
loss: 0.055835  [70400/70533]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.220215 

Epoch 9
-------------------------------
loss: 0.110764  [    0/70533]
loss: 0.107497  [ 6400/70533]
loss: 0.123630  [12800/70533]
loss: 0.103344  [19200/70533]
loss: 0.071285  [25600/70533]
loss: 0.055628  [32000/70533]
loss: 0.153822  [38400/70533]
loss: 0.152877  [44800/70533]
loss: 0.207207  [51200/70533]
loss: 0.079768  [57600/70533]
loss: 0.121118  [64000/70533]
loss: 0.147049  [70400/70533]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.232998 

Epoch 10
-------------------------------
loss: 0.135193  [    0/70533]
loss: 0.084584  [ 6400/70533]
loss: 0.215838  [12800/70533]
loss: 0.119260  [19200/70533]
loss: 0.082436  [25600/70533]
loss: 0.082458  [32000/70533]
loss: 0.077517  [38400/70533]
loss: 0.224854  [44800/70533]
loss: 0.286407  [51200/70533]
loss: 0.216806  [57600/70533]
loss: 0.182099  [64000/70533]
loss: 0.088145  [70400/70533]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.177998 

Epoch 11
-------------------------------
loss: 0.104432  [    0/70533]
loss: 0.139504  [ 6400/70533]
loss: 0.105781  [12800/70533]
loss: 0.104532  [19200/70533]
loss: 0.258643  [25600/70533]
loss: 0.195621  [32000/70533]
loss: 0.129105  [38400/70533]
loss: 0.153466  [44800/70533]
loss: 0.152917  [51200/70533]
loss: 0.107340  [57600/70533]
loss: 0.214872  [64000/70533]
loss: 0.312768  [70400/70533]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.176157 

Epoch 12
-------------------------------
loss: 0.082941  [    0/70533]
loss: 0.096487  [ 6400/70533]
loss: 0.124494  [12800/70533]
loss: 0.166855  [19200/70533]
loss: 0.119407  [25600/70533]
loss: 0.197168  [32000/70533]
loss: 0.085252  [38400/70533]
loss: 0.198889  [44800/70533]
loss: 0.072572  [51200/70533]
loss: 0.215819  [57600/70533]
loss: 0.154547  [64000/70533]
loss: 0.234214  [70400/70533]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180063 

Epoch 13
-------------------------------
loss: 0.237442  [    0/70533]
loss: 0.199316  [ 6400/70533]
loss: 0.259096  [12800/70533]
loss: 0.188119  [19200/70533]
loss: 0.133710  [25600/70533]
loss: 0.102296  [32000/70533]
loss: 0.109894  [38400/70533]
loss: 0.203378  [44800/70533]
loss: 0.130479  [51200/70533]
loss: 0.130850  [57600/70533]
loss: 0.194988  [64000/70533]
loss: 0.044923  [70400/70533]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.181547 

Epoch 14
-------------------------------
loss: 0.122255  [    0/70533]
loss: 0.081758  [ 6400/70533]
loss: 0.105966  [12800/70533]
loss: 0.120217  [19200/70533]
loss: 0.183423  [25600/70533]
loss: 0.132439  [32000/70533]
loss: 0.105044  [38400/70533]
loss: 0.101960  [44800/70533]
loss: 0.222711  [51200/70533]
loss: 0.056358  [57600/70533]
loss: 0.130878  [64000/70533]
loss: 0.162446  [70400/70533]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.267886 

Epoch 15
-------------------------------
loss: 0.228068  [    0/70533]
loss: 0.165927  [ 6400/70533]
loss: 0.185931  [12800/70533]
loss: 0.164060  [19200/70533]
loss: 0.124808  [25600/70533]
loss: 0.110549  [32000/70533]
loss: 0.052838  [38400/70533]
loss: 0.178805  [44800/70533]
loss: 1.691148  [51200/70533]
loss: 0.209620  [57600/70533]
loss: 0.205555  [64000/70533]
loss: 0.116976  [70400/70533]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.159748 

Epoch 16
-------------------------------
loss: 0.273004  [    0/70533]
loss: 0.102849  [ 6400/70533]
loss: 0.107727  [12800/70533]
loss: 0.058861  [19200/70533]
loss: 0.052711  [25600/70533]
loss: 0.049322  [32000/70533]
loss: 0.092818  [38400/70533]
loss: 0.152356  [44800/70533]
loss: 0.115080  [51200/70533]
loss: 0.159699  [57600/70533]
loss: 0.110678  [64000/70533]
loss: 0.098854  [70400/70533]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.166689 

Epoch 17
-------------------------------
loss: 0.083120  [    0/70533]
loss: 0.077156  [ 6400/70533]
loss: 0.180971  [12800/70533]
loss: 0.256092  [19200/70533]
loss: 0.165849  [25600/70533]
loss: 0.161285  [32000/70533]
loss: 0.074706  [38400/70533]
loss: 0.119867  [44800/70533]
loss: 0.196494  [51200/70533]
loss: 0.082805  [57600/70533]
loss: 0.152995  [64000/70533]
loss: 0.218764  [70400/70533]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.187507 

Epoch 18
-------------------------------
loss: 0.219237  [    0/70533]
loss: 0.102513  [ 6400/70533]
loss: 0.213626  [12800/70533]
loss: 0.056109  [19200/70533]
loss: 0.073439  [25600/70533]
loss: 0.093259  [32000/70533]
loss: 0.076703  [38400/70533]
loss: 0.180585  [44800/70533]
loss: 0.192258  [51200/70533]
loss: 0.126152  [57600/70533]
loss: 0.078553  [64000/70533]
loss: 0.068461  [70400/70533]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.154919 

Epoch 19
-------------------------------
loss: 0.087282  [    0/70533]
loss: 0.123253  [ 6400/70533]
loss: 0.072817  [12800/70533]
loss: 0.214684  [19200/70533]
loss: 0.039673  [25600/70533]
loss: 0.098989  [32000/70533]
loss: 0.160333  [38400/70533]
loss: 0.065556  [44800/70533]
loss: 0.301639  [51200/70533]
loss: 0.054254  [57600/70533]
loss: 0.128096  [64000/70533]
loss: 0.145778  [70400/70533]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.150209 

Epoch 20
-------------------------------
loss: 0.075480  [    0/70533]
loss: 0.055438  [ 6400/70533]
loss: 0.178750  [12800/70533]
loss: 0.166769  [19200/70533]
loss: 0.079232  [25600/70533]
loss: 0.215244  [32000/70533]
loss: 0.199521  [38400/70533]
loss: 0.081144  [44800/70533]
loss: 0.203609  [51200/70533]
loss: 0.049229  [57600/70533]
loss: 0.213535  [64000/70533]
loss: 0.353262  [70400/70533]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.193498 

Epoch 21
-------------------------------
loss: 0.167847  [    0/70533]
loss: 0.068479  [ 6400/70533]
loss: 0.169547  [12800/70533]
loss: 0.113330  [19200/70533]
loss: 0.137885  [25600/70533]
loss: 0.102936  [32000/70533]
loss: 0.133790  [38400/70533]
loss: 0.103305  [44800/70533]
loss: 0.101978  [51200/70533]
loss: 0.114065  [57600/70533]
loss: 0.109496  [64000/70533]
loss: 0.156659  [70400/70533]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.218042 

Epoch 22
-------------------------------
loss: 0.243101  [    0/70533]
loss: 0.147066  [ 6400/70533]
loss: 0.084754  [12800/70533]
loss: 0.086585  [19200/70533]
loss: 0.067714  [25600/70533]
loss: 0.159079  [32000/70533]
loss: 0.119807  [38400/70533]
loss: 0.230929  [44800/70533]
loss: 0.104959  [51200/70533]
loss: 0.103920  [57600/70533]
loss: 0.164292  [64000/70533]
loss: 0.103741  [70400/70533]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.151458 

Epoch 23
-------------------------------
loss: 0.082993  [    0/70533]
loss: 0.045387  [ 6400/70533]
loss: 0.112420  [12800/70533]
loss: 0.126424  [19200/70533]
loss: 0.168258  [25600/70533]
loss: 0.109148  [32000/70533]
loss: 0.071130  [38400/70533]
loss: 0.152468  [44800/70533]
loss: 0.196855  [51200/70533]
loss: 0.129435  [57600/70533]
loss: 0.132726  [64000/70533]
loss: 0.221843  [70400/70533]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.157766 

Epoch 24
-------------------------------
loss: 0.113611  [    0/70533]
loss: 0.096731  [ 6400/70533]
loss: 0.059454  [12800/70533]
loss: 0.102776  [19200/70533]
loss: 0.081577  [25600/70533]
loss: 0.127448  [32000/70533]
loss: 0.047789  [38400/70533]
loss: 0.264495  [44800/70533]
loss: 0.186104  [51200/70533]
loss: 0.109847  [57600/70533]
loss: 0.190681  [64000/70533]
loss: 0.099957  [70400/70533]
loss: 0.046531  [19200/70717]
loss: 0.035660  [25600/70717]
loss: 0.133264  [32000/70717]
loss: 0.018036  [38400/70717]
loss: 0.190671  [44800/70717]
loss: 0.169560  [51200/70717]
loss: 0.094196  [57600/70717]
loss: 0.072416  [64000/70717]
loss: 0.080817  [70400/70717]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.136083 

Epoch 26
-------------------------------
loss: 0.046639  [    0/70717]
loss: 0.058689  [ 6400/70717]
loss: 0.045437  [12800/70717]
loss: 0.057411  [19200/70717]
loss: 0.208495  [25600/70717]
loss: 0.080151  [32000/70717]
loss: 0.048982  [38400/70717]
loss: 0.065337  [44800/70717]
loss: 0.020458  [51200/70717]
loss: 0.062125  [57600/70717]
loss: 0.115107  [64000/70717]
loss: 0.131015  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.122749 

Epoch 27
-------------------------------
loss: 0.081852  [    0/70717]
loss: 0.109030  [ 6400/70717]
loss: 0.152080  [12800/70717]
loss: 0.074763  [19200/70717]
loss: 0.090015  [25600/70717]
loss: 0.022940  [32000/70717]
loss: 0.072355  [38400/70717]
loss: 0.080309  [44800/70717]
loss: 0.105874  [51200/70717]
loss: 0.036832  [57600/70717]
loss: 0.104348  [64000/70717]
loss: 0.209519  [70400/70717]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.126938 

Epoch 28
-------------------------------
loss: 0.069364  [    0/70717]
loss: 0.019491  [ 6400/70717]
loss: 0.101220  [12800/70717]
loss: 0.064550  [19200/70717]
loss: 0.069852  [25600/70717]
loss: 0.156039  [32000/70717]
loss: 0.074122  [38400/70717]
loss: 0.110523  [44800/70717]
loss: 0.086880  [51200/70717]
loss: 0.170327  [57600/70717]
loss: 0.171355  [64000/70717]
loss: 0.021646  [70400/70717]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.129057 

Epoch 29
-------------------------------
loss: 0.117105  [    0/70717]
loss: 0.072214  [ 6400/70717]
loss: 0.099664  [12800/70717]
loss: 0.085419  [19200/70717]
loss: 0.059591  [25600/70717]
loss: 0.176223  [32000/70717]
loss: 0.104497  [38400/70717]
loss: 0.080190  [44800/70717]
loss: 0.046388  [51200/70717]
loss: 0.048895  [57600/70717]
loss: 0.054498  [64000/70717]
loss: 0.039662  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.124939 

Epoch 30
-------------------------------
loss: 0.034940  [    0/70717]
loss: 0.126263  [ 6400/70717]
loss: 0.084656  [12800/70717]
loss: 0.164111  [19200/70717]
loss: 0.136113  [25600/70717]
loss: 0.123906  [32000/70717]
loss: 0.149522  [38400/70717]
loss: 0.071812  [44800/70717]
loss: 0.064255  [51200/70717]
loss: 0.179416  [57600/70717]
loss: 0.051216  [64000/70717]
loss: 0.241680  [70400/70717]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.145658 

Epoch 31
-------------------------------
loss: 0.086056  [    0/70717]
loss: 0.028783  [ 6400/70717]
loss: 0.148312  [12800/70717]
loss: 0.109921  [19200/70717]
loss: 0.035469  [25600/70717]
loss: 0.024282  [32000/70717]
loss: 0.102422  [38400/70717]
loss: 0.094661  [44800/70717]
loss: 0.091320  [51200/70717]
loss: 0.101602  [57600/70717]
loss: 0.061434  [64000/70717]
loss: 0.120755  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.119642 

Epoch 32
-------------------------------
loss: 0.081140  [    0/70717]
loss: 0.099078  [ 6400/70717]
loss: 0.055492  [12800/70717]
loss: 0.143039  [19200/70717]
loss: 0.147263  [25600/70717]
loss: 0.056323  [32000/70717]
loss: 0.058470  [38400/70717]
loss: 0.153438  [44800/70717]
loss: 0.083534  [51200/70717]
loss: 0.215006  [57600/70717]
loss: 0.103299  [64000/70717]
loss: 0.183790  [70400/70717]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.136497 

Epoch 33
-------------------------------
loss: 0.063827  [    0/70717]
loss: 0.020864  [ 6400/70717]
loss: 0.088099  [12800/70717]
loss: 0.118616  [19200/70717]
loss: 0.062198  [25600/70717]
loss: 0.087709  [32000/70717]
loss: 0.069148  [38400/70717]
loss: 0.300547  [44800/70717]
loss: 0.023640  [51200/70717]
loss: 0.029694  [57600/70717]
loss: 0.022748  [64000/70717]
loss: 0.067628  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.120636 

Epoch 34
-------------------------------
loss: 0.049815  [    0/70717]
loss: 0.046630  [ 6400/70717]
loss: 0.082118  [12800/70717]
loss: 0.113606  [19200/70717]
loss: 0.058939  [25600/70717]
loss: 0.087609  [32000/70717]
loss: 0.049923  [38400/70717]
loss: 0.092746  [44800/70717]
loss: 0.014753  [51200/70717]
loss: 0.024123  [57600/70717]
loss: 0.089176  [64000/70717]
loss: 0.133242  [70400/70717]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.129820 

Epoch 35
-------------------------------
loss: 0.136772  [    0/70717]
loss: 0.090014  [ 6400/70717]
loss: 0.248444  [12800/70717]
loss: 0.030230  [19200/70717]
loss: 0.069006  [25600/70717]
loss: 0.102725  [32000/70717]
loss: 0.172365  [38400/70717]
loss: 0.180617  [44800/70717]
loss: 0.065030  [51200/70717]
loss: 0.042554  [57600/70717]
loss: 0.045446  [64000/70717]
loss: 0.168888  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.118858 

Epoch 36
-------------------------------
loss: 0.109706  [    0/70717]
loss: 0.052554  [ 6400/70717]
loss: 0.063617  [12800/70717]
loss: 0.155292  [19200/70717]
loss: 0.045902  [25600/70717]
loss: 0.059434  [32000/70717]
loss: 0.122519  [38400/70717]
loss: 0.031244  [44800/70717]
loss: 0.103322  [51200/70717]
loss: 0.053166  [57600/70717]
loss: 0.288674  [64000/70717]
loss: 0.052550  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.124632 

Epoch 37
-------------------------------
loss: 0.230438  [    0/70717]
loss: 0.124608  [ 6400/70717]
loss: 0.262647  [12800/70717]
loss: 0.136366  [19200/70717]
loss: 0.065074  [25600/70717]
loss: 0.119453  [32000/70717]
loss: 0.027202  [38400/70717]
loss: 0.244975  [44800/70717]
loss: 0.139383  [51200/70717]
loss: 0.091011  [57600/70717]
loss: 0.049043  [64000/70717]
loss: 0.099086  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.119404 

Epoch 38
-------------------------------
loss: 0.015622  [    0/70717]
loss: 0.055781  [ 6400/70717]
loss: 0.068637  [12800/70717]
loss: 0.072238  [19200/70717]
loss: 0.041697  [25600/70717]
loss: 0.135569  [32000/70717]
loss: 0.021680  [38400/70717]
loss: 0.062910  [44800/70717]
loss: 0.175639  [51200/70717]
loss: 0.108438  [57600/70717]
loss: 0.114853  [64000/70717]
loss: 0.164868  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.123190 

Epoch 39
-------------------------------
loss: 0.034479  [    0/70717]
loss: 0.087502  [ 6400/70717]
loss: 0.075128  [12800/70717]
loss: 0.087153  [19200/70717]
loss: 0.107258  [25600/70717]
loss: 0.054862  [32000/70717]
loss: 0.111208  [38400/70717]
loss: 0.070153  [44800/70717]
loss: 0.058912  [51200/70717]
loss: 0.066255  [57600/70717]
loss: 0.067301  [64000/70717]
loss: 0.256735  [70400/70717]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.139812 

Epoch 40
-------------------------------
loss: 0.134047  [    0/70717]
loss: 0.025619  [ 6400/70717]
loss: 0.144885  [12800/70717]
loss: 0.043075  [19200/70717]
loss: 0.156551  [25600/70717]
loss: 0.112879  [32000/70717]
loss: 0.069812  [38400/70717]
loss: 0.062501  [44800/70717]
loss: 0.056627  [51200/70717]
loss: 0.050429  [57600/70717]
loss: 0.146695  [64000/70717]
loss: 0.048830  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.129211 

Epoch 41
-------------------------------
loss: 0.075366  [    0/70717]
loss: 0.100897  [ 6400/70717]
loss: 0.116278  [12800/70717]
loss: 0.105263  [19200/70717]
loss: 0.111913  [25600/70717]
loss: 0.065288  [32000/70717]
loss: 0.056118  [38400/70717]
loss: 0.118436  [44800/70717]
loss: 0.099239  [51200/70717]
loss: 0.077464  [57600/70717]
loss: 0.044337  [64000/70717]
loss: 0.274954  [70400/70717]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.125000 

Epoch 42
-------------------------------
loss: 0.179623  [    0/70717]
loss: 0.020081  [ 6400/70717]
loss: 0.084601  [12800/70717]
loss: 0.064903  [19200/70717]
loss: 0.041043  [25600/70717]
loss: 0.147365  [32000/70717]
loss: 0.084556  [38400/70717]
loss: 0.113497  [44800/70717]
loss: 0.133777  [51200/70717]
loss: 0.087496  [57600/70717]
loss: 0.120165  [64000/70717]
loss: 0.037099  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.120515 

Epoch 43
-------------------------------
loss: 0.075506  [    0/70717]
loss: 0.100298  [ 6400/70717]
loss: 0.078006  [12800/70717]
loss: 0.065425  [19200/70717]
2022/09/20 18:12:31 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 18:13:38 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.150901  [ 6400/69698]
loss: 0.165585  [12800/69698]
loss: 0.086858  [19200/69698]
loss: 0.096976  [25600/69698]
loss: 0.126635  [32000/69698]
loss: 0.150416  [38400/69698]
loss: 0.199033  [44800/69698]
loss: 0.076394  [51200/69698]
loss: 0.112627  [57600/69698]
loss: 0.244393  [64000/69698]
Test Error: 
 Accuracy: 88.0%, Avg loss: 0.338523 

Epoch 12
-------------------------------
loss: 0.391170  [    0/69698]
loss: 0.156642  [ 6400/69698]
loss: 0.227714  [12800/69698]
loss: 0.319231  [19200/69698]
loss: 0.121505  [25600/69698]
loss: 0.204217  [32000/69698]
loss: 0.207644  [38400/69698]
loss: 0.146943  [44800/69698]
loss: 0.232357  [51200/69698]
loss: 0.091829  [57600/69698]
loss: 0.176699  [64000/69698]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.171535 

Epoch 13
-------------------------------
loss: 0.098776  [    0/69698]
loss: 0.136329  [ 6400/69698]
loss: 0.247471  [12800/69698]
loss: 0.109622  [19200/69698]
loss: 0.083801  [25600/69698]
loss: 0.082203  [32000/69698]
loss: 0.105903  [38400/69698]
loss: 0.139395  [44800/69698]
loss: 0.101862  [51200/69698]
loss: 0.125158  [57600/69698]
loss: 0.066001  [64000/69698]
Test Error: 
 Accuracy: 90.3%, Avg loss: 0.290011 

Epoch 14
-------------------------------
loss: 0.242783  [    0/69698]
loss: 0.057228  [ 6400/69698]
loss: 0.124687  [12800/69698]
loss: 0.283635  [19200/69698]
loss: 0.116624  [25600/69698]
loss: 0.163795  [32000/69698]
loss: 0.071692  [38400/69698]
loss: 0.166435  [44800/69698]
loss: 0.123435  [51200/69698]
loss: 0.220106  [57600/69698]
loss: 0.198191  [64000/69698]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.173885 

Epoch 15
-------------------------------
loss: 0.175272  [    0/69698]
loss: 0.122340  [ 6400/69698]
loss: 0.175511  [12800/69698]
loss: 0.277056  [19200/69698]
loss: 0.215845  [25600/69698]
loss: 0.158209  [32000/69698]
loss: 0.141635  [38400/69698]
loss: 0.198659  [44800/69698]
loss: 0.134655  [51200/69698]
loss: 0.088501  [57600/69698]
loss: 0.400901  [64000/69698]
Test Error: 
 Accuracy: 90.6%, Avg loss: 0.233907 

Epoch 16
-------------------------------
loss: 0.227365  [    0/69698]
loss: 0.142704  [ 6400/69698]
loss: 0.211274  [12800/69698]
loss: 0.055100  [19200/69698]
loss: 0.192043  [25600/69698]
loss: 0.331548  [32000/69698]
loss: 0.135092  [38400/69698]
loss: 0.127981  [44800/69698]
loss: 0.141022  [51200/69698]
loss: 0.290095  [57600/69698]
loss: 0.129361  [64000/69698]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.173668 

Epoch 17
-------------------------------
loss: 0.177802  [    0/69698]
loss: 0.084963  [ 6400/69698]
loss: 0.091093  [12800/69698]
loss: 0.093300  [19200/69698]
loss: 0.104963  [25600/69698]
loss: 0.126358  [32000/69698]
loss: 0.159505  [38400/69698]
loss: 0.174589  [44800/69698]
loss: 0.089980  [51200/69698]
loss: 0.170823  [57600/69698]
loss: 0.104454  [64000/69698]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.176802 

Epoch 18
-------------------------------
loss: 0.200506  [    0/69698]
loss: 0.186458  [ 6400/69698]
loss: 0.373084  [12800/69698]
loss: 0.110766  [19200/69698]
loss: 0.215250  [25600/69698]
loss: 0.095737  [32000/69698]
loss: 0.114534  [38400/69698]
loss: 0.124493  [44800/69698]
loss: 0.186486  [51200/69698]
loss: 0.144598  [57600/69698]
loss: 0.155403  [64000/69698]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.167657 

Epoch 19
-------------------------------
loss: 0.170973  [    0/69698]
loss: 0.215252  [ 6400/69698]
loss: 0.123487  [12800/69698]
loss: 0.225040  [19200/69698]
loss: 0.168822  [25600/69698]
loss: 0.262295  [32000/69698]
loss: 0.155000  [38400/69698]
loss: 0.215120  [44800/69698]
loss: 0.206825  [51200/69698]
loss: 0.295612  [57600/69698]
loss: 0.191821  [64000/69698]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.163479 

Epoch 20
-------------------------------
loss: 0.135402  [    0/69698]
loss: 0.110430  [ 6400/69698]
loss: 0.124258  [12800/69698]
loss: 0.178414  [19200/69698]
loss: 0.109859  [25600/69698]
loss: 0.098742  [32000/69698]
loss: 0.239410  [38400/69698]
loss: 0.125373  [44800/69698]
loss: 0.330127  [51200/69698]
loss: 0.186444  [57600/69698]
loss: 0.238807  [64000/69698]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.177192 

Epoch 21
-------------------------------
loss: 0.116054  [    0/69698]
loss: 0.431661  [ 6400/69698]
loss: 0.187858  [12800/69698]
loss: 0.144630  [19200/69698]
loss: 0.132817  [25600/69698]
loss: 0.062676  [32000/69698]
loss: 0.130200  [38400/69698]
loss: 0.117567  [44800/69698]
loss: 0.161764  [51200/69698]
loss: 0.101288  [57600/69698]
loss: 0.227135  [64000/69698]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170543 

Epoch 22
-------------------------------
loss: 0.127250  [    0/69698]
loss: 0.152988  [ 6400/69698]
loss: 0.090398  [12800/69698]
loss: 0.324788  [19200/69698]
loss: 0.181813  [25600/69698]
loss: 0.164522  [32000/69698]
loss: 0.272151  [38400/69698]
loss: 0.116832  [44800/69698]
loss: 0.107914  [51200/69698]
loss: 0.173195  [57600/69698]
loss: 0.167235  [64000/69698]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.164810 

Epoch 23
-------------------------------
loss: 0.249794  [    0/69698]
loss: 0.077411  [ 6400/69698]
loss: 0.038085  [12800/69698]
loss: 0.102489  [19200/69698]
loss: 0.105468  [25600/69698]
loss: 0.113501  [32000/69698]
loss: 0.087547  [38400/69698]
loss: 0.209815  [44800/69698]
loss: 0.239030  [51200/69698]
loss: 0.207469  [57600/69698]
loss: 0.128359  [64000/69698]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.173407 

Epoch 24
-------------------------------
loss: 0.150851  [    0/69698]
loss: 0.140683  [ 6400/69698]
loss: 0.137306  [12800/69698]
loss: 0.255815  [19200/69698]
loss: 0.063012  [25600/69698]
loss: 0.163204  [32000/69698]
loss: 0.242629  [38400/69698]
loss: 0.094621  [44800/69698]
loss: 0.204316  [51200/69698]
loss: 0.063045  [57600/69698]
loss: 0.166512  [64000/69698]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.165844 

Epoch 25
-------------------------------
loss: 0.191920  [    0/69698]
loss: 0.132552  [ 6400/69698]
loss: 0.176750  [12800/69698]
loss: 0.141492  [19200/69698]
loss: 0.203574  [25600/69698]
loss: 0.142392  [32000/69698]
loss: 0.116061  [38400/69698]
loss: 0.140326  [44800/69698]
loss: 0.172342  [51200/69698]
loss: 0.120576  [57600/69698]
loss: 0.157964  [64000/69698]
Test Error: 
 Accuracy: 85.4%, Avg loss: 0.561306 

Epoch 26
-------------------------------
loss: 0.325747  [    0/69698]
loss: 0.085854  [ 6400/69698]
loss: 0.423696  [12800/69698]
loss: 0.105650  [19200/69698]
loss: 0.117294  [25600/69698]
loss: 0.218796  [32000/69698]
loss: 0.084691  [38400/69698]
loss: 0.175482  [44800/69698]
loss: 0.128754  [51200/69698]
loss: 0.090483  [57600/69698]
loss: 0.189133  [64000/69698]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.171526 

Epoch 27
-------------------------------
loss: 0.240075  [    0/69698]
loss: 0.135147  [ 6400/69698]
loss: 0.123441  [12800/69698]
loss: 0.137676  [19200/69698]
loss: 0.129182  [25600/69698]
loss: 0.115880  [32000/69698]
loss: 0.057945  [38400/69698]
loss: 0.127456  [44800/69698]
loss: 0.082827  [51200/69698]
loss: 0.088918  [57600/69698]
loss: 0.141512  [64000/69698]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.172212 

Epoch 28
-------------------------------
loss: 0.140589  [    0/69698]
loss: 0.212564  [ 6400/69698]
loss: 0.144308  [12800/69698]
loss: 0.098865  [19200/69698]
loss: 0.228077  [25600/69698]
loss: 0.081499  [32000/69698]
loss: 0.163824  [38400/69698]
loss: 0.161814  [44800/69698]
loss: 0.152399  [51200/69698]
loss: 0.144990  [57600/69698]
loss: 0.085523  [64000/69698]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.179155 

Epoch 29
-------------------------------
loss: 0.163278  [    0/69698]
loss: 0.164249  [ 6400/69698]
loss: 0.172209  [12800/69698]
loss: 0.111766  [19200/69698]
loss: 0.116988  [25600/69698]
loss: 0.149981  [32000/69698]
loss: 0.109058  [38400/69698]
loss: 0.158773  [44800/69698]
loss: 0.160011  [51200/69698]
loss: 0.064349  [57600/69698]
loss: 0.177282  [64000/69698]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.167596 

Epoch 30
-------------------------------
loss: 0.138825  [    0/69698]
loss: 0.138227  [ 6400/69698]
loss: 0.134895  [12800/69698]
loss: 0.111254  [19200/69698]
loss: 0.156086  [25600/69698]
loss: 0.190839  [32000/69698]
loss: 0.070306  [64000/69473]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.173992 

Epoch 15
-------------------------------
loss: 0.158505  [    0/69473]
loss: 0.158018  [ 6400/69473]
loss: 0.160063  [12800/69473]
loss: 0.136865  [19200/69473]
loss: 1.648142  [25600/69473]
loss: 0.098836  [32000/69473]
loss: 0.138939  [38400/69473]
loss: 0.118196  [44800/69473]
loss: 0.134041  [51200/69473]
loss: 0.095840  [57600/69473]
loss: 0.192445  [64000/69473]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.168691 

Epoch 16
-------------------------------
loss: 0.107684  [    0/69473]
loss: 0.280820  [ 6400/69473]
loss: 0.103581  [12800/69473]
loss: 0.231233  [19200/69473]
loss: 0.174627  [25600/69473]
loss: 0.085210  [32000/69473]
loss: 0.149728  [38400/69473]
loss: 0.128270  [44800/69473]
loss: 0.177976  [51200/69473]
loss: 0.161088  [57600/69473]
loss: 0.145300  [64000/69473]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.170765 

Epoch 17
-------------------------------
loss: 0.121142  [    0/69473]
loss: 0.150734  [ 6400/69473]
loss: 0.247545  [12800/69473]
loss: 0.102503  [19200/69473]
loss: 0.136405  [25600/69473]
loss: 0.154042  [32000/69473]
loss: 0.164744  [38400/69473]
loss: 1.717798  [44800/69473]
loss: 0.142616  [51200/69473]
loss: 0.122846  [57600/69473]
loss: 0.116076  [64000/69473]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170567 

Epoch 18
-------------------------------
loss: 0.112042  [    0/69473]
loss: 0.160579  [ 6400/69473]
loss: 0.140055  [12800/69473]
loss: 0.057976  [19200/69473]
loss: 0.177558  [25600/69473]
loss: 0.073594  [32000/69473]
loss: 0.113425  [38400/69473]
loss: 0.150483  [44800/69473]
loss: 0.254463  [51200/69473]
loss: 0.228788  [57600/69473]
loss: 0.044363  [64000/69473]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.165890 

Epoch 19
-------------------------------
loss: 0.129678  [    0/69473]
loss: 0.235976  [ 6400/69473]
loss: 0.067352  [12800/69473]
loss: 0.085511  [19200/69473]
loss: 1.776279  [25600/69473]
loss: 0.154286  [32000/69473]
loss: 0.206261  [38400/69473]
loss: 0.311864  [44800/69473]
loss: 0.110409  [51200/69473]
loss: 0.130503  [57600/69473]
loss: 0.017747  [64000/69473]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.162973 

Epoch 20
-------------------------------
loss: 0.202093  [    0/69473]
loss: 0.069207  [ 6400/69473]
loss: 0.073643  [12800/69473]
loss: 0.121225  [19200/69473]
loss: 0.177530  [25600/69473]
loss: 0.033844  [32000/69473]
loss: 0.176419  [38400/69473]
loss: 0.051053  [44800/69473]
loss: 0.133297  [51200/69473]
loss: 0.118608  [57600/69473]
loss: 0.109803  [64000/69473]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.181533 

Epoch 21
-------------------------------
loss: 0.144439  [    0/69473]
loss: 0.216780  [ 6400/69473]
loss: 0.195967  [12800/69473]
loss: 0.070820  [19200/69473]
loss: 0.148909  [25600/69473]
loss: 0.105412  [32000/69473]
loss: 0.123528  [38400/69473]
loss: 0.177400  [44800/69473]
loss: 0.103605  [51200/69473]
loss: 0.099685  [57600/69473]
loss: 0.062318  [64000/69473]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.168436 

Epoch 22
-------------------------------
loss: 0.104266  [    0/69473]
loss: 0.058359  [ 6400/69473]
loss: 0.296089  [12800/69473]
loss: 0.339663  [19200/69473]
loss: 0.079471  [25600/69473]
loss: 0.129494  [32000/69473]
loss: 0.277324  [38400/69473]
loss: 0.143161  [44800/69473]
loss: 0.147806  [51200/69473]
loss: 0.153751  [57600/69473]
loss: 0.076637  [64000/69473]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.161886 

Epoch 23
-------------------------------
loss: 0.083262  [    0/69473]
loss: 0.198720  [ 6400/69473]
loss: 0.132141  [12800/69473]
loss: 0.058830  [19200/69473]
loss: 0.154022  [25600/69473]
loss: 0.082928  [32000/69473]
loss: 0.147852  [38400/69473]
loss: 0.188949  [44800/69473]
loss: 0.243243  [51200/69473]
loss: 1.807097  [57600/69473]
loss: 0.155533  [64000/69473]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171002 

Epoch 24
-------------------------------
loss: 0.125925  [    0/69473]
loss: 0.100809  [ 6400/69473]
loss: 0.084338  [12800/69473]
loss: 0.134503  [19200/69473]
loss: 0.254617  [25600/69473]
loss: 0.071254  [32000/69473]
loss: 0.042872  [38400/69473]
loss: 0.011607  [44800/69473]
loss: 0.211386  [51200/69473]
loss: 0.120530  [57600/69473]
loss: 0.105063  [64000/69473]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.161110 

Epoch 25
-------------------------------
loss: 0.158825  [    0/69473]
loss: 0.512617  [ 6400/69473]
loss: 0.093537  [12800/69473]
loss: 0.158277  [19200/69473]
loss: 0.173633  [25600/69473]
loss: 0.139874  [32000/69473]
loss: 0.157379  [38400/69473]
loss: 0.115724  [44800/69473]
loss: 0.146738  [51200/69473]
loss: 1.655680  [57600/69473]
loss: 0.061894  [64000/69473]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.166385 

Epoch 26
-------------------------------
loss: 0.134525  [    0/69473]
loss: 0.238411  [ 6400/69473]
loss: 0.257636  [12800/69473]
loss: 0.103064  [19200/69473]
loss: 0.110988  [25600/69473]
loss: 0.132077  [32000/69473]
loss: 0.238321  [38400/69473]
loss: 0.092013  [44800/69473]
loss: 0.073344  [51200/69473]
loss: 0.186006  [57600/69473]
loss: 0.159964  [64000/69473]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160874 

Epoch 27
-------------------------------
loss: 0.140511  [    0/69473]
loss: 0.074620  [ 6400/69473]
loss: 0.105572  [12800/69473]
loss: 0.066923  [19200/69473]
loss: 0.353539  [25600/69473]
loss: 0.177916  [32000/69473]
loss: 0.147558  [38400/69473]
loss: 0.042649  [44800/69473]
loss: 0.177423  [51200/69473]
loss: 0.087046  [57600/69473]
loss: 0.184838  [64000/69473]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169345 

Epoch 28
-------------------------------
loss: 0.126296  [    0/69473]
loss: 0.089443  [ 6400/69473]
loss: 0.163848  [12800/69473]
loss: 0.183190  [19200/69473]
loss: 0.216167  [25600/69473]
loss: 0.103645  [32000/69473]
loss: 0.168583  [38400/69473]
loss: 0.176057  [44800/69473]
loss: 0.231580  [51200/69473]
loss: 0.162464  [57600/69473]
loss: 0.114737  [64000/69473]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.174246 

Epoch 29
-------------------------------
loss: 0.132401  [    0/69473]
loss: 0.137338  [ 6400/69473]
loss: 0.161465  [12800/69473]
loss: 0.175530  [19200/69473]
loss: 0.106340  [25600/69473]
loss: 0.212387  [32000/69473]
loss: 0.152895  [38400/69473]
loss: 0.073956  [44800/69473]
loss: 0.047066  [51200/69473]
loss: 0.142697  [57600/69473]
loss: 1.615778  [64000/69473]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.180095 

Epoch 30
-------------------------------
loss: 0.058028  [    0/69473]
loss: 0.063751  [ 6400/69473]
loss: 0.155602  [12800/69473]
loss: 0.156255  [19200/69473]
loss: 0.124110  [25600/69473]
loss: 0.126869  [32000/69473]
loss: 0.124817  [38400/69473]
loss: 0.113765  [44800/69473]
loss: 0.131750  [51200/69473]
loss: 0.205989  [57600/69473]
loss: 0.171180  [64000/69473]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.169978 

Epoch 31
-------------------------------
loss: 0.132894  [    0/69473]
loss: 0.078334  [ 6400/69473]
loss: 0.141753  [12800/69473]
loss: 0.092832  [19200/69473]
loss: 0.128158  [25600/69473]
loss: 0.060335  [32000/69473]
loss: 0.241474  [38400/69473]
loss: 0.183585  [44800/69473]
loss: 0.169653  [51200/69473]
loss: 0.167308  [57600/69473]
loss: 0.092244  [64000/69473]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.162173 

Epoch 32
-------------------------------
loss: 0.133965  [    0/69473]
loss: 0.117444  [ 6400/69473]
loss: 0.096569  [12800/69473]
loss: 0.143848  [19200/69473]
loss: 0.063325  [25600/69473]
loss: 0.120860  [32000/69473]
loss: 0.112822  [38400/69473]
loss: 0.205889  [44800/69473]
loss: 0.115092  [51200/69473]
loss: 0.221495  [57600/69473]
loss: 0.101022  [64000/69473]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170288 

Epoch 33
-------------------------------
loss: 0.227202  [    0/69473]
loss: 0.246715  [ 6400/69473]
loss: 0.196942  [12800/69473]
loss: 0.081611  [19200/69473]
loss: 0.213725  [25600/69473]
loss: 0.141010  [32000/69473]
loss: 0.073244  [38400/69473]
loss: 0.151854  [44800/69473]
loss: 0.131817  [51200/69473]
loss: 0.165810  [57600/69473]
loss: 0.058798  [64000/69473]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.164449 

Epoch 34
-------------------------------
loss: 0.109806  [    0/69473]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.184667 

Epoch 15
-------------------------------
loss: 0.105981  [    0/70070]
loss: 0.243308  [ 6400/70070]
loss: 0.121687  [12800/70070]
loss: 0.172750  [19200/70070]
loss: 0.187475  [25600/70070]
loss: 0.162014  [32000/70070]
loss: 0.161839  [38400/70070]
loss: 0.244708  [44800/70070]
loss: 0.226515  [51200/70070]
loss: 0.222939  [57600/70070]
loss: 0.151234  [64000/70070]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.197734 

Epoch 16
-------------------------------
loss: 0.199916  [    0/70070]
loss: 0.162135  [ 6400/70070]
loss: 0.257642  [12800/70070]
loss: 0.308559  [19200/70070]
loss: 0.265178  [25600/70070]
loss: 0.251215  [32000/70070]
loss: 0.265045  [38400/70070]
loss: 0.167330  [44800/70070]
loss: 0.207947  [51200/70070]
loss: 0.147709  [57600/70070]
loss: 0.279875  [64000/70070]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.175791 

Epoch 17
-------------------------------
loss: 0.185964  [    0/70070]
loss: 0.216536  [ 6400/70070]
loss: 0.187673  [12800/70070]
loss: 0.310024  [19200/70070]
loss: 0.222224  [25600/70070]
loss: 0.168053  [32000/70070]
loss: 0.098560  [38400/70070]
loss: 0.233264  [44800/70070]
loss: 0.103166  [51200/70070]
loss: 0.290536  [57600/70070]
loss: 0.231282  [64000/70070]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.178325 

Epoch 18
-------------------------------
loss: 0.264283  [    0/70070]
loss: 0.187524  [ 6400/70070]
loss: 0.134991  [12800/70070]
loss: 0.188931  [19200/70070]
loss: 0.302669  [25600/70070]
loss: 0.123636  [32000/70070]
loss: 0.245676  [38400/70070]
loss: 0.105166  [44800/70070]
loss: 0.169262  [51200/70070]
loss: 0.127665  [57600/70070]
loss: 0.151120  [64000/70070]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.175278 

Epoch 19
-------------------------------
loss: 0.210630  [    0/70070]
loss: 0.215029  [ 6400/70070]
loss: 0.227336  [12800/70070]
loss: 0.280707  [19200/70070]
loss: 0.243579  [25600/70070]
loss: 0.145505  [32000/70070]
loss: 0.194009  [38400/70070]
loss: 0.273306  [44800/70070]
loss: 0.167825  [51200/70070]
loss: 0.112154  [57600/70070]
loss: 0.248933  [64000/70070]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177914 

Epoch 20
-------------------------------
loss: 0.283232  [    0/70070]
loss: 0.126364  [ 6400/70070]
loss: 0.128602  [12800/70070]
loss: 0.216213  [19200/70070]
loss: 0.330483  [25600/70070]
loss: 0.187236  [32000/70070]
loss: 0.172506  [38400/70070]
loss: 0.314090  [44800/70070]
loss: 0.152390  [51200/70070]
loss: 0.290779  [57600/70070]
loss: 0.178184  [64000/70070]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.176690 

Epoch 21
-------------------------------
loss: 0.183791  [    0/70070]
loss: 0.142529  [ 6400/70070]
loss: 0.238100  [12800/70070]
loss: 0.224433  [19200/70070]
loss: 0.128202  [25600/70070]
loss: 0.132161  [32000/70070]
loss: 0.150949  [38400/70070]
loss: 0.185461  [44800/70070]
loss: 0.116889  [51200/70070]
loss: 0.196651  [57600/70070]
loss: 0.275287  [64000/70070]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.181123 

Epoch 22
-------------------------------
loss: 0.141424  [    0/70070]
loss: 0.202774  [ 6400/70070]
loss: 0.084541  [12800/70070]
loss: 0.339417  [19200/70070]
loss: 0.121609  [25600/70070]
loss: 0.158683  [32000/70070]
loss: 0.186972  [38400/70070]
loss: 0.187981  [44800/70070]
loss: 0.280259  [51200/70070]
loss: 0.250895  [57600/70070]
loss: 0.234354  [64000/70070]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.178547 

Epoch 23
-------------------------------
loss: 0.176185  [    0/70070]
loss: 0.141751  [ 6400/70070]
loss: 0.289747  [12800/70070]
loss: 0.133548  [19200/70070]
loss: 0.083644  [25600/70070]
loss: 0.122114  [32000/70070]
loss: 0.170540  [38400/70070]
loss: 0.221961  [44800/70070]
loss: 0.117911  [51200/70070]
loss: 0.137401  [57600/70070]
loss: 0.183379  [64000/70070]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.185737 

Epoch 24
-------------------------------
loss: 0.225887  [    0/70070]
loss: 0.165949  [ 6400/70070]
loss: 0.149687  [12800/70070]
loss: 0.100881  [19200/70070]
loss: 0.085066  [25600/70070]
loss: 0.300261  [32000/70070]
loss: 0.049330  [38400/70070]
loss: 0.138223  [44800/70070]
loss: 0.156948  [51200/70070]
loss: 0.301123  [57600/70070]
loss: 0.170577  [64000/70070]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.207432 

Epoch 25
-------------------------------
loss: 0.152730  [    0/70070]
loss: 0.258329  [ 6400/70070]
loss: 0.235062  [12800/70070]
loss: 0.197521  [19200/70070]
loss: 0.108702  [25600/70070]
loss: 0.170796  [32000/70070]
loss: 0.322528  [38400/70070]
loss: 0.250620  [44800/70070]
loss: 0.202584  [51200/70070]
loss: 0.182993  [57600/70070]
loss: 0.152455  [64000/70070]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.187109 

Epoch 26
-------------------------------
loss: 0.208453  [    0/70070]
loss: 0.114966  [ 6400/70070]
loss: 0.146056  [12800/70070]
loss: 0.152958  [19200/70070]
loss: 0.239403  [25600/70070]
loss: 0.363661  [32000/70070]
loss: 0.107933  [38400/70070]
loss: 0.265122  [44800/70070]
loss: 0.154047  [51200/70070]
loss: 0.147360  [57600/70070]
loss: 0.355358  [64000/70070]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.176696 

Epoch 27
-------------------------------
loss: 0.121902  [    0/70070]
loss: 0.184195  [ 6400/70070]
loss: 0.216507  [12800/70070]
loss: 0.293376  [19200/70070]
loss: 0.183208  [25600/70070]
loss: 0.195306  [32000/70070]
loss: 0.178332  [38400/70070]
loss: 0.195545  [44800/70070]
loss: 0.253633  [51200/70070]
loss: 0.213445  [57600/70070]
loss: 0.142309  [64000/70070]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.187117 

Epoch 28
-------------------------------
loss: 0.195369  [    0/70070]
loss: 0.168648  [ 6400/70070]
loss: 0.233486  [12800/70070]
loss: 0.212846  [19200/70070]
loss: 0.163291  [25600/70070]
loss: 0.172809  [32000/70070]
loss: 0.150517  [38400/70070]
loss: 0.161645  [44800/70070]
loss: 0.206802  [51200/70070]
loss: 0.131068  [57600/70070]
loss: 0.213716  [64000/70070]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.187182 

Epoch 29
-------------------------------
loss: 0.205728  [    0/70070]
loss: 0.198317  [ 6400/70070]
loss: 0.258454  [12800/70070]
loss: 0.138303  [19200/70070]
loss: 0.192078  [25600/70070]
loss: 0.140272  [32000/70070]
loss: 0.186843  [38400/70070]
loss: 0.207537  [44800/70070]
loss: 0.178045  [51200/70070]
loss: 0.133985  [57600/70070]
loss: 0.101197  [64000/70070]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.188941 

Epoch 30
-------------------------------
loss: 0.274772  [    0/70070]
loss: 0.219087  [ 6400/70070]
loss: 0.226261  [12800/70070]
loss: 0.217114  [19200/70070]
loss: 0.230602  [25600/70070]
loss: 0.084794  [32000/70070]
loss: 0.223390  [38400/70070]
loss: 0.146979  [44800/70070]
loss: 0.249687  [51200/70070]
loss: 0.232315  [57600/70070]
loss: 0.201825  [64000/70070]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.175119 

Epoch 31
-------------------------------
loss: 0.192375  [    0/70070]
loss: 0.144189  [ 6400/70070]
loss: 0.225401  [12800/70070]
loss: 0.097976  [19200/70070]
loss: 0.061418  [25600/70070]
loss: 0.125432  [32000/70070]
loss: 0.210326  [38400/70070]
loss: 0.137715  [44800/70070]
loss: 0.197010  [51200/70070]
loss: 0.181559  [57600/70070]
loss: 0.126692  [64000/70070]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.175123 

Epoch 32
-------------------------------
loss: 0.210496  [    0/70070]
loss: 0.183194  [ 6400/70070]
loss: 0.219363  [12800/70070]
loss: 0.090670  [19200/70070]
loss: 0.108593  [25600/70070]
loss: 0.172891  [32000/70070]
loss: 0.179490  [38400/70070]
loss: 0.220377  [44800/70070]
loss: 0.226684  [51200/70070]
loss: 0.165506  [57600/70070]
loss: 0.327973  [64000/70070]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.169847 

Epoch 33
-------------------------------
loss: 0.198347  [    0/70070]
loss: 0.122620  [ 6400/70070]
loss: 0.273860  [12800/70070]
loss: 0.271434  [19200/70070]
loss: 0.137816  [25600/70070]
loss: 0.187646  [32000/70070]
loss: 0.160361  [38400/70070]
loss: 0.152907  [44800/70070]
loss: 0.206245  [51200/70070]
loss: 0.103809  [57600/70070]
loss: 0.063333  [64000/70070]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.174270 

Epoch 34
-------------------------------
loss: 0.316358  [    0/70070]
loss: 0.173310  [ 6400/70070]
loss: 0.123450  [ 6400/70245]
loss: 0.209739  [12800/70245]
loss: 0.233400  [19200/70245]
loss: 0.163146  [25600/70245]
loss: 0.109214  [32000/70245]
loss: 0.153969  [38400/70245]
loss: 0.261935  [44800/70245]
loss: 0.217626  [51200/70245]
loss: 0.158062  [57600/70245]
loss: 0.136316  [64000/70245]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.177919 

Epoch 12
-------------------------------
loss: 0.202116  [    0/70245]
loss: 0.209580  [ 6400/70245]
loss: 0.138858  [12800/70245]
loss: 0.183126  [19200/70245]
loss: 0.104796  [25600/70245]
loss: 0.124706  [32000/70245]
loss: 0.156204  [38400/70245]
loss: 0.271465  [44800/70245]
loss: 0.182211  [51200/70245]
loss: 0.251476  [57600/70245]
loss: 0.218891  [64000/70245]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.181738 

Epoch 13
-------------------------------
loss: 0.215092  [    0/70245]
loss: 0.231578  [ 6400/70245]
loss: 0.197694  [12800/70245]
loss: 0.144343  [19200/70245]
loss: 0.193907  [25600/70245]
loss: 0.218226  [32000/70245]
loss: 0.197277  [38400/70245]
loss: 0.149320  [44800/70245]
loss: 0.268215  [51200/70245]
loss: 0.121969  [57600/70245]
loss: 0.158812  [64000/70245]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.177028 

Epoch 14
-------------------------------
loss: 0.129354  [    0/70245]
loss: 0.105006  [ 6400/70245]
loss: 0.129923  [12800/70245]
loss: 0.089602  [19200/70245]
loss: 0.205985  [25600/70245]
loss: 0.098070  [32000/70245]
loss: 0.179008  [38400/70245]
loss: 0.108679  [44800/70245]
loss: 0.215458  [51200/70245]
loss: 0.232488  [57600/70245]
loss: 0.256905  [64000/70245]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.173758 

Epoch 15
-------------------------------
loss: 0.138260  [    0/70245]
loss: 0.223533  [ 6400/70245]
loss: 0.177474  [12800/70245]
loss: 0.149561  [19200/70245]
loss: 0.130701  [25600/70245]
loss: 0.195405  [32000/70245]
loss: 0.148478  [38400/70245]
loss: 0.237175  [44800/70245]
loss: 0.154354  [51200/70245]
loss: 0.176896  [57600/70245]
loss: 0.171281  [64000/70245]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.180345 

Epoch 16
-------------------------------
loss: 0.227397  [    0/70245]
loss: 0.128939  [ 6400/70245]
loss: 0.242653  [12800/70245]
loss: 0.189422  [19200/70245]
loss: 0.118295  [25600/70245]
loss: 0.152596  [32000/70245]
loss: 0.176386  [38400/70245]
loss: 0.135661  [44800/70245]
loss: 0.324450  [51200/70245]
loss: 0.083974  [57600/70245]
loss: 0.145066  [64000/70245]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.165082 

Epoch 17
-------------------------------
loss: 0.293873  [    0/70245]
loss: 0.230326  [ 6400/70245]
loss: 0.257089  [12800/70245]
loss: 0.284819  [19200/70245]
loss: 0.183337  [25600/70245]
loss: 0.189115  [32000/70245]
loss: 0.130680  [38400/70245]
loss: 0.151618  [44800/70245]
loss: 0.132057  [51200/70245]
loss: 0.131425  [57600/70245]
loss: 0.073190  [64000/70245]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.193236 

Epoch 18
-------------------------------
loss: 0.206419  [    0/70245]
loss: 0.168551  [ 6400/70245]
loss: 0.205174  [12800/70245]
loss: 0.256985  [19200/70245]
loss: 0.290388  [25600/70245]
loss: 0.172118  [32000/70245]
loss: 0.143401  [38400/70245]
loss: 0.107603  [44800/70245]
loss: 0.102134  [51200/70245]
loss: 0.202268  [57600/70245]
loss: 0.104308  [64000/70245]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.191860 

Epoch 19
-------------------------------
loss: 0.175236  [    0/70245]
loss: 0.148947  [ 6400/70245]
loss: 0.211356  [12800/70245]
loss: 0.160612  [19200/70245]
loss: 0.158508  [25600/70245]
loss: 0.130042  [32000/70245]
loss: 0.177257  [38400/70245]
loss: 0.203816  [44800/70245]
loss: 0.143235  [51200/70245]
loss: 0.120869  [57600/70245]
loss: 0.247965  [64000/70245]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.165514 

Epoch 20
-------------------------------
loss: 0.155881  [    0/70245]
loss: 0.231646  [ 6400/70245]
loss: 0.187920  [12800/70245]
loss: 0.210368  [19200/70245]
loss: 0.203172  [25600/70245]
loss: 0.168458  [32000/70245]
loss: 0.156021  [38400/70245]
loss: 0.139286  [44800/70245]
loss: 0.150622  [51200/70245]
loss: 0.236170  [57600/70245]
loss: 0.075856  [64000/70245]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.161946 

Epoch 21
-------------------------------
loss: 0.153109  [    0/70245]
loss: 0.140073  [ 6400/70245]
loss: 0.104881  [12800/70245]
loss: 0.203811  [19200/70245]
loss: 0.120480  [25600/70245]
loss: 0.125896  [32000/70245]
loss: 0.356246  [38400/70245]
loss: 0.202973  [44800/70245]
loss: 0.152812  [51200/70245]
loss: 0.229189  [57600/70245]
loss: 0.159557  [64000/70245]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.162166 

Epoch 22
-------------------------------
loss: 0.088766  [    0/70245]
loss: 0.114033  [ 6400/70245]
loss: 0.220574  [12800/70245]
loss: 0.110046  [19200/70245]
loss: 0.111505  [25600/70245]
loss: 0.164127  [32000/70245]
loss: 0.297540  [38400/70245]
loss: 0.121256  [44800/70245]
loss: 0.186677  [51200/70245]
loss: 0.216065  [57600/70245]
loss: 0.166310  [64000/70245]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.164561 

Epoch 23
-------------------------------
loss: 0.133787  [    0/70245]
loss: 0.088977  [ 6400/70245]
loss: 0.175155  [12800/70245]
loss: 0.266408  [19200/70245]
loss: 0.189446  [25600/70245]
loss: 0.199159  [32000/70245]
loss: 0.218318  [38400/70245]
loss: 0.155413  [44800/70245]
loss: 0.174110  [51200/70245]
loss: 0.046307  [57600/70245]
loss: 0.137588  [64000/70245]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.163186 

Epoch 24
-------------------------------
loss: 0.087436  [    0/70245]
loss: 0.169518  [ 6400/70245]
loss: 0.237940  [12800/70245]
loss: 0.160475  [19200/70245]
loss: 0.129224  [25600/70245]
loss: 0.124575  [32000/70245]
loss: 0.215932  [38400/70245]
loss: 0.126340  [44800/70245]
loss: 0.219244  [51200/70245]
loss: 0.167284  [57600/70245]
loss: 0.136382  [64000/70245]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.163116 

Epoch 25
-------------------------------
loss: 0.162483  [    0/70245]
loss: 0.223910  [ 6400/70245]
loss: 0.215790  [12800/70245]
loss: 0.205809  [19200/70245]
loss: 0.130065  [25600/70245]
loss: 0.284685  [32000/70245]
loss: 0.148444  [38400/70245]
loss: 0.140153  [44800/70245]
loss: 0.163707  [51200/70245]
loss: 0.198154  [57600/70245]
loss: 0.155763  [64000/70245]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.173228 

Epoch 26
-------------------------------
loss: 0.191201  [    0/70245]
loss: 0.271565  [ 6400/70245]
loss: 0.187472  [12800/70245]
loss: 0.106789  [19200/70245]
loss: 0.224325  [25600/70245]
loss: 0.108701  [32000/70245]
loss: 0.111545  [38400/70245]
loss: 0.290855  [44800/70245]
loss: 0.144180  [51200/70245]
loss: 0.336585  [57600/70245]
loss: 0.256056  [64000/70245]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.167037 

Epoch 27
-------------------------------
loss: 0.213452  [    0/70245]
loss: 0.174498  [ 6400/70245]
loss: 0.186006  [12800/70245]
loss: 0.172372  [19200/70245]
loss: 0.105468  [25600/70245]
loss: 0.172384  [32000/70245]
loss: 0.156549  [38400/70245]
loss: 0.231890  [44800/70245]
loss: 0.149806  [51200/70245]
loss: 0.115851  [57600/70245]
loss: 0.189759  [64000/70245]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.162420 

Epoch 28
-------------------------------
loss: 0.174285  [    0/70245]
loss: 0.198011  [ 6400/70245]
loss: 0.287604  [12800/70245]
loss: 0.255943  [19200/70245]
loss: 0.236874  [25600/70245]
loss: 0.153645  [32000/70245]
loss: 0.221571  [38400/70245]
loss: 0.160451  [44800/70245]
loss: 0.145415  [51200/70245]
loss: 0.142459  [57600/70245]
loss: 0.132659  [64000/70245]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.160241 

Epoch 29
-------------------------------
loss: 0.126592  [    0/70245]
loss: 0.238637  [ 6400/70245]
loss: 0.226751  [12800/70245]
loss: 0.281972  [19200/70245]
loss: 0.167299  [25600/70245]
loss: 0.128967  [32000/70245]
loss: 0.253383  [38400/70245]
loss: 0.175752  [44800/70245]
loss: 0.245621  [51200/70245]
loss: 0.157946  [57600/70245]
loss: 0.236266  [64000/70245]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.160659 

Epoch 30
-------------------------------
loss: 0.087096  [    0/70245]
loss: 0.127824  [ 6400/70245]
loss: 0.193436  [12800/70245]
loss: 0.092075  [19200/70245]
loss: 0.095316  [25600/70245]
loss: 0.159933  [32000/70245]
loss: 0.112381  [44800/71095]
loss: 0.032457  [51200/71095]
loss: 0.093725  [57600/71095]
loss: 0.064177  [64000/71095]
loss: 0.080595  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.163214 

Epoch 29
-------------------------------
loss: 0.050514  [    0/71095]
loss: 0.057788  [ 6400/71095]
loss: 0.062200  [12800/71095]
loss: 0.051206  [19200/71095]
loss: 0.161514  [25600/71095]
loss: 0.055343  [32000/71095]
loss: 0.056992  [38400/71095]
loss: 0.057764  [44800/71095]
loss: 0.118218  [51200/71095]
loss: 0.050868  [57600/71095]
loss: 0.121441  [64000/71095]
loss: 0.058476  [70400/71095]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.165252 

Epoch 30
-------------------------------
loss: 0.083443  [    0/71095]
loss: 0.059188  [ 6400/71095]
loss: 0.129270  [12800/71095]
loss: 0.062007  [19200/71095]
loss: 0.019377  [25600/71095]
loss: 0.133467  [32000/71095]
loss: 0.062672  [38400/71095]
loss: 0.034761  [44800/71095]
loss: 0.042858  [51200/71095]
loss: 0.153331  [57600/71095]
loss: 0.133941  [64000/71095]
loss: 0.110815  [70400/71095]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.156176 

Epoch 31
-------------------------------
loss: 0.070562  [    0/71095]
loss: 0.076881  [ 6400/71095]
loss: 0.081988  [12800/71095]
loss: 0.202880  [19200/71095]
loss: 0.101098  [25600/71095]
loss: 0.092071  [32000/71095]
loss: 0.055631  [38400/71095]
loss: 0.158054  [44800/71095]
loss: 0.056670  [51200/71095]
loss: 0.192963  [57600/71095]
loss: 0.075173  [64000/71095]
loss: 0.061856  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.160915 

Epoch 32
-------------------------------
loss: 0.045369  [    0/71095]
loss: 0.145316  [ 6400/71095]
loss: 0.054705  [12800/71095]
loss: 0.079418  [19200/71095]
loss: 0.097979  [25600/71095]
loss: 0.162979  [32000/71095]
loss: 0.084444  [38400/71095]
loss: 0.047649  [44800/71095]
loss: 0.126948  [51200/71095]
loss: 0.056184  [57600/71095]
loss: 0.041558  [64000/71095]
loss: 0.071303  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.157323 

Epoch 33
-------------------------------
loss: 0.070525  [    0/71095]
loss: 0.024603  [ 6400/71095]
loss: 0.064396  [12800/71095]
loss: 0.093697  [19200/71095]
loss: 0.071374  [25600/71095]
loss: 0.081419  [32000/71095]
loss: 0.081243  [38400/71095]
loss: 0.090529  [44800/71095]
loss: 0.060309  [51200/71095]
loss: 0.065934  [57600/71095]
loss: 0.065110  [64000/71095]
loss: 0.108813  [70400/71095]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.165152 

Epoch 34
-------------------------------
loss: 0.178628  [    0/71095]
loss: 0.078467  [ 6400/71095]
loss: 0.043591  [12800/71095]
loss: 0.118911  [19200/71095]
loss: 0.095084  [25600/71095]
loss: 0.106687  [32000/71095]
loss: 0.076782  [38400/71095]
loss: 0.199946  [44800/71095]
loss: 0.063242  [51200/71095]
loss: 0.136928  [57600/71095]
loss: 0.098411  [64000/71095]
loss: 0.041545  [70400/71095]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.155213 

Epoch 35
-------------------------------
loss: 0.033843  [    0/71095]
loss: 0.055759  [ 6400/71095]
loss: 0.088726  [12800/71095]
loss: 0.073040  [19200/71095]
loss: 0.049170  [25600/71095]
loss: 0.049861  [32000/71095]
loss: 0.057630  [38400/71095]
loss: 0.078281  [44800/71095]
loss: 0.124312  [51200/71095]
loss: 0.044436  [57600/71095]
loss: 0.032841  [64000/71095]
loss: 0.178391  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.152350 

Epoch 36
-------------------------------
loss: 0.116067  [    0/71095]
loss: 0.056643  [ 6400/71095]
loss: 0.034842  [12800/71095]
loss: 0.333536  [19200/71095]
loss: 0.186525  [25600/71095]
loss: 0.126413  [32000/71095]
loss: 0.103523  [38400/71095]
loss: 0.119418  [44800/71095]
loss: 0.072770  [51200/71095]
loss: 0.090103  [57600/71095]
loss: 0.084845  [64000/71095]
loss: 0.120279  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.151529 

Epoch 37
-------------------------------
loss: 0.140972  [    0/71095]
loss: 0.101388  [ 6400/71095]
loss: 0.061086  [12800/71095]
loss: 0.103851  [19200/71095]
loss: 0.098453  [25600/71095]
loss: 0.115091  [32000/71095]
loss: 0.151340  [38400/71095]
loss: 0.030724  [44800/71095]
loss: 0.112552  [51200/71095]
loss: 0.057860  [57600/71095]
loss: 0.075761  [64000/71095]
loss: 0.047082  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.154830 

Epoch 38
-------------------------------
loss: 1.614217  [    0/71095]
loss: 0.135217  [ 6400/71095]
loss: 0.070849  [12800/71095]
loss: 0.090490  [19200/71095]
loss: 0.156352  [25600/71095]
loss: 0.075425  [32000/71095]
loss: 0.120349  [38400/71095]
loss: 0.110825  [44800/71095]
loss: 0.114247  [51200/71095]
loss: 0.026955  [57600/71095]
loss: 0.156164  [64000/71095]
loss: 0.105249  [70400/71095]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.150053 

Epoch 39
-------------------------------
loss: 0.040263  [    0/71095]
loss: 0.056307  [ 6400/71095]
loss: 0.048626  [12800/71095]
loss: 0.195885  [19200/71095]
loss: 0.038915  [25600/71095]
loss: 0.083613  [32000/71095]
loss: 0.047735  [38400/71095]
loss: 0.060444  [44800/71095]
loss: 0.226822  [51200/71095]
loss: 0.137008  [57600/71095]
loss: 0.218311  [64000/71095]
loss: 0.270472  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.153389 

Epoch 40
-------------------------------
loss: 0.055908  [    0/71095]
loss: 0.089955  [ 6400/71095]
loss: 0.066226  [12800/71095]
loss: 0.150552  [19200/71095]
loss: 0.148891  [25600/71095]
loss: 0.110053  [32000/71095]
loss: 0.057505  [38400/71095]
loss: 0.086045  [44800/71095]
loss: 0.058660  [51200/71095]
loss: 0.091236  [57600/71095]
loss: 0.131175  [64000/71095]
loss: 1.644459  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.153758 

Epoch 41
-------------------------------
loss: 0.255645  [    0/71095]
loss: 0.078303  [ 6400/71095]
loss: 0.071961  [12800/71095]
loss: 0.108120  [19200/71095]
loss: 0.041850  [25600/71095]
loss: 0.079143  [32000/71095]
loss: 0.113506  [38400/71095]
loss: 0.268372  [44800/71095]
loss: 0.035734  [51200/71095]
loss: 0.193793  [57600/71095]
loss: 0.084126  [64000/71095]
loss: 0.090408  [70400/71095]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.165667 

Epoch 42
-------------------------------
loss: 0.038004  [    0/71095]
loss: 0.041153  [ 6400/71095]
loss: 0.063816  [12800/71095]
loss: 0.216356  [19200/71095]
loss: 0.247331  [25600/71095]
loss: 0.143459  [32000/71095]
loss: 0.193224  [38400/71095]
loss: 0.064852  [44800/71095]
loss: 0.058992  [51200/71095]
loss: 0.116527  [57600/71095]
loss: 0.121749  [64000/71095]
loss: 0.087752  [70400/71095]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.159764 

Epoch 43
-------------------------------
loss: 0.119368  [    0/71095]
loss: 0.072654  [ 6400/71095]
loss: 0.043939  [12800/71095]
loss: 0.149783  [19200/71095]
loss: 0.151105  [25600/71095]
loss: 0.014201  [32000/71095]
loss: 0.163488  [38400/71095]
loss: 0.099153  [44800/71095]
loss: 0.054982  [51200/71095]
loss: 0.103512  [57600/71095]
loss: 0.167812  [64000/71095]
loss: 0.052786  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.154659 

Epoch 44
-------------------------------
loss: 0.047372  [    0/71095]
loss: 0.185423  [ 6400/71095]
loss: 0.072403  [12800/71095]
loss: 0.025874  [19200/71095]
loss: 0.055146  [25600/71095]
loss: 0.030560  [32000/71095]
loss: 0.045831  [38400/71095]
loss: 0.142537  [44800/71095]
loss: 0.063744  [51200/71095]
loss: 0.102365  [57600/71095]
loss: 0.082832  [64000/71095]
loss: 0.095658  [70400/71095]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.169566 

Epoch 45
-------------------------------
loss: 0.059406  [    0/71095]
loss: 0.045775  [ 6400/71095]
loss: 0.047817  [12800/71095]
loss: 0.148088  [19200/71095]
loss: 0.192342  [25600/71095]
loss: 0.070884  [32000/71095]
loss: 0.245856  [38400/71095]
loss: 0.131636  [44800/71095]
loss: 0.050668  [51200/71095]
loss: 0.208396  [57600/71095]
loss: 0.053648  [64000/71095]
loss: 0.144852  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.154384 

Epoch 46
-------------------------------
loss: 0.084874  [    0/71095]
loss: 0.115559  [ 6400/71095]
loss: 0.057499  [12800/71095]
loss: 0.032067  [19200/71095]
loss: 0.052651  [25600/71095]
loss: 0.060982  [32000/71095]
loss: 0.124828  [38400/71095]
loss: 0.125143  [44800/71095]
loss: 0.208428  [51200/70677]
loss: 0.120706  [57600/70677]
loss: 0.062518  [64000/70677]
loss: 0.191646  [70400/70677]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.215177 

Epoch 29
-------------------------------
loss: 0.154947  [    0/70677]
loss: 0.111741  [ 6400/70677]
loss: 0.208007  [12800/70677]
loss: 0.174376  [19200/70677]
loss: 0.099508  [25600/70677]
loss: 0.151494  [32000/70677]
loss: 0.159769  [38400/70677]
loss: 0.058501  [44800/70677]
loss: 0.190636  [51200/70677]
loss: 0.141479  [57600/70677]
loss: 0.193721  [64000/70677]
loss: 0.168501  [70400/70677]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.217459 

Epoch 30
-------------------------------
loss: 0.291496  [    0/70677]
loss: 0.164642  [ 6400/70677]
loss: 0.181494  [12800/70677]
loss: 0.241711  [19200/70677]
loss: 0.151548  [25600/70677]
loss: 0.178835  [32000/70677]
loss: 0.192306  [38400/70677]
loss: 0.113111  [44800/70677]
loss: 0.290810  [51200/70677]
loss: 0.097294  [57600/70677]
loss: 0.240733  [64000/70677]
loss: 0.270419  [70400/70677]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.229827 

Epoch 31
-------------------------------
loss: 0.146387  [    0/70677]
loss: 0.076656  [ 6400/70677]
loss: 0.207001  [12800/70677]
loss: 0.155585  [19200/70677]
loss: 0.229227  [25600/70677]
loss: 0.265492  [32000/70677]
loss: 0.184509  [38400/70677]
loss: 0.151043  [44800/70677]
loss: 0.185260  [51200/70677]
loss: 0.131155  [57600/70677]
loss: 0.139379  [64000/70677]
loss: 0.264585  [70400/70677]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.240206 

Epoch 32
-------------------------------
loss: 0.212049  [    0/70677]
loss: 0.282518  [ 6400/70677]
loss: 0.119598  [12800/70677]
loss: 0.150574  [19200/70677]
loss: 0.169442  [25600/70677]
loss: 0.096022  [32000/70677]
loss: 0.138889  [38400/70677]
loss: 0.101980  [44800/70677]
loss: 0.088467  [51200/70677]
loss: 0.173545  [57600/70677]
loss: 0.177288  [64000/70677]
loss: 0.176767  [70400/70677]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.228761 

Epoch 33
-------------------------------
loss: 0.124706  [    0/70677]
loss: 0.184022  [ 6400/70677]
loss: 0.085219  [12800/70677]
loss: 0.141307  [19200/70677]
loss: 0.326473  [25600/70677]
loss: 0.064115  [32000/70677]
loss: 0.219926  [38400/70677]
loss: 0.159051  [44800/70677]
loss: 0.145282  [51200/70677]
loss: 0.081880  [57600/70677]
loss: 0.177559  [64000/70677]
loss: 0.120188  [70400/70677]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.225937 

Epoch 34
-------------------------------
loss: 0.139172  [    0/70677]
loss: 0.267382  [ 6400/70677]
loss: 0.139126  [12800/70677]
loss: 0.169714  [19200/70677]
loss: 0.160892  [25600/70677]
loss: 0.192774  [32000/70677]
loss: 0.111925  [38400/70677]
loss: 0.181902  [44800/70677]
loss: 1.764803  [51200/70677]
loss: 0.131987  [57600/70677]
loss: 0.077789  [64000/70677]
loss: 0.186061  [70400/70677]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.233305 

Epoch 35
-------------------------------
loss: 0.150729  [    0/70677]
loss: 0.171122  [ 6400/70677]
loss: 0.056838  [12800/70677]
loss: 0.077929  [19200/70677]
loss: 0.362145  [25600/70677]
loss: 0.195514  [32000/70677]
loss: 0.307919  [38400/70677]
loss: 0.129013  [44800/70677]
loss: 0.109019  [51200/70677]
loss: 0.040238  [57600/70677]
loss: 0.185918  [64000/70677]
loss: 0.088253  [70400/70677]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.203722 

Epoch 36
-------------------------------
loss: 0.143479  [    0/70677]
loss: 0.061589  [ 6400/70677]
loss: 0.117804  [12800/70677]
loss: 0.163645  [19200/70677]
loss: 0.151100  [25600/70677]
loss: 0.086007  [32000/70677]
loss: 0.100424  [38400/70677]
loss: 0.137242  [44800/70677]
loss: 0.328537  [51200/70677]
loss: 0.168301  [57600/70677]
loss: 0.227646  [64000/70677]
loss: 0.145738  [70400/70677]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.221187 

Epoch 37
-------------------------------
loss: 0.258392  [    0/70677]
loss: 0.236656  [ 6400/70677]
loss: 0.182106  [12800/70677]
loss: 0.189904  [19200/70677]
loss: 0.200377  [25600/70677]
loss: 0.088941  [32000/70677]
loss: 0.155730  [38400/70677]
loss: 0.141511  [44800/70677]
loss: 0.156750  [51200/70677]
loss: 0.263334  [57600/70677]
loss: 0.182600  [64000/70677]
loss: 1.741914  [70400/70677]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.225949 

Epoch 38
-------------------------------
loss: 0.128924  [    0/70677]
loss: 0.178989  [ 6400/70677]
loss: 0.276233  [12800/70677]
loss: 0.146407  [19200/70677]
loss: 0.179039  [25600/70677]
loss: 0.150930  [32000/70677]
loss: 0.106274  [38400/70677]
loss: 0.186755  [44800/70677]
loss: 0.159215  [51200/70677]
loss: 0.148808  [57600/70677]
loss: 0.097964  [64000/70677]
loss: 0.288415  [70400/70677]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.220435 

Epoch 39
-------------------------------
loss: 0.157877  [    0/70677]
loss: 0.092679  [ 6400/70677]
loss: 0.112782  [12800/70677]
loss: 0.152497  [19200/70677]
loss: 0.207768  [25600/70677]
loss: 0.196039  [32000/70677]
loss: 0.142356  [38400/70677]
loss: 0.125691  [44800/70677]
loss: 0.069725  [51200/70677]
loss: 0.285426  [57600/70677]
loss: 0.069063  [64000/70677]
loss: 0.262146  [70400/70677]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.220972 

Epoch 40
-------------------------------
loss: 0.339245  [    0/70677]
loss: 0.186083  [ 6400/70677]
loss: 0.048554  [12800/70677]
loss: 0.110792  [19200/70677]
loss: 0.122955  [25600/70677]
loss: 0.123186  [32000/70677]
loss: 0.131760  [38400/70677]
loss: 0.129327  [44800/70677]
loss: 0.164681  [51200/70677]
loss: 0.130699  [57600/70677]
loss: 0.138994  [64000/70677]
loss: 0.401498  [70400/70677]
Test Error: 
 Accuracy: 90.7%, Avg loss: 0.314151 

Epoch 41
-------------------------------
loss: 1.866878  [    0/70677]
loss: 0.156414  [ 6400/70677]
loss: 0.224179  [12800/70677]
loss: 0.097465  [19200/70677]
loss: 0.079457  [25600/70677]
loss: 0.082931  [32000/70677]
loss: 0.163947  [38400/70677]
loss: 0.105058  [44800/70677]
loss: 0.111882  [51200/70677]
loss: 0.071849  [57600/70677]
loss: 0.170557  [64000/70677]
loss: 0.237620  [70400/70677]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.218619 

Epoch 42
-------------------------------
loss: 0.187078  [    0/70677]
loss: 0.167783  [ 6400/70677]
loss: 0.120869  [12800/70677]
loss: 0.238322  [19200/70677]
loss: 0.188810  [25600/70677]
loss: 0.108568  [32000/70677]
loss: 0.112896  [38400/70677]
loss: 0.159134  [44800/70677]
loss: 0.216338  [51200/70677]
loss: 0.079740  [57600/70677]
loss: 0.119674  [64000/70677]
loss: 0.182571  [70400/70677]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.213816 

Epoch 43
-------------------------------
loss: 0.154662  [    0/70677]
loss: 0.111018  [ 6400/70677]
loss: 0.072506  [12800/70677]
loss: 0.105806  [19200/70677]
loss: 0.158823  [25600/70677]
loss: 0.128777  [32000/70677]
loss: 0.136323  [38400/70677]
loss: 0.189766  [44800/70677]
loss: 0.233665  [51200/70677]
loss: 0.108414  [57600/70677]
loss: 0.177816  [64000/70677]
loss: 0.084712  [70400/70677]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.220994 

Epoch 44
-------------------------------
loss: 0.121328  [    0/70677]
loss: 0.094650  [ 6400/70677]
loss: 0.061094  [12800/70677]
loss: 0.252194  [19200/70677]
loss: 0.213464  [25600/70677]
loss: 0.070336  [32000/70677]
loss: 0.117483  [38400/70677]
loss: 0.166612  [44800/70677]
loss: 0.118133  [51200/70677]
loss: 0.053955  [57600/70677]
loss: 0.090349  [64000/70677]
loss: 0.169858  [70400/70677]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.217028 

Epoch 45
-------------------------------
loss: 0.091948  [    0/70677]
loss: 0.133444  [ 6400/70677]
loss: 0.165813  [12800/70677]
loss: 0.175534  [19200/70677]
loss: 0.140981  [25600/70677]
loss: 0.131722  [32000/70677]
loss: 0.170110  [38400/70677]
loss: 0.072954  [44800/70677]
loss: 0.243001  [51200/70677]
loss: 0.156379  [57600/70677]
loss: 0.142140  [64000/70677]
loss: 0.202199  [70400/70677]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.217818 

Epoch 46
-------------------------------
loss: 0.142323  [    0/70677]
loss: 0.061856  [ 6400/70677]
loss: 0.305573  [12800/70677]
loss: 0.167826  [19200/70677]
loss: 0.187845  [25600/70677]
loss: 0.176995  [32000/70677]
loss: 0.127814  [38400/70677]
loss: 0.194415  [44800/70677]
loss: 0.122660  [51200/70677]
loss: 0.228922  [19200/70523]
loss: 0.236869  [25600/70523]
loss: 0.143937  [32000/70523]
loss: 0.036653  [38400/70523]
loss: 0.120187  [44800/70523]
loss: 0.133183  [51200/70523]
loss: 0.138603  [57600/70523]
loss: 0.107537  [64000/70523]
loss: 0.183008  [70400/70523]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.168248 

Epoch 26
-------------------------------
loss: 0.247499  [    0/70523]
loss: 0.127079  [ 6400/70523]
loss: 0.273423  [12800/70523]
loss: 0.292673  [19200/70523]
loss: 0.193092  [25600/70523]
loss: 0.117626  [32000/70523]
loss: 0.103487  [38400/70523]
loss: 0.260419  [44800/70523]
loss: 0.227879  [51200/70523]
loss: 0.216671  [57600/70523]
loss: 0.099991  [64000/70523]
loss: 0.123457  [70400/70523]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.170752 

Epoch 27
-------------------------------
loss: 0.305340  [    0/70523]
loss: 0.083057  [ 6400/70523]
loss: 0.145475  [12800/70523]
loss: 0.219486  [19200/70523]
loss: 0.170930  [25600/70523]
loss: 0.065921  [32000/70523]
loss: 0.103639  [38400/70523]
loss: 0.082209  [44800/70523]
loss: 0.217900  [51200/70523]
loss: 0.117486  [57600/70523]
loss: 0.124876  [64000/70523]
loss: 0.203557  [70400/70523]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.172075 

Epoch 28
-------------------------------
loss: 0.075908  [    0/70523]
loss: 0.038593  [ 6400/70523]
loss: 0.261465  [12800/70523]
loss: 0.205433  [19200/70523]
loss: 0.261008  [25600/70523]
loss: 0.325926  [32000/70523]
loss: 0.147590  [38400/70523]
loss: 0.110199  [44800/70523]
loss: 0.133076  [51200/70523]
loss: 0.206038  [57600/70523]
loss: 0.230346  [64000/70523]
loss: 0.101930  [70400/70523]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.177579 

Epoch 29
-------------------------------
loss: 0.095411  [    0/70523]
loss: 0.082392  [ 6400/70523]
loss: 0.213250  [12800/70523]
loss: 0.206589  [19200/70523]
loss: 0.124824  [25600/70523]
loss: 0.095187  [32000/70523]
loss: 0.133392  [38400/70523]
loss: 0.240595  [44800/70523]
loss: 0.104021  [51200/70523]
loss: 0.169771  [57600/70523]
loss: 0.155586  [64000/70523]
loss: 0.074427  [70400/70523]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.168130 

Epoch 30
-------------------------------
loss: 0.161787  [    0/70523]
loss: 0.092125  [ 6400/70523]
loss: 0.106441  [12800/70523]
loss: 0.083337  [19200/70523]
loss: 0.218637  [25600/70523]
loss: 0.163973  [32000/70523]
loss: 0.250860  [38400/70523]
loss: 0.197256  [44800/70523]
loss: 0.182382  [51200/70523]
loss: 0.108389  [57600/70523]
loss: 0.136541  [64000/70523]
loss: 0.098893  [70400/70523]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174045 

Epoch 31
-------------------------------
loss: 0.177438  [    0/70523]
loss: 0.123849  [ 6400/70523]
loss: 0.159013  [12800/70523]
loss: 0.164517  [19200/70523]
loss: 0.134585  [25600/70523]
loss: 0.235083  [32000/70523]
loss: 0.082267  [38400/70523]
loss: 0.116012  [44800/70523]
loss: 0.106136  [51200/70523]
loss: 0.295546  [57600/70523]
loss: 0.157558  [64000/70523]
loss: 0.264591  [70400/70523]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171141 

Epoch 32
-------------------------------
loss: 0.107642  [    0/70523]
loss: 0.062109  [ 6400/70523]
loss: 0.224118  [12800/70523]
loss: 0.089559  [19200/70523]
loss: 0.120674  [25600/70523]
loss: 0.207475  [32000/70523]
loss: 0.191166  [38400/70523]
loss: 0.183277  [44800/70523]
loss: 0.116560  [51200/70523]
loss: 0.217133  [57600/70523]
loss: 0.145375  [64000/70523]
loss: 0.241131  [70400/70523]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173238 

Epoch 33
-------------------------------
loss: 0.113789  [    0/70523]
loss: 0.154592  [ 6400/70523]
loss: 0.111253  [12800/70523]
loss: 0.125201  [19200/70523]
loss: 0.146249  [25600/70523]
loss: 0.203566  [32000/70523]
loss: 0.206938  [38400/70523]
loss: 0.215994  [44800/70523]
loss: 0.149941  [51200/70523]
loss: 0.141492  [57600/70523]
loss: 0.227102  [64000/70523]
loss: 0.255349  [70400/70523]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.167371 

Epoch 34
-------------------------------
loss: 0.212670  [    0/70523]
loss: 0.166180  [ 6400/70523]
loss: 0.144507  [12800/70523]
loss: 0.223669  [19200/70523]
loss: 0.134858  [25600/70523]
loss: 0.133672  [32000/70523]
loss: 0.097779  [38400/70523]
loss: 0.126576  [44800/70523]
loss: 0.284254  [51200/70523]
loss: 0.197203  [57600/70523]
loss: 0.089450  [64000/70523]
loss: 0.120276  [70400/70523]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.173869 

Epoch 35
-------------------------------
loss: 0.179390  [    0/70523]
loss: 0.281728  [ 6400/70523]
loss: 0.242493  [12800/70523]
loss: 0.073872  [19200/70523]
loss: 0.194350  [25600/70523]
loss: 0.404744  [32000/70523]
loss: 0.148511  [38400/70523]
loss: 0.064316  [44800/70523]
loss: 0.114940  [51200/70523]
loss: 0.217054  [57600/70523]
loss: 0.227724  [64000/70523]
loss: 0.262076  [70400/70523]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.173756 

Epoch 36
-------------------------------
loss: 0.159238  [    0/70523]
loss: 0.211611  [ 6400/70523]
loss: 0.058972  [12800/70523]
loss: 0.125187  [19200/70523]
loss: 0.090944  [25600/70523]
loss: 0.121045  [32000/70523]
loss: 0.094084  [38400/70523]
loss: 0.083761  [44800/70523]
loss: 0.080519  [51200/70523]
loss: 0.237281  [57600/70523]
loss: 0.078419  [64000/70523]
loss: 0.145220  [70400/70523]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.163161 

Epoch 37
-------------------------------
loss: 0.231699  [    0/70523]
loss: 0.042076  [ 6400/70523]
loss: 0.157910  [12800/70523]
loss: 0.119701  [19200/70523]
loss: 0.178514  [25600/70523]
loss: 0.088511  [32000/70523]
loss: 0.047850  [38400/70523]
loss: 0.130389  [44800/70523]
loss: 0.219178  [51200/70523]
loss: 0.217410  [57600/70523]
loss: 0.159653  [64000/70523]
loss: 0.110744  [70400/70523]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.169009 

Epoch 38
-------------------------------
loss: 0.217555  [    0/70523]
loss: 0.100820  [ 6400/70523]
loss: 0.253185  [12800/70523]
loss: 0.118367  [19200/70523]
loss: 0.148576  [25600/70523]
loss: 0.157568  [32000/70523]
loss: 0.151422  [38400/70523]
loss: 0.229757  [44800/70523]
loss: 0.281959  [51200/70523]
loss: 0.194148  [57600/70523]
loss: 0.158600  [64000/70523]
loss: 0.152908  [70400/70523]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.167323 

Epoch 39
-------------------------------
loss: 0.141862  [    0/70523]
loss: 0.087814  [ 6400/70523]
loss: 0.251634  [12800/70523]
loss: 0.212033  [19200/70523]
loss: 0.139256  [25600/70523]
loss: 0.120886  [32000/70523]
loss: 0.231932  [38400/70523]
loss: 0.110919  [44800/70523]
loss: 0.151953  [51200/70523]
loss: 0.255687  [57600/70523]
loss: 0.072679  [64000/70523]
loss: 0.106523  [70400/70523]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177788 

Epoch 40
-------------------------------
loss: 0.086104  [    0/70523]
loss: 0.272265  [ 6400/70523]
loss: 0.095202  [12800/70523]
loss: 0.077368  [19200/70523]
loss: 0.195975  [25600/70523]
loss: 0.253763  [32000/70523]
loss: 0.179800  [38400/70523]
loss: 0.138827  [44800/70523]
loss: 0.089819  [51200/70523]
loss: 0.122163  [57600/70523]
loss: 0.148440  [64000/70523]
loss: 0.170897  [70400/70523]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177873 

Epoch 41
-------------------------------
loss: 0.121245  [    0/70523]
loss: 0.112520  [ 6400/70523]
loss: 0.241592  [12800/70523]
loss: 0.284483  [19200/70523]
loss: 0.228217  [25600/70523]
loss: 0.079009  [32000/70523]
loss: 0.195301  [38400/70523]
loss: 0.200850  [44800/70523]
loss: 0.209604  [51200/70523]
loss: 0.163222  [57600/70523]
loss: 0.142963  [64000/70523]
loss: 0.185504  [70400/70523]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.176252 

Epoch 42
-------------------------------
loss: 0.079759  [    0/70523]
loss: 0.122058  [ 6400/70523]
loss: 0.246740  [12800/70523]
loss: 0.095002  [19200/70523]
loss: 0.142191  [25600/70523]
loss: 0.174395  [32000/70523]
loss: 0.148192  [38400/70523]
loss: 0.276926  [44800/70523]
loss: 0.167334  [51200/70523]
loss: 0.112400  [57600/70523]
loss: 0.199920  [64000/70523]
loss: 0.133440  [70400/70523]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.175661 

Epoch 43
-------------------------------
loss: 0.098537  [    0/70523]
loss: 0.182565  [ 6400/70523]
loss: 0.048661  [12800/70523]
loss: 0.148223  [19200/70523]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.130644 

Epoch 22
-------------------------------
loss: 0.084787  [    0/70549]
loss: 0.098480  [ 6400/70549]
loss: 0.130007  [12800/70549]
loss: 0.120375  [19200/70549]
loss: 0.072127  [25600/70549]
loss: 0.213234  [32000/70549]
loss: 0.152573  [38400/70549]
loss: 0.149607  [44800/70549]
loss: 0.087049  [51200/70549]
loss: 0.192559  [57600/70549]
loss: 0.057041  [64000/70549]
loss: 0.072657  [70400/70549]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.127740 

Epoch 23
-------------------------------
loss: 0.102432  [    0/70549]
loss: 0.077493  [ 6400/70549]
loss: 0.134184  [12800/70549]
loss: 0.084533  [19200/70549]
loss: 0.077641  [25600/70549]
loss: 0.086653  [32000/70549]
loss: 0.119956  [38400/70549]
loss: 1.683890  [44800/70549]
loss: 0.189699  [51200/70549]
loss: 0.218164  [57600/70549]
loss: 1.630774  [64000/70549]
loss: 0.085915  [70400/70549]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.138110 

Epoch 24
-------------------------------
loss: 0.090245  [    0/70549]
loss: 0.094521  [ 6400/70549]
loss: 0.109445  [12800/70549]
loss: 0.122726  [19200/70549]
loss: 0.104985  [25600/70549]
loss: 0.153356  [32000/70549]
loss: 0.111776  [38400/70549]
loss: 0.162330  [44800/70549]
loss: 0.194360  [51200/70549]
loss: 0.056720  [57600/70549]
loss: 0.156371  [64000/70549]
loss: 0.094339  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.122540 

Epoch 25
-------------------------------
loss: 0.023606  [    0/70549]
loss: 0.078985  [ 6400/70549]
loss: 0.091773  [12800/70549]
loss: 0.068862  [19200/70549]
loss: 0.081237  [25600/70549]
loss: 0.211884  [32000/70549]
loss: 0.120187  [38400/70549]
loss: 0.059298  [44800/70549]
loss: 0.206942  [51200/70549]
loss: 0.100124  [57600/70549]
loss: 0.073292  [64000/70549]
loss: 0.106010  [70400/70549]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.135417 

Epoch 26
-------------------------------
loss: 0.050308  [    0/70549]
loss: 0.156309  [ 6400/70549]
loss: 0.063947  [12800/70549]
loss: 0.174418  [19200/70549]
loss: 0.178409  [25600/70549]
loss: 0.094131  [32000/70549]
loss: 0.153358  [38400/70549]
loss: 0.155933  [44800/70549]
loss: 0.168761  [51200/70549]
loss: 0.056582  [57600/70549]
loss: 0.182139  [64000/70549]
loss: 0.087539  [70400/70549]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.138673 

Epoch 27
-------------------------------
loss: 0.078734  [    0/70549]
loss: 0.139574  [ 6400/70549]
loss: 0.159742  [12800/70549]
loss: 0.223729  [19200/70549]
loss: 0.136327  [25600/70549]
loss: 0.194080  [32000/70549]
loss: 0.155103  [38400/70549]
loss: 0.076537  [44800/70549]
loss: 0.064900  [51200/70549]
loss: 0.095874  [57600/70549]
loss: 0.084090  [64000/70549]
loss: 0.040957  [70400/70549]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.134923 

Epoch 28
-------------------------------
loss: 0.073675  [    0/70549]
loss: 0.095717  [ 6400/70549]
loss: 0.040476  [12800/70549]
loss: 0.114586  [19200/70549]
loss: 0.128125  [25600/70549]
loss: 0.059033  [32000/70549]
loss: 1.675467  [38400/70549]
loss: 0.057043  [44800/70549]
loss: 0.262730  [51200/70549]
loss: 0.207834  [57600/70549]
loss: 0.030029  [64000/70549]
loss: 0.127765  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.125303 

Epoch 29
-------------------------------
loss: 0.094992  [    0/70549]
loss: 0.061356  [ 6400/70549]
loss: 0.091653  [12800/70549]
loss: 0.109626  [19200/70549]
loss: 0.117643  [25600/70549]
loss: 0.117624  [32000/70549]
loss: 0.311450  [38400/70549]
loss: 0.085443  [44800/70549]
loss: 0.205551  [51200/70549]
loss: 0.088673  [57600/70549]
loss: 0.168659  [64000/70549]
loss: 0.145940  [70400/70549]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.120565 

Epoch 30
-------------------------------
loss: 0.159004  [    0/70549]
loss: 0.156065  [ 6400/70549]
loss: 0.167276  [12800/70549]
loss: 0.160050  [19200/70549]
loss: 0.100603  [25600/70549]
loss: 0.064641  [32000/70549]
loss: 0.145411  [38400/70549]
loss: 0.108404  [44800/70549]
loss: 0.061133  [51200/70549]
loss: 0.177580  [57600/70549]
loss: 0.035619  [64000/70549]
loss: 0.103555  [70400/70549]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.126625 

Epoch 31
-------------------------------
loss: 0.088108  [    0/70549]
loss: 0.078179  [ 6400/70549]
loss: 0.067711  [12800/70549]
loss: 0.187244  [19200/70549]
loss: 0.168282  [25600/70549]
loss: 0.107571  [32000/70549]
loss: 0.080313  [38400/70549]
loss: 0.163091  [44800/70549]
loss: 0.178631  [51200/70549]
loss: 0.110511  [57600/70549]
loss: 0.141244  [64000/70549]
loss: 0.022593  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.122195 

Epoch 32
-------------------------------
loss: 0.046152  [    0/70549]
loss: 0.110152  [ 6400/70549]
loss: 0.084286  [12800/70549]
loss: 0.261564  [19200/70549]
loss: 0.120386  [25600/70549]
loss: 0.124412  [32000/70549]
loss: 0.116872  [38400/70549]
loss: 0.120880  [44800/70549]
loss: 0.158063  [51200/70549]
loss: 0.061138  [57600/70549]
loss: 0.108317  [64000/70549]
loss: 0.115984  [70400/70549]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.131243 

Epoch 33
-------------------------------
loss: 0.105628  [    0/70549]
loss: 0.152905  [ 6400/70549]
loss: 0.110091  [12800/70549]
loss: 0.120353  [19200/70549]
loss: 0.172400  [25600/70549]
loss: 0.186362  [32000/70549]
loss: 0.160897  [38400/70549]
loss: 0.125471  [44800/70549]
loss: 0.113479  [51200/70549]
loss: 0.092469  [57600/70549]
loss: 0.232374  [64000/70549]
loss: 0.139732  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.125110 

Epoch 34
-------------------------------
loss: 0.063049  [    0/70549]
loss: 0.030648  [ 6400/70549]
loss: 0.107131  [12800/70549]
loss: 0.172858  [19200/70549]
loss: 0.116872  [25600/70549]
loss: 0.038985  [32000/70549]
loss: 0.075643  [38400/70549]
loss: 0.186643  [44800/70549]
loss: 0.172671  [51200/70549]
loss: 0.162427  [57600/70549]
loss: 0.233035  [64000/70549]
loss: 0.076106  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.127522 

Epoch 35
-------------------------------
loss: 0.121715  [    0/70549]
loss: 0.130590  [ 6400/70549]
loss: 0.089346  [12800/70549]
loss: 0.047269  [19200/70549]
loss: 0.075145  [25600/70549]
loss: 0.136496  [32000/70549]
loss: 0.185302  [38400/70549]
loss: 0.119448  [44800/70549]
loss: 0.084879  [51200/70549]
loss: 0.034736  [57600/70549]
loss: 0.055801  [64000/70549]
loss: 0.109299  [70400/70549]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.130681 

Epoch 36
-------------------------------
loss: 0.098728  [    0/70549]
loss: 0.053948  [ 6400/70549]
loss: 1.593944  [12800/70549]
loss: 0.214389  [19200/70549]
loss: 0.179659  [25600/70549]
loss: 0.130817  [32000/70549]
loss: 0.117986  [38400/70549]
loss: 0.132395  [44800/70549]
loss: 0.136475  [51200/70549]
loss: 0.024785  [57600/70549]
loss: 0.113748  [64000/70549]
loss: 0.156568  [70400/70549]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.124939 

Epoch 37
-------------------------------
loss: 0.200653  [    0/70549]
loss: 0.043639  [ 6400/70549]
loss: 0.024587  [12800/70549]
loss: 0.028324  [19200/70549]
loss: 0.142430  [25600/70549]
loss: 0.072023  [32000/70549]
loss: 0.108288  [38400/70549]
loss: 0.111757  [44800/70549]
loss: 0.092917  [51200/70549]
loss: 0.141760  [57600/70549]
loss: 0.075045  [64000/70549]
loss: 0.015400  [70400/70549]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.128256 

Epoch 38
-------------------------------
loss: 0.126255  [    0/70549]
loss: 0.137687  [ 6400/70549]
loss: 0.084981  [12800/70549]
loss: 1.759202  [19200/70549]
loss: 0.203140  [25600/70549]
loss: 0.133967  [32000/70549]
loss: 0.114101  [38400/70549]
loss: 0.076207  [44800/70549]
loss: 0.131565  [51200/70549]
loss: 0.162265  [57600/70549]
loss: 0.055830  [64000/70549]
loss: 0.168405  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.120386 

Epoch 39
-------------------------------
loss: 0.074242  [    0/70549]
loss: 0.056457  [ 6400/70549]
loss: 0.100679  [12800/70549]
loss: 0.070103  [19200/70549]
loss: 0.181016  [25600/70549]
loss: 0.140937  [32000/70549]
loss: 0.047964  [38400/70549]
loss: 0.125069  [44800/70549]
loss: 0.094512  [51200/70549]
loss: 0.076252  [57600/70549]
loss: 0.187277  [64000/70549]
loss: 0.090995  [70400/70549]
loss: 0.035596  [51200/70391]
loss: 0.154425  [57600/70391]
loss: 0.072126  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.150078 

Epoch 31
-------------------------------
loss: 0.017266  [    0/70391]
loss: 0.095224  [ 6400/70391]
loss: 0.079820  [12800/70391]
loss: 0.059366  [19200/70391]
loss: 0.028801  [25600/70391]
loss: 0.171876  [32000/70391]
loss: 0.068210  [38400/70391]
loss: 0.031940  [44800/70391]
loss: 0.073253  [51200/70391]
loss: 0.096194  [57600/70391]
loss: 0.055892  [64000/70391]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.146987 

Epoch 32
-------------------------------
loss: 0.051394  [    0/70391]
loss: 0.078045  [ 6400/70391]
loss: 0.096849  [12800/70391]
loss: 0.085826  [19200/70391]
loss: 0.134244  [25600/70391]
loss: 0.029620  [32000/70391]
loss: 0.111576  [38400/70391]
loss: 0.021837  [44800/70391]
loss: 0.106700  [51200/70391]
loss: 0.289810  [57600/70391]
loss: 0.035146  [64000/70391]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.145645 

Epoch 33
-------------------------------
loss: 0.102949  [    0/70391]
loss: 0.082788  [ 6400/70391]
loss: 0.048000  [12800/70391]
loss: 0.056712  [19200/70391]
loss: 0.057937  [25600/70391]
loss: 0.098142  [32000/70391]
loss: 0.017669  [38400/70391]
loss: 0.064229  [44800/70391]
loss: 0.025352  [51200/70391]
loss: 0.237937  [57600/70391]
loss: 1.679080  [64000/70391]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.151616 

Epoch 34
-------------------------------
loss: 0.063777  [    0/70391]
loss: 0.092430  [ 6400/70391]
loss: 0.176148  [12800/70391]
loss: 0.043851  [19200/70391]
loss: 0.007959  [25600/70391]
loss: 0.022365  [32000/70391]
loss: 0.041310  [38400/70391]
loss: 0.053428  [44800/70391]
loss: 0.167251  [51200/70391]
loss: 0.033720  [57600/70391]
loss: 0.096613  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.148587 

Epoch 35
-------------------------------
loss: 0.102425  [    0/70391]
loss: 0.079826  [ 6400/70391]
loss: 0.072170  [12800/70391]
loss: 0.097219  [19200/70391]
loss: 0.068597  [25600/70391]
loss: 0.058463  [32000/70391]
loss: 0.023030  [38400/70391]
loss: 0.051168  [44800/70391]
loss: 0.147151  [51200/70391]
loss: 0.066148  [57600/70391]
loss: 0.220387  [64000/70391]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.151937 

Epoch 36
-------------------------------
loss: 0.104237  [    0/70391]
loss: 0.034834  [ 6400/70391]
loss: 0.032731  [12800/70391]
loss: 0.021697  [19200/70391]
loss: 0.048646  [25600/70391]
loss: 0.063217  [32000/70391]
loss: 0.111917  [38400/70391]
loss: 0.105126  [44800/70391]
loss: 0.047984  [51200/70391]
loss: 0.076512  [57600/70391]
loss: 0.187634  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.151247 

Epoch 37
-------------------------------
loss: 0.013648  [    0/70391]
loss: 0.151038  [ 6400/70391]
loss: 0.213734  [12800/70391]
loss: 0.008235  [19200/70391]
loss: 0.072886  [25600/70391]
loss: 0.065132  [32000/70391]
loss: 0.205213  [38400/70391]
loss: 0.052232  [44800/70391]
loss: 0.049359  [51200/70391]
loss: 0.039492  [57600/70391]
loss: 0.095345  [64000/70391]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.157632 

Epoch 38
-------------------------------
loss: 0.034850  [    0/70391]
loss: 0.090173  [ 6400/70391]
loss: 0.020981  [12800/70391]
loss: 0.068326  [19200/70391]
loss: 0.065996  [25600/70391]
loss: 0.278502  [32000/70391]
loss: 0.091596  [38400/70391]
loss: 0.117574  [44800/70391]
loss: 0.029443  [51200/70391]
loss: 0.159056  [57600/70391]
loss: 0.152121  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.151313 

Epoch 39
-------------------------------
loss: 0.123267  [    0/70391]
loss: 0.198381  [ 6400/70391]
loss: 0.028610  [12800/70391]
loss: 0.055634  [19200/70391]
loss: 0.013282  [25600/70391]
loss: 0.034475  [32000/70391]
loss: 1.642578  [38400/70391]
loss: 0.080225  [44800/70391]
loss: 0.183431  [51200/70391]
loss: 0.047919  [57600/70391]
loss: 0.045806  [64000/70391]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.145436 

Epoch 40
-------------------------------
loss: 0.079867  [    0/70391]
loss: 0.148852  [ 6400/70391]
loss: 0.037893  [12800/70391]
loss: 0.068153  [19200/70391]
loss: 0.026725  [25600/70391]
loss: 0.047022  [32000/70391]
loss: 0.030143  [38400/70391]
loss: 0.024367  [44800/70391]
loss: 0.111988  [51200/70391]
loss: 0.103310  [57600/70391]
loss: 0.083921  [64000/70391]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.149466 

Epoch 41
-------------------------------
loss: 0.013387  [    0/70391]
loss: 0.079608  [ 6400/70391]
loss: 0.069712  [12800/70391]
loss: 0.033265  [19200/70391]
loss: 0.091859  [25600/70391]
loss: 0.072862  [32000/70391]
loss: 0.030040  [38400/70391]
loss: 0.097083  [44800/70391]
loss: 0.081198  [51200/70391]
loss: 0.058515  [57600/70391]
loss: 0.112631  [64000/70391]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.150893 

Epoch 42
-------------------------------
loss: 0.054313  [    0/70391]
loss: 0.115789  [ 6400/70391]
loss: 0.032689  [12800/70391]
loss: 0.083316  [19200/70391]
loss: 0.119364  [25600/70391]
loss: 0.089857  [32000/70391]
loss: 0.108198  [38400/70391]
loss: 0.064850  [44800/70391]
loss: 0.151542  [51200/70391]
loss: 0.245201  [57600/70391]
loss: 0.061409  [64000/70391]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.150893 

Epoch 43
-------------------------------
loss: 0.079863  [    0/70391]
loss: 0.047918  [ 6400/70391]
loss: 0.201119  [12800/70391]
loss: 0.085836  [19200/70391]
loss: 0.135200  [25600/70391]
loss: 0.053705  [32000/70391]
loss: 0.037928  [38400/70391]
loss: 0.145008  [44800/70391]
loss: 0.044405  [51200/70391]
loss: 0.047136  [57600/70391]
loss: 0.175776  [64000/70391]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.150516 

Epoch 44
-------------------------------
loss: 0.052975  [    0/70391]
loss: 0.095095  [ 6400/70391]
loss: 0.126588  [12800/70391]
loss: 0.117712  [19200/70391]
loss: 0.090434  [25600/70391]
loss: 0.065720  [32000/70391]
loss: 0.026880  [38400/70391]
loss: 0.147932  [44800/70391]
loss: 0.074275  [51200/70391]
loss: 0.153198  [57600/70391]
loss: 0.082654  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.147099 

Epoch 45
-------------------------------
loss: 0.038535  [    0/70391]
loss: 0.040830  [ 6400/70391]
loss: 0.098914  [12800/70391]
loss: 0.062538  [19200/70391]
loss: 0.060985  [25600/70391]
loss: 0.033057  [32000/70391]
loss: 0.100618  [38400/70391]
loss: 0.087695  [44800/70391]
loss: 0.273209  [51200/70391]
loss: 0.039805  [57600/70391]
loss: 0.122662  [64000/70391]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.143935 

Epoch 46
-------------------------------
loss: 0.061374  [    0/70391]
loss: 0.193458  [ 6400/70391]
loss: 0.078526  [12800/70391]
loss: 0.084126  [19200/70391]
loss: 0.041931  [25600/70391]
loss: 0.021375  [32000/70391]
loss: 0.095217  [38400/70391]
loss: 0.048594  [44800/70391]
loss: 0.055780  [51200/70391]
loss: 0.221007  [57600/70391]
loss: 0.028102  [64000/70391]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.148314 

Epoch 47
-------------------------------
loss: 0.115681  [    0/70391]
loss: 0.025069  [ 6400/70391]
loss: 0.098156  [12800/70391]
loss: 0.022761  [19200/70391]
loss: 0.073172  [25600/70391]
loss: 0.102740  [32000/70391]
loss: 0.105017  [38400/70391]
loss: 0.147333  [44800/70391]
loss: 0.034009  [51200/70391]
loss: 0.114860  [57600/70391]
loss: 0.036356  [64000/70391]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.147913 

Epoch 48
-------------------------------
loss: 0.095448  [    0/70391]
loss: 0.030935  [ 6400/70391]
loss: 0.080939  [12800/70391]
loss: 0.076879  [19200/70391]
loss: 0.060447  [25600/70391]
loss: 0.032506  [32000/70391]
loss: 0.075480  [38400/70391]
loss: 0.086063  [44800/70391]
loss: 0.110343  [51200/70391]
loss: 0.159243  [57600/70391]
loss: 0.034772  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.149171 

Epoch 49
-------------------------------
loss: 0.030618  [    0/70391]
loss: 0.139850  [ 6400/70391]
loss: 0.130987  [12800/70391]
loss: 0.051503  [19200/70391]
loss: 0.071243  [25600/70391]
loss: 0.134289  [32000/70391]
loss: 0.126341  [38400/70391]
loss: 0.055207  [44800/70391]
loss: 0.103172  [51200/70391]
loss: 0.081854  [57600/70391]
loss: 0.098988  [64000/70391]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.157510 

loss: 0.071461  [44800/71653]
loss: 0.040428  [51200/71653]
loss: 0.115002  [57600/71653]
loss: 0.037737  [64000/71653]
loss: 0.060875  [70400/71653]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.119737 

Epoch 29
-------------------------------
loss: 0.014103  [    0/71653]
loss: 0.060287  [ 6400/71653]
loss: 0.130033  [12800/71653]
loss: 0.086417  [19200/71653]
loss: 0.116009  [25600/71653]
loss: 0.038571  [32000/71653]
loss: 0.216361  [38400/71653]
loss: 0.100670  [44800/71653]
loss: 0.021518  [51200/71653]
loss: 0.018177  [57600/71653]
loss: 0.098176  [64000/71653]
loss: 0.153780  [70400/71653]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.112259 

Epoch 30
-------------------------------
loss: 0.054628  [    0/71653]
loss: 0.243779  [ 6400/71653]
loss: 0.103441  [12800/71653]
loss: 0.107071  [19200/71653]
loss: 0.178208  [25600/71653]
loss: 0.133833  [32000/71653]
loss: 0.087089  [38400/71653]
loss: 0.175393  [44800/71653]
loss: 0.054436  [51200/71653]
loss: 0.014549  [57600/71653]
loss: 0.043754  [64000/71653]
loss: 0.045201  [70400/71653]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.114399 

Epoch 31
-------------------------------
loss: 0.072592  [    0/71653]
loss: 0.081140  [ 6400/71653]
loss: 0.074123  [12800/71653]
loss: 0.051657  [19200/71653]
loss: 0.107502  [25600/71653]
loss: 0.073826  [32000/71653]
loss: 0.032679  [38400/71653]
loss: 0.065750  [44800/71653]
loss: 0.076682  [51200/71653]
loss: 0.018983  [57600/71653]
loss: 0.053707  [64000/71653]
loss: 0.077607  [70400/71653]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.114173 

Epoch 32
-------------------------------
loss: 0.047272  [    0/71653]
loss: 0.070391  [ 6400/71653]
loss: 0.027455  [12800/71653]
loss: 0.045534  [19200/71653]
loss: 0.081210  [25600/71653]
loss: 0.059989  [32000/71653]
loss: 0.028326  [38400/71653]
loss: 0.034762  [44800/71653]
loss: 0.062646  [51200/71653]
loss: 0.010536  [57600/71653]
loss: 0.037718  [64000/71653]
loss: 0.105263  [70400/71653]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.111106 

Epoch 33
-------------------------------
loss: 0.051865  [    0/71653]
loss: 0.091997  [ 6400/71653]
loss: 0.053851  [12800/71653]
loss: 0.196764  [19200/71653]
loss: 0.076567  [25600/71653]
loss: 0.036033  [32000/71653]
loss: 0.017217  [38400/71653]
loss: 0.039666  [44800/71653]
loss: 0.023742  [51200/71653]
loss: 0.125765  [57600/71653]
loss: 0.023354  [64000/71653]
loss: 0.052228  [70400/71653]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.113122 

Epoch 34
-------------------------------
loss: 0.056745  [    0/71653]
loss: 0.163467  [ 6400/71653]
loss: 0.066596  [12800/71653]
loss: 0.039342  [19200/71653]
loss: 0.033507  [25600/71653]
loss: 0.151525  [32000/71653]
loss: 0.089569  [38400/71653]
loss: 0.018193  [44800/71653]
loss: 0.045099  [51200/71653]
loss: 0.049435  [57600/71653]
loss: 0.070733  [64000/71653]
loss: 0.068168  [70400/71653]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.114469 

Epoch 35
-------------------------------
loss: 1.626412  [    0/71653]
loss: 0.022833  [ 6400/71653]
loss: 0.080907  [12800/71653]
loss: 0.090211  [19200/71653]
loss: 0.078923  [25600/71653]
loss: 0.035701  [32000/71653]
loss: 0.134928  [38400/71653]
loss: 0.098640  [44800/71653]
loss: 0.056271  [51200/71653]
loss: 0.108401  [57600/71653]
loss: 0.042018  [64000/71653]
loss: 0.036657  [70400/71653]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.110984 

Epoch 36
-------------------------------
loss: 0.029175  [    0/71653]
loss: 0.101841  [ 6400/71653]
loss: 0.098640  [12800/71653]
loss: 0.087919  [19200/71653]
loss: 0.071499  [25600/71653]
loss: 0.269583  [32000/71653]
loss: 0.111444  [38400/71653]
loss: 0.227276  [44800/71653]
loss: 0.045106  [51200/71653]
loss: 0.072353  [57600/71653]
loss: 0.062706  [64000/71653]
loss: 0.125121  [70400/71653]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.117630 

Epoch 37
-------------------------------
loss: 0.091049  [    0/71653]
loss: 0.069417  [ 6400/71653]
loss: 0.082854  [12800/71653]
loss: 1.643439  [19200/71653]
loss: 0.113022  [25600/71653]
loss: 0.056482  [32000/71653]
loss: 0.114813  [38400/71653]
loss: 0.056583  [44800/71653]
loss: 0.020622  [51200/71653]
loss: 0.072749  [57600/71653]
loss: 0.047344  [64000/71653]
loss: 0.093272  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.109601 

Epoch 38
-------------------------------
loss: 0.094638  [    0/71653]
loss: 0.145776  [ 6400/71653]
loss: 0.063496  [12800/71653]
loss: 0.157001  [19200/71653]
loss: 0.045978  [25600/71653]
loss: 0.042829  [32000/71653]
loss: 0.050371  [38400/71653]
loss: 0.056971  [44800/71653]
loss: 0.161822  [51200/71653]
loss: 0.088459  [57600/71653]
loss: 0.103384  [64000/71653]
loss: 0.089064  [70400/71653]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.114296 

Epoch 39
-------------------------------
loss: 0.063506  [    0/71653]
loss: 0.106541  [ 6400/71653]
loss: 0.079572  [12800/71653]
loss: 0.070894  [19200/71653]
loss: 0.104376  [25600/71653]
loss: 0.042504  [32000/71653]
loss: 0.040484  [38400/71653]
loss: 0.068591  [44800/71653]
loss: 0.034486  [51200/71653]
loss: 0.058349  [57600/71653]
loss: 0.094378  [64000/71653]
loss: 0.072004  [70400/71653]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.116818 

Epoch 40
-------------------------------
loss: 0.036590  [    0/71653]
loss: 0.033230  [ 6400/71653]
loss: 0.015952  [12800/71653]
loss: 0.131735  [19200/71653]
loss: 0.069202  [25600/71653]
loss: 0.090580  [32000/71653]
loss: 0.090570  [38400/71653]
loss: 0.062425  [44800/71653]
loss: 0.128921  [51200/71653]
loss: 0.094729  [57600/71653]
loss: 0.116936  [64000/71653]
loss: 0.062935  [70400/71653]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.121237 

Epoch 41
-------------------------------
loss: 0.010479  [    0/71653]
loss: 0.121818  [ 6400/71653]
loss: 0.079108  [12800/71653]
loss: 0.102296  [19200/71653]
loss: 0.076155  [25600/71653]
loss: 0.024266  [32000/71653]
loss: 0.064120  [38400/71653]
loss: 0.321593  [44800/71653]
loss: 0.096064  [51200/71653]
loss: 0.142287  [57600/71653]
loss: 0.045893  [64000/71653]
loss: 0.034358  [70400/71653]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.114991 

Epoch 42
-------------------------------
loss: 0.061816  [    0/71653]
loss: 0.050234  [ 6400/71653]
loss: 0.023891  [12800/71653]
loss: 0.086410  [19200/71653]
loss: 0.064407  [25600/71653]
loss: 0.100490  [32000/71653]
loss: 0.044049  [38400/71653]
loss: 0.028731  [44800/71653]
loss: 0.065870  [51200/71653]
loss: 0.191674  [57600/71653]
loss: 0.050030  [64000/71653]
loss: 0.088636  [70400/71653]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.113254 

Epoch 43
-------------------------------
loss: 0.039762  [    0/71653]
loss: 0.248037  [ 6400/71653]
loss: 0.055939  [12800/71653]
loss: 1.605021  [19200/71653]
loss: 0.062435  [25600/71653]
loss: 0.157391  [32000/71653]
loss: 0.023965  [38400/71653]
loss: 0.039697  [44800/71653]
loss: 0.090449  [51200/71653]
loss: 0.097084  [57600/71653]
loss: 0.108629  [64000/71653]
loss: 0.079411  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.115138 

Epoch 44
-------------------------------
loss: 0.111649  [    0/71653]
loss: 0.177949  [ 6400/71653]
loss: 0.036608  [12800/71653]
loss: 0.120530  [19200/71653]
loss: 0.037566  [25600/71653]
loss: 0.070835  [32000/71653]
loss: 0.055252  [38400/71653]
loss: 0.018458  [44800/71653]
loss: 0.037884  [51200/71653]
loss: 0.080989  [57600/71653]
loss: 0.149112  [64000/71653]
loss: 0.022665  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.107694 

Epoch 45
-------------------------------
loss: 0.092709  [    0/71653]
loss: 0.079904  [ 6400/71653]
loss: 0.044173  [12800/71653]
loss: 0.092546  [19200/71653]
loss: 0.100573  [25600/71653]
loss: 0.126739  [32000/71653]
loss: 0.072240  [38400/71653]
loss: 0.150318  [44800/71653]
loss: 0.052782  [51200/71653]
loss: 0.094949  [57600/71653]
loss: 0.091582  [64000/71653]
loss: 0.069222  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.111766 

Epoch 46
-------------------------------
loss: 0.060973  [    0/71653]
loss: 0.149271  [ 6400/71653]
loss: 0.114232  [12800/71653]
loss: 0.056270  [19200/71653]
loss: 0.027664  [25600/71653]
loss: 0.014391  [32000/71653]
loss: 0.116466  [38400/71653]
loss: 0.078527  [44800/71653]
2022/09/20 18:19:11 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.166779  [    0/69530]
loss: 0.132186  [ 6400/69530]
loss: 0.079313  [12800/69530]
loss: 0.170587  [19200/69530]
loss: 0.195029  [25600/69530]
loss: 0.125173  [32000/69530]
loss: 0.148102  [38400/69530]
loss: 0.169152  [44800/69530]
loss: 0.221451  [51200/69530]
loss: 0.080118  [57600/69530]
loss: 1.712420  [64000/69530]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.173288 

Epoch 28
-------------------------------
loss: 0.163685  [    0/69530]
loss: 0.148391  [ 6400/69530]
loss: 0.189401  [12800/69530]
loss: 0.062014  [19200/69530]
loss: 0.146811  [25600/69530]
loss: 0.188915  [32000/69530]
loss: 0.119600  [38400/69530]
loss: 0.169144  [44800/69530]
loss: 0.218910  [51200/69530]
loss: 0.261703  [57600/69530]
loss: 0.115803  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.176222 

Epoch 29
-------------------------------
loss: 0.084486  [    0/69530]
loss: 0.118019  [ 6400/69530]
loss: 0.174908  [12800/69530]
loss: 0.160699  [19200/69530]
loss: 0.112673  [25600/69530]
loss: 0.172991  [32000/69530]
loss: 0.148188  [38400/69530]
loss: 0.101269  [44800/69530]
loss: 0.223747  [51200/69530]
loss: 0.110819  [57600/69530]
loss: 0.117400  [64000/69530]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.196425 

Epoch 30
-------------------------------
loss: 0.144558  [    0/69530]
loss: 0.110976  [ 6400/69530]
loss: 0.091424  [12800/69530]
loss: 0.128425  [19200/69530]
loss: 0.170397  [25600/69530]
loss: 0.160045  [32000/69530]
loss: 0.101108  [38400/69530]
loss: 0.148186  [44800/69530]
loss: 0.208601  [51200/69530]
loss: 0.168211  [57600/69530]
loss: 0.071629  [64000/69530]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174356 

Epoch 31
-------------------------------
loss: 0.104602  [    0/69530]
loss: 0.179244  [ 6400/69530]
loss: 0.174370  [12800/69530]
loss: 0.153551  [19200/69530]
loss: 0.246836  [25600/69530]
loss: 0.162624  [32000/69530]
loss: 0.099453  [38400/69530]
loss: 0.109996  [44800/69530]
loss: 0.125767  [51200/69530]
loss: 0.158287  [57600/69530]
loss: 0.181677  [64000/69530]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.173589 

Epoch 32
-------------------------------
loss: 0.108054  [    0/69530]
loss: 0.059398  [ 6400/69530]
loss: 0.116077  [12800/69530]
loss: 0.308445  [19200/69530]
loss: 0.117979  [25600/69530]
loss: 0.095700  [32000/69530]
loss: 0.180628  [38400/69530]
loss: 0.139424  [44800/69530]
loss: 0.039255  [51200/69530]
loss: 0.109744  [57600/69530]
loss: 0.152358  [64000/69530]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174503 

Epoch 33
-------------------------------
loss: 0.250115  [    0/69530]
loss: 0.157183  [ 6400/69530]
loss: 0.147938  [12800/69530]
loss: 0.267170  [19200/69530]
loss: 0.126250  [25600/69530]
loss: 0.141870  [32000/69530]
loss: 0.201139  [38400/69530]
loss: 0.082374  [44800/69530]
loss: 0.115825  [51200/69530]
loss: 0.234761  [57600/69530]
loss: 0.114826  [64000/69530]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.167755 

Epoch 34
-------------------------------
loss: 0.250086  [    0/69530]
loss: 0.123614  [ 6400/69530]
loss: 0.228860  [12800/69530]
loss: 0.194534  [19200/69530]
loss: 0.136916  [25600/69530]
loss: 0.115843  [32000/69530]
loss: 0.124310  [38400/69530]
loss: 0.124986  [44800/69530]
loss: 0.137333  [51200/69530]
loss: 0.245004  [57600/69530]
loss: 0.091725  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.181664 

Epoch 35
-------------------------------
loss: 0.152557  [    0/69530]
loss: 0.093320  [ 6400/69530]
loss: 0.138098  [12800/69530]
loss: 0.080363  [19200/69530]
loss: 0.191129  [25600/69530]
loss: 0.152836  [32000/69530]
loss: 0.197240  [38400/69530]
loss: 0.239196  [44800/69530]
loss: 0.060619  [51200/69530]
loss: 0.143412  [57600/69530]
loss: 0.122799  [64000/69530]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.192303 

Epoch 36
-------------------------------
loss: 0.220269  [    0/69530]
loss: 0.124590  [ 6400/69530]
loss: 0.151331  [12800/69530]
loss: 0.146265  [19200/69530]
loss: 0.201954  [25600/69530]
loss: 0.090005  [32000/69530]
loss: 0.127057  [38400/69530]
loss: 0.193489  [44800/69530]
loss: 0.132745  [51200/69530]
loss: 0.203656  [57600/69530]
loss: 0.086864  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.177361 

Epoch 37
-------------------------------
loss: 0.139112  [    0/69530]
loss: 0.124100  [ 6400/69530]
loss: 0.241159  [12800/69530]
loss: 0.135126  [19200/69530]
loss: 0.162267  [25600/69530]
loss: 0.152742  [32000/69530]
loss: 0.141978  [38400/69530]
loss: 0.251444  [44800/69530]
loss: 0.213121  [51200/69530]
loss: 0.192568  [57600/69530]
loss: 0.124843  [64000/69530]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180258 

Epoch 38
-------------------------------
loss: 0.198489  [    0/69530]
loss: 0.116627  [ 6400/69530]
loss: 0.138198  [12800/69530]
loss: 0.098001  [19200/69530]
loss: 0.139210  [25600/69530]
loss: 0.089767  [32000/69530]
loss: 0.160953  [38400/69530]
loss: 0.185026  [44800/69530]
loss: 0.162847  [51200/69530]
loss: 0.145084  [57600/69530]
loss: 0.130245  [64000/69530]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.172773 

Epoch 39
-------------------------------
loss: 0.107087  [    0/69530]
loss: 0.195092  [ 6400/69530]
loss: 0.225450  [12800/69530]
loss: 0.187022  [19200/69530]
loss: 0.093647  [25600/69530]
loss: 0.157582  [32000/69530]
loss: 0.170384  [38400/69530]
loss: 0.155321  [44800/69530]
loss: 0.143714  [51200/69530]
loss: 0.163661  [57600/69530]
loss: 0.109566  [64000/69530]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.184594 

Epoch 40
-------------------------------
loss: 0.165613  [    0/69530]
loss: 0.085997  [ 6400/69530]
loss: 0.123854  [12800/69530]
loss: 0.230854  [19200/69530]
loss: 0.170389  [25600/69530]
loss: 0.181132  [32000/69530]
loss: 0.164945  [38400/69530]
loss: 0.083765  [44800/69530]
loss: 0.178959  [51200/69530]
loss: 0.124137  [57600/69530]
loss: 0.135858  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.180124 

Epoch 41
-------------------------------
loss: 0.092333  [    0/69530]
loss: 0.250120  [ 6400/69530]
loss: 0.148124  [12800/69530]
loss: 0.232165  [19200/69530]
loss: 0.051540  [25600/69530]
loss: 0.166949  [32000/69530]
loss: 0.062919  [38400/69530]
loss: 0.198546  [44800/69530]
loss: 0.168873  [51200/69530]
loss: 0.128822  [57600/69530]
loss: 0.194269  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.185351 

Epoch 42
-------------------------------
loss: 0.051556  [    0/69530]
loss: 0.207505  [ 6400/69530]
loss: 0.140006  [12800/69530]
loss: 0.085500  [19200/69530]
loss: 0.116412  [25600/69530]
loss: 0.179234  [32000/69530]
loss: 0.118597  [38400/69530]
loss: 0.057843  [44800/69530]
loss: 1.737864  [51200/69530]
loss: 0.188765  [57600/69530]
loss: 0.071866  [64000/69530]
Test Error: 
 Accuracy: 90.9%, Avg loss: 0.236999 

Epoch 43
-------------------------------
loss: 0.121171  [    0/69530]
loss: 0.239070  [ 6400/69530]
loss: 0.101329  [12800/69530]
loss: 0.206736  [19200/69530]
loss: 0.201831  [25600/69530]
loss: 0.116801  [32000/69530]
loss: 0.170028  [38400/69530]
loss: 0.129149  [44800/69530]
loss: 0.099350  [51200/69530]
loss: 0.101945  [57600/69530]
loss: 0.179783  [64000/69530]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.169752 

Epoch 44
-------------------------------
loss: 0.095211  [    0/69530]
loss: 0.132439  [ 6400/69530]
loss: 0.104399  [12800/69530]
loss: 0.284799  [19200/69530]
loss: 0.175753  [25600/69530]
loss: 0.154340  [32000/69530]
loss: 0.178542  [38400/69530]
loss: 0.137755  [44800/69530]
loss: 0.120205  [51200/69530]
loss: 0.243858  [57600/69530]
loss: 0.118459  [64000/69530]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.181764 

Epoch 45
-------------------------------
loss: 0.059191  [    0/69530]
loss: 0.081107  [ 6400/69530]
loss: 0.163834  [12800/69530]
loss: 0.180074  [19200/69530]
loss: 1.718876  [25600/69530]
loss: 0.157809  [32000/69530]
loss: 0.138541  [38400/69530]
loss: 0.134036  [44800/69530]
loss: 0.114114  [51200/69530]
loss: 0.076241  [57600/69530]
loss: 0.178521  [64000/69530]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174516 

Epoch 46
-------------------------------
loss: 0.237174  [    0/69530]
loss: 0.107219  [ 6400/69530]
loss: 0.088152  [12800/69530]
loss: 0.089480  [19200/69530]
loss: 0.176594  [25600/69530]
2022/09/20 18:20:04 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 18:20:38 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Epoch 27
-------------------------------
loss: 0.177413  [    0/69274]
loss: 0.137153  [ 6400/69274]
loss: 0.189745  [12800/69274]
loss: 0.125372  [19200/69274]
loss: 0.159383  [25600/69274]
loss: 0.101482  [32000/69274]
loss: 0.120955  [38400/69274]
loss: 0.118973  [44800/69274]
loss: 0.065030  [51200/69274]
loss: 0.198327  [57600/69274]
loss: 0.081009  [64000/69274]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.189760 

Epoch 28
-------------------------------
loss: 0.168403  [    0/69274]
loss: 0.124486  [ 6400/69274]
loss: 0.248939  [12800/69274]
loss: 0.083559  [19200/69274]
loss: 0.289741  [25600/69274]
loss: 0.098579  [32000/69274]
loss: 0.138713  [38400/69274]
loss: 0.147941  [44800/69274]
loss: 0.164172  [51200/69274]
loss: 1.651732  [57600/69274]
loss: 0.116304  [64000/69274]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.175113 

Epoch 29
-------------------------------
loss: 0.073742  [    0/69274]
loss: 0.070166  [ 6400/69274]
loss: 0.216739  [12800/69274]
loss: 0.163013  [19200/69274]
loss: 0.191948  [25600/69274]
loss: 0.094513  [32000/69274]
loss: 0.189827  [38400/69274]
loss: 0.188003  [44800/69274]
loss: 0.170815  [51200/69274]
loss: 0.175891  [57600/69274]
loss: 0.110137  [64000/69274]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.179986 

Epoch 30
-------------------------------
loss: 0.145168  [    0/69274]
loss: 0.087433  [ 6400/69274]
loss: 0.138771  [12800/69274]
loss: 0.145402  [19200/69274]
loss: 0.217221  [25600/69274]
loss: 0.297191  [32000/69274]
loss: 0.145054  [38400/69274]
loss: 0.159600  [44800/69274]
loss: 0.108022  [51200/69274]
loss: 0.228438  [57600/69274]
loss: 1.747565  [64000/69274]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.196384 

Epoch 31
-------------------------------
loss: 0.076623  [    0/69274]
loss: 0.081694  [ 6400/69274]
loss: 0.102009  [12800/69274]
loss: 0.085466  [19200/69274]
loss: 0.106463  [25600/69274]
loss: 0.132696  [32000/69274]
loss: 0.158158  [38400/69274]
loss: 0.267174  [44800/69274]
loss: 0.094237  [51200/69274]
loss: 0.265057  [57600/69274]
loss: 0.112822  [64000/69274]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.169759 

Epoch 32
-------------------------------
loss: 0.053716  [    0/69274]
loss: 0.290745  [ 6400/69274]
loss: 0.195213  [12800/69274]
loss: 0.148258  [19200/69274]
loss: 0.106969  [25600/69274]
loss: 0.072122  [32000/69274]
loss: 0.085087  [38400/69274]
loss: 0.216933  [44800/69274]
loss: 0.169410  [51200/69274]
loss: 0.109444  [57600/69274]
loss: 0.204820  [64000/69274]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171637 

Epoch 33
-------------------------------
loss: 0.073919  [    0/69274]
loss: 0.128711  [ 6400/69274]
loss: 0.100377  [12800/69274]
loss: 0.074692  [19200/69274]
loss: 0.114535  [25600/69274]
loss: 0.196313  [32000/69274]
loss: 0.097464  [38400/69274]
loss: 0.058211  [44800/69274]
loss: 0.125782  [51200/69274]
loss: 0.245531  [57600/69274]
loss: 0.169700  [64000/69274]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171675 

Epoch 34
-------------------------------
loss: 0.053120  [    0/69274]
loss: 1.659326  [ 6400/69274]
loss: 0.169093  [12800/69274]
loss: 0.084436  [19200/69274]
loss: 0.080776  [25600/69274]
loss: 0.105356  [32000/69274]
loss: 0.122363  [38400/69274]
loss: 0.105464  [44800/69274]
loss: 0.187184  [51200/69274]
loss: 0.145044  [57600/69274]
loss: 0.081156  [64000/69274]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.166942 

Epoch 35
-------------------------------
loss: 0.222728  [    0/69274]
loss: 0.083966  [ 6400/69274]
loss: 0.109088  [12800/69274]
loss: 0.104033  [19200/69274]
loss: 0.071110  [25600/69274]
loss: 0.084935  [32000/69274]
loss: 0.071872  [38400/69274]
loss: 0.185043  [44800/69274]
loss: 0.177436  [51200/69274]
loss: 0.086301  [57600/69274]
loss: 0.098056  [64000/69274]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.181316 

Epoch 36
-------------------------------
loss: 0.182804  [    0/69274]
loss: 0.096504  [ 6400/69274]
loss: 0.150842  [12800/69274]
loss: 0.119536  [19200/69274]
loss: 0.115902  [25600/69274]
loss: 0.163606  [32000/69274]
loss: 0.062701  [38400/69274]
loss: 0.167083  [44800/69274]
loss: 0.189417  [51200/69274]
loss: 0.078594  [57600/69274]
loss: 0.156082  [64000/69274]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.176947 

Epoch 37
-------------------------------
loss: 0.082501  [    0/69274]
loss: 0.097282  [ 6400/69274]
loss: 0.192895  [12800/69274]
loss: 0.050368  [19200/69274]
loss: 0.141211  [25600/69274]
loss: 0.078963  [32000/69274]
loss: 0.126214  [38400/69274]
loss: 0.147597  [44800/69274]
loss: 0.122414  [51200/69274]
loss: 0.116794  [57600/69274]
loss: 0.258104  [64000/69274]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.178508 

Epoch 38
-------------------------------
loss: 0.109842  [    0/69274]
loss: 0.221878  [ 6400/69274]
loss: 0.194370  [12800/69274]
loss: 0.057878  [19200/69274]
loss: 0.133697  [25600/69274]
loss: 0.195367  [32000/69274]
loss: 0.106003  [38400/69274]
loss: 0.124115  [44800/69274]
loss: 0.154386  [51200/69274]
loss: 0.110599  [57600/69274]
loss: 0.097056  [64000/69274]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.174753 

Epoch 39
-------------------------------
loss: 0.131256  [    0/69274]
loss: 0.119276  [ 6400/69274]
loss: 0.063594  [12800/69274]
loss: 0.106659  [19200/69274]
loss: 0.051664  [25600/69274]
loss: 0.182461  [32000/69274]
loss: 0.260750  [38400/69274]
loss: 0.034479  [44800/69274]
loss: 0.225335  [51200/69274]
loss: 0.126968  [57600/69274]
loss: 0.177024  [64000/69274]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.171657 

Epoch 40
-------------------------------
loss: 0.102989  [    0/69274]
loss: 0.119042  [ 6400/69274]
loss: 0.155583  [12800/69274]
loss: 0.139443  [19200/69274]
loss: 0.099172  [25600/69274]
loss: 0.094612  [32000/69274]
loss: 0.063894  [38400/69274]
loss: 0.090377  [44800/69274]
loss: 0.167257  [51200/69274]
loss: 0.157023  [57600/69274]
loss: 1.690948  [64000/69274]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.171810 

Epoch 41
-------------------------------
loss: 0.115737  [    0/69274]
loss: 0.101892  [ 6400/69274]
loss: 0.175444  [12800/69274]
loss: 1.693607  [19200/69274]
loss: 0.281344  [25600/69274]
loss: 0.113669  [32000/69274]
loss: 0.083802  [38400/69274]
loss: 0.216468  [44800/69274]
loss: 0.200816  [51200/69274]
loss: 0.264902  [57600/69274]
loss: 0.283720  [64000/69274]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.186512 

Epoch 42
-------------------------------
loss: 0.171380  [    0/69274]
loss: 0.079307  [ 6400/69274]
loss: 0.071051  [12800/69274]
loss: 0.116416  [19200/69274]
loss: 0.038428  [25600/69274]
loss: 0.057183  [32000/69274]
loss: 0.278431  [38400/69274]
loss: 0.323178  [44800/69274]
loss: 0.095854  [51200/69274]
loss: 0.066124  [57600/69274]
loss: 0.065815  [64000/69274]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174467 

Epoch 43
-------------------------------
loss: 0.099720  [    0/69274]
loss: 0.169963  [ 6400/69274]
loss: 0.148303  [12800/69274]
loss: 0.084349  [19200/69274]
loss: 0.248725  [25600/69274]
loss: 0.084295  [32000/69274]
loss: 0.190385  [38400/69274]
loss: 0.294682  [44800/69274]
loss: 0.200325  [51200/69274]
loss: 0.160113  [57600/69274]
loss: 0.122487  [64000/69274]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.169869 

Epoch 44
-------------------------------
loss: 0.138986  [    0/69274]
loss: 0.046531  [ 6400/69274]
loss: 0.204031  [12800/69274]
loss: 0.121042  [19200/69274]
loss: 0.070961  [25600/69274]
loss: 0.116073  [32000/69274]
loss: 0.179490  [38400/69274]
loss: 0.110152  [44800/69274]
loss: 0.138154  [51200/69274]
loss: 0.106488  [57600/69274]
loss: 0.136538  [64000/69274]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.177508 

Epoch 45
-------------------------------
loss: 0.026544  [    0/69274]
loss: 0.193423  [ 6400/69274]
loss: 0.220141  [12800/69274]
loss: 0.206704  [19200/69274]
loss: 0.220016  [25600/69274]
loss: 0.221148  [32000/69274]
loss: 0.120832  [38400/69274]
loss: 0.133527  [44800/69274]
loss: 0.084101  [51200/69274]
loss: 0.115641  [57600/69274]
loss: 0.169171  [64000/69274]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.168893 

Epoch 46
-------------------------------
loss: 0.142629  [    0/69274]
loss: 0.160509  [ 6400/69274]
loss: 0.116294  [12800/69274]
2022/09/20 18:21:44 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 18:21:51 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.040700  [70400/70852]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.169791 

Epoch 32
-------------------------------
loss: 0.104901  [    0/70852]
loss: 0.246508  [ 6400/70852]
loss: 0.090857  [12800/70852]
loss: 0.046118  [19200/70852]
loss: 0.166968  [25600/70852]
loss: 0.082506  [32000/70852]
loss: 0.150024  [38400/70852]
loss: 0.286545  [44800/70852]
loss: 0.124569  [51200/70852]
loss: 0.136746  [57600/70852]
loss: 0.111092  [64000/70852]
loss: 0.052225  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.167056 

Epoch 33
-------------------------------
loss: 0.096377  [    0/70852]
loss: 0.461679  [ 6400/70852]
loss: 0.065788  [12800/70852]
loss: 0.097705  [19200/70852]
loss: 0.036954  [25600/70852]
loss: 0.142689  [32000/70852]
loss: 0.107576  [38400/70852]
loss: 0.135306  [44800/70852]
loss: 0.142630  [51200/70852]
loss: 0.034513  [57600/70852]
loss: 0.085239  [64000/70852]
loss: 0.036717  [70400/70852]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.177988 

Epoch 34
-------------------------------
loss: 0.218786  [    0/70852]
loss: 0.049874  [ 6400/70852]
loss: 0.178049  [12800/70852]
loss: 0.037762  [19200/70852]
loss: 0.161397  [25600/70852]
loss: 0.100759  [32000/70852]
loss: 0.118406  [38400/70852]
loss: 0.147489  [44800/70852]
loss: 0.131038  [51200/70852]
loss: 0.090988  [57600/70852]
loss: 0.123041  [64000/70852]
loss: 0.310390  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.164512 

Epoch 35
-------------------------------
loss: 0.057436  [    0/70852]
loss: 0.164908  [ 6400/70852]
loss: 0.111335  [12800/70852]
loss: 0.034651  [19200/70852]
loss: 0.106628  [25600/70852]
loss: 0.102785  [32000/70852]
loss: 0.086848  [38400/70852]
loss: 0.328017  [44800/70852]
loss: 0.078280  [51200/70852]
loss: 0.092999  [57600/70852]
loss: 0.170535  [64000/70852]
loss: 0.054607  [70400/70852]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.165914 

Epoch 36
-------------------------------
loss: 0.080778  [    0/70852]
loss: 0.078878  [ 6400/70852]
loss: 0.198047  [12800/70852]
loss: 0.255314  [19200/70852]
loss: 0.034872  [25600/70852]
loss: 0.214561  [32000/70852]
loss: 0.032510  [38400/70852]
loss: 0.207649  [44800/70852]
loss: 0.110898  [51200/70852]
loss: 0.084810  [57600/70852]
loss: 0.074332  [64000/70852]
loss: 0.182353  [70400/70852]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.226183 

Epoch 37
-------------------------------
loss: 0.099510  [    0/70852]
loss: 0.156906  [ 6400/70852]
loss: 0.270630  [12800/70852]
loss: 0.071978  [19200/70852]
loss: 0.081720  [25600/70852]
loss: 0.052255  [32000/70852]
loss: 0.082218  [38400/70852]
loss: 0.126042  [44800/70852]
loss: 1.597323  [51200/70852]
loss: 0.059380  [57600/70852]
loss: 0.113756  [64000/70852]
loss: 0.094801  [70400/70852]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.161594 

Epoch 38
-------------------------------
loss: 0.136297  [    0/70852]
loss: 0.161633  [ 6400/70852]
loss: 0.171428  [12800/70852]
loss: 0.149894  [19200/70852]
loss: 0.023415  [25600/70852]
loss: 0.178429  [32000/70852]
loss: 0.095300  [38400/70852]
loss: 0.192076  [44800/70852]
loss: 0.147526  [51200/70852]
loss: 0.107260  [57600/70852]
loss: 0.124081  [64000/70852]
loss: 0.165146  [70400/70852]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.219890 

Epoch 39
-------------------------------
loss: 0.246142  [    0/70852]
loss: 0.084216  [ 6400/70852]
loss: 0.084992  [12800/70852]
loss: 0.189924  [19200/70852]
loss: 0.054977  [25600/70852]
loss: 0.082234  [32000/70852]
loss: 0.101357  [38400/70852]
loss: 0.100701  [44800/70852]
loss: 0.104758  [51200/70852]
loss: 0.169947  [57600/70852]
loss: 0.066725  [64000/70852]
loss: 0.122642  [70400/70852]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.194373 

Epoch 40
-------------------------------
loss: 0.048374  [    0/70852]
loss: 0.068854  [ 6400/70852]
loss: 0.151023  [12800/70852]
loss: 0.073312  [19200/70852]
loss: 0.090706  [25600/70852]
loss: 0.096497  [32000/70852]
loss: 0.111227  [38400/70852]
loss: 0.024801  [44800/70852]
loss: 0.060284  [51200/70852]
loss: 0.205818  [57600/70852]
loss: 0.076481  [64000/70852]
loss: 0.139549  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.167876 

Epoch 41
-------------------------------
loss: 1.710644  [    0/70852]
loss: 0.045066  [ 6400/70852]
loss: 0.079335  [12800/70852]
loss: 0.121830  [19200/70852]
loss: 0.103177  [25600/70852]
loss: 0.099423  [32000/70852]
loss: 0.072340  [38400/70852]
loss: 0.047735  [44800/70852]
loss: 0.229732  [51200/70852]
loss: 1.679302  [57600/70852]
loss: 0.115637  [64000/70852]
loss: 0.061635  [70400/70852]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.171792 

Epoch 42
-------------------------------
loss: 0.093639  [    0/70852]
loss: 0.119590  [ 6400/70852]
loss: 1.619234  [12800/70852]
loss: 0.085384  [19200/70852]
loss: 0.047412  [25600/70852]
loss: 0.135733  [32000/70852]
loss: 0.089061  [38400/70852]
loss: 0.081399  [44800/70852]
loss: 0.098362  [51200/70852]
loss: 0.196580  [57600/70852]
loss: 0.049298  [64000/70852]
loss: 0.092381  [70400/70852]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.170472 

Epoch 43
-------------------------------
loss: 0.080312  [    0/70852]
loss: 0.042493  [ 6400/70852]
loss: 0.159945  [12800/70852]
loss: 0.073150  [19200/70852]
loss: 0.154006  [25600/70852]
loss: 0.121121  [32000/70852]
loss: 0.066836  [38400/70852]
loss: 0.156932  [44800/70852]
loss: 0.108058  [51200/70852]
loss: 0.205155  [57600/70852]
loss: 0.083163  [64000/70852]
loss: 0.112760  [70400/70852]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.186331 

Epoch 44
-------------------------------
loss: 0.079239  [    0/70852]
loss: 0.097600  [ 6400/70852]
loss: 0.135357  [12800/70852]
loss: 0.106737  [19200/70852]
loss: 0.110836  [25600/70852]
loss: 0.092095  [32000/70852]
loss: 0.110027  [38400/70852]
loss: 0.038216  [44800/70852]
loss: 0.229906  [51200/70852]
loss: 0.145066  [57600/70852]
loss: 0.085524  [64000/70852]
loss: 0.112990  [70400/70852]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.160896 

Epoch 45
-------------------------------
loss: 0.087220  [    0/70852]
loss: 0.061722  [ 6400/70852]
loss: 0.106601  [12800/70852]
loss: 0.058418  [19200/70852]
loss: 0.127850  [25600/70852]
loss: 0.170012  [32000/70852]
loss: 0.102307  [38400/70852]
loss: 0.156125  [44800/70852]
loss: 0.101043  [51200/70852]
loss: 0.125780  [57600/70852]
loss: 0.089877  [64000/70852]
loss: 0.129283  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.164827 

Epoch 46
-------------------------------
loss: 0.206727  [    0/70852]
loss: 0.053789  [ 6400/70852]
loss: 0.111614  [12800/70852]
loss: 0.102540  [19200/70852]
loss: 0.203820  [25600/70852]
loss: 0.056527  [32000/70852]
loss: 0.155827  [38400/70852]
loss: 0.148093  [44800/70852]
loss: 0.107113  [51200/70852]
loss: 0.152820  [57600/70852]
loss: 0.077900  [64000/70852]
loss: 0.193370  [70400/70852]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.165707 

Epoch 47
-------------------------------
loss: 0.146414  [    0/70852]
loss: 0.066993  [ 6400/70852]
loss: 0.108941  [12800/70852]
loss: 0.030464  [19200/70852]
loss: 0.158612  [25600/70852]
loss: 0.115520  [32000/70852]
loss: 0.140871  [38400/70852]
loss: 0.082149  [44800/70852]
loss: 0.200784  [51200/70852]
loss: 0.113942  [57600/70852]
loss: 0.091222  [64000/70852]
loss: 0.161798  [70400/70852]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.171933 

Epoch 48
-------------------------------
loss: 0.195445  [    0/70852]
loss: 0.146993  [ 6400/70852]
loss: 0.289956  [12800/70852]
loss: 0.159749  [19200/70852]
loss: 0.078362  [25600/70852]
loss: 1.614461  [32000/70852]
loss: 0.103503  [38400/70852]
loss: 0.111857  [44800/70852]
loss: 0.124893  [51200/70852]
loss: 0.107171  [57600/70852]
loss: 0.251492  [64000/70852]
loss: 0.172474  [70400/70852]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.196603 

Epoch 49
-------------------------------
loss: 0.125208  [    0/70852]
loss: 0.172709  [ 6400/70852]
loss: 0.139202  [12800/70852]
loss: 0.130924  [19200/70852]
loss: 0.123549  [25600/70852]
loss: 0.066583  [32000/70852]
loss: 0.041844  [38400/70852]
loss: 0.180029  [44800/70852]
loss: 0.106697  [51200/70852]
loss: 0.124007  [57600/70852]
loss: 0.089949  [64000/70852]
loss: 0.130501  [70400/70852]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.117408 

Epoch 40
-------------------------------
loss: 0.052606  [    0/71783]
loss: 0.029692  [ 6400/71783]
loss: 0.028792  [12800/71783]
loss: 0.013984  [19200/71783]
loss: 0.081630  [25600/71783]
loss: 0.066086  [32000/71783]
loss: 0.045252  [38400/71783]
loss: 0.018306  [44800/71783]
loss: 0.043342  [51200/71783]
loss: 0.035934  [57600/71783]
loss: 0.018029  [64000/71783]
loss: 0.007390  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.097707 

Epoch 41
-------------------------------
loss: 0.010877  [    0/71783]
loss: 0.050376  [ 6400/71783]
loss: 0.004603  [12800/71783]
loss: 0.020956  [19200/71783]
loss: 0.054504  [25600/71783]
loss: 0.020526  [32000/71783]
loss: 0.028871  [38400/71783]
loss: 0.030439  [44800/71783]
loss: 0.037889  [51200/71783]
loss: 0.046355  [57600/71783]
loss: 0.008728  [64000/71783]
loss: 0.030695  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.101449 

Epoch 42
-------------------------------
loss: 0.077811  [    0/71783]
loss: 0.010032  [ 6400/71783]
loss: 0.014962  [12800/71783]
loss: 0.055374  [19200/71783]
loss: 0.029075  [25600/71783]
loss: 0.021952  [32000/71783]
loss: 0.006064  [38400/71783]
loss: 0.103369  [44800/71783]
loss: 0.012588  [51200/71783]
loss: 0.092651  [57600/71783]
loss: 0.083705  [64000/71783]
loss: 0.078183  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.094247 

Epoch 43
-------------------------------
loss: 0.093607  [    0/71783]
loss: 0.075311  [ 6400/71783]
loss: 0.021968  [12800/71783]
loss: 0.030715  [19200/71783]
loss: 0.049436  [25600/71783]
loss: 0.043648  [32000/71783]
loss: 0.010956  [38400/71783]
loss: 0.073608  [44800/71783]
loss: 0.010015  [51200/71783]
loss: 0.055419  [57600/71783]
loss: 0.020715  [64000/71783]
loss: 0.043283  [70400/71783]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.122658 

Epoch 44
-------------------------------
loss: 0.057987  [    0/71783]
loss: 0.021152  [ 6400/71783]
loss: 0.023176  [12800/71783]
loss: 0.020091  [19200/71783]
loss: 0.031877  [25600/71783]
loss: 0.008151  [32000/71783]
loss: 0.010029  [38400/71783]
loss: 0.104842  [44800/71783]
loss: 0.048301  [51200/71783]
loss: 0.032581  [57600/71783]
loss: 0.033034  [64000/71783]
loss: 0.051752  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.101631 

Epoch 45
-------------------------------
loss: 0.049618  [    0/71783]
loss: 0.008206  [ 6400/71783]
loss: 0.087718  [12800/71783]
loss: 0.035730  [19200/71783]
loss: 0.012570  [25600/71783]
loss: 0.043411  [32000/71783]
loss: 0.031154  [38400/71783]
loss: 0.026451  [44800/71783]
loss: 0.014310  [51200/71783]
loss: 0.015332  [57600/71783]
loss: 0.042607  [64000/71783]
loss: 0.099873  [70400/71783]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.102330 

Epoch 46
-------------------------------
loss: 0.011630  [    0/71783]
loss: 0.025339  [ 6400/71783]
loss: 0.077496  [12800/71783]
loss: 0.052310  [19200/71783]
loss: 0.014407  [25600/71783]
loss: 0.080032  [32000/71783]
loss: 0.014242  [38400/71783]
loss: 0.028648  [44800/71783]
loss: 0.105320  [51200/71783]
loss: 0.082676  [57600/71783]
loss: 0.003292  [64000/71783]
loss: 0.006713  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.113734 

Epoch 47
-------------------------------
loss: 0.042967  [    0/71783]
loss: 0.077592  [ 6400/71783]
loss: 0.060696  [12800/71783]
loss: 0.060726  [19200/71783]
loss: 0.089172  [25600/71783]
loss: 0.045456  [32000/71783]
loss: 0.041706  [38400/71783]
loss: 0.077836  [44800/71783]
loss: 0.044727  [51200/71783]
loss: 0.016457  [57600/71783]
loss: 0.006637  [64000/71783]
loss: 0.004076  [70400/71783]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.100435 

Epoch 48
-------------------------------
loss: 0.023344  [    0/71783]
loss: 0.010081  [ 6400/71783]
loss: 0.094892  [12800/71783]
loss: 0.009955  [19200/71783]
loss: 0.069543  [25600/71783]
loss: 0.023209  [32000/71783]
loss: 0.068481  [38400/71783]
loss: 0.103590  [44800/71783]
loss: 0.044288  [51200/71783]
loss: 0.028962  [57600/71783]
loss: 0.053509  [64000/71783]
loss: 0.009105  [70400/71783]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.104658 

Epoch 49
-------------------------------
loss: 0.019113  [    0/71783]
loss: 0.030362  [ 6400/71783]
loss: 0.039358  [12800/71783]
loss: 0.002601  [19200/71783]
loss: 0.073386  [25600/71783]
loss: 0.079251  [32000/71783]
loss: 0.004737  [38400/71783]
loss: 0.104775  [44800/71783]
loss: 0.019803  [51200/71783]
loss: 0.100283  [57600/71783]
loss: 0.084921  [64000/71783]
loss: 0.017765  [70400/71783]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.091268 

Epoch 50
-------------------------------
loss: 0.016611  [    0/71783]
loss: 0.098478  [ 6400/71783]
loss: 0.040746  [12800/71783]
loss: 0.006652  [19200/71783]
loss: 0.005014  [25600/71783]
loss: 0.017668  [32000/71783]
loss: 0.004493  [38400/71783]
loss: 0.021695  [44800/71783]
loss: 0.016851  [51200/71783]
loss: 0.025840  [57600/71783]
loss: 0.028183  [64000/71783]
loss: 0.105936  [70400/71783]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.134301 

Epoch 1
-------------------------------
loss: 0.653249  [    0/69713]
loss: 0.328106  [ 6400/69713]
loss: 0.202699  [12800/69713]
loss: 0.162022  [19200/69713]
loss: 0.253608  [25600/69713]
loss: 0.253724  [32000/69713]
loss: 0.280164  [38400/69713]
loss: 0.265044  [44800/69713]
loss: 0.290873  [51200/69713]
loss: 0.116226  [57600/69713]
loss: 0.242110  [64000/69713]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.232313 

Epoch 2
-------------------------------
loss: 0.211085  [    0/69713]
loss: 0.252847  [ 6400/69713]
loss: 0.173002  [12800/69713]
loss: 0.182945  [19200/69713]
loss: 0.168904  [25600/69713]
loss: 0.294784  [32000/69713]
loss: 0.205612  [38400/69713]
loss: 0.138902  [44800/69713]
loss: 0.152050  [51200/69713]
loss: 0.136670  [57600/69713]
loss: 0.197398  [64000/69713]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.211563 

Epoch 3
-------------------------------
loss: 0.160053  [    0/69713]
loss: 0.259076  [ 6400/69713]
loss: 0.208026  [12800/69713]
loss: 0.142671  [19200/69713]
loss: 0.229861  [25600/69713]
loss: 0.178892  [32000/69713]
loss: 0.182325  [38400/69713]
loss: 0.123468  [44800/69713]
loss: 0.193493  [51200/69713]
loss: 0.316884  [57600/69713]
loss: 0.153133  [64000/69713]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.206417 

Epoch 4
-------------------------------
loss: 0.120554  [    0/69713]
loss: 0.091596  [ 6400/69713]
loss: 0.182515  [12800/69713]
loss: 0.131797  [19200/69713]
loss: 0.078922  [25600/69713]
loss: 0.213896  [32000/69713]
loss: 0.150018  [38400/69713]
loss: 0.136366  [44800/69713]
loss: 0.199967  [51200/69713]
loss: 0.217532  [57600/69713]
loss: 0.132875  [64000/69713]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.176126 

Epoch 5
-------------------------------
loss: 0.151881  [    0/69713]
loss: 0.192277  [ 6400/69713]
loss: 0.168894  [12800/69713]
loss: 0.162476  [19200/69713]
loss: 0.165379  [25600/69713]
loss: 0.175318  [32000/69713]
loss: 0.213944  [38400/69713]
loss: 0.077755  [44800/69713]
loss: 0.153333  [51200/69713]
loss: 0.141110  [57600/69713]
loss: 0.158514  [64000/69713]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.192333 

Epoch 6
-------------------------------
loss: 0.386398  [    0/69713]
loss: 0.203877  [ 6400/69713]
loss: 0.265668  [12800/69713]
loss: 0.127662  [19200/69713]
loss: 0.294620  [25600/69713]
loss: 0.370406  [32000/69713]
loss: 0.246952  [38400/69713]
loss: 0.230730  [44800/69713]
loss: 0.176573  [51200/69713]
loss: 0.297223  [57600/69713]
loss: 0.185755  [64000/69713]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.176881 

Epoch 7
-------------------------------
loss: 0.123648  [    0/69713]
loss: 0.109900  [ 6400/69713]
loss: 0.171491  [12800/69713]
loss: 0.102396  [19200/69713]
loss: 0.060502  [25600/69713]
loss: 0.157883  [32000/69713]
loss: 0.118282  [38400/69713]
loss: 0.279335  [44800/69713]
loss: 0.151991  [51200/69713]
loss: 0.217991  [57600/69713]
loss: 0.178859  [64000/69713]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.189246 

Epoch 8
-------------------------------
loss: 0.186835  [    0/69713]
loss: 0.063434  [ 6400/69713]
loss: 0.154222  [12800/69713]
loss: 0.139356  [19200/69713]
loss: 0.445579  [25600/69713]
2022/09/20 18:23:59 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.166064  [44800/69949]
loss: 0.266821  [51200/69949]
loss: 0.188365  [57600/69949]
loss: 0.160445  [64000/69949]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.147976 

Epoch 31
-------------------------------
loss: 0.133270  [    0/69949]
loss: 0.096749  [ 6400/69949]
loss: 0.063964  [12800/69949]
loss: 0.148481  [19200/69949]
loss: 0.070092  [25600/69949]
loss: 0.063215  [32000/69949]
loss: 0.127096  [38400/69949]
loss: 0.160027  [44800/69949]
loss: 0.142440  [51200/69949]
loss: 0.090240  [57600/69949]
loss: 0.103026  [64000/69949]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.160924 

Epoch 32
-------------------------------
loss: 0.076537  [    0/69949]
loss: 0.163886  [ 6400/69949]
loss: 0.156120  [12800/69949]
loss: 0.199691  [19200/69949]
loss: 0.086828  [25600/69949]
loss: 0.124345  [32000/69949]
loss: 0.061755  [38400/69949]
loss: 0.081937  [44800/69949]
loss: 0.187030  [51200/69949]
loss: 0.159407  [57600/69949]
loss: 0.153844  [64000/69949]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.155697 

Epoch 33
-------------------------------
loss: 0.075717  [    0/69949]
loss: 0.144510  [ 6400/69949]
loss: 0.174483  [12800/69949]
loss: 0.145525  [19200/69949]
loss: 0.180354  [25600/69949]
loss: 0.312488  [32000/69949]
loss: 0.099151  [38400/69949]
loss: 0.106016  [44800/69949]
loss: 0.143376  [51200/69949]
loss: 0.125141  [57600/69949]
loss: 0.036160  [64000/69949]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.143102 

Epoch 34
-------------------------------
loss: 0.200928  [    0/69949]
loss: 0.176365  [ 6400/69949]
loss: 0.091753  [12800/69949]
loss: 0.074828  [19200/69949]
loss: 0.140835  [25600/69949]
loss: 0.238465  [32000/69949]
loss: 0.159418  [38400/69949]
loss: 0.186737  [44800/69949]
loss: 0.057242  [51200/69949]
loss: 0.104036  [57600/69949]
loss: 0.192138  [64000/69949]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.153177 

Epoch 35
-------------------------------
loss: 0.082875  [    0/69949]
loss: 0.234973  [ 6400/69949]
loss: 0.118767  [12800/69949]
loss: 0.124211  [19200/69949]
loss: 0.096338  [25600/69949]
loss: 0.075910  [32000/69949]
loss: 0.119824  [38400/69949]
loss: 0.106530  [44800/69949]
loss: 0.267468  [51200/69949]
loss: 0.134130  [57600/69949]
loss: 0.058896  [64000/69949]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.140851 

Epoch 36
-------------------------------
loss: 0.259366  [    0/69949]
loss: 0.157316  [ 6400/69949]
loss: 0.059978  [12800/69949]
loss: 0.125802  [19200/69949]
loss: 0.107269  [25600/69949]
loss: 0.070359  [32000/69949]
loss: 0.078818  [38400/69949]
loss: 0.047820  [44800/69949]
loss: 0.102146  [51200/69949]
loss: 0.118451  [57600/69949]
loss: 0.068306  [64000/69949]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.153062 

Epoch 37
-------------------------------
loss: 0.175569  [    0/69949]
loss: 0.157622  [ 6400/69949]
loss: 0.149747  [12800/69949]
loss: 0.134882  [19200/69949]
loss: 0.237013  [25600/69949]
loss: 0.206962  [32000/69949]
loss: 0.123511  [38400/69949]
loss: 0.070086  [44800/69949]
loss: 0.054837  [51200/69949]
loss: 0.120889  [57600/69949]
loss: 0.045492  [64000/69949]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.152234 

Epoch 38
-------------------------------
loss: 0.098563  [    0/69949]
loss: 0.191911  [ 6400/69949]
loss: 0.174025  [12800/69949]
loss: 0.107530  [19200/69949]
loss: 0.096592  [25600/69949]
loss: 0.144307  [32000/69949]
loss: 0.035443  [38400/69949]
loss: 0.194003  [44800/69949]
loss: 0.094283  [51200/69949]
loss: 0.085245  [57600/69949]
loss: 0.055951  [64000/69949]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.145101 

Epoch 39
-------------------------------
loss: 0.108590  [    0/69949]
loss: 0.131266  [ 6400/69949]
loss: 0.262627  [12800/69949]
loss: 0.102930  [19200/69949]
loss: 0.043079  [25600/69949]
loss: 0.188398  [32000/69949]
loss: 0.112837  [38400/69949]
loss: 0.156095  [44800/69949]
loss: 0.044247  [51200/69949]
loss: 0.072891  [57600/69949]
loss: 0.108384  [64000/69949]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.146701 

Epoch 40
-------------------------------
loss: 0.123757  [    0/69949]
loss: 0.056305  [ 6400/69949]
loss: 0.109492  [12800/69949]
loss: 0.174823  [19200/69949]
loss: 0.162850  [25600/69949]
loss: 0.032514  [32000/69949]
loss: 0.130856  [38400/69949]
loss: 0.169499  [44800/69949]
loss: 0.037303  [51200/69949]
loss: 0.156364  [57600/69949]
loss: 0.069364  [64000/69949]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.151980 

Epoch 41
-------------------------------
loss: 0.057537  [    0/69949]
loss: 0.138108  [ 6400/69949]
loss: 0.069129  [12800/69949]
loss: 0.078539  [19200/69949]
loss: 0.101660  [25600/69949]
loss: 0.096373  [32000/69949]
loss: 0.123833  [38400/69949]
loss: 0.143127  [44800/69949]
loss: 0.373186  [51200/69949]
loss: 0.195847  [57600/69949]
loss: 0.156836  [64000/69949]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.144501 

Epoch 42
-------------------------------
loss: 0.191824  [    0/69949]
loss: 0.158144  [ 6400/69949]
loss: 0.074888  [12800/69949]
loss: 0.035191  [19200/69949]
loss: 0.100082  [25600/69949]
loss: 0.045470  [32000/69949]
loss: 0.203577  [38400/69949]
loss: 0.237347  [44800/69949]
loss: 0.127864  [51200/69949]
loss: 0.130305  [57600/69949]
loss: 0.108317  [64000/69949]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.141906 

Epoch 43
-------------------------------
loss: 0.075146  [    0/69949]
loss: 0.207773  [ 6400/69949]
loss: 0.089764  [12800/69949]
loss: 0.166176  [19200/69949]
loss: 0.090479  [25600/69949]
loss: 0.168803  [32000/69949]
loss: 0.208916  [38400/69949]
loss: 0.138450  [44800/69949]
loss: 0.124443  [51200/69949]
loss: 0.162747  [57600/69949]
loss: 0.160033  [64000/69949]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.150699 

Epoch 44
-------------------------------
loss: 0.070524  [    0/69949]
loss: 0.114719  [ 6400/69949]
loss: 0.132970  [12800/69949]
loss: 0.099945  [19200/69949]
loss: 0.157346  [25600/69949]
loss: 0.176427  [32000/69949]
loss: 0.098136  [38400/69949]
loss: 0.148759  [44800/69949]
loss: 0.087960  [51200/69949]
loss: 0.041706  [57600/69949]
loss: 0.084574  [64000/69949]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.156747 

Epoch 45
-------------------------------
loss: 0.114307  [    0/69949]
loss: 1.619712  [ 6400/69949]
loss: 0.113952  [12800/69949]
loss: 0.112641  [19200/69949]
loss: 0.155779  [25600/69949]
loss: 0.188206  [32000/69949]
loss: 0.235930  [38400/69949]
loss: 0.115100  [44800/69949]
loss: 0.126284  [51200/69949]
loss: 0.093637  [57600/69949]
loss: 0.151700  [64000/69949]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.137648 

Epoch 46
-------------------------------
loss: 0.079805  [    0/69949]
loss: 0.099181  [ 6400/69949]
loss: 0.167107  [12800/69949]
loss: 0.133845  [19200/69949]
loss: 0.106255  [25600/69949]
loss: 0.103377  [32000/69949]
loss: 0.165209  [38400/69949]
loss: 0.189742  [44800/69949]
loss: 0.105249  [51200/69949]
loss: 0.233973  [57600/69949]
loss: 0.161240  [64000/69949]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.140646 

Epoch 47
-------------------------------
loss: 0.153605  [    0/69949]
loss: 0.160329  [ 6400/69949]
loss: 0.339931  [12800/69949]
loss: 0.116869  [19200/69949]
loss: 0.074419  [25600/69949]
loss: 0.112642  [32000/69949]
loss: 0.180857  [38400/69949]
loss: 0.114181  [44800/69949]
loss: 0.131304  [51200/69949]
loss: 0.124430  [57600/69949]
loss: 0.148743  [64000/69949]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.139559 

Epoch 48
-------------------------------
loss: 0.068940  [    0/69949]
loss: 0.123900  [ 6400/69949]
loss: 0.131239  [12800/69949]
loss: 0.125637  [19200/69949]
loss: 0.167265  [25600/69949]
loss: 0.102047  [32000/69949]
loss: 0.126757  [38400/69949]
loss: 0.023290  [44800/69949]
loss: 0.076012  [51200/69949]
loss: 0.060474  [57600/69949]
loss: 0.189791  [64000/69949]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.142487 

Epoch 49
-------------------------------
loss: 0.076516  [    0/69949]
loss: 0.150179  [ 6400/69949]
loss: 0.186804  [12800/69949]
loss: 0.147949  [19200/69949]
loss: 0.149998  [25600/69949]
loss: 0.064098  [32000/69949]
loss: 0.078616  [38400/69949]
loss: 0.076275  [44800/69949]
loss: 0.098572  [51200/69949]
loss: 0.168612  [57600/69949]
loss: 0.158348  [64000/69949]
loss: 0.061601  [12800/69641]
loss: 0.048849  [19200/69641]
loss: 0.288436  [25600/69641]
loss: 0.117902  [32000/69641]
loss: 0.051481  [38400/69641]
loss: 0.074997  [44800/69641]
loss: 0.178613  [51200/69641]
loss: 0.153096  [57600/69641]
loss: 0.047048  [64000/69641]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.122625 

Epoch 35
-------------------------------
loss: 0.030846  [    0/69641]
loss: 0.184429  [ 6400/69641]
loss: 0.035740  [12800/69641]
loss: 0.185137  [19200/69641]
loss: 0.111903  [25600/69641]
loss: 0.043471  [32000/69641]
loss: 0.078940  [38400/69641]
loss: 0.159865  [44800/69641]
loss: 0.134732  [51200/69641]
loss: 0.089700  [57600/69641]
loss: 0.139298  [64000/69641]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.119254 

Epoch 36
-------------------------------
loss: 0.075733  [    0/69641]
loss: 0.013341  [ 6400/69641]
loss: 0.216998  [12800/69641]
loss: 0.111108  [19200/69641]
loss: 0.031316  [25600/69641]
loss: 0.047252  [32000/69641]
loss: 0.009164  [38400/69641]
loss: 0.217353  [44800/69641]
loss: 0.069826  [51200/69641]
loss: 0.152241  [57600/69641]
loss: 0.108578  [64000/69641]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.119982 

Epoch 37
-------------------------------
loss: 0.065212  [    0/69641]
loss: 0.035597  [ 6400/69641]
loss: 0.096107  [12800/69641]
loss: 0.080386  [19200/69641]
loss: 0.152185  [25600/69641]
loss: 0.077739  [32000/69641]
loss: 0.052090  [38400/69641]
loss: 0.110433  [44800/69641]
loss: 0.079275  [51200/69641]
loss: 0.193973  [57600/69641]
loss: 0.120998  [64000/69641]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.198044 

Epoch 38
-------------------------------
loss: 0.094597  [    0/69641]
loss: 0.044824  [ 6400/69641]
loss: 0.077102  [12800/69641]
loss: 0.063664  [19200/69641]
loss: 0.033769  [25600/69641]
loss: 0.164306  [32000/69641]
loss: 0.301268  [38400/69641]
loss: 0.059746  [44800/69641]
loss: 0.174305  [51200/69641]
loss: 0.045319  [57600/69641]
loss: 0.110405  [64000/69641]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.107556 

Epoch 39
-------------------------------
loss: 0.050636  [    0/69641]
loss: 0.067337  [ 6400/69641]
loss: 0.191386  [12800/69641]
loss: 0.116982  [19200/69641]
loss: 0.089582  [25600/69641]
loss: 0.169447  [32000/69641]
loss: 0.075512  [38400/69641]
loss: 0.076899  [44800/69641]
loss: 0.062578  [51200/69641]
loss: 0.007692  [57600/69641]
loss: 0.106417  [64000/69641]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.106735 

Epoch 40
-------------------------------
loss: 0.020919  [    0/69641]
loss: 0.052587  [ 6400/69641]
loss: 0.116302  [12800/69641]
loss: 0.173816  [19200/69641]
loss: 0.177502  [25600/69641]
loss: 0.153575  [32000/69641]
loss: 0.092020  [38400/69641]
loss: 0.080850  [44800/69641]
loss: 0.065542  [51200/69641]
loss: 0.040091  [57600/69641]
loss: 0.050495  [64000/69641]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.109849 

Epoch 41
-------------------------------
loss: 0.024143  [    0/69641]
loss: 0.133581  [ 6400/69641]
loss: 0.089337  [12800/69641]
loss: 0.186369  [19200/69641]
loss: 0.064996  [25600/69641]
loss: 0.047634  [32000/69641]
loss: 0.117256  [38400/69641]
loss: 0.093048  [44800/69641]
loss: 0.096583  [51200/69641]
loss: 0.078230  [57600/69641]
loss: 0.084823  [64000/69641]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.116870 

Epoch 42
-------------------------------
loss: 0.115515  [    0/69641]
loss: 0.108039  [ 6400/69641]
loss: 0.117236  [12800/69641]
loss: 0.082962  [19200/69641]
loss: 0.151821  [25600/69641]
loss: 0.117711  [32000/69641]
loss: 0.053928  [38400/69641]
loss: 0.074677  [44800/69641]
loss: 0.142182  [51200/69641]
loss: 0.118970  [57600/69641]
loss: 0.067259  [64000/69641]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.139149 

Epoch 43
-------------------------------
loss: 0.037370  [    0/69641]
loss: 0.052492  [ 6400/69641]
loss: 0.151260  [12800/69641]
loss: 0.086856  [19200/69641]
loss: 0.060042  [25600/69641]
loss: 0.104092  [32000/69641]
loss: 0.214790  [38400/69641]
loss: 0.137006  [44800/69641]
loss: 0.162228  [51200/69641]
loss: 0.023348  [57600/69641]
loss: 0.087370  [64000/69641]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.113964 

Epoch 44
-------------------------------
loss: 0.185602  [    0/69641]
loss: 0.176431  [ 6400/69641]
loss: 0.064684  [12800/69641]
loss: 0.034511  [19200/69641]
loss: 0.097692  [25600/69641]
loss: 0.109592  [32000/69641]
loss: 0.124458  [38400/69641]
loss: 0.081538  [44800/69641]
loss: 0.066183  [51200/69641]
loss: 0.090415  [57600/69641]
loss: 0.153238  [64000/69641]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.110917 

Epoch 45
-------------------------------
loss: 0.155070  [    0/69641]
loss: 0.035486  [ 6400/69641]
loss: 0.139218  [12800/69641]
loss: 0.086383  [19200/69641]
loss: 0.062994  [25600/69641]
loss: 0.201588  [32000/69641]
loss: 0.122424  [38400/69641]
loss: 0.082485  [44800/69641]
loss: 0.071200  [51200/69641]
loss: 0.045147  [57600/69641]
loss: 0.058290  [64000/69641]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.141571 

Epoch 46
-------------------------------
loss: 0.097220  [    0/69641]
loss: 0.059788  [ 6400/69641]
loss: 0.053722  [12800/69641]
loss: 0.032578  [19200/69641]
loss: 0.036419  [25600/69641]
loss: 0.072034  [32000/69641]
loss: 0.079852  [38400/69641]
loss: 0.104889  [44800/69641]
loss: 0.090375  [51200/69641]
loss: 0.063646  [57600/69641]
loss: 0.029262  [64000/69641]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.124504 

Epoch 47
-------------------------------
loss: 0.061574  [    0/69641]
loss: 0.060609  [ 6400/69641]
loss: 0.082317  [12800/69641]
loss: 0.124080  [19200/69641]
loss: 0.231167  [25600/69641]
loss: 0.096320  [32000/69641]
loss: 0.070719  [38400/69641]
loss: 0.086273  [44800/69641]
loss: 0.073596  [51200/69641]
loss: 0.034133  [57600/69641]
loss: 0.081325  [64000/69641]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.118924 

Epoch 48
-------------------------------
loss: 0.191284  [    0/69641]
loss: 0.097780  [ 6400/69641]
loss: 0.141913  [12800/69641]
loss: 0.030715  [19200/69641]
loss: 0.070651  [25600/69641]
loss: 0.081149  [32000/69641]
loss: 0.174833  [38400/69641]
loss: 0.058952  [44800/69641]
loss: 0.101831  [51200/69641]
loss: 0.105176  [57600/69641]
loss: 0.047603  [64000/69641]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.134137 

Epoch 49
-------------------------------
loss: 0.126392  [    0/69641]
loss: 0.088345  [ 6400/69641]
loss: 0.047609  [12800/69641]
loss: 0.086903  [19200/69641]
loss: 0.112445  [25600/69641]
loss: 0.169682  [32000/69641]
loss: 0.054111  [38400/69641]
loss: 0.155041  [44800/69641]
loss: 0.078032  [51200/69641]
loss: 0.059484  [57600/69641]
loss: 0.032211  [64000/69641]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.129072 

Epoch 50
-------------------------------
loss: 0.112835  [    0/69641]
loss: 0.060559  [ 6400/69641]
loss: 0.110436  [12800/69641]
loss: 0.021340  [19200/69641]
loss: 0.074751  [25600/69641]
loss: 0.102587  [32000/69641]
loss: 0.128600  [38400/69641]
loss: 0.147803  [44800/69641]
loss: 0.045880  [51200/69641]
loss: 0.188808  [57600/69641]
loss: 0.056973  [64000/69641]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.109441 

Epoch 1
-------------------------------
loss: 0.673034  [    0/72195]
loss: 0.191091  [ 6400/72195]
loss: 0.093872  [12800/72195]
loss: 0.226908  [19200/72195]
loss: 0.194578  [25600/72195]
loss: 0.124910  [32000/72195]
loss: 0.167721  [38400/72195]
loss: 0.067235  [44800/72195]
loss: 0.051187  [51200/72195]
loss: 0.042820  [57600/72195]
loss: 0.201110  [64000/72195]
loss: 0.140235  [70400/72195]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.089086 

Epoch 2
-------------------------------
loss: 0.021018  [    0/72195]
loss: 0.101990  [ 6400/72195]
loss: 0.176315  [12800/72195]
loss: 0.025286  [19200/72195]
loss: 0.097339  [25600/72195]
loss: 0.135798  [32000/72195]
loss: 0.037912  [38400/72195]
loss: 0.050612  [44800/72195]
loss: 0.049058  [51200/72195]
loss: 0.071402  [57600/72195]
loss: 0.057159  [64000/72195]
loss: 0.034537  [70400/72195]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076579 

Epoch 3
-------------------------------
loss: 0.027940  [    0/72195]
loss: 0.005199  [ 6400/72195]
loss: 0.113925  [12800/72195]
loss: 0.055628  [19200/72195]
loss: 0.116992  [25600/72195]
2022/09/20 18:25:23 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 18:25:49 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 18:25:52 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.187007  [19200/70480]
loss: 0.145896  [25600/70480]
loss: 0.063224  [32000/70480]
loss: 0.098696  [38400/70480]
loss: 0.127580  [44800/70480]
loss: 0.185623  [51200/70480]
loss: 1.756621  [57600/70480]
loss: 0.187986  [64000/70480]
loss: 0.099263  [70400/70480]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.201945 

Epoch 18
-------------------------------
loss: 0.415884  [    0/70480]
loss: 0.112337  [ 6400/70480]
loss: 1.682295  [12800/70480]
loss: 0.067612  [19200/70480]
loss: 0.120200  [25600/70480]
loss: 0.292912  [32000/70480]
loss: 0.103563  [38400/70480]
loss: 0.213910  [44800/70480]
loss: 0.102461  [51200/70480]
loss: 0.098162  [57600/70480]
loss: 0.114680  [64000/70480]
loss: 0.122774  [70400/70480]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.200034 

Epoch 19
-------------------------------
loss: 0.191797  [    0/70480]
loss: 0.192482  [ 6400/70480]
loss: 0.124624  [12800/70480]
loss: 0.129566  [19200/70480]
loss: 0.101380  [25600/70480]
loss: 0.073383  [32000/70480]
loss: 0.112403  [38400/70480]
loss: 0.174867  [44800/70480]
loss: 0.187248  [51200/70480]
loss: 0.179197  [57600/70480]
loss: 0.095080  [64000/70480]
loss: 0.126256  [70400/70480]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.176458 

Epoch 20
-------------------------------
loss: 0.163855  [    0/70480]
loss: 0.128631  [ 6400/70480]
loss: 0.168984  [12800/70480]
loss: 0.104453  [19200/70480]
loss: 0.161052  [25600/70480]
loss: 0.105786  [32000/70480]
loss: 0.098871  [38400/70480]
loss: 0.253844  [44800/70480]
loss: 0.201511  [51200/70480]
loss: 0.142140  [57600/70480]
loss: 0.195124  [64000/70480]
loss: 0.159372  [70400/70480]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.185438 

Epoch 21
-------------------------------
loss: 0.188726  [    0/70480]
loss: 0.095525  [ 6400/70480]
loss: 0.155095  [12800/70480]
loss: 0.185971  [19200/70480]
loss: 0.127893  [25600/70480]
loss: 0.201720  [32000/70480]
loss: 0.221663  [38400/70480]
loss: 1.620432  [44800/70480]
loss: 0.142512  [51200/70480]
loss: 0.173555  [57600/70480]
loss: 0.167007  [64000/70480]
loss: 0.148244  [70400/70480]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.228770 

Epoch 22
-------------------------------
loss: 0.256924  [    0/70480]
loss: 0.337230  [ 6400/70480]
loss: 0.123703  [12800/70480]
loss: 0.111130  [19200/70480]
loss: 0.191746  [25600/70480]
loss: 0.142733  [32000/70480]
loss: 0.182404  [38400/70480]
loss: 0.112406  [44800/70480]
loss: 0.151433  [51200/70480]
loss: 0.085803  [57600/70480]
loss: 0.124115  [64000/70480]
loss: 0.133906  [70400/70480]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.185984 

Epoch 23
-------------------------------
loss: 0.067535  [    0/70480]
loss: 0.176868  [ 6400/70480]
loss: 0.087249  [12800/70480]
loss: 0.180859  [19200/70480]
loss: 0.178198  [25600/70480]
loss: 0.279826  [32000/70480]
loss: 0.132389  [38400/70480]
loss: 0.247875  [44800/70480]
loss: 0.283063  [51200/70480]
loss: 0.208752  [57600/70480]
loss: 0.101201  [64000/70480]
loss: 0.166791  [70400/70480]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.183962 

Epoch 24
-------------------------------
loss: 0.272467  [    0/70480]
loss: 0.182618  [ 6400/70480]
loss: 0.202271  [12800/70480]
loss: 0.145538  [19200/70480]
loss: 0.213310  [25600/70480]
loss: 0.256719  [32000/70480]
loss: 0.121326  [38400/70480]
loss: 0.106850  [44800/70480]
loss: 1.623846  [51200/70480]
loss: 0.198216  [57600/70480]
loss: 0.189016  [64000/70480]
loss: 0.231540  [70400/70480]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.176993 

Epoch 25
-------------------------------
loss: 0.118316  [    0/70480]
loss: 0.078975  [ 6400/70480]
loss: 0.077049  [12800/70480]
loss: 0.114798  [19200/70480]
loss: 0.046092  [25600/70480]
loss: 0.105648  [32000/70480]
loss: 0.115493  [38400/70480]
loss: 0.095916  [44800/70480]
loss: 0.134671  [51200/70480]
loss: 0.109889  [57600/70480]
loss: 0.166676  [64000/70480]
loss: 0.093421  [70400/70480]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.184022 

Epoch 26
-------------------------------
loss: 0.242256  [    0/70480]
loss: 0.130217  [ 6400/70480]
loss: 0.189094  [12800/70480]
loss: 0.088574  [19200/70480]
loss: 0.052436  [25600/70480]
loss: 0.138867  [32000/70480]
loss: 0.051659  [38400/70480]
loss: 0.067620  [44800/70480]
loss: 0.199181  [51200/70480]
loss: 0.078321  [57600/70480]
loss: 0.135162  [64000/70480]
loss: 0.115912  [70400/70480]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.198786 

Epoch 27
-------------------------------
loss: 0.156596  [    0/70480]
loss: 0.229844  [ 6400/70480]
loss: 0.067970  [12800/70480]
loss: 0.290694  [19200/70480]
loss: 0.173453  [25600/70480]
loss: 0.304351  [32000/70480]
loss: 0.138741  [38400/70480]
loss: 0.131916  [44800/70480]
loss: 0.106376  [51200/70480]
loss: 0.080539  [57600/70480]
loss: 1.677303  [64000/70480]
loss: 0.114258  [70400/70480]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.176553 

Epoch 28
-------------------------------
loss: 0.109235  [    0/70480]
loss: 0.108044  [ 6400/70480]
loss: 0.268949  [12800/70480]
loss: 0.189726  [19200/70480]
loss: 0.138690  [25600/70480]
loss: 0.194421  [32000/70480]
loss: 0.069976  [38400/70480]
loss: 0.150127  [44800/70480]
loss: 0.225353  [51200/70480]
loss: 0.127568  [57600/70480]
loss: 0.262657  [64000/70480]
loss: 0.184844  [70400/70480]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.189102 

Epoch 29
-------------------------------
loss: 0.203109  [    0/70480]
loss: 0.087575  [ 6400/70480]
loss: 0.142577  [12800/70480]
loss: 0.122127  [19200/70480]
loss: 0.154129  [25600/70480]
loss: 0.311977  [32000/70480]
loss: 0.236718  [38400/70480]
loss: 0.106989  [44800/70480]
loss: 0.103344  [51200/70480]
loss: 0.153650  [57600/70480]
loss: 0.310792  [64000/70480]
loss: 0.094320  [70400/70480]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.223679 

Epoch 30
-------------------------------
loss: 0.107370  [    0/70480]
loss: 0.128422  [ 6400/70480]
loss: 0.099227  [12800/70480]
loss: 0.283691  [19200/70480]
loss: 0.201528  [25600/70480]
loss: 0.095173  [32000/70480]
loss: 0.138135  [38400/70480]
loss: 0.157558  [44800/70480]
loss: 0.146534  [51200/70480]
loss: 0.058212  [57600/70480]
loss: 0.142932  [64000/70480]
loss: 0.206153  [70400/70480]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.250904 

Epoch 31
-------------------------------
loss: 0.086180  [    0/70480]
loss: 0.196032  [ 6400/70480]
loss: 0.193916  [12800/70480]
loss: 0.228620  [19200/70480]
loss: 0.197100  [25600/70480]
loss: 0.121673  [32000/70480]
loss: 0.155757  [38400/70480]
loss: 0.152740  [44800/70480]
loss: 0.120268  [51200/70480]
loss: 0.120858  [57600/70480]
loss: 0.115474  [64000/70480]
loss: 0.181397  [70400/70480]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.173637 

Epoch 32
-------------------------------
loss: 0.172816  [    0/70480]
loss: 0.070756  [ 6400/70480]
loss: 0.229777  [12800/70480]
loss: 0.208238  [19200/70480]
loss: 0.254934  [25600/70480]
loss: 0.056271  [32000/70480]
loss: 0.178341  [38400/70480]
loss: 0.149618  [44800/70480]
loss: 0.145127  [51200/70480]
loss: 0.389936  [57600/70480]
loss: 1.756218  [64000/70480]
loss: 0.078522  [70400/70480]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.178687 

Epoch 33
-------------------------------
loss: 0.121902  [    0/70480]
loss: 0.123017  [ 6400/70480]
loss: 0.165914  [12800/70480]
loss: 0.210948  [19200/70480]
loss: 0.110219  [25600/70480]
loss: 0.183078  [32000/70480]
loss: 0.106845  [38400/70480]
loss: 0.126506  [44800/70480]
loss: 0.112860  [51200/70480]
loss: 0.192836  [57600/70480]
loss: 0.099120  [64000/70480]
loss: 0.093061  [70400/70480]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.181707 

Epoch 34
-------------------------------
loss: 0.171218  [    0/70480]
loss: 0.085647  [ 6400/70480]
loss: 0.127017  [12800/70480]
loss: 0.124562  [19200/70480]
loss: 0.168361  [25600/70480]
loss: 0.158082  [32000/70480]
loss: 0.104276  [38400/70480]
loss: 0.136195  [44800/70480]
loss: 0.111281  [51200/70480]
loss: 0.125651  [57600/70480]
loss: 0.196516  [64000/70480]
loss: 0.151354  [70400/70480]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.175472 

Epoch 35
-------------------------------
loss: 0.073102  [    0/70480]
loss: 0.117481  [ 6400/70480]
loss: 0.199213  [12800/70480]
loss: 0.178024  [19200/70480]
2022/09/20 18:27:09 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 18:27:53 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.183749 

Epoch 25
-------------------------------
loss: 0.051691  [    0/70533]
loss: 0.071073  [ 6400/70533]
loss: 0.171947  [12800/70533]
loss: 0.236572  [19200/70533]
loss: 0.213396  [25600/70533]
loss: 0.113247  [32000/70533]
loss: 0.160374  [38400/70533]
loss: 0.267544  [44800/70533]
loss: 0.135173  [51200/70533]
loss: 0.068014  [57600/70533]
loss: 0.104863  [64000/70533]
loss: 0.082521  [70400/70533]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.185027 

Epoch 26
-------------------------------
loss: 0.056885  [    0/70533]
loss: 0.097685  [ 6400/70533]
loss: 0.169307  [12800/70533]
loss: 0.254790  [19200/70533]
loss: 0.089761  [25600/70533]
loss: 0.101312  [32000/70533]
loss: 0.071367  [38400/70533]
loss: 0.172168  [44800/70533]
loss: 0.106143  [51200/70533]
loss: 0.150490  [57600/70533]
loss: 0.157323  [64000/70533]
loss: 0.131446  [70400/70533]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.183222 

Epoch 27
-------------------------------
loss: 0.111037  [    0/70533]
loss: 0.056657  [ 6400/70533]
loss: 0.079796  [12800/70533]
loss: 0.095082  [19200/70533]
loss: 0.139868  [25600/70533]
loss: 0.085713  [32000/70533]
loss: 0.072007  [38400/70533]
loss: 0.205228  [44800/70533]
loss: 0.122613  [51200/70533]
loss: 0.152141  [57600/70533]
loss: 0.181923  [64000/70533]
loss: 0.053246  [70400/70533]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.187098 

Epoch 28
-------------------------------
loss: 0.168323  [    0/70533]
loss: 0.160277  [ 6400/70533]
loss: 0.041633  [12800/70533]
loss: 0.075697  [19200/70533]
loss: 0.147160  [25600/70533]
loss: 0.121279  [32000/70533]
loss: 0.199147  [38400/70533]
loss: 0.113046  [44800/70533]
loss: 0.196732  [51200/70533]
loss: 0.131629  [57600/70533]
loss: 0.102147  [64000/70533]
loss: 0.178270  [70400/70533]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.195162 

Epoch 29
-------------------------------
loss: 0.139494  [    0/70533]
loss: 0.141498  [ 6400/70533]
loss: 0.114398  [12800/70533]
loss: 0.095715  [19200/70533]
loss: 0.128809  [25600/70533]
loss: 0.188306  [32000/70533]
loss: 0.195438  [38400/70533]
loss: 0.088435  [44800/70533]
loss: 0.184038  [51200/70533]
loss: 0.151049  [57600/70533]
loss: 0.102492  [64000/70533]
loss: 0.198501  [70400/70533]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.186244 

Epoch 30
-------------------------------
loss: 0.074547  [    0/70533]
loss: 0.103198  [ 6400/70533]
loss: 0.119014  [12800/70533]
loss: 0.122488  [19200/70533]
loss: 0.145812  [25600/70533]
loss: 0.156353  [32000/70533]
loss: 0.112468  [38400/70533]
loss: 0.197360  [44800/70533]
loss: 0.116651  [51200/70533]
loss: 0.081366  [57600/70533]
loss: 0.130463  [64000/70533]
loss: 0.164522  [70400/70533]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.206885 

Epoch 31
-------------------------------
loss: 0.171723  [    0/70533]
loss: 0.287540  [ 6400/70533]
loss: 0.181441  [12800/70533]
loss: 0.118811  [19200/70533]
loss: 0.016842  [25600/70533]
loss: 0.186710  [32000/70533]
loss: 0.096552  [38400/70533]
loss: 0.100592  [44800/70533]
loss: 0.165689  [51200/70533]
loss: 0.082001  [57600/70533]
loss: 0.106915  [64000/70533]
loss: 0.090063  [70400/70533]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.233479 

Epoch 32
-------------------------------
loss: 0.111724  [    0/70533]
loss: 0.258714  [ 6400/70533]
loss: 0.043495  [12800/70533]
loss: 0.076354  [19200/70533]
loss: 0.053243  [25600/70533]
loss: 0.101374  [32000/70533]
loss: 0.131638  [38400/70533]
loss: 0.195088  [44800/70533]
loss: 0.177608  [51200/70533]
loss: 1.758033  [57600/70533]
loss: 0.110064  [64000/70533]
loss: 0.238075  [70400/70533]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.181034 

Epoch 33
-------------------------------
loss: 0.083273  [    0/70533]
loss: 0.030330  [ 6400/70533]
loss: 0.137612  [12800/70533]
loss: 0.078354  [19200/70533]
loss: 0.187849  [25600/70533]
loss: 0.159425  [32000/70533]
loss: 0.077466  [38400/70533]
loss: 0.075208  [44800/70533]
loss: 0.102630  [51200/70533]
loss: 0.116142  [57600/70533]
loss: 0.074840  [64000/70533]
loss: 0.042781  [70400/70533]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.156658 

Epoch 34
-------------------------------
loss: 0.058929  [    0/70533]
loss: 0.293895  [ 6400/70533]
loss: 0.134778  [12800/70533]
loss: 0.089364  [19200/70533]
loss: 0.133027  [25600/70533]
loss: 0.083414  [32000/70533]
loss: 0.088661  [38400/70533]
loss: 0.102537  [44800/70533]
loss: 0.180089  [51200/70533]
loss: 0.147948  [57600/70533]
loss: 0.061161  [64000/70533]
loss: 0.188267  [70400/70533]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.189875 

Epoch 35
-------------------------------
loss: 0.160439  [    0/70533]
loss: 0.081605  [ 6400/70533]
loss: 0.161313  [12800/70533]
loss: 0.133556  [19200/70533]
loss: 0.165566  [25600/70533]
loss: 0.049281  [32000/70533]
loss: 0.094493  [38400/70533]
loss: 0.130340  [44800/70533]
loss: 0.083035  [51200/70533]
loss: 0.179425  [57600/70533]
loss: 0.240666  [64000/70533]
loss: 0.085291  [70400/70533]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.158838 

Epoch 36
-------------------------------
loss: 0.040898  [    0/70533]
loss: 0.193010  [ 6400/70533]
loss: 0.169431  [12800/70533]
loss: 0.157029  [19200/70533]
loss: 0.180444  [25600/70533]
loss: 0.099475  [32000/70533]
loss: 0.053660  [38400/70533]
loss: 0.130638  [44800/70533]
loss: 0.054748  [51200/70533]
loss: 0.043014  [57600/70533]
loss: 0.103940  [64000/70533]
loss: 0.181010  [70400/70533]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.183915 

Epoch 37
-------------------------------
loss: 0.107686  [    0/70533]
loss: 0.135571  [ 6400/70533]
loss: 0.150931  [12800/70533]
loss: 0.175162  [19200/70533]
loss: 0.163779  [25600/70533]
loss: 0.093382  [32000/70533]
loss: 0.109243  [38400/70533]
loss: 0.202011  [44800/70533]
loss: 0.184634  [51200/70533]
loss: 0.077900  [57600/70533]
loss: 0.039118  [64000/70533]
loss: 0.136074  [70400/70533]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.185746 

Epoch 38
-------------------------------
loss: 0.211640  [    0/70533]
loss: 0.160392  [ 6400/70533]
loss: 0.126985  [12800/70533]
loss: 0.139292  [19200/70533]
loss: 0.082171  [25600/70533]
loss: 0.077518  [32000/70533]
loss: 0.143042  [38400/70533]
loss: 0.057017  [44800/70533]
loss: 0.049827  [51200/70533]
loss: 0.262048  [57600/70533]
loss: 0.137515  [64000/70533]
loss: 0.080475  [70400/70533]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.183625 

Epoch 39
-------------------------------
loss: 0.130468  [    0/70533]
loss: 0.171692  [ 6400/70533]
loss: 0.114505  [12800/70533]
loss: 0.110813  [19200/70533]
loss: 0.190641  [25600/70533]
loss: 1.639115  [32000/70533]
loss: 0.121279  [38400/70533]
loss: 0.096918  [44800/70533]
loss: 1.647100  [51200/70533]
loss: 0.181850  [57600/70533]
loss: 0.259070  [64000/70533]
loss: 0.142182  [70400/70533]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.175478 

Epoch 40
-------------------------------
loss: 0.234687  [    0/70533]
loss: 0.224015  [ 6400/70533]
loss: 0.101231  [12800/70533]
loss: 0.144473  [19200/70533]
loss: 0.147047  [25600/70533]
loss: 0.142004  [32000/70533]
loss: 0.183286  [38400/70533]
loss: 0.079121  [44800/70533]
loss: 0.068604  [51200/70533]
loss: 0.127366  [57600/70533]
loss: 0.081343  [64000/70533]
loss: 0.166803  [70400/70533]
Test Error: 
 Accuracy: 91.1%, Avg loss: 0.550474 

Epoch 41
-------------------------------
loss: 0.344812  [    0/70533]
loss: 0.103832  [ 6400/70533]
loss: 0.105199  [12800/70533]
loss: 0.083746  [19200/70533]
loss: 0.084846  [25600/70533]
loss: 0.148131  [32000/70533]
loss: 0.107209  [38400/70533]
loss: 0.166242  [44800/70533]
loss: 0.148210  [51200/70533]
loss: 0.107290  [57600/70533]
loss: 0.103917  [64000/70533]
loss: 0.083082  [70400/70533]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.218097 

Epoch 42
-------------------------------
loss: 1.706443  [    0/70533]
loss: 0.061384  [ 6400/70533]
loss: 0.097547  [12800/70533]
loss: 0.090674  [19200/70533]
loss: 0.070889  [25600/70533]
loss: 0.028829  [32000/70533]
loss: 0.256594  [38400/70533]
loss: 0.149565  [44800/70533]
loss: 0.137429  [51200/70533]
loss: 0.065480  [57600/70533]
loss: 0.121886  [64000/70533]
loss: 0.027450  [70400/70533]
2022/09/20 18:29:22 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.135406  [32000/70487]
loss: 0.216537  [38400/70487]
loss: 0.144332  [44800/70487]
loss: 0.167554  [51200/70487]
loss: 0.189471  [57600/70487]
loss: 0.141501  [64000/70487]
loss: 0.092729  [70400/70487]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.187296 

Epoch 44
-------------------------------
loss: 0.121115  [    0/70487]
loss: 0.155573  [ 6400/70487]
loss: 0.088952  [12800/70487]
loss: 0.231061  [19200/70487]
loss: 0.121159  [25600/70487]
loss: 0.070013  [32000/70487]
loss: 0.189917  [38400/70487]
loss: 0.186684  [44800/70487]
loss: 0.162108  [51200/70487]
loss: 0.121957  [57600/70487]
loss: 0.206808  [64000/70487]
loss: 0.143376  [70400/70487]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.207987 

Epoch 45
-------------------------------
loss: 0.112968  [    0/70487]
loss: 0.148215  [ 6400/70487]
loss: 0.221625  [12800/70487]
loss: 0.117335  [19200/70487]
loss: 0.245331  [25600/70487]
loss: 0.228743  [32000/70487]
loss: 0.239089  [38400/70487]
loss: 0.134235  [44800/70487]
loss: 0.056543  [51200/70487]
loss: 0.110218  [57600/70487]
loss: 0.201631  [64000/70487]
loss: 0.146643  [70400/70487]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.202084 

Epoch 46
-------------------------------
loss: 0.076244  [    0/70487]
loss: 0.184095  [ 6400/70487]
loss: 0.249646  [12800/70487]
loss: 0.118857  [19200/70487]
loss: 0.226651  [25600/70487]
loss: 0.137504  [32000/70487]
loss: 0.152749  [38400/70487]
loss: 0.158942  [44800/70487]
loss: 0.161162  [51200/70487]
loss: 0.165085  [57600/70487]
loss: 0.222561  [64000/70487]
loss: 0.154428  [70400/70487]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.193707 

Epoch 47
-------------------------------
loss: 0.122148  [    0/70487]
loss: 0.146330  [ 6400/70487]
loss: 0.150388  [12800/70487]
loss: 1.750161  [19200/70487]
loss: 0.124335  [25600/70487]
loss: 0.074699  [32000/70487]
loss: 0.279186  [38400/70487]
loss: 0.041022  [44800/70487]
loss: 0.234605  [51200/70487]
loss: 0.241827  [57600/70487]
loss: 0.197716  [64000/70487]
loss: 0.157823  [70400/70487]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.214579 

Epoch 48
-------------------------------
loss: 1.857550  [    0/70487]
loss: 0.141458  [ 6400/70487]
loss: 0.169786  [12800/70487]
loss: 0.207033  [19200/70487]
loss: 0.120781  [25600/70487]
loss: 0.026236  [32000/70487]
loss: 0.184885  [38400/70487]
loss: 0.194219  [44800/70487]
loss: 0.163378  [51200/70487]
loss: 0.216778  [57600/70487]
loss: 0.101012  [64000/70487]
loss: 0.169487  [70400/70487]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.183194 

Epoch 49
-------------------------------
loss: 0.162715  [    0/70487]
loss: 0.126709  [ 6400/70487]
loss: 0.109485  [12800/70487]
loss: 0.221222  [19200/70487]
loss: 0.211414  [25600/70487]
loss: 0.048245  [32000/70487]
loss: 0.169572  [38400/70487]
loss: 0.196821  [44800/70487]
loss: 0.180120  [51200/70487]
loss: 0.091288  [57600/70487]
loss: 0.141675  [64000/70487]
loss: 0.120995  [70400/70487]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.195220 

Epoch 50
-------------------------------
loss: 0.084622  [    0/70487]
loss: 0.240338  [ 6400/70487]
loss: 0.207896  [12800/70487]
loss: 0.102806  [19200/70487]
loss: 0.272322  [25600/70487]
loss: 0.135169  [32000/70487]
loss: 1.710153  [38400/70487]
loss: 0.227909  [44800/70487]
loss: 0.124102  [51200/70487]
loss: 0.083284  [57600/70487]
loss: 0.186307  [64000/70487]
loss: 0.290375  [70400/70487]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.215315 

Epoch 1
-------------------------------
loss: 0.647884  [    0/70068]
loss: 0.386310  [ 6400/70068]
loss: 0.182905  [12800/70068]
loss: 0.305870  [19200/70068]
loss: 0.244146  [25600/70068]
loss: 0.204237  [32000/70068]
loss: 0.179491  [38400/70068]
loss: 0.313751  [44800/70068]
loss: 0.240264  [51200/70068]
loss: 0.235106  [57600/70068]
loss: 0.240932  [64000/70068]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.250340 

Epoch 2
-------------------------------
loss: 0.158110  [    0/70068]
loss: 0.191947  [ 6400/70068]
loss: 0.316285  [12800/70068]
loss: 0.240190  [19200/70068]
loss: 0.188567  [25600/70068]
loss: 0.188002  [32000/70068]
loss: 0.211169  [38400/70068]
loss: 0.231754  [44800/70068]
loss: 0.073815  [51200/70068]
loss: 0.304228  [57600/70068]
loss: 0.172898  [64000/70068]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.222740 

Epoch 3
-------------------------------
loss: 0.160112  [    0/70068]
loss: 0.156508  [ 6400/70068]
loss: 0.184826  [12800/70068]
loss: 0.170367  [19200/70068]
loss: 0.180438  [25600/70068]
loss: 0.228132  [32000/70068]
loss: 0.267122  [38400/70068]
loss: 0.185485  [44800/70068]
loss: 0.150455  [51200/70068]
loss: 0.228301  [57600/70068]
loss: 0.174937  [64000/70068]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.205662 

Epoch 4
-------------------------------
loss: 0.084698  [    0/70068]
loss: 1.796041  [ 6400/70068]
loss: 0.167113  [12800/70068]
loss: 0.166279  [19200/70068]
loss: 0.175034  [25600/70068]
loss: 0.191175  [32000/70068]
loss: 0.154254  [38400/70068]
loss: 0.067747  [44800/70068]
loss: 0.114417  [51200/70068]
loss: 0.212681  [57600/70068]
loss: 0.137556  [64000/70068]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.210458 

Epoch 5
-------------------------------
loss: 0.219657  [    0/70068]
loss: 0.118895  [ 6400/70068]
loss: 0.306190  [12800/70068]
loss: 0.206681  [19200/70068]
loss: 0.215517  [25600/70068]
loss: 0.182813  [32000/70068]
loss: 0.123512  [38400/70068]
loss: 0.220960  [44800/70068]
loss: 0.089838  [51200/70068]
loss: 0.179903  [57600/70068]
loss: 0.128158  [64000/70068]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.198933 

Epoch 6
-------------------------------
loss: 0.126350  [    0/70068]
loss: 0.129189  [ 6400/70068]
loss: 0.237745  [12800/70068]
loss: 0.141839  [19200/70068]
loss: 0.171293  [25600/70068]
loss: 0.302413  [32000/70068]
loss: 0.135255  [38400/70068]
loss: 0.251691  [44800/70068]
loss: 0.084019  [51200/70068]
loss: 0.267149  [57600/70068]
loss: 0.273111  [64000/70068]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.177640 

Epoch 7
-------------------------------
loss: 0.321623  [    0/70068]
loss: 0.172654  [ 6400/70068]
loss: 0.223383  [12800/70068]
loss: 0.273031  [19200/70068]
loss: 0.147248  [25600/70068]
loss: 0.196674  [32000/70068]
loss: 0.221572  [38400/70068]
loss: 0.114809  [44800/70068]
loss: 0.169490  [51200/70068]
loss: 0.147558  [57600/70068]
loss: 0.190772  [64000/70068]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.177374 

Epoch 8
-------------------------------
loss: 0.090717  [    0/70068]
loss: 0.203864  [ 6400/70068]
loss: 0.130664  [12800/70068]
loss: 0.072473  [19200/70068]
loss: 0.115323  [25600/70068]
loss: 0.216379  [32000/70068]
loss: 0.167708  [38400/70068]
loss: 0.087062  [44800/70068]
loss: 0.115865  [51200/70068]
loss: 0.119686  [57600/70068]
loss: 0.206520  [64000/70068]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.183539 

Epoch 9
-------------------------------
loss: 0.170405  [    0/70068]
loss: 0.192652  [ 6400/70068]
loss: 0.111363  [12800/70068]
loss: 0.133787  [19200/70068]
loss: 0.132748  [25600/70068]
loss: 0.105849  [32000/70068]
loss: 0.116232  [38400/70068]
loss: 0.209736  [44800/70068]
loss: 0.170084  [51200/70068]
loss: 0.104075  [57600/70068]
loss: 0.041995  [64000/70068]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.177249 

Epoch 10
-------------------------------
loss: 0.173477  [    0/70068]
loss: 0.089007  [ 6400/70068]
loss: 0.147840  [12800/70068]
loss: 0.136136  [19200/70068]
loss: 0.176042  [25600/70068]
loss: 0.119703  [32000/70068]
loss: 0.083651  [38400/70068]
loss: 0.211407  [44800/70068]
loss: 0.129282  [51200/70068]
loss: 0.095034  [57600/70068]
loss: 0.123694  [64000/70068]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.176552 

Epoch 11
-------------------------------
loss: 0.271177  [    0/70068]
loss: 0.190425  [ 6400/70068]
loss: 0.165829  [12800/70068]
loss: 0.215997  [19200/70068]
loss: 0.122941  [25600/70068]
loss: 0.138114  [32000/70068]
loss: 0.168604  [38400/70068]
loss: 0.153678  [44800/70068]
loss: 0.194077  [51200/70068]
loss: 0.118081  [57600/70068]
loss: 0.209413  [64000/70068]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.177253 

Epoch 12
-------------------------------
loss: 0.087498  [    0/70068]
loss: 0.115118  [ 6400/70068]
loss: 0.064092  [25600/70717]
loss: 0.066982  [32000/70717]
loss: 0.086901  [38400/70717]
loss: 0.091797  [44800/70717]
loss: 0.163060  [51200/70717]
loss: 0.053358  [57600/70717]
loss: 0.145682  [64000/70717]
loss: 0.047401  [70400/70717]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.125686 

Epoch 44
-------------------------------
loss: 0.069633  [    0/70717]
loss: 0.114695  [ 6400/70717]
loss: 0.091994  [12800/70717]
loss: 0.104484  [19200/70717]
loss: 0.092501  [25600/70717]
loss: 0.109570  [32000/70717]
loss: 0.118848  [38400/70717]
loss: 0.022780  [44800/70717]
loss: 0.126130  [51200/70717]
loss: 0.110195  [57600/70717]
loss: 0.137844  [64000/70717]
loss: 0.085266  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.124901 

Epoch 45
-------------------------------
loss: 0.212396  [    0/70717]
loss: 0.109705  [ 6400/70717]
loss: 0.007901  [12800/70717]
loss: 0.021319  [19200/70717]
loss: 0.102408  [25600/70717]
loss: 0.196667  [32000/70717]
loss: 0.253302  [38400/70717]
loss: 0.158394  [44800/70717]
loss: 0.158840  [51200/70717]
loss: 0.138628  [57600/70717]
loss: 0.214716  [64000/70717]
loss: 0.038243  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.127976 

Epoch 46
-------------------------------
loss: 0.136517  [    0/70717]
loss: 0.041418  [ 6400/70717]
loss: 0.109129  [12800/70717]
loss: 0.133635  [19200/70717]
loss: 0.099161  [25600/70717]
loss: 0.119520  [32000/70717]
loss: 0.097702  [38400/70717]
loss: 0.114293  [44800/70717]
loss: 0.094460  [51200/70717]
loss: 0.093775  [57600/70717]
loss: 0.033572  [64000/70717]
loss: 0.084227  [70400/70717]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.128528 

Epoch 47
-------------------------------
loss: 0.096949  [    0/70717]
loss: 0.121531  [ 6400/70717]
loss: 0.101032  [12800/70717]
loss: 0.054112  [19200/70717]
loss: 0.081496  [25600/70717]
loss: 0.072147  [32000/70717]
loss: 0.134601  [38400/70717]
loss: 0.192668  [44800/70717]
loss: 0.053877  [51200/70717]
loss: 0.080304  [57600/70717]
loss: 0.075535  [64000/70717]
loss: 0.102165  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.121811 

Epoch 48
-------------------------------
loss: 0.033963  [    0/70717]
loss: 0.255078  [ 6400/70717]
loss: 0.081275  [12800/70717]
loss: 0.042678  [19200/70717]
loss: 0.171750  [25600/70717]
loss: 0.105427  [32000/70717]
loss: 0.217819  [38400/70717]
loss: 0.035465  [44800/70717]
loss: 0.138457  [51200/70717]
loss: 0.065982  [57600/70717]
loss: 0.031708  [64000/70717]
loss: 0.107883  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.131846 

Epoch 49
-------------------------------
loss: 0.104511  [    0/70717]
loss: 0.067816  [ 6400/70717]
loss: 0.178002  [12800/70717]
loss: 0.207209  [19200/70717]
loss: 0.114026  [25600/70717]
loss: 0.028271  [32000/70717]
loss: 0.052965  [38400/70717]
loss: 0.020748  [44800/70717]
loss: 0.153024  [51200/70717]
loss: 0.085587  [57600/70717]
loss: 0.044451  [64000/70717]
loss: 0.083827  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.121772 

Epoch 50
-------------------------------
loss: 0.033808  [    0/70717]
loss: 0.121328  [ 6400/70717]
loss: 0.050369  [12800/70717]
loss: 0.116862  [19200/70717]
loss: 0.089428  [25600/70717]
loss: 0.040435  [32000/70717]
loss: 0.154787  [38400/70717]
loss: 0.147783  [44800/70717]
loss: 0.163075  [51200/70717]
loss: 0.198199  [57600/70717]
loss: 0.150101  [64000/70717]
loss: 0.041365  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.123065 

Epoch 1
-------------------------------
loss: 0.695849  [    0/71142]
loss: 0.467747  [ 6400/71142]
loss: 0.248509  [12800/71142]
loss: 0.066443  [19200/71142]
loss: 0.154920  [25600/71142]
loss: 0.143810  [32000/71142]
loss: 0.139103  [38400/71142]
loss: 0.096275  [44800/71142]
loss: 0.060884  [51200/71142]
loss: 0.167835  [57600/71142]
loss: 0.156762  [64000/71142]
loss: 0.161359  [70400/71142]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.117302 

Epoch 2
-------------------------------
loss: 0.138056  [    0/71142]
loss: 0.144570  [ 6400/71142]
loss: 0.039653  [12800/71142]
loss: 0.072079  [19200/71142]
loss: 0.084289  [25600/71142]
loss: 0.050831  [32000/71142]
loss: 0.167450  [38400/71142]
loss: 0.119238  [44800/71142]
loss: 0.211164  [51200/71142]
loss: 0.041669  [57600/71142]
loss: 0.142616  [64000/71142]
loss: 0.093526  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.095483 

Epoch 3
-------------------------------
loss: 0.126661  [    0/71142]
loss: 0.066570  [ 6400/71142]
loss: 0.110189  [12800/71142]
loss: 0.145529  [19200/71142]
loss: 0.097341  [25600/71142]
loss: 0.125831  [32000/71142]
loss: 0.184092  [38400/71142]
loss: 0.074339  [44800/71142]
loss: 0.230644  [51200/71142]
loss: 0.060504  [57600/71142]
loss: 0.180846  [64000/71142]
loss: 0.139199  [70400/71142]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.096724 

Epoch 4
-------------------------------
loss: 0.125431  [    0/71142]
loss: 0.165003  [ 6400/71142]
loss: 0.140405  [12800/71142]
loss: 0.119292  [19200/71142]
loss: 0.078242  [25600/71142]
loss: 0.077625  [32000/71142]
loss: 0.118859  [38400/71142]
loss: 0.101465  [44800/71142]
loss: 0.106830  [51200/71142]
loss: 0.130742  [57600/71142]
loss: 0.064235  [64000/71142]
loss: 0.105451  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.088616 

Epoch 5
-------------------------------
loss: 0.085799  [    0/71142]
loss: 0.084324  [ 6400/71142]
loss: 0.089725  [12800/71142]
loss: 0.062569  [19200/71142]
loss: 0.038279  [25600/71142]
loss: 0.091571  [32000/71142]
loss: 0.197227  [38400/71142]
loss: 0.113390  [44800/71142]
loss: 0.066426  [51200/71142]
loss: 0.050608  [57600/71142]
loss: 0.060885  [64000/71142]
loss: 0.143364  [70400/71142]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.085365 

Epoch 6
-------------------------------
loss: 0.079100  [    0/71142]
loss: 0.036260  [ 6400/71142]
loss: 0.097753  [12800/71142]
loss: 0.180636  [19200/71142]
loss: 0.158660  [25600/71142]
loss: 0.137532  [32000/71142]
loss: 0.254317  [38400/71142]
loss: 0.025723  [44800/71142]
loss: 0.107375  [51200/71142]
loss: 0.122645  [57600/71142]
loss: 0.080849  [64000/71142]
loss: 0.056382  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.081968 

Epoch 7
-------------------------------
loss: 0.036582  [    0/71142]
loss: 0.074613  [ 6400/71142]
loss: 0.107428  [12800/71142]
loss: 0.061496  [19200/71142]
loss: 0.141706  [25600/71142]
loss: 0.107365  [32000/71142]
loss: 0.098324  [38400/71142]
loss: 0.124585  [44800/71142]
loss: 0.028794  [51200/71142]
loss: 0.126363  [57600/71142]
loss: 0.144611  [64000/71142]
loss: 0.038927  [70400/71142]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095599 

Epoch 8
-------------------------------
loss: 0.137504  [    0/71142]
loss: 0.070465  [ 6400/71142]
loss: 0.114231  [12800/71142]
loss: 0.193119  [19200/71142]
loss: 0.068945  [25600/71142]
loss: 0.052678  [32000/71142]
loss: 0.110839  [38400/71142]
loss: 0.027217  [44800/71142]
loss: 0.092210  [51200/71142]
loss: 0.116611  [57600/71142]
loss: 0.094004  [64000/71142]
loss: 0.079726  [70400/71142]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.087734 

Epoch 9
-------------------------------
loss: 0.137377  [    0/71142]
loss: 0.020534  [ 6400/71142]
loss: 0.173123  [12800/71142]
loss: 0.106371  [19200/71142]
loss: 0.038231  [25600/71142]
loss: 0.042368  [32000/71142]
loss: 0.118835  [38400/71142]
loss: 0.069743  [44800/71142]
loss: 0.045076  [51200/71142]
loss: 0.128933  [57600/71142]
loss: 0.093522  [64000/71142]
loss: 0.123388  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090821 

Epoch 10
-------------------------------
loss: 0.197837  [    0/71142]
loss: 0.131200  [ 6400/71142]
loss: 0.045226  [12800/71142]
loss: 0.073431  [19200/71142]
loss: 0.065878  [25600/71142]
loss: 0.146814  [32000/71142]
loss: 0.074246  [38400/71142]
loss: 0.091977  [44800/71142]
loss: 0.103106  [51200/71142]
loss: 0.091054  [57600/71142]
loss: 0.098187  [64000/71142]
loss: 0.086465  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.086701 

Epoch 11
-------------------------------
loss: 0.057815  [    0/71142]
loss: 0.036331  [ 6400/71142]
loss: 0.250359  [12800/71142]
loss: 0.085658  [19200/71142]
loss: 0.040465  [25600/71142]
2022/09/20 18:35:05 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 18:36:29 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.054541  [38400/69698]
loss: 0.177902  [44800/69698]
loss: 0.270539  [51200/69698]
loss: 0.221043  [57600/69698]
loss: 0.128738  [64000/69698]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.168050 

Epoch 31
-------------------------------
loss: 0.100313  [    0/69698]
loss: 0.163730  [ 6400/69698]
loss: 0.100249  [12800/69698]
loss: 0.066883  [19200/69698]
loss: 0.204915  [25600/69698]
loss: 0.051083  [32000/69698]
loss: 0.164636  [38400/69698]
loss: 0.194291  [44800/69698]
loss: 0.157385  [51200/69698]
loss: 0.330761  [57600/69698]
loss: 0.190900  [64000/69698]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.164524 

Epoch 32
-------------------------------
loss: 0.117653  [    0/69698]
loss: 0.291926  [ 6400/69698]
loss: 0.168137  [12800/69698]
loss: 0.056342  [19200/69698]
loss: 0.129063  [25600/69698]
loss: 0.094438  [32000/69698]
loss: 0.212333  [38400/69698]
loss: 0.099634  [44800/69698]
loss: 0.207166  [51200/69698]
loss: 0.163372  [57600/69698]
loss: 0.083619  [64000/69698]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.165546 

Epoch 33
-------------------------------
loss: 0.187105  [    0/69698]
loss: 0.123787  [ 6400/69698]
loss: 0.160495  [12800/69698]
loss: 0.161681  [19200/69698]
loss: 0.118692  [25600/69698]
loss: 0.125964  [32000/69698]
loss: 0.136813  [38400/69698]
loss: 0.119023  [44800/69698]
loss: 0.156805  [51200/69698]
loss: 0.165180  [57600/69698]
loss: 0.163717  [64000/69698]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.199887 

Epoch 34
-------------------------------
loss: 0.172065  [    0/69698]
loss: 0.170033  [ 6400/69698]
loss: 0.181083  [12800/69698]
loss: 0.145720  [19200/69698]
loss: 0.113564  [25600/69698]
loss: 0.096577  [32000/69698]
loss: 0.073197  [38400/69698]
loss: 0.204618  [44800/69698]
loss: 0.165947  [51200/69698]
loss: 0.161344  [57600/69698]
loss: 0.175191  [64000/69698]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.174091 

Epoch 35
-------------------------------
loss: 0.174606  [    0/69698]
loss: 0.069357  [ 6400/69698]
loss: 0.122118  [12800/69698]
loss: 0.106407  [19200/69698]
loss: 0.173491  [25600/69698]
loss: 0.073543  [32000/69698]
loss: 0.243561  [38400/69698]
loss: 0.087097  [44800/69698]
loss: 0.178049  [51200/69698]
loss: 0.183594  [57600/69698]
loss: 0.286399  [64000/69698]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169383 

Epoch 36
-------------------------------
loss: 0.167568  [    0/69698]
loss: 0.181363  [ 6400/69698]
loss: 0.146649  [12800/69698]
loss: 0.093750  [19200/69698]
loss: 0.133991  [25600/69698]
loss: 0.147002  [32000/69698]
loss: 0.116048  [38400/69698]
loss: 0.190618  [44800/69698]
loss: 0.213559  [51200/69698]
loss: 0.197046  [57600/69698]
loss: 0.175766  [64000/69698]
Test Error: 
 Accuracy: 90.0%, Avg loss: 0.308875 

Epoch 37
-------------------------------
loss: 0.308670  [    0/69698]
loss: 0.174178  [ 6400/69698]
loss: 0.285056  [12800/69698]
loss: 0.135209  [19200/69698]
loss: 0.142812  [25600/69698]
loss: 0.164496  [32000/69698]
loss: 0.209225  [38400/69698]
loss: 0.191318  [44800/69698]
loss: 0.136046  [51200/69698]
loss: 0.197246  [57600/69698]
loss: 0.140778  [64000/69698]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174758 

Epoch 38
-------------------------------
loss: 0.157028  [    0/69698]
loss: 0.158683  [ 6400/69698]
loss: 0.184533  [12800/69698]
loss: 1.643944  [19200/69698]
loss: 0.240408  [25600/69698]
loss: 0.105941  [32000/69698]
loss: 0.236591  [38400/69698]
loss: 0.130308  [44800/69698]
loss: 0.088592  [51200/69698]
loss: 0.153438  [57600/69698]
loss: 0.208513  [64000/69698]
Test Error: 
 Accuracy: 78.9%, Avg loss: 0.791116 

Epoch 39
-------------------------------
loss: 0.501072  [    0/69698]
loss: 0.130029  [ 6400/69698]
loss: 0.163065  [12800/69698]
loss: 0.053653  [19200/69698]
loss: 0.055629  [25600/69698]
loss: 0.089381  [32000/69698]
loss: 0.061013  [38400/69698]
loss: 0.092746  [44800/69698]
loss: 0.184249  [51200/69698]
loss: 0.128870  [57600/69698]
loss: 0.141098  [64000/69698]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.205375 

Epoch 40
-------------------------------
loss: 0.113794  [    0/69698]
loss: 0.232968  [ 6400/69698]
loss: 0.238338  [12800/69698]
loss: 0.131200  [19200/69698]
loss: 0.174864  [25600/69698]
loss: 0.065471  [32000/69698]
loss: 0.059461  [38400/69698]
loss: 0.140176  [44800/69698]
loss: 0.278596  [51200/69698]
loss: 0.258007  [57600/69698]
loss: 0.152227  [64000/69698]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.170985 

Epoch 41
-------------------------------
loss: 0.248750  [    0/69698]
loss: 0.104718  [ 6400/69698]
loss: 0.207941  [12800/69698]
loss: 0.128268  [19200/69698]
loss: 0.059529  [25600/69698]
loss: 0.140641  [32000/69698]
loss: 0.155813  [38400/69698]
loss: 0.089119  [44800/69698]
loss: 0.084591  [51200/69698]
loss: 0.184406  [57600/69698]
loss: 0.270399  [64000/69698]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.177653 

Epoch 42
-------------------------------
loss: 0.085885  [    0/69698]
loss: 0.095225  [ 6400/69698]
loss: 0.100521  [12800/69698]
loss: 0.176767  [19200/69698]
loss: 0.263349  [25600/69698]
loss: 0.093817  [32000/69698]
loss: 0.116559  [38400/69698]
loss: 0.116692  [44800/69698]
loss: 0.095011  [51200/69698]
loss: 0.179030  [57600/69698]
loss: 0.250129  [64000/69698]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.235256 

Epoch 43
-------------------------------
loss: 0.272614  [    0/69698]
loss: 0.174060  [ 6400/69698]
loss: 0.139276  [12800/69698]
loss: 0.087283  [19200/69698]
loss: 0.184773  [25600/69698]
loss: 0.109673  [32000/69698]
loss: 0.065454  [38400/69698]
loss: 0.131685  [44800/69698]
loss: 0.271829  [51200/69698]
loss: 0.111566  [57600/69698]
loss: 0.099677  [64000/69698]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.161817 

Epoch 44
-------------------------------
loss: 0.160757  [    0/69698]
loss: 0.087627  [ 6400/69698]
loss: 0.188165  [12800/69698]
loss: 0.091330  [19200/69698]
loss: 0.220822  [25600/69698]
loss: 0.088514  [32000/69698]
loss: 0.134408  [38400/69698]
loss: 0.094601  [44800/69698]
loss: 0.098375  [51200/69698]
loss: 0.111240  [57600/69698]
loss: 0.147181  [64000/69698]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.176065 

Epoch 45
-------------------------------
loss: 0.113253  [    0/69698]
loss: 0.119031  [ 6400/69698]
loss: 0.218277  [12800/69698]
loss: 0.094337  [19200/69698]
loss: 0.059048  [25600/69698]
loss: 0.186049  [32000/69698]
loss: 0.161900  [38400/69698]
loss: 0.090024  [44800/69698]
loss: 0.157168  [51200/69698]
loss: 0.111022  [57600/69698]
loss: 0.148240  [64000/69698]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.164920 

Epoch 46
-------------------------------
loss: 0.222821  [    0/69698]
loss: 0.184728  [ 6400/69698]
loss: 0.223398  [12800/69698]
loss: 0.224932  [19200/69698]
loss: 0.090608  [25600/69698]
loss: 0.173808  [32000/69698]
loss: 0.092252  [38400/69698]
loss: 0.131765  [44800/69698]
loss: 0.090674  [51200/69698]
loss: 0.094297  [57600/69698]
loss: 0.098316  [64000/69698]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.171736 

Epoch 47
-------------------------------
loss: 0.132642  [    0/69698]
loss: 0.126170  [ 6400/69698]
loss: 0.116632  [12800/69698]
loss: 0.254905  [19200/69698]
loss: 0.133924  [25600/69698]
loss: 0.210064  [32000/69698]
loss: 0.128461  [38400/69698]
loss: 0.174365  [44800/69698]
loss: 0.114780  [51200/69698]
loss: 0.240016  [57600/69698]
loss: 0.095887  [64000/69698]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.165824 

Epoch 48
-------------------------------
loss: 0.103600  [    0/69698]
loss: 0.116738  [ 6400/69698]
loss: 0.167126  [12800/69698]
loss: 0.119720  [19200/69698]
loss: 0.243084  [25600/69698]
loss: 0.224314  [32000/69698]
loss: 0.051085  [38400/69698]
loss: 0.259719  [44800/69698]
loss: 0.152060  [51200/69698]
loss: 0.080177  [57600/69698]
loss: 0.247605  [64000/69698]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.168527 

Epoch 49
-------------------------------
loss: 0.196604  [    0/69698]
loss: 0.179856  [ 6400/69698]
loss: 0.097577  [12800/69698]
loss: 0.141135  [19200/69698]
loss: 0.120315  [25600/69698]
loss: 0.166922  [32000/69698]
loss: 0.088949  [38400/69698]
loss: 0.079886  [44800/69698]
loss: 0.206899  [51200/69698]
loss: 0.170286  [57600/69698]
loss: 0.100461  [64000/69698]
loss: 0.125832  [38400/70245]
loss: 0.233371  [44800/70245]
loss: 0.148973  [51200/70245]
loss: 0.182162  [57600/70245]
loss: 0.142687  [64000/70245]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.193369 

Epoch 31
-------------------------------
loss: 0.184761  [    0/70245]
loss: 0.356451  [ 6400/70245]
loss: 0.170970  [12800/70245]
loss: 0.082715  [19200/70245]
loss: 0.240168  [25600/70245]
loss: 0.184476  [32000/70245]
loss: 0.203045  [38400/70245]
loss: 0.194669  [44800/70245]
loss: 0.169375  [51200/70245]
loss: 0.262198  [57600/70245]
loss: 0.122019  [64000/70245]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.173368 

Epoch 32
-------------------------------
loss: 0.119373  [    0/70245]
loss: 0.097030  [ 6400/70245]
loss: 0.175426  [12800/70245]
loss: 0.239345  [19200/70245]
loss: 0.207229  [25600/70245]
loss: 0.142035  [32000/70245]
loss: 0.405564  [38400/70245]
loss: 0.159348  [44800/70245]
loss: 0.129847  [51200/70245]
loss: 0.138184  [57600/70245]
loss: 0.096804  [64000/70245]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.173727 

Epoch 33
-------------------------------
loss: 0.164859  [    0/70245]
loss: 0.082741  [ 6400/70245]
loss: 0.109668  [12800/70245]
loss: 0.148553  [19200/70245]
loss: 0.097577  [25600/70245]
loss: 0.251481  [32000/70245]
loss: 0.133565  [38400/70245]
loss: 0.163993  [44800/70245]
loss: 0.131866  [51200/70245]
loss: 0.140767  [57600/70245]
loss: 0.171975  [64000/70245]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.164903 

Epoch 34
-------------------------------
loss: 0.096207  [    0/70245]
loss: 0.212362  [ 6400/70245]
loss: 0.231460  [12800/70245]
loss: 0.109475  [19200/70245]
loss: 0.126331  [25600/70245]
loss: 0.177636  [32000/70245]
loss: 0.169567  [38400/70245]
loss: 0.177125  [44800/70245]
loss: 0.334341  [51200/70245]
loss: 0.116423  [57600/70245]
loss: 0.262658  [64000/70245]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.170757 

Epoch 35
-------------------------------
loss: 0.113653  [    0/70245]
loss: 0.125402  [ 6400/70245]
loss: 0.100069  [12800/70245]
loss: 0.151398  [19200/70245]
loss: 0.224468  [25600/70245]
loss: 0.228628  [32000/70245]
loss: 0.147407  [38400/70245]
loss: 0.113424  [44800/70245]
loss: 0.130814  [51200/70245]
loss: 0.140361  [57600/70245]
loss: 0.173899  [64000/70245]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.190503 

Epoch 36
-------------------------------
loss: 0.249213  [    0/70245]
loss: 0.064787  [ 6400/70245]
loss: 0.111085  [12800/70245]
loss: 0.081044  [19200/70245]
loss: 0.218955  [25600/70245]
loss: 0.152023  [32000/70245]
loss: 0.115703  [38400/70245]
loss: 0.197350  [44800/70245]
loss: 0.117769  [51200/70245]
loss: 0.184802  [57600/70245]
loss: 0.207323  [64000/70245]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.190739 

Epoch 37
-------------------------------
loss: 0.302490  [    0/70245]
loss: 0.241098  [ 6400/70245]
loss: 0.110354  [12800/70245]
loss: 0.272677  [19200/70245]
loss: 0.131348  [25600/70245]
loss: 0.134095  [32000/70245]
loss: 0.101098  [38400/70245]
loss: 0.127628  [44800/70245]
loss: 0.218323  [51200/70245]
loss: 0.096423  [57600/70245]
loss: 0.098908  [64000/70245]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.169846 

Epoch 38
-------------------------------
loss: 0.192248  [    0/70245]
loss: 0.308113  [ 6400/70245]
loss: 0.206467  [12800/70245]
loss: 0.259093  [19200/70245]
loss: 0.116403  [25600/70245]
loss: 0.226078  [32000/70245]
loss: 0.198740  [38400/70245]
loss: 0.151902  [44800/70245]
loss: 0.104119  [51200/70245]
loss: 0.195678  [57600/70245]
loss: 0.142190  [64000/70245]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.160885 

Epoch 39
-------------------------------
loss: 0.108220  [    0/70245]
loss: 0.162295  [ 6400/70245]
loss: 0.075175  [12800/70245]
loss: 0.106189  [19200/70245]
loss: 0.170552  [25600/70245]
loss: 0.280476  [32000/70245]
loss: 0.198672  [38400/70245]
loss: 0.156264  [44800/70245]
loss: 0.114081  [51200/70245]
loss: 0.080702  [57600/70245]
loss: 0.119698  [64000/70245]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.165332 

Epoch 40
-------------------------------
loss: 0.112024  [    0/70245]
loss: 0.044441  [ 6400/70245]
loss: 0.197256  [12800/70245]
loss: 0.213967  [19200/70245]
loss: 0.180377  [25600/70245]
loss: 0.090171  [32000/70245]
loss: 0.137072  [38400/70245]
loss: 0.218003  [44800/70245]
loss: 0.194298  [51200/70245]
loss: 0.218620  [57600/70245]
loss: 0.095053  [64000/70245]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.169751 

Epoch 41
-------------------------------
loss: 0.141750  [    0/70245]
loss: 0.095093  [ 6400/70245]
loss: 0.118417  [12800/70245]
loss: 0.152295  [19200/70245]
loss: 0.127597  [25600/70245]
loss: 0.178193  [32000/70245]
loss: 0.113341  [38400/70245]
loss: 0.098665  [44800/70245]
loss: 0.201516  [51200/70245]
loss: 0.231256  [57600/70245]
loss: 0.174022  [64000/70245]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.180421 

Epoch 42
-------------------------------
loss: 0.066731  [    0/70245]
loss: 0.196222  [ 6400/70245]
loss: 0.198430  [12800/70245]
loss: 0.243655  [19200/70245]
loss: 0.199769  [25600/70245]
loss: 0.208658  [32000/70245]
loss: 0.077336  [38400/70245]
loss: 0.168311  [44800/70245]
loss: 0.129801  [51200/70245]
loss: 0.175232  [57600/70245]
loss: 0.171076  [64000/70245]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.161206 

Epoch 43
-------------------------------
loss: 0.195870  [    0/70245]
loss: 0.191769  [ 6400/70245]
loss: 0.108149  [12800/70245]
loss: 0.201269  [19200/70245]
loss: 0.095992  [25600/70245]
loss: 0.162970  [32000/70245]
loss: 0.155482  [38400/70245]
loss: 0.129352  [44800/70245]
loss: 0.094147  [51200/70245]
loss: 0.170588  [57600/70245]
loss: 0.307677  [64000/70245]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.160327 

Epoch 44
-------------------------------
loss: 0.145665  [    0/70245]
loss: 0.154179  [ 6400/70245]
loss: 0.172276  [12800/70245]
loss: 0.159026  [19200/70245]
loss: 0.152332  [25600/70245]
loss: 0.158193  [32000/70245]
loss: 0.139405  [38400/70245]
loss: 0.145363  [44800/70245]
loss: 0.066914  [51200/70245]
loss: 0.339508  [57600/70245]
loss: 0.233585  [64000/70245]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.171068 

Epoch 45
-------------------------------
loss: 0.158207  [    0/70245]
loss: 0.142971  [ 6400/70245]
loss: 0.056453  [12800/70245]
loss: 0.217501  [19200/70245]
loss: 0.201632  [25600/70245]
loss: 0.117295  [32000/70245]
loss: 0.200204  [38400/70245]
loss: 0.255981  [44800/70245]
loss: 0.222718  [51200/70245]
loss: 0.125045  [57600/70245]
loss: 0.165000  [64000/70245]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.168691 

Epoch 46
-------------------------------
loss: 0.174176  [    0/70245]
loss: 0.072990  [ 6400/70245]
loss: 0.217891  [12800/70245]
loss: 0.132291  [19200/70245]
loss: 0.105394  [25600/70245]
loss: 0.296801  [32000/70245]
loss: 0.175281  [38400/70245]
loss: 0.184745  [44800/70245]
loss: 0.149560  [51200/70245]
loss: 0.195751  [57600/70245]
loss: 0.102246  [64000/70245]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.176481 

Epoch 47
-------------------------------
loss: 0.129840  [    0/70245]
loss: 0.131740  [ 6400/70245]
loss: 0.166159  [12800/70245]
loss: 0.321958  [19200/70245]
loss: 0.133427  [25600/70245]
loss: 0.173293  [32000/70245]
loss: 0.206006  [38400/70245]
loss: 0.103450  [44800/70245]
loss: 0.118477  [51200/70245]
loss: 0.116206  [57600/70245]
loss: 0.206292  [64000/70245]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.178353 

Epoch 48
-------------------------------
loss: 0.123819  [    0/70245]
loss: 0.271214  [ 6400/70245]
loss: 0.122918  [12800/70245]
loss: 0.126148  [19200/70245]
loss: 0.115654  [25600/70245]
loss: 0.158152  [32000/70245]
loss: 0.188651  [38400/70245]
loss: 0.154872  [44800/70245]
loss: 0.135760  [51200/70245]
loss: 0.318614  [57600/70245]
loss: 0.165856  [64000/70245]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.156692 

Epoch 49
-------------------------------
loss: 0.193996  [    0/70245]
loss: 0.184450  [ 6400/70245]
loss: 0.287416  [12800/70245]
loss: 0.187246  [19200/70245]
loss: 0.144363  [25600/70245]
loss: 0.106858  [32000/70245]
loss: 0.161518  [38400/70245]
loss: 0.127663  [44800/70245]
loss: 0.209268  [51200/70245]
loss: 0.246578  [57600/70245]
loss: 0.131225  [64000/70245]
2022/09/20 18:38:49 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 18:39:07 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.186488  [57600/70677]
loss: 0.141891  [64000/70677]
loss: 0.220604  [70400/70677]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.223181 

Epoch 47
-------------------------------
loss: 0.140505  [    0/70677]
loss: 0.099845  [ 6400/70677]
loss: 0.092457  [12800/70677]
loss: 0.244672  [19200/70677]
loss: 0.109040  [25600/70677]
loss: 0.140182  [32000/70677]
loss: 0.202753  [38400/70677]
loss: 0.144920  [44800/70677]
loss: 0.198453  [51200/70677]
loss: 0.075905  [57600/70677]
loss: 0.236812  [64000/70677]
loss: 0.105542  [70400/70677]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.219001 

Epoch 48
-------------------------------
loss: 0.172926  [    0/70677]
loss: 0.175675  [ 6400/70677]
loss: 0.079613  [12800/70677]
loss: 0.150279  [19200/70677]
loss: 0.161693  [25600/70677]
loss: 0.235010  [32000/70677]
loss: 0.136884  [38400/70677]
loss: 0.111232  [44800/70677]
loss: 0.156920  [51200/70677]
loss: 0.138704  [57600/70677]
loss: 0.191561  [64000/70677]
loss: 0.055699  [70400/70677]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.208756 

Epoch 49
-------------------------------
loss: 0.085372  [    0/70677]
loss: 0.233833  [ 6400/70677]
loss: 0.080952  [12800/70677]
loss: 0.081958  [19200/70677]
loss: 0.330892  [25600/70677]
loss: 0.228265  [32000/70677]
loss: 0.100555  [38400/70677]
loss: 0.095378  [44800/70677]
loss: 0.122037  [51200/70677]
loss: 0.178737  [57600/70677]
loss: 0.125496  [64000/70677]
loss: 0.195121  [70400/70677]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.225931 

Epoch 50
-------------------------------
loss: 0.200478  [    0/70677]
loss: 0.249222  [ 6400/70677]
loss: 0.283427  [12800/70677]
loss: 0.181188  [19200/70677]
loss: 0.173937  [25600/70677]
loss: 0.126177  [32000/70677]
loss: 0.089917  [38400/70677]
loss: 0.125684  [44800/70677]
loss: 0.262259  [51200/70677]
loss: 0.138667  [57600/70677]
loss: 0.261289  [64000/70677]
loss: 0.220015  [70400/70677]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.265045 

Epoch 1
-------------------------------
loss: 0.655424  [    0/71083]
loss: 0.231858  [ 6400/71083]
loss: 0.110786  [12800/71083]
loss: 0.081664  [19200/71083]
loss: 0.118231  [25600/71083]
loss: 0.153416  [32000/71083]
loss: 0.085230  [38400/71083]
loss: 0.211063  [44800/71083]
loss: 0.089146  [51200/71083]
loss: 0.053232  [57600/71083]
loss: 0.203499  [64000/71083]
loss: 0.027738  [70400/71083]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.119323 

Epoch 2
-------------------------------
loss: 0.149258  [    0/71083]
loss: 0.080047  [ 6400/71083]
loss: 0.125549  [12800/71083]
loss: 0.084355  [19200/71083]
loss: 0.216280  [25600/71083]
loss: 0.046840  [32000/71083]
loss: 0.073076  [38400/71083]
loss: 0.115067  [44800/71083]
loss: 0.083568  [51200/71083]
loss: 0.177993  [57600/71083]
loss: 0.060932  [64000/71083]
loss: 0.069552  [70400/71083]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.109135 

Epoch 3
-------------------------------
loss: 0.101714  [    0/71083]
loss: 0.044169  [ 6400/71083]
loss: 0.101218  [12800/71083]
loss: 0.140595  [19200/71083]
loss: 0.049562  [25600/71083]
loss: 0.108496  [32000/71083]
loss: 0.176849  [38400/71083]
loss: 0.116196  [44800/71083]
loss: 0.110991  [51200/71083]
loss: 0.028132  [57600/71083]
loss: 0.132028  [64000/71083]
loss: 0.056781  [70400/71083]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.104660 

Epoch 4
-------------------------------
loss: 0.113426  [    0/71083]
loss: 0.101033  [ 6400/71083]
loss: 0.094582  [12800/71083]
loss: 0.212047  [19200/71083]
loss: 0.071312  [25600/71083]
loss: 0.115821  [32000/71083]
loss: 0.113030  [38400/71083]
loss: 0.110647  [44800/71083]
loss: 0.158864  [51200/71083]
loss: 0.191289  [57600/71083]
loss: 0.022609  [64000/71083]
loss: 0.055169  [70400/71083]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.100536 

Epoch 5
-------------------------------
loss: 0.060872  [    0/71083]
loss: 0.080605  [ 6400/71083]
loss: 0.074955  [12800/71083]
loss: 0.082384  [19200/71083]
loss: 0.091228  [25600/71083]
loss: 0.276447  [32000/71083]
loss: 0.088284  [38400/71083]
loss: 0.066749  [44800/71083]
loss: 0.091803  [51200/71083]
loss: 0.013573  [57600/71083]
loss: 0.152724  [64000/71083]
loss: 0.097487  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.097831 

Epoch 6
-------------------------------
loss: 0.122355  [    0/71083]
loss: 0.062178  [ 6400/71083]
loss: 0.060963  [12800/71083]
loss: 0.135552  [19200/71083]
loss: 0.031010  [25600/71083]
loss: 0.073365  [32000/71083]
loss: 0.123552  [38400/71083]
loss: 0.057877  [44800/71083]
loss: 0.202963  [51200/71083]
loss: 0.113878  [57600/71083]
loss: 0.096670  [64000/71083]
loss: 0.113234  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.101684 

Epoch 7
-------------------------------
loss: 0.085149  [    0/71083]
loss: 0.018082  [ 6400/71083]
loss: 0.036746  [12800/71083]
loss: 0.092189  [19200/71083]
loss: 0.118436  [25600/71083]
loss: 0.104668  [32000/71083]
loss: 0.156172  [38400/71083]
loss: 0.094654  [44800/71083]
loss: 0.105652  [51200/71083]
loss: 0.170715  [57600/71083]
loss: 0.224198  [64000/71083]
loss: 0.037685  [70400/71083]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.103071 

Epoch 8
-------------------------------
loss: 0.051702  [    0/71083]
loss: 0.033428  [ 6400/71083]
loss: 0.072283  [12800/71083]
loss: 0.007574  [19200/71083]
loss: 0.119772  [25600/71083]
loss: 0.101926  [32000/71083]
loss: 0.156721  [38400/71083]
loss: 0.042192  [44800/71083]
loss: 0.085833  [51200/71083]
loss: 0.072113  [57600/71083]
loss: 0.056030  [64000/71083]
loss: 0.118196  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.099621 

Epoch 9
-------------------------------
loss: 0.102401  [    0/71083]
loss: 0.121140  [ 6400/71083]
loss: 0.121821  [12800/71083]
loss: 0.084406  [19200/71083]
loss: 0.087435  [25600/71083]
loss: 0.099827  [32000/71083]
loss: 0.059411  [38400/71083]
loss: 0.052269  [44800/71083]
loss: 0.031893  [51200/71083]
loss: 0.257537  [57600/71083]
loss: 0.096643  [64000/71083]
loss: 0.055628  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.101215 

Epoch 10
-------------------------------
loss: 0.057129  [    0/71083]
loss: 0.037983  [ 6400/71083]
loss: 0.065573  [12800/71083]
loss: 0.058519  [19200/71083]
loss: 0.047723  [25600/71083]
loss: 0.073466  [32000/71083]
loss: 0.164667  [38400/71083]
loss: 0.122775  [44800/71083]
loss: 0.039068  [51200/71083]
loss: 0.087551  [57600/71083]
loss: 0.100426  [64000/71083]
loss: 0.046949  [70400/71083]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.100878 

Epoch 11
-------------------------------
loss: 0.172477  [    0/71083]
loss: 0.063250  [ 6400/71083]
loss: 0.083747  [12800/71083]
loss: 0.102772  [19200/71083]
loss: 0.075820  [25600/71083]
loss: 0.072828  [32000/71083]
loss: 0.089111  [38400/71083]
loss: 0.045246  [44800/71083]
loss: 0.041489  [51200/71083]
loss: 0.034798  [57600/71083]
loss: 0.068120  [64000/71083]
loss: 0.056651  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.110798 

Epoch 12
-------------------------------
loss: 0.027763  [    0/71083]
loss: 0.081737  [ 6400/71083]
loss: 0.081727  [12800/71083]
loss: 0.054652  [19200/71083]
loss: 0.075278  [25600/71083]
loss: 0.032026  [32000/71083]
loss: 0.127543  [38400/71083]
loss: 0.060315  [44800/71083]
loss: 0.049773  [51200/71083]
loss: 0.098864  [57600/71083]
loss: 0.144295  [64000/71083]
loss: 0.021184  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.107096 

Epoch 13
-------------------------------
loss: 0.030503  [    0/71083]
loss: 0.069839  [ 6400/71083]
loss: 0.121434  [12800/71083]
loss: 0.132794  [19200/71083]
loss: 0.075547  [25600/71083]
loss: 0.046640  [32000/71083]
loss: 0.077986  [38400/71083]
loss: 0.035507  [44800/71083]
loss: 0.042619  [51200/71083]
loss: 0.064271  [57600/71083]
loss: 0.106156  [64000/71083]
loss: 0.034918  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.106885 

Epoch 14
-------------------------------
loss: 0.053924  [    0/71083]
loss: 0.128421  [ 6400/71083]
loss: 0.049311  [12800/71083]
loss: 0.077593  [19200/71083]
loss: 0.042011  [25600/71083]
loss: 0.115239  [32000/71083]
loss: 0.088497  [38400/71083]
loss: 0.032415  [44800/71083]
loss: 0.077809  [51200/71083]
loss: 0.105675  [57600/71083]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.131187 

Epoch 40
-------------------------------
loss: 0.160437  [    0/70549]
loss: 0.135762  [ 6400/70549]
loss: 0.150151  [12800/70549]
loss: 0.073717  [19200/70549]
loss: 0.138010  [25600/70549]
loss: 0.111514  [32000/70549]
loss: 0.060490  [38400/70549]
loss: 0.095715  [44800/70549]
loss: 0.052489  [51200/70549]
loss: 0.172351  [57600/70549]
loss: 0.129755  [64000/70549]
loss: 0.013536  [70400/70549]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.122145 

Epoch 41
-------------------------------
loss: 0.084226  [    0/70549]
loss: 0.182275  [ 6400/70549]
loss: 0.059099  [12800/70549]
loss: 0.091723  [19200/70549]
loss: 0.082950  [25600/70549]
loss: 0.040959  [32000/70549]
loss: 0.075064  [38400/70549]
loss: 0.159709  [44800/70549]
loss: 0.138042  [51200/70549]
loss: 0.172157  [57600/70549]
loss: 0.187098  [64000/70549]
loss: 0.114754  [70400/70549]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.125701 

Epoch 42
-------------------------------
loss: 0.146922  [    0/70549]
loss: 0.114335  [ 6400/70549]
loss: 0.174819  [12800/70549]
loss: 0.160057  [19200/70549]
loss: 0.150573  [25600/70549]
loss: 0.174412  [32000/70549]
loss: 0.062797  [38400/70549]
loss: 0.041592  [44800/70549]
loss: 0.118748  [51200/70549]
loss: 0.067556  [57600/70549]
loss: 0.234085  [64000/70549]
loss: 0.112074  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.124268 

Epoch 43
-------------------------------
loss: 0.051880  [    0/70549]
loss: 0.129965  [ 6400/70549]
loss: 0.143520  [12800/70549]
loss: 0.076244  [19200/70549]
loss: 0.099954  [25600/70549]
loss: 0.099016  [32000/70549]
loss: 0.132550  [38400/70549]
loss: 0.150858  [44800/70549]
loss: 0.176883  [51200/70549]
loss: 0.083124  [57600/70549]
loss: 0.089889  [64000/70549]
loss: 0.124045  [70400/70549]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.125097 

Epoch 44
-------------------------------
loss: 0.051375  [    0/70549]
loss: 0.091675  [ 6400/70549]
loss: 0.089238  [12800/70549]
loss: 0.130770  [19200/70549]
loss: 0.079598  [25600/70549]
loss: 0.063437  [32000/70549]
loss: 0.145680  [38400/70549]
loss: 0.099263  [44800/70549]
loss: 0.138070  [51200/70549]
loss: 0.138084  [57600/70549]
loss: 0.030645  [64000/70549]
loss: 0.035580  [70400/70549]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.128333 

Epoch 45
-------------------------------
loss: 0.127566  [    0/70549]
loss: 0.055013  [ 6400/70549]
loss: 0.131771  [12800/70549]
loss: 0.107514  [19200/70549]
loss: 0.076049  [25600/70549]
loss: 0.074475  [32000/70549]
loss: 0.076303  [38400/70549]
loss: 0.103461  [44800/70549]
loss: 0.056827  [51200/70549]
loss: 0.126245  [57600/70549]
loss: 0.120098  [64000/70549]
loss: 0.119008  [70400/70549]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.122974 

Epoch 46
-------------------------------
loss: 0.082878  [    0/70549]
loss: 0.088918  [ 6400/70549]
loss: 0.076147  [12800/70549]
loss: 0.088952  [19200/70549]
loss: 0.181483  [25600/70549]
loss: 0.069752  [32000/70549]
loss: 0.127799  [38400/70549]
loss: 0.101791  [44800/70549]
loss: 0.150424  [51200/70549]
loss: 0.054680  [57600/70549]
loss: 0.135593  [64000/70549]
loss: 0.194189  [70400/70549]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.121757 

Epoch 47
-------------------------------
loss: 0.087668  [    0/70549]
loss: 0.074173  [ 6400/70549]
loss: 0.143106  [12800/70549]
loss: 0.090281  [19200/70549]
loss: 0.089774  [25600/70549]
loss: 0.153998  [32000/70549]
loss: 0.049742  [38400/70549]
loss: 0.082783  [44800/70549]
loss: 0.045905  [51200/70549]
loss: 0.134837  [57600/70549]
loss: 0.201619  [64000/70549]
loss: 0.089023  [70400/70549]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.128044 

Epoch 48
-------------------------------
loss: 0.122156  [    0/70549]
loss: 0.093280  [ 6400/70549]
loss: 0.118699  [12800/70549]
loss: 0.044257  [19200/70549]
loss: 0.058230  [25600/70549]
loss: 0.131462  [32000/70549]
loss: 0.060492  [38400/70549]
loss: 0.142469  [44800/70549]
loss: 0.232125  [51200/70549]
loss: 0.189237  [57600/70549]
loss: 0.082349  [64000/70549]
loss: 0.071342  [70400/70549]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.122987 

Epoch 49
-------------------------------
loss: 0.176872  [    0/70549]
loss: 0.087043  [ 6400/70549]
loss: 0.046261  [12800/70549]
loss: 0.134297  [19200/70549]
loss: 0.086804  [25600/70549]
loss: 0.046179  [32000/70549]
loss: 0.098700  [38400/70549]
loss: 0.113318  [44800/70549]
loss: 0.219144  [51200/70549]
loss: 0.110716  [57600/70549]
loss: 0.046057  [64000/70549]
loss: 0.106209  [70400/70549]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.121289 

Epoch 50
-------------------------------
loss: 0.071401  [    0/70549]
loss: 0.081960  [ 6400/70549]
loss: 0.112087  [12800/70549]
loss: 0.106081  [19200/70549]
loss: 0.053341  [25600/70549]
loss: 0.074498  [32000/70549]
loss: 0.281779  [38400/70549]
loss: 0.065110  [44800/70549]
loss: 0.035773  [51200/70549]
loss: 0.179667  [57600/70549]
loss: 0.128638  [64000/70549]
loss: 0.034188  [70400/70549]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.128447 

Epoch 1
-------------------------------
loss: 0.701537  [    0/69183]
loss: 0.171605  [ 6400/69183]
loss: 0.253468  [12800/69183]
loss: 0.176214  [19200/69183]
loss: 0.122542  [25600/69183]
loss: 0.198652  [32000/69183]
loss: 0.193531  [38400/69183]
loss: 0.164092  [44800/69183]
loss: 0.155775  [51200/69183]
loss: 0.180943  [57600/69183]
loss: 0.175872  [64000/69183]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.158810 

Epoch 2
-------------------------------
loss: 0.219503  [    0/69183]
loss: 0.203844  [ 6400/69183]
loss: 0.156921  [12800/69183]
loss: 0.162287  [19200/69183]
loss: 0.158440  [25600/69183]
loss: 0.161627  [32000/69183]
loss: 0.112780  [38400/69183]
loss: 0.195612  [44800/69183]
loss: 0.141222  [51200/69183]
loss: 0.060463  [57600/69183]
loss: 0.184467  [64000/69183]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.141663 

Epoch 3
-------------------------------
loss: 0.166108  [    0/69183]
loss: 0.090043  [ 6400/69183]
loss: 0.169768  [12800/69183]
loss: 0.082533  [19200/69183]
loss: 0.126718  [25600/69183]
loss: 0.143270  [32000/69183]
loss: 0.094684  [38400/69183]
loss: 0.160160  [44800/69183]
loss: 0.148342  [51200/69183]
loss: 0.072869  [57600/69183]
loss: 0.153547  [64000/69183]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.136345 

Epoch 4
-------------------------------
loss: 0.236521  [    0/69183]
loss: 0.058845  [ 6400/69183]
loss: 0.100731  [12800/69183]
loss: 0.118415  [19200/69183]
loss: 0.068043  [25600/69183]
loss: 0.090245  [32000/69183]
loss: 0.149177  [38400/69183]
loss: 0.210600  [44800/69183]
loss: 0.130846  [51200/69183]
loss: 0.113055  [57600/69183]
loss: 0.054044  [64000/69183]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.133623 

Epoch 5
-------------------------------
loss: 0.068070  [    0/69183]
loss: 0.200537  [ 6400/69183]
loss: 0.133912  [12800/69183]
loss: 0.123579  [19200/69183]
loss: 0.182949  [25600/69183]
loss: 0.094619  [32000/69183]
loss: 0.187399  [38400/69183]
loss: 0.143717  [44800/69183]
loss: 0.079341  [51200/69183]
loss: 0.141734  [57600/69183]
loss: 0.139554  [64000/69183]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.129640 

Epoch 6
-------------------------------
loss: 0.054890  [    0/69183]
loss: 0.201661  [ 6400/69183]
loss: 0.079528  [12800/69183]
loss: 0.093567  [19200/69183]
loss: 0.155836  [25600/69183]
loss: 0.111275  [32000/69183]
loss: 0.134660  [38400/69183]
loss: 0.088163  [44800/69183]
loss: 0.052238  [51200/69183]
loss: 0.130405  [57600/69183]
loss: 0.105385  [64000/69183]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.127534 

Epoch 7
-------------------------------
loss: 0.068469  [    0/69183]
loss: 0.153486  [ 6400/69183]
loss: 0.072690  [12800/69183]
loss: 0.092126  [19200/69183]
loss: 0.063848  [25600/69183]
loss: 0.116475  [32000/69183]
loss: 0.147076  [38400/69183]
loss: 0.103723  [44800/69183]
loss: 0.181643  [51200/69183]
loss: 0.109744  [57600/69183]
loss: 0.285736  [64000/69183]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.123918 

Epoch 8
-------------------------------
loss: 0.108646  [    0/69183]
loss: 0.115962  [ 6400/69183]
loss: 0.191149  [12800/69183]
loss: 0.114453  [19200/69183]
loss: 0.071527  [25600/69183]
loss: 0.198527  [ 6400/69473]
loss: 0.066700  [12800/69473]
loss: 0.081595  [19200/69473]
loss: 0.214322  [25600/69473]
loss: 0.100542  [32000/69473]
loss: 0.337483  [38400/69473]
loss: 0.153726  [44800/69473]
loss: 0.144351  [51200/69473]
loss: 0.069812  [57600/69473]
loss: 0.207800  [64000/69473]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.161535 

Epoch 35
-------------------------------
loss: 0.147668  [    0/69473]
loss: 0.144910  [ 6400/69473]
loss: 0.133502  [12800/69473]
loss: 0.082917  [19200/69473]
loss: 0.140574  [25600/69473]
loss: 0.141829  [32000/69473]
loss: 0.124471  [38400/69473]
loss: 0.119532  [44800/69473]
loss: 0.152823  [51200/69473]
loss: 0.123669  [57600/69473]
loss: 0.067712  [64000/69473]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.163957 

Epoch 36
-------------------------------
loss: 0.088409  [    0/69473]
loss: 0.078968  [ 6400/69473]
loss: 0.241301  [12800/69473]
loss: 0.107030  [19200/69473]
loss: 0.122171  [25600/69473]
loss: 0.118578  [32000/69473]
loss: 0.040744  [38400/69473]
loss: 0.157437  [44800/69473]
loss: 0.158687  [51200/69473]
loss: 0.115701  [57600/69473]
loss: 0.112090  [64000/69473]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.175415 

Epoch 37
-------------------------------
loss: 0.113129  [    0/69473]
loss: 0.127641  [ 6400/69473]
loss: 0.076473  [12800/69473]
loss: 0.110995  [19200/69473]
loss: 0.138689  [25600/69473]
loss: 0.056303  [32000/69473]
loss: 0.182557  [38400/69473]
loss: 0.159452  [44800/69473]
loss: 0.043091  [51200/69473]
loss: 0.089635  [57600/69473]
loss: 0.122766  [64000/69473]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.178853 

Epoch 38
-------------------------------
loss: 0.144413  [    0/69473]
loss: 0.132568  [ 6400/69473]
loss: 0.032127  [12800/69473]
loss: 0.079085  [19200/69473]
loss: 0.113439  [25600/69473]
loss: 0.295622  [32000/69473]
loss: 0.090175  [38400/69473]
loss: 0.070088  [44800/69473]
loss: 0.079565  [51200/69473]
loss: 0.046393  [57600/69473]
loss: 0.183760  [64000/69473]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.167635 

Epoch 39
-------------------------------
loss: 0.140421  [    0/69473]
loss: 0.097365  [ 6400/69473]
loss: 0.147944  [12800/69473]
loss: 0.113929  [19200/69473]
loss: 0.218343  [25600/69473]
loss: 0.109961  [32000/69473]
loss: 0.086142  [38400/69473]
loss: 0.108471  [44800/69473]
loss: 0.089107  [51200/69473]
loss: 0.190765  [57600/69473]
loss: 0.095994  [64000/69473]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.156642 

Epoch 40
-------------------------------
loss: 0.146376  [    0/69473]
loss: 0.110375  [ 6400/69473]
loss: 0.109787  [12800/69473]
loss: 0.241015  [19200/69473]
loss: 0.239470  [25600/69473]
loss: 0.204199  [32000/69473]
loss: 0.105464  [38400/69473]
loss: 0.240965  [44800/69473]
loss: 0.100690  [51200/69473]
loss: 0.123859  [57600/69473]
loss: 0.188282  [64000/69473]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.167807 

Epoch 41
-------------------------------
loss: 0.062870  [    0/69473]
loss: 1.676838  [ 6400/69473]
loss: 0.057827  [12800/69473]
loss: 0.308808  [19200/69473]
loss: 0.109136  [25600/69473]
loss: 0.166691  [32000/69473]
loss: 0.244133  [38400/69473]
loss: 0.158438  [44800/69473]
loss: 0.238285  [51200/69473]
loss: 0.099938  [57600/69473]
loss: 0.173207  [64000/69473]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.165461 

Epoch 42
-------------------------------
loss: 0.221160  [    0/69473]
loss: 0.138966  [ 6400/69473]
loss: 0.179747  [12800/69473]
loss: 0.078259  [19200/69473]
loss: 0.141072  [25600/69473]
loss: 0.126970  [32000/69473]
loss: 0.068174  [38400/69473]
loss: 0.096362  [44800/69473]
loss: 0.108409  [51200/69473]
loss: 0.108568  [57600/69473]
loss: 0.117118  [64000/69473]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.171058 

Epoch 43
-------------------------------
loss: 0.150992  [    0/69473]
loss: 0.045006  [ 6400/69473]
loss: 0.170456  [12800/69473]
loss: 0.057864  [19200/69473]
loss: 0.127160  [25600/69473]
loss: 0.105237  [32000/69473]
loss: 0.068482  [38400/69473]
loss: 0.165698  [44800/69473]
loss: 0.153511  [51200/69473]
loss: 0.135170  [57600/69473]
loss: 0.166992  [64000/69473]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.164280 

Epoch 44
-------------------------------
loss: 0.141906  [    0/69473]
loss: 0.062370  [ 6400/69473]
loss: 0.267347  [12800/69473]
loss: 0.117527  [19200/69473]
loss: 0.067144  [25600/69473]
loss: 0.120279  [32000/69473]
loss: 0.180851  [38400/69473]
loss: 0.174370  [44800/69473]
loss: 0.122405  [51200/69473]
loss: 0.107750  [57600/69473]
loss: 0.134733  [64000/69473]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.166663 

Epoch 45
-------------------------------
loss: 0.140908  [    0/69473]
loss: 0.101640  [ 6400/69473]
loss: 0.121345  [12800/69473]
loss: 0.073325  [19200/69473]
loss: 0.172632  [25600/69473]
loss: 0.132456  [32000/69473]
loss: 0.162557  [38400/69473]
loss: 0.067120  [44800/69473]
loss: 0.261450  [51200/69473]
loss: 0.119387  [57600/69473]
loss: 0.114009  [64000/69473]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.175669 

Epoch 46
-------------------------------
loss: 0.093544  [    0/69473]
loss: 0.077103  [ 6400/69473]
loss: 0.175118  [12800/69473]
loss: 0.126189  [19200/69473]
loss: 0.121045  [25600/69473]
loss: 0.161107  [32000/69473]
loss: 0.104062  [38400/69473]
loss: 0.156785  [44800/69473]
loss: 0.158541  [51200/69473]
loss: 0.112488  [57600/69473]
loss: 0.097619  [64000/69473]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.166867 

Epoch 47
-------------------------------
loss: 0.200182  [    0/69473]
loss: 0.177467  [ 6400/69473]
loss: 0.079961  [12800/69473]
loss: 0.111112  [19200/69473]
loss: 0.129635  [25600/69473]
loss: 0.218970  [32000/69473]
loss: 0.122118  [38400/69473]
loss: 0.118649  [44800/69473]
loss: 0.094611  [51200/69473]
loss: 0.097595  [57600/69473]
loss: 0.308799  [64000/69473]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.176012 

Epoch 48
-------------------------------
loss: 0.057168  [    0/69473]
loss: 0.144048  [ 6400/69473]
loss: 0.129231  [12800/69473]
loss: 0.173855  [19200/69473]
loss: 0.051033  [25600/69473]
loss: 0.140105  [32000/69473]
loss: 0.226287  [38400/69473]
loss: 0.050091  [44800/69473]
loss: 0.061484  [51200/69473]
loss: 0.051376  [57600/69473]
loss: 0.160397  [64000/69473]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180617 

Epoch 49
-------------------------------
loss: 0.201714  [    0/69473]
loss: 0.070774  [ 6400/69473]
loss: 0.065059  [12800/69473]
loss: 0.166665  [19200/69473]
loss: 0.113825  [25600/69473]
loss: 0.201526  [32000/69473]
loss: 0.185374  [38400/69473]
loss: 0.045365  [44800/69473]
loss: 0.088430  [51200/69473]
loss: 0.162326  [57600/69473]
loss: 0.085775  [64000/69473]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.161434 

Epoch 50
-------------------------------
loss: 0.171882  [    0/69473]
loss: 0.085635  [ 6400/69473]
loss: 1.717085  [12800/69473]
loss: 0.059154  [19200/69473]
loss: 0.058544  [25600/69473]
loss: 0.380053  [32000/69473]
loss: 0.106255  [38400/69473]
loss: 0.098988  [44800/69473]
loss: 0.161192  [51200/69473]
loss: 0.147600  [57600/69473]
loss: 0.137109  [64000/69473]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.165737 

Epoch 1
-------------------------------
loss: 0.708795  [    0/71193]
loss: 0.238980  [ 6400/71193]
loss: 0.170545  [12800/71193]
loss: 0.150591  [19200/71193]
loss: 0.325322  [25600/71193]
loss: 0.159669  [32000/71193]
loss: 0.151055  [38400/71193]
loss: 0.179723  [44800/71193]
loss: 0.135006  [51200/71193]
loss: 0.095230  [57600/71193]
loss: 0.189606  [64000/71193]
loss: 0.152348  [70400/71193]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.147431 

Epoch 2
-------------------------------
loss: 0.088273  [    0/71193]
loss: 0.161319  [ 6400/71193]
loss: 0.073891  [12800/71193]
loss: 0.231002  [19200/71193]
loss: 0.154156  [25600/71193]
loss: 0.085147  [32000/71193]
loss: 0.215314  [38400/71193]
loss: 0.077725  [44800/71193]
loss: 0.139368  [51200/71193]
loss: 0.113215  [57600/71193]
loss: 0.168866  [64000/71193]
loss: 0.066250  [70400/71193]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.139016 

Epoch 3
-------------------------------
loss: 0.179871  [    0/71193]
loss: 0.169895  [ 6400/71193]
loss: 0.108825  [12800/71193]
loss: 0.231301  [19200/71193]
loss: 0.067053  [51200/71095]
loss: 0.075507  [57600/71095]
loss: 0.096665  [64000/71095]
loss: 0.100118  [70400/71095]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.155349 

Epoch 47
-------------------------------
loss: 0.062531  [    0/71095]
loss: 0.070116  [ 6400/71095]
loss: 0.120655  [12800/71095]
loss: 0.067259  [19200/71095]
loss: 0.062280  [25600/71095]
loss: 0.120932  [32000/71095]
loss: 0.039723  [38400/71095]
loss: 0.121079  [44800/71095]
loss: 0.155428  [51200/71095]
loss: 0.096077  [57600/71095]
loss: 0.058556  [64000/71095]
loss: 0.136988  [70400/71095]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.159924 

Epoch 48
-------------------------------
loss: 0.120844  [    0/71095]
loss: 0.110832  [ 6400/71095]
loss: 0.114771  [12800/71095]
loss: 0.062259  [19200/71095]
loss: 0.037369  [25600/71095]
loss: 0.102769  [32000/71095]
loss: 0.121204  [38400/71095]
loss: 1.815306  [44800/71095]
loss: 0.138630  [51200/71095]
loss: 0.102075  [57600/71095]
loss: 0.112832  [64000/71095]
loss: 0.121818  [70400/71095]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.164888 

Epoch 49
-------------------------------
loss: 0.096321  [    0/71095]
loss: 0.049806  [ 6400/71095]
loss: 0.076827  [12800/71095]
loss: 0.113867  [19200/71095]
loss: 0.088272  [25600/71095]
loss: 0.049243  [32000/71095]
loss: 0.031669  [38400/71095]
loss: 0.084474  [44800/71095]
loss: 0.147955  [51200/71095]
loss: 0.096979  [57600/71095]
loss: 0.024206  [64000/71095]
loss: 0.047045  [70400/71095]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.157208 

Epoch 50
-------------------------------
loss: 0.083434  [    0/71095]
loss: 0.127142  [ 6400/71095]
loss: 0.104463  [12800/71095]
loss: 0.046130  [19200/71095]
loss: 0.089307  [25600/71095]
loss: 0.089657  [32000/71095]
loss: 0.310205  [38400/71095]
loss: 0.231958  [44800/71095]
loss: 0.153106  [51200/71095]
loss: 0.149012  [57600/71095]
loss: 0.035948  [64000/71095]
loss: 0.047906  [70400/71095]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.149353 

Epoch 1
-------------------------------
loss: 0.692842  [    0/69860]
loss: 0.245548  [ 6400/69860]
loss: 0.150009  [12800/69860]
loss: 0.233554  [19200/69860]
loss: 0.207748  [25600/69860]
loss: 0.123578  [32000/69860]
loss: 0.200650  [38400/69860]
loss: 0.133265  [44800/69860]
loss: 0.169085  [51200/69860]
loss: 0.063660  [57600/69860]
loss: 0.097872  [64000/69860]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.118774 

Epoch 2
-------------------------------
loss: 0.101992  [    0/69860]
loss: 0.096039  [ 6400/69860]
loss: 0.135383  [12800/69860]
loss: 0.132555  [19200/69860]
loss: 0.078715  [25600/69860]
loss: 0.130590  [32000/69860]
loss: 0.174731  [38400/69860]
loss: 0.141339  [44800/69860]
loss: 0.060458  [51200/69860]
loss: 0.136443  [57600/69860]
loss: 0.065523  [64000/69860]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.110062 

Epoch 3
-------------------------------
loss: 0.117759  [    0/69860]
loss: 0.131481  [ 6400/69860]
loss: 0.069014  [12800/69860]
loss: 0.083829  [19200/69860]
loss: 0.091873  [25600/69860]
loss: 0.105932  [32000/69860]
loss: 0.171114  [38400/69860]
loss: 0.078202  [44800/69860]
loss: 0.155616  [51200/69860]
loss: 0.121024  [57600/69860]
loss: 0.075014  [64000/69860]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.107278 

Epoch 4
-------------------------------
loss: 0.043294  [    0/69860]
loss: 0.116832  [ 6400/69860]
loss: 0.169173  [12800/69860]
loss: 0.050529  [19200/69860]
loss: 0.048006  [25600/69860]
loss: 0.058679  [32000/69860]
loss: 0.075307  [38400/69860]
loss: 0.126054  [44800/69860]
loss: 0.180594  [51200/69860]
loss: 0.122398  [57600/69860]
loss: 0.199833  [64000/69860]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.105045 

Epoch 5
-------------------------------
loss: 0.109998  [    0/69860]
loss: 0.186128  [ 6400/69860]
loss: 0.096517  [12800/69860]
loss: 0.112642  [19200/69860]
loss: 0.072838  [25600/69860]
loss: 0.086023  [32000/69860]
loss: 0.064879  [38400/69860]
loss: 0.101293  [44800/69860]
loss: 0.122619  [51200/69860]
loss: 0.073908  [57600/69860]
loss: 0.156771  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.096885 

Epoch 6
-------------------------------
loss: 0.055172  [    0/69860]
loss: 0.059070  [ 6400/69860]
loss: 0.052467  [12800/69860]
loss: 0.051493  [19200/69860]
loss: 0.239022  [25600/69860]
loss: 0.043300  [32000/69860]
loss: 0.131610  [38400/69860]
loss: 0.144266  [44800/69860]
loss: 0.175978  [51200/69860]
loss: 0.195057  [57600/69860]
loss: 0.021374  [64000/69860]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.098934 

Epoch 7
-------------------------------
loss: 0.073599  [    0/69860]
loss: 0.188990  [ 6400/69860]
loss: 0.125515  [12800/69860]
loss: 0.149620  [19200/69860]
loss: 0.058361  [25600/69860]
loss: 0.091380  [32000/69860]
loss: 0.181856  [38400/69860]
loss: 0.090424  [44800/69860]
loss: 0.226565  [51200/69860]
loss: 0.276168  [57600/69860]
loss: 0.042739  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.100135 

Epoch 8
-------------------------------
loss: 0.091665  [    0/69860]
loss: 0.073933  [ 6400/69860]
loss: 0.087711  [12800/69860]
loss: 0.122320  [19200/69860]
loss: 0.062356  [25600/69860]
loss: 0.143162  [32000/69860]
loss: 0.179523  [38400/69860]
loss: 0.093515  [44800/69860]
loss: 0.104771  [51200/69860]
loss: 0.139399  [57600/69860]
loss: 0.099287  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.097592 

Epoch 9
-------------------------------
loss: 0.071269  [    0/69860]
loss: 0.390968  [ 6400/69860]
loss: 0.063498  [12800/69860]
loss: 0.039111  [19200/69860]
loss: 0.128404  [25600/69860]
loss: 0.152995  [32000/69860]
loss: 0.065602  [38400/69860]
loss: 0.109317  [44800/69860]
loss: 0.067699  [51200/69860]
loss: 0.105384  [57600/69860]
loss: 0.038734  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.096981 

Epoch 10
-------------------------------
loss: 0.054355  [    0/69860]
loss: 0.097556  [ 6400/69860]
loss: 0.096370  [12800/69860]
loss: 0.055807  [19200/69860]
loss: 0.055162  [25600/69860]
loss: 0.103280  [32000/69860]
loss: 0.095076  [38400/69860]
loss: 0.090833  [44800/69860]
loss: 0.023852  [51200/69860]
loss: 0.046765  [57600/69860]
loss: 0.042923  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.098693 

Epoch 11
-------------------------------
loss: 0.044861  [    0/69860]
loss: 0.182492  [ 6400/69860]
loss: 0.079467  [12800/69860]
loss: 0.126299  [19200/69860]
loss: 0.068198  [25600/69860]
loss: 0.081635  [32000/69860]
loss: 0.136407  [38400/69860]
loss: 0.116166  [44800/69860]
loss: 0.091395  [51200/69860]
loss: 0.077399  [57600/69860]
loss: 0.145995  [64000/69860]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.106066 

Epoch 12
-------------------------------
loss: 0.075163  [    0/69860]
loss: 0.119615  [ 6400/69860]
loss: 0.028641  [12800/69860]
loss: 0.086053  [19200/69860]
loss: 0.147213  [25600/69860]
loss: 0.257452  [32000/69860]
loss: 0.216936  [38400/69860]
loss: 0.039169  [44800/69860]
loss: 0.023267  [51200/69860]
loss: 0.215246  [57600/69860]
loss: 0.085138  [64000/69860]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.107903 

Epoch 13
-------------------------------
loss: 0.204702  [    0/69860]
loss: 0.071132  [ 6400/69860]
loss: 0.056970  [12800/69860]
loss: 0.033949  [19200/69860]
loss: 0.156339  [25600/69860]
loss: 0.116088  [32000/69860]
loss: 0.058495  [38400/69860]
loss: 0.111161  [44800/69860]
loss: 0.087012  [51200/69860]
loss: 0.114180  [57600/69860]
loss: 0.080172  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101245 

Epoch 14
-------------------------------
loss: 0.056916  [    0/69860]
loss: 0.136325  [ 6400/69860]
loss: 0.085857  [12800/69860]
loss: 0.262064  [19200/69860]
loss: 0.055277  [25600/69860]
loss: 0.217188  [32000/69860]
loss: 0.063668  [38400/69860]
loss: 0.169874  [44800/69860]
loss: 0.097188  [51200/69860]
loss: 0.092181  [57600/69860]
loss: 0.049354  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.098608 

Epoch 15
-------------------------------
loss: 0.052179  [    0/69860]
loss: 0.160676  [ 6400/69860]
loss: 0.073264  [12800/69860]
loss: 0.193508  [19200/69860]
loss: 0.062061  [25600/69860]
loss: 0.110972  [32000/69860]
loss: 0.115107  [38400/69860]
loss: 0.190639  [44800/69860]
2022/09/20 18:40:58 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.266743  [25600/70523]
loss: 0.107998  [32000/70523]
loss: 0.158298  [38400/70523]
loss: 0.218458  [44800/70523]
loss: 0.080255  [51200/70523]
loss: 0.132089  [57600/70523]
loss: 0.101746  [64000/70523]
loss: 0.087771  [70400/70523]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.167544 

Epoch 44
-------------------------------
loss: 0.156351  [    0/70523]
loss: 0.194082  [ 6400/70523]
loss: 0.158547  [12800/70523]
loss: 0.111449  [19200/70523]
loss: 0.093487  [25600/70523]
loss: 0.346649  [32000/70523]
loss: 0.139927  [38400/70523]
loss: 0.118552  [44800/70523]
loss: 0.220529  [51200/70523]
loss: 0.066595  [57600/70523]
loss: 0.137484  [64000/70523]
loss: 0.103657  [70400/70523]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.174596 

Epoch 45
-------------------------------
loss: 0.117778  [    0/70523]
loss: 0.148346  [ 6400/70523]
loss: 0.156898  [12800/70523]
loss: 0.197786  [19200/70523]
loss: 0.247580  [25600/70523]
loss: 0.280271  [32000/70523]
loss: 0.117718  [38400/70523]
loss: 0.192322  [44800/70523]
loss: 0.179725  [51200/70523]
loss: 0.184479  [57600/70523]
loss: 0.108158  [64000/70523]
loss: 0.167328  [70400/70523]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.177052 

Epoch 46
-------------------------------
loss: 0.119249  [    0/70523]
loss: 0.133468  [ 6400/70523]
loss: 0.093558  [12800/70523]
loss: 0.096772  [19200/70523]
loss: 0.079892  [25600/70523]
loss: 0.249850  [32000/70523]
loss: 0.162886  [38400/70523]
loss: 0.157094  [44800/70523]
loss: 0.126940  [51200/70523]
loss: 0.117726  [57600/70523]
loss: 0.126982  [64000/70523]
loss: 0.171798  [70400/70523]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.168220 

Epoch 47
-------------------------------
loss: 0.114443  [    0/70523]
loss: 0.099290  [ 6400/70523]
loss: 0.213445  [12800/70523]
loss: 0.123450  [19200/70523]
loss: 1.704107  [25600/70523]
loss: 0.132532  [32000/70523]
loss: 0.202861  [38400/70523]
loss: 0.219682  [44800/70523]
loss: 0.081003  [51200/70523]
loss: 0.182442  [57600/70523]
loss: 0.135772  [64000/70523]
loss: 0.140868  [70400/70523]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.169011 

Epoch 48
-------------------------------
loss: 0.278417  [    0/70523]
loss: 0.151137  [ 6400/70523]
loss: 0.166759  [12800/70523]
loss: 0.166104  [19200/70523]
loss: 0.214054  [25600/70523]
loss: 0.159258  [32000/70523]
loss: 0.135590  [38400/70523]
loss: 0.078893  [44800/70523]
loss: 0.072765  [51200/70523]
loss: 0.183802  [57600/70523]
loss: 0.117540  [64000/70523]
loss: 0.201887  [70400/70523]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.170320 

Epoch 49
-------------------------------
loss: 0.168418  [    0/70523]
loss: 0.196309  [ 6400/70523]
loss: 0.259380  [12800/70523]
loss: 0.116705  [19200/70523]
loss: 0.111282  [25600/70523]
loss: 0.156022  [32000/70523]
loss: 0.275632  [38400/70523]
loss: 0.108189  [44800/70523]
loss: 0.147640  [51200/70523]
loss: 0.132530  [57600/70523]
loss: 0.157956  [64000/70523]
loss: 0.125838  [70400/70523]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.183070 

Epoch 50
-------------------------------
loss: 0.170168  [    0/70523]
loss: 0.052719  [ 6400/70523]
loss: 0.073224  [12800/70523]
loss: 0.083437  [19200/70523]
loss: 0.193602  [25600/70523]
loss: 0.150633  [32000/70523]
loss: 0.232749  [38400/70523]
loss: 0.103708  [44800/70523]
loss: 0.113919  [51200/70523]
loss: 0.189474  [57600/70523]
loss: 0.213418  [64000/70523]
loss: 0.147514  [70400/70523]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.165390 

Epoch 1
-------------------------------
loss: 0.657571  [    0/70632]
loss: 0.149832  [ 6400/70632]
loss: 0.249082  [12800/70632]
loss: 0.087785  [19200/70632]
loss: 0.170322  [25600/70632]
loss: 0.274155  [32000/70632]
loss: 0.068360  [38400/70632]
loss: 0.213005  [44800/70632]
loss: 0.156462  [51200/70632]
loss: 0.121799  [57600/70632]
loss: 0.204051  [64000/70632]
loss: 0.157791  [70400/70632]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.121785 

Epoch 2
-------------------------------
loss: 0.158077  [    0/70632]
loss: 0.411186  [ 6400/70632]
loss: 0.132554  [12800/70632]
loss: 0.060022  [19200/70632]
loss: 0.202297  [25600/70632]
loss: 0.058285  [32000/70632]
loss: 0.163291  [38400/70632]
loss: 0.083560  [44800/70632]
loss: 0.150788  [51200/70632]
loss: 0.157503  [57600/70632]
loss: 0.044571  [64000/70632]
loss: 0.057496  [70400/70632]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.104992 

Epoch 3
-------------------------------
loss: 0.109853  [    0/70632]
loss: 0.121574  [ 6400/70632]
loss: 0.138949  [12800/70632]
loss: 0.109175  [19200/70632]
loss: 0.166813  [25600/70632]
loss: 0.123907  [32000/70632]
loss: 0.101656  [38400/70632]
loss: 0.136849  [44800/70632]
loss: 0.139407  [51200/70632]
loss: 0.119022  [57600/70632]
loss: 0.039591  [64000/70632]
loss: 0.065218  [70400/70632]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.105459 

Epoch 4
-------------------------------
loss: 0.059109  [    0/70632]
loss: 0.092544  [ 6400/70632]
loss: 0.069476  [12800/70632]
loss: 0.101391  [19200/70632]
loss: 0.199669  [25600/70632]
loss: 0.123044  [32000/70632]
loss: 0.127330  [38400/70632]
loss: 0.044649  [44800/70632]
loss: 0.099465  [51200/70632]
loss: 0.212471  [57600/70632]
loss: 0.179664  [64000/70632]
loss: 0.207070  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.102494 

Epoch 5
-------------------------------
loss: 0.028735  [    0/70632]
loss: 0.186775  [ 6400/70632]
loss: 0.011250  [12800/70632]
loss: 0.053310  [19200/70632]
loss: 0.127662  [25600/70632]
loss: 0.071911  [32000/70632]
loss: 0.069581  [38400/70632]
loss: 0.031978  [44800/70632]
loss: 0.103542  [51200/70632]
loss: 0.132805  [57600/70632]
loss: 0.124782  [64000/70632]
loss: 0.071099  [70400/70632]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.114166 

Epoch 6
-------------------------------
loss: 0.029276  [    0/70632]
loss: 0.049437  [ 6400/70632]
loss: 0.115614  [12800/70632]
loss: 0.029321  [19200/70632]
loss: 0.074709  [25600/70632]
loss: 0.138180  [32000/70632]
loss: 0.066875  [38400/70632]
loss: 0.144819  [44800/70632]
loss: 0.121236  [51200/70632]
loss: 0.163131  [57600/70632]
loss: 0.089483  [64000/70632]
loss: 0.155424  [70400/70632]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.104272 

Epoch 7
-------------------------------
loss: 0.098556  [    0/70632]
loss: 0.151451  [ 6400/70632]
loss: 0.137375  [12800/70632]
loss: 0.014308  [19200/70632]
loss: 0.121735  [25600/70632]
loss: 0.184395  [32000/70632]
loss: 0.158879  [38400/70632]
loss: 0.093732  [44800/70632]
loss: 0.191124  [51200/70632]
loss: 0.158733  [57600/70632]
loss: 0.140855  [64000/70632]
loss: 0.228029  [70400/70632]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.123752 

Epoch 8
-------------------------------
loss: 0.183483  [    0/70632]
loss: 0.086760  [ 6400/70632]
loss: 0.099234  [12800/70632]
loss: 0.232209  [19200/70632]
loss: 0.251249  [25600/70632]
loss: 0.080529  [32000/70632]
loss: 0.111716  [38400/70632]
loss: 0.054308  [44800/70632]
loss: 0.087397  [51200/70632]
loss: 0.117995  [57600/70632]
loss: 0.088451  [64000/70632]
loss: 0.134573  [70400/70632]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.116237 

Epoch 9
-------------------------------
loss: 0.058409  [    0/70632]
loss: 0.085644  [ 6400/70632]
loss: 0.163376  [12800/70632]
loss: 0.122886  [19200/70632]
loss: 0.108526  [25600/70632]
loss: 0.083950  [32000/70632]
loss: 0.105495  [38400/70632]
loss: 0.144044  [44800/70632]
loss: 0.105334  [51200/70632]
loss: 0.149591  [57600/70632]
loss: 0.123471  [64000/70632]
loss: 0.068871  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.107217 

Epoch 10
-------------------------------
loss: 0.131524  [    0/70632]
loss: 0.078191  [ 6400/70632]
loss: 0.071446  [12800/70632]
loss: 0.113652  [19200/70632]
loss: 0.069173  [25600/70632]
loss: 0.104499  [32000/70632]
loss: 0.094120  [38400/70632]
loss: 0.041358  [44800/70632]
loss: 0.070002  [51200/70632]
loss: 0.068552  [57600/70632]
loss: 0.149574  [64000/70632]
loss: 0.055294  [70400/70632]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.100428 

Epoch 11
-------------------------------
loss: 0.040724  [    0/70632]
loss: 0.116705  [ 6400/70632]
loss: 0.200950  [12800/70632]
loss: 0.138424  [19200/70632]
loss: 0.131037  [25600/70632]
Epoch 50
-------------------------------
loss: 0.066572  [    0/70391]
loss: 0.075289  [ 6400/70391]
loss: 0.062042  [12800/70391]
loss: 0.177981  [19200/70391]
loss: 0.109870  [25600/70391]
loss: 0.076851  [32000/70391]
loss: 0.091961  [38400/70391]
loss: 0.052292  [44800/70391]
loss: 0.127330  [51200/70391]
loss: 0.125420  [57600/70391]
loss: 0.073246  [64000/70391]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.153621 

Epoch 1
-------------------------------
loss: 0.695000  [    0/70352]
loss: 0.179587  [ 6400/70352]
loss: 0.214625  [12800/70352]
loss: 0.178416  [19200/70352]
loss: 0.211506  [25600/70352]
loss: 0.083724  [32000/70352]
loss: 0.190888  [38400/70352]
loss: 0.110788  [44800/70352]
loss: 0.162952  [51200/70352]
loss: 0.095156  [57600/70352]
loss: 0.075077  [64000/70352]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.186407 

Epoch 2
-------------------------------
loss: 0.144714  [    0/70352]
loss: 0.085539  [ 6400/70352]
loss: 0.073840  [12800/70352]
loss: 0.112188  [19200/70352]
loss: 0.080019  [25600/70352]
loss: 0.051763  [32000/70352]
loss: 0.078055  [38400/70352]
loss: 0.134388  [44800/70352]
loss: 0.064723  [51200/70352]
loss: 0.084539  [57600/70352]
loss: 0.094640  [64000/70352]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.137696 

Epoch 3
-------------------------------
loss: 0.171182  [    0/70352]
loss: 0.085424  [ 6400/70352]
loss: 0.038149  [12800/70352]
loss: 0.144257  [19200/70352]
loss: 0.078327  [25600/70352]
loss: 0.065218  [32000/70352]
loss: 0.129701  [38400/70352]
loss: 0.086197  [44800/70352]
loss: 0.077002  [51200/70352]
loss: 0.076424  [57600/70352]
loss: 0.218475  [64000/70352]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.140936 

Epoch 4
-------------------------------
loss: 0.121757  [    0/70352]
loss: 0.114724  [ 6400/70352]
loss: 0.055117  [12800/70352]
loss: 0.107494  [19200/70352]
loss: 0.127099  [25600/70352]
loss: 0.034192  [32000/70352]
loss: 0.046244  [38400/70352]
loss: 0.127428  [44800/70352]
loss: 0.125612  [51200/70352]
loss: 0.180541  [57600/70352]
loss: 0.112425  [64000/70352]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.141041 

Epoch 5
-------------------------------
loss: 0.108493  [    0/70352]
loss: 0.037252  [ 6400/70352]
loss: 0.026354  [12800/70352]
loss: 0.052931  [19200/70352]
loss: 0.226738  [25600/70352]
loss: 0.095446  [32000/70352]
loss: 0.096319  [38400/70352]
loss: 0.095722  [44800/70352]
loss: 0.045175  [51200/70352]
loss: 0.178559  [57600/70352]
loss: 0.088759  [64000/70352]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.130677 

Epoch 6
-------------------------------
loss: 0.059310  [    0/70352]
loss: 0.098366  [ 6400/70352]
loss: 0.075600  [12800/70352]
loss: 0.059524  [19200/70352]
loss: 0.047749  [25600/70352]
loss: 0.023279  [32000/70352]
loss: 0.114805  [38400/70352]
loss: 0.088708  [44800/70352]
loss: 0.068648  [51200/70352]
loss: 0.084926  [57600/70352]
loss: 0.075626  [64000/70352]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.131685 

Epoch 7
-------------------------------
loss: 0.084517  [    0/70352]
loss: 0.100884  [ 6400/70352]
loss: 0.065296  [12800/70352]
loss: 0.108080  [19200/70352]
loss: 0.168810  [25600/70352]
loss: 0.081415  [32000/70352]
loss: 0.045992  [38400/70352]
loss: 0.148519  [44800/70352]
loss: 0.119329  [51200/70352]
loss: 0.173149  [57600/70352]
loss: 0.056687  [64000/70352]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.119099 

Epoch 8
-------------------------------
loss: 0.038372  [    0/70352]
loss: 0.048135  [ 6400/70352]
loss: 0.122513  [12800/70352]
loss: 0.138162  [19200/70352]
loss: 0.021861  [25600/70352]
loss: 0.060363  [32000/70352]
loss: 0.113877  [38400/70352]
loss: 0.074644  [44800/70352]
loss: 0.056706  [51200/70352]
loss: 0.065518  [57600/70352]
loss: 0.181609  [64000/70352]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.117664 

Epoch 9
-------------------------------
loss: 0.108832  [    0/70352]
loss: 0.181947  [ 6400/70352]
loss: 0.066357  [12800/70352]
loss: 0.063650  [19200/70352]
loss: 0.056796  [25600/70352]
loss: 0.069886  [32000/70352]
loss: 0.113366  [38400/70352]
loss: 0.137006  [44800/70352]
loss: 0.074868  [51200/70352]
loss: 0.079827  [57600/70352]
loss: 0.053205  [64000/70352]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.129836 

Epoch 10
-------------------------------
loss: 0.100865  [    0/70352]
loss: 0.040379  [ 6400/70352]
loss: 0.039730  [12800/70352]
loss: 0.030802  [19200/70352]
loss: 0.048821  [25600/70352]
loss: 0.116496  [32000/70352]
loss: 0.159157  [38400/70352]
loss: 0.019238  [44800/70352]
loss: 0.032803  [51200/70352]
loss: 0.127713  [57600/70352]
loss: 0.078277  [64000/70352]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.122890 

Epoch 11
-------------------------------
loss: 0.078114  [    0/70352]
loss: 0.022247  [ 6400/70352]
loss: 0.081863  [12800/70352]
loss: 0.476485  [19200/70352]
loss: 0.187455  [25600/70352]
loss: 0.043109  [32000/70352]
loss: 0.195953  [38400/70352]
loss: 0.098070  [44800/70352]
loss: 0.121056  [51200/70352]
loss: 0.055430  [57600/70352]
loss: 0.046596  [64000/70352]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.117645 

Epoch 12
-------------------------------
loss: 0.035351  [    0/70352]
loss: 0.075277  [ 6400/70352]
loss: 0.066331  [12800/70352]
loss: 0.081524  [19200/70352]
loss: 0.059581  [25600/70352]
loss: 0.018001  [32000/70352]
loss: 0.061634  [38400/70352]
loss: 0.038047  [44800/70352]
loss: 0.144560  [51200/70352]
loss: 0.108950  [57600/70352]
loss: 0.126459  [64000/70352]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.123482 

Epoch 13
-------------------------------
loss: 0.065365  [    0/70352]
loss: 0.071068  [ 6400/70352]
loss: 0.072958  [12800/70352]
loss: 0.035954  [19200/70352]
loss: 0.079809  [25600/70352]
loss: 0.070523  [32000/70352]
loss: 0.149208  [38400/70352]
loss: 0.109518  [44800/70352]
loss: 0.091028  [51200/70352]
loss: 0.049901  [57600/70352]
loss: 0.046249  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.118727 

Epoch 14
-------------------------------
loss: 0.049652  [    0/70352]
loss: 0.114311  [ 6400/70352]
loss: 0.107910  [12800/70352]
loss: 0.035554  [19200/70352]
loss: 0.101530  [25600/70352]
loss: 0.130741  [32000/70352]
loss: 0.078623  [38400/70352]
loss: 0.099295  [44800/70352]
loss: 0.062704  [51200/70352]
loss: 0.171116  [57600/70352]
loss: 0.053256  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.116502 

Epoch 15
-------------------------------
loss: 0.110010  [    0/70352]
loss: 0.124169  [ 6400/70352]
loss: 0.021135  [12800/70352]
loss: 0.061432  [19200/70352]
loss: 0.084404  [25600/70352]
loss: 0.046477  [32000/70352]
loss: 0.065157  [38400/70352]
loss: 0.063006  [44800/70352]
loss: 0.053460  [51200/70352]
loss: 0.079540  [57600/70352]
loss: 0.074355  [64000/70352]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.133794 

Epoch 16
-------------------------------
loss: 0.037015  [    0/70352]
loss: 0.111045  [ 6400/70352]
loss: 0.197973  [12800/70352]
loss: 0.071411  [19200/70352]
loss: 0.058101  [25600/70352]
loss: 0.046167  [32000/70352]
loss: 0.188751  [38400/70352]
loss: 0.027249  [44800/70352]
loss: 0.165063  [51200/70352]
loss: 0.057327  [57600/70352]
loss: 0.097774  [64000/70352]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.117138 

Epoch 17
-------------------------------
loss: 0.039256  [    0/70352]
loss: 0.124799  [ 6400/70352]
loss: 0.291964  [12800/70352]
loss: 0.019084  [19200/70352]
loss: 0.032359  [25600/70352]
loss: 0.053122  [32000/70352]
loss: 0.026077  [38400/70352]
loss: 0.034485  [44800/70352]
loss: 0.064685  [51200/70352]
loss: 0.045823  [57600/70352]
loss: 0.100698  [64000/70352]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.130063 

Epoch 18
-------------------------------
loss: 0.006416  [    0/70352]
loss: 0.116870  [ 6400/70352]
loss: 0.141072  [12800/70352]
loss: 0.025192  [19200/70352]
loss: 0.054390  [25600/70352]
loss: 0.210598  [32000/70352]
loss: 0.187250  [38400/70352]
loss: 0.087850  [44800/70352]
loss: 0.077974  [51200/70352]
loss: 0.118029  [57600/70352]
loss: 0.070522  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.120668 

Epoch 19
-------------------------------
loss: 0.032620  [    0/70352]
loss: 0.066330  [ 6400/70352]
loss: 0.046082  [12800/70352]
loss: 0.094300  [19200/70352]
loss: 0.105237  [12800/70070]
loss: 0.083624  [19200/70070]
loss: 0.168442  [25600/70070]
loss: 0.245235  [32000/70070]
loss: 0.185867  [38400/70070]
loss: 0.144661  [44800/70070]
loss: 0.219285  [51200/70070]
loss: 0.423532  [57600/70070]
loss: 0.193974  [64000/70070]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.182832 

Epoch 35
-------------------------------
loss: 0.212857  [    0/70070]
loss: 0.120074  [ 6400/70070]
loss: 0.098419  [12800/70070]
loss: 0.309985  [19200/70070]
loss: 0.349193  [25600/70070]
loss: 0.110277  [32000/70070]
loss: 0.188590  [38400/70070]
loss: 0.323837  [44800/70070]
loss: 0.213919  [51200/70070]
loss: 0.156038  [57600/70070]
loss: 0.114988  [64000/70070]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.198298 

Epoch 36
-------------------------------
loss: 0.287835  [    0/70070]
loss: 0.312123  [ 6400/70070]
loss: 0.157272  [12800/70070]
loss: 0.230321  [19200/70070]
loss: 0.247710  [25600/70070]
loss: 0.113226  [32000/70070]
loss: 0.184966  [38400/70070]
loss: 0.144070  [44800/70070]
loss: 0.177251  [51200/70070]
loss: 0.285507  [57600/70070]
loss: 0.270959  [64000/70070]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.184474 

Epoch 37
-------------------------------
loss: 0.115648  [    0/70070]
loss: 0.195518  [ 6400/70070]
loss: 0.158769  [12800/70070]
loss: 0.174702  [19200/70070]
loss: 0.363399  [25600/70070]
loss: 0.219950  [32000/70070]
loss: 0.145034  [38400/70070]
loss: 0.201309  [44800/70070]
loss: 0.234839  [51200/70070]
loss: 0.146941  [57600/70070]
loss: 0.128931  [64000/70070]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.192555 

Epoch 38
-------------------------------
loss: 0.119254  [    0/70070]
loss: 0.175028  [ 6400/70070]
loss: 0.202703  [12800/70070]
loss: 0.234357  [19200/70070]
loss: 0.144212  [25600/70070]
loss: 0.132983  [32000/70070]
loss: 0.183844  [38400/70070]
loss: 0.231126  [44800/70070]
loss: 0.121693  [51200/70070]
loss: 0.207348  [57600/70070]
loss: 0.077758  [64000/70070]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.186322 

Epoch 39
-------------------------------
loss: 0.167865  [    0/70070]
loss: 0.254827  [ 6400/70070]
loss: 0.096146  [12800/70070]
loss: 0.198766  [19200/70070]
loss: 0.147009  [25600/70070]
loss: 0.106590  [32000/70070]
loss: 0.254423  [38400/70070]
loss: 0.184722  [44800/70070]
loss: 0.312816  [51200/70070]
loss: 0.157695  [57600/70070]
loss: 0.174582  [64000/70070]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.197749 

Epoch 40
-------------------------------
loss: 0.158940  [    0/70070]
loss: 0.113064  [ 6400/70070]
loss: 0.131455  [12800/70070]
loss: 0.100036  [19200/70070]
loss: 0.173962  [25600/70070]
loss: 0.109135  [32000/70070]
loss: 0.144495  [38400/70070]
loss: 0.128111  [44800/70070]
loss: 0.139093  [51200/70070]
loss: 0.161535  [57600/70070]
loss: 0.177582  [64000/70070]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.189547 

Epoch 41
-------------------------------
loss: 0.223980  [    0/70070]
loss: 0.261026  [ 6400/70070]
loss: 0.180168  [12800/70070]
loss: 0.144638  [19200/70070]
loss: 0.077005  [25600/70070]
loss: 0.187640  [32000/70070]
loss: 0.165730  [38400/70070]
loss: 0.177175  [44800/70070]
loss: 0.247273  [51200/70070]
loss: 0.151880  [57600/70070]
loss: 0.068587  [64000/70070]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.194972 

Epoch 42
-------------------------------
loss: 0.236287  [    0/70070]
loss: 0.256015  [ 6400/70070]
loss: 0.233326  [12800/70070]
loss: 0.116149  [19200/70070]
loss: 0.224388  [25600/70070]
loss: 0.171768  [32000/70070]
loss: 0.155462  [38400/70070]
loss: 0.191613  [44800/70070]
loss: 0.137523  [51200/70070]
loss: 0.283099  [57600/70070]
loss: 0.175378  [64000/70070]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.192485 

Epoch 43
-------------------------------
loss: 0.140601  [    0/70070]
loss: 0.246866  [ 6400/70070]
loss: 0.287468  [12800/70070]
loss: 0.157757  [19200/70070]
loss: 0.225910  [25600/70070]
loss: 0.115591  [32000/70070]
loss: 0.178831  [38400/70070]
loss: 0.228211  [44800/70070]
loss: 0.097881  [51200/70070]
loss: 0.254882  [57600/70070]
loss: 0.161043  [64000/70070]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.182219 

Epoch 44
-------------------------------
loss: 0.192153  [    0/70070]
loss: 0.223325  [ 6400/70070]
loss: 0.130304  [12800/70070]
loss: 0.113886  [19200/70070]
loss: 0.225503  [25600/70070]
loss: 0.192950  [32000/70070]
loss: 0.165751  [38400/70070]
loss: 0.139344  [44800/70070]
loss: 0.158314  [51200/70070]
loss: 0.083125  [57600/70070]
loss: 0.227489  [64000/70070]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.188818 

Epoch 45
-------------------------------
loss: 0.229364  [    0/70070]
loss: 0.211100  [ 6400/70070]
loss: 0.110350  [12800/70070]
loss: 0.153163  [19200/70070]
loss: 0.151600  [25600/70070]
loss: 0.170123  [32000/70070]
loss: 0.233286  [38400/70070]
loss: 0.173511  [44800/70070]
loss: 0.367349  [51200/70070]
loss: 0.224107  [57600/70070]
loss: 0.128411  [64000/70070]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.189278 

Epoch 46
-------------------------------
loss: 0.239926  [    0/70070]
loss: 0.163171  [ 6400/70070]
loss: 0.144126  [12800/70070]
loss: 0.090197  [19200/70070]
loss: 0.075848  [25600/70070]
loss: 0.246937  [32000/70070]
loss: 0.109587  [38400/70070]
loss: 0.317762  [44800/70070]
loss: 0.194258  [51200/70070]
loss: 0.182126  [57600/70070]
loss: 0.150153  [64000/70070]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.179805 

Epoch 47
-------------------------------
loss: 0.127209  [    0/70070]
loss: 0.268267  [ 6400/70070]
loss: 0.208052  [12800/70070]
loss: 0.178329  [19200/70070]
loss: 0.221119  [25600/70070]
loss: 0.063125  [32000/70070]
loss: 0.210694  [38400/70070]
loss: 0.115494  [44800/70070]
loss: 0.067394  [51200/70070]
loss: 0.159426  [57600/70070]
loss: 0.207387  [64000/70070]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.189289 

Epoch 48
-------------------------------
loss: 0.207888  [    0/70070]
loss: 0.230116  [ 6400/70070]
loss: 0.290514  [12800/70070]
loss: 0.216856  [19200/70070]
loss: 0.129047  [25600/70070]
loss: 0.274031  [32000/70070]
loss: 0.084793  [38400/70070]
loss: 0.170293  [44800/70070]
loss: 0.146731  [51200/70070]
loss: 0.209084  [57600/70070]
loss: 0.283367  [64000/70070]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.193065 

Epoch 49
-------------------------------
loss: 0.155036  [    0/70070]
loss: 0.222202  [ 6400/70070]
loss: 0.217843  [12800/70070]
loss: 0.148759  [19200/70070]
loss: 0.166698  [25600/70070]
loss: 0.243224  [32000/70070]
loss: 0.152774  [38400/70070]
loss: 0.176979  [44800/70070]
loss: 0.162425  [51200/70070]
loss: 0.180249  [57600/70070]
loss: 0.106433  [64000/70070]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.189931 

Epoch 50
-------------------------------
loss: 0.212647  [    0/70070]
loss: 0.268224  [ 6400/70070]
loss: 0.171666  [12800/70070]
loss: 0.110666  [19200/70070]
loss: 0.139976  [25600/70070]
loss: 0.111068  [32000/70070]
loss: 0.234647  [38400/70070]
loss: 0.156224  [44800/70070]
loss: 0.235788  [51200/70070]
loss: 0.172259  [57600/70070]
loss: 0.280914  [64000/70070]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.199652 

Epoch 1
-------------------------------
loss: 0.728212  [    0/71148]
loss: 0.262537  [ 6400/71148]
loss: 0.170436  [12800/71148]
loss: 0.185441  [19200/71148]
loss: 0.116771  [25600/71148]
loss: 0.321740  [32000/71148]
loss: 0.215020  [38400/71148]
loss: 0.135185  [44800/71148]
loss: 0.159158  [51200/71148]
loss: 0.128867  [57600/71148]
loss: 0.156586  [64000/71148]
loss: 0.156927  [70400/71148]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.185171 

Epoch 2
-------------------------------
loss: 0.141502  [    0/71148]
loss: 0.168176  [ 6400/71148]
loss: 0.237271  [12800/71148]
loss: 0.130795  [19200/71148]
loss: 0.136354  [25600/71148]
loss: 0.098648  [32000/71148]
loss: 1.741551  [38400/71148]
loss: 0.116163  [44800/71148]
loss: 0.231099  [51200/71148]
loss: 0.182728  [57600/71148]
loss: 0.213252  [64000/71148]
loss: 0.122993  [70400/71148]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.163273 

Epoch 3
-------------------------------
loss: 0.104085  [    0/71148]
loss: 0.130691  [ 6400/71148]
loss: 0.057929  [12800/71148]
loss: 0.105856  [19200/71148]
loss: 0.089537  [25600/71148]
loss: 0.160008  [51200/71653]
loss: 0.185780  [57600/71653]
loss: 0.100662  [64000/71653]
loss: 0.189703  [70400/71653]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.117495 

Epoch 47
-------------------------------
loss: 0.055499  [    0/71653]
loss: 0.093045  [ 6400/71653]
loss: 0.047062  [12800/71653]
loss: 0.101842  [19200/71653]
loss: 0.069663  [25600/71653]
loss: 0.111207  [32000/71653]
loss: 0.174982  [38400/71653]
loss: 0.065323  [44800/71653]
loss: 0.092587  [51200/71653]
loss: 0.027066  [57600/71653]
loss: 0.104330  [64000/71653]
loss: 0.057115  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.111633 

Epoch 48
-------------------------------
loss: 0.038424  [    0/71653]
loss: 0.131321  [ 6400/71653]
loss: 0.044078  [12800/71653]
loss: 0.029887  [19200/71653]
loss: 0.115239  [25600/71653]
loss: 0.030172  [32000/71653]
loss: 0.118023  [38400/71653]
loss: 0.102174  [44800/71653]
loss: 0.215341  [51200/71653]
loss: 0.112376  [57600/71653]
loss: 0.092299  [64000/71653]
loss: 0.119691  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.113256 

Epoch 49
-------------------------------
loss: 0.054798  [    0/71653]
loss: 0.040683  [ 6400/71653]
loss: 0.043471  [12800/71653]
loss: 0.021255  [19200/71653]
loss: 0.022856  [25600/71653]
loss: 0.058345  [32000/71653]
loss: 0.031241  [38400/71653]
loss: 0.069594  [44800/71653]
loss: 0.053765  [51200/71653]
loss: 0.076690  [57600/71653]
loss: 0.021285  [64000/71653]
loss: 0.091678  [70400/71653]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.113178 

Epoch 50
-------------------------------
loss: 0.018193  [    0/71653]
loss: 0.138502  [ 6400/71653]
loss: 0.082425  [12800/71653]
loss: 0.081935  [19200/71653]
loss: 0.057713  [25600/71653]
loss: 0.008576  [32000/71653]
loss: 0.069657  [38400/71653]
loss: 0.038330  [44800/71653]
loss: 0.103011  [51200/71653]
loss: 0.054080  [57600/71653]
loss: 0.054615  [64000/71653]
loss: 0.146979  [70400/71653]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.111124 

Epoch 1
-------------------------------
loss: 0.639390  [    0/71143]
loss: 0.148198  [ 6400/71143]
loss: 0.094564  [12800/71143]
loss: 0.201378  [19200/71143]
loss: 0.129499  [25600/71143]
loss: 0.163977  [32000/71143]
loss: 0.055463  [38400/71143]
loss: 0.146229  [44800/71143]
loss: 0.311041  [51200/71143]
loss: 0.124414  [57600/71143]
loss: 0.103532  [64000/71143]
loss: 0.127343  [70400/71143]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102598 

Epoch 2
-------------------------------
loss: 0.048676  [    0/71143]
loss: 0.101728  [ 6400/71143]
loss: 0.135803  [12800/71143]
loss: 0.120243  [19200/71143]
loss: 0.096394  [25600/71143]
loss: 0.111853  [32000/71143]
loss: 0.077444  [38400/71143]
loss: 0.134781  [44800/71143]
loss: 0.171118  [51200/71143]
loss: 0.177203  [57600/71143]
loss: 0.114988  [64000/71143]
loss: 0.154411  [70400/71143]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.088988 

Epoch 3
-------------------------------
loss: 0.044598  [    0/71143]
loss: 0.217629  [ 6400/71143]
loss: 0.116330  [12800/71143]
loss: 0.059114  [19200/71143]
loss: 0.053801  [25600/71143]
loss: 0.057771  [32000/71143]
loss: 0.255718  [38400/71143]
loss: 0.104062  [44800/71143]
loss: 0.069475  [51200/71143]
loss: 0.092543  [57600/71143]
loss: 0.216455  [64000/71143]
loss: 0.162173  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.086908 

Epoch 4
-------------------------------
loss: 0.098371  [    0/71143]
loss: 0.077545  [ 6400/71143]
loss: 0.045381  [12800/71143]
loss: 0.148873  [19200/71143]
loss: 0.104143  [25600/71143]
loss: 0.044265  [32000/71143]
loss: 0.035159  [38400/71143]
loss: 0.062095  [44800/71143]
loss: 0.033228  [51200/71143]
loss: 0.082614  [57600/71143]
loss: 0.132384  [64000/71143]
loss: 0.090668  [70400/71143]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.087627 

Epoch 5
-------------------------------
loss: 0.097825  [    0/71143]
loss: 0.103942  [ 6400/71143]
loss: 0.081734  [12800/71143]
loss: 0.046280  [19200/71143]
loss: 0.071341  [25600/71143]
loss: 0.220048  [32000/71143]
loss: 0.054567  [38400/71143]
loss: 0.129487  [44800/71143]
loss: 0.083524  [51200/71143]
loss: 0.065020  [57600/71143]
loss: 0.091889  [64000/71143]
loss: 0.149194  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.083223 

Epoch 6
-------------------------------
loss: 0.043940  [    0/71143]
loss: 0.043852  [ 6400/71143]
loss: 0.082351  [12800/71143]
loss: 0.168100  [19200/71143]
loss: 0.035971  [25600/71143]
loss: 0.071206  [32000/71143]
loss: 0.054561  [38400/71143]
loss: 0.052863  [44800/71143]
loss: 0.156525  [51200/71143]
loss: 0.156086  [57600/71143]
loss: 0.077153  [64000/71143]
loss: 0.042438  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.085323 

Epoch 7
-------------------------------
loss: 0.149405  [    0/71143]
loss: 0.029676  [ 6400/71143]
loss: 0.108384  [12800/71143]
loss: 0.032211  [19200/71143]
loss: 0.076735  [25600/71143]
loss: 0.152799  [32000/71143]
loss: 0.095594  [38400/71143]
loss: 0.055638  [44800/71143]
loss: 0.058480  [51200/71143]
loss: 0.040809  [57600/71143]
loss: 0.140265  [64000/71143]
loss: 0.057466  [70400/71143]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.080243 

Epoch 8
-------------------------------
loss: 0.089236  [    0/71143]
loss: 0.018123  [ 6400/71143]
loss: 0.088197  [12800/71143]
loss: 0.034794  [19200/71143]
loss: 0.088942  [25600/71143]
loss: 0.146704  [32000/71143]
loss: 0.037999  [38400/71143]
loss: 0.109541  [44800/71143]
loss: 0.066520  [51200/71143]
loss: 0.152801  [57600/71143]
loss: 0.028110  [64000/71143]
loss: 0.076855  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.079858 

Epoch 9
-------------------------------
loss: 0.023616  [    0/71143]
loss: 0.112354  [ 6400/71143]
loss: 0.098377  [12800/71143]
loss: 0.027367  [19200/71143]
loss: 0.075077  [25600/71143]
loss: 0.044081  [32000/71143]
loss: 0.061181  [38400/71143]
loss: 0.133604  [44800/71143]
loss: 0.086396  [51200/71143]
loss: 0.147523  [57600/71143]
loss: 0.086808  [64000/71143]
loss: 0.065888  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.080593 

Epoch 10
-------------------------------
loss: 0.096911  [    0/71143]
loss: 0.028005  [ 6400/71143]
loss: 0.120933  [12800/71143]
loss: 0.089213  [19200/71143]
loss: 0.042535  [25600/71143]
loss: 0.030514  [32000/71143]
loss: 0.062113  [38400/71143]
loss: 0.102973  [44800/71143]
loss: 0.105918  [51200/71143]
loss: 0.061486  [57600/71143]
loss: 0.171865  [64000/71143]
loss: 0.087838  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.078628 

Epoch 11
-------------------------------
loss: 0.134171  [    0/71143]
loss: 0.054977  [ 6400/71143]
loss: 0.062614  [12800/71143]
loss: 0.042948  [19200/71143]
loss: 0.054457  [25600/71143]
loss: 0.073349  [32000/71143]
loss: 0.107008  [38400/71143]
loss: 0.043744  [44800/71143]
loss: 0.053964  [51200/71143]
loss: 0.098048  [57600/71143]
loss: 0.186009  [64000/71143]
loss: 0.081092  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.078196 

Epoch 12
-------------------------------
loss: 0.142604  [    0/71143]
loss: 0.128582  [ 6400/71143]
loss: 0.071636  [12800/71143]
loss: 0.056553  [19200/71143]
loss: 0.008399  [25600/71143]
loss: 0.048528  [32000/71143]
loss: 0.120984  [38400/71143]
loss: 0.091130  [44800/71143]
loss: 0.138938  [51200/71143]
loss: 0.156759  [57600/71143]
loss: 0.027964  [64000/71143]
loss: 0.041046  [70400/71143]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.078882 

Epoch 13
-------------------------------
loss: 0.128179  [    0/71143]
loss: 0.085806  [ 6400/71143]
loss: 0.124331  [12800/71143]
loss: 0.052429  [19200/71143]
loss: 0.076985  [25600/71143]
loss: 0.052329  [32000/71143]
loss: 0.106351  [38400/71143]
loss: 0.148743  [44800/71143]
loss: 0.073940  [51200/71143]
loss: 0.064716  [57600/71143]
loss: 0.133540  [64000/71143]
loss: 0.124205  [70400/71143]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.081884 

Epoch 14
-------------------------------
loss: 0.089889  [    0/71143]
loss: 0.076059  [ 6400/71143]
loss: 0.079727  [12800/71143]
loss: 0.125940  [19200/71143]
loss: 0.140177  [25600/71143]
loss: 0.072019  [32000/71143]
loss: 0.086593  [38400/71143]
loss: 0.125427  [44800/71143]
loss: 0.134416  [51200/71143]
loss: 0.184742  [32000/69530]
loss: 0.187412  [38400/69530]
loss: 0.124813  [44800/69530]
loss: 0.121569  [51200/69530]
loss: 0.134674  [57600/69530]
loss: 0.096425  [64000/69530]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.176104 

Epoch 47
-------------------------------
loss: 0.216312  [    0/69530]
loss: 0.190233  [ 6400/69530]
loss: 0.129655  [12800/69530]
loss: 0.171872  [19200/69530]
loss: 0.073723  [25600/69530]
loss: 0.164255  [32000/69530]
loss: 0.134624  [38400/69530]
loss: 0.094129  [44800/69530]
loss: 0.188169  [51200/69530]
loss: 0.125819  [57600/69530]
loss: 0.109811  [64000/69530]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.177553 

Epoch 48
-------------------------------
loss: 0.112106  [    0/69530]
loss: 0.025882  [ 6400/69530]
loss: 0.123478  [12800/69530]
loss: 0.159613  [19200/69530]
loss: 0.229604  [25600/69530]
loss: 0.104555  [32000/69530]
loss: 0.128071  [38400/69530]
loss: 0.096775  [44800/69530]
loss: 0.151295  [51200/69530]
loss: 0.252405  [57600/69530]
loss: 0.160640  [64000/69530]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.188320 

Epoch 49
-------------------------------
loss: 0.079611  [    0/69530]
loss: 0.258796  [ 6400/69530]
loss: 0.122364  [12800/69530]
loss: 0.084114  [19200/69530]
loss: 0.131166  [25600/69530]
loss: 0.091613  [32000/69530]
loss: 0.137947  [38400/69530]
loss: 0.135482  [44800/69530]
loss: 0.132192  [51200/69530]
loss: 0.060038  [57600/69530]
loss: 0.187592  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.179005 

Epoch 50
-------------------------------
loss: 0.103470  [    0/69530]
loss: 0.152782  [ 6400/69530]
loss: 0.108337  [12800/69530]
loss: 0.371956  [19200/69530]
loss: 0.158267  [25600/69530]
loss: 0.075858  [32000/69530]
loss: 0.137891  [38400/69530]
loss: 0.117306  [44800/69530]
loss: 0.123995  [51200/69530]
loss: 0.212729  [57600/69530]
loss: 0.143354  [64000/69530]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.178042 

Epoch 1
-------------------------------
loss: 0.684805  [    0/70349]
loss: 0.117285  [ 6400/70349]
loss: 0.113414  [12800/70349]
loss: 0.146471  [19200/70349]
loss: 0.151934  [25600/70349]
loss: 0.117125  [32000/70349]
loss: 0.190690  [38400/70349]
loss: 0.112892  [44800/70349]
loss: 0.169199  [51200/70349]
loss: 0.206006  [57600/70349]
loss: 0.131409  [64000/70349]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.131446 

Epoch 2
-------------------------------
loss: 0.194669  [    0/70349]
loss: 0.033375  [ 6400/70349]
loss: 0.135293  [12800/70349]
loss: 0.139419  [19200/70349]
loss: 0.086823  [25600/70349]
loss: 0.136799  [32000/70349]
loss: 0.122175  [38400/70349]
loss: 0.034328  [44800/70349]
loss: 0.197987  [51200/70349]
loss: 0.070469  [57600/70349]
loss: 0.115510  [64000/70349]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.115340 

Epoch 3
-------------------------------
loss: 0.158205  [    0/70349]
loss: 0.116448  [ 6400/70349]
loss: 0.080371  [12800/70349]
loss: 0.176679  [19200/70349]
loss: 0.113044  [25600/70349]
loss: 0.081656  [32000/70349]
loss: 0.156671  [38400/70349]
loss: 0.207723  [44800/70349]
loss: 0.361725  [51200/70349]
loss: 0.183159  [57600/70349]
loss: 0.099184  [64000/70349]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.107854 

Epoch 4
-------------------------------
loss: 0.255154  [    0/70349]
loss: 0.086186  [ 6400/70349]
loss: 0.071996  [12800/70349]
loss: 0.128163  [19200/70349]
loss: 0.116519  [25600/70349]
loss: 0.093702  [32000/70349]
loss: 0.079492  [38400/70349]
loss: 0.100646  [44800/70349]
loss: 0.104704  [51200/70349]
loss: 0.134034  [57600/70349]
loss: 0.205714  [64000/70349]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.104935 

Epoch 5
-------------------------------
loss: 0.040850  [    0/70349]
loss: 0.084726  [ 6400/70349]
loss: 0.028189  [12800/70349]
loss: 0.180939  [19200/70349]
loss: 0.103340  [25600/70349]
loss: 0.051240  [32000/70349]
loss: 0.062501  [38400/70349]
loss: 0.147949  [44800/70349]
loss: 0.099659  [51200/70349]
loss: 0.043261  [57600/70349]
loss: 0.107008  [64000/70349]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.111355 

Epoch 6
-------------------------------
loss: 0.111164  [    0/70349]
loss: 0.079942  [ 6400/70349]
loss: 0.078050  [12800/70349]
loss: 0.135224  [19200/70349]
loss: 0.112346  [25600/70349]
loss: 0.234959  [32000/70349]
loss: 0.075960  [38400/70349]
loss: 0.147062  [44800/70349]
loss: 0.109172  [51200/70349]
loss: 0.136546  [57600/70349]
loss: 0.089884  [64000/70349]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.103949 

Epoch 7
-------------------------------
loss: 0.033769  [    0/70349]
loss: 0.044151  [ 6400/70349]
loss: 0.060421  [12800/70349]
loss: 0.145986  [19200/70349]
loss: 0.319015  [25600/70349]
loss: 0.052477  [32000/70349]
loss: 0.071588  [38400/70349]
loss: 0.079466  [44800/70349]
loss: 0.076793  [51200/70349]
loss: 0.184639  [57600/70349]
loss: 0.070865  [64000/70349]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.105383 

Epoch 8
-------------------------------
loss: 0.048936  [    0/70349]
loss: 0.138176  [ 6400/70349]
loss: 0.072639  [12800/70349]
loss: 0.117213  [19200/70349]
loss: 0.199567  [25600/70349]
loss: 0.080563  [32000/70349]
loss: 0.110812  [38400/70349]
loss: 0.051108  [44800/70349]
loss: 0.077227  [51200/70349]
loss: 0.046445  [57600/70349]
loss: 0.126327  [64000/70349]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095897 

Epoch 9
-------------------------------
loss: 0.053540  [    0/70349]
loss: 0.073732  [ 6400/70349]
loss: 0.176881  [12800/70349]
loss: 0.116517  [19200/70349]
loss: 0.059868  [25600/70349]
loss: 0.133359  [32000/70349]
loss: 0.074694  [38400/70349]
loss: 0.143892  [44800/70349]
loss: 0.100746  [51200/70349]
loss: 0.452586  [57600/70349]
loss: 0.172851  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099589 

Epoch 10
-------------------------------
loss: 0.088602  [    0/70349]
loss: 0.196717  [ 6400/70349]
loss: 0.114783  [12800/70349]
loss: 0.062958  [19200/70349]
loss: 0.162919  [25600/70349]
loss: 0.203983  [32000/70349]
loss: 0.104050  [38400/70349]
loss: 0.460129  [44800/70349]
loss: 0.175439  [51200/70349]
loss: 0.106031  [57600/70349]
loss: 0.064179  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.097960 

Epoch 11
-------------------------------
loss: 0.045822  [    0/70349]
loss: 0.033952  [ 6400/70349]
loss: 0.052413  [12800/70349]
loss: 0.060124  [19200/70349]
loss: 0.037078  [25600/70349]
loss: 0.170562  [32000/70349]
loss: 0.167093  [38400/70349]
loss: 0.137183  [44800/70349]
loss: 0.061376  [51200/70349]
loss: 0.133267  [57600/70349]
loss: 0.042462  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.103666 

Epoch 12
-------------------------------
loss: 0.111343  [    0/70349]
loss: 0.067997  [ 6400/70349]
loss: 0.069597  [12800/70349]
loss: 0.077872  [19200/70349]
loss: 0.087446  [25600/70349]
loss: 0.108252  [32000/70349]
loss: 0.103616  [38400/70349]
loss: 0.047940  [44800/70349]
loss: 0.129801  [51200/70349]
loss: 0.039465  [57600/70349]
loss: 0.068608  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.098670 

Epoch 13
-------------------------------
loss: 0.082424  [    0/70349]
loss: 0.153191  [ 6400/70349]
loss: 0.135512  [12800/70349]
loss: 0.137278  [19200/70349]
loss: 0.125754  [25600/70349]
loss: 0.180823  [32000/70349]
loss: 0.135775  [38400/70349]
loss: 0.151816  [44800/70349]
loss: 0.024918  [51200/70349]
loss: 0.078664  [57600/70349]
loss: 0.107518  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.104406 

Epoch 14
-------------------------------
loss: 0.095714  [    0/70349]
loss: 0.087668  [ 6400/70349]
loss: 0.067366  [12800/70349]
loss: 0.042887  [19200/70349]
loss: 0.061242  [25600/70349]
loss: 0.082640  [32000/70349]
loss: 0.078385  [38400/70349]
loss: 0.059128  [44800/70349]
loss: 0.170341  [51200/70349]
loss: 0.049061  [57600/70349]
loss: 0.031610  [64000/70349]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102489 

Epoch 15
-------------------------------
loss: 0.177921  [    0/70349]
loss: 0.153136  [ 6400/70349]
loss: 0.113967  [12800/70349]
loss: 0.150099  [19200/70349]
loss: 0.054562  [25600/70349]
loss: 0.088050  [32000/70349]
loss: 0.102414  [38400/70349]
loss: 0.076477  [44800/70349]
loss: 0.060990  [51200/70349]
loss: 0.094875  [57600/70349]
loss: 0.043077  [19200/69274]
loss: 0.087539  [25600/69274]
loss: 0.244638  [32000/69274]
loss: 0.071309  [38400/69274]
loss: 0.275381  [44800/69274]
loss: 0.120715  [51200/69274]
loss: 0.080433  [57600/69274]
loss: 0.301264  [64000/69274]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.189449 

Epoch 47
-------------------------------
loss: 0.221411  [    0/69274]
loss: 0.124229  [ 6400/69274]
loss: 0.078768  [12800/69274]
loss: 0.089837  [19200/69274]
loss: 0.192767  [25600/69274]
loss: 0.096886  [32000/69274]
loss: 0.233728  [38400/69274]
loss: 0.177186  [44800/69274]
loss: 0.076362  [51200/69274]
loss: 0.099271  [57600/69274]
loss: 0.094148  [64000/69274]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.206593 

Epoch 48
-------------------------------
loss: 0.076028  [    0/69274]
loss: 0.220574  [ 6400/69274]
loss: 0.187392  [12800/69274]
loss: 0.183482  [19200/69274]
loss: 0.051481  [25600/69274]
loss: 0.117261  [32000/69274]
loss: 0.151530  [38400/69274]
loss: 0.060110  [44800/69274]
loss: 0.048027  [51200/69274]
loss: 0.126976  [57600/69274]
loss: 1.679477  [64000/69274]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.173641 

Epoch 49
-------------------------------
loss: 0.169114  [    0/69274]
loss: 0.140216  [ 6400/69274]
loss: 0.137090  [12800/69274]
loss: 0.146892  [19200/69274]
loss: 0.063967  [25600/69274]
loss: 0.258442  [32000/69274]
loss: 0.178412  [38400/69274]
loss: 0.155915  [44800/69274]
loss: 0.263084  [51200/69274]
loss: 0.077763  [57600/69274]
loss: 0.092087  [64000/69274]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.169735 

Epoch 50
-------------------------------
loss: 0.193184  [    0/69274]
loss: 0.183783  [ 6400/69274]
loss: 0.119511  [12800/69274]
loss: 0.135364  [19200/69274]
loss: 0.218599  [25600/69274]
loss: 0.166040  [32000/69274]
loss: 0.131702  [38400/69274]
loss: 0.183500  [44800/69274]
loss: 0.109779  [51200/69274]
loss: 0.180637  [57600/69274]
loss: 0.195659  [64000/69274]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.174310 

Epoch 1
-------------------------------
loss: 0.730572  [    0/71103]
loss: 0.176005  [ 6400/71103]
loss: 0.130619  [12800/71103]
loss: 0.187603  [19200/71103]
loss: 0.072740  [25600/71103]
loss: 0.047506  [32000/71103]
loss: 0.071609  [38400/71103]
loss: 0.040061  [44800/71103]
loss: 0.144332  [51200/71103]
loss: 0.140629  [57600/71103]
loss: 0.124116  [64000/71103]
loss: 0.042728  [70400/71103]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.104076 

Epoch 2
-------------------------------
loss: 0.208755  [    0/71103]
loss: 0.098255  [ 6400/71103]
loss: 0.061280  [12800/71103]
loss: 0.169777  [19200/71103]
loss: 0.133555  [25600/71103]
loss: 0.151512  [32000/71103]
loss: 0.094469  [38400/71103]
loss: 0.110025  [44800/71103]
loss: 0.024880  [51200/71103]
loss: 0.128916  [57600/71103]
loss: 0.077371  [64000/71103]
loss: 0.055300  [70400/71103]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.089350 

Epoch 3
-------------------------------
loss: 0.136699  [    0/71103]
loss: 0.116012  [ 6400/71103]
loss: 0.048982  [12800/71103]
loss: 0.042761  [19200/71103]
loss: 0.101824  [25600/71103]
loss: 0.090130  [32000/71103]
loss: 0.087376  [38400/71103]
loss: 0.065655  [44800/71103]
loss: 0.081573  [51200/71103]
loss: 0.132741  [57600/71103]
loss: 0.021603  [64000/71103]
loss: 0.094509  [70400/71103]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.090320 

Epoch 4
-------------------------------
loss: 0.054497  [    0/71103]
loss: 0.055030  [ 6400/71103]
loss: 0.116637  [12800/71103]
loss: 0.153645  [19200/71103]
loss: 0.332767  [25600/71103]
loss: 0.122039  [32000/71103]
loss: 0.041257  [38400/71103]
loss: 0.050649  [44800/71103]
loss: 0.071588  [51200/71103]
loss: 0.200297  [57600/71103]
loss: 0.113967  [64000/71103]
loss: 0.161044  [70400/71103]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.086731 

Epoch 5
-------------------------------
loss: 0.064428  [    0/71103]
loss: 0.113778  [ 6400/71103]
loss: 0.129583  [12800/71103]
loss: 0.139506  [19200/71103]
loss: 0.133234  [25600/71103]
loss: 0.086897  [32000/71103]
loss: 0.045647  [38400/71103]
loss: 0.057900  [44800/71103]
loss: 0.091948  [51200/71103]
loss: 0.093231  [57600/71103]
loss: 0.086714  [64000/71103]
loss: 0.113960  [70400/71103]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.087873 

Epoch 6
-------------------------------
loss: 0.143365  [    0/71103]
loss: 0.122086  [ 6400/71103]
loss: 0.033926  [12800/71103]
loss: 0.059448  [19200/71103]
loss: 0.089346  [25600/71103]
loss: 0.031192  [32000/71103]
loss: 0.182044  [38400/71103]
loss: 0.156494  [44800/71103]
loss: 0.040481  [51200/71103]
loss: 0.068011  [57600/71103]
loss: 0.060671  [64000/71103]
loss: 0.140140  [70400/71103]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.097030 

Epoch 7
-------------------------------
loss: 0.057968  [    0/71103]
loss: 0.015107  [ 6400/71103]
loss: 0.026928  [12800/71103]
loss: 0.066142  [19200/71103]
loss: 0.160749  [25600/71103]
loss: 0.079164  [32000/71103]
loss: 0.100189  [38400/71103]
loss: 0.137239  [44800/71103]
loss: 0.021828  [51200/71103]
loss: 0.072899  [57600/71103]
loss: 0.081052  [64000/71103]
loss: 0.136344  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.084604 

Epoch 8
-------------------------------
loss: 0.078197  [    0/71103]
loss: 0.101905  [ 6400/71103]
loss: 0.024972  [12800/71103]
loss: 0.072775  [19200/71103]
loss: 0.066420  [25600/71103]
loss: 0.039146  [32000/71103]
loss: 0.028041  [38400/71103]
loss: 0.131659  [44800/71103]
loss: 0.159164  [51200/71103]
loss: 0.113589  [57600/71103]
loss: 0.040124  [64000/71103]
loss: 0.051039  [70400/71103]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.098162 

Epoch 9
-------------------------------
loss: 0.048588  [    0/71103]
loss: 0.023342  [ 6400/71103]
loss: 0.078322  [12800/71103]
loss: 0.080281  [19200/71103]
loss: 0.033242  [25600/71103]
loss: 0.006720  [32000/71103]
loss: 0.123879  [38400/71103]
loss: 0.120172  [44800/71103]
loss: 0.069831  [51200/71103]
loss: 0.028107  [57600/71103]
loss: 0.069467  [64000/71103]
loss: 0.045482  [70400/71103]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.087243 

Epoch 10
-------------------------------
loss: 0.037548  [    0/71103]
loss: 0.022567  [ 6400/71103]
loss: 0.013461  [12800/71103]
loss: 0.125034  [19200/71103]
loss: 0.112487  [25600/71103]
loss: 0.019384  [32000/71103]
loss: 0.062095  [38400/71103]
loss: 0.082879  [44800/71103]
loss: 0.060626  [51200/71103]
loss: 0.083030  [57600/71103]
loss: 0.073657  [64000/71103]
loss: 0.085694  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.085421 

Epoch 11
-------------------------------
loss: 0.055588  [    0/71103]
loss: 0.034615  [ 6400/71103]
loss: 0.041126  [12800/71103]
loss: 0.061654  [19200/71103]
loss: 0.110981  [25600/71103]
loss: 0.126158  [32000/71103]
loss: 0.066073  [38400/71103]
loss: 0.044326  [44800/71103]
loss: 0.078585  [51200/71103]
loss: 0.199701  [57600/71103]
loss: 0.060852  [64000/71103]
loss: 0.026494  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.086465 

Epoch 12
-------------------------------
loss: 0.018558  [    0/71103]
loss: 0.064565  [ 6400/71103]
loss: 0.072698  [12800/71103]
loss: 0.032954  [19200/71103]
loss: 0.168398  [25600/71103]
loss: 0.067358  [32000/71103]
loss: 0.074145  [38400/71103]
loss: 0.048704  [44800/71103]
loss: 0.128724  [51200/71103]
loss: 0.089679  [57600/71103]
loss: 0.029675  [64000/71103]
loss: 0.048135  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.085182 

Epoch 13
-------------------------------
loss: 0.111453  [    0/71103]
loss: 0.113871  [ 6400/71103]
loss: 0.075543  [12800/71103]
loss: 0.068364  [19200/71103]
loss: 0.089947  [25600/71103]
loss: 0.153648  [32000/71103]
loss: 0.024420  [38400/71103]
loss: 0.022766  [44800/71103]
loss: 0.053749  [51200/71103]
loss: 0.056820  [57600/71103]
loss: 0.102307  [64000/71103]
loss: 0.054104  [70400/71103]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.083622 

Epoch 14
-------------------------------
loss: 0.073642  [    0/71103]
loss: 0.148596  [ 6400/71103]
loss: 0.104527  [12800/71103]
loss: 0.038412  [19200/71103]
loss: 0.222869  [25600/71103]
loss: 0.092762  [32000/71103]
loss: 0.037981  [38400/71103]
loss: 0.077698  [44800/71103]
loss: 0.068484  [51200/71103]
loss: 0.138399  [32000/72195]
loss: 0.046951  [38400/72195]
loss: 0.021658  [44800/72195]
loss: 0.054820  [51200/72195]
loss: 0.030411  [57600/72195]
loss: 0.146380  [64000/72195]
loss: 0.053859  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.071924 

Epoch 4
-------------------------------
loss: 0.010580  [    0/72195]
loss: 0.058796  [ 6400/72195]
loss: 0.080088  [12800/72195]
loss: 0.051401  [19200/72195]
loss: 0.027358  [25600/72195]
loss: 0.073838  [32000/72195]
loss: 0.030671  [38400/72195]
loss: 0.006496  [44800/72195]
loss: 0.056102  [51200/72195]
loss: 0.027630  [57600/72195]
loss: 0.043330  [64000/72195]
loss: 0.012621  [70400/72195]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.073749 

Epoch 5
-------------------------------
loss: 0.044738  [    0/72195]
loss: 0.126614  [ 6400/72195]
loss: 0.048578  [12800/72195]
loss: 0.053615  [19200/72195]
loss: 0.011211  [25600/72195]
loss: 0.060299  [32000/72195]
loss: 0.047404  [38400/72195]
loss: 0.109651  [44800/72195]
loss: 0.194966  [51200/72195]
loss: 0.148139  [57600/72195]
loss: 0.015349  [64000/72195]
loss: 0.203038  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073356 

Epoch 6
-------------------------------
loss: 0.015076  [    0/72195]
loss: 0.012697  [ 6400/72195]
loss: 0.028906  [12800/72195]
loss: 0.016671  [19200/72195]
loss: 0.081809  [25600/72195]
loss: 0.097909  [32000/72195]
loss: 0.009640  [38400/72195]
loss: 0.039680  [44800/72195]
loss: 0.097189  [51200/72195]
loss: 0.059790  [57600/72195]
loss: 0.025603  [64000/72195]
loss: 0.061102  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069212 

Epoch 7
-------------------------------
loss: 0.014886  [    0/72195]
loss: 0.002969  [ 6400/72195]
loss: 0.009255  [12800/72195]
loss: 0.014935  [19200/72195]
loss: 0.022448  [25600/72195]
loss: 0.022659  [32000/72195]
loss: 0.010689  [38400/72195]
loss: 0.162714  [44800/72195]
loss: 0.021309  [51200/72195]
loss: 0.057642  [57600/72195]
loss: 0.025021  [64000/72195]
loss: 0.052962  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069236 

Epoch 8
-------------------------------
loss: 0.067395  [    0/72195]
loss: 0.020818  [ 6400/72195]
loss: 0.070691  [12800/72195]
loss: 0.087323  [19200/72195]
loss: 0.045817  [25600/72195]
loss: 0.008062  [32000/72195]
loss: 0.118551  [38400/72195]
loss: 0.044625  [44800/72195]
loss: 0.055019  [51200/72195]
loss: 0.022476  [57600/72195]
loss: 0.053497  [64000/72195]
loss: 0.102725  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067951 

Epoch 9
-------------------------------
loss: 0.023107  [    0/72195]
loss: 0.178689  [ 6400/72195]
loss: 0.014948  [12800/72195]
loss: 0.045374  [19200/72195]
loss: 0.063630  [25600/72195]
loss: 0.058917  [32000/72195]
loss: 0.050098  [38400/72195]
loss: 0.017392  [44800/72195]
loss: 0.016837  [51200/72195]
loss: 0.047040  [57600/72195]
loss: 0.103050  [64000/72195]
loss: 0.103800  [70400/72195]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.067209 

Epoch 10
-------------------------------
loss: 0.090882  [    0/72195]
loss: 0.009571  [ 6400/72195]
loss: 0.086838  [12800/72195]
loss: 0.063822  [19200/72195]
loss: 0.052649  [25600/72195]
loss: 0.007986  [32000/72195]
loss: 0.033611  [38400/72195]
loss: 0.025310  [44800/72195]
loss: 0.020970  [51200/72195]
loss: 0.031541  [57600/72195]
loss: 0.031825  [64000/72195]
loss: 0.018622  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.066851 

Epoch 11
-------------------------------
loss: 0.066128  [    0/72195]
loss: 0.030611  [ 6400/72195]
loss: 0.023953  [12800/72195]
loss: 0.077929  [19200/72195]
loss: 0.054714  [25600/72195]
loss: 0.054707  [32000/72195]
loss: 0.015645  [38400/72195]
loss: 0.027588  [44800/72195]
loss: 0.025470  [51200/72195]
loss: 0.023064  [57600/72195]
loss: 0.098620  [64000/72195]
loss: 0.022723  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.067303 

Epoch 12
-------------------------------
loss: 0.007520  [    0/72195]
loss: 0.026096  [ 6400/72195]
loss: 0.015821  [12800/72195]
loss: 0.057321  [19200/72195]
loss: 0.027421  [25600/72195]
loss: 0.005031  [32000/72195]
loss: 0.033106  [38400/72195]
loss: 0.024660  [44800/72195]
loss: 0.011025  [51200/72195]
loss: 0.047671  [57600/72195]
loss: 0.063213  [64000/72195]
loss: 0.089661  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068797 

Epoch 13
-------------------------------
loss: 0.025734  [    0/72195]
loss: 0.058396  [ 6400/72195]
loss: 0.009213  [12800/72195]
loss: 0.056743  [19200/72195]
loss: 0.074212  [25600/72195]
loss: 0.060447  [32000/72195]
loss: 0.033102  [38400/72195]
loss: 0.060627  [44800/72195]
loss: 0.061881  [51200/72195]
loss: 0.014089  [57600/72195]
loss: 0.021743  [64000/72195]
loss: 0.210934  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071159 

Epoch 14
-------------------------------
loss: 0.063886  [    0/72195]
loss: 0.002012  [ 6400/72195]
loss: 0.086441  [12800/72195]
loss: 0.005241  [19200/72195]
loss: 0.186048  [25600/72195]
loss: 0.043794  [32000/72195]
loss: 0.008801  [38400/72195]
loss: 0.080832  [44800/72195]
loss: 0.022124  [51200/72195]
loss: 0.050842  [57600/72195]
loss: 0.029196  [64000/72195]
loss: 0.015182  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073199 

Epoch 15
-------------------------------
loss: 0.033277  [    0/72195]
loss: 0.040619  [ 6400/72195]
loss: 0.033521  [12800/72195]
loss: 0.008791  [19200/72195]
loss: 0.040386  [25600/72195]
loss: 0.009481  [32000/72195]
loss: 0.028924  [38400/72195]
loss: 0.020197  [44800/72195]
loss: 0.032469  [51200/72195]
loss: 0.042967  [57600/72195]
loss: 0.017024  [64000/72195]
loss: 0.015137  [70400/72195]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.067627 

Epoch 16
-------------------------------
loss: 0.029676  [    0/72195]
loss: 0.015762  [ 6400/72195]
loss: 0.050112  [12800/72195]
loss: 0.003677  [19200/72195]
loss: 0.090917  [25600/72195]
loss: 0.037344  [32000/72195]
loss: 0.041575  [38400/72195]
loss: 0.037997  [44800/72195]
loss: 0.004631  [51200/72195]
loss: 0.058838  [57600/72195]
loss: 0.016325  [64000/72195]
loss: 0.022397  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.071084 

Epoch 17
-------------------------------
loss: 0.003166  [    0/72195]
loss: 0.014112  [ 6400/72195]
loss: 0.128350  [12800/72195]
loss: 0.073593  [19200/72195]
loss: 0.046351  [25600/72195]
loss: 0.026750  [32000/72195]
loss: 0.050021  [38400/72195]
loss: 0.051691  [44800/72195]
loss: 0.032209  [51200/72195]
loss: 0.012062  [57600/72195]
loss: 0.022188  [64000/72195]
loss: 0.013280  [70400/72195]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.067560 

Epoch 18
-------------------------------
loss: 0.015778  [    0/72195]
loss: 0.011350  [ 6400/72195]
loss: 0.015094  [12800/72195]
loss: 0.015939  [19200/72195]
loss: 0.007082  [25600/72195]
loss: 0.024850  [32000/72195]
loss: 0.012488  [38400/72195]
loss: 0.052234  [44800/72195]
loss: 0.009718  [51200/72195]
loss: 0.012647  [57600/72195]
loss: 0.034425  [64000/72195]
loss: 0.072104  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.068250 

Epoch 19
-------------------------------
loss: 0.035078  [    0/72195]
loss: 0.014747  [ 6400/72195]
loss: 0.009426  [12800/72195]
loss: 0.011639  [19200/72195]
loss: 0.111859  [25600/72195]
loss: 0.037924  [32000/72195]
loss: 0.022032  [38400/72195]
loss: 0.065401  [44800/72195]
loss: 0.002663  [51200/72195]
loss: 0.048067  [57600/72195]
loss: 0.002550  [64000/72195]
loss: 0.027218  [70400/72195]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.075490 

Epoch 20
-------------------------------
loss: 0.097258  [    0/72195]
loss: 0.028231  [ 6400/72195]
loss: 0.024559  [12800/72195]
loss: 0.014331  [19200/72195]
loss: 0.026242  [25600/72195]
loss: 0.114579  [32000/72195]
loss: 0.008407  [38400/72195]
loss: 0.012700  [44800/72195]
loss: 0.002934  [51200/72195]
loss: 0.046694  [57600/72195]
loss: 0.014826  [64000/72195]
loss: 0.039573  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071356 

Epoch 21
-------------------------------
loss: 0.048280  [    0/72195]
loss: 0.005814  [ 6400/72195]
loss: 0.015129  [12800/72195]
loss: 0.029688  [19200/72195]
loss: 0.028524  [25600/72195]
loss: 0.017725  [32000/72195]
loss: 0.078697  [32000/69713]
loss: 0.197096  [38400/69713]
loss: 0.092213  [44800/69713]
loss: 0.170583  [51200/69713]
loss: 0.096315  [57600/69713]
loss: 0.376332  [64000/69713]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.168269 

Epoch 9
-------------------------------
loss: 0.207414  [    0/69713]
loss: 0.150004  [ 6400/69713]
loss: 0.223436  [12800/69713]
loss: 0.143011  [19200/69713]
loss: 0.201560  [25600/69713]
loss: 0.091342  [32000/69713]
loss: 0.204952  [38400/69713]
loss: 0.086573  [44800/69713]
loss: 0.187865  [51200/69713]
loss: 0.165594  [57600/69713]
loss: 0.104563  [64000/69713]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.191129 

Epoch 10
-------------------------------
loss: 0.078169  [    0/69713]
loss: 0.232407  [ 6400/69713]
loss: 0.174145  [12800/69713]
loss: 0.131510  [19200/69713]
loss: 0.154849  [25600/69713]
loss: 0.047360  [32000/69713]
loss: 0.124890  [38400/69713]
loss: 0.221132  [44800/69713]
loss: 0.197936  [51200/69713]
loss: 0.272361  [57600/69713]
loss: 0.167769  [64000/69713]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.208761 

Epoch 11
-------------------------------
loss: 0.105454  [    0/69713]
loss: 0.113296  [ 6400/69713]
loss: 0.120178  [12800/69713]
loss: 0.107504  [19200/69713]
loss: 0.146864  [25600/69713]
loss: 0.179211  [32000/69713]
loss: 0.133414  [38400/69713]
loss: 0.146804  [44800/69713]
loss: 0.214698  [51200/69713]
loss: 0.243763  [57600/69713]
loss: 0.150661  [64000/69713]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.173070 

Epoch 12
-------------------------------
loss: 0.152503  [    0/69713]
loss: 0.098519  [ 6400/69713]
loss: 0.218626  [12800/69713]
loss: 0.132913  [19200/69713]
loss: 0.115283  [25600/69713]
loss: 0.091619  [32000/69713]
loss: 0.194954  [38400/69713]
loss: 0.071786  [44800/69713]
loss: 0.078885  [51200/69713]
loss: 0.256557  [57600/69713]
loss: 0.078865  [64000/69713]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.172150 

Epoch 13
-------------------------------
loss: 0.153548  [    0/69713]
loss: 0.135716  [ 6400/69713]
loss: 0.107168  [12800/69713]
loss: 0.169241  [19200/69713]
loss: 0.174886  [25600/69713]
loss: 0.235913  [32000/69713]
loss: 0.076195  [38400/69713]
loss: 0.333435  [44800/69713]
loss: 0.162136  [51200/69713]
loss: 0.100756  [57600/69713]
loss: 0.163353  [64000/69713]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.173184 

Epoch 14
-------------------------------
loss: 0.134859  [    0/69713]
loss: 0.161197  [ 6400/69713]
loss: 0.077444  [12800/69713]
loss: 0.221542  [19200/69713]
loss: 0.128519  [25600/69713]
loss: 0.309239  [32000/69713]
loss: 0.189678  [38400/69713]
loss: 0.116053  [44800/69713]
loss: 0.199776  [51200/69713]
loss: 0.150063  [57600/69713]
loss: 0.124431  [64000/69713]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.174629 

Epoch 15
-------------------------------
loss: 0.108194  [    0/69713]
loss: 0.136129  [ 6400/69713]
loss: 0.170770  [12800/69713]
loss: 0.139467  [19200/69713]
loss: 0.094067  [25600/69713]
loss: 0.193029  [32000/69713]
loss: 0.137037  [38400/69713]
loss: 0.142016  [44800/69713]
loss: 0.099814  [51200/69713]
loss: 0.175082  [57600/69713]
loss: 0.106011  [64000/69713]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.178292 

Epoch 16
-------------------------------
loss: 0.128601  [    0/69713]
loss: 0.193097  [ 6400/69713]
loss: 0.091010  [12800/69713]
loss: 0.100992  [19200/69713]
loss: 0.233639  [25600/69713]
loss: 0.179480  [32000/69713]
loss: 0.265922  [38400/69713]
loss: 0.055599  [44800/69713]
loss: 0.203509  [51200/69713]
loss: 0.044016  [57600/69713]
loss: 0.159802  [64000/69713]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.173102 

Epoch 17
-------------------------------
loss: 0.125961  [    0/69713]
loss: 0.113018  [ 6400/69713]
loss: 0.109922  [12800/69713]
loss: 0.115342  [19200/69713]
loss: 0.103475  [25600/69713]
loss: 0.098334  [32000/69713]
loss: 0.181547  [38400/69713]
loss: 0.189982  [44800/69713]
loss: 0.083218  [51200/69713]
loss: 0.117325  [57600/69713]
loss: 0.181379  [64000/69713]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.168079 

Epoch 18
-------------------------------
loss: 0.138183  [    0/69713]
loss: 0.132104  [ 6400/69713]
loss: 0.117951  [12800/69713]
loss: 0.129837  [19200/69713]
loss: 0.119876  [25600/69713]
loss: 0.146578  [32000/69713]
loss: 0.191595  [38400/69713]
loss: 0.151029  [44800/69713]
loss: 0.172927  [51200/69713]
loss: 0.126758  [57600/69713]
loss: 0.254539  [64000/69713]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.224723 

Epoch 19
-------------------------------
loss: 0.123223  [    0/69713]
loss: 0.166909  [ 6400/69713]
loss: 0.188966  [12800/69713]
loss: 0.213830  [19200/69713]
loss: 0.162312  [25600/69713]
loss: 0.148684  [32000/69713]
loss: 0.251067  [38400/69713]
loss: 0.115598  [44800/69713]
loss: 0.081484  [51200/69713]
loss: 0.106439  [57600/69713]
loss: 0.288269  [64000/69713]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.167333 

Epoch 20
-------------------------------
loss: 0.081133  [    0/69713]
loss: 0.073098  [ 6400/69713]
loss: 0.084514  [12800/69713]
loss: 0.119271  [19200/69713]
loss: 0.100091  [25600/69713]
loss: 0.222955  [32000/69713]
loss: 0.145477  [38400/69713]
loss: 0.143678  [44800/69713]
loss: 0.182027  [51200/69713]
loss: 0.118100  [57600/69713]
loss: 0.211436  [64000/69713]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.177223 

Epoch 21
-------------------------------
loss: 0.109281  [    0/69713]
loss: 0.098318  [ 6400/69713]
loss: 0.081724  [12800/69713]
loss: 0.078674  [19200/69713]
loss: 0.140017  [25600/69713]
loss: 0.170469  [32000/69713]
loss: 0.075737  [38400/69713]
loss: 0.319006  [44800/69713]
loss: 0.164047  [51200/69713]
loss: 0.118557  [57600/69713]
loss: 0.175414  [64000/69713]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.164062 

Epoch 22
-------------------------------
loss: 0.171014  [    0/69713]
loss: 0.121936  [ 6400/69713]
loss: 0.209783  [12800/69713]
loss: 0.137680  [19200/69713]
loss: 0.089934  [25600/69713]
loss: 0.212061  [32000/69713]
loss: 0.089905  [38400/69713]
loss: 0.126586  [44800/69713]
loss: 0.194705  [51200/69713]
loss: 1.611930  [57600/69713]
loss: 0.132989  [64000/69713]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.167396 

Epoch 23
-------------------------------
loss: 0.118977  [    0/69713]
loss: 0.190328  [ 6400/69713]
loss: 0.196019  [12800/69713]
loss: 0.285093  [19200/69713]
loss: 0.094328  [25600/69713]
loss: 0.154329  [32000/69713]
loss: 0.417744  [38400/69713]
loss: 0.197430  [44800/69713]
loss: 0.185162  [51200/69713]
loss: 0.222861  [57600/69713]
loss: 0.144472  [64000/69713]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.171662 

Epoch 24
-------------------------------
loss: 0.122741  [    0/69713]
loss: 0.099053  [ 6400/69713]
loss: 0.127153  [12800/69713]
loss: 0.131699  [19200/69713]
loss: 0.115847  [25600/69713]
loss: 0.054702  [32000/69713]
loss: 0.098976  [38400/69713]
loss: 0.095623  [44800/69713]
loss: 0.155826  [51200/69713]
loss: 0.085117  [57600/69713]
loss: 0.107828  [64000/69713]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.181952 

Epoch 25
-------------------------------
loss: 0.150865  [    0/69713]
loss: 0.156234  [ 6400/69713]
loss: 0.251296  [12800/69713]
loss: 0.055900  [19200/69713]
loss: 0.101295  [25600/69713]
loss: 0.136441  [32000/69713]
loss: 0.148817  [38400/69713]
loss: 0.378609  [44800/69713]
loss: 0.158290  [51200/69713]
loss: 0.103219  [57600/69713]
loss: 0.163170  [64000/69713]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162378 

Epoch 26
-------------------------------
loss: 0.179431  [    0/69713]
loss: 0.098787  [ 6400/69713]
loss: 0.248152  [12800/69713]
loss: 0.124789  [19200/69713]
loss: 0.086087  [25600/69713]
loss: 0.129633  [32000/69713]
loss: 0.136630  [38400/69713]
loss: 0.110174  [44800/69713]
loss: 0.222816  [51200/69713]
loss: 0.141934  [57600/69713]
loss: 0.033475  [64000/69713]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.173542 

Epoch 27
-------------------------------
loss: 0.181918  [    0/69713]
loss: 0.193611  [ 6400/69713]
loss: 0.068306  [12800/69713]
loss: 0.169738  [19200/69713]
loss: 0.127176  [25600/69713]
loss: 0.163189  [32000/69713]
loss: 0.168920  [38400/69713]
loss: 0.101645  [44800/69713]
loss: 0.101641  [51200/69713]
loss: 0.105409  [57600/69713]
2022/09/20 18:48:38 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.171232 

Epoch 50
-------------------------------
loss: 0.128669  [    0/70852]
loss: 0.100281  [ 6400/70852]
loss: 0.079177  [12800/70852]
loss: 0.245221  [19200/70852]
loss: 0.114316  [25600/70852]
loss: 0.111781  [32000/70852]
loss: 0.047051  [38400/70852]
loss: 0.078711  [44800/70852]
loss: 0.121102  [51200/70852]
loss: 0.067062  [57600/70852]
loss: 0.086197  [64000/70852]
loss: 0.077192  [70400/70852]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.165492 

Epoch 1
-------------------------------
loss: 0.687350  [    0/69810]
loss: 0.308366  [ 6400/69810]
loss: 0.097914  [12800/69810]
loss: 0.096958  [19200/69810]
loss: 0.210458  [25600/69810]
loss: 0.144486  [32000/69810]
loss: 0.173989  [38400/69810]
loss: 0.053326  [44800/69810]
loss: 0.132211  [51200/69810]
loss: 0.149365  [57600/69810]
loss: 0.135878  [64000/69810]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.108682 

Epoch 2
-------------------------------
loss: 0.138902  [    0/69810]
loss: 0.188085  [ 6400/69810]
loss: 0.071729  [12800/69810]
loss: 0.089426  [19200/69810]
loss: 0.124552  [25600/69810]
loss: 0.062791  [32000/69810]
loss: 0.132755  [38400/69810]
loss: 0.074895  [44800/69810]
loss: 0.050688  [51200/69810]
loss: 0.224834  [57600/69810]
loss: 0.128139  [64000/69810]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.103259 

Epoch 3
-------------------------------
loss: 0.128119  [    0/69810]
loss: 0.183282  [ 6400/69810]
loss: 0.094154  [12800/69810]
loss: 0.127366  [19200/69810]
loss: 0.317429  [25600/69810]
loss: 0.117326  [32000/69810]
loss: 0.185221  [38400/69810]
loss: 0.111430  [44800/69810]
loss: 0.172694  [51200/69810]
loss: 0.105360  [57600/69810]
loss: 0.047383  [64000/69810]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101343 

Epoch 4
-------------------------------
loss: 0.182094  [    0/69810]
loss: 0.102033  [ 6400/69810]
loss: 0.082260  [12800/69810]
loss: 0.132753  [19200/69810]
loss: 0.103130  [25600/69810]
loss: 0.049196  [32000/69810]
loss: 0.039708  [38400/69810]
loss: 0.151604  [44800/69810]
loss: 0.056293  [51200/69810]
loss: 0.230490  [57600/69810]
loss: 0.091673  [64000/69810]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.106427 

Epoch 5
-------------------------------
loss: 0.119869  [    0/69810]
loss: 0.067906  [ 6400/69810]
loss: 0.058843  [12800/69810]
loss: 0.086092  [19200/69810]
loss: 0.090779  [25600/69810]
loss: 0.061836  [32000/69810]
loss: 0.061474  [38400/69810]
loss: 0.064211  [44800/69810]
loss: 0.054401  [51200/69810]
loss: 0.188033  [57600/69810]
loss: 0.109277  [64000/69810]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095863 

Epoch 6
-------------------------------
loss: 0.099146  [    0/69810]
loss: 0.128300  [ 6400/69810]
loss: 0.180034  [12800/69810]
loss: 0.114836  [19200/69810]
loss: 0.087190  [25600/69810]
loss: 0.084334  [32000/69810]
loss: 0.082100  [38400/69810]
loss: 0.171741  [44800/69810]
loss: 0.119756  [51200/69810]
loss: 0.185221  [57600/69810]
loss: 0.143393  [64000/69810]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.094856 

Epoch 7
-------------------------------
loss: 0.083172  [    0/69810]
loss: 0.065881  [ 6400/69810]
loss: 0.124618  [12800/69810]
loss: 0.152091  [19200/69810]
loss: 0.045609  [25600/69810]
loss: 0.163043  [32000/69810]
loss: 0.087702  [38400/69810]
loss: 0.056543  [44800/69810]
loss: 0.180534  [51200/69810]
loss: 0.051256  [57600/69810]
loss: 0.087032  [64000/69810]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.090853 

Epoch 8
-------------------------------
loss: 0.021981  [    0/69810]
loss: 0.098356  [ 6400/69810]
loss: 0.137333  [12800/69810]
loss: 0.137635  [19200/69810]
loss: 0.025206  [25600/69810]
loss: 0.090748  [32000/69810]
loss: 0.168344  [38400/69810]
loss: 0.132241  [44800/69810]
loss: 0.115089  [51200/69810]
loss: 0.094508  [57600/69810]
loss: 0.076209  [64000/69810]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.087280 

Epoch 9
-------------------------------
loss: 0.126011  [    0/69810]
loss: 0.105157  [ 6400/69810]
loss: 0.210664  [12800/69810]
loss: 0.082865  [19200/69810]
loss: 0.099234  [25600/69810]
loss: 0.058195  [32000/69810]
loss: 0.145883  [38400/69810]
loss: 0.055695  [44800/69810]
loss: 0.117973  [51200/69810]
loss: 0.227501  [57600/69810]
loss: 0.083091  [64000/69810]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.093299 

Epoch 10
-------------------------------
loss: 0.129725  [    0/69810]
loss: 0.046333  [ 6400/69810]
loss: 0.082988  [12800/69810]
loss: 0.112826  [19200/69810]
loss: 0.153829  [25600/69810]
loss: 0.018442  [32000/69810]
loss: 0.066807  [38400/69810]
loss: 0.142368  [44800/69810]
loss: 0.064417  [51200/69810]
loss: 0.087913  [57600/69810]
loss: 0.032294  [64000/69810]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.091410 

Epoch 11
-------------------------------
loss: 0.111669  [    0/69810]
loss: 0.123676  [ 6400/69810]
loss: 0.299382  [12800/69810]
loss: 0.057972  [19200/69810]
loss: 0.085418  [25600/69810]
loss: 0.078093  [32000/69810]
loss: 0.178945  [38400/69810]
loss: 0.054679  [44800/69810]
loss: 0.050325  [51200/69810]
loss: 0.013809  [57600/69810]
loss: 0.053576  [64000/69810]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.086260 

Epoch 12
-------------------------------
loss: 0.215015  [    0/69810]
loss: 0.145782  [ 6400/69810]
loss: 0.123529  [12800/69810]
loss: 0.076987  [19200/69810]
loss: 0.080825  [25600/69810]
loss: 0.064897  [32000/69810]
loss: 0.066490  [38400/69810]
loss: 0.109665  [44800/69810]
loss: 0.049682  [51200/69810]
loss: 0.047463  [57600/69810]
loss: 0.164488  [64000/69810]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.083863 

Epoch 13
-------------------------------
loss: 0.086626  [    0/69810]
loss: 0.110988  [ 6400/69810]
loss: 0.087652  [12800/69810]
loss: 0.146650  [19200/69810]
loss: 0.069636  [25600/69810]
loss: 0.096445  [32000/69810]
loss: 0.148366  [38400/69810]
loss: 0.180863  [44800/69810]
loss: 0.097823  [51200/69810]
loss: 0.046898  [57600/69810]
loss: 0.127345  [64000/69810]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.102228 

Epoch 14
-------------------------------
loss: 0.155990  [    0/69810]
loss: 0.045207  [ 6400/69810]
loss: 0.052376  [12800/69810]
loss: 0.112014  [19200/69810]
loss: 0.163354  [25600/69810]
loss: 0.147860  [32000/69810]
loss: 0.085151  [38400/69810]
loss: 0.222490  [44800/69810]
loss: 0.060474  [51200/69810]
loss: 0.022527  [57600/69810]
loss: 0.107726  [64000/69810]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.083948 

Epoch 15
-------------------------------
loss: 0.043899  [    0/69810]
loss: 0.039543  [ 6400/69810]
loss: 0.051219  [12800/69810]
loss: 0.040989  [19200/69810]
loss: 0.080964  [25600/69810]
loss: 0.150690  [32000/69810]
loss: 0.134107  [38400/69810]
loss: 0.058267  [44800/69810]
loss: 0.033146  [51200/69810]
loss: 0.079549  [57600/69810]
loss: 0.183032  [64000/69810]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.085526 

Epoch 16
-------------------------------
loss: 0.054100  [    0/69810]
loss: 0.200932  [ 6400/69810]
loss: 0.048921  [12800/69810]
loss: 0.024461  [19200/69810]
loss: 0.139870  [25600/69810]
loss: 0.128552  [32000/69810]
loss: 0.054205  [38400/69810]
loss: 0.160614  [44800/69810]
loss: 0.069634  [51200/69810]
loss: 0.095015  [57600/69810]
loss: 0.184271  [64000/69810]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.082319 

Epoch 17
-------------------------------
loss: 0.140134  [    0/69810]
loss: 0.034529  [ 6400/69810]
loss: 0.098027  [12800/69810]
loss: 0.077582  [19200/69810]
loss: 0.120608  [25600/69810]
loss: 0.133054  [32000/69810]
loss: 0.091455  [38400/69810]
loss: 0.113702  [44800/69810]
loss: 0.120267  [51200/69810]
loss: 0.048686  [57600/69810]
loss: 0.086158  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.091171 

Epoch 18
-------------------------------
loss: 0.052169  [    0/69810]
loss: 0.063004  [ 6400/69810]
loss: 0.064320  [12800/69810]
loss: 0.068952  [19200/69810]
loss: 0.121884  [25600/69810]
loss: 0.099968  [32000/69810]
loss: 0.082806  [38400/69810]
loss: 0.027058  [44800/69810]
loss: 0.060789  [51200/69810]
loss: 0.048217  [57600/69810]
loss: 0.052005  [64000/69810]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.095342 

Epoch 19
-------------------------------
loss: 0.093396  [    0/69810]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.153886 

Epoch 50
-------------------------------
loss: 0.105984  [    0/69949]
loss: 0.184168  [ 6400/69949]
loss: 0.111046  [12800/69949]
loss: 0.157695  [19200/69949]
loss: 0.094336  [25600/69949]
loss: 0.139138  [32000/69949]
loss: 0.175491  [38400/69949]
loss: 0.221222  [44800/69949]
loss: 0.111860  [51200/69949]
loss: 0.198818  [57600/69949]
loss: 0.218805  [64000/69949]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146570 

Epoch 1
-------------------------------
loss: 0.642368  [    0/69947]
loss: 0.174881  [ 6400/69947]
loss: 0.220371  [12800/69947]
loss: 0.198902  [19200/69947]
loss: 0.233275  [25600/69947]
loss: 0.170253  [32000/69947]
loss: 0.289353  [38400/69947]
loss: 0.046495  [44800/69947]
loss: 0.169958  [51200/69947]
loss: 0.189201  [57600/69947]
loss: 0.103727  [64000/69947]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.136492 

Epoch 2
-------------------------------
loss: 0.080891  [    0/69947]
loss: 0.098562  [ 6400/69947]
loss: 0.070483  [12800/69947]
loss: 0.154199  [19200/69947]
loss: 0.125229  [25600/69947]
loss: 0.068657  [32000/69947]
loss: 0.101722  [38400/69947]
loss: 0.108696  [44800/69947]
loss: 0.082265  [51200/69947]
loss: 0.192694  [57600/69947]
loss: 0.116772  [64000/69947]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.128177 

Epoch 3
-------------------------------
loss: 0.087352  [    0/69947]
loss: 0.148791  [ 6400/69947]
loss: 0.239677  [12800/69947]
loss: 0.149925  [19200/69947]
loss: 0.104238  [25600/69947]
loss: 0.129723  [32000/69947]
loss: 0.164631  [38400/69947]
loss: 0.138941  [44800/69947]
loss: 0.167571  [51200/69947]
loss: 0.166726  [57600/69947]
loss: 0.151954  [64000/69947]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.148375 

Epoch 4
-------------------------------
loss: 0.114264  [    0/69947]
loss: 0.129274  [ 6400/69947]
loss: 0.155979  [12800/69947]
loss: 0.150634  [19200/69947]
loss: 0.064860  [25600/69947]
loss: 0.060019  [32000/69947]
loss: 0.186840  [38400/69947]
loss: 0.073204  [44800/69947]
loss: 0.210988  [51200/69947]
loss: 0.156936  [57600/69947]
loss: 0.135388  [64000/69947]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.123878 

Epoch 5
-------------------------------
loss: 0.087838  [    0/69947]
loss: 0.076941  [ 6400/69947]
loss: 0.085123  [12800/69947]
loss: 0.105816  [19200/69947]
loss: 0.115506  [25600/69947]
loss: 0.195982  [32000/69947]
loss: 0.220768  [38400/69947]
loss: 0.057090  [44800/69947]
loss: 0.163325  [51200/69947]
loss: 0.098682  [57600/69947]
loss: 0.145781  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.117868 

Epoch 6
-------------------------------
loss: 0.198534  [    0/69947]
loss: 0.094976  [ 6400/69947]
loss: 0.055173  [12800/69947]
loss: 0.091374  [19200/69947]
loss: 0.036093  [25600/69947]
loss: 0.091597  [32000/69947]
loss: 0.172969  [38400/69947]
loss: 0.144834  [44800/69947]
loss: 0.178233  [51200/69947]
loss: 0.125598  [57600/69947]
loss: 0.100162  [64000/69947]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.120291 

Epoch 7
-------------------------------
loss: 0.203135  [    0/69947]
loss: 0.063422  [ 6400/69947]
loss: 0.098571  [12800/69947]
loss: 0.144789  [19200/69947]
loss: 0.157104  [25600/69947]
loss: 0.111225  [32000/69947]
loss: 0.045633  [38400/69947]
loss: 0.102216  [44800/69947]
loss: 0.128384  [51200/69947]
loss: 0.157039  [57600/69947]
loss: 0.210977  [64000/69947]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.132313 

Epoch 8
-------------------------------
loss: 0.111253  [    0/69947]
loss: 0.192012  [ 6400/69947]
loss: 0.209738  [12800/69947]
loss: 0.166099  [19200/69947]
loss: 0.088506  [25600/69947]
loss: 0.124204  [32000/69947]
loss: 0.103637  [38400/69947]
loss: 0.120705  [44800/69947]
loss: 0.040051  [51200/69947]
loss: 0.160754  [57600/69947]
loss: 0.077747  [64000/69947]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.116419 

Epoch 9
-------------------------------
loss: 0.121092  [    0/69947]
loss: 0.167434  [ 6400/69947]
loss: 0.100902  [12800/69947]
loss: 0.067978  [19200/69947]
loss: 0.052282  [25600/69947]
loss: 0.192239  [32000/69947]
loss: 0.093154  [38400/69947]
loss: 0.276030  [44800/69947]
loss: 0.104858  [51200/69947]
loss: 0.074449  [57600/69947]
loss: 0.168639  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.114158 

Epoch 10
-------------------------------
loss: 0.121111  [    0/69947]
loss: 0.055140  [ 6400/69947]
loss: 0.065630  [12800/69947]
loss: 0.086252  [19200/69947]
loss: 0.116532  [25600/69947]
loss: 0.177249  [32000/69947]
loss: 0.080033  [38400/69947]
loss: 0.112991  [44800/69947]
loss: 0.158656  [51200/69947]
loss: 0.036361  [57600/69947]
loss: 0.138480  [64000/69947]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.123603 

Epoch 11
-------------------------------
loss: 0.207950  [    0/69947]
loss: 0.093305  [ 6400/69947]
loss: 0.103275  [12800/69947]
loss: 0.105587  [19200/69947]
loss: 0.158650  [25600/69947]
loss: 0.139948  [32000/69947]
loss: 0.191656  [38400/69947]
loss: 0.136195  [44800/69947]
loss: 0.086835  [51200/69947]
loss: 0.107754  [57600/69947]
loss: 0.053171  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.110124 

Epoch 12
-------------------------------
loss: 0.119727  [    0/69947]
loss: 0.146441  [ 6400/69947]
loss: 0.043577  [12800/69947]
loss: 0.148244  [19200/69947]
loss: 0.188147  [25600/69947]
loss: 0.033479  [32000/69947]
loss: 0.193718  [38400/69947]
loss: 0.114165  [44800/69947]
loss: 0.062855  [51200/69947]
loss: 0.116936  [57600/69947]
loss: 0.144239  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.104643 

Epoch 13
-------------------------------
loss: 0.057253  [    0/69947]
loss: 0.205098  [ 6400/69947]
loss: 0.079527  [12800/69947]
loss: 0.064287  [19200/69947]
loss: 0.076644  [25600/69947]
loss: 0.138098  [32000/69947]
loss: 0.104770  [38400/69947]
loss: 0.096697  [44800/69947]
loss: 0.100016  [51200/69947]
loss: 0.058537  [57600/69947]
loss: 0.082864  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.107400 

Epoch 14
-------------------------------
loss: 0.127709  [    0/69947]
loss: 0.073085  [ 6400/69947]
loss: 0.098903  [12800/69947]
loss: 0.118780  [19200/69947]
loss: 0.082178  [25600/69947]
loss: 0.151779  [32000/69947]
loss: 0.097397  [38400/69947]
loss: 0.092368  [44800/69947]
loss: 0.056883  [51200/69947]
loss: 0.159266  [57600/69947]
loss: 0.084110  [64000/69947]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.110125 

Epoch 15
-------------------------------
loss: 0.132721  [    0/69947]
loss: 0.146054  [ 6400/69947]
loss: 0.129861  [12800/69947]
loss: 0.059852  [19200/69947]
loss: 0.101871  [25600/69947]
loss: 0.087091  [32000/69947]
loss: 0.043274  [38400/69947]
loss: 0.051857  [44800/69947]
loss: 0.107602  [51200/69947]
loss: 0.075274  [57600/69947]
loss: 0.035144  [64000/69947]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.113695 

Epoch 16
-------------------------------
loss: 0.084899  [    0/69947]
loss: 0.099460  [ 6400/69947]
loss: 0.142241  [12800/69947]
loss: 0.113895  [19200/69947]
loss: 0.182074  [25600/69947]
loss: 0.020645  [32000/69947]
loss: 0.108035  [38400/69947]
loss: 0.032815  [44800/69947]
loss: 0.103232  [51200/69947]
loss: 0.109803  [57600/69947]
loss: 0.056903  [64000/69947]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.108855 

Epoch 17
-------------------------------
loss: 0.120889  [    0/69947]
loss: 0.058029  [ 6400/69947]
loss: 0.018607  [12800/69947]
loss: 0.152650  [19200/69947]
loss: 0.103543  [25600/69947]
loss: 0.122832  [32000/69947]
loss: 0.111410  [38400/69947]
loss: 0.100166  [44800/69947]
loss: 0.099491  [51200/69947]
loss: 0.151464  [57600/69947]
loss: 0.066292  [64000/69947]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.103366 

Epoch 18
-------------------------------
loss: 0.047749  [    0/69947]
loss: 0.119983  [ 6400/69947]
loss: 0.087291  [12800/69947]
loss: 0.047074  [19200/69947]
loss: 0.153237  [25600/69947]
loss: 0.133347  [32000/69947]
loss: 0.169665  [38400/69947]
loss: 0.119573  [44800/69947]
loss: 0.063821  [51200/69947]
loss: 0.064536  [57600/69947]
loss: 0.069807  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.111325 

Epoch 19
-------------------------------
loss: 0.107157  [    0/69947]
loss: 0.129282  [ 6400/69947]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.182767 

Epoch 43
-------------------------------
loss: 0.104860  [    0/70533]
loss: 0.158315  [ 6400/70533]
loss: 0.137306  [12800/70533]
loss: 0.123431  [19200/70533]
loss: 0.145852  [25600/70533]
loss: 0.098205  [32000/70533]
loss: 1.656860  [38400/70533]
loss: 0.123975  [44800/70533]
loss: 0.093735  [51200/70533]
loss: 0.098565  [57600/70533]
loss: 0.118116  [64000/70533]
loss: 0.109825  [70400/70533]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.197842 

Epoch 44
-------------------------------
loss: 0.071545  [    0/70533]
loss: 0.104532  [ 6400/70533]
loss: 0.155790  [12800/70533]
loss: 0.191570  [19200/70533]
loss: 0.087009  [25600/70533]
loss: 0.153750  [32000/70533]
loss: 0.123321  [38400/70533]
loss: 0.091272  [44800/70533]
loss: 0.094291  [51200/70533]
loss: 0.223831  [57600/70533]
loss: 0.131596  [64000/70533]
loss: 0.169257  [70400/70533]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.188940 

Epoch 45
-------------------------------
loss: 0.223794  [    0/70533]
loss: 0.178882  [ 6400/70533]
loss: 0.097283  [12800/70533]
loss: 0.074796  [19200/70533]
loss: 0.016746  [25600/70533]
loss: 0.125076  [32000/70533]
loss: 0.108433  [38400/70533]
loss: 0.164861  [44800/70533]
loss: 0.030038  [51200/70533]
loss: 0.184528  [57600/70533]
loss: 0.215560  [64000/70533]
loss: 0.267872  [70400/70533]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.195697 

Epoch 46
-------------------------------
loss: 1.087726  [    0/70533]
loss: 0.110455  [ 6400/70533]
loss: 0.162501  [12800/70533]
loss: 0.139773  [19200/70533]
loss: 0.152558  [25600/70533]
loss: 0.088559  [32000/70533]
loss: 0.207101  [38400/70533]
loss: 0.064846  [44800/70533]
loss: 0.152726  [51200/70533]
loss: 0.167909  [57600/70533]
loss: 0.202999  [64000/70533]
loss: 0.299658  [70400/70533]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.184656 

Epoch 47
-------------------------------
loss: 0.103372  [    0/70533]
loss: 0.123987  [ 6400/70533]
loss: 0.157562  [12800/70533]
loss: 0.055559  [19200/70533]
loss: 0.101719  [25600/70533]
loss: 0.068405  [32000/70533]
loss: 0.202178  [38400/70533]
loss: 0.044279  [44800/70533]
loss: 0.081657  [51200/70533]
loss: 0.094016  [57600/70533]
loss: 0.089142  [64000/70533]
loss: 1.660327  [70400/70533]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.185669 

Epoch 48
-------------------------------
loss: 0.128940  [    0/70533]
loss: 0.110862  [ 6400/70533]
loss: 0.125104  [12800/70533]
loss: 0.131965  [19200/70533]
loss: 0.062471  [25600/70533]
loss: 0.114337  [32000/70533]
loss: 0.169332  [38400/70533]
loss: 0.116770  [44800/70533]
loss: 0.127690  [51200/70533]
loss: 0.099284  [57600/70533]
loss: 0.197156  [64000/70533]
loss: 0.065631  [70400/70533]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.190999 

Epoch 49
-------------------------------
loss: 0.095211  [    0/70533]
loss: 0.102185  [ 6400/70533]
loss: 0.068857  [12800/70533]
loss: 0.215865  [19200/70533]
loss: 0.200966  [25600/70533]
loss: 0.104735  [32000/70533]
loss: 0.082111  [38400/70533]
loss: 0.128559  [44800/70533]
loss: 0.286258  [51200/70533]
loss: 0.150972  [57600/70533]
loss: 0.087170  [64000/70533]
loss: 0.104186  [70400/70533]
Test Error: 
 Accuracy: 89.6%, Avg loss: 0.341699 

Epoch 50
-------------------------------
loss: 0.257436  [    0/70533]
loss: 0.054677  [ 6400/70533]
loss: 0.065449  [12800/70533]
loss: 0.102541  [19200/70533]
loss: 0.151322  [25600/70533]
loss: 0.150529  [32000/70533]
loss: 0.104392  [38400/70533]
loss: 0.152199  [44800/70533]
loss: 0.173970  [51200/70533]
loss: 0.077522  [57600/70533]
loss: 0.138667  [64000/70533]
loss: 0.085527  [70400/70533]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.158179 

Epoch 1
-------------------------------
loss: 0.679538  [    0/69308]
loss: 0.417266  [ 6400/69308]
loss: 0.436781  [12800/69308]
loss: 0.251496  [19200/69308]
loss: 0.276944  [25600/69308]
loss: 0.445560  [32000/69308]
loss: 0.199532  [38400/69308]
loss: 0.354058  [44800/69308]
loss: 0.278931  [51200/69308]
loss: 0.314584  [57600/69308]
loss: 0.211966  [64000/69308]
Test Error: 
 Accuracy: 90.8%, Avg loss: 0.218095 

Epoch 2
-------------------------------
loss: 0.137907  [    0/69308]
loss: 0.220516  [ 6400/69308]
loss: 0.201447  [12800/69308]
loss: 0.217533  [19200/69308]
loss: 0.247066  [25600/69308]
loss: 0.175499  [32000/69308]
loss: 0.260982  [38400/69308]
loss: 0.137004  [44800/69308]
loss: 0.196112  [51200/69308]
loss: 0.167635  [57600/69308]
loss: 0.205475  [64000/69308]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.197657 

Epoch 3
-------------------------------
loss: 0.221675  [    0/69308]
loss: 0.218786  [ 6400/69308]
loss: 0.181752  [12800/69308]
loss: 0.210037  [19200/69308]
loss: 0.150188  [25600/69308]
loss: 0.203242  [32000/69308]
loss: 0.267703  [38400/69308]
loss: 0.339776  [44800/69308]
loss: 0.164821  [51200/69308]
loss: 0.218850  [57600/69308]
loss: 0.174355  [64000/69308]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.198229 

Epoch 4
-------------------------------
loss: 0.187589  [    0/69308]
loss: 0.286693  [ 6400/69308]
loss: 0.221928  [12800/69308]
loss: 0.154300  [19200/69308]
loss: 0.185570  [25600/69308]
loss: 0.265408  [32000/69308]
loss: 0.230912  [38400/69308]
loss: 0.214827  [44800/69308]
loss: 0.193260  [51200/69308]
loss: 0.396739  [57600/69308]
loss: 0.207632  [64000/69308]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.184675 

Epoch 5
-------------------------------
loss: 0.091824  [    0/69308]
loss: 0.195426  [ 6400/69308]
loss: 0.229120  [12800/69308]
loss: 0.227906  [19200/69308]
loss: 0.194692  [25600/69308]
loss: 0.250593  [32000/69308]
loss: 0.213345  [38400/69308]
loss: 0.223931  [44800/69308]
loss: 0.183490  [51200/69308]
loss: 0.219904  [57600/69308]
loss: 0.160107  [64000/69308]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.180272 

Epoch 6
-------------------------------
loss: 0.145201  [    0/69308]
loss: 0.152774  [ 6400/69308]
loss: 0.181869  [12800/69308]
loss: 0.134058  [19200/69308]
loss: 0.245610  [25600/69308]
loss: 0.355469  [32000/69308]
loss: 0.325912  [38400/69308]
loss: 0.301563  [44800/69308]
loss: 0.209554  [51200/69308]
loss: 0.149998  [57600/69308]
loss: 0.114447  [64000/69308]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.174996 

Epoch 7
-------------------------------
loss: 0.312622  [    0/69308]
loss: 0.206920  [ 6400/69308]
loss: 0.173864  [12800/69308]
loss: 0.124734  [19200/69308]
loss: 0.167347  [25600/69308]
loss: 0.166462  [32000/69308]
loss: 0.185006  [38400/69308]
loss: 0.224329  [44800/69308]
loss: 0.192392  [51200/69308]
loss: 0.324230  [57600/69308]
loss: 0.261374  [64000/69308]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.177757 

Epoch 8
-------------------------------
loss: 0.165743  [    0/69308]
loss: 0.351746  [ 6400/69308]
loss: 0.204789  [12800/69308]
loss: 0.192839  [19200/69308]
loss: 0.278205  [25600/69308]
loss: 0.213371  [32000/69308]
loss: 0.182689  [38400/69308]
loss: 0.276511  [44800/69308]
loss: 0.221417  [51200/69308]
loss: 0.225703  [57600/69308]
loss: 0.258126  [64000/69308]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177063 

Epoch 9
-------------------------------
loss: 0.125554  [    0/69308]
loss: 0.205629  [ 6400/69308]
loss: 0.175814  [12800/69308]
loss: 0.185261  [19200/69308]
loss: 0.266042  [25600/69308]
loss: 0.148104  [32000/69308]
loss: 0.182988  [38400/69308]
loss: 0.268773  [44800/69308]
loss: 0.241858  [51200/69308]
loss: 0.213376  [57600/69308]
loss: 0.192775  [64000/69308]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.171267 

Epoch 10
-------------------------------
loss: 0.249829  [    0/69308]
loss: 0.226395  [ 6400/69308]
loss: 0.269130  [12800/69308]
loss: 0.207995  [19200/69308]
loss: 0.145078  [25600/69308]
loss: 0.295722  [32000/69308]
loss: 0.123583  [38400/69308]
loss: 0.244886  [44800/69308]
loss: 0.171231  [51200/69308]
loss: 0.433921  [57600/69308]
loss: 0.214905  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.169804 

Epoch 11
-------------------------------
loss: 0.216092  [    0/69308]
loss: 0.131941  [ 6400/69308]
loss: 0.229982  [12800/69308]
loss: 0.200060  [19200/69308]
loss: 0.167802  [25600/69308]
loss: 0.114012  [32000/69308]
loss: 0.202460  [38400/69308]
loss: 0.097836  [44800/69308]
loss: 0.205215  [25600/70480]
loss: 0.212722  [32000/70480]
loss: 0.145179  [38400/70480]
loss: 0.182548  [44800/70480]
loss: 0.146672  [51200/70480]
loss: 0.251567  [57600/70480]
loss: 0.106476  [64000/70480]
loss: 0.108749  [70400/70480]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.207110 

Epoch 36
-------------------------------
loss: 0.091788  [    0/70480]
loss: 0.149189  [ 6400/70480]
loss: 0.213871  [12800/70480]
loss: 0.184592  [19200/70480]
loss: 0.179287  [25600/70480]
loss: 0.187888  [32000/70480]
loss: 0.229384  [38400/70480]
loss: 0.124531  [44800/70480]
loss: 0.241982  [51200/70480]
loss: 0.151190  [57600/70480]
loss: 0.125810  [64000/70480]
loss: 0.172108  [70400/70480]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.182674 

Epoch 37
-------------------------------
loss: 0.161659  [    0/70480]
loss: 0.105944  [ 6400/70480]
loss: 0.137435  [12800/70480]
loss: 0.149552  [19200/70480]
loss: 0.072604  [25600/70480]
loss: 0.242504  [32000/70480]
loss: 0.133130  [38400/70480]
loss: 0.152680  [44800/70480]
loss: 0.165900  [51200/70480]
loss: 0.181615  [57600/70480]
loss: 0.160013  [64000/70480]
loss: 0.119357  [70400/70480]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.186460 

Epoch 38
-------------------------------
loss: 0.303750  [    0/70480]
loss: 0.190834  [ 6400/70480]
loss: 0.079790  [12800/70480]
loss: 0.188373  [19200/70480]
loss: 0.107046  [25600/70480]
loss: 0.130361  [32000/70480]
loss: 0.220042  [38400/70480]
loss: 0.156401  [44800/70480]
loss: 0.164120  [51200/70480]
loss: 0.213724  [57600/70480]
loss: 0.249381  [64000/70480]
loss: 0.108556  [70400/70480]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.184578 

Epoch 39
-------------------------------
loss: 0.170816  [    0/70480]
loss: 0.151678  [ 6400/70480]
loss: 0.118550  [12800/70480]
loss: 0.094873  [19200/70480]
loss: 0.233351  [25600/70480]
loss: 0.131831  [32000/70480]
loss: 0.144545  [38400/70480]
loss: 0.129247  [44800/70480]
loss: 0.221941  [51200/70480]
loss: 0.189339  [57600/70480]
loss: 0.107651  [64000/70480]
loss: 0.154571  [70400/70480]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.195271 

Epoch 40
-------------------------------
loss: 0.188546  [    0/70480]
loss: 0.090458  [ 6400/70480]
loss: 0.145985  [12800/70480]
loss: 0.243145  [19200/70480]
loss: 0.222836  [25600/70480]
loss: 0.146047  [32000/70480]
loss: 0.148109  [38400/70480]
loss: 0.105447  [44800/70480]
loss: 0.153972  [51200/70480]
loss: 0.072879  [57600/70480]
loss: 0.161900  [64000/70480]
loss: 0.078247  [70400/70480]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.180605 

Epoch 41
-------------------------------
loss: 0.155907  [    0/70480]
loss: 0.093894  [ 6400/70480]
loss: 0.178915  [12800/70480]
loss: 0.108395  [19200/70480]
loss: 0.141611  [25600/70480]
loss: 0.159107  [32000/70480]
loss: 0.170400  [38400/70480]
loss: 0.168815  [44800/70480]
loss: 0.205701  [51200/70480]
loss: 0.088220  [57600/70480]
loss: 0.169868  [64000/70480]
loss: 0.151051  [70400/70480]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.192446 

Epoch 42
-------------------------------
loss: 0.166614  [    0/70480]
loss: 0.120330  [ 6400/70480]
loss: 0.192158  [12800/70480]
loss: 0.154552  [19200/70480]
loss: 0.077338  [25600/70480]
loss: 0.223517  [32000/70480]
loss: 0.046491  [38400/70480]
loss: 0.248763  [44800/70480]
loss: 0.120040  [51200/70480]
loss: 0.237228  [57600/70480]
loss: 0.225970  [64000/70480]
loss: 0.309458  [70400/70480]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.183962 

Epoch 43
-------------------------------
loss: 0.110480  [    0/70480]
loss: 0.123229  [ 6400/70480]
loss: 0.087962  [12800/70480]
loss: 0.221209  [19200/70480]
loss: 0.203937  [25600/70480]
loss: 0.061025  [32000/70480]
loss: 0.102502  [38400/70480]
loss: 0.114151  [44800/70480]
loss: 0.212059  [51200/70480]
loss: 0.116265  [57600/70480]
loss: 0.083915  [64000/70480]
loss: 0.092600  [70400/70480]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.181139 

Epoch 44
-------------------------------
loss: 0.138554  [    0/70480]
loss: 0.128335  [ 6400/70480]
loss: 0.148324  [12800/70480]
loss: 0.122176  [19200/70480]
loss: 0.288671  [25600/70480]
loss: 0.129339  [32000/70480]
loss: 0.237810  [38400/70480]
loss: 0.159089  [44800/70480]
loss: 0.192394  [51200/70480]
loss: 0.113466  [57600/70480]
loss: 0.184583  [64000/70480]
loss: 0.074806  [70400/70480]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.185016 

Epoch 45
-------------------------------
loss: 0.213914  [    0/70480]
loss: 0.163270  [ 6400/70480]
loss: 0.103904  [12800/70480]
loss: 0.134230  [19200/70480]
loss: 0.129697  [25600/70480]
loss: 0.218954  [32000/70480]
loss: 0.091316  [38400/70480]
loss: 0.152634  [44800/70480]
loss: 0.116282  [51200/70480]
loss: 0.190465  [57600/70480]
loss: 0.186216  [64000/70480]
loss: 0.150555  [70400/70480]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.175603 

Epoch 46
-------------------------------
loss: 0.116597  [    0/70480]
loss: 0.141742  [ 6400/70480]
loss: 0.089768  [12800/70480]
loss: 0.080842  [19200/70480]
loss: 0.139343  [25600/70480]
loss: 0.113960  [32000/70480]
loss: 0.122263  [38400/70480]
loss: 0.072918  [44800/70480]
loss: 0.139909  [51200/70480]
loss: 0.110430  [57600/70480]
loss: 0.247862  [64000/70480]
loss: 0.185188  [70400/70480]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.172129 

Epoch 47
-------------------------------
loss: 0.228034  [    0/70480]
loss: 0.220711  [ 6400/70480]
loss: 0.089054  [12800/70480]
loss: 0.184808  [19200/70480]
loss: 0.100974  [25600/70480]
loss: 0.157712  [32000/70480]
loss: 0.088464  [38400/70480]
loss: 0.134005  [44800/70480]
loss: 0.150891  [51200/70480]
loss: 0.123051  [57600/70480]
loss: 0.230663  [64000/70480]
loss: 0.116769  [70400/70480]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.210633 

Epoch 48
-------------------------------
loss: 0.184352  [    0/70480]
loss: 0.085716  [ 6400/70480]
loss: 0.169392  [12800/70480]
loss: 0.178131  [19200/70480]
loss: 0.084658  [25600/70480]
loss: 0.219590  [32000/70480]
loss: 0.222784  [38400/70480]
loss: 0.132216  [44800/70480]
loss: 0.153430  [51200/70480]
loss: 0.088794  [57600/70480]
loss: 0.078672  [64000/70480]
loss: 0.101841  [70400/70480]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.169586 

Epoch 49
-------------------------------
loss: 0.098778  [    0/70480]
loss: 0.198132  [ 6400/70480]
loss: 0.308687  [12800/70480]
loss: 0.097918  [19200/70480]
loss: 0.084376  [25600/70480]
loss: 0.182741  [32000/70480]
loss: 0.096636  [38400/70480]
loss: 0.192108  [44800/70480]
loss: 0.112426  [51200/70480]
loss: 0.072581  [57600/70480]
loss: 0.211281  [64000/70480]
loss: 0.135243  [70400/70480]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.179321 

Epoch 50
-------------------------------
loss: 0.079884  [    0/70480]
loss: 0.107053  [ 6400/70480]
loss: 0.231757  [12800/70480]
loss: 0.093188  [19200/70480]
loss: 0.173549  [25600/70480]
loss: 0.171785  [32000/70480]
loss: 0.143659  [38400/70480]
loss: 0.085851  [44800/70480]
loss: 0.179648  [51200/70480]
loss: 0.114537  [57600/70480]
loss: 0.167634  [64000/70480]
loss: 0.259487  [70400/70480]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.182901 

Epoch 1
-------------------------------
loss: 0.669284  [    0/69683]
loss: 0.333780  [ 6400/69683]
loss: 0.245164  [12800/69683]
loss: 0.285432  [19200/69683]
loss: 0.128186  [25600/69683]
loss: 0.232896  [32000/69683]
loss: 0.398961  [38400/69683]
loss: 0.219238  [44800/69683]
loss: 0.239894  [51200/69683]
loss: 0.225106  [57600/69683]
loss: 0.168153  [64000/69683]
Test Error: 
 Accuracy: 90.9%, Avg loss: 0.227764 

Epoch 2
-------------------------------
loss: 0.278257  [    0/69683]
loss: 0.158988  [ 6400/69683]
loss: 0.211767  [12800/69683]
loss: 0.228570  [19200/69683]
loss: 0.240111  [25600/69683]
loss: 0.348798  [32000/69683]
loss: 0.250395  [38400/69683]
loss: 0.191922  [44800/69683]
loss: 0.187064  [51200/69683]
loss: 0.201811  [57600/69683]
loss: 0.257750  [64000/69683]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.191190 

Epoch 3
-------------------------------
loss: 0.191493  [    0/69683]
loss: 0.173955  [ 6400/69683]
loss: 0.187300  [12800/69683]
loss: 0.132973  [19200/69683]
loss: 0.190158  [25600/69683]
loss: 0.188440  [32000/69683]
loss: 0.253640  [38400/69683]
loss: 0.113458  [12800/70068]
loss: 0.194365  [19200/70068]
loss: 0.086631  [25600/70068]
loss: 0.138695  [32000/70068]
loss: 0.110683  [38400/70068]
loss: 0.107280  [44800/70068]
loss: 0.243790  [51200/70068]
loss: 0.188030  [57600/70068]
loss: 0.203700  [64000/70068]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170205 

Epoch 13
-------------------------------
loss: 0.108092  [    0/70068]
loss: 0.129234  [ 6400/70068]
loss: 0.117215  [12800/70068]
loss: 0.148303  [19200/70068]
loss: 0.117453  [25600/70068]
loss: 0.118850  [32000/70068]
loss: 0.094168  [38400/70068]
loss: 0.174615  [44800/70068]
loss: 0.170542  [51200/70068]
loss: 0.414963  [57600/70068]
loss: 0.130647  [64000/70068]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.176641 

Epoch 14
-------------------------------
loss: 0.213693  [    0/70068]
loss: 0.127726  [ 6400/70068]
loss: 0.245674  [12800/70068]
loss: 0.119255  [19200/70068]
loss: 0.163666  [25600/70068]
loss: 0.086160  [32000/70068]
loss: 0.210423  [38400/70068]
loss: 0.170425  [44800/70068]
loss: 0.169930  [51200/70068]
loss: 0.100074  [57600/70068]
loss: 0.207342  [64000/70068]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.174246 

Epoch 15
-------------------------------
loss: 0.173523  [    0/70068]
loss: 0.133093  [ 6400/70068]
loss: 0.064072  [12800/70068]
loss: 0.171131  [19200/70068]
loss: 0.123311  [25600/70068]
loss: 0.178027  [32000/70068]
loss: 0.330804  [38400/70068]
loss: 0.059004  [44800/70068]
loss: 0.100527  [51200/70068]
loss: 0.183013  [57600/70068]
loss: 0.149311  [64000/70068]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.171985 

Epoch 16
-------------------------------
loss: 0.148927  [    0/70068]
loss: 0.211062  [ 6400/70068]
loss: 0.129970  [12800/70068]
loss: 0.120625  [19200/70068]
loss: 0.104499  [25600/70068]
loss: 0.208121  [32000/70068]
loss: 0.037162  [38400/70068]
loss: 0.213587  [44800/70068]
loss: 0.263403  [51200/70068]
loss: 0.067652  [57600/70068]
loss: 0.133300  [64000/70068]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.171744 

Epoch 17
-------------------------------
loss: 0.249861  [    0/70068]
loss: 0.157067  [ 6400/70068]
loss: 0.315481  [12800/70068]
loss: 0.182286  [19200/70068]
loss: 0.197939  [25600/70068]
loss: 0.061294  [32000/70068]
loss: 0.167872  [38400/70068]
loss: 0.197848  [44800/70068]
loss: 0.152401  [51200/70068]
loss: 0.109988  [57600/70068]
loss: 0.269048  [64000/70068]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.175111 

Epoch 18
-------------------------------
loss: 0.211579  [    0/70068]
loss: 0.110410  [ 6400/70068]
loss: 0.099418  [12800/70068]
loss: 0.113050  [19200/70068]
loss: 0.313200  [25600/70068]
loss: 0.232547  [32000/70068]
loss: 0.120081  [38400/70068]
loss: 0.163746  [44800/70068]
loss: 0.146063  [51200/70068]
loss: 0.241934  [57600/70068]
loss: 0.266856  [64000/70068]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.168046 

Epoch 19
-------------------------------
loss: 0.049936  [    0/70068]
loss: 0.080413  [ 6400/70068]
loss: 0.079312  [12800/70068]
loss: 0.149502  [19200/70068]
loss: 0.089948  [25600/70068]
loss: 0.207951  [32000/70068]
loss: 0.219651  [38400/70068]
loss: 0.136855  [44800/70068]
loss: 0.201735  [51200/70068]
loss: 0.182867  [57600/70068]
loss: 0.130869  [64000/70068]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.182418 

Epoch 20
-------------------------------
loss: 0.210247  [    0/70068]
loss: 0.186151  [ 6400/70068]
loss: 0.176442  [12800/70068]
loss: 0.152774  [19200/70068]
loss: 0.113725  [25600/70068]
loss: 0.184894  [32000/70068]
loss: 0.272406  [38400/70068]
loss: 0.134906  [44800/70068]
loss: 0.287862  [51200/70068]
loss: 0.164909  [57600/70068]
loss: 0.204313  [64000/70068]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.170657 

Epoch 21
-------------------------------
loss: 0.122529  [    0/70068]
loss: 0.205348  [ 6400/70068]
loss: 0.170932  [12800/70068]
loss: 0.079008  [19200/70068]
loss: 0.077660  [25600/70068]
loss: 0.102898  [32000/70068]
loss: 0.155464  [38400/70068]
loss: 0.239211  [44800/70068]
loss: 0.155865  [51200/70068]
loss: 0.094025  [57600/70068]
loss: 0.258764  [64000/70068]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.173611 

Epoch 22
-------------------------------
loss: 0.118778  [    0/70068]
loss: 0.130202  [ 6400/70068]
loss: 0.147177  [12800/70068]
loss: 0.193479  [19200/70068]
loss: 0.266825  [25600/70068]
loss: 0.126445  [32000/70068]
loss: 0.192319  [38400/70068]
loss: 0.168781  [44800/70068]
loss: 0.171419  [51200/70068]
loss: 0.148372  [57600/70068]
loss: 0.060465  [64000/70068]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.166619 

Epoch 23
-------------------------------
loss: 0.162228  [    0/70068]
loss: 0.148080  [ 6400/70068]
loss: 0.084445  [12800/70068]
loss: 0.202830  [19200/70068]
loss: 0.081809  [25600/70068]
loss: 0.160029  [32000/70068]
loss: 0.119640  [38400/70068]
loss: 0.044665  [44800/70068]
loss: 0.278690  [51200/70068]
loss: 0.178219  [57600/70068]
loss: 0.148528  [64000/70068]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169625 

Epoch 24
-------------------------------
loss: 0.061373  [    0/70068]
loss: 0.100879  [ 6400/70068]
loss: 0.136405  [12800/70068]
loss: 0.146206  [19200/70068]
loss: 0.137354  [25600/70068]
loss: 0.127254  [32000/70068]
loss: 0.137057  [38400/70068]
loss: 0.165850  [44800/70068]
loss: 0.140892  [51200/70068]
loss: 0.145596  [57600/70068]
loss: 0.163259  [64000/70068]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.166626 

Epoch 25
-------------------------------
loss: 0.116416  [    0/70068]
loss: 0.066090  [ 6400/70068]
loss: 0.106590  [12800/70068]
loss: 0.065841  [19200/70068]
loss: 0.161233  [25600/70068]
loss: 0.186610  [32000/70068]
loss: 0.137748  [38400/70068]
loss: 0.182566  [44800/70068]
loss: 0.109084  [51200/70068]
loss: 0.173494  [57600/70068]
loss: 0.104360  [64000/70068]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.164609 

Epoch 26
-------------------------------
loss: 0.157946  [    0/70068]
loss: 0.317551  [ 6400/70068]
loss: 0.114148  [12800/70068]
loss: 0.250316  [19200/70068]
loss: 0.153789  [25600/70068]
loss: 0.168369  [32000/70068]
loss: 0.279283  [38400/70068]
loss: 0.184783  [44800/70068]
loss: 0.144914  [51200/70068]
loss: 0.133308  [57600/70068]
loss: 0.142209  [64000/70068]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.175492 

Epoch 27
-------------------------------
loss: 0.094175  [    0/70068]
loss: 0.173689  [ 6400/70068]
loss: 0.128799  [12800/70068]
loss: 0.202959  [19200/70068]
loss: 0.148150  [25600/70068]
loss: 0.216792  [32000/70068]
loss: 0.331915  [38400/70068]
loss: 0.198660  [44800/70068]
loss: 0.110291  [51200/70068]
loss: 0.115301  [57600/70068]
loss: 0.153475  [64000/70068]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.189081 

Epoch 28
-------------------------------
loss: 0.242322  [    0/70068]
loss: 0.179121  [ 6400/70068]
loss: 0.116052  [12800/70068]
loss: 0.151562  [19200/70068]
loss: 0.109650  [25600/70068]
loss: 0.083940  [32000/70068]
loss: 0.244162  [38400/70068]
loss: 0.084188  [44800/70068]
loss: 0.121350  [51200/70068]
loss: 0.189472  [57600/70068]
loss: 0.131872  [64000/70068]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.166627 

Epoch 29
-------------------------------
loss: 0.136973  [    0/70068]
loss: 0.160442  [ 6400/70068]
loss: 0.108873  [12800/70068]
loss: 0.108627  [19200/70068]
loss: 0.143893  [25600/70068]
loss: 0.066652  [32000/70068]
loss: 0.078924  [38400/70068]
loss: 0.137798  [44800/70068]
loss: 0.099105  [51200/70068]
loss: 0.117872  [57600/70068]
loss: 0.125769  [64000/70068]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.177435 

Epoch 30
-------------------------------
loss: 0.078796  [    0/70068]
loss: 0.118912  [ 6400/70068]
loss: 0.140255  [12800/70068]
loss: 0.095848  [19200/70068]
loss: 0.189683  [25600/70068]
loss: 0.158054  [32000/70068]
loss: 0.305843  [38400/70068]
loss: 0.107156  [44800/70068]
loss: 0.217747  [51200/70068]
loss: 0.111107  [57600/70068]
loss: 0.082380  [64000/70068]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.166983 

Epoch 31
-------------------------------
loss: 0.134554  [    0/70068]
loss: 0.233298  [ 6400/70068]
loss: 0.238884  [12800/70068]
loss: 0.187802  [19200/70068]
loss: 0.175117  [25600/70068]
loss: 0.099219  [32000/70068]
loss: 0.206903  [38400/70068]
loss: 0.117803  [32000/71142]
loss: 0.077190  [38400/71142]
loss: 0.077605  [44800/71142]
loss: 0.101666  [51200/71142]
loss: 0.127401  [57600/71142]
loss: 0.030365  [64000/71142]
loss: 0.174884  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.083017 

Epoch 12
-------------------------------
loss: 0.058033  [    0/71142]
loss: 0.105179  [ 6400/71142]
loss: 0.038660  [12800/71142]
loss: 0.070614  [19200/71142]
loss: 0.051456  [25600/71142]
loss: 0.174435  [32000/71142]
loss: 0.132437  [38400/71142]
loss: 0.068633  [44800/71142]
loss: 0.156046  [51200/71142]
loss: 0.006096  [57600/71142]
loss: 0.086510  [64000/71142]
loss: 0.096932  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.082378 

Epoch 13
-------------------------------
loss: 0.034204  [    0/71142]
loss: 0.084541  [ 6400/71142]
loss: 0.078153  [12800/71142]
loss: 0.048656  [19200/71142]
loss: 0.050908  [25600/71142]
loss: 0.202269  [32000/71142]
loss: 0.020945  [38400/71142]
loss: 0.090131  [44800/71142]
loss: 0.020586  [51200/71142]
loss: 0.054910  [57600/71142]
loss: 0.153936  [64000/71142]
loss: 0.129026  [70400/71142]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.083464 

Epoch 14
-------------------------------
loss: 0.092135  [    0/71142]
loss: 0.079712  [ 6400/71142]
loss: 0.103482  [12800/71142]
loss: 0.088378  [19200/71142]
loss: 0.083717  [25600/71142]
loss: 0.093411  [32000/71142]
loss: 0.054500  [38400/71142]
loss: 0.018076  [44800/71142]
loss: 0.128772  [51200/71142]
loss: 0.100028  [57600/71142]
loss: 0.053859  [64000/71142]
loss: 0.120176  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.085427 

Epoch 15
-------------------------------
loss: 0.153961  [    0/71142]
loss: 0.102118  [ 6400/71142]
loss: 0.085283  [12800/71142]
loss: 0.048173  [19200/71142]
loss: 0.142480  [25600/71142]
loss: 0.194806  [32000/71142]
loss: 0.134663  [38400/71142]
loss: 0.049516  [44800/71142]
loss: 0.144472  [51200/71142]
loss: 0.029646  [57600/71142]
loss: 0.158567  [64000/71142]
loss: 0.048836  [70400/71142]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.084482 

Epoch 16
-------------------------------
loss: 0.121511  [    0/71142]
loss: 0.099525  [ 6400/71142]
loss: 0.214459  [12800/71142]
loss: 0.159547  [19200/71142]
loss: 0.051677  [25600/71142]
loss: 0.040924  [32000/71142]
loss: 0.090538  [38400/71142]
loss: 0.084258  [44800/71142]
loss: 0.074822  [51200/71142]
loss: 0.049109  [57600/71142]
loss: 0.164061  [64000/71142]
loss: 0.133729  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.082435 

Epoch 17
-------------------------------
loss: 0.052711  [    0/71142]
loss: 0.120723  [ 6400/71142]
loss: 0.096918  [12800/71142]
loss: 0.084496  [19200/71142]
loss: 0.031928  [25600/71142]
loss: 0.064670  [32000/71142]
loss: 0.059848  [38400/71142]
loss: 0.105023  [44800/71142]
loss: 0.187705  [51200/71142]
loss: 0.046245  [57600/71142]
loss: 0.060298  [64000/71142]
loss: 0.034759  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.086070 

Epoch 18
-------------------------------
loss: 0.049577  [    0/71142]
loss: 0.041704  [ 6400/71142]
loss: 0.145399  [12800/71142]
loss: 0.106816  [19200/71142]
loss: 0.086406  [25600/71142]
loss: 0.020922  [32000/71142]
loss: 0.079844  [38400/71142]
loss: 0.177988  [44800/71142]
loss: 0.131698  [51200/71142]
loss: 0.166346  [57600/71142]
loss: 0.078654  [64000/71142]
loss: 0.044861  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.089051 

Epoch 19
-------------------------------
loss: 0.075470  [    0/71142]
loss: 0.066889  [ 6400/71142]
loss: 0.113200  [12800/71142]
loss: 0.051240  [19200/71142]
loss: 0.056844  [25600/71142]
loss: 0.173793  [32000/71142]
loss: 0.070294  [38400/71142]
loss: 0.124493  [44800/71142]
loss: 0.044798  [51200/71142]
loss: 0.111861  [57600/71142]
loss: 0.063531  [64000/71142]
loss: 0.062976  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090439 

Epoch 20
-------------------------------
loss: 0.108390  [    0/71142]
loss: 0.058855  [ 6400/71142]
loss: 0.085085  [12800/71142]
loss: 0.069952  [19200/71142]
loss: 0.075527  [25600/71142]
loss: 0.055624  [32000/71142]
loss: 0.084995  [38400/71142]
loss: 0.028833  [44800/71142]
loss: 0.097436  [51200/71142]
loss: 0.108788  [57600/71142]
loss: 0.055899  [64000/71142]
loss: 0.147186  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.085380 

Epoch 21
-------------------------------
loss: 0.056588  [    0/71142]
loss: 0.081987  [ 6400/71142]
loss: 0.015572  [12800/71142]
loss: 0.041761  [19200/71142]
loss: 0.207909  [25600/71142]
loss: 0.135110  [32000/71142]
loss: 0.078506  [38400/71142]
loss: 0.052515  [44800/71142]
loss: 0.092273  [51200/71142]
loss: 0.145990  [57600/71142]
loss: 0.040777  [64000/71142]
loss: 0.058356  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.089112 

Epoch 22
-------------------------------
loss: 0.054902  [    0/71142]
loss: 0.158042  [ 6400/71142]
loss: 0.058406  [12800/71142]
loss: 0.071614  [19200/71142]
loss: 0.124679  [25600/71142]
loss: 0.119244  [32000/71142]
loss: 0.160038  [38400/71142]
loss: 0.044432  [44800/71142]
loss: 0.083359  [51200/71142]
loss: 0.178143  [57600/71142]
loss: 0.095452  [64000/71142]
loss: 0.087672  [70400/71142]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.084908 

Epoch 23
-------------------------------
loss: 0.014025  [    0/71142]
loss: 0.136368  [ 6400/71142]
loss: 0.070559  [12800/71142]
loss: 0.081599  [19200/71142]
loss: 0.088860  [25600/71142]
loss: 0.070844  [32000/71142]
loss: 0.045025  [38400/71142]
loss: 0.075077  [44800/71142]
loss: 0.146202  [51200/71142]
loss: 0.095113  [57600/71142]
loss: 0.082794  [64000/71142]
loss: 0.017935  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.090349 

Epoch 24
-------------------------------
loss: 0.034922  [    0/71142]
loss: 0.131939  [ 6400/71142]
loss: 0.028583  [12800/71142]
loss: 0.061468  [19200/71142]
loss: 0.069063  [25600/71142]
loss: 0.129042  [32000/71142]
loss: 0.017528  [38400/71142]
loss: 0.116814  [44800/71142]
loss: 0.101179  [51200/71142]
loss: 0.080952  [57600/71142]
loss: 0.224493  [64000/71142]
loss: 0.017732  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.089992 

Epoch 25
-------------------------------
loss: 0.194073  [    0/71142]
loss: 0.086092  [ 6400/71142]
loss: 0.059940  [12800/71142]
loss: 0.043862  [19200/71142]
loss: 0.037790  [25600/71142]
loss: 0.045863  [32000/71142]
loss: 0.087219  [38400/71142]
loss: 0.048256  [44800/71142]
loss: 0.055761  [51200/71142]
loss: 0.044231  [57600/71142]
loss: 0.086618  [64000/71142]
loss: 0.067763  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.089294 

Epoch 26
-------------------------------
loss: 0.049974  [    0/71142]
loss: 0.020374  [ 6400/71142]
loss: 0.027832  [12800/71142]
loss: 0.072463  [19200/71142]
loss: 0.055359  [25600/71142]
loss: 0.046276  [32000/71142]
loss: 0.049419  [38400/71142]
loss: 0.124864  [44800/71142]
loss: 0.031387  [51200/71142]
loss: 0.151738  [57600/71142]
loss: 0.131095  [64000/71142]
loss: 0.107442  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.089711 

Epoch 27
-------------------------------
loss: 0.127373  [    0/71142]
loss: 0.015905  [ 6400/71142]
loss: 0.031761  [12800/71142]
loss: 0.086760  [19200/71142]
loss: 0.072482  [25600/71142]
loss: 0.210180  [32000/71142]
loss: 0.058430  [38400/71142]
loss: 0.077612  [44800/71142]
loss: 0.078666  [51200/71142]
loss: 0.047922  [57600/71142]
loss: 0.085683  [64000/71142]
loss: 0.054635  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.088040 

Epoch 28
-------------------------------
loss: 0.146381  [    0/71142]
loss: 0.110880  [ 6400/71142]
loss: 0.014124  [12800/71142]
loss: 0.169516  [19200/71142]
loss: 0.033868  [25600/71142]
loss: 0.145434  [32000/71142]
loss: 0.034952  [38400/71142]
loss: 0.067141  [44800/71142]
loss: 0.048488  [51200/71142]
loss: 0.071656  [57600/71142]
loss: 0.035011  [64000/71142]
loss: 0.027551  [70400/71142]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095016 

Epoch 29
-------------------------------
loss: 0.081364  [    0/71142]
loss: 0.044830  [ 6400/71142]
loss: 0.055360  [12800/71142]
loss: 0.053305  [19200/71142]
loss: 0.061166  [25600/71142]
loss: 0.043868  [32000/71142]
loss: 0.112704  [25600/71193]
loss: 0.147451  [32000/71193]
loss: 0.176606  [38400/71193]
loss: 0.130533  [44800/71193]
loss: 0.143109  [51200/71193]
loss: 0.129278  [57600/71193]
loss: 0.101952  [64000/71193]
loss: 0.196052  [70400/71193]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.140973 

Epoch 4
-------------------------------
loss: 0.123513  [    0/71193]
loss: 0.074341  [ 6400/71193]
loss: 0.127842  [12800/71193]
loss: 0.110633  [19200/71193]
loss: 0.192671  [25600/71193]
loss: 0.124269  [32000/71193]
loss: 0.091851  [38400/71193]
loss: 0.113232  [44800/71193]
loss: 0.111688  [51200/71193]
loss: 0.178647  [57600/71193]
loss: 0.103452  [64000/71193]
loss: 0.146434  [70400/71193]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139833 

Epoch 5
-------------------------------
loss: 0.237271  [    0/71193]
loss: 0.238147  [ 6400/71193]
loss: 0.151818  [12800/71193]
loss: 0.165294  [19200/71193]
loss: 0.073543  [25600/71193]
loss: 0.127036  [32000/71193]
loss: 0.163387  [38400/71193]
loss: 0.077050  [44800/71193]
loss: 0.170311  [51200/71193]
loss: 0.120037  [57600/71193]
loss: 0.161252  [64000/71193]
loss: 0.086472  [70400/71193]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.129707 

Epoch 6
-------------------------------
loss: 0.124461  [    0/71193]
loss: 0.265154  [ 6400/71193]
loss: 0.080468  [12800/71193]
loss: 0.192833  [19200/71193]
loss: 0.059366  [25600/71193]
loss: 0.102190  [32000/71193]
loss: 0.109066  [38400/71193]
loss: 0.067623  [44800/71193]
loss: 0.167409  [51200/71193]
loss: 0.062982  [57600/71193]
loss: 0.047007  [64000/71193]
loss: 0.065065  [70400/71193]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.130355 

Epoch 7
-------------------------------
loss: 0.160996  [    0/71193]
loss: 0.125456  [ 6400/71193]
loss: 0.119195  [12800/71193]
loss: 0.121884  [19200/71193]
loss: 0.175143  [25600/71193]
loss: 0.200221  [32000/71193]
loss: 0.042416  [38400/71193]
loss: 0.118283  [44800/71193]
loss: 0.107101  [51200/71193]
loss: 0.157237  [57600/71193]
loss: 0.095252  [64000/71193]
loss: 0.222828  [70400/71193]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.133122 

Epoch 8
-------------------------------
loss: 0.033783  [    0/71193]
loss: 0.152764  [ 6400/71193]
loss: 0.151118  [12800/71193]
loss: 0.136721  [19200/71193]
loss: 0.125083  [25600/71193]
loss: 0.302630  [32000/71193]
loss: 0.084645  [38400/71193]
loss: 0.225131  [44800/71193]
loss: 0.161174  [51200/71193]
loss: 0.176061  [57600/71193]
loss: 0.121022  [64000/71193]
loss: 0.111533  [70400/71193]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.128170 

Epoch 9
-------------------------------
loss: 0.107425  [    0/71193]
loss: 0.257904  [ 6400/71193]
loss: 0.087051  [12800/71193]
loss: 0.176700  [19200/71193]
loss: 0.065506  [25600/71193]
loss: 0.183866  [32000/71193]
loss: 0.171050  [38400/71193]
loss: 0.094415  [44800/71193]
loss: 0.087505  [51200/71193]
loss: 0.117532  [57600/71193]
loss: 0.083158  [64000/71193]
loss: 0.145105  [70400/71193]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.137386 

Epoch 10
-------------------------------
loss: 0.132921  [    0/71193]
loss: 0.211875  [ 6400/71193]
loss: 0.181166  [12800/71193]
loss: 0.147551  [19200/71193]
loss: 0.052728  [25600/71193]
loss: 0.152280  [32000/71193]
loss: 0.118607  [38400/71193]
loss: 0.132413  [44800/71193]
loss: 0.151933  [51200/71193]
loss: 0.111678  [57600/71193]
loss: 0.154251  [64000/71193]
loss: 0.137965  [70400/71193]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.125176 

Epoch 11
-------------------------------
loss: 0.156979  [    0/71193]
loss: 0.089123  [ 6400/71193]
loss: 0.150721  [12800/71193]
loss: 0.079293  [19200/71193]
loss: 0.163308  [25600/71193]
loss: 0.184103  [32000/71193]
loss: 0.173157  [38400/71193]
loss: 0.072348  [44800/71193]
loss: 0.197419  [51200/71193]
loss: 0.214426  [57600/71193]
loss: 0.104062  [64000/71193]
loss: 0.147671  [70400/71193]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.126976 

Epoch 12
-------------------------------
loss: 0.083802  [    0/71193]
loss: 0.058505  [ 6400/71193]
loss: 0.090983  [12800/71193]
loss: 0.115011  [19200/71193]
loss: 0.076715  [25600/71193]
loss: 0.101052  [32000/71193]
loss: 0.132785  [38400/71193]
loss: 0.258522  [44800/71193]
loss: 0.037734  [51200/71193]
loss: 0.121350  [57600/71193]
loss: 0.155750  [64000/71193]
loss: 0.094251  [70400/71193]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.127319 

Epoch 13
-------------------------------
loss: 0.041978  [    0/71193]
loss: 0.093441  [ 6400/71193]
loss: 0.265291  [12800/71193]
loss: 0.114675  [19200/71193]
loss: 0.316858  [25600/71193]
loss: 0.074868  [32000/71193]
loss: 0.048744  [38400/71193]
loss: 0.093055  [44800/71193]
loss: 0.083918  [51200/71193]
loss: 0.156362  [57600/71193]
loss: 0.089872  [64000/71193]
loss: 0.117553  [70400/71193]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.138316 

Epoch 14
-------------------------------
loss: 0.160498  [    0/71193]
loss: 0.095225  [ 6400/71193]
loss: 0.169348  [12800/71193]
loss: 0.086297  [19200/71193]
loss: 0.058496  [25600/71193]
loss: 0.135787  [32000/71193]
loss: 0.186931  [38400/71193]
loss: 0.226670  [44800/71193]
loss: 0.039221  [51200/71193]
loss: 0.330668  [57600/71193]
loss: 0.078591  [64000/71193]
loss: 0.200424  [70400/71193]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.129662 

Epoch 15
-------------------------------
loss: 0.162695  [    0/71193]
loss: 0.056322  [ 6400/71193]
loss: 0.077218  [12800/71193]
loss: 0.145462  [19200/71193]
loss: 0.094093  [25600/71193]
loss: 0.149491  [32000/71193]
loss: 0.046109  [38400/71193]
loss: 0.174910  [44800/71193]
loss: 0.110652  [51200/71193]
loss: 0.083201  [57600/71193]
loss: 0.107174  [64000/71193]
loss: 0.119845  [70400/71193]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.134324 

Epoch 16
-------------------------------
loss: 0.100604  [    0/71193]
loss: 0.245005  [ 6400/71193]
loss: 0.171331  [12800/71193]
loss: 0.091695  [19200/71193]
loss: 0.068455  [25600/71193]
loss: 0.277816  [32000/71193]
loss: 0.190386  [38400/71193]
loss: 0.082589  [44800/71193]
loss: 0.127586  [51200/71193]
loss: 0.055410  [57600/71193]
loss: 0.083599  [64000/71193]
loss: 0.074989  [70400/71193]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.126140 

Epoch 17
-------------------------------
loss: 0.112514  [    0/71193]
loss: 0.067176  [ 6400/71193]
loss: 0.095538  [12800/71193]
loss: 0.051589  [19200/71193]
loss: 0.106387  [25600/71193]
loss: 0.162794  [32000/71193]
loss: 0.144880  [38400/71193]
loss: 0.094243  [44800/71193]
loss: 0.092647  [51200/71193]
loss: 0.116123  [57600/71193]
loss: 0.083404  [64000/71193]
loss: 0.174972  [70400/71193]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.130510 

Epoch 18
-------------------------------
loss: 0.208797  [    0/71193]
loss: 0.064956  [ 6400/71193]
loss: 0.166350  [12800/71193]
loss: 0.100724  [19200/71193]
loss: 0.054841  [25600/71193]
loss: 0.087168  [32000/71193]
loss: 0.114500  [38400/71193]
loss: 0.072377  [44800/71193]
loss: 0.105196  [51200/71193]
loss: 0.137403  [57600/71193]
loss: 0.089389  [64000/71193]
loss: 0.099840  [70400/71193]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.127371 

Epoch 19
-------------------------------
loss: 0.082485  [    0/71193]
loss: 0.084265  [ 6400/71193]
loss: 0.037307  [12800/71193]
loss: 0.134036  [19200/71193]
loss: 0.095899  [25600/71193]
loss: 0.078047  [32000/71193]
loss: 0.076738  [38400/71193]
loss: 0.086168  [44800/71193]
loss: 0.206111  [51200/71193]
loss: 0.245153  [57600/71193]
loss: 0.048842  [64000/71193]
loss: 0.143868  [70400/71193]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.126741 

Epoch 20
-------------------------------
loss: 0.082106  [    0/71193]
loss: 0.208811  [ 6400/71193]
loss: 0.034897  [12800/71193]
loss: 0.085057  [19200/71193]
loss: 0.143430  [25600/71193]
loss: 0.051124  [32000/71193]
loss: 0.092582  [38400/71193]
loss: 0.171153  [44800/71193]
loss: 0.189365  [51200/71193]
loss: 0.207145  [57600/71193]
loss: 0.141752  [64000/71193]
loss: 0.150089  [70400/71193]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.136070 

Epoch 21
-------------------------------
loss: 0.085912  [    0/71193]
loss: 0.096765  [ 6400/71193]
loss: 0.183121  [12800/71193]
loss: 0.066865  [19200/71193]
loss: 0.151069  [25600/71193]
loss: 0.106119  [32000/69183]
loss: 0.124919  [38400/69183]
loss: 0.131222  [44800/69183]
loss: 0.156715  [51200/69183]
loss: 0.096192  [57600/69183]
loss: 0.072042  [64000/69183]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.143066 

Epoch 9
-------------------------------
loss: 0.196423  [    0/69183]
loss: 0.130297  [ 6400/69183]
loss: 0.177653  [12800/69183]
loss: 0.181137  [19200/69183]
loss: 0.051733  [25600/69183]
loss: 0.084150  [32000/69183]
loss: 0.058868  [38400/69183]
loss: 0.241515  [44800/69183]
loss: 0.163889  [51200/69183]
loss: 0.070849  [57600/69183]
loss: 0.111995  [64000/69183]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.126407 

Epoch 10
-------------------------------
loss: 0.081857  [    0/69183]
loss: 0.209701  [ 6400/69183]
loss: 0.150192  [12800/69183]
loss: 0.143725  [19200/69183]
loss: 0.146453  [25600/69183]
loss: 0.029434  [32000/69183]
loss: 0.111298  [38400/69183]
loss: 0.085778  [44800/69183]
loss: 0.304957  [51200/69183]
loss: 0.155288  [57600/69183]
loss: 0.091863  [64000/69183]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.125180 

Epoch 11
-------------------------------
loss: 0.044544  [    0/69183]
loss: 0.122734  [ 6400/69183]
loss: 0.114205  [12800/69183]
loss: 0.158133  [19200/69183]
loss: 0.156722  [25600/69183]
loss: 0.194991  [32000/69183]
loss: 0.144911  [38400/69183]
loss: 0.139513  [44800/69183]
loss: 0.104081  [51200/69183]
loss: 0.271449  [57600/69183]
loss: 0.196215  [64000/69183]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.133655 

Epoch 12
-------------------------------
loss: 0.129962  [    0/69183]
loss: 0.106426  [ 6400/69183]
loss: 0.177735  [12800/69183]
loss: 0.045050  [19200/69183]
loss: 0.074032  [25600/69183]
loss: 0.177120  [32000/69183]
loss: 0.128966  [38400/69183]
loss: 0.108077  [44800/69183]
loss: 0.186828  [51200/69183]
loss: 0.119528  [57600/69183]
loss: 0.129903  [64000/69183]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.127820 

Epoch 13
-------------------------------
loss: 0.135760  [    0/69183]
loss: 0.172717  [ 6400/69183]
loss: 0.175631  [12800/69183]
loss: 0.127377  [19200/69183]
loss: 0.059900  [25600/69183]
loss: 0.087200  [32000/69183]
loss: 0.139239  [38400/69183]
loss: 0.293737  [44800/69183]
loss: 0.028899  [51200/69183]
loss: 0.112045  [57600/69183]
loss: 0.121326  [64000/69183]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.125986 

Epoch 14
-------------------------------
loss: 0.119634  [    0/69183]
loss: 0.143975  [ 6400/69183]
loss: 0.058311  [12800/69183]
loss: 0.104768  [19200/69183]
loss: 0.056549  [25600/69183]
loss: 0.098177  [32000/69183]
loss: 0.046437  [38400/69183]
loss: 0.133191  [44800/69183]
loss: 0.095950  [51200/69183]
loss: 0.126266  [57600/69183]
loss: 0.086891  [64000/69183]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.129068 

Epoch 15
-------------------------------
loss: 0.103634  [    0/69183]
loss: 0.226619  [ 6400/69183]
loss: 0.078064  [12800/69183]
loss: 0.073182  [19200/69183]
loss: 0.090135  [25600/69183]
loss: 0.103627  [32000/69183]
loss: 0.056448  [38400/69183]
loss: 0.137885  [44800/69183]
loss: 0.067140  [51200/69183]
loss: 0.162721  [57600/69183]
loss: 0.102790  [64000/69183]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.117416 

Epoch 16
-------------------------------
loss: 0.095636  [    0/69183]
loss: 0.059533  [ 6400/69183]
loss: 0.316990  [12800/69183]
loss: 1.733935  [19200/69183]
loss: 0.054172  [25600/69183]
loss: 0.078567  [32000/69183]
loss: 0.092552  [38400/69183]
loss: 0.079678  [44800/69183]
loss: 0.318826  [51200/69183]
loss: 0.160187  [57600/69183]
loss: 0.074502  [64000/69183]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.123231 

Epoch 17
-------------------------------
loss: 0.098409  [    0/69183]
loss: 0.104523  [ 6400/69183]
loss: 0.119055  [12800/69183]
loss: 0.078595  [19200/69183]
loss: 0.074608  [25600/69183]
loss: 0.044597  [32000/69183]
loss: 0.090989  [38400/69183]
loss: 0.090598  [44800/69183]
loss: 0.158644  [51200/69183]
loss: 0.116364  [57600/69183]
loss: 0.067800  [64000/69183]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.119826 

Epoch 18
-------------------------------
loss: 0.083411  [    0/69183]
loss: 0.099604  [ 6400/69183]
loss: 0.151443  [12800/69183]
loss: 0.172359  [19200/69183]
loss: 0.060355  [25600/69183]
loss: 0.084673  [32000/69183]
loss: 0.136390  [38400/69183]
loss: 0.141231  [44800/69183]
loss: 0.194820  [51200/69183]
loss: 0.108546  [57600/69183]
loss: 0.140296  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.118117 

Epoch 19
-------------------------------
loss: 0.189275  [    0/69183]
loss: 0.062061  [ 6400/69183]
loss: 0.120885  [12800/69183]
loss: 0.054290  [19200/69183]
loss: 0.159095  [25600/69183]
loss: 0.185170  [32000/69183]
loss: 0.109614  [38400/69183]
loss: 0.105764  [44800/69183]
loss: 0.145227  [51200/69183]
loss: 0.104811  [57600/69183]
loss: 0.126689  [64000/69183]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.122496 

Epoch 20
-------------------------------
loss: 0.115648  [    0/69183]
loss: 0.045591  [ 6400/69183]
loss: 0.085358  [12800/69183]
loss: 0.129175  [19200/69183]
loss: 0.214987  [25600/69183]
loss: 0.091370  [32000/69183]
loss: 0.070503  [38400/69183]
loss: 0.052625  [44800/69183]
loss: 0.180450  [51200/69183]
loss: 0.072051  [57600/69183]
loss: 0.057615  [64000/69183]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.126934 

Epoch 21
-------------------------------
loss: 0.088184  [    0/69183]
loss: 0.071151  [ 6400/69183]
loss: 0.077209  [12800/69183]
loss: 0.165733  [19200/69183]
loss: 0.056933  [25600/69183]
loss: 0.061318  [32000/69183]
loss: 0.145786  [38400/69183]
loss: 0.243023  [44800/69183]
loss: 0.122937  [51200/69183]
loss: 0.081201  [57600/69183]
loss: 0.182782  [64000/69183]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.128193 

Epoch 22
-------------------------------
loss: 0.094624  [    0/69183]
loss: 0.084994  [ 6400/69183]
loss: 0.043369  [12800/69183]
loss: 0.100343  [19200/69183]
loss: 0.025354  [25600/69183]
loss: 0.074115  [32000/69183]
loss: 0.048840  [38400/69183]
loss: 0.340946  [44800/69183]
loss: 0.074660  [51200/69183]
loss: 0.116882  [57600/69183]
loss: 0.085509  [64000/69183]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.124537 

Epoch 23
-------------------------------
loss: 0.096020  [    0/69183]
loss: 0.017431  [ 6400/69183]
loss: 0.138943  [12800/69183]
loss: 0.093201  [19200/69183]
loss: 0.047982  [25600/69183]
loss: 0.108607  [32000/69183]
loss: 0.085618  [38400/69183]
loss: 0.188969  [44800/69183]
loss: 0.068845  [51200/69183]
loss: 0.136357  [57600/69183]
loss: 0.194937  [64000/69183]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.122336 

Epoch 24
-------------------------------
loss: 0.117053  [    0/69183]
loss: 0.043580  [ 6400/69183]
loss: 0.061418  [12800/69183]
loss: 0.048946  [19200/69183]
loss: 0.109511  [25600/69183]
loss: 0.057624  [32000/69183]
loss: 0.186634  [38400/69183]
loss: 0.191269  [44800/69183]
loss: 0.091826  [51200/69183]
loss: 0.105610  [57600/69183]
loss: 0.119292  [64000/69183]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.132519 

Epoch 25
-------------------------------
loss: 0.107289  [    0/69183]
loss: 0.090299  [ 6400/69183]
loss: 0.090604  [12800/69183]
loss: 0.061899  [19200/69183]
loss: 0.087549  [25600/69183]
loss: 0.086512  [32000/69183]
loss: 0.059876  [38400/69183]
loss: 0.257192  [44800/69183]
loss: 0.150448  [51200/69183]
loss: 0.146110  [57600/69183]
loss: 0.176316  [64000/69183]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.126208 

Epoch 26
-------------------------------
loss: 0.130420  [    0/69183]
loss: 0.085964  [ 6400/69183]
loss: 0.051732  [12800/69183]
loss: 0.187305  [19200/69183]
loss: 0.153275  [25600/69183]
loss: 0.133278  [32000/69183]
loss: 0.117376  [38400/69183]
loss: 0.086450  [44800/69183]
loss: 0.123103  [51200/69183]
loss: 0.130072  [57600/69183]
loss: 0.192731  [64000/69183]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.132017 

Epoch 27
-------------------------------
loss: 0.116152  [    0/69183]
loss: 0.122901  [ 6400/69183]
loss: 0.070899  [12800/69183]
loss: 0.089422  [19200/69183]
loss: 0.219744  [25600/69183]
loss: 0.216469  [32000/69183]
loss: 0.102607  [38400/69183]
loss: 0.036920  [44800/69183]
loss: 0.083330  [51200/69183]
loss: 0.064269  [57600/69183]
loss: 0.063959  [64000/71083]
loss: 0.066816  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.103661 

Epoch 15
-------------------------------
loss: 0.022412  [    0/71083]
loss: 0.038453  [ 6400/71083]
loss: 0.047345  [12800/71083]
loss: 0.087366  [19200/71083]
loss: 0.064935  [25600/71083]
loss: 0.150897  [32000/71083]
loss: 0.049952  [38400/71083]
loss: 0.083807  [44800/71083]
loss: 0.042325  [51200/71083]
loss: 0.076367  [57600/71083]
loss: 0.075085  [64000/71083]
loss: 0.032420  [70400/71083]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.110727 

Epoch 16
-------------------------------
loss: 0.028732  [    0/71083]
loss: 0.064805  [ 6400/71083]
loss: 0.034156  [12800/71083]
loss: 0.033485  [19200/71083]
loss: 0.039272  [25600/71083]
loss: 0.070742  [32000/71083]
loss: 0.174723  [38400/71083]
loss: 0.047613  [44800/71083]
loss: 0.104777  [51200/71083]
loss: 0.021472  [57600/71083]
loss: 0.065687  [64000/71083]
loss: 0.059618  [70400/71083]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.107291 

Epoch 17
-------------------------------
loss: 0.002838  [    0/71083]
loss: 0.098002  [ 6400/71083]
loss: 0.333400  [12800/71083]
loss: 0.165598  [19200/71083]
loss: 0.116592  [25600/71083]
loss: 0.034036  [32000/71083]
loss: 0.047818  [38400/71083]
loss: 0.093048  [44800/71083]
loss: 0.169989  [51200/71083]
loss: 0.017705  [57600/71083]
loss: 0.176583  [64000/71083]
loss: 0.098641  [70400/71083]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.107250 

Epoch 18
-------------------------------
loss: 0.053108  [    0/71083]
loss: 0.045401  [ 6400/71083]
loss: 0.028351  [12800/71083]
loss: 0.042414  [19200/71083]
loss: 0.079950  [25600/71083]
loss: 0.037844  [32000/71083]
loss: 0.072147  [38400/71083]
loss: 0.027121  [44800/71083]
loss: 0.078492  [51200/71083]
loss: 0.026182  [57600/71083]
loss: 0.060910  [64000/71083]
loss: 0.018220  [70400/71083]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.104771 

Epoch 19
-------------------------------
loss: 0.192869  [    0/71083]
loss: 0.037347  [ 6400/71083]
loss: 0.072485  [12800/71083]
loss: 0.265626  [19200/71083]
loss: 0.083426  [25600/71083]
loss: 0.041239  [32000/71083]
loss: 0.066409  [38400/71083]
loss: 0.154695  [44800/71083]
loss: 0.118996  [51200/71083]
loss: 0.116850  [57600/71083]
loss: 0.016686  [64000/71083]
loss: 0.173280  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.105767 

Epoch 20
-------------------------------
loss: 0.061097  [    0/71083]
loss: 0.062254  [ 6400/71083]
loss: 0.077871  [12800/71083]
loss: 0.148733  [19200/71083]
loss: 0.051711  [25600/71083]
loss: 0.024722  [32000/71083]
loss: 0.059055  [38400/71083]
loss: 0.112526  [44800/71083]
loss: 0.075529  [51200/71083]
loss: 0.069615  [57600/71083]
loss: 0.124777  [64000/71083]
loss: 0.135413  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.106094 

Epoch 21
-------------------------------
loss: 0.062524  [    0/71083]
loss: 0.035458  [ 6400/71083]
loss: 0.093473  [12800/71083]
loss: 0.060705  [19200/71083]
loss: 0.028537  [25600/71083]
loss: 0.028544  [32000/71083]
loss: 0.057100  [38400/71083]
loss: 0.099343  [44800/71083]
loss: 0.059033  [51200/71083]
loss: 0.025065  [57600/71083]
loss: 0.103807  [64000/71083]
loss: 0.102164  [70400/71083]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.097401 

Epoch 22
-------------------------------
loss: 0.032321  [    0/71083]
loss: 0.084445  [ 6400/71083]
loss: 0.045856  [12800/71083]
loss: 0.045050  [19200/71083]
loss: 0.032592  [25600/71083]
loss: 0.065328  [32000/71083]
loss: 0.128648  [38400/71083]
loss: 0.049538  [44800/71083]
loss: 0.063047  [51200/71083]
loss: 0.086305  [57600/71083]
loss: 0.072490  [64000/71083]
loss: 0.009776  [70400/71083]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.118510 

Epoch 23
-------------------------------
loss: 0.034607  [    0/71083]
loss: 0.081660  [ 6400/71083]
loss: 0.099699  [12800/71083]
loss: 0.008058  [19200/71083]
loss: 0.139385  [25600/71083]
loss: 0.100658  [32000/71083]
loss: 0.097222  [38400/71083]
loss: 0.080558  [44800/71083]
loss: 0.065630  [51200/71083]
loss: 0.361122  [57600/71083]
loss: 0.101469  [64000/71083]
loss: 0.051554  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.102074 

Epoch 24
-------------------------------
loss: 0.042775  [    0/71083]
loss: 0.227596  [ 6400/71083]
loss: 0.037924  [12800/71083]
loss: 0.070469  [19200/71083]
loss: 0.123517  [25600/71083]
loss: 0.045093  [32000/71083]
loss: 0.320038  [38400/71083]
loss: 0.035144  [44800/71083]
loss: 0.189520  [51200/71083]
loss: 0.090027  [57600/71083]
loss: 0.093629  [64000/71083]
loss: 0.021544  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.100883 

Epoch 25
-------------------------------
loss: 0.053809  [    0/71083]
loss: 0.099530  [ 6400/71083]
loss: 0.068019  [12800/71083]
loss: 0.061922  [19200/71083]
loss: 0.043780  [25600/71083]
loss: 0.053905  [32000/71083]
loss: 0.067819  [38400/71083]
loss: 0.104681  [44800/71083]
loss: 0.125207  [51200/71083]
loss: 0.133464  [57600/71083]
loss: 0.029078  [64000/71083]
loss: 0.024172  [70400/71083]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.107485 

Epoch 26
-------------------------------
loss: 0.010262  [    0/71083]
loss: 0.026021  [ 6400/71083]
loss: 0.101003  [12800/71083]
loss: 0.029652  [19200/71083]
loss: 0.071819  [25600/71083]
loss: 0.037954  [32000/71083]
loss: 0.027143  [38400/71083]
loss: 0.181925  [44800/71083]
loss: 0.035263  [51200/71083]
loss: 0.053365  [57600/71083]
loss: 0.016972  [64000/71083]
loss: 0.057114  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.101590 

Epoch 27
-------------------------------
loss: 0.019167  [    0/71083]
loss: 0.078861  [ 6400/71083]
loss: 0.006846  [12800/71083]
loss: 0.021762  [19200/71083]
loss: 0.077577  [25600/71083]
loss: 0.031830  [32000/71083]
loss: 0.115012  [38400/71083]
loss: 0.036347  [44800/71083]
loss: 0.069291  [51200/71083]
loss: 0.096783  [57600/71083]
loss: 0.053520  [64000/71083]
loss: 0.027350  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.099134 

Epoch 28
-------------------------------
loss: 0.146531  [    0/71083]
loss: 0.059212  [ 6400/71083]
loss: 0.051626  [12800/71083]
loss: 0.049356  [19200/71083]
loss: 0.068019  [25600/71083]
loss: 0.163049  [32000/71083]
loss: 0.119426  [38400/71083]
loss: 0.199941  [44800/71083]
loss: 0.086502  [51200/71083]
loss: 0.078934  [57600/71083]
loss: 0.061235  [64000/71083]
loss: 0.037027  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.103567 

Epoch 29
-------------------------------
loss: 0.079921  [    0/71083]
loss: 0.053186  [ 6400/71083]
loss: 0.033366  [12800/71083]
loss: 0.067666  [19200/71083]
loss: 0.039795  [25600/71083]
loss: 0.044169  [32000/71083]
loss: 0.045837  [38400/71083]
loss: 0.065061  [44800/71083]
loss: 0.088536  [51200/71083]
loss: 0.176361  [57600/71083]
loss: 0.050598  [64000/71083]
loss: 0.023860  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.101395 

Epoch 30
-------------------------------
loss: 0.105876  [    0/71083]
loss: 0.056057  [ 6400/71083]
loss: 0.034801  [12800/71083]
loss: 0.193088  [19200/71083]
loss: 0.038966  [25600/71083]
loss: 0.097554  [32000/71083]
loss: 0.092987  [38400/71083]
loss: 0.097261  [44800/71083]
loss: 0.043989  [51200/71083]
loss: 0.051466  [57600/71083]
loss: 0.041671  [64000/71083]
loss: 0.135657  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.105142 

Epoch 31
-------------------------------
loss: 0.063765  [    0/71083]
loss: 0.021612  [ 6400/71083]
loss: 0.019746  [12800/71083]
loss: 0.043795  [19200/71083]
loss: 0.042807  [25600/71083]
loss: 0.081252  [32000/71083]
loss: 0.056550  [38400/71083]
loss: 0.111097  [44800/71083]
loss: 0.057591  [51200/71083]
loss: 0.221705  [57600/71083]
loss: 0.081422  [64000/71083]
loss: 0.056159  [70400/71083]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.095180 

Epoch 32
-------------------------------
loss: 0.030491  [    0/71083]
loss: 0.036160  [ 6400/71083]
loss: 0.121680  [12800/71083]
loss: 0.115359  [19200/71083]
loss: 0.075895  [25600/71083]
loss: 0.142974  [32000/71083]
loss: 0.088635  [38400/71083]
loss: 0.054215  [44800/71083]
loss: 0.150510  [51200/71083]
loss: 0.037794  [57600/71083]
loss: 0.041957  [64000/71083]
loss: 0.099536  [32000/70632]
loss: 0.075547  [38400/70632]
loss: 0.141569  [44800/70632]
loss: 0.145735  [51200/70632]
loss: 0.159542  [57600/70632]
loss: 0.077538  [64000/70632]
loss: 0.092140  [70400/70632]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.110850 

Epoch 12
-------------------------------
loss: 0.082543  [    0/70632]
loss: 0.107769  [ 6400/70632]
loss: 0.064683  [12800/70632]
loss: 0.087323  [19200/70632]
loss: 0.146744  [25600/70632]
loss: 0.088022  [32000/70632]
loss: 0.089437  [38400/70632]
loss: 0.058429  [44800/70632]
loss: 0.171387  [51200/70632]
loss: 0.156484  [57600/70632]
loss: 0.124781  [64000/70632]
loss: 0.082586  [70400/70632]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.111533 

Epoch 13
-------------------------------
loss: 0.045538  [    0/70632]
loss: 0.028471  [ 6400/70632]
loss: 0.076179  [12800/70632]
loss: 0.180009  [19200/70632]
loss: 0.077505  [25600/70632]
loss: 0.074536  [32000/70632]
loss: 0.054794  [38400/70632]
loss: 0.074016  [44800/70632]
loss: 0.077762  [51200/70632]
loss: 0.151285  [57600/70632]
loss: 0.082982  [64000/70632]
loss: 0.183822  [70400/70632]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.115603 

Epoch 14
-------------------------------
loss: 0.130407  [    0/70632]
loss: 0.066073  [ 6400/70632]
loss: 0.123371  [12800/70632]
loss: 0.134405  [19200/70632]
loss: 0.079654  [25600/70632]
loss: 0.045464  [32000/70632]
loss: 0.232324  [38400/70632]
loss: 0.039476  [44800/70632]
loss: 0.060095  [51200/70632]
loss: 0.088145  [57600/70632]
loss: 0.191829  [64000/70632]
loss: 0.097879  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.111362 

Epoch 15
-------------------------------
loss: 0.135225  [    0/70632]
loss: 0.255241  [ 6400/70632]
loss: 0.098753  [12800/70632]
loss: 0.118858  [19200/70632]
loss: 0.079260  [25600/70632]
loss: 0.062458  [32000/70632]
loss: 0.057524  [38400/70632]
loss: 0.055958  [44800/70632]
loss: 0.131055  [51200/70632]
loss: 0.053636  [57600/70632]
loss: 0.098222  [64000/70632]
loss: 0.117940  [70400/70632]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.107211 

Epoch 16
-------------------------------
loss: 0.125280  [    0/70632]
loss: 0.080370  [ 6400/70632]
loss: 0.106578  [12800/70632]
loss: 0.095705  [19200/70632]
loss: 0.029835  [25600/70632]
loss: 0.059198  [32000/70632]
loss: 0.065984  [38400/70632]
loss: 0.079287  [44800/70632]
loss: 0.080351  [51200/70632]
loss: 0.146395  [57600/70632]
loss: 0.074376  [64000/70632]
loss: 0.075238  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.106191 

Epoch 17
-------------------------------
loss: 0.045465  [    0/70632]
loss: 0.110345  [ 6400/70632]
loss: 0.131703  [12800/70632]
loss: 0.071915  [19200/70632]
loss: 0.100395  [25600/70632]
loss: 0.101623  [32000/70632]
loss: 0.055265  [38400/70632]
loss: 0.120080  [44800/70632]
loss: 0.112882  [51200/70632]
loss: 0.185214  [57600/70632]
loss: 0.076966  [64000/70632]
loss: 0.129271  [70400/70632]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.115934 

Epoch 18
-------------------------------
loss: 0.081970  [    0/70632]
loss: 0.071768  [ 6400/70632]
loss: 0.065243  [12800/70632]
loss: 0.099190  [19200/70632]
loss: 0.125629  [25600/70632]
loss: 0.114305  [32000/70632]
loss: 0.059488  [38400/70632]
loss: 0.054946  [44800/70632]
loss: 0.113315  [51200/70632]
loss: 0.060072  [57600/70632]
loss: 0.062653  [64000/70632]
loss: 0.096035  [70400/70632]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.107167 

Epoch 19
-------------------------------
loss: 0.040266  [    0/70632]
loss: 0.060349  [ 6400/70632]
loss: 0.085948  [12800/70632]
loss: 0.083510  [19200/70632]
loss: 0.159901  [25600/70632]
loss: 0.064170  [32000/70632]
loss: 0.173969  [38400/70632]
loss: 0.037168  [44800/70632]
loss: 0.170934  [51200/70632]
loss: 0.086839  [57600/70632]
loss: 0.084718  [64000/70632]
loss: 0.045431  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.102687 

Epoch 20
-------------------------------
loss: 0.115588  [    0/70632]
loss: 0.084191  [ 6400/70632]
loss: 0.144756  [12800/70632]
loss: 0.067081  [19200/70632]
loss: 0.053403  [25600/70632]
loss: 0.095178  [32000/70632]
loss: 0.106222  [38400/70632]
loss: 0.071882  [44800/70632]
loss: 0.142459  [51200/70632]
loss: 0.151262  [57600/70632]
loss: 0.066774  [64000/70632]
loss: 0.094287  [70400/70632]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.101873 

Epoch 21
-------------------------------
loss: 0.066158  [    0/70632]
loss: 0.114472  [ 6400/70632]
loss: 0.121573  [12800/70632]
loss: 0.118684  [19200/70632]
loss: 0.082152  [25600/70632]
loss: 0.111154  [32000/70632]
loss: 0.145479  [38400/70632]
loss: 0.166426  [44800/70632]
loss: 0.051830  [51200/70632]
loss: 0.082443  [57600/70632]
loss: 0.053041  [64000/70632]
loss: 0.043373  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102417 

Epoch 22
-------------------------------
loss: 0.028243  [    0/70632]
loss: 0.040253  [ 6400/70632]
loss: 0.066307  [12800/70632]
loss: 0.129128  [19200/70632]
loss: 0.114349  [25600/70632]
loss: 0.145108  [32000/70632]
loss: 0.059958  [38400/70632]
loss: 0.092851  [44800/70632]
loss: 0.111078  [51200/70632]
loss: 0.163484  [57600/70632]
loss: 0.143418  [64000/70632]
loss: 0.058112  [70400/70632]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.102777 

Epoch 23
-------------------------------
loss: 0.132637  [    0/70632]
loss: 0.137428  [ 6400/70632]
loss: 0.097994  [12800/70632]
loss: 0.091813  [19200/70632]
loss: 0.129886  [25600/70632]
loss: 0.048648  [32000/70632]
loss: 0.095399  [38400/70632]
loss: 0.092798  [44800/70632]
loss: 0.087666  [51200/70632]
loss: 0.047372  [57600/70632]
loss: 0.073896  [64000/70632]
loss: 0.028194  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.111454 

Epoch 24
-------------------------------
loss: 0.055570  [    0/70632]
loss: 0.146772  [ 6400/70632]
loss: 0.084518  [12800/70632]
loss: 0.031748  [19200/70632]
loss: 0.100428  [25600/70632]
loss: 0.107382  [32000/70632]
loss: 0.020822  [38400/70632]
loss: 0.075724  [44800/70632]
loss: 0.041928  [51200/70632]
loss: 0.046642  [57600/70632]
loss: 0.139117  [64000/70632]
loss: 0.058825  [70400/70632]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.102040 

Epoch 25
-------------------------------
loss: 0.075775  [    0/70632]
loss: 0.167215  [ 6400/70632]
loss: 0.081971  [12800/70632]
loss: 0.092009  [19200/70632]
loss: 0.091244  [25600/70632]
loss: 0.115363  [32000/70632]
loss: 0.190450  [38400/70632]
loss: 0.088161  [44800/70632]
loss: 0.115762  [51200/70632]
loss: 0.079396  [57600/70632]
loss: 0.130374  [64000/70632]
loss: 0.107510  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.105185 

Epoch 26
-------------------------------
loss: 0.204928  [    0/70632]
loss: 0.056905  [ 6400/70632]
loss: 0.053663  [12800/70632]
loss: 0.275980  [19200/70632]
loss: 0.247072  [25600/70632]
loss: 0.155592  [32000/70632]
loss: 0.119992  [38400/70632]
loss: 0.137921  [44800/70632]
loss: 0.138105  [51200/70632]
loss: 0.070197  [57600/70632]
loss: 0.238416  [64000/70632]
loss: 0.103259  [70400/70632]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.113537 

Epoch 27
-------------------------------
loss: 0.094699  [    0/70632]
loss: 0.044440  [ 6400/70632]
loss: 0.017485  [12800/70632]
loss: 0.069692  [19200/70632]
loss: 0.073858  [25600/70632]
loss: 0.035561  [32000/70632]
loss: 0.055078  [38400/70632]
loss: 0.072414  [44800/70632]
loss: 0.066679  [51200/70632]
loss: 0.193878  [57600/70632]
loss: 0.076334  [64000/70632]
loss: 0.071292  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110078 

Epoch 28
-------------------------------
loss: 0.128958  [    0/70632]
loss: 0.093243  [ 6400/70632]
loss: 0.097315  [12800/70632]
loss: 0.101526  [19200/70632]
loss: 0.083499  [25600/70632]
loss: 0.127816  [32000/70632]
loss: 0.084016  [38400/70632]
loss: 0.099320  [44800/70632]
loss: 0.071200  [51200/70632]
loss: 0.090672  [57600/70632]
loss: 0.125586  [64000/70632]
loss: 0.094624  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.105462 

Epoch 29
-------------------------------
loss: 0.062065  [    0/70632]
loss: 0.112543  [ 6400/70632]
loss: 0.189796  [12800/70632]
loss: 0.065000  [19200/70632]
loss: 0.077960  [25600/70632]
loss: 0.065581  [32000/70632]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.167653 

Epoch 50
-------------------------------
loss: 0.219553  [    0/69698]
loss: 0.118371  [ 6400/69698]
loss: 0.110030  [12800/69698]
loss: 0.236282  [19200/69698]
loss: 0.173230  [25600/69698]
loss: 0.069182  [32000/69698]
loss: 0.222824  [38400/69698]
loss: 0.109633  [44800/69698]
loss: 0.209773  [51200/69698]
loss: 0.057470  [57600/69698]
loss: 0.178336  [64000/69698]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.162844 

Epoch 1
-------------------------------
loss: 0.681167  [    0/71147]
loss: 0.305136  [ 6400/71147]
loss: 0.182676  [12800/71147]
loss: 0.341124  [19200/71147]
loss: 0.253616  [25600/71147]
loss: 0.123103  [32000/71147]
loss: 0.210436  [38400/71147]
loss: 0.227699  [44800/71147]
loss: 0.241789  [51200/71147]
loss: 0.200807  [57600/71147]
loss: 0.312454  [64000/71147]
loss: 0.125450  [70400/71147]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.203441 

Epoch 2
-------------------------------
loss: 0.259421  [    0/71147]
loss: 0.164779  [ 6400/71147]
loss: 0.130940  [12800/71147]
loss: 0.152175  [19200/71147]
loss: 0.174163  [25600/71147]
loss: 0.189279  [32000/71147]
loss: 0.163431  [38400/71147]
loss: 0.134697  [44800/71147]
loss: 0.251533  [51200/71147]
loss: 0.173729  [57600/71147]
loss: 0.145489  [64000/71147]
loss: 0.185439  [70400/71147]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.166712 

Epoch 3
-------------------------------
loss: 0.146345  [    0/71147]
loss: 0.301607  [ 6400/71147]
loss: 0.197825  [12800/71147]
loss: 0.176830  [19200/71147]
loss: 0.136314  [25600/71147]
loss: 0.215454  [32000/71147]
loss: 0.216316  [38400/71147]
loss: 0.150452  [44800/71147]
loss: 0.237599  [51200/71147]
loss: 0.134642  [57600/71147]
loss: 0.162161  [64000/71147]
loss: 0.170409  [70400/71147]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174492 

Epoch 4
-------------------------------
loss: 0.177955  [    0/71147]
loss: 0.251249  [ 6400/71147]
loss: 0.137203  [12800/71147]
loss: 0.222334  [19200/71147]
loss: 0.105812  [25600/71147]
loss: 0.148387  [32000/71147]
loss: 0.209707  [38400/71147]
loss: 0.099016  [44800/71147]
loss: 0.133255  [51200/71147]
loss: 0.128213  [57600/71147]
loss: 0.053657  [64000/71147]
loss: 0.285523  [70400/71147]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.166980 

Epoch 5
-------------------------------
loss: 0.101179  [    0/71147]
loss: 0.124508  [ 6400/71147]
loss: 0.173273  [12800/71147]
loss: 0.297600  [19200/71147]
loss: 0.167415  [25600/71147]
loss: 0.217656  [32000/71147]
loss: 0.096809  [38400/71147]
loss: 0.205909  [44800/71147]
loss: 0.132763  [51200/71147]
loss: 0.197312  [57600/71147]
loss: 0.146928  [64000/71147]
loss: 0.214945  [70400/71147]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160956 

Epoch 6
-------------------------------
loss: 0.168867  [    0/71147]
loss: 0.056585  [ 6400/71147]
loss: 0.153078  [12800/71147]
loss: 0.103342  [19200/71147]
loss: 0.145184  [25600/71147]
loss: 0.272451  [32000/71147]
loss: 0.121100  [38400/71147]
loss: 0.190906  [44800/71147]
loss: 0.114863  [51200/71147]
loss: 0.146929  [57600/71147]
loss: 0.108868  [64000/71147]
loss: 0.155559  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159993 

Epoch 7
-------------------------------
loss: 0.192320  [    0/71147]
loss: 0.185076  [ 6400/71147]
loss: 0.092555  [12800/71147]
loss: 0.110044  [19200/71147]
loss: 0.200697  [25600/71147]
loss: 0.153219  [32000/71147]
loss: 0.177745  [38400/71147]
loss: 0.178694  [44800/71147]
loss: 0.232234  [51200/71147]
loss: 0.126890  [57600/71147]
loss: 0.196013  [64000/71147]
loss: 0.143515  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.160640 

Epoch 8
-------------------------------
loss: 0.136875  [    0/71147]
loss: 0.124006  [ 6400/71147]
loss: 0.275326  [12800/71147]
loss: 0.116256  [19200/71147]
loss: 0.220466  [25600/71147]
loss: 0.143992  [32000/71147]
loss: 0.075330  [38400/71147]
loss: 0.156042  [44800/71147]
loss: 0.074673  [51200/71147]
loss: 0.075145  [57600/71147]
loss: 0.107633  [64000/71147]
loss: 0.133109  [70400/71147]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.167215 

Epoch 9
-------------------------------
loss: 0.222198  [    0/71147]
loss: 0.294878  [ 6400/71147]
loss: 0.179734  [12800/71147]
loss: 0.200763  [19200/71147]
loss: 0.175173  [25600/71147]
loss: 0.114317  [32000/71147]
loss: 0.166516  [38400/71147]
loss: 0.154986  [44800/71147]
loss: 0.083544  [51200/71147]
loss: 0.129239  [57600/71147]
loss: 0.176854  [64000/71147]
loss: 0.181949  [70400/71147]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.169671 

Epoch 10
-------------------------------
loss: 0.172011  [    0/71147]
loss: 0.074139  [ 6400/71147]
loss: 0.184296  [12800/71147]
loss: 0.092443  [19200/71147]
loss: 0.185979  [25600/71147]
loss: 0.128529  [32000/71147]
loss: 0.292079  [38400/71147]
loss: 0.143819  [44800/71147]
loss: 0.068168  [51200/71147]
loss: 0.117303  [57600/71147]
loss: 0.101151  [64000/71147]
loss: 0.162526  [70400/71147]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.153973 

Epoch 11
-------------------------------
loss: 0.117733  [    0/71147]
loss: 0.109119  [ 6400/71147]
loss: 0.132670  [12800/71147]
loss: 0.171988  [19200/71147]
loss: 0.087712  [25600/71147]
loss: 0.061600  [32000/71147]
loss: 0.294898  [38400/71147]
loss: 0.086150  [44800/71147]
loss: 0.125184  [51200/71147]
loss: 0.149853  [57600/71147]
loss: 0.144635  [64000/71147]
loss: 0.161793  [70400/71147]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160554 

Epoch 12
-------------------------------
loss: 0.200094  [    0/71147]
loss: 0.093954  [ 6400/71147]
loss: 0.128518  [12800/71147]
loss: 0.251198  [19200/71147]
loss: 0.256900  [25600/71147]
loss: 0.134112  [32000/71147]
loss: 0.160894  [38400/71147]
loss: 0.116805  [44800/71147]
loss: 0.123755  [51200/71147]
loss: 0.158140  [57600/71147]
loss: 0.136417  [64000/71147]
loss: 0.222277  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.155107 

Epoch 13
-------------------------------
loss: 0.176009  [    0/71147]
loss: 0.121159  [ 6400/71147]
loss: 0.070441  [12800/71147]
loss: 0.069264  [19200/71147]
loss: 0.151978  [25600/71147]
loss: 0.141771  [32000/71147]
loss: 0.167536  [38400/71147]
loss: 0.174668  [44800/71147]
loss: 0.176924  [51200/71147]
loss: 0.127026  [57600/71147]
loss: 0.125470  [64000/71147]
loss: 0.141386  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.153005 

Epoch 14
-------------------------------
loss: 0.114634  [    0/71147]
loss: 0.134434  [ 6400/71147]
loss: 0.132141  [12800/71147]
loss: 0.238896  [19200/71147]
loss: 0.088269  [25600/71147]
loss: 0.206856  [32000/71147]
loss: 0.117097  [38400/71147]
loss: 0.069173  [44800/71147]
loss: 0.117932  [51200/71147]
loss: 0.157334  [57600/71147]
loss: 0.057889  [64000/71147]
loss: 0.134079  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150212 

Epoch 15
-------------------------------
loss: 0.169953  [    0/71147]
loss: 0.093618  [ 6400/71147]
loss: 0.267693  [12800/71147]
loss: 0.134098  [19200/71147]
loss: 0.136401  [25600/71147]
loss: 0.115996  [32000/71147]
loss: 0.110127  [38400/71147]
loss: 0.097141  [44800/71147]
loss: 0.091818  [51200/71147]
loss: 0.201075  [57600/71147]
loss: 0.164358  [64000/71147]
loss: 0.176709  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.164861 

Epoch 16
-------------------------------
loss: 0.100639  [    0/71147]
loss: 0.173659  [ 6400/71147]
loss: 0.092465  [12800/71147]
loss: 0.159947  [19200/71147]
loss: 0.088008  [25600/71147]
loss: 0.081578  [32000/71147]
loss: 0.086933  [38400/71147]
loss: 0.253367  [44800/71147]
loss: 0.128510  [51200/71147]
loss: 0.054792  [57600/71147]
loss: 0.182832  [64000/71147]
loss: 0.167475  [70400/71147]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.171444 

Epoch 17
-------------------------------
loss: 0.206805  [    0/71147]
loss: 0.070462  [ 6400/71147]
loss: 0.190693  [12800/71147]
loss: 0.161581  [19200/71147]
loss: 0.069696  [25600/71147]
loss: 0.112430  [32000/71147]
loss: 0.183402  [38400/71147]
loss: 0.214428  [44800/71147]
loss: 0.165228  [51200/71147]
loss: 0.083602  [57600/71147]
loss: 0.138937  [64000/71147]
loss: 0.123664  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.165954 

loss: 0.092667  [25600/70352]
loss: 0.028503  [32000/70352]
loss: 0.148693  [38400/70352]
loss: 0.088892  [44800/70352]
loss: 0.071053  [51200/70352]
loss: 0.171795  [57600/70352]
loss: 0.098019  [64000/70352]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.124522 

Epoch 20
-------------------------------
loss: 0.125483  [    0/70352]
loss: 0.092947  [ 6400/70352]
loss: 0.115034  [12800/70352]
loss: 0.046330  [19200/70352]
loss: 0.131994  [25600/70352]
loss: 0.061181  [32000/70352]
loss: 0.031037  [38400/70352]
loss: 0.028652  [44800/70352]
loss: 0.075411  [51200/70352]
loss: 0.060906  [57600/70352]
loss: 0.049277  [64000/70352]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.123691 

Epoch 21
-------------------------------
loss: 0.128952  [    0/70352]
loss: 0.077718  [ 6400/70352]
loss: 0.023370  [12800/70352]
loss: 0.035772  [19200/70352]
loss: 0.040352  [25600/70352]
loss: 0.037851  [32000/70352]
loss: 0.116641  [38400/70352]
loss: 0.028752  [44800/70352]
loss: 0.092998  [51200/70352]
loss: 0.111479  [57600/70352]
loss: 0.062593  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.117125 

Epoch 22
-------------------------------
loss: 0.031011  [    0/70352]
loss: 0.107314  [ 6400/70352]
loss: 0.111319  [12800/70352]
loss: 0.009391  [19200/70352]
loss: 0.049165  [25600/70352]
loss: 0.107272  [32000/70352]
loss: 0.104050  [38400/70352]
loss: 0.058501  [44800/70352]
loss: 0.076616  [51200/70352]
loss: 0.041145  [57600/70352]
loss: 0.130666  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.124807 

Epoch 23
-------------------------------
loss: 0.041893  [    0/70352]
loss: 0.113802  [ 6400/70352]
loss: 0.034534  [12800/70352]
loss: 0.045617  [19200/70352]
loss: 0.082016  [25600/70352]
loss: 0.043515  [32000/70352]
loss: 0.024514  [38400/70352]
loss: 0.076520  [44800/70352]
loss: 0.237075  [51200/70352]
loss: 0.054610  [57600/70352]
loss: 0.138591  [64000/70352]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.131779 

Epoch 24
-------------------------------
loss: 0.149099  [    0/70352]
loss: 0.121246  [ 6400/70352]
loss: 0.073693  [12800/70352]
loss: 0.117671  [19200/70352]
loss: 0.029396  [25600/70352]
loss: 0.028393  [32000/70352]
loss: 0.087469  [38400/70352]
loss: 0.067782  [44800/70352]
loss: 0.099523  [51200/70352]
loss: 0.073952  [57600/70352]
loss: 0.085129  [64000/70352]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.139953 

Epoch 25
-------------------------------
loss: 0.013998  [    0/70352]
loss: 0.077719  [ 6400/70352]
loss: 0.030952  [12800/70352]
loss: 0.141552  [19200/70352]
loss: 0.213299  [25600/70352]
loss: 0.123645  [32000/70352]
loss: 0.025237  [38400/70352]
loss: 0.032662  [44800/70352]
loss: 0.116734  [51200/70352]
loss: 0.052294  [57600/70352]
loss: 0.020522  [64000/70352]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.121470 

Epoch 26
-------------------------------
loss: 0.116700  [    0/70352]
loss: 0.050401  [ 6400/70352]
loss: 0.062641  [12800/70352]
loss: 0.029025  [19200/70352]
loss: 0.033635  [25600/70352]
loss: 0.059132  [32000/70352]
loss: 0.011376  [38400/70352]
loss: 0.093472  [44800/70352]
loss: 0.025551  [51200/70352]
loss: 0.044088  [57600/70352]
loss: 0.087880  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.121168 

Epoch 27
-------------------------------
loss: 0.097564  [    0/70352]
loss: 0.068449  [ 6400/70352]
loss: 0.038139  [12800/70352]
loss: 0.127740  [19200/70352]
loss: 0.142285  [25600/70352]
loss: 0.011097  [32000/70352]
loss: 0.159755  [38400/70352]
loss: 0.188896  [44800/70352]
loss: 0.063096  [51200/70352]
loss: 0.186301  [57600/70352]
loss: 0.058681  [64000/70352]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.119669 

Epoch 28
-------------------------------
loss: 0.032525  [    0/70352]
loss: 0.127615  [ 6400/70352]
loss: 0.088947  [12800/70352]
loss: 0.101095  [19200/70352]
loss: 0.062672  [25600/70352]
loss: 0.307314  [32000/70352]
loss: 0.222594  [38400/70352]
loss: 0.045987  [44800/70352]
loss: 0.165800  [51200/70352]
loss: 0.071632  [57600/70352]
loss: 0.045793  [64000/70352]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.106846 

Epoch 29
-------------------------------
loss: 0.077820  [    0/70352]
loss: 0.056167  [ 6400/70352]
loss: 0.026692  [12800/70352]
loss: 0.024927  [19200/70352]
loss: 0.117079  [25600/70352]
loss: 0.037724  [32000/70352]
loss: 0.030495  [38400/70352]
loss: 0.166606  [44800/70352]
loss: 0.185059  [51200/70352]
loss: 0.066742  [57600/70352]
loss: 0.176074  [64000/70352]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.125951 

Epoch 30
-------------------------------
loss: 0.067878  [    0/70352]
loss: 0.220381  [ 6400/70352]
loss: 0.027642  [12800/70352]
loss: 0.065095  [19200/70352]
loss: 0.010736  [25600/70352]
loss: 0.056132  [32000/70352]
loss: 0.031356  [38400/70352]
loss: 0.029411  [44800/70352]
loss: 0.008394  [51200/70352]
loss: 0.063113  [57600/70352]
loss: 0.083945  [64000/70352]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.145806 

Epoch 31
-------------------------------
loss: 0.029843  [    0/70352]
loss: 0.089369  [ 6400/70352]
loss: 0.026995  [12800/70352]
loss: 0.157807  [19200/70352]
loss: 0.022235  [25600/70352]
loss: 0.041656  [32000/70352]
loss: 0.081565  [38400/70352]
loss: 0.101602  [44800/70352]
loss: 0.052285  [51200/70352]
loss: 0.091670  [57600/70352]
loss: 0.061027  [64000/70352]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.120054 

Epoch 32
-------------------------------
loss: 0.052466  [    0/70352]
loss: 0.070864  [ 6400/70352]
loss: 0.122724  [12800/70352]
loss: 0.048130  [19200/70352]
loss: 0.054433  [25600/70352]
loss: 0.044437  [32000/70352]
loss: 0.039818  [38400/70352]
loss: 0.059111  [44800/70352]
loss: 0.069713  [51200/70352]
loss: 0.039985  [57600/70352]
loss: 0.045670  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.108652 

Epoch 33
-------------------------------
loss: 0.033144  [    0/70352]
loss: 0.058931  [ 6400/70352]
loss: 0.039994  [12800/70352]
loss: 0.087923  [19200/70352]
loss: 0.033735  [25600/70352]
loss: 0.038911  [32000/70352]
loss: 0.068119  [38400/70352]
loss: 0.137915  [44800/70352]
loss: 0.071670  [51200/70352]
loss: 0.003448  [57600/70352]
loss: 0.102022  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.124992 

Epoch 34
-------------------------------
loss: 0.045080  [    0/70352]
loss: 0.061946  [ 6400/70352]
loss: 0.059028  [12800/70352]
loss: 0.067389  [19200/70352]
loss: 0.033628  [25600/70352]
loss: 0.068126  [32000/70352]
loss: 0.059645  [38400/70352]
loss: 0.042360  [44800/70352]
loss: 0.057526  [51200/70352]
loss: 0.076661  [57600/70352]
loss: 0.092068  [64000/70352]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.122433 

Epoch 35
-------------------------------
loss: 0.050908  [    0/70352]
loss: 0.046825  [ 6400/70352]
loss: 0.112790  [12800/70352]
loss: 0.015942  [19200/70352]
loss: 0.070796  [25600/70352]
loss: 0.046354  [32000/70352]
loss: 0.105963  [38400/70352]
loss: 0.026291  [44800/70352]
loss: 0.102070  [51200/70352]
loss: 0.049081  [57600/70352]
loss: 0.051312  [64000/70352]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.137378 

Epoch 36
-------------------------------
loss: 0.100207  [    0/70352]
loss: 0.069098  [ 6400/70352]
loss: 0.112763  [12800/70352]
loss: 0.060395  [19200/70352]
loss: 0.115659  [25600/70352]
loss: 0.076431  [32000/70352]
loss: 0.049267  [38400/70352]
loss: 0.066398  [44800/70352]
loss: 0.092261  [51200/70352]
loss: 0.085436  [57600/70352]
loss: 0.069455  [64000/70352]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.130592 

Epoch 37
-------------------------------
loss: 0.152392  [    0/70352]
loss: 0.074111  [ 6400/70352]
loss: 0.024535  [12800/70352]
loss: 0.100948  [19200/70352]
loss: 0.049534  [25600/70352]
loss: 0.157805  [32000/70352]
loss: 0.071456  [38400/70352]
loss: 0.107179  [44800/70352]
loss: 0.071712  [51200/70352]
loss: 0.051547  [57600/70352]
loss: 0.024629  [64000/70352]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.115993 

Epoch 38
-------------------------------
loss: 0.098565  [    0/70352]
loss: 0.063973  [ 6400/70352]
loss: 0.217738  [12800/70352]
loss: 0.039157  [19200/70352]
loss: 0.079772  [25600/70352]
loss: 0.087271  [32000/70352]
loss: 0.172070  [38400/70352]
loss: 0.046631  [44800/70352]
loss: 0.036441  [51200/70352]
loss: 0.238747  [32000/71148]
loss: 0.104158  [38400/71148]
loss: 0.093647  [44800/71148]
loss: 0.209242  [51200/71148]
loss: 0.109422  [57600/71148]
loss: 0.056616  [64000/71148]
loss: 0.152170  [70400/71148]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.152318 

Epoch 4
-------------------------------
loss: 0.146313  [    0/71148]
loss: 0.155271  [ 6400/71148]
loss: 0.148066  [12800/71148]
loss: 0.283853  [19200/71148]
loss: 0.082878  [25600/71148]
loss: 0.059649  [32000/71148]
loss: 0.099565  [38400/71148]
loss: 0.191648  [44800/71148]
loss: 0.100556  [51200/71148]
loss: 0.210723  [57600/71148]
loss: 0.208488  [64000/71148]
loss: 0.249520  [70400/71148]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.144509 

Epoch 5
-------------------------------
loss: 0.126535  [    0/71148]
loss: 0.203503  [ 6400/71148]
loss: 0.089162  [12800/71148]
loss: 0.177196  [19200/71148]
loss: 0.054525  [25600/71148]
loss: 0.145341  [32000/71148]
loss: 0.117037  [38400/71148]
loss: 0.131624  [44800/71148]
loss: 0.083258  [51200/71148]
loss: 0.131072  [57600/71148]
loss: 0.107180  [64000/71148]
loss: 0.099772  [70400/71148]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.149952 

Epoch 6
-------------------------------
loss: 0.140149  [    0/71148]
loss: 0.147549  [ 6400/71148]
loss: 0.218318  [12800/71148]
loss: 0.118217  [19200/71148]
loss: 0.117139  [25600/71148]
loss: 0.086037  [32000/71148]
loss: 0.133388  [38400/71148]
loss: 0.103012  [44800/71148]
loss: 0.236295  [51200/71148]
loss: 0.077555  [57600/71148]
loss: 0.224371  [64000/71148]
loss: 0.205828  [70400/71148]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139545 

Epoch 7
-------------------------------
loss: 0.305131  [    0/71148]
loss: 0.132591  [ 6400/71148]
loss: 0.124661  [12800/71148]
loss: 0.151704  [19200/71148]
loss: 0.225718  [25600/71148]
loss: 0.205337  [32000/71148]
loss: 0.092790  [38400/71148]
loss: 0.245407  [44800/71148]
loss: 0.164443  [51200/71148]
loss: 0.109429  [57600/71148]
loss: 0.117103  [64000/71148]
loss: 0.142980  [70400/71148]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.140151 

Epoch 8
-------------------------------
loss: 0.238065  [    0/71148]
loss: 0.040204  [ 6400/71148]
loss: 0.094619  [12800/71148]
loss: 0.133190  [19200/71148]
loss: 0.170724  [25600/71148]
loss: 0.197891  [32000/71148]
loss: 0.042113  [38400/71148]
loss: 0.195890  [44800/71148]
loss: 0.278708  [51200/71148]
loss: 0.131697  [57600/71148]
loss: 0.063866  [64000/71148]
loss: 0.098042  [70400/71148]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.138982 

Epoch 9
-------------------------------
loss: 0.169504  [    0/71148]
loss: 0.090413  [ 6400/71148]
loss: 0.040593  [12800/71148]
loss: 0.195158  [19200/71148]
loss: 0.181093  [25600/71148]
loss: 0.122613  [32000/71148]
loss: 0.210033  [38400/71148]
loss: 0.179772  [44800/71148]
loss: 0.209913  [51200/71148]
loss: 0.181532  [57600/71148]
loss: 0.153800  [64000/71148]
loss: 0.128976  [70400/71148]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.140220 

Epoch 10
-------------------------------
loss: 0.056730  [    0/71148]
loss: 0.111223  [ 6400/71148]
loss: 0.082672  [12800/71148]
loss: 0.104103  [19200/71148]
loss: 0.130845  [25600/71148]
loss: 0.160781  [32000/71148]
loss: 0.280979  [38400/71148]
loss: 0.126616  [44800/71148]
loss: 0.180785  [51200/71148]
loss: 0.104033  [57600/71148]
loss: 0.078858  [64000/71148]
loss: 0.197852  [70400/71148]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.143292 

Epoch 11
-------------------------------
loss: 0.083767  [    0/71148]
loss: 0.155434  [ 6400/71148]
loss: 0.151158  [12800/71148]
loss: 0.163738  [19200/71148]
loss: 0.108797  [25600/71148]
loss: 0.098577  [32000/71148]
loss: 0.188335  [38400/71148]
loss: 0.145120  [44800/71148]
loss: 0.090740  [51200/71148]
loss: 0.118227  [57600/71148]
loss: 0.132786  [64000/71148]
loss: 0.154400  [70400/71148]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.135161 

Epoch 12
-------------------------------
loss: 0.086365  [    0/71148]
loss: 0.056734  [ 6400/71148]
loss: 0.100220  [12800/71148]
loss: 0.101320  [19200/71148]
loss: 0.108413  [25600/71148]
loss: 0.078801  [32000/71148]
loss: 0.113762  [38400/71148]
loss: 0.186259  [44800/71148]
loss: 0.173944  [51200/71148]
loss: 0.206358  [57600/71148]
loss: 0.102612  [64000/71148]
loss: 0.132097  [70400/71148]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.134271 

Epoch 13
-------------------------------
loss: 0.163139  [    0/71148]
loss: 0.253257  [ 6400/71148]
loss: 0.154525  [12800/71148]
loss: 0.075061  [19200/71148]
loss: 0.060979  [25600/71148]
loss: 0.127199  [32000/71148]
loss: 0.199362  [38400/71148]
loss: 0.149129  [44800/71148]
loss: 0.178525  [51200/71148]
loss: 0.124280  [57600/71148]
loss: 0.124993  [64000/71148]
loss: 0.108822  [70400/71148]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.137527 

Epoch 14
-------------------------------
loss: 0.139497  [    0/71148]
loss: 0.171102  [ 6400/71148]
loss: 0.083662  [12800/71148]
loss: 0.090807  [19200/71148]
loss: 0.095920  [25600/71148]
loss: 0.100556  [32000/71148]
loss: 0.134383  [38400/71148]
loss: 0.126909  [44800/71148]
loss: 0.141017  [51200/71148]
loss: 0.156503  [57600/71148]
loss: 0.115289  [64000/71148]
loss: 0.040095  [70400/71148]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.152584 

Epoch 15
-------------------------------
loss: 0.070756  [    0/71148]
loss: 0.080895  [ 6400/71148]
loss: 0.095690  [12800/71148]
loss: 0.152031  [19200/71148]
loss: 0.181872  [25600/71148]
loss: 0.109616  [32000/71148]
loss: 0.208384  [38400/71148]
loss: 0.036853  [44800/71148]
loss: 0.137287  [51200/71148]
loss: 0.140532  [57600/71148]
loss: 0.141837  [64000/71148]
loss: 0.136396  [70400/71148]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.142794 

Epoch 16
-------------------------------
loss: 0.109405  [    0/71148]
loss: 0.124805  [ 6400/71148]
loss: 0.093404  [12800/71148]
loss: 0.128736  [19200/71148]
loss: 0.108427  [25600/71148]
loss: 0.130868  [32000/71148]
loss: 0.090562  [38400/71148]
loss: 0.176392  [44800/71148]
loss: 0.183501  [51200/71148]
loss: 0.133076  [57600/71148]
loss: 0.244112  [64000/71148]
loss: 0.313032  [70400/71148]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.134342 

Epoch 17
-------------------------------
loss: 0.115133  [    0/71148]
loss: 0.077873  [ 6400/71148]
loss: 0.180398  [12800/71148]
loss: 0.148146  [19200/71148]
loss: 0.108501  [25600/71148]
loss: 0.103880  [32000/71148]
loss: 0.158385  [38400/71148]
loss: 0.015474  [44800/71148]
loss: 0.081178  [51200/71148]
loss: 0.093892  [57600/71148]
loss: 0.065174  [64000/71148]
loss: 0.092241  [70400/71148]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.134741 

Epoch 18
-------------------------------
loss: 0.041306  [    0/71148]
loss: 0.183335  [ 6400/71148]
loss: 0.094411  [12800/71148]
loss: 0.156731  [19200/71148]
loss: 0.092312  [25600/71148]
loss: 0.074988  [32000/71148]
loss: 0.144689  [38400/71148]
loss: 0.094529  [44800/71148]
loss: 0.108642  [51200/71148]
loss: 0.136187  [57600/71148]
loss: 0.101512  [64000/71148]
loss: 0.193792  [70400/71148]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.140419 

Epoch 19
-------------------------------
loss: 0.147781  [    0/71148]
loss: 0.086744  [ 6400/71148]
loss: 0.070940  [12800/71148]
loss: 0.120176  [19200/71148]
loss: 0.103036  [25600/71148]
loss: 0.152711  [32000/71148]
loss: 0.098563  [38400/71148]
loss: 0.060295  [44800/71148]
loss: 0.059137  [51200/71148]
loss: 0.168467  [57600/71148]
loss: 0.178497  [64000/71148]
loss: 0.103370  [70400/71148]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.137577 

Epoch 20
-------------------------------
loss: 0.118394  [    0/71148]
loss: 0.051436  [ 6400/71148]
loss: 0.218294  [12800/71148]
loss: 0.091940  [19200/71148]
loss: 0.072274  [25600/71148]
loss: 0.087876  [32000/71148]
loss: 0.133694  [38400/71148]
loss: 0.116063  [44800/71148]
loss: 0.137685  [51200/71148]
loss: 0.103044  [57600/71148]
loss: 0.064009  [64000/71148]
loss: 0.085828  [70400/71148]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147142 

Epoch 21
-------------------------------
loss: 0.251477  [    0/71148]
loss: 0.125756  [ 6400/71148]
loss: 0.118760  [12800/71148]
loss: 0.088371  [19200/71148]
loss: 0.192671  [25600/71148]
loss: 0.193884  [32000/71148]
loss: 0.129331  [51200/69860]
loss: 0.063599  [57600/69860]
loss: 0.191450  [64000/69860]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.107018 

Epoch 16
-------------------------------
loss: 0.100929  [    0/69860]
loss: 0.103576  [ 6400/69860]
loss: 0.080448  [12800/69860]
loss: 0.108486  [19200/69860]
loss: 0.056043  [25600/69860]
loss: 0.058150  [32000/69860]
loss: 0.094043  [38400/69860]
loss: 0.044514  [44800/69860]
loss: 0.157390  [51200/69860]
loss: 0.127916  [57600/69860]
loss: 0.202152  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.096186 

Epoch 17
-------------------------------
loss: 0.042756  [    0/69860]
loss: 0.045797  [ 6400/69860]
loss: 0.119250  [12800/69860]
loss: 0.066787  [19200/69860]
loss: 0.110583  [25600/69860]
loss: 0.099223  [32000/69860]
loss: 0.039880  [38400/69860]
loss: 0.105427  [44800/69860]
loss: 0.084370  [51200/69860]
loss: 0.121772  [57600/69860]
loss: 0.153697  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099743 

Epoch 18
-------------------------------
loss: 0.069904  [    0/69860]
loss: 0.217213  [ 6400/69860]
loss: 0.048686  [12800/69860]
loss: 0.095509  [19200/69860]
loss: 0.037643  [25600/69860]
loss: 0.109484  [32000/69860]
loss: 0.102667  [38400/69860]
loss: 0.092005  [44800/69860]
loss: 0.106272  [51200/69860]
loss: 0.206331  [57600/69860]
loss: 0.080349  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.100223 

Epoch 19
-------------------------------
loss: 0.153285  [    0/69860]
loss: 0.114187  [ 6400/69860]
loss: 0.191238  [12800/69860]
loss: 0.106659  [19200/69860]
loss: 0.134981  [25600/69860]
loss: 0.085086  [32000/69860]
loss: 0.147634  [38400/69860]
loss: 0.054190  [44800/69860]
loss: 0.151497  [51200/69860]
loss: 0.032874  [57600/69860]
loss: 0.115770  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.100071 

Epoch 20
-------------------------------
loss: 0.097760  [    0/69860]
loss: 0.061743  [ 6400/69860]
loss: 0.044598  [12800/69860]
loss: 0.065908  [19200/69860]
loss: 0.089623  [25600/69860]
loss: 0.085071  [32000/69860]
loss: 0.099983  [38400/69860]
loss: 0.069635  [44800/69860]
loss: 0.169202  [51200/69860]
loss: 0.068346  [57600/69860]
loss: 0.078840  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.098924 

Epoch 21
-------------------------------
loss: 0.195896  [    0/69860]
loss: 0.112583  [ 6400/69860]
loss: 0.033628  [12800/69860]
loss: 0.162786  [19200/69860]
loss: 0.110040  [25600/69860]
loss: 0.123084  [32000/69860]
loss: 0.144175  [38400/69860]
loss: 0.047107  [44800/69860]
loss: 0.034430  [51200/69860]
loss: 0.065565  [57600/69860]
loss: 0.070708  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.105492 

Epoch 22
-------------------------------
loss: 0.087511  [    0/69860]
loss: 0.070245  [ 6400/69860]
loss: 0.120663  [12800/69860]
loss: 0.105766  [19200/69860]
loss: 0.171918  [25600/69860]
loss: 0.299510  [32000/69860]
loss: 0.086225  [38400/69860]
loss: 0.150286  [44800/69860]
loss: 0.089649  [51200/69860]
loss: 0.120164  [57600/69860]
loss: 0.054519  [64000/69860]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.104712 

Epoch 23
-------------------------------
loss: 0.091472  [    0/69860]
loss: 0.130677  [ 6400/69860]
loss: 0.132052  [12800/69860]
loss: 0.077045  [19200/69860]
loss: 0.067845  [25600/69860]
loss: 0.152923  [32000/69860]
loss: 0.034983  [38400/69860]
loss: 0.076790  [44800/69860]
loss: 0.248734  [51200/69860]
loss: 0.052285  [57600/69860]
loss: 0.165773  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099897 

Epoch 24
-------------------------------
loss: 0.127157  [    0/69860]
loss: 0.151299  [ 6400/69860]
loss: 0.030908  [12800/69860]
loss: 0.086570  [19200/69860]
loss: 0.088174  [25600/69860]
loss: 0.067904  [32000/69860]
loss: 0.051422  [38400/69860]
loss: 0.048708  [44800/69860]
loss: 0.074990  [51200/69860]
loss: 0.076129  [57600/69860]
loss: 0.165465  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.104367 

Epoch 25
-------------------------------
loss: 0.098172  [    0/69860]
loss: 0.060681  [ 6400/69860]
loss: 0.182802  [12800/69860]
loss: 0.067343  [19200/69860]
loss: 0.046254  [25600/69860]
loss: 0.104564  [32000/69860]
loss: 0.050064  [38400/69860]
loss: 0.125431  [44800/69860]
loss: 0.045058  [51200/69860]
loss: 0.116256  [57600/69860]
loss: 0.047695  [64000/69860]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.097324 

Epoch 26
-------------------------------
loss: 0.182798  [    0/69860]
loss: 0.014526  [ 6400/69860]
loss: 0.201076  [12800/69860]
loss: 0.048261  [19200/69860]
loss: 0.210860  [25600/69860]
loss: 0.146894  [32000/69860]
loss: 0.141700  [38400/69860]
loss: 0.172836  [44800/69860]
loss: 0.130506  [51200/69860]
loss: 0.031544  [57600/69860]
loss: 0.056796  [64000/69860]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.120482 

Epoch 27
-------------------------------
loss: 0.124561  [    0/69860]
loss: 0.054869  [ 6400/69860]
loss: 0.101039  [12800/69860]
loss: 0.054353  [19200/69860]
loss: 0.065264  [25600/69860]
loss: 0.239450  [32000/69860]
loss: 0.225418  [38400/69860]
loss: 0.085434  [44800/69860]
loss: 0.120131  [51200/69860]
loss: 0.132196  [57600/69860]
loss: 0.070492  [64000/69860]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.096202 

Epoch 28
-------------------------------
loss: 0.071908  [    0/69860]
loss: 0.057694  [ 6400/69860]
loss: 0.037607  [12800/69860]
loss: 0.031443  [19200/69860]
loss: 0.057997  [25600/69860]
loss: 0.274960  [32000/69860]
loss: 0.041615  [38400/69860]
loss: 0.027800  [44800/69860]
loss: 0.055562  [51200/69860]
loss: 0.100753  [57600/69860]
loss: 0.104179  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.103326 

Epoch 29
-------------------------------
loss: 0.062733  [    0/69860]
loss: 0.103012  [ 6400/69860]
loss: 0.091955  [12800/69860]
loss: 0.068587  [19200/69860]
loss: 0.089696  [25600/69860]
loss: 0.059866  [32000/69860]
loss: 0.220009  [38400/69860]
loss: 0.111152  [44800/69860]
loss: 0.070089  [51200/69860]
loss: 0.048849  [57600/69860]
loss: 0.153650  [64000/69860]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.125370 

Epoch 30
-------------------------------
loss: 0.123506  [    0/69860]
loss: 0.071419  [ 6400/69860]
loss: 0.065769  [12800/69860]
loss: 0.143085  [19200/69860]
loss: 0.103816  [25600/69860]
loss: 0.094721  [32000/69860]
loss: 0.050845  [38400/69860]
loss: 0.110704  [44800/69860]
loss: 0.081963  [51200/69860]
loss: 0.219085  [57600/69860]
loss: 0.119650  [64000/69860]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.106018 

Epoch 31
-------------------------------
loss: 0.139641  [    0/69860]
loss: 0.086968  [ 6400/69860]
loss: 0.065327  [12800/69860]
loss: 0.133015  [19200/69860]
loss: 0.209200  [25600/69860]
loss: 0.064846  [32000/69860]
loss: 0.055375  [38400/69860]
loss: 0.172949  [44800/69860]
loss: 0.154516  [51200/69860]
loss: 0.113062  [57600/69860]
loss: 0.091992  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.101986 

Epoch 32
-------------------------------
loss: 0.063445  [    0/69860]
loss: 0.179895  [ 6400/69860]
loss: 0.247898  [12800/69860]
loss: 0.132309  [19200/69860]
loss: 0.038691  [25600/69860]
loss: 0.108616  [32000/69860]
loss: 0.098287  [38400/69860]
loss: 0.099288  [44800/69860]
loss: 0.104983  [51200/69860]
loss: 0.049732  [57600/69860]
loss: 0.167101  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.096680 

Epoch 33
-------------------------------
loss: 0.040172  [    0/69860]
loss: 0.142258  [ 6400/69860]
loss: 0.166311  [12800/69860]
loss: 0.044057  [19200/69860]
loss: 0.088349  [25600/69860]
loss: 0.133689  [32000/69860]
loss: 0.047719  [38400/69860]
loss: 0.064670  [44800/69860]
loss: 0.052009  [51200/69860]
loss: 0.079234  [57600/69860]
loss: 0.106448  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099119 

Epoch 34
-------------------------------
loss: 0.030054  [    0/69860]
loss: 0.056133  [ 6400/69860]
loss: 0.060736  [12800/69860]
loss: 0.074987  [19200/69860]
loss: 0.028441  [25600/69860]
loss: 0.196643  [32000/69860]
loss: 0.130621  [38400/69860]
loss: 0.119567  [44800/69860]
loss: 0.099395  [51200/69860]
loss: 0.032249  [57600/69860]
loss: 0.107455  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.105626 

loss: 0.032494  [57600/71143]
loss: 0.072337  [64000/71143]
loss: 0.094338  [70400/71143]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.077988 

Epoch 15
-------------------------------
loss: 0.042537  [    0/71143]
loss: 0.074152  [ 6400/71143]
loss: 0.102477  [12800/71143]
loss: 0.035002  [19200/71143]
loss: 0.124097  [25600/71143]
loss: 0.096313  [32000/71143]
loss: 0.099066  [38400/71143]
loss: 0.126938  [44800/71143]
loss: 0.049111  [51200/71143]
loss: 0.052122  [57600/71143]
loss: 0.083570  [64000/71143]
loss: 0.094929  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.078948 

Epoch 16
-------------------------------
loss: 0.053356  [    0/71143]
loss: 0.018571  [ 6400/71143]
loss: 0.050467  [12800/71143]
loss: 0.093993  [19200/71143]
loss: 0.074099  [25600/71143]
loss: 0.052667  [32000/71143]
loss: 0.083636  [38400/71143]
loss: 0.027347  [44800/71143]
loss: 0.084974  [51200/71143]
loss: 0.052072  [57600/71143]
loss: 0.086784  [64000/71143]
loss: 0.151514  [70400/71143]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.077142 

Epoch 17
-------------------------------
loss: 0.038102  [    0/71143]
loss: 0.016704  [ 6400/71143]
loss: 0.098536  [12800/71143]
loss: 0.081110  [19200/71143]
loss: 0.068595  [25600/71143]
loss: 0.070155  [32000/71143]
loss: 0.038884  [38400/71143]
loss: 0.105082  [44800/71143]
loss: 0.118372  [51200/71143]
loss: 0.044498  [57600/71143]
loss: 0.144868  [64000/71143]
loss: 0.363807  [70400/71143]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.079674 

Epoch 18
-------------------------------
loss: 0.115581  [    0/71143]
loss: 0.011241  [ 6400/71143]
loss: 0.027130  [12800/71143]
loss: 0.079882  [19200/71143]
loss: 0.088726  [25600/71143]
loss: 0.017227  [32000/71143]
loss: 0.092552  [38400/71143]
loss: 0.076496  [44800/71143]
loss: 0.102424  [51200/71143]
loss: 0.010797  [57600/71143]
loss: 0.074902  [64000/71143]
loss: 0.113025  [70400/71143]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.079732 

Epoch 19
-------------------------------
loss: 0.097236  [    0/71143]
loss: 0.092471  [ 6400/71143]
loss: 0.160153  [12800/71143]
loss: 0.090423  [19200/71143]
loss: 0.080848  [25600/71143]
loss: 0.110522  [32000/71143]
loss: 0.083100  [38400/71143]
loss: 0.013833  [44800/71143]
loss: 0.081780  [51200/71143]
loss: 0.081788  [57600/71143]
loss: 0.099683  [64000/71143]
loss: 0.082581  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.079111 

Epoch 20
-------------------------------
loss: 0.129910  [    0/71143]
loss: 0.068184  [ 6400/71143]
loss: 0.032612  [12800/71143]
loss: 0.011705  [19200/71143]
loss: 0.110299  [25600/71143]
loss: 0.135651  [32000/71143]
loss: 0.168349  [38400/71143]
loss: 0.158870  [44800/71143]
loss: 0.063353  [51200/71143]
loss: 0.026323  [57600/71143]
loss: 0.218442  [64000/71143]
loss: 0.169617  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.085344 

Epoch 21
-------------------------------
loss: 0.027918  [    0/71143]
loss: 0.102563  [ 6400/71143]
loss: 0.099474  [12800/71143]
loss: 0.053445  [19200/71143]
loss: 0.088306  [25600/71143]
loss: 0.075518  [32000/71143]
loss: 0.067535  [38400/71143]
loss: 0.046023  [44800/71143]
loss: 0.100738  [51200/71143]
loss: 0.038465  [57600/71143]
loss: 0.060899  [64000/71143]
loss: 0.038901  [70400/71143]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.081783 

Epoch 22
-------------------------------
loss: 0.042168  [    0/71143]
loss: 0.086899  [ 6400/71143]
loss: 0.118916  [12800/71143]
loss: 0.054774  [19200/71143]
loss: 0.018317  [25600/71143]
loss: 0.031221  [32000/71143]
loss: 0.038340  [38400/71143]
loss: 0.090275  [44800/71143]
loss: 0.137889  [51200/71143]
loss: 0.070119  [57600/71143]
loss: 0.050603  [64000/71143]
loss: 0.070831  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.081091 

Epoch 23
-------------------------------
loss: 0.014208  [    0/71143]
loss: 0.034884  [ 6400/71143]
loss: 0.053745  [12800/71143]
loss: 0.064531  [19200/71143]
loss: 0.045048  [25600/71143]
loss: 0.115243  [32000/71143]
loss: 0.058851  [38400/71143]
loss: 0.098551  [44800/71143]
loss: 0.118147  [51200/71143]
loss: 0.038415  [57600/71143]
loss: 0.094252  [64000/71143]
loss: 0.075488  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.089263 

Epoch 24
-------------------------------
loss: 0.151756  [    0/71143]
loss: 0.077752  [ 6400/71143]
loss: 0.103560  [12800/71143]
loss: 0.055685  [19200/71143]
loss: 0.051188  [25600/71143]
loss: 0.044907  [32000/71143]
loss: 0.065737  [38400/71143]
loss: 0.055862  [44800/71143]
loss: 0.100671  [51200/71143]
loss: 0.053578  [57600/71143]
loss: 0.028489  [64000/71143]
loss: 0.057498  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084627 

Epoch 25
-------------------------------
loss: 0.120670  [    0/71143]
loss: 0.122901  [ 6400/71143]
loss: 0.083737  [12800/71143]
loss: 0.090447  [19200/71143]
loss: 0.026755  [25600/71143]
loss: 0.086996  [32000/71143]
loss: 0.057197  [38400/71143]
loss: 0.082429  [44800/71143]
loss: 0.089553  [51200/71143]
loss: 0.080178  [57600/71143]
loss: 0.068597  [64000/71143]
loss: 0.080694  [70400/71143]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081659 

Epoch 26
-------------------------------
loss: 0.142837  [    0/71143]
loss: 0.136875  [ 6400/71143]
loss: 0.090467  [12800/71143]
loss: 0.072323  [19200/71143]
loss: 0.095553  [25600/71143]
loss: 0.044724  [32000/71143]
loss: 0.259133  [38400/71143]
loss: 0.083090  [44800/71143]
loss: 0.033236  [51200/71143]
loss: 0.076760  [57600/71143]
loss: 0.046808  [64000/71143]
loss: 0.032721  [70400/71143]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.089528 

Epoch 27
-------------------------------
loss: 0.106685  [    0/71143]
loss: 0.067726  [ 6400/71143]
loss: 0.050367  [12800/71143]
loss: 0.107658  [19200/71143]
loss: 0.120894  [25600/71143]
loss: 0.047443  [32000/71143]
loss: 0.066334  [38400/71143]
loss: 0.055246  [44800/71143]
loss: 0.091220  [51200/71143]
loss: 0.063121  [57600/71143]
loss: 0.140001  [64000/71143]
loss: 0.066605  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.086673 

Epoch 28
-------------------------------
loss: 0.100195  [    0/71143]
loss: 0.028912  [ 6400/71143]
loss: 0.024628  [12800/71143]
loss: 0.020104  [19200/71143]
loss: 0.125195  [25600/71143]
loss: 0.052832  [32000/71143]
loss: 0.075674  [38400/71143]
loss: 0.085834  [44800/71143]
loss: 0.073731  [51200/71143]
loss: 0.071962  [57600/71143]
loss: 0.045061  [64000/71143]
loss: 0.046294  [70400/71143]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.097183 

Epoch 29
-------------------------------
loss: 0.111814  [    0/71143]
loss: 0.174907  [ 6400/71143]
loss: 0.047625  [12800/71143]
loss: 0.084690  [19200/71143]
loss: 0.036328  [25600/71143]
loss: 0.135952  [32000/71143]
loss: 0.032965  [38400/71143]
loss: 0.115434  [44800/71143]
loss: 0.127262  [51200/71143]
loss: 0.021863  [57600/71143]
loss: 0.044127  [64000/71143]
loss: 0.076430  [70400/71143]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.081326 

Epoch 30
-------------------------------
loss: 0.020346  [    0/71143]
loss: 0.084703  [ 6400/71143]
loss: 0.022490  [12800/71143]
loss: 0.228022  [19200/71143]
loss: 0.019865  [25600/71143]
loss: 0.099482  [32000/71143]
loss: 0.067682  [38400/71143]
loss: 0.137278  [44800/71143]
loss: 0.182387  [51200/71143]
loss: 0.007009  [57600/71143]
loss: 0.027705  [64000/71143]
loss: 0.081831  [70400/71143]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.094279 

Epoch 31
-------------------------------
loss: 0.045699  [    0/71143]
loss: 0.091965  [ 6400/71143]
loss: 0.032570  [12800/71143]
loss: 0.056878  [19200/71143]
loss: 0.059906  [25600/71143]
loss: 0.207436  [32000/71143]
loss: 0.041679  [38400/71143]
loss: 0.013047  [44800/71143]
loss: 0.088954  [51200/71143]
loss: 0.111923  [57600/71143]
loss: 0.075366  [64000/71143]
loss: 0.052219  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.082107 

Epoch 32
-------------------------------
loss: 0.020369  [    0/71143]
loss: 1.635395  [ 6400/71143]
loss: 0.124115  [12800/71143]
loss: 0.053988  [19200/71143]
loss: 0.065233  [25600/71143]
loss: 0.052795  [32000/71143]
loss: 0.055160  [38400/71143]
loss: 0.042656  [44800/71143]
loss: 0.040806  [51200/71143]
loss: 0.048623  [57600/71143]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.161308 

Epoch 50
-------------------------------
loss: 0.128907  [    0/70245]
loss: 0.119448  [ 6400/70245]
loss: 0.172832  [12800/70245]
loss: 0.159717  [19200/70245]
loss: 0.169481  [25600/70245]
loss: 0.097123  [32000/70245]
loss: 0.156900  [38400/70245]
loss: 0.179963  [44800/70245]
loss: 0.100457  [51200/70245]
loss: 0.138408  [57600/70245]
loss: 0.172800  [64000/70245]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.162292 

Epoch 1
-------------------------------
loss: 0.689545  [    0/69508]
loss: 0.357657  [ 6400/69508]
loss: 0.404388  [12800/69508]
loss: 0.325309  [19200/69508]
loss: 0.236225  [25600/69508]
loss: 0.306470  [32000/69508]
loss: 0.150247  [38400/69508]
loss: 0.300273  [44800/69508]
loss: 0.295626  [51200/69508]
loss: 0.188299  [57600/69508]
loss: 0.188690  [64000/69508]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.209304 

Epoch 2
-------------------------------
loss: 0.199936  [    0/69508]
loss: 0.199435  [ 6400/69508]
loss: 0.176287  [12800/69508]
loss: 0.255871  [19200/69508]
loss: 0.257119  [25600/69508]
loss: 0.227044  [32000/69508]
loss: 0.254316  [38400/69508]
loss: 0.206198  [44800/69508]
loss: 0.198728  [51200/69508]
loss: 0.236361  [57600/69508]
loss: 0.222408  [64000/69508]
Test Error: 
 Accuracy: 90.8%, Avg loss: 0.213521 

Epoch 3
-------------------------------
loss: 0.292123  [    0/69508]
loss: 0.170735  [ 6400/69508]
loss: 0.195436  [12800/69508]
loss: 0.249496  [19200/69508]
loss: 0.241614  [25600/69508]
loss: 0.201087  [32000/69508]
loss: 0.331404  [38400/69508]
loss: 0.202019  [44800/69508]
loss: 0.185142  [51200/69508]
loss: 0.169057  [57600/69508]
loss: 0.215927  [64000/69508]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.191174 

Epoch 4
-------------------------------
loss: 0.206315  [    0/69508]
loss: 0.178454  [ 6400/69508]
loss: 0.139397  [12800/69508]
loss: 0.122856  [19200/69508]
loss: 0.245796  [25600/69508]
loss: 0.359039  [32000/69508]
loss: 0.234952  [38400/69508]
loss: 0.208321  [44800/69508]
loss: 0.128231  [51200/69508]
loss: 0.190372  [57600/69508]
loss: 0.259513  [64000/69508]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.183393 

Epoch 5
-------------------------------
loss: 0.154812  [    0/69508]
loss: 0.222113  [ 6400/69508]
loss: 0.338547  [12800/69508]
loss: 0.143511  [19200/69508]
loss: 0.147937  [25600/69508]
loss: 0.156380  [32000/69508]
loss: 0.110506  [38400/69508]
loss: 1.701060  [44800/69508]
loss: 0.153647  [51200/69508]
loss: 0.189347  [57600/69508]
loss: 0.175600  [64000/69508]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.191696 

Epoch 6
-------------------------------
loss: 0.267605  [    0/69508]
loss: 0.134008  [ 6400/69508]
loss: 0.283312  [12800/69508]
loss: 0.199038  [19200/69508]
loss: 0.176980  [25600/69508]
loss: 0.231028  [32000/69508]
loss: 0.268328  [38400/69508]
loss: 0.308923  [44800/69508]
loss: 0.238547  [51200/69508]
loss: 0.109300  [57600/69508]
loss: 0.224108  [64000/69508]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.193494 

Epoch 7
-------------------------------
loss: 0.118625  [    0/69508]
loss: 0.171353  [ 6400/69508]
loss: 0.290862  [12800/69508]
loss: 0.272530  [19200/69508]
loss: 0.208127  [25600/69508]
loss: 0.319201  [32000/69508]
loss: 0.153161  [38400/69508]
loss: 0.227609  [44800/69508]
loss: 0.195033  [51200/69508]
loss: 0.259487  [57600/69508]
loss: 0.251790  [64000/69508]
Test Error: 
 Accuracy: 84.2%, Avg loss: 0.310867 

Epoch 8
-------------------------------
loss: 0.199789  [    0/69508]
loss: 0.156696  [ 6400/69508]
loss: 0.230203  [12800/69508]
loss: 0.182725  [19200/69508]
loss: 0.163069  [25600/69508]
loss: 0.129911  [32000/69508]
loss: 0.083683  [38400/69508]
loss: 0.132583  [44800/69508]
loss: 0.160274  [51200/69508]
loss: 0.185270  [57600/69508]
loss: 0.162092  [64000/69508]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.177681 

Epoch 9
-------------------------------
loss: 0.188784  [    0/69508]
loss: 0.235726  [ 6400/69508]
loss: 0.156694  [12800/69508]
loss: 0.157179  [19200/69508]
loss: 0.162173  [25600/69508]
loss: 0.218237  [32000/69508]
loss: 0.249791  [38400/69508]
loss: 0.191621  [44800/69508]
loss: 0.189705  [51200/69508]
loss: 0.162370  [57600/69508]
loss: 0.183202  [64000/69508]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.173509 

Epoch 10
-------------------------------
loss: 0.140667  [    0/69508]
loss: 0.252063  [ 6400/69508]
loss: 0.211735  [12800/69508]
loss: 0.170957  [19200/69508]
loss: 0.123919  [25600/69508]
loss: 0.379291  [32000/69508]
loss: 0.317729  [38400/69508]
loss: 0.067914  [44800/69508]
loss: 0.195650  [51200/69508]
loss: 0.223531  [57600/69508]
loss: 0.357671  [64000/69508]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.188007 

Epoch 11
-------------------------------
loss: 0.144292  [    0/69508]
loss: 0.153063  [ 6400/69508]
loss: 0.211521  [12800/69508]
loss: 0.193308  [19200/69508]
loss: 0.176846  [25600/69508]
loss: 0.239505  [32000/69508]
loss: 0.125171  [38400/69508]
loss: 0.184688  [44800/69508]
loss: 0.271850  [51200/69508]
loss: 0.256956  [57600/69508]
loss: 0.154987  [64000/69508]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.184090 

Epoch 12
-------------------------------
loss: 0.250166  [    0/69508]
loss: 0.159961  [ 6400/69508]
loss: 0.169449  [12800/69508]
loss: 0.130849  [19200/69508]
loss: 0.192395  [25600/69508]
loss: 0.285745  [32000/69508]
loss: 0.231377  [38400/69508]
loss: 0.288654  [44800/69508]
loss: 0.160033  [51200/69508]
loss: 0.153206  [57600/69508]
loss: 0.141231  [64000/69508]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.178300 

Epoch 13
-------------------------------
loss: 0.237517  [    0/69508]
loss: 0.205281  [ 6400/69508]
loss: 0.185964  [12800/69508]
loss: 0.164587  [19200/69508]
loss: 0.141755  [25600/69508]
loss: 0.248416  [32000/69508]
loss: 0.225093  [38400/69508]
loss: 0.121340  [44800/69508]
loss: 0.159814  [51200/69508]
loss: 0.205313  [57600/69508]
loss: 0.209920  [64000/69508]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.174627 

Epoch 14
-------------------------------
loss: 0.278371  [    0/69508]
loss: 0.275779  [ 6400/69508]
loss: 0.165172  [12800/69508]
loss: 0.186267  [19200/69508]
loss: 0.203446  [25600/69508]
loss: 0.204453  [32000/69508]
loss: 0.113945  [38400/69508]
loss: 0.167700  [44800/69508]
loss: 0.190346  [51200/69508]
loss: 0.202979  [57600/69508]
loss: 0.156956  [64000/69508]
Test Error: 
 Accuracy: 78.9%, Avg loss: 0.377589 

Epoch 15
-------------------------------
loss: 0.304201  [    0/69508]
loss: 0.191960  [ 6400/69508]
loss: 0.213283  [12800/69508]
loss: 0.276058  [19200/69508]
loss: 0.215536  [25600/69508]
loss: 0.087604  [32000/69508]
loss: 0.179430  [38400/69508]
loss: 0.101958  [44800/69508]
loss: 0.177460  [51200/69508]
loss: 0.223752  [57600/69508]
loss: 0.154490  [64000/69508]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.175026 

Epoch 16
-------------------------------
loss: 0.142498  [    0/69508]
loss: 0.243876  [ 6400/69508]
loss: 0.107056  [12800/69508]
loss: 0.172562  [19200/69508]
loss: 0.143562  [25600/69508]
loss: 0.217125  [32000/69508]
loss: 0.212327  [38400/69508]
loss: 0.243718  [44800/69508]
loss: 0.109595  [51200/69508]
loss: 0.178371  [57600/69508]
loss: 0.204090  [64000/69508]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.206427 

Epoch 17
-------------------------------
loss: 0.177383  [    0/69508]
loss: 0.132540  [ 6400/69508]
loss: 0.136730  [12800/69508]
loss: 0.141795  [19200/69508]
loss: 0.212008  [25600/69508]
loss: 0.253744  [32000/69508]
loss: 0.198878  [38400/69508]
loss: 0.271312  [44800/69508]
loss: 0.212247  [51200/69508]
loss: 0.249888  [57600/69508]
loss: 0.213259  [64000/69508]
Test Error: 
 Accuracy: 83.9%, Avg loss: 0.486259 

Epoch 18
-------------------------------
loss: 0.438928  [    0/69508]
loss: 0.278451  [ 6400/69508]
loss: 0.185630  [12800/69508]
loss: 0.134720  [19200/69508]
loss: 0.183713  [25600/69508]
loss: 0.155892  [32000/69508]
loss: 0.203571  [38400/69508]
loss: 0.175280  [44800/69508]
loss: 0.163052  [51200/69508]
loss: 0.181528  [57600/69508]
loss: 0.226372  [64000/69508]
Test Error: 
 Accuracy: 85.2%, Avg loss: 0.286564 

Epoch 19
-------------------------------
loss: 0.214295  [    0/69508]
loss: 0.304763  [ 6400/69508]
loss: 0.127336  [57600/71103]
loss: 0.064017  [64000/71103]
loss: 0.015970  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.084777 

Epoch 15
-------------------------------
loss: 0.163209  [    0/71103]
loss: 0.181933  [ 6400/71103]
loss: 0.028039  [12800/71103]
loss: 0.007536  [19200/71103]
loss: 0.031444  [25600/71103]
loss: 0.082916  [32000/71103]
loss: 0.031929  [38400/71103]
loss: 0.034971  [44800/71103]
loss: 0.081238  [51200/71103]
loss: 0.135901  [57600/71103]
loss: 0.103660  [64000/71103]
loss: 0.025727  [70400/71103]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.082622 

Epoch 16
-------------------------------
loss: 0.052098  [    0/71103]
loss: 0.064297  [ 6400/71103]
loss: 0.101875  [12800/71103]
loss: 0.104262  [19200/71103]
loss: 0.056684  [25600/71103]
loss: 0.073769  [32000/71103]
loss: 0.027991  [38400/71103]
loss: 0.099836  [44800/71103]
loss: 0.021604  [51200/71103]
loss: 0.024438  [57600/71103]
loss: 0.009324  [64000/71103]
loss: 0.081417  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.086776 

Epoch 17
-------------------------------
loss: 0.211641  [    0/71103]
loss: 0.059085  [ 6400/71103]
loss: 0.102568  [12800/71103]
loss: 0.096144  [19200/71103]
loss: 0.080015  [25600/71103]
loss: 0.008033  [32000/71103]
loss: 0.028933  [38400/71103]
loss: 0.023804  [44800/71103]
loss: 0.065692  [51200/71103]
loss: 0.040470  [57600/71103]
loss: 0.020555  [64000/71103]
loss: 0.117141  [70400/71103]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.091834 

Epoch 18
-------------------------------
loss: 0.028126  [    0/71103]
loss: 0.035993  [ 6400/71103]
loss: 0.089088  [12800/71103]
loss: 0.123624  [19200/71103]
loss: 0.020348  [25600/71103]
loss: 0.032887  [32000/71103]
loss: 0.046262  [38400/71103]
loss: 0.049692  [44800/71103]
loss: 0.041348  [51200/71103]
loss: 0.086040  [57600/71103]
loss: 0.031833  [64000/71103]
loss: 0.118435  [70400/71103]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.091374 

Epoch 19
-------------------------------
loss: 0.015459  [    0/71103]
loss: 0.049322  [ 6400/71103]
loss: 0.082978  [12800/71103]
loss: 0.087573  [19200/71103]
loss: 0.102828  [25600/71103]
loss: 0.013910  [32000/71103]
loss: 0.168494  [38400/71103]
loss: 0.017183  [44800/71103]
loss: 0.026005  [51200/71103]
loss: 0.082810  [57600/71103]
loss: 0.058081  [64000/71103]
loss: 0.135122  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.083996 

Epoch 20
-------------------------------
loss: 0.016857  [    0/71103]
loss: 0.003426  [ 6400/71103]
loss: 0.009826  [12800/71103]
loss: 0.014907  [19200/71103]
loss: 0.192378  [25600/71103]
loss: 0.051401  [32000/71103]
loss: 0.183454  [38400/71103]
loss: 0.085840  [44800/71103]
loss: 0.034204  [51200/71103]
loss: 0.013095  [57600/71103]
loss: 0.032929  [64000/71103]
loss: 0.028622  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.087142 

Epoch 21
-------------------------------
loss: 0.048987  [    0/71103]
loss: 0.034577  [ 6400/71103]
loss: 0.012571  [12800/71103]
loss: 0.082837  [19200/71103]
loss: 0.080023  [25600/71103]
loss: 0.024399  [32000/71103]
loss: 0.318193  [38400/71103]
loss: 0.045553  [44800/71103]
loss: 0.027053  [51200/71103]
loss: 0.062159  [57600/71103]
loss: 0.069178  [64000/71103]
loss: 0.109049  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.084917 

Epoch 22
-------------------------------
loss: 0.031713  [    0/71103]
loss: 0.102962  [ 6400/71103]
loss: 0.047752  [12800/71103]
loss: 0.241801  [19200/71103]
loss: 0.032459  [25600/71103]
loss: 0.049648  [32000/71103]
loss: 0.101779  [38400/71103]
loss: 0.070034  [44800/71103]
loss: 0.049470  [51200/71103]
loss: 0.074775  [57600/71103]
loss: 0.076398  [64000/71103]
loss: 0.030143  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.084603 

Epoch 23
-------------------------------
loss: 0.018536  [    0/71103]
loss: 0.093781  [ 6400/71103]
loss: 0.030154  [12800/71103]
loss: 0.092766  [19200/71103]
loss: 0.055701  [25600/71103]
loss: 0.060518  [32000/71103]
loss: 0.123459  [38400/71103]
loss: 0.121903  [44800/71103]
loss: 0.105448  [51200/71103]
loss: 0.108433  [57600/71103]
loss: 0.065744  [64000/71103]
loss: 0.126818  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.085113 

Epoch 24
-------------------------------
loss: 0.049553  [    0/71103]
loss: 0.029380  [ 6400/71103]
loss: 0.071288  [12800/71103]
loss: 0.098546  [19200/71103]
loss: 0.039119  [25600/71103]
loss: 0.018063  [32000/71103]
loss: 0.038462  [38400/71103]
loss: 0.027542  [44800/71103]
loss: 0.060920  [51200/71103]
loss: 0.051352  [57600/71103]
loss: 0.022100  [64000/71103]
loss: 0.048858  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.084907 

Epoch 25
-------------------------------
loss: 0.051431  [    0/71103]
loss: 0.026567  [ 6400/71103]
loss: 0.131770  [12800/71103]
loss: 0.066217  [19200/71103]
loss: 0.062985  [25600/71103]
loss: 0.210733  [32000/71103]
loss: 0.119093  [38400/71103]
loss: 0.027090  [44800/71103]
loss: 0.148808  [51200/71103]
loss: 0.034606  [57600/71103]
loss: 0.050726  [64000/71103]
loss: 0.093618  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.083547 

Epoch 26
-------------------------------
loss: 0.121022  [    0/71103]
loss: 0.043503  [ 6400/71103]
loss: 0.046799  [12800/71103]
loss: 0.080092  [19200/71103]
loss: 0.085341  [25600/71103]
loss: 0.100703  [32000/71103]
loss: 0.162647  [38400/71103]
loss: 0.033275  [44800/71103]
loss: 0.021323  [51200/71103]
loss: 0.012963  [57600/71103]
loss: 0.082859  [64000/71103]
loss: 0.101470  [70400/71103]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084033 

Epoch 27
-------------------------------
loss: 0.052194  [    0/71103]
loss: 0.009626  [ 6400/71103]
loss: 0.020908  [12800/71103]
loss: 0.055633  [19200/71103]
loss: 0.018382  [25600/71103]
loss: 0.062137  [32000/71103]
loss: 0.138986  [38400/71103]
loss: 0.078988  [44800/71103]
loss: 0.067915  [51200/71103]
loss: 0.040245  [57600/71103]
loss: 0.117042  [64000/71103]
loss: 0.104694  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.083772 

Epoch 28
-------------------------------
loss: 0.023343  [    0/71103]
loss: 0.053064  [ 6400/71103]
loss: 0.015500  [12800/71103]
loss: 0.072980  [19200/71103]
loss: 0.106883  [25600/71103]
loss: 0.055680  [32000/71103]
loss: 0.019448  [38400/71103]
loss: 0.028276  [44800/71103]
loss: 0.121225  [51200/71103]
loss: 0.017850  [57600/71103]
loss: 0.346240  [64000/71103]
loss: 0.015479  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.086191 

Epoch 29
-------------------------------
loss: 0.002504  [    0/71103]
loss: 0.149547  [ 6400/71103]
loss: 0.067385  [12800/71103]
loss: 0.075107  [19200/71103]
loss: 0.021546  [25600/71103]
loss: 0.041772  [32000/71103]
loss: 0.028726  [38400/71103]
loss: 0.049060  [44800/71103]
loss: 0.030957  [51200/71103]
loss: 0.063313  [57600/71103]
loss: 0.186261  [64000/71103]
loss: 0.026782  [70400/71103]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.089627 

Epoch 30
-------------------------------
loss: 0.057446  [    0/71103]
loss: 0.045927  [ 6400/71103]
loss: 0.054335  [12800/71103]
loss: 0.206782  [19200/71103]
loss: 0.097740  [25600/71103]
loss: 0.037676  [32000/71103]
loss: 0.083773  [38400/71103]
loss: 0.076476  [44800/71103]
loss: 0.100838  [51200/71103]
loss: 0.079794  [57600/71103]
loss: 0.060548  [64000/71103]
loss: 0.058800  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.084757 

Epoch 31
-------------------------------
loss: 0.023215  [    0/71103]
loss: 0.158031  [ 6400/71103]
loss: 0.034701  [12800/71103]
loss: 0.095186  [19200/71103]
loss: 0.078472  [25600/71103]
loss: 0.056834  [32000/71103]
loss: 0.015284  [38400/71103]
loss: 0.132956  [44800/71103]
loss: 0.006276  [51200/71103]
loss: 0.091458  [57600/71103]
loss: 0.031264  [64000/71103]
loss: 0.054751  [70400/71103]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.082495 

Epoch 32
-------------------------------
loss: 0.049781  [    0/71103]
loss: 0.038556  [ 6400/71103]
loss: 0.068744  [12800/71103]
loss: 0.034792  [19200/71103]
loss: 0.051604  [25600/71103]
loss: 0.142452  [32000/71103]
loss: 0.062970  [38400/71103]
loss: 0.021965  [44800/71103]
loss: 0.063931  [51200/71103]
loss: 0.036841  [57600/71103]
loss: 0.014215  [38400/72195]
loss: 0.032247  [44800/72195]
loss: 0.013786  [51200/72195]
loss: 0.069657  [57600/72195]
loss: 0.078586  [64000/72195]
loss: 0.071406  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.069326 

Epoch 22
-------------------------------
loss: 0.036411  [    0/72195]
loss: 0.014401  [ 6400/72195]
loss: 0.088924  [12800/72195]
loss: 0.016088  [19200/72195]
loss: 0.083372  [25600/72195]
loss: 0.021206  [32000/72195]
loss: 0.031251  [38400/72195]
loss: 0.060813  [44800/72195]
loss: 0.025940  [51200/72195]
loss: 0.136731  [57600/72195]
loss: 0.094937  [64000/72195]
loss: 0.037772  [70400/72195]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.068749 

Epoch 23
-------------------------------
loss: 0.041321  [    0/72195]
loss: 0.040693  [ 6400/72195]
loss: 0.027920  [12800/72195]
loss: 0.032785  [19200/72195]
loss: 0.038367  [25600/72195]
loss: 0.010296  [32000/72195]
loss: 0.029705  [38400/72195]
loss: 0.017803  [44800/72195]
loss: 0.024125  [51200/72195]
loss: 0.033486  [57600/72195]
loss: 0.048958  [64000/72195]
loss: 0.039111  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.077797 

Epoch 24
-------------------------------
loss: 0.009954  [    0/72195]
loss: 0.025051  [ 6400/72195]
loss: 0.004815  [12800/72195]
loss: 0.070554  [19200/72195]
loss: 0.046448  [25600/72195]
loss: 0.015041  [32000/72195]
loss: 0.014338  [38400/72195]
loss: 0.053989  [44800/72195]
loss: 0.008197  [51200/72195]
loss: 0.029484  [57600/72195]
loss: 0.048642  [64000/72195]
loss: 0.016278  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.076792 

Epoch 25
-------------------------------
loss: 0.003777  [    0/72195]
loss: 0.019545  [ 6400/72195]
loss: 0.014845  [12800/72195]
loss: 0.022962  [19200/72195]
loss: 0.017256  [25600/72195]
loss: 0.018425  [32000/72195]
loss: 0.018939  [38400/72195]
loss: 0.220238  [44800/72195]
loss: 0.008365  [51200/72195]
loss: 0.017233  [57600/72195]
loss: 0.072310  [64000/72195]
loss: 0.025574  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.071594 

Epoch 26
-------------------------------
loss: 0.015949  [    0/72195]
loss: 0.053966  [ 6400/72195]
loss: 0.020194  [12800/72195]
loss: 0.102872  [19200/72195]
loss: 0.009409  [25600/72195]
loss: 0.004042  [32000/72195]
loss: 0.034426  [38400/72195]
loss: 0.003578  [44800/72195]
loss: 0.007852  [51200/72195]
loss: 1.569854  [57600/72195]
loss: 0.017155  [64000/72195]
loss: 0.040690  [70400/72195]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.085631 

Epoch 27
-------------------------------
loss: 0.052631  [    0/72195]
loss: 0.015014  [ 6400/72195]
loss: 0.173845  [12800/72195]
loss: 0.079868  [19200/72195]
loss: 0.024573  [25600/72195]
loss: 0.075874  [32000/72195]
loss: 0.059969  [38400/72195]
loss: 0.073828  [44800/72195]
loss: 0.113737  [51200/72195]
loss: 0.112948  [57600/72195]
loss: 0.013378  [64000/72195]
loss: 0.032425  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.073751 

Epoch 28
-------------------------------
loss: 0.013146  [    0/72195]
loss: 0.035044  [ 6400/72195]
loss: 0.034615  [12800/72195]
loss: 0.029098  [19200/72195]
loss: 0.017485  [25600/72195]
loss: 0.055503  [32000/72195]
loss: 0.149543  [38400/72195]
loss: 0.009367  [44800/72195]
loss: 0.020090  [51200/72195]
loss: 0.083283  [57600/72195]
loss: 0.015305  [64000/72195]
loss: 0.034643  [70400/72195]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.080642 

Epoch 29
-------------------------------
loss: 0.047764  [    0/72195]
loss: 0.035340  [ 6400/72195]
loss: 0.051684  [12800/72195]
loss: 0.040508  [19200/72195]
loss: 0.031074  [25600/72195]
loss: 0.008083  [32000/72195]
loss: 0.159585  [38400/72195]
loss: 0.076348  [44800/72195]
loss: 0.034563  [51200/72195]
loss: 0.210194  [57600/72195]
loss: 0.026698  [64000/72195]
loss: 0.066388  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.072990 

Epoch 30
-------------------------------
loss: 0.007381  [    0/72195]
loss: 0.010674  [ 6400/72195]
loss: 0.081311  [12800/72195]
loss: 0.027550  [19200/72195]
loss: 0.008057  [25600/72195]
loss: 0.003514  [32000/72195]
loss: 0.003657  [38400/72195]
loss: 0.007409  [44800/72195]
loss: 0.035051  [51200/72195]
loss: 0.281229  [57600/72195]
loss: 0.027079  [64000/72195]
loss: 0.075808  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.070351 

Epoch 31
-------------------------------
loss: 0.074866  [    0/72195]
loss: 0.046534  [ 6400/72195]
loss: 0.062164  [12800/72195]
loss: 0.007057  [19200/72195]
loss: 0.011563  [25600/72195]
loss: 0.023588  [32000/72195]
loss: 0.011226  [38400/72195]
loss: 0.023510  [44800/72195]
loss: 0.001849  [51200/72195]
loss: 0.031089  [57600/72195]
loss: 0.040315  [64000/72195]
loss: 0.066811  [70400/72195]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.158296 

Epoch 32
-------------------------------
loss: 0.113695  [    0/72195]
loss: 0.046891  [ 6400/72195]
loss: 0.070633  [12800/72195]
loss: 0.036697  [19200/72195]
loss: 0.011959  [25600/72195]
loss: 0.050580  [32000/72195]
loss: 0.013932  [38400/72195]
loss: 0.026408  [44800/72195]
loss: 0.005139  [51200/72195]
loss: 0.012798  [57600/72195]
loss: 0.042605  [64000/72195]
loss: 0.036995  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.083447 

Epoch 33
-------------------------------
loss: 0.015656  [    0/72195]
loss: 0.001357  [ 6400/72195]
loss: 0.126888  [12800/72195]
loss: 0.007463  [19200/72195]
loss: 0.024100  [25600/72195]
loss: 0.002945  [32000/72195]
loss: 0.032046  [38400/72195]
loss: 0.039289  [44800/72195]
loss: 0.033926  [51200/72195]
loss: 0.083633  [57600/72195]
loss: 0.018532  [64000/72195]
loss: 0.029424  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.080366 

Epoch 34
-------------------------------
loss: 0.003454  [    0/72195]
loss: 0.014186  [ 6400/72195]
loss: 0.015592  [12800/72195]
loss: 0.012945  [19200/72195]
loss: 0.008420  [25600/72195]
loss: 0.011002  [32000/72195]
loss: 0.021487  [38400/72195]
loss: 0.025033  [44800/72195]
loss: 0.011541  [51200/72195]
loss: 0.030350  [57600/72195]
loss: 0.057532  [64000/72195]
loss: 0.014236  [70400/72195]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.076175 

Epoch 35
-------------------------------
loss: 0.052401  [    0/72195]
loss: 0.007728  [ 6400/72195]
loss: 0.006411  [12800/72195]
loss: 0.073211  [19200/72195]
loss: 0.054398  [25600/72195]
loss: 0.015497  [32000/72195]
loss: 0.046571  [38400/72195]
loss: 0.010312  [44800/72195]
loss: 0.002651  [51200/72195]
loss: 0.010618  [57600/72195]
loss: 0.001343  [64000/72195]
loss: 0.018016  [70400/72195]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.090369 

Epoch 36
-------------------------------
loss: 0.022139  [    0/72195]
loss: 0.006291  [ 6400/72195]
loss: 0.010150  [12800/72195]
loss: 0.093963  [19200/72195]
loss: 0.072811  [25600/72195]
loss: 0.035614  [32000/72195]
loss: 0.025349  [38400/72195]
loss: 0.011035  [44800/72195]
loss: 0.019913  [51200/72195]
loss: 0.011918  [57600/72195]
loss: 0.010854  [64000/72195]
loss: 0.006572  [70400/72195]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.072489 

Epoch 37
-------------------------------
loss: 0.002145  [    0/72195]
loss: 0.025330  [ 6400/72195]
loss: 0.005324  [12800/72195]
loss: 0.049421  [19200/72195]
loss: 0.003739  [25600/72195]
loss: 0.071842  [32000/72195]
loss: 0.014761  [38400/72195]
loss: 0.006411  [44800/72195]
loss: 0.092728  [51200/72195]
loss: 0.070557  [57600/72195]
loss: 0.049508  [64000/72195]
loss: 0.030252  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.074421 

Epoch 38
-------------------------------
loss: 0.036010  [    0/72195]
loss: 0.048071  [ 6400/72195]
loss: 0.015189  [12800/72195]
loss: 0.072991  [19200/72195]
loss: 0.091282  [25600/72195]
loss: 0.036922  [32000/72195]
loss: 0.040678  [38400/72195]
loss: 0.018545  [44800/72195]
loss: 0.092313  [51200/72195]
loss: 0.011428  [57600/72195]
loss: 0.005068  [64000/72195]
loss: 0.001443  [70400/72195]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.077318 

Epoch 39
-------------------------------
loss: 0.004271  [    0/72195]
loss: 0.009477  [ 6400/72195]
loss: 0.071445  [12800/72195]
loss: 0.025209  [19200/72195]
loss: 0.003983  [25600/72195]
loss: 0.060453  [32000/72195]
loss: 0.008537  [38400/72195]
loss: 0.052242  [64000/70349]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.202614 

Epoch 16
-------------------------------
loss: 0.072131  [    0/70349]
loss: 0.047473  [ 6400/70349]
loss: 0.063416  [12800/70349]
loss: 0.075682  [19200/70349]
loss: 0.143645  [25600/70349]
loss: 0.023993  [32000/70349]
loss: 0.115687  [38400/70349]
loss: 0.138237  [44800/70349]
loss: 0.081497  [51200/70349]
loss: 0.095813  [57600/70349]
loss: 0.068369  [64000/70349]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.104235 

Epoch 17
-------------------------------
loss: 0.054127  [    0/70349]
loss: 0.126291  [ 6400/70349]
loss: 0.041471  [12800/70349]
loss: 0.127080  [19200/70349]
loss: 0.072338  [25600/70349]
loss: 0.104308  [32000/70349]
loss: 0.082051  [38400/70349]
loss: 0.075137  [44800/70349]
loss: 0.152556  [51200/70349]
loss: 0.065707  [57600/70349]
loss: 0.069370  [64000/70349]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.119628 

Epoch 18
-------------------------------
loss: 0.081729  [    0/70349]
loss: 0.032027  [ 6400/70349]
loss: 0.151315  [12800/70349]
loss: 0.048596  [19200/70349]
loss: 0.086610  [25600/70349]
loss: 0.063705  [32000/70349]
loss: 0.052120  [38400/70349]
loss: 0.164926  [44800/70349]
loss: 0.064481  [51200/70349]
loss: 0.075414  [57600/70349]
loss: 0.053048  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.099920 

Epoch 19
-------------------------------
loss: 0.023800  [    0/70349]
loss: 0.226967  [ 6400/70349]
loss: 0.119200  [12800/70349]
loss: 0.120960  [19200/70349]
loss: 0.123922  [25600/70349]
loss: 0.055580  [32000/70349]
loss: 0.031251  [38400/70349]
loss: 0.266510  [44800/70349]
loss: 0.123137  [51200/70349]
loss: 0.033408  [57600/70349]
loss: 0.072023  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.107501 

Epoch 20
-------------------------------
loss: 0.059696  [    0/70349]
loss: 0.140633  [ 6400/70349]
loss: 0.132313  [12800/70349]
loss: 0.168656  [19200/70349]
loss: 0.024227  [25600/70349]
loss: 0.101603  [32000/70349]
loss: 0.097539  [38400/70349]
loss: 0.242573  [44800/70349]
loss: 0.146327  [51200/70349]
loss: 0.020236  [57600/70349]
loss: 0.190793  [64000/70349]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.112867 

Epoch 21
-------------------------------
loss: 0.063604  [    0/70349]
loss: 0.056290  [ 6400/70349]
loss: 0.050009  [12800/70349]
loss: 0.079706  [19200/70349]
loss: 0.029740  [25600/70349]
loss: 0.149006  [32000/70349]
loss: 0.103321  [38400/70349]
loss: 0.048688  [44800/70349]
loss: 0.071430  [51200/70349]
loss: 0.034765  [57600/70349]
loss: 0.216333  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.108477 

Epoch 22
-------------------------------
loss: 0.127834  [    0/70349]
loss: 0.057062  [ 6400/70349]
loss: 0.044527  [12800/70349]
loss: 0.110271  [19200/70349]
loss: 0.047294  [25600/70349]
loss: 0.018412  [32000/70349]
loss: 0.170547  [38400/70349]
loss: 0.073295  [44800/70349]
loss: 0.067238  [51200/70349]
loss: 0.060893  [57600/70349]
loss: 0.083203  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.105548 

Epoch 23
-------------------------------
loss: 0.096215  [    0/70349]
loss: 0.083734  [ 6400/70349]
loss: 0.083889  [12800/70349]
loss: 0.075459  [19200/70349]
loss: 0.083740  [25600/70349]
loss: 0.066470  [32000/70349]
loss: 0.072445  [38400/70349]
loss: 0.133463  [44800/70349]
loss: 0.243023  [51200/70349]
loss: 0.145817  [57600/70349]
loss: 0.086098  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102705 

Epoch 24
-------------------------------
loss: 0.023584  [    0/70349]
loss: 0.145436  [ 6400/70349]
loss: 0.135228  [12800/70349]
loss: 0.132141  [19200/70349]
loss: 0.035777  [25600/70349]
loss: 0.012660  [32000/70349]
loss: 0.026103  [38400/70349]
loss: 0.148825  [44800/70349]
loss: 0.295675  [51200/70349]
loss: 0.182970  [57600/70349]
loss: 0.091607  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112635 

Epoch 25
-------------------------------
loss: 0.127449  [    0/70349]
loss: 0.053334  [ 6400/70349]
loss: 0.085301  [12800/70349]
loss: 0.132646  [19200/70349]
loss: 0.054077  [25600/70349]
loss: 0.146063  [32000/70349]
loss: 0.050455  [38400/70349]
loss: 0.125848  [44800/70349]
loss: 0.052077  [51200/70349]
loss: 0.100924  [57600/70349]
loss: 0.039941  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.104132 

Epoch 26
-------------------------------
loss: 0.123522  [    0/70349]
loss: 0.046920  [ 6400/70349]
loss: 0.169328  [12800/70349]
loss: 0.072431  [19200/70349]
loss: 0.115688  [25600/70349]
loss: 0.151979  [32000/70349]
loss: 0.083662  [38400/70349]
loss: 0.073340  [44800/70349]
loss: 0.039690  [51200/70349]
loss: 0.228328  [57600/70349]
loss: 0.168130  [64000/70349]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.108049 

Epoch 27
-------------------------------
loss: 0.039769  [    0/70349]
loss: 0.049031  [ 6400/70349]
loss: 0.105323  [12800/70349]
loss: 0.088192  [19200/70349]
loss: 0.076250  [25600/70349]
loss: 0.043534  [32000/70349]
loss: 0.121558  [38400/70349]
loss: 0.171618  [44800/70349]
loss: 0.017774  [51200/70349]
loss: 0.111752  [57600/70349]
loss: 0.169178  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.110459 

Epoch 28
-------------------------------
loss: 0.068160  [    0/70349]
loss: 0.043614  [ 6400/70349]
loss: 0.032629  [12800/70349]
loss: 0.055925  [19200/70349]
loss: 0.086340  [25600/70349]
loss: 0.030787  [32000/70349]
loss: 0.026062  [38400/70349]
loss: 0.219632  [44800/70349]
loss: 0.069833  [51200/70349]
loss: 0.083612  [57600/70349]
loss: 0.113254  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.107616 

Epoch 29
-------------------------------
loss: 0.052143  [    0/70349]
loss: 0.133370  [ 6400/70349]
loss: 0.117921  [12800/70349]
loss: 0.116644  [19200/70349]
loss: 0.123208  [25600/70349]
loss: 0.116094  [32000/70349]
loss: 0.046953  [38400/70349]
loss: 0.071381  [44800/70349]
loss: 0.031676  [51200/70349]
loss: 0.047989  [57600/70349]
loss: 0.021166  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.105110 

Epoch 30
-------------------------------
loss: 0.069812  [    0/70349]
loss: 0.062395  [ 6400/70349]
loss: 0.078905  [12800/70349]
loss: 0.032254  [19200/70349]
loss: 0.072596  [25600/70349]
loss: 0.174871  [32000/70349]
loss: 0.082694  [38400/70349]
loss: 0.078770  [44800/70349]
loss: 0.106256  [51200/70349]
loss: 0.082848  [57600/70349]
loss: 0.061852  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.105639 

Epoch 31
-------------------------------
loss: 0.061729  [    0/70349]
loss: 0.037222  [ 6400/70349]
loss: 0.074860  [12800/70349]
loss: 0.152021  [19200/70349]
loss: 0.067629  [25600/70349]
loss: 0.217991  [32000/70349]
loss: 0.056262  [38400/70349]
loss: 0.059420  [44800/70349]
loss: 0.091075  [51200/70349]
loss: 0.078002  [57600/70349]
loss: 0.070068  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.100615 

Epoch 32
-------------------------------
loss: 0.050308  [    0/70349]
loss: 0.207168  [ 6400/70349]
loss: 0.137202  [12800/70349]
loss: 0.021666  [19200/70349]
loss: 0.058445  [25600/70349]
loss: 0.083858  [32000/70349]
loss: 0.106949  [38400/70349]
loss: 0.106379  [44800/70349]
loss: 0.052653  [51200/70349]
loss: 0.049660  [57600/70349]
loss: 0.158480  [64000/70349]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.125366 

Epoch 33
-------------------------------
loss: 0.146562  [    0/70349]
loss: 0.053950  [ 6400/70349]
loss: 0.063756  [12800/70349]
loss: 0.105626  [19200/70349]
loss: 0.010774  [25600/70349]
loss: 0.069250  [32000/70349]
loss: 0.096204  [38400/70349]
loss: 0.117407  [44800/70349]
loss: 0.084960  [51200/70349]
loss: 0.056005  [57600/70349]
loss: 0.297036  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.105291 

Epoch 34
-------------------------------
loss: 0.026815  [    0/70349]
loss: 0.211079  [ 6400/70349]
loss: 0.046784  [12800/70349]
loss: 0.045581  [19200/70349]
loss: 0.113907  [25600/70349]
loss: 0.073084  [32000/70349]
loss: 0.047351  [38400/70349]
loss: 0.090575  [44800/70349]
loss: 0.079536  [51200/70349]
loss: 0.035826  [57600/70349]
loss: 0.084337  [64000/70349]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.111744 

Epoch 35
-------------------------------
loss: 0.053952  [    0/70349]
loss: 0.074469  [64000/69713]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.169718 

Epoch 28
-------------------------------
loss: 0.095282  [    0/69713]
loss: 0.060757  [ 6400/69713]
loss: 0.151237  [12800/69713]
loss: 0.171561  [19200/69713]
loss: 0.088869  [25600/69713]
loss: 0.071439  [32000/69713]
loss: 0.089088  [38400/69713]
loss: 0.112703  [44800/69713]
loss: 0.169678  [51200/69713]
loss: 0.117280  [57600/69713]
loss: 0.188281  [64000/69713]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.170267 

Epoch 29
-------------------------------
loss: 0.112889  [    0/69713]
loss: 0.212456  [ 6400/69713]
loss: 0.175832  [12800/69713]
loss: 0.118446  [19200/69713]
loss: 0.065040  [25600/69713]
loss: 0.107493  [32000/69713]
loss: 0.069597  [38400/69713]
loss: 0.047558  [44800/69713]
loss: 0.100644  [51200/69713]
loss: 0.121266  [57600/69713]
loss: 0.079819  [64000/69713]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.187042 

Epoch 30
-------------------------------
loss: 0.088186  [    0/69713]
loss: 0.071434  [ 6400/69713]
loss: 0.149204  [12800/69713]
loss: 0.074086  [19200/69713]
loss: 0.144404  [25600/69713]
loss: 0.127551  [32000/69713]
loss: 0.213277  [38400/69713]
loss: 0.086744  [44800/69713]
loss: 0.265409  [51200/69713]
loss: 0.088620  [57600/69713]
loss: 0.126089  [64000/69713]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.179447 

Epoch 31
-------------------------------
loss: 0.090948  [    0/69713]
loss: 0.067406  [ 6400/69713]
loss: 0.119238  [12800/69713]
loss: 0.053326  [19200/69713]
loss: 0.067099  [25600/69713]
loss: 0.107451  [32000/69713]
loss: 0.129687  [38400/69713]
loss: 0.137675  [44800/69713]
loss: 0.090888  [51200/69713]
loss: 0.136579  [57600/69713]
loss: 0.081922  [64000/69713]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.182406 

Epoch 32
-------------------------------
loss: 0.186737  [    0/69713]
loss: 0.133806  [ 6400/69713]
loss: 0.219605  [12800/69713]
loss: 0.157948  [19200/69713]
loss: 0.101180  [25600/69713]
loss: 0.109886  [32000/69713]
loss: 0.045670  [38400/69713]
loss: 0.178252  [44800/69713]
loss: 0.061121  [51200/69713]
loss: 0.050659  [57600/69713]
loss: 0.162867  [64000/69713]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.175442 

Epoch 33
-------------------------------
loss: 0.203306  [    0/69713]
loss: 0.061768  [ 6400/69713]
loss: 0.141844  [12800/69713]
loss: 0.480980  [19200/69713]
loss: 0.123737  [25600/69713]
loss: 0.094979  [32000/69713]
loss: 0.059284  [38400/69713]
loss: 0.234084  [44800/69713]
loss: 0.231563  [51200/69713]
loss: 0.078069  [57600/69713]
loss: 0.089782  [64000/69713]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.179587 

Epoch 34
-------------------------------
loss: 0.094763  [    0/69713]
loss: 0.169982  [ 6400/69713]
loss: 0.257624  [12800/69713]
loss: 0.160715  [19200/69713]
loss: 0.135074  [25600/69713]
loss: 0.175633  [32000/69713]
loss: 0.152658  [38400/69713]
loss: 0.145004  [44800/69713]
loss: 0.117454  [51200/69713]
loss: 0.148490  [57600/69713]
loss: 0.184795  [64000/69713]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.172785 

Epoch 35
-------------------------------
loss: 0.241852  [    0/69713]
loss: 0.095998  [ 6400/69713]
loss: 0.125774  [12800/69713]
loss: 0.098432  [19200/69713]
loss: 0.124043  [25600/69713]
loss: 0.128006  [32000/69713]
loss: 0.099901  [38400/69713]
loss: 0.111064  [44800/69713]
loss: 0.096695  [51200/69713]
loss: 0.148811  [57600/69713]
loss: 0.143413  [64000/69713]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.165231 

Epoch 36
-------------------------------
loss: 0.160978  [    0/69713]
loss: 0.153196  [ 6400/69713]
loss: 0.175731  [12800/69713]
loss: 0.076613  [19200/69713]
loss: 0.227259  [25600/69713]
loss: 0.082697  [32000/69713]
loss: 0.106275  [38400/69713]
loss: 0.151791  [44800/69713]
loss: 0.131482  [51200/69713]
loss: 0.139561  [57600/69713]
loss: 0.113722  [64000/69713]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.186200 

Epoch 37
-------------------------------
loss: 0.361298  [    0/69713]
loss: 0.089254  [ 6400/69713]
loss: 0.030718  [12800/69713]
loss: 0.050535  [19200/69713]
loss: 0.069575  [25600/69713]
loss: 0.107273  [32000/69713]
loss: 0.193480  [38400/69713]
loss: 0.205323  [44800/69713]
loss: 0.180064  [51200/69713]
loss: 0.095848  [57600/69713]
loss: 0.189941  [64000/69713]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.163024 

Epoch 38
-------------------------------
loss: 0.120215  [    0/69713]
loss: 0.087626  [ 6400/69713]
loss: 0.074655  [12800/69713]
loss: 0.222981  [19200/69713]
loss: 0.207580  [25600/69713]
loss: 0.095833  [32000/69713]
loss: 0.146141  [38400/69713]
loss: 0.245906  [44800/69713]
loss: 0.221652  [51200/69713]
loss: 0.168035  [57600/69713]
loss: 0.106808  [64000/69713]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.169698 

Epoch 39
-------------------------------
loss: 0.129988  [    0/69713]
loss: 0.114840  [ 6400/69713]
loss: 0.223983  [12800/69713]
loss: 0.252158  [19200/69713]
loss: 0.197505  [25600/69713]
loss: 0.122759  [32000/69713]
loss: 0.075675  [38400/69713]
loss: 0.088399  [44800/69713]
loss: 0.139880  [51200/69713]
loss: 0.114823  [57600/69713]
loss: 0.192615  [64000/69713]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.194386 

Epoch 40
-------------------------------
loss: 0.238841  [    0/69713]
loss: 0.078906  [ 6400/69713]
loss: 0.179220  [12800/69713]
loss: 0.160866  [19200/69713]
loss: 0.221564  [25600/69713]
loss: 0.047287  [32000/69713]
loss: 0.102325  [38400/69713]
loss: 0.180682  [44800/69713]
loss: 0.162072  [51200/69713]
loss: 0.089336  [57600/69713]
loss: 0.046019  [64000/69713]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.178699 

Epoch 41
-------------------------------
loss: 0.096266  [    0/69713]
loss: 0.160811  [ 6400/69713]
loss: 0.156220  [12800/69713]
loss: 0.087743  [19200/69713]
loss: 0.121494  [25600/69713]
loss: 0.063400  [32000/69713]
loss: 0.168482  [38400/69713]
loss: 1.625451  [44800/69713]
loss: 0.066653  [51200/69713]
loss: 0.127527  [57600/69713]
loss: 0.081148  [64000/69713]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.165435 

Epoch 42
-------------------------------
loss: 0.149069  [    0/69713]
loss: 0.140814  [ 6400/69713]
loss: 0.140198  [12800/69713]
loss: 0.150680  [19200/69713]
loss: 0.156213  [25600/69713]
loss: 0.173031  [32000/69713]
loss: 0.198226  [38400/69713]
loss: 0.130823  [44800/69713]
loss: 0.263835  [51200/69713]
loss: 0.167318  [57600/69713]
loss: 0.149877  [64000/69713]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.173001 

Epoch 43
-------------------------------
loss: 0.067965  [    0/69713]
loss: 0.157561  [ 6400/69713]
loss: 0.128042  [12800/69713]
loss: 0.186222  [19200/69713]
loss: 0.114927  [25600/69713]
loss: 0.122547  [32000/69713]
loss: 0.080734  [38400/69713]
loss: 0.132124  [44800/69713]
loss: 0.103308  [51200/69713]
loss: 0.120534  [57600/69713]
loss: 0.192609  [64000/69713]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.171542 

Epoch 44
-------------------------------
loss: 0.225793  [    0/69713]
loss: 0.182349  [ 6400/69713]
loss: 0.127416  [12800/69713]
loss: 0.113481  [19200/69713]
loss: 0.089751  [25600/69713]
loss: 0.162915  [32000/69713]
loss: 0.056243  [38400/69713]
loss: 0.083390  [44800/69713]
loss: 0.150606  [51200/69713]
loss: 0.022278  [57600/69713]
loss: 0.068943  [64000/69713]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.163358 

Epoch 45
-------------------------------
loss: 0.093476  [    0/69713]
loss: 0.145875  [ 6400/69713]
loss: 0.113328  [12800/69713]
loss: 0.099144  [19200/69713]
loss: 0.111873  [25600/69713]
loss: 0.236363  [32000/69713]
loss: 0.147408  [38400/69713]
loss: 0.133725  [44800/69713]
loss: 0.172377  [51200/69713]
loss: 0.113952  [57600/69713]
loss: 0.124972  [64000/69713]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.172577 

Epoch 46
-------------------------------
loss: 0.149331  [    0/69713]
loss: 0.144641  [ 6400/69713]
loss: 0.170721  [12800/69713]
loss: 0.108837  [19200/69713]
loss: 0.112925  [25600/69713]
loss: 0.198344  [32000/69713]
loss: 0.122175  [38400/69713]
loss: 0.121611  [44800/69713]
loss: 0.134540  [51200/69713]
loss: 0.135362  [57600/69713]
loss: 0.037497  [64000/69713]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.167160 

Epoch 47
-------------------------------
loss: 0.147288  [    0/69713]
loss: 0.316429  [ 6400/69810]
loss: 0.122719  [12800/69810]
loss: 0.107238  [19200/69810]
loss: 0.073917  [25600/69810]
loss: 0.125200  [32000/69810]
loss: 0.113592  [38400/69810]
loss: 0.060076  [44800/69810]
loss: 0.075916  [51200/69810]
loss: 0.015284  [57600/69810]
loss: 0.091922  [64000/69810]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090524 

Epoch 20
-------------------------------
loss: 0.053465  [    0/69810]
loss: 0.076307  [ 6400/69810]
loss: 0.152784  [12800/69810]
loss: 0.204990  [19200/69810]
loss: 0.131729  [25600/69810]
loss: 0.051093  [32000/69810]
loss: 0.078899  [38400/69810]
loss: 0.041687  [44800/69810]
loss: 0.102872  [51200/69810]
loss: 0.052866  [57600/69810]
loss: 0.065792  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.096640 

Epoch 21
-------------------------------
loss: 0.097666  [    0/69810]
loss: 0.082730  [ 6400/69810]
loss: 0.064252  [12800/69810]
loss: 0.109617  [19200/69810]
loss: 0.089896  [25600/69810]
loss: 0.129445  [32000/69810]
loss: 0.136511  [38400/69810]
loss: 0.247754  [44800/69810]
loss: 0.157454  [51200/69810]
loss: 0.037209  [57600/69810]
loss: 0.049773  [64000/69810]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.097214 

Epoch 22
-------------------------------
loss: 0.072322  [    0/69810]
loss: 0.187908  [ 6400/69810]
loss: 0.045162  [12800/69810]
loss: 0.106495  [19200/69810]
loss: 0.133556  [25600/69810]
loss: 0.097969  [32000/69810]
loss: 0.148837  [38400/69810]
loss: 0.156269  [44800/69810]
loss: 0.089977  [51200/69810]
loss: 0.044989  [57600/69810]
loss: 0.164061  [64000/69810]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.091945 

Epoch 23
-------------------------------
loss: 0.088502  [    0/69810]
loss: 0.178529  [ 6400/69810]
loss: 0.020133  [12800/69810]
loss: 0.042037  [19200/69810]
loss: 0.143046  [25600/69810]
loss: 0.025247  [32000/69810]
loss: 0.192386  [38400/69810]
loss: 0.026170  [44800/69810]
loss: 0.046821  [51200/69810]
loss: 0.089077  [57600/69810]
loss: 0.113949  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.096827 

Epoch 24
-------------------------------
loss: 0.092775  [    0/69810]
loss: 0.159321  [ 6400/69810]
loss: 0.141438  [12800/69810]
loss: 0.024389  [19200/69810]
loss: 0.079904  [25600/69810]
loss: 0.094351  [32000/69810]
loss: 0.060695  [38400/69810]
loss: 0.175814  [44800/69810]
loss: 0.087352  [51200/69810]
loss: 0.081526  [57600/69810]
loss: 0.083776  [64000/69810]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099935 

Epoch 25
-------------------------------
loss: 0.125954  [    0/69810]
loss: 0.034531  [ 6400/69810]
loss: 0.070051  [12800/69810]
loss: 0.114112  [19200/69810]
loss: 0.045013  [25600/69810]
loss: 0.141466  [32000/69810]
loss: 0.078824  [38400/69810]
loss: 0.047920  [44800/69810]
loss: 0.048535  [51200/69810]
loss: 0.092689  [57600/69810]
loss: 0.069673  [64000/69810]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.092321 

Epoch 26
-------------------------------
loss: 0.153494  [    0/69810]
loss: 0.023479  [ 6400/69810]
loss: 0.055523  [12800/69810]
loss: 0.026173  [19200/69810]
loss: 0.093874  [25600/69810]
loss: 0.124641  [32000/69810]
loss: 0.174842  [38400/69810]
loss: 0.032477  [44800/69810]
loss: 0.086053  [51200/69810]
loss: 0.055996  [57600/69810]
loss: 0.049887  [64000/69810]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.099254 

Epoch 27
-------------------------------
loss: 0.040479  [    0/69810]
loss: 0.124182  [ 6400/69810]
loss: 0.087029  [12800/69810]
loss: 0.034507  [19200/69810]
loss: 0.043825  [25600/69810]
loss: 0.093999  [32000/69810]
loss: 0.048799  [38400/69810]
loss: 0.080265  [44800/69810]
loss: 0.062901  [51200/69810]
loss: 0.142798  [57600/69810]
loss: 0.032411  [64000/69810]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.102190 

Epoch 28
-------------------------------
loss: 0.085699  [    0/69810]
loss: 0.126877  [ 6400/69810]
loss: 0.073285  [12800/69810]
loss: 0.084068  [19200/69810]
loss: 0.042846  [25600/69810]
loss: 0.132368  [32000/69810]
loss: 0.187820  [38400/69810]
loss: 0.052530  [44800/69810]
loss: 0.036810  [51200/69810]
loss: 0.114520  [57600/69810]
loss: 0.015040  [64000/69810]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.104042 

Epoch 29
-------------------------------
loss: 0.027563  [    0/69810]
loss: 0.107757  [ 6400/69810]
loss: 0.114656  [12800/69810]
loss: 0.109337  [19200/69810]
loss: 0.148598  [25600/69810]
loss: 0.059898  [32000/69810]
loss: 0.056822  [38400/69810]
loss: 0.048351  [44800/69810]
loss: 0.047900  [51200/69810]
loss: 0.116267  [57600/69810]
loss: 0.062553  [64000/69810]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.092062 

Epoch 30
-------------------------------
loss: 0.075700  [    0/69810]
loss: 0.120223  [ 6400/69810]
loss: 0.087791  [12800/69810]
loss: 0.080087  [19200/69810]
loss: 0.116559  [25600/69810]
loss: 0.214132  [32000/69810]
loss: 0.160321  [38400/69810]
loss: 0.125305  [44800/69810]
loss: 0.092161  [51200/69810]
loss: 0.038863  [57600/69810]
loss: 0.062459  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.092416 

Epoch 31
-------------------------------
loss: 0.066796  [    0/69810]
loss: 0.118821  [ 6400/69810]
loss: 0.068811  [12800/69810]
loss: 0.095653  [19200/69810]
loss: 0.031773  [25600/69810]
loss: 0.038093  [32000/69810]
loss: 0.064413  [38400/69810]
loss: 0.041219  [44800/69810]
loss: 0.060994  [51200/69810]
loss: 0.112488  [57600/69810]
loss: 0.144672  [64000/69810]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.117133 

Epoch 32
-------------------------------
loss: 0.086402  [    0/69810]
loss: 0.030503  [ 6400/69810]
loss: 0.172226  [12800/69810]
loss: 0.104177  [19200/69810]
loss: 0.042421  [25600/69810]
loss: 0.079177  [32000/69810]
loss: 0.208861  [38400/69810]
loss: 0.095121  [44800/69810]
loss: 0.068938  [51200/69810]
loss: 0.102033  [57600/69810]
loss: 0.085488  [64000/69810]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.092697 

Epoch 33
-------------------------------
loss: 0.042002  [    0/69810]
loss: 0.070001  [ 6400/69810]
loss: 0.125445  [12800/69810]
loss: 0.138407  [19200/69810]
loss: 0.128301  [25600/69810]
loss: 0.026798  [32000/69810]
loss: 0.083185  [38400/69810]
loss: 0.103523  [44800/69810]
loss: 0.169962  [51200/69810]
loss: 0.027624  [57600/69810]
loss: 0.106668  [64000/69810]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.087628 

Epoch 34
-------------------------------
loss: 0.097872  [    0/69810]
loss: 0.113352  [ 6400/69810]
loss: 0.201450  [12800/69810]
loss: 0.085099  [19200/69810]
loss: 0.064831  [25600/69810]
loss: 0.108775  [32000/69810]
loss: 0.071303  [38400/69810]
loss: 0.097755  [44800/69810]
loss: 0.208483  [51200/69810]
loss: 0.053621  [57600/69810]
loss: 0.104497  [64000/69810]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.086683 

Epoch 35
-------------------------------
loss: 0.084706  [    0/69810]
loss: 0.083239  [ 6400/69810]
loss: 0.055828  [12800/69810]
loss: 0.052496  [19200/69810]
loss: 0.085972  [25600/69810]
loss: 0.057200  [32000/69810]
loss: 0.096065  [38400/69810]
loss: 0.104612  [44800/69810]
loss: 0.078823  [51200/69810]
loss: 0.032074  [57600/69810]
loss: 0.040602  [64000/69810]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.097420 

Epoch 36
-------------------------------
loss: 0.060927  [    0/69810]
loss: 0.074432  [ 6400/69810]
loss: 0.064895  [12800/69810]
loss: 0.038612  [19200/69810]
loss: 0.093558  [25600/69810]
loss: 0.040632  [32000/69810]
loss: 0.021950  [38400/69810]
loss: 0.143799  [44800/69810]
loss: 0.028730  [51200/69810]
loss: 0.097613  [57600/69810]
loss: 0.170135  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.096543 

Epoch 37
-------------------------------
loss: 0.208363  [    0/69810]
loss: 0.036328  [ 6400/69810]
loss: 0.077594  [12800/69810]
loss: 0.059492  [19200/69810]
loss: 0.069163  [25600/69810]
loss: 0.162957  [32000/69810]
loss: 0.064357  [38400/69810]
loss: 0.070278  [44800/69810]
loss: 0.066015  [51200/69810]
loss: 0.106993  [57600/69810]
loss: 0.065289  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090096 

Epoch 38
-------------------------------
loss: 0.096160  [    0/69810]
loss: 0.195265  [ 6400/69810]
loss: 0.026598  [12800/69810]
loss: 0.046883  [19200/69810]
loss: 0.192509  [25600/69810]
loss: 0.112477  [32000/69810]
loss: 0.086650  [12800/69947]
loss: 0.088735  [19200/69947]
loss: 0.081866  [25600/69947]
loss: 0.063556  [32000/69947]
loss: 0.082955  [38400/69947]
loss: 0.102615  [44800/69947]
loss: 0.141725  [51200/69947]
loss: 0.134560  [57600/69947]
loss: 0.081262  [64000/69947]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.119916 

Epoch 20
-------------------------------
loss: 0.143714  [    0/69947]
loss: 0.048504  [ 6400/69947]
loss: 0.103442  [12800/69947]
loss: 0.193574  [19200/69947]
loss: 0.094434  [25600/69947]
loss: 0.123605  [32000/69947]
loss: 0.015875  [38400/69947]
loss: 0.142522  [44800/69947]
loss: 0.066694  [51200/69947]
loss: 0.132863  [57600/69947]
loss: 0.123750  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.110299 

Epoch 21
-------------------------------
loss: 0.098841  [    0/69947]
loss: 0.025290  [ 6400/69947]
loss: 0.044878  [12800/69947]
loss: 0.162822  [19200/69947]
loss: 0.070990  [25600/69947]
loss: 0.208704  [32000/69947]
loss: 0.117894  [38400/69947]
loss: 0.060941  [44800/69947]
loss: 0.100764  [51200/69947]
loss: 0.249435  [57600/69947]
loss: 0.146245  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.107496 

Epoch 22
-------------------------------
loss: 0.128876  [    0/69947]
loss: 0.068796  [ 6400/69947]
loss: 0.091232  [12800/69947]
loss: 0.048104  [19200/69947]
loss: 0.084552  [25600/69947]
loss: 0.093946  [32000/69947]
loss: 0.107212  [38400/69947]
loss: 0.082914  [44800/69947]
loss: 0.064255  [51200/69947]
loss: 0.213434  [57600/69947]
loss: 0.102347  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.106291 

Epoch 23
-------------------------------
loss: 0.140153  [    0/69947]
loss: 0.166399  [ 6400/69947]
loss: 0.159700  [12800/69947]
loss: 0.055314  [19200/69947]
loss: 0.052836  [25600/69947]
loss: 0.083314  [32000/69947]
loss: 0.127919  [38400/69947]
loss: 0.080571  [44800/69947]
loss: 0.173487  [51200/69947]
loss: 0.148058  [57600/69947]
loss: 0.081843  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.108545 

Epoch 24
-------------------------------
loss: 0.057035  [    0/69947]
loss: 0.072455  [ 6400/69947]
loss: 0.290299  [12800/69947]
loss: 0.202127  [19200/69947]
loss: 0.034494  [25600/69947]
loss: 0.058986  [32000/69947]
loss: 0.061211  [38400/69947]
loss: 0.056686  [44800/69947]
loss: 0.079753  [51200/69947]
loss: 0.118412  [57600/69947]
loss: 0.139896  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.108205 

Epoch 25
-------------------------------
loss: 0.056437  [    0/69947]
loss: 0.182901  [ 6400/69947]
loss: 0.132906  [12800/69947]
loss: 0.080077  [19200/69947]
loss: 0.090636  [25600/69947]
loss: 0.104592  [32000/69947]
loss: 0.224663  [38400/69947]
loss: 0.133795  [44800/69947]
loss: 0.137140  [51200/69947]
loss: 0.078625  [57600/69947]
loss: 0.111205  [64000/69947]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.105340 

Epoch 26
-------------------------------
loss: 0.125911  [    0/69947]
loss: 0.142745  [ 6400/69947]
loss: 0.109815  [12800/69947]
loss: 0.204144  [19200/69947]
loss: 0.092070  [25600/69947]
loss: 0.023382  [32000/69947]
loss: 0.068976  [38400/69947]
loss: 0.090702  [44800/69947]
loss: 0.106485  [51200/69947]
loss: 0.227190  [57600/69947]
loss: 0.054244  [64000/69947]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.121471 

Epoch 27
-------------------------------
loss: 0.090156  [    0/69947]
loss: 0.093048  [ 6400/69947]
loss: 0.098742  [12800/69947]
loss: 0.136573  [19200/69947]
loss: 0.032397  [25600/69947]
loss: 0.145936  [32000/69947]
loss: 0.099617  [38400/69947]
loss: 0.145842  [44800/69947]
loss: 0.079526  [51200/69947]
loss: 0.045962  [57600/69947]
loss: 0.064711  [64000/69947]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.121923 

Epoch 28
-------------------------------
loss: 0.061571  [    0/69947]
loss: 0.025367  [ 6400/69947]
loss: 0.076584  [12800/69947]
loss: 0.180967  [19200/69947]
loss: 0.037386  [25600/69947]
loss: 0.181771  [32000/69947]
loss: 0.130985  [38400/69947]
loss: 0.164406  [44800/69947]
loss: 0.116966  [51200/69947]
loss: 0.082254  [57600/69947]
loss: 0.073731  [64000/69947]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.118205 

Epoch 29
-------------------------------
loss: 0.064002  [    0/69947]
loss: 0.118886  [ 6400/69947]
loss: 0.122486  [12800/69947]
loss: 0.055638  [19200/69947]
loss: 0.219579  [25600/69947]
loss: 0.103584  [32000/69947]
loss: 0.099267  [38400/69947]
loss: 0.094476  [44800/69947]
loss: 0.145323  [51200/69947]
loss: 0.072646  [57600/69947]
loss: 0.137824  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.114664 

Epoch 30
-------------------------------
loss: 0.067162  [    0/69947]
loss: 0.020573  [ 6400/69947]
loss: 0.090508  [12800/69947]
loss: 0.091702  [19200/69947]
loss: 0.154361  [25600/69947]
loss: 0.107775  [32000/69947]
loss: 0.132739  [38400/69947]
loss: 0.128285  [44800/69947]
loss: 0.117720  [51200/69947]
loss: 0.035172  [57600/69947]
loss: 0.119510  [64000/69947]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.102719 

Epoch 31
-------------------------------
loss: 0.072892  [    0/69947]
loss: 0.178411  [ 6400/69947]
loss: 0.251549  [12800/69947]
loss: 0.111167  [19200/69947]
loss: 0.083261  [25600/69947]
loss: 0.140513  [32000/69947]
loss: 0.138280  [38400/69947]
loss: 0.214965  [44800/69947]
loss: 0.115090  [51200/69947]
loss: 0.136161  [57600/69947]
loss: 0.234015  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.114066 

Epoch 32
-------------------------------
loss: 0.153261  [    0/69947]
loss: 0.121158  [ 6400/69947]
loss: 0.124500  [12800/69947]
loss: 0.073171  [19200/69947]
loss: 0.194290  [25600/69947]
loss: 0.266384  [32000/69947]
loss: 0.152181  [38400/69947]
loss: 0.115505  [44800/69947]
loss: 0.264823  [51200/69947]
loss: 0.195001  [57600/69947]
loss: 0.132482  [64000/69947]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.124500 

Epoch 33
-------------------------------
loss: 0.115541  [    0/69947]
loss: 0.101344  [ 6400/69947]
loss: 0.101774  [12800/69947]
loss: 0.063449  [19200/69947]
loss: 0.168285  [25600/69947]
loss: 0.215334  [32000/69947]
loss: 0.183429  [38400/69947]
loss: 0.188639  [44800/69947]
loss: 0.058402  [51200/69947]
loss: 0.088870  [57600/69947]
loss: 0.095986  [64000/69947]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.118383 

Epoch 34
-------------------------------
loss: 0.105209  [    0/69947]
loss: 0.078003  [ 6400/69947]
loss: 0.119287  [12800/69947]
loss: 0.085743  [19200/69947]
loss: 0.171374  [25600/69947]
loss: 0.096693  [32000/69947]
loss: 0.172897  [38400/69947]
loss: 0.166589  [44800/69947]
loss: 0.148906  [51200/69947]
loss: 0.101804  [57600/69947]
loss: 0.132095  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.118317 

Epoch 35
-------------------------------
loss: 0.095895  [    0/69947]
loss: 0.087625  [ 6400/69947]
loss: 0.120207  [12800/69947]
loss: 0.075735  [19200/69947]
loss: 0.106905  [25600/69947]
loss: 0.075329  [32000/69947]
loss: 0.199552  [38400/69947]
loss: 0.146925  [44800/69947]
loss: 0.125540  [51200/69947]
loss: 0.097970  [57600/69947]
loss: 0.079939  [64000/69947]
Test Error: 
 Accuracy: 89.4%, Avg loss: 0.376197 

Epoch 36
-------------------------------
loss: 0.111924  [    0/69947]
loss: 0.107667  [ 6400/69947]
loss: 0.110869  [12800/69947]
loss: 0.069260  [19200/69947]
loss: 0.109260  [25600/69947]
loss: 0.125064  [32000/69947]
loss: 0.167376  [38400/69947]
loss: 0.121675  [44800/69947]
loss: 0.078800  [51200/69947]
loss: 0.137981  [57600/69947]
loss: 0.143050  [64000/69947]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.126970 

Epoch 37
-------------------------------
loss: 0.043368  [    0/69947]
loss: 0.131633  [ 6400/69947]
loss: 0.063995  [12800/69947]
loss: 0.076232  [19200/69947]
loss: 0.036508  [25600/69947]
loss: 0.199232  [32000/69947]
loss: 0.124766  [38400/69947]
loss: 0.119379  [44800/69947]
loss: 0.183765  [51200/69947]
loss: 0.102153  [57600/69947]
loss: 0.053648  [64000/69947]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.121775 

Epoch 38
-------------------------------
loss: 0.070839  [    0/69947]
loss: 0.339907  [ 6400/69947]
loss: 0.211947  [12800/69947]
loss: 0.189341  [19200/69947]
loss: 0.033139  [25600/69947]
loss: 0.192101  [32000/69947]
loss: 0.082105  [38400/69947]
loss: 0.100576  [38400/71142]
loss: 0.104017  [44800/71142]
loss: 0.016176  [51200/71142]
loss: 0.099700  [57600/71142]
loss: 0.128334  [64000/71142]
loss: 0.080245  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.088971 

Epoch 30
-------------------------------
loss: 0.023096  [    0/71142]
loss: 0.234845  [ 6400/71142]
loss: 0.079885  [12800/71142]
loss: 0.033013  [19200/71142]
loss: 0.110741  [25600/71142]
loss: 0.065024  [32000/71142]
loss: 0.074022  [38400/71142]
loss: 0.278766  [44800/71142]
loss: 0.047194  [51200/71142]
loss: 0.083204  [57600/71142]
loss: 0.055800  [64000/71142]
loss: 0.127162  [70400/71142]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.087737 

Epoch 31
-------------------------------
loss: 0.019520  [    0/71142]
loss: 0.137598  [ 6400/71142]
loss: 0.054660  [12800/71142]
loss: 0.050031  [19200/71142]
loss: 0.100892  [25600/71142]
loss: 0.026192  [32000/71142]
loss: 0.068779  [38400/71142]
loss: 0.024608  [44800/71142]
loss: 0.054080  [51200/71142]
loss: 0.072069  [57600/71142]
loss: 0.194352  [64000/71142]
loss: 0.047282  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.088010 

Epoch 32
-------------------------------
loss: 0.075022  [    0/71142]
loss: 0.034806  [ 6400/71142]
loss: 0.120093  [12800/71142]
loss: 0.128584  [19200/71142]
loss: 0.085938  [25600/71142]
loss: 0.078935  [32000/71142]
loss: 0.046074  [38400/71142]
loss: 0.107228  [44800/71142]
loss: 0.034759  [51200/71142]
loss: 0.167317  [57600/71142]
loss: 0.067780  [64000/71142]
loss: 0.032983  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.091582 

Epoch 33
-------------------------------
loss: 0.059980  [    0/71142]
loss: 0.076984  [ 6400/71142]
loss: 0.097216  [12800/71142]
loss: 0.065335  [19200/71142]
loss: 0.044856  [25600/71142]
loss: 0.128313  [32000/71142]
loss: 0.057058  [38400/71142]
loss: 0.063645  [44800/71142]
loss: 0.070923  [51200/71142]
loss: 0.118963  [57600/71142]
loss: 0.063174  [64000/71142]
loss: 0.058216  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.094014 

Epoch 34
-------------------------------
loss: 0.046611  [    0/71142]
loss: 0.044257  [ 6400/71142]
loss: 0.074426  [12800/71142]
loss: 0.027368  [19200/71142]
loss: 0.143837  [25600/71142]
loss: 0.070361  [32000/71142]
loss: 0.054237  [38400/71142]
loss: 0.202166  [44800/71142]
loss: 0.049683  [51200/71142]
loss: 0.064062  [57600/71142]
loss: 0.106799  [64000/71142]
loss: 0.065502  [70400/71142]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.093303 

Epoch 35
-------------------------------
loss: 0.076112  [    0/71142]
loss: 0.040148  [ 6400/71142]
loss: 0.051137  [12800/71142]
loss: 0.086375  [19200/71142]
loss: 0.081287  [25600/71142]
loss: 0.061976  [32000/71142]
loss: 0.026682  [38400/71142]
loss: 0.164625  [44800/71142]
loss: 0.230236  [51200/71142]
loss: 0.137586  [57600/71142]
loss: 0.094950  [64000/71142]
loss: 0.080557  [70400/71142]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.104731 

Epoch 36
-------------------------------
loss: 0.069407  [    0/71142]
loss: 0.132574  [ 6400/71142]
loss: 0.176819  [12800/71142]
loss: 0.069061  [19200/71142]
loss: 0.053022  [25600/71142]
loss: 0.052581  [32000/71142]
loss: 0.072354  [38400/71142]
loss: 0.054245  [44800/71142]
loss: 0.158218  [51200/71142]
loss: 0.101835  [57600/71142]
loss: 0.093544  [64000/71142]
loss: 0.028688  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.088871 

Epoch 37
-------------------------------
loss: 0.088388  [    0/71142]
loss: 0.050397  [ 6400/71142]
loss: 0.059283  [12800/71142]
loss: 0.075837  [19200/71142]
loss: 0.017841  [25600/71142]
loss: 0.104780  [32000/71142]
loss: 0.036202  [38400/71142]
loss: 0.134748  [44800/71142]
loss: 0.120184  [51200/71142]
loss: 0.060730  [57600/71142]
loss: 0.103851  [64000/71142]
loss: 0.037088  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.093831 

Epoch 38
-------------------------------
loss: 0.121503  [    0/71142]
loss: 0.029280  [ 6400/71142]
loss: 0.049167  [12800/71142]
loss: 0.046761  [19200/71142]
loss: 0.153123  [25600/71142]
loss: 0.085607  [32000/71142]
loss: 0.087318  [38400/71142]
loss: 0.046564  [44800/71142]
loss: 0.079429  [51200/71142]
loss: 0.060257  [57600/71142]
loss: 0.133957  [64000/71142]
loss: 0.073189  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.088499 

Epoch 39
-------------------------------
loss: 0.076815  [    0/71142]
loss: 0.050427  [ 6400/71142]
loss: 0.159027  [12800/71142]
loss: 0.083783  [19200/71142]
loss: 0.134813  [25600/71142]
loss: 0.031942  [32000/71142]
loss: 0.022035  [38400/71142]
loss: 0.044443  [44800/71142]
loss: 0.127222  [51200/71142]
loss: 0.085972  [57600/71142]
loss: 0.049324  [64000/71142]
loss: 0.138902  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.087984 

Epoch 40
-------------------------------
loss: 0.027985  [    0/71142]
loss: 0.153041  [ 6400/71142]
loss: 0.081316  [12800/71142]
loss: 0.041405  [19200/71142]
loss: 0.055936  [25600/71142]
loss: 0.039902  [32000/71142]
loss: 0.093861  [38400/71142]
loss: 0.026636  [44800/71142]
loss: 0.125829  [51200/71142]
loss: 0.047308  [57600/71142]
loss: 0.135858  [64000/71142]
loss: 0.059264  [70400/71142]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.098449 

Epoch 41
-------------------------------
loss: 0.034803  [    0/71142]
loss: 0.080616  [ 6400/71142]
loss: 0.086626  [12800/71142]
loss: 0.138334  [19200/71142]
loss: 0.074117  [25600/71142]
loss: 0.106020  [32000/71142]
loss: 0.055879  [38400/71142]
loss: 0.086524  [44800/71142]
loss: 0.067905  [51200/71142]
loss: 0.047557  [57600/71142]
loss: 0.128568  [64000/71142]
loss: 0.052794  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.092580 

Epoch 42
-------------------------------
loss: 0.034885  [    0/71142]
loss: 0.195404  [ 6400/71142]
loss: 0.049013  [12800/71142]
loss: 0.079197  [19200/71142]
loss: 0.097070  [25600/71142]
loss: 0.035718  [32000/71142]
loss: 0.088201  [38400/71142]
loss: 0.074799  [44800/71142]
loss: 0.044142  [51200/71142]
loss: 0.075320  [57600/71142]
loss: 0.034857  [64000/71142]
loss: 0.061294  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.087708 

Epoch 43
-------------------------------
loss: 0.076372  [    0/71142]
loss: 0.187702  [ 6400/71142]
loss: 0.093850  [12800/71142]
loss: 0.091808  [19200/71142]
loss: 0.061763  [25600/71142]
loss: 0.103033  [32000/71142]
loss: 0.050326  [38400/71142]
loss: 0.075322  [44800/71142]
loss: 0.149121  [51200/71142]
loss: 0.237784  [57600/71142]
loss: 0.120758  [64000/71142]
loss: 0.048511  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.087443 

Epoch 44
-------------------------------
loss: 0.096115  [    0/71142]
loss: 0.129862  [ 6400/71142]
loss: 0.024251  [12800/71142]
loss: 0.109392  [19200/71142]
loss: 0.085126  [25600/71142]
loss: 0.178401  [32000/71142]
loss: 0.051684  [38400/71142]
loss: 0.040346  [44800/71142]
loss: 0.099443  [51200/71142]
loss: 0.138080  [57600/71142]
loss: 0.051750  [64000/71142]
loss: 0.097921  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090958 

Epoch 45
-------------------------------
loss: 0.109186  [    0/71142]
loss: 0.072461  [ 6400/71142]
loss: 0.024306  [12800/71142]
loss: 0.074859  [19200/71142]
loss: 0.044671  [25600/71142]
loss: 0.090533  [32000/71142]
loss: 0.181942  [38400/71142]
loss: 0.099780  [44800/71142]
loss: 0.113267  [51200/71142]
loss: 0.074693  [57600/71142]
loss: 0.110241  [64000/71142]
loss: 0.087172  [70400/71142]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.088921 

Epoch 46
-------------------------------
loss: 0.040286  [    0/71142]
loss: 0.086895  [ 6400/71142]
loss: 0.094299  [12800/71142]
loss: 0.171638  [19200/71142]
loss: 0.077125  [25600/71142]
loss: 0.033836  [32000/71142]
loss: 0.105486  [38400/71142]
loss: 0.057017  [44800/71142]
loss: 0.047838  [51200/71142]
loss: 0.027596  [57600/71142]
loss: 0.081613  [64000/71142]
loss: 0.054610  [70400/71142]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.093248 

Epoch 47
-------------------------------
loss: 0.086781  [    0/71142]
loss: 0.085936  [ 6400/71142]
loss: 0.073161  [12800/71142]
loss: 0.112968  [19200/71142]
loss: 0.054038  [25600/71142]
loss: 0.088816  [32000/71142]
loss: 0.018856  [38400/71142]
loss: 0.267317  [51200/69308]
loss: 0.135349  [57600/69308]
loss: 0.152832  [64000/69308]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.164957 

Epoch 12
-------------------------------
loss: 0.246197  [    0/69308]
loss: 0.115908  [ 6400/69308]
loss: 0.277136  [12800/69308]
loss: 0.169601  [19200/69308]
loss: 0.226980  [25600/69308]
loss: 0.124136  [32000/69308]
loss: 0.142317  [38400/69308]
loss: 0.242042  [44800/69308]
loss: 0.273269  [51200/69308]
loss: 0.296184  [57600/69308]
loss: 0.173211  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.175157 

Epoch 13
-------------------------------
loss: 0.191811  [    0/69308]
loss: 0.093861  [ 6400/69308]
loss: 0.404129  [12800/69308]
loss: 0.176150  [19200/69308]
loss: 0.122351  [25600/69308]
loss: 0.185650  [32000/69308]
loss: 0.134568  [38400/69308]
loss: 0.225176  [44800/69308]
loss: 0.229211  [51200/69308]
loss: 0.212192  [57600/69308]
loss: 0.109202  [64000/69308]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.173370 

Epoch 14
-------------------------------
loss: 0.189967  [    0/69308]
loss: 0.131642  [ 6400/69308]
loss: 0.178345  [12800/69308]
loss: 0.207157  [19200/69308]
loss: 0.194638  [25600/69308]
loss: 0.150635  [32000/69308]
loss: 0.100634  [38400/69308]
loss: 0.173954  [44800/69308]
loss: 0.216037  [51200/69308]
loss: 0.235916  [57600/69308]
loss: 0.173841  [64000/69308]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.172217 

Epoch 15
-------------------------------
loss: 0.136977  [    0/69308]
loss: 0.179942  [ 6400/69308]
loss: 0.186949  [12800/69308]
loss: 0.162414  [19200/69308]
loss: 0.111073  [25600/69308]
loss: 0.151891  [32000/69308]
loss: 0.325367  [38400/69308]
loss: 0.157062  [44800/69308]
loss: 0.192678  [51200/69308]
loss: 0.134803  [57600/69308]
loss: 0.120322  [64000/69308]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.172368 

Epoch 16
-------------------------------
loss: 0.336975  [    0/69308]
loss: 0.091720  [ 6400/69308]
loss: 0.155216  [12800/69308]
loss: 0.244674  [19200/69308]
loss: 0.188762  [25600/69308]
loss: 0.173413  [32000/69308]
loss: 0.164489  [38400/69308]
loss: 0.107593  [44800/69308]
loss: 0.148017  [51200/69308]
loss: 0.141580  [57600/69308]
loss: 0.169964  [64000/69308]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.169811 

Epoch 17
-------------------------------
loss: 0.122046  [    0/69308]
loss: 0.195669  [ 6400/69308]
loss: 0.133001  [12800/69308]
loss: 0.086568  [19200/69308]
loss: 0.170755  [25600/69308]
loss: 0.099951  [32000/69308]
loss: 0.277027  [38400/69308]
loss: 0.150663  [44800/69308]
loss: 0.190120  [51200/69308]
loss: 0.230422  [57600/69308]
loss: 0.119328  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.178911 

Epoch 18
-------------------------------
loss: 0.108483  [    0/69308]
loss: 0.258664  [ 6400/69308]
loss: 0.111075  [12800/69308]
loss: 0.307340  [19200/69308]
loss: 0.171173  [25600/69308]
loss: 0.154993  [32000/69308]
loss: 0.131793  [38400/69308]
loss: 0.152110  [44800/69308]
loss: 0.141220  [51200/69308]
loss: 0.249708  [57600/69308]
loss: 0.164329  [64000/69308]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.181185 

Epoch 19
-------------------------------
loss: 0.141814  [    0/69308]
loss: 0.170287  [ 6400/69308]
loss: 0.131527  [12800/69308]
loss: 0.158858  [19200/69308]
loss: 0.246948  [25600/69308]
loss: 0.204534  [32000/69308]
loss: 1.679636  [38400/69308]
loss: 0.177041  [44800/69308]
loss: 0.207505  [51200/69308]
loss: 0.230671  [57600/69308]
loss: 0.294339  [64000/69308]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.172445 

Epoch 20
-------------------------------
loss: 0.174344  [    0/69308]
loss: 0.165528  [ 6400/69308]
loss: 0.087323  [12800/69308]
loss: 0.361426  [19200/69308]
loss: 0.133943  [25600/69308]
loss: 0.131718  [32000/69308]
loss: 0.164959  [38400/69308]
loss: 0.230344  [44800/69308]
loss: 0.142523  [51200/69308]
loss: 0.105591  [57600/69308]
loss: 0.078827  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.180648 

Epoch 21
-------------------------------
loss: 0.092355  [    0/69308]
loss: 0.268854  [ 6400/69308]
loss: 0.152080  [12800/69308]
loss: 0.195562  [19200/69308]
loss: 0.163877  [25600/69308]
loss: 0.261078  [32000/69308]
loss: 0.207754  [38400/69308]
loss: 0.160307  [44800/69308]
loss: 0.211387  [51200/69308]
loss: 0.274389  [57600/69308]
loss: 0.258733  [64000/69308]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.168049 

Epoch 22
-------------------------------
loss: 0.177460  [    0/69308]
loss: 0.118822  [ 6400/69308]
loss: 0.120527  [12800/69308]
loss: 0.162073  [19200/69308]
loss: 0.117225  [25600/69308]
loss: 0.258616  [32000/69308]
loss: 0.101965  [38400/69308]
loss: 0.134862  [44800/69308]
loss: 0.141449  [51200/69308]
loss: 0.177586  [57600/69308]
loss: 0.228165  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.176938 

Epoch 23
-------------------------------
loss: 0.105598  [    0/69308]
loss: 0.185228  [ 6400/69308]
loss: 0.128673  [12800/69308]
loss: 0.212587  [19200/69308]
loss: 0.213940  [25600/69308]
loss: 0.062022  [32000/69308]
loss: 0.140466  [38400/69308]
loss: 0.149464  [44800/69308]
loss: 0.228694  [51200/69308]
loss: 0.207310  [57600/69308]
loss: 0.109442  [64000/69308]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.172710 

Epoch 24
-------------------------------
loss: 0.226379  [    0/69308]
loss: 0.346069  [ 6400/69308]
loss: 0.185957  [12800/69308]
loss: 0.169795  [19200/69308]
loss: 0.178472  [25600/69308]
loss: 0.226923  [32000/69308]
loss: 0.298576  [38400/69308]
loss: 0.222522  [44800/69308]
loss: 0.160218  [51200/69308]
loss: 0.178536  [57600/69308]
loss: 0.116186  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.179570 

Epoch 25
-------------------------------
loss: 0.186471  [    0/69308]
loss: 0.260863  [ 6400/69308]
loss: 0.206286  [12800/69308]
loss: 0.134173  [19200/69308]
loss: 0.178067  [25600/69308]
loss: 0.120222  [32000/69308]
loss: 0.158290  [38400/69308]
loss: 0.108687  [44800/69308]
loss: 0.148047  [51200/69308]
loss: 0.178171  [57600/69308]
loss: 0.102459  [64000/69308]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.176205 

Epoch 26
-------------------------------
loss: 0.239864  [    0/69308]
loss: 0.070268  [ 6400/69308]
loss: 0.058141  [12800/69308]
loss: 0.224682  [19200/69308]
loss: 0.164754  [25600/69308]
loss: 0.124136  [32000/69308]
loss: 0.170164  [38400/69308]
loss: 0.109868  [44800/69308]
loss: 0.215701  [51200/69308]
loss: 0.067290  [57600/69308]
loss: 0.121750  [64000/69308]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.172016 

Epoch 27
-------------------------------
loss: 0.288579  [    0/69308]
loss: 0.186382  [ 6400/69308]
loss: 0.154944  [12800/69308]
loss: 0.155091  [19200/69308]
loss: 0.184648  [25600/69308]
loss: 0.133089  [32000/69308]
loss: 0.181464  [38400/69308]
loss: 0.100875  [44800/69308]
loss: 0.242876  [51200/69308]
loss: 0.365455  [57600/69308]
loss: 0.119194  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.170130 

Epoch 28
-------------------------------
loss: 0.110368  [    0/69308]
loss: 0.217900  [ 6400/69308]
loss: 0.141673  [12800/69308]
loss: 0.249323  [19200/69308]
loss: 0.116796  [25600/69308]
loss: 0.156017  [32000/69308]
loss: 0.199175  [38400/69308]
loss: 0.176645  [44800/69308]
loss: 0.261572  [51200/69308]
loss: 0.192492  [57600/69308]
loss: 0.134012  [64000/69308]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.177489 

Epoch 29
-------------------------------
loss: 0.169805  [    0/69308]
loss: 0.274099  [ 6400/69308]
loss: 0.251532  [12800/69308]
loss: 0.262207  [19200/69308]
loss: 0.188075  [25600/69308]
loss: 0.286831  [32000/69308]
loss: 0.214173  [38400/69308]
loss: 0.170984  [44800/69308]
loss: 0.156502  [51200/69308]
loss: 0.147737  [57600/69308]
loss: 0.123988  [64000/69308]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.173210 

Epoch 30
-------------------------------
loss: 0.131078  [    0/69308]
loss: 0.164387  [ 6400/69308]
loss: 0.225402  [12800/69308]
loss: 0.220308  [19200/69308]
loss: 0.162042  [25600/69308]
loss: 0.204390  [32000/69308]
loss: 0.173278  [38400/69308]
loss: 0.117249  [44800/69308]
loss: 0.303697  [51200/69308]
loss: 0.114590  [57600/69308]
loss: 0.140327  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.171680 

/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:17:56 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.179793  [44800/69683]
loss: 0.150137  [51200/69683]
loss: 0.134179  [57600/69683]
loss: 0.180558  [64000/69683]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.191641 

Epoch 4
-------------------------------
loss: 0.160183  [    0/69683]
loss: 0.158464  [ 6400/69683]
loss: 0.164923  [12800/69683]
loss: 0.180563  [19200/69683]
loss: 0.144916  [25600/69683]
loss: 0.314052  [32000/69683]
loss: 0.217522  [38400/69683]
loss: 0.181350  [44800/69683]
loss: 0.173512  [51200/69683]
loss: 0.226977  [57600/69683]
loss: 0.205810  [64000/69683]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.201641 

Epoch 5
-------------------------------
loss: 0.132720  [    0/69683]
loss: 0.179186  [ 6400/69683]
loss: 0.168870  [12800/69683]
loss: 0.187666  [19200/69683]
loss: 0.219645  [25600/69683]
loss: 0.222181  [32000/69683]
loss: 0.239502  [38400/69683]
loss: 0.294426  [44800/69683]
loss: 0.205588  [51200/69683]
loss: 0.263137  [57600/69683]
loss: 0.218647  [64000/69683]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.194947 

Epoch 6
-------------------------------
loss: 0.280808  [    0/69683]
loss: 0.217266  [ 6400/69683]
loss: 0.209241  [12800/69683]
loss: 0.194961  [19200/69683]
loss: 0.233656  [25600/69683]
loss: 0.197735  [32000/69683]
loss: 0.158108  [38400/69683]
loss: 0.169341  [44800/69683]
loss: 0.187879  [51200/69683]
loss: 0.227208  [57600/69683]
loss: 0.251228  [64000/69683]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.188529 

Epoch 7
-------------------------------
loss: 0.166829  [    0/69683]
loss: 0.182134  [ 6400/69683]
loss: 0.112017  [12800/69683]
loss: 0.177267  [19200/69683]
loss: 0.195390  [25600/69683]
loss: 0.277051  [32000/69683]
loss: 0.186862  [38400/69683]
loss: 0.221510  [44800/69683]
loss: 0.120056  [51200/69683]
loss: 0.162299  [57600/69683]
loss: 0.197166  [64000/69683]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.176224 

Epoch 8
-------------------------------
loss: 0.109364  [    0/69683]
loss: 0.364045  [ 6400/69683]
loss: 0.300799  [12800/69683]
loss: 0.157781  [19200/69683]
loss: 0.266296  [25600/69683]
loss: 0.299187  [32000/69683]
loss: 0.078607  [38400/69683]
loss: 0.352091  [44800/69683]
loss: 0.353533  [51200/69683]
loss: 0.105439  [57600/69683]
loss: 0.173244  [64000/69683]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.178921 

Epoch 9
-------------------------------
loss: 0.173576  [    0/69683]
loss: 0.127111  [ 6400/69683]
loss: 0.191257  [12800/69683]
loss: 0.419321  [19200/69683]
loss: 0.322473  [25600/69683]
loss: 0.222297  [32000/69683]
loss: 0.170592  [38400/69683]
loss: 0.310822  [44800/69683]
loss: 0.226940  [51200/69683]
loss: 0.193226  [57600/69683]
loss: 0.229350  [64000/69683]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.181533 

Epoch 10
-------------------------------
loss: 0.283506  [    0/69683]
loss: 0.211343  [ 6400/69683]
loss: 0.190631  [12800/69683]
loss: 0.407287  [19200/69683]
loss: 0.157604  [25600/69683]
loss: 0.110239  [32000/69683]
loss: 0.232034  [38400/69683]
loss: 0.151628  [44800/69683]
loss: 0.114935  [51200/69683]
loss: 0.177089  [57600/69683]
loss: 0.170546  [64000/69683]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.180970 

Epoch 11
-------------------------------
loss: 0.248733  [    0/69683]
loss: 0.120493  [ 6400/69683]
loss: 0.182072  [12800/69683]
loss: 0.238803  [19200/69683]
loss: 0.172956  [25600/69683]
loss: 0.263895  [32000/69683]
loss: 0.184347  [38400/69683]
loss: 0.169813  [44800/69683]
loss: 0.202051  [51200/69683]
loss: 0.141615  [57600/69683]
loss: 0.179709  [64000/69683]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.174414 

Epoch 12
-------------------------------
loss: 0.157017  [    0/69683]
loss: 0.220429  [ 6400/69683]
loss: 0.157350  [12800/69683]
loss: 0.162562  [19200/69683]
loss: 0.161103  [25600/69683]
loss: 0.262204  [32000/69683]
loss: 0.197147  [38400/69683]
loss: 0.232305  [44800/69683]
loss: 0.130820  [51200/69683]
loss: 0.243895  [57600/69683]
loss: 0.222880  [64000/69683]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.172167 

Epoch 13
-------------------------------
loss: 0.249206  [    0/69683]
loss: 0.303910  [ 6400/69683]
loss: 0.196414  [12800/69683]
loss: 0.148029  [19200/69683]
loss: 0.245846  [25600/69683]
loss: 0.097061  [32000/69683]
loss: 0.147766  [38400/69683]
loss: 0.169753  [44800/69683]
loss: 0.318633  [51200/69683]
loss: 0.182352  [57600/69683]
loss: 0.235138  [64000/69683]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.176319 

Epoch 14
-------------------------------
loss: 0.103224  [    0/69683]
loss: 0.190771  [ 6400/69683]
loss: 0.206264  [12800/69683]
loss: 0.139680  [19200/69683]
loss: 0.133239  [25600/69683]
loss: 0.138364  [32000/69683]
loss: 0.175694  [38400/69683]
loss: 0.195174  [44800/69683]
loss: 0.354970  [51200/69683]
loss: 0.210623  [57600/69683]
loss: 0.159640  [64000/69683]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177717 

Epoch 15
-------------------------------
loss: 0.206441  [    0/69683]
loss: 0.133881  [ 6400/69683]
loss: 0.172996  [12800/69683]
loss: 0.250944  [19200/69683]
loss: 0.161907  [25600/69683]
loss: 0.149524  [32000/69683]
loss: 0.201653  [38400/69683]
loss: 0.163278  [44800/69683]
loss: 0.115261  [51200/69683]
loss: 0.333364  [57600/69683]
loss: 0.147647  [64000/69683]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.178639 

Epoch 16
-------------------------------
loss: 0.132832  [    0/69683]
loss: 0.216988  [ 6400/69683]
loss: 0.139663  [12800/69683]
loss: 0.152906  [19200/69683]
loss: 0.263968  [25600/69683]
loss: 0.135698  [32000/69683]
loss: 0.127681  [38400/69683]
loss: 0.189412  [44800/69683]
loss: 0.153449  [51200/69683]
loss: 1.738841  [57600/69683]
loss: 0.147831  [64000/69683]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.181942 

Epoch 17
-------------------------------
loss: 0.110470  [    0/69683]
loss: 0.159085  [ 6400/69683]
loss: 0.173546  [12800/69683]
loss: 0.226031  [19200/69683]
loss: 0.203991  [25600/69683]
loss: 0.125928  [32000/69683]
loss: 0.167062  [38400/69683]
loss: 0.234657  [44800/69683]
loss: 0.127720  [51200/69683]
loss: 0.222695  [57600/69683]
loss: 0.170390  [64000/69683]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.175960 

Epoch 18
-------------------------------
loss: 0.092413  [    0/69683]
loss: 0.185708  [ 6400/69683]
loss: 0.132080  [12800/69683]
loss: 0.187696  [19200/69683]
loss: 0.135991  [25600/69683]
loss: 0.132604  [32000/69683]
loss: 0.211518  [38400/69683]
loss: 0.177684  [44800/69683]
loss: 0.204336  [51200/69683]
loss: 0.217869  [57600/69683]
loss: 0.134136  [64000/69683]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.186233 

Epoch 19
-------------------------------
loss: 0.380892  [    0/69683]
loss: 0.188960  [ 6400/69683]
loss: 0.212179  [12800/69683]
loss: 0.157675  [19200/69683]
loss: 0.130466  [25600/69683]
loss: 0.160703  [32000/69683]
loss: 0.149982  [38400/69683]
loss: 0.132884  [44800/69683]
loss: 0.158674  [51200/69683]
loss: 0.192711  [57600/69683]
loss: 0.180986  [64000/69683]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.188096 

Epoch 20
-------------------------------
loss: 0.171916  [    0/69683]
loss: 0.179939  [ 6400/69683]
loss: 0.274202  [12800/69683]
loss: 0.178525  [19200/69683]
loss: 0.307323  [25600/69683]
loss: 0.194712  [32000/69683]
loss: 0.262096  [38400/69683]
loss: 0.218000  [44800/69683]
loss: 0.153080  [51200/69683]
loss: 0.176824  [57600/69683]
loss: 0.246910  [64000/69683]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.177759 

Epoch 21
-------------------------------
loss: 0.185722  [    0/69683]
loss: 0.092802  [ 6400/69683]
loss: 0.229699  [12800/69683]
loss: 0.266101  [19200/69683]
loss: 0.203447  [25600/69683]
loss: 0.131519  [32000/69683]
loss: 0.172469  [38400/69683]
loss: 0.266923  [44800/69683]
loss: 0.210822  [51200/69683]
loss: 0.250907  [57600/69683]
loss: 0.192249  [64000/69683]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.181139 

Epoch 22
-------------------------------
loss: 0.086213  [    0/69683]
loss: 0.108849  [ 6400/69683]
loss: 0.203926  [12800/69683]
loss: 0.088050  [19200/69683]
loss: 0.175920  [25600/69683]
loss: 0.242954  [32000/69683]
loss: 0.244618  [38400/69683]
loss: 0.438605  [44800/69683]
loss: 0.217957  [51200/69683]
loss: 0.216271  [57600/69683]
loss: 0.229150  [64000/69683]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:19:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.111560  [44800/70068]
loss: 0.287514  [51200/70068]
loss: 0.186017  [57600/70068]
loss: 0.105248  [64000/70068]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.163655 

Epoch 32
-------------------------------
loss: 0.215023  [    0/70068]
loss: 0.124870  [ 6400/70068]
loss: 0.171329  [12800/70068]
loss: 0.081671  [19200/70068]
loss: 0.093007  [25600/70068]
loss: 0.151701  [32000/70068]
loss: 0.155909  [38400/70068]
loss: 0.155205  [44800/70068]
loss: 0.231666  [51200/70068]
loss: 0.148481  [57600/70068]
loss: 0.166897  [64000/70068]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.174198 

Epoch 33
-------------------------------
loss: 0.128510  [    0/70068]
loss: 0.097825  [ 6400/70068]
loss: 0.113697  [12800/70068]
loss: 0.079661  [19200/70068]
loss: 0.179383  [25600/70068]
loss: 0.154220  [32000/70068]
loss: 0.090627  [38400/70068]
loss: 0.098243  [44800/70068]
loss: 0.091158  [51200/70068]
loss: 0.092583  [57600/70068]
loss: 0.125181  [64000/70068]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.166330 

Epoch 34
-------------------------------
loss: 0.142221  [    0/70068]
loss: 0.226465  [ 6400/70068]
loss: 0.083848  [12800/70068]
loss: 0.138921  [19200/70068]
loss: 0.093681  [25600/70068]
loss: 0.139227  [32000/70068]
loss: 0.116595  [38400/70068]
loss: 0.121958  [44800/70068]
loss: 0.103707  [51200/70068]
loss: 0.150031  [57600/70068]
loss: 0.075120  [64000/70068]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.167600 

Epoch 35
-------------------------------
loss: 0.110221  [    0/70068]
loss: 0.173501  [ 6400/70068]
loss: 0.167821  [12800/70068]
loss: 0.097272  [19200/70068]
loss: 0.217251  [25600/70068]
loss: 0.321030  [32000/70068]
loss: 0.062144  [38400/70068]
loss: 0.165583  [44800/70068]
loss: 0.111630  [51200/70068]
loss: 0.038067  [57600/70068]
loss: 0.172018  [64000/70068]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169553 

Epoch 36
-------------------------------
loss: 0.063509  [    0/70068]
loss: 0.220716  [ 6400/70068]
loss: 0.187484  [12800/70068]
loss: 0.167313  [19200/70068]
loss: 0.120692  [25600/70068]
loss: 0.141721  [32000/70068]
loss: 0.103722  [38400/70068]
loss: 0.113146  [44800/70068]
loss: 0.215085  [51200/70068]
loss: 0.149133  [57600/70068]
loss: 0.089548  [64000/70068]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.160493 

Epoch 37
-------------------------------
loss: 0.127411  [    0/70068]
loss: 0.105009  [ 6400/70068]
loss: 0.121676  [12800/70068]
loss: 0.141752  [19200/70068]
loss: 0.216674  [25600/70068]
loss: 0.104316  [32000/70068]
loss: 0.292072  [38400/70068]
loss: 0.113078  [44800/70068]
loss: 0.180509  [51200/70068]
loss: 0.225645  [57600/70068]
loss: 0.091643  [64000/70068]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.168462 

Epoch 38
-------------------------------
loss: 0.147899  [    0/70068]
loss: 0.136462  [ 6400/70068]
loss: 1.691995  [12800/70068]
loss: 0.092278  [19200/70068]
loss: 0.245028  [25600/70068]
loss: 0.105872  [32000/70068]
loss: 0.231803  [38400/70068]
loss: 0.099663  [44800/70068]
loss: 0.177764  [51200/70068]
loss: 0.123144  [57600/70068]
loss: 0.088181  [64000/70068]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.166528 

Epoch 39
-------------------------------
loss: 0.112078  [    0/70068]
loss: 0.153415  [ 6400/70068]
loss: 0.222859  [12800/70068]
loss: 0.087865  [19200/70068]
loss: 0.135935  [25600/70068]
loss: 0.182068  [32000/70068]
loss: 0.301762  [38400/70068]
loss: 0.063744  [44800/70068]
loss: 0.132118  [51200/70068]
loss: 0.061623  [57600/70068]
loss: 0.044585  [64000/70068]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.162327 

Epoch 40
-------------------------------
loss: 0.068838  [    0/70068]
loss: 0.251879  [ 6400/70068]
loss: 0.169359  [12800/70068]
loss: 0.170268  [19200/70068]
loss: 0.115071  [25600/70068]
loss: 0.171970  [32000/70068]
loss: 0.076385  [38400/70068]
loss: 0.162352  [44800/70068]
loss: 0.143189  [51200/70068]
loss: 0.060401  [57600/70068]
loss: 0.107133  [64000/70068]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162888 

Epoch 41
-------------------------------
loss: 0.152073  [    0/70068]
loss: 0.161157  [ 6400/70068]
loss: 0.169265  [12800/70068]
loss: 0.203181  [19200/70068]
loss: 0.250628  [25600/70068]
loss: 0.152258  [32000/70068]
loss: 0.048373  [38400/70068]
loss: 0.084343  [44800/70068]
loss: 1.641472  [51200/70068]
loss: 0.118255  [57600/70068]
loss: 0.129477  [64000/70068]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.158640 

Epoch 42
-------------------------------
loss: 0.098627  [    0/70068]
loss: 0.102354  [ 6400/70068]
loss: 0.033053  [12800/70068]
loss: 0.116112  [19200/70068]
loss: 0.229208  [25600/70068]
loss: 0.069540  [32000/70068]
loss: 0.111458  [38400/70068]
loss: 0.088036  [44800/70068]
loss: 0.160684  [51200/70068]
loss: 0.204683  [57600/70068]
loss: 0.219412  [64000/70068]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.166678 

Epoch 43
-------------------------------
loss: 0.158330  [    0/70068]
loss: 0.113193  [ 6400/70068]
loss: 0.127703  [12800/70068]
loss: 0.060965  [19200/70068]
loss: 0.061154  [25600/70068]
loss: 0.105579  [32000/70068]
loss: 0.098188  [38400/70068]
loss: 0.131710  [44800/70068]
loss: 0.091413  [51200/70068]
loss: 0.183680  [57600/70068]
loss: 0.281877  [64000/70068]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169652 

Epoch 44
-------------------------------
loss: 0.134258  [    0/70068]
loss: 0.130242  [ 6400/70068]
loss: 0.175285  [12800/70068]
loss: 0.231233  [19200/70068]
loss: 0.158966  [25600/70068]
loss: 0.117322  [32000/70068]
loss: 0.071837  [38400/70068]
loss: 0.183734  [44800/70068]
loss: 0.161619  [51200/70068]
loss: 0.245137  [57600/70068]
loss: 0.062143  [64000/70068]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.163746 

Epoch 45
-------------------------------
loss: 0.078016  [    0/70068]
loss: 0.216575  [ 6400/70068]
loss: 0.027971  [12800/70068]
loss: 0.045811  [19200/70068]
loss: 0.236704  [25600/70068]
loss: 0.109535  [32000/70068]
loss: 0.185736  [38400/70068]
loss: 0.133968  [44800/70068]
loss: 0.130891  [51200/70068]
loss: 0.185574  [57600/70068]
loss: 0.185290  [64000/70068]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162441 

Epoch 46
-------------------------------
loss: 0.161574  [    0/70068]
loss: 0.104389  [ 6400/70068]
loss: 0.153387  [12800/70068]
loss: 0.154378  [19200/70068]
loss: 0.189719  [25600/70068]
loss: 0.190358  [32000/70068]
loss: 0.189622  [38400/70068]
loss: 0.194403  [44800/70068]
loss: 0.144394  [51200/70068]
loss: 0.248075  [57600/70068]
loss: 0.122158  [64000/70068]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.164306 

Epoch 47
-------------------------------
loss: 0.116020  [    0/70068]
loss: 0.056035  [ 6400/70068]
loss: 0.129928  [12800/70068]
loss: 0.157040  [19200/70068]
loss: 0.103736  [25600/70068]
loss: 0.140257  [32000/70068]
loss: 0.092080  [38400/70068]
loss: 0.098190  [44800/70068]
loss: 0.160357  [51200/70068]
loss: 0.124095  [57600/70068]
loss: 0.123977  [64000/70068]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.173593 

Epoch 48
-------------------------------
loss: 0.104181  [    0/70068]
loss: 0.057062  [ 6400/70068]
loss: 0.084272  [12800/70068]
loss: 0.110077  [19200/70068]
loss: 0.067569  [25600/70068]
loss: 0.050621  [32000/70068]
loss: 0.232600  [38400/70068]
loss: 0.062592  [44800/70068]
loss: 0.068225  [51200/70068]
loss: 0.162202  [57600/70068]
loss: 0.101640  [64000/70068]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.174686 

Epoch 49
-------------------------------
loss: 0.194018  [    0/70068]
loss: 0.106188  [ 6400/70068]
loss: 0.071513  [12800/70068]
loss: 0.118949  [19200/70068]
loss: 0.101859  [25600/70068]
loss: 0.096137  [32000/70068]
loss: 0.080536  [38400/70068]
loss: 0.099277  [44800/70068]
loss: 0.117297  [51200/70068]
loss: 0.143351  [57600/70068]
loss: 0.163707  [64000/70068]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.164003 

Epoch 50
-------------------------------
loss: 0.087128  [    0/70068]
loss: 0.150786  [ 6400/70068]
loss: 0.223726  [12800/70068]
loss: 0.112651  [19200/70068]
loss: 0.191404  [25600/70068]
loss: 0.233255  [32000/70068]
loss: 0.070033  [38400/70068]
loss: 0.389779  [44800/70068]
loss: 0.044771  [51200/70068]
loss: 0.176300  [57600/70068]
loss: 0.209974  [64000/70068]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:22:05 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:22:16 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:23:47 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:23:58 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.037301  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.099602 

Epoch 33
-------------------------------
loss: 0.210730  [    0/71083]
loss: 0.095653  [ 6400/71083]
loss: 0.092925  [12800/71083]
loss: 0.099998  [19200/71083]
loss: 0.024808  [25600/71083]
loss: 0.108826  [32000/71083]
loss: 0.014990  [38400/71083]
loss: 0.162606  [44800/71083]
loss: 0.050345  [51200/71083]
loss: 0.058976  [57600/71083]
loss: 0.149380  [64000/71083]
loss: 0.081863  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.102993 

Epoch 34
-------------------------------
loss: 0.125472  [    0/71083]
loss: 0.112142  [ 6400/71083]
loss: 0.068336  [12800/71083]
loss: 0.152071  [19200/71083]
loss: 0.103103  [25600/71083]
loss: 0.280475  [32000/71083]
loss: 0.068310  [38400/71083]
loss: 0.006492  [44800/71083]
loss: 0.034686  [51200/71083]
loss: 0.065048  [57600/71083]
loss: 0.048618  [64000/71083]
loss: 0.043447  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.105483 

Epoch 35
-------------------------------
loss: 0.074901  [    0/71083]
loss: 0.087959  [ 6400/71083]
loss: 0.012358  [12800/71083]
loss: 0.094701  [19200/71083]
loss: 0.182730  [25600/71083]
loss: 0.061452  [32000/71083]
loss: 0.046731  [38400/71083]
loss: 0.090957  [44800/71083]
loss: 0.035763  [51200/71083]
loss: 0.077932  [57600/71083]
loss: 0.063287  [64000/71083]
loss: 0.064207  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.103127 

Epoch 36
-------------------------------
loss: 0.037265  [    0/71083]
loss: 0.059450  [ 6400/71083]
loss: 0.029171  [12800/71083]
loss: 0.034452  [19200/71083]
loss: 0.115319  [25600/71083]
loss: 0.083249  [32000/71083]
loss: 0.032819  [38400/71083]
loss: 0.101060  [44800/71083]
loss: 0.063922  [51200/71083]
loss: 0.153958  [57600/71083]
loss: 0.055032  [64000/71083]
loss: 0.052614  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.101074 

Epoch 37
-------------------------------
loss: 0.038524  [    0/71083]
loss: 0.086547  [ 6400/71083]
loss: 0.070420  [12800/71083]
loss: 0.032659  [19200/71083]
loss: 0.057682  [25600/71083]
loss: 0.190719  [32000/71083]
loss: 0.046936  [38400/71083]
loss: 0.055948  [44800/71083]
loss: 0.075622  [51200/71083]
loss: 0.193382  [57600/71083]
loss: 0.063148  [64000/71083]
loss: 0.077948  [70400/71083]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.101236 

Epoch 38
-------------------------------
loss: 0.024018  [    0/71083]
loss: 0.036899  [ 6400/71083]
loss: 0.122878  [12800/71083]
loss: 0.127515  [19200/71083]
loss: 0.042567  [25600/71083]
loss: 0.075871  [32000/71083]
loss: 0.039176  [38400/71083]
loss: 0.062954  [44800/71083]
loss: 0.020040  [51200/71083]
loss: 0.016636  [57600/71083]
loss: 0.341442  [64000/71083]
loss: 0.050158  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.106162 

Epoch 39
-------------------------------
loss: 0.068091  [    0/71083]
loss: 0.019950  [ 6400/71083]
loss: 0.134700  [12800/71083]
loss: 0.034435  [19200/71083]
loss: 0.042140  [25600/71083]
loss: 0.046387  [32000/71083]
loss: 0.056468  [38400/71083]
loss: 0.017938  [44800/71083]
loss: 0.026392  [51200/71083]
loss: 0.038721  [57600/71083]
loss: 0.187134  [64000/71083]
loss: 0.028071  [70400/71083]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.105380 

Epoch 40
-------------------------------
loss: 0.091128  [    0/71083]
loss: 0.012445  [ 6400/71083]
loss: 0.082015  [12800/71083]
loss: 0.031469  [19200/71083]
loss: 1.606947  [25600/71083]
loss: 0.070462  [32000/71083]
loss: 0.038811  [38400/71083]
loss: 0.093685  [44800/71083]
loss: 0.021899  [51200/71083]
loss: 0.050074  [57600/71083]
loss: 0.044295  [64000/71083]
loss: 0.140512  [70400/71083]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.104837 

Epoch 41
-------------------------------
loss: 0.073679  [    0/71083]
loss: 0.069255  [ 6400/71083]
loss: 0.093033  [12800/71083]
loss: 0.057631  [19200/71083]
loss: 0.043002  [25600/71083]
loss: 0.118889  [32000/71083]
loss: 0.104092  [38400/71083]
loss: 0.089741  [44800/71083]
loss: 0.156071  [51200/71083]
loss: 0.026887  [57600/71083]
loss: 0.066373  [64000/71083]
loss: 0.072447  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.103549 

Epoch 42
-------------------------------
loss: 0.044847  [    0/71083]
loss: 0.143889  [ 6400/71083]
loss: 0.128421  [12800/71083]
loss: 0.138979  [19200/71083]
loss: 0.043917  [25600/71083]
loss: 0.235701  [32000/71083]
loss: 0.079184  [38400/71083]
loss: 0.084409  [44800/71083]
loss: 0.082140  [51200/71083]
loss: 0.050878  [57600/71083]
loss: 0.108499  [64000/71083]
loss: 0.078191  [70400/71083]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.100960 

Epoch 43
-------------------------------
loss: 0.051877  [    0/71083]
loss: 0.194566  [ 6400/71083]
loss: 0.029994  [12800/71083]
loss: 0.046159  [19200/71083]
loss: 0.081483  [25600/71083]
loss: 0.029506  [32000/71083]
loss: 0.034126  [38400/71083]
loss: 0.045351  [44800/71083]
loss: 0.026283  [51200/71083]
loss: 0.096914  [57600/71083]
loss: 0.021880  [64000/71083]
loss: 0.067887  [70400/71083]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.109041 

Epoch 44
-------------------------------
loss: 0.057654  [    0/71083]
loss: 0.073617  [ 6400/71083]
loss: 0.049289  [12800/71083]
loss: 0.044278  [19200/71083]
loss: 0.065911  [25600/71083]
loss: 0.084413  [32000/71083]
loss: 0.220259  [38400/71083]
loss: 0.080098  [44800/71083]
loss: 0.031155  [51200/71083]
loss: 0.107174  [57600/71083]
loss: 0.080928  [64000/71083]
loss: 0.035004  [70400/71083]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.106834 

Epoch 45
-------------------------------
loss: 0.069623  [    0/71083]
loss: 0.019091  [ 6400/71083]
loss: 0.088977  [12800/71083]
loss: 0.059193  [19200/71083]
loss: 0.154684  [25600/71083]
loss: 0.126226  [32000/71083]
loss: 0.074055  [38400/71083]
loss: 0.053513  [44800/71083]
loss: 0.048227  [51200/71083]
loss: 0.129962  [57600/71083]
loss: 0.056090  [64000/71083]
loss: 0.041682  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.100550 

Epoch 46
-------------------------------
loss: 0.074213  [    0/71083]
loss: 0.039820  [ 6400/71083]
loss: 0.109020  [12800/71083]
loss: 0.027937  [19200/71083]
loss: 0.105039  [25600/71083]
loss: 0.105180  [32000/71083]
loss: 0.012286  [38400/71083]
loss: 0.015391  [44800/71083]
loss: 0.032224  [51200/71083]
loss: 0.022880  [57600/71083]
loss: 0.051685  [64000/71083]
loss: 0.013276  [70400/71083]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.112011 

Epoch 47
-------------------------------
loss: 0.066466  [    0/71083]
loss: 0.063345  [ 6400/71083]
loss: 0.038616  [12800/71083]
loss: 0.107403  [19200/71083]
loss: 0.071915  [25600/71083]
loss: 0.037593  [32000/71083]
loss: 0.046902  [38400/71083]
loss: 0.019075  [44800/71083]
loss: 0.171650  [51200/71083]
loss: 0.027154  [57600/71083]
loss: 0.079156  [64000/71083]
loss: 0.014319  [70400/71083]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.104609 

Epoch 48
-------------------------------
loss: 0.017690  [    0/71083]
loss: 0.040576  [ 6400/71083]
loss: 0.134836  [12800/71083]
loss: 0.078872  [19200/71083]
loss: 0.078870  [25600/71083]
loss: 0.033902  [32000/71083]
loss: 0.059337  [38400/71083]
loss: 0.118489  [44800/71083]
loss: 0.114340  [51200/71083]
loss: 0.198699  [57600/71083]
loss: 0.035342  [64000/71083]
loss: 0.085735  [70400/71083]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.105050 

Epoch 49
-------------------------------
loss: 0.046460  [    0/71083]
loss: 0.038802  [ 6400/71083]
loss: 0.071313  [12800/71083]
loss: 0.059524  [19200/71083]
loss: 0.112124  [25600/71083]
loss: 0.097825  [32000/71083]
loss: 0.066799  [38400/71083]
loss: 0.078688  [44800/71083]
loss: 0.063022  [51200/71083]
loss: 0.074855  [57600/71083]
loss: 0.046573  [64000/71083]
loss: 0.078681  [70400/71083]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.098951 

Epoch 50
-------------------------------
loss: 0.071122  [    0/71083]
loss: 0.063591  [ 6400/71083]
loss: 0.060990  [12800/71083]
loss: 0.055828  [19200/71083]
loss: 0.063418  [25600/71083]
loss: 0.007050  [32000/71083]
loss: 0.030285  [38400/71083]
loss: 0.071199  [44800/71083]
loss: 0.033724  [51200/71083]
loss: 0.061429  [57600/71083]
loss: 0.211635  [64000/71083]
loss: 0.137649  [70400/71083]
loss: 0.197051  [32000/71193]
loss: 0.074565  [38400/71193]
loss: 0.213178  [44800/71193]
loss: 0.115571  [51200/71193]
loss: 0.121127  [57600/71193]
loss: 0.132376  [64000/71193]
loss: 0.196473  [70400/71193]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.136716 

Epoch 22
-------------------------------
loss: 0.084933  [    0/71193]
loss: 0.183045  [ 6400/71193]
loss: 0.065750  [12800/71193]
loss: 0.106395  [19200/71193]
loss: 0.068583  [25600/71193]
loss: 0.165651  [32000/71193]
loss: 0.099479  [38400/71193]
loss: 0.157576  [44800/71193]
loss: 0.084879  [51200/71193]
loss: 0.140143  [57600/71193]
loss: 0.119504  [64000/71193]
loss: 0.125141  [70400/71193]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139429 

Epoch 23
-------------------------------
loss: 0.172575  [    0/71193]
loss: 0.118238  [ 6400/71193]
loss: 0.106720  [12800/71193]
loss: 0.077333  [19200/71193]
loss: 0.062790  [25600/71193]
loss: 0.109687  [32000/71193]
loss: 0.089732  [38400/71193]
loss: 0.067159  [44800/71193]
loss: 0.149599  [51200/71193]
loss: 0.106529  [57600/71193]
loss: 0.108390  [64000/71193]
loss: 0.139156  [70400/71193]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.128830 

Epoch 24
-------------------------------
loss: 0.049379  [    0/71193]
loss: 0.059698  [ 6400/71193]
loss: 0.118455  [12800/71193]
loss: 0.063164  [19200/71193]
loss: 0.135553  [25600/71193]
loss: 0.166065  [32000/71193]
loss: 0.124562  [38400/71193]
loss: 0.072186  [44800/71193]
loss: 0.117696  [51200/71193]
loss: 0.027642  [57600/71193]
loss: 0.221008  [64000/71193]
loss: 0.148401  [70400/71193]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.129483 

Epoch 25
-------------------------------
loss: 0.199006  [    0/71193]
loss: 0.105246  [ 6400/71193]
loss: 0.066571  [12800/71193]
loss: 0.103273  [19200/71193]
loss: 0.056091  [25600/71193]
loss: 0.036745  [32000/71193]
loss: 0.106689  [38400/71193]
loss: 0.080500  [44800/71193]
loss: 0.045252  [51200/71193]
loss: 0.090693  [57600/71193]
loss: 0.154502  [64000/71193]
loss: 0.204470  [70400/71193]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.139610 

Epoch 26
-------------------------------
loss: 0.123431  [    0/71193]
loss: 0.068158  [ 6400/71193]
loss: 0.079760  [12800/71193]
loss: 0.030162  [19200/71193]
loss: 0.130907  [25600/71193]
loss: 0.188125  [32000/71193]
loss: 0.088532  [38400/71193]
loss: 0.292481  [44800/71193]
loss: 0.091693  [51200/71193]
loss: 0.211267  [57600/71193]
loss: 0.124868  [64000/71193]
loss: 0.128953  [70400/71193]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.131684 

Epoch 27
-------------------------------
loss: 0.092556  [    0/71193]
loss: 0.156105  [ 6400/71193]
loss: 0.106262  [12800/71193]
loss: 0.132047  [19200/71193]
loss: 0.138432  [25600/71193]
loss: 0.180826  [32000/71193]
loss: 0.130600  [38400/71193]
loss: 0.099970  [44800/71193]
loss: 0.073790  [51200/71193]
loss: 0.077768  [57600/71193]
loss: 0.080260  [64000/71193]
loss: 0.087131  [70400/71193]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.130316 

Epoch 28
-------------------------------
loss: 0.211584  [    0/71193]
loss: 0.069593  [ 6400/71193]
loss: 0.203998  [12800/71193]
loss: 0.191182  [19200/71193]
loss: 0.182401  [25600/71193]
loss: 0.056929  [32000/71193]
loss: 0.130395  [38400/71193]
loss: 0.107380  [44800/71193]
loss: 0.149769  [51200/71193]
loss: 0.111095  [57600/71193]
loss: 0.087011  [64000/71193]
loss: 0.113834  [70400/71193]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.173419 

Epoch 29
-------------------------------
loss: 0.112423  [    0/71193]
loss: 0.069327  [ 6400/71193]
loss: 0.077592  [12800/71193]
loss: 0.256728  [19200/71193]
loss: 0.100900  [25600/71193]
loss: 0.090042  [32000/71193]
loss: 0.148052  [38400/71193]
loss: 0.261041  [44800/71193]
loss: 0.049683  [51200/71193]
loss: 0.188257  [57600/71193]
loss: 0.082499  [64000/71193]
loss: 0.066453  [70400/71193]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.144964 

Epoch 30
-------------------------------
loss: 0.096860  [    0/71193]
loss: 0.134286  [ 6400/71193]
loss: 0.056128  [12800/71193]
loss: 0.122766  [19200/71193]
loss: 0.170820  [25600/71193]
loss: 0.148907  [32000/71193]
loss: 0.137641  [38400/71193]
loss: 0.191214  [44800/71193]
loss: 0.149354  [51200/71193]
loss: 0.145912  [57600/71193]
loss: 0.075011  [64000/71193]
loss: 0.162197  [70400/71193]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.136374 

Epoch 31
-------------------------------
loss: 0.066921  [    0/71193]
loss: 0.076300  [ 6400/71193]
loss: 0.064489  [12800/71193]
loss: 0.120099  [19200/71193]
loss: 0.062160  [25600/71193]
loss: 0.191407  [32000/71193]
loss: 0.131873  [38400/71193]
loss: 0.134320  [44800/71193]
loss: 0.112754  [51200/71193]
loss: 0.188550  [57600/71193]
loss: 0.070608  [64000/71193]
loss: 0.107108  [70400/71193]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.132205 

Epoch 32
-------------------------------
loss: 0.111194  [    0/71193]
loss: 0.075621  [ 6400/71193]
loss: 0.111854  [12800/71193]
loss: 0.113330  [19200/71193]
loss: 0.090909  [25600/71193]
loss: 0.226233  [32000/71193]
loss: 0.186415  [38400/71193]
loss: 0.153754  [44800/71193]
loss: 0.191606  [51200/71193]
loss: 0.213506  [57600/71193]
loss: 0.062921  [64000/71193]
loss: 0.179255  [70400/71193]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.127041 

Epoch 33
-------------------------------
loss: 0.180805  [    0/71193]
loss: 0.071614  [ 6400/71193]
loss: 0.048008  [12800/71193]
loss: 0.125032  [19200/71193]
loss: 0.199724  [25600/71193]
loss: 0.104052  [32000/71193]
loss: 0.112928  [38400/71193]
loss: 0.132394  [44800/71193]
loss: 0.165608  [51200/71193]
loss: 0.082365  [57600/71193]
loss: 0.188120  [64000/71193]
loss: 0.046601  [70400/71193]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.134114 

Epoch 34
-------------------------------
loss: 0.086790  [    0/71193]
loss: 0.033086  [ 6400/71193]
loss: 0.143229  [12800/71193]
loss: 0.031344  [19200/71193]
loss: 0.079463  [25600/71193]
loss: 0.142963  [32000/71193]
loss: 0.077112  [38400/71193]
loss: 0.130991  [44800/71193]
loss: 0.075797  [51200/71193]
loss: 0.205075  [57600/71193]
loss: 0.078609  [64000/71193]
loss: 0.054974  [70400/71193]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.132549 

Epoch 35
-------------------------------
loss: 0.062980  [    0/71193]
loss: 0.098832  [ 6400/71193]
loss: 0.155078  [12800/71193]
loss: 0.159996  [19200/71193]
loss: 0.127407  [25600/71193]
loss: 0.076830  [32000/71193]
loss: 0.115836  [38400/71193]
loss: 0.112524  [44800/71193]
loss: 0.228319  [51200/71193]
loss: 0.043905  [57600/71193]
loss: 0.055576  [64000/71193]
loss: 0.136426  [70400/71193]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.140837 

Epoch 36
-------------------------------
loss: 0.097833  [    0/71193]
loss: 0.158328  [ 6400/71193]
loss: 0.086016  [12800/71193]
loss: 0.118089  [19200/71193]
loss: 0.130003  [25600/71193]
loss: 0.134201  [32000/71193]
loss: 0.083916  [38400/71193]
loss: 0.245486  [44800/71193]
loss: 0.082873  [51200/71193]
loss: 0.163792  [57600/71193]
loss: 0.129370  [64000/71193]
loss: 0.064330  [70400/71193]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.127502 

Epoch 37
-------------------------------
loss: 0.099894  [    0/71193]
loss: 0.115075  [ 6400/71193]
loss: 0.148831  [12800/71193]
loss: 0.145053  [19200/71193]
loss: 0.031588  [25600/71193]
loss: 0.059018  [32000/71193]
loss: 0.104366  [38400/71193]
loss: 0.100797  [44800/71193]
loss: 0.232140  [51200/71193]
loss: 0.084358  [57600/71193]
loss: 0.119570  [64000/71193]
loss: 0.195928  [70400/71193]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.150825 

Epoch 38
-------------------------------
loss: 0.132797  [    0/71193]
loss: 0.149813  [ 6400/71193]
loss: 0.141217  [12800/71193]
loss: 0.099108  [19200/71193]
loss: 0.194206  [25600/71193]
loss: 0.139826  [32000/71193]
loss: 0.046946  [38400/71193]
loss: 0.249541  [44800/71193]
loss: 0.179538  [51200/71193]
loss: 0.105750  [57600/71193]
loss: 0.094819  [64000/71193]
loss: 0.125766  [70400/71193]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.130779 

Epoch 39
-------------------------------
loss: 0.071133  [    0/71193]
loss: 0.101412  [ 6400/71193]
loss: 0.068441  [12800/71193]
loss: 0.071002  [19200/71193]
loss: 0.080861  [25600/71193]
loss: 0.089681  [32000/71193]
loss: 0.051195  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.127490 

Epoch 28
-------------------------------
loss: 0.108008  [    0/69183]
loss: 0.119045  [ 6400/69183]
loss: 0.062603  [12800/69183]
loss: 0.032680  [19200/69183]
loss: 0.112971  [25600/69183]
loss: 0.107928  [32000/69183]
loss: 0.045828  [38400/69183]
loss: 0.177510  [44800/69183]
loss: 0.118980  [51200/69183]
loss: 0.085906  [57600/69183]
loss: 0.195143  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.121097 

Epoch 29
-------------------------------
loss: 0.113316  [    0/69183]
loss: 0.136541  [ 6400/69183]
loss: 0.033700  [12800/69183]
loss: 0.043836  [19200/69183]
loss: 0.148647  [25600/69183]
loss: 0.091086  [32000/69183]
loss: 0.050838  [38400/69183]
loss: 0.151200  [44800/69183]
loss: 0.113478  [51200/69183]
loss: 0.129435  [57600/69183]
loss: 0.121470  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.121638 

Epoch 30
-------------------------------
loss: 0.217070  [    0/69183]
loss: 0.076245  [ 6400/69183]
loss: 0.201375  [12800/69183]
loss: 0.145186  [19200/69183]
loss: 0.077960  [25600/69183]
loss: 0.113394  [32000/69183]
loss: 0.101129  [38400/69183]
loss: 0.089488  [44800/69183]
loss: 0.091950  [51200/69183]
loss: 0.188717  [57600/69183]
loss: 0.106208  [64000/69183]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.122077 

Epoch 31
-------------------------------
loss: 0.121763  [    0/69183]
loss: 0.094275  [ 6400/69183]
loss: 0.070593  [12800/69183]
loss: 0.093550  [19200/69183]
loss: 0.088678  [25600/69183]
loss: 0.111116  [32000/69183]
loss: 0.172563  [38400/69183]
loss: 0.064762  [44800/69183]
loss: 0.080309  [51200/69183]
loss: 0.064402  [57600/69183]
loss: 0.057809  [64000/69183]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.124419 

Epoch 32
-------------------------------
loss: 0.024607  [    0/69183]
loss: 0.087590  [ 6400/69183]
loss: 0.141345  [12800/69183]
loss: 0.092928  [19200/69183]
loss: 0.109861  [25600/69183]
loss: 0.088723  [32000/69183]
loss: 0.031925  [38400/69183]
loss: 0.150725  [44800/69183]
loss: 0.113047  [51200/69183]
loss: 0.072775  [57600/69183]
loss: 0.080772  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.125445 

Epoch 33
-------------------------------
loss: 0.090258  [    0/69183]
loss: 0.071992  [ 6400/69183]
loss: 0.042507  [12800/69183]
loss: 0.195843  [19200/69183]
loss: 0.085084  [25600/69183]
loss: 0.087387  [32000/69183]
loss: 0.165533  [38400/69183]
loss: 0.090306  [44800/69183]
loss: 0.122852  [51200/69183]
loss: 0.093664  [57600/69183]
loss: 0.088910  [64000/69183]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.128200 

Epoch 34
-------------------------------
loss: 0.158465  [    0/69183]
loss: 0.043675  [ 6400/69183]
loss: 0.093250  [12800/69183]
loss: 0.167772  [19200/69183]
loss: 0.029577  [25600/69183]
loss: 0.022059  [32000/69183]
loss: 0.107289  [38400/69183]
loss: 0.158776  [44800/69183]
loss: 0.094107  [51200/69183]
loss: 0.180903  [57600/69183]
loss: 0.050562  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.134867 

Epoch 35
-------------------------------
loss: 0.101109  [    0/69183]
loss: 0.069946  [ 6400/69183]
loss: 0.074542  [12800/69183]
loss: 0.068912  [19200/69183]
loss: 0.135134  [25600/69183]
loss: 0.102372  [32000/69183]
loss: 0.121670  [38400/69183]
loss: 0.096687  [44800/69183]
loss: 0.101095  [51200/69183]
loss: 0.090493  [57600/69183]
loss: 0.102702  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.124666 

Epoch 36
-------------------------------
loss: 0.076941  [    0/69183]
loss: 0.104243  [ 6400/69183]
loss: 0.068836  [12800/69183]
loss: 0.078046  [19200/69183]
loss: 0.154824  [25600/69183]
loss: 0.112676  [32000/69183]
loss: 0.138967  [38400/69183]
loss: 0.105230  [44800/69183]
loss: 0.084103  [51200/69183]
loss: 0.061796  [57600/69183]
loss: 0.264459  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.128818 

Epoch 37
-------------------------------
loss: 0.066618  [    0/69183]
loss: 0.051259  [ 6400/69183]
loss: 0.135134  [12800/69183]
loss: 0.123236  [19200/69183]
loss: 0.112099  [25600/69183]
loss: 0.177862  [32000/69183]
loss: 0.075601  [38400/69183]
loss: 0.131892  [44800/69183]
loss: 0.169068  [51200/69183]
loss: 0.026618  [57600/69183]
loss: 0.125115  [64000/69183]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.124821 

Epoch 38
-------------------------------
loss: 0.072978  [    0/69183]
loss: 0.178067  [ 6400/69183]
loss: 0.046802  [12800/69183]
loss: 0.088383  [19200/69183]
loss: 0.036788  [25600/69183]
loss: 0.134997  [32000/69183]
loss: 0.179873  [38400/69183]
loss: 0.168271  [44800/69183]
loss: 0.262877  [51200/69183]
loss: 0.072033  [57600/69183]
loss: 0.186584  [64000/69183]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.127150 

Epoch 39
-------------------------------
loss: 0.097618  [    0/69183]
loss: 0.155573  [ 6400/69183]
loss: 0.155367  [12800/69183]
loss: 0.056299  [19200/69183]
loss: 0.106186  [25600/69183]
loss: 0.218197  [32000/69183]
loss: 0.081818  [38400/69183]
loss: 0.063872  [44800/69183]
loss: 0.098565  [51200/69183]
loss: 0.149512  [57600/69183]
loss: 0.117288  [64000/69183]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.125955 

Epoch 40
-------------------------------
loss: 0.072552  [    0/69183]
loss: 0.165650  [ 6400/69183]
loss: 0.058359  [12800/69183]
loss: 0.076564  [19200/69183]
loss: 0.159319  [25600/69183]
loss: 0.097934  [32000/69183]
loss: 0.117654  [38400/69183]
loss: 0.053523  [44800/69183]
loss: 0.084087  [51200/69183]
loss: 0.058001  [57600/69183]
loss: 0.154003  [64000/69183]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.132060 

Epoch 41
-------------------------------
loss: 0.205105  [    0/69183]
loss: 0.078487  [ 6400/69183]
loss: 0.046545  [12800/69183]
loss: 0.115099  [19200/69183]
loss: 0.181792  [25600/69183]
loss: 0.149170  [32000/69183]
loss: 0.106174  [38400/69183]
loss: 0.098482  [44800/69183]
loss: 0.126839  [51200/69183]
loss: 0.169536  [57600/69183]
loss: 0.213083  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.129954 

Epoch 42
-------------------------------
loss: 0.036184  [    0/69183]
loss: 0.157597  [ 6400/69183]
loss: 0.068467  [12800/69183]
loss: 0.045020  [19200/69183]
loss: 0.159217  [25600/69183]
loss: 0.085953  [32000/69183]
loss: 0.056912  [38400/69183]
loss: 0.228393  [44800/69183]
loss: 0.176171  [51200/69183]
loss: 0.055696  [57600/69183]
loss: 0.134976  [64000/69183]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.122236 

Epoch 43
-------------------------------
loss: 0.086863  [    0/69183]
loss: 0.152034  [ 6400/69183]
loss: 0.074451  [12800/69183]
loss: 0.110874  [19200/69183]
loss: 0.062030  [25600/69183]
loss: 0.104656  [32000/69183]
loss: 0.111815  [38400/69183]
loss: 0.120029  [44800/69183]
loss: 0.089658  [51200/69183]
loss: 0.164229  [57600/69183]
loss: 0.087606  [64000/69183]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.121045 

Epoch 44
-------------------------------
loss: 0.112041  [    0/69183]
loss: 0.052575  [ 6400/69183]
loss: 0.075160  [12800/69183]
loss: 0.119569  [19200/69183]
loss: 0.075245  [25600/69183]
loss: 0.048204  [32000/69183]
loss: 0.124226  [38400/69183]
loss: 0.043672  [44800/69183]
loss: 0.093091  [51200/69183]
loss: 0.137539  [57600/69183]
loss: 0.137141  [64000/69183]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.124785 

Epoch 45
-------------------------------
loss: 0.200197  [    0/69183]
loss: 0.162661  [ 6400/69183]
loss: 0.077557  [12800/69183]
loss: 0.190042  [19200/69183]
loss: 0.049242  [25600/69183]
loss: 0.094550  [32000/69183]
loss: 0.065447  [38400/69183]
loss: 0.051562  [44800/69183]
loss: 0.133496  [51200/69183]
loss: 0.150824  [57600/69183]
loss: 0.142181  [64000/69183]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.122422 

Epoch 46
-------------------------------
loss: 0.069733  [    0/69183]
loss: 0.102126  [ 6400/69183]
loss: 0.048222  [12800/69183]
loss: 0.102929  [19200/69183]
loss: 0.156224  [25600/69183]
loss: 0.144294  [32000/69183]
loss: 0.112100  [38400/69183]
loss: 0.019126  [44800/69183]
loss: 0.089612  [51200/69183]
loss: 0.078322  [57600/69183]
loss: 0.215159  [64000/69183]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.122728 

Epoch 47
-------------------------------
loss: 0.083348  [    0/69183]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:25:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.104675  [38400/71148]
loss: 0.052984  [44800/71148]
loss: 0.132195  [51200/71148]
loss: 0.083792  [57600/71148]
loss: 0.082662  [64000/71148]
loss: 0.176428  [70400/71148]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.136349 

Epoch 22
-------------------------------
loss: 0.146792  [    0/71148]
loss: 0.064436  [ 6400/71148]
loss: 0.073471  [12800/71148]
loss: 0.197246  [19200/71148]
loss: 0.107266  [25600/71148]
loss: 0.087944  [32000/71148]
loss: 0.084393  [38400/71148]
loss: 0.215243  [44800/71148]
loss: 0.245619  [51200/71148]
loss: 0.141684  [57600/71148]
loss: 0.176644  [64000/71148]
loss: 0.118670  [70400/71148]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.151850 

Epoch 23
-------------------------------
loss: 0.059456  [    0/71148]
loss: 0.145100  [ 6400/71148]
loss: 0.151219  [12800/71148]
loss: 0.014366  [19200/71148]
loss: 0.038667  [25600/71148]
loss: 0.053703  [32000/71148]
loss: 0.145724  [38400/71148]
loss: 0.173078  [44800/71148]
loss: 0.172449  [51200/71148]
loss: 0.206544  [57600/71148]
loss: 0.099366  [64000/71148]
loss: 0.139379  [70400/71148]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.142341 

Epoch 24
-------------------------------
loss: 0.040198  [    0/71148]
loss: 0.161080  [ 6400/71148]
loss: 0.130789  [12800/71148]
loss: 0.090179  [19200/71148]
loss: 0.109475  [25600/71148]
loss: 0.062386  [32000/71148]
loss: 0.104652  [38400/71148]
loss: 0.114269  [44800/71148]
loss: 0.119213  [51200/71148]
loss: 0.125555  [57600/71148]
loss: 0.117400  [64000/71148]
loss: 0.176305  [70400/71148]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.145298 

Epoch 25
-------------------------------
loss: 0.095204  [    0/71148]
loss: 0.119682  [ 6400/71148]
loss: 0.140467  [12800/71148]
loss: 0.079636  [19200/71148]
loss: 0.131655  [25600/71148]
loss: 0.125224  [32000/71148]
loss: 0.103861  [38400/71148]
loss: 0.117475  [44800/71148]
loss: 0.065377  [51200/71148]
loss: 0.195584  [57600/71148]
loss: 0.101284  [64000/71148]
loss: 0.148403  [70400/71148]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.137298 

Epoch 26
-------------------------------
loss: 0.076509  [    0/71148]
loss: 1.667569  [ 6400/71148]
loss: 0.075946  [12800/71148]
loss: 0.040005  [19200/71148]
loss: 0.181147  [25600/71148]
loss: 0.151888  [32000/71148]
loss: 0.091484  [38400/71148]
loss: 0.081938  [44800/71148]
loss: 0.272992  [51200/71148]
loss: 0.061357  [57600/71148]
loss: 0.107486  [64000/71148]
loss: 0.176699  [70400/71148]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.143425 

Epoch 27
-------------------------------
loss: 0.100002  [    0/71148]
loss: 0.088504  [ 6400/71148]
loss: 0.079904  [12800/71148]
loss: 0.079100  [19200/71148]
loss: 0.023021  [25600/71148]
loss: 0.065551  [32000/71148]
loss: 0.082692  [38400/71148]
loss: 0.155874  [44800/71148]
loss: 0.190053  [51200/71148]
loss: 0.079168  [57600/71148]
loss: 0.204425  [64000/71148]
loss: 0.154722  [70400/71148]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.146902 

Epoch 28
-------------------------------
loss: 0.097760  [    0/71148]
loss: 0.063091  [ 6400/71148]
loss: 0.102316  [12800/71148]
loss: 0.091227  [19200/71148]
loss: 0.205458  [25600/71148]
loss: 0.136302  [32000/71148]
loss: 0.132857  [38400/71148]
loss: 0.096534  [44800/71148]
loss: 0.073528  [51200/71148]
loss: 0.166739  [57600/71148]
loss: 0.135858  [64000/71148]
loss: 0.100816  [70400/71148]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.142672 

Epoch 29
-------------------------------
loss: 0.115640  [    0/71148]
loss: 0.075823  [ 6400/71148]
loss: 0.097715  [12800/71148]
loss: 0.208374  [19200/71148]
loss: 0.142384  [25600/71148]
loss: 0.146668  [32000/71148]
loss: 0.065005  [38400/71148]
loss: 0.129171  [44800/71148]
loss: 0.144011  [51200/71148]
loss: 0.102739  [57600/71148]
loss: 0.110552  [64000/71148]
loss: 0.135781  [70400/71148]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.140579 

Epoch 30
-------------------------------
loss: 0.095270  [    0/71148]
loss: 0.089030  [ 6400/71148]
loss: 0.093015  [12800/71148]
loss: 0.076185  [19200/71148]
loss: 0.193876  [25600/71148]
loss: 0.175226  [32000/71148]
loss: 0.101241  [38400/71148]
loss: 0.096945  [44800/71148]
loss: 0.115911  [51200/71148]
loss: 0.133896  [57600/71148]
loss: 1.702428  [64000/71148]
loss: 0.103350  [70400/71148]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.146455 

Epoch 31
-------------------------------
loss: 0.076349  [    0/71148]
loss: 0.053670  [ 6400/71148]
loss: 0.096671  [12800/71148]
loss: 0.134599  [19200/71148]
loss: 0.163861  [25600/71148]
loss: 0.128485  [32000/71148]
loss: 0.103078  [38400/71148]
loss: 0.237058  [44800/71148]
loss: 0.140314  [51200/71148]
loss: 0.131886  [57600/71148]
loss: 0.113755  [64000/71148]
loss: 0.073327  [70400/71148]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.143941 

Epoch 32
-------------------------------
loss: 0.152402  [    0/71148]
loss: 0.070687  [ 6400/71148]
loss: 0.122034  [12800/71148]
loss: 0.096013  [19200/71148]
loss: 0.242869  [25600/71148]
loss: 0.120131  [32000/71148]
loss: 0.074227  [38400/71148]
loss: 0.210747  [44800/71148]
loss: 0.073370  [51200/71148]
loss: 0.080122  [57600/71148]
loss: 0.097712  [64000/71148]
loss: 0.086557  [70400/71148]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150381 

Epoch 33
-------------------------------
loss: 0.135052  [    0/71148]
loss: 0.042546  [ 6400/71148]
loss: 0.086341  [12800/71148]
loss: 0.131922  [19200/71148]
loss: 0.039667  [25600/71148]
loss: 0.113721  [32000/71148]
loss: 0.139282  [38400/71148]
loss: 0.106418  [44800/71148]
loss: 0.082771  [51200/71148]
loss: 0.180142  [57600/71148]
loss: 0.216884  [64000/71148]
loss: 0.080801  [70400/71148]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.160326 

Epoch 34
-------------------------------
loss: 0.074504  [    0/71148]
loss: 0.085962  [ 6400/71148]
loss: 0.193515  [12800/71148]
loss: 0.096440  [19200/71148]
loss: 0.149707  [25600/71148]
loss: 0.057482  [32000/71148]
loss: 0.129122  [38400/71148]
loss: 0.097421  [44800/71148]
loss: 0.226244  [51200/71148]
loss: 0.139598  [57600/71148]
loss: 0.166935  [64000/71148]
loss: 0.132099  [70400/71148]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.141772 

Epoch 35
-------------------------------
loss: 0.069961  [    0/71148]
loss: 0.134212  [ 6400/71148]
loss: 0.095216  [12800/71148]
loss: 0.255855  [19200/71148]
loss: 0.108154  [25600/71148]
loss: 0.197620  [32000/71148]
loss: 0.070771  [38400/71148]
loss: 0.199285  [44800/71148]
loss: 0.033594  [51200/71148]
loss: 0.163478  [57600/71148]
loss: 0.120171  [64000/71148]
loss: 0.144007  [70400/71148]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.145086 

Epoch 36
-------------------------------
loss: 0.070686  [    0/71148]
loss: 0.118917  [ 6400/71148]
loss: 0.081709  [12800/71148]
loss: 0.257592  [19200/71148]
loss: 0.059518  [25600/71148]
loss: 0.143302  [32000/71148]
loss: 0.123470  [38400/71148]
loss: 0.086783  [44800/71148]
loss: 0.063176  [51200/71148]
loss: 0.218065  [57600/71148]
loss: 0.093628  [64000/71148]
loss: 0.189137  [70400/71148]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.143723 

Epoch 37
-------------------------------
loss: 0.065246  [    0/71148]
loss: 0.132432  [ 6400/71148]
loss: 0.127081  [12800/71148]
loss: 0.168656  [19200/71148]
loss: 0.115671  [25600/71148]
loss: 0.156644  [32000/71148]
loss: 0.076466  [38400/71148]
loss: 0.086353  [44800/71148]
loss: 0.134176  [51200/71148]
loss: 0.122378  [57600/71148]
loss: 0.158730  [64000/71148]
loss: 0.147901  [70400/71148]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.148844 

Epoch 38
-------------------------------
loss: 0.198831  [    0/71148]
loss: 0.184576  [ 6400/71148]
loss: 0.085114  [12800/71148]
loss: 0.162106  [19200/71148]
loss: 0.108752  [25600/71148]
loss: 0.149492  [32000/71148]
loss: 0.045648  [38400/71148]
loss: 0.089468  [44800/71148]
loss: 0.106476  [51200/71148]
loss: 0.067456  [57600/71148]
loss: 0.071083  [64000/71148]
loss: 0.076228  [70400/71148]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.150640 

Epoch 39
-------------------------------
loss: 0.212640  [    0/71148]
loss: 0.093956  [ 6400/71148]
loss: 0.115608  [12800/71148]
loss: 0.100812  [19200/71148]
loss: 0.102522  [25600/71148]
loss: 0.103149  [32000/71148]
loss: 0.180480  [38400/71148]
Epoch 18
-------------------------------
loss: 0.105317  [    0/71147]
loss: 0.102334  [ 6400/71147]
loss: 0.256266  [12800/71147]
loss: 0.149385  [19200/71147]
loss: 0.137178  [25600/71147]
loss: 0.083377  [32000/71147]
loss: 0.059784  [38400/71147]
loss: 0.122679  [44800/71147]
loss: 0.105689  [51200/71147]
loss: 0.098579  [57600/71147]
loss: 0.094934  [64000/71147]
loss: 0.178394  [70400/71147]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.162937 

Epoch 19
-------------------------------
loss: 0.168974  [    0/71147]
loss: 0.176433  [ 6400/71147]
loss: 0.135696  [12800/71147]
loss: 0.069033  [19200/71147]
loss: 0.160529  [25600/71147]
loss: 0.212644  [32000/71147]
loss: 0.148491  [38400/71147]
loss: 0.163512  [44800/71147]
loss: 0.187867  [51200/71147]
loss: 0.105525  [57600/71147]
loss: 0.089993  [64000/71147]
loss: 0.174993  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.166181 

Epoch 20
-------------------------------
loss: 0.143604  [    0/71147]
loss: 0.258478  [ 6400/71147]
loss: 0.183641  [12800/71147]
loss: 0.116333  [19200/71147]
loss: 0.113551  [25600/71147]
loss: 0.145131  [32000/71147]
loss: 0.139990  [38400/71147]
loss: 0.108161  [44800/71147]
loss: 0.150011  [51200/71147]
loss: 0.149585  [57600/71147]
loss: 0.161130  [64000/71147]
loss: 0.155180  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.168116 

Epoch 21
-------------------------------
loss: 0.149901  [    0/71147]
loss: 0.173719  [ 6400/71147]
loss: 0.144231  [12800/71147]
loss: 0.131861  [19200/71147]
loss: 0.130396  [25600/71147]
loss: 0.150607  [32000/71147]
loss: 0.145390  [38400/71147]
loss: 0.112314  [44800/71147]
loss: 0.102825  [51200/71147]
loss: 0.190235  [57600/71147]
loss: 0.208558  [64000/71147]
loss: 0.220545  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.162037 

Epoch 22
-------------------------------
loss: 0.097408  [    0/71147]
loss: 0.179248  [ 6400/71147]
loss: 0.182394  [12800/71147]
loss: 0.167217  [19200/71147]
loss: 0.105383  [25600/71147]
loss: 0.147938  [32000/71147]
loss: 0.101103  [38400/71147]
loss: 0.132631  [44800/71147]
loss: 0.057693  [51200/71147]
loss: 0.138431  [57600/71147]
loss: 0.077072  [64000/71147]
loss: 0.157515  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.155160 

Epoch 23
-------------------------------
loss: 0.258424  [    0/71147]
loss: 0.164257  [ 6400/71147]
loss: 0.146298  [12800/71147]
loss: 0.083791  [19200/71147]
loss: 0.103160  [25600/71147]
loss: 0.129357  [32000/71147]
loss: 0.255270  [38400/71147]
loss: 0.105327  [44800/71147]
loss: 0.104238  [51200/71147]
loss: 0.127980  [57600/71147]
loss: 0.115525  [64000/71147]
loss: 0.158521  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.159687 

Epoch 24
-------------------------------
loss: 0.241795  [    0/71147]
loss: 0.244560  [ 6400/71147]
loss: 0.151035  [12800/71147]
loss: 0.197963  [19200/71147]
loss: 0.258878  [25600/71147]
loss: 0.099671  [32000/71147]
loss: 0.070465  [38400/71147]
loss: 0.108714  [44800/71147]
loss: 0.129182  [51200/71147]
loss: 0.123383  [57600/71147]
loss: 0.077975  [64000/71147]
loss: 0.168196  [70400/71147]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.149704 

Epoch 25
-------------------------------
loss: 0.081483  [    0/71147]
loss: 0.094167  [ 6400/71147]
loss: 0.028775  [12800/71147]
loss: 0.146202  [19200/71147]
loss: 0.111996  [25600/71147]
loss: 0.208242  [32000/71147]
loss: 0.155338  [38400/71147]
loss: 0.123693  [44800/71147]
loss: 0.096979  [51200/71147]
loss: 0.134439  [57600/71147]
loss: 0.144492  [64000/71147]
loss: 0.108404  [70400/71147]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.152757 

Epoch 26
-------------------------------
loss: 0.100405  [    0/71147]
loss: 0.090611  [ 6400/71147]
loss: 0.093565  [12800/71147]
loss: 0.147473  [19200/71147]
loss: 0.183574  [25600/71147]
loss: 0.087596  [32000/71147]
loss: 0.377871  [38400/71147]
loss: 0.085337  [44800/71147]
loss: 0.131742  [51200/71147]
loss: 0.124731  [57600/71147]
loss: 0.113854  [64000/71147]
loss: 0.160092  [70400/71147]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.148751 

Epoch 27
-------------------------------
loss: 0.114705  [    0/71147]
loss: 0.183162  [ 6400/71147]
loss: 0.186687  [12800/71147]
loss: 0.124928  [19200/71147]
loss: 0.161094  [25600/71147]
loss: 0.112632  [32000/71147]
loss: 0.137744  [38400/71147]
loss: 0.107218  [44800/71147]
loss: 0.057054  [51200/71147]
loss: 0.058905  [57600/71147]
loss: 0.264311  [64000/71147]
loss: 0.071479  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.150736 

Epoch 28
-------------------------------
loss: 0.098784  [    0/71147]
loss: 0.117365  [ 6400/71147]
loss: 0.107573  [12800/71147]
loss: 0.147337  [19200/71147]
loss: 0.129080  [25600/71147]
loss: 0.089828  [32000/71147]
loss: 0.138530  [38400/71147]
loss: 0.072644  [44800/71147]
loss: 0.064213  [51200/71147]
loss: 0.096280  [57600/71147]
loss: 0.177793  [64000/71147]
loss: 0.185280  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.158636 

Epoch 29
-------------------------------
loss: 0.081473  [    0/71147]
loss: 0.109811  [ 6400/71147]
loss: 0.176275  [12800/71147]
loss: 0.115156  [19200/71147]
loss: 0.046779  [25600/71147]
loss: 0.117881  [32000/71147]
loss: 0.082039  [38400/71147]
loss: 0.116652  [44800/71147]
loss: 0.106061  [51200/71147]
loss: 0.171249  [57600/71147]
loss: 0.123568  [64000/71147]
loss: 0.116397  [70400/71147]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.159033 

Epoch 30
-------------------------------
loss: 0.141595  [    0/71147]
loss: 0.215773  [ 6400/71147]
loss: 0.158561  [12800/71147]
loss: 0.200564  [19200/71147]
loss: 0.131924  [25600/71147]
loss: 0.168482  [32000/71147]
loss: 0.133010  [38400/71147]
loss: 0.163214  [44800/71147]
loss: 0.113946  [51200/71147]
loss: 0.125876  [57600/71147]
loss: 0.278255  [64000/71147]
loss: 0.182639  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150100 

Epoch 31
-------------------------------
loss: 0.079223  [    0/71147]
loss: 0.076312  [ 6400/71147]
loss: 0.136509  [12800/71147]
loss: 0.163554  [19200/71147]
loss: 0.126864  [25600/71147]
loss: 0.113232  [32000/71147]
loss: 0.232641  [38400/71147]
loss: 0.171416  [44800/71147]
loss: 0.146918  [51200/71147]
loss: 0.138985  [57600/71147]
loss: 0.139264  [64000/71147]
loss: 0.115627  [70400/71147]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.152562 

Epoch 32
-------------------------------
loss: 0.091563  [    0/71147]
loss: 0.129011  [ 6400/71147]
loss: 0.085716  [12800/71147]
loss: 0.063080  [19200/71147]
loss: 0.175335  [25600/71147]
loss: 0.090888  [32000/71147]
loss: 0.124595  [38400/71147]
loss: 0.096016  [44800/71147]
loss: 0.084580  [51200/71147]
loss: 0.116341  [57600/71147]
loss: 0.123519  [64000/71147]
loss: 0.121959  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.150294 

Epoch 33
-------------------------------
loss: 0.112178  [    0/71147]
loss: 0.184874  [ 6400/71147]
loss: 0.162961  [12800/71147]
loss: 0.330071  [19200/71147]
loss: 0.085667  [25600/71147]
loss: 0.126402  [32000/71147]
loss: 0.099615  [38400/71147]
loss: 0.173268  [44800/71147]
loss: 0.159718  [51200/71147]
loss: 0.157867  [57600/71147]
loss: 0.128325  [64000/71147]
loss: 0.164193  [70400/71147]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.148533 

Epoch 34
-------------------------------
loss: 0.127687  [    0/71147]
loss: 0.143695  [ 6400/71147]
loss: 0.140510  [12800/71147]
loss: 0.110033  [19200/71147]
loss: 0.271243  [25600/71147]
loss: 0.161962  [32000/71147]
loss: 0.083572  [38400/71147]
loss: 0.140335  [44800/71147]
loss: 0.157771  [51200/71147]
loss: 0.058679  [57600/71147]
loss: 0.152863  [64000/71147]
loss: 0.173780  [70400/71147]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.159025 

Epoch 35
-------------------------------
loss: 0.098896  [    0/71147]
loss: 0.035565  [ 6400/71147]
loss: 0.052289  [12800/71147]
loss: 0.076985  [19200/71147]
loss: 0.138717  [25600/71147]
loss: 0.109719  [32000/71147]
loss: 0.111816  [38400/71147]
loss: 0.087101  [44800/71147]
loss: 0.226851  [51200/71147]
loss: 0.249848  [57600/71147]
loss: 0.118076  [64000/71147]
loss: 0.155656  [70400/71147]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.159076 

loss: 0.065802  [38400/70632]
loss: 0.072375  [44800/70632]
loss: 0.078509  [51200/70632]
loss: 0.083855  [57600/70632]
loss: 0.100403  [64000/70632]
loss: 0.039192  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.105196 

Epoch 30
-------------------------------
loss: 0.078002  [    0/70632]
loss: 0.072437  [ 6400/70632]
loss: 0.065948  [12800/70632]
loss: 0.055008  [19200/70632]
loss: 0.064606  [25600/70632]
loss: 0.067928  [32000/70632]
loss: 0.061925  [38400/70632]
loss: 0.168111  [44800/70632]
loss: 0.103610  [51200/70632]
loss: 0.111406  [57600/70632]
loss: 0.062339  [64000/70632]
loss: 0.083411  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102427 

Epoch 31
-------------------------------
loss: 0.071776  [    0/70632]
loss: 0.059798  [ 6400/70632]
loss: 0.155452  [12800/70632]
loss: 0.081405  [19200/70632]
loss: 0.026611  [25600/70632]
loss: 0.051295  [32000/70632]
loss: 0.093149  [38400/70632]
loss: 0.125785  [44800/70632]
loss: 0.070686  [51200/70632]
loss: 0.135403  [57600/70632]
loss: 0.085806  [64000/70632]
loss: 0.054055  [70400/70632]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.105266 

Epoch 32
-------------------------------
loss: 0.060059  [    0/70632]
loss: 0.158309  [ 6400/70632]
loss: 0.152061  [12800/70632]
loss: 0.163066  [19200/70632]
loss: 0.097078  [25600/70632]
loss: 0.120615  [32000/70632]
loss: 0.071854  [38400/70632]
loss: 0.040552  [44800/70632]
loss: 0.077190  [51200/70632]
loss: 0.112429  [57600/70632]
loss: 0.137072  [64000/70632]
loss: 0.084415  [70400/70632]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.110472 

Epoch 33
-------------------------------
loss: 0.058441  [    0/70632]
loss: 0.072779  [ 6400/70632]
loss: 0.024405  [12800/70632]
loss: 0.058372  [19200/70632]
loss: 0.091247  [25600/70632]
loss: 0.099106  [32000/70632]
loss: 0.115754  [38400/70632]
loss: 0.026046  [44800/70632]
loss: 0.178439  [51200/70632]
loss: 0.092852  [57600/70632]
loss: 0.044245  [64000/70632]
loss: 0.107610  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.103239 

Epoch 34
-------------------------------
loss: 0.115357  [    0/70632]
loss: 0.057025  [ 6400/70632]
loss: 0.194529  [12800/70632]
loss: 0.144457  [19200/70632]
loss: 0.065059  [25600/70632]
loss: 0.102195  [32000/70632]
loss: 0.062733  [38400/70632]
loss: 0.021673  [44800/70632]
loss: 0.117807  [51200/70632]
loss: 0.124418  [57600/70632]
loss: 0.064811  [64000/70632]
loss: 0.097173  [70400/70632]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.122365 

Epoch 35
-------------------------------
loss: 0.134014  [    0/70632]
loss: 0.162769  [ 6400/70632]
loss: 0.100095  [12800/70632]
loss: 0.071449  [19200/70632]
loss: 0.048602  [25600/70632]
loss: 0.053673  [32000/70632]
loss: 0.077445  [38400/70632]
loss: 0.169603  [44800/70632]
loss: 0.287466  [51200/70632]
loss: 0.096512  [57600/70632]
loss: 0.161843  [64000/70632]
loss: 0.094369  [70400/70632]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.115369 

Epoch 36
-------------------------------
loss: 0.092989  [    0/70632]
loss: 0.057644  [ 6400/70632]
loss: 0.071712  [12800/70632]
loss: 0.105158  [19200/70632]
loss: 0.034020  [25600/70632]
loss: 0.104559  [32000/70632]
loss: 0.050143  [38400/70632]
loss: 0.015879  [44800/70632]
loss: 0.153499  [51200/70632]
loss: 0.155089  [57600/70632]
loss: 0.139890  [64000/70632]
loss: 0.100496  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.107495 

Epoch 37
-------------------------------
loss: 0.105956  [    0/70632]
loss: 0.123537  [ 6400/70632]
loss: 0.044910  [12800/70632]
loss: 0.064637  [19200/70632]
loss: 0.090014  [25600/70632]
loss: 0.089932  [32000/70632]
loss: 0.024330  [38400/70632]
loss: 0.116677  [44800/70632]
loss: 0.127934  [51200/70632]
loss: 0.064248  [57600/70632]
loss: 0.066885  [64000/70632]
loss: 0.160292  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.105238 

Epoch 38
-------------------------------
loss: 0.097741  [    0/70632]
loss: 0.186143  [ 6400/70632]
loss: 0.045938  [12800/70632]
loss: 0.050029  [19200/70632]
loss: 0.085297  [25600/70632]
loss: 0.064176  [32000/70632]
loss: 0.051617  [38400/70632]
loss: 0.194224  [44800/70632]
loss: 0.077710  [51200/70632]
loss: 0.153477  [57600/70632]
loss: 0.152876  [64000/70632]
loss: 0.053168  [70400/70632]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.104572 

Epoch 39
-------------------------------
loss: 0.046641  [    0/70632]
loss: 0.140037  [ 6400/70632]
loss: 0.055577  [12800/70632]
loss: 0.049832  [19200/70632]
loss: 0.065825  [25600/70632]
loss: 0.069872  [32000/70632]
loss: 0.050784  [38400/70632]
loss: 0.036379  [44800/70632]
loss: 0.064733  [51200/70632]
loss: 0.194153  [57600/70632]
loss: 0.071631  [64000/70632]
loss: 0.238429  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.108929 

Epoch 40
-------------------------------
loss: 0.068412  [    0/70632]
loss: 0.067087  [ 6400/70632]
loss: 0.191027  [12800/70632]
loss: 0.162137  [19200/70632]
loss: 0.057446  [25600/70632]
loss: 0.098813  [32000/70632]
loss: 0.093511  [38400/70632]
loss: 0.073049  [44800/70632]
loss: 0.052108  [51200/70632]
loss: 0.192626  [57600/70632]
loss: 0.056323  [64000/70632]
loss: 0.044676  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112476 

Epoch 41
-------------------------------
loss: 0.135903  [    0/70632]
loss: 0.032156  [ 6400/70632]
loss: 0.116769  [12800/70632]
loss: 0.064163  [19200/70632]
loss: 0.076555  [25600/70632]
loss: 0.059136  [32000/70632]
loss: 0.121465  [38400/70632]
loss: 0.035480  [44800/70632]
loss: 0.100039  [51200/70632]
loss: 0.146547  [57600/70632]
loss: 0.096563  [64000/70632]
loss: 0.147758  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110040 

Epoch 42
-------------------------------
loss: 0.026613  [    0/70632]
loss: 0.062682  [ 6400/70632]
loss: 0.019479  [12800/70632]
loss: 0.090807  [19200/70632]
loss: 0.087803  [25600/70632]
loss: 0.155854  [32000/70632]
loss: 0.121542  [38400/70632]
loss: 0.114528  [44800/70632]
loss: 0.038222  [51200/70632]
loss: 0.065080  [57600/70632]
loss: 0.042406  [64000/70632]
loss: 0.156028  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.111372 

Epoch 43
-------------------------------
loss: 0.047790  [    0/70632]
loss: 0.089420  [ 6400/70632]
loss: 0.116702  [12800/70632]
loss: 0.109078  [19200/70632]
loss: 0.059958  [25600/70632]
loss: 0.015764  [32000/70632]
loss: 0.140194  [38400/70632]
loss: 0.217139  [44800/70632]
loss: 0.057849  [51200/70632]
loss: 0.091542  [57600/70632]
loss: 0.037959  [64000/70632]
loss: 0.105437  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112612 

Epoch 44
-------------------------------
loss: 0.016275  [    0/70632]
loss: 0.078910  [ 6400/70632]
loss: 0.069419  [12800/70632]
loss: 0.038879  [19200/70632]
loss: 0.098572  [25600/70632]
loss: 0.045608  [32000/70632]
loss: 0.037076  [38400/70632]
loss: 0.088602  [44800/70632]
loss: 0.135091  [51200/70632]
loss: 0.104570  [57600/70632]
loss: 0.112253  [64000/70632]
loss: 0.134613  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.109264 

Epoch 45
-------------------------------
loss: 0.103503  [    0/70632]
loss: 0.031938  [ 6400/70632]
loss: 0.055601  [12800/70632]
loss: 0.131239  [19200/70632]
loss: 0.138182  [25600/70632]
loss: 0.102431  [32000/70632]
loss: 0.058241  [38400/70632]
loss: 0.176905  [44800/70632]
loss: 0.075056  [51200/70632]
loss: 0.046380  [57600/70632]
loss: 0.058261  [64000/70632]
loss: 0.167870  [70400/70632]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.107270 

Epoch 46
-------------------------------
loss: 0.025604  [    0/70632]
loss: 0.065081  [ 6400/70632]
loss: 0.097940  [12800/70632]
loss: 0.091563  [19200/70632]
loss: 0.104849  [25600/70632]
loss: 0.067109  [32000/70632]
loss: 0.065231  [38400/70632]
loss: 0.163501  [44800/70632]
loss: 0.107990  [51200/70632]
loss: 0.069909  [57600/70632]
loss: 0.116686  [64000/70632]
loss: 0.059261  [70400/70632]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.108275 

Epoch 47
-------------------------------
loss: 0.119881  [    0/70632]
loss: 0.209563  [ 6400/70632]
loss: 0.080379  [12800/70632]
loss: 0.112015  [19200/70632]
loss: 0.077129  [25600/70632]
loss: 0.047194  [32000/70632]
loss: 0.060575  [38400/70632]
loss: 0.048003  [64000/71143]
loss: 0.125617  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084967 

Epoch 33
-------------------------------
loss: 0.060308  [    0/71143]
loss: 0.072020  [ 6400/71143]
loss: 0.036276  [12800/71143]
loss: 0.077821  [19200/71143]
loss: 0.038065  [25600/71143]
loss: 0.081964  [32000/71143]
loss: 0.040583  [38400/71143]
loss: 0.042580  [44800/71143]
loss: 0.035198  [51200/71143]
loss: 0.107657  [57600/71143]
loss: 0.115649  [64000/71143]
loss: 0.042500  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.083855 

Epoch 34
-------------------------------
loss: 0.184824  [    0/71143]
loss: 0.096848  [ 6400/71143]
loss: 0.093038  [12800/71143]
loss: 0.087639  [19200/71143]
loss: 0.071835  [25600/71143]
loss: 0.095751  [32000/71143]
loss: 0.079503  [38400/71143]
loss: 0.096846  [44800/71143]
loss: 0.105377  [51200/71143]
loss: 0.075985  [57600/71143]
loss: 0.063984  [64000/71143]
loss: 0.071828  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084211 

Epoch 35
-------------------------------
loss: 0.045355  [    0/71143]
loss: 0.035917  [ 6400/71143]
loss: 0.035861  [12800/71143]
loss: 0.034465  [19200/71143]
loss: 0.072415  [25600/71143]
loss: 0.145095  [32000/71143]
loss: 0.038230  [38400/71143]
loss: 0.034504  [44800/71143]
loss: 0.031916  [51200/71143]
loss: 0.037926  [57600/71143]
loss: 0.085692  [64000/71143]
loss: 0.082479  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.084937 

Epoch 36
-------------------------------
loss: 0.032959  [    0/71143]
loss: 0.015711  [ 6400/71143]
loss: 0.107538  [12800/71143]
loss: 0.038972  [19200/71143]
loss: 0.043924  [25600/71143]
loss: 0.068213  [32000/71143]
loss: 0.138812  [38400/71143]
loss: 0.082268  [44800/71143]
loss: 0.163100  [51200/71143]
loss: 0.129655  [57600/71143]
loss: 0.050398  [64000/71143]
loss: 0.056588  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.087096 

Epoch 37
-------------------------------
loss: 0.087229  [    0/71143]
loss: 0.068160  [ 6400/71143]
loss: 0.129688  [12800/71143]
loss: 0.063260  [19200/71143]
loss: 0.067234  [25600/71143]
loss: 0.078515  [32000/71143]
loss: 0.106651  [38400/71143]
loss: 0.060341  [44800/71143]
loss: 0.091610  [51200/71143]
loss: 0.132076  [57600/71143]
loss: 0.110257  [64000/71143]
loss: 0.138451  [70400/71143]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.085916 

Epoch 38
-------------------------------
loss: 0.025079  [    0/71143]
loss: 0.056011  [ 6400/71143]
loss: 0.071850  [12800/71143]
loss: 0.113637  [19200/71143]
loss: 0.009258  [25600/71143]
loss: 0.045018  [32000/71143]
loss: 0.086110  [38400/71143]
loss: 0.066564  [44800/71143]
loss: 0.066517  [51200/71143]
loss: 0.051167  [57600/71143]
loss: 0.026584  [64000/71143]
loss: 0.052179  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.088854 

Epoch 39
-------------------------------
loss: 0.054177  [    0/71143]
loss: 0.072427  [ 6400/71143]
loss: 0.030794  [12800/71143]
loss: 0.053924  [19200/71143]
loss: 0.027468  [25600/71143]
loss: 0.064152  [32000/71143]
loss: 0.109350  [38400/71143]
loss: 0.054649  [44800/71143]
loss: 0.092539  [51200/71143]
loss: 0.045975  [57600/71143]
loss: 0.063013  [64000/71143]
loss: 0.063179  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.083858 

Epoch 40
-------------------------------
loss: 0.071952  [    0/71143]
loss: 0.080385  [ 6400/71143]
loss: 0.051886  [12800/71143]
loss: 0.033773  [19200/71143]
loss: 0.112762  [25600/71143]
loss: 0.117360  [32000/71143]
loss: 0.082508  [38400/71143]
loss: 0.079416  [44800/71143]
loss: 0.071129  [51200/71143]
loss: 0.100985  [57600/71143]
loss: 0.091692  [64000/71143]
loss: 0.057563  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.082745 

Epoch 41
-------------------------------
loss: 0.083618  [    0/71143]
loss: 0.006080  [ 6400/71143]
loss: 0.063065  [12800/71143]
loss: 0.025141  [19200/71143]
loss: 0.079121  [25600/71143]
loss: 0.064880  [32000/71143]
loss: 0.119811  [38400/71143]
loss: 0.021795  [44800/71143]
loss: 0.100403  [51200/71143]
loss: 0.064035  [57600/71143]
loss: 0.071464  [64000/71143]
loss: 0.091163  [70400/71143]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089520 

Epoch 42
-------------------------------
loss: 0.068833  [    0/71143]
loss: 0.008788  [ 6400/71143]
loss: 0.066196  [12800/71143]
loss: 0.074913  [19200/71143]
loss: 0.224996  [25600/71143]
loss: 0.098831  [32000/71143]
loss: 0.100339  [38400/71143]
loss: 0.061629  [44800/71143]
loss: 0.063282  [51200/71143]
loss: 0.148471  [57600/71143]
loss: 0.054991  [64000/71143]
loss: 0.089441  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.091280 

Epoch 43
-------------------------------
loss: 0.081751  [    0/71143]
loss: 0.109497  [ 6400/71143]
loss: 0.139862  [12800/71143]
loss: 0.050965  [19200/71143]
loss: 0.068131  [25600/71143]
loss: 0.126016  [32000/71143]
loss: 0.069928  [38400/71143]
loss: 0.046543  [44800/71143]
loss: 0.203980  [51200/71143]
loss: 0.040230  [57600/71143]
loss: 0.036069  [64000/71143]
loss: 0.110168  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.085914 

Epoch 44
-------------------------------
loss: 0.037484  [    0/71143]
loss: 0.297671  [ 6400/71143]
loss: 0.009541  [12800/71143]
loss: 0.003278  [19200/71143]
loss: 0.059219  [25600/71143]
loss: 0.091328  [32000/71143]
loss: 0.127036  [38400/71143]
loss: 0.031746  [44800/71143]
loss: 0.226134  [51200/71143]
loss: 0.027320  [57600/71143]
loss: 0.080839  [64000/71143]
loss: 0.043903  [70400/71143]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.083695 

Epoch 45
-------------------------------
loss: 0.131854  [    0/71143]
loss: 0.108417  [ 6400/71143]
loss: 0.143961  [12800/71143]
loss: 0.032147  [19200/71143]
loss: 0.107652  [25600/71143]
loss: 0.101803  [32000/71143]
loss: 0.098233  [38400/71143]
loss: 0.129773  [44800/71143]
loss: 0.031198  [51200/71143]
loss: 0.017892  [57600/71143]
loss: 0.066000  [64000/71143]
loss: 0.017461  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.083198 

Epoch 46
-------------------------------
loss: 0.069633  [    0/71143]
loss: 0.023432  [ 6400/71143]
loss: 0.127466  [12800/71143]
loss: 0.073825  [19200/71143]
loss: 0.017493  [25600/71143]
loss: 0.115077  [32000/71143]
loss: 0.073488  [38400/71143]
loss: 0.085616  [44800/71143]
loss: 0.055839  [51200/71143]
loss: 0.073512  [57600/71143]
loss: 0.036033  [64000/71143]
loss: 0.069370  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086108 

Epoch 47
-------------------------------
loss: 0.101346  [    0/71143]
loss: 0.047070  [ 6400/71143]
loss: 0.145675  [12800/71143]
loss: 0.105355  [19200/71143]
loss: 0.078975  [25600/71143]
loss: 0.024217  [32000/71143]
loss: 0.064551  [38400/71143]
loss: 0.023443  [44800/71143]
loss: 0.038480  [51200/71143]
loss: 0.081371  [57600/71143]
loss: 0.113414  [64000/71143]
loss: 0.065986  [70400/71143]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.087133 

Epoch 48
-------------------------------
loss: 0.024072  [    0/71143]
loss: 0.012835  [ 6400/71143]
loss: 0.054869  [12800/71143]
loss: 0.053903  [19200/71143]
loss: 0.100702  [25600/71143]
loss: 0.042248  [32000/71143]
loss: 0.028562  [38400/71143]
loss: 0.038949  [44800/71143]
loss: 0.052431  [51200/71143]
loss: 0.027096  [57600/71143]
loss: 0.078885  [64000/71143]
loss: 0.065232  [70400/71143]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.085954 

Epoch 49
-------------------------------
loss: 0.073589  [    0/71143]
loss: 0.034007  [ 6400/71143]
loss: 0.042466  [12800/71143]
loss: 0.032226  [19200/71143]
loss: 0.008552  [25600/71143]
loss: 0.125853  [32000/71143]
loss: 0.048662  [38400/71143]
loss: 0.086244  [44800/71143]
loss: 0.133024  [51200/71143]
loss: 0.190840  [57600/71143]
loss: 0.030273  [64000/71143]
loss: 0.064300  [70400/71143]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.084659 

Epoch 50
-------------------------------
loss: 0.047896  [    0/71143]
loss: 0.148879  [ 6400/71143]
loss: 0.075082  [12800/71143]
loss: 0.063956  [19200/71143]
loss: 0.169843  [25600/71143]
loss: 0.066748  [32000/71143]
loss: 0.111055  [38400/71143]
loss: 0.035609  [44800/71143]
loss: 0.075816  [51200/71143]
loss: 0.059199  [57600/71143]
loss: 0.049837  [64000/71143]
loss: 0.104516  [64000/71103]
loss: 0.073816  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.091019 

Epoch 33
-------------------------------
loss: 0.021370  [    0/71103]
loss: 0.036813  [ 6400/71103]
loss: 0.279025  [12800/71103]
loss: 0.070047  [19200/71103]
loss: 0.025552  [25600/71103]
loss: 0.022937  [32000/71103]
loss: 0.069663  [38400/71103]
loss: 0.074734  [44800/71103]
loss: 0.048200  [51200/71103]
loss: 0.008412  [57600/71103]
loss: 0.138024  [64000/71103]
loss: 0.011821  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.088967 

Epoch 34
-------------------------------
loss: 0.026890  [    0/71103]
loss: 0.054256  [ 6400/71103]
loss: 0.057034  [12800/71103]
loss: 0.059485  [19200/71103]
loss: 0.182649  [25600/71103]
loss: 0.109173  [32000/71103]
loss: 0.075243  [38400/71103]
loss: 0.052756  [44800/71103]
loss: 0.063160  [51200/71103]
loss: 0.078984  [57600/71103]
loss: 0.079209  [64000/71103]
loss: 0.057238  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.087072 

Epoch 35
-------------------------------
loss: 0.015077  [    0/71103]
loss: 0.051178  [ 6400/71103]
loss: 0.050263  [12800/71103]
loss: 0.023523  [19200/71103]
loss: 0.070127  [25600/71103]
loss: 0.092330  [32000/71103]
loss: 0.056526  [38400/71103]
loss: 0.080273  [44800/71103]
loss: 0.089371  [51200/71103]
loss: 0.055099  [57600/71103]
loss: 0.098973  [64000/71103]
loss: 0.076437  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.086502 

Epoch 36
-------------------------------
loss: 0.030250  [    0/71103]
loss: 0.049710  [ 6400/71103]
loss: 0.096726  [12800/71103]
loss: 0.050599  [19200/71103]
loss: 0.034898  [25600/71103]
loss: 0.091142  [32000/71103]
loss: 0.066484  [38400/71103]
loss: 0.087789  [44800/71103]
loss: 0.079557  [51200/71103]
loss: 0.115605  [57600/71103]
loss: 0.121000  [64000/71103]
loss: 0.038397  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.086337 

Epoch 37
-------------------------------
loss: 0.043363  [    0/71103]
loss: 0.130650  [ 6400/71103]
loss: 0.058987  [12800/71103]
loss: 0.033178  [19200/71103]
loss: 0.011276  [25600/71103]
loss: 0.042315  [32000/71103]
loss: 0.029255  [38400/71103]
loss: 0.015492  [44800/71103]
loss: 0.049189  [51200/71103]
loss: 0.162054  [57600/71103]
loss: 0.063399  [64000/71103]
loss: 0.020531  [70400/71103]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.097064 

Epoch 38
-------------------------------
loss: 0.047573  [    0/71103]
loss: 0.032688  [ 6400/71103]
loss: 0.038634  [12800/71103]
loss: 0.048806  [19200/71103]
loss: 0.090109  [25600/71103]
loss: 0.081933  [32000/71103]
loss: 0.053080  [38400/71103]
loss: 0.022696  [44800/71103]
loss: 0.060949  [51200/71103]
loss: 0.045217  [57600/71103]
loss: 0.105335  [64000/71103]
loss: 0.062011  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090108 

Epoch 39
-------------------------------
loss: 0.010894  [    0/71103]
loss: 0.046323  [ 6400/71103]
loss: 0.027423  [12800/71103]
loss: 0.087081  [19200/71103]
loss: 0.056869  [25600/71103]
loss: 0.018224  [32000/71103]
loss: 0.148190  [38400/71103]
loss: 0.065447  [44800/71103]
loss: 0.027021  [51200/71103]
loss: 0.036883  [57600/71103]
loss: 0.049748  [64000/71103]
loss: 0.059347  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090119 

Epoch 40
-------------------------------
loss: 0.062946  [    0/71103]
loss: 0.047333  [ 6400/71103]
loss: 0.047829  [12800/71103]
loss: 0.058254  [19200/71103]
loss: 0.112549  [25600/71103]
loss: 0.049586  [32000/71103]
loss: 0.073220  [38400/71103]
loss: 0.036501  [44800/71103]
loss: 0.036528  [51200/71103]
loss: 0.017127  [57600/71103]
loss: 0.096390  [64000/71103]
loss: 0.064398  [70400/71103]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.088300 

Epoch 41
-------------------------------
loss: 0.005844  [    0/71103]
loss: 0.091979  [ 6400/71103]
loss: 0.032256  [12800/71103]
loss: 0.042506  [19200/71103]
loss: 0.053038  [25600/71103]
loss: 0.094881  [32000/71103]
loss: 0.064806  [38400/71103]
loss: 0.042882  [44800/71103]
loss: 0.040522  [51200/71103]
loss: 0.066311  [57600/71103]
loss: 0.094550  [64000/71103]
loss: 0.083311  [70400/71103]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.090138 

Epoch 42
-------------------------------
loss: 0.028646  [    0/71103]
loss: 0.084852  [ 6400/71103]
loss: 0.018443  [12800/71103]
loss: 0.060786  [19200/71103]
loss: 0.038765  [25600/71103]
loss: 0.030780  [32000/71103]
loss: 0.045882  [38400/71103]
loss: 0.112562  [44800/71103]
loss: 0.089378  [51200/71103]
loss: 0.025607  [57600/71103]
loss: 0.076580  [64000/71103]
loss: 0.073922  [70400/71103]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.094163 

Epoch 43
-------------------------------
loss: 0.044838  [    0/71103]
loss: 0.072641  [ 6400/71103]
loss: 0.045101  [12800/71103]
loss: 0.023930  [19200/71103]
loss: 0.025079  [25600/71103]
loss: 0.029669  [32000/71103]
loss: 0.067123  [38400/71103]
loss: 0.066554  [44800/71103]
loss: 0.058300  [51200/71103]
loss: 0.016545  [57600/71103]
loss: 0.019274  [64000/71103]
loss: 0.141466  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.089247 

Epoch 44
-------------------------------
loss: 0.042890  [    0/71103]
loss: 0.010701  [ 6400/71103]
loss: 0.008282  [12800/71103]
loss: 0.089583  [19200/71103]
loss: 0.027023  [25600/71103]
loss: 0.060650  [32000/71103]
loss: 0.008060  [38400/71103]
loss: 0.017400  [44800/71103]
loss: 0.020247  [51200/71103]
loss: 0.028614  [57600/71103]
loss: 0.034589  [64000/71103]
loss: 0.046880  [70400/71103]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.101275 

Epoch 45
-------------------------------
loss: 0.018977  [    0/71103]
loss: 0.039604  [ 6400/71103]
loss: 0.201928  [12800/71103]
loss: 0.053289  [19200/71103]
loss: 0.019124  [25600/71103]
loss: 0.137067  [32000/71103]
loss: 0.019700  [38400/71103]
loss: 0.163777  [44800/71103]
loss: 0.041278  [51200/71103]
loss: 0.152509  [57600/71103]
loss: 0.204570  [64000/71103]
loss: 0.058191  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.094654 

Epoch 46
-------------------------------
loss: 0.031241  [    0/71103]
loss: 0.075303  [ 6400/71103]
loss: 0.048193  [12800/71103]
loss: 0.040059  [19200/71103]
loss: 0.117081  [25600/71103]
loss: 0.025326  [32000/71103]
loss: 0.031940  [38400/71103]
loss: 0.040841  [44800/71103]
loss: 0.021649  [51200/71103]
loss: 0.317069  [57600/71103]
loss: 0.055548  [64000/71103]
loss: 0.020805  [70400/71103]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.093984 

Epoch 47
-------------------------------
loss: 0.128251  [    0/71103]
loss: 0.126659  [ 6400/71103]
loss: 0.076978  [12800/71103]
loss: 0.092311  [19200/71103]
loss: 0.041065  [25600/71103]
loss: 0.011293  [32000/71103]
loss: 0.028740  [38400/71103]
loss: 0.137308  [44800/71103]
loss: 0.048197  [51200/71103]
loss: 0.213497  [57600/71103]
loss: 0.018108  [64000/71103]
loss: 0.090990  [70400/71103]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.095083 

Epoch 48
-------------------------------
loss: 0.007093  [    0/71103]
loss: 0.093409  [ 6400/71103]
loss: 0.030653  [12800/71103]
loss: 0.011696  [19200/71103]
loss: 0.089881  [25600/71103]
loss: 0.022833  [32000/71103]
loss: 0.034276  [38400/71103]
loss: 0.190777  [44800/71103]
loss: 0.012183  [51200/71103]
loss: 0.023439  [57600/71103]
loss: 0.130024  [64000/71103]
loss: 0.194753  [70400/71103]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.091364 

Epoch 49
-------------------------------
loss: 0.022855  [    0/71103]
loss: 0.011309  [ 6400/71103]
loss: 0.037949  [12800/71103]
loss: 0.065892  [19200/71103]
loss: 0.032090  [25600/71103]
loss: 0.062750  [32000/71103]
loss: 0.046886  [38400/71103]
loss: 0.091888  [44800/71103]
loss: 0.068325  [51200/71103]
loss: 0.116058  [57600/71103]
loss: 0.046020  [64000/71103]
loss: 0.075192  [70400/71103]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.089831 

Epoch 50
-------------------------------
loss: 0.113145  [    0/71103]
loss: 0.038914  [ 6400/71103]
loss: 0.022952  [12800/71103]
loss: 0.013799  [19200/71103]
loss: 0.093708  [25600/71103]
loss: 0.098434  [32000/71103]
loss: 0.022674  [38400/71103]
loss: 0.064225  [44800/71103]
loss: 0.083825  [51200/71103]
loss: 0.020294  [57600/71103]
loss: 0.022967  [64000/71103]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:29:00 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.054579  [57600/70352]
loss: 0.061116  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.111797 

Epoch 39
-------------------------------
loss: 0.061975  [    0/70352]
loss: 0.125440  [ 6400/70352]
loss: 0.052783  [12800/70352]
loss: 0.044028  [19200/70352]
loss: 0.014915  [25600/70352]
loss: 0.076682  [32000/70352]
loss: 0.057256  [38400/70352]
loss: 0.060511  [44800/70352]
loss: 0.067053  [51200/70352]
loss: 0.131673  [57600/70352]
loss: 0.129981  [64000/70352]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.113213 

Epoch 40
-------------------------------
loss: 0.135622  [    0/70352]
loss: 0.013511  [ 6400/70352]
loss: 0.051479  [12800/70352]
loss: 0.082642  [19200/70352]
loss: 0.200785  [25600/70352]
loss: 0.060469  [32000/70352]
loss: 0.020814  [38400/70352]
loss: 0.055461  [44800/70352]
loss: 0.123443  [51200/70352]
loss: 0.043110  [57600/70352]
loss: 0.126226  [64000/70352]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.133729 

Epoch 41
-------------------------------
loss: 0.022355  [    0/70352]
loss: 0.025955  [ 6400/70352]
loss: 0.120274  [12800/70352]
loss: 0.070971  [19200/70352]
loss: 0.044268  [25600/70352]
loss: 0.214497  [32000/70352]
loss: 0.115222  [38400/70352]
loss: 0.085476  [44800/70352]
loss: 0.038478  [51200/70352]
loss: 0.081747  [57600/70352]
loss: 0.090723  [64000/70352]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.121267 

Epoch 42
-------------------------------
loss: 0.046267  [    0/70352]
loss: 0.048115  [ 6400/70352]
loss: 0.065872  [12800/70352]
loss: 0.180249  [19200/70352]
loss: 0.140560  [25600/70352]
loss: 0.092716  [32000/70352]
loss: 0.042606  [38400/70352]
loss: 0.048034  [44800/70352]
loss: 0.082558  [51200/70352]
loss: 0.060877  [57600/70352]
loss: 0.102456  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.120739 

Epoch 43
-------------------------------
loss: 0.022683  [    0/70352]
loss: 0.072421  [ 6400/70352]
loss: 0.069181  [12800/70352]
loss: 0.035915  [19200/70352]
loss: 0.075561  [25600/70352]
loss: 0.023348  [32000/70352]
loss: 0.035401  [38400/70352]
loss: 0.025337  [44800/70352]
loss: 0.126538  [51200/70352]
loss: 0.138933  [57600/70352]
loss: 0.092922  [64000/70352]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.117655 

Epoch 44
-------------------------------
loss: 0.134522  [    0/70352]
loss: 0.031729  [ 6400/70352]
loss: 0.049255  [12800/70352]
loss: 0.010605  [19200/70352]
loss: 0.069685  [25600/70352]
loss: 0.139122  [32000/70352]
loss: 0.105607  [38400/70352]
loss: 0.057467  [44800/70352]
loss: 0.116160  [51200/70352]
loss: 0.015868  [57600/70352]
loss: 0.187822  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.123683 

Epoch 45
-------------------------------
loss: 0.034145  [    0/70352]
loss: 0.031379  [ 6400/70352]
loss: 0.040633  [12800/70352]
loss: 0.121346  [19200/70352]
loss: 0.051867  [25600/70352]
loss: 0.224718  [32000/70352]
loss: 0.028353  [38400/70352]
loss: 0.052095  [44800/70352]
loss: 0.051515  [51200/70352]
loss: 0.094262  [57600/70352]
loss: 0.030470  [64000/70352]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.123545 

Epoch 46
-------------------------------
loss: 0.194016  [    0/70352]
loss: 0.057409  [ 6400/70352]
loss: 0.014809  [12800/70352]
loss: 0.035606  [19200/70352]
loss: 0.070644  [25600/70352]
loss: 0.077762  [32000/70352]
loss: 0.065382  [38400/70352]
loss: 0.106293  [44800/70352]
loss: 0.103697  [51200/70352]
loss: 0.064337  [57600/70352]
loss: 0.144495  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.118470 

Epoch 47
-------------------------------
loss: 0.037921  [    0/70352]
loss: 0.010241  [ 6400/70352]
loss: 0.053576  [12800/70352]
loss: 0.028684  [19200/70352]
loss: 0.013722  [25600/70352]
loss: 0.041986  [32000/70352]
loss: 0.030158  [38400/70352]
loss: 0.053566  [44800/70352]
loss: 0.158394  [51200/70352]
loss: 0.057116  [57600/70352]
loss: 0.024906  [64000/70352]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110200 

Epoch 48
-------------------------------
loss: 0.075900  [    0/70352]
loss: 0.076155  [ 6400/70352]
loss: 0.060443  [12800/70352]
loss: 0.021103  [19200/70352]
loss: 0.024810  [25600/70352]
loss: 0.052218  [32000/70352]
loss: 0.110728  [38400/70352]
loss: 0.009887  [44800/70352]
loss: 0.050878  [51200/70352]
loss: 0.079572  [57600/70352]
loss: 0.015672  [64000/70352]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.129410 

Epoch 49
-------------------------------
loss: 0.062160  [    0/70352]
loss: 0.028811  [ 6400/70352]
loss: 0.086256  [12800/70352]
loss: 0.065126  [19200/70352]
loss: 0.116783  [25600/70352]
loss: 0.074802  [32000/70352]
loss: 0.106965  [38400/70352]
loss: 0.045495  [44800/70352]
loss: 0.033905  [51200/70352]
loss: 0.087493  [57600/70352]
loss: 0.062183  [64000/70352]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.119639 

Epoch 50
-------------------------------
loss: 0.086572  [    0/70352]
loss: 0.185775  [ 6400/70352]
loss: 0.079054  [12800/70352]
loss: 0.095297  [19200/70352]
loss: 0.022273  [25600/70352]
loss: 0.031277  [32000/70352]
loss: 0.022949  [38400/70352]
loss: 0.056877  [44800/70352]
loss: 0.036387  [51200/70352]
loss: 0.072784  [57600/70352]
loss: 0.038200  [64000/70352]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112300 

Epoch 1
-------------------------------
loss: 0.701478  [    0/71801]
loss: 0.193547  [ 6400/71801]
loss: 0.130942  [12800/71801]
loss: 0.058555  [19200/71801]
loss: 0.073408  [25600/71801]
loss: 0.072125  [32000/71801]
loss: 0.058178  [38400/71801]
loss: 0.229570  [44800/71801]
loss: 0.160954  [51200/71801]
loss: 0.081547  [57600/71801]
loss: 0.052688  [64000/71801]
loss: 0.011737  [70400/71801]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.073961 

Epoch 2
-------------------------------
loss: 0.058199  [    0/71801]
loss: 0.031855  [ 6400/71801]
loss: 0.068106  [12800/71801]
loss: 0.054751  [19200/71801]
loss: 0.764435  [25600/71801]
loss: 0.067541  [32000/71801]
loss: 0.023683  [38400/71801]
loss: 0.019930  [44800/71801]
loss: 0.064077  [51200/71801]
loss: 0.020754  [57600/71801]
loss: 0.073631  [64000/71801]
loss: 0.071980  [70400/71801]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.067482 

Epoch 3
-------------------------------
loss: 0.061730  [    0/71801]
loss: 0.009017  [ 6400/71801]
loss: 0.047730  [12800/71801]
loss: 0.047937  [19200/71801]
loss: 0.093869  [25600/71801]
loss: 0.036570  [32000/71801]
loss: 0.033426  [38400/71801]
loss: 0.022639  [44800/71801]
loss: 0.042112  [51200/71801]
loss: 0.092094  [57600/71801]
loss: 0.034020  [64000/71801]
loss: 0.028522  [70400/71801]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.057540 

Epoch 4
-------------------------------
loss: 0.022778  [    0/71801]
loss: 0.046418  [ 6400/71801]
loss: 0.072157  [12800/71801]
loss: 0.065323  [19200/71801]
loss: 0.245927  [25600/71801]
loss: 0.076756  [32000/71801]
loss: 0.051472  [38400/71801]
loss: 0.106114  [44800/71801]
loss: 0.030893  [51200/71801]
loss: 0.085443  [57600/71801]
loss: 0.033069  [64000/71801]
loss: 0.028784  [70400/71801]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.058898 

Epoch 5
-------------------------------
loss: 0.033151  [    0/71801]
loss: 0.084339  [ 6400/71801]
loss: 0.083354  [12800/71801]
loss: 0.040820  [19200/71801]
loss: 0.067588  [25600/71801]
loss: 0.038243  [32000/71801]
loss: 0.077726  [38400/71801]
loss: 0.063570  [44800/71801]
loss: 0.012504  [51200/71801]
loss: 0.091999  [57600/71801]
loss: 0.036105  [64000/71801]
loss: 0.022097  [70400/71801]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.061663 

Epoch 6
-------------------------------
loss: 0.008945  [    0/71801]
loss: 0.019617  [ 6400/71801]
loss: 0.006495  [12800/71801]
loss: 0.090566  [19200/71801]
loss: 0.041371  [25600/71801]
loss: 0.050190  [32000/71801]
loss: 0.083272  [38400/71801]
loss: 0.049348  [44800/71801]
loss: 0.025628  [51200/71801]
loss: 0.010670  [57600/71801]
loss: 0.015233  [64000/71801]
loss: 0.038812  [70400/71801]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.058650 

Epoch 7
-------------------------------
loss: 0.037267  [    0/71801]
loss: 0.039371  [ 6400/71801]
loss: 0.011935  [12800/71801]
loss: 0.036440  [19200/71801]
loss: 0.070903  [25600/71801]
loss: 0.055789  [32000/71801]
loss: 0.112557  [38400/71801]
loss: 0.070974  [44800/71801]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:29:06 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:29:18 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:29:45 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Epoch 35
-------------------------------
loss: 0.067823  [    0/69860]
loss: 0.063081  [ 6400/69860]
loss: 0.065214  [12800/69860]
loss: 0.161378  [19200/69860]
loss: 0.116738  [25600/69860]
loss: 0.059526  [32000/69860]
loss: 0.066856  [38400/69860]
loss: 0.146182  [44800/69860]
loss: 0.089259  [51200/69860]
loss: 0.084738  [57600/69860]
loss: 0.096072  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097826 

Epoch 36
-------------------------------
loss: 0.126030  [    0/69860]
loss: 0.086640  [ 6400/69860]
loss: 0.112467  [12800/69860]
loss: 0.124746  [19200/69860]
loss: 0.083774  [25600/69860]
loss: 0.033299  [32000/69860]
loss: 0.097742  [38400/69860]
loss: 0.147556  [44800/69860]
loss: 0.087363  [51200/69860]
loss: 0.036992  [57600/69860]
loss: 0.150093  [64000/69860]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.116844 

Epoch 37
-------------------------------
loss: 0.043551  [    0/69860]
loss: 0.040982  [ 6400/69860]
loss: 0.091848  [12800/69860]
loss: 0.194948  [19200/69860]
loss: 0.054272  [25600/69860]
loss: 0.138309  [32000/69860]
loss: 0.257940  [38400/69860]
loss: 0.099866  [44800/69860]
loss: 0.033273  [51200/69860]
loss: 0.130411  [57600/69860]
loss: 0.091831  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099167 

Epoch 38
-------------------------------
loss: 0.073582  [    0/69860]
loss: 0.046346  [ 6400/69860]
loss: 0.052530  [12800/69860]
loss: 0.074990  [19200/69860]
loss: 0.141548  [25600/69860]
loss: 0.035906  [32000/69860]
loss: 0.117351  [38400/69860]
loss: 0.134518  [44800/69860]
loss: 0.091348  [51200/69860]
loss: 0.079065  [57600/69860]
loss: 0.132095  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097682 

Epoch 39
-------------------------------
loss: 0.045956  [    0/69860]
loss: 0.136062  [ 6400/69860]
loss: 0.154695  [12800/69860]
loss: 0.085215  [19200/69860]
loss: 0.073287  [25600/69860]
loss: 0.074265  [32000/69860]
loss: 0.067384  [38400/69860]
loss: 0.146863  [44800/69860]
loss: 0.148140  [51200/69860]
loss: 0.125140  [57600/69860]
loss: 0.119197  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.103641 

Epoch 40
-------------------------------
loss: 0.152605  [    0/69860]
loss: 0.156263  [ 6400/69860]
loss: 0.064940  [12800/69860]
loss: 0.096639  [19200/69860]
loss: 0.032049  [25600/69860]
loss: 0.090637  [32000/69860]
loss: 0.166328  [38400/69860]
loss: 0.016523  [44800/69860]
loss: 0.134896  [51200/69860]
loss: 0.109686  [57600/69860]
loss: 0.031399  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.098204 

Epoch 41
-------------------------------
loss: 0.134648  [    0/69860]
loss: 0.030102  [ 6400/69860]
loss: 0.054600  [12800/69860]
loss: 0.100839  [19200/69860]
loss: 0.142323  [25600/69860]
loss: 0.041687  [32000/69860]
loss: 0.055730  [38400/69860]
loss: 0.073626  [44800/69860]
loss: 0.068802  [51200/69860]
loss: 0.033818  [57600/69860]
loss: 0.078403  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.098414 

Epoch 42
-------------------------------
loss: 0.058357  [    0/69860]
loss: 0.204442  [ 6400/69860]
loss: 0.066585  [12800/69860]
loss: 0.056684  [19200/69860]
loss: 0.222154  [25600/69860]
loss: 0.155743  [32000/69860]
loss: 0.290354  [38400/69860]
loss: 0.022008  [44800/69860]
loss: 0.104977  [51200/69860]
loss: 0.132347  [57600/69860]
loss: 0.102614  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.104327 

Epoch 43
-------------------------------
loss: 0.071760  [    0/69860]
loss: 0.225996  [ 6400/69860]
loss: 0.057805  [12800/69860]
loss: 0.125375  [19200/69860]
loss: 0.108416  [25600/69860]
loss: 0.034017  [32000/69860]
loss: 0.087852  [38400/69860]
loss: 0.008980  [44800/69860]
loss: 0.084371  [51200/69860]
loss: 0.078889  [57600/69860]
loss: 0.055950  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102583 

Epoch 44
-------------------------------
loss: 0.131290  [    0/69860]
loss: 0.259866  [ 6400/69860]
loss: 0.187838  [12800/69860]
loss: 0.108181  [19200/69860]
loss: 0.072114  [25600/69860]
loss: 0.166272  [32000/69860]
loss: 0.051844  [38400/69860]
loss: 0.103374  [44800/69860]
loss: 0.062535  [51200/69860]
loss: 0.207076  [57600/69860]
loss: 0.114779  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.098508 

Epoch 45
-------------------------------
loss: 0.073578  [    0/69860]
loss: 0.099731  [ 6400/69860]
loss: 0.049335  [12800/69860]
loss: 0.055703  [19200/69860]
loss: 0.032058  [25600/69860]
loss: 0.083695  [32000/69860]
loss: 0.186194  [38400/69860]
loss: 0.037871  [44800/69860]
loss: 0.109205  [51200/69860]
loss: 0.130501  [57600/69860]
loss: 0.061042  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.101784 

Epoch 46
-------------------------------
loss: 0.107437  [    0/69860]
loss: 0.065112  [ 6400/69860]
loss: 0.066420  [12800/69860]
loss: 0.082756  [19200/69860]
loss: 0.070560  [25600/69860]
loss: 0.111604  [32000/69860]
loss: 0.058810  [38400/69860]
loss: 0.096436  [44800/69860]
loss: 0.077878  [51200/69860]
loss: 0.084310  [57600/69860]
loss: 0.163209  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.103408 

Epoch 47
-------------------------------
loss: 0.089599  [    0/69860]
loss: 0.137377  [ 6400/69860]
loss: 0.100135  [12800/69860]
loss: 0.037262  [19200/69860]
loss: 0.178527  [25600/69860]
loss: 0.089869  [32000/69860]
loss: 0.156892  [38400/69860]
loss: 0.153436  [44800/69860]
loss: 0.046157  [51200/69860]
loss: 0.063301  [57600/69860]
loss: 0.081649  [64000/69860]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.105056 

Epoch 48
-------------------------------
loss: 0.050065  [    0/69860]
loss: 0.029556  [ 6400/69860]
loss: 0.043620  [12800/69860]
loss: 0.102154  [19200/69860]
loss: 0.039936  [25600/69860]
loss: 0.015502  [32000/69860]
loss: 0.087538  [38400/69860]
loss: 0.087764  [44800/69860]
loss: 0.094340  [51200/69860]
loss: 0.119052  [57600/69860]
loss: 0.098310  [64000/69860]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.106555 

Epoch 49
-------------------------------
loss: 0.140865  [    0/69860]
loss: 0.120143  [ 6400/69860]
loss: 0.055982  [12800/69860]
loss: 0.021769  [19200/69860]
loss: 0.114439  [25600/69860]
loss: 0.203672  [32000/69860]
loss: 0.100930  [38400/69860]
loss: 0.063507  [44800/69860]
loss: 0.055821  [51200/69860]
loss: 0.127022  [57600/69860]
loss: 0.055710  [64000/69860]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.105224 

Epoch 50
-------------------------------
loss: 0.093368  [    0/69860]
loss: 0.090925  [ 6400/69860]
loss: 0.033585  [12800/69860]
loss: 0.072923  [19200/69860]
loss: 0.052722  [25600/69860]
loss: 0.059386  [32000/69860]
loss: 0.046225  [38400/69860]
loss: 0.146588  [44800/69860]
loss: 0.066938  [51200/69860]
loss: 0.062704  [57600/69860]
loss: 0.066939  [64000/69860]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.104721 

Epoch 1
-------------------------------
loss: 0.646439  [    0/71337]
loss: 0.297742  [ 6400/71337]
loss: 0.313461  [12800/71337]
loss: 0.232370  [19200/71337]
loss: 0.153904  [25600/71337]
loss: 0.139877  [32000/71337]
loss: 0.131178  [38400/71337]
loss: 0.153469  [44800/71337]
loss: 0.128854  [51200/71337]
loss: 0.149104  [57600/71337]
loss: 0.096905  [64000/71337]
loss: 0.126974  [70400/71337]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.127870 

Epoch 2
-------------------------------
loss: 0.059576  [    0/71337]
loss: 0.115022  [ 6400/71337]
loss: 0.138210  [12800/71337]
loss: 0.078001  [19200/71337]
loss: 0.179668  [25600/71337]
loss: 0.114053  [32000/71337]
loss: 0.036109  [38400/71337]
loss: 0.210357  [44800/71337]
loss: 0.231432  [51200/71337]
loss: 0.130676  [57600/71337]
loss: 0.078306  [64000/71337]
loss: 0.080686  [70400/71337]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.119175 

Epoch 3
-------------------------------
loss: 0.072599  [    0/71337]
loss: 0.144526  [ 6400/71337]
loss: 0.137609  [12800/71337]
loss: 0.125785  [19200/71337]
loss: 0.045224  [25600/71337]
loss: 0.039757  [32000/71337]
loss: 0.189524  [38400/71337]
loss: 0.188033  [44800/71337]
loss: 0.116770  [51200/71337]
loss: 0.118594  [57600/71337]
loss: 0.085634  [64000/71337]
loss: 0.111845  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.113105 

Epoch 4
-------------------------------
loss: 0.201692  [12800/69508]
loss: 0.312113  [19200/69508]
loss: 0.113291  [25600/69508]
loss: 0.232990  [32000/69508]
loss: 0.254947  [38400/69508]
loss: 0.148102  [44800/69508]
loss: 0.179080  [51200/69508]
loss: 0.190706  [57600/69508]
loss: 0.250331  [64000/69508]
Test Error: 
 Accuracy: 89.5%, Avg loss: 0.236422 

Epoch 20
-------------------------------
loss: 0.207960  [    0/69508]
loss: 0.118609  [ 6400/69508]
loss: 0.137464  [12800/69508]
loss: 0.172949  [19200/69508]
loss: 0.216003  [25600/69508]
loss: 0.141483  [32000/69508]
loss: 0.179101  [38400/69508]
loss: 0.192908  [44800/69508]
loss: 0.108672  [51200/69508]
loss: 0.222189  [57600/69508]
loss: 0.095168  [64000/69508]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.203664 

Epoch 21
-------------------------------
loss: 0.202203  [    0/69508]
loss: 0.149537  [ 6400/69508]
loss: 0.234197  [12800/69508]
loss: 0.139025  [19200/69508]
loss: 0.192394  [25600/69508]
loss: 0.147853  [32000/69508]
loss: 0.192917  [38400/69508]
loss: 0.186294  [44800/69508]
loss: 0.168005  [51200/69508]
loss: 0.140194  [57600/69508]
loss: 0.228818  [64000/69508]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.167411 

Epoch 22
-------------------------------
loss: 0.118138  [    0/69508]
loss: 0.174496  [ 6400/69508]
loss: 0.145026  [12800/69508]
loss: 0.170369  [19200/69508]
loss: 0.190303  [25600/69508]
loss: 0.204742  [32000/69508]
loss: 0.158277  [38400/69508]
loss: 0.183068  [44800/69508]
loss: 0.181938  [51200/69508]
loss: 0.076317  [57600/69508]
loss: 0.146659  [64000/69508]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.186317 

Epoch 23
-------------------------------
loss: 0.245595  [    0/69508]
loss: 0.217804  [ 6400/69508]
loss: 0.100880  [12800/69508]
loss: 0.230247  [19200/69508]
loss: 0.128823  [25600/69508]
loss: 0.173772  [32000/69508]
loss: 0.141493  [38400/69508]
loss: 0.243135  [44800/69508]
loss: 0.317851  [51200/69508]
loss: 0.138472  [57600/69508]
loss: 0.177494  [64000/69508]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.179795 

Epoch 24
-------------------------------
loss: 0.185761  [    0/69508]
loss: 0.140020  [ 6400/69508]
loss: 0.173350  [12800/69508]
loss: 0.209614  [19200/69508]
loss: 0.190719  [25600/69508]
loss: 0.226379  [32000/69508]
loss: 0.183773  [38400/69508]
loss: 0.202761  [44800/69508]
loss: 0.194084  [51200/69508]
loss: 0.146796  [57600/69508]
loss: 0.224160  [64000/69508]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.181335 

Epoch 25
-------------------------------
loss: 0.161729  [    0/69508]
loss: 0.120704  [ 6400/69508]
loss: 0.193643  [12800/69508]
loss: 0.221059  [19200/69508]
loss: 0.184263  [25600/69508]
loss: 0.226780  [32000/69508]
loss: 0.132166  [38400/69508]
loss: 0.216553  [44800/69508]
loss: 0.202052  [51200/69508]
loss: 0.188055  [57600/69508]
loss: 0.223247  [64000/69508]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.167578 

Epoch 26
-------------------------------
loss: 0.127833  [    0/69508]
loss: 0.136636  [ 6400/69508]
loss: 0.190375  [12800/69508]
loss: 0.131606  [19200/69508]
loss: 0.110121  [25600/69508]
loss: 0.328620  [32000/69508]
loss: 0.173363  [38400/69508]
loss: 0.205498  [44800/69508]
loss: 0.139996  [51200/69508]
loss: 0.207505  [57600/69508]
loss: 0.251979  [64000/69508]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.172624 

Epoch 27
-------------------------------
loss: 0.160593  [    0/69508]
loss: 0.219223  [ 6400/69508]
loss: 0.122776  [12800/69508]
loss: 0.195939  [19200/69508]
loss: 0.253898  [25600/69508]
loss: 0.110541  [32000/69508]
loss: 0.147860  [38400/69508]
loss: 0.109121  [44800/69508]
loss: 0.097594  [51200/69508]
loss: 0.209568  [57600/69508]
loss: 0.274417  [64000/69508]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.175756 

Epoch 28
-------------------------------
loss: 0.143264  [    0/69508]
loss: 0.110910  [ 6400/69508]
loss: 0.259166  [12800/69508]
loss: 0.334148  [19200/69508]
loss: 0.207124  [25600/69508]
loss: 0.185480  [32000/69508]
loss: 0.337346  [38400/69508]
loss: 0.208936  [44800/69508]
loss: 0.232476  [51200/69508]
loss: 0.170256  [57600/69508]
loss: 0.155712  [64000/69508]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.167206 

Epoch 29
-------------------------------
loss: 0.199884  [    0/69508]
loss: 0.200458  [ 6400/69508]
loss: 0.244944  [12800/69508]
loss: 0.100030  [19200/69508]
loss: 0.318975  [25600/69508]
loss: 0.314587  [32000/69508]
loss: 0.141866  [38400/69508]
loss: 0.254952  [44800/69508]
loss: 0.256051  [51200/69508]
loss: 0.163848  [57600/69508]
loss: 0.166054  [64000/69508]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.183845 

Epoch 30
-------------------------------
loss: 0.255755  [    0/69508]
loss: 0.235713  [ 6400/69508]
loss: 0.129830  [12800/69508]
loss: 0.254964  [19200/69508]
loss: 0.244404  [25600/69508]
loss: 0.102025  [32000/69508]
loss: 0.191618  [38400/69508]
loss: 0.150415  [44800/69508]
loss: 0.079234  [51200/69508]
loss: 0.185307  [57600/69508]
loss: 0.148292  [64000/69508]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.184247 

Epoch 31
-------------------------------
loss: 0.312206  [    0/69508]
loss: 0.303014  [ 6400/69508]
loss: 0.228939  [12800/69508]
loss: 0.217522  [19200/69508]
loss: 0.174705  [25600/69508]
loss: 0.125135  [32000/69508]
loss: 0.111613  [38400/69508]
loss: 0.242115  [44800/69508]
loss: 0.109164  [51200/69508]
loss: 0.255072  [57600/69508]
loss: 0.153200  [64000/69508]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.206690 

Epoch 32
-------------------------------
loss: 0.215936  [    0/69508]
loss: 0.143575  [ 6400/69508]
loss: 0.196324  [12800/69508]
loss: 0.063873  [19200/69508]
loss: 0.157407  [25600/69508]
loss: 0.182976  [32000/69508]
loss: 0.144583  [38400/69508]
loss: 0.188170  [44800/69508]
loss: 0.184574  [51200/69508]
loss: 0.196358  [57600/69508]
loss: 0.233184  [64000/69508]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.171707 

Epoch 33
-------------------------------
loss: 0.202599  [    0/69508]
loss: 0.121312  [ 6400/69508]
loss: 0.231546  [12800/69508]
loss: 0.149471  [19200/69508]
loss: 0.158772  [25600/69508]
loss: 0.168807  [32000/69508]
loss: 0.142220  [38400/69508]
loss: 0.252153  [44800/69508]
loss: 0.096350  [51200/69508]
loss: 0.159845  [57600/69508]
loss: 0.135522  [64000/69508]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.174302 

Epoch 34
-------------------------------
loss: 0.212954  [    0/69508]
loss: 0.132143  [ 6400/69508]
loss: 0.123343  [12800/69508]
loss: 0.045916  [19200/69508]
loss: 0.181047  [25600/69508]
loss: 0.138662  [32000/69508]
loss: 0.170789  [38400/69508]
loss: 0.310718  [44800/69508]
loss: 0.159632  [51200/69508]
loss: 0.143707  [57600/69508]
loss: 0.084482  [64000/69508]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.170853 

Epoch 35
-------------------------------
loss: 0.254933  [    0/69508]
loss: 0.221332  [ 6400/69508]
loss: 0.176110  [12800/69508]
loss: 0.249548  [19200/69508]
loss: 0.166688  [25600/69508]
loss: 0.118501  [32000/69508]
loss: 0.113385  [38400/69508]
loss: 0.122613  [44800/69508]
loss: 0.256750  [51200/69508]
loss: 0.105975  [57600/69508]
loss: 0.113912  [64000/69508]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.175959 

Epoch 36
-------------------------------
loss: 0.190003  [    0/69508]
loss: 0.169462  [ 6400/69508]
loss: 0.135905  [12800/69508]
loss: 0.284675  [19200/69508]
loss: 0.181510  [25600/69508]
loss: 0.140727  [32000/69508]
loss: 0.110608  [38400/69508]
loss: 0.210616  [44800/69508]
loss: 0.292464  [51200/69508]
loss: 0.158974  [57600/69508]
loss: 0.106818  [64000/69508]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.167427 

Epoch 37
-------------------------------
loss: 0.222915  [    0/69508]
loss: 0.146524  [ 6400/69508]
loss: 0.102199  [12800/69508]
loss: 0.148224  [19200/69508]
loss: 0.032252  [25600/69508]
loss: 0.205375  [32000/69508]
loss: 0.227891  [38400/69508]
loss: 0.112826  [44800/69508]
loss: 0.192272  [51200/69508]
loss: 0.101215  [57600/69508]
loss: 0.267338  [64000/69508]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.170832 

Epoch 38
-------------------------------
loss: 0.206039  [    0/69508]
loss: 0.150614  [ 6400/69508]
loss: 0.143526  [12800/69508]
loss: 0.199676  [19200/69508]
loss: 0.067028  [25600/69508]
loss: 0.212471  [32000/69508]
loss: 0.187230  [38400/69508]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:30:22 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:31:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:40:07 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.034821  [44800/72195]
loss: 0.016489  [51200/72195]
loss: 0.013198  [57600/72195]
loss: 0.012053  [64000/72195]
loss: 0.038175  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.075884 

Epoch 40
-------------------------------
loss: 0.015082  [    0/72195]
loss: 0.013849  [ 6400/72195]
loss: 0.015979  [12800/72195]
loss: 0.002517  [19200/72195]
loss: 0.030742  [25600/72195]
loss: 0.003387  [32000/72195]
loss: 0.000510  [38400/72195]
loss: 0.040254  [44800/72195]
loss: 0.031410  [51200/72195]
loss: 0.008531  [57600/72195]
loss: 0.044663  [64000/72195]
loss: 0.027474  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.077234 

Epoch 41
-------------------------------
loss: 0.128594  [    0/72195]
loss: 0.030308  [ 6400/72195]
loss: 0.040817  [12800/72195]
loss: 0.078701  [19200/72195]
loss: 0.004633  [25600/72195]
loss: 0.010726  [32000/72195]
loss: 0.017086  [38400/72195]
loss: 0.173215  [44800/72195]
loss: 0.012394  [51200/72195]
loss: 0.024703  [57600/72195]
loss: 0.032534  [64000/72195]
loss: 0.061195  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.081787 

Epoch 42
-------------------------------
loss: 0.030538  [    0/72195]
loss: 0.066132  [ 6400/72195]
loss: 0.060130  [12800/72195]
loss: 0.038358  [19200/72195]
loss: 0.216236  [25600/72195]
loss: 0.030273  [32000/72195]
loss: 0.035451  [38400/72195]
loss: 0.022673  [44800/72195]
loss: 0.063413  [51200/72195]
loss: 0.010970  [57600/72195]
loss: 0.039934  [64000/72195]
loss: 0.002465  [70400/72195]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.074353 

Epoch 43
-------------------------------
loss: 0.017763  [    0/72195]
loss: 0.020247  [ 6400/72195]
loss: 0.096146  [12800/72195]
loss: 0.018817  [19200/72195]
loss: 0.005306  [25600/72195]
loss: 0.027153  [32000/72195]
loss: 0.016930  [38400/72195]
loss: 0.034636  [44800/72195]
loss: 0.051723  [51200/72195]
loss: 0.002970  [57600/72195]
loss: 0.099832  [64000/72195]
loss: 0.103292  [70400/72195]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.099977 

Epoch 44
-------------------------------
loss: 0.149782  [    0/72195]
loss: 0.051007  [ 6400/72195]
loss: 0.043454  [12800/72195]
loss: 0.020726  [19200/72195]
loss: 0.015238  [25600/72195]
loss: 0.009768  [32000/72195]
loss: 0.001715  [38400/72195]
loss: 0.041680  [44800/72195]
loss: 0.017552  [51200/72195]
loss: 0.116949  [57600/72195]
loss: 0.038987  [64000/72195]
loss: 0.006489  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.074231 

Epoch 45
-------------------------------
loss: 0.029273  [    0/72195]
loss: 0.097833  [ 6400/72195]
loss: 0.019201  [12800/72195]
loss: 0.080281  [19200/72195]
loss: 0.015185  [25600/72195]
loss: 0.020869  [32000/72195]
loss: 0.005155  [38400/72195]
loss: 0.015314  [44800/72195]
loss: 0.064703  [51200/72195]
loss: 0.018444  [57600/72195]
loss: 0.021723  [64000/72195]
loss: 0.013824  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.082936 

Epoch 46
-------------------------------
loss: 0.045444  [    0/72195]
loss: 0.007763  [ 6400/72195]
loss: 0.010325  [12800/72195]
loss: 0.061636  [19200/72195]
loss: 0.094289  [25600/72195]
loss: 0.041549  [32000/72195]
loss: 0.034676  [38400/72195]
loss: 0.063554  [44800/72195]
loss: 0.150712  [51200/72195]
loss: 0.012982  [57600/72195]
loss: 0.021360  [64000/72195]
loss: 0.018018  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.083513 

Epoch 47
-------------------------------
loss: 1.570502  [    0/72195]
loss: 0.000111  [ 6400/72195]
loss: 0.022151  [12800/72195]
loss: 0.029080  [19200/72195]
loss: 0.155774  [25600/72195]
loss: 0.005349  [32000/72195]
loss: 0.040020  [38400/72195]
loss: 0.021056  [44800/72195]
loss: 0.007252  [51200/72195]
loss: 0.020715  [57600/72195]
loss: 0.015379  [64000/72195]
loss: 0.024252  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.074601 

Epoch 48
-------------------------------
loss: 0.029077  [    0/72195]
loss: 0.003978  [ 6400/72195]
loss: 0.040566  [12800/72195]
loss: 0.083843  [19200/72195]
loss: 0.003570  [25600/72195]
loss: 0.121783  [32000/72195]
loss: 0.012115  [38400/72195]
loss: 0.015461  [44800/72195]
loss: 0.063203  [51200/72195]
loss: 0.044116  [57600/72195]
loss: 0.012267  [64000/72195]
loss: 0.111721  [70400/72195]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.081874 

Epoch 49
-------------------------------
loss: 0.056850  [    0/72195]
loss: 0.053505  [ 6400/72195]
loss: 0.150247  [12800/72195]
loss: 0.004367  [19200/72195]
loss: 0.090724  [25600/72195]
loss: 0.071916  [32000/72195]
loss: 0.119073  [38400/72195]
loss: 0.002897  [44800/72195]
loss: 0.012571  [51200/72195]
loss: 0.000325  [57600/72195]
loss: 0.048278  [64000/72195]
loss: 0.032422  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.081210 

Epoch 50
-------------------------------
loss: 0.013406  [    0/72195]
loss: 0.023593  [ 6400/72195]
loss: 0.002426  [12800/72195]
loss: 0.006111  [19200/72195]
loss: 0.024081  [25600/72195]
loss: 0.119142  [32000/72195]
loss: 0.057859  [38400/72195]
loss: 0.083622  [44800/72195]
loss: 0.009569  [51200/72195]
loss: 0.031298  [57600/72195]
loss: 0.041026  [64000/72195]
loss: 0.017296  [70400/72195]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.076903 

Epoch 1
-------------------------------
loss: 0.671474  [    0/71250]
loss: 0.186728  [ 6400/71250]
loss: 0.111231  [12800/71250]
loss: 0.188850  [19200/71250]
loss: 0.299413  [25600/71250]
loss: 0.079180  [32000/71250]
loss: 0.169144  [38400/71250]
loss: 0.182022  [44800/71250]
loss: 0.147975  [51200/71250]
loss: 0.101814  [57600/71250]
loss: 0.084862  [64000/71250]
loss: 0.172912  [70400/71250]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.157368 

Epoch 2
-------------------------------
loss: 0.106554  [    0/71250]
loss: 0.194961  [ 6400/71250]
loss: 0.075421  [12800/71250]
loss: 0.077241  [19200/71250]
loss: 0.059758  [25600/71250]
loss: 0.108016  [32000/71250]
loss: 0.103838  [38400/71250]
loss: 0.120375  [44800/71250]
loss: 0.156159  [51200/71250]
loss: 0.218205  [57600/71250]
loss: 0.153030  [64000/71250]
loss: 0.079254  [70400/71250]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.127121 

Epoch 3
-------------------------------
loss: 0.095175  [    0/71250]
loss: 0.153148  [ 6400/71250]
loss: 0.226526  [12800/71250]
loss: 0.150635  [19200/71250]
loss: 0.143455  [25600/71250]
loss: 0.138188  [32000/71250]
loss: 0.116749  [38400/71250]
loss: 0.175884  [44800/71250]
loss: 0.180213  [51200/71250]
loss: 0.040363  [57600/71250]
loss: 1.615522  [64000/71250]
loss: 0.081999  [70400/71250]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.131961 

Epoch 4
-------------------------------
loss: 0.073316  [    0/71250]
loss: 0.057988  [ 6400/71250]
loss: 0.157143  [12800/71250]
loss: 0.088370  [19200/71250]
loss: 0.154375  [25600/71250]
loss: 0.136953  [32000/71250]
loss: 0.069083  [38400/71250]
loss: 0.068839  [44800/71250]
loss: 0.099973  [51200/71250]
loss: 0.096434  [57600/71250]
loss: 0.154449  [64000/71250]
loss: 0.151012  [70400/71250]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.118894 

Epoch 5
-------------------------------
loss: 0.215616  [    0/71250]
loss: 0.204185  [ 6400/71250]
loss: 0.256955  [12800/71250]
loss: 0.086197  [19200/71250]
loss: 0.033703  [25600/71250]
loss: 0.086054  [32000/71250]
loss: 0.113723  [38400/71250]
loss: 0.115582  [44800/71250]
loss: 0.178228  [51200/71250]
loss: 0.116974  [57600/71250]
loss: 0.205169  [64000/71250]
loss: 0.135072  [70400/71250]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099988 

Epoch 6
-------------------------------
loss: 0.151281  [    0/71250]
loss: 0.122310  [ 6400/71250]
loss: 0.115871  [12800/71250]
loss: 0.102458  [19200/71250]
loss: 0.081994  [25600/71250]
loss: 0.196603  [32000/71250]
loss: 0.131914  [38400/71250]
loss: 0.140454  [44800/71250]
loss: 0.093205  [51200/71250]
loss: 0.125206  [57600/71250]
loss: 0.175393  [64000/71250]
loss: 0.077607  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102712 

Epoch 7
-------------------------------
loss: 0.114345  [    0/71250]
loss: 0.170241  [ 6400/71250]
loss: 0.071628  [12800/71250]
loss: 0.091516  [19200/71250]
loss: 0.099270  [25600/71250]
loss: 0.075389  [32000/71250]
loss: 0.091213  [38400/71250]
loss: 0.116176  [44800/71250]
loss: 0.056347  [ 6400/70349]
loss: 0.058685  [12800/70349]
loss: 0.049282  [19200/70349]
loss: 0.098241  [25600/70349]
loss: 0.149723  [32000/70349]
loss: 0.067216  [38400/70349]
loss: 0.044887  [44800/70349]
loss: 0.169360  [51200/70349]
loss: 0.058069  [57600/70349]
loss: 0.059303  [64000/70349]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.120803 

Epoch 36
-------------------------------
loss: 0.055811  [    0/70349]
loss: 0.042788  [ 6400/70349]
loss: 0.053981  [12800/70349]
loss: 0.043055  [19200/70349]
loss: 0.066893  [25600/70349]
loss: 0.072592  [32000/70349]
loss: 0.044626  [38400/70349]
loss: 0.074976  [44800/70349]
loss: 0.049748  [51200/70349]
loss: 0.070144  [57600/70349]
loss: 0.036850  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112206 

Epoch 37
-------------------------------
loss: 0.063169  [    0/70349]
loss: 0.029354  [ 6400/70349]
loss: 0.058931  [12800/70349]
loss: 0.030029  [19200/70349]
loss: 0.112250  [25600/70349]
loss: 0.092638  [32000/70349]
loss: 0.027104  [38400/70349]
loss: 0.158220  [44800/70349]
loss: 0.090136  [51200/70349]
loss: 0.044089  [57600/70349]
loss: 0.235645  [64000/70349]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.123164 

Epoch 38
-------------------------------
loss: 0.144668  [    0/70349]
loss: 0.167012  [ 6400/70349]
loss: 0.103891  [12800/70349]
loss: 0.054479  [19200/70349]
loss: 0.099547  [25600/70349]
loss: 0.033435  [32000/70349]
loss: 0.069986  [38400/70349]
loss: 0.092218  [44800/70349]
loss: 0.044545  [51200/70349]
loss: 0.092534  [57600/70349]
loss: 0.176127  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.108964 

Epoch 39
-------------------------------
loss: 0.071443  [    0/70349]
loss: 0.146439  [ 6400/70349]
loss: 0.054838  [12800/70349]
loss: 0.191995  [19200/70349]
loss: 0.134713  [25600/70349]
loss: 0.081180  [32000/70349]
loss: 0.083479  [38400/70349]
loss: 0.060904  [44800/70349]
loss: 0.064756  [51200/70349]
loss: 0.076859  [57600/70349]
loss: 0.162095  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112173 

Epoch 40
-------------------------------
loss: 0.034995  [    0/70349]
loss: 0.046565  [ 6400/70349]
loss: 0.040112  [12800/70349]
loss: 0.062553  [19200/70349]
loss: 0.032918  [25600/70349]
loss: 0.028798  [32000/70349]
loss: 0.050824  [38400/70349]
loss: 0.033695  [44800/70349]
loss: 0.158869  [51200/70349]
loss: 0.195404  [57600/70349]
loss: 0.095558  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.106153 

Epoch 41
-------------------------------
loss: 0.104145  [    0/70349]
loss: 0.053589  [ 6400/70349]
loss: 0.010074  [12800/70349]
loss: 0.100543  [19200/70349]
loss: 0.136651  [25600/70349]
loss: 0.110286  [32000/70349]
loss: 0.106597  [38400/70349]
loss: 0.109814  [44800/70349]
loss: 0.082993  [51200/70349]
loss: 0.153592  [57600/70349]
loss: 0.114429  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.106202 

Epoch 42
-------------------------------
loss: 0.116841  [    0/70349]
loss: 0.130091  [ 6400/70349]
loss: 0.068099  [12800/70349]
loss: 0.155127  [19200/70349]
loss: 0.249817  [25600/70349]
loss: 0.188715  [32000/70349]
loss: 0.155386  [38400/70349]
loss: 0.043618  [44800/70349]
loss: 0.027428  [51200/70349]
loss: 0.027189  [57600/70349]
loss: 0.005424  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.104229 

Epoch 43
-------------------------------
loss: 0.028939  [    0/70349]
loss: 0.041569  [ 6400/70349]
loss: 0.056358  [12800/70349]
loss: 0.157016  [19200/70349]
loss: 0.062421  [25600/70349]
loss: 0.261034  [32000/70349]
loss: 0.084162  [38400/70349]
loss: 0.071515  [44800/70349]
loss: 0.031585  [51200/70349]
loss: 0.083482  [57600/70349]
loss: 0.047035  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.109748 

Epoch 44
-------------------------------
loss: 0.158999  [    0/70349]
loss: 0.050347  [ 6400/70349]
loss: 0.052198  [12800/70349]
loss: 0.149916  [19200/70349]
loss: 0.013189  [25600/70349]
loss: 0.026273  [32000/70349]
loss: 0.165728  [38400/70349]
loss: 0.138851  [44800/70349]
loss: 0.151701  [51200/70349]
loss: 0.138435  [57600/70349]
loss: 0.039763  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.111829 

Epoch 45
-------------------------------
loss: 0.093008  [    0/70349]
loss: 0.068849  [ 6400/70349]
loss: 0.050283  [12800/70349]
loss: 0.062680  [19200/70349]
loss: 0.062046  [25600/70349]
loss: 0.256156  [32000/70349]
loss: 0.123618  [38400/70349]
loss: 0.249990  [44800/70349]
loss: 0.045916  [51200/70349]
loss: 0.143262  [57600/70349]
loss: 0.089393  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.109179 

Epoch 46
-------------------------------
loss: 0.052740  [    0/70349]
loss: 0.175069  [ 6400/70349]
loss: 0.084116  [12800/70349]
loss: 0.064674  [19200/70349]
loss: 0.080836  [25600/70349]
loss: 0.083574  [32000/70349]
loss: 0.078680  [38400/70349]
loss: 0.033214  [44800/70349]
loss: 0.062723  [51200/70349]
loss: 0.081716  [57600/70349]
loss: 0.006861  [64000/70349]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.108227 

Epoch 47
-------------------------------
loss: 0.017289  [    0/70349]
loss: 0.044095  [ 6400/70349]
loss: 0.055058  [12800/70349]
loss: 0.019540  [19200/70349]
loss: 0.037682  [25600/70349]
loss: 0.122495  [32000/70349]
loss: 0.036889  [38400/70349]
loss: 0.090401  [44800/70349]
loss: 0.030716  [51200/70349]
loss: 0.071225  [57600/70349]
loss: 0.069270  [64000/70349]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.105471 

Epoch 48
-------------------------------
loss: 0.043652  [    0/70349]
loss: 0.146800  [ 6400/70349]
loss: 0.183228  [12800/70349]
loss: 0.013494  [19200/70349]
loss: 0.051188  [25600/70349]
loss: 0.036359  [32000/70349]
loss: 0.094814  [38400/70349]
loss: 0.149990  [44800/70349]
loss: 0.117905  [51200/70349]
loss: 0.090815  [57600/70349]
loss: 0.037782  [64000/70349]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.115708 

Epoch 49
-------------------------------
loss: 0.057712  [    0/70349]
loss: 0.076083  [ 6400/70349]
loss: 0.033811  [12800/70349]
loss: 0.049413  [19200/70349]
loss: 0.065201  [25600/70349]
loss: 0.279949  [32000/70349]
loss: 0.052188  [38400/70349]
loss: 0.079249  [44800/70349]
loss: 0.066820  [51200/70349]
loss: 0.047398  [57600/70349]
loss: 0.037825  [64000/70349]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.132511 

Epoch 50
-------------------------------
loss: 0.211426  [    0/70349]
loss: 0.024523  [ 6400/70349]
loss: 0.143743  [12800/70349]
loss: 0.021107  [19200/70349]
loss: 0.022118  [25600/70349]
loss: 0.051278  [32000/70349]
loss: 0.059004  [38400/70349]
loss: 0.195414  [44800/70349]
loss: 0.111533  [51200/70349]
loss: 0.103607  [57600/70349]
loss: 0.096057  [64000/70349]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.111471 

Epoch 1
-------------------------------
loss: 0.661484  [    0/69546]
loss: 0.266004  [ 6400/69546]
loss: 0.147869  [12800/69546]
loss: 0.245733  [19200/69546]
loss: 0.147000  [25600/69546]
loss: 0.169676  [32000/69546]
loss: 0.240075  [38400/69546]
loss: 0.102590  [44800/69546]
loss: 0.160393  [51200/69546]
loss: 0.078335  [57600/69546]
loss: 0.236052  [64000/69546]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139894 

Epoch 2
-------------------------------
loss: 0.096135  [    0/69546]
loss: 0.119488  [ 6400/69546]
loss: 0.128798  [12800/69546]
loss: 0.124054  [19200/69546]
loss: 0.133274  [25600/69546]
loss: 0.144577  [32000/69546]
loss: 0.086664  [38400/69546]
loss: 0.101914  [44800/69546]
loss: 0.089348  [51200/69546]
loss: 0.292656  [57600/69546]
loss: 0.182974  [64000/69546]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.125546 

Epoch 3
-------------------------------
loss: 0.128955  [    0/69546]
loss: 0.197693  [ 6400/69546]
loss: 0.209248  [12800/69546]
loss: 0.268484  [19200/69546]
loss: 0.100877  [25600/69546]
loss: 0.288370  [32000/69546]
loss: 0.164190  [38400/69546]
loss: 0.190905  [44800/69546]
loss: 0.235012  [51200/69546]
loss: 0.129124  [57600/69546]
loss: 0.189506  [64000/69546]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.131343 

Epoch 4
-------------------------------
loss: 0.108607  [    0/69546]
loss: 0.177277  [ 6400/69546]
loss: 0.252388  [12800/69546]
loss: 0.123912  [19200/69546]
loss: 0.222567  [25600/69546]
loss: 0.218943  [32000/69546]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:46:17 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.131048  [ 6400/69713]
loss: 0.078088  [12800/69713]
loss: 0.168666  [19200/69713]
loss: 0.111710  [25600/69713]
loss: 0.105558  [32000/69713]
loss: 0.176158  [38400/69713]
loss: 0.092630  [44800/69713]
loss: 0.159410  [51200/69713]
loss: 0.125091  [57600/69713]
loss: 0.168734  [64000/69713]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.167566 

Epoch 48
-------------------------------
loss: 0.090929  [    0/69713]
loss: 0.074997  [ 6400/69713]
loss: 0.161676  [12800/69713]
loss: 0.118362  [19200/69713]
loss: 0.113897  [25600/69713]
loss: 0.054385  [32000/69713]
loss: 0.064739  [38400/69713]
loss: 0.168198  [44800/69713]
loss: 0.155635  [51200/69713]
loss: 1.667752  [57600/69713]
loss: 0.120197  [64000/69713]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.171692 

Epoch 49
-------------------------------
loss: 0.183523  [    0/69713]
loss: 0.142667  [ 6400/69713]
loss: 0.080464  [12800/69713]
loss: 0.108649  [19200/69713]
loss: 0.275336  [25600/69713]
loss: 0.127298  [32000/69713]
loss: 0.047254  [38400/69713]
loss: 0.223498  [44800/69713]
loss: 0.178636  [51200/69713]
loss: 0.097349  [57600/69713]
loss: 0.203461  [64000/69713]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.174101 

Epoch 50
-------------------------------
loss: 0.050659  [    0/69713]
loss: 0.102331  [ 6400/69713]
loss: 0.082060  [12800/69713]
loss: 0.147117  [19200/69713]
loss: 0.200707  [25600/69713]
loss: 0.134732  [32000/69713]
loss: 0.197116  [38400/69713]
loss: 0.136932  [44800/69713]
loss: 0.063910  [51200/69713]
loss: 0.169411  [57600/69713]
loss: 0.080911  [64000/69713]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.171694 

Epoch 1
-------------------------------
loss: 0.657459  [    0/69752]
loss: 0.148316  [ 6400/69752]
loss: 0.160301  [12800/69752]
loss: 0.183591  [19200/69752]
loss: 0.275157  [25600/69752]
loss: 0.252260  [32000/69752]
loss: 0.260965  [38400/69752]
loss: 0.306264  [44800/69752]
loss: 0.327305  [51200/69752]
loss: 0.178970  [57600/69752]
loss: 0.197971  [64000/69752]
Test Error: 
 Accuracy: 91.0%, Avg loss: 0.238687 

Epoch 2
-------------------------------
loss: 0.307586  [    0/69752]
loss: 0.153434  [ 6400/69752]
loss: 0.183198  [12800/69752]
loss: 0.394184  [19200/69752]
loss: 0.216215  [25600/69752]
loss: 0.176761  [32000/69752]
loss: 0.137536  [38400/69752]
loss: 0.160594  [44800/69752]
loss: 0.251439  [51200/69752]
loss: 0.233474  [57600/69752]
loss: 0.439946  [64000/69752]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.216079 

Epoch 3
-------------------------------
loss: 0.198806  [    0/69752]
loss: 0.118690  [ 6400/69752]
loss: 0.266019  [12800/69752]
loss: 0.189752  [19200/69752]
loss: 0.333529  [25600/69752]
loss: 0.246009  [32000/69752]
loss: 0.172415  [38400/69752]
loss: 0.266476  [44800/69752]
loss: 0.213498  [51200/69752]
loss: 0.191673  [57600/69752]
loss: 0.210902  [64000/69752]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.208453 

Epoch 4
-------------------------------
loss: 0.190145  [    0/69752]
loss: 0.356659  [ 6400/69752]
loss: 0.264597  [12800/69752]
loss: 0.119985  [19200/69752]
loss: 0.101887  [25600/69752]
loss: 0.150719  [32000/69752]
loss: 0.225173  [38400/69752]
loss: 0.147104  [44800/69752]
loss: 0.156485  [51200/69752]
loss: 0.334457  [57600/69752]
loss: 0.135627  [64000/69752]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.199741 

Epoch 5
-------------------------------
loss: 0.088185  [    0/69752]
loss: 0.149393  [ 6400/69752]
loss: 0.059578  [12800/69752]
loss: 0.159301  [19200/69752]
loss: 0.243170  [25600/69752]
loss: 0.261982  [32000/69752]
loss: 0.149492  [38400/69752]
loss: 0.177721  [44800/69752]
loss: 0.177928  [51200/69752]
loss: 0.086891  [57600/69752]
loss: 0.305102  [64000/69752]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.196459 

Epoch 6
-------------------------------
loss: 0.307753  [    0/69752]
loss: 0.113266  [ 6400/69752]
loss: 0.212434  [12800/69752]
loss: 0.126444  [19200/69752]
loss: 0.237010  [25600/69752]
loss: 0.214445  [32000/69752]
loss: 0.080625  [38400/69752]
loss: 0.109249  [44800/69752]
loss: 0.149029  [51200/69752]
loss: 0.177512  [57600/69752]
loss: 0.112115  [64000/69752]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.202856 

Epoch 7
-------------------------------
loss: 0.290344  [    0/69752]
loss: 0.333924  [ 6400/69752]
loss: 0.135287  [12800/69752]
loss: 0.167641  [19200/69752]
loss: 0.305554  [25600/69752]
loss: 0.161895  [32000/69752]
loss: 0.163843  [38400/69752]
loss: 0.162501  [44800/69752]
loss: 0.113504  [51200/69752]
loss: 0.122265  [57600/69752]
loss: 0.209539  [64000/69752]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.204553 

Epoch 8
-------------------------------
loss: 0.192575  [    0/69752]
loss: 0.219457  [ 6400/69752]
loss: 0.266576  [12800/69752]
loss: 0.128641  [19200/69752]
loss: 0.275323  [25600/69752]
loss: 0.261234  [32000/69752]
loss: 0.298812  [38400/69752]
loss: 0.161827  [44800/69752]
loss: 0.319257  [51200/69752]
loss: 0.203456  [57600/69752]
loss: 0.166059  [64000/69752]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.203547 

Epoch 9
-------------------------------
loss: 0.152117  [    0/69752]
loss: 0.089972  [ 6400/69752]
loss: 0.043687  [12800/69752]
loss: 0.162699  [19200/69752]
loss: 0.126530  [25600/69752]
loss: 0.228762  [32000/69752]
loss: 0.179329  [38400/69752]
loss: 0.146166  [44800/69752]
loss: 0.154142  [51200/69752]
loss: 0.135585  [57600/69752]
loss: 0.238457  [64000/69752]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.191237 

Epoch 10
-------------------------------
loss: 0.055209  [    0/69752]
loss: 0.143046  [ 6400/69752]
loss: 0.180368  [12800/69752]
loss: 0.145028  [19200/69752]
loss: 0.213555  [25600/69752]
loss: 0.142417  [32000/69752]
loss: 0.166357  [38400/69752]
loss: 0.158774  [44800/69752]
loss: 0.188178  [51200/69752]
loss: 0.074880  [57600/69752]
loss: 0.102454  [64000/69752]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.184336 

Epoch 11
-------------------------------
loss: 0.118414  [    0/69752]
loss: 0.118205  [ 6400/69752]
loss: 0.199661  [12800/69752]
loss: 0.142097  [19200/69752]
loss: 0.158546  [25600/69752]
loss: 0.149131  [32000/69752]
loss: 0.126142  [38400/69752]
loss: 0.173253  [44800/69752]
loss: 0.074490  [51200/69752]
loss: 0.220221  [57600/69752]
loss: 0.150458  [64000/69752]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.194527 

Epoch 12
-------------------------------
loss: 0.144882  [    0/69752]
loss: 0.229901  [ 6400/69752]
loss: 0.153786  [12800/69752]
loss: 0.113317  [19200/69752]
loss: 0.048390  [25600/69752]
loss: 0.172688  [32000/69752]
loss: 0.158180  [38400/69752]
loss: 0.089188  [44800/69752]
loss: 0.131049  [51200/69752]
loss: 0.086401  [57600/69752]
loss: 0.068389  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.182319 

Epoch 13
-------------------------------
loss: 0.052689  [    0/69752]
loss: 0.141216  [ 6400/69752]
loss: 0.159450  [12800/69752]
loss: 0.194368  [19200/69752]
loss: 0.162902  [25600/69752]
loss: 0.147769  [32000/69752]
loss: 3.337647  [38400/69752]
loss: 0.260571  [44800/69752]
loss: 0.064419  [51200/69752]
loss: 1.635255  [57600/69752]
loss: 0.181282  [64000/69752]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.188606 

Epoch 14
-------------------------------
loss: 0.156413  [    0/69752]
loss: 0.150499  [ 6400/69752]
loss: 0.246893  [12800/69752]
loss: 0.218790  [19200/69752]
loss: 0.102835  [25600/69752]
loss: 0.073997  [32000/69752]
loss: 0.130049  [38400/69752]
loss: 0.126200  [44800/69752]
loss: 0.208603  [51200/69752]
loss: 0.263264  [57600/69752]
loss: 0.182713  [64000/69752]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.191963 

Epoch 15
-------------------------------
loss: 1.750518  [    0/69752]
loss: 0.055186  [ 6400/69752]
loss: 0.198579  [12800/69752]
loss: 0.082917  [19200/69752]
loss: 0.180449  [25600/69752]
loss: 0.167920  [32000/69752]
loss: 0.154555  [38400/69752]
loss: 0.200965  [44800/69752]
loss: 0.103751  [51200/69752]
loss: 0.148844  [57600/69752]
loss: 0.171435  [64000/69752]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.188437 

Epoch 16
-------------------------------
loss: 0.089162  [    0/69752]
loss: 0.225505  [ 6400/69752]
loss: 0.203859  [12800/69752]
loss: 0.248721  [19200/69752]
loss: 0.133383  [25600/69752]
loss: 0.047499  [32000/69752]
loss: 0.055507  [38400/69810]
loss: 0.075873  [44800/69810]
loss: 0.080445  [51200/69810]
loss: 0.092138  [57600/69810]
loss: 0.183599  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.091709 

Epoch 39
-------------------------------
loss: 0.085676  [    0/69810]
loss: 0.041034  [ 6400/69810]
loss: 0.063183  [12800/69810]
loss: 0.098081  [19200/69810]
loss: 0.113777  [25600/69810]
loss: 0.062021  [32000/69810]
loss: 0.167235  [38400/69810]
loss: 0.077841  [44800/69810]
loss: 0.050452  [51200/69810]
loss: 0.110719  [57600/69810]
loss: 0.060584  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.091897 

Epoch 40
-------------------------------
loss: 0.150266  [    0/69810]
loss: 0.047897  [ 6400/69810]
loss: 0.024875  [12800/69810]
loss: 0.074188  [19200/69810]
loss: 0.081112  [25600/69810]
loss: 0.133798  [32000/69810]
loss: 0.060059  [38400/69810]
loss: 0.101883  [44800/69810]
loss: 0.056245  [51200/69810]
loss: 0.112251  [57600/69810]
loss: 0.134760  [64000/69810]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.109431 

Epoch 41
-------------------------------
loss: 0.047794  [    0/69810]
loss: 0.077034  [ 6400/69810]
loss: 0.055546  [12800/69810]
loss: 0.119040  [19200/69810]
loss: 0.039751  [25600/69810]
loss: 0.129842  [32000/69810]
loss: 0.061712  [38400/69810]
loss: 0.044958  [44800/69810]
loss: 0.051041  [51200/69810]
loss: 0.109960  [57600/69810]
loss: 0.057413  [64000/69810]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099799 

Epoch 42
-------------------------------
loss: 0.102704  [    0/69810]
loss: 0.077878  [ 6400/69810]
loss: 0.026495  [12800/69810]
loss: 0.146958  [19200/69810]
loss: 0.047903  [25600/69810]
loss: 0.102367  [32000/69810]
loss: 0.052495  [38400/69810]
loss: 0.101594  [44800/69810]
loss: 0.064794  [51200/69810]
loss: 0.023593  [57600/69810]
loss: 0.155236  [64000/69810]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.093986 

Epoch 43
-------------------------------
loss: 0.061584  [    0/69810]
loss: 0.056078  [ 6400/69810]
loss: 0.065373  [12800/69810]
loss: 0.034501  [19200/69810]
loss: 0.105266  [25600/69810]
loss: 0.078701  [32000/69810]
loss: 0.112998  [38400/69810]
loss: 0.066301  [44800/69810]
loss: 0.111160  [51200/69810]
loss: 0.098940  [57600/69810]
loss: 0.083275  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.089590 

Epoch 44
-------------------------------
loss: 0.087187  [    0/69810]
loss: 0.119340  [ 6400/69810]
loss: 0.045703  [12800/69810]
loss: 0.236652  [19200/69810]
loss: 0.051908  [25600/69810]
loss: 0.059082  [32000/69810]
loss: 0.143157  [38400/69810]
loss: 0.165722  [44800/69810]
loss: 0.028324  [51200/69810]
loss: 0.223866  [57600/69810]
loss: 0.092698  [64000/69810]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.090501 

Epoch 45
-------------------------------
loss: 0.057325  [    0/69810]
loss: 0.199846  [ 6400/69810]
loss: 0.049677  [12800/69810]
loss: 0.123092  [19200/69810]
loss: 0.165100  [25600/69810]
loss: 0.137799  [32000/69810]
loss: 0.079642  [38400/69810]
loss: 0.009164  [44800/69810]
loss: 0.074725  [51200/69810]
loss: 0.116719  [57600/69810]
loss: 0.144156  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.093149 

Epoch 46
-------------------------------
loss: 0.105115  [    0/69810]
loss: 0.131556  [ 6400/69810]
loss: 0.096906  [12800/69810]
loss: 0.104893  [19200/69810]
loss: 0.180438  [25600/69810]
loss: 0.097602  [32000/69810]
loss: 0.113171  [38400/69810]
loss: 0.186509  [44800/69810]
loss: 0.037536  [51200/69810]
loss: 0.085547  [57600/69810]
loss: 0.148760  [64000/69810]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.090935 

Epoch 47
-------------------------------
loss: 0.084943  [    0/69810]
loss: 0.078419  [ 6400/69810]
loss: 0.059751  [12800/69810]
loss: 0.073937  [19200/69810]
loss: 0.042373  [25600/69810]
loss: 0.107335  [32000/69810]
loss: 0.026380  [38400/69810]
loss: 0.063748  [44800/69810]
loss: 0.047483  [51200/69810]
loss: 0.064120  [57600/69810]
loss: 0.096127  [64000/69810]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.092302 

Epoch 48
-------------------------------
loss: 0.036626  [    0/69810]
loss: 0.121894  [ 6400/69810]
loss: 0.090070  [12800/69810]
loss: 0.045422  [19200/69810]
loss: 0.086774  [25600/69810]
loss: 0.114579  [32000/69810]
loss: 0.069952  [38400/69810]
loss: 0.137246  [44800/69810]
loss: 0.055456  [51200/69810]
loss: 0.104890  [57600/69810]
loss: 0.114778  [64000/69810]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.092695 

Epoch 49
-------------------------------
loss: 0.032375  [    0/69810]
loss: 0.069463  [ 6400/69810]
loss: 0.043931  [12800/69810]
loss: 0.209656  [19200/69810]
loss: 0.033387  [25600/69810]
loss: 0.035260  [32000/69810]
loss: 0.048233  [38400/69810]
loss: 0.077246  [44800/69810]
loss: 0.062964  [51200/69810]
loss: 0.099296  [57600/69810]
loss: 0.100775  [64000/69810]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.103476 

Epoch 50
-------------------------------
loss: 0.018587  [    0/69810]
loss: 0.053927  [ 6400/69810]
loss: 0.055976  [12800/69810]
loss: 0.077715  [19200/69810]
loss: 0.027997  [25600/69810]
loss: 0.102468  [32000/69810]
loss: 0.062562  [38400/69810]
loss: 0.065213  [44800/69810]
loss: 0.088198  [51200/69810]
loss: 0.126925  [57600/69810]
loss: 0.102225  [64000/69810]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.092872 

Epoch 1
-------------------------------
loss: 0.654779  [    0/70818]
loss: 0.139451  [ 6400/70818]
loss: 0.110221  [12800/70818]
loss: 0.290851  [19200/70818]
loss: 0.128442  [25600/70818]
loss: 0.132255  [32000/70818]
loss: 0.168945  [38400/70818]
loss: 0.223524  [44800/70818]
loss: 0.182844  [51200/70818]
loss: 0.215391  [57600/70818]
loss: 0.202039  [64000/70818]
loss: 0.223699  [70400/70818]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.139535 

Epoch 2
-------------------------------
loss: 0.186812  [    0/70818]
loss: 0.106260  [ 6400/70818]
loss: 0.107291  [12800/70818]
loss: 0.077058  [19200/70818]
loss: 0.205335  [25600/70818]
loss: 0.312467  [32000/70818]
loss: 0.109565  [38400/70818]
loss: 0.106255  [44800/70818]
loss: 0.060772  [51200/70818]
loss: 0.038059  [57600/70818]
loss: 0.130516  [64000/70818]
loss: 0.121675  [70400/70818]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.149712 

Epoch 3
-------------------------------
loss: 0.147032  [    0/70818]
loss: 0.119848  [ 6400/70818]
loss: 0.180530  [12800/70818]
loss: 0.024849  [19200/70818]
loss: 0.079846  [25600/70818]
loss: 0.101195  [32000/70818]
loss: 0.145789  [38400/70818]
loss: 0.075217  [44800/70818]
loss: 0.084043  [51200/70818]
loss: 0.083203  [57600/70818]
loss: 0.093598  [64000/70818]
loss: 0.139867  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.118179 

Epoch 4
-------------------------------
loss: 0.091158  [    0/70818]
loss: 0.127184  [ 6400/70818]
loss: 0.032649  [12800/70818]
loss: 0.120863  [19200/70818]
loss: 0.143691  [25600/70818]
loss: 0.119689  [32000/70818]
loss: 0.064424  [38400/70818]
loss: 0.138338  [44800/70818]
loss: 0.128041  [51200/70818]
loss: 0.150088  [57600/70818]
loss: 0.072821  [64000/70818]
loss: 0.129664  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.117498 

Epoch 5
-------------------------------
loss: 0.147007  [    0/70818]
loss: 0.150042  [ 6400/70818]
loss: 0.081557  [12800/70818]
loss: 0.258337  [19200/70818]
loss: 0.060742  [25600/70818]
loss: 0.158759  [32000/70818]
loss: 0.191902  [38400/70818]
loss: 0.019179  [44800/70818]
loss: 0.089245  [51200/70818]
loss: 0.058255  [57600/70818]
loss: 0.111698  [64000/70818]
loss: 0.049249  [70400/70818]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.128386 

Epoch 6
-------------------------------
loss: 0.113579  [    0/70818]
loss: 0.197848  [ 6400/70818]
loss: 0.089553  [12800/70818]
loss: 0.063756  [19200/70818]
loss: 0.106307  [25600/70818]
loss: 0.069746  [32000/70818]
loss: 0.071174  [38400/70818]
loss: 0.081268  [44800/70818]
loss: 0.169004  [51200/70818]
loss: 0.105394  [57600/70818]
loss: 0.085949  [64000/70818]
loss: 0.048254  [70400/70818]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.112552 

Epoch 7
-------------------------------
loss: 0.181055  [    0/70818]
loss: 0.073557  [ 6400/70818]
loss: 0.105823  [12800/70818]
loss: 0.091668  [19200/70818]
loss: 0.080636  [25600/70818]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:47:08 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Epoch 31
-------------------------------
loss: 0.120514  [    0/69308]
loss: 0.069220  [ 6400/69308]
loss: 0.185713  [12800/69308]
loss: 0.146318  [19200/69308]
loss: 0.146400  [25600/69308]
loss: 0.267741  [32000/69308]
loss: 0.229327  [38400/69308]
loss: 0.102346  [44800/69308]
loss: 0.121788  [51200/69308]
loss: 0.143432  [57600/69308]
loss: 0.172933  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.171670 

Epoch 32
-------------------------------
loss: 0.137741  [    0/69308]
loss: 0.144673  [ 6400/69308]
loss: 0.094211  [12800/69308]
loss: 0.069763  [19200/69308]
loss: 0.091237  [25600/69308]
loss: 0.108923  [32000/69308]
loss: 0.206546  [38400/69308]
loss: 0.206336  [44800/69308]
loss: 0.250806  [51200/69308]
loss: 0.162913  [57600/69308]
loss: 0.161615  [64000/69308]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.174858 

Epoch 33
-------------------------------
loss: 0.200630  [    0/69308]
loss: 0.157127  [ 6400/69308]
loss: 0.163085  [12800/69308]
loss: 0.160603  [19200/69308]
loss: 0.142851  [25600/69308]
loss: 0.217048  [32000/69308]
loss: 0.118670  [38400/69308]
loss: 0.222943  [44800/69308]
loss: 0.325655  [51200/69308]
loss: 0.139962  [57600/69308]
loss: 0.231807  [64000/69308]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.171052 

Epoch 34
-------------------------------
loss: 0.249768  [    0/69308]
loss: 0.148230  [ 6400/69308]
loss: 0.131037  [12800/69308]
loss: 0.177421  [19200/69308]
loss: 0.184915  [25600/69308]
loss: 0.114805  [32000/69308]
loss: 0.107078  [38400/69308]
loss: 0.166034  [44800/69308]
loss: 0.160859  [51200/69308]
loss: 0.205505  [57600/69308]
loss: 0.179906  [64000/69308]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.179131 

Epoch 35
-------------------------------
loss: 0.211298  [    0/69308]
loss: 0.222575  [ 6400/69308]
loss: 0.303062  [12800/69308]
loss: 0.220443  [19200/69308]
loss: 0.118069  [25600/69308]
loss: 0.195594  [32000/69308]
loss: 0.103283  [38400/69308]
loss: 0.191561  [44800/69308]
loss: 0.193758  [51200/69308]
loss: 0.216160  [57600/69308]
loss: 0.281530  [64000/69308]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.189514 

Epoch 36
-------------------------------
loss: 0.227288  [    0/69308]
loss: 0.235742  [ 6400/69308]
loss: 0.092529  [12800/69308]
loss: 0.193761  [19200/69308]
loss: 0.129716  [25600/69308]
loss: 0.149116  [32000/69308]
loss: 0.223758  [38400/69308]
loss: 0.400949  [44800/69308]
loss: 0.083352  [51200/69308]
loss: 0.146298  [57600/69308]
loss: 0.150530  [64000/69308]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.183711 

Epoch 37
-------------------------------
loss: 0.189155  [    0/69308]
loss: 0.055081  [ 6400/69308]
loss: 0.182047  [12800/69308]
loss: 0.136630  [19200/69308]
loss: 0.259237  [25600/69308]
loss: 0.125677  [32000/69308]
loss: 0.235684  [38400/69308]
loss: 0.139224  [44800/69308]
loss: 0.212010  [51200/69308]
loss: 0.278486  [57600/69308]
loss: 0.189059  [64000/69308]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.180144 

Epoch 38
-------------------------------
loss: 0.101923  [    0/69308]
loss: 0.334764  [ 6400/69308]
loss: 0.114330  [12800/69308]
loss: 0.207098  [19200/69308]
loss: 0.242403  [25600/69308]
loss: 0.178713  [32000/69308]
loss: 0.179881  [38400/69308]
loss: 0.235499  [44800/69308]
loss: 0.148960  [51200/69308]
loss: 0.113967  [57600/69308]
loss: 0.184978  [64000/69308]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.175952 

Epoch 39
-------------------------------
loss: 0.128360  [    0/69308]
loss: 0.069498  [ 6400/69308]
loss: 0.176578  [12800/69308]
loss: 0.200478  [19200/69308]
loss: 0.089348  [25600/69308]
loss: 0.138984  [32000/69308]
loss: 0.174505  [38400/69308]
loss: 0.110100  [44800/69308]
loss: 0.169677  [51200/69308]
loss: 0.315384  [57600/69308]
loss: 0.452755  [64000/69308]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174489 

Epoch 40
-------------------------------
loss: 0.174875  [    0/69308]
loss: 0.265233  [ 6400/69308]
loss: 0.208272  [12800/69308]
loss: 0.209914  [19200/69308]
loss: 0.190850  [25600/69308]
loss: 0.132385  [32000/69308]
loss: 0.207378  [38400/69308]
loss: 0.119208  [44800/69308]
loss: 0.184224  [51200/69308]
loss: 0.108845  [57600/69308]
loss: 0.153722  [64000/69308]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.172731 

Epoch 41
-------------------------------
loss: 0.188784  [    0/69308]
loss: 0.127899  [ 6400/69308]
loss: 0.126806  [12800/69308]
loss: 0.137044  [19200/69308]
loss: 0.061771  [25600/69308]
loss: 0.140141  [32000/69308]
loss: 0.232646  [38400/69308]
loss: 0.110146  [44800/69308]
loss: 0.189909  [51200/69308]
loss: 0.123339  [57600/69308]
loss: 0.089400  [64000/69308]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.177790 

Epoch 42
-------------------------------
loss: 0.320208  [    0/69308]
loss: 0.218251  [ 6400/69308]
loss: 0.098487  [12800/69308]
loss: 0.175089  [19200/69308]
loss: 0.126429  [25600/69308]
loss: 0.250311  [32000/69308]
loss: 0.186264  [38400/69308]
loss: 0.201741  [44800/69308]
loss: 0.143532  [51200/69308]
loss: 0.112308  [57600/69308]
loss: 0.103968  [64000/69308]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.176916 

Epoch 43
-------------------------------
loss: 0.278893  [    0/69308]
loss: 0.091370  [ 6400/69308]
loss: 0.125194  [12800/69308]
loss: 0.139029  [19200/69308]
loss: 0.257439  [25600/69308]
loss: 0.146025  [32000/69308]
loss: 0.083319  [38400/69308]
loss: 0.411799  [44800/69308]
loss: 0.183333  [51200/69308]
loss: 0.135892  [57600/69308]
loss: 0.133953  [64000/69308]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.171641 

Epoch 44
-------------------------------
loss: 0.146309  [    0/69308]
loss: 0.144875  [ 6400/69308]
loss: 0.140447  [12800/69308]
loss: 0.269144  [19200/69308]
loss: 0.141940  [25600/69308]
loss: 0.184835  [32000/69308]
loss: 0.227624  [38400/69308]
loss: 0.186164  [44800/69308]
loss: 0.260549  [51200/69308]
loss: 0.121018  [57600/69308]
loss: 0.208221  [64000/69308]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.176420 

Epoch 45
-------------------------------
loss: 0.175465  [    0/69308]
loss: 0.162503  [ 6400/69308]
loss: 0.159232  [12800/69308]
loss: 0.200603  [19200/69308]
loss: 0.155552  [25600/69308]
loss: 0.307068  [32000/69308]
loss: 0.113469  [38400/69308]
loss: 0.166246  [44800/69308]
loss: 0.111072  [51200/69308]
loss: 0.140805  [57600/69308]
loss: 0.184126  [64000/69308]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.172972 

Epoch 46
-------------------------------
loss: 0.112679  [    0/69308]
loss: 0.214267  [ 6400/69308]
loss: 0.134728  [12800/69308]
loss: 0.127301  [19200/69308]
loss: 0.136292  [25600/69308]
loss: 0.125997  [32000/69308]
loss: 0.116209  [38400/69308]
loss: 0.143606  [44800/69308]
loss: 0.097694  [51200/69308]
loss: 0.132814  [57600/69308]
loss: 0.140588  [64000/69308]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.169180 

Epoch 47
-------------------------------
loss: 0.112788  [    0/69308]
loss: 0.145271  [ 6400/69308]
loss: 0.173349  [12800/69308]
loss: 0.160913  [19200/69308]
loss: 0.138101  [25600/69308]
loss: 0.223044  [32000/69308]
loss: 0.160847  [38400/69308]
loss: 0.255111  [44800/69308]
loss: 0.086661  [51200/69308]
loss: 0.259238  [57600/69308]
loss: 0.204927  [64000/69308]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.169028 

Epoch 48
-------------------------------
loss: 0.169521  [    0/69308]
loss: 0.164790  [ 6400/69308]
loss: 0.117492  [12800/69308]
loss: 0.135472  [19200/69308]
loss: 0.149597  [25600/69308]
loss: 0.104650  [32000/69308]
loss: 0.115166  [38400/69308]
loss: 0.139083  [44800/69308]
loss: 0.127630  [51200/69308]
loss: 0.164133  [57600/69308]
loss: 0.161338  [64000/69308]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.183197 

Epoch 49
-------------------------------
loss: 0.206562  [    0/69308]
loss: 0.250568  [ 6400/69308]
loss: 0.132634  [12800/69308]
loss: 0.339332  [19200/69308]
loss: 0.141621  [25600/69308]
loss: 0.337043  [32000/69308]
loss: 0.119930  [38400/69308]
loss: 0.182713  [44800/69308]
loss: 0.137359  [51200/69308]
loss: 0.228609  [57600/69308]
loss: 0.208826  [64000/69308]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.169905 

Epoch 50
-------------------------------
loss: 0.132503  [    0/69308]
loss: 0.180099  [ 6400/69308]
loss: 0.313756  [12800/69308]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.178548 

Epoch 23
-------------------------------
loss: 0.160100  [    0/69683]
loss: 0.158763  [ 6400/69683]
loss: 0.219050  [12800/69683]
loss: 0.196898  [19200/69683]
loss: 0.139614  [25600/69683]
loss: 0.158241  [32000/69683]
loss: 0.203279  [38400/69683]
loss: 0.137442  [44800/69683]
loss: 0.151933  [51200/69683]
loss: 0.164079  [57600/69683]
loss: 0.148042  [64000/69683]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.170818 

Epoch 24
-------------------------------
loss: 0.284029  [    0/69683]
loss: 0.176602  [ 6400/69683]
loss: 0.117960  [12800/69683]
loss: 0.174802  [19200/69683]
loss: 0.169575  [25600/69683]
loss: 0.298573  [32000/69683]
loss: 0.203168  [38400/69683]
loss: 0.226849  [44800/69683]
loss: 0.143686  [51200/69683]
loss: 0.210564  [57600/69683]
loss: 0.225936  [64000/69683]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.174676 

Epoch 25
-------------------------------
loss: 0.210739  [    0/69683]
loss: 0.205465  [ 6400/69683]
loss: 0.266693  [12800/69683]
loss: 0.127603  [19200/69683]
loss: 0.233496  [25600/69683]
loss: 0.217766  [32000/69683]
loss: 0.069522  [38400/69683]
loss: 0.155816  [44800/69683]
loss: 0.136466  [51200/69683]
loss: 0.197486  [57600/69683]
loss: 0.137656  [64000/69683]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.174812 

Epoch 26
-------------------------------
loss: 0.222207  [    0/69683]
loss: 0.179004  [ 6400/69683]
loss: 0.116943  [12800/69683]
loss: 0.234731  [19200/69683]
loss: 0.255048  [25600/69683]
loss: 0.152248  [32000/69683]
loss: 0.252522  [38400/69683]
loss: 0.235576  [44800/69683]
loss: 0.173715  [51200/69683]
loss: 0.185601  [57600/69683]
loss: 0.138819  [64000/69683]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.181313 

Epoch 27
-------------------------------
loss: 0.166777  [    0/69683]
loss: 0.254971  [ 6400/69683]
loss: 0.149331  [12800/69683]
loss: 0.213876  [19200/69683]
loss: 0.252870  [25600/69683]
loss: 0.229823  [32000/69683]
loss: 0.137857  [38400/69683]
loss: 0.273380  [44800/69683]
loss: 0.235753  [51200/69683]
loss: 0.213819  [57600/69683]
loss: 0.112153  [64000/69683]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177953 

Epoch 28
-------------------------------
loss: 0.198481  [    0/69683]
loss: 0.142012  [ 6400/69683]
loss: 0.192356  [12800/69683]
loss: 0.219722  [19200/69683]
loss: 0.153483  [25600/69683]
loss: 0.199543  [32000/69683]
loss: 0.175659  [38400/69683]
loss: 0.103298  [44800/69683]
loss: 0.254739  [51200/69683]
loss: 0.187154  [57600/69683]
loss: 0.165653  [64000/69683]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.172158 

Epoch 29
-------------------------------
loss: 0.119141  [    0/69683]
loss: 0.144574  [ 6400/69683]
loss: 0.248406  [12800/69683]
loss: 0.216005  [19200/69683]
loss: 0.197240  [25600/69683]
loss: 0.177148  [32000/69683]
loss: 0.258070  [38400/69683]
loss: 1.775486  [44800/69683]
loss: 0.153886  [51200/69683]
loss: 0.252058  [57600/69683]
loss: 0.221747  [64000/69683]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.179449 

Epoch 30
-------------------------------
loss: 0.207963  [    0/69683]
loss: 0.141066  [ 6400/69683]
loss: 0.211935  [12800/69683]
loss: 0.221491  [19200/69683]
loss: 0.216810  [25600/69683]
loss: 0.100008  [32000/69683]
loss: 0.150599  [38400/69683]
loss: 0.206561  [44800/69683]
loss: 0.176187  [51200/69683]
loss: 0.254614  [57600/69683]
loss: 0.233751  [64000/69683]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.172652 

Epoch 31
-------------------------------
loss: 1.726586  [    0/69683]
loss: 0.207455  [ 6400/69683]
loss: 0.276366  [12800/69683]
loss: 0.247812  [19200/69683]
loss: 0.221731  [25600/69683]
loss: 0.098353  [32000/69683]
loss: 0.222217  [38400/69683]
loss: 0.372176  [44800/69683]
loss: 0.223941  [51200/69683]
loss: 0.239461  [57600/69683]
loss: 0.181981  [64000/69683]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.175561 

Epoch 32
-------------------------------
loss: 0.067802  [    0/69683]
loss: 0.186124  [ 6400/69683]
loss: 0.207617  [12800/69683]
loss: 0.170470  [19200/69683]
loss: 0.164156  [25600/69683]
loss: 0.178471  [32000/69683]
loss: 0.188722  [38400/69683]
loss: 0.200979  [44800/69683]
loss: 0.164354  [51200/69683]
loss: 0.195721  [57600/69683]
loss: 0.257981  [64000/69683]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.174460 

Epoch 33
-------------------------------
loss: 0.146341  [    0/69683]
loss: 0.069857  [ 6400/69683]
loss: 0.279234  [12800/69683]
loss: 0.326482  [19200/69683]
loss: 0.072922  [25600/69683]
loss: 0.174530  [32000/69683]
loss: 0.142489  [38400/69683]
loss: 0.290740  [44800/69683]
loss: 0.148311  [51200/69683]
loss: 0.188910  [57600/69683]
loss: 0.146886  [64000/69683]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.176195 

Epoch 34
-------------------------------
loss: 0.189005  [    0/69683]
loss: 0.283548  [ 6400/69683]
loss: 0.174867  [12800/69683]
loss: 0.147509  [19200/69683]
loss: 0.219192  [25600/69683]
loss: 0.198126  [32000/69683]
loss: 0.214028  [38400/69683]
loss: 0.233003  [44800/69683]
loss: 0.232493  [51200/69683]
loss: 0.157150  [57600/69683]
loss: 0.150468  [64000/69683]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.184120 

Epoch 35
-------------------------------
loss: 0.131993  [    0/69683]
loss: 0.174563  [ 6400/69683]
loss: 0.357401  [12800/69683]
loss: 0.226028  [19200/69683]
loss: 0.130804  [25600/69683]
loss: 0.187055  [32000/69683]
loss: 0.113931  [38400/69683]
loss: 0.239628  [44800/69683]
loss: 0.199861  [51200/69683]
loss: 0.173284  [57600/69683]
loss: 0.202536  [64000/69683]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.175007 

Epoch 36
-------------------------------
loss: 0.279910  [    0/69683]
loss: 0.240852  [ 6400/69683]
loss: 0.144055  [12800/69683]
loss: 0.277565  [19200/69683]
loss: 0.136880  [25600/69683]
loss: 0.128478  [32000/69683]
loss: 0.136818  [38400/69683]
loss: 0.181750  [44800/69683]
loss: 0.202044  [51200/69683]
loss: 0.148743  [57600/69683]
loss: 0.156376  [64000/69683]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.176112 

Epoch 37
-------------------------------
loss: 0.155721  [    0/69683]
loss: 0.111058  [ 6400/69683]
loss: 0.188873  [12800/69683]
loss: 0.171538  [19200/69683]
loss: 0.252738  [25600/69683]
loss: 0.192769  [32000/69683]
loss: 0.210784  [38400/69683]
loss: 0.205061  [44800/69683]
loss: 0.263231  [51200/69683]
loss: 0.207173  [57600/69683]
loss: 0.183099  [64000/69683]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.174537 

Epoch 38
-------------------------------
loss: 0.113426  [    0/69683]
loss: 0.262287  [ 6400/69683]
loss: 0.221677  [12800/69683]
loss: 0.194530  [19200/69683]
loss: 0.201826  [25600/69683]
loss: 0.155246  [32000/69683]
loss: 0.160499  [38400/69683]
loss: 0.113581  [44800/69683]
loss: 0.173428  [51200/69683]
loss: 0.145873  [57600/69683]
loss: 0.336752  [64000/69683]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.172950 

Epoch 39
-------------------------------
loss: 0.213465  [    0/69683]
loss: 0.161736  [ 6400/69683]
loss: 0.362895  [12800/69683]
loss: 0.236537  [19200/69683]
loss: 0.224794  [25600/69683]
loss: 0.165665  [32000/69683]
loss: 0.194455  [38400/69683]
loss: 0.188751  [44800/69683]
loss: 0.168017  [51200/69683]
loss: 0.153951  [57600/69683]
loss: 0.188597  [64000/69683]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.182784 

Epoch 40
-------------------------------
loss: 0.190092  [    0/69683]
loss: 0.153435  [ 6400/69683]
loss: 0.221860  [12800/69683]
loss: 0.298846  [19200/69683]
loss: 0.083793  [25600/69683]
loss: 0.185314  [32000/69683]
loss: 0.147820  [38400/69683]
loss: 0.231041  [44800/69683]
loss: 0.243766  [51200/69683]
loss: 0.190984  [57600/69683]
loss: 0.178003  [64000/69683]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.176760 

Epoch 41
-------------------------------
loss: 0.161277  [    0/69683]
loss: 0.214996  [ 6400/69683]
loss: 0.134018  [12800/69683]
loss: 0.250634  [19200/69683]
loss: 0.225651  [25600/69683]
loss: 0.159042  [32000/69683]
loss: 0.119355  [38400/69683]
loss: 0.221223  [44800/69683]
loss: 0.227286  [51200/69683]
loss: 0.269387  [57600/69683]
loss: 0.179834  [64000/69683]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.186844 

Epoch 42
-------------------------------
loss: 0.181156  [    0/69683]
loss: 0.162435  [ 6400/69683]
loss: 0.135911  [44800/71142]
loss: 0.090555  [51200/71142]
loss: 0.133730  [57600/71142]
loss: 0.091840  [64000/71142]
loss: 0.085755  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090664 

Epoch 48
-------------------------------
loss: 0.056753  [    0/71142]
loss: 0.091645  [ 6400/71142]
loss: 0.153619  [12800/71142]
loss: 0.087881  [19200/71142]
loss: 0.126662  [25600/71142]
loss: 0.118678  [32000/71142]
loss: 0.134194  [38400/71142]
loss: 0.143155  [44800/71142]
loss: 0.128642  [51200/71142]
loss: 0.157416  [57600/71142]
loss: 0.044592  [64000/71142]
loss: 0.039101  [70400/71142]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.097894 

Epoch 49
-------------------------------
loss: 0.152891  [    0/71142]
loss: 0.013479  [ 6400/71142]
loss: 0.123894  [12800/71142]
loss: 0.107204  [19200/71142]
loss: 0.144611  [25600/71142]
loss: 0.105109  [32000/71142]
loss: 0.071226  [38400/71142]
loss: 0.063631  [44800/71142]
loss: 0.044579  [51200/71142]
loss: 0.051250  [57600/71142]
loss: 0.080722  [64000/71142]
loss: 0.146554  [70400/71142]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.092638 

Epoch 50
-------------------------------
loss: 0.191409  [    0/71142]
loss: 0.061155  [ 6400/71142]
loss: 0.240145  [12800/71142]
loss: 0.166307  [19200/71142]
loss: 0.101361  [25600/71142]
loss: 0.142951  [32000/71142]
loss: 0.033877  [38400/71142]
loss: 0.103578  [44800/71142]
loss: 0.064128  [51200/71142]
loss: 0.085584  [57600/71142]
loss: 0.023403  [64000/71142]
loss: 0.036763  [70400/71142]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.092064 

Epoch 1
-------------------------------
loss: 0.701807  [    0/70896]
loss: 0.260066  [ 6400/70896]
loss: 0.185002  [12800/70896]
loss: 0.226890  [19200/70896]
loss: 0.214294  [25600/70896]
loss: 0.126388  [32000/70896]
loss: 0.146558  [38400/70896]
loss: 0.075290  [44800/70896]
loss: 0.156726  [51200/70896]
loss: 0.170624  [57600/70896]
loss: 0.152689  [64000/70896]
loss: 0.082493  [70400/70896]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.157796 

Epoch 2
-------------------------------
loss: 0.189327  [    0/70896]
loss: 0.180006  [ 6400/70896]
loss: 0.117634  [12800/70896]
loss: 0.107119  [19200/70896]
loss: 0.104133  [25600/70896]
loss: 0.085024  [32000/70896]
loss: 0.133490  [38400/70896]
loss: 0.288148  [44800/70896]
loss: 0.042637  [51200/70896]
loss: 0.148052  [57600/70896]
loss: 0.073741  [64000/70896]
loss: 0.138813  [70400/70896]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.147683 

Epoch 3
-------------------------------
loss: 0.033263  [    0/70896]
loss: 0.084985  [ 6400/70896]
loss: 0.106747  [12800/70896]
loss: 0.147690  [19200/70896]
loss: 0.129502  [25600/70896]
loss: 0.112970  [32000/70896]
loss: 0.139417  [38400/70896]
loss: 0.073097  [44800/70896]
loss: 0.057553  [51200/70896]
loss: 0.095776  [57600/70896]
loss: 0.077928  [64000/70896]
loss: 0.137154  [70400/70896]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.134661 

Epoch 4
-------------------------------
loss: 0.073575  [    0/70896]
loss: 0.174301  [ 6400/70896]
loss: 0.073043  [12800/70896]
loss: 0.093259  [19200/70896]
loss: 0.026353  [25600/70896]
loss: 0.145563  [32000/70896]
loss: 0.094822  [38400/70896]
loss: 0.066165  [44800/70896]
loss: 0.147098  [51200/70896]
loss: 0.157956  [57600/70896]
loss: 0.172041  [64000/70896]
loss: 0.148625  [70400/70896]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.139646 

Epoch 5
-------------------------------
loss: 0.034430  [    0/70896]
loss: 0.104382  [ 6400/70896]
loss: 0.120718  [12800/70896]
loss: 0.043512  [19200/70896]
loss: 0.085753  [25600/70896]
loss: 0.061124  [32000/70896]
loss: 0.057631  [38400/70896]
loss: 0.071923  [44800/70896]
loss: 0.191723  [51200/70896]
loss: 0.068203  [57600/70896]
loss: 0.121447  [64000/70896]
loss: 0.056112  [70400/70896]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.140286 

Epoch 6
-------------------------------
loss: 0.090707  [    0/70896]
loss: 0.256231  [ 6400/70896]
loss: 0.031113  [12800/70896]
loss: 0.065648  [19200/70896]
loss: 0.077507  [25600/70896]
loss: 0.131759  [32000/70896]
loss: 0.048731  [38400/70896]
loss: 0.057164  [44800/70896]
loss: 0.097153  [51200/70896]
loss: 0.084920  [57600/70896]
loss: 0.146481  [64000/70896]
loss: 0.134433  [70400/70896]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.134630 

Epoch 7
-------------------------------
loss: 0.053551  [    0/70896]
loss: 0.077931  [ 6400/70896]
loss: 0.093119  [12800/70896]
loss: 0.135048  [19200/70896]
loss: 0.092047  [25600/70896]
loss: 0.093739  [32000/70896]
loss: 0.116030  [38400/70896]
loss: 0.043074  [44800/70896]
loss: 0.097802  [51200/70896]
loss: 0.093098  [57600/70896]
loss: 0.115642  [64000/70896]
loss: 0.016280  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.129818 

Epoch 8
-------------------------------
loss: 0.040192  [    0/70896]
loss: 0.211783  [ 6400/70896]
loss: 0.060727  [12800/70896]
loss: 0.096200  [19200/70896]
loss: 0.169652  [25600/70896]
loss: 0.120876  [32000/70896]
loss: 1.604007  [38400/70896]
loss: 0.091842  [44800/70896]
loss: 0.074601  [51200/70896]
loss: 0.049877  [57600/70896]
loss: 0.116607  [64000/70896]
loss: 0.076594  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.128583 

Epoch 9
-------------------------------
loss: 0.047838  [    0/70896]
loss: 0.162886  [ 6400/70896]
loss: 0.115215  [12800/70896]
loss: 0.096131  [19200/70896]
loss: 0.032530  [25600/70896]
loss: 0.104613  [32000/70896]
loss: 0.092227  [38400/70896]
loss: 0.183081  [44800/70896]
loss: 0.099657  [51200/70896]
loss: 0.152960  [57600/70896]
loss: 0.085820  [64000/70896]
loss: 0.223436  [70400/70896]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.125319 

Epoch 10
-------------------------------
loss: 0.128909  [    0/70896]
loss: 0.197893  [ 6400/70896]
loss: 0.149320  [12800/70896]
loss: 0.043278  [19200/70896]
loss: 0.081067  [25600/70896]
loss: 0.128980  [32000/70896]
loss: 0.106130  [38400/70896]
loss: 0.152646  [44800/70896]
loss: 0.020462  [51200/70896]
loss: 0.049680  [57600/70896]
loss: 0.080711  [64000/70896]
loss: 0.098571  [70400/70896]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.135897 

Epoch 11
-------------------------------
loss: 0.042387  [    0/70896]
loss: 0.056669  [ 6400/70896]
loss: 0.083217  [12800/70896]
loss: 0.081874  [19200/70896]
loss: 0.150672  [25600/70896]
loss: 0.058938  [32000/70896]
loss: 0.202069  [38400/70896]
loss: 0.019579  [44800/70896]
loss: 0.082364  [51200/70896]
loss: 0.214203  [57600/70896]
loss: 0.050986  [64000/70896]
loss: 0.114803  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.128241 

Epoch 12
-------------------------------
loss: 0.090766  [    0/70896]
loss: 0.035771  [ 6400/70896]
loss: 0.030017  [12800/70896]
loss: 0.121078  [19200/70896]
loss: 0.122985  [25600/70896]
loss: 0.053760  [32000/70896]
loss: 0.085845  [38400/70896]
loss: 0.054630  [44800/70896]
loss: 0.119427  [51200/70896]
loss: 0.203732  [57600/70896]
loss: 0.036991  [64000/70896]
loss: 0.091966  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.129709 

Epoch 13
-------------------------------
loss: 0.021161  [    0/70896]
loss: 0.125024  [ 6400/70896]
loss: 0.133771  [12800/70896]
loss: 0.095775  [19200/70896]
loss: 0.070644  [25600/70896]
loss: 0.078444  [32000/70896]
loss: 0.054271  [38400/70896]
loss: 0.154492  [44800/70896]
loss: 0.052807  [51200/70896]
loss: 0.030900  [57600/70896]
loss: 0.268690  [64000/70896]
loss: 0.034883  [70400/70896]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.131400 

Epoch 14
-------------------------------
loss: 0.075275  [    0/70896]
loss: 1.644321  [ 6400/70896]
loss: 0.074601  [12800/70896]
loss: 0.039915  [19200/70896]
loss: 0.187078  [25600/70896]
loss: 0.062133  [32000/70896]
loss: 0.066678  [38400/70896]
loss: 0.101714  [44800/70896]
loss: 0.070203  [51200/70896]
loss: 0.103098  [57600/70896]
loss: 0.064386  [64000/70896]
loss: 0.012523  [70400/70896]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.131177 

Epoch 15
-------------------------------
loss: 0.021989  [    0/70896]
loss: 0.055483  [ 6400/70896]
loss: 0.063614  [12800/70896]
loss: 0.099993  [19200/70896]
loss: 0.087284  [25600/70896]
loss: 0.132631  [32000/70896]
loss: 1.624144  [38400/70896]
loss: 0.023491  [44800/70896]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:49:53 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.113092  [44800/69947]
loss: 0.199802  [51200/69947]
loss: 0.153412  [57600/69947]
loss: 0.096862  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.116013 

Epoch 39
-------------------------------
loss: 0.117667  [    0/69947]
loss: 0.105090  [ 6400/69947]
loss: 0.062902  [12800/69947]
loss: 0.121759  [19200/69947]
loss: 0.052525  [25600/69947]
loss: 0.103301  [32000/69947]
loss: 0.231228  [38400/69947]
loss: 0.169691  [44800/69947]
loss: 0.172649  [51200/69947]
loss: 0.099176  [57600/69947]
loss: 0.080729  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.112126 

Epoch 40
-------------------------------
loss: 0.067038  [    0/69947]
loss: 0.146418  [ 6400/69947]
loss: 0.113963  [12800/69947]
loss: 0.138441  [19200/69947]
loss: 0.166782  [25600/69947]
loss: 0.136243  [32000/69947]
loss: 0.136144  [38400/69947]
loss: 0.106534  [44800/69947]
loss: 0.149538  [51200/69947]
loss: 0.149816  [57600/69947]
loss: 0.129486  [64000/69947]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.114895 

Epoch 41
-------------------------------
loss: 0.139107  [    0/69947]
loss: 0.217445  [ 6400/69947]
loss: 0.113628  [12800/69947]
loss: 0.158949  [19200/69947]
loss: 0.057757  [25600/69947]
loss: 0.168091  [32000/69947]
loss: 0.059970  [38400/69947]
loss: 0.148388  [44800/69947]
loss: 0.092865  [51200/69947]
loss: 0.093202  [57600/69947]
loss: 0.036112  [64000/69947]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.109813 

Epoch 42
-------------------------------
loss: 0.068844  [    0/69947]
loss: 0.149186  [ 6400/69947]
loss: 0.082682  [12800/69947]
loss: 0.107451  [19200/69947]
loss: 0.069177  [25600/69947]
loss: 0.110871  [32000/69947]
loss: 0.108408  [38400/69947]
loss: 0.190173  [44800/69947]
loss: 0.065121  [51200/69947]
loss: 0.045343  [57600/69947]
loss: 0.019198  [64000/69947]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.117047 

Epoch 43
-------------------------------
loss: 0.094139  [    0/69947]
loss: 0.045261  [ 6400/69947]
loss: 0.099795  [12800/69947]
loss: 0.200828  [19200/69947]
loss: 0.077013  [25600/69947]
loss: 0.036294  [32000/69947]
loss: 0.022980  [38400/69947]
loss: 0.083437  [44800/69947]
loss: 0.158699  [51200/69947]
loss: 0.073015  [57600/69947]
loss: 0.100563  [64000/69947]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.117715 

Epoch 44
-------------------------------
loss: 0.079894  [    0/69947]
loss: 0.084167  [ 6400/69947]
loss: 0.158746  [12800/69947]
loss: 0.133992  [19200/69947]
loss: 0.074067  [25600/69947]
loss: 0.084493  [32000/69947]
loss: 0.032887  [38400/69947]
loss: 0.136297  [44800/69947]
loss: 0.166822  [51200/69947]
loss: 0.067923  [57600/69947]
loss: 0.171103  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.112924 

Epoch 45
-------------------------------
loss: 0.144624  [    0/69947]
loss: 0.068094  [ 6400/69947]
loss: 0.082582  [12800/69947]
loss: 0.082031  [19200/69947]
loss: 0.125431  [25600/69947]
loss: 0.145943  [32000/69947]
loss: 0.084994  [38400/69947]
loss: 0.110076  [44800/69947]
loss: 0.028826  [51200/69947]
loss: 0.041231  [57600/69947]
loss: 0.145643  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.114046 

Epoch 46
-------------------------------
loss: 0.123749  [    0/69947]
loss: 0.070057  [ 6400/69947]
loss: 0.130296  [12800/69947]
loss: 0.128910  [19200/69947]
loss: 0.147106  [25600/69947]
loss: 0.060661  [32000/69947]
loss: 0.062488  [38400/69947]
loss: 0.064625  [44800/69947]
loss: 0.153204  [51200/69947]
loss: 0.028188  [57600/69947]
loss: 0.196205  [64000/69947]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.112028 

Epoch 47
-------------------------------
loss: 0.116784  [    0/69947]
loss: 0.122972  [ 6400/69947]
loss: 0.109276  [12800/69947]
loss: 0.078721  [19200/69947]
loss: 0.070481  [25600/69947]
loss: 0.157268  [32000/69947]
loss: 0.136047  [38400/69947]
loss: 0.080097  [44800/69947]
loss: 0.039552  [51200/69947]
loss: 0.122921  [57600/69947]
loss: 0.065617  [64000/69947]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.125573 

Epoch 48
-------------------------------
loss: 0.175201  [    0/69947]
loss: 0.127271  [ 6400/69947]
loss: 0.044586  [12800/69947]
loss: 0.079768  [19200/69947]
loss: 0.053155  [25600/69947]
loss: 0.112700  [32000/69947]
loss: 0.159370  [38400/69947]
loss: 0.093525  [44800/69947]
loss: 0.116849  [51200/69947]
loss: 0.078081  [57600/69947]
loss: 0.111589  [64000/69947]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.112450 

Epoch 49
-------------------------------
loss: 0.070047  [    0/69947]
loss: 0.030091  [ 6400/69947]
loss: 0.182109  [12800/69947]
loss: 0.185768  [19200/69947]
loss: 0.274292  [25600/69947]
loss: 0.075791  [32000/69947]
loss: 0.147355  [38400/69947]
loss: 0.029093  [44800/69947]
loss: 0.093817  [51200/69947]
loss: 0.168755  [57600/69947]
loss: 0.096425  [64000/69947]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.105255 

Epoch 50
-------------------------------
loss: 0.110419  [    0/69947]
loss: 0.124333  [ 6400/69947]
loss: 0.148148  [12800/69947]
loss: 0.059956  [19200/69947]
loss: 0.115389  [25600/69947]
loss: 0.067192  [32000/69947]
loss: 0.117735  [38400/69947]
loss: 0.179818  [44800/69947]
loss: 0.044237  [51200/69947]
loss: 0.035528  [57600/69947]
loss: 0.058113  [64000/69947]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.117911 

Epoch 1
-------------------------------
loss: 0.654365  [    0/70031]
loss: 0.213424  [ 6400/70031]
loss: 0.121482  [12800/70031]
loss: 0.175125  [19200/70031]
loss: 0.159930  [25600/70031]
loss: 0.108569  [32000/70031]
loss: 0.184817  [38400/70031]
loss: 0.256139  [44800/70031]
loss: 0.190808  [51200/70031]
loss: 0.315022  [57600/70031]
loss: 0.085228  [64000/70031]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.133750 

Epoch 2
-------------------------------
loss: 0.242081  [    0/70031]
loss: 0.172774  [ 6400/70031]
loss: 0.129839  [12800/70031]
loss: 0.155082  [19200/70031]
loss: 0.158394  [25600/70031]
loss: 0.076099  [32000/70031]
loss: 0.167150  [38400/70031]
loss: 0.155486  [44800/70031]
loss: 0.139027  [51200/70031]
loss: 0.238983  [57600/70031]
loss: 0.279628  [64000/70031]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.140854 

Epoch 3
-------------------------------
loss: 0.192008  [    0/70031]
loss: 0.104580  [ 6400/70031]
loss: 0.188854  [12800/70031]
loss: 0.095189  [19200/70031]
loss: 0.113537  [25600/70031]
loss: 0.199698  [32000/70031]
loss: 0.189363  [38400/70031]
loss: 0.148957  [44800/70031]
loss: 0.166985  [51200/70031]
loss: 0.220277  [57600/70031]
loss: 0.058032  [64000/70031]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.116845 

Epoch 4
-------------------------------
loss: 0.112891  [    0/70031]
loss: 0.153983  [ 6400/70031]
loss: 0.144570  [12800/70031]
loss: 0.062126  [19200/70031]
loss: 0.058229  [25600/70031]
loss: 0.103111  [32000/70031]
loss: 0.147400  [38400/70031]
loss: 0.205594  [44800/70031]
loss: 0.153443  [51200/70031]
loss: 0.111981  [57600/70031]
loss: 0.165424  [64000/70031]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.116572 

Epoch 5
-------------------------------
loss: 0.091523  [    0/70031]
loss: 0.148999  [ 6400/70031]
loss: 0.061796  [12800/70031]
loss: 0.264540  [19200/70031]
loss: 0.101052  [25600/70031]
loss: 0.014647  [32000/70031]
loss: 0.100589  [38400/70031]
loss: 0.091159  [44800/70031]
loss: 0.117192  [51200/70031]
loss: 0.078728  [57600/70031]
loss: 0.105629  [64000/70031]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.116366 

Epoch 6
-------------------------------
loss: 0.076616  [    0/70031]
loss: 0.057269  [ 6400/70031]
loss: 0.032523  [12800/70031]
loss: 0.088902  [19200/70031]
loss: 0.091050  [25600/70031]
loss: 0.094087  [32000/70031]
loss: 0.140443  [38400/70031]
loss: 0.159156  [44800/70031]
loss: 0.191577  [51200/70031]
loss: 0.126722  [57600/70031]
loss: 0.090215  [64000/70031]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110974 

Epoch 7
-------------------------------
loss: 0.137218  [    0/70031]
loss: 0.109955  [ 6400/70031]
loss: 0.073200  [12800/70031]
loss: 0.130893  [19200/70031]
loss: 0.145332  [25600/70031]
loss: 0.090759  [32000/70031]
loss: 0.072811  [38400/70031]
loss: 0.096410  [44800/70031]
loss: 0.136463  [51200/70031]
loss: 0.082587  [57600/70031]
loss: 0.122328  [64000/70031]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.163695 

Epoch 1
-------------------------------
loss: 0.694912  [    0/72262]
loss: 0.071184  [ 6400/72262]
loss: 0.052047  [12800/72262]
loss: 0.092515  [19200/72262]
loss: 0.067099  [25600/72262]
loss: 0.074931  [32000/72262]
loss: 0.164995  [38400/72262]
loss: 0.085459  [44800/72262]
loss: 0.061567  [51200/72262]
loss: 0.051522  [57600/72262]
loss: 0.080163  [64000/72262]
loss: 0.016206  [70400/72262]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.066858 

Epoch 2
-------------------------------
loss: 0.077599  [    0/72262]
loss: 0.215586  [ 6400/72262]
loss: 0.011443  [12800/72262]
loss: 0.071051  [19200/72262]
loss: 0.078354  [25600/72262]
loss: 0.138545  [32000/72262]
loss: 0.069769  [38400/72262]
loss: 0.055581  [44800/72262]
loss: 0.031364  [51200/72262]
loss: 0.076737  [57600/72262]
loss: 0.083987  [64000/72262]
loss: 0.030174  [70400/72262]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.060685 

Epoch 3
-------------------------------
loss: 0.037028  [    0/72262]
loss: 0.085576  [ 6400/72262]
loss: 0.015183  [12800/72262]
loss: 0.035615  [19200/72262]
loss: 0.039746  [25600/72262]
loss: 0.100159  [32000/72262]
loss: 0.043410  [38400/72262]
loss: 0.023836  [44800/72262]
loss: 0.036865  [51200/72262]
loss: 0.112762  [57600/72262]
loss: 0.071157  [64000/72262]
loss: 0.268229  [70400/72262]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.050619 

Epoch 4
-------------------------------
loss: 0.013857  [    0/72262]
loss: 0.029993  [ 6400/72262]
loss: 0.089821  [12800/72262]
loss: 0.043423  [19200/72262]
loss: 0.017637  [25600/72262]
loss: 0.033104  [32000/72262]
loss: 0.034551  [38400/72262]
loss: 0.021639  [44800/72262]
loss: 0.014859  [51200/72262]
loss: 0.099977  [57600/72262]
loss: 0.133693  [64000/72262]
loss: 0.054683  [70400/72262]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.046485 

Epoch 5
-------------------------------
loss: 0.031548  [    0/72262]
loss: 0.045575  [ 6400/72262]
loss: 0.079637  [12800/72262]
loss: 0.017603  [19200/72262]
loss: 0.015353  [25600/72262]
loss: 0.048756  [32000/72262]
loss: 0.011109  [38400/72262]
loss: 0.023734  [44800/72262]
loss: 0.088075  [51200/72262]
loss: 0.062068  [57600/72262]
loss: 0.029236  [64000/72262]
loss: 0.019427  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.042975 

Epoch 6
-------------------------------
loss: 0.011422  [    0/72262]
loss: 0.034483  [ 6400/72262]
loss: 0.008262  [12800/72262]
loss: 0.027852  [19200/72262]
loss: 0.034041  [25600/72262]
loss: 0.088072  [32000/72262]
loss: 0.040161  [38400/72262]
loss: 0.060472  [44800/72262]
loss: 0.072595  [51200/72262]
loss: 0.019912  [57600/72262]
loss: 0.063486  [64000/72262]
loss: 0.100606  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.046300 

Epoch 7
-------------------------------
loss: 0.038494  [    0/72262]
loss: 0.024034  [ 6400/72262]
loss: 0.010045  [12800/72262]
loss: 0.057914  [19200/72262]
loss: 0.040425  [25600/72262]
loss: 0.060507  [32000/72262]
loss: 0.014778  [38400/72262]
loss: 0.050161  [44800/72262]
loss: 0.008465  [51200/72262]
loss: 0.184358  [57600/72262]
loss: 0.030581  [64000/72262]
loss: 0.027067  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.042475 

Epoch 8
-------------------------------
loss: 0.015921  [    0/72262]
loss: 0.038935  [ 6400/72262]
loss: 0.025326  [12800/72262]
loss: 0.033258  [19200/72262]
loss: 0.184949  [25600/72262]
loss: 0.023799  [32000/72262]
loss: 0.018785  [38400/72262]
loss: 0.044581  [44800/72262]
loss: 0.019298  [51200/72262]
loss: 0.017705  [57600/72262]
loss: 0.011301  [64000/72262]
loss: 0.029847  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.045343 

Epoch 9
-------------------------------
loss: 0.051797  [    0/72262]
loss: 0.033498  [ 6400/72262]
loss: 0.009036  [12800/72262]
loss: 0.124266  [19200/72262]
loss: 0.026748  [25600/72262]
loss: 0.014809  [32000/72262]
loss: 0.016250  [38400/72262]
loss: 0.087535  [44800/72262]
loss: 0.023464  [51200/72262]
loss: 0.027052  [57600/72262]
loss: 0.008721  [64000/72262]
loss: 0.007881  [70400/72262]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.346404 

Epoch 10
-------------------------------
loss: 0.148982  [    0/72262]
loss: 0.060460  [ 6400/72262]
loss: 0.022241  [12800/72262]
loss: 0.063840  [19200/72262]
loss: 0.011636  [25600/72262]
loss: 0.018403  [32000/72262]
loss: 0.024605  [38400/72262]
loss: 0.066675  [44800/72262]
loss: 0.030774  [51200/72262]
loss: 0.006059  [57600/72262]
loss: 0.213003  [64000/72262]
loss: 0.077721  [70400/72262]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.075563 

Epoch 11
-------------------------------
loss: 0.051604  [    0/72262]
loss: 0.080087  [ 6400/72262]
loss: 0.026414  [12800/72262]
loss: 0.010562  [19200/72262]
loss: 0.010953  [25600/72262]
loss: 0.017150  [32000/72262]
loss: 0.031979  [38400/72262]
loss: 0.003886  [44800/72262]
loss: 0.014407  [51200/72262]
loss: 0.022155  [57600/72262]
loss: 0.095596  [64000/72262]
loss: 0.102545  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.042914 

Epoch 12
-------------------------------
loss: 0.060173  [    0/72262]
loss: 0.012233  [ 6400/72262]
loss: 0.011842  [12800/72262]
loss: 0.042743  [19200/72262]
loss: 0.012690  [25600/72262]
loss: 0.014703  [32000/72262]
loss: 0.110465  [38400/72262]
loss: 0.036438  [44800/72262]
loss: 0.051096  [51200/72262]
loss: 0.045835  [57600/72262]
loss: 0.017371  [64000/72262]
loss: 0.008874  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.057275 

Epoch 13
-------------------------------
loss: 0.016161  [    0/72262]
loss: 0.030874  [ 6400/72262]
loss: 0.015984  [12800/72262]
loss: 0.016850  [19200/72262]
loss: 0.018977  [25600/72262]
loss: 0.003905  [32000/72262]
loss: 0.029028  [38400/72262]
loss: 0.012813  [44800/72262]
loss: 0.097401  [51200/72262]
loss: 0.018310  [57600/72262]
loss: 0.050313  [64000/72262]
loss: 0.042151  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.056784 

Epoch 14
-------------------------------
loss: 0.003246  [    0/72262]
loss: 0.023340  [ 6400/72262]
loss: 0.030238  [12800/72262]
loss: 0.051500  [19200/72262]
loss: 0.002187  [25600/72262]
loss: 0.008268  [32000/72262]
loss: 0.012878  [38400/72262]
loss: 0.067384  [44800/72262]
loss: 0.104087  [51200/72262]
loss: 0.008308  [57600/72262]
loss: 0.000666  [64000/72262]
loss: 0.043901  [70400/72262]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.044789 

Epoch 15
-------------------------------
loss: 0.022873  [    0/72262]
loss: 0.046249  [ 6400/72262]
loss: 0.002369  [12800/72262]
loss: 0.023523  [19200/72262]
loss: 0.004662  [25600/72262]
loss: 0.017952  [32000/72262]
loss: 0.028550  [38400/72262]
loss: 0.034498  [44800/72262]
loss: 0.008897  [51200/72262]
loss: 0.163103  [57600/72262]
loss: 0.030428  [64000/72262]
loss: 0.051518  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.060386 

Epoch 16
-------------------------------
loss: 0.009767  [    0/72262]
loss: 0.024285  [ 6400/72262]
loss: 0.076043  [12800/72262]
loss: 0.011816  [19200/72262]
loss: 0.155642  [25600/72262]
loss: 0.016425  [32000/72262]
loss: 0.048456  [38400/72262]
loss: 0.020884  [44800/72262]
loss: 0.072551  [51200/72262]
loss: 0.049422  [57600/72262]
loss: 0.014018  [64000/72262]
loss: 0.051833  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.049686 

Epoch 17
-------------------------------
loss: 0.037983  [    0/72262]
loss: 0.105833  [ 6400/72262]
loss: 0.000395  [12800/72262]
loss: 0.005870  [19200/72262]
loss: 0.001090  [25600/72262]
loss: 0.032858  [32000/72262]
loss: 0.048301  [38400/72262]
loss: 0.002579  [44800/72262]
loss: 0.189501  [51200/72262]
loss: 0.011061  [57600/72262]
loss: 0.024310  [64000/72262]
loss: 0.031147  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.077870 

Epoch 18
-------------------------------
loss: 0.007802  [    0/72262]
loss: 0.112730  [ 6400/72262]
loss: 0.003402  [12800/72262]
loss: 0.093730  [19200/72262]
loss: 0.056181  [25600/72262]
loss: 0.027315  [32000/72262]
loss: 0.015581  [38400/72262]
loss: 0.068937  [44800/72262]
loss: 0.008307  [51200/72262]
loss: 0.010568  [57600/72262]
loss: 0.065800  [64000/72262]
loss: 0.058886  [70400/72262]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:53:14 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 19:54:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.098954 

Epoch 1
-------------------------------
loss: 0.661705  [    0/70717]
loss: 0.201540  [ 6400/70717]
loss: 0.209542  [12800/70717]
loss: 0.116389  [19200/70717]
loss: 0.128792  [25600/70717]
loss: 0.247401  [32000/70717]
loss: 0.142162  [38400/70717]
loss: 0.078299  [44800/70717]
loss: 0.117344  [51200/70717]
loss: 0.241854  [57600/70717]
loss: 0.166178  [64000/70717]
loss: 0.111732  [70400/70717]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.156483 

Epoch 2
-------------------------------
loss: 0.212734  [    0/70717]
loss: 0.136443  [ 6400/70717]
loss: 0.119234  [12800/70717]
loss: 0.150766  [19200/70717]
loss: 0.196000  [25600/70717]
loss: 0.114409  [32000/70717]
loss: 0.084350  [38400/70717]
loss: 0.065270  [44800/70717]
loss: 0.071593  [51200/70717]
loss: 0.131741  [57600/70717]
loss: 0.197689  [64000/70717]
loss: 0.169784  [70400/70717]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.126922 

Epoch 3
-------------------------------
loss: 0.057294  [    0/70717]
loss: 0.072697  [ 6400/70717]
loss: 0.139170  [12800/70717]
loss: 0.154130  [19200/70717]
loss: 0.235328  [25600/70717]
loss: 0.083096  [32000/70717]
loss: 0.132301  [38400/70717]
loss: 0.113166  [44800/70717]
loss: 0.117778  [51200/70717]
loss: 0.267776  [57600/70717]
loss: 0.151741  [64000/70717]
loss: 0.145051  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.119175 

Epoch 4
-------------------------------
loss: 0.144105  [    0/70717]
loss: 0.135845  [ 6400/70717]
loss: 0.134828  [12800/70717]
loss: 0.066863  [19200/70717]
loss: 0.105833  [25600/70717]
loss: 0.063095  [32000/70717]
loss: 0.249977  [38400/70717]
loss: 0.090099  [44800/70717]
loss: 0.070605  [51200/70717]
loss: 0.161832  [57600/70717]
loss: 0.148419  [64000/70717]
loss: 0.073871  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.116413 

Epoch 5
-------------------------------
loss: 0.049410  [    0/70717]
loss: 0.157054  [ 6400/70717]
loss: 0.139028  [12800/70717]
loss: 0.201052  [19200/70717]
loss: 0.110483  [25600/70717]
loss: 0.140042  [32000/70717]
loss: 0.073043  [38400/70717]
loss: 0.100921  [44800/70717]
loss: 0.087786  [51200/70717]
loss: 0.179286  [57600/70717]
loss: 0.138619  [64000/70717]
loss: 0.065615  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.123693 

Epoch 6
-------------------------------
loss: 0.118656  [    0/70717]
loss: 0.100705  [ 6400/70717]
loss: 0.034802  [12800/70717]
loss: 0.090265  [19200/70717]
loss: 0.109383  [25600/70717]
loss: 0.100646  [32000/70717]
loss: 0.176465  [38400/70717]
loss: 0.151139  [44800/70717]
loss: 0.071319  [51200/70717]
loss: 0.083789  [57600/70717]
loss: 0.082006  [64000/70717]
loss: 0.090832  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.115719 

Epoch 7
-------------------------------
loss: 0.061166  [    0/70717]
loss: 0.123445  [ 6400/70717]
loss: 0.205207  [12800/70717]
loss: 0.110523  [19200/70717]
loss: 0.040966  [25600/70717]
loss: 0.131885  [32000/70717]
loss: 0.112773  [38400/70717]
loss: 0.065970  [44800/70717]
loss: 0.046981  [51200/70717]
loss: 0.050383  [57600/70717]
loss: 0.091539  [64000/70717]
loss: 0.130191  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112158 

Epoch 8
-------------------------------
loss: 0.054704  [    0/70717]
loss: 0.073441  [ 6400/70717]
loss: 0.093388  [12800/70717]
loss: 0.091247  [19200/70717]
loss: 0.116086  [25600/70717]
loss: 0.164167  [32000/70717]
loss: 0.110366  [38400/70717]
loss: 0.086920  [44800/70717]
loss: 0.129998  [51200/70717]
loss: 0.084682  [57600/70717]
loss: 0.085407  [64000/70717]
loss: 0.049272  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.118435 

Epoch 9
-------------------------------
loss: 0.085656  [    0/70717]
loss: 0.164845  [ 6400/70717]
loss: 0.074109  [12800/70717]
loss: 0.158330  [19200/70717]
loss: 0.130585  [25600/70717]
loss: 0.202334  [32000/70717]
loss: 0.073735  [38400/70717]
loss: 0.099314  [44800/70717]
loss: 0.109576  [51200/70717]
loss: 0.285827  [57600/70717]
loss: 0.090893  [64000/70717]
loss: 0.132116  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.116339 

Epoch 10
-------------------------------
loss: 0.056841  [    0/70717]
loss: 0.135236  [ 6400/70717]
loss: 0.086836  [12800/70717]
loss: 0.055528  [19200/70717]
loss: 0.020836  [25600/70717]
loss: 0.153756  [32000/70717]
loss: 0.147633  [38400/70717]
loss: 0.176528  [44800/70717]
loss: 1.631114  [51200/70717]
loss: 0.118319  [57600/70717]
loss: 0.121699  [64000/70717]
loss: 0.115843  [70400/70717]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.117160 

Epoch 11
-------------------------------
loss: 0.112725  [    0/70717]
loss: 0.133816  [ 6400/70717]
loss: 0.143946  [12800/70717]
loss: 0.100115  [19200/70717]
loss: 0.166363  [25600/70717]
loss: 0.082242  [32000/70717]
loss: 0.089876  [38400/70717]
loss: 0.108265  [44800/70717]
loss: 0.104352  [51200/70717]
loss: 0.171001  [57600/70717]
loss: 0.109008  [64000/70717]
loss: 0.139615  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.114803 

Epoch 12
-------------------------------
loss: 0.132429  [    0/70717]
loss: 0.071241  [ 6400/70717]
loss: 0.094931  [12800/70717]
loss: 0.206154  [19200/70717]
loss: 0.093259  [25600/70717]
loss: 0.115445  [32000/70717]
loss: 0.151002  [38400/70717]
loss: 0.092429  [44800/70717]
loss: 0.017512  [51200/70717]
loss: 0.281276  [57600/70717]
loss: 0.078778  [64000/70717]
loss: 0.156795  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.113143 

Epoch 13
-------------------------------
loss: 0.105719  [    0/70717]
loss: 0.048974  [ 6400/70717]
loss: 0.154150  [12800/70717]
loss: 0.166425  [19200/70717]
loss: 0.086689  [25600/70717]
loss: 0.085406  [32000/70717]
loss: 0.141522  [38400/70717]
loss: 0.175760  [44800/70717]
loss: 0.149477  [51200/70717]
loss: 0.144135  [57600/70717]
loss: 0.072506  [64000/70717]
loss: 0.172483  [70400/70717]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.128830 

Epoch 14
-------------------------------
loss: 0.110783  [    0/70717]
loss: 0.092991  [ 6400/70717]
loss: 0.090123  [12800/70717]
loss: 0.054169  [19200/70717]
loss: 0.093469  [25600/70717]
loss: 0.052228  [32000/70717]
loss: 0.102690  [38400/70717]
loss: 0.039211  [44800/70717]
loss: 0.035021  [51200/70717]
loss: 0.057535  [57600/70717]
loss: 0.088881  [64000/70717]
loss: 0.129278  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.115109 

Epoch 15
-------------------------------
loss: 0.126705  [    0/70717]
loss: 0.093656  [ 6400/70717]
loss: 0.095100  [12800/70717]
loss: 0.038145  [19200/70717]
loss: 0.091434  [25600/70717]
loss: 0.088079  [32000/70717]
loss: 0.163288  [38400/70717]
loss: 0.063530  [44800/70717]
loss: 0.135648  [51200/70717]
loss: 0.200436  [57600/70717]
loss: 0.081411  [64000/70717]
loss: 0.179813  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.111463 

Epoch 16
-------------------------------
loss: 0.051517  [    0/70717]
loss: 0.162086  [ 6400/70717]
loss: 0.091682  [12800/70717]
loss: 0.049598  [19200/70717]
loss: 0.172063  [25600/70717]
loss: 0.240887  [32000/70717]
loss: 0.060352  [38400/70717]
loss: 0.081397  [44800/70717]
loss: 0.180480  [51200/70717]
loss: 0.108353  [57600/70717]
loss: 0.177853  [64000/70717]
loss: 0.101457  [70400/70717]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.122132 

Epoch 17
-------------------------------
loss: 0.097122  [    0/70717]
loss: 0.036791  [ 6400/70717]
loss: 0.208209  [12800/70717]
loss: 0.167714  [19200/70717]
loss: 0.064272  [25600/70717]
loss: 0.027111  [32000/70717]
loss: 0.149500  [38400/70717]
loss: 0.041947  [44800/70717]
loss: 0.183692  [51200/70717]
loss: 0.295522  [57600/70717]
loss: 0.085075  [64000/70717]
loss: 0.058254  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.114892 

Epoch 18
-------------------------------
loss: 0.048050  [    0/70717]
loss: 0.079947  [ 6400/70717]
loss: 0.143343  [12800/70717]
loss: 0.174573  [19200/70717]
loss: 0.130348  [25600/70717]
loss: 0.056484  [32000/70717]
loss: 0.091803  [38400/70717]
loss: 0.137405  [44800/70717]
loss: 0.091537  [51200/70717]
loss: 0.077875  [57600/70717]
loss: 0.065486  [64000/70717]
loss: 0.052329  [70400/70717]
loss: 0.048316  [38400/71193]
loss: 0.109469  [44800/71193]
loss: 0.099971  [51200/71193]
loss: 0.179017  [57600/71193]
loss: 0.113998  [64000/71193]
loss: 0.111993  [70400/71193]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.134956 

Epoch 40
-------------------------------
loss: 0.136737  [    0/71193]
loss: 0.075731  [ 6400/71193]
loss: 0.070517  [12800/71193]
loss: 0.093887  [19200/71193]
loss: 0.179224  [25600/71193]
loss: 0.107980  [32000/71193]
loss: 0.129221  [38400/71193]
loss: 0.202966  [44800/71193]
loss: 0.162752  [51200/71193]
loss: 0.122912  [57600/71193]
loss: 0.120982  [64000/71193]
loss: 0.075417  [70400/71193]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.152577 

Epoch 41
-------------------------------
loss: 0.107768  [    0/71193]
loss: 0.065600  [ 6400/71193]
loss: 0.138027  [12800/71193]
loss: 0.072957  [19200/71193]
loss: 0.082067  [25600/71193]
loss: 0.098486  [32000/71193]
loss: 0.154431  [38400/71193]
loss: 0.063997  [44800/71193]
loss: 0.144963  [51200/71193]
loss: 0.072769  [57600/71193]
loss: 0.166053  [64000/71193]
loss: 0.120916  [70400/71193]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.129210 

Epoch 42
-------------------------------
loss: 0.043995  [    0/71193]
loss: 0.056171  [ 6400/71193]
loss: 0.165116  [12800/71193]
loss: 0.123861  [19200/71193]
loss: 0.200260  [25600/71193]
loss: 0.131775  [32000/71193]
loss: 0.145407  [38400/71193]
loss: 0.058250  [44800/71193]
loss: 0.068426  [51200/71193]
loss: 0.153136  [57600/71193]
loss: 0.109451  [64000/71193]
loss: 0.148061  [70400/71193]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.129700 

Epoch 43
-------------------------------
loss: 0.079667  [    0/71193]
loss: 0.048006  [ 6400/71193]
loss: 0.091193  [12800/71193]
loss: 0.160184  [19200/71193]
loss: 0.095704  [25600/71193]
loss: 0.058061  [32000/71193]
loss: 0.158727  [38400/71193]
loss: 0.071162  [44800/71193]
loss: 0.161575  [51200/71193]
loss: 0.099043  [57600/71193]
loss: 0.070113  [64000/71193]
loss: 0.057363  [70400/71193]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.135858 

Epoch 44
-------------------------------
loss: 0.086413  [    0/71193]
loss: 0.044355  [ 6400/71193]
loss: 0.130219  [12800/71193]
loss: 0.107817  [19200/71193]
loss: 0.220886  [25600/71193]
loss: 0.096496  [32000/71193]
loss: 0.147544  [38400/71193]
loss: 0.132375  [44800/71193]
loss: 0.081532  [51200/71193]
loss: 0.078867  [57600/71193]
loss: 0.087589  [64000/71193]
loss: 0.077812  [70400/71193]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.130678 

Epoch 45
-------------------------------
loss: 0.089546  [    0/71193]
loss: 0.171608  [ 6400/71193]
loss: 0.121725  [12800/71193]
loss: 0.277074  [19200/71193]
loss: 0.162766  [25600/71193]
loss: 0.160643  [32000/71193]
loss: 0.124885  [38400/71193]
loss: 0.055815  [44800/71193]
loss: 0.077915  [51200/71193]
loss: 0.078526  [57600/71193]
loss: 0.162100  [64000/71193]
loss: 0.144885  [70400/71193]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.143007 

Epoch 46
-------------------------------
loss: 0.130897  [    0/71193]
loss: 0.173137  [ 6400/71193]
loss: 0.075632  [12800/71193]
loss: 0.029506  [19200/71193]
loss: 0.047671  [25600/71193]
loss: 0.061518  [32000/71193]
loss: 0.095792  [38400/71193]
loss: 0.035251  [44800/71193]
loss: 0.081192  [51200/71193]
loss: 0.122843  [57600/71193]
loss: 0.125675  [64000/71193]
loss: 0.217491  [70400/71193]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.139849 

Epoch 47
-------------------------------
loss: 0.054897  [    0/71193]
loss: 0.082604  [ 6400/71193]
loss: 0.129115  [12800/71193]
loss: 0.099879  [19200/71193]
loss: 0.088979  [25600/71193]
loss: 0.064045  [32000/71193]
loss: 0.178108  [38400/71193]
loss: 0.079895  [44800/71193]
loss: 0.041464  [51200/71193]
loss: 0.051804  [57600/71193]
loss: 0.085176  [64000/71193]
loss: 0.212646  [70400/71193]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139462 

Epoch 48
-------------------------------
loss: 0.177036  [    0/71193]
loss: 0.105077  [ 6400/71193]
loss: 0.094814  [12800/71193]
loss: 0.150000  [19200/71193]
loss: 0.147365  [25600/71193]
loss: 0.090394  [32000/71193]
loss: 0.185043  [38400/71193]
loss: 0.168844  [44800/71193]
loss: 0.176421  [51200/71193]
loss: 0.075326  [57600/71193]
loss: 0.129459  [64000/71193]
loss: 0.216608  [70400/71193]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.131396 

Epoch 49
-------------------------------
loss: 0.089180  [    0/71193]
loss: 0.219003  [ 6400/71193]
loss: 0.109279  [12800/71193]
loss: 0.095675  [19200/71193]
loss: 0.116559  [25600/71193]
loss: 0.075164  [32000/71193]
loss: 0.046232  [38400/71193]
loss: 0.081208  [44800/71193]
loss: 0.154849  [51200/71193]
loss: 0.093667  [57600/71193]
loss: 0.233613  [64000/71193]
loss: 0.128162  [70400/71193]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.130127 

Epoch 50
-------------------------------
loss: 0.109554  [    0/71193]
loss: 0.122061  [ 6400/71193]
loss: 0.061109  [12800/71193]
loss: 0.123918  [19200/71193]
loss: 0.050282  [25600/71193]
loss: 0.202385  [32000/71193]
loss: 0.066306  [38400/71193]
loss: 0.141351  [44800/71193]
loss: 0.168756  [51200/71193]
loss: 0.123634  [57600/71193]
loss: 0.059503  [64000/71193]
loss: 0.244957  [70400/71193]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.137829 

Epoch 1
-------------------------------
loss: 0.669846  [    0/69195]
loss: 0.273462  [ 6400/69195]
loss: 0.148060  [12800/69195]
loss: 0.125357  [19200/69195]
loss: 0.332284  [25600/69195]
loss: 0.367171  [32000/69195]
loss: 0.234160  [38400/69195]
loss: 0.125823  [44800/69195]
loss: 0.221161  [51200/69195]
loss: 0.194149  [57600/69195]
loss: 0.283774  [64000/69195]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.187786 

Epoch 2
-------------------------------
loss: 0.250946  [    0/69195]
loss: 0.196938  [ 6400/69195]
loss: 0.170480  [12800/69195]
loss: 0.152072  [19200/69195]
loss: 0.204467  [25600/69195]
loss: 0.143917  [32000/69195]
loss: 0.099094  [38400/69195]
loss: 0.239735  [44800/69195]
loss: 0.183747  [51200/69195]
loss: 0.185151  [57600/69195]
loss: 0.164262  [64000/69195]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.163690 

Epoch 3
-------------------------------
loss: 0.125387  [    0/69195]
loss: 0.117624  [ 6400/69195]
loss: 0.223017  [12800/69195]
loss: 0.189321  [19200/69195]
loss: 0.099159  [25600/69195]
loss: 0.191466  [32000/69195]
loss: 0.117712  [38400/69195]
loss: 0.114462  [44800/69195]
loss: 0.192607  [51200/69195]
loss: 0.101554  [57600/69195]
loss: 0.322093  [64000/69195]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.164287 

Epoch 4
-------------------------------
loss: 0.158110  [    0/69195]
loss: 0.223151  [ 6400/69195]
loss: 0.194215  [12800/69195]
loss: 0.131930  [19200/69195]
loss: 0.242886  [25600/69195]
loss: 0.356209  [32000/69195]
loss: 0.226103  [38400/69195]
loss: 0.237867  [44800/69195]
loss: 0.165802  [51200/69195]
loss: 0.160030  [57600/69195]
loss: 0.087656  [64000/69195]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.146809 

Epoch 5
-------------------------------
loss: 0.171726  [    0/69195]
loss: 0.061619  [ 6400/69195]
loss: 0.095521  [12800/69195]
loss: 0.118043  [19200/69195]
loss: 0.136817  [25600/69195]
loss: 0.182288  [32000/69195]
loss: 0.133341  [38400/69195]
loss: 0.144605  [44800/69195]
loss: 0.227585  [51200/69195]
loss: 0.184533  [57600/69195]
loss: 0.149787  [64000/69195]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.148988 

Epoch 6
-------------------------------
loss: 0.085518  [    0/69195]
loss: 0.083333  [ 6400/69195]
loss: 0.061696  [12800/69195]
loss: 0.054074  [19200/69195]
loss: 0.132098  [25600/69195]
loss: 0.165054  [32000/69195]
loss: 0.078859  [38400/69195]
loss: 0.146378  [44800/69195]
loss: 0.101796  [51200/69195]
loss: 0.297998  [57600/69195]
loss: 0.203979  [64000/69195]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.172617 

Epoch 7
-------------------------------
loss: 0.120805  [    0/69195]
loss: 0.257410  [ 6400/69195]
loss: 0.112459  [12800/69195]
loss: 0.249715  [19200/69195]
loss: 0.145257  [25600/69195]
loss: 0.081303  [32000/69195]
loss: 0.207948  [38400/69195]
loss: 0.139463  [44800/69195]
loss: 0.124235  [51200/69195]
loss: 0.134714  [57600/69195]
loss: 0.152911  [64000/69195]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.152074 

loss: 0.074040  [ 6400/69183]
loss: 0.051886  [12800/69183]
loss: 0.034502  [19200/69183]
loss: 0.136759  [25600/69183]
loss: 0.084449  [32000/69183]
loss: 0.174103  [38400/69183]
loss: 0.062141  [44800/69183]
loss: 0.075193  [51200/69183]
loss: 0.045692  [57600/69183]
loss: 0.227051  [64000/69183]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.133827 

Epoch 48
-------------------------------
loss: 0.118635  [    0/69183]
loss: 0.110206  [ 6400/69183]
loss: 0.074787  [12800/69183]
loss: 0.112100  [19200/69183]
loss: 0.058747  [25600/69183]
loss: 0.138347  [32000/69183]
loss: 0.084111  [38400/69183]
loss: 0.076494  [44800/69183]
loss: 0.237877  [51200/69183]
loss: 0.088976  [57600/69183]
loss: 0.181345  [64000/69183]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.127328 

Epoch 49
-------------------------------
loss: 0.102179  [    0/69183]
loss: 0.070900  [ 6400/69183]
loss: 0.139093  [12800/69183]
loss: 0.139592  [19200/69183]
loss: 0.068602  [25600/69183]
loss: 0.096250  [32000/69183]
loss: 0.126211  [38400/69183]
loss: 0.187423  [44800/69183]
loss: 0.055089  [51200/69183]
loss: 0.049211  [57600/69183]
loss: 0.056282  [64000/69183]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.137216 

Epoch 50
-------------------------------
loss: 0.102992  [    0/69183]
loss: 0.102762  [ 6400/69183]
loss: 0.142396  [12800/69183]
loss: 0.051823  [19200/69183]
loss: 0.076425  [25600/69183]
loss: 0.175091  [32000/69183]
loss: 0.184501  [38400/69183]
loss: 0.051126  [44800/69183]
loss: 0.060131  [51200/69183]
loss: 0.086950  [57600/69183]
loss: 0.088225  [64000/69183]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.121832 

Epoch 1
-------------------------------
loss: 0.665900  [    0/71124]
loss: 0.220501  [ 6400/71124]
loss: 0.278219  [12800/71124]
loss: 0.196411  [19200/71124]
loss: 0.107759  [25600/71124]
loss: 0.178985  [32000/71124]
loss: 0.226100  [38400/71124]
loss: 0.235175  [44800/71124]
loss: 0.143865  [51200/71124]
loss: 0.268730  [57600/71124]
loss: 0.151563  [64000/71124]
loss: 0.115772  [70400/71124]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.163207 

Epoch 2
-------------------------------
loss: 0.118428  [    0/71124]
loss: 0.165428  [ 6400/71124]
loss: 0.196829  [12800/71124]
loss: 0.124311  [19200/71124]
loss: 0.174388  [25600/71124]
loss: 0.253604  [32000/71124]
loss: 0.112203  [38400/71124]
loss: 0.088597  [44800/71124]
loss: 0.139896  [51200/71124]
loss: 0.097496  [57600/71124]
loss: 0.094667  [64000/71124]
loss: 0.116827  [70400/71124]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.157124 

Epoch 3
-------------------------------
loss: 0.159546  [    0/71124]
loss: 0.099131  [ 6400/71124]
loss: 0.138069  [12800/71124]
loss: 0.189211  [19200/71124]
loss: 0.103373  [25600/71124]
loss: 0.099245  [32000/71124]
loss: 0.070372  [38400/71124]
loss: 0.162768  [44800/71124]
loss: 0.158194  [51200/71124]
loss: 0.123655  [57600/71124]
loss: 0.064064  [64000/71124]
loss: 0.062082  [70400/71124]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.141834 

Epoch 4
-------------------------------
loss: 0.068195  [    0/71124]
loss: 0.106024  [ 6400/71124]
loss: 0.066335  [12800/71124]
loss: 0.060847  [19200/71124]
loss: 0.064207  [25600/71124]
loss: 0.100205  [32000/71124]
loss: 0.252705  [38400/71124]
loss: 0.125633  [44800/71124]
loss: 0.110329  [51200/71124]
loss: 0.063233  [57600/71124]
loss: 0.152898  [64000/71124]
loss: 0.093576  [70400/71124]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.137409 

Epoch 5
-------------------------------
loss: 0.126769  [    0/71124]
loss: 0.180703  [ 6400/71124]
loss: 0.114193  [12800/71124]
loss: 0.061195  [19200/71124]
loss: 0.165910  [25600/71124]
loss: 0.104896  [32000/71124]
loss: 0.134534  [38400/71124]
loss: 0.039957  [44800/71124]
loss: 0.080629  [51200/71124]
loss: 0.158004  [57600/71124]
loss: 0.132578  [64000/71124]
loss: 0.078838  [70400/71124]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.130906 

Epoch 6
-------------------------------
loss: 0.106251  [    0/71124]
loss: 0.082624  [ 6400/71124]
loss: 0.150398  [12800/71124]
loss: 0.159892  [19200/71124]
loss: 0.099609  [25600/71124]
loss: 0.145858  [32000/71124]
loss: 0.096071  [38400/71124]
loss: 0.121822  [44800/71124]
loss: 0.137705  [51200/71124]
loss: 0.177180  [57600/71124]
loss: 0.139669  [64000/71124]
loss: 0.212559  [70400/71124]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.125965 

Epoch 7
-------------------------------
loss: 0.192043  [    0/71124]
loss: 0.125452  [ 6400/71124]
loss: 0.132545  [12800/71124]
loss: 0.057782  [19200/71124]
loss: 0.084826  [25600/71124]
loss: 0.254698  [32000/71124]
loss: 0.065577  [38400/71124]
loss: 0.162264  [44800/71124]
loss: 0.238683  [51200/71124]
loss: 0.043631  [57600/71124]
loss: 0.231493  [64000/71124]
loss: 0.053268  [70400/71124]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.126248 

Epoch 8
-------------------------------
loss: 0.127380  [    0/71124]
loss: 0.205504  [ 6400/71124]
loss: 0.047701  [12800/71124]
loss: 0.163020  [19200/71124]
loss: 0.190035  [25600/71124]
loss: 0.099981  [32000/71124]
loss: 0.075830  [38400/71124]
loss: 0.091566  [44800/71124]
loss: 0.130851  [51200/71124]
loss: 0.070439  [57600/71124]
loss: 0.029914  [64000/71124]
loss: 0.027894  [70400/71124]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.125125 

Epoch 9
-------------------------------
loss: 0.069909  [    0/71124]
loss: 0.069812  [ 6400/71124]
loss: 0.189952  [12800/71124]
loss: 0.098898  [19200/71124]
loss: 0.141826  [25600/71124]
loss: 0.269464  [32000/71124]
loss: 0.073359  [38400/71124]
loss: 0.132296  [44800/71124]
loss: 0.095916  [51200/71124]
loss: 0.082052  [57600/71124]
loss: 0.033227  [64000/71124]
loss: 0.236800  [70400/71124]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.122452 

Epoch 10
-------------------------------
loss: 0.131361  [    0/71124]
loss: 0.071809  [ 6400/71124]
loss: 0.040172  [12800/71124]
loss: 0.264678  [19200/71124]
loss: 0.034222  [25600/71124]
loss: 0.118478  [32000/71124]
loss: 0.070472  [38400/71124]
loss: 0.067795  [44800/71124]
loss: 0.130824  [51200/71124]
loss: 0.061212  [57600/71124]
loss: 0.054760  [64000/71124]
loss: 0.155012  [70400/71124]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.116120 

Epoch 11
-------------------------------
loss: 0.104405  [    0/71124]
loss: 0.108638  [ 6400/71124]
loss: 0.087177  [12800/71124]
loss: 0.119570  [19200/71124]
loss: 0.134619  [25600/71124]
loss: 0.080717  [32000/71124]
loss: 0.123577  [38400/71124]
loss: 0.088426  [44800/71124]
loss: 0.105003  [51200/71124]
loss: 0.263308  [57600/71124]
loss: 0.115189  [64000/71124]
loss: 0.028797  [70400/71124]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.126572 

Epoch 12
-------------------------------
loss: 0.048460  [    0/71124]
loss: 0.133434  [ 6400/71124]
loss: 0.119146  [12800/71124]
loss: 0.055339  [19200/71124]
loss: 0.162279  [25600/71124]
loss: 0.093790  [32000/71124]
loss: 0.161271  [38400/71124]
loss: 0.095941  [44800/71124]
loss: 0.035544  [51200/71124]
loss: 0.078184  [57600/71124]
loss: 0.105028  [64000/71124]
loss: 0.211275  [70400/71124]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.121413 

Epoch 13
-------------------------------
loss: 0.105866  [    0/71124]
loss: 0.190295  [ 6400/71124]
loss: 0.083813  [12800/71124]
loss: 0.204755  [19200/71124]
loss: 0.065480  [25600/71124]
loss: 0.065011  [32000/71124]
loss: 0.082185  [38400/71124]
loss: 0.363702  [44800/71124]
loss: 0.107303  [51200/71124]
loss: 0.115373  [57600/71124]
loss: 0.043268  [64000/71124]
loss: 0.033492  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.113020 

Epoch 14
-------------------------------
loss: 0.087204  [    0/71124]
loss: 0.099365  [ 6400/71124]
loss: 0.132993  [12800/71124]
loss: 0.087273  [19200/71124]
loss: 0.273891  [25600/71124]
loss: 0.104356  [32000/71124]
loss: 0.093432  [38400/71124]
loss: 0.086644  [44800/71124]
loss: 0.085360  [51200/71124]
loss: 0.058929  [57600/71124]
loss: 0.118923  [64000/71124]
loss: 0.080630  [70400/71124]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.129086 

Epoch 15
-------------------------------
loss: 0.101078  [    0/71124]
loss: 0.070955  [ 6400/71124]
loss: 0.079682  [12800/71124]
loss: 0.090453  [19200/71124]
loss: 0.233928  [25600/71124]
loss: 0.206900  [32000/71124]
loss: 0.051673  [51200/71801]
loss: 0.025603  [57600/71801]
loss: 0.059768  [64000/71801]
loss: 0.024945  [70400/71801]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.055263 

Epoch 8
-------------------------------
loss: 0.021815  [    0/71801]
loss: 0.211668  [ 6400/71801]
loss: 0.005648  [12800/71801]
loss: 0.105348  [19200/71801]
loss: 0.023149  [25600/71801]
loss: 0.020382  [32000/71801]
loss: 0.083655  [38400/71801]
loss: 0.023373  [44800/71801]
loss: 0.044982  [51200/71801]
loss: 0.006175  [57600/71801]
loss: 0.022565  [64000/71801]
loss: 0.105312  [70400/71801]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.058775 

Epoch 9
-------------------------------
loss: 0.014094  [    0/71801]
loss: 0.036181  [ 6400/71801]
loss: 0.070175  [12800/71801]
loss: 0.063758  [19200/71801]
loss: 0.040295  [25600/71801]
loss: 0.003953  [32000/71801]
loss: 0.041707  [38400/71801]
loss: 0.023794  [44800/71801]
loss: 0.053294  [51200/71801]
loss: 0.010089  [57600/71801]
loss: 0.121550  [64000/71801]
loss: 0.081982  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.051557 

Epoch 10
-------------------------------
loss: 0.016456  [    0/71801]
loss: 0.021487  [ 6400/71801]
loss: 0.099902  [12800/71801]
loss: 0.056748  [19200/71801]
loss: 0.013455  [25600/71801]
loss: 0.029414  [32000/71801]
loss: 0.111539  [38400/71801]
loss: 0.091443  [44800/71801]
loss: 0.026492  [51200/71801]
loss: 0.010990  [57600/71801]
loss: 0.035584  [64000/71801]
loss: 0.015838  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.049553 

Epoch 11
-------------------------------
loss: 0.036505  [    0/71801]
loss: 0.011110  [ 6400/71801]
loss: 0.060475  [12800/71801]
loss: 0.018061  [19200/71801]
loss: 0.009746  [25600/71801]
loss: 0.098970  [32000/71801]
loss: 0.059391  [38400/71801]
loss: 0.043586  [44800/71801]
loss: 0.067521  [51200/71801]
loss: 0.018019  [57600/71801]
loss: 0.004640  [64000/71801]
loss: 0.037208  [70400/71801]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.057063 

Epoch 12
-------------------------------
loss: 0.101959  [    0/71801]
loss: 0.016736  [ 6400/71801]
loss: 0.018717  [12800/71801]
loss: 0.032577  [19200/71801]
loss: 0.038923  [25600/71801]
loss: 0.016642  [32000/71801]
loss: 0.108144  [38400/71801]
loss: 0.042296  [44800/71801]
loss: 0.082345  [51200/71801]
loss: 0.016148  [57600/71801]
loss: 0.066538  [64000/71801]
loss: 0.212423  [70400/71801]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.056261 

Epoch 13
-------------------------------
loss: 0.022950  [    0/71801]
loss: 0.012258  [ 6400/71801]
loss: 0.004855  [12800/71801]
loss: 0.008676  [19200/71801]
loss: 0.029613  [25600/71801]
loss: 0.008074  [32000/71801]
loss: 0.065285  [38400/71801]
loss: 0.125535  [44800/71801]
loss: 0.011172  [51200/71801]
loss: 0.105236  [57600/71801]
loss: 0.011565  [64000/71801]
loss: 0.051518  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.048160 

Epoch 14
-------------------------------
loss: 0.021652  [    0/71801]
loss: 0.024287  [ 6400/71801]
loss: 0.014990  [12800/71801]
loss: 0.022474  [19200/71801]
loss: 0.040230  [25600/71801]
loss: 0.035804  [32000/71801]
loss: 0.028982  [38400/71801]
loss: 0.015616  [44800/71801]
loss: 0.072569  [51200/71801]
loss: 0.183553  [57600/71801]
loss: 0.039884  [64000/71801]
loss: 0.015598  [70400/71801]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.051241 

Epoch 15
-------------------------------
loss: 0.032574  [    0/71801]
loss: 0.005891  [ 6400/71801]
loss: 0.048916  [12800/71801]
loss: 0.052817  [19200/71801]
loss: 0.060427  [25600/71801]
loss: 0.033195  [32000/71801]
loss: 0.045534  [38400/71801]
loss: 0.004857  [44800/71801]
loss: 0.021584  [51200/71801]
loss: 0.033739  [57600/71801]
loss: 0.017900  [64000/71801]
loss: 0.022256  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.050337 

Epoch 16
-------------------------------
loss: 0.055698  [    0/71801]
loss: 0.023622  [ 6400/71801]
loss: 0.043844  [12800/71801]
loss: 0.030551  [19200/71801]
loss: 0.091879  [25600/71801]
loss: 0.031236  [32000/71801]
loss: 0.062411  [38400/71801]
loss: 0.063490  [44800/71801]
loss: 0.006327  [51200/71801]
loss: 0.012264  [57600/71801]
loss: 0.026321  [64000/71801]
loss: 0.081760  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.049855 

Epoch 17
-------------------------------
loss: 0.103492  [    0/71801]
loss: 0.006075  [ 6400/71801]
loss: 0.020786  [12800/71801]
loss: 0.004300  [19200/71801]
loss: 0.012753  [25600/71801]
loss: 0.008929  [32000/71801]
loss: 0.090429  [38400/71801]
loss: 0.082692  [44800/71801]
loss: 0.006993  [51200/71801]
loss: 0.026894  [57600/71801]
loss: 0.008335  [64000/71801]
loss: 0.021651  [70400/71801]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.052961 

Epoch 18
-------------------------------
loss: 0.016068  [    0/71801]
loss: 0.022471  [ 6400/71801]
loss: 0.017562  [12800/71801]
loss: 0.080871  [19200/71801]
loss: 0.180528  [25600/71801]
loss: 0.026809  [32000/71801]
loss: 0.081838  [38400/71801]
loss: 0.032215  [44800/71801]
loss: 0.075793  [51200/71801]
loss: 0.001912  [57600/71801]
loss: 0.013514  [64000/71801]
loss: 0.080925  [70400/71801]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.049645 

Epoch 19
-------------------------------
loss: 0.031867  [    0/71801]
loss: 0.131982  [ 6400/71801]
loss: 0.074041  [12800/71801]
loss: 0.136715  [19200/71801]
loss: 0.006502  [25600/71801]
loss: 0.027303  [32000/71801]
loss: 0.078898  [38400/71801]
loss: 0.041677  [44800/71801]
loss: 0.024291  [51200/71801]
loss: 0.031451  [57600/71801]
loss: 0.028308  [64000/71801]
loss: 0.026034  [70400/71801]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.063109 

Epoch 20
-------------------------------
loss: 0.011827  [    0/71801]
loss: 0.011789  [ 6400/71801]
loss: 0.060526  [12800/71801]
loss: 0.020974  [19200/71801]
loss: 0.020552  [25600/71801]
loss: 0.101301  [32000/71801]
loss: 0.084854  [38400/71801]
loss: 0.036700  [44800/71801]
loss: 0.102715  [51200/71801]
loss: 0.004769  [57600/71801]
loss: 0.098451  [64000/71801]
loss: 0.062979  [70400/71801]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.055059 

Epoch 21
-------------------------------
loss: 0.026439  [    0/71801]
loss: 0.087761  [ 6400/71801]
loss: 0.045381  [12800/71801]
loss: 0.025336  [19200/71801]
loss: 0.016630  [25600/71801]
loss: 0.021030  [32000/71801]
loss: 0.126583  [38400/71801]
loss: 0.018388  [44800/71801]
loss: 0.097563  [51200/71801]
loss: 0.057254  [57600/71801]
loss: 0.030199  [64000/71801]
loss: 0.001678  [70400/71801]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.065550 

Epoch 22
-------------------------------
loss: 0.040756  [    0/71801]
loss: 0.037762  [ 6400/71801]
loss: 0.018541  [12800/71801]
loss: 0.005029  [19200/71801]
loss: 0.009194  [25600/71801]
loss: 0.007508  [32000/71801]
loss: 0.008590  [38400/71801]
loss: 0.014519  [44800/71801]
loss: 0.007988  [51200/71801]
loss: 0.008836  [57600/71801]
loss: 0.001949  [64000/71801]
loss: 0.027986  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.053097 

Epoch 23
-------------------------------
loss: 0.052155  [    0/71801]
loss: 0.025824  [ 6400/71801]
loss: 0.010103  [12800/71801]
loss: 0.014334  [19200/71801]
loss: 0.121606  [25600/71801]
loss: 0.010807  [32000/71801]
loss: 0.036807  [38400/71801]
loss: 0.009849  [44800/71801]
loss: 0.006858  [51200/71801]
loss: 0.018813  [57600/71801]
loss: 0.015839  [64000/71801]
loss: 0.009727  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.050523 

Epoch 24
-------------------------------
loss: 0.071240  [    0/71801]
loss: 0.010303  [ 6400/71801]
loss: 0.042888  [12800/71801]
loss: 0.152752  [19200/71801]
loss: 0.065819  [25600/71801]
loss: 0.023078  [32000/71801]
loss: 0.056240  [38400/71801]
loss: 0.062863  [44800/71801]
loss: 0.009660  [51200/71801]
loss: 0.009177  [57600/71801]
loss: 0.028569  [64000/71801]
loss: 0.116910  [70400/71801]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.062957 

Epoch 25
-------------------------------
loss: 0.049215  [    0/71801]
loss: 0.011778  [ 6400/71801]
loss: 0.070559  [12800/71801]
loss: 0.007787  [19200/71801]
loss: 0.011889  [25600/71801]
loss: 0.007566  [32000/71801]
loss: 0.007819  [38400/71801]
loss: 0.029808  [44800/71801]
loss: 0.013389  [51200/71801]
loss: 0.137657  [44800/71148]
loss: 0.132410  [51200/71148]
loss: 0.075869  [57600/71148]
loss: 0.187034  [64000/71148]
loss: 0.098663  [70400/71148]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.136030 

Epoch 40
-------------------------------
loss: 0.118490  [    0/71148]
loss: 0.065842  [ 6400/71148]
loss: 0.047691  [12800/71148]
loss: 0.084132  [19200/71148]
loss: 0.207179  [25600/71148]
loss: 0.108189  [32000/71148]
loss: 0.133309  [38400/71148]
loss: 0.072207  [44800/71148]
loss: 0.059115  [51200/71148]
loss: 0.212447  [57600/71148]
loss: 0.098359  [64000/71148]
loss: 0.099129  [70400/71148]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.158978 

Epoch 41
-------------------------------
loss: 0.060181  [    0/71148]
loss: 0.099102  [ 6400/71148]
loss: 0.056357  [12800/71148]
loss: 0.112884  [19200/71148]
loss: 0.152671  [25600/71148]
loss: 0.201510  [32000/71148]
loss: 0.102200  [38400/71148]
loss: 0.067044  [44800/71148]
loss: 0.130641  [51200/71148]
loss: 0.088871  [57600/71148]
loss: 0.103716  [64000/71148]
loss: 0.139747  [70400/71148]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139310 

Epoch 42
-------------------------------
loss: 0.078697  [    0/71148]
loss: 0.075500  [ 6400/71148]
loss: 0.044249  [12800/71148]
loss: 0.140240  [19200/71148]
loss: 0.068780  [25600/71148]
loss: 0.110719  [32000/71148]
loss: 0.248576  [38400/71148]
loss: 0.144231  [44800/71148]
loss: 0.071864  [51200/71148]
loss: 0.135484  [57600/71148]
loss: 0.095503  [64000/71148]
loss: 0.127106  [70400/71148]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.139443 

Epoch 43
-------------------------------
loss: 0.084162  [    0/71148]
loss: 0.117401  [ 6400/71148]
loss: 0.153233  [12800/71148]
loss: 0.160462  [19200/71148]
loss: 0.143966  [25600/71148]
loss: 0.121833  [32000/71148]
loss: 0.194655  [38400/71148]
loss: 0.103640  [44800/71148]
loss: 0.117031  [51200/71148]
loss: 0.312839  [57600/71148]
loss: 0.029931  [64000/71148]
loss: 0.153032  [70400/71148]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.137547 

Epoch 44
-------------------------------
loss: 0.164008  [    0/71148]
loss: 0.028783  [ 6400/71148]
loss: 0.101080  [12800/71148]
loss: 0.088288  [19200/71148]
loss: 0.098510  [25600/71148]
loss: 0.069301  [32000/71148]
loss: 0.109646  [38400/71148]
loss: 0.069140  [44800/71148]
loss: 0.081739  [51200/71148]
loss: 0.066246  [57600/71148]
loss: 0.151814  [64000/71148]
loss: 0.197561  [70400/71148]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.147403 

Epoch 45
-------------------------------
loss: 0.080651  [    0/71148]
loss: 0.044009  [ 6400/71148]
loss: 0.097307  [12800/71148]
loss: 0.119342  [19200/71148]
loss: 0.085356  [25600/71148]
loss: 0.125943  [32000/71148]
loss: 0.065865  [38400/71148]
loss: 0.154939  [44800/71148]
loss: 0.271922  [51200/71148]
loss: 0.138505  [57600/71148]
loss: 0.099026  [64000/71148]
loss: 0.202146  [70400/71148]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.143251 

Epoch 46
-------------------------------
loss: 0.158084  [    0/71148]
loss: 0.195982  [ 6400/71148]
loss: 0.072595  [12800/71148]
loss: 0.100057  [19200/71148]
loss: 0.173951  [25600/71148]
loss: 0.155529  [32000/71148]
loss: 0.177629  [38400/71148]
loss: 0.122009  [44800/71148]
loss: 0.117937  [51200/71148]
loss: 0.067603  [57600/71148]
loss: 0.090836  [64000/71148]
loss: 0.121498  [70400/71148]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.148683 

Epoch 47
-------------------------------
loss: 0.175613  [    0/71148]
loss: 0.190002  [ 6400/71148]
loss: 0.191593  [12800/71148]
loss: 0.047127  [19200/71148]
loss: 0.048988  [25600/71148]
loss: 0.102138  [32000/71148]
loss: 0.040953  [38400/71148]
loss: 0.067400  [44800/71148]
loss: 0.108528  [51200/71148]
loss: 0.133560  [57600/71148]
loss: 0.113237  [64000/71148]
loss: 0.066135  [70400/71148]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.149583 

Epoch 48
-------------------------------
loss: 0.048258  [    0/71148]
loss: 0.113045  [ 6400/71148]
loss: 0.071123  [12800/71148]
loss: 0.106707  [19200/71148]
loss: 0.141429  [25600/71148]
loss: 0.029965  [32000/71148]
loss: 0.164952  [38400/71148]
loss: 0.116196  [44800/71148]
loss: 0.126645  [51200/71148]
loss: 0.066795  [57600/71148]
loss: 0.076861  [64000/71148]
loss: 0.010570  [70400/71148]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.137955 

Epoch 49
-------------------------------
loss: 0.122443  [    0/71148]
loss: 0.082528  [ 6400/71148]
loss: 0.064445  [12800/71148]
loss: 0.090114  [19200/71148]
loss: 0.128538  [25600/71148]
loss: 0.081826  [32000/71148]
loss: 0.086476  [38400/71148]
loss: 0.098340  [44800/71148]
loss: 0.080439  [51200/71148]
loss: 0.080420  [57600/71148]
loss: 0.073410  [64000/71148]
loss: 0.227791  [70400/71148]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.136410 

Epoch 50
-------------------------------
loss: 0.033917  [    0/71148]
loss: 0.122899  [ 6400/71148]
loss: 0.053456  [12800/71148]
loss: 0.122178  [19200/71148]
loss: 0.029812  [25600/71148]
loss: 0.112085  [32000/71148]
loss: 0.072102  [38400/71148]
loss: 0.088245  [44800/71148]
loss: 0.141769  [51200/71148]
loss: 0.153924  [57600/71148]
loss: 0.038016  [64000/71148]
loss: 0.101251  [70400/71148]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.137209 

Epoch 1
-------------------------------
loss: 0.651219  [    0/69840]
loss: 0.328712  [ 6400/69840]
loss: 0.293983  [12800/69840]
loss: 0.152928  [19200/69840]
loss: 0.274917  [25600/69840]
loss: 0.148368  [32000/69840]
loss: 0.216449  [38400/69840]
loss: 0.202511  [44800/69840]
loss: 0.169179  [51200/69840]
loss: 0.234440  [57600/69840]
loss: 0.343733  [64000/69840]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.192523 

Epoch 2
-------------------------------
loss: 0.199092  [    0/69840]
loss: 0.211444  [ 6400/69840]
loss: 0.295211  [12800/69840]
loss: 0.337972  [19200/69840]
loss: 0.207773  [25600/69840]
loss: 0.327411  [32000/69840]
loss: 0.213880  [38400/69840]
loss: 0.243786  [44800/69840]
loss: 0.261901  [51200/69840]
loss: 0.161141  [57600/69840]
loss: 0.251418  [64000/69840]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.179495 

Epoch 3
-------------------------------
loss: 0.160985  [    0/69840]
loss: 0.157822  [ 6400/69840]
loss: 0.200180  [12800/69840]
loss: 0.166852  [19200/69840]
loss: 0.262195  [25600/69840]
loss: 0.207063  [32000/69840]
loss: 0.205590  [38400/69840]
loss: 0.204907  [44800/69840]
loss: 0.198072  [51200/69840]
loss: 0.126783  [57600/69840]
loss: 0.136679  [64000/69840]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.185869 

Epoch 4
-------------------------------
loss: 0.200371  [    0/69840]
loss: 0.140378  [ 6400/69840]
loss: 0.202336  [12800/69840]
loss: 0.171812  [19200/69840]
loss: 0.330872  [25600/69840]
loss: 0.104769  [32000/69840]
loss: 0.192421  [38400/69840]
loss: 0.185950  [44800/69840]
loss: 0.195975  [51200/69840]
loss: 0.194052  [57600/69840]
loss: 0.102528  [64000/69840]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.188097 

Epoch 5
-------------------------------
loss: 0.190519  [    0/69840]
loss: 0.171962  [ 6400/69840]
loss: 0.165106  [12800/69840]
loss: 0.157899  [19200/69840]
loss: 0.256131  [25600/69840]
loss: 0.176492  [32000/69840]
loss: 0.266325  [38400/69840]
loss: 0.108390  [44800/69840]
loss: 0.180752  [51200/69840]
loss: 0.204623  [57600/69840]
loss: 0.149639  [64000/69840]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.174585 

Epoch 6
-------------------------------
loss: 0.272905  [    0/69840]
loss: 0.223956  [ 6400/69840]
loss: 0.132833  [12800/69840]
loss: 0.200442  [19200/69840]
loss: 0.303425  [25600/69840]
loss: 0.176777  [32000/69840]
loss: 0.128776  [38400/69840]
loss: 0.117545  [44800/69840]
loss: 0.133060  [51200/69840]
loss: 1.403080  [57600/69840]
loss: 0.216330  [64000/69840]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.160979 

Epoch 7
-------------------------------
loss: 0.091700  [    0/69840]
loss: 0.120108  [ 6400/69840]
loss: 0.138752  [12800/69840]
loss: 0.212904  [19200/69840]
loss: 0.145505  [25600/69840]
loss: 0.124836  [32000/69840]
loss: 0.181991  [38400/69840]
loss: 0.194794  [44800/69840]
loss: 0.109312  [51200/69840]
loss: 0.113127  [57600/69840]
loss: 0.107735  [64000/69840]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.182485 

Epoch 8
-------------------------------
Epoch 36
-------------------------------
loss: 0.127627  [    0/71147]
loss: 0.095373  [ 6400/71147]
loss: 0.211043  [12800/71147]
loss: 0.197295  [19200/71147]
loss: 0.123590  [25600/71147]
loss: 0.125694  [32000/71147]
loss: 0.202386  [38400/71147]
loss: 0.201507  [44800/71147]
loss: 0.106981  [51200/71147]
loss: 0.267906  [57600/71147]
loss: 0.115418  [64000/71147]
loss: 0.059870  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.158283 

Epoch 37
-------------------------------
loss: 0.075792  [    0/71147]
loss: 0.170766  [ 6400/71147]
loss: 0.084113  [12800/71147]
loss: 0.081517  [19200/71147]
loss: 0.207407  [25600/71147]
loss: 0.103694  [32000/71147]
loss: 0.211808  [38400/71147]
loss: 0.149959  [44800/71147]
loss: 0.199635  [51200/71147]
loss: 0.109209  [57600/71147]
loss: 0.279567  [64000/71147]
loss: 0.099975  [70400/71147]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.163736 

Epoch 38
-------------------------------
loss: 0.069253  [    0/71147]
loss: 0.143236  [ 6400/71147]
loss: 0.114954  [12800/71147]
loss: 0.044748  [19200/71147]
loss: 0.087835  [25600/71147]
loss: 0.225380  [32000/71147]
loss: 0.107272  [38400/71147]
loss: 0.154657  [44800/71147]
loss: 0.145938  [51200/71147]
loss: 0.212328  [57600/71147]
loss: 0.129541  [64000/71147]
loss: 0.191698  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.159923 

Epoch 39
-------------------------------
loss: 0.176769  [    0/71147]
loss: 0.132183  [ 6400/71147]
loss: 0.080335  [12800/71147]
loss: 0.159854  [19200/71147]
loss: 0.274673  [25600/71147]
loss: 0.152287  [32000/71147]
loss: 0.125305  [38400/71147]
loss: 0.099956  [44800/71147]
loss: 0.182941  [51200/71147]
loss: 0.224115  [57600/71147]
loss: 0.049378  [64000/71147]
loss: 0.178916  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.166055 

Epoch 40
-------------------------------
loss: 0.125778  [    0/71147]
loss: 0.114040  [ 6400/71147]
loss: 0.097812  [12800/71147]
loss: 0.087368  [19200/71147]
loss: 0.182775  [25600/71147]
loss: 0.117600  [32000/71147]
loss: 0.269209  [38400/71147]
loss: 0.077976  [44800/71147]
loss: 0.172392  [51200/71147]
loss: 0.123160  [57600/71147]
loss: 0.186956  [64000/71147]
loss: 0.132183  [70400/71147]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.170166 

Epoch 41
-------------------------------
loss: 0.186185  [    0/71147]
loss: 0.172946  [ 6400/71147]
loss: 0.195769  [12800/71147]
loss: 0.332319  [19200/71147]
loss: 0.086724  [25600/71147]
loss: 0.236134  [32000/71147]
loss: 0.083693  [38400/71147]
loss: 0.105745  [44800/71147]
loss: 0.156942  [51200/71147]
loss: 0.087408  [57600/71147]
loss: 0.147666  [64000/71147]
loss: 0.157402  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.163116 

Epoch 42
-------------------------------
loss: 0.099575  [    0/71147]
loss: 0.120676  [ 6400/71147]
loss: 0.097098  [12800/71147]
loss: 0.093186  [19200/71147]
loss: 0.117247  [25600/71147]
loss: 0.163285  [32000/71147]
loss: 0.209480  [38400/71147]
loss: 0.149722  [44800/71147]
loss: 0.174400  [51200/71147]
loss: 0.145679  [57600/71147]
loss: 0.191480  [64000/71147]
loss: 0.080208  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157751 

Epoch 43
-------------------------------
loss: 0.140195  [    0/71147]
loss: 0.129230  [ 6400/71147]
loss: 0.044077  [12800/71147]
loss: 0.143220  [19200/71147]
loss: 0.197048  [25600/71147]
loss: 0.133923  [32000/71147]
loss: 0.095165  [38400/71147]
loss: 0.259130  [44800/71147]
loss: 0.145442  [51200/71147]
loss: 0.065792  [57600/71147]
loss: 0.169807  [64000/71147]
loss: 0.057436  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162897 

Epoch 44
-------------------------------
loss: 0.198683  [    0/71147]
loss: 0.098359  [ 6400/71147]
loss: 0.156050  [12800/71147]
loss: 0.140864  [19200/71147]
loss: 0.089468  [25600/71147]
loss: 0.231117  [32000/71147]
loss: 0.158666  [38400/71147]
loss: 0.042614  [44800/71147]
loss: 0.154231  [51200/71147]
loss: 0.106094  [57600/71147]
loss: 0.229224  [64000/71147]
loss: 0.123728  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.160425 

Epoch 45
-------------------------------
loss: 0.071009  [    0/71147]
loss: 0.125723  [ 6400/71147]
loss: 0.101009  [12800/71147]
loss: 0.126484  [19200/71147]
loss: 0.113662  [25600/71147]
loss: 0.096713  [32000/71147]
loss: 0.126316  [38400/71147]
loss: 0.041803  [44800/71147]
loss: 0.068630  [51200/71147]
loss: 0.135173  [57600/71147]
loss: 0.180493  [64000/71147]
loss: 0.110384  [70400/71147]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.165359 

Epoch 46
-------------------------------
loss: 0.084702  [    0/71147]
loss: 0.081577  [ 6400/71147]
loss: 0.220833  [12800/71147]
loss: 0.139333  [19200/71147]
loss: 0.188609  [25600/71147]
loss: 0.090070  [32000/71147]
loss: 0.085556  [38400/71147]
loss: 0.126623  [44800/71147]
loss: 0.168884  [51200/71147]
loss: 0.073672  [57600/71147]
loss: 0.109485  [64000/71147]
loss: 0.120398  [70400/71147]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.162452 

Epoch 47
-------------------------------
loss: 0.069150  [    0/71147]
loss: 0.089751  [ 6400/71147]
loss: 0.087139  [12800/71147]
loss: 0.136046  [19200/71147]
loss: 0.124073  [25600/71147]
loss: 0.194042  [32000/71147]
loss: 0.144990  [38400/71147]
loss: 0.163292  [44800/71147]
loss: 0.329030  [51200/71147]
loss: 0.225421  [57600/71147]
loss: 0.059073  [64000/71147]
loss: 0.178916  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.164162 

Epoch 48
-------------------------------
loss: 0.100596  [    0/71147]
loss: 0.057585  [ 6400/71147]
loss: 0.111055  [12800/71147]
loss: 0.149957  [19200/71147]
loss: 0.128768  [25600/71147]
loss: 0.183042  [32000/71147]
loss: 0.123051  [38400/71147]
loss: 0.084284  [44800/71147]
loss: 0.091402  [51200/71147]
loss: 0.173134  [57600/71147]
loss: 0.121768  [64000/71147]
loss: 0.173221  [70400/71147]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.162195 

Epoch 49
-------------------------------
loss: 0.146651  [    0/71147]
loss: 0.166215  [ 6400/71147]
loss: 0.106407  [12800/71147]
loss: 0.069080  [19200/71147]
loss: 0.128581  [25600/71147]
loss: 0.207545  [32000/71147]
loss: 0.131748  [38400/71147]
loss: 0.116871  [44800/71147]
loss: 0.195772  [51200/71147]
loss: 0.090415  [57600/71147]
loss: 0.153300  [64000/71147]
loss: 0.222232  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.156967 

Epoch 50
-------------------------------
loss: 0.126636  [    0/71147]
loss: 0.105283  [ 6400/71147]
loss: 0.255972  [12800/71147]
loss: 0.136718  [19200/71147]
loss: 0.137184  [25600/71147]
loss: 0.215300  [32000/71147]
loss: 0.119764  [38400/71147]
loss: 0.139450  [44800/71147]
loss: 0.156773  [51200/71147]
loss: 0.133025  [57600/71147]
loss: 0.157157  [64000/71147]
loss: 0.044262  [70400/71147]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.175600 

Epoch 1
-------------------------------
loss: 0.652221  [    0/69642]
loss: 0.228713  [ 6400/69642]
loss: 1.747206  [12800/69642]
loss: 0.128061  [19200/69642]
loss: 0.234362  [25600/69642]
loss: 0.369340  [32000/69642]
loss: 0.369345  [38400/69642]
loss: 0.318025  [44800/69642]
loss: 0.191075  [51200/69642]
loss: 0.174704  [57600/69642]
loss: 0.242870  [64000/69642]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.202677 

Epoch 2
-------------------------------
loss: 0.289618  [    0/69642]
loss: 0.090944  [ 6400/69642]
loss: 0.251220  [12800/69642]
loss: 0.113903  [19200/69642]
loss: 0.261152  [25600/69642]
loss: 0.139007  [32000/69642]
loss: 0.294092  [38400/69642]
loss: 0.110892  [44800/69642]
loss: 0.233892  [51200/69642]
loss: 0.179398  [57600/69642]
loss: 0.192835  [64000/69642]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.172007 

Epoch 3
-------------------------------
loss: 0.176253  [    0/69642]
loss: 0.162180  [ 6400/69642]
loss: 0.240628  [12800/69642]
loss: 0.186337  [19200/69642]
loss: 0.204678  [25600/69642]
loss: 0.168422  [32000/69642]
loss: 0.211960  [38400/69642]
loss: 0.174319  [44800/69642]
loss: 0.192725  [51200/69642]
loss: 0.456496  [57600/69642]
loss: 0.339955  [64000/69642]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.163942 

Epoch 4
-------------------------------
loss: 0.111232  [    0/69642]
loss: 0.271586  [ 6400/69642]
loss: 0.157073  [12800/69642]
loss: 0.093094  [    0/71337]
loss: 0.087835  [ 6400/71337]
loss: 0.067820  [12800/71337]
loss: 0.075614  [19200/71337]
loss: 0.104999  [25600/71337]
loss: 0.103938  [32000/71337]
loss: 0.153457  [38400/71337]
loss: 0.083336  [44800/71337]
loss: 0.067067  [51200/71337]
loss: 0.210958  [57600/71337]
loss: 0.159144  [64000/71337]
loss: 0.115825  [70400/71337]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.119361 

Epoch 5
-------------------------------
loss: 0.101128  [    0/71337]
loss: 0.050048  [ 6400/71337]
loss: 0.156013  [12800/71337]
loss: 0.165906  [19200/71337]
loss: 0.119743  [25600/71337]
loss: 0.039692  [32000/71337]
loss: 0.074801  [38400/71337]
loss: 0.072537  [44800/71337]
loss: 0.055289  [51200/71337]
loss: 0.068482  [57600/71337]
loss: 0.092598  [64000/71337]
loss: 0.127475  [70400/71337]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112233 

Epoch 6
-------------------------------
loss: 0.087887  [    0/71337]
loss: 0.115944  [ 6400/71337]
loss: 0.059516  [12800/71337]
loss: 0.034544  [19200/71337]
loss: 0.116491  [25600/71337]
loss: 0.074140  [32000/71337]
loss: 0.032675  [38400/71337]
loss: 0.162188  [44800/71337]
loss: 0.068281  [51200/71337]
loss: 0.102445  [57600/71337]
loss: 0.087259  [64000/71337]
loss: 0.046929  [70400/71337]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.107805 

Epoch 7
-------------------------------
loss: 0.143265  [    0/71337]
loss: 0.034589  [ 6400/71337]
loss: 0.107160  [12800/71337]
loss: 0.238919  [19200/71337]
loss: 0.112454  [25600/71337]
loss: 0.323395  [32000/71337]
loss: 0.123192  [38400/71337]
loss: 0.128538  [44800/71337]
loss: 0.119993  [51200/71337]
loss: 0.154567  [57600/71337]
loss: 0.180356  [64000/71337]
loss: 0.026746  [70400/71337]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.118915 

Epoch 8
-------------------------------
loss: 0.049289  [    0/71337]
loss: 0.110519  [ 6400/71337]
loss: 0.084616  [12800/71337]
loss: 0.096395  [19200/71337]
loss: 0.150023  [25600/71337]
loss: 0.070298  [32000/71337]
loss: 0.085516  [38400/71337]
loss: 0.075185  [44800/71337]
loss: 0.083636  [51200/71337]
loss: 0.064300  [57600/71337]
loss: 0.139550  [64000/71337]
loss: 0.145025  [70400/71337]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112782 

Epoch 9
-------------------------------
loss: 0.087643  [    0/71337]
loss: 0.038932  [ 6400/71337]
loss: 0.198622  [12800/71337]
loss: 0.125815  [19200/71337]
loss: 0.056296  [25600/71337]
loss: 0.107657  [32000/71337]
loss: 0.114414  [38400/71337]
loss: 0.049919  [44800/71337]
loss: 0.071485  [51200/71337]
loss: 0.097038  [57600/71337]
loss: 0.114017  [64000/71337]
loss: 0.050565  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110104 

Epoch 10
-------------------------------
loss: 0.138844  [    0/71337]
loss: 0.120006  [ 6400/71337]
loss: 0.163905  [12800/71337]
loss: 0.081949  [19200/71337]
loss: 0.067369  [25600/71337]
loss: 0.112486  [32000/71337]
loss: 0.031315  [38400/71337]
loss: 0.071548  [44800/71337]
loss: 0.074368  [51200/71337]
loss: 0.110081  [57600/71337]
loss: 0.055232  [64000/71337]
loss: 0.036203  [70400/71337]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.107095 

Epoch 11
-------------------------------
loss: 0.192886  [    0/71337]
loss: 0.086689  [ 6400/71337]
loss: 0.065478  [12800/71337]
loss: 0.089868  [19200/71337]
loss: 0.072296  [25600/71337]
loss: 0.092548  [32000/71337]
loss: 0.136697  [38400/71337]
loss: 0.058366  [44800/71337]
loss: 0.076642  [51200/71337]
loss: 0.133897  [57600/71337]
loss: 0.097715  [64000/71337]
loss: 0.223664  [70400/71337]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.104335 

Epoch 12
-------------------------------
loss: 0.071587  [    0/71337]
loss: 0.052530  [ 6400/71337]
loss: 0.061107  [12800/71337]
loss: 0.088228  [19200/71337]
loss: 0.057672  [25600/71337]
loss: 0.182518  [32000/71337]
loss: 0.324088  [38400/71337]
loss: 0.207442  [44800/71337]
loss: 0.060206  [51200/71337]
loss: 0.141088  [57600/71337]
loss: 0.046762  [64000/71337]
loss: 0.041269  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.114042 

Epoch 13
-------------------------------
loss: 0.058710  [    0/71337]
loss: 0.057110  [ 6400/71337]
loss: 0.091623  [12800/71337]
loss: 0.081173  [19200/71337]
loss: 0.028382  [25600/71337]
loss: 0.099512  [32000/71337]
loss: 0.057469  [38400/71337]
loss: 0.092895  [44800/71337]
loss: 0.081604  [51200/71337]
loss: 0.028927  [57600/71337]
loss: 0.070891  [64000/71337]
loss: 0.095160  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110168 

Epoch 14
-------------------------------
loss: 0.107859  [    0/71337]
loss: 0.049968  [ 6400/71337]
loss: 0.065973  [12800/71337]
loss: 0.278327  [19200/71337]
loss: 0.078478  [25600/71337]
loss: 0.153895  [32000/71337]
loss: 0.059010  [38400/71337]
loss: 0.043681  [44800/71337]
loss: 0.077649  [51200/71337]
loss: 0.106966  [57600/71337]
loss: 0.054890  [64000/71337]
loss: 0.104884  [70400/71337]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.108762 

Epoch 15
-------------------------------
loss: 0.060803  [    0/71337]
loss: 0.036109  [ 6400/71337]
loss: 0.077440  [12800/71337]
loss: 0.147173  [19200/71337]
loss: 0.100646  [25600/71337]
loss: 0.100477  [32000/71337]
loss: 0.112646  [38400/71337]
loss: 0.096887  [44800/71337]
loss: 0.178249  [51200/71337]
loss: 0.051319  [57600/71337]
loss: 0.172337  [64000/71337]
loss: 0.236218  [70400/71337]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.107217 

Epoch 16
-------------------------------
loss: 0.055596  [    0/71337]
loss: 0.026404  [ 6400/71337]
loss: 0.175649  [12800/71337]
loss: 0.075248  [19200/71337]
loss: 0.045530  [25600/71337]
loss: 0.066272  [32000/71337]
loss: 0.050020  [38400/71337]
loss: 0.048881  [44800/71337]
loss: 0.307017  [51200/71337]
loss: 0.072492  [57600/71337]
loss: 0.071481  [64000/71337]
loss: 0.101634  [70400/71337]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110894 

Epoch 17
-------------------------------
loss: 0.101650  [    0/71337]
loss: 0.030176  [ 6400/71337]
loss: 0.105392  [12800/71337]
loss: 0.040618  [19200/71337]
loss: 0.139779  [25600/71337]
loss: 0.130367  [32000/71337]
loss: 0.088814  [38400/71337]
loss: 0.062583  [44800/71337]
loss: 0.043553  [51200/71337]
loss: 0.061413  [57600/71337]
loss: 0.059477  [64000/71337]
loss: 0.112354  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.114368 

Epoch 18
-------------------------------
loss: 0.064269  [    0/71337]
loss: 0.189818  [ 6400/71337]
loss: 0.035717  [12800/71337]
loss: 0.048086  [19200/71337]
loss: 0.053056  [25600/71337]
loss: 0.141738  [32000/71337]
loss: 0.049049  [38400/71337]
loss: 0.118443  [44800/71337]
loss: 0.051659  [51200/71337]
loss: 0.092736  [57600/71337]
loss: 0.182492  [64000/71337]
loss: 0.057429  [70400/71337]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117173 

Epoch 19
-------------------------------
loss: 0.068475  [    0/71337]
loss: 0.062578  [ 6400/71337]
loss: 0.089314  [12800/71337]
loss: 0.107822  [19200/71337]
loss: 0.047116  [25600/71337]
loss: 0.107156  [32000/71337]
loss: 0.129324  [38400/71337]
loss: 0.078936  [44800/71337]
loss: 0.220684  [51200/71337]
loss: 0.035004  [57600/71337]
loss: 0.130530  [64000/71337]
loss: 0.072393  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.108905 

Epoch 20
-------------------------------
loss: 0.059054  [    0/71337]
loss: 0.029151  [ 6400/71337]
loss: 0.113621  [12800/71337]
loss: 0.072703  [19200/71337]
loss: 0.034004  [25600/71337]
loss: 0.079922  [32000/71337]
loss: 0.108522  [38400/71337]
loss: 0.067572  [44800/71337]
loss: 0.141738  [51200/71337]
loss: 0.077383  [57600/71337]
loss: 0.100362  [64000/71337]
loss: 0.091613  [70400/71337]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.119312 

Epoch 21
-------------------------------
loss: 0.117130  [    0/71337]
loss: 0.078344  [ 6400/71337]
loss: 0.040633  [12800/71337]
loss: 0.037062  [19200/71337]
loss: 0.143044  [25600/71337]
loss: 0.177771  [32000/71337]
loss: 0.067733  [38400/71337]
loss: 0.121872  [44800/71337]
loss: 0.182513  [51200/71337]
loss: 0.098874  [57600/71337]
loss: 0.079225  [64000/71337]
loss: 0.064660  [70400/71337]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.111094 

Epoch 22
-------------------------------
loss: 0.127411  [    0/71337]
/data/sources/eugen/negative-class-optimization/src/NegativeClassOptimization/NegativeClassOptimization/visualisations.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(figsize=(14, 7))
2022/09/20 20:00:10 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.085491  [44800/70632]
loss: 0.108900  [51200/70632]
loss: 0.135472  [57600/70632]
loss: 0.073187  [64000/70632]
loss: 0.040091  [70400/70632]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.103448 

Epoch 48
-------------------------------
loss: 0.068005  [    0/70632]
loss: 0.037238  [ 6400/70632]
loss: 0.061408  [12800/70632]
loss: 0.098889  [19200/70632]
loss: 0.058139  [25600/70632]
loss: 0.191834  [32000/70632]
loss: 0.045951  [38400/70632]
loss: 0.047789  [44800/70632]
loss: 0.062199  [51200/70632]
loss: 0.041861  [57600/70632]
loss: 0.101781  [64000/70632]
loss: 0.160796  [70400/70632]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.107108 

Epoch 49
-------------------------------
loss: 0.126897  [    0/70632]
loss: 0.208684  [ 6400/70632]
loss: 0.077512  [12800/70632]
loss: 0.108098  [19200/70632]
loss: 0.077117  [25600/70632]
loss: 0.090845  [32000/70632]
loss: 0.053862  [38400/70632]
loss: 0.156652  [44800/70632]
loss: 0.125772  [51200/70632]
loss: 0.167795  [57600/70632]
loss: 0.070817  [64000/70632]
loss: 0.163196  [70400/70632]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112219 

Epoch 50
-------------------------------
loss: 0.206433  [    0/70632]
loss: 0.066602  [ 6400/70632]
loss: 0.014860  [12800/70632]
loss: 0.127383  [19200/70632]
loss: 0.052067  [25600/70632]
loss: 0.086500  [32000/70632]
loss: 0.054220  [38400/70632]
loss: 0.152029  [44800/70632]
loss: 0.127215  [51200/70632]
loss: 0.160039  [57600/70632]
loss: 0.099127  [64000/70632]
loss: 0.124106  [70400/70632]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.113813 

Epoch 1
-------------------------------
loss: 0.660877  [    0/70299]
loss: 0.255283  [ 6400/70299]
loss: 0.133690  [12800/70299]
loss: 0.196056  [19200/70299]
loss: 0.213388  [25600/70299]
loss: 0.087245  [32000/70299]
loss: 0.087422  [38400/70299]
loss: 0.205943  [44800/70299]
loss: 0.040507  [51200/70299]
loss: 0.126814  [57600/70299]
loss: 0.073400  [64000/70299]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.124039 

Epoch 2
-------------------------------
loss: 0.071183  [    0/70299]
loss: 0.078428  [ 6400/70299]
loss: 0.142597  [12800/70299]
loss: 0.161941  [19200/70299]
loss: 0.090896  [25600/70299]
loss: 0.186772  [32000/70299]
loss: 0.073680  [38400/70299]
loss: 0.040782  [44800/70299]
loss: 0.083925  [51200/70299]
loss: 0.104064  [57600/70299]
loss: 0.142155  [64000/70299]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.107196 

Epoch 3
-------------------------------
loss: 0.095705  [    0/70299]
loss: 0.046559  [ 6400/70299]
loss: 0.085864  [12800/70299]
loss: 0.070808  [19200/70299]
loss: 0.033305  [25600/70299]
loss: 0.071864  [32000/70299]
loss: 0.069658  [38400/70299]
loss: 0.053381  [44800/70299]
loss: 0.153952  [51200/70299]
loss: 0.113285  [57600/70299]
loss: 0.171371  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.103907 

Epoch 4
-------------------------------
loss: 0.125402  [    0/70299]
loss: 0.085253  [ 6400/70299]
loss: 0.038732  [12800/70299]
loss: 0.190555  [19200/70299]
loss: 0.139070  [25600/70299]
loss: 0.062560  [32000/70299]
loss: 0.137316  [38400/70299]
loss: 0.103224  [44800/70299]
loss: 0.101073  [51200/70299]
loss: 0.072253  [57600/70299]
loss: 0.026539  [64000/70299]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.117035 

Epoch 5
-------------------------------
loss: 0.195899  [    0/70299]
loss: 0.021058  [ 6400/70299]
loss: 0.053482  [12800/70299]
loss: 0.100986  [19200/70299]
loss: 0.071055  [25600/70299]
loss: 0.048366  [32000/70299]
loss: 0.145999  [38400/70299]
loss: 0.113922  [44800/70299]
loss: 0.159415  [51200/70299]
loss: 0.086510  [57600/70299]
loss: 0.051443  [64000/70299]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.102761 

Epoch 6
-------------------------------
loss: 1.611572  [    0/70299]
loss: 0.116949  [ 6400/70299]
loss: 0.108001  [12800/70299]
loss: 0.145073  [19200/70299]
loss: 0.043854  [25600/70299]
loss: 0.029973  [32000/70299]
loss: 0.038812  [38400/70299]
loss: 0.153687  [44800/70299]
loss: 0.095849  [51200/70299]
loss: 0.094061  [57600/70299]
loss: 0.112786  [64000/70299]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.129733 

Epoch 7
-------------------------------
loss: 0.087634  [    0/70299]
loss: 0.137875  [ 6400/70299]
loss: 0.066164  [12800/70299]
loss: 0.109111  [19200/70299]
loss: 0.054367  [25600/70299]
loss: 0.129174  [32000/70299]
loss: 0.059780  [38400/70299]
loss: 0.068903  [44800/70299]
loss: 0.076148  [51200/70299]
loss: 0.089385  [57600/70299]
loss: 0.033278  [64000/70299]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.095528 

Epoch 8
-------------------------------
loss: 0.141187  [    0/70299]
loss: 0.155823  [ 6400/70299]
loss: 0.119059  [12800/70299]
loss: 0.180225  [19200/70299]
loss: 0.062915  [25600/70299]
loss: 0.027519  [32000/70299]
loss: 0.069546  [38400/70299]
loss: 0.051226  [44800/70299]
loss: 0.137699  [51200/70299]
loss: 0.103179  [57600/70299]
loss: 0.070383  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.099471 

Epoch 9
-------------------------------
loss: 0.040206  [    0/70299]
loss: 0.096167  [ 6400/70299]
loss: 0.055504  [12800/70299]
loss: 0.110909  [19200/70299]
loss: 0.021836  [25600/70299]
loss: 0.096693  [32000/70299]
loss: 0.044078  [38400/70299]
loss: 0.060326  [44800/70299]
loss: 0.117916  [51200/70299]
loss: 0.119932  [57600/70299]
loss: 0.128643  [64000/70299]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.097437 

Epoch 10
-------------------------------
loss: 0.120214  [    0/70299]
loss: 0.102371  [ 6400/70299]
loss: 0.060360  [12800/70299]
loss: 0.214282  [19200/70299]
loss: 0.128617  [25600/70299]
loss: 0.153629  [32000/70299]
loss: 0.087235  [38400/70299]
loss: 0.145781  [44800/70299]
loss: 0.050052  [51200/70299]
loss: 0.081720  [57600/70299]
loss: 0.190863  [64000/70299]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.113627 

Epoch 11
-------------------------------
loss: 0.084149  [    0/70299]
loss: 0.121506  [ 6400/70299]
loss: 0.087200  [12800/70299]
loss: 0.042108  [19200/70299]
loss: 0.123690  [25600/70299]
loss: 0.206543  [32000/70299]
loss: 0.019017  [38400/70299]
loss: 0.211964  [44800/70299]
loss: 0.079157  [51200/70299]
loss: 0.009276  [57600/70299]
loss: 0.047071  [64000/70299]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.095467 

Epoch 12
-------------------------------
loss: 0.092644  [    0/70299]
loss: 0.033556  [ 6400/70299]
loss: 0.157563  [12800/70299]
loss: 0.036871  [19200/70299]
loss: 0.213626  [25600/70299]
loss: 0.094174  [32000/70299]
loss: 0.106310  [38400/70299]
loss: 0.074877  [44800/70299]
loss: 0.131291  [51200/70299]
loss: 0.083198  [57600/70299]
loss: 0.118862  [64000/70299]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.097744 

Epoch 13
-------------------------------
loss: 0.083803  [    0/70299]
loss: 0.017267  [ 6400/70299]
loss: 0.057041  [12800/70299]
loss: 0.035440  [19200/70299]
loss: 0.074158  [25600/70299]
loss: 0.158729  [32000/70299]
loss: 0.048674  [38400/70299]
loss: 0.097504  [44800/70299]
loss: 0.099072  [51200/70299]
loss: 0.159077  [57600/70299]
loss: 0.040811  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.104115 

Epoch 14
-------------------------------
loss: 0.053640  [    0/70299]
loss: 0.044039  [ 6400/70299]
loss: 0.082094  [12800/70299]
loss: 0.038887  [19200/70299]
loss: 0.038867  [25600/70299]
loss: 0.248104  [32000/70299]
loss: 0.148017  [38400/70299]
loss: 0.026116  [44800/70299]
loss: 0.072638  [51200/70299]
loss: 0.043270  [57600/70299]
loss: 0.138676  [64000/70299]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.096987 

Epoch 15
-------------------------------
loss: 0.048923  [    0/70299]
loss: 0.075168  [ 6400/70299]
loss: 0.150320  [12800/70299]
loss: 0.044833  [19200/70299]
loss: 0.063991  [25600/70299]
loss: 0.107862  [32000/70299]
loss: 0.143091  [38400/70299]
loss: 0.031106  [44800/70299]
loss: 0.042232  [51200/70299]
loss: 0.064799  [57600/70299]
loss: 0.083568  [64000/70299]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.098140 

Epoch 16
-------------------------------
loss: 0.059236  [    0/70299]
loss: 0.089365  [ 6400/70299]
loss: 0.045102  [12800/70299]
loss: 0.047014  [19200/70299]
loss: 0.050985  [25600/70299]
loss: 0.180132  [32000/70299]
loss: 0.035808  [38400/70299]
loss: 0.075166  [44800/70299]
loss: 0.048289  [70400/71103]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.105337 

Epoch 1
-------------------------------
loss: 0.698436  [    0/69766]
loss: 0.240555  [ 6400/69766]
loss: 0.224008  [12800/69766]
loss: 0.195056  [19200/69766]
loss: 0.163517  [25600/69766]
loss: 0.168184  [32000/69766]
loss: 0.192000  [38400/69766]
loss: 0.205264  [44800/69766]
loss: 0.121185  [51200/69766]
loss: 0.122544  [57600/69766]
loss: 0.108814  [64000/69766]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.185221 

Epoch 2
-------------------------------
loss: 0.077605  [    0/69766]
loss: 0.213971  [ 6400/69766]
loss: 0.250749  [12800/69766]
loss: 0.096064  [19200/69766]
loss: 0.181949  [25600/69766]
loss: 0.152528  [32000/69766]
loss: 0.298367  [38400/69766]
loss: 0.119590  [44800/69766]
loss: 0.203970  [51200/69766]
loss: 0.234586  [57600/69766]
loss: 0.154742  [64000/69766]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.174793 

Epoch 3
-------------------------------
loss: 0.151997  [    0/69766]
loss: 0.148738  [ 6400/69766]
loss: 0.121500  [12800/69766]
loss: 0.143397  [19200/69766]
loss: 1.666021  [25600/69766]
loss: 0.152612  [32000/69766]
loss: 0.087080  [38400/69766]
loss: 0.066379  [44800/69766]
loss: 0.162750  [51200/69766]
loss: 0.186164  [57600/69766]
loss: 0.084951  [64000/69766]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.145345 

Epoch 4
-------------------------------
loss: 0.101504  [    0/69766]
loss: 0.096786  [ 6400/69766]
loss: 0.111180  [12800/69766]
loss: 0.183563  [19200/69766]
loss: 0.128792  [25600/69766]
loss: 0.104892  [32000/69766]
loss: 0.127627  [38400/69766]
loss: 0.118911  [44800/69766]
loss: 0.126739  [51200/69766]
loss: 0.136425  [57600/69766]
loss: 0.125559  [64000/69766]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.141856 

Epoch 5
-------------------------------
loss: 0.041345  [    0/69766]
loss: 0.127808  [ 6400/69766]
loss: 0.159886  [12800/69766]
loss: 0.078143  [19200/69766]
loss: 0.098293  [25600/69766]
loss: 0.196661  [32000/69766]
loss: 0.196620  [38400/69766]
loss: 0.140764  [44800/69766]
loss: 0.116327  [51200/69766]
loss: 0.151142  [57600/69766]
loss: 0.121531  [64000/69766]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.135421 

Epoch 6
-------------------------------
loss: 0.075208  [    0/69766]
loss: 0.118195  [ 6400/69766]
loss: 0.065019  [12800/69766]
loss: 0.182410  [19200/69766]
loss: 0.113267  [25600/69766]
loss: 0.102900  [32000/69766]
loss: 0.221073  [38400/69766]
loss: 0.191176  [44800/69766]
loss: 0.081909  [51200/69766]
loss: 0.178155  [57600/69766]
loss: 0.106474  [64000/69766]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.164752 

Epoch 7
-------------------------------
loss: 0.077352  [    0/69766]
loss: 0.153443  [ 6400/69766]
loss: 0.066903  [12800/69766]
loss: 0.062344  [19200/69766]
loss: 0.119685  [25600/69766]
loss: 0.132708  [32000/69766]
loss: 0.203414  [38400/69766]
loss: 0.098409  [44800/69766]
loss: 0.054573  [51200/69766]
loss: 0.087907  [57600/69766]
loss: 0.084929  [64000/69766]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.139754 

Epoch 8
-------------------------------
loss: 0.062427  [    0/69766]
loss: 0.222070  [ 6400/69766]
loss: 0.051202  [12800/69766]
loss: 0.096607  [19200/69766]
loss: 0.062851  [25600/69766]
loss: 0.145485  [32000/69766]
loss: 0.204968  [38400/69766]
loss: 0.117227  [44800/69766]
loss: 0.032543  [51200/69766]
loss: 0.121097  [57600/69766]
loss: 0.169851  [64000/69766]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.136279 

Epoch 9
-------------------------------
loss: 0.038983  [    0/69766]
loss: 0.136754  [ 6400/69766]
loss: 0.033405  [12800/69766]
loss: 0.099992  [19200/69766]
loss: 0.090963  [25600/69766]
loss: 0.139681  [32000/69766]
loss: 0.110703  [38400/69766]
loss: 0.217931  [44800/69766]
loss: 0.181384  [51200/69766]
loss: 0.124168  [57600/69766]
loss: 0.055130  [64000/69766]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.128719 

Epoch 10
-------------------------------
loss: 0.089170  [    0/69766]
loss: 0.079108  [ 6400/69766]
loss: 0.202968  [12800/69766]
loss: 0.097274  [19200/69766]
loss: 0.129939  [25600/69766]
loss: 0.159877  [32000/69766]
loss: 0.100478  [38400/69766]
loss: 0.096066  [44800/69766]
loss: 0.176282  [51200/69766]
loss: 0.100696  [57600/69766]
loss: 0.090276  [64000/69766]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.137139 

Epoch 11
-------------------------------
loss: 0.150860  [    0/69766]
loss: 0.062737  [ 6400/69766]
loss: 0.080655  [12800/69766]
loss: 0.108203  [19200/69766]
loss: 0.112293  [25600/69766]
loss: 0.160893  [32000/69766]
loss: 0.120618  [38400/69766]
loss: 0.072049  [44800/69766]
loss: 0.061480  [51200/69766]
loss: 0.094817  [57600/69766]
loss: 0.052348  [64000/69766]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.137035 

Epoch 12
-------------------------------
loss: 0.042220  [    0/69766]
loss: 0.200966  [ 6400/69766]
loss: 0.140983  [12800/69766]
loss: 0.195510  [19200/69766]
loss: 0.114232  [25600/69766]
loss: 0.099002  [32000/69766]
loss: 0.057036  [38400/69766]
loss: 0.060089  [44800/69766]
loss: 0.031990  [51200/69766]
loss: 0.113003  [57600/69766]
loss: 0.068354  [64000/69766]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.140635 

Epoch 13
-------------------------------
loss: 0.117254  [    0/69766]
loss: 0.100861  [ 6400/69766]
loss: 0.083713  [12800/69766]
loss: 0.089441  [19200/69766]
loss: 0.107631  [25600/69766]
loss: 0.154941  [32000/69766]
loss: 0.185087  [38400/69766]
loss: 0.076300  [44800/69766]
loss: 0.212305  [51200/69766]
loss: 0.205311  [57600/69766]
loss: 0.082425  [64000/69766]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.128851 

Epoch 14
-------------------------------
loss: 0.088564  [    0/69766]
loss: 0.181817  [ 6400/69766]
loss: 0.077779  [12800/69766]
loss: 0.086540  [19200/69766]
loss: 0.094137  [25600/69766]
loss: 0.102414  [32000/69766]
loss: 0.062813  [38400/69766]
loss: 0.166040  [44800/69766]
loss: 0.160952  [51200/69766]
loss: 0.033215  [57600/69766]
loss: 0.082773  [64000/69766]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.134276 

Epoch 15
-------------------------------
loss: 0.123495  [    0/69766]
loss: 0.024128  [ 6400/69766]
loss: 0.079060  [12800/69766]
loss: 0.064074  [19200/69766]
loss: 0.098926  [25600/69766]
loss: 0.110363  [32000/69766]
loss: 0.061715  [38400/69766]
loss: 0.178144  [44800/69766]
loss: 0.140703  [51200/69766]
loss: 0.255622  [57600/69766]
loss: 0.061231  [64000/69766]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.140100 

Epoch 16
-------------------------------
loss: 1.640463  [    0/69766]
loss: 0.067138  [ 6400/69766]
loss: 0.169066  [12800/69766]
loss: 0.088647  [19200/69766]
loss: 0.107111  [25600/69766]
loss: 0.172094  [32000/69766]
loss: 0.171646  [38400/69766]
loss: 0.233254  [44800/69766]
loss: 0.118543  [51200/69766]
loss: 0.092485  [57600/69766]
loss: 0.187397  [64000/69766]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.130439 

Epoch 17
-------------------------------
loss: 0.063086  [    0/69766]
loss: 0.147591  [ 6400/69766]
loss: 0.049691  [12800/69766]
loss: 0.153604  [19200/69766]
loss: 0.064574  [25600/69766]
loss: 0.106026  [32000/69766]
loss: 0.120063  [38400/69766]
loss: 0.116786  [44800/69766]
loss: 0.026568  [51200/69766]
loss: 0.078438  [57600/69766]
loss: 0.159177  [64000/69766]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.134687 

Epoch 18
-------------------------------
loss: 0.054771  [    0/69766]
loss: 0.112585  [ 6400/69766]
loss: 0.049955  [12800/69766]
loss: 0.207845  [19200/69766]
loss: 0.139482  [25600/69766]
loss: 0.127028  [32000/69766]
loss: 0.084491  [38400/69766]
loss: 0.184282  [44800/69766]
loss: 0.160526  [51200/69766]
loss: 0.186457  [57600/69766]
loss: 0.278690  [64000/69766]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.142208 

Epoch 19
-------------------------------
loss: 0.115263  [    0/69766]
loss: 0.127843  [ 6400/69766]
loss: 0.145320  [12800/69766]
loss: 1.629267  [19200/69766]
loss: 0.096947  [25600/69766]
loss: 0.299008  [32000/69766]
loss: 0.066808  [38400/69766]
loss: 0.058054  [44800/69766]
loss: 0.105175  [51200/69766]
loss: 0.122184  [57600/69766]
loss: 0.074694  [64000/69766]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.152053 

Epoch 20
-------------------------------
loss: 0.096756  [    0/69766]
loss: 0.095556  [51200/71250]
loss: 0.144516  [57600/71250]
loss: 0.084701  [64000/71250]
loss: 0.062608  [70400/71250]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.100666 

Epoch 8
-------------------------------
loss: 0.136427  [    0/71250]
loss: 0.123728  [ 6400/71250]
loss: 0.041309  [12800/71250]
loss: 0.129618  [19200/71250]
loss: 0.027871  [25600/71250]
loss: 0.066710  [32000/71250]
loss: 0.116108  [38400/71250]
loss: 0.060322  [44800/71250]
loss: 0.075834  [51200/71250]
loss: 0.032460  [57600/71250]
loss: 0.065204  [64000/71250]
loss: 0.073879  [70400/71250]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.097613 

Epoch 9
-------------------------------
loss: 0.028136  [    0/71250]
loss: 0.090453  [ 6400/71250]
loss: 0.135051  [12800/71250]
loss: 0.160281  [19200/71250]
loss: 0.064257  [25600/71250]
loss: 0.167681  [32000/71250]
loss: 0.050140  [38400/71250]
loss: 0.064734  [44800/71250]
loss: 0.115664  [51200/71250]
loss: 0.086450  [57600/71250]
loss: 0.193068  [64000/71250]
loss: 0.086884  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.100293 

Epoch 10
-------------------------------
loss: 0.053239  [    0/71250]
loss: 0.104886  [ 6400/71250]
loss: 0.097788  [12800/71250]
loss: 0.060328  [19200/71250]
loss: 0.061293  [25600/71250]
loss: 0.178400  [32000/71250]
loss: 0.059054  [38400/71250]
loss: 0.148834  [44800/71250]
loss: 0.238340  [51200/71250]
loss: 0.016962  [57600/71250]
loss: 0.084732  [64000/71250]
loss: 0.061653  [70400/71250]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.095853 

Epoch 11
-------------------------------
loss: 0.091947  [    0/71250]
loss: 0.068583  [ 6400/71250]
loss: 0.060957  [12800/71250]
loss: 0.047008  [19200/71250]
loss: 0.186595  [25600/71250]
loss: 0.074574  [32000/71250]
loss: 0.144280  [38400/71250]
loss: 0.087128  [44800/71250]
loss: 0.090606  [51200/71250]
loss: 0.133521  [57600/71250]
loss: 0.080822  [64000/71250]
loss: 0.054061  [70400/71250]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.095670 

Epoch 12
-------------------------------
loss: 0.146465  [    0/71250]
loss: 0.107227  [ 6400/71250]
loss: 0.194721  [12800/71250]
loss: 0.097815  [19200/71250]
loss: 0.019141  [25600/71250]
loss: 0.053850  [32000/71250]
loss: 0.121305  [38400/71250]
loss: 0.048281  [44800/71250]
loss: 0.129207  [51200/71250]
loss: 0.059458  [57600/71250]
loss: 0.099546  [64000/71250]
loss: 0.143931  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099450 

Epoch 13
-------------------------------
loss: 0.182689  [    0/71250]
loss: 0.084664  [ 6400/71250]
loss: 0.065474  [12800/71250]
loss: 0.157799  [19200/71250]
loss: 0.175559  [25600/71250]
loss: 0.097115  [32000/71250]
loss: 0.075946  [38400/71250]
loss: 0.046903  [44800/71250]
loss: 0.068255  [51200/71250]
loss: 0.137901  [57600/71250]
loss: 0.033723  [64000/71250]
loss: 0.055797  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.100305 

Epoch 14
-------------------------------
loss: 0.068939  [    0/71250]
loss: 0.086445  [ 6400/71250]
loss: 0.097837  [12800/71250]
loss: 0.079008  [19200/71250]
loss: 0.111480  [25600/71250]
loss: 0.069279  [32000/71250]
loss: 0.169217  [38400/71250]
loss: 0.051170  [44800/71250]
loss: 0.264130  [51200/71250]
loss: 0.059364  [57600/71250]
loss: 0.073729  [64000/71250]
loss: 0.101658  [70400/71250]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.092745 

Epoch 15
-------------------------------
loss: 0.054142  [    0/71250]
loss: 0.074185  [ 6400/71250]
loss: 0.128636  [12800/71250]
loss: 0.072761  [19200/71250]
loss: 0.083062  [25600/71250]
loss: 0.161961  [32000/71250]
loss: 0.029191  [38400/71250]
loss: 0.062485  [44800/71250]
loss: 0.087264  [51200/71250]
loss: 0.110123  [57600/71250]
loss: 0.063568  [64000/71250]
loss: 0.143083  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.098261 

Epoch 16
-------------------------------
loss: 0.038838  [    0/71250]
loss: 0.061173  [ 6400/71250]
loss: 0.255145  [12800/71250]
loss: 0.060811  [19200/71250]
loss: 0.209508  [25600/71250]
loss: 0.029385  [32000/71250]
loss: 0.095464  [38400/71250]
loss: 0.087186  [44800/71250]
loss: 0.127316  [51200/71250]
loss: 0.173241  [57600/71250]
loss: 0.096706  [64000/71250]
loss: 0.130586  [70400/71250]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.103890 

Epoch 17
-------------------------------
loss: 0.079846  [    0/71250]
loss: 0.100228  [ 6400/71250]
loss: 0.092707  [12800/71250]
loss: 0.053838  [19200/71250]
loss: 0.075865  [25600/71250]
loss: 0.040730  [32000/71250]
loss: 0.068624  [38400/71250]
loss: 0.140562  [44800/71250]
loss: 0.105273  [51200/71250]
loss: 0.168186  [57600/71250]
loss: 0.212333  [64000/71250]
loss: 0.044752  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.096281 

Epoch 18
-------------------------------
loss: 0.067579  [    0/71250]
loss: 0.069628  [ 6400/71250]
loss: 0.022773  [12800/71250]
loss: 0.064541  [19200/71250]
loss: 0.061964  [25600/71250]
loss: 0.101042  [32000/71250]
loss: 0.123975  [38400/71250]
loss: 0.084132  [44800/71250]
loss: 0.050742  [51200/71250]
loss: 0.125441  [57600/71250]
loss: 0.098831  [64000/71250]
loss: 0.064271  [70400/71250]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.100057 

Epoch 19
-------------------------------
loss: 0.099578  [    0/71250]
loss: 0.184057  [ 6400/71250]
loss: 0.081310  [12800/71250]
loss: 0.189068  [19200/71250]
loss: 0.039506  [25600/71250]
loss: 0.083153  [32000/71250]
loss: 0.070891  [38400/71250]
loss: 0.087439  [44800/71250]
loss: 0.086662  [51200/71250]
loss: 0.152445  [57600/71250]
loss: 0.053003  [64000/71250]
loss: 0.069211  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.094348 

Epoch 20
-------------------------------
loss: 0.050036  [    0/71250]
loss: 0.028066  [ 6400/71250]
loss: 0.166881  [12800/71250]
loss: 0.029762  [19200/71250]
loss: 0.073190  [25600/71250]
loss: 0.065154  [32000/71250]
loss: 0.119060  [38400/71250]
loss: 0.039671  [44800/71250]
loss: 0.039681  [51200/71250]
loss: 0.085428  [57600/71250]
loss: 0.054590  [64000/71250]
loss: 0.077259  [70400/71250]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.092016 

Epoch 21
-------------------------------
loss: 0.038391  [    0/71250]
loss: 0.061508  [ 6400/71250]
loss: 0.080508  [12800/71250]
loss: 0.068500  [19200/71250]
loss: 0.127344  [25600/71250]
loss: 0.188588  [32000/71250]
loss: 0.128472  [38400/71250]
loss: 0.056932  [44800/71250]
loss: 0.073869  [51200/71250]
loss: 0.167947  [57600/71250]
loss: 0.048544  [64000/71250]
loss: 0.102995  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.105180 

Epoch 22
-------------------------------
loss: 0.163053  [    0/71250]
loss: 0.117322  [ 6400/71250]
loss: 0.067513  [12800/71250]
loss: 0.224384  [19200/71250]
loss: 0.053512  [25600/71250]
loss: 0.041269  [32000/71250]
loss: 0.071997  [38400/71250]
loss: 0.034617  [44800/71250]
loss: 0.148812  [51200/71250]
loss: 0.060931  [57600/71250]
loss: 0.055094  [64000/71250]
loss: 0.087627  [70400/71250]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.110733 

Epoch 23
-------------------------------
loss: 0.054882  [    0/71250]
loss: 0.043254  [ 6400/71250]
loss: 0.066078  [12800/71250]
loss: 0.160255  [19200/71250]
loss: 0.073648  [25600/71250]
loss: 0.059196  [32000/71250]
loss: 0.047509  [38400/71250]
loss: 0.079099  [44800/71250]
loss: 0.081738  [51200/71250]
loss: 0.057943  [57600/71250]
loss: 0.140153  [64000/71250]
loss: 0.123843  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.100993 

Epoch 24
-------------------------------
loss: 0.058441  [    0/71250]
loss: 0.091237  [ 6400/71250]
loss: 0.076871  [12800/71250]
loss: 0.130388  [19200/71250]
loss: 0.053555  [25600/71250]
loss: 0.099592  [32000/71250]
loss: 0.063435  [38400/71250]
loss: 0.135832  [44800/71250]
loss: 0.118118  [51200/71250]
loss: 0.080877  [57600/71250]
loss: 0.077737  [64000/71250]
loss: 0.214294  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099931 

Epoch 25
-------------------------------
loss: 0.100139  [    0/71250]
loss: 0.062783  [ 6400/71250]
loss: 0.049761  [12800/71250]
loss: 0.178607  [19200/71250]
loss: 0.033355  [25600/71250]
loss: 0.072324  [32000/71250]
loss: 0.019408  [38400/71250]
loss: 0.039422  [44800/71250]
loss: 0.100575  [51200/71250]
loss: 0.137109  [44800/69508]
loss: 0.189109  [51200/69508]
loss: 0.137562  [57600/69508]
loss: 0.116436  [64000/69508]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.173400 

Epoch 39
-------------------------------
loss: 0.255997  [    0/69508]
loss: 0.190131  [ 6400/69508]
loss: 0.135829  [12800/69508]
loss: 0.238845  [19200/69508]
loss: 0.121215  [25600/69508]
loss: 0.101562  [32000/69508]
loss: 0.223791  [38400/69508]
loss: 0.159787  [44800/69508]
loss: 0.309169  [51200/69508]
loss: 0.231772  [57600/69508]
loss: 0.183104  [64000/69508]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.178779 

Epoch 40
-------------------------------
loss: 0.119497  [    0/69508]
loss: 0.148736  [ 6400/69508]
loss: 0.162127  [12800/69508]
loss: 0.165160  [19200/69508]
loss: 0.109251  [25600/69508]
loss: 0.177970  [32000/69508]
loss: 0.152501  [38400/69508]
loss: 0.181208  [44800/69508]
loss: 0.270006  [51200/69508]
loss: 0.180559  [57600/69508]
loss: 0.143929  [64000/69508]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.171367 

Epoch 41
-------------------------------
loss: 0.130950  [    0/69508]
loss: 0.185914  [ 6400/69508]
loss: 0.239959  [12800/69508]
loss: 0.365895  [19200/69508]
loss: 0.083214  [25600/69508]
loss: 0.278019  [32000/69508]
loss: 0.169527  [38400/69508]
loss: 0.289875  [44800/69508]
loss: 0.153497  [51200/69508]
loss: 0.246017  [57600/69508]
loss: 0.131359  [64000/69508]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.186994 

Epoch 42
-------------------------------
loss: 0.168853  [    0/69508]
loss: 0.228422  [ 6400/69508]
loss: 0.148728  [12800/69508]
loss: 0.150150  [19200/69508]
loss: 0.160646  [25600/69508]
loss: 0.056370  [32000/69508]
loss: 0.115963  [38400/69508]
loss: 0.114446  [44800/69508]
loss: 0.207425  [51200/69508]
loss: 0.193445  [57600/69508]
loss: 0.224846  [64000/69508]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.217661 

Epoch 43
-------------------------------
loss: 0.162449  [    0/69508]
loss: 0.103816  [ 6400/69508]
loss: 0.192561  [12800/69508]
loss: 0.129878  [19200/69508]
loss: 0.160345  [25600/69508]
loss: 0.179155  [32000/69508]
loss: 0.113995  [38400/69508]
loss: 0.077762  [44800/69508]
loss: 0.271433  [51200/69508]
loss: 0.126415  [57600/69508]
loss: 0.315721  [64000/69508]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177798 

Epoch 44
-------------------------------
loss: 0.180947  [    0/69508]
loss: 0.211461  [ 6400/69508]
loss: 0.177886  [12800/69508]
loss: 0.382629  [19200/69508]
loss: 0.144943  [25600/69508]
loss: 0.225886  [32000/69508]
loss: 0.252252  [38400/69508]
loss: 0.171822  [44800/69508]
loss: 0.088490  [51200/69508]
loss: 0.191080  [57600/69508]
loss: 0.371140  [64000/69508]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.171857 

Epoch 45
-------------------------------
loss: 0.181855  [    0/69508]
loss: 0.217490  [ 6400/69508]
loss: 0.125299  [12800/69508]
loss: 0.135070  [19200/69508]
loss: 0.153119  [25600/69508]
loss: 0.111716  [32000/69508]
loss: 0.172570  [38400/69508]
loss: 0.222803  [44800/69508]
loss: 0.145373  [51200/69508]
loss: 0.152928  [57600/69508]
loss: 0.128836  [64000/69508]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.181281 

Epoch 46
-------------------------------
loss: 0.213710  [    0/69508]
loss: 0.094921  [ 6400/69508]
loss: 0.139498  [12800/69508]
loss: 0.203909  [19200/69508]
loss: 0.154870  [25600/69508]
loss: 0.274897  [32000/69508]
loss: 0.214025  [38400/69508]
loss: 0.069041  [44800/69508]
loss: 0.112708  [51200/69508]
loss: 0.121097  [57600/69508]
loss: 0.048643  [64000/69508]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.184843 

Epoch 47
-------------------------------
loss: 0.310723  [    0/69508]
loss: 0.106074  [ 6400/69508]
loss: 0.159325  [12800/69508]
loss: 0.102306  [19200/69508]
loss: 0.176806  [25600/69508]
loss: 0.193096  [32000/69508]
loss: 0.103911  [38400/69508]
loss: 0.152172  [44800/69508]
loss: 0.270590  [51200/69508]
loss: 0.261724  [57600/69508]
loss: 0.200900  [64000/69508]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.168402 

Epoch 48
-------------------------------
loss: 0.161207  [    0/69508]
loss: 0.240078  [ 6400/69508]
loss: 0.206396  [12800/69508]
loss: 0.149289  [19200/69508]
loss: 0.206619  [25600/69508]
loss: 0.267576  [32000/69508]
loss: 0.141708  [38400/69508]
loss: 0.200613  [44800/69508]
loss: 0.140672  [51200/69508]
loss: 0.158798  [57600/69508]
loss: 0.150233  [64000/69508]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.203325 

Epoch 49
-------------------------------
loss: 0.179715  [    0/69508]
loss: 0.211855  [ 6400/69508]
loss: 0.168891  [12800/69508]
loss: 0.290640  [19200/69508]
loss: 0.146050  [25600/69508]
loss: 0.205943  [32000/69508]
loss: 0.092887  [38400/69508]
loss: 0.158864  [44800/69508]
loss: 0.228474  [51200/69508]
loss: 0.094773  [57600/69508]
loss: 0.197764  [64000/69508]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.193113 

Epoch 50
-------------------------------
loss: 0.149926  [    0/69508]
loss: 0.187517  [ 6400/69508]
loss: 0.237681  [12800/69508]
loss: 0.159477  [19200/69508]
loss: 0.126289  [25600/69508]
loss: 0.221289  [32000/69508]
loss: 0.088277  [38400/69508]
loss: 0.187792  [44800/69508]
loss: 0.279790  [51200/69508]
loss: 0.141447  [57600/69508]
loss: 0.193328  [64000/69508]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.178137 

Epoch 1
-------------------------------
loss: 0.636844  [    0/69886]
loss: 0.255194  [ 6400/69886]
loss: 0.299591  [12800/69886]
loss: 0.127476  [19200/69886]
loss: 0.285892  [25600/69886]
loss: 0.426385  [32000/69886]
loss: 0.197251  [38400/69886]
loss: 0.219176  [44800/69886]
loss: 0.248809  [51200/69886]
loss: 0.226373  [57600/69886]
loss: 0.140380  [64000/69886]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.207211 

Epoch 2
-------------------------------
loss: 0.171805  [    0/69886]
loss: 0.288973  [ 6400/69886]
loss: 0.212139  [12800/69886]
loss: 0.212708  [19200/69886]
loss: 0.170794  [25600/69886]
loss: 0.153521  [32000/69886]
loss: 0.251718  [38400/69886]
loss: 0.269925  [44800/69886]
loss: 0.184969  [51200/69886]
loss: 0.232164  [57600/69886]
loss: 0.267428  [64000/69886]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.179254 

Epoch 3
-------------------------------
loss: 0.228169  [    0/69886]
loss: 0.220386  [ 6400/69886]
loss: 0.146290  [12800/69886]
loss: 0.143879  [19200/69886]
loss: 0.231922  [25600/69886]
loss: 0.229149  [32000/69886]
loss: 0.305461  [38400/69886]
loss: 0.198790  [44800/69886]
loss: 0.136968  [51200/69886]
loss: 0.145165  [57600/69886]
loss: 0.106789  [64000/69886]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.180000 

Epoch 4
-------------------------------
loss: 0.248554  [    0/69886]
loss: 0.105372  [ 6400/69886]
loss: 0.183520  [12800/69886]
loss: 0.254125  [19200/69886]
loss: 0.211725  [25600/69886]
loss: 0.195720  [32000/69886]
loss: 0.114102  [38400/69886]
loss: 0.201243  [44800/69886]
loss: 0.185430  [51200/69886]
loss: 0.179267  [57600/69886]
loss: 0.160616  [64000/69886]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.178310 

Epoch 5
-------------------------------
loss: 0.277645  [    0/69886]
loss: 0.144671  [ 6400/69886]
loss: 0.265292  [12800/69886]
loss: 0.215273  [19200/69886]
loss: 0.188206  [25600/69886]
loss: 0.124839  [32000/69886]
loss: 0.139167  [38400/69886]
loss: 0.253898  [44800/69886]
loss: 0.090232  [51200/69886]
loss: 0.170535  [57600/69886]
loss: 0.315273  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.163151 

Epoch 6
-------------------------------
loss: 0.233670  [    0/69886]
loss: 0.241712  [ 6400/69886]
loss: 0.259788  [12800/69886]
loss: 0.176685  [19200/69886]
loss: 0.157395  [25600/69886]
loss: 0.236497  [32000/69886]
loss: 0.133254  [38400/69886]
loss: 0.066557  [44800/69886]
loss: 0.135088  [51200/69886]
loss: 0.173054  [57600/69886]
loss: 0.139054  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.162241 

Epoch 7
-------------------------------
loss: 0.072117  [    0/69886]
loss: 0.165560  [ 6400/69886]
loss: 0.109306  [12800/69886]
loss: 0.111380  [19200/69886]
loss: 0.214612  [25600/69886]
loss: 0.179086  [32000/69886]
loss: 0.123409  [38400/69886]
loss: 0.253381  [44800/69886]
loss: 0.125373  [51200/69886]
loss: 0.146387  [57600/69886]
loss: 0.115887  [64000/69886]
Epoch 1
-------------------------------
loss: 0.885909  [    0/70535]
loss: 0.243468  [ 6400/70535]
loss: 0.216377  [12800/70535]
loss: 0.267657  [19200/70535]
loss: 0.219442  [25600/70535]
loss: 0.317733  [32000/70535]
loss: 0.179511  [38400/70535]
loss: 0.334910  [44800/70535]
loss: 0.267798  [51200/70535]
loss: 0.180234  [57600/70535]
loss: 0.181909  [64000/70535]
loss: 0.157279  [70400/70535]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.238084 

Epoch 2
-------------------------------
loss: 0.185209  [    0/70535]
loss: 0.231106  [ 6400/70535]
loss: 0.188013  [12800/70535]
loss: 0.200216  [19200/70535]
loss: 0.156846  [25600/70535]
loss: 0.237788  [32000/70535]
loss: 0.132936  [38400/70535]
loss: 0.308375  [44800/70535]
loss: 0.151985  [51200/70535]
loss: 0.291071  [57600/70535]
loss: 0.186404  [64000/70535]
loss: 0.216530  [70400/70535]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.210138 

Epoch 3
-------------------------------
loss: 0.167253  [    0/70535]
loss: 0.310244  [ 6400/70535]
loss: 0.254125  [12800/70535]
loss: 0.158373  [19200/70535]
loss: 0.236150  [25600/70535]
loss: 0.108116  [32000/70535]
loss: 0.200077  [38400/70535]
loss: 0.238745  [44800/70535]
loss: 0.206598  [51200/70535]
loss: 0.176961  [57600/70535]
loss: 0.200554  [64000/70535]
loss: 0.089521  [70400/70535]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.206083 

Epoch 4
-------------------------------
loss: 0.125191  [    0/70535]
loss: 0.215698  [ 6400/70535]
loss: 0.168720  [12800/70535]
loss: 0.254674  [19200/70535]
loss: 0.293625  [25600/70535]
loss: 0.190276  [32000/70535]
loss: 0.299095  [38400/70535]
loss: 0.219720  [44800/70535]
loss: 0.240741  [51200/70535]
loss: 0.137278  [57600/70535]
loss: 0.177251  [64000/70535]
loss: 0.189936  [70400/70535]
Test Error: 
 Accuracy: 91.0%, Avg loss: 0.207402 

Epoch 5
-------------------------------
loss: 0.139342  [    0/70535]
loss: 0.184984  [ 6400/70535]
loss: 0.163314  [12800/70535]
loss: 0.285257  [19200/70535]
loss: 0.160491  [25600/70535]
loss: 0.246964  [32000/70535]
loss: 0.146596  [38400/70535]
loss: 0.075380  [44800/70535]
loss: 0.298800  [51200/70535]
loss: 0.188779  [57600/70535]
loss: 0.132405  [64000/70535]
loss: 0.162193  [70400/70535]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.179514 

Epoch 6
-------------------------------
loss: 0.255659  [    0/70535]
loss: 0.159363  [ 6400/70535]
loss: 0.106705  [12800/70535]
loss: 0.173953  [19200/70535]
loss: 0.281966  [25600/70535]
loss: 0.137325  [32000/70535]
loss: 0.150219  [38400/70535]
loss: 0.161667  [44800/70535]
loss: 0.202964  [51200/70535]
loss: 0.188139  [57600/70535]
loss: 0.146398  [64000/70535]
loss: 0.284478  [70400/70535]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.180388 

Epoch 7
-------------------------------
loss: 0.251280  [    0/70535]
loss: 0.111431  [ 6400/70535]
loss: 0.215299  [12800/70535]
loss: 0.104389  [19200/70535]
loss: 0.208569  [25600/70535]
loss: 0.221111  [32000/70535]
loss: 0.336379  [38400/70535]
loss: 0.164401  [44800/70535]
loss: 0.093803  [51200/70535]
loss: 0.147419  [57600/70535]
loss: 0.184910  [64000/70535]
loss: 0.172412  [70400/70535]
Test Error: 
 Accuracy: 90.9%, Avg loss: 0.208135 

Epoch 8
-------------------------------
loss: 0.258203  [    0/70535]
loss: 0.208825  [ 6400/70535]
loss: 0.180765  [12800/70535]
loss: 0.254615  [19200/70535]
loss: 0.180046  [25600/70535]
loss: 0.155215  [32000/70535]
loss: 0.175045  [38400/70535]
loss: 0.243814  [44800/70535]
loss: 0.196002  [51200/70535]
loss: 0.204156  [57600/70535]
loss: 0.145121  [64000/70535]
loss: 0.158877  [70400/70535]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.190790 

Epoch 9
-------------------------------
loss: 0.122379  [    0/70535]
loss: 0.100665  [ 6400/70535]
loss: 0.176721  [12800/70535]
loss: 0.198982  [19200/70535]
loss: 0.177169  [25600/70535]
loss: 0.194959  [32000/70535]
loss: 0.150013  [38400/70535]
loss: 0.141945  [44800/70535]
loss: 0.134720  [51200/70535]
loss: 0.196917  [57600/70535]
loss: 0.080026  [64000/70535]
loss: 0.251197  [70400/70535]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.193270 

Epoch 10
-------------------------------
loss: 0.145873  [    0/70535]
loss: 0.151870  [ 6400/70535]
loss: 0.248888  [12800/70535]
loss: 0.110833  [19200/70535]
loss: 0.118028  [25600/70535]
loss: 0.244202  [32000/70535]
loss: 0.144065  [38400/70535]
loss: 0.161478  [44800/70535]
loss: 0.123607  [51200/70535]
loss: 0.190711  [57600/70535]
loss: 0.252486  [64000/70535]
loss: 0.213537  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.189246 

Epoch 11
-------------------------------
loss: 0.176957  [    0/70535]
loss: 0.134168  [ 6400/70535]
loss: 0.089364  [12800/70535]
loss: 0.281773  [19200/70535]
loss: 0.157183  [25600/70535]
loss: 0.070798  [32000/70535]
loss: 0.322632  [38400/70535]
loss: 0.180711  [44800/70535]
loss: 0.105778  [51200/70535]
loss: 0.230373  [57600/70535]
loss: 0.226600  [64000/70535]
loss: 0.054573  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.187177 

Epoch 12
-------------------------------
loss: 0.238876  [    0/70535]
loss: 0.085393  [ 6400/70535]
loss: 0.195763  [12800/70535]
loss: 0.288902  [19200/70535]
loss: 0.123546  [25600/70535]
loss: 0.207083  [32000/70535]
loss: 0.171398  [38400/70535]
loss: 0.261841  [44800/70535]
loss: 0.079487  [51200/70535]
loss: 0.156264  [57600/70535]
loss: 0.237674  [64000/70535]
loss: 0.250948  [70400/70535]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.236998 

Epoch 13
-------------------------------
loss: 0.189389  [    0/70535]
loss: 0.068985  [ 6400/70535]
loss: 0.184882  [12800/70535]
loss: 0.242261  [19200/70535]
loss: 0.201961  [25600/70535]
loss: 0.104203  [32000/70535]
loss: 0.133446  [38400/70535]
loss: 0.277944  [44800/70535]
loss: 0.202419  [51200/70535]
loss: 0.250401  [57600/70535]
loss: 0.163706  [64000/70535]
loss: 0.127863  [70400/70535]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.193305 

Epoch 14
-------------------------------
loss: 0.171614  [    0/70535]
loss: 0.181284  [ 6400/70535]
loss: 0.084768  [12800/70535]
loss: 0.122785  [19200/70535]
loss: 0.288334  [25600/70535]
loss: 0.225495  [32000/70535]
loss: 0.175442  [38400/70535]
loss: 0.147880  [44800/70535]
loss: 0.144828  [51200/70535]
loss: 0.108316  [57600/70535]
loss: 0.208832  [64000/70535]
loss: 0.147091  [70400/70535]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.192140 

Epoch 15
-------------------------------
loss: 0.115359  [    0/70535]
loss: 0.208607  [ 6400/70535]
loss: 0.229501  [12800/70535]
loss: 0.111708  [19200/70535]
loss: 0.082260  [25600/70535]
loss: 0.177262  [32000/70535]
loss: 0.159960  [38400/70535]
loss: 0.169824  [44800/70535]
loss: 0.165577  [51200/70535]
loss: 0.173664  [57600/70535]
loss: 0.210419  [64000/70535]
loss: 0.177404  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.185993 

Epoch 16
-------------------------------
loss: 0.153289  [    0/70535]
loss: 0.162752  [ 6400/70535]
loss: 0.148709  [12800/70535]
loss: 0.287549  [19200/70535]
loss: 0.118156  [25600/70535]
loss: 0.126960  [32000/70535]
loss: 0.266836  [38400/70535]
loss: 0.149580  [44800/70535]
loss: 0.099881  [51200/70535]
loss: 0.074572  [57600/70535]
loss: 0.140994  [64000/70535]
loss: 0.202978  [70400/70535]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.175438 

Epoch 17
-------------------------------
loss: 0.256792  [    0/70535]
loss: 0.071041  [ 6400/70535]
loss: 0.209668  [12800/70535]
loss: 0.053024  [19200/70535]
loss: 0.245389  [25600/70535]
loss: 0.128150  [32000/70535]
loss: 0.301564  [38400/70535]
loss: 0.194947  [44800/70535]
loss: 0.132831  [51200/70535]
loss: 0.193738  [57600/70535]
loss: 0.228702  [64000/70535]
loss: 0.159110  [70400/70535]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.188039 

Epoch 18
-------------------------------
loss: 0.281529  [    0/70535]
loss: 0.094741  [ 6400/70535]
loss: 0.197520  [12800/70535]
loss: 0.114889  [19200/70535]
loss: 0.240847  [25600/70535]
loss: 0.105586  [32000/70535]
loss: 0.172354  [38400/70535]
loss: 0.171631  [44800/70535]
loss: 0.202154  [51200/70535]
loss: 0.153854  [57600/70535]
loss: 0.147845  [64000/70535]
loss: 0.140770  [70400/70535]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.186241 

Epoch 19
-------------------------------
loss: 0.124997  [38400/69546]
loss: 0.179476  [44800/69546]
loss: 0.049931  [51200/69546]
loss: 0.167367  [57600/69546]
loss: 0.111891  [64000/69546]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.121850 

Epoch 5
-------------------------------
loss: 0.099386  [    0/69546]
loss: 0.103422  [ 6400/69546]
loss: 0.138849  [12800/69546]
loss: 0.030630  [19200/69546]
loss: 0.174790  [25600/69546]
loss: 0.168552  [32000/69546]
loss: 0.102381  [38400/69546]
loss: 0.161284  [44800/69546]
loss: 0.289788  [51200/69546]
loss: 0.118937  [57600/69546]
loss: 0.162342  [64000/69546]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.134937 

Epoch 6
-------------------------------
loss: 0.148370  [    0/69546]
loss: 0.136973  [ 6400/69546]
loss: 0.189976  [12800/69546]
loss: 0.097756  [19200/69546]
loss: 0.040683  [25600/69546]
loss: 0.074119  [32000/69546]
loss: 0.125697  [38400/69546]
loss: 0.095693  [44800/69546]
loss: 0.105458  [51200/69546]
loss: 0.160438  [57600/69546]
loss: 0.150553  [64000/69546]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.121126 

Epoch 7
-------------------------------
loss: 0.086086  [    0/69546]
loss: 0.122491  [ 6400/69546]
loss: 0.091275  [12800/69546]
loss: 0.125995  [19200/69546]
loss: 0.090573  [25600/69546]
loss: 0.205929  [32000/69546]
loss: 0.208073  [38400/69546]
loss: 0.155565  [44800/69546]
loss: 0.183102  [51200/69546]
loss: 0.154767  [57600/69546]
loss: 0.079224  [64000/69546]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.126293 

Epoch 8
-------------------------------
loss: 0.105256  [    0/69546]
loss: 0.143362  [ 6400/69546]
loss: 0.161216  [12800/69546]
loss: 0.165062  [19200/69546]
loss: 0.140584  [25600/69546]
loss: 0.090597  [32000/69546]
loss: 0.261650  [38400/69546]
loss: 0.214367  [44800/69546]
loss: 0.067977  [51200/69546]
loss: 0.225296  [57600/69546]
loss: 0.100206  [64000/69546]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.127183 

Epoch 9
-------------------------------
loss: 0.176838  [    0/69546]
loss: 0.129446  [ 6400/69546]
loss: 0.152771  [12800/69546]
loss: 0.178996  [19200/69546]
loss: 0.089249  [25600/69546]
loss: 0.107933  [32000/69546]
loss: 0.076569  [38400/69546]
loss: 0.070815  [44800/69546]
loss: 0.054196  [51200/69546]
loss: 0.081457  [57600/69546]
loss: 0.135983  [64000/69546]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.126550 

Epoch 10
-------------------------------
loss: 0.207037  [    0/69546]
loss: 0.074916  [ 6400/69546]
loss: 0.260591  [12800/69546]
loss: 0.088745  [19200/69546]
loss: 0.146723  [25600/69546]
loss: 0.134812  [32000/69546]
loss: 0.062907  [38400/69546]
loss: 0.040609  [44800/69546]
loss: 0.058062  [51200/69546]
loss: 0.210388  [57600/69546]
loss: 0.063340  [64000/69546]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.121115 

Epoch 11
-------------------------------
loss: 0.130770  [    0/69546]
loss: 0.131714  [ 6400/69546]
loss: 1.675312  [12800/69546]
loss: 0.057420  [19200/69546]
loss: 0.142187  [25600/69546]
loss: 0.153766  [32000/69546]
loss: 0.098103  [38400/69546]
loss: 0.145566  [44800/69546]
loss: 0.067243  [51200/69546]
loss: 0.117246  [57600/69546]
loss: 0.139446  [64000/69546]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.119123 

Epoch 12
-------------------------------
loss: 0.074485  [    0/69546]
loss: 0.150925  [ 6400/69546]
loss: 0.182047  [12800/69546]
loss: 0.137778  [19200/69546]
loss: 0.143080  [25600/69546]
loss: 0.056911  [32000/69546]
loss: 0.078460  [38400/69546]
loss: 0.057694  [44800/69546]
loss: 0.079613  [51200/69546]
loss: 0.099459  [57600/69546]
loss: 0.067453  [64000/69546]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.122281 

Epoch 13
-------------------------------
loss: 0.218543  [    0/69546]
loss: 0.138060  [ 6400/69546]
loss: 0.146686  [12800/69546]
loss: 0.098220  [19200/69546]
loss: 0.097246  [25600/69546]
loss: 0.089253  [32000/69546]
loss: 0.159864  [38400/69546]
loss: 0.072936  [44800/69546]
loss: 0.099173  [51200/69546]
loss: 0.202565  [57600/69546]
loss: 0.229592  [64000/69546]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.127988 

Epoch 14
-------------------------------
loss: 0.172602  [    0/69546]
loss: 0.092506  [ 6400/69546]
loss: 0.062319  [12800/69546]
loss: 0.115886  [19200/69546]
loss: 0.150716  [25600/69546]
loss: 0.069500  [32000/69546]
loss: 0.152592  [38400/69546]
loss: 0.145053  [44800/69546]
loss: 0.126591  [51200/69546]
loss: 0.101995  [57600/69546]
loss: 0.234483  [64000/69546]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.132173 

Epoch 15
-------------------------------
loss: 0.142997  [    0/69546]
loss: 0.120513  [ 6400/69546]
loss: 0.088205  [12800/69546]
loss: 0.160642  [19200/69546]
loss: 0.104039  [25600/69546]
loss: 0.057971  [32000/69546]
loss: 0.092840  [38400/69546]
loss: 0.127704  [44800/69546]
loss: 0.127477  [51200/69546]
loss: 0.132305  [57600/69546]
loss: 0.070691  [64000/69546]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.147328 

Epoch 16
-------------------------------
loss: 0.058367  [    0/69546]
loss: 0.134918  [ 6400/69546]
loss: 0.145981  [12800/69546]
loss: 0.106709  [19200/69546]
loss: 0.095601  [25600/69546]
loss: 0.052380  [32000/69546]
loss: 0.197132  [38400/69546]
loss: 0.150321  [44800/69546]
loss: 0.191271  [51200/69546]
loss: 0.088017  [57600/69546]
loss: 0.124142  [64000/69546]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.118131 

Epoch 17
-------------------------------
loss: 0.070746  [    0/69546]
loss: 0.190974  [ 6400/69546]
loss: 0.181496  [12800/69546]
loss: 0.118097  [19200/69546]
loss: 0.120304  [25600/69546]
loss: 0.101605  [32000/69546]
loss: 0.172825  [38400/69546]
loss: 0.138547  [44800/69546]
loss: 0.074333  [51200/69546]
loss: 0.092160  [57600/69546]
loss: 0.099115  [64000/69546]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.116047 

Epoch 18
-------------------------------
loss: 0.073783  [    0/69546]
loss: 0.061339  [ 6400/69546]
loss: 0.181640  [12800/69546]
loss: 0.086772  [19200/69546]
loss: 0.073103  [25600/69546]
loss: 0.094007  [32000/69546]
loss: 0.109181  [38400/69546]
loss: 0.033319  [44800/69546]
loss: 0.071929  [51200/69546]
loss: 0.091165  [57600/69546]
loss: 0.048875  [64000/69546]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.119828 

Epoch 19
-------------------------------
loss: 0.067434  [    0/69546]
loss: 0.067823  [ 6400/69546]
loss: 0.136833  [12800/69546]
loss: 0.079584  [19200/69546]
loss: 0.184176  [25600/69546]
loss: 0.069526  [32000/69546]
loss: 0.110970  [38400/69546]
loss: 0.160625  [44800/69546]
loss: 0.137610  [51200/69546]
loss: 0.085552  [57600/69546]
loss: 0.132448  [64000/69546]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.115047 

Epoch 20
-------------------------------
loss: 0.134126  [    0/69546]
loss: 0.060278  [ 6400/69546]
loss: 0.144889  [12800/69546]
loss: 0.134810  [19200/69546]
loss: 0.062929  [25600/69546]
loss: 0.121627  [32000/69546]
loss: 0.079140  [38400/69546]
loss: 0.145294  [44800/69546]
loss: 0.211948  [51200/69546]
loss: 0.065211  [57600/69546]
loss: 0.108813  [64000/69546]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.120513 

Epoch 21
-------------------------------
loss: 0.074507  [    0/69546]
loss: 0.065412  [ 6400/69546]
loss: 0.095937  [12800/69546]
loss: 0.036432  [19200/69546]
loss: 0.112089  [25600/69546]
loss: 0.042468  [32000/69546]
loss: 0.175724  [38400/69546]
loss: 0.086668  [44800/69546]
loss: 0.121122  [51200/69546]
loss: 0.103806  [57600/69546]
loss: 0.037894  [64000/69546]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.124834 

Epoch 22
-------------------------------
loss: 0.154344  [    0/69546]
loss: 0.164067  [ 6400/69546]
loss: 0.230377  [12800/69546]
loss: 0.067063  [19200/69546]
loss: 0.125479  [25600/69546]
loss: 0.062178  [32000/69546]
loss: 0.128985  [38400/69546]
loss: 0.126128  [44800/69546]
loss: 0.092719  [51200/69546]
loss: 0.058783  [57600/69546]
loss: 0.123467  [64000/69546]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.121510 

Epoch 23
-------------------------------
loss: 0.167310  [    0/69546]
loss: 0.118730  [ 6400/69546]
loss: 0.086256  [12800/69546]
loss: 0.072782  [19200/69546]
loss: 0.039719  [25600/69546]
loss: 0.063443  [32000/69546]
loss: 0.130333  [38400/69546]
loss: 0.147338  [44800/69546]
loss: 0.141369  [51200/69546]
loss: 0.078841  [57600/69546]
loss: 0.064440  [64000/69546]
loss: 0.118547  [32000/70818]
loss: 0.157948  [38400/70818]
loss: 0.112944  [44800/70818]
loss: 0.045854  [51200/70818]
loss: 0.184399  [57600/70818]
loss: 0.142045  [64000/70818]
loss: 0.043215  [70400/70818]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.091683 

Epoch 8
-------------------------------
loss: 0.091383  [    0/70818]
loss: 0.133573  [ 6400/70818]
loss: 0.084231  [12800/70818]
loss: 0.166349  [19200/70818]
loss: 0.142757  [25600/70818]
loss: 0.071035  [32000/70818]
loss: 0.107264  [38400/70818]
loss: 0.059100  [44800/70818]
loss: 0.146244  [51200/70818]
loss: 0.103592  [57600/70818]
loss: 0.048365  [64000/70818]
loss: 0.026692  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.094617 

Epoch 9
-------------------------------
loss: 0.116553  [    0/70818]
loss: 0.053032  [ 6400/70818]
loss: 0.066956  [12800/70818]
loss: 0.032990  [19200/70818]
loss: 0.042390  [25600/70818]
loss: 0.139275  [32000/70818]
loss: 0.128632  [38400/70818]
loss: 0.087732  [44800/70818]
loss: 0.081792  [51200/70818]
loss: 0.073212  [57600/70818]
loss: 0.213977  [64000/70818]
loss: 0.042196  [70400/70818]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.090464 

Epoch 10
-------------------------------
loss: 0.081082  [    0/70818]
loss: 0.092345  [ 6400/70818]
loss: 0.076011  [12800/70818]
loss: 0.052772  [19200/70818]
loss: 0.112145  [25600/70818]
loss: 0.110224  [32000/70818]
loss: 0.064802  [38400/70818]
loss: 0.073286  [44800/70818]
loss: 0.029899  [51200/70818]
loss: 0.222057  [57600/70818]
loss: 0.087854  [64000/70818]
loss: 0.034155  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.096715 

Epoch 11
-------------------------------
loss: 0.193750  [    0/70818]
loss: 0.081369  [ 6400/70818]
loss: 0.152050  [12800/70818]
loss: 0.119517  [19200/70818]
loss: 0.066185  [25600/70818]
loss: 0.086909  [32000/70818]
loss: 0.280853  [38400/70818]
loss: 0.211428  [44800/70818]
loss: 0.085849  [51200/70818]
loss: 0.051482  [57600/70818]
loss: 0.056941  [64000/70818]
loss: 0.215421  [70400/70818]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.097438 

Epoch 12
-------------------------------
loss: 0.072934  [    0/70818]
loss: 0.112195  [ 6400/70818]
loss: 0.049423  [12800/70818]
loss: 0.123416  [19200/70818]
loss: 0.031983  [25600/70818]
loss: 0.046531  [32000/70818]
loss: 0.150119  [38400/70818]
loss: 0.085967  [44800/70818]
loss: 0.346886  [51200/70818]
loss: 0.111911  [57600/70818]
loss: 0.127979  [64000/70818]
loss: 0.058150  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.092681 

Epoch 13
-------------------------------
loss: 0.098720  [    0/70818]
loss: 0.069866  [ 6400/70818]
loss: 0.113195  [12800/70818]
loss: 0.089496  [19200/70818]
loss: 0.111826  [25600/70818]
loss: 0.141135  [32000/70818]
loss: 0.168025  [38400/70818]
loss: 0.089231  [44800/70818]
loss: 0.107779  [51200/70818]
loss: 0.168532  [57600/70818]
loss: 0.098976  [64000/70818]
loss: 0.102639  [70400/70818]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.092321 

Epoch 14
-------------------------------
loss: 0.077233  [    0/70818]
loss: 0.125896  [ 6400/70818]
loss: 0.105384  [12800/70818]
loss: 0.136016  [19200/70818]
loss: 0.102446  [25600/70818]
loss: 0.104117  [32000/70818]
loss: 0.175892  [38400/70818]
loss: 0.113913  [44800/70818]
loss: 0.057551  [51200/70818]
loss: 0.039647  [57600/70818]
loss: 0.104013  [64000/70818]
loss: 0.073777  [70400/70818]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.087308 

Epoch 15
-------------------------------
loss: 0.071884  [    0/70818]
loss: 0.064444  [ 6400/70818]
loss: 0.134939  [12800/70818]
loss: 0.052415  [19200/70818]
loss: 0.119648  [25600/70818]
loss: 0.102985  [32000/70818]
loss: 0.173473  [38400/70818]
loss: 0.141386  [44800/70818]
loss: 0.077752  [51200/70818]
loss: 0.035454  [57600/70818]
loss: 0.136029  [64000/70818]
loss: 0.091186  [70400/70818]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090140 

Epoch 16
-------------------------------
loss: 0.105526  [    0/70818]
loss: 0.035008  [ 6400/70818]
loss: 0.063788  [12800/70818]
loss: 0.150186  [19200/70818]
loss: 0.033794  [25600/70818]
loss: 0.156657  [32000/70818]
loss: 0.067965  [38400/70818]
loss: 0.076113  [44800/70818]
loss: 0.174318  [51200/70818]
loss: 0.106674  [57600/70818]
loss: 0.062131  [64000/70818]
loss: 0.036751  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.094832 

Epoch 17
-------------------------------
loss: 0.167562  [    0/70818]
loss: 0.203776  [ 6400/70818]
loss: 0.059592  [12800/70818]
loss: 0.100259  [19200/70818]
loss: 0.083501  [25600/70818]
loss: 0.021301  [32000/70818]
loss: 0.043492  [38400/70818]
loss: 0.154050  [44800/70818]
loss: 0.125897  [51200/70818]
loss: 0.144709  [57600/70818]
loss: 0.182206  [64000/70818]
loss: 0.032368  [70400/70818]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.093941 

Epoch 18
-------------------------------
loss: 0.109162  [    0/70818]
loss: 0.157186  [ 6400/70818]
loss: 0.132396  [12800/70818]
loss: 0.090006  [19200/70818]
loss: 0.186552  [25600/70818]
loss: 0.063797  [32000/70818]
loss: 0.043880  [38400/70818]
loss: 0.200257  [44800/70818]
loss: 0.076279  [51200/70818]
loss: 0.047521  [57600/70818]
loss: 0.069566  [64000/70818]
loss: 0.058146  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097052 

Epoch 19
-------------------------------
loss: 0.088082  [    0/70818]
loss: 0.116283  [ 6400/70818]
loss: 0.083836  [12800/70818]
loss: 0.076535  [19200/70818]
loss: 0.251270  [25600/70818]
loss: 0.034353  [32000/70818]
loss: 0.123330  [38400/70818]
loss: 0.043426  [44800/70818]
loss: 0.091632  [51200/70818]
loss: 0.170285  [57600/70818]
loss: 1.360527  [64000/70818]
loss: 0.145016  [70400/70818]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.092160 

Epoch 20
-------------------------------
loss: 0.066288  [    0/70818]
loss: 0.087212  [ 6400/70818]
loss: 0.083823  [12800/70818]
loss: 0.111451  [19200/70818]
loss: 0.178708  [25600/70818]
loss: 0.143337  [32000/70818]
loss: 0.029477  [38400/70818]
loss: 0.070180  [44800/70818]
loss: 0.144255  [51200/70818]
loss: 0.065082  [57600/70818]
loss: 0.127545  [64000/70818]
loss: 0.091378  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.098329 

Epoch 21
-------------------------------
loss: 0.129777  [    0/70818]
loss: 0.082863  [ 6400/70818]
loss: 0.071237  [12800/70818]
loss: 0.084161  [19200/70818]
loss: 0.107311  [25600/70818]
loss: 1.389632  [32000/70818]
loss: 0.130263  [38400/70818]
loss: 0.084981  [44800/70818]
loss: 0.128445  [51200/70818]
loss: 0.089972  [57600/70818]
loss: 0.047244  [64000/70818]
loss: 0.048916  [70400/70818]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.099551 

Epoch 22
-------------------------------
loss: 0.083103  [    0/70818]
loss: 0.076509  [ 6400/70818]
loss: 0.071901  [12800/70818]
loss: 0.099856  [19200/70818]
loss: 0.098737  [25600/70818]
loss: 0.036928  [32000/70818]
loss: 0.040364  [38400/70818]
loss: 0.044428  [44800/70818]
loss: 0.173650  [51200/70818]
loss: 0.081158  [57600/70818]
loss: 0.112771  [64000/70818]
loss: 0.094194  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.095020 

Epoch 23
-------------------------------
loss: 0.021524  [    0/70818]
loss: 0.095626  [ 6400/70818]
loss: 0.038422  [12800/70818]
loss: 0.149415  [19200/70818]
loss: 0.132293  [25600/70818]
loss: 0.122655  [32000/70818]
loss: 0.059052  [38400/70818]
loss: 0.098855  [44800/70818]
loss: 0.091261  [51200/70818]
loss: 0.039227  [57600/70818]
loss: 0.077631  [64000/70818]
loss: 0.091181  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.090300 

Epoch 24
-------------------------------
loss: 0.070394  [    0/70818]
loss: 0.097204  [ 6400/70818]
loss: 0.259983  [12800/70818]
loss: 0.056220  [19200/70818]
loss: 0.096419  [25600/70818]
loss: 0.058020  [32000/70818]
loss: 0.141126  [38400/70818]
loss: 0.134006  [44800/70818]
loss: 0.088067  [51200/70818]
loss: 0.080196  [57600/70818]
loss: 0.098554  [64000/70818]
loss: 0.044188  [70400/70818]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.096356 

Epoch 25
-------------------------------
loss: 0.127031  [    0/70818]
loss: 0.217626  [ 6400/70818]
loss: 0.053816  [12800/70818]
loss: 0.065314  [19200/70818]
loss: 0.012087  [25600/70818]
loss: 0.176453  [32000/70818]
loss: 0.052642  [51200/70896]
loss: 0.049478  [57600/70896]
loss: 0.043915  [64000/70896]
loss: 0.103315  [70400/70896]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.145368 

Epoch 16
-------------------------------
loss: 0.054846  [    0/70896]
loss: 0.088284  [ 6400/70896]
loss: 0.103800  [12800/70896]
loss: 0.009417  [19200/70896]
loss: 0.059647  [25600/70896]
loss: 0.174716  [32000/70896]
loss: 0.160305  [38400/70896]
loss: 0.134892  [44800/70896]
loss: 0.046466  [51200/70896]
loss: 0.045728  [57600/70896]
loss: 0.052664  [64000/70896]
loss: 0.087178  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.127061 

Epoch 17
-------------------------------
loss: 0.086149  [    0/70896]
loss: 0.056746  [ 6400/70896]
loss: 0.091307  [12800/70896]
loss: 0.046128  [19200/70896]
loss: 0.048360  [25600/70896]
loss: 0.024511  [32000/70896]
loss: 0.095715  [38400/70896]
loss: 0.101555  [44800/70896]
loss: 0.132680  [51200/70896]
loss: 0.097553  [57600/70896]
loss: 0.044748  [64000/70896]
loss: 0.111012  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.129241 

Epoch 18
-------------------------------
loss: 0.079596  [    0/70896]
loss: 0.068639  [ 6400/70896]
loss: 0.159889  [12800/70896]
loss: 0.031041  [19200/70896]
loss: 0.066417  [25600/70896]
loss: 0.117985  [32000/70896]
loss: 0.120657  [38400/70896]
loss: 0.034758  [44800/70896]
loss: 0.043055  [51200/70896]
loss: 0.062784  [57600/70896]
loss: 0.029328  [64000/70896]
loss: 0.033432  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.125659 

Epoch 19
-------------------------------
loss: 0.093114  [    0/70896]
loss: 0.062647  [ 6400/70896]
loss: 0.049477  [12800/70896]
loss: 0.089537  [19200/70896]
loss: 0.105234  [25600/70896]
loss: 0.044408  [32000/70896]
loss: 0.082617  [38400/70896]
loss: 0.096211  [44800/70896]
loss: 0.144279  [51200/70896]
loss: 0.037203  [57600/70896]
loss: 0.086535  [64000/70896]
loss: 0.138282  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.128995 

Epoch 20
-------------------------------
loss: 0.107996  [    0/70896]
loss: 0.131253  [ 6400/70896]
loss: 1.656630  [12800/70896]
loss: 0.137764  [19200/70896]
loss: 0.100834  [25600/70896]
loss: 0.105509  [32000/70896]
loss: 0.117177  [38400/70896]
loss: 0.236585  [44800/70896]
loss: 0.066147  [51200/70896]
loss: 0.042683  [57600/70896]
loss: 0.054987  [64000/70896]
loss: 0.104378  [70400/70896]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.132393 

Epoch 21
-------------------------------
loss: 0.062057  [    0/70896]
loss: 0.070847  [ 6400/70896]
loss: 0.093721  [12800/70896]
loss: 0.109669  [19200/70896]
loss: 0.084731  [25600/70896]
loss: 0.063232  [32000/70896]
loss: 0.029922  [38400/70896]
loss: 0.190888  [44800/70896]
loss: 0.062213  [51200/70896]
loss: 0.069335  [57600/70896]
loss: 0.118634  [64000/70896]
loss: 0.107334  [70400/70896]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.127331 

Epoch 22
-------------------------------
loss: 0.213293  [    0/70896]
loss: 0.063880  [ 6400/70896]
loss: 0.026586  [12800/70896]
loss: 0.091175  [19200/70896]
loss: 0.062506  [25600/70896]
loss: 0.054378  [32000/70896]
loss: 0.085339  [38400/70896]
loss: 0.056882  [44800/70896]
loss: 0.081280  [51200/70896]
loss: 0.067044  [57600/70896]
loss: 0.029901  [64000/70896]
loss: 0.108112  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.131347 

Epoch 23
-------------------------------
loss: 0.093721  [    0/70896]
loss: 0.123899  [ 6400/70896]
loss: 0.050007  [12800/70896]
loss: 0.092565  [19200/70896]
loss: 0.029367  [25600/70896]
loss: 0.051864  [32000/70896]
loss: 0.054772  [38400/70896]
loss: 0.113453  [44800/70896]
loss: 0.071306  [51200/70896]
loss: 0.124759  [57600/70896]
loss: 0.157076  [64000/70896]
loss: 0.075212  [70400/70896]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.136347 

Epoch 24
-------------------------------
loss: 0.131855  [    0/70896]
loss: 0.014648  [ 6400/70896]
loss: 0.122527  [12800/70896]
loss: 0.142412  [19200/70896]
loss: 0.042208  [25600/70896]
loss: 0.041994  [32000/70896]
loss: 0.043913  [38400/70896]
loss: 0.053725  [44800/70896]
loss: 0.188111  [51200/70896]
loss: 0.075940  [57600/70896]
loss: 0.034211  [64000/70896]
loss: 0.045573  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.130437 

Epoch 25
-------------------------------
loss: 0.076214  [    0/70896]
loss: 0.216437  [ 6400/70896]
loss: 0.050160  [12800/70896]
loss: 0.153049  [19200/70896]
loss: 0.153444  [25600/70896]
loss: 0.142039  [32000/70896]
loss: 0.037404  [38400/70896]
loss: 0.054695  [44800/70896]
loss: 0.063750  [51200/70896]
loss: 0.163785  [57600/70896]
loss: 0.081381  [64000/70896]
loss: 0.078765  [70400/70896]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.141604 

Epoch 26
-------------------------------
loss: 0.058442  [    0/70896]
loss: 0.026440  [ 6400/70896]
loss: 0.037265  [12800/70896]
loss: 0.133242  [19200/70896]
loss: 0.057792  [25600/70896]
loss: 0.108464  [32000/70896]
loss: 0.049362  [38400/70896]
loss: 0.167315  [44800/70896]
loss: 0.030667  [51200/70896]
loss: 0.095157  [57600/70896]
loss: 0.072790  [64000/70896]
loss: 1.601385  [70400/70896]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.134175 

Epoch 27
-------------------------------
loss: 0.088581  [    0/70896]
loss: 0.034010  [ 6400/70896]
loss: 0.015576  [12800/70896]
loss: 0.088568  [19200/70896]
loss: 0.088641  [25600/70896]
loss: 0.049052  [32000/70896]
loss: 0.137075  [38400/70896]
loss: 0.047292  [44800/70896]
loss: 0.066035  [51200/70896]
loss: 0.064071  [57600/70896]
loss: 0.095261  [64000/70896]
loss: 0.081516  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.131828 

Epoch 28
-------------------------------
loss: 0.065069  [    0/70896]
loss: 0.007598  [ 6400/70896]
loss: 0.041496  [12800/70896]
loss: 0.105365  [19200/70896]
loss: 0.052370  [25600/70896]
loss: 0.061844  [32000/70896]
loss: 0.035639  [38400/70896]
loss: 0.102037  [44800/70896]
loss: 0.109572  [51200/70896]
loss: 0.054476  [57600/70896]
loss: 0.075000  [64000/70896]
loss: 0.084953  [70400/70896]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.139135 

Epoch 29
-------------------------------
loss: 0.121829  [    0/70896]
loss: 0.076993  [ 6400/70896]
loss: 0.107001  [12800/70896]
loss: 0.131085  [19200/70896]
loss: 0.171701  [25600/70896]
loss: 0.122751  [32000/70896]
loss: 0.087386  [38400/70896]
loss: 0.063897  [44800/70896]
loss: 0.026529  [51200/70896]
loss: 0.061082  [57600/70896]
loss: 0.073530  [64000/70896]
loss: 0.090691  [70400/70896]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.128083 

Epoch 30
-------------------------------
loss: 0.011784  [    0/70896]
loss: 0.089363  [ 6400/70896]
loss: 0.055356  [12800/70896]
loss: 0.164944  [19200/70896]
loss: 0.021465  [25600/70896]
loss: 0.063931  [32000/70896]
loss: 0.080185  [38400/70896]
loss: 0.076255  [44800/70896]
loss: 0.060886  [51200/70896]
loss: 0.035731  [57600/70896]
loss: 0.254731  [64000/70896]
loss: 0.077484  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.131151 

Epoch 31
-------------------------------
loss: 0.062004  [    0/70896]
loss: 0.051981  [ 6400/70896]
loss: 0.095971  [12800/70896]
loss: 0.143217  [19200/70896]
loss: 0.068557  [25600/70896]
loss: 0.072097  [32000/70896]
loss: 0.126880  [38400/70896]
loss: 0.087858  [44800/70896]
loss: 0.173111  [51200/70896]
loss: 0.099993  [57600/70896]
loss: 0.081607  [64000/70896]
loss: 0.082465  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.131145 

Epoch 32
-------------------------------
loss: 0.027884  [    0/70896]
loss: 0.088384  [ 6400/70896]
loss: 0.107756  [12800/70896]
loss: 0.127663  [19200/70896]
loss: 0.057103  [25600/70896]
loss: 0.047946  [32000/70896]
loss: 0.049403  [38400/70896]
loss: 0.041927  [44800/70896]
loss: 0.036114  [51200/70896]
loss: 0.071374  [57600/70896]
loss: 0.025474  [64000/70896]
loss: 0.052777  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.128216 

Epoch 33
-------------------------------
loss: 0.136436  [    0/70896]
loss: 0.126660  [ 6400/70896]
loss: 0.048585  [12800/70896]
loss: 0.065724  [19200/70896]
loss: 0.187750  [25600/70896]
loss: 0.171113  [32000/70896]
loss: 0.093283  [38400/70896]
loss: 0.138927  [44800/70896]
loss: 0.098249  [51200/70896]
loss: 0.167622  [38400/69752]
loss: 0.137009  [44800/69752]
loss: 0.194512  [51200/69752]
loss: 0.160772  [57600/69752]
loss: 0.135687  [64000/69752]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.186674 

Epoch 17
-------------------------------
loss: 0.094180  [    0/69752]
loss: 0.082824  [ 6400/69752]
loss: 0.153634  [12800/69752]
loss: 0.127954  [19200/69752]
loss: 0.152835  [25600/69752]
loss: 0.089498  [32000/69752]
loss: 0.230106  [38400/69752]
loss: 0.073695  [44800/69752]
loss: 0.074574  [51200/69752]
loss: 0.095779  [57600/69752]
loss: 0.264500  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.182525 

Epoch 18
-------------------------------
loss: 0.028068  [    0/69752]
loss: 0.315386  [ 6400/69752]
loss: 0.158172  [12800/69752]
loss: 0.171902  [19200/69752]
loss: 0.245443  [25600/69752]
loss: 0.150658  [32000/69752]
loss: 0.078668  [38400/69752]
loss: 0.060346  [44800/69752]
loss: 0.164100  [51200/69752]
loss: 0.174559  [57600/69752]
loss: 0.099792  [64000/69752]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.181289 

Epoch 19
-------------------------------
loss: 0.115144  [    0/69752]
loss: 0.166221  [ 6400/69752]
loss: 0.175056  [12800/69752]
loss: 0.252412  [19200/69752]
loss: 0.164747  [25600/69752]
loss: 0.210135  [32000/69752]
loss: 0.147505  [38400/69752]
loss: 0.099985  [44800/69752]
loss: 0.080251  [51200/69752]
loss: 0.203289  [57600/69752]
loss: 0.107919  [64000/69752]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.189734 

Epoch 20
-------------------------------
loss: 1.616123  [    0/69752]
loss: 0.092265  [ 6400/69752]
loss: 0.112186  [12800/69752]
loss: 0.274042  [19200/69752]
loss: 0.094218  [25600/69752]
loss: 0.141421  [32000/69752]
loss: 0.102765  [38400/69752]
loss: 0.180767  [44800/69752]
loss: 0.190380  [51200/69752]
loss: 0.164209  [57600/69752]
loss: 0.061758  [64000/69752]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.185432 

Epoch 21
-------------------------------
loss: 0.099433  [    0/69752]
loss: 0.179386  [ 6400/69752]
loss: 0.185097  [12800/69752]
loss: 0.135124  [19200/69752]
loss: 0.104325  [25600/69752]
loss: 0.141302  [32000/69752]
loss: 1.693109  [38400/69752]
loss: 0.096753  [44800/69752]
loss: 0.235653  [51200/69752]
loss: 0.199256  [57600/69752]
loss: 0.157232  [64000/69752]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.183416 

Epoch 22
-------------------------------
loss: 0.184964  [    0/69752]
loss: 0.129935  [ 6400/69752]
loss: 0.133770  [12800/69752]
loss: 0.141739  [19200/69752]
loss: 0.143096  [25600/69752]
loss: 0.084830  [32000/69752]
loss: 0.182800  [38400/69752]
loss: 0.278405  [44800/69752]
loss: 0.173475  [51200/69752]
loss: 0.092419  [57600/69752]
loss: 0.137133  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180813 

Epoch 23
-------------------------------
loss: 0.080818  [    0/69752]
loss: 0.070493  [ 6400/69752]
loss: 0.203160  [12800/69752]
loss: 0.091521  [19200/69752]
loss: 0.114499  [25600/69752]
loss: 0.300285  [32000/69752]
loss: 0.116672  [38400/69752]
loss: 0.148988  [44800/69752]
loss: 0.092319  [51200/69752]
loss: 0.116264  [57600/69752]
loss: 0.239251  [64000/69752]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.178572 

Epoch 24
-------------------------------
loss: 0.113567  [    0/69752]
loss: 0.217616  [ 6400/69752]
loss: 0.129990  [12800/69752]
loss: 0.246024  [19200/69752]
loss: 0.197285  [25600/69752]
loss: 0.131833  [32000/69752]
loss: 0.242415  [38400/69752]
loss: 0.251212  [44800/69752]
loss: 0.211448  [51200/69752]
loss: 0.091678  [57600/69752]
loss: 0.118380  [64000/69752]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.181523 

Epoch 25
-------------------------------
loss: 0.106390  [    0/69752]
loss: 0.178904  [ 6400/69752]
loss: 0.364664  [12800/69752]
loss: 0.062295  [19200/69752]
loss: 0.165200  [25600/69752]
loss: 0.158773  [32000/69752]
loss: 0.100360  [38400/69752]
loss: 0.243557  [44800/69752]
loss: 0.087776  [51200/69752]
loss: 0.120193  [57600/69752]
loss: 0.216669  [64000/69752]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.191454 

Epoch 26
-------------------------------
loss: 0.142111  [    0/69752]
loss: 0.111225  [ 6400/69752]
loss: 0.143687  [12800/69752]
loss: 0.164107  [19200/69752]
loss: 0.190062  [25600/69752]
loss: 0.121469  [32000/69752]
loss: 0.281105  [38400/69752]
loss: 0.190650  [44800/69752]
loss: 0.115822  [51200/69752]
loss: 0.229364  [57600/69752]
loss: 0.206512  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.182725 

Epoch 27
-------------------------------
loss: 1.675637  [    0/69752]
loss: 0.187623  [ 6400/69752]
loss: 0.159112  [12800/69752]
loss: 0.177478  [19200/69752]
loss: 0.137867  [25600/69752]
loss: 0.259825  [32000/69752]
loss: 0.105970  [38400/69752]
loss: 0.143322  [44800/69752]
loss: 0.070597  [51200/69752]
loss: 0.156311  [57600/69752]
loss: 1.706038  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.181624 

Epoch 28
-------------------------------
loss: 0.175570  [    0/69752]
loss: 0.152389  [ 6400/69752]
loss: 0.152087  [12800/69752]
loss: 0.104155  [19200/69752]
loss: 0.067361  [25600/69752]
loss: 0.096592  [32000/69752]
loss: 0.189270  [38400/69752]
loss: 0.114530  [44800/69752]
loss: 0.123913  [51200/69752]
loss: 0.151688  [57600/69752]
loss: 0.092934  [64000/69752]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.191096 

Epoch 29
-------------------------------
loss: 0.078050  [    0/69752]
loss: 0.203574  [ 6400/69752]
loss: 0.120524  [12800/69752]
loss: 0.082406  [19200/69752]
loss: 0.114350  [25600/69752]
loss: 0.079659  [32000/69752]
loss: 0.127750  [38400/69752]
loss: 0.241479  [44800/69752]
loss: 0.198149  [51200/69752]
loss: 0.276261  [57600/69752]
loss: 0.139591  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.180625 

Epoch 30
-------------------------------
loss: 0.108646  [    0/69752]
loss: 0.093130  [ 6400/69752]
loss: 0.225121  [12800/69752]
loss: 0.054620  [19200/69752]
loss: 0.212449  [25600/69752]
loss: 0.185921  [32000/69752]
loss: 0.219870  [38400/69752]
loss: 0.157926  [44800/69752]
loss: 0.361631  [51200/69752]
loss: 0.178739  [57600/69752]
loss: 0.160965  [64000/69752]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.184675 

Epoch 31
-------------------------------
loss: 0.111599  [    0/69752]
loss: 0.093555  [ 6400/69752]
loss: 0.222615  [12800/69752]
loss: 0.145103  [19200/69752]
loss: 0.097425  [25600/69752]
loss: 0.100331  [32000/69752]
loss: 0.206275  [38400/69752]
loss: 0.160121  [44800/69752]
loss: 0.122260  [51200/69752]
loss: 0.226102  [57600/69752]
loss: 0.198745  [64000/69752]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.176796 

Epoch 32
-------------------------------
loss: 0.174286  [    0/69752]
loss: 0.159147  [ 6400/69752]
loss: 0.103685  [12800/69752]
loss: 0.159151  [19200/69752]
loss: 0.294626  [25600/69752]
loss: 0.265975  [32000/69752]
loss: 0.145070  [38400/69752]
loss: 0.107326  [44800/69752]
loss: 0.111329  [51200/69752]
loss: 0.197637  [57600/69752]
loss: 0.221119  [64000/69752]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.170088 

Epoch 33
-------------------------------
loss: 0.106001  [    0/69752]
loss: 0.128646  [ 6400/69752]
loss: 0.181291  [12800/69752]
loss: 0.109629  [19200/69752]
loss: 0.188915  [25600/69752]
loss: 0.078999  [32000/69752]
loss: 0.124258  [38400/69752]
loss: 0.211441  [44800/69752]
loss: 0.084560  [51200/69752]
loss: 0.276850  [57600/69752]
loss: 0.138458  [64000/69752]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.168731 

Epoch 34
-------------------------------
loss: 0.220020  [    0/69752]
loss: 0.116840  [ 6400/69752]
loss: 0.177264  [12800/69752]
loss: 0.118677  [19200/69752]
loss: 0.121872  [25600/69752]
loss: 0.195443  [32000/69752]
loss: 0.137800  [38400/69752]
loss: 0.187944  [44800/69752]
loss: 0.159811  [51200/69752]
loss: 0.164236  [57600/69752]
loss: 0.274640  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.174710 

Epoch 35
-------------------------------
loss: 0.180440  [    0/69752]
loss: 0.165691  [ 6400/69752]
loss: 0.104631  [12800/69752]
loss: 0.074504  [19200/69752]
loss: 0.175227  [25600/69752]
loss: 0.130835  [32000/69752]
loss: 0.169710  [38400/69752]
loss: 0.194689  [44800/69752]
loss: 0.099104  [51200/69752]
loss: 0.111900  [57600/69752]
loss: 0.084984  [64000/69752]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.102698 

Epoch 19
-------------------------------
loss: 0.039749  [    0/72262]
loss: 0.053575  [ 6400/72262]
loss: 0.047725  [12800/72262]
loss: 0.003352  [19200/72262]
loss: 0.060112  [25600/72262]
loss: 0.000565  [32000/72262]
loss: 0.000369  [38400/72262]
loss: 0.032643  [44800/72262]
loss: 0.035399  [51200/72262]
loss: 0.053293  [57600/72262]
loss: 0.001470  [64000/72262]
loss: 0.028191  [70400/72262]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.052626 

Epoch 20
-------------------------------
loss: 0.007316  [    0/72262]
loss: 0.040942  [ 6400/72262]
loss: 0.013503  [12800/72262]
loss: 0.061402  [19200/72262]
loss: 0.033486  [25600/72262]
loss: 0.028087  [32000/72262]
loss: 0.180141  [38400/72262]
loss: 0.001059  [44800/72262]
loss: 0.092542  [51200/72262]
loss: 0.003349  [57600/72262]
loss: 0.024661  [64000/72262]
loss: 0.046697  [70400/72262]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.082924 

Epoch 21
-------------------------------
loss: 0.028243  [    0/72262]
loss: 0.095912  [ 6400/72262]
loss: 0.050926  [12800/72262]
loss: 0.011124  [19200/72262]
loss: 0.043502  [25600/72262]
loss: 0.001058  [32000/72262]
loss: 0.096743  [38400/72262]
loss: 0.001590  [44800/72262]
loss: 0.104384  [51200/72262]
loss: 0.035997  [57600/72262]
loss: 0.005830  [64000/72262]
loss: 0.014388  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.083460 

Epoch 22
-------------------------------
loss: 0.021181  [    0/72262]
loss: 0.006543  [ 6400/72262]
loss: 0.019421  [12800/72262]
loss: 0.003842  [19200/72262]
loss: 0.023364  [25600/72262]
loss: 0.017304  [32000/72262]
loss: 0.033854  [38400/72262]
loss: 0.025577  [44800/72262]
loss: 0.006433  [51200/72262]
loss: 0.028270  [57600/72262]
loss: 0.035781  [64000/72262]
loss: 0.003826  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.081719 

Epoch 23
-------------------------------
loss: 0.013281  [    0/72262]
loss: 0.038042  [ 6400/72262]
loss: 0.030096  [12800/72262]
loss: 0.006465  [19200/72262]
loss: 0.025670  [25600/72262]
loss: 0.017130  [32000/72262]
loss: 0.031634  [38400/72262]
loss: 0.008940  [44800/72262]
loss: 0.092726  [51200/72262]
loss: 0.024428  [57600/72262]
loss: 0.029340  [64000/72262]
loss: 0.004533  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.093496 

Epoch 24
-------------------------------
loss: 0.010658  [    0/72262]
loss: 0.028589  [ 6400/72262]
loss: 0.017067  [12800/72262]
loss: 0.043096  [19200/72262]
loss: 0.014090  [25600/72262]
loss: 0.000539  [32000/72262]
loss: 0.012271  [38400/72262]
loss: 0.018157  [44800/72262]
loss: 0.024446  [51200/72262]
loss: 0.048198  [57600/72262]
loss: 0.009438  [64000/72262]
loss: 0.009357  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.101424 

Epoch 25
-------------------------------
loss: 0.006988  [    0/72262]
loss: 0.005857  [ 6400/72262]
loss: 0.001641  [12800/72262]
loss: 0.014734  [19200/72262]
loss: 0.016432  [25600/72262]
loss: 0.012842  [32000/72262]
loss: 0.036803  [38400/72262]
loss: 0.017019  [44800/72262]
loss: 0.014212  [51200/72262]
loss: 0.009683  [57600/72262]
loss: 0.018183  [64000/72262]
loss: 0.007869  [70400/72262]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.099637 

Epoch 26
-------------------------------
loss: 0.014014  [    0/72262]
loss: 0.027362  [ 6400/72262]
loss: 0.006251  [12800/72262]
loss: 0.016506  [19200/72262]
loss: 0.022054  [25600/72262]
loss: 0.020024  [32000/72262]
loss: 0.024777  [38400/72262]
loss: 0.015752  [44800/72262]
loss: 0.003568  [51200/72262]
loss: 0.026786  [57600/72262]
loss: 0.007432  [64000/72262]
loss: 0.053062  [70400/72262]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.081378 

Epoch 27
-------------------------------
loss: 0.034318  [    0/72262]
loss: 0.019786  [ 6400/72262]
loss: 0.022192  [12800/72262]
loss: 0.013916  [19200/72262]
loss: 0.028542  [25600/72262]
loss: 0.020029  [32000/72262]
loss: 0.020464  [38400/72262]
loss: 0.040353  [44800/72262]
loss: 0.028524  [51200/72262]
loss: 0.028943  [57600/72262]
loss: 0.013950  [64000/72262]
loss: 0.027117  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.078799 

Epoch 28
-------------------------------
loss: 0.013882  [    0/72262]
loss: 0.012771  [ 6400/72262]
loss: 0.010552  [12800/72262]
loss: 0.017057  [19200/72262]
loss: 0.019873  [25600/72262]
loss: 0.026659  [32000/72262]
loss: 0.077530  [38400/72262]
loss: 0.004292  [44800/72262]
loss: 0.025598  [51200/72262]
loss: 0.024644  [57600/72262]
loss: 0.001703  [64000/72262]
loss: 0.008693  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.090569 

Epoch 29
-------------------------------
loss: 0.020171  [    0/72262]
loss: 0.011640  [ 6400/72262]
loss: 0.016094  [12800/72262]
loss: 0.051798  [19200/72262]
loss: 0.054307  [25600/72262]
loss: 0.003121  [32000/72262]
loss: 0.027717  [38400/72262]
loss: 0.013462  [44800/72262]
loss: 0.009684  [51200/72262]
loss: 0.060530  [57600/72262]
loss: 0.012976  [64000/72262]
loss: 0.011991  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.081625 

Epoch 30
-------------------------------
loss: 0.042199  [    0/72262]
loss: 0.022715  [ 6400/72262]
loss: 0.007989  [12800/72262]
loss: 0.002482  [19200/72262]
loss: 0.015566  [25600/72262]
loss: 0.008802  [32000/72262]
loss: 0.025030  [38400/72262]
loss: 0.007007  [44800/72262]
loss: 0.000151  [51200/72262]
loss: 0.014129  [57600/72262]
loss: 0.004165  [64000/72262]
loss: 0.026899  [70400/72262]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.084438 

Epoch 31
-------------------------------
loss: 0.018064  [    0/72262]
loss: 0.011741  [ 6400/72262]
loss: 0.082530  [12800/72262]
loss: 0.045610  [19200/72262]
loss: 0.012523  [25600/72262]
loss: 0.004648  [32000/72262]
loss: 0.008593  [38400/72262]
loss: 0.068959  [44800/72262]
loss: 0.012457  [51200/72262]
loss: 0.000412  [57600/72262]
loss: 0.001622  [64000/72262]
loss: 0.111586  [70400/72262]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.084800 

Epoch 32
-------------------------------
loss: 0.031088  [    0/72262]
loss: 0.073373  [ 6400/72262]
loss: 0.002609  [12800/72262]
loss: 0.016549  [19200/72262]
loss: 0.091621  [25600/72262]
loss: 0.017711  [32000/72262]
loss: 0.012349  [38400/72262]
loss: 0.026070  [44800/72262]
loss: 0.000915  [51200/72262]
loss: 0.002050  [57600/72262]
loss: 0.071031  [64000/72262]
loss: 0.041790  [70400/72262]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.081481 

Epoch 33
-------------------------------
loss: 0.061509  [    0/72262]
loss: 0.002397  [ 6400/72262]
loss: 0.019993  [12800/72262]
loss: 0.010401  [19200/72262]
loss: 0.010411  [25600/72262]
loss: 0.024157  [32000/72262]
loss: 0.000416  [38400/72262]
loss: 0.014495  [44800/72262]
loss: 0.020121  [51200/72262]
loss: 0.146244  [57600/72262]
loss: 0.130997  [64000/72262]
loss: 0.164382  [70400/72262]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.077977 

Epoch 34
-------------------------------
loss: 0.059852  [    0/72262]
loss: 0.010438  [ 6400/72262]
loss: 0.013825  [12800/72262]
loss: 0.051639  [19200/72262]
loss: 0.176492  [25600/72262]
loss: 0.035440  [32000/72262]
loss: 0.026515  [38400/72262]
loss: 0.003038  [44800/72262]
loss: 0.150299  [51200/72262]
loss: 0.014737  [57600/72262]
loss: 0.002046  [64000/72262]
loss: 0.009427  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.084486 

Epoch 35
-------------------------------
loss: 0.002599  [    0/72262]
loss: 0.000160  [ 6400/72262]
loss: 0.000241  [12800/72262]
loss: 0.002445  [19200/72262]
loss: 0.055704  [25600/72262]
loss: 0.009559  [32000/72262]
loss: 0.002081  [38400/72262]
loss: 0.030904  [44800/72262]
loss: 0.000606  [51200/72262]
loss: 0.008826  [57600/72262]
loss: 0.055451  [64000/72262]
loss: 0.028601  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.079050 

Epoch 36
-------------------------------
loss: 0.001320  [    0/72262]
loss: 0.028717  [ 6400/72262]
loss: 0.008609  [12800/72262]
loss: 0.007589  [19200/72262]
loss: 0.004753  [25600/72262]
loss: 0.038967  [32000/72262]
loss: 0.068544  [38400/72262]
loss: 0.092134  [44800/72262]
loss: 0.119410  [51200/72262]
loss: 0.066044  [57600/72262]
loss: 0.023916  [64000/72262]
loss: 0.013295  [70400/72262]
loss: 0.225924  [19200/69308]
loss: 0.227022  [25600/69308]
loss: 0.159659  [32000/69308]
loss: 0.153817  [38400/69308]
loss: 0.147617  [44800/69308]
loss: 0.242530  [51200/69308]
loss: 0.232522  [57600/69308]
loss: 0.081316  [64000/69308]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.193445 

Epoch 1
-------------------------------
loss: 0.678361  [    0/69886]
loss: 0.264389  [ 6400/69886]
loss: 0.240126  [12800/69886]
loss: 0.456374  [19200/69886]
loss: 0.192270  [25600/69886]
loss: 0.328449  [32000/69886]
loss: 0.206695  [38400/69886]
loss: 0.307929  [44800/69886]
loss: 0.238970  [51200/69886]
loss: 0.314924  [57600/69886]
loss: 0.163650  [64000/69886]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.195760 

Epoch 2
-------------------------------
loss: 0.200918  [    0/69886]
loss: 0.223513  [ 6400/69886]
loss: 0.173333  [12800/69886]
loss: 0.158998  [19200/69886]
loss: 0.237941  [25600/69886]
loss: 0.135836  [32000/69886]
loss: 0.211890  [38400/69886]
loss: 0.281564  [44800/69886]
loss: 0.133308  [51200/69886]
loss: 0.183132  [57600/69886]
loss: 0.158174  [64000/69886]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.186297 

Epoch 3
-------------------------------
loss: 0.201120  [    0/69886]
loss: 0.251706  [ 6400/69886]
loss: 0.246696  [12800/69886]
loss: 0.274646  [19200/69886]
loss: 0.284775  [25600/69886]
loss: 0.154739  [32000/69886]
loss: 0.235386  [38400/69886]
loss: 0.236038  [44800/69886]
loss: 0.116391  [51200/69886]
loss: 0.289205  [57600/69886]
loss: 0.263173  [64000/69886]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.180167 

Epoch 4
-------------------------------
loss: 0.217972  [    0/69886]
loss: 0.187578  [ 6400/69886]
loss: 0.313924  [12800/69886]
loss: 0.167179  [19200/69886]
loss: 0.104953  [25600/69886]
loss: 0.225791  [32000/69886]
loss: 0.155596  [38400/69886]
loss: 0.250457  [44800/69886]
loss: 0.225878  [51200/69886]
loss: 0.114767  [57600/69886]
loss: 0.358386  [64000/69886]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.185405 

Epoch 5
-------------------------------
loss: 0.149860  [    0/69886]
loss: 0.136331  [ 6400/69886]
loss: 0.174618  [12800/69886]
loss: 0.253943  [19200/69886]
loss: 0.129313  [25600/69886]
loss: 0.355770  [32000/69886]
loss: 0.140843  [38400/69886]
loss: 0.124612  [44800/69886]
loss: 0.181084  [51200/69886]
loss: 0.236429  [57600/69886]
loss: 0.113233  [64000/69886]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.180239 

Epoch 6
-------------------------------
loss: 0.219300  [    0/69886]
loss: 0.252810  [ 6400/69886]
loss: 0.122804  [12800/69886]
loss: 0.217696  [19200/69886]
loss: 0.264159  [25600/69886]
loss: 0.284603  [32000/69886]
loss: 0.191511  [38400/69886]
loss: 0.260990  [44800/69886]
loss: 0.143770  [51200/69886]
loss: 0.268448  [57600/69886]
loss: 0.213960  [64000/69886]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.173970 

Epoch 7
-------------------------------
loss: 0.225455  [    0/69886]
loss: 0.171672  [ 6400/69886]
loss: 0.165128  [12800/69886]
loss: 0.144590  [19200/69886]
loss: 0.173543  [25600/69886]
loss: 0.198923  [32000/69886]
loss: 0.144088  [38400/69886]
loss: 0.218500  [44800/69886]
loss: 0.174020  [51200/69886]
loss: 0.222618  [57600/69886]
loss: 0.118223  [64000/69886]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.170209 

Epoch 8
-------------------------------
loss: 0.259622  [    0/69886]
loss: 0.179971  [ 6400/69886]
loss: 0.350933  [12800/69886]
loss: 0.101912  [19200/69886]
loss: 0.122133  [25600/69886]
loss: 0.181588  [32000/69886]
loss: 0.212651  [38400/69886]
loss: 0.172738  [44800/69886]
loss: 0.180156  [51200/69886]
loss: 0.121651  [57600/69886]
loss: 0.116353  [64000/69886]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.173747 

Epoch 9
-------------------------------
loss: 0.120833  [    0/69886]
loss: 0.094493  [ 6400/69886]
loss: 0.175634  [12800/69886]
loss: 0.122572  [19200/69886]
loss: 0.271319  [25600/69886]
loss: 0.094980  [32000/69886]
loss: 0.265460  [38400/69886]
loss: 0.242535  [44800/69886]
loss: 0.157862  [51200/69886]
loss: 0.126856  [57600/69886]
loss: 0.152052  [64000/69886]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.170318 

Epoch 10
-------------------------------
loss: 0.143245  [    0/69886]
loss: 0.201111  [ 6400/69886]
loss: 0.211691  [12800/69886]
loss: 0.176962  [19200/69886]
loss: 0.159094  [25600/69886]
loss: 0.177356  [32000/69886]
loss: 0.176799  [38400/69886]
loss: 0.183297  [44800/69886]
loss: 0.308755  [51200/69886]
loss: 0.153345  [57600/69886]
loss: 0.083199  [64000/69886]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.165377 

Epoch 11
-------------------------------
loss: 0.156646  [    0/69886]
loss: 0.141975  [ 6400/69886]
loss: 0.164463  [12800/69886]
loss: 0.070653  [19200/69886]
loss: 0.179745  [25600/69886]
loss: 0.154716  [32000/69886]
loss: 0.226991  [38400/69886]
loss: 0.282176  [44800/69886]
loss: 0.122650  [51200/69886]
loss: 0.190634  [57600/69886]
loss: 0.155345  [64000/69886]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.171187 

Epoch 12
-------------------------------
loss: 0.159827  [    0/69886]
loss: 0.186376  [ 6400/69886]
loss: 0.081186  [12800/69886]
loss: 0.121244  [19200/69886]
loss: 0.136579  [25600/69886]
loss: 0.172746  [32000/69886]
loss: 0.158390  [38400/69886]
loss: 0.237152  [44800/69886]
loss: 0.137712  [51200/69886]
loss: 0.188204  [57600/69886]
loss: 0.174630  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.163211 

Epoch 13
-------------------------------
loss: 0.076197  [    0/69886]
loss: 0.316065  [ 6400/69886]
loss: 0.283138  [12800/69886]
loss: 0.185334  [19200/69886]
loss: 0.134699  [25600/69886]
loss: 0.119221  [32000/69886]
loss: 0.077483  [38400/69886]
loss: 0.246526  [44800/69886]
loss: 0.208291  [51200/69886]
loss: 0.167580  [57600/69886]
loss: 0.202918  [64000/69886]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.171339 

Epoch 14
-------------------------------
loss: 0.174399  [    0/69886]
loss: 0.245419  [ 6400/69886]
loss: 0.124843  [12800/69886]
loss: 0.119124  [19200/69886]
loss: 0.230629  [25600/69886]
loss: 0.261296  [32000/69886]
loss: 0.188811  [38400/69886]
loss: 0.169148  [44800/69886]
loss: 0.145160  [51200/69886]
loss: 0.165828  [57600/69886]
loss: 0.112640  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.161914 

Epoch 15
-------------------------------
loss: 0.248228  [    0/69886]
loss: 0.203871  [ 6400/69886]
loss: 0.162415  [12800/69886]
loss: 0.177329  [19200/69886]
loss: 0.143821  [25600/69886]
loss: 0.221428  [32000/69886]
loss: 0.132459  [38400/69886]
loss: 0.153443  [44800/69886]
loss: 0.234796  [51200/69886]
loss: 0.162194  [57600/69886]
loss: 0.252147  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.162277 

Epoch 16
-------------------------------
loss: 0.153069  [    0/69886]
loss: 0.147802  [ 6400/69886]
loss: 0.080494  [12800/69886]
loss: 0.259017  [19200/69886]
loss: 0.181956  [25600/69886]
loss: 0.093108  [32000/69886]
loss: 0.154030  [38400/69886]
loss: 0.079723  [44800/69886]
loss: 0.131934  [51200/69886]
loss: 0.162409  [57600/69886]
loss: 0.185642  [64000/69886]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.174524 

Epoch 17
-------------------------------
loss: 0.162762  [    0/69886]
loss: 0.267525  [ 6400/69886]
loss: 0.118870  [12800/69886]
loss: 0.161322  [19200/69886]
loss: 0.170589  [25600/69886]
loss: 0.158509  [32000/69886]
loss: 0.112506  [38400/69886]
loss: 0.140151  [44800/69886]
loss: 0.151020  [51200/69886]
loss: 0.244406  [57600/69886]
loss: 0.186979  [64000/69886]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.165222 

Epoch 18
-------------------------------
loss: 0.149579  [    0/69886]
loss: 0.287224  [ 6400/69886]
loss: 0.153890  [12800/69886]
loss: 0.101046  [19200/69886]
loss: 0.123163  [25600/69886]
loss: 0.174113  [32000/69886]
loss: 0.197948  [38400/69886]
loss: 0.218813  [44800/69886]
loss: 0.110241  [51200/69886]
loss: 0.088455  [57600/69886]
loss: 0.144713  [64000/69886]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.169039 

Epoch 19
-------------------------------
loss: 0.070865  [    0/69886]
loss: 0.141325  [ 6400/69886]
loss: 0.172606  [12800/69886]
loss: 0.178377  [19200/69886]
loss: 0.166744  [25600/69886]
loss: 0.192257  [32000/69886]
loss: 0.224106  [38400/69886]
loss: 0.111203  [44800/69886]
loss: 0.175461  [12800/69683]
loss: 0.264816  [19200/69683]
loss: 0.305976  [25600/69683]
loss: 0.239035  [32000/69683]
loss: 0.191745  [38400/69683]
loss: 0.155542  [44800/69683]
loss: 0.136623  [51200/69683]
loss: 0.125507  [57600/69683]
loss: 0.108331  [64000/69683]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.182700 

Epoch 43
-------------------------------
loss: 0.221007  [    0/69683]
loss: 0.209165  [ 6400/69683]
loss: 0.193303  [12800/69683]
loss: 0.130085  [19200/69683]
loss: 0.282100  [25600/69683]
loss: 0.100178  [32000/69683]
loss: 0.127203  [38400/69683]
loss: 0.196395  [44800/69683]
loss: 0.279394  [51200/69683]
loss: 0.125274  [57600/69683]
loss: 0.198904  [64000/69683]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.171626 

Epoch 44
-------------------------------
loss: 0.107586  [    0/69683]
loss: 0.233353  [ 6400/69683]
loss: 0.203616  [12800/69683]
loss: 0.133937  [19200/69683]
loss: 0.215853  [25600/69683]
loss: 0.248758  [32000/69683]
loss: 0.249245  [38400/69683]
loss: 0.153308  [44800/69683]
loss: 0.146942  [51200/69683]
loss: 0.253088  [57600/69683]
loss: 0.109359  [64000/69683]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.175943 

Epoch 45
-------------------------------
loss: 0.156165  [    0/69683]
loss: 0.082083  [ 6400/69683]
loss: 0.235473  [12800/69683]
loss: 0.099942  [19200/69683]
loss: 0.155587  [25600/69683]
loss: 0.149883  [32000/69683]
loss: 0.345770  [38400/69683]
loss: 0.275778  [44800/69683]
loss: 0.091967  [51200/69683]
loss: 0.125515  [57600/69683]
loss: 0.147130  [64000/69683]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.170588 

Epoch 46
-------------------------------
loss: 0.141495  [    0/69683]
loss: 0.203684  [ 6400/69683]
loss: 1.661811  [12800/69683]
loss: 0.167372  [19200/69683]
loss: 0.097180  [25600/69683]
loss: 0.147437  [32000/69683]
loss: 0.137659  [38400/69683]
loss: 0.156600  [44800/69683]
loss: 0.157018  [51200/69683]
loss: 0.174001  [57600/69683]
loss: 0.183537  [64000/69683]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.171658 

Epoch 47
-------------------------------
loss: 0.212678  [    0/69683]
loss: 0.094669  [ 6400/69683]
loss: 0.167963  [12800/69683]
loss: 0.200883  [19200/69683]
loss: 0.222451  [25600/69683]
loss: 0.164769  [32000/69683]
loss: 0.114473  [38400/69683]
loss: 0.167741  [44800/69683]
loss: 0.182134  [51200/69683]
loss: 0.121040  [57600/69683]
loss: 0.192935  [64000/69683]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.172481 

Epoch 48
-------------------------------
loss: 0.184572  [    0/69683]
loss: 0.171441  [ 6400/69683]
loss: 0.232321  [12800/69683]
loss: 0.124061  [19200/69683]
loss: 0.169909  [25600/69683]
loss: 0.132453  [32000/69683]
loss: 0.170529  [38400/69683]
loss: 0.128797  [44800/69683]
loss: 0.180310  [51200/69683]
loss: 0.203268  [57600/69683]
loss: 0.158112  [64000/69683]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.178784 

Epoch 49
-------------------------------
loss: 0.257411  [    0/69683]
loss: 0.181944  [ 6400/69683]
loss: 0.250552  [12800/69683]
loss: 0.197954  [19200/69683]
loss: 0.165663  [25600/69683]
loss: 0.253437  [32000/69683]
loss: 0.125235  [38400/69683]
loss: 0.164480  [44800/69683]
loss: 0.293143  [51200/69683]
loss: 0.127891  [57600/69683]
loss: 0.235063  [64000/69683]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.178675 

Epoch 50
-------------------------------
loss: 0.165348  [    0/69683]
loss: 0.259424  [ 6400/69683]
loss: 0.120317  [12800/69683]
loss: 0.159553  [19200/69683]
loss: 0.240631  [25600/69683]
loss: 0.115505  [32000/69683]
loss: 0.203075  [38400/69683]
loss: 0.172183  [44800/69683]
loss: 0.268646  [51200/69683]
loss: 0.122451  [57600/69683]
loss: 0.216773  [64000/69683]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.178649 

Epoch 1
-------------------------------
loss: 0.641896  [    0/70245]
loss: 0.401612  [ 6400/70245]
loss: 0.246102  [12800/70245]
loss: 0.353801  [19200/70245]
loss: 0.179292  [25600/70245]
loss: 0.419145  [32000/70245]
loss: 0.203774  [38400/70245]
loss: 0.170940  [44800/70245]
loss: 0.220442  [51200/70245]
loss: 0.207472  [57600/70245]
loss: 0.255488  [64000/70245]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.232135 

Epoch 2
-------------------------------
loss: 0.301804  [    0/70245]
loss: 0.230218  [ 6400/70245]
loss: 0.157882  [12800/70245]
loss: 0.259930  [19200/70245]
loss: 0.251822  [25600/70245]
loss: 0.280345  [32000/70245]
loss: 0.209767  [38400/70245]
loss: 0.248692  [44800/70245]
loss: 0.282044  [51200/70245]
loss: 0.277986  [57600/70245]
loss: 0.239898  [64000/70245]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.228990 

Epoch 3
-------------------------------
loss: 0.219619  [    0/70245]
loss: 0.306288  [ 6400/70245]
loss: 0.349961  [12800/70245]
loss: 0.146044  [19200/70245]
loss: 0.219865  [25600/70245]
loss: 0.228611  [32000/70245]
loss: 0.205233  [38400/70245]
loss: 0.208058  [44800/70245]
loss: 0.195307  [51200/70245]
loss: 0.155102  [57600/70245]
loss: 0.293365  [64000/70245]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.213647 

Epoch 4
-------------------------------
loss: 0.183529  [    0/70245]
loss: 0.099385  [ 6400/70245]
loss: 0.127482  [12800/70245]
loss: 0.139058  [19200/70245]
loss: 0.260767  [25600/70245]
loss: 0.188110  [32000/70245]
loss: 0.201835  [38400/70245]
loss: 0.160763  [44800/70245]
loss: 0.173759  [51200/70245]
loss: 0.201066  [57600/70245]
loss: 0.214165  [64000/70245]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.217001 

Epoch 5
-------------------------------
loss: 0.090982  [    0/70245]
loss: 0.258536  [ 6400/70245]
loss: 0.219721  [12800/70245]
loss: 0.190469  [19200/70245]
loss: 0.319055  [25600/70245]
loss: 0.262842  [32000/70245]
loss: 0.180380  [38400/70245]
loss: 0.151703  [44800/70245]
loss: 0.215047  [51200/70245]
loss: 0.170870  [57600/70245]
loss: 0.190465  [64000/70245]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.214206 

Epoch 6
-------------------------------
loss: 0.140968  [    0/70245]
loss: 0.149745  [ 6400/70245]
loss: 0.285656  [12800/70245]
loss: 0.162309  [19200/70245]
loss: 0.241735  [25600/70245]
loss: 0.117527  [32000/70245]
loss: 0.253381  [38400/70245]
loss: 0.193032  [44800/70245]
loss: 0.214985  [51200/70245]
loss: 0.279865  [57600/70245]
loss: 0.245437  [64000/70245]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.212003 

Epoch 7
-------------------------------
loss: 0.096155  [    0/70245]
loss: 0.201602  [ 6400/70245]
loss: 0.310614  [12800/70245]
loss: 0.153193  [19200/70245]
loss: 0.314308  [25600/70245]
loss: 0.221141  [32000/70245]
loss: 0.273026  [38400/70245]
loss: 0.240930  [44800/70245]
loss: 0.163450  [51200/70245]
loss: 0.132053  [57600/70245]
loss: 0.240951  [64000/70245]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.209343 

Epoch 8
-------------------------------
loss: 0.238277  [    0/70245]
loss: 0.198166  [ 6400/70245]
loss: 0.126143  [12800/70245]
loss: 0.300411  [19200/70245]
loss: 0.141069  [25600/70245]
loss: 0.222914  [32000/70245]
loss: 0.136509  [38400/70245]
loss: 0.262160  [44800/70245]
loss: 0.137051  [51200/70245]
loss: 0.163178  [57600/70245]
loss: 0.257154  [64000/70245]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.206494 

Epoch 9
-------------------------------
loss: 0.139164  [    0/70245]
loss: 0.165889  [ 6400/70245]
loss: 0.108468  [12800/70245]
loss: 0.177128  [19200/70245]
loss: 0.154171  [25600/70245]
loss: 0.231584  [32000/70245]
loss: 0.249465  [38400/70245]
loss: 0.221640  [44800/70245]
loss: 0.158500  [51200/70245]
loss: 0.239325  [57600/70245]
loss: 0.185459  [64000/70245]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.204821 

Epoch 10
-------------------------------
loss: 0.118357  [    0/70245]
loss: 0.189510  [ 6400/70245]
loss: 0.103875  [12800/70245]
loss: 0.107858  [19200/70245]
loss: 0.112337  [25600/70245]
loss: 0.161844  [32000/70245]
loss: 0.164663  [38400/70245]
loss: 0.168516  [44800/70245]
loss: 0.102892  [51200/70245]
loss: 0.235545  [57600/70245]
loss: 1.688503  [64000/70245]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.209222 

Epoch 11
-------------------------------
loss: 0.394218  [    0/70245]
loss: 0.228361  [ 6400/70245]
loss: 0.139935  [12800/70245]
loss: 0.367710  [19200/70245]
loss: 0.158182  [25600/70245]
loss: 0.196614  [32000/70245]
loss: 0.153200  [38400/70245]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110521 

Epoch 8
-------------------------------
loss: 0.117757  [    0/70031]
loss: 0.062807  [ 6400/70031]
loss: 0.105025  [12800/70031]
loss: 0.135620  [19200/70031]
loss: 0.061660  [25600/70031]
loss: 0.209340  [32000/70031]
loss: 0.067624  [38400/70031]
loss: 0.144745  [44800/70031]
loss: 0.112558  [51200/70031]
loss: 0.088070  [57600/70031]
loss: 0.034450  [64000/70031]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.120783 

Epoch 9
-------------------------------
loss: 0.144293  [    0/70031]
loss: 0.134991  [ 6400/70031]
loss: 0.115031  [12800/70031]
loss: 0.086911  [19200/70031]
loss: 0.217299  [25600/70031]
loss: 0.143511  [32000/70031]
loss: 0.035880  [38400/70031]
loss: 0.233460  [44800/70031]
loss: 0.104522  [51200/70031]
loss: 0.102802  [57600/70031]
loss: 0.131087  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112903 

Epoch 10
-------------------------------
loss: 0.062362  [    0/70031]
loss: 0.133677  [ 6400/70031]
loss: 0.093075  [12800/70031]
loss: 0.035993  [19200/70031]
loss: 0.140036  [25600/70031]
loss: 0.160712  [32000/70031]
loss: 0.110073  [38400/70031]
loss: 0.083143  [44800/70031]
loss: 0.155612  [51200/70031]
loss: 0.037236  [57600/70031]
loss: 0.066611  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.113417 

Epoch 11
-------------------------------
loss: 0.044830  [    0/70031]
loss: 0.132959  [ 6400/70031]
loss: 0.122491  [12800/70031]
loss: 0.049114  [19200/70031]
loss: 0.066978  [25600/70031]
loss: 0.090301  [32000/70031]
loss: 0.167098  [38400/70031]
loss: 0.086521  [44800/70031]
loss: 0.170646  [51200/70031]
loss: 0.149222  [57600/70031]
loss: 0.118329  [64000/70031]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.126241 

Epoch 12
-------------------------------
loss: 0.051779  [    0/70031]
loss: 0.110753  [ 6400/70031]
loss: 0.071948  [12800/70031]
loss: 0.151896  [19200/70031]
loss: 0.120313  [25600/70031]
loss: 0.085770  [32000/70031]
loss: 0.160164  [38400/70031]
loss: 0.209949  [44800/70031]
loss: 0.095595  [51200/70031]
loss: 0.115070  [57600/70031]
loss: 0.123919  [64000/70031]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.107683 

Epoch 13
-------------------------------
loss: 0.129629  [    0/70031]
loss: 0.157678  [ 6400/70031]
loss: 0.073347  [12800/70031]
loss: 0.067940  [19200/70031]
loss: 0.023427  [25600/70031]
loss: 0.050081  [32000/70031]
loss: 0.048202  [38400/70031]
loss: 0.128100  [44800/70031]
loss: 0.027157  [51200/70031]
loss: 0.062077  [57600/70031]
loss: 0.128862  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.116137 

Epoch 14
-------------------------------
loss: 0.055616  [    0/70031]
loss: 0.076698  [ 6400/70031]
loss: 0.121803  [12800/70031]
loss: 0.092076  [19200/70031]
loss: 0.074174  [25600/70031]
loss: 0.075591  [32000/70031]
loss: 0.063833  [38400/70031]
loss: 0.083422  [44800/70031]
loss: 0.106151  [51200/70031]
loss: 0.183128  [57600/70031]
loss: 0.059899  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101221 

Epoch 15
-------------------------------
loss: 0.061764  [    0/70031]
loss: 0.069240  [ 6400/70031]
loss: 0.143435  [12800/70031]
loss: 0.056924  [19200/70031]
loss: 0.049067  [25600/70031]
loss: 0.064612  [32000/70031]
loss: 0.069152  [38400/70031]
loss: 0.081262  [44800/70031]
loss: 0.075784  [51200/70031]
loss: 0.108063  [57600/70031]
loss: 0.165082  [64000/70031]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.097325 

Epoch 16
-------------------------------
loss: 0.068678  [    0/70031]
loss: 0.143260  [ 6400/70031]
loss: 0.057939  [12800/70031]
loss: 0.080685  [19200/70031]
loss: 0.059843  [25600/70031]
loss: 0.103209  [32000/70031]
loss: 1.687299  [38400/70031]
loss: 0.180585  [44800/70031]
loss: 0.107516  [51200/70031]
loss: 0.078946  [57600/70031]
loss: 0.103134  [64000/70031]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.113615 

Epoch 17
-------------------------------
loss: 0.144700  [    0/70031]
loss: 0.163698  [ 6400/70031]
loss: 0.085109  [12800/70031]
loss: 0.070989  [19200/70031]
loss: 0.068736  [25600/70031]
loss: 0.076808  [32000/70031]
loss: 0.134698  [38400/70031]
loss: 0.205022  [44800/70031]
loss: 0.058556  [51200/70031]
loss: 0.122164  [57600/70031]
loss: 0.157801  [64000/70031]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.123699 

Epoch 18
-------------------------------
loss: 0.052004  [    0/70031]
loss: 0.204693  [ 6400/70031]
loss: 0.034234  [12800/70031]
loss: 0.087509  [19200/70031]
loss: 0.090090  [25600/70031]
loss: 0.145519  [32000/70031]
loss: 0.057979  [38400/70031]
loss: 0.070712  [44800/70031]
loss: 0.099828  [51200/70031]
loss: 0.065534  [57600/70031]
loss: 0.093617  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101723 

Epoch 19
-------------------------------
loss: 0.051519  [    0/70031]
loss: 0.078301  [ 6400/70031]
loss: 0.128885  [12800/70031]
loss: 0.195240  [19200/70031]
loss: 0.072362  [25600/70031]
loss: 0.102661  [32000/70031]
loss: 0.080163  [38400/70031]
loss: 0.071510  [44800/70031]
loss: 0.040365  [51200/70031]
loss: 0.083146  [57600/70031]
loss: 0.064975  [64000/70031]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102759 

Epoch 20
-------------------------------
loss: 0.111382  [    0/70031]
loss: 0.071093  [ 6400/70031]
loss: 0.128678  [12800/70031]
loss: 0.155831  [19200/70031]
loss: 0.085578  [25600/70031]
loss: 0.054704  [32000/70031]
loss: 0.271335  [38400/70031]
loss: 0.152087  [44800/70031]
loss: 0.129792  [51200/70031]
loss: 0.087258  [57600/70031]
loss: 0.127124  [64000/70031]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102887 

Epoch 21
-------------------------------
loss: 0.069084  [    0/70031]
loss: 0.079567  [ 6400/70031]
loss: 0.081797  [12800/70031]
loss: 0.116613  [19200/70031]
loss: 0.101420  [25600/70031]
loss: 0.132542  [32000/70031]
loss: 0.056279  [38400/70031]
loss: 0.042701  [44800/70031]
loss: 0.090407  [51200/70031]
loss: 0.115870  [57600/70031]
loss: 0.183161  [64000/70031]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.098749 

Epoch 22
-------------------------------
loss: 0.055114  [    0/70031]
loss: 0.039722  [ 6400/70031]
loss: 0.193878  [12800/70031]
loss: 0.100874  [19200/70031]
loss: 0.073332  [25600/70031]
loss: 0.130173  [32000/70031]
loss: 0.100581  [38400/70031]
loss: 0.092244  [44800/70031]
loss: 0.092193  [51200/70031]
loss: 0.083911  [57600/70031]
loss: 0.087334  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.105767 

Epoch 23
-------------------------------
loss: 0.097858  [    0/70031]
loss: 0.084564  [ 6400/70031]
loss: 0.061645  [12800/70031]
loss: 0.106661  [19200/70031]
loss: 0.095985  [25600/70031]
loss: 0.019571  [32000/70031]
loss: 0.131577  [38400/70031]
loss: 0.124770  [44800/70031]
loss: 0.100037  [51200/70031]
loss: 0.066381  [57600/70031]
loss: 0.112887  [64000/70031]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.106739 

Epoch 24
-------------------------------
loss: 0.071732  [    0/70031]
loss: 0.069834  [ 6400/70031]
loss: 0.072679  [12800/70031]
loss: 0.022817  [19200/70031]
loss: 0.073771  [25600/70031]
loss: 0.086340  [32000/70031]
loss: 0.027988  [38400/70031]
loss: 0.062732  [44800/70031]
loss: 0.095671  [51200/70031]
loss: 0.049158  [57600/70031]
loss: 0.032973  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.104043 

Epoch 25
-------------------------------
loss: 0.087501  [    0/70031]
loss: 0.096467  [ 6400/70031]
loss: 0.056723  [12800/70031]
loss: 0.145525  [19200/70031]
loss: 0.130486  [25600/70031]
loss: 0.095997  [32000/70031]
loss: 0.083650  [38400/70031]
loss: 0.084225  [44800/70031]
loss: 0.034790  [51200/70031]
loss: 0.079634  [57600/70031]
loss: 0.144525  [64000/70031]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.115973 

Epoch 26
-------------------------------
loss: 0.049923  [    0/70031]
loss: 0.069430  [ 6400/70031]
loss: 0.107615  [12800/70031]
loss: 0.067025  [19200/70031]
loss: 0.055014  [25600/70031]
loss: 0.059356  [32000/70031]
loss: 0.224314  [38400/70031]
loss: 0.082699  [44800/70031]
loss: 0.109126  [51200/70031]
loss: 0.054448  [57600/70031]
loss: 0.078235  [64000/70031]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.101607 

Epoch 27
-------------------------------
loss: 0.181376  [    0/70031]
loss: 0.051371  [ 6400/70031]
loss: 0.039729  [38400/71124]
loss: 0.136432  [44800/71124]
loss: 0.085276  [51200/71124]
loss: 0.149063  [57600/71124]
loss: 0.056177  [64000/71124]
loss: 0.139516  [70400/71124]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.119789 

Epoch 16
-------------------------------
loss: 0.046235  [    0/71124]
loss: 0.111954  [ 6400/71124]
loss: 0.215253  [12800/71124]
loss: 0.230052  [19200/71124]
loss: 0.061895  [25600/71124]
loss: 0.141050  [32000/71124]
loss: 0.034962  [38400/71124]
loss: 0.076238  [44800/71124]
loss: 0.077499  [51200/71124]
loss: 0.087379  [57600/71124]
loss: 0.113672  [64000/71124]
loss: 0.094816  [70400/71124]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.129482 

Epoch 17
-------------------------------
loss: 0.091113  [    0/71124]
loss: 0.144523  [ 6400/71124]
loss: 0.194161  [12800/71124]
loss: 0.049713  [19200/71124]
loss: 0.048570  [25600/71124]
loss: 0.118960  [32000/71124]
loss: 0.169735  [38400/71124]
loss: 0.043619  [44800/71124]
loss: 0.074593  [51200/71124]
loss: 0.160844  [57600/71124]
loss: 0.150236  [64000/71124]
loss: 0.181738  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.111269 

Epoch 18
-------------------------------
loss: 0.277584  [    0/71124]
loss: 0.164969  [ 6400/71124]
loss: 0.159822  [12800/71124]
loss: 0.094149  [19200/71124]
loss: 0.101987  [25600/71124]
loss: 0.066906  [32000/71124]
loss: 0.193806  [38400/71124]
loss: 0.144677  [44800/71124]
loss: 0.159279  [51200/71124]
loss: 0.107258  [57600/71124]
loss: 0.063575  [64000/71124]
loss: 0.073420  [70400/71124]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.140409 

Epoch 19
-------------------------------
loss: 0.087621  [    0/71124]
loss: 0.089165  [ 6400/71124]
loss: 0.161803  [12800/71124]
loss: 0.120388  [19200/71124]
loss: 0.208100  [25600/71124]
loss: 0.137360  [32000/71124]
loss: 0.092969  [38400/71124]
loss: 0.109030  [44800/71124]
loss: 0.091288  [51200/71124]
loss: 0.191272  [57600/71124]
loss: 0.090707  [64000/71124]
loss: 0.105975  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.108222 

Epoch 20
-------------------------------
loss: 0.057185  [    0/71124]
loss: 0.112829  [ 6400/71124]
loss: 0.093487  [12800/71124]
loss: 0.037787  [19200/71124]
loss: 0.066902  [25600/71124]
loss: 0.171360  [32000/71124]
loss: 0.095222  [38400/71124]
loss: 0.056282  [44800/71124]
loss: 0.130586  [51200/71124]
loss: 0.053402  [57600/71124]
loss: 0.085589  [64000/71124]
loss: 0.151639  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.109105 

Epoch 21
-------------------------------
loss: 0.160922  [    0/71124]
loss: 0.055130  [ 6400/71124]
loss: 0.080080  [12800/71124]
loss: 0.080546  [19200/71124]
loss: 0.117900  [25600/71124]
loss: 0.118335  [32000/71124]
loss: 0.119629  [38400/71124]
loss: 0.056917  [44800/71124]
loss: 0.194894  [51200/71124]
loss: 0.118798  [57600/71124]
loss: 0.063141  [64000/71124]
loss: 0.133776  [70400/71124]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.128892 

Epoch 22
-------------------------------
loss: 0.085774  [    0/71124]
loss: 0.073986  [ 6400/71124]
loss: 0.135434  [12800/71124]
loss: 0.138915  [19200/71124]
loss: 0.078898  [25600/71124]
loss: 0.111509  [32000/71124]
loss: 0.115343  [38400/71124]
loss: 0.157463  [44800/71124]
loss: 0.068516  [51200/71124]
loss: 0.182950  [57600/71124]
loss: 0.042565  [64000/71124]
loss: 0.132979  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.110741 

Epoch 23
-------------------------------
loss: 0.100564  [    0/71124]
loss: 0.120977  [ 6400/71124]
loss: 0.104936  [12800/71124]
loss: 0.127269  [19200/71124]
loss: 0.258406  [25600/71124]
loss: 0.055171  [32000/71124]
loss: 0.087788  [38400/71124]
loss: 0.125111  [44800/71124]
loss: 0.212582  [51200/71124]
loss: 0.129213  [57600/71124]
loss: 0.161152  [64000/71124]
loss: 0.083768  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.114545 

Epoch 24
-------------------------------
loss: 0.107283  [    0/71124]
loss: 0.034082  [ 6400/71124]
loss: 0.036966  [12800/71124]
loss: 0.157167  [19200/71124]
loss: 0.150402  [25600/71124]
loss: 0.107544  [32000/71124]
loss: 0.036207  [38400/71124]
loss: 0.142576  [44800/71124]
loss: 0.100385  [51200/71124]
loss: 0.194088  [57600/71124]
loss: 0.101033  [64000/71124]
loss: 0.019928  [70400/71124]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.109339 

Epoch 25
-------------------------------
loss: 0.117315  [    0/71124]
loss: 0.162581  [ 6400/71124]
loss: 0.060679  [12800/71124]
loss: 0.058607  [19200/71124]
loss: 0.153722  [25600/71124]
loss: 0.145149  [32000/71124]
loss: 0.102146  [38400/71124]
loss: 0.086984  [44800/71124]
loss: 0.163896  [51200/71124]
loss: 0.108087  [57600/71124]
loss: 0.079184  [64000/71124]
loss: 0.066023  [70400/71124]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.122322 

Epoch 26
-------------------------------
loss: 0.141651  [    0/71124]
loss: 0.042375  [ 6400/71124]
loss: 0.092970  [12800/71124]
loss: 0.166247  [19200/71124]
loss: 0.058351  [25600/71124]
loss: 0.045526  [32000/71124]
loss: 0.155766  [38400/71124]
loss: 0.244215  [44800/71124]
loss: 0.100797  [51200/71124]
loss: 0.070834  [57600/71124]
loss: 0.119789  [64000/71124]
loss: 0.135957  [70400/71124]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.115725 

Epoch 27
-------------------------------
loss: 0.084143  [    0/71124]
loss: 0.057811  [ 6400/71124]
loss: 0.100428  [12800/71124]
loss: 0.116933  [19200/71124]
loss: 0.084687  [25600/71124]
loss: 0.085099  [32000/71124]
loss: 0.109968  [38400/71124]
loss: 0.116368  [44800/71124]
loss: 0.079532  [51200/71124]
loss: 0.354608  [57600/71124]
loss: 0.190108  [64000/71124]
loss: 0.171453  [70400/71124]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.109238 

Epoch 28
-------------------------------
loss: 0.076277  [    0/71124]
loss: 0.104207  [ 6400/71124]
loss: 0.087006  [12800/71124]
loss: 0.161798  [19200/71124]
loss: 0.091631  [25600/71124]
loss: 0.127352  [32000/71124]
loss: 0.168849  [38400/71124]
loss: 0.232348  [44800/71124]
loss: 0.066307  [51200/71124]
loss: 0.075239  [57600/71124]
loss: 0.191972  [64000/71124]
loss: 0.125639  [70400/71124]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.126423 

Epoch 29
-------------------------------
loss: 0.071557  [    0/71124]
loss: 0.123053  [ 6400/71124]
loss: 0.191972  [12800/71124]
loss: 0.065546  [19200/71124]
loss: 0.065997  [25600/71124]
loss: 0.160948  [32000/71124]
loss: 0.055481  [38400/71124]
loss: 0.048984  [44800/71124]
loss: 0.123561  [51200/71124]
loss: 0.110184  [57600/71124]
loss: 0.152903  [64000/71124]
loss: 0.056256  [70400/71124]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.137750 

Epoch 30
-------------------------------
loss: 0.098745  [    0/71124]
loss: 0.064604  [ 6400/71124]
loss: 0.068857  [12800/71124]
loss: 0.089600  [19200/71124]
loss: 0.043357  [25600/71124]
loss: 0.195744  [32000/71124]
loss: 0.115419  [38400/71124]
loss: 0.054429  [44800/71124]
loss: 0.044124  [51200/71124]
loss: 0.073808  [57600/71124]
loss: 0.186924  [64000/71124]
loss: 0.062584  [70400/71124]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.113075 

Epoch 31
-------------------------------
loss: 0.053539  [    0/71124]
loss: 0.111649  [ 6400/71124]
loss: 0.157603  [12800/71124]
loss: 0.029043  [19200/71124]
loss: 0.149087  [25600/71124]
loss: 0.191446  [32000/71124]
loss: 0.032999  [38400/71124]
loss: 0.044186  [44800/71124]
loss: 0.121632  [51200/71124]
loss: 0.135175  [57600/71124]
loss: 0.116077  [64000/71124]
loss: 0.125052  [70400/71124]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.124054 

Epoch 32
-------------------------------
loss: 0.082195  [    0/71124]
loss: 0.163186  [ 6400/71124]
loss: 0.166846  [12800/71124]
loss: 0.119593  [19200/71124]
loss: 0.094876  [25600/71124]
loss: 0.100641  [32000/71124]
loss: 0.112229  [38400/71124]
loss: 0.155193  [44800/71124]
loss: 0.049723  [51200/71124]
loss: 0.067754  [57600/71124]
loss: 0.136192  [64000/71124]
loss: 0.053570  [70400/71124]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.122386 

Epoch 33
-------------------------------
loss: 0.159590  [    0/71124]
loss: 0.073542  [ 6400/71124]
loss: 0.080750  [12800/71124]
loss: 0.094180  [19200/71124]
loss: 0.078209  [25600/71124]
loss: 0.041208  [32000/71124]
loss: 0.097433  [38400/71124]
loss: 0.061378  [57600/71801]
loss: 0.048239  [64000/71801]
loss: 0.010795  [70400/71801]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.060197 

Epoch 26
-------------------------------
loss: 0.006792  [    0/71801]
loss: 0.040544  [ 6400/71801]
loss: 0.002734  [12800/71801]
loss: 0.037629  [19200/71801]
loss: 0.095148  [25600/71801]
loss: 0.022457  [32000/71801]
loss: 0.017568  [38400/71801]
loss: 0.015168  [44800/71801]
loss: 0.084628  [51200/71801]
loss: 0.096541  [57600/71801]
loss: 0.036500  [64000/71801]
loss: 0.087897  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.055536 

Epoch 27
-------------------------------
loss: 0.097975  [    0/71801]
loss: 0.004462  [ 6400/71801]
loss: 0.016377  [12800/71801]
loss: 0.027004  [19200/71801]
loss: 0.205919  [25600/71801]
loss: 0.086846  [32000/71801]
loss: 0.045606  [38400/71801]
loss: 0.041136  [44800/71801]
loss: 0.020078  [51200/71801]
loss: 0.005981  [57600/71801]
loss: 0.102328  [64000/71801]
loss: 0.008572  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.054093 

Epoch 28
-------------------------------
loss: 0.054506  [    0/71801]
loss: 0.010945  [ 6400/71801]
loss: 0.214184  [12800/71801]
loss: 0.069637  [19200/71801]
loss: 0.027489  [25600/71801]
loss: 0.021934  [32000/71801]
loss: 0.049759  [38400/71801]
loss: 0.032533  [44800/71801]
loss: 0.020638  [51200/71801]
loss: 0.007275  [57600/71801]
loss: 0.002729  [64000/71801]
loss: 0.004244  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.062682 

Epoch 29
-------------------------------
loss: 0.043575  [    0/71801]
loss: 0.062077  [ 6400/71801]
loss: 0.047242  [12800/71801]
loss: 0.017500  [19200/71801]
loss: 0.035108  [25600/71801]
loss: 0.012427  [32000/71801]
loss: 0.060532  [38400/71801]
loss: 0.129493  [44800/71801]
loss: 0.010039  [51200/71801]
loss: 0.062222  [57600/71801]
loss: 0.006546  [64000/71801]
loss: 0.022214  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.055871 

Epoch 30
-------------------------------
loss: 0.012160  [    0/71801]
loss: 0.006373  [ 6400/71801]
loss: 0.022647  [12800/71801]
loss: 0.093835  [19200/71801]
loss: 0.045827  [25600/71801]
loss: 0.057438  [32000/71801]
loss: 0.004814  [38400/71801]
loss: 0.197477  [44800/71801]
loss: 0.006211  [51200/71801]
loss: 0.243674  [57600/71801]
loss: 0.030258  [64000/71801]
loss: 0.045255  [70400/71801]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.065670 

Epoch 31
-------------------------------
loss: 0.002193  [    0/71801]
loss: 0.030298  [ 6400/71801]
loss: 0.010368  [12800/71801]
loss: 0.106537  [19200/71801]
loss: 0.001541  [25600/71801]
loss: 0.009041  [32000/71801]
loss: 0.057667  [38400/71801]
loss: 0.007677  [44800/71801]
loss: 0.006104  [51200/71801]
loss: 0.058956  [57600/71801]
loss: 0.084758  [64000/71801]
loss: 0.000794  [70400/71801]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.055190 

Epoch 32
-------------------------------
loss: 0.004919  [    0/71801]
loss: 0.011242  [ 6400/71801]
loss: 0.054023  [12800/71801]
loss: 0.038815  [19200/71801]
loss: 0.040963  [25600/71801]
loss: 0.036060  [32000/71801]
loss: 0.074857  [38400/71801]
loss: 0.071973  [44800/71801]
loss: 0.042853  [51200/71801]
loss: 0.007635  [57600/71801]
loss: 0.119550  [64000/71801]
loss: 0.068252  [70400/71801]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.054077 

Epoch 33
-------------------------------
loss: 0.059969  [    0/71801]
loss: 0.013040  [ 6400/71801]
loss: 0.060850  [12800/71801]
loss: 0.003772  [19200/71801]
loss: 0.008122  [25600/71801]
loss: 0.038112  [32000/71801]
loss: 0.010945  [38400/71801]
loss: 0.036180  [44800/71801]
loss: 0.015006  [51200/71801]
loss: 0.004172  [57600/71801]
loss: 0.027699  [64000/71801]
loss: 0.005063  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.057781 

Epoch 34
-------------------------------
loss: 0.008073  [    0/71801]
loss: 0.112333  [ 6400/71801]
loss: 0.015159  [12800/71801]
loss: 0.033151  [19200/71801]
loss: 0.069843  [25600/71801]
loss: 0.050639  [32000/71801]
loss: 0.080128  [38400/71801]
loss: 0.032874  [44800/71801]
loss: 0.017921  [51200/71801]
loss: 0.003875  [57600/71801]
loss: 0.003410  [64000/71801]
loss: 0.035801  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.059493 

Epoch 35
-------------------------------
loss: 0.052118  [    0/71801]
loss: 0.024786  [ 6400/71801]
loss: 0.043029  [12800/71801]
loss: 0.018011  [19200/71801]
loss: 0.051512  [25600/71801]
loss: 0.005842  [32000/71801]
loss: 0.045826  [38400/71801]
loss: 0.005623  [44800/71801]
loss: 0.047938  [51200/71801]
loss: 0.089744  [57600/71801]
loss: 0.053631  [64000/71801]
loss: 0.030919  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.061476 

Epoch 36
-------------------------------
loss: 0.017876  [    0/71801]
loss: 0.018321  [ 6400/71801]
loss: 0.001147  [12800/71801]
loss: 0.050416  [19200/71801]
loss: 0.066157  [25600/71801]
loss: 0.034800  [32000/71801]
loss: 0.004977  [38400/71801]
loss: 0.010908  [44800/71801]
loss: 0.020104  [51200/71801]
loss: 0.001227  [57600/71801]
loss: 0.163538  [64000/71801]
loss: 0.030283  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.073999 

Epoch 37
-------------------------------
loss: 0.014331  [    0/71801]
loss: 0.050391  [ 6400/71801]
loss: 0.011741  [12800/71801]
loss: 0.003712  [19200/71801]
loss: 0.023152  [25600/71801]
loss: 0.006627  [32000/71801]
loss: 0.035365  [38400/71801]
loss: 0.001741  [44800/71801]
loss: 0.008541  [51200/71801]
loss: 0.005082  [57600/71801]
loss: 0.051684  [64000/71801]
loss: 0.067899  [70400/71801]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.053708 

Epoch 38
-------------------------------
loss: 1.577629  [    0/71801]
loss: 0.034718  [ 6400/71801]
loss: 0.009409  [12800/71801]
loss: 0.001116  [19200/71801]
loss: 0.002494  [25600/71801]
loss: 0.023553  [32000/71801]
loss: 0.011729  [38400/71801]
loss: 0.027365  [44800/71801]
loss: 0.030672  [51200/71801]
loss: 0.047971  [57600/71801]
loss: 0.045468  [64000/71801]
loss: 0.007840  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.060908 

Epoch 39
-------------------------------
loss: 0.007115  [    0/71801]
loss: 0.012154  [ 6400/71801]
loss: 0.009186  [12800/71801]
loss: 0.150829  [19200/71801]
loss: 0.072233  [25600/71801]
loss: 0.028527  [32000/71801]
loss: 0.003098  [38400/71801]
loss: 0.036381  [44800/71801]
loss: 0.051557  [51200/71801]
loss: 0.040674  [57600/71801]
loss: 0.019046  [64000/71801]
loss: 0.048532  [70400/71801]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.066840 

Epoch 40
-------------------------------
loss: 0.083714  [    0/71801]
loss: 0.011719  [ 6400/71801]
loss: 0.071034  [12800/71801]
loss: 0.064986  [19200/71801]
loss: 0.033144  [25600/71801]
loss: 0.003496  [32000/71801]
loss: 0.017849  [38400/71801]
loss: 0.007040  [44800/71801]
loss: 0.000920  [51200/71801]
loss: 0.079718  [57600/71801]
loss: 0.007842  [64000/71801]
loss: 0.037060  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.068799 

Epoch 41
-------------------------------
loss: 0.061341  [    0/71801]
loss: 0.019393  [ 6400/71801]
loss: 0.045522  [12800/71801]
loss: 0.006258  [19200/71801]
loss: 0.059839  [25600/71801]
loss: 0.001923  [32000/71801]
loss: 0.003701  [38400/71801]
loss: 0.122687  [44800/71801]
loss: 0.021718  [51200/71801]
loss: 0.027684  [57600/71801]
loss: 0.050014  [64000/71801]
loss: 0.010419  [70400/71801]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.067069 

Epoch 42
-------------------------------
loss: 0.020157  [    0/71801]
loss: 0.030526  [ 6400/71801]
loss: 0.012497  [12800/71801]
loss: 0.003987  [19200/71801]
loss: 0.032202  [25600/71801]
loss: 0.048031  [32000/71801]
loss: 0.038568  [38400/71801]
loss: 0.024008  [44800/71801]
loss: 0.015952  [51200/71801]
loss: 0.031351  [57600/71801]
loss: 0.032548  [64000/71801]
loss: 0.025384  [70400/71801]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.074385 

Epoch 43
-------------------------------
loss: 0.013994  [    0/71801]
loss: 0.041910  [ 6400/71801]
loss: 0.020680  [12800/71801]
loss: 0.098031  [19200/71801]
loss: 0.045375  [25600/71801]
loss: 0.058088  [32000/71801]
loss: 0.065960  [38400/71801]
loss: 0.003812  [44800/71801]
loss: 0.063389  [51200/71801]
loss: 0.010693  [57600/71801]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.114696 

Epoch 19
-------------------------------
loss: 0.074120  [    0/70717]
loss: 0.094819  [ 6400/70717]
loss: 0.064635  [12800/70717]
loss: 0.147476  [19200/70717]
loss: 0.197949  [25600/70717]
loss: 0.098970  [32000/70717]
loss: 0.107382  [38400/70717]
loss: 0.061648  [44800/70717]
loss: 0.064232  [51200/70717]
loss: 0.058899  [57600/70717]
loss: 0.041129  [64000/70717]
loss: 0.201580  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110551 

Epoch 20
-------------------------------
loss: 0.075006  [    0/70717]
loss: 0.160908  [ 6400/70717]
loss: 0.173088  [12800/70717]
loss: 0.037242  [19200/70717]
loss: 0.100740  [25600/70717]
loss: 0.063665  [32000/70717]
loss: 0.084965  [38400/70717]
loss: 0.090433  [44800/70717]
loss: 0.134165  [51200/70717]
loss: 0.055435  [57600/70717]
loss: 0.131792  [64000/70717]
loss: 0.165288  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.112327 

Epoch 21
-------------------------------
loss: 0.054112  [    0/70717]
loss: 0.164718  [ 6400/70717]
loss: 0.075175  [12800/70717]
loss: 0.096646  [19200/70717]
loss: 0.057917  [25600/70717]
loss: 0.109734  [32000/70717]
loss: 0.352520  [38400/70717]
loss: 0.090975  [44800/70717]
loss: 0.167761  [51200/70717]
loss: 0.038893  [57600/70717]
loss: 0.105452  [64000/70717]
loss: 0.129945  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.121215 

Epoch 22
-------------------------------
loss: 0.124134  [    0/70717]
loss: 0.036486  [ 6400/70717]
loss: 0.024631  [12800/70717]
loss: 0.127651  [19200/70717]
loss: 0.064438  [25600/70717]
loss: 0.109602  [32000/70717]
loss: 0.087607  [38400/70717]
loss: 0.190235  [44800/70717]
loss: 0.064919  [51200/70717]
loss: 0.168931  [57600/70717]
loss: 0.097362  [64000/70717]
loss: 0.059117  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.119374 

Epoch 23
-------------------------------
loss: 0.023865  [    0/70717]
loss: 0.174266  [ 6400/70717]
loss: 0.117327  [12800/70717]
loss: 0.053198  [19200/70717]
loss: 0.052955  [25600/70717]
loss: 0.101734  [32000/70717]
loss: 0.096254  [38400/70717]
loss: 0.144543  [44800/70717]
loss: 0.057207  [51200/70717]
loss: 0.154140  [57600/70717]
loss: 0.025495  [64000/70717]
loss: 0.095632  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.111233 

Epoch 24
-------------------------------
loss: 0.089107  [    0/70717]
loss: 0.112115  [ 6400/70717]
loss: 0.095468  [12800/70717]
loss: 0.111733  [19200/70717]
loss: 0.081614  [25600/70717]
loss: 0.081972  [32000/70717]
loss: 0.175966  [38400/70717]
loss: 0.051774  [44800/70717]
loss: 0.106806  [51200/70717]
loss: 1.698006  [57600/70717]
loss: 0.100720  [64000/70717]
loss: 0.116790  [70400/70717]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.111894 

Epoch 25
-------------------------------
loss: 0.221934  [    0/70717]
loss: 0.126562  [ 6400/70717]
loss: 0.049631  [12800/70717]
loss: 0.180455  [19200/70717]
loss: 0.157520  [25600/70717]
loss: 0.086521  [32000/70717]
loss: 0.112998  [38400/70717]
loss: 0.047832  [44800/70717]
loss: 0.107956  [51200/70717]
loss: 0.092427  [57600/70717]
loss: 0.060814  [64000/70717]
loss: 0.313910  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110311 

Epoch 26
-------------------------------
loss: 0.098506  [    0/70717]
loss: 0.018635  [ 6400/70717]
loss: 0.204210  [12800/70717]
loss: 0.054040  [19200/70717]
loss: 0.136219  [25600/70717]
loss: 0.111259  [32000/70717]
loss: 0.053522  [38400/70717]
loss: 0.107484  [44800/70717]
loss: 0.206340  [51200/70717]
loss: 0.143019  [57600/70717]
loss: 0.116884  [64000/70717]
loss: 0.059409  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.113865 

Epoch 27
-------------------------------
loss: 0.072889  [    0/70717]
loss: 0.061752  [ 6400/70717]
loss: 0.074212  [12800/70717]
loss: 0.088760  [19200/70717]
loss: 0.092799  [25600/70717]
loss: 0.084644  [32000/70717]
loss: 0.189841  [38400/70717]
loss: 0.207603  [44800/70717]
loss: 0.141963  [51200/70717]
loss: 0.237106  [57600/70717]
loss: 0.053194  [64000/70717]
loss: 0.161098  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.118531 

Epoch 28
-------------------------------
loss: 0.145678  [    0/70717]
loss: 0.075468  [ 6400/70717]
loss: 0.101270  [12800/70717]
loss: 0.126703  [19200/70717]
loss: 0.083376  [25600/70717]
loss: 0.054663  [32000/70717]
loss: 0.093984  [38400/70717]
loss: 0.053822  [44800/70717]
loss: 0.085526  [51200/70717]
loss: 0.090371  [57600/70717]
loss: 0.092752  [64000/70717]
loss: 0.020418  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.119850 

Epoch 29
-------------------------------
loss: 0.043022  [    0/70717]
loss: 0.071032  [ 6400/70717]
loss: 0.095010  [12800/70717]
loss: 0.058988  [19200/70717]
loss: 0.120356  [25600/70717]
loss: 0.252169  [32000/70717]
loss: 0.162721  [38400/70717]
loss: 0.033787  [44800/70717]
loss: 0.155818  [51200/70717]
loss: 0.152469  [57600/70717]
loss: 0.074718  [64000/70717]
loss: 0.061678  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.114722 

Epoch 30
-------------------------------
loss: 0.041368  [    0/70717]
loss: 0.071770  [ 6400/70717]
loss: 0.097866  [12800/70717]
loss: 0.062510  [19200/70717]
loss: 0.112908  [25600/70717]
loss: 0.119040  [32000/70717]
loss: 0.080920  [38400/70717]
loss: 0.165067  [44800/70717]
loss: 0.062176  [51200/70717]
loss: 0.091735  [57600/70717]
loss: 0.081551  [64000/70717]
loss: 0.056042  [70400/70717]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.111738 

Epoch 31
-------------------------------
loss: 0.090881  [    0/70717]
loss: 0.041172  [ 6400/70717]
loss: 0.044819  [12800/70717]
loss: 0.038307  [19200/70717]
loss: 0.057976  [25600/70717]
loss: 0.060673  [32000/70717]
loss: 0.114553  [38400/70717]
loss: 0.034832  [44800/70717]
loss: 0.110093  [51200/70717]
loss: 0.143254  [57600/70717]
loss: 0.055691  [64000/70717]
loss: 0.072896  [70400/70717]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.123729 

Epoch 32
-------------------------------
loss: 0.154135  [    0/70717]
loss: 0.093218  [ 6400/70717]
loss: 0.056904  [12800/70717]
loss: 0.159495  [19200/70717]
loss: 0.060633  [25600/70717]
loss: 0.161607  [32000/70717]
loss: 0.064254  [38400/70717]
loss: 0.042463  [44800/70717]
loss: 0.041161  [51200/70717]
loss: 0.123059  [57600/70717]
loss: 0.046862  [64000/70717]
loss: 0.028306  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.113834 

Epoch 33
-------------------------------
loss: 0.043934  [    0/70717]
loss: 0.075330  [ 6400/70717]
loss: 0.081398  [12800/70717]
loss: 0.136084  [19200/70717]
loss: 0.033246  [25600/70717]
loss: 0.187908  [32000/70717]
loss: 0.069502  [38400/70717]
loss: 0.037278  [44800/70717]
loss: 0.041461  [51200/70717]
loss: 0.052906  [57600/70717]
loss: 0.092507  [64000/70717]
loss: 0.067526  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.112707 

Epoch 34
-------------------------------
loss: 0.164446  [    0/70717]
loss: 0.177723  [ 6400/70717]
loss: 0.099357  [12800/70717]
loss: 0.098251  [19200/70717]
loss: 0.021434  [25600/70717]
loss: 0.039630  [32000/70717]
loss: 0.108138  [38400/70717]
loss: 0.101646  [44800/70717]
loss: 0.078376  [51200/70717]
loss: 0.085474  [57600/70717]
loss: 0.065737  [64000/70717]
loss: 0.100384  [70400/70717]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.106077 

Epoch 35
-------------------------------
loss: 0.055409  [    0/70717]
loss: 0.074901  [ 6400/70717]
loss: 0.087068  [12800/70717]
loss: 0.161943  [19200/70717]
loss: 0.164627  [25600/70717]
loss: 0.146570  [32000/70717]
loss: 0.078408  [38400/70717]
loss: 0.162321  [44800/70717]
loss: 0.041396  [51200/70717]
loss: 0.042887  [57600/70717]
loss: 0.060024  [64000/70717]
loss: 0.075095  [70400/70717]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.112839 

Epoch 36
-------------------------------
loss: 0.134212  [    0/70717]
loss: 0.135441  [ 6400/70717]
loss: 0.073217  [12800/70717]
loss: 0.197843  [19200/70717]
loss: 0.103283  [25600/70717]
loss: 0.063973  [32000/70717]
loss: 0.093853  [38400/70717]
loss: 0.079248  [44800/70717]
loss: 0.129547  [51200/70717]
loss: 0.096859  [57600/70717]
loss: 0.092121  [64000/70717]
loss: 0.115011  [70400/70717]
Epoch 8
-------------------------------
loss: 0.141133  [    0/69195]
loss: 0.111128  [ 6400/69195]
loss: 0.278439  [12800/69195]
loss: 0.110766  [19200/69195]
loss: 0.111753  [25600/69195]
loss: 0.130503  [32000/69195]
loss: 0.110927  [38400/69195]
loss: 0.128262  [44800/69195]
loss: 0.141025  [51200/69195]
loss: 0.112724  [57600/69195]
loss: 0.246487  [64000/69195]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.181015 

Epoch 9
-------------------------------
loss: 0.238352  [    0/69195]
loss: 0.264756  [ 6400/69195]
loss: 0.139904  [12800/69195]
loss: 0.135093  [19200/69195]
loss: 0.150951  [25600/69195]
loss: 0.246121  [32000/69195]
loss: 0.122101  [38400/69195]
loss: 0.090013  [44800/69195]
loss: 0.114950  [51200/69195]
loss: 0.103125  [57600/69195]
loss: 0.155955  [64000/69195]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.148422 

Epoch 10
-------------------------------
loss: 0.115927  [    0/69195]
loss: 0.195469  [ 6400/69195]
loss: 0.267986  [12800/69195]
loss: 0.155521  [19200/69195]
loss: 0.072830  [25600/69195]
loss: 0.091226  [32000/69195]
loss: 0.179690  [38400/69195]
loss: 0.157079  [44800/69195]
loss: 0.143816  [51200/69195]
loss: 0.200918  [57600/69195]
loss: 0.086553  [64000/69195]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.169744 

Epoch 11
-------------------------------
loss: 0.167681  [    0/69195]
loss: 0.153398  [ 6400/69195]
loss: 0.146628  [12800/69195]
loss: 0.165698  [19200/69195]
loss: 0.162953  [25600/69195]
loss: 0.179679  [32000/69195]
loss: 0.183829  [38400/69195]
loss: 0.162651  [44800/69195]
loss: 0.149758  [51200/69195]
loss: 0.098048  [57600/69195]
loss: 0.079319  [64000/69195]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.139627 

Epoch 12
-------------------------------
loss: 0.096768  [    0/69195]
loss: 0.221270  [ 6400/69195]
loss: 0.188979  [12800/69195]
loss: 0.081302  [19200/69195]
loss: 0.095002  [25600/69195]
loss: 0.101273  [32000/69195]
loss: 0.135420  [38400/69195]
loss: 0.216481  [44800/69195]
loss: 0.158749  [51200/69195]
loss: 0.118176  [57600/69195]
loss: 0.147770  [64000/69195]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.148937 

Epoch 13
-------------------------------
loss: 0.103944  [    0/69195]
loss: 0.135018  [ 6400/69195]
loss: 0.226032  [12800/69195]
loss: 0.221741  [19200/69195]
loss: 0.199889  [25600/69195]
loss: 0.074119  [32000/69195]
loss: 0.114787  [38400/69195]
loss: 0.142823  [44800/69195]
loss: 0.119252  [51200/69195]
loss: 0.234219  [57600/69195]
loss: 0.192823  [64000/69195]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.138905 

Epoch 14
-------------------------------
loss: 0.070144  [    0/69195]
loss: 0.198759  [ 6400/69195]
loss: 0.116616  [12800/69195]
loss: 0.181093  [19200/69195]
loss: 0.231300  [25600/69195]
loss: 0.148278  [32000/69195]
loss: 0.101827  [38400/69195]
loss: 0.166668  [44800/69195]
loss: 0.166104  [51200/69195]
loss: 0.211775  [57600/69195]
loss: 0.203031  [64000/69195]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.140787 

Epoch 15
-------------------------------
loss: 0.070987  [    0/69195]
loss: 0.186563  [ 6400/69195]
loss: 0.059430  [12800/69195]
loss: 0.089582  [19200/69195]
loss: 0.138376  [25600/69195]
loss: 0.166731  [32000/69195]
loss: 0.221100  [38400/69195]
loss: 0.214669  [44800/69195]
loss: 0.143028  [51200/69195]
loss: 0.101555  [57600/69195]
loss: 0.209921  [64000/69195]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.144846 

Epoch 16
-------------------------------
loss: 0.169765  [    0/69195]
loss: 0.183143  [ 6400/69195]
loss: 0.259508  [12800/69195]
loss: 0.123933  [19200/69195]
loss: 0.257995  [25600/69195]
loss: 0.227817  [32000/69195]
loss: 0.104009  [38400/69195]
loss: 0.199961  [44800/69195]
loss: 0.117257  [51200/69195]
loss: 0.085007  [57600/69195]
loss: 0.123803  [64000/69195]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.140645 

Epoch 17
-------------------------------
loss: 0.194971  [    0/69195]
loss: 0.063576  [ 6400/69195]
loss: 0.211192  [12800/69195]
loss: 0.125999  [19200/69195]
loss: 0.064407  [25600/69195]
loss: 0.054146  [32000/69195]
loss: 0.161915  [38400/69195]
loss: 0.105806  [44800/69195]
loss: 0.187223  [51200/69195]
loss: 0.184547  [57600/69195]
loss: 0.174637  [64000/69195]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.139794 

Epoch 18
-------------------------------
loss: 0.143418  [    0/69195]
loss: 0.244812  [ 6400/69195]
loss: 0.145056  [12800/69195]
loss: 0.145443  [19200/69195]
loss: 0.097618  [25600/69195]
loss: 0.110776  [32000/69195]
loss: 0.123298  [38400/69195]
loss: 0.247877  [44800/69195]
loss: 0.173532  [51200/69195]
loss: 0.120208  [57600/69195]
loss: 0.255521  [64000/69195]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.137291 

Epoch 19
-------------------------------
loss: 0.126108  [    0/69195]
loss: 0.091461  [ 6400/69195]
loss: 0.145399  [12800/69195]
loss: 0.158564  [19200/69195]
loss: 0.299753  [25600/69195]
loss: 0.137043  [32000/69195]
loss: 0.171419  [38400/69195]
loss: 0.120426  [44800/69195]
loss: 0.320120  [51200/69195]
loss: 0.118153  [57600/69195]
loss: 0.113208  [64000/69195]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.135440 

Epoch 20
-------------------------------
loss: 0.232124  [    0/69195]
loss: 0.148993  [ 6400/69195]
loss: 0.080602  [12800/69195]
loss: 0.183288  [19200/69195]
loss: 0.150360  [25600/69195]
loss: 0.186234  [32000/69195]
loss: 0.135365  [38400/69195]
loss: 0.157068  [44800/69195]
loss: 0.144724  [51200/69195]
loss: 0.080641  [57600/69195]
loss: 0.216813  [64000/69195]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.146955 

Epoch 21
-------------------------------
loss: 0.078161  [    0/69195]
loss: 0.198836  [ 6400/69195]
loss: 0.153298  [12800/69195]
loss: 0.188477  [19200/69195]
loss: 0.171639  [25600/69195]
loss: 0.152811  [32000/69195]
loss: 0.140964  [38400/69195]
loss: 0.154778  [44800/69195]
loss: 0.088883  [51200/69195]
loss: 0.314053  [57600/69195]
loss: 0.052048  [64000/69195]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.149815 

Epoch 22
-------------------------------
loss: 0.208741  [    0/69195]
loss: 0.058503  [ 6400/69195]
loss: 0.150866  [12800/69195]
loss: 0.251607  [19200/69195]
loss: 0.157092  [25600/69195]
loss: 0.194220  [32000/69195]
loss: 0.168079  [38400/69195]
loss: 0.126940  [44800/69195]
loss: 0.132676  [51200/69195]
loss: 0.184145  [57600/69195]
loss: 0.140772  [64000/69195]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.139922 

Epoch 23
-------------------------------
loss: 0.213019  [    0/69195]
loss: 0.155223  [ 6400/69195]
loss: 0.050022  [12800/69195]
loss: 0.124049  [19200/69195]
loss: 0.221032  [25600/69195]
loss: 0.117488  [32000/69195]
loss: 0.182646  [38400/69195]
loss: 0.106369  [44800/69195]
loss: 0.264105  [51200/69195]
loss: 0.114442  [57600/69195]
loss: 0.113321  [64000/69195]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.133044 

Epoch 24
-------------------------------
loss: 0.139662  [    0/69195]
loss: 0.087053  [ 6400/69195]
loss: 0.113886  [12800/69195]
loss: 0.087665  [19200/69195]
loss: 0.151790  [25600/69195]
loss: 0.063907  [32000/69195]
loss: 0.112228  [38400/69195]
loss: 0.091714  [44800/69195]
loss: 0.137773  [51200/69195]
loss: 0.172790  [57600/69195]
loss: 0.047372  [64000/69195]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.146843 

Epoch 25
-------------------------------
loss: 0.066575  [    0/69195]
loss: 0.106390  [ 6400/69195]
loss: 0.215681  [12800/69195]
loss: 0.095196  [19200/69195]
loss: 0.199680  [25600/69195]
loss: 0.071373  [32000/69195]
loss: 0.213507  [38400/69195]
loss: 0.215967  [44800/69195]
loss: 0.261779  [51200/69195]
loss: 0.087692  [57600/69195]
loss: 0.160893  [64000/69195]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.142485 

Epoch 26
-------------------------------
loss: 0.228036  [    0/69195]
loss: 0.249985  [ 6400/69195]
loss: 0.094247  [12800/69195]
loss: 0.166731  [19200/69195]
loss: 0.071968  [25600/69195]
loss: 0.128035  [32000/69195]
loss: 0.129703  [38400/69195]
loss: 0.194013  [44800/69195]
loss: 0.283627  [51200/69195]
loss: 0.128977  [57600/69195]
loss: 0.152652  [64000/69195]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.142862 

Epoch 27
-------------------------------
loss: 0.082072  [    0/69195]
loss: 0.188169  [ 6400/69195]
loss: 0.071134  [12800/69195]
loss: 0.194420  [    0/69840]
loss: 0.166166  [ 6400/69840]
loss: 0.111187  [12800/69840]
loss: 0.137464  [19200/69840]
loss: 0.068041  [25600/69840]
loss: 0.106204  [32000/69840]
loss: 0.150528  [38400/69840]
loss: 0.210961  [44800/69840]
loss: 0.232900  [51200/69840]
loss: 0.405787  [57600/69840]
loss: 0.171878  [64000/69840]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.186529 

Epoch 9
-------------------------------
loss: 0.176160  [    0/69840]
loss: 0.074127  [ 6400/69840]
loss: 0.084379  [12800/69840]
loss: 0.191788  [19200/69840]
loss: 0.160397  [25600/69840]
loss: 0.131869  [32000/69840]
loss: 0.134045  [38400/69840]
loss: 0.115148  [44800/69840]
loss: 0.204095  [51200/69840]
loss: 0.369628  [57600/69840]
loss: 0.161914  [64000/69840]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174603 

Epoch 10
-------------------------------
loss: 0.240620  [    0/69840]
loss: 0.113117  [ 6400/69840]
loss: 0.204879  [12800/69840]
loss: 0.187941  [19200/69840]
loss: 0.184045  [25600/69840]
loss: 0.107852  [32000/69840]
loss: 0.136505  [38400/69840]
loss: 0.092271  [44800/69840]
loss: 0.238224  [51200/69840]
loss: 0.125868  [57600/69840]
loss: 0.125924  [64000/69840]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.163702 

Epoch 11
-------------------------------
loss: 0.210553  [    0/69840]
loss: 0.224545  [ 6400/69840]
loss: 0.181586  [12800/69840]
loss: 0.249228  [19200/69840]
loss: 0.194478  [25600/69840]
loss: 0.075617  [32000/69840]
loss: 0.130947  [38400/69840]
loss: 0.149596  [44800/69840]
loss: 0.164260  [51200/69840]
loss: 0.107167  [57600/69840]
loss: 0.189770  [64000/69840]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159122 

Epoch 12
-------------------------------
loss: 0.152103  [    0/69840]
loss: 0.128206  [ 6400/69840]
loss: 0.121217  [12800/69840]
loss: 0.201971  [19200/69840]
loss: 0.186234  [25600/69840]
loss: 0.165587  [32000/69840]
loss: 0.135957  [38400/69840]
loss: 0.153568  [44800/69840]
loss: 0.070526  [51200/69840]
loss: 0.076878  [57600/69840]
loss: 0.160049  [64000/69840]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.161533 

Epoch 13
-------------------------------
loss: 0.098177  [    0/69840]
loss: 0.238432  [ 6400/69840]
loss: 0.211124  [12800/69840]
loss: 0.089013  [19200/69840]
loss: 0.255471  [25600/69840]
loss: 0.079659  [32000/69840]
loss: 0.147017  [38400/69840]
loss: 0.123706  [44800/69840]
loss: 0.150543  [51200/69840]
loss: 0.111463  [57600/69840]
loss: 0.190051  [64000/69840]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157038 

Epoch 14
-------------------------------
loss: 0.134477  [    0/69840]
loss: 0.130947  [ 6400/69840]
loss: 0.079229  [12800/69840]
loss: 0.319179  [19200/69840]
loss: 0.168314  [25600/69840]
loss: 0.114725  [32000/69840]
loss: 0.100936  [38400/69840]
loss: 0.155236  [44800/69840]
loss: 0.097761  [51200/69840]
loss: 0.132605  [57600/69840]
loss: 0.157797  [64000/69840]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.157727 

Epoch 15
-------------------------------
loss: 0.123963  [    0/69840]
loss: 0.197775  [ 6400/69840]
loss: 0.185287  [12800/69840]
loss: 0.130602  [19200/69840]
loss: 0.160692  [25600/69840]
loss: 1.667084  [32000/69840]
loss: 0.154640  [38400/69840]
loss: 0.165508  [44800/69840]
loss: 0.133897  [51200/69840]
loss: 0.089544  [57600/69840]
loss: 0.160837  [64000/69840]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.191572 

Epoch 16
-------------------------------
loss: 0.084326  [    0/69840]
loss: 0.118093  [ 6400/69840]
loss: 0.167407  [12800/69840]
loss: 0.156960  [19200/69840]
loss: 0.164961  [25600/69840]
loss: 0.115160  [32000/69840]
loss: 0.205030  [38400/69840]
loss: 0.228193  [44800/69840]
loss: 0.126980  [51200/69840]
loss: 0.234391  [57600/69840]
loss: 0.092221  [64000/69840]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.159811 

Epoch 17
-------------------------------
loss: 0.059240  [    0/69840]
loss: 0.144352  [ 6400/69840]
loss: 0.096603  [12800/69840]
loss: 0.143348  [19200/69840]
loss: 0.130230  [25600/69840]
loss: 0.131402  [32000/69840]
loss: 0.075442  [38400/69840]
loss: 0.123463  [44800/69840]
loss: 0.221094  [51200/69840]
loss: 0.097313  [57600/69840]
loss: 0.147339  [64000/69840]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.158659 

Epoch 18
-------------------------------
loss: 0.162279  [    0/69840]
loss: 0.204856  [ 6400/69840]
loss: 0.105303  [12800/69840]
loss: 0.254949  [19200/69840]
loss: 0.085322  [25600/69840]
loss: 0.049940  [32000/69840]
loss: 0.277317  [38400/69840]
loss: 0.204132  [44800/69840]
loss: 0.102114  [51200/69840]
loss: 0.195554  [57600/69840]
loss: 0.187988  [64000/69840]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.160971 

Epoch 19
-------------------------------
loss: 0.182417  [    0/69840]
loss: 0.124286  [ 6400/69840]
loss: 0.123164  [12800/69840]
loss: 0.151687  [19200/69840]
loss: 0.187469  [25600/69840]
loss: 0.137013  [32000/69840]
loss: 0.219395  [38400/69840]
loss: 0.138125  [44800/69840]
loss: 0.205927  [51200/69840]
loss: 0.209227  [57600/69840]
loss: 0.109587  [64000/69840]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170541 

Epoch 20
-------------------------------
loss: 0.198493  [    0/69840]
loss: 0.113425  [ 6400/69840]
loss: 0.143677  [12800/69840]
loss: 0.212848  [19200/69840]
loss: 0.108248  [25600/69840]
loss: 0.194068  [32000/69840]
loss: 0.200945  [38400/69840]
loss: 0.193300  [44800/69840]
loss: 0.082183  [51200/69840]
loss: 0.106631  [57600/69840]
loss: 0.152984  [64000/69840]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.214335 

Epoch 21
-------------------------------
loss: 0.150869  [    0/69840]
loss: 0.049232  [ 6400/69840]
loss: 0.099366  [12800/69840]
loss: 0.127307  [19200/69840]
loss: 0.061855  [25600/69840]
loss: 0.152143  [32000/69840]
loss: 0.185683  [38400/69840]
loss: 0.321671  [44800/69840]
loss: 0.118705  [51200/69840]
loss: 0.172481  [57600/69840]
loss: 0.108845  [64000/69840]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.166119 

Epoch 22
-------------------------------
loss: 0.074637  [    0/69840]
loss: 0.183293  [ 6400/69840]
loss: 0.101792  [12800/69840]
loss: 0.155087  [19200/69840]
loss: 0.144210  [25600/69840]
loss: 0.119984  [32000/69840]
loss: 0.132761  [38400/69840]
loss: 0.093221  [44800/69840]
loss: 0.160561  [51200/69840]
loss: 0.121795  [57600/69840]
loss: 0.178995  [64000/69840]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.165177 

Epoch 23
-------------------------------
loss: 0.190763  [    0/69840]
loss: 0.159227  [ 6400/69840]
loss: 0.071284  [12800/69840]
loss: 0.181618  [19200/69840]
loss: 0.172258  [25600/69840]
loss: 0.162702  [32000/69840]
loss: 0.246283  [38400/69840]
loss: 0.244145  [44800/69840]
loss: 0.105484  [51200/69840]
loss: 0.130313  [57600/69840]
loss: 0.145803  [64000/69840]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.158017 

Epoch 24
-------------------------------
loss: 0.171513  [    0/69840]
loss: 0.139835  [ 6400/69840]
loss: 0.121240  [12800/69840]
loss: 0.197110  [19200/69840]
loss: 0.109775  [25600/69840]
loss: 0.172679  [32000/69840]
loss: 0.087805  [38400/69840]
loss: 0.155971  [44800/69840]
loss: 0.162211  [51200/69840]
loss: 0.106983  [57600/69840]
loss: 0.070064  [64000/69840]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.163703 

Epoch 25
-------------------------------
loss: 0.098986  [    0/69840]
loss: 0.150030  [ 6400/69840]
loss: 0.118800  [12800/69840]
loss: 0.208337  [19200/69840]
loss: 0.139408  [25600/69840]
loss: 0.210317  [32000/69840]
loss: 0.235433  [38400/69840]
loss: 0.067524  [44800/69840]
loss: 0.167754  [51200/69840]
loss: 0.202568  [57600/69840]
loss: 0.148595  [64000/69840]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.159834 

Epoch 26
-------------------------------
loss: 0.117986  [    0/69840]
loss: 0.200117  [ 6400/69840]
loss: 0.215197  [12800/69840]
loss: 0.083166  [19200/69840]
loss: 0.113016  [25600/69840]
loss: 0.042027  [32000/69840]
loss: 0.080583  [38400/69840]
loss: 0.224207  [44800/69840]
loss: 0.127024  [51200/69840]
loss: 0.146962  [57600/69840]
loss: 0.122816  [64000/69840]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.162075 

Epoch 27
-------------------------------
loss: 0.140360  [    0/69840]
loss: 0.152314  [ 6400/69840]
loss: 0.149913  [12800/69840]
loss: 0.058154  [19200/69840]
loss: 1.791933  [25600/69840]
loss: 0.048974  [ 6400/71337]
loss: 0.104103  [12800/71337]
loss: 0.052433  [19200/71337]
loss: 0.135027  [25600/71337]
loss: 0.051767  [32000/71337]
loss: 0.110524  [38400/71337]
loss: 0.059725  [44800/71337]
loss: 0.121563  [51200/71337]
loss: 0.125193  [57600/71337]
loss: 0.188762  [64000/71337]
loss: 0.071205  [70400/71337]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.109102 

Epoch 23
-------------------------------
loss: 0.139561  [    0/71337]
loss: 0.124457  [ 6400/71337]
loss: 0.020562  [12800/71337]
loss: 0.044587  [19200/71337]
loss: 0.085411  [25600/71337]
loss: 0.157354  [32000/71337]
loss: 0.104242  [38400/71337]
loss: 0.018890  [44800/71337]
loss: 0.108423  [51200/71337]
loss: 0.060576  [57600/71337]
loss: 0.101526  [64000/71337]
loss: 0.117525  [70400/71337]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.131482 

Epoch 24
-------------------------------
loss: 0.101941  [    0/71337]
loss: 0.108141  [ 6400/71337]
loss: 0.039334  [12800/71337]
loss: 0.116447  [19200/71337]
loss: 0.102131  [25600/71337]
loss: 0.076925  [32000/71337]
loss: 0.040320  [38400/71337]
loss: 0.023246  [44800/71337]
loss: 0.114167  [51200/71337]
loss: 0.020240  [57600/71337]
loss: 0.144540  [64000/71337]
loss: 0.067375  [70400/71337]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.119164 

Epoch 25
-------------------------------
loss: 0.049677  [    0/71337]
loss: 0.058645  [ 6400/71337]
loss: 0.045644  [12800/71337]
loss: 0.030511  [19200/71337]
loss: 0.074836  [25600/71337]
loss: 0.069680  [32000/71337]
loss: 0.153290  [38400/71337]
loss: 0.081397  [44800/71337]
loss: 0.065007  [51200/71337]
loss: 0.016383  [57600/71337]
loss: 0.040851  [64000/71337]
loss: 0.081632  [70400/71337]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.118201 

Epoch 26
-------------------------------
loss: 0.116156  [    0/71337]
loss: 0.078758  [ 6400/71337]
loss: 0.079135  [12800/71337]
loss: 0.079773  [19200/71337]
loss: 0.053088  [25600/71337]
loss: 0.097357  [32000/71337]
loss: 0.086603  [38400/71337]
loss: 0.094889  [44800/71337]
loss: 0.119576  [51200/71337]
loss: 0.092907  [57600/71337]
loss: 0.063220  [64000/71337]
loss: 0.091698  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.108476 

Epoch 27
-------------------------------
loss: 0.026710  [    0/71337]
loss: 0.044427  [ 6400/71337]
loss: 0.077991  [12800/71337]
loss: 0.039053  [19200/71337]
loss: 0.113616  [25600/71337]
loss: 0.045279  [32000/71337]
loss: 0.031670  [38400/71337]
loss: 0.079926  [44800/71337]
loss: 0.075190  [51200/71337]
loss: 0.023425  [57600/71337]
loss: 0.029604  [64000/71337]
loss: 0.072492  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.114768 

Epoch 28
-------------------------------
loss: 0.096108  [    0/71337]
loss: 0.112664  [ 6400/71337]
loss: 0.060848  [12800/71337]
loss: 0.082058  [19200/71337]
loss: 0.047614  [25600/71337]
loss: 0.079855  [32000/71337]
loss: 0.178307  [38400/71337]
loss: 0.098693  [44800/71337]
loss: 0.036725  [51200/71337]
loss: 0.053223  [57600/71337]
loss: 0.135410  [64000/71337]
loss: 0.048711  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.109503 

Epoch 29
-------------------------------
loss: 0.101742  [    0/71337]
loss: 0.081656  [ 6400/71337]
loss: 0.102130  [12800/71337]
loss: 0.174538  [19200/71337]
loss: 0.072937  [25600/71337]
loss: 0.092330  [32000/71337]
loss: 0.028614  [38400/71337]
loss: 0.061960  [44800/71337]
loss: 0.056239  [51200/71337]
loss: 0.114753  [57600/71337]
loss: 0.107097  [64000/71337]
loss: 0.048780  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.114345 

Epoch 30
-------------------------------
loss: 0.096652  [    0/71337]
loss: 0.025611  [ 6400/71337]
loss: 0.106014  [12800/71337]
loss: 0.054330  [19200/71337]
loss: 0.042988  [25600/71337]
loss: 0.085512  [32000/71337]
loss: 0.130647  [38400/71337]
loss: 0.112142  [44800/71337]
loss: 0.020643  [51200/71337]
loss: 0.037946  [57600/71337]
loss: 0.126406  [64000/71337]
loss: 0.093193  [70400/71337]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.114226 

Epoch 31
-------------------------------
loss: 0.077025  [    0/71337]
loss: 0.052864  [ 6400/71337]
loss: 0.057819  [12800/71337]
loss: 0.189890  [19200/71337]
loss: 0.182320  [25600/71337]
loss: 0.081173  [32000/71337]
loss: 0.020606  [38400/71337]
loss: 0.070828  [44800/71337]
loss: 0.092620  [51200/71337]
loss: 0.141808  [57600/71337]
loss: 0.067558  [64000/71337]
loss: 0.165324  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112958 

Epoch 32
-------------------------------
loss: 0.048228  [    0/71337]
loss: 0.097237  [ 6400/71337]
loss: 0.085847  [12800/71337]
loss: 0.062299  [19200/71337]
loss: 0.078756  [25600/71337]
loss: 0.092666  [32000/71337]
loss: 0.158520  [38400/71337]
loss: 0.148547  [44800/71337]
loss: 0.103898  [51200/71337]
loss: 0.087483  [57600/71337]
loss: 0.104861  [64000/71337]
loss: 0.039878  [70400/71337]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117923 

Epoch 33
-------------------------------
loss: 0.035529  [    0/71337]
loss: 0.078708  [ 6400/71337]
loss: 0.084661  [12800/71337]
loss: 0.114167  [19200/71337]
loss: 0.117138  [25600/71337]
loss: 0.027977  [32000/71337]
loss: 0.019717  [38400/71337]
loss: 0.057744  [44800/71337]
loss: 0.129309  [51200/71337]
loss: 0.063449  [57600/71337]
loss: 0.032670  [64000/71337]
loss: 0.223066  [70400/71337]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117262 

Epoch 34
-------------------------------
loss: 0.101376  [    0/71337]
loss: 0.062524  [ 6400/71337]
loss: 0.077425  [12800/71337]
loss: 0.104916  [19200/71337]
loss: 0.107183  [25600/71337]
loss: 0.055570  [32000/71337]
loss: 0.069054  [38400/71337]
loss: 0.071698  [44800/71337]
loss: 0.120208  [51200/71337]
loss: 0.100161  [57600/71337]
loss: 0.142278  [64000/71337]
loss: 0.051909  [70400/71337]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.118424 

Epoch 35
-------------------------------
loss: 0.044195  [    0/71337]
loss: 0.196238  [ 6400/71337]
loss: 0.106352  [12800/71337]
loss: 0.046949  [19200/71337]
loss: 0.038546  [25600/71337]
loss: 0.100115  [32000/71337]
loss: 0.093253  [38400/71337]
loss: 0.083826  [44800/71337]
loss: 0.147499  [51200/71337]
loss: 0.016562  [57600/71337]
loss: 0.097741  [64000/71337]
loss: 0.024919  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110891 

Epoch 36
-------------------------------
loss: 0.047943  [    0/71337]
loss: 0.043738  [ 6400/71337]
loss: 0.044049  [12800/71337]
loss: 0.139507  [19200/71337]
loss: 0.077829  [25600/71337]
loss: 0.027828  [32000/71337]
loss: 0.178244  [38400/71337]
loss: 0.113627  [44800/71337]
loss: 0.174209  [51200/71337]
loss: 0.056829  [57600/71337]
loss: 0.104763  [64000/71337]
loss: 0.050860  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112838 

Epoch 37
-------------------------------
loss: 0.083816  [    0/71337]
loss: 0.144129  [ 6400/71337]
loss: 1.644239  [12800/71337]
loss: 0.094783  [19200/71337]
loss: 0.219696  [25600/71337]
loss: 0.118986  [32000/71337]
loss: 0.048708  [38400/71337]
loss: 0.201940  [44800/71337]
loss: 0.063777  [51200/71337]
loss: 0.033291  [57600/71337]
loss: 0.043056  [64000/71337]
loss: 0.027346  [70400/71337]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.123192 

Epoch 38
-------------------------------
loss: 0.086649  [    0/71337]
loss: 0.016558  [ 6400/71337]
loss: 0.041115  [12800/71337]
loss: 0.050494  [19200/71337]
loss: 0.018495  [25600/71337]
loss: 0.077297  [32000/71337]
loss: 0.154091  [38400/71337]
loss: 0.055333  [44800/71337]
loss: 0.096606  [51200/71337]
loss: 0.045359  [57600/71337]
loss: 0.145039  [64000/71337]
loss: 0.151885  [70400/71337]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110001 

Epoch 39
-------------------------------
loss: 0.016537  [    0/71337]
loss: 0.213800  [ 6400/71337]
loss: 0.081398  [12800/71337]
loss: 0.118079  [19200/71337]
loss: 0.128237  [25600/71337]
loss: 0.150698  [32000/71337]
loss: 0.085563  [38400/71337]
loss: 0.243084  [44800/71337]
loss: 0.147737  [51200/71337]
loss: 0.062399  [57600/71337]
loss: 0.068917  [64000/71337]
loss: 0.169597  [70400/71337]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.115165 

Epoch 40
-------------------------------
loss: 0.044494  [    0/71337]
loss: 0.062988  [ 6400/71337]
loss: 0.123892  [19200/69642]
loss: 0.206615  [25600/69642]
loss: 0.147457  [32000/69642]
loss: 0.115867  [38400/69642]
loss: 0.306550  [44800/69642]
loss: 0.159038  [51200/69642]
loss: 0.252483  [57600/69642]
loss: 0.249366  [64000/69642]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.175283 

Epoch 5
-------------------------------
loss: 0.114365  [    0/69642]
loss: 0.164464  [ 6400/69642]
loss: 0.214822  [12800/69642]
loss: 0.181115  [19200/69642]
loss: 0.330556  [25600/69642]
loss: 0.166282  [32000/69642]
loss: 0.204086  [38400/69642]
loss: 0.240969  [44800/69642]
loss: 0.122566  [51200/69642]
loss: 0.186986  [57600/69642]
loss: 0.092786  [64000/69642]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.156027 

Epoch 6
-------------------------------
loss: 0.099878  [    0/69642]
loss: 0.183702  [ 6400/69642]
loss: 0.150507  [12800/69642]
loss: 0.542721  [19200/69642]
loss: 0.154472  [25600/69642]
loss: 0.219802  [32000/69642]
loss: 0.108801  [38400/69642]
loss: 0.159168  [44800/69642]
loss: 0.177852  [51200/69642]
loss: 0.105308  [57600/69642]
loss: 0.179626  [64000/69642]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.150714 

Epoch 7
-------------------------------
loss: 0.194129  [    0/69642]
loss: 0.205420  [ 6400/69642]
loss: 0.083219  [12800/69642]
loss: 0.137404  [19200/69642]
loss: 0.143487  [25600/69642]
loss: 0.164994  [32000/69642]
loss: 0.149809  [38400/69642]
loss: 0.188127  [44800/69642]
loss: 0.188403  [51200/69642]
loss: 0.091024  [57600/69642]
loss: 0.185115  [64000/69642]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.152745 

Epoch 8
-------------------------------
loss: 0.193187  [    0/69642]
loss: 0.189570  [ 6400/69642]
loss: 0.129746  [12800/69642]
loss: 0.135437  [19200/69642]
loss: 0.103415  [25600/69642]
loss: 0.136190  [32000/69642]
loss: 0.173251  [38400/69642]
loss: 0.068443  [44800/69642]
loss: 0.112977  [51200/69642]
loss: 0.137847  [57600/69642]
loss: 0.248755  [64000/69642]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.158463 

Epoch 9
-------------------------------
loss: 0.190345  [    0/69642]
loss: 0.193525  [ 6400/69642]
loss: 0.269108  [12800/69642]
loss: 0.194436  [19200/69642]
loss: 0.301304  [25600/69642]
loss: 0.216393  [32000/69642]
loss: 0.191069  [38400/69642]
loss: 0.079443  [44800/69642]
loss: 0.080643  [51200/69642]
loss: 0.177684  [57600/69642]
loss: 0.251316  [64000/69642]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.153059 

Epoch 10
-------------------------------
loss: 0.221056  [    0/69642]
loss: 0.152975  [ 6400/69642]
loss: 0.118880  [12800/69642]
loss: 0.179528  [19200/69642]
loss: 1.695341  [25600/69642]
loss: 0.069540  [32000/69642]
loss: 0.195942  [38400/69642]
loss: 0.258422  [44800/69642]
loss: 0.191095  [51200/69642]
loss: 0.274921  [57600/69642]
loss: 0.129813  [64000/69642]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.157573 

Epoch 11
-------------------------------
loss: 0.227089  [    0/69642]
loss: 0.102062  [ 6400/69642]
loss: 0.085601  [12800/69642]
loss: 0.160850  [19200/69642]
loss: 0.133230  [25600/69642]
loss: 0.159528  [32000/69642]
loss: 0.136502  [38400/69642]
loss: 0.226777  [44800/69642]
loss: 0.117552  [51200/69642]
loss: 0.246728  [57600/69642]
loss: 0.254135  [64000/69642]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.147074 

Epoch 12
-------------------------------
loss: 0.259662  [    0/69642]
loss: 0.274786  [ 6400/69642]
loss: 0.229438  [12800/69642]
loss: 0.264413  [19200/69642]
loss: 0.140969  [25600/69642]
loss: 0.173228  [32000/69642]
loss: 0.098075  [38400/69642]
loss: 0.225084  [44800/69642]
loss: 0.274941  [51200/69642]
loss: 0.173385  [57600/69642]
loss: 0.137616  [64000/69642]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.151082 

Epoch 13
-------------------------------
loss: 0.317204  [    0/69642]
loss: 0.137626  [ 6400/69642]
loss: 0.227300  [12800/69642]
loss: 0.138490  [19200/69642]
loss: 0.165174  [25600/69642]
loss: 0.288288  [32000/69642]
loss: 0.522884  [38400/69642]
loss: 0.149108  [44800/69642]
loss: 0.064304  [51200/69642]
loss: 0.140801  [57600/69642]
loss: 0.258691  [64000/69642]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.153622 

Epoch 14
-------------------------------
loss: 0.164380  [    0/69642]
loss: 0.163912  [ 6400/69642]
loss: 0.124709  [12800/69642]
loss: 0.165115  [19200/69642]
loss: 0.226155  [25600/69642]
loss: 0.174944  [32000/69642]
loss: 0.094356  [38400/69642]
loss: 0.203177  [44800/69642]
loss: 0.069679  [51200/69642]
loss: 0.107551  [57600/69642]
loss: 0.150338  [64000/69642]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.168381 

Epoch 15
-------------------------------
loss: 0.143997  [    0/69642]
loss: 0.196001  [ 6400/69642]
loss: 0.165099  [12800/69642]
loss: 0.197022  [19200/69642]
loss: 0.169242  [25600/69642]
loss: 0.252412  [32000/69642]
loss: 0.097004  [38400/69642]
loss: 0.154831  [44800/69642]
loss: 0.257919  [51200/69642]
loss: 0.342516  [57600/69642]
loss: 0.183111  [64000/69642]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.153971 

Epoch 16
-------------------------------
loss: 0.110521  [    0/69642]
loss: 0.194517  [ 6400/69642]
loss: 0.176115  [12800/69642]
loss: 0.085258  [19200/69642]
loss: 0.312853  [25600/69642]
loss: 0.086830  [32000/69642]
loss: 0.091077  [38400/69642]
loss: 0.179244  [44800/69642]
loss: 0.175152  [51200/69642]
loss: 0.147040  [57600/69642]
loss: 0.166666  [64000/69642]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.166962 

Epoch 17
-------------------------------
loss: 0.151119  [    0/69642]
loss: 0.254503  [ 6400/69642]
loss: 0.150026  [12800/69642]
loss: 0.180310  [19200/69642]
loss: 0.156137  [25600/69642]
loss: 0.143035  [32000/69642]
loss: 0.080336  [38400/69642]
loss: 0.158562  [44800/69642]
loss: 0.281175  [51200/69642]
loss: 0.155063  [57600/69642]
loss: 0.146164  [64000/69642]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.163617 

Epoch 18
-------------------------------
loss: 0.110935  [    0/69642]
loss: 0.206568  [ 6400/69642]
loss: 0.233532  [12800/69642]
loss: 0.257812  [19200/69642]
loss: 0.184597  [25600/69642]
loss: 0.207296  [32000/69642]
loss: 0.105378  [38400/69642]
loss: 0.084458  [44800/69642]
loss: 0.123457  [51200/69642]
loss: 0.132446  [57600/69642]
loss: 0.103582  [64000/69642]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.152114 

Epoch 19
-------------------------------
loss: 0.155707  [    0/69642]
loss: 0.113522  [ 6400/69642]
loss: 0.176327  [12800/69642]
loss: 0.129622  [19200/69642]
loss: 0.085876  [25600/69642]
loss: 0.147301  [32000/69642]
loss: 0.130581  [38400/69642]
loss: 0.189489  [44800/69642]
loss: 0.102005  [51200/69642]
loss: 0.066319  [57600/69642]
loss: 0.177056  [64000/69642]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.168322 

Epoch 20
-------------------------------
loss: 0.201941  [    0/69642]
loss: 0.145825  [ 6400/69642]
loss: 0.072233  [12800/69642]
loss: 0.236070  [19200/69642]
loss: 0.060607  [25600/69642]
loss: 0.119683  [32000/69642]
loss: 0.205878  [38400/69642]
loss: 0.197946  [44800/69642]
loss: 0.137548  [51200/69642]
loss: 0.089356  [57600/69642]
loss: 0.170308  [64000/69642]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.150357 

Epoch 21
-------------------------------
loss: 0.133964  [    0/69642]
loss: 0.145452  [ 6400/69642]
loss: 0.112413  [12800/69642]
loss: 0.134301  [19200/69642]
loss: 0.107529  [25600/69642]
loss: 0.223114  [32000/69642]
loss: 0.170475  [38400/69642]
loss: 0.108755  [44800/69642]
loss: 0.208823  [51200/69642]
loss: 0.181844  [57600/69642]
loss: 0.131567  [64000/69642]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.155252 

Epoch 22
-------------------------------
loss: 0.131912  [    0/69642]
loss: 0.110730  [ 6400/69642]
loss: 0.127957  [12800/69642]
loss: 0.146870  [19200/69642]
loss: 0.280216  [25600/69642]
loss: 0.203938  [32000/69642]
loss: 0.313709  [38400/69642]
loss: 0.071203  [44800/69642]
loss: 0.081339  [51200/69642]
loss: 0.212948  [57600/69642]
loss: 0.112215  [64000/69642]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.202879 

Epoch 23
-------------------------------
loss: 0.128251  [    0/69642]
loss: 0.184876  [ 6400/69642]
loss: 0.149330  [12800/69642]
loss: 0.198840  [19200/69642]
loss: 0.143882  [25600/69642]
loss: 0.182689  [32000/69642]
loss: 0.174749  [38400/69642]
loss: 0.190130  [44800/69642]
loss: 0.221353  [ 6400/69766]
loss: 0.061364  [12800/69766]
loss: 0.049727  [19200/69766]
loss: 0.117741  [25600/69766]
loss: 0.090431  [32000/69766]
loss: 0.077628  [38400/69766]
loss: 0.139971  [44800/69766]
loss: 0.037515  [51200/69766]
loss: 0.074038  [57600/69766]
loss: 0.233354  [64000/69766]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.128007 

Epoch 21
-------------------------------
loss: 0.042300  [    0/69766]
loss: 0.170346  [ 6400/69766]
loss: 0.132108  [12800/69766]
loss: 0.130609  [19200/69766]
loss: 0.146868  [25600/69766]
loss: 0.106967  [32000/69766]
loss: 0.123256  [38400/69766]
loss: 0.135305  [44800/69766]
loss: 0.083993  [51200/69766]
loss: 0.137290  [57600/69766]
loss: 0.107193  [64000/69766]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.249416 

Epoch 22
-------------------------------
loss: 0.135691  [    0/69766]
loss: 0.053312  [ 6400/69766]
loss: 0.080459  [12800/69766]
loss: 0.072075  [19200/69766]
loss: 0.060823  [25600/69766]
loss: 0.069845  [32000/69766]
loss: 0.039297  [38400/69766]
loss: 0.052643  [44800/69766]
loss: 0.097875  [51200/69766]
loss: 0.066801  [57600/69766]
loss: 0.110889  [64000/69766]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.130617 

Epoch 23
-------------------------------
loss: 0.184358  [    0/69766]
loss: 0.098072  [ 6400/69766]
loss: 0.045580  [12800/69766]
loss: 0.310656  [19200/69766]
loss: 0.077908  [25600/69766]
loss: 0.056133  [32000/69766]
loss: 0.103079  [38400/69766]
loss: 0.179680  [44800/69766]
loss: 0.253762  [51200/69766]
loss: 0.047326  [57600/69766]
loss: 0.077216  [64000/69766]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.135375 

Epoch 24
-------------------------------
loss: 0.069482  [    0/69766]
loss: 0.148850  [ 6400/69766]
loss: 0.045882  [12800/69766]
loss: 0.094788  [19200/69766]
loss: 0.063167  [25600/69766]
loss: 0.129876  [32000/69766]
loss: 0.190253  [38400/69766]
loss: 0.044332  [44800/69766]
loss: 0.105950  [51200/69766]
loss: 0.059584  [57600/69766]
loss: 0.120860  [64000/69766]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.130569 

Epoch 25
-------------------------------
loss: 0.074754  [    0/69766]
loss: 0.053707  [ 6400/69766]
loss: 0.038083  [12800/69766]
loss: 0.093501  [19200/69766]
loss: 0.122444  [25600/69766]
loss: 0.088083  [32000/69766]
loss: 0.097808  [38400/69766]
loss: 0.187288  [44800/69766]
loss: 0.156244  [51200/69766]
loss: 0.184798  [57600/69766]
loss: 0.045971  [64000/69766]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.132857 

Epoch 26
-------------------------------
loss: 0.104480  [    0/69766]
loss: 0.091455  [ 6400/69766]
loss: 0.179422  [12800/69766]
loss: 0.158020  [19200/69766]
loss: 0.143129  [25600/69766]
loss: 0.122608  [32000/69766]
loss: 0.114299  [38400/69766]
loss: 0.291788  [44800/69766]
loss: 0.097922  [51200/69766]
loss: 0.129891  [57600/69766]
loss: 0.068167  [64000/69766]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.126621 

Epoch 27
-------------------------------
loss: 0.099011  [    0/69766]
loss: 0.079121  [ 6400/69766]
loss: 0.113028  [12800/69766]
loss: 1.641917  [19200/69766]
loss: 0.133311  [25600/69766]
loss: 0.150621  [32000/69766]
loss: 0.210852  [38400/69766]
loss: 0.078968  [44800/69766]
loss: 0.136603  [51200/69766]
loss: 0.226471  [57600/69766]
loss: 0.144605  [64000/69766]
Test Error: 
 Accuracy: 84.8%, Avg loss: 0.410866 

Epoch 28
-------------------------------
loss: 0.331753  [    0/69766]
loss: 0.113444  [ 6400/69766]
loss: 0.044027  [12800/69766]
loss: 0.211918  [19200/69766]
loss: 0.152261  [25600/69766]
loss: 0.151263  [32000/69766]
loss: 0.082371  [38400/69766]
loss: 0.100896  [44800/69766]
loss: 0.089833  [51200/69766]
loss: 0.118146  [57600/69766]
loss: 0.166097  [64000/69766]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.132164 

Epoch 29
-------------------------------
loss: 0.108929  [    0/69766]
loss: 0.070986  [ 6400/69766]
loss: 0.138379  [12800/69766]
loss: 0.069136  [19200/69766]
loss: 1.636031  [25600/69766]
loss: 0.082440  [32000/69766]
loss: 0.090015  [38400/69766]
loss: 0.068916  [44800/69766]
loss: 0.191974  [51200/69766]
loss: 0.098211  [57600/69766]
loss: 0.077832  [64000/69766]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.161168 

Epoch 30
-------------------------------
loss: 0.128472  [    0/69766]
loss: 0.095410  [ 6400/69766]
loss: 0.179759  [12800/69766]
loss: 0.105117  [19200/69766]
loss: 0.175736  [25600/69766]
loss: 0.112906  [32000/69766]
loss: 0.102311  [38400/69766]
loss: 0.038842  [44800/69766]
loss: 0.100460  [51200/69766]
loss: 0.050545  [57600/69766]
loss: 0.176691  [64000/69766]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.133660 

Epoch 31
-------------------------------
loss: 0.107746  [    0/69766]
loss: 0.035878  [ 6400/69766]
loss: 0.247077  [12800/69766]
loss: 0.208945  [19200/69766]
loss: 0.057919  [25600/69766]
loss: 0.145377  [32000/69766]
loss: 0.130418  [38400/69766]
loss: 0.115515  [44800/69766]
loss: 0.123728  [51200/69766]
loss: 0.123690  [57600/69766]
loss: 0.050615  [64000/69766]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.137137 

Epoch 32
-------------------------------
loss: 1.631702  [    0/69766]
loss: 0.143725  [ 6400/69766]
loss: 0.037725  [12800/69766]
loss: 0.058689  [19200/69766]
loss: 0.190798  [25600/69766]
loss: 0.108314  [32000/69766]
loss: 0.199749  [38400/69766]
loss: 0.109163  [44800/69766]
loss: 0.111197  [51200/69766]
loss: 0.096337  [57600/69766]
loss: 0.082820  [64000/69766]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.130409 

Epoch 33
-------------------------------
loss: 0.265253  [    0/69766]
loss: 0.109199  [ 6400/69766]
loss: 0.227844  [12800/69766]
loss: 0.040331  [19200/69766]
loss: 0.196373  [25600/69766]
loss: 0.083837  [32000/69766]
loss: 0.087901  [38400/69766]
loss: 0.136451  [44800/69766]
loss: 0.105121  [51200/69766]
loss: 0.139987  [57600/69766]
loss: 0.048999  [64000/69766]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.131445 

Epoch 34
-------------------------------
loss: 0.193222  [    0/69766]
loss: 0.075000  [ 6400/69766]
loss: 0.057786  [12800/69766]
loss: 0.073445  [19200/69766]
loss: 0.097312  [25600/69766]
loss: 0.123542  [32000/69766]
loss: 0.031833  [38400/69766]
loss: 0.134043  [44800/69766]
loss: 0.256354  [51200/69766]
loss: 0.173313  [57600/69766]
loss: 0.096907  [64000/69766]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.153218 

Epoch 35
-------------------------------
loss: 0.124185  [    0/69766]
loss: 0.073059  [ 6400/69766]
loss: 0.086432  [12800/69766]
loss: 0.057611  [19200/69766]
loss: 0.200663  [25600/69766]
loss: 0.107421  [32000/69766]
loss: 0.114554  [38400/69766]
loss: 0.141902  [44800/69766]
loss: 0.049048  [51200/69766]
loss: 0.096414  [57600/69766]
loss: 0.030979  [64000/69766]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.144743 

Epoch 36
-------------------------------
loss: 0.099922  [    0/69766]
loss: 0.086923  [ 6400/69766]
loss: 0.071294  [12800/69766]
loss: 0.088877  [19200/69766]
loss: 0.047530  [25600/69766]
loss: 0.058888  [32000/69766]
loss: 0.142036  [38400/69766]
loss: 0.092682  [44800/69766]
loss: 0.097466  [51200/69766]
loss: 0.251432  [57600/69766]
loss: 0.101371  [64000/69766]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.133085 

Epoch 37
-------------------------------
loss: 0.030972  [    0/69766]
loss: 0.144679  [ 6400/69766]
loss: 0.089643  [12800/69766]
loss: 0.065448  [19200/69766]
loss: 0.068280  [25600/69766]
loss: 0.168651  [32000/69766]
loss: 0.058166  [38400/69766]
loss: 0.064758  [44800/69766]
loss: 0.071648  [51200/69766]
loss: 0.068205  [57600/69766]
loss: 0.099099  [64000/69766]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.126877 

Epoch 38
-------------------------------
loss: 0.030197  [    0/69766]
loss: 0.109665  [ 6400/69766]
loss: 0.141782  [12800/69766]
loss: 0.075266  [19200/69766]
loss: 0.132632  [25600/69766]
loss: 0.054522  [32000/69766]
loss: 0.111247  [38400/69766]
loss: 0.228887  [44800/69766]
loss: 0.060690  [51200/69766]
loss: 0.205113  [57600/69766]
loss: 0.090032  [64000/69766]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.131456 

Epoch 39
-------------------------------
loss: 0.115517  [    0/69766]
loss: 0.084380  [ 6400/69766]
loss: 0.091613  [12800/69766]
loss: 0.122173  [19200/69766]
loss: 0.079257  [25600/69766]
loss: 0.100992  [32000/69766]
loss: 0.160147  [51200/70299]
loss: 0.041395  [57600/70299]
loss: 0.077583  [64000/70299]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.101248 

Epoch 17
-------------------------------
loss: 0.058973  [    0/70299]
loss: 0.063606  [ 6400/70299]
loss: 0.105516  [12800/70299]
loss: 0.058872  [19200/70299]
loss: 0.117863  [25600/70299]
loss: 0.084242  [32000/70299]
loss: 0.102087  [38400/70299]
loss: 0.120704  [44800/70299]
loss: 0.072646  [51200/70299]
loss: 0.065062  [57600/70299]
loss: 0.171784  [64000/70299]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.098720 

Epoch 18
-------------------------------
loss: 0.068315  [    0/70299]
loss: 0.096504  [ 6400/70299]
loss: 0.123582  [12800/70299]
loss: 0.013719  [19200/70299]
loss: 0.059745  [25600/70299]
loss: 0.147122  [32000/70299]
loss: 0.059890  [38400/70299]
loss: 0.167287  [44800/70299]
loss: 0.054489  [51200/70299]
loss: 0.041966  [57600/70299]
loss: 0.059993  [64000/70299]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.104682 

Epoch 19
-------------------------------
loss: 0.091741  [    0/70299]
loss: 0.028194  [ 6400/70299]
loss: 0.064882  [12800/70299]
loss: 0.016069  [19200/70299]
loss: 0.096118  [25600/70299]
loss: 0.051172  [32000/70299]
loss: 0.034816  [38400/70299]
loss: 0.064214  [44800/70299]
loss: 0.039736  [51200/70299]
loss: 0.105295  [57600/70299]
loss: 0.158662  [64000/70299]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.115062 

Epoch 20
-------------------------------
loss: 0.104185  [    0/70299]
loss: 0.082943  [ 6400/70299]
loss: 0.077797  [12800/70299]
loss: 0.115263  [19200/70299]
loss: 0.050371  [25600/70299]
loss: 0.090926  [32000/70299]
loss: 0.064754  [38400/70299]
loss: 0.041913  [44800/70299]
loss: 0.126696  [51200/70299]
loss: 0.134323  [57600/70299]
loss: 0.016515  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.100310 

Epoch 21
-------------------------------
loss: 0.122244  [    0/70299]
loss: 0.046862  [ 6400/70299]
loss: 0.063242  [12800/70299]
loss: 0.067990  [19200/70299]
loss: 0.066744  [25600/70299]
loss: 0.042118  [32000/70299]
loss: 0.069135  [38400/70299]
loss: 0.125340  [44800/70299]
loss: 0.090976  [51200/70299]
loss: 0.071890  [57600/70299]
loss: 0.031415  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.101993 

Epoch 22
-------------------------------
loss: 0.349294  [    0/70299]
loss: 0.071644  [ 6400/70299]
loss: 0.124815  [12800/70299]
loss: 0.220549  [19200/70299]
loss: 0.094040  [25600/70299]
loss: 0.052335  [32000/70299]
loss: 0.176818  [38400/70299]
loss: 0.082676  [44800/70299]
loss: 0.110191  [51200/70299]
loss: 0.095054  [57600/70299]
loss: 0.096250  [64000/70299]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.103241 

Epoch 23
-------------------------------
loss: 0.039857  [    0/70299]
loss: 0.038188  [ 6400/70299]
loss: 0.082886  [12800/70299]
loss: 0.057038  [19200/70299]
loss: 0.065178  [25600/70299]
loss: 0.215777  [32000/70299]
loss: 0.125625  [38400/70299]
loss: 0.052656  [44800/70299]
loss: 0.040950  [51200/70299]
loss: 0.070554  [57600/70299]
loss: 0.084537  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.098586 

Epoch 24
-------------------------------
loss: 0.025811  [    0/70299]
loss: 1.645980  [ 6400/70299]
loss: 0.068640  [12800/70299]
loss: 0.193379  [19200/70299]
loss: 0.029145  [25600/70299]
loss: 0.093895  [32000/70299]
loss: 0.075987  [38400/70299]
loss: 0.130353  [44800/70299]
loss: 0.053285  [51200/70299]
loss: 0.101641  [57600/70299]
loss: 0.088447  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.097932 

Epoch 25
-------------------------------
loss: 0.040798  [    0/70299]
loss: 0.131551  [ 6400/70299]
loss: 0.102963  [12800/70299]
loss: 0.053349  [19200/70299]
loss: 0.224708  [25600/70299]
loss: 0.084996  [32000/70299]
loss: 0.028327  [38400/70299]
loss: 0.101656  [44800/70299]
loss: 0.061996  [51200/70299]
loss: 0.053063  [57600/70299]
loss: 0.031205  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.102217 

Epoch 26
-------------------------------
loss: 0.076461  [    0/70299]
loss: 0.062132  [ 6400/70299]
loss: 0.031943  [12800/70299]
loss: 0.050907  [19200/70299]
loss: 0.016781  [25600/70299]
loss: 0.183528  [32000/70299]
loss: 0.092631  [38400/70299]
loss: 0.062627  [44800/70299]
loss: 0.089607  [51200/70299]
loss: 0.159393  [57600/70299]
loss: 0.108606  [64000/70299]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.097441 

Epoch 27
-------------------------------
loss: 0.079471  [    0/70299]
loss: 0.087168  [ 6400/70299]
loss: 0.055541  [12800/70299]
loss: 0.055467  [19200/70299]
loss: 0.273477  [25600/70299]
loss: 0.076247  [32000/70299]
loss: 0.069243  [38400/70299]
loss: 0.054585  [44800/70299]
loss: 0.059577  [51200/70299]
loss: 0.068774  [57600/70299]
loss: 0.081075  [64000/70299]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.099204 

Epoch 28
-------------------------------
loss: 0.022609  [    0/70299]
loss: 0.120822  [ 6400/70299]
loss: 0.038704  [12800/70299]
loss: 0.012909  [19200/70299]
loss: 0.033014  [25600/70299]
loss: 0.088727  [32000/70299]
loss: 0.032935  [38400/70299]
loss: 0.056013  [44800/70299]
loss: 0.036790  [51200/70299]
loss: 0.094178  [57600/70299]
loss: 0.229788  [64000/70299]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.118277 

Epoch 29
-------------------------------
loss: 0.173127  [    0/70299]
loss: 0.085699  [ 6400/70299]
loss: 0.251693  [12800/70299]
loss: 0.077289  [19200/70299]
loss: 0.052244  [25600/70299]
loss: 0.113585  [32000/70299]
loss: 0.023161  [38400/70299]
loss: 0.081948  [44800/70299]
loss: 0.073971  [51200/70299]
loss: 0.039239  [57600/70299]
loss: 0.073023  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.100529 

Epoch 30
-------------------------------
loss: 0.117994  [    0/70299]
loss: 0.043493  [ 6400/70299]
loss: 0.078362  [12800/70299]
loss: 0.088663  [19200/70299]
loss: 0.066951  [25600/70299]
loss: 0.081901  [32000/70299]
loss: 0.114161  [38400/70299]
loss: 0.137356  [44800/70299]
loss: 0.059788  [51200/70299]
loss: 0.075276  [57600/70299]
loss: 0.058539  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.102830 

Epoch 31
-------------------------------
loss: 0.065383  [    0/70299]
loss: 0.096264  [ 6400/70299]
loss: 0.135393  [12800/70299]
loss: 0.034377  [19200/70299]
loss: 0.095565  [25600/70299]
loss: 0.039065  [32000/70299]
loss: 0.057952  [38400/70299]
loss: 0.173489  [44800/70299]
loss: 0.059540  [51200/70299]
loss: 0.011161  [57600/70299]
loss: 0.115415  [64000/70299]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.108391 

Epoch 32
-------------------------------
loss: 0.064588  [    0/70299]
loss: 0.118027  [ 6400/70299]
loss: 0.061949  [12800/70299]
loss: 0.087538  [19200/70299]
loss: 1.637977  [25600/70299]
loss: 0.042797  [32000/70299]
loss: 0.026299  [38400/70299]
loss: 0.024941  [44800/70299]
loss: 0.030302  [51200/70299]
loss: 0.141080  [57600/70299]
loss: 0.040908  [64000/70299]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110411 

Epoch 33
-------------------------------
loss: 0.172935  [    0/70299]
loss: 0.122887  [ 6400/70299]
loss: 0.059737  [12800/70299]
loss: 0.048264  [19200/70299]
loss: 0.127785  [25600/70299]
loss: 0.084061  [32000/70299]
loss: 0.066369  [38400/70299]
loss: 0.151169  [44800/70299]
loss: 0.104589  [51200/70299]
loss: 0.099894  [57600/70299]
loss: 0.091459  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.106490 

Epoch 34
-------------------------------
loss: 0.014863  [    0/70299]
loss: 0.043266  [ 6400/70299]
loss: 0.029268  [12800/70299]
loss: 0.096580  [19200/70299]
loss: 0.043773  [25600/70299]
loss: 0.017489  [32000/70299]
loss: 0.110639  [38400/70299]
loss: 0.087145  [44800/70299]
loss: 0.072695  [51200/70299]
loss: 0.150477  [57600/70299]
loss: 0.077311  [64000/70299]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110590 

Epoch 35
-------------------------------
loss: 0.121479  [    0/70299]
loss: 0.073415  [ 6400/70299]
loss: 0.095413  [12800/70299]
loss: 0.056622  [19200/70299]
loss: 0.119386  [25600/70299]
loss: 0.094416  [32000/70299]
loss: 0.103476  [38400/70299]
loss: 0.124681  [44800/70299]
loss: 0.146745  [51200/70299]
loss: 0.091573  [57600/70299]
loss: 0.149183  [64000/70299]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.102175 

loss: 0.077494  [57600/71250]
loss: 0.160297  [64000/71250]
loss: 0.116546  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.106149 

Epoch 26
-------------------------------
loss: 0.056405  [    0/71250]
loss: 0.030034  [ 6400/71250]
loss: 0.108561  [12800/71250]
loss: 0.044356  [19200/71250]
loss: 0.252505  [25600/71250]
loss: 0.085532  [32000/71250]
loss: 0.185861  [38400/71250]
loss: 0.060427  [44800/71250]
loss: 0.093597  [51200/71250]
loss: 0.254601  [57600/71250]
loss: 0.101450  [64000/71250]
loss: 0.109591  [70400/71250]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.101738 

Epoch 27
-------------------------------
loss: 0.087608  [    0/71250]
loss: 0.024455  [ 6400/71250]
loss: 0.087874  [12800/71250]
loss: 0.104002  [19200/71250]
loss: 0.024775  [25600/71250]
loss: 0.139264  [32000/71250]
loss: 0.099246  [38400/71250]
loss: 0.089989  [44800/71250]
loss: 0.169396  [51200/71250]
loss: 0.061131  [57600/71250]
loss: 0.144592  [64000/71250]
loss: 0.062225  [70400/71250]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095942 

Epoch 28
-------------------------------
loss: 0.076303  [    0/71250]
loss: 0.127353  [ 6400/71250]
loss: 0.024419  [12800/71250]
loss: 0.064295  [19200/71250]
loss: 0.149408  [25600/71250]
loss: 0.077199  [32000/71250]
loss: 0.042328  [38400/71250]
loss: 0.090024  [44800/71250]
loss: 0.031039  [51200/71250]
loss: 0.043174  [57600/71250]
loss: 0.149072  [64000/71250]
loss: 0.049469  [70400/71250]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.101166 

Epoch 29
-------------------------------
loss: 0.079321  [    0/71250]
loss: 0.130502  [ 6400/71250]
loss: 0.082987  [12800/71250]
loss: 0.075206  [19200/71250]
loss: 0.368681  [25600/71250]
loss: 0.064204  [32000/71250]
loss: 0.074442  [38400/71250]
loss: 0.105275  [44800/71250]
loss: 0.147419  [51200/71250]
loss: 0.101574  [57600/71250]
loss: 0.169499  [64000/71250]
loss: 0.074616  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.096273 

Epoch 30
-------------------------------
loss: 0.141778  [    0/71250]
loss: 0.051709  [ 6400/71250]
loss: 0.089842  [12800/71250]
loss: 0.070877  [19200/71250]
loss: 0.105196  [25600/71250]
loss: 0.045486  [32000/71250]
loss: 0.119344  [38400/71250]
loss: 0.103703  [44800/71250]
loss: 0.175705  [51200/71250]
loss: 0.137018  [57600/71250]
loss: 0.102867  [64000/71250]
loss: 0.134250  [70400/71250]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095569 

Epoch 31
-------------------------------
loss: 0.060271  [    0/71250]
loss: 0.100641  [ 6400/71250]
loss: 0.150320  [12800/71250]
loss: 0.111259  [19200/71250]
loss: 0.124939  [25600/71250]
loss: 0.038077  [32000/71250]
loss: 0.270325  [38400/71250]
loss: 0.145855  [44800/71250]
loss: 0.148006  [51200/71250]
loss: 0.126809  [57600/71250]
loss: 0.036321  [64000/71250]
loss: 0.103802  [70400/71250]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.107552 

Epoch 32
-------------------------------
loss: 0.017780  [    0/71250]
loss: 0.221705  [ 6400/71250]
loss: 0.040291  [12800/71250]
loss: 0.067975  [19200/71250]
loss: 0.067037  [25600/71250]
loss: 0.116766  [32000/71250]
loss: 0.164137  [38400/71250]
loss: 0.099592  [44800/71250]
loss: 0.060251  [51200/71250]
loss: 0.061772  [57600/71250]
loss: 0.094428  [64000/71250]
loss: 0.063729  [70400/71250]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.153118 

Epoch 33
-------------------------------
loss: 0.096678  [    0/71250]
loss: 0.118906  [ 6400/71250]
loss: 0.127939  [12800/71250]
loss: 0.052803  [19200/71250]
loss: 0.139684  [25600/71250]
loss: 0.093934  [32000/71250]
loss: 0.079612  [38400/71250]
loss: 0.115828  [44800/71250]
loss: 0.116263  [51200/71250]
loss: 0.186091  [57600/71250]
loss: 0.051810  [64000/71250]
loss: 0.021246  [70400/71250]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.100358 

Epoch 34
-------------------------------
loss: 0.141547  [    0/71250]
loss: 0.162104  [ 6400/71250]
loss: 0.058820  [12800/71250]
loss: 0.157632  [19200/71250]
loss: 0.046501  [25600/71250]
loss: 0.046015  [32000/71250]
loss: 0.133827  [38400/71250]
loss: 0.046306  [44800/71250]
loss: 0.101578  [51200/71250]
loss: 0.097270  [57600/71250]
loss: 0.060305  [64000/71250]
loss: 0.073189  [70400/71250]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.093244 

Epoch 35
-------------------------------
loss: 0.063121  [    0/71250]
loss: 0.116962  [ 6400/71250]
loss: 0.058767  [12800/71250]
loss: 0.122831  [19200/71250]
loss: 0.137557  [25600/71250]
loss: 0.035144  [32000/71250]
loss: 0.035739  [38400/71250]
loss: 0.118174  [44800/71250]
loss: 0.058620  [51200/71250]
loss: 0.029633  [57600/71250]
loss: 0.103876  [64000/71250]
loss: 0.078267  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.094868 

Epoch 36
-------------------------------
loss: 0.067624  [    0/71250]
loss: 0.158417  [ 6400/71250]
loss: 0.103667  [12800/71250]
loss: 0.062700  [19200/71250]
loss: 0.205775  [25600/71250]
loss: 0.100963  [32000/71250]
loss: 0.020817  [38400/71250]
loss: 0.129023  [44800/71250]
loss: 0.058020  [51200/71250]
loss: 0.060254  [57600/71250]
loss: 0.059112  [64000/71250]
loss: 0.125956  [70400/71250]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.093407 

Epoch 37
-------------------------------
loss: 0.163716  [    0/71250]
loss: 0.028578  [ 6400/71250]
loss: 0.026514  [12800/71250]
loss: 0.222653  [19200/71250]
loss: 0.080359  [25600/71250]
loss: 0.092255  [32000/71250]
loss: 0.084970  [38400/71250]
loss: 0.064401  [44800/71250]
loss: 0.080333  [51200/71250]
loss: 0.051238  [57600/71250]
loss: 0.056285  [64000/71250]
loss: 0.079273  [70400/71250]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.096468 

Epoch 38
-------------------------------
loss: 0.077276  [    0/71250]
loss: 0.136210  [ 6400/71250]
loss: 0.101485  [12800/71250]
loss: 0.098004  [19200/71250]
loss: 0.035291  [25600/71250]
loss: 0.188847  [32000/71250]
loss: 0.066326  [38400/71250]
loss: 0.112152  [44800/71250]
loss: 0.093715  [51200/71250]
loss: 0.184882  [57600/71250]
loss: 0.049085  [64000/71250]
loss: 0.133834  [70400/71250]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.105568 

Epoch 39
-------------------------------
loss: 0.079612  [    0/71250]
loss: 0.147410  [ 6400/71250]
loss: 0.039561  [12800/71250]
loss: 0.091027  [19200/71250]
loss: 0.055435  [25600/71250]
loss: 0.029130  [32000/71250]
loss: 0.037663  [38400/71250]
loss: 0.029647  [44800/71250]
loss: 0.103105  [51200/71250]
loss: 0.201517  [57600/71250]
loss: 0.146043  [64000/71250]
loss: 0.060750  [70400/71250]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101305 

Epoch 40
-------------------------------
loss: 0.062397  [    0/71250]
loss: 0.046586  [ 6400/71250]
loss: 0.067998  [12800/71250]
loss: 0.081845  [19200/71250]
loss: 0.051171  [25600/71250]
loss: 0.106343  [32000/71250]
loss: 0.155642  [38400/71250]
loss: 0.084221  [44800/71250]
loss: 0.144030  [51200/71250]
loss: 0.093659  [57600/71250]
loss: 0.056541  [64000/71250]
loss: 0.066344  [70400/71250]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.126028 

Epoch 41
-------------------------------
loss: 0.089661  [    0/71250]
loss: 0.044422  [ 6400/71250]
loss: 0.094988  [12800/71250]
loss: 0.144097  [19200/71250]
loss: 0.055241  [25600/71250]
loss: 0.096458  [32000/71250]
loss: 0.088410  [38400/71250]
loss: 0.107705  [44800/71250]
loss: 0.026156  [51200/71250]
loss: 0.030640  [57600/71250]
loss: 0.047572  [64000/71250]
loss: 0.045231  [70400/71250]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.093575 

Epoch 42
-------------------------------
loss: 0.078303  [    0/71250]
loss: 0.035883  [ 6400/71250]
loss: 0.070436  [12800/71250]
loss: 0.038475  [19200/71250]
loss: 0.115603  [25600/71250]
loss: 0.056156  [32000/71250]
loss: 0.046347  [38400/71250]
loss: 0.072649  [44800/71250]
loss: 0.157973  [51200/71250]
loss: 0.031755  [57600/71250]
loss: 0.062685  [64000/71250]
loss: 0.030433  [70400/71250]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.095461 

Epoch 43
-------------------------------
loss: 0.055449  [    0/71250]
loss: 0.081671  [ 6400/71250]
loss: 0.109906  [12800/71250]
loss: 0.099424  [19200/71250]
loss: 0.089742  [25600/71250]
loss: 0.052870  [32000/71250]
loss: 0.041080  [38400/71250]
loss: 0.095771  [44800/71250]
loss: 0.060175  [51200/71250]
loss: 0.046472  [57600/71250]
2022/09/20 20:27:56 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.163084 

Epoch 8
-------------------------------
loss: 0.105127  [    0/69886]
loss: 0.227559  [ 6400/69886]
loss: 0.126074  [12800/69886]
loss: 0.224183  [19200/69886]
loss: 0.075373  [25600/69886]
loss: 0.179062  [32000/69886]
loss: 0.251550  [38400/69886]
loss: 0.233274  [44800/69886]
loss: 0.260090  [51200/69886]
loss: 0.211530  [57600/69886]
loss: 0.173355  [64000/69886]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.164885 

Epoch 9
-------------------------------
loss: 0.083868  [    0/69886]
loss: 0.139324  [ 6400/69886]
loss: 0.208615  [12800/69886]
loss: 0.155917  [19200/69886]
loss: 0.140661  [25600/69886]
loss: 0.369893  [32000/69886]
loss: 0.215538  [38400/69886]
loss: 0.130009  [44800/69886]
loss: 0.149330  [51200/69886]
loss: 0.191306  [57600/69886]
loss: 0.122166  [64000/69886]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.168728 

Epoch 10
-------------------------------
loss: 0.123244  [    0/69886]
loss: 0.310648  [ 6400/69886]
loss: 0.139575  [12800/69886]
loss: 0.241993  [19200/69886]
loss: 0.123214  [25600/69886]
loss: 0.130626  [32000/69886]
loss: 0.223371  [38400/69886]
loss: 0.212334  [44800/69886]
loss: 0.085537  [51200/69886]
loss: 0.163222  [57600/69886]
loss: 0.073047  [64000/69886]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.176521 

Epoch 11
-------------------------------
loss: 0.150467  [    0/69886]
loss: 0.289517  [ 6400/69886]
loss: 0.119646  [12800/69886]
loss: 0.176107  [19200/69886]
loss: 0.137796  [25600/69886]
loss: 0.158728  [32000/69886]
loss: 0.168273  [38400/69886]
loss: 0.224892  [44800/69886]
loss: 0.111585  [51200/69886]
loss: 0.184304  [57600/69886]
loss: 0.292150  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.161075 

Epoch 12
-------------------------------
loss: 0.091241  [    0/69886]
loss: 0.266582  [ 6400/69886]
loss: 0.137204  [12800/69886]
loss: 0.101084  [19200/69886]
loss: 0.175978  [25600/69886]
loss: 0.205079  [32000/69886]
loss: 0.150208  [38400/69886]
loss: 0.137810  [44800/69886]
loss: 0.151539  [51200/69886]
loss: 0.090067  [57600/69886]
loss: 0.126353  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.162213 

Epoch 13
-------------------------------
loss: 0.129875  [    0/69886]
loss: 0.200447  [ 6400/69886]
loss: 0.110701  [12800/69886]
loss: 0.220423  [19200/69886]
loss: 0.137436  [25600/69886]
loss: 0.216785  [32000/69886]
loss: 0.212450  [38400/69886]
loss: 0.155820  [44800/69886]
loss: 0.208782  [51200/69886]
loss: 0.112978  [57600/69886]
loss: 0.168509  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.159624 

Epoch 14
-------------------------------
loss: 0.204401  [    0/69886]
loss: 0.274870  [ 6400/69886]
loss: 0.189603  [12800/69886]
loss: 0.168896  [19200/69886]
loss: 0.246949  [25600/69886]
loss: 0.084849  [32000/69886]
loss: 0.196639  [38400/69886]
loss: 0.076616  [44800/69886]
loss: 0.219063  [51200/69886]
loss: 0.138566  [57600/69886]
loss: 0.150761  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.167360 

Epoch 15
-------------------------------
loss: 0.182176  [    0/69886]
loss: 0.119608  [ 6400/69886]
loss: 0.144164  [12800/69886]
loss: 0.160894  [19200/69886]
loss: 0.189713  [25600/69886]
loss: 0.132776  [32000/69886]
loss: 0.394610  [38400/69886]
loss: 0.248937  [44800/69886]
loss: 0.130270  [51200/69886]
loss: 0.147034  [57600/69886]
loss: 0.243128  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.158837 

Epoch 16
-------------------------------
loss: 0.154881  [    0/69886]
loss: 0.112203  [ 6400/69886]
loss: 0.204296  [12800/69886]
loss: 0.158534  [19200/69886]
loss: 0.223181  [25600/69886]
loss: 0.125486  [32000/69886]
loss: 0.197658  [38400/69886]
loss: 0.278874  [44800/69886]
loss: 0.112166  [51200/69886]
loss: 0.162815  [57600/69886]
loss: 0.138085  [64000/69886]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.184168 

Epoch 17
-------------------------------
loss: 0.179303  [    0/69886]
loss: 0.188815  [ 6400/69886]
loss: 0.215885  [12800/69886]
loss: 0.124466  [19200/69886]
loss: 0.120580  [25600/69886]
loss: 0.214122  [32000/69886]
loss: 0.130276  [38400/69886]
loss: 0.113113  [44800/69886]
loss: 0.151763  [51200/69886]
loss: 0.152930  [57600/69886]
loss: 0.235174  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.160043 

Epoch 18
-------------------------------
loss: 0.132652  [    0/69886]
loss: 0.240984  [ 6400/69886]
loss: 0.074372  [12800/69886]
loss: 0.063890  [19200/69886]
loss: 0.214170  [25600/69886]
loss: 0.096074  [32000/69886]
loss: 0.104024  [38400/69886]
loss: 0.139948  [44800/69886]
loss: 0.109653  [51200/69886]
loss: 0.157304  [57600/69886]
loss: 0.084805  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.160386 

Epoch 19
-------------------------------
loss: 0.136429  [    0/69886]
loss: 0.201705  [ 6400/69886]
loss: 0.094650  [12800/69886]
loss: 0.066422  [19200/69886]
loss: 0.102042  [25600/69886]
loss: 0.143229  [32000/69886]
loss: 0.162674  [38400/69886]
loss: 0.156675  [44800/69886]
loss: 0.304184  [51200/69886]
loss: 0.250971  [57600/69886]
loss: 0.259311  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.157687 

Epoch 20
-------------------------------
loss: 0.085288  [    0/69886]
loss: 0.072563  [ 6400/69886]
loss: 0.154469  [12800/69886]
loss: 0.152398  [19200/69886]
loss: 0.110208  [25600/69886]
loss: 0.209071  [32000/69886]
loss: 0.073705  [38400/69886]
loss: 0.244764  [44800/69886]
loss: 0.090252  [51200/69886]
loss: 0.081125  [57600/69886]
loss: 0.198024  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.160350 

Epoch 21
-------------------------------
loss: 0.187859  [    0/69886]
loss: 0.093144  [ 6400/69886]
loss: 0.220411  [12800/69886]
loss: 0.135467  [19200/69886]
loss: 0.209426  [25600/69886]
loss: 0.213655  [32000/69886]
loss: 0.079226  [38400/69886]
loss: 0.158634  [44800/69886]
loss: 0.153245  [51200/69886]
loss: 0.332326  [57600/69886]
loss: 0.179687  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.161955 

Epoch 22
-------------------------------
loss: 0.260619  [    0/69886]
loss: 0.112233  [ 6400/69886]
loss: 0.103913  [12800/69886]
loss: 0.064529  [19200/69886]
loss: 0.202957  [25600/69886]
loss: 0.186802  [32000/69886]
loss: 0.139443  [38400/69886]
loss: 0.358400  [44800/69886]
loss: 0.153277  [51200/69886]
loss: 0.141922  [57600/69886]
loss: 0.155250  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.168619 

Epoch 23
-------------------------------
loss: 0.178839  [    0/69886]
loss: 0.219709  [ 6400/69886]
loss: 0.283687  [12800/69886]
loss: 0.126400  [19200/69886]
loss: 0.152325  [25600/69886]
loss: 0.217139  [32000/69886]
loss: 0.208002  [38400/69886]
loss: 0.261474  [44800/69886]
loss: 0.231150  [51200/69886]
loss: 0.152364  [57600/69886]
loss: 0.234401  [64000/69886]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.179014 

Epoch 24
-------------------------------
loss: 0.091059  [    0/69886]
loss: 0.181042  [ 6400/69886]
loss: 0.172778  [12800/69886]
loss: 0.157386  [19200/69886]
loss: 0.163419  [25600/69886]
loss: 0.209321  [32000/69886]
loss: 0.233665  [38400/69886]
loss: 0.087424  [44800/69886]
loss: 0.220673  [51200/69886]
loss: 0.204754  [57600/69886]
loss: 0.220037  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.160855 

Epoch 25
-------------------------------
loss: 0.149302  [    0/69886]
loss: 0.134427  [ 6400/69886]
loss: 0.126578  [12800/69886]
loss: 0.207495  [19200/69886]
loss: 0.168275  [25600/69886]
loss: 0.129182  [32000/69886]
loss: 0.263954  [38400/69886]
loss: 0.129125  [44800/69886]
loss: 0.154871  [51200/69886]
loss: 0.153896  [57600/69886]
loss: 0.197405  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.168175 

Epoch 26
-------------------------------
loss: 0.125330  [    0/69886]
loss: 0.093992  [ 6400/69886]
loss: 0.095302  [12800/69886]
loss: 0.201959  [19200/69886]
loss: 0.124582  [25600/69886]
loss: 0.071326  [32000/69886]
loss: 0.251339  [38400/69886]
loss: 0.117558  [44800/69886]
loss: 0.158339  [51200/69886]
loss: 0.144199  [57600/69886]
loss: 0.124152  [64000/69886]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.168820 

Epoch 27
-------------------------------
loss: 0.187745  [    0/69886]
loss: 0.217585  [ 6400/69886]
loss: 0.111734  [    0/70535]
loss: 0.121016  [ 6400/70535]
loss: 0.179163  [12800/70535]
loss: 0.071672  [19200/70535]
loss: 0.175921  [25600/70535]
loss: 0.173095  [32000/70535]
loss: 0.204522  [38400/70535]
loss: 0.105654  [44800/70535]
loss: 0.110258  [51200/70535]
loss: 0.128842  [57600/70535]
loss: 0.151658  [64000/70535]
loss: 0.226155  [70400/70535]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.195901 

Epoch 20
-------------------------------
loss: 0.086547  [    0/70535]
loss: 0.305083  [ 6400/70535]
loss: 0.168886  [12800/70535]
loss: 0.160213  [19200/70535]
loss: 0.103379  [25600/70535]
loss: 0.209695  [32000/70535]
loss: 0.154560  [38400/70535]
loss: 0.126976  [44800/70535]
loss: 0.150467  [51200/70535]
loss: 0.199549  [57600/70535]
loss: 0.244378  [64000/70535]
loss: 0.171764  [70400/70535]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.189578 

Epoch 21
-------------------------------
loss: 0.239700  [    0/70535]
loss: 0.094228  [ 6400/70535]
loss: 0.141578  [12800/70535]
loss: 0.201523  [19200/70535]
loss: 0.253814  [25600/70535]
loss: 0.303791  [32000/70535]
loss: 0.132519  [38400/70535]
loss: 0.189150  [44800/70535]
loss: 0.152590  [51200/70535]
loss: 0.154380  [57600/70535]
loss: 0.153223  [64000/70535]
loss: 0.117046  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.186812 

Epoch 22
-------------------------------
loss: 0.159443  [    0/70535]
loss: 0.185280  [ 6400/70535]
loss: 0.246177  [12800/70535]
loss: 0.167729  [19200/70535]
loss: 0.237024  [25600/70535]
loss: 0.172547  [32000/70535]
loss: 0.092194  [38400/70535]
loss: 0.101427  [44800/70535]
loss: 0.119537  [51200/70535]
loss: 0.152252  [57600/70535]
loss: 0.194960  [64000/70535]
loss: 0.212196  [70400/70535]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.210343 

Epoch 23
-------------------------------
loss: 0.208958  [    0/70535]
loss: 0.109590  [ 6400/70535]
loss: 0.093033  [12800/70535]
loss: 0.370502  [19200/70535]
loss: 0.417007  [25600/70535]
loss: 0.135628  [32000/70535]
loss: 0.147578  [38400/70535]
loss: 0.142526  [44800/70535]
loss: 0.117911  [51200/70535]
loss: 0.074592  [57600/70535]
loss: 0.211742  [64000/70535]
loss: 0.105928  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.167735 

Epoch 24
-------------------------------
loss: 0.128568  [    0/70535]
loss: 0.224250  [ 6400/70535]
loss: 0.109574  [12800/70535]
loss: 0.262196  [19200/70535]
loss: 0.132463  [25600/70535]
loss: 0.143412  [32000/70535]
loss: 0.139808  [38400/70535]
loss: 0.092143  [44800/70535]
loss: 0.228932  [51200/70535]
loss: 0.244762  [57600/70535]
loss: 0.179142  [64000/70535]
loss: 0.112763  [70400/70535]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.195628 

Epoch 25
-------------------------------
loss: 0.082761  [    0/70535]
loss: 0.184249  [ 6400/70535]
loss: 0.134802  [12800/70535]
loss: 0.174746  [19200/70535]
loss: 0.049923  [25600/70535]
loss: 0.142159  [32000/70535]
loss: 0.133372  [38400/70535]
loss: 0.125248  [44800/70535]
loss: 0.104814  [51200/70535]
loss: 0.167562  [57600/70535]
loss: 0.246965  [64000/70535]
loss: 0.187464  [70400/70535]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.184511 

Epoch 26
-------------------------------
loss: 0.069090  [    0/70535]
loss: 0.105692  [ 6400/70535]
loss: 0.128020  [12800/70535]
loss: 0.172221  [19200/70535]
loss: 0.115249  [25600/70535]
loss: 0.099957  [32000/70535]
loss: 0.145243  [38400/70535]
loss: 0.248925  [44800/70535]
loss: 0.178379  [51200/70535]
loss: 0.124649  [57600/70535]
loss: 0.233128  [64000/70535]
loss: 0.166141  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.187268 

Epoch 27
-------------------------------
loss: 0.100537  [    0/70535]
loss: 0.090626  [ 6400/70535]
loss: 0.111932  [12800/70535]
loss: 0.115354  [19200/70535]
loss: 0.178694  [25600/70535]
loss: 0.123242  [32000/70535]
loss: 0.153043  [38400/70535]
loss: 0.205669  [44800/70535]
loss: 0.091830  [51200/70535]
loss: 0.180773  [57600/70535]
loss: 0.192201  [64000/70535]
loss: 0.211111  [70400/70535]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.178822 

Epoch 28
-------------------------------
loss: 0.155048  [    0/70535]
loss: 0.071764  [ 6400/70535]
loss: 0.198871  [12800/70535]
loss: 0.149633  [19200/70535]
loss: 0.223237  [25600/70535]
loss: 0.160217  [32000/70535]
loss: 0.148572  [38400/70535]
loss: 0.103038  [44800/70535]
loss: 0.197671  [51200/70535]
loss: 0.076436  [57600/70535]
loss: 0.228113  [64000/70535]
loss: 0.070251  [70400/70535]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.183575 

Epoch 29
-------------------------------
loss: 0.101973  [    0/70535]
loss: 0.158543  [ 6400/70535]
loss: 0.134598  [12800/70535]
loss: 0.399948  [19200/70535]
loss: 0.159312  [25600/70535]
loss: 0.132805  [32000/70535]
loss: 0.137957  [38400/70535]
loss: 0.064460  [44800/70535]
loss: 0.118542  [51200/70535]
loss: 0.153894  [57600/70535]
loss: 0.226547  [64000/70535]
loss: 0.208331  [70400/70535]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.186678 

Epoch 30
-------------------------------
loss: 0.129144  [    0/70535]
loss: 0.230385  [ 6400/70535]
loss: 0.175659  [12800/70535]
loss: 0.060551  [19200/70535]
loss: 0.189392  [25600/70535]
loss: 0.204928  [32000/70535]
loss: 0.206998  [38400/70535]
loss: 0.158364  [44800/70535]
loss: 0.147233  [51200/70535]
loss: 0.209397  [57600/70535]
loss: 0.226126  [64000/70535]
loss: 0.193965  [70400/70535]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.156966 

Epoch 31
-------------------------------
loss: 0.202273  [    0/70535]
loss: 0.092584  [ 6400/70535]
loss: 0.177844  [12800/70535]
loss: 0.186020  [19200/70535]
loss: 0.103890  [25600/70535]
loss: 0.087053  [32000/70535]
loss: 0.126591  [38400/70535]
loss: 0.212429  [44800/70535]
loss: 0.174916  [51200/70535]
loss: 0.225974  [57600/70535]
loss: 0.088115  [64000/70535]
loss: 0.225383  [70400/70535]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.193453 

Epoch 32
-------------------------------
loss: 0.158284  [    0/70535]
loss: 0.124576  [ 6400/70535]
loss: 0.103813  [12800/70535]
loss: 0.160353  [19200/70535]
loss: 0.162511  [25600/70535]
loss: 0.082567  [32000/70535]
loss: 0.181468  [38400/70535]
loss: 0.124839  [44800/70535]
loss: 0.118517  [51200/70535]
loss: 0.132379  [57600/70535]
loss: 0.115628  [64000/70535]
loss: 0.183804  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.161602 

Epoch 33
-------------------------------
loss: 0.244240  [    0/70535]
loss: 0.211481  [ 6400/70535]
loss: 0.187237  [12800/70535]
loss: 0.169974  [19200/70535]
loss: 0.097882  [25600/70535]
loss: 0.232568  [32000/70535]
loss: 0.103938  [38400/70535]
loss: 0.108459  [44800/70535]
loss: 0.184022  [51200/70535]
loss: 0.082896  [57600/70535]
loss: 0.134128  [64000/70535]
loss: 0.169001  [70400/70535]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.159683 

Epoch 34
-------------------------------
loss: 0.090500  [    0/70535]
loss: 0.092962  [ 6400/70535]
loss: 0.092501  [12800/70535]
loss: 0.089523  [19200/70535]
loss: 0.166276  [25600/70535]
loss: 0.111603  [32000/70535]
loss: 0.189463  [38400/70535]
loss: 0.252517  [44800/70535]
loss: 0.196095  [51200/70535]
loss: 0.178779  [57600/70535]
loss: 0.200292  [64000/70535]
loss: 0.160780  [70400/70535]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.166946 

Epoch 35
-------------------------------
loss: 0.194143  [    0/70535]
loss: 0.135238  [ 6400/70535]
loss: 0.099182  [12800/70535]
loss: 0.217172  [19200/70535]
loss: 0.069062  [25600/70535]
loss: 0.240885  [32000/70535]
loss: 0.336916  [38400/70535]
loss: 0.067386  [44800/70535]
loss: 0.193982  [51200/70535]
loss: 0.262080  [57600/70535]
loss: 0.163172  [64000/70535]
loss: 0.176577  [70400/70535]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.192211 

Epoch 36
-------------------------------
loss: 0.141764  [    0/70535]
loss: 0.211298  [ 6400/70535]
loss: 0.127174  [12800/70535]
loss: 0.163066  [19200/70535]
loss: 0.068380  [25600/70535]
loss: 0.192969  [32000/70535]
loss: 0.225649  [38400/70535]
loss: 0.110693  [44800/70535]
loss: 0.135623  [51200/70535]
loss: 0.249939  [57600/70535]
loss: 0.192991  [64000/70535]
loss: 0.203646  [70400/70535]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.194446 

Epoch 37
-------------------------------
loss: 0.090023  [    0/70535]
2022/09/20 20:31:09 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 20:31:10 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.015314  [38400/70818]
loss: 0.062796  [44800/70818]
loss: 0.085962  [51200/70818]
loss: 0.103707  [57600/70818]
loss: 0.168741  [64000/70818]
loss: 0.124600  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.099563 

Epoch 26
-------------------------------
loss: 0.090924  [    0/70818]
loss: 0.123005  [ 6400/70818]
loss: 0.094351  [12800/70818]
loss: 0.105161  [19200/70818]
loss: 0.076621  [25600/70818]
loss: 0.070380  [32000/70818]
loss: 0.079988  [38400/70818]
loss: 0.064192  [44800/70818]
loss: 0.046679  [51200/70818]
loss: 0.099362  [57600/70818]
loss: 0.069515  [64000/70818]
loss: 0.218908  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.094118 

Epoch 27
-------------------------------
loss: 0.115309  [    0/70818]
loss: 0.089233  [ 6400/70818]
loss: 0.065389  [12800/70818]
loss: 0.076078  [19200/70818]
loss: 0.071053  [25600/70818]
loss: 0.097048  [32000/70818]
loss: 0.062272  [38400/70818]
loss: 0.054485  [44800/70818]
loss: 0.076640  [51200/70818]
loss: 0.121222  [57600/70818]
loss: 0.046791  [64000/70818]
loss: 0.190846  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112734 

Epoch 28
-------------------------------
loss: 0.094242  [    0/70818]
loss: 0.113412  [ 6400/70818]
loss: 0.106523  [12800/70818]
loss: 0.100758  [19200/70818]
loss: 0.058534  [25600/70818]
loss: 0.081453  [32000/70818]
loss: 0.080682  [38400/70818]
loss: 0.086592  [44800/70818]
loss: 0.106028  [51200/70818]
loss: 0.093660  [57600/70818]
loss: 0.083688  [64000/70818]
loss: 0.172968  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.109888 

Epoch 29
-------------------------------
loss: 0.039924  [    0/70818]
loss: 0.132663  [ 6400/70818]
loss: 0.021713  [12800/70818]
loss: 0.125662  [19200/70818]
loss: 0.258639  [25600/70818]
loss: 0.127467  [32000/70818]
loss: 0.062018  [38400/70818]
loss: 0.027141  [44800/70818]
loss: 0.068311  [51200/70818]
loss: 0.199231  [57600/70818]
loss: 0.101917  [64000/70818]
loss: 0.060724  [70400/70818]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.107615 

Epoch 30
-------------------------------
loss: 0.175419  [    0/70818]
loss: 0.054896  [ 6400/70818]
loss: 0.072505  [12800/70818]
loss: 0.070501  [19200/70818]
loss: 0.061438  [25600/70818]
loss: 0.116400  [32000/70818]
loss: 0.169891  [38400/70818]
loss: 0.091230  [44800/70818]
loss: 0.111861  [51200/70818]
loss: 0.080155  [57600/70818]
loss: 0.166504  [64000/70818]
loss: 0.057834  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.097055 

Epoch 31
-------------------------------
loss: 0.082020  [    0/70818]
loss: 0.084981  [ 6400/70818]
loss: 0.038507  [12800/70818]
loss: 0.075210  [19200/70818]
loss: 0.090809  [25600/70818]
loss: 0.079924  [32000/70818]
loss: 0.058324  [38400/70818]
loss: 0.098894  [44800/70818]
loss: 0.148151  [51200/70818]
loss: 0.057929  [57600/70818]
loss: 0.044879  [64000/70818]
loss: 0.101130  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.096998 

Epoch 32
-------------------------------
loss: 0.114902  [    0/70818]
loss: 0.080479  [ 6400/70818]
loss: 0.008806  [12800/70818]
loss: 0.074262  [19200/70818]
loss: 0.073990  [25600/70818]
loss: 0.023073  [32000/70818]
loss: 0.135442  [38400/70818]
loss: 0.116237  [44800/70818]
loss: 0.282081  [51200/70818]
loss: 0.138431  [57600/70818]
loss: 0.025691  [64000/70818]
loss: 0.150592  [70400/70818]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.108722 

Epoch 33
-------------------------------
loss: 0.040441  [    0/70818]
loss: 0.077474  [ 6400/70818]
loss: 0.054638  [12800/70818]
loss: 0.193346  [19200/70818]
loss: 0.090271  [25600/70818]
loss: 0.094236  [32000/70818]
loss: 0.020009  [38400/70818]
loss: 0.026235  [44800/70818]
loss: 0.075418  [51200/70818]
loss: 0.056422  [57600/70818]
loss: 0.156785  [64000/70818]
loss: 0.077298  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.100790 

Epoch 34
-------------------------------
loss: 0.055016  [    0/70818]
loss: 0.046479  [ 6400/70818]
loss: 0.066072  [12800/70818]
loss: 0.145570  [19200/70818]
loss: 0.299283  [25600/70818]
loss: 0.179666  [32000/70818]
loss: 0.258556  [38400/70818]
loss: 0.307849  [44800/70818]
loss: 0.114507  [51200/70818]
loss: 0.064633  [57600/70818]
loss: 0.079460  [64000/70818]
loss: 0.053737  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.109588 

Epoch 35
-------------------------------
loss: 0.024108  [    0/70818]
loss: 0.121196  [ 6400/70818]
loss: 0.075738  [12800/70818]
loss: 0.015872  [19200/70818]
loss: 0.024282  [25600/70818]
loss: 0.017134  [32000/70818]
loss: 0.168584  [38400/70818]
loss: 0.080396  [44800/70818]
loss: 0.092372  [51200/70818]
loss: 0.048128  [57600/70818]
loss: 0.083160  [64000/70818]
loss: 0.157013  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.106267 

Epoch 36
-------------------------------
loss: 0.020348  [    0/70818]
loss: 0.106844  [ 6400/70818]
loss: 0.068541  [12800/70818]
loss: 0.032990  [19200/70818]
loss: 0.069616  [25600/70818]
loss: 0.062551  [32000/70818]
loss: 0.044856  [38400/70818]
loss: 0.060105  [44800/70818]
loss: 0.089188  [51200/70818]
loss: 0.123315  [57600/70818]
loss: 0.162526  [64000/70818]
loss: 0.232485  [70400/70818]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.109624 

Epoch 37
-------------------------------
loss: 0.044815  [    0/70818]
loss: 0.013497  [ 6400/70818]
loss: 0.033349  [12800/70818]
loss: 0.089284  [19200/70818]
loss: 0.118878  [25600/70818]
loss: 0.101572  [32000/70818]
loss: 0.076070  [38400/70818]
loss: 0.042644  [44800/70818]
loss: 0.098818  [51200/70818]
loss: 0.037318  [57600/70818]
loss: 0.070104  [64000/70818]
loss: 0.117930  [70400/70818]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.107805 

Epoch 38
-------------------------------
loss: 0.194250  [    0/70818]
loss: 0.101291  [ 6400/70818]
loss: 0.112707  [12800/70818]
loss: 0.074558  [19200/70818]
loss: 0.058395  [25600/70818]
loss: 0.135790  [32000/70818]
loss: 0.107788  [38400/70818]
loss: 0.078631  [44800/70818]
loss: 0.122246  [51200/70818]
loss: 0.041734  [57600/70818]
loss: 0.095365  [64000/70818]
loss: 0.055444  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.111183 

Epoch 39
-------------------------------
loss: 0.068222  [    0/70818]
loss: 0.082808  [ 6400/70818]
loss: 0.091252  [12800/70818]
loss: 0.044849  [19200/70818]
loss: 0.202748  [25600/70818]
loss: 0.091896  [32000/70818]
loss: 0.148532  [38400/70818]
loss: 0.147788  [44800/70818]
loss: 0.080403  [51200/70818]
loss: 0.042604  [57600/70818]
loss: 0.027587  [64000/70818]
loss: 0.121367  [70400/70818]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.118403 

Epoch 40
-------------------------------
loss: 0.136292  [    0/70818]
loss: 0.018060  [ 6400/70818]
loss: 0.039092  [12800/70818]
loss: 0.040649  [19200/70818]
loss: 0.100378  [25600/70818]
loss: 0.048783  [32000/70818]
loss: 0.092376  [38400/70818]
loss: 0.103050  [44800/70818]
loss: 0.072233  [51200/70818]
loss: 0.071017  [57600/70818]
loss: 0.111813  [64000/70818]
loss: 0.089581  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.103912 

Epoch 41
-------------------------------
loss: 0.054851  [    0/70818]
loss: 0.072107  [ 6400/70818]
loss: 0.092214  [12800/70818]
loss: 0.034078  [19200/70818]
loss: 0.040655  [25600/70818]
loss: 0.324754  [32000/70818]
loss: 0.090739  [38400/70818]
loss: 0.104806  [44800/70818]
loss: 0.056564  [51200/70818]
loss: 0.044481  [57600/70818]
loss: 0.084660  [64000/70818]
loss: 0.068899  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.096188 

Epoch 42
-------------------------------
loss: 0.122785  [    0/70818]
loss: 0.054282  [ 6400/70818]
loss: 0.047553  [12800/70818]
loss: 0.043915  [19200/70818]
loss: 0.035948  [25600/70818]
loss: 0.110450  [32000/70818]
loss: 0.056019  [38400/70818]
loss: 0.065978  [44800/70818]
loss: 0.053553  [51200/70818]
loss: 0.050675  [57600/70818]
loss: 0.031487  [64000/70818]
loss: 0.114387  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.092823 

Epoch 43
-------------------------------
loss: 0.040353  [    0/70818]
loss: 0.086046  [ 6400/70818]
loss: 0.068352  [12800/70818]
loss: 0.024118  [19200/70818]
loss: 0.033979  [25600/70818]
loss: 0.060469  [32000/70818]
loss: 0.128885  [38400/70818]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.145470 

Epoch 24
-------------------------------
loss: 0.102599  [    0/69546]
loss: 0.160697  [ 6400/69546]
loss: 0.052878  [12800/69546]
loss: 0.081456  [19200/69546]
loss: 0.067793  [25600/69546]
loss: 0.123176  [32000/69546]
loss: 0.094205  [38400/69546]
loss: 0.283854  [44800/69546]
loss: 0.072849  [51200/69546]
loss: 0.121380  [57600/69546]
loss: 0.094173  [64000/69546]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.118462 

Epoch 25
-------------------------------
loss: 0.050051  [    0/69546]
loss: 0.061387  [ 6400/69546]
loss: 0.110009  [12800/69546]
loss: 0.071621  [19200/69546]
loss: 0.134238  [25600/69546]
loss: 0.168904  [32000/69546]
loss: 0.168440  [38400/69546]
loss: 0.127829  [44800/69546]
loss: 0.160536  [51200/69546]
loss: 0.090442  [57600/69546]
loss: 0.072035  [64000/69546]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.129933 

Epoch 26
-------------------------------
loss: 0.084485  [    0/69546]
loss: 0.185432  [ 6400/69546]
loss: 0.120814  [12800/69546]
loss: 0.184098  [19200/69546]
loss: 0.115999  [25600/69546]
loss: 0.101776  [32000/69546]
loss: 0.038669  [38400/69546]
loss: 0.137874  [44800/69546]
loss: 0.116920  [51200/69546]
loss: 0.211242  [57600/69546]
loss: 0.118154  [64000/69546]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.125257 

Epoch 27
-------------------------------
loss: 0.060669  [    0/69546]
loss: 0.061954  [ 6400/69546]
loss: 0.086231  [12800/69546]
loss: 0.091237  [19200/69546]
loss: 0.100534  [25600/69546]
loss: 0.131665  [32000/69546]
loss: 0.203767  [38400/69546]
loss: 0.170234  [44800/69546]
loss: 0.171431  [51200/69546]
loss: 0.160696  [57600/69546]
loss: 0.093651  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.125347 

Epoch 28
-------------------------------
loss: 0.136821  [    0/69546]
loss: 0.102638  [ 6400/69546]
loss: 0.119917  [12800/69546]
loss: 0.127728  [19200/69546]
loss: 0.149028  [25600/69546]
loss: 0.236528  [32000/69546]
loss: 0.296131  [38400/69546]
loss: 0.104215  [44800/69546]
loss: 0.108714  [51200/69546]
loss: 0.075010  [57600/69546]
loss: 0.049209  [64000/69546]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.133825 

Epoch 29
-------------------------------
loss: 0.107447  [    0/69546]
loss: 0.054806  [ 6400/69546]
loss: 0.229781  [12800/69546]
loss: 0.159873  [19200/69546]
loss: 0.144093  [25600/69546]
loss: 0.071446  [32000/69546]
loss: 0.086611  [38400/69546]
loss: 0.115571  [44800/69546]
loss: 0.142900  [51200/69546]
loss: 0.119286  [57600/69546]
loss: 0.200969  [64000/69546]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.117355 

Epoch 30
-------------------------------
loss: 0.124810  [    0/69546]
loss: 0.060315  [ 6400/69546]
loss: 0.036633  [12800/69546]
loss: 0.083352  [19200/69546]
loss: 0.103605  [25600/69546]
loss: 0.047435  [32000/69546]
loss: 0.061164  [38400/69546]
loss: 0.159179  [44800/69546]
loss: 0.079539  [51200/69546]
loss: 0.050599  [57600/69546]
loss: 0.080300  [64000/69546]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.125361 

Epoch 31
-------------------------------
loss: 0.137307  [    0/69546]
loss: 0.130332  [ 6400/69546]
loss: 0.058339  [12800/69546]
loss: 0.085331  [19200/69546]
loss: 0.067293  [25600/69546]
loss: 0.126671  [32000/69546]
loss: 0.193925  [38400/69546]
loss: 0.062429  [44800/69546]
loss: 0.171315  [51200/69546]
loss: 0.115830  [57600/69546]
loss: 0.051839  [64000/69546]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.127972 

Epoch 32
-------------------------------
loss: 0.105580  [    0/69546]
loss: 0.122325  [ 6400/69546]
loss: 0.106916  [12800/69546]
loss: 0.088033  [19200/69546]
loss: 0.120149  [25600/69546]
loss: 0.148536  [32000/69546]
loss: 0.161319  [38400/69546]
loss: 0.203446  [44800/69546]
loss: 0.087038  [51200/69546]
loss: 0.047562  [57600/69546]
loss: 0.103774  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.122718 

Epoch 33
-------------------------------
loss: 0.043899  [    0/69546]
loss: 0.110127  [ 6400/69546]
loss: 0.044341  [12800/69546]
loss: 0.057351  [19200/69546]
loss: 0.140987  [25600/69546]
loss: 0.084118  [32000/69546]
loss: 0.054725  [38400/69546]
loss: 0.076002  [44800/69546]
loss: 0.188418  [51200/69546]
loss: 0.276951  [57600/69546]
loss: 0.090278  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.127627 

Epoch 34
-------------------------------
loss: 0.111026  [    0/69546]
loss: 0.060428  [ 6400/69546]
loss: 0.079639  [12800/69546]
loss: 0.022324  [19200/69546]
loss: 0.045257  [25600/69546]
loss: 0.211169  [32000/69546]
loss: 0.097896  [38400/69546]
loss: 0.073697  [44800/69546]
loss: 0.085816  [51200/69546]
loss: 0.104237  [57600/69546]
loss: 0.168170  [64000/69546]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.124760 

Epoch 35
-------------------------------
loss: 0.150707  [    0/69546]
loss: 0.140750  [ 6400/69546]
loss: 0.153292  [12800/69546]
loss: 0.106279  [19200/69546]
loss: 0.116415  [25600/69546]
loss: 0.035706  [32000/69546]
loss: 0.114887  [38400/69546]
loss: 0.102680  [44800/69546]
loss: 0.271513  [51200/69546]
loss: 0.081519  [57600/69546]
loss: 0.143779  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.130706 

Epoch 36
-------------------------------
loss: 0.115143  [    0/69546]
loss: 0.123629  [ 6400/69546]
loss: 0.059275  [12800/69546]
loss: 0.042935  [19200/69546]
loss: 0.060257  [25600/69546]
loss: 0.166011  [32000/69546]
loss: 0.050321  [38400/69546]
loss: 0.052619  [44800/69546]
loss: 0.166778  [51200/69546]
loss: 0.146171  [57600/69546]
loss: 0.103556  [64000/69546]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.124292 

Epoch 37
-------------------------------
loss: 0.042831  [    0/69546]
loss: 0.054042  [ 6400/69546]
loss: 0.227922  [12800/69546]
loss: 0.056372  [19200/69546]
loss: 0.082192  [25600/69546]
loss: 0.154532  [32000/69546]
loss: 0.174971  [38400/69546]
loss: 0.078136  [44800/69546]
loss: 0.109483  [51200/69546]
loss: 0.102634  [57600/69546]
loss: 0.175355  [64000/69546]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.118915 

Epoch 38
-------------------------------
loss: 0.155300  [    0/69546]
loss: 0.158603  [ 6400/69546]
loss: 0.119499  [12800/69546]
loss: 0.137261  [19200/69546]
loss: 0.086627  [25600/69546]
loss: 0.085509  [32000/69546]
loss: 0.077755  [38400/69546]
loss: 0.070438  [44800/69546]
loss: 0.042499  [51200/69546]
loss: 0.111308  [57600/69546]
loss: 0.090335  [64000/69546]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.128749 

Epoch 39
-------------------------------
loss: 0.092959  [    0/69546]
loss: 0.298984  [ 6400/69546]
loss: 0.163067  [12800/69546]
loss: 0.115336  [19200/69546]
loss: 1.749055  [25600/69546]
loss: 0.094929  [32000/69546]
loss: 0.132612  [38400/69546]
loss: 0.224689  [44800/69546]
loss: 0.337625  [51200/69546]
loss: 0.081080  [57600/69546]
loss: 0.160843  [64000/69546]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.133642 

Epoch 40
-------------------------------
loss: 0.277786  [    0/69546]
loss: 0.090971  [ 6400/69546]
loss: 0.159066  [12800/69546]
loss: 1.577527  [19200/69546]
loss: 0.081936  [25600/69546]
loss: 0.127436  [32000/69546]
loss: 0.120188  [38400/69546]
loss: 0.094770  [44800/69546]
loss: 0.029976  [51200/69546]
loss: 0.095487  [57600/69546]
loss: 0.248147  [64000/69546]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.121978 

Epoch 41
-------------------------------
loss: 0.114499  [    0/69546]
loss: 0.019229  [ 6400/69546]
loss: 0.048573  [12800/69546]
loss: 0.058077  [19200/69546]
loss: 0.090372  [25600/69546]
loss: 0.195713  [32000/69546]
loss: 0.120339  [38400/69546]
loss: 0.063441  [44800/69546]
loss: 0.130266  [51200/69546]
loss: 0.040018  [57600/69546]
loss: 0.062423  [64000/69546]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.169834 

Epoch 42
-------------------------------
loss: 0.210831  [    0/69546]
loss: 0.166675  [ 6400/69546]
loss: 0.062576  [12800/69546]
loss: 0.096895  [19200/69546]
loss: 0.039089  [25600/69546]
loss: 0.056564  [32000/69546]
loss: 0.101070  [38400/69546]
loss: 0.140065  [44800/69546]
loss: 0.108891  [51200/69546]
loss: 0.197026  [57600/69546]
loss: 0.129205  [64000/69546]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.120736 

Epoch 43
-------------------------------
loss: 0.183243  [    0/69546]
loss: 0.120491  [ 6400/69546]
2022/09/20 20:32:21 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 20:35:29 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 1.760495  [57600/70896]
loss: 0.219588  [64000/70896]
loss: 0.033818  [70400/70896]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.126665 

Epoch 34
-------------------------------
loss: 0.063314  [    0/70896]
loss: 0.115262  [ 6400/70896]
loss: 0.044829  [12800/70896]
loss: 0.066378  [19200/70896]
loss: 0.105584  [25600/70896]
loss: 0.088600  [32000/70896]
loss: 0.057957  [38400/70896]
loss: 0.037240  [44800/70896]
loss: 0.112566  [51200/70896]
loss: 0.090465  [57600/70896]
loss: 0.056837  [64000/70896]
loss: 0.183096  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.129453 

Epoch 35
-------------------------------
loss: 0.151953  [    0/70896]
loss: 0.025484  [ 6400/70896]
loss: 0.102221  [12800/70896]
loss: 0.054449  [19200/70896]
loss: 0.128190  [25600/70896]
loss: 0.073093  [32000/70896]
loss: 0.073490  [38400/70896]
loss: 0.173948  [44800/70896]
loss: 0.174163  [51200/70896]
loss: 0.035974  [57600/70896]
loss: 0.072379  [64000/70896]
loss: 0.053117  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.131228 

Epoch 36
-------------------------------
loss: 0.075713  [    0/70896]
loss: 0.115587  [ 6400/70896]
loss: 0.069926  [12800/70896]
loss: 0.063216  [19200/70896]
loss: 0.065673  [25600/70896]
loss: 0.078022  [32000/70896]
loss: 0.122198  [38400/70896]
loss: 0.115449  [44800/70896]
loss: 0.078445  [51200/70896]
loss: 0.037077  [57600/70896]
loss: 0.089255  [64000/70896]
loss: 0.147039  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.132229 

Epoch 37
-------------------------------
loss: 0.027843  [    0/70896]
loss: 0.063267  [ 6400/70896]
loss: 0.136948  [12800/70896]
loss: 0.112170  [19200/70896]
loss: 0.078831  [25600/70896]
loss: 0.167488  [32000/70896]
loss: 0.029678  [38400/70896]
loss: 0.141330  [44800/70896]
loss: 0.098480  [51200/70896]
loss: 0.039764  [57600/70896]
loss: 0.084638  [64000/70896]
loss: 0.163818  [70400/70896]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.143514 

Epoch 38
-------------------------------
loss: 0.038476  [    0/70896]
loss: 0.062753  [ 6400/70896]
loss: 0.037106  [12800/70896]
loss: 0.205248  [19200/70896]
loss: 0.044180  [25600/70896]
loss: 0.122030  [32000/70896]
loss: 0.084095  [38400/70896]
loss: 0.125141  [44800/70896]
loss: 0.037041  [51200/70896]
loss: 0.055975  [57600/70896]
loss: 0.129911  [64000/70896]
loss: 0.096637  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.129956 

Epoch 39
-------------------------------
loss: 0.030828  [    0/70896]
loss: 0.062155  [ 6400/70896]
loss: 0.032433  [12800/70896]
loss: 0.172891  [19200/70896]
loss: 0.110207  [25600/70896]
loss: 0.045455  [32000/70896]
loss: 0.071073  [38400/70896]
loss: 0.090223  [44800/70896]
loss: 0.049610  [51200/70896]
loss: 0.057393  [57600/70896]
loss: 0.092520  [64000/70896]
loss: 0.102004  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.130889 

Epoch 40
-------------------------------
loss: 0.081649  [    0/70896]
loss: 0.064671  [ 6400/70896]
loss: 0.214774  [12800/70896]
loss: 0.015742  [19200/70896]
loss: 0.083308  [25600/70896]
loss: 0.101589  [32000/70896]
loss: 0.060742  [38400/70896]
loss: 0.071596  [44800/70896]
loss: 0.095900  [51200/70896]
loss: 0.024550  [57600/70896]
loss: 0.093131  [64000/70896]
loss: 0.040470  [70400/70896]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.127414 

Epoch 41
-------------------------------
loss: 0.057308  [    0/70896]
loss: 0.070888  [ 6400/70896]
loss: 0.052051  [12800/70896]
loss: 0.077016  [19200/70896]
loss: 0.063310  [25600/70896]
loss: 0.159010  [32000/70896]
loss: 0.021050  [38400/70896]
loss: 0.090764  [44800/70896]
loss: 0.133195  [51200/70896]
loss: 0.092084  [57600/70896]
loss: 0.054843  [64000/70896]
loss: 0.180408  [70400/70896]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.134290 

Epoch 42
-------------------------------
loss: 0.132715  [    0/70896]
loss: 0.092540  [ 6400/70896]
loss: 0.059371  [12800/70896]
loss: 0.062684  [19200/70896]
loss: 0.071356  [25600/70896]
loss: 0.081751  [32000/70896]
loss: 0.066440  [38400/70896]
loss: 0.245421  [44800/70896]
loss: 0.151974  [51200/70896]
loss: 0.051474  [57600/70896]
loss: 0.136467  [64000/70896]
loss: 0.083134  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.139288 

Epoch 43
-------------------------------
loss: 0.096673  [    0/70896]
loss: 0.121731  [ 6400/70896]
loss: 0.085111  [12800/70896]
loss: 0.094540  [19200/70896]
loss: 0.102306  [25600/70896]
loss: 0.050155  [32000/70896]
loss: 0.121262  [38400/70896]
loss: 0.033454  [44800/70896]
loss: 0.160772  [51200/70896]
loss: 0.080653  [57600/70896]
loss: 0.057979  [64000/70896]
loss: 0.079648  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.134959 

Epoch 44
-------------------------------
loss: 0.062273  [    0/70896]
loss: 0.178073  [ 6400/70896]
loss: 0.198252  [12800/70896]
loss: 0.061172  [19200/70896]
loss: 0.024805  [25600/70896]
loss: 0.170391  [32000/70896]
loss: 0.038355  [38400/70896]
loss: 0.032772  [44800/70896]
loss: 0.032345  [51200/70896]
loss: 0.026503  [57600/70896]
loss: 0.087374  [64000/70896]
loss: 0.059068  [70400/70896]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.129385 

Epoch 45
-------------------------------
loss: 0.079478  [    0/70896]
loss: 0.096071  [ 6400/70896]
loss: 0.048474  [12800/70896]
loss: 0.068989  [19200/70896]
loss: 0.065741  [25600/70896]
loss: 0.201236  [32000/70896]
loss: 1.602362  [38400/70896]
loss: 0.194957  [44800/70896]
loss: 0.106622  [51200/70896]
loss: 0.033729  [57600/70896]
loss: 0.042165  [64000/70896]
loss: 0.050666  [70400/70896]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.135125 

Epoch 46
-------------------------------
loss: 0.067421  [    0/70896]
loss: 0.021912  [ 6400/70896]
loss: 0.068880  [12800/70896]
loss: 0.025238  [19200/70896]
loss: 0.157593  [25600/70896]
loss: 0.045187  [32000/70896]
loss: 0.027357  [38400/70896]
loss: 0.099504  [44800/70896]
loss: 0.035317  [51200/70896]
loss: 0.146674  [57600/70896]
loss: 0.039290  [64000/70896]
loss: 0.105365  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.130344 

Epoch 47
-------------------------------
loss: 0.042396  [    0/70896]
loss: 0.053143  [ 6400/70896]
loss: 0.090951  [12800/70896]
loss: 0.025955  [19200/70896]
loss: 0.124178  [25600/70896]
loss: 0.053211  [32000/70896]
loss: 0.062026  [38400/70896]
loss: 0.021828  [44800/70896]
loss: 0.057633  [51200/70896]
loss: 0.018805  [57600/70896]
loss: 0.042584  [64000/70896]
loss: 0.102855  [70400/70896]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.132207 

Epoch 48
-------------------------------
loss: 0.104027  [    0/70896]
loss: 0.088680  [ 6400/70896]
loss: 0.090868  [12800/70896]
loss: 0.091374  [19200/70896]
loss: 0.062246  [25600/70896]
loss: 0.044399  [32000/70896]
loss: 0.112068  [38400/70896]
loss: 0.062060  [44800/70896]
loss: 0.033608  [51200/70896]
loss: 0.032232  [57600/70896]
loss: 0.266838  [64000/70896]
loss: 0.020440  [70400/70896]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.128838 

Epoch 49
-------------------------------
loss: 0.019374  [    0/70896]
loss: 0.079866  [ 6400/70896]
loss: 0.028607  [12800/70896]
loss: 0.062571  [19200/70896]
loss: 0.059410  [25600/70896]
loss: 0.086300  [32000/70896]
loss: 0.086218  [38400/70896]
loss: 0.070055  [44800/70896]
loss: 0.093037  [51200/70896]
loss: 0.069592  [57600/70896]
loss: 0.058377  [64000/70896]
loss: 0.080831  [70400/70896]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.138108 

Epoch 50
-------------------------------
loss: 0.051824  [    0/70896]
loss: 0.032208  [ 6400/70896]
loss: 0.065785  [12800/70896]
loss: 1.613831  [19200/70896]
loss: 0.054069  [25600/70896]
loss: 0.052024  [32000/70896]
loss: 0.268133  [38400/70896]
loss: 0.097408  [44800/70896]
loss: 0.087995  [51200/70896]
loss: 0.066789  [57600/70896]
loss: 0.104086  [64000/70896]
loss: 0.110711  [70400/70896]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.137237 

Epoch 1
-------------------------------
loss: 0.668079  [    0/71701]
loss: 0.203238  [ 6400/71701]
loss: 0.136931  [12800/71701]
loss: 0.076412  [19200/71701]
loss: 0.129473  [25600/71701]
loss: 0.116535  [32000/71701]
loss: 0.173623  [38400/71701]
loss: 0.039767  [44800/71701]
loss: 0.100098  [51200/71701]
loss: 0.066818  [57600/71701]
2022/09/20 20:36:37 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 20:36:44 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.112730  [51200/69886]
loss: 0.118084  [57600/69886]
loss: 0.170215  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.164343 

Epoch 20
-------------------------------
loss: 0.250764  [    0/69886]
loss: 0.158666  [ 6400/69886]
loss: 0.155354  [12800/69886]
loss: 0.172172  [19200/69886]
loss: 0.076251  [25600/69886]
loss: 0.109539  [32000/69886]
loss: 0.188527  [38400/69886]
loss: 0.172352  [44800/69886]
loss: 0.156666  [51200/69886]
loss: 0.181931  [57600/69886]
loss: 0.260429  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.162510 

Epoch 21
-------------------------------
loss: 0.070552  [    0/69886]
loss: 0.129205  [ 6400/69886]
loss: 0.197937  [12800/69886]
loss: 0.169283  [19200/69886]
loss: 0.148932  [25600/69886]
loss: 0.187662  [32000/69886]
loss: 0.180128  [38400/69886]
loss: 0.107144  [44800/69886]
loss: 0.217937  [51200/69886]
loss: 0.124730  [57600/69886]
loss: 0.175265  [64000/69886]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.171253 

Epoch 22
-------------------------------
loss: 0.193025  [    0/69886]
loss: 0.078784  [ 6400/69886]
loss: 0.235729  [12800/69886]
loss: 0.186852  [19200/69886]
loss: 0.080781  [25600/69886]
loss: 0.204902  [32000/69886]
loss: 0.132037  [38400/69886]
loss: 0.112305  [44800/69886]
loss: 0.114812  [51200/69886]
loss: 0.131951  [57600/69886]
loss: 0.196516  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.167250 

Epoch 23
-------------------------------
loss: 0.107333  [    0/69886]
loss: 0.151424  [ 6400/69886]
loss: 0.216848  [12800/69886]
loss: 0.342310  [19200/69886]
loss: 0.210678  [25600/69886]
loss: 0.124208  [32000/69886]
loss: 0.199800  [38400/69886]
loss: 0.115390  [44800/69886]
loss: 0.398272  [51200/69886]
loss: 0.173417  [57600/69886]
loss: 0.084478  [64000/69886]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.172142 

Epoch 24
-------------------------------
loss: 0.188319  [    0/69886]
loss: 0.173101  [ 6400/69886]
loss: 0.144242  [12800/69886]
loss: 0.086094  [19200/69886]
loss: 0.170582  [25600/69886]
loss: 0.230473  [32000/69886]
loss: 0.157523  [38400/69886]
loss: 0.206060  [44800/69886]
loss: 0.132793  [51200/69886]
loss: 0.150751  [57600/69886]
loss: 0.193887  [64000/69886]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.177767 

Epoch 25
-------------------------------
loss: 0.188476  [    0/69886]
loss: 0.224488  [ 6400/69886]
loss: 0.387268  [12800/69886]
loss: 0.161479  [19200/69886]
loss: 0.274248  [25600/69886]
loss: 0.265030  [32000/69886]
loss: 0.253093  [38400/69886]
loss: 0.089416  [44800/69886]
loss: 0.171429  [51200/69886]
loss: 0.096418  [57600/69886]
loss: 0.207664  [64000/69886]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.175629 

Epoch 26
-------------------------------
loss: 0.193578  [    0/69886]
loss: 0.186174  [ 6400/69886]
loss: 0.188528  [12800/69886]
loss: 0.166804  [19200/69886]
loss: 0.161727  [25600/69886]
loss: 0.126234  [32000/69886]
loss: 0.101239  [38400/69886]
loss: 0.121927  [44800/69886]
loss: 0.203789  [51200/69886]
loss: 0.170423  [57600/69886]
loss: 0.171418  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.166413 

Epoch 27
-------------------------------
loss: 0.142571  [    0/69886]
loss: 0.435038  [ 6400/69886]
loss: 0.187568  [12800/69886]
loss: 0.126926  [19200/69886]
loss: 0.201215  [25600/69886]
loss: 0.252323  [32000/69886]
loss: 0.180674  [38400/69886]
loss: 0.204224  [44800/69886]
loss: 0.122041  [51200/69886]
loss: 0.208321  [57600/69886]
loss: 0.320621  [64000/69886]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.183474 

Epoch 28
-------------------------------
loss: 0.272102  [    0/69886]
loss: 0.155594  [ 6400/69886]
loss: 0.144628  [12800/69886]
loss: 0.121524  [19200/69886]
loss: 0.202692  [25600/69886]
loss: 0.118784  [32000/69886]
loss: 0.215162  [38400/69886]
loss: 0.091223  [44800/69886]
loss: 0.121619  [51200/69886]
loss: 0.272605  [57600/69886]
loss: 0.198833  [64000/69886]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.166414 

Epoch 29
-------------------------------
loss: 0.229099  [    0/69886]
loss: 0.151305  [ 6400/69886]
loss: 0.089480  [12800/69886]
loss: 0.078857  [19200/69886]
loss: 0.106691  [25600/69886]
loss: 0.225664  [32000/69886]
loss: 0.100283  [38400/69886]
loss: 0.097230  [44800/69886]
loss: 0.167908  [51200/69886]
loss: 0.284302  [57600/69886]
loss: 0.176094  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.159229 

Epoch 30
-------------------------------
loss: 0.172456  [    0/69886]
loss: 0.104528  [ 6400/69886]
loss: 0.182353  [12800/69886]
loss: 0.068562  [19200/69886]
loss: 0.227543  [25600/69886]
loss: 0.186182  [32000/69886]
loss: 0.096901  [38400/69886]
loss: 0.136841  [44800/69886]
loss: 0.128268  [51200/69886]
loss: 0.342204  [57600/69886]
loss: 0.207752  [64000/69886]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.169676 

Epoch 31
-------------------------------
loss: 0.144112  [    0/69886]
loss: 0.137554  [ 6400/69886]
loss: 0.170782  [12800/69886]
loss: 0.203203  [19200/69886]
loss: 0.038491  [25600/69886]
loss: 0.164090  [32000/69886]
loss: 0.233203  [38400/69886]
loss: 0.097004  [44800/69886]
loss: 0.197047  [51200/69886]
loss: 0.202323  [57600/69886]
loss: 0.108155  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.161424 

Epoch 32
-------------------------------
loss: 0.214167  [    0/69886]
loss: 0.072091  [ 6400/69886]
loss: 0.139498  [12800/69886]
loss: 0.354388  [19200/69886]
loss: 0.223213  [25600/69886]
loss: 0.219781  [32000/69886]
loss: 0.143192  [38400/69886]
loss: 0.104329  [44800/69886]
loss: 0.171462  [51200/69886]
loss: 0.276073  [57600/69886]
loss: 0.271018  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.170500 

Epoch 33
-------------------------------
loss: 0.144555  [    0/69886]
loss: 0.127144  [ 6400/69886]
loss: 0.168473  [12800/69886]
loss: 0.229595  [19200/69886]
loss: 0.183096  [25600/69886]
loss: 0.117696  [32000/69886]
loss: 0.260723  [38400/69886]
loss: 0.135529  [44800/69886]
loss: 0.144151  [51200/69886]
loss: 0.118507  [57600/69886]
loss: 0.318951  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.156521 

Epoch 34
-------------------------------
loss: 0.245522  [    0/69886]
loss: 0.106210  [ 6400/69886]
loss: 0.179251  [12800/69886]
loss: 0.139812  [19200/69886]
loss: 0.230403  [25600/69886]
loss: 0.211420  [32000/69886]
loss: 0.240442  [38400/69886]
loss: 0.105667  [44800/69886]
loss: 0.156452  [51200/69886]
loss: 0.178851  [57600/69886]
loss: 0.248803  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.159661 

Epoch 35
-------------------------------
loss: 0.222330  [    0/69886]
loss: 0.175737  [ 6400/69886]
loss: 0.073754  [12800/69886]
loss: 0.177064  [19200/69886]
loss: 0.206756  [25600/69886]
loss: 0.173276  [32000/69886]
loss: 0.199336  [38400/69886]
loss: 0.202869  [44800/69886]
loss: 0.113390  [51200/69886]
loss: 0.135877  [57600/69886]
loss: 0.176339  [64000/69886]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.169179 

Epoch 36
-------------------------------
loss: 0.206989  [    0/69886]
loss: 0.157377  [ 6400/69886]
loss: 0.252454  [12800/69886]
loss: 0.073692  [19200/69886]
loss: 0.069608  [25600/69886]
loss: 0.304563  [32000/69886]
loss: 0.248072  [38400/69886]
loss: 0.245354  [44800/69886]
loss: 0.134208  [51200/69886]
loss: 0.381418  [57600/69886]
loss: 0.133098  [64000/69886]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.157141 

Epoch 37
-------------------------------
loss: 0.193212  [    0/69886]
loss: 0.145854  [ 6400/69886]
loss: 0.222646  [12800/69886]
loss: 0.165270  [19200/69886]
loss: 0.162704  [25600/69886]
loss: 0.183602  [32000/69886]
loss: 0.108828  [38400/69886]
loss: 0.185819  [44800/69886]
loss: 0.134643  [51200/69886]
loss: 0.165800  [57600/69886]
loss: 0.207476  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.166675 

Epoch 38
-------------------------------
loss: 0.118345  [    0/69886]
loss: 0.220599  [ 6400/69886]
loss: 0.126298  [12800/69886]
loss: 0.183128  [19200/69886]
loss: 0.220793  [25600/69886]
loss: 0.117973  [32000/69886]
loss: 0.224103  [38400/69886]
loss: 0.209025  [44800/69886]
loss: 0.187966  [51200/69886]
loss: 0.077411  [57600/69886]
loss: 0.098724  [64000/69886]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.169481 

2022/09/20 20:37:31 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.086695 

Epoch 37
-------------------------------
loss: 0.050380  [    0/72262]
loss: 0.002958  [ 6400/72262]
loss: 0.004838  [12800/72262]
loss: 0.019346  [19200/72262]
loss: 0.013133  [25600/72262]
loss: 0.004046  [32000/72262]
loss: 0.013907  [38400/72262]
loss: 0.050264  [44800/72262]
loss: 0.012189  [51200/72262]
loss: 0.015262  [57600/72262]
loss: 0.003622  [64000/72262]
loss: 0.006169  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.084841 

Epoch 38
-------------------------------
loss: 0.016249  [    0/72262]
loss: 0.015249  [ 6400/72262]
loss: 0.000463  [12800/72262]
loss: 0.105577  [19200/72262]
loss: 0.147138  [25600/72262]
loss: 0.026184  [32000/72262]
loss: 0.077927  [38400/72262]
loss: 0.038272  [44800/72262]
loss: 0.008051  [51200/72262]
loss: 0.077423  [57600/72262]
loss: 0.097529  [64000/72262]
loss: 0.082313  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.097210 

Epoch 39
-------------------------------
loss: 0.033288  [    0/72262]
loss: 0.000454  [ 6400/72262]
loss: 0.007267  [12800/72262]
loss: 0.019600  [19200/72262]
loss: 0.039655  [25600/72262]
loss: 0.002245  [32000/72262]
loss: 0.029508  [38400/72262]
loss: 0.018398  [44800/72262]
loss: 0.001596  [51200/72262]
loss: 0.002100  [57600/72262]
loss: 0.087916  [64000/72262]
loss: 0.003937  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.101614 

Epoch 40
-------------------------------
loss: 0.110024  [    0/72262]
loss: 0.001138  [ 6400/72262]
loss: 0.008982  [12800/72262]
loss: 0.029387  [19200/72262]
loss: 0.040710  [25600/72262]
loss: 0.063689  [32000/72262]
loss: 0.007941  [38400/72262]
loss: 0.013605  [44800/72262]
loss: 0.075914  [51200/72262]
loss: 0.009365  [57600/72262]
loss: 0.005027  [64000/72262]
loss: 0.021685  [70400/72262]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.083194 

Epoch 41
-------------------------------
loss: 0.013463  [    0/72262]
loss: 0.039320  [ 6400/72262]
loss: 0.017662  [12800/72262]
loss: 0.014712  [19200/72262]
loss: 0.001147  [25600/72262]
loss: 0.000945  [32000/72262]
loss: 0.004896  [38400/72262]
loss: 0.000371  [44800/72262]
loss: 0.023970  [51200/72262]
loss: 0.017496  [57600/72262]
loss: 0.089475  [64000/72262]
loss: 0.004614  [70400/72262]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.089156 

Epoch 42
-------------------------------
loss: 0.002162  [    0/72262]
loss: 0.000739  [ 6400/72262]
loss: 0.002461  [12800/72262]
loss: 0.008617  [19200/72262]
loss: 0.020941  [25600/72262]
loss: 0.020193  [32000/72262]
loss: 0.009412  [38400/72262]
loss: 0.008638  [44800/72262]
loss: 0.014108  [51200/72262]
loss: 0.000542  [57600/72262]
loss: 0.027904  [64000/72262]
loss: 0.000662  [70400/72262]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.085930 

Epoch 43
-------------------------------
loss: 0.000290  [    0/72262]
loss: 0.005071  [ 6400/72262]
loss: 0.014555  [12800/72262]
loss: 0.001747  [19200/72262]
loss: 0.001342  [25600/72262]
loss: 0.012670  [32000/72262]
loss: 0.012638  [38400/72262]
loss: 0.023435  [44800/72262]
loss: 0.039417  [51200/72262]
loss: 0.006583  [57600/72262]
loss: 0.049967  [64000/72262]
loss: 0.002510  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.088342 

Epoch 44
-------------------------------
loss: 0.002572  [    0/72262]
loss: 0.074979  [ 6400/72262]
loss: 0.027796  [12800/72262]
loss: 0.024784  [19200/72262]
loss: 0.004976  [25600/72262]
loss: 0.024221  [32000/72262]
loss: 0.030395  [38400/72262]
loss: 0.040117  [44800/72262]
loss: 0.004278  [51200/72262]
loss: 0.099553  [57600/72262]
loss: 0.018101  [64000/72262]
loss: 0.008102  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.084518 

Epoch 45
-------------------------------
loss: 0.018252  [    0/72262]
loss: 0.007419  [ 6400/72262]
loss: 0.013600  [12800/72262]
loss: 0.027946  [19200/72262]
loss: 0.046090  [25600/72262]
loss: 0.005386  [32000/72262]
loss: 0.021298  [38400/72262]
loss: 0.029461  [44800/72262]
loss: 0.006264  [51200/72262]
loss: 0.002364  [57600/72262]
loss: 0.018386  [64000/72262]
loss: 0.035396  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.097045 

Epoch 46
-------------------------------
loss: 0.003930  [    0/72262]
loss: 0.016946  [ 6400/72262]
loss: 0.068564  [12800/72262]
loss: 0.040275  [19200/72262]
loss: 0.036376  [25600/72262]
loss: 0.007955  [32000/72262]
loss: 0.016476  [38400/72262]
loss: 0.003614  [44800/72262]
loss: 0.022895  [51200/72262]
loss: 0.000798  [57600/72262]
loss: 0.002398  [64000/72262]
loss: 0.000967  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.102217 

Epoch 47
-------------------------------
loss: 0.013582  [    0/72262]
loss: 0.005553  [ 6400/72262]
loss: 0.018381  [12800/72262]
loss: 0.033956  [19200/72262]
loss: 0.000134  [25600/72262]
loss: 0.140281  [32000/72262]
loss: 0.032416  [38400/72262]
loss: 0.026766  [44800/72262]
loss: 0.053526  [51200/72262]
loss: 0.035435  [57600/72262]
loss: 0.146075  [64000/72262]
loss: 0.052057  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.099289 

Epoch 48
-------------------------------
loss: 0.002781  [    0/72262]
loss: 0.015545  [ 6400/72262]
loss: 0.015186  [12800/72262]
loss: 0.018051  [19200/72262]
loss: 0.036004  [25600/72262]
loss: 0.107276  [32000/72262]
loss: 0.018342  [38400/72262]
loss: 0.006016  [44800/72262]
loss: 0.025536  [51200/72262]
loss: 0.023598  [57600/72262]
loss: 0.018784  [64000/72262]
loss: 0.026135  [70400/72262]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.102409 

Epoch 49
-------------------------------
loss: 0.001470  [    0/72262]
loss: 0.017751  [ 6400/72262]
loss: 0.030628  [12800/72262]
loss: 0.094771  [19200/72262]
loss: 0.020012  [25600/72262]
loss: 0.007831  [32000/72262]
loss: 0.008659  [38400/72262]
loss: 0.012436  [44800/72262]
loss: 0.070238  [51200/72262]
loss: 0.000613  [57600/72262]
loss: 0.003076  [64000/72262]
loss: 0.015979  [70400/72262]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.115273 

Epoch 50
-------------------------------
loss: 0.019185  [    0/72262]
loss: 0.015458  [ 6400/72262]
loss: 0.033061  [12800/72262]
loss: 0.068953  [19200/72262]
loss: 0.149577  [25600/72262]
loss: 0.010524  [32000/72262]
loss: 0.019239  [38400/72262]
loss: 0.003051  [44800/72262]
loss: 0.007426  [51200/72262]
loss: 0.004942  [57600/72262]
loss: 0.001837  [64000/72262]
loss: 0.001360  [70400/72262]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.106794 

Epoch 1
-------------------------------
loss: 0.722663  [    0/72605]
loss: 0.240654  [ 6400/72605]
loss: 0.073222  [12800/72605]
loss: 0.069566  [19200/72605]
loss: 0.027728  [25600/72605]
loss: 0.086954  [32000/72605]
loss: 0.174836  [38400/72605]
loss: 0.013886  [44800/72605]
loss: 0.012956  [51200/72605]
loss: 0.025243  [57600/72605]
loss: 0.017982  [64000/72605]
loss: 0.267534  [70400/72605]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.045335 

Epoch 2
-------------------------------
loss: 0.004436  [    0/72605]
loss: 0.102311  [ 6400/72605]
loss: 0.064104  [12800/72605]
loss: 0.004132  [19200/72605]
loss: 0.003948  [25600/72605]
loss: 0.003718  [32000/72605]
loss: 0.041395  [38400/72605]
loss: 0.016745  [44800/72605]
loss: 0.095656  [51200/72605]
loss: 0.025172  [57600/72605]
loss: 0.044852  [64000/72605]
loss: 0.008298  [70400/72605]
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.049646 

Epoch 3
-------------------------------
loss: 0.096311  [    0/72605]
loss: 0.026818  [ 6400/72605]
loss: 0.006634  [12800/72605]
loss: 0.015653  [19200/72605]
loss: 0.006244  [25600/72605]
loss: 0.013508  [32000/72605]
loss: 0.006245  [38400/72605]
loss: 0.028137  [44800/72605]
loss: 0.007015  [51200/72605]
loss: 0.032571  [57600/72605]
loss: 0.007887  [64000/72605]
loss: 0.009397  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.050768 

Epoch 4
-------------------------------
loss: 0.006353  [    0/72605]
loss: 0.020076  [ 6400/72605]
loss: 0.001071  [12800/72605]
loss: 0.031740  [19200/72605]
loss: 0.242819  [25600/72605]
loss: 0.016960  [32000/72605]
loss: 0.002302  [38400/72605]
loss: 0.012441  [44800/72605]
loss: 0.001777  [51200/72605]
loss: 0.009411  [57600/72605]
loss: 0.001392  [64000/72605]
loss: 0.002902  [70400/72605]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.201548 

Epoch 36
-------------------------------
loss: 0.217915  [    0/69752]
loss: 0.095065  [ 6400/69752]
loss: 0.146173  [12800/69752]
loss: 0.198064  [19200/69752]
loss: 0.093807  [25600/69752]
loss: 0.235702  [32000/69752]
loss: 0.163432  [38400/69752]
loss: 0.116152  [44800/69752]
loss: 0.102675  [51200/69752]
loss: 0.086561  [57600/69752]
loss: 0.108309  [64000/69752]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.169947 

Epoch 37
-------------------------------
loss: 0.085762  [    0/69752]
loss: 0.227304  [ 6400/69752]
loss: 0.125549  [12800/69752]
loss: 0.107479  [19200/69752]
loss: 0.156998  [25600/69752]
loss: 0.072795  [32000/69752]
loss: 0.305444  [38400/69752]
loss: 0.261753  [44800/69752]
loss: 0.098767  [51200/69752]
loss: 0.098221  [57600/69752]
loss: 0.221317  [64000/69752]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.169054 

Epoch 38
-------------------------------
loss: 0.035537  [    0/69752]
loss: 0.153530  [ 6400/69752]
loss: 0.133402  [12800/69752]
loss: 0.100356  [19200/69752]
loss: 0.196349  [25600/69752]
loss: 0.174481  [32000/69752]
loss: 0.117538  [38400/69752]
loss: 0.131896  [44800/69752]
loss: 0.177502  [51200/69752]
loss: 0.108840  [57600/69752]
loss: 0.105167  [64000/69752]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.172853 

Epoch 39
-------------------------------
loss: 0.147281  [    0/69752]
loss: 0.062395  [ 6400/69752]
loss: 0.058850  [12800/69752]
loss: 0.112255  [19200/69752]
loss: 0.096981  [25600/69752]
loss: 0.129216  [32000/69752]
loss: 0.232950  [38400/69752]
loss: 0.151992  [44800/69752]
loss: 0.799537  [51200/69752]
loss: 0.145390  [57600/69752]
loss: 0.214687  [64000/69752]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.177930 

Epoch 40
-------------------------------
loss: 0.121683  [    0/69752]
loss: 0.074245  [ 6400/69752]
loss: 0.127680  [12800/69752]
loss: 0.083954  [19200/69752]
loss: 0.129424  [25600/69752]
loss: 0.053110  [32000/69752]
loss: 0.133630  [38400/69752]
loss: 0.196918  [44800/69752]
loss: 0.158235  [51200/69752]
loss: 0.267992  [57600/69752]
loss: 0.104065  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.170970 

Epoch 41
-------------------------------
loss: 0.287292  [    0/69752]
loss: 0.073953  [ 6400/69752]
loss: 0.108251  [12800/69752]
loss: 0.223570  [19200/69752]
loss: 0.189601  [25600/69752]
loss: 0.102553  [32000/69752]
loss: 0.124035  [38400/69752]
loss: 0.177170  [44800/69752]
loss: 0.315853  [51200/69752]
loss: 0.137608  [57600/69752]
loss: 0.130090  [64000/69752]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.170891 

Epoch 42
-------------------------------
loss: 0.128669  [    0/69752]
loss: 0.085865  [ 6400/69752]
loss: 0.105111  [12800/69752]
loss: 0.033500  [19200/69752]
loss: 0.122218  [25600/69752]
loss: 0.147138  [32000/69752]
loss: 0.172830  [38400/69752]
loss: 0.306574  [44800/69752]
loss: 0.265651  [51200/69752]
loss: 0.224821  [57600/69752]
loss: 0.135187  [64000/69752]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.187754 

Epoch 43
-------------------------------
loss: 0.161497  [    0/69752]
loss: 0.175885  [ 6400/69752]
loss: 0.165026  [12800/69752]
loss: 0.201055  [19200/69752]
loss: 0.056333  [25600/69752]
loss: 0.117301  [32000/69752]
loss: 0.231700  [38400/69752]
loss: 0.136804  [44800/69752]
loss: 0.124417  [51200/69752]
loss: 0.220546  [57600/69752]
loss: 0.095923  [64000/69752]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.176300 

Epoch 44
-------------------------------
loss: 0.072395  [    0/69752]
loss: 0.065980  [ 6400/69752]
loss: 0.162774  [12800/69752]
loss: 0.074264  [19200/69752]
loss: 0.168896  [25600/69752]
loss: 0.187106  [32000/69752]
loss: 0.210389  [38400/69752]
loss: 0.287136  [44800/69752]
loss: 0.269134  [51200/69752]
loss: 0.020017  [57600/69752]
loss: 0.086126  [64000/69752]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.174130 

Epoch 45
-------------------------------
loss: 0.097107  [    0/69752]
loss: 0.057460  [ 6400/69752]
loss: 0.051919  [12800/69752]
loss: 0.131486  [19200/69752]
loss: 0.104421  [25600/69752]
loss: 0.213701  [32000/69752]
loss: 0.113153  [38400/69752]
loss: 0.071298  [44800/69752]
loss: 0.198068  [51200/69752]
loss: 0.084029  [57600/69752]
loss: 0.162586  [64000/69752]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.168119 

Epoch 46
-------------------------------
loss: 0.098495  [    0/69752]
loss: 0.176214  [ 6400/69752]
loss: 0.096313  [12800/69752]
loss: 0.084485  [19200/69752]
loss: 0.231198  [25600/69752]
loss: 0.126438  [32000/69752]
loss: 0.198057  [38400/69752]
loss: 0.116904  [44800/69752]
loss: 0.210931  [51200/69752]
loss: 0.151313  [57600/69752]
loss: 0.089437  [64000/69752]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.181006 

Epoch 47
-------------------------------
loss: 0.176881  [    0/69752]
loss: 0.126428  [ 6400/69752]
loss: 0.086197  [12800/69752]
loss: 0.142587  [19200/69752]
loss: 0.206762  [25600/69752]
loss: 0.188651  [32000/69752]
loss: 0.214560  [38400/69752]
loss: 0.062659  [44800/69752]
loss: 0.129902  [51200/69752]
loss: 0.120839  [57600/69752]
loss: 0.164014  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.172178 

Epoch 48
-------------------------------
loss: 0.091708  [    0/69752]
loss: 0.073165  [ 6400/69752]
loss: 0.151160  [12800/69752]
loss: 0.117681  [19200/69752]
loss: 0.109561  [25600/69752]
loss: 0.143913  [32000/69752]
loss: 0.180050  [38400/69752]
loss: 0.108387  [44800/69752]
loss: 0.269884  [51200/69752]
loss: 0.103103  [57600/69752]
loss: 0.241753  [64000/69752]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.173048 

Epoch 49
-------------------------------
loss: 0.098451  [    0/69752]
loss: 0.068164  [ 6400/69752]
loss: 0.115760  [12800/69752]
loss: 0.185359  [19200/69752]
loss: 0.138874  [25600/69752]
loss: 0.155728  [32000/69752]
loss: 0.082947  [38400/69752]
loss: 0.167597  [44800/69752]
loss: 0.081140  [51200/69752]
loss: 0.070908  [57600/69752]
loss: 0.122965  [64000/69752]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.183732 

Epoch 50
-------------------------------
loss: 0.086368  [    0/69752]
loss: 0.130867  [ 6400/69752]
loss: 0.073382  [12800/69752]
loss: 0.114804  [19200/69752]
loss: 0.206959  [25600/69752]
loss: 0.096757  [32000/69752]
loss: 0.214835  [38400/69752]
loss: 0.108404  [44800/69752]
loss: 0.070382  [51200/69752]
loss: 0.250429  [57600/69752]
loss: 0.106152  [64000/69752]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.166820 

Epoch 1
-------------------------------
loss: 0.603619  [    0/69987]
loss: 0.360315  [ 6400/69987]
loss: 0.340765  [12800/69987]
loss: 0.326556  [19200/69987]
loss: 0.271979  [25600/69987]
loss: 0.293066  [32000/69987]
loss: 0.313946  [38400/69987]
loss: 0.256196  [44800/69987]
loss: 0.196643  [51200/69987]
loss: 0.262862  [57600/69987]
loss: 0.241822  [64000/69987]
Test Error: 
 Accuracy: 90.6%, Avg loss: 0.247664 

Epoch 2
-------------------------------
loss: 0.149372  [    0/69987]
loss: 0.158472  [ 6400/69987]
loss: 0.176154  [12800/69987]
loss: 0.321993  [19200/69987]
loss: 0.199284  [25600/69987]
loss: 0.278139  [32000/69987]
loss: 0.211531  [38400/69987]
loss: 0.285879  [44800/69987]
loss: 0.370636  [51200/69987]
loss: 0.107295  [57600/69987]
loss: 0.260219  [64000/69987]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.218497 

Epoch 3
-------------------------------
loss: 0.194277  [    0/69987]
loss: 0.117503  [ 6400/69987]
loss: 0.134379  [12800/69987]
loss: 0.139312  [19200/69987]
loss: 0.276996  [25600/69987]
loss: 0.242029  [32000/69987]
loss: 0.164097  [38400/69987]
loss: 0.141831  [44800/69987]
loss: 0.416307  [51200/69987]
loss: 0.133409  [57600/69987]
loss: 0.125022  [64000/69987]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.213877 

Epoch 4
-------------------------------
loss: 0.166336  [    0/69987]
loss: 0.138776  [ 6400/69987]
loss: 0.163428  [12800/69987]
loss: 0.124903  [19200/69987]
loss: 0.165714  [25600/69987]
loss: 0.300133  [32000/69987]
loss: 0.147049  [38400/69987]
loss: 0.263143  [44800/69987]
loss: 0.215486  [51200/69987]
loss: 0.263940  [57600/69987]
loss: 0.232349  [64000/69987]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.208048 

Epoch 5
-------------------------------
loss: 0.113560  [    0/69987]
loss: 0.153393  [ 6400/69987]
2022/09/20 20:39:07 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.190223  [44800/70245]
loss: 0.250474  [51200/70245]
loss: 0.197315  [57600/70245]
loss: 0.204516  [64000/70245]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.220578 

Epoch 12
-------------------------------
loss: 0.141513  [    0/70245]
loss: 0.049866  [ 6400/70245]
loss: 0.144872  [12800/70245]
loss: 0.215708  [19200/70245]
loss: 0.144592  [25600/70245]
loss: 0.190622  [32000/70245]
loss: 0.157345  [38400/70245]
loss: 0.334108  [44800/70245]
loss: 0.177596  [51200/70245]
loss: 0.226815  [57600/70245]
loss: 0.201534  [64000/70245]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.209681 

Epoch 13
-------------------------------
loss: 0.326682  [    0/70245]
loss: 0.133204  [ 6400/70245]
loss: 0.107957  [12800/70245]
loss: 0.098070  [19200/70245]
loss: 0.120913  [25600/70245]
loss: 0.148253  [32000/70245]
loss: 0.239412  [38400/70245]
loss: 0.213783  [44800/70245]
loss: 0.201963  [51200/70245]
loss: 0.116227  [57600/70245]
loss: 0.136483  [64000/70245]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.198338 

Epoch 14
-------------------------------
loss: 0.144447  [    0/70245]
loss: 0.135475  [ 6400/70245]
loss: 0.200063  [12800/70245]
loss: 0.131431  [19200/70245]
loss: 0.156755  [25600/70245]
loss: 0.188723  [32000/70245]
loss: 0.096289  [38400/70245]
loss: 0.117228  [44800/70245]
loss: 0.204324  [51200/70245]
loss: 0.241284  [57600/70245]
loss: 0.197857  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.194970 

Epoch 15
-------------------------------
loss: 0.224139  [    0/70245]
loss: 0.177996  [ 6400/70245]
loss: 0.119262  [12800/70245]
loss: 0.206058  [19200/70245]
loss: 0.120889  [25600/70245]
loss: 1.724530  [32000/70245]
loss: 0.179833  [38400/70245]
loss: 0.208403  [44800/70245]
loss: 0.136200  [51200/70245]
loss: 0.146303  [57600/70245]
loss: 0.185741  [64000/70245]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.195503 

Epoch 16
-------------------------------
loss: 0.153869  [    0/70245]
loss: 0.285512  [ 6400/70245]
loss: 1.722847  [12800/70245]
loss: 0.306567  [19200/70245]
loss: 0.181784  [25600/70245]
loss: 0.222330  [32000/70245]
loss: 0.142414  [38400/70245]
loss: 0.139836  [44800/70245]
loss: 0.136052  [51200/70245]
loss: 0.115403  [57600/70245]
loss: 0.123833  [64000/70245]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.201584 

Epoch 17
-------------------------------
loss: 0.135336  [    0/70245]
loss: 0.276795  [ 6400/70245]
loss: 0.121599  [12800/70245]
loss: 0.079459  [19200/70245]
loss: 0.213361  [25600/70245]
loss: 0.130297  [32000/70245]
loss: 0.202242  [38400/70245]
loss: 0.154480  [44800/70245]
loss: 0.223633  [51200/70245]
loss: 0.066355  [57600/70245]
loss: 0.181143  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.198822 

Epoch 18
-------------------------------
loss: 0.120945  [    0/70245]
loss: 0.138437  [ 6400/70245]
loss: 0.320638  [12800/70245]
loss: 0.110120  [19200/70245]
loss: 0.153568  [25600/70245]
loss: 0.158884  [32000/70245]
loss: 0.151194  [38400/70245]
loss: 0.252994  [44800/70245]
loss: 0.160240  [51200/70245]
loss: 1.685157  [57600/70245]
loss: 0.299041  [64000/70245]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.211347 

Epoch 19
-------------------------------
loss: 0.192833  [    0/70245]
loss: 0.112403  [ 6400/70245]
loss: 0.255362  [12800/70245]
loss: 0.254841  [19200/70245]
loss: 0.115654  [25600/70245]
loss: 0.176383  [32000/70245]
loss: 0.225542  [38400/70245]
loss: 0.130028  [44800/70245]
loss: 0.148831  [51200/70245]
loss: 0.158980  [57600/70245]
loss: 0.134864  [64000/70245]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.197577 

Epoch 20
-------------------------------
loss: 0.236122  [    0/70245]
loss: 0.187779  [ 6400/70245]
loss: 0.130846  [12800/70245]
loss: 0.129881  [19200/70245]
loss: 0.129544  [25600/70245]
loss: 0.139498  [32000/70245]
loss: 0.142525  [38400/70245]
loss: 0.155122  [44800/70245]
loss: 0.167168  [51200/70245]
loss: 0.119482  [57600/70245]
loss: 0.116963  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.200119 

Epoch 21
-------------------------------
loss: 0.222030  [    0/70245]
loss: 0.217715  [ 6400/70245]
loss: 0.095260  [12800/70245]
loss: 0.109253  [19200/70245]
loss: 0.192042  [25600/70245]
loss: 0.131486  [32000/70245]
loss: 0.087024  [38400/70245]
loss: 0.232249  [44800/70245]
loss: 0.161563  [51200/70245]
loss: 0.151839  [57600/70245]
loss: 0.224304  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.199335 

Epoch 22
-------------------------------
loss: 0.186133  [    0/70245]
loss: 0.190477  [ 6400/70245]
loss: 0.202270  [12800/70245]
loss: 0.132238  [19200/70245]
loss: 0.339246  [25600/70245]
loss: 0.178089  [32000/70245]
loss: 0.205936  [38400/70245]
loss: 0.265670  [44800/70245]
loss: 0.165075  [51200/70245]
loss: 0.244940  [57600/70245]
loss: 0.178132  [64000/70245]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.217539 

Epoch 23
-------------------------------
loss: 0.259051  [    0/70245]
loss: 0.196878  [ 6400/70245]
loss: 0.205487  [12800/70245]
loss: 0.166470  [19200/70245]
loss: 0.098363  [25600/70245]
loss: 0.201731  [32000/70245]
loss: 0.183778  [38400/70245]
loss: 0.272329  [44800/70245]
loss: 0.233691  [51200/70245]
loss: 0.140230  [57600/70245]
loss: 0.176930  [64000/70245]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.205500 

Epoch 24
-------------------------------
loss: 0.232851  [    0/70245]
loss: 0.246906  [ 6400/70245]
loss: 0.161311  [12800/70245]
loss: 0.170380  [19200/70245]
loss: 0.179314  [25600/70245]
loss: 0.089706  [32000/70245]
loss: 0.190357  [38400/70245]
loss: 0.199309  [44800/70245]
loss: 0.118279  [51200/70245]
loss: 0.199421  [57600/70245]
loss: 0.104731  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.199559 

Epoch 25
-------------------------------
loss: 0.186832  [    0/70245]
loss: 0.231585  [ 6400/70245]
loss: 0.111362  [12800/70245]
loss: 0.103898  [19200/70245]
loss: 0.322195  [25600/70245]
loss: 0.208592  [32000/70245]
loss: 0.194951  [38400/70245]
loss: 0.095566  [44800/70245]
loss: 0.127475  [51200/70245]
loss: 0.168102  [57600/70245]
loss: 0.316754  [64000/70245]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.205402 

Epoch 26
-------------------------------
loss: 0.254373  [    0/70245]
loss: 0.300248  [ 6400/70245]
loss: 0.123887  [12800/70245]
loss: 0.149827  [19200/70245]
loss: 0.262851  [25600/70245]
loss: 0.183278  [32000/70245]
loss: 0.165805  [38400/70245]
loss: 0.166029  [44800/70245]
loss: 0.241051  [51200/70245]
loss: 0.357638  [57600/70245]
loss: 0.278863  [64000/70245]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.193795 

Epoch 27
-------------------------------
loss: 0.165237  [    0/70245]
loss: 0.142495  [ 6400/70245]
loss: 1.669313  [12800/70245]
loss: 0.119784  [19200/70245]
loss: 0.117022  [25600/70245]
loss: 0.200475  [32000/70245]
loss: 0.207427  [38400/70245]
loss: 0.181256  [44800/70245]
loss: 0.165025  [51200/70245]
loss: 0.157165  [57600/70245]
loss: 0.136996  [64000/70245]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.193073 

Epoch 28
-------------------------------
loss: 0.173083  [    0/70245]
loss: 0.219151  [ 6400/70245]
loss: 0.206308  [12800/70245]
loss: 0.155552  [19200/70245]
loss: 0.073500  [25600/70245]
loss: 0.232525  [32000/70245]
loss: 0.187360  [38400/70245]
loss: 0.110395  [44800/70245]
loss: 0.156181  [51200/70245]
loss: 0.248917  [57600/70245]
loss: 0.191197  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.196462 

Epoch 29
-------------------------------
loss: 0.170693  [    0/70245]
loss: 0.150788  [ 6400/70245]
loss: 0.132334  [12800/70245]
loss: 0.129368  [19200/70245]
loss: 0.207341  [25600/70245]
loss: 0.116377  [32000/70245]
loss: 0.232392  [38400/70245]
loss: 0.168057  [44800/70245]
loss: 0.139275  [51200/70245]
loss: 0.292044  [57600/70245]
loss: 0.190895  [64000/70245]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.203443 

Epoch 30
-------------------------------
loss: 0.132959  [    0/70245]
loss: 0.189625  [ 6400/70245]
loss: 0.262959  [12800/70245]
loss: 0.140171  [19200/70245]
loss: 0.164884  [25600/70245]
loss: 0.216609  [32000/70245]
loss: 0.205621  [38400/70245]
loss: 0.148171  [44800/70245]
loss: 0.123710  [51200/70245]
loss: 0.205739  [57600/70245]
loss: 0.131502  [64000/70245]
2022/09/20 20:40:40 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.135297  [12800/70031]
loss: 0.093437  [19200/70031]
loss: 0.090205  [25600/70031]
loss: 0.049882  [32000/70031]
loss: 0.141054  [38400/70031]
loss: 1.624658  [44800/70031]
loss: 0.057056  [51200/70031]
loss: 0.084870  [57600/70031]
loss: 0.079784  [64000/70031]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.187592 

Epoch 28
-------------------------------
loss: 0.257077  [    0/70031]
loss: 0.068583  [ 6400/70031]
loss: 0.127816  [12800/70031]
loss: 0.057286  [19200/70031]
loss: 0.127722  [25600/70031]
loss: 0.082754  [32000/70031]
loss: 0.095846  [38400/70031]
loss: 0.087057  [44800/70031]
loss: 0.068879  [51200/70031]
loss: 0.091114  [57600/70031]
loss: 0.136117  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.107420 

Epoch 29
-------------------------------
loss: 0.059971  [    0/70031]
loss: 0.109416  [ 6400/70031]
loss: 0.069036  [12800/70031]
loss: 0.066576  [19200/70031]
loss: 0.113124  [25600/70031]
loss: 0.104068  [32000/70031]
loss: 0.088503  [38400/70031]
loss: 0.161121  [44800/70031]
loss: 0.170482  [51200/70031]
loss: 0.253333  [57600/70031]
loss: 0.075704  [64000/70031]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.114644 

Epoch 30
-------------------------------
loss: 0.124090  [    0/70031]
loss: 0.069716  [ 6400/70031]
loss: 0.143713  [12800/70031]
loss: 0.227860  [19200/70031]
loss: 0.058210  [25600/70031]
loss: 0.030408  [32000/70031]
loss: 0.109321  [38400/70031]
loss: 0.097569  [44800/70031]
loss: 0.098355  [51200/70031]
loss: 0.181050  [57600/70031]
loss: 0.099941  [64000/70031]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.126591 

Epoch 31
-------------------------------
loss: 0.147233  [    0/70031]
loss: 0.119063  [ 6400/70031]
loss: 0.066988  [12800/70031]
loss: 0.123415  [19200/70031]
loss: 0.165451  [25600/70031]
loss: 0.125169  [32000/70031]
loss: 0.106129  [38400/70031]
loss: 0.183122  [44800/70031]
loss: 0.135889  [51200/70031]
loss: 0.141238  [57600/70031]
loss: 0.292913  [64000/70031]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.124691 

Epoch 32
-------------------------------
loss: 0.104563  [    0/70031]
loss: 0.080952  [ 6400/70031]
loss: 0.091557  [12800/70031]
loss: 0.055597  [19200/70031]
loss: 0.083529  [25600/70031]
loss: 0.114121  [32000/70031]
loss: 0.113830  [38400/70031]
loss: 0.027308  [44800/70031]
loss: 0.067516  [51200/70031]
loss: 0.043482  [57600/70031]
loss: 0.071593  [64000/70031]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.108278 

Epoch 33
-------------------------------
loss: 0.145916  [    0/70031]
loss: 0.065988  [ 6400/70031]
loss: 0.132288  [12800/70031]
loss: 0.116213  [19200/70031]
loss: 0.134337  [25600/70031]
loss: 0.116815  [32000/70031]
loss: 0.132618  [38400/70031]
loss: 0.122862  [44800/70031]
loss: 0.083200  [51200/70031]
loss: 0.172636  [57600/70031]
loss: 0.160554  [64000/70031]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.103865 

Epoch 34
-------------------------------
loss: 0.117521  [    0/70031]
loss: 0.129645  [ 6400/70031]
loss: 0.073596  [12800/70031]
loss: 0.053725  [19200/70031]
loss: 0.109181  [25600/70031]
loss: 0.086210  [32000/70031]
loss: 0.035662  [38400/70031]
loss: 0.124316  [44800/70031]
loss: 0.087881  [51200/70031]
loss: 0.097165  [57600/70031]
loss: 0.098140  [64000/70031]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.106499 

Epoch 35
-------------------------------
loss: 0.188343  [    0/70031]
loss: 0.094507  [ 6400/70031]
loss: 0.118509  [12800/70031]
loss: 0.121513  [19200/70031]
loss: 0.081162  [25600/70031]
loss: 0.058071  [32000/70031]
loss: 0.036671  [38400/70031]
loss: 0.108591  [44800/70031]
loss: 0.052919  [51200/70031]
loss: 0.168751  [57600/70031]
loss: 0.096372  [64000/70031]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.112794 

Epoch 36
-------------------------------
loss: 0.065424  [    0/70031]
loss: 0.210534  [ 6400/70031]
loss: 0.059133  [12800/70031]
loss: 0.019108  [19200/70031]
loss: 0.205441  [25600/70031]
loss: 0.066468  [32000/70031]
loss: 0.120812  [38400/70031]
loss: 0.151025  [44800/70031]
loss: 0.075053  [51200/70031]
loss: 0.091964  [57600/70031]
loss: 0.090939  [64000/70031]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.103815 

Epoch 37
-------------------------------
loss: 0.043092  [    0/70031]
loss: 0.101843  [ 6400/70031]
loss: 0.047767  [12800/70031]
loss: 0.140091  [19200/70031]
loss: 0.124864  [25600/70031]
loss: 0.117776  [32000/70031]
loss: 0.142727  [38400/70031]
loss: 0.067582  [44800/70031]
loss: 0.115693  [51200/70031]
loss: 0.032556  [57600/70031]
loss: 0.028298  [64000/70031]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.113428 

Epoch 38
-------------------------------
loss: 0.114786  [    0/70031]
loss: 0.130646  [ 6400/70031]
loss: 0.054649  [12800/70031]
loss: 0.194252  [19200/70031]
loss: 0.186766  [25600/70031]
loss: 0.165397  [32000/70031]
loss: 0.054429  [38400/70031]
loss: 0.110198  [44800/70031]
loss: 0.117613  [51200/70031]
loss: 0.118021  [57600/70031]
loss: 0.151221  [64000/70031]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.109672 

Epoch 39
-------------------------------
loss: 0.047896  [    0/70031]
loss: 0.058760  [ 6400/70031]
loss: 0.156708  [12800/70031]
loss: 0.086058  [19200/70031]
loss: 0.090124  [25600/70031]
loss: 0.086554  [32000/70031]
loss: 0.067647  [38400/70031]
loss: 0.068724  [44800/70031]
loss: 0.022547  [51200/70031]
loss: 0.099537  [57600/70031]
loss: 0.190063  [64000/70031]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.115618 

Epoch 40
-------------------------------
loss: 0.030315  [    0/70031]
loss: 0.063801  [ 6400/70031]
loss: 0.048585  [12800/70031]
loss: 0.052077  [19200/70031]
loss: 0.015157  [25600/70031]
loss: 0.044721  [32000/70031]
loss: 0.140463  [38400/70031]
loss: 0.107354  [44800/70031]
loss: 0.062609  [51200/70031]
loss: 0.111533  [57600/70031]
loss: 0.122851  [64000/70031]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.141442 

Epoch 41
-------------------------------
loss: 0.151540  [    0/70031]
loss: 0.025160  [ 6400/70031]
loss: 0.070175  [12800/70031]
loss: 0.129839  [19200/70031]
loss: 0.106661  [25600/70031]
loss: 0.065758  [32000/70031]
loss: 0.114043  [38400/70031]
loss: 0.187434  [44800/70031]
loss: 0.122144  [51200/70031]
loss: 0.210130  [57600/70031]
loss: 0.141850  [64000/70031]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.107571 

Epoch 42
-------------------------------
loss: 0.047409  [    0/70031]
loss: 0.084747  [ 6400/70031]
loss: 0.142125  [12800/70031]
loss: 0.068034  [19200/70031]
loss: 0.123205  [25600/70031]
loss: 0.061517  [32000/70031]
loss: 0.108692  [38400/70031]
loss: 0.040869  [44800/70031]
loss: 0.120769  [51200/70031]
loss: 0.075174  [57600/70031]
loss: 0.122369  [64000/70031]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.108163 

Epoch 43
-------------------------------
loss: 0.174326  [    0/70031]
loss: 0.026553  [ 6400/70031]
loss: 0.333131  [12800/70031]
loss: 0.093019  [19200/70031]
loss: 0.106304  [25600/70031]
loss: 0.102702  [32000/70031]
loss: 0.075694  [38400/70031]
loss: 0.044418  [44800/70031]
loss: 0.064276  [51200/70031]
loss: 0.221076  [57600/70031]
loss: 0.062448  [64000/70031]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.126216 

Epoch 44
-------------------------------
loss: 0.086110  [    0/70031]
loss: 0.126278  [ 6400/70031]
loss: 0.030951  [12800/70031]
loss: 0.075929  [19200/70031]
loss: 0.053182  [25600/70031]
loss: 0.078692  [32000/70031]
loss: 0.074673  [38400/70031]
loss: 0.128951  [44800/70031]
loss: 0.142313  [51200/70031]
loss: 0.035520  [57600/70031]
loss: 0.161161  [64000/70031]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.129041 

Epoch 45
-------------------------------
loss: 0.107111  [    0/70031]
loss: 0.064255  [ 6400/70031]
loss: 0.023499  [12800/70031]
loss: 0.140559  [19200/70031]
loss: 0.105208  [25600/70031]
loss: 0.047125  [32000/70031]
loss: 0.097872  [38400/70031]
loss: 0.078838  [44800/70031]
loss: 0.118196  [51200/70031]
loss: 0.049413  [57600/70031]
loss: 0.134689  [64000/70031]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.119302 

Epoch 46
-------------------------------
loss: 0.087622  [    0/70031]
loss: 0.134083  [ 6400/70031]
loss: 0.072276  [12800/70031]
loss: 0.123985  [19200/70031]
loss: 0.077739  [25600/70031]
loss: 0.154930  [32000/70031]
loss: 0.076904  [38400/70031]
2022/09/20 20:41:23 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.077760  [19200/69195]
loss: 0.084822  [25600/69195]
loss: 0.142676  [32000/69195]
loss: 0.186633  [38400/69195]
loss: 0.229117  [44800/69195]
loss: 0.066362  [51200/69195]
loss: 0.110987  [57600/69195]
loss: 0.076868  [64000/69195]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.149124 

Epoch 28
-------------------------------
loss: 0.125724  [    0/69195]
loss: 0.088000  [ 6400/69195]
loss: 0.171829  [12800/69195]
loss: 0.130179  [19200/69195]
loss: 0.091058  [25600/69195]
loss: 0.148642  [32000/69195]
loss: 0.185147  [38400/69195]
loss: 0.118310  [44800/69195]
loss: 0.161075  [51200/69195]
loss: 0.087054  [57600/69195]
loss: 0.199759  [64000/69195]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.155773 

Epoch 29
-------------------------------
loss: 0.091395  [    0/69195]
loss: 0.149519  [ 6400/69195]
loss: 0.040860  [12800/69195]
loss: 0.057554  [19200/69195]
loss: 0.188110  [25600/69195]
loss: 0.097770  [32000/69195]
loss: 0.164721  [38400/69195]
loss: 0.118196  [44800/69195]
loss: 0.109981  [51200/69195]
loss: 0.231607  [57600/69195]
loss: 0.105304  [64000/69195]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.138422 

Epoch 30
-------------------------------
loss: 0.135477  [    0/69195]
loss: 0.122301  [ 6400/69195]
loss: 0.072822  [12800/69195]
loss: 0.176268  [19200/69195]
loss: 0.211379  [25600/69195]
loss: 0.113764  [32000/69195]
loss: 0.205150  [38400/69195]
loss: 0.189059  [44800/69195]
loss: 0.070956  [51200/69195]
loss: 0.090842  [57600/69195]
loss: 0.064186  [64000/69195]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.153359 

Epoch 31
-------------------------------
loss: 0.108080  [    0/69195]
loss: 0.200344  [ 6400/69195]
loss: 0.130043  [12800/69195]
loss: 0.131962  [19200/69195]
loss: 0.149843  [25600/69195]
loss: 0.106603  [32000/69195]
loss: 0.338023  [38400/69195]
loss: 0.109826  [44800/69195]
loss: 0.115874  [51200/69195]
loss: 0.141317  [57600/69195]
loss: 0.177330  [64000/69195]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.141693 

Epoch 32
-------------------------------
loss: 0.152666  [    0/69195]
loss: 0.141984  [ 6400/69195]
loss: 0.068352  [12800/69195]
loss: 0.179993  [19200/69195]
loss: 0.102396  [25600/69195]
loss: 0.067805  [32000/69195]
loss: 0.223538  [38400/69195]
loss: 0.239256  [44800/69195]
loss: 0.079770  [51200/69195]
loss: 0.239924  [57600/69195]
loss: 0.161273  [64000/69195]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.167744 

Epoch 33
-------------------------------
loss: 0.170752  [    0/69195]
loss: 0.199554  [ 6400/69195]
loss: 0.160627  [12800/69195]
loss: 0.182464  [19200/69195]
loss: 0.135616  [25600/69195]
loss: 0.080067  [32000/69195]
loss: 0.236073  [38400/69195]
loss: 0.039634  [44800/69195]
loss: 0.155352  [51200/69195]
loss: 0.104243  [57600/69195]
loss: 0.219864  [64000/69195]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.154535 

Epoch 34
-------------------------------
loss: 0.219946  [    0/69195]
loss: 0.106770  [ 6400/69195]
loss: 0.187850  [12800/69195]
loss: 0.064112  [19200/69195]
loss: 0.101890  [25600/69195]
loss: 0.065670  [32000/69195]
loss: 0.176788  [38400/69195]
loss: 0.104285  [44800/69195]
loss: 0.096399  [51200/69195]
loss: 0.112985  [57600/69195]
loss: 0.131471  [64000/69195]
Test Error: 
 Accuracy: 91.0%, Avg loss: 0.237288 

Epoch 35
-------------------------------
loss: 0.170550  [    0/69195]
loss: 0.236031  [ 6400/69195]
loss: 0.220548  [12800/69195]
loss: 0.101239  [19200/69195]
loss: 0.137657  [25600/69195]
loss: 0.063314  [32000/69195]
loss: 0.141640  [38400/69195]
loss: 0.081397  [44800/69195]
loss: 0.259869  [51200/69195]
loss: 0.200723  [57600/69195]
loss: 0.130198  [64000/69195]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.138398 

Epoch 36
-------------------------------
loss: 0.108160  [    0/69195]
loss: 0.135467  [ 6400/69195]
loss: 0.055914  [12800/69195]
loss: 0.145603  [19200/69195]
loss: 0.090790  [25600/69195]
loss: 0.147993  [32000/69195]
loss: 0.109205  [38400/69195]
loss: 0.157131  [44800/69195]
loss: 0.067643  [51200/69195]
loss: 0.186691  [57600/69195]
loss: 0.097091  [64000/69195]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.197935 

Epoch 37
-------------------------------
loss: 0.199472  [    0/69195]
loss: 0.141718  [ 6400/69195]
loss: 0.186048  [12800/69195]
loss: 0.081925  [19200/69195]
loss: 0.145542  [25600/69195]
loss: 0.137455  [32000/69195]
loss: 0.142328  [38400/69195]
loss: 0.079760  [44800/69195]
loss: 0.137453  [51200/69195]
loss: 0.121492  [57600/69195]
loss: 0.062628  [64000/69195]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.142207 

Epoch 38
-------------------------------
loss: 0.174580  [    0/69195]
loss: 0.233112  [ 6400/69195]
loss: 0.157854  [12800/69195]
loss: 0.205588  [19200/69195]
loss: 0.114272  [25600/69195]
loss: 0.117327  [32000/69195]
loss: 0.183812  [38400/69195]
loss: 0.115110  [44800/69195]
loss: 0.141328  [51200/69195]
loss: 0.162988  [57600/69195]
loss: 0.078735  [64000/69195]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.140112 

Epoch 39
-------------------------------
loss: 0.101738  [    0/69195]
loss: 0.171016  [ 6400/69195]
loss: 0.170374  [12800/69195]
loss: 0.162184  [19200/69195]
loss: 0.194969  [25600/69195]
loss: 0.233480  [32000/69195]
loss: 0.185884  [38400/69195]
loss: 0.184040  [44800/69195]
loss: 0.204496  [51200/69195]
loss: 0.175959  [57600/69195]
loss: 0.085632  [64000/69195]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.145957 

Epoch 40
-------------------------------
loss: 0.070701  [    0/69195]
loss: 0.130317  [ 6400/69195]
loss: 0.153757  [12800/69195]
loss: 1.707298  [19200/69195]
loss: 0.272039  [25600/69195]
loss: 0.073273  [32000/69195]
loss: 0.099402  [38400/69195]
loss: 0.142750  [44800/69195]
loss: 0.070546  [51200/69195]
loss: 0.148568  [57600/69195]
loss: 0.129489  [64000/69195]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.155660 

Epoch 41
-------------------------------
loss: 0.134744  [    0/69195]
loss: 0.185565  [ 6400/69195]
loss: 0.164611  [12800/69195]
loss: 0.179559  [19200/69195]
loss: 0.109747  [25600/69195]
loss: 0.100743  [32000/69195]
loss: 0.092678  [38400/69195]
loss: 0.044756  [44800/69195]
loss: 0.130983  [51200/69195]
loss: 0.132337  [57600/69195]
loss: 0.114010  [64000/69195]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.171960 

Epoch 42
-------------------------------
loss: 0.151584  [    0/69195]
loss: 0.048009  [ 6400/69195]
loss: 0.072967  [12800/69195]
loss: 0.132855  [19200/69195]
loss: 0.154352  [25600/69195]
loss: 0.101390  [32000/69195]
loss: 0.060229  [38400/69195]
loss: 0.161507  [44800/69195]
loss: 0.163372  [51200/69195]
loss: 0.125675  [57600/69195]
loss: 0.088456  [64000/69195]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.151116 

Epoch 43
-------------------------------
loss: 0.185214  [    0/69195]
loss: 0.199546  [ 6400/69195]
loss: 0.152157  [12800/69195]
loss: 0.183272  [19200/69195]
loss: 0.134697  [25600/69195]
loss: 0.158064  [32000/69195]
loss: 0.158763  [38400/69195]
loss: 0.127178  [44800/69195]
loss: 0.104515  [51200/69195]
loss: 0.136196  [57600/69195]
loss: 0.150808  [64000/69195]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.148176 

Epoch 44
-------------------------------
loss: 0.129995  [    0/69195]
loss: 0.194914  [ 6400/69195]
loss: 0.185168  [12800/69195]
loss: 0.133925  [19200/69195]
loss: 0.044232  [25600/69195]
loss: 0.052459  [32000/69195]
loss: 0.113892  [38400/69195]
loss: 0.180745  [44800/69195]
loss: 0.127307  [51200/69195]
loss: 0.127775  [57600/69195]
loss: 0.211827  [64000/69195]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.153511 

Epoch 45
-------------------------------
loss: 0.115858  [    0/69195]
loss: 0.126517  [ 6400/69195]
loss: 0.286945  [12800/69195]
loss: 0.095872  [19200/69195]
loss: 0.204444  [25600/69195]
loss: 0.243248  [32000/69195]
loss: 0.180010  [38400/69195]
loss: 0.141537  [44800/69195]
loss: 0.116663  [51200/69195]
loss: 0.159683  [57600/69195]
loss: 0.104706  [64000/69195]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.194808 

Epoch 46
-------------------------------
loss: 0.093271  [    0/69195]
loss: 0.107283  [ 6400/69195]
loss: 0.154664  [12800/69195]
loss: 0.159665  [19200/69195]
loss: 0.138678  [25600/69195]
loss: 0.071905  [32000/69195]
loss: 0.075747  [38400/69195]
loss: 0.162265  [44800/69195]
loss: 0.114815  [44800/71124]
loss: 0.102290  [51200/71124]
loss: 0.081356  [57600/71124]
loss: 0.141831  [64000/71124]
loss: 0.141133  [70400/71124]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.126720 

Epoch 34
-------------------------------
loss: 0.067994  [    0/71124]
loss: 0.098180  [ 6400/71124]
loss: 0.113219  [12800/71124]
loss: 0.077748  [19200/71124]
loss: 0.121434  [25600/71124]
loss: 0.260806  [32000/71124]
loss: 0.090793  [38400/71124]
loss: 0.063344  [44800/71124]
loss: 0.077416  [51200/71124]
loss: 0.056134  [57600/71124]
loss: 0.182905  [64000/71124]
loss: 0.061718  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.115390 

Epoch 35
-------------------------------
loss: 0.053983  [    0/71124]
loss: 0.063581  [ 6400/71124]
loss: 0.208458  [12800/71124]
loss: 0.173909  [19200/71124]
loss: 0.172473  [25600/71124]
loss: 0.093181  [32000/71124]
loss: 0.129243  [38400/71124]
loss: 0.069000  [44800/71124]
loss: 0.073998  [51200/71124]
loss: 0.090878  [57600/71124]
loss: 0.086676  [64000/71124]
loss: 0.062683  [70400/71124]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.113257 

Epoch 36
-------------------------------
loss: 0.045089  [    0/71124]
loss: 0.019887  [ 6400/71124]
loss: 0.066284  [12800/71124]
loss: 0.097135  [19200/71124]
loss: 0.046053  [25600/71124]
loss: 0.030738  [32000/71124]
loss: 0.089400  [38400/71124]
loss: 0.047205  [44800/71124]
loss: 0.076431  [51200/71124]
loss: 0.053011  [57600/71124]
loss: 0.150706  [64000/71124]
loss: 0.101851  [70400/71124]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.123256 

Epoch 37
-------------------------------
loss: 0.114572  [    0/71124]
loss: 0.092934  [ 6400/71124]
loss: 0.193009  [12800/71124]
loss: 0.114816  [19200/71124]
loss: 0.110305  [25600/71124]
loss: 0.091254  [32000/71124]
loss: 0.139860  [38400/71124]
loss: 0.086051  [44800/71124]
loss: 0.107550  [51200/71124]
loss: 0.114413  [57600/71124]
loss: 0.165936  [64000/71124]
loss: 0.061110  [70400/71124]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.123931 

Epoch 38
-------------------------------
loss: 0.226149  [    0/71124]
loss: 0.086528  [ 6400/71124]
loss: 0.068553  [12800/71124]
loss: 0.203989  [19200/71124]
loss: 0.083688  [25600/71124]
loss: 0.051000  [32000/71124]
loss: 0.135032  [38400/71124]
loss: 0.039051  [44800/71124]
loss: 0.094397  [51200/71124]
loss: 0.082675  [57600/71124]
loss: 0.027308  [64000/71124]
loss: 0.092000  [70400/71124]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.117218 

Epoch 39
-------------------------------
loss: 0.056890  [    0/71124]
loss: 0.119880  [ 6400/71124]
loss: 0.050791  [12800/71124]
loss: 0.107892  [19200/71124]
loss: 0.161682  [25600/71124]
loss: 0.047863  [32000/71124]
loss: 0.070569  [38400/71124]
loss: 0.171564  [44800/71124]
loss: 0.057314  [51200/71124]
loss: 0.036199  [57600/71124]
loss: 0.153280  [64000/71124]
loss: 0.114458  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.118116 

Epoch 40
-------------------------------
loss: 0.065760  [    0/71124]
loss: 0.149892  [ 6400/71124]
loss: 0.071902  [12800/71124]
loss: 0.111145  [19200/71124]
loss: 0.134424  [25600/71124]
loss: 0.028137  [32000/71124]
loss: 0.096322  [38400/71124]
loss: 0.246338  [44800/71124]
loss: 0.060697  [51200/71124]
loss: 0.084167  [57600/71124]
loss: 0.101247  [64000/71124]
loss: 0.085815  [70400/71124]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.134316 

Epoch 41
-------------------------------
loss: 0.087105  [    0/71124]
loss: 0.159984  [ 6400/71124]
loss: 0.133195  [12800/71124]
loss: 0.112342  [19200/71124]
loss: 0.119796  [25600/71124]
loss: 0.061078  [32000/71124]
loss: 0.072183  [38400/71124]
loss: 0.084922  [44800/71124]
loss: 0.029502  [51200/71124]
loss: 0.150263  [57600/71124]
loss: 0.152655  [64000/71124]
loss: 0.104781  [70400/71124]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.150141 

Epoch 42
-------------------------------
loss: 0.113632  [    0/71124]
loss: 0.186770  [ 6400/71124]
loss: 0.227360  [12800/71124]
loss: 0.048892  [19200/71124]
loss: 0.167120  [25600/71124]
loss: 0.063737  [32000/71124]
loss: 0.066003  [38400/71124]
loss: 0.059347  [44800/71124]
loss: 0.147044  [51200/71124]
loss: 0.058299  [57600/71124]
loss: 0.119824  [64000/71124]
loss: 0.158735  [70400/71124]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.129127 

Epoch 43
-------------------------------
loss: 0.099006  [    0/71124]
loss: 0.118942  [ 6400/71124]
loss: 0.146732  [12800/71124]
loss: 0.086814  [19200/71124]
loss: 0.104248  [25600/71124]
loss: 0.151208  [32000/71124]
loss: 0.034480  [38400/71124]
loss: 0.078072  [44800/71124]
loss: 0.143535  [51200/71124]
loss: 0.078813  [57600/71124]
loss: 0.026508  [64000/71124]
loss: 0.159814  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.123884 

Epoch 44
-------------------------------
loss: 0.064861  [    0/71124]
loss: 0.086136  [ 6400/71124]
loss: 0.024424  [12800/71124]
loss: 0.180615  [19200/71124]
loss: 0.030294  [25600/71124]
loss: 0.075417  [32000/71124]
loss: 0.076092  [38400/71124]
loss: 0.069066  [44800/71124]
loss: 0.165707  [51200/71124]
loss: 0.053583  [57600/71124]
loss: 0.236492  [64000/71124]
loss: 0.090494  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.125500 

Epoch 45
-------------------------------
loss: 0.086873  [    0/71124]
loss: 0.058862  [ 6400/71124]
loss: 0.094216  [12800/71124]
loss: 0.057988  [19200/71124]
loss: 0.079896  [25600/71124]
loss: 0.086266  [32000/71124]
loss: 0.125661  [38400/71124]
loss: 0.117562  [44800/71124]
loss: 0.161376  [51200/71124]
loss: 0.101654  [57600/71124]
loss: 0.081862  [64000/71124]
loss: 0.061473  [70400/71124]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.119467 

Epoch 46
-------------------------------
loss: 0.085471  [    0/71124]
loss: 0.102271  [ 6400/71124]
loss: 0.075521  [12800/71124]
loss: 0.130241  [19200/71124]
loss: 0.079292  [25600/71124]
loss: 0.010710  [32000/71124]
loss: 0.130171  [38400/71124]
loss: 0.068736  [44800/71124]
loss: 0.092928  [51200/71124]
loss: 0.135283  [57600/71124]
loss: 0.072260  [64000/71124]
loss: 0.226388  [70400/71124]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.115199 

Epoch 47
-------------------------------
loss: 0.043500  [    0/71124]
loss: 0.132355  [ 6400/71124]
loss: 0.086649  [12800/71124]
loss: 0.073384  [19200/71124]
loss: 0.024094  [25600/71124]
loss: 0.049889  [32000/71124]
loss: 0.035713  [38400/71124]
loss: 0.225423  [44800/71124]
loss: 0.051566  [51200/71124]
loss: 0.030259  [57600/71124]
loss: 0.120990  [64000/71124]
loss: 0.078497  [70400/71124]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.125453 

Epoch 48
-------------------------------
loss: 0.056243  [    0/71124]
loss: 0.025743  [ 6400/71124]
loss: 0.064134  [12800/71124]
loss: 0.021161  [19200/71124]
loss: 0.095680  [25600/71124]
loss: 0.046654  [32000/71124]
loss: 0.098844  [38400/71124]
loss: 0.069341  [44800/71124]
loss: 0.122403  [51200/71124]
loss: 0.122296  [57600/71124]
loss: 0.039575  [64000/71124]
loss: 0.116567  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.113027 

Epoch 49
-------------------------------
loss: 0.096977  [    0/71124]
loss: 0.038282  [ 6400/71124]
loss: 0.103075  [12800/71124]
loss: 0.036232  [19200/71124]
loss: 0.050021  [25600/71124]
loss: 0.175417  [32000/71124]
loss: 0.135754  [38400/71124]
loss: 0.147051  [44800/71124]
loss: 0.049075  [51200/71124]
loss: 0.071316  [57600/71124]
loss: 0.152214  [64000/71124]
loss: 0.036520  [70400/71124]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.110629 

Epoch 50
-------------------------------
loss: 0.052651  [    0/71124]
loss: 0.033223  [ 6400/71124]
loss: 0.082748  [12800/71124]
loss: 0.111431  [19200/71124]
loss: 0.148124  [25600/71124]
loss: 0.097720  [32000/71124]
loss: 0.145826  [38400/71124]
loss: 0.088128  [44800/71124]
loss: 0.105245  [51200/71124]
loss: 0.142983  [57600/71124]
loss: 0.036319  [64000/71124]
loss: 0.172611  [70400/71124]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.115104 

Epoch 1
-------------------------------
loss: 0.703454  [    0/70549]
loss: 0.291025  [ 6400/70549]
loss: 0.297632  [12800/70549]
loss: 0.430303  [19200/70549]
loss: 0.243123  [25600/70549]
loss: 0.230549  [32000/70549]
loss: 0.173698  [38400/70549]
loss: 0.124975  [44800/70549]
loss: 0.159768  [64000/71801]
loss: 0.002169  [70400/71801]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.065201 

Epoch 44
-------------------------------
loss: 0.002806  [    0/71801]
loss: 0.048087  [ 6400/71801]
loss: 0.011523  [12800/71801]
loss: 0.010429  [19200/71801]
loss: 0.014867  [25600/71801]
loss: 0.037436  [32000/71801]
loss: 0.008245  [38400/71801]
loss: 0.007493  [44800/71801]
loss: 0.010545  [51200/71801]
loss: 0.004712  [57600/71801]
loss: 0.007433  [64000/71801]
loss: 0.023488  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.067417 

Epoch 45
-------------------------------
loss: 0.034607  [    0/71801]
loss: 0.001697  [ 6400/71801]
loss: 0.022350  [12800/71801]
loss: 0.010052  [19200/71801]
loss: 0.015435  [25600/71801]
loss: 0.007637  [32000/71801]
loss: 0.034187  [38400/71801]
loss: 0.006585  [44800/71801]
loss: 0.153848  [51200/71801]
loss: 0.006059  [57600/71801]
loss: 0.094893  [64000/71801]
loss: 0.017649  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.070719 

Epoch 46
-------------------------------
loss: 0.004330  [    0/71801]
loss: 0.035477  [ 6400/71801]
loss: 0.022307  [12800/71801]
loss: 0.028533  [19200/71801]
loss: 0.004582  [25600/71801]
loss: 0.005982  [32000/71801]
loss: 0.068043  [38400/71801]
loss: 0.010448  [44800/71801]
loss: 0.035319  [51200/71801]
loss: 0.009389  [57600/71801]
loss: 0.004408  [64000/71801]
loss: 0.002301  [70400/71801]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.072346 

Epoch 47
-------------------------------
loss: 0.011360  [    0/71801]
loss: 0.091690  [ 6400/71801]
loss: 0.005414  [12800/71801]
loss: 0.025734  [19200/71801]
loss: 0.013364  [25600/71801]
loss: 0.096472  [32000/71801]
loss: 0.017853  [38400/71801]
loss: 0.138641  [44800/71801]
loss: 0.044650  [51200/71801]
loss: 0.005785  [57600/71801]
loss: 0.074670  [64000/71801]
loss: 0.001446  [70400/71801]
Test Error: 
 Accuracy: 98.2%, Avg loss: 0.069463 

Epoch 48
-------------------------------
loss: 0.048892  [    0/71801]
loss: 0.178370  [ 6400/71801]
loss: 0.010651  [12800/71801]
loss: 0.010952  [19200/71801]
loss: 0.008358  [25600/71801]
loss: 0.055745  [32000/71801]
loss: 0.024864  [38400/71801]
loss: 0.028649  [44800/71801]
loss: 0.046518  [51200/71801]
loss: 0.097176  [57600/71801]
loss: 0.064964  [64000/71801]
loss: 0.001345  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.067946 

Epoch 49
-------------------------------
loss: 0.002045  [    0/71801]
loss: 0.002120  [ 6400/71801]
loss: 0.027453  [12800/71801]
loss: 0.065515  [19200/71801]
loss: 0.046187  [25600/71801]
loss: 0.051963  [32000/71801]
loss: 0.023951  [38400/71801]
loss: 0.012574  [44800/71801]
loss: 0.015500  [51200/71801]
loss: 0.001510  [57600/71801]
loss: 0.001196  [64000/71801]
loss: 0.003889  [70400/71801]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.069861 

Epoch 50
-------------------------------
loss: 0.009346  [    0/71801]
loss: 0.007998  [ 6400/71801]
loss: 0.042903  [12800/71801]
loss: 0.027142  [19200/71801]
loss: 0.008264  [25600/71801]
loss: 0.053132  [32000/71801]
loss: 0.016369  [38400/71801]
loss: 0.003846  [44800/71801]
loss: 0.059881  [51200/71801]
loss: 0.006202  [57600/71801]
loss: 0.018259  [64000/71801]
loss: 0.015864  [70400/71801]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.072542 

Epoch 1
-------------------------------
loss: 0.693286  [    0/71157]
loss: 0.125980  [ 6400/71157]
loss: 0.086782  [12800/71157]
loss: 0.122110  [19200/71157]
loss: 0.140475  [25600/71157]
loss: 0.173716  [32000/71157]
loss: 0.157296  [38400/71157]
loss: 0.143593  [44800/71157]
loss: 0.115476  [51200/71157]
loss: 0.097391  [57600/71157]
loss: 0.153670  [64000/71157]
loss: 0.118353  [70400/71157]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.115954 

Epoch 2
-------------------------------
loss: 0.070306  [    0/71157]
loss: 0.088601  [ 6400/71157]
loss: 0.102334  [12800/71157]
loss: 0.224148  [19200/71157]
loss: 0.081965  [25600/71157]
loss: 0.079881  [32000/71157]
loss: 0.115923  [38400/71157]
loss: 0.169429  [44800/71157]
loss: 0.101800  [51200/71157]
loss: 0.144936  [57600/71157]
loss: 0.103466  [64000/71157]
loss: 0.061904  [70400/71157]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.102450 

Epoch 3
-------------------------------
loss: 0.108717  [    0/71157]
loss: 0.079540  [ 6400/71157]
loss: 0.200164  [12800/71157]
loss: 0.176474  [19200/71157]
loss: 0.052995  [25600/71157]
loss: 0.113164  [32000/71157]
loss: 0.039292  [38400/71157]
loss: 0.182007  [44800/71157]
loss: 0.119169  [51200/71157]
loss: 0.056301  [57600/71157]
loss: 0.082397  [64000/71157]
loss: 0.078616  [70400/71157]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.099123 

Epoch 4
-------------------------------
loss: 0.098591  [    0/71157]
loss: 0.125635  [ 6400/71157]
loss: 0.114848  [12800/71157]
loss: 0.232088  [19200/71157]
loss: 0.032588  [25600/71157]
loss: 0.232526  [32000/71157]
loss: 0.136963  [38400/71157]
loss: 0.277807  [44800/71157]
loss: 0.109013  [51200/71157]
loss: 0.095929  [57600/71157]
loss: 0.072470  [64000/71157]
loss: 0.031467  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097161 

Epoch 5
-------------------------------
loss: 0.014430  [    0/71157]
loss: 0.102819  [ 6400/71157]
loss: 0.154727  [12800/71157]
loss: 0.056992  [19200/71157]
loss: 0.091352  [25600/71157]
loss: 0.061194  [32000/71157]
loss: 0.088354  [38400/71157]
loss: 0.093398  [44800/71157]
loss: 0.080161  [51200/71157]
loss: 0.045961  [57600/71157]
loss: 0.023696  [64000/71157]
loss: 0.095786  [70400/71157]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.097543 

Epoch 6
-------------------------------
loss: 0.043825  [    0/71157]
loss: 0.083595  [ 6400/71157]
loss: 0.074962  [12800/71157]
loss: 0.021115  [19200/71157]
loss: 0.195335  [25600/71157]
loss: 0.070127  [32000/71157]
loss: 0.109037  [38400/71157]
loss: 0.118192  [44800/71157]
loss: 0.113598  [51200/71157]
loss: 0.079997  [57600/71157]
loss: 0.108564  [64000/71157]
loss: 0.031001  [70400/71157]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099102 

Epoch 7
-------------------------------
loss: 0.128829  [    0/71157]
loss: 0.049905  [ 6400/71157]
loss: 0.082745  [12800/71157]
loss: 0.037158  [19200/71157]
loss: 0.158631  [25600/71157]
loss: 0.136091  [32000/71157]
loss: 0.037443  [38400/71157]
loss: 0.113169  [44800/71157]
loss: 0.113951  [51200/71157]
loss: 0.079377  [57600/71157]
loss: 0.099577  [64000/71157]
loss: 0.234330  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.091749 

Epoch 8
-------------------------------
loss: 0.055850  [    0/71157]
loss: 0.049416  [ 6400/71157]
loss: 0.124965  [12800/71157]
loss: 0.021629  [19200/71157]
loss: 0.068210  [25600/71157]
loss: 0.083060  [32000/71157]
loss: 0.099463  [38400/71157]
loss: 0.048570  [44800/71157]
loss: 0.085315  [51200/71157]
loss: 0.024029  [57600/71157]
loss: 0.088934  [64000/71157]
loss: 0.101252  [70400/71157]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.096446 

Epoch 9
-------------------------------
loss: 0.048695  [    0/71157]
loss: 0.127758  [ 6400/71157]
loss: 0.057142  [12800/71157]
loss: 0.095254  [19200/71157]
loss: 0.069094  [25600/71157]
loss: 0.105155  [32000/71157]
loss: 0.074322  [38400/71157]
loss: 0.016092  [44800/71157]
loss: 0.059241  [51200/71157]
loss: 0.092979  [57600/71157]
loss: 0.045835  [64000/71157]
loss: 0.104260  [70400/71157]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.093357 

Epoch 10
-------------------------------
loss: 0.035968  [    0/71157]
loss: 0.087558  [ 6400/71157]
loss: 0.085743  [12800/71157]
loss: 0.074991  [19200/71157]
loss: 0.113477  [25600/71157]
loss: 0.135269  [32000/71157]
loss: 0.189702  [38400/71157]
loss: 0.103101  [44800/71157]
loss: 0.026065  [51200/71157]
loss: 0.100436  [57600/71157]
loss: 0.051219  [64000/71157]
loss: 0.116713  [70400/71157]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.104249 

Epoch 11
-------------------------------
loss: 0.162807  [    0/71157]
loss: 0.094890  [ 6400/71157]
loss: 0.040336  [12800/71157]
loss: 0.100173  [19200/71157]
loss: 0.062138  [25600/71157]
loss: 0.067822  [32000/71157]
loss: 0.068382  [38400/71157]
loss: 0.075954  [44800/71157]
loss: 0.054260  [51200/71157]
loss: 0.075059  [57600/71157]
loss: 0.067619  [64000/71157]
loss: 0.105709  [32000/69840]
loss: 0.153381  [38400/69840]
loss: 0.169927  [44800/69840]
loss: 0.130648  [51200/69840]
loss: 0.183688  [57600/69840]
loss: 0.225737  [64000/69840]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.175745 

Epoch 28
-------------------------------
loss: 0.107849  [    0/69840]
loss: 0.167645  [ 6400/69840]
loss: 0.122325  [12800/69840]
loss: 0.159539  [19200/69840]
loss: 0.127643  [25600/69840]
loss: 0.092665  [32000/69840]
loss: 0.124949  [38400/69840]
loss: 0.400309  [44800/69840]
loss: 0.093093  [51200/69840]
loss: 0.077201  [57600/69840]
loss: 0.047772  [64000/69840]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.180095 

Epoch 29
-------------------------------
loss: 0.175850  [    0/69840]
loss: 0.171413  [ 6400/69840]
loss: 0.180811  [12800/69840]
loss: 0.083470  [19200/69840]
loss: 0.245847  [25600/69840]
loss: 0.176085  [32000/69840]
loss: 0.125440  [38400/69840]
loss: 0.124880  [44800/69840]
loss: 0.114650  [51200/69840]
loss: 0.191405  [57600/69840]
loss: 0.136359  [64000/69840]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.166154 

Epoch 30
-------------------------------
loss: 0.078424  [    0/69840]
loss: 0.151885  [ 6400/69840]
loss: 0.073627  [12800/69840]
loss: 0.180062  [19200/69840]
loss: 0.091784  [25600/69840]
loss: 0.114479  [32000/69840]
loss: 0.187904  [38400/69840]
loss: 0.143738  [44800/69840]
loss: 0.117313  [51200/69840]
loss: 0.138087  [57600/69840]
loss: 1.753477  [64000/69840]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.156303 

Epoch 31
-------------------------------
loss: 0.125689  [    0/69840]
loss: 0.108338  [ 6400/69840]
loss: 0.105618  [12800/69840]
loss: 0.057198  [19200/69840]
loss: 0.161322  [25600/69840]
loss: 0.119476  [32000/69840]
loss: 0.114394  [38400/69840]
loss: 0.189474  [44800/69840]
loss: 0.133623  [51200/69840]
loss: 0.140368  [57600/69840]
loss: 0.113046  [64000/69840]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.155418 

Epoch 32
-------------------------------
loss: 0.106979  [    0/69840]
loss: 0.162287  [ 6400/69840]
loss: 0.153731  [12800/69840]
loss: 0.089059  [19200/69840]
loss: 0.232993  [25600/69840]
loss: 0.213834  [32000/69840]
loss: 0.162915  [38400/69840]
loss: 0.131579  [44800/69840]
loss: 0.106509  [51200/69840]
loss: 0.173627  [57600/69840]
loss: 0.282289  [64000/69840]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.167347 

Epoch 33
-------------------------------
loss: 0.153186  [    0/69840]
loss: 0.081987  [ 6400/69840]
loss: 0.155679  [12800/69840]
loss: 0.133545  [19200/69840]
loss: 0.162816  [25600/69840]
loss: 1.696928  [32000/69840]
loss: 0.125937  [38400/69840]
loss: 0.271808  [44800/69840]
loss: 1.814870  [51200/69840]
loss: 0.047541  [57600/69840]
loss: 0.257123  [64000/69840]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.157440 

Epoch 34
-------------------------------
loss: 0.192246  [    0/69840]
loss: 0.173574  [ 6400/69840]
loss: 0.172183  [12800/69840]
loss: 0.080028  [19200/69840]
loss: 0.135337  [25600/69840]
loss: 0.157933  [32000/69840]
loss: 0.176673  [38400/69840]
loss: 0.240273  [44800/69840]
loss: 0.081695  [51200/69840]
loss: 0.214052  [57600/69840]
loss: 0.176036  [64000/69840]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.165198 

Epoch 35
-------------------------------
loss: 0.113159  [    0/69840]
loss: 0.140417  [ 6400/69840]
loss: 0.168874  [12800/69840]
loss: 0.128347  [19200/69840]
loss: 0.217082  [25600/69840]
loss: 0.138490  [32000/69840]
loss: 0.145351  [38400/69840]
loss: 0.197841  [44800/69840]
loss: 0.096006  [51200/69840]
loss: 0.100892  [57600/69840]
loss: 0.263741  [64000/69840]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.164488 

Epoch 36
-------------------------------
loss: 0.061669  [    0/69840]
loss: 0.119203  [ 6400/69840]
loss: 0.100611  [12800/69840]
loss: 0.189664  [19200/69840]
loss: 0.121140  [25600/69840]
loss: 0.113192  [32000/69840]
loss: 0.179741  [38400/69840]
loss: 0.264562  [44800/69840]
loss: 0.165059  [51200/69840]
loss: 0.075902  [57600/69840]
loss: 0.300721  [64000/69840]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.162518 

Epoch 37
-------------------------------
loss: 0.093118  [    0/69840]
loss: 0.221721  [ 6400/69840]
loss: 0.118272  [12800/69840]
loss: 0.190740  [19200/69840]
loss: 0.157084  [25600/69840]
loss: 0.166939  [32000/69840]
loss: 0.094699  [38400/69840]
loss: 0.168487  [44800/69840]
loss: 0.194269  [51200/69840]
loss: 0.183778  [57600/69840]
loss: 0.083342  [64000/69840]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.166080 

Epoch 38
-------------------------------
loss: 0.140309  [    0/69840]
loss: 0.046714  [ 6400/69840]
loss: 0.050691  [12800/69840]
loss: 0.231812  [19200/69840]
loss: 0.101603  [25600/69840]
loss: 0.079062  [32000/69840]
loss: 0.292491  [38400/69840]
loss: 0.143326  [44800/69840]
loss: 0.201241  [51200/69840]
loss: 0.098496  [57600/69840]
loss: 0.136796  [64000/69840]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.157182 

Epoch 39
-------------------------------
loss: 0.149778  [    0/69840]
loss: 0.080441  [ 6400/69840]
loss: 0.159282  [12800/69840]
loss: 0.108217  [19200/69840]
loss: 0.124391  [25600/69840]
loss: 0.063926  [32000/69840]
loss: 0.078828  [38400/69840]
loss: 0.136739  [44800/69840]
loss: 0.143993  [51200/69840]
loss: 0.208159  [57600/69840]
loss: 0.191970  [64000/69840]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.157261 

Epoch 40
-------------------------------
loss: 0.119338  [    0/69840]
loss: 0.098107  [ 6400/69840]
loss: 0.145833  [12800/69840]
loss: 0.252758  [19200/69840]
loss: 0.104959  [25600/69840]
loss: 0.239952  [32000/69840]
loss: 0.108537  [38400/69840]
loss: 0.064207  [44800/69840]
loss: 0.093663  [51200/69840]
loss: 0.141259  [57600/69840]
loss: 0.140664  [64000/69840]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.160289 

Epoch 41
-------------------------------
loss: 0.137368  [    0/69840]
loss: 0.155079  [ 6400/69840]
loss: 0.060007  [12800/69840]
loss: 0.132218  [19200/69840]
loss: 0.064304  [25600/69840]
loss: 0.210282  [32000/69840]
loss: 0.145031  [38400/69840]
loss: 0.252481  [44800/69840]
loss: 0.146223  [51200/69840]
loss: 0.167225  [57600/69840]
loss: 0.155263  [64000/69840]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.161793 

Epoch 42
-------------------------------
loss: 0.154930  [    0/69840]
loss: 0.151856  [ 6400/69840]
loss: 0.138706  [12800/69840]
loss: 0.121148  [19200/69840]
loss: 0.128249  [25600/69840]
loss: 0.099886  [32000/69840]
loss: 0.061424  [38400/69840]
loss: 0.115609  [44800/69840]
loss: 0.103256  [51200/69840]
loss: 1.760920  [57600/69840]
loss: 0.142589  [64000/69840]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.172904 

Epoch 43
-------------------------------
loss: 0.187799  [    0/69840]
loss: 0.126523  [ 6400/69840]
loss: 0.115318  [12800/69840]
loss: 0.189483  [19200/69840]
loss: 0.170268  [25600/69840]
loss: 0.186615  [32000/69840]
loss: 0.091239  [38400/69840]
loss: 0.236047  [44800/69840]
loss: 0.078527  [51200/69840]
loss: 0.082955  [57600/69840]
loss: 0.145125  [64000/69840]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.163608 

Epoch 44
-------------------------------
loss: 0.142055  [    0/69840]
loss: 0.154661  [ 6400/69840]
loss: 0.167266  [12800/69840]
loss: 0.126611  [19200/69840]
loss: 0.040577  [25600/69840]
loss: 0.169045  [32000/69840]
loss: 0.137150  [38400/69840]
loss: 0.131269  [44800/69840]
loss: 0.081651  [51200/69840]
loss: 0.111241  [57600/69840]
loss: 0.107784  [64000/69840]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.156578 

Epoch 45
-------------------------------
loss: 0.096269  [    0/69840]
loss: 0.231957  [ 6400/69840]
loss: 0.214389  [12800/69840]
loss: 0.182683  [19200/69840]
loss: 0.138826  [25600/69840]
loss: 0.078871  [32000/69840]
loss: 0.157489  [38400/69840]
loss: 0.112174  [44800/69840]
loss: 0.149630  [51200/69840]
loss: 0.212876  [57600/69840]
loss: 0.220437  [64000/69840]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.155575 

Epoch 46
-------------------------------
loss: 1.741422  [    0/69840]
loss: 0.147286  [ 6400/69840]
loss: 0.159639  [12800/69840]
loss: 0.060049  [19200/69840]
loss: 0.195454  [25600/69840]
loss: 0.222558  [32000/69840]
loss: 0.120726  [38400/69840]
loss: 0.055419  [44800/69840]
loss: 0.090900  [51200/69840]
loss: 0.201235  [57600/69840]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.111229 

Epoch 37
-------------------------------
loss: 0.082618  [    0/70717]
loss: 0.251406  [ 6400/70717]
loss: 0.142051  [12800/70717]
loss: 0.107134  [19200/70717]
loss: 0.153261  [25600/70717]
loss: 0.071443  [32000/70717]
loss: 0.094344  [38400/70717]
loss: 0.069759  [44800/70717]
loss: 0.174575  [51200/70717]
loss: 0.082295  [57600/70717]
loss: 0.073508  [64000/70717]
loss: 0.081076  [70400/70717]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.108894 

Epoch 38
-------------------------------
loss: 0.106857  [    0/70717]
loss: 0.102855  [ 6400/70717]
loss: 0.062256  [12800/70717]
loss: 0.040307  [19200/70717]
loss: 0.072087  [25600/70717]
loss: 0.051290  [32000/70717]
loss: 1.303446  [38400/70717]
loss: 0.044186  [44800/70717]
loss: 0.092685  [51200/70717]
loss: 0.109885  [57600/70717]
loss: 0.116374  [64000/70717]
loss: 0.095947  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101246 

Epoch 39
-------------------------------
loss: 0.175699  [    0/70717]
loss: 0.028718  [ 6400/70717]
loss: 0.049755  [12800/70717]
loss: 0.051181  [19200/70717]
loss: 0.116986  [25600/70717]
loss: 0.054321  [32000/70717]
loss: 0.079421  [38400/70717]
loss: 0.070547  [44800/70717]
loss: 0.119172  [51200/70717]
loss: 0.088212  [57600/70717]
loss: 0.128223  [64000/70717]
loss: 0.102698  [70400/70717]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.102224 

Epoch 40
-------------------------------
loss: 0.158810  [    0/70717]
loss: 0.138410  [ 6400/70717]
loss: 0.051766  [12800/70717]
loss: 0.080907  [19200/70717]
loss: 0.074088  [25600/70717]
loss: 0.039659  [32000/70717]
loss: 0.141149  [38400/70717]
loss: 0.047498  [44800/70717]
loss: 0.246426  [51200/70717]
loss: 0.154825  [57600/70717]
loss: 0.162185  [64000/70717]
loss: 0.083609  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.108896 

Epoch 41
-------------------------------
loss: 0.059414  [    0/70717]
loss: 0.033838  [ 6400/70717]
loss: 0.060549  [12800/70717]
loss: 0.137158  [19200/70717]
loss: 0.037745  [25600/70717]
loss: 0.067034  [32000/70717]
loss: 0.139476  [38400/70717]
loss: 0.046965  [44800/70717]
loss: 0.090590  [51200/70717]
loss: 0.081308  [57600/70717]
loss: 0.168742  [64000/70717]
loss: 0.070076  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.106243 

Epoch 42
-------------------------------
loss: 0.050028  [    0/70717]
loss: 0.081430  [ 6400/70717]
loss: 0.054865  [12800/70717]
loss: 0.180894  [19200/70717]
loss: 0.053423  [25600/70717]
loss: 0.130999  [32000/70717]
loss: 0.056030  [38400/70717]
loss: 0.050582  [44800/70717]
loss: 0.233654  [51200/70717]
loss: 0.109518  [57600/70717]
loss: 0.209884  [64000/70717]
loss: 0.037901  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101771 

Epoch 43
-------------------------------
loss: 0.174087  [    0/70717]
loss: 0.033295  [ 6400/70717]
loss: 0.158336  [12800/70717]
loss: 0.070895  [19200/70717]
loss: 0.176883  [25600/70717]
loss: 0.046290  [32000/70717]
loss: 0.145446  [38400/70717]
loss: 0.109950  [44800/70717]
loss: 0.050793  [51200/70717]
loss: 0.077769  [57600/70717]
loss: 0.160555  [64000/70717]
loss: 0.031558  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.103347 

Epoch 44
-------------------------------
loss: 0.096359  [    0/70717]
loss: 0.079190  [ 6400/70717]
loss: 0.064861  [12800/70717]
loss: 0.042494  [19200/70717]
loss: 0.115238  [25600/70717]
loss: 0.180948  [32000/70717]
loss: 0.158543  [38400/70717]
loss: 0.107348  [44800/70717]
loss: 0.175053  [51200/70717]
loss: 0.021612  [57600/70717]
loss: 0.029320  [64000/70717]
loss: 0.186555  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.107239 

Epoch 45
-------------------------------
loss: 0.163671  [    0/70717]
loss: 0.070366  [ 6400/70717]
loss: 0.037986  [12800/70717]
loss: 0.069230  [19200/70717]
loss: 0.069293  [25600/70717]
loss: 0.049905  [32000/70717]
loss: 0.168638  [38400/70717]
loss: 0.057012  [44800/70717]
loss: 0.128807  [51200/70717]
loss: 0.065183  [57600/70717]
loss: 0.060939  [64000/70717]
loss: 0.031158  [70400/70717]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.100788 

Epoch 46
-------------------------------
loss: 0.064963  [    0/70717]
loss: 0.142829  [ 6400/70717]
loss: 0.074804  [12800/70717]
loss: 0.151371  [19200/70717]
loss: 0.099530  [25600/70717]
loss: 0.072540  [32000/70717]
loss: 0.062009  [38400/70717]
loss: 0.137373  [44800/70717]
loss: 0.077918  [51200/70717]
loss: 0.073108  [57600/70717]
loss: 0.122695  [64000/70717]
loss: 0.083215  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.104078 

Epoch 47
-------------------------------
loss: 0.026620  [    0/70717]
loss: 0.114043  [ 6400/70717]
loss: 0.022106  [12800/70717]
loss: 0.066164  [19200/70717]
loss: 0.021881  [25600/70717]
loss: 0.086760  [32000/70717]
loss: 0.143308  [38400/70717]
loss: 0.156103  [44800/70717]
loss: 0.082908  [51200/70717]
loss: 0.093864  [57600/70717]
loss: 0.091566  [64000/70717]
loss: 0.124049  [70400/70717]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095203 

Epoch 48
-------------------------------
loss: 0.136762  [    0/70717]
loss: 0.165850  [ 6400/70717]
loss: 0.019296  [12800/70717]
loss: 0.056998  [19200/70717]
loss: 0.111736  [25600/70717]
loss: 0.026994  [32000/70717]
loss: 0.245061  [38400/70717]
loss: 0.116601  [44800/70717]
loss: 0.066022  [51200/70717]
loss: 0.108391  [57600/70717]
loss: 0.282483  [64000/70717]
loss: 0.038478  [70400/70717]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097770 

Epoch 49
-------------------------------
loss: 0.133155  [    0/70717]
loss: 0.067574  [ 6400/70717]
loss: 0.152765  [12800/70717]
loss: 0.040780  [19200/70717]
loss: 0.177973  [25600/70717]
loss: 0.061110  [32000/70717]
loss: 0.131828  [38400/70717]
loss: 0.086930  [44800/70717]
loss: 0.112282  [51200/70717]
loss: 0.190485  [57600/70717]
loss: 0.101282  [64000/70717]
loss: 0.052737  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.097704 

Epoch 50
-------------------------------
loss: 0.110428  [    0/70717]
loss: 0.077262  [ 6400/70717]
loss: 0.106671  [12800/70717]
loss: 0.040284  [19200/70717]
loss: 0.032773  [25600/70717]
loss: 0.090655  [32000/70717]
loss: 0.213018  [38400/70717]
loss: 0.057912  [44800/70717]
loss: 0.098002  [51200/70717]
loss: 0.091048  [57600/70717]
loss: 0.122372  [64000/70717]
loss: 0.184165  [70400/70717]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.104400 

Epoch 1
-------------------------------
loss: 0.674289  [    0/69667]
loss: 0.174814  [ 6400/69667]
loss: 0.170056  [12800/69667]
loss: 0.162864  [19200/69667]
loss: 0.187222  [25600/69667]
loss: 0.159953  [32000/69667]
loss: 0.137974  [38400/69667]
loss: 0.204060  [44800/69667]
loss: 0.110820  [51200/69667]
loss: 0.134923  [57600/69667]
loss: 0.198364  [64000/69667]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.148801 

Epoch 2
-------------------------------
loss: 0.175710  [    0/69667]
loss: 0.107794  [ 6400/69667]
loss: 0.270662  [12800/69667]
loss: 0.127849  [19200/69667]
loss: 0.101500  [25600/69667]
loss: 0.149740  [32000/69667]
loss: 0.222928  [38400/69667]
loss: 0.233025  [44800/69667]
loss: 0.188020  [51200/69667]
loss: 0.189749  [57600/69667]
loss: 0.184905  [64000/69667]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.134074 

Epoch 3
-------------------------------
loss: 0.183743  [    0/69667]
loss: 0.157153  [ 6400/69667]
loss: 0.140686  [12800/69667]
loss: 0.077296  [19200/69667]
loss: 0.104124  [25600/69667]
loss: 0.243798  [32000/69667]
loss: 0.124353  [38400/69667]
loss: 0.207268  [44800/69667]
loss: 0.125845  [51200/69667]
loss: 0.196708  [57600/69667]
loss: 0.120714  [64000/69667]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.136313 

Epoch 4
-------------------------------
loss: 0.080425  [    0/69667]
loss: 0.093188  [ 6400/69667]
loss: 0.086230  [12800/69667]
loss: 0.112409  [19200/69667]
loss: 0.030906  [25600/69667]
loss: 0.125270  [32000/69667]
loss: 0.161346  [38400/69667]
loss: 0.164782  [44800/69667]
loss: 0.171275  [51200/69667]
loss: 0.191737  [57600/69667]
loss: 0.141746  [64000/69667]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.145048 

Epoch 5
-------------------------------
loss: 0.169775  [    0/69667]
loss: 0.121431  [ 6400/69667]
2022/09/20 20:45:12 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.108050  [12800/71337]
loss: 0.093805  [19200/71337]
loss: 0.098835  [25600/71337]
loss: 0.107077  [32000/71337]
loss: 0.016738  [38400/71337]
loss: 0.060702  [44800/71337]
loss: 0.099898  [51200/71337]
loss: 0.061130  [57600/71337]
loss: 0.076932  [64000/71337]
loss: 0.064445  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.108871 

Epoch 41
-------------------------------
loss: 0.077878  [    0/71337]
loss: 0.137288  [ 6400/71337]
loss: 0.064041  [12800/71337]
loss: 0.138159  [19200/71337]
loss: 0.046571  [25600/71337]
loss: 0.146815  [32000/71337]
loss: 0.087042  [38400/71337]
loss: 0.054233  [44800/71337]
loss: 0.032323  [51200/71337]
loss: 0.069536  [57600/71337]
loss: 0.036698  [64000/71337]
loss: 0.078654  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.115311 

Epoch 42
-------------------------------
loss: 0.116292  [    0/71337]
loss: 0.055642  [ 6400/71337]
loss: 0.057546  [12800/71337]
loss: 0.057115  [19200/71337]
loss: 0.110996  [25600/71337]
loss: 0.191056  [32000/71337]
loss: 0.130005  [38400/71337]
loss: 0.147732  [44800/71337]
loss: 0.045389  [51200/71337]
loss: 0.120136  [57600/71337]
loss: 0.063255  [64000/71337]
loss: 0.145203  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.106720 

Epoch 43
-------------------------------
loss: 0.058987  [    0/71337]
loss: 0.092072  [ 6400/71337]
loss: 0.061057  [12800/71337]
loss: 0.183175  [19200/71337]
loss: 0.102077  [25600/71337]
loss: 0.057170  [32000/71337]
loss: 0.061299  [38400/71337]
loss: 0.145888  [44800/71337]
loss: 0.067335  [51200/71337]
loss: 0.066106  [57600/71337]
loss: 0.078594  [64000/71337]
loss: 0.089646  [70400/71337]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.113913 

Epoch 44
-------------------------------
loss: 0.181138  [    0/71337]
loss: 0.030928  [ 6400/71337]
loss: 0.079778  [12800/71337]
loss: 0.132762  [19200/71337]
loss: 0.034866  [25600/71337]
loss: 0.064501  [32000/71337]
loss: 0.045934  [38400/71337]
loss: 0.123490  [44800/71337]
loss: 0.063805  [51200/71337]
loss: 0.115897  [57600/71337]
loss: 0.033874  [64000/71337]
loss: 0.119245  [70400/71337]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.116637 

Epoch 45
-------------------------------
loss: 0.054608  [    0/71337]
loss: 0.073138  [ 6400/71337]
loss: 0.106977  [12800/71337]
loss: 0.008890  [19200/71337]
loss: 0.040449  [25600/71337]
loss: 0.159903  [32000/71337]
loss: 0.247096  [38400/71337]
loss: 0.061688  [44800/71337]
loss: 0.166777  [51200/71337]
loss: 0.085407  [57600/71337]
loss: 0.131673  [64000/71337]
loss: 0.050075  [70400/71337]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.128101 

Epoch 46
-------------------------------
loss: 0.073001  [    0/71337]
loss: 0.020002  [ 6400/71337]
loss: 0.068224  [12800/71337]
loss: 0.155979  [19200/71337]
loss: 0.135883  [25600/71337]
loss: 0.069872  [32000/71337]
loss: 0.084100  [38400/71337]
loss: 0.085900  [44800/71337]
loss: 0.060985  [51200/71337]
loss: 0.063533  [57600/71337]
loss: 0.077820  [64000/71337]
loss: 0.013449  [70400/71337]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.107207 

Epoch 47
-------------------------------
loss: 0.038710  [    0/71337]
loss: 0.066260  [ 6400/71337]
loss: 0.038313  [12800/71337]
loss: 0.105011  [19200/71337]
loss: 0.050407  [25600/71337]
loss: 0.061495  [32000/71337]
loss: 0.123691  [38400/71337]
loss: 0.058513  [44800/71337]
loss: 0.093197  [51200/71337]
loss: 0.110055  [57600/71337]
loss: 0.029779  [64000/71337]
loss: 0.150611  [70400/71337]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.124788 

Epoch 48
-------------------------------
loss: 0.104202  [    0/71337]
loss: 0.070798  [ 6400/71337]
loss: 0.063773  [12800/71337]
loss: 0.048421  [19200/71337]
loss: 0.155168  [25600/71337]
loss: 0.092839  [32000/71337]
loss: 0.082098  [38400/71337]
loss: 0.121120  [44800/71337]
loss: 0.022355  [51200/71337]
loss: 0.178933  [57600/71337]
loss: 0.076733  [64000/71337]
loss: 0.064405  [70400/71337]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.127485 

Epoch 49
-------------------------------
loss: 0.032148  [    0/71337]
loss: 0.025962  [ 6400/71337]
loss: 0.146032  [12800/71337]
loss: 0.193933  [19200/71337]
loss: 0.060525  [25600/71337]
loss: 0.045748  [32000/71337]
loss: 0.029511  [38400/71337]
loss: 0.030095  [44800/71337]
loss: 0.055402  [51200/71337]
loss: 0.086550  [57600/71337]
loss: 0.085320  [64000/71337]
loss: 0.028670  [70400/71337]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.121957 

Epoch 50
-------------------------------
loss: 0.071703  [    0/71337]
loss: 0.035618  [ 6400/71337]
loss: 0.042802  [12800/71337]
loss: 0.143590  [19200/71337]
loss: 0.015734  [25600/71337]
loss: 0.018958  [32000/71337]
loss: 0.078271  [38400/71337]
loss: 0.041168  [44800/71337]
loss: 0.069660  [51200/71337]
loss: 0.084137  [57600/71337]
loss: 0.215161  [64000/71337]
loss: 0.145172  [70400/71337]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.124688 

Epoch 1
-------------------------------
loss: 0.638372  [    0/71047]
loss: 0.164200  [ 6400/71047]
loss: 0.235117  [12800/71047]
loss: 0.051640  [19200/71047]
loss: 0.229675  [25600/71047]
loss: 0.067431  [32000/71047]
loss: 0.105117  [38400/71047]
loss: 0.041721  [44800/71047]
loss: 0.081208  [51200/71047]
loss: 0.081341  [57600/71047]
loss: 0.038791  [64000/71047]
loss: 0.102123  [70400/71047]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.098942 

Epoch 2
-------------------------------
loss: 0.086412  [    0/71047]
loss: 0.074774  [ 6400/71047]
loss: 0.047164  [12800/71047]
loss: 0.330560  [19200/71047]
loss: 0.019139  [25600/71047]
loss: 0.135159  [32000/71047]
loss: 0.048130  [38400/71047]
loss: 0.073848  [44800/71047]
loss: 0.150140  [51200/71047]
loss: 0.122489  [57600/71047]
loss: 0.052265  [64000/71047]
loss: 0.059372  [70400/71047]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.103864 

Epoch 3
-------------------------------
loss: 0.062193  [    0/71047]
loss: 0.099103  [ 6400/71047]
loss: 0.136136  [12800/71047]
loss: 0.137681  [19200/71047]
loss: 0.031458  [25600/71047]
loss: 0.084393  [32000/71047]
loss: 0.109486  [38400/71047]
loss: 0.128397  [44800/71047]
loss: 0.038728  [51200/71047]
loss: 0.064904  [57600/71047]
loss: 0.107537  [64000/71047]
loss: 0.163162  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.087826 

Epoch 4
-------------------------------
loss: 0.134809  [    0/71047]
loss: 0.116304  [ 6400/71047]
loss: 0.114887  [12800/71047]
loss: 0.110910  [19200/71047]
loss: 0.119505  [25600/71047]
loss: 0.055098  [32000/71047]
loss: 0.237471  [38400/71047]
loss: 0.042537  [44800/71047]
loss: 0.055849  [51200/71047]
loss: 0.065703  [57600/71047]
loss: 0.033278  [64000/71047]
loss: 0.080841  [70400/71047]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.087575 

Epoch 5
-------------------------------
loss: 0.134479  [    0/71047]
loss: 0.114263  [ 6400/71047]
loss: 0.083723  [12800/71047]
loss: 0.071649  [19200/71047]
loss: 0.104395  [25600/71047]
loss: 0.079369  [32000/71047]
loss: 0.010625  [38400/71047]
loss: 0.156215  [44800/71047]
loss: 0.064433  [51200/71047]
loss: 0.019694  [57600/71047]
loss: 0.030329  [64000/71047]
loss: 0.083320  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.080905 

Epoch 6
-------------------------------
loss: 0.089408  [    0/71047]
loss: 0.059587  [ 6400/71047]
loss: 0.030149  [12800/71047]
loss: 0.035001  [19200/71047]
loss: 0.060639  [25600/71047]
loss: 0.015196  [32000/71047]
loss: 0.104628  [38400/71047]
loss: 0.096029  [44800/71047]
loss: 0.087825  [51200/71047]
loss: 0.036044  [57600/71047]
loss: 0.097011  [64000/71047]
loss: 0.051622  [70400/71047]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.084626 

Epoch 7
-------------------------------
loss: 0.053040  [    0/71047]
loss: 0.040217  [ 6400/71047]
loss: 0.045162  [12800/71047]
loss: 0.081367  [19200/71047]
loss: 0.032043  [25600/71047]
loss: 0.095285  [32000/71047]
loss: 0.093019  [38400/71047]
loss: 0.146200  [44800/71047]
loss: 0.060222  [51200/71047]
loss: 0.140832  [57600/71047]
loss: 0.027063  [64000/71047]
loss: 0.074461  [70400/71047]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.087202 

Epoch 8
-------------------------------
loss: 0.062590  [    0/71047]
loss: 0.118002  [ 6400/71047]
loss: 0.023528  [12800/71047]
loss: 0.110645  [51200/69642]
loss: 0.125565  [57600/69642]
loss: 0.113650  [64000/69642]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.178898 

Epoch 24
-------------------------------
loss: 0.191733  [    0/69642]
loss: 0.114068  [ 6400/69642]
loss: 0.145069  [12800/69642]
loss: 0.180506  [19200/69642]
loss: 0.111573  [25600/69642]
loss: 0.127087  [32000/69642]
loss: 0.145761  [38400/69642]
loss: 0.070005  [44800/69642]
loss: 0.173822  [51200/69642]
loss: 0.142415  [57600/69642]
loss: 0.134158  [64000/69642]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.157245 

Epoch 25
-------------------------------
loss: 0.110961  [    0/69642]
loss: 0.126166  [ 6400/69642]
loss: 0.152057  [12800/69642]
loss: 0.177348  [19200/69642]
loss: 0.153145  [25600/69642]
loss: 0.120017  [32000/69642]
loss: 0.174483  [38400/69642]
loss: 0.189721  [44800/69642]
loss: 0.111226  [51200/69642]
loss: 0.093234  [57600/69642]
loss: 0.251123  [64000/69642]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.159931 

Epoch 26
-------------------------------
loss: 0.129292  [    0/69642]
loss: 0.195042  [ 6400/69642]
loss: 0.169024  [12800/69642]
loss: 0.159869  [19200/69642]
loss: 0.189080  [25600/69642]
loss: 0.182078  [32000/69642]
loss: 0.129656  [38400/69642]
loss: 0.248239  [44800/69642]
loss: 0.187747  [51200/69642]
loss: 0.212222  [57600/69642]
loss: 0.069279  [64000/69642]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.155733 

Epoch 27
-------------------------------
loss: 0.207324  [    0/69642]
loss: 0.145233  [ 6400/69642]
loss: 0.203835  [12800/69642]
loss: 0.138410  [19200/69642]
loss: 0.286871  [25600/69642]
loss: 0.134992  [32000/69642]
loss: 0.256011  [38400/69642]
loss: 0.177574  [44800/69642]
loss: 0.235358  [51200/69642]
loss: 0.206925  [57600/69642]
loss: 0.136206  [64000/69642]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.160080 

Epoch 28
-------------------------------
loss: 0.163540  [    0/69642]
loss: 0.151684  [ 6400/69642]
loss: 0.094751  [12800/69642]
loss: 0.193063  [19200/69642]
loss: 0.195614  [25600/69642]
loss: 0.057642  [32000/69642]
loss: 0.238263  [38400/69642]
loss: 0.129409  [44800/69642]
loss: 0.172375  [51200/69642]
loss: 0.084575  [57600/69642]
loss: 0.189215  [64000/69642]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.150409 

Epoch 29
-------------------------------
loss: 0.174404  [    0/69642]
loss: 0.168909  [ 6400/69642]
loss: 0.119717  [12800/69642]
loss: 0.080719  [19200/69642]
loss: 0.113147  [25600/69642]
loss: 0.128004  [32000/69642]
loss: 0.138363  [38400/69642]
loss: 0.135333  [44800/69642]
loss: 0.159101  [51200/69642]
loss: 0.113416  [57600/69642]
loss: 0.099004  [64000/69642]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.172161 

Epoch 30
-------------------------------
loss: 0.077265  [    0/69642]
loss: 0.153671  [ 6400/69642]
loss: 0.148770  [12800/69642]
loss: 0.295764  [19200/69642]
loss: 0.125604  [25600/69642]
loss: 0.177392  [32000/69642]
loss: 0.144145  [38400/69642]
loss: 0.210908  [44800/69642]
loss: 0.152345  [51200/69642]
loss: 0.105149  [57600/69642]
loss: 0.186485  [64000/69642]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.155050 

Epoch 31
-------------------------------
loss: 0.188591  [    0/69642]
loss: 0.164063  [ 6400/69642]
loss: 1.718781  [12800/69642]
loss: 0.170833  [19200/69642]
loss: 0.161297  [25600/69642]
loss: 0.155919  [32000/69642]
loss: 0.180360  [38400/69642]
loss: 0.144156  [44800/69642]
loss: 0.057732  [51200/69642]
loss: 0.132940  [57600/69642]
loss: 0.138571  [64000/69642]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.150357 

Epoch 32
-------------------------------
loss: 0.055034  [    0/69642]
loss: 0.081956  [ 6400/69642]
loss: 0.226274  [12800/69642]
loss: 0.136813  [19200/69642]
loss: 0.142996  [25600/69642]
loss: 0.117785  [32000/69642]
loss: 0.208490  [38400/69642]
loss: 0.136087  [44800/69642]
loss: 0.120571  [51200/69642]
loss: 0.174316  [57600/69642]
loss: 0.123968  [64000/69642]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.150549 

Epoch 33
-------------------------------
loss: 0.199615  [    0/69642]
loss: 0.240817  [ 6400/69642]
loss: 0.156347  [12800/69642]
loss: 0.198868  [19200/69642]
loss: 0.403359  [25600/69642]
loss: 0.095609  [32000/69642]
loss: 0.108162  [38400/69642]
loss: 0.201023  [44800/69642]
loss: 0.172761  [51200/69642]
loss: 0.314276  [57600/69642]
loss: 0.162970  [64000/69642]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.185724 

Epoch 34
-------------------------------
loss: 0.211855  [    0/69642]
loss: 0.138087  [ 6400/69642]
loss: 0.139519  [12800/69642]
loss: 0.194029  [19200/69642]
loss: 0.132170  [25600/69642]
loss: 0.108134  [32000/69642]
loss: 0.186675  [38400/69642]
loss: 0.137798  [44800/69642]
loss: 0.090982  [51200/69642]
loss: 0.260280  [57600/69642]
loss: 0.253528  [64000/69642]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.164650 

Epoch 35
-------------------------------
loss: 0.150563  [    0/69642]
loss: 0.264387  [ 6400/69642]
loss: 0.103173  [12800/69642]
loss: 0.167045  [19200/69642]
loss: 0.134199  [25600/69642]
loss: 0.279588  [32000/69642]
loss: 0.070419  [38400/69642]
loss: 0.129361  [44800/69642]
loss: 0.072513  [51200/69642]
loss: 0.214216  [57600/69642]
loss: 0.223116  [64000/69642]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.162152 

Epoch 36
-------------------------------
loss: 0.107477  [    0/69642]
loss: 0.184593  [ 6400/69642]
loss: 0.138235  [12800/69642]
loss: 0.152122  [19200/69642]
loss: 0.216075  [25600/69642]
loss: 0.124784  [32000/69642]
loss: 0.121854  [38400/69642]
loss: 0.196622  [44800/69642]
loss: 0.234765  [51200/69642]
loss: 0.085136  [57600/69642]
loss: 0.156968  [64000/69642]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.167048 

Epoch 37
-------------------------------
loss: 0.248217  [    0/69642]
loss: 0.199898  [ 6400/69642]
loss: 0.084899  [12800/69642]
loss: 0.109020  [19200/69642]
loss: 0.243870  [25600/69642]
loss: 0.107501  [32000/69642]
loss: 0.323446  [38400/69642]
loss: 0.188380  [44800/69642]
loss: 0.146821  [51200/69642]
loss: 0.135109  [57600/69642]
loss: 0.168478  [64000/69642]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.181144 

Epoch 38
-------------------------------
loss: 0.110370  [    0/69642]
loss: 0.125195  [ 6400/69642]
loss: 0.108410  [12800/69642]
loss: 0.143499  [19200/69642]
loss: 0.207629  [25600/69642]
loss: 0.094313  [32000/69642]
loss: 0.105819  [38400/69642]
loss: 0.183122  [44800/69642]
loss: 0.216959  [51200/69642]
loss: 0.192149  [57600/69642]
loss: 0.186041  [64000/69642]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.158788 

Epoch 39
-------------------------------
loss: 0.105745  [    0/69642]
loss: 0.200769  [ 6400/69642]
loss: 0.172768  [12800/69642]
loss: 0.154000  [19200/69642]
loss: 0.203190  [25600/69642]
loss: 0.177467  [32000/69642]
loss: 0.135221  [38400/69642]
loss: 0.163852  [44800/69642]
loss: 0.233009  [51200/69642]
loss: 0.059442  [57600/69642]
loss: 0.171153  [64000/69642]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.153277 

Epoch 40
-------------------------------
loss: 0.109384  [    0/69642]
loss: 0.087095  [ 6400/69642]
loss: 0.285353  [12800/69642]
loss: 0.126377  [19200/69642]
loss: 0.094958  [25600/69642]
loss: 0.157376  [32000/69642]
loss: 0.192182  [38400/69642]
loss: 0.119211  [44800/69642]
loss: 0.187472  [51200/69642]
loss: 0.101859  [57600/69642]
loss: 0.152586  [64000/69642]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.160656 

Epoch 41
-------------------------------
loss: 0.138355  [    0/69642]
loss: 0.152392  [ 6400/69642]
loss: 0.107864  [12800/69642]
loss: 0.089882  [19200/69642]
loss: 0.168242  [25600/69642]
loss: 0.103134  [32000/69642]
loss: 0.221257  [38400/69642]
loss: 0.124119  [44800/69642]
loss: 0.176066  [51200/69642]
loss: 0.163481  [57600/69642]
loss: 0.098933  [64000/69642]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.166057 

Epoch 42
-------------------------------
loss: 0.155060  [    0/69642]
loss: 0.113698  [ 6400/69642]
loss: 0.192371  [12800/69642]
loss: 0.135911  [19200/69642]
loss: 0.197359  [25600/69642]
loss: 0.181650  [32000/69642]
loss: 0.117558  [38400/69642]
loss: 0.209365  [44800/69642]
loss: 0.157690  [51200/69642]
loss: 0.190210  [57600/69642]
loss: 0.217843  [64000/69642]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.181929 

2022/09/20 20:47:43 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 20:47:49 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 20:49:25 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.055481  [64000/71250]
loss: 0.074389  [70400/71250]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.118864 

Epoch 44
-------------------------------
loss: 0.118054  [    0/71250]
loss: 0.051349  [ 6400/71250]
loss: 0.048000  [12800/71250]
loss: 0.036417  [19200/71250]
loss: 0.070483  [25600/71250]
loss: 0.049057  [32000/71250]
loss: 0.139794  [38400/71250]
loss: 0.029365  [44800/71250]
loss: 0.070321  [51200/71250]
loss: 0.058075  [57600/71250]
loss: 0.104992  [64000/71250]
loss: 0.207893  [70400/71250]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.100296 

Epoch 45
-------------------------------
loss: 0.052676  [    0/71250]
loss: 0.095393  [ 6400/71250]
loss: 0.036125  [12800/71250]
loss: 0.073922  [19200/71250]
loss: 0.095453  [25600/71250]
loss: 0.067861  [32000/71250]
loss: 0.083805  [38400/71250]
loss: 0.151330  [44800/71250]
loss: 0.062447  [51200/71250]
loss: 0.116691  [57600/71250]
loss: 0.085469  [64000/71250]
loss: 0.027439  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.098932 

Epoch 46
-------------------------------
loss: 0.064518  [    0/71250]
loss: 0.078512  [ 6400/71250]
loss: 0.083490  [12800/71250]
loss: 0.162197  [19200/71250]
loss: 0.146628  [25600/71250]
loss: 0.058590  [32000/71250]
loss: 0.096878  [38400/71250]
loss: 0.038804  [44800/71250]
loss: 0.088094  [51200/71250]
loss: 0.047575  [57600/71250]
loss: 0.061809  [64000/71250]
loss: 0.057328  [70400/71250]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.110742 

Epoch 47
-------------------------------
loss: 0.098423  [    0/71250]
loss: 0.053527  [ 6400/71250]
loss: 0.155765  [12800/71250]
loss: 0.065412  [19200/71250]
loss: 0.224323  [25600/71250]
loss: 0.060009  [32000/71250]
loss: 0.079133  [38400/71250]
loss: 0.033995  [44800/71250]
loss: 0.035152  [51200/71250]
loss: 0.118028  [57600/71250]
loss: 0.097935  [64000/71250]
loss: 0.134782  [70400/71250]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.094291 

Epoch 48
-------------------------------
loss: 0.085924  [    0/71250]
loss: 0.100591  [ 6400/71250]
loss: 0.134606  [12800/71250]
loss: 0.071628  [19200/71250]
loss: 0.038109  [25600/71250]
loss: 0.041965  [32000/71250]
loss: 0.053303  [38400/71250]
loss: 0.144805  [44800/71250]
loss: 0.074516  [51200/71250]
loss: 0.077392  [57600/71250]
loss: 0.084370  [64000/71250]
loss: 0.042242  [70400/71250]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.097210 

Epoch 49
-------------------------------
loss: 0.070285  [    0/71250]
loss: 0.041017  [ 6400/71250]
loss: 0.159660  [12800/71250]
loss: 0.083588  [19200/71250]
loss: 0.104258  [25600/71250]
loss: 0.083382  [32000/71250]
loss: 0.083177  [38400/71250]
loss: 0.040459  [44800/71250]
loss: 0.108902  [51200/71250]
loss: 0.165092  [57600/71250]
loss: 0.006089  [64000/71250]
loss: 0.035286  [70400/71250]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.106764 

Epoch 50
-------------------------------
loss: 0.088513  [    0/71250]
loss: 0.188896  [ 6400/71250]
loss: 0.045548  [12800/71250]
loss: 0.079490  [19200/71250]
loss: 0.051040  [25600/71250]
loss: 0.073617  [32000/71250]
loss: 0.110832  [38400/71250]
loss: 0.109203  [44800/71250]
loss: 0.054685  [51200/71250]
loss: 0.140632  [57600/71250]
loss: 0.022762  [64000/71250]
loss: 0.063777  [70400/71250]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099180 

Epoch 1
-------------------------------
loss: 0.697802  [    0/70789]
loss: 0.201548  [ 6400/70789]
loss: 0.053455  [12800/70789]
loss: 0.085866  [19200/70789]
loss: 0.126132  [25600/70789]
loss: 0.059414  [32000/70789]
loss: 0.196193  [38400/70789]
loss: 0.059758  [44800/70789]
loss: 0.137155  [51200/70789]
loss: 0.060093  [57600/70789]
loss: 0.059733  [64000/70789]
loss: 0.224238  [70400/70789]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.086487 

Epoch 2
-------------------------------
loss: 0.146052  [    0/70789]
loss: 0.100989  [ 6400/70789]
loss: 0.156008  [12800/70789]
loss: 0.039135  [19200/70789]
loss: 0.097302  [25600/70789]
loss: 0.175668  [32000/70789]
loss: 0.042834  [38400/70789]
loss: 0.108360  [44800/70789]
loss: 0.052230  [51200/70789]
loss: 0.037834  [57600/70789]
loss: 0.061365  [64000/70789]
loss: 0.068394  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075162 

Epoch 3
-------------------------------
loss: 0.079244  [    0/70789]
loss: 0.101633  [ 6400/70789]
loss: 0.043433  [12800/70789]
loss: 0.047990  [19200/70789]
loss: 0.066941  [25600/70789]
loss: 0.072827  [32000/70789]
loss: 0.077327  [38400/70789]
loss: 0.117018  [44800/70789]
loss: 0.070384  [51200/70789]
loss: 0.099528  [57600/70789]
loss: 0.197429  [64000/70789]
loss: 0.016043  [70400/70789]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.073714 

Epoch 4
-------------------------------
loss: 0.081762  [    0/70789]
loss: 0.058707  [ 6400/70789]
loss: 0.082150  [12800/70789]
loss: 0.113824  [19200/70789]
loss: 0.070256  [25600/70789]
loss: 0.036441  [32000/70789]
loss: 0.087101  [38400/70789]
loss: 0.091664  [44800/70789]
loss: 0.038318  [51200/70789]
loss: 0.125975  [57600/70789]
loss: 0.050904  [64000/70789]
loss: 0.118854  [70400/70789]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.074798 

Epoch 5
-------------------------------
loss: 0.013461  [    0/70789]
loss: 0.054267  [ 6400/70789]
loss: 0.087522  [12800/70789]
loss: 0.068658  [19200/70789]
loss: 0.116993  [25600/70789]
loss: 0.011019  [32000/70789]
loss: 0.024458  [38400/70789]
loss: 0.136625  [44800/70789]
loss: 0.084367  [51200/70789]
loss: 0.069232  [57600/70789]
loss: 0.050941  [64000/70789]
loss: 0.127712  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.071373 

Epoch 6
-------------------------------
loss: 0.041198  [    0/70789]
loss: 0.039214  [ 6400/70789]
loss: 0.168733  [12800/70789]
loss: 0.100539  [19200/70789]
loss: 0.041790  [25600/70789]
loss: 0.107968  [32000/70789]
loss: 0.228961  [38400/70789]
loss: 0.053463  [44800/70789]
loss: 0.035277  [51200/70789]
loss: 0.038101  [57600/70789]
loss: 0.029643  [64000/70789]
loss: 0.031026  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.072687 

Epoch 7
-------------------------------
loss: 0.024848  [    0/70789]
loss: 0.040090  [ 6400/70789]
loss: 0.147649  [12800/70789]
loss: 0.029549  [19200/70789]
loss: 0.014898  [25600/70789]
loss: 0.162845  [32000/70789]
loss: 0.042086  [38400/70789]
loss: 0.020426  [44800/70789]
loss: 0.105489  [51200/70789]
loss: 0.088148  [57600/70789]
loss: 0.021291  [64000/70789]
loss: 0.041472  [70400/70789]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.064139 

Epoch 8
-------------------------------
loss: 0.116982  [    0/70789]
loss: 0.051402  [ 6400/70789]
loss: 0.012374  [12800/70789]
loss: 0.096135  [19200/70789]
loss: 0.057691  [25600/70789]
loss: 0.108413  [32000/70789]
loss: 0.149763  [38400/70789]
loss: 0.127324  [44800/70789]
loss: 0.150494  [51200/70789]
loss: 0.018385  [57600/70789]
loss: 0.045058  [64000/70789]
loss: 0.129567  [70400/70789]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.066757 

Epoch 9
-------------------------------
loss: 0.086830  [    0/70789]
loss: 0.016150  [ 6400/70789]
loss: 0.121290  [12800/70789]
loss: 0.092452  [19200/70789]
loss: 0.011166  [25600/70789]
loss: 0.050186  [32000/70789]
loss: 0.112148  [38400/70789]
loss: 0.095056  [44800/70789]
loss: 0.041756  [51200/70789]
loss: 0.017344  [57600/70789]
loss: 0.067328  [64000/70789]
loss: 0.153092  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067459 

Epoch 10
-------------------------------
loss: 0.204398  [    0/70789]
loss: 0.045484  [ 6400/70789]
loss: 0.011513  [12800/70789]
loss: 0.051201  [19200/70789]
loss: 0.045980  [25600/70789]
loss: 0.053618  [32000/70789]
loss: 0.032174  [38400/70789]
loss: 0.117919  [44800/70789]
loss: 0.035710  [51200/70789]
loss: 0.016725  [57600/70789]
loss: 0.072573  [64000/70789]
loss: 0.128878  [70400/70789]
Test Error: 
 Accuracy: 98.0%, Avg loss: 0.064305 

Epoch 11
-------------------------------
loss: 0.058443  [    0/70789]
loss: 0.093902  [ 6400/70789]
loss: 0.020270  [12800/70789]
loss: 0.012491  [19200/70789]
loss: 0.046112  [25600/70789]
loss: 0.028170  [32000/70789]
loss: 0.061340  [38400/70789]
loss: 0.043593  [44800/70789]
loss: 0.122402  [51200/70789]
loss: 0.031303  [57600/70789]
loss: 0.040790  [64000/70789]
2022/09/20 20:50:18 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 20:51:56 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.189479  [12800/69886]
loss: 0.204815  [19200/69886]
loss: 0.173101  [25600/69886]
loss: 0.151662  [32000/69886]
loss: 0.070631  [38400/69886]
loss: 0.240353  [44800/69886]
loss: 0.220081  [51200/69886]
loss: 0.134233  [57600/69886]
loss: 0.179579  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.160534 

Epoch 28
-------------------------------
loss: 0.206063  [    0/69886]
loss: 0.144845  [ 6400/69886]
loss: 0.193485  [12800/69886]
loss: 0.247180  [19200/69886]
loss: 0.087724  [25600/69886]
loss: 0.213639  [32000/69886]
loss: 0.142595  [38400/69886]
loss: 0.175338  [44800/69886]
loss: 0.198949  [51200/69886]
loss: 0.320259  [57600/69886]
loss: 0.177645  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.161359 

Epoch 29
-------------------------------
loss: 0.293757  [    0/69886]
loss: 0.130199  [ 6400/69886]
loss: 0.243915  [12800/69886]
loss: 0.094184  [19200/69886]
loss: 0.092047  [25600/69886]
loss: 0.140384  [32000/69886]
loss: 0.206020  [38400/69886]
loss: 0.182925  [44800/69886]
loss: 0.128596  [51200/69886]
loss: 0.185536  [57600/69886]
loss: 0.166111  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.159840 

Epoch 30
-------------------------------
loss: 0.261044  [    0/69886]
loss: 0.165139  [ 6400/69886]
loss: 0.068360  [12800/69886]
loss: 0.174064  [19200/69886]
loss: 0.148642  [25600/69886]
loss: 0.188672  [32000/69886]
loss: 0.245295  [38400/69886]
loss: 0.188950  [44800/69886]
loss: 0.159489  [51200/69886]
loss: 0.217862  [57600/69886]
loss: 0.153038  [64000/69886]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.162158 

Epoch 31
-------------------------------
loss: 0.129854  [    0/69886]
loss: 0.095278  [ 6400/69886]
loss: 0.064697  [12800/69886]
loss: 0.224748  [19200/69886]
loss: 0.180054  [25600/69886]
loss: 0.132869  [32000/69886]
loss: 0.168561  [38400/69886]
loss: 0.245704  [44800/69886]
loss: 0.199601  [51200/69886]
loss: 0.138228  [57600/69886]
loss: 0.322141  [64000/69886]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.159117 

Epoch 32
-------------------------------
loss: 0.125414  [    0/69886]
loss: 0.155315  [ 6400/69886]
loss: 0.091266  [12800/69886]
loss: 0.200431  [19200/69886]
loss: 0.128212  [25600/69886]
loss: 0.205610  [32000/69886]
loss: 0.104710  [38400/69886]
loss: 0.155005  [44800/69886]
loss: 0.117369  [51200/69886]
loss: 0.097013  [57600/69886]
loss: 0.142072  [64000/69886]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.165650 

Epoch 33
-------------------------------
loss: 0.142627  [    0/69886]
loss: 0.177475  [ 6400/69886]
loss: 0.135753  [12800/69886]
loss: 0.130765  [19200/69886]
loss: 0.210317  [25600/69886]
loss: 0.236844  [32000/69886]
loss: 0.227179  [38400/69886]
loss: 0.160360  [44800/69886]
loss: 0.076025  [51200/69886]
loss: 0.160119  [57600/69886]
loss: 0.179826  [64000/69886]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.162863 

Epoch 34
-------------------------------
loss: 0.238973  [    0/69886]
loss: 0.053974  [ 6400/69886]
loss: 0.137862  [12800/69886]
loss: 0.159003  [19200/69886]
loss: 0.110685  [25600/69886]
loss: 0.134548  [32000/69886]
loss: 0.318436  [38400/69886]
loss: 0.119169  [44800/69886]
loss: 0.126068  [51200/69886]
loss: 0.158197  [57600/69886]
loss: 0.155651  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.160950 

Epoch 35
-------------------------------
loss: 0.166492  [    0/69886]
loss: 0.168003  [ 6400/69886]
loss: 0.102382  [12800/69886]
loss: 0.113897  [19200/69886]
loss: 0.188561  [25600/69886]
loss: 0.113294  [32000/69886]
loss: 0.215493  [38400/69886]
loss: 0.077675  [44800/69886]
loss: 0.128700  [51200/69886]
loss: 0.285374  [57600/69886]
loss: 0.161634  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.169694 

Epoch 36
-------------------------------
loss: 0.172861  [    0/69886]
loss: 0.215933  [ 6400/69886]
loss: 0.266069  [12800/69886]
loss: 0.192928  [19200/69886]
loss: 0.131702  [25600/69886]
loss: 0.144147  [32000/69886]
loss: 0.173506  [38400/69886]
loss: 0.186187  [44800/69886]
loss: 0.188197  [51200/69886]
loss: 0.169950  [57600/69886]
loss: 0.128670  [64000/69886]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.159140 

Epoch 37
-------------------------------
loss: 0.119359  [    0/69886]
loss: 0.119659  [ 6400/69886]
loss: 0.250443  [12800/69886]
loss: 0.155724  [19200/69886]
loss: 0.113817  [25600/69886]
loss: 0.276321  [32000/69886]
loss: 0.140916  [38400/69886]
loss: 0.143966  [44800/69886]
loss: 0.239433  [51200/69886]
loss: 0.100051  [57600/69886]
loss: 0.202570  [64000/69886]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.155945 

Epoch 38
-------------------------------
loss: 0.138523  [    0/69886]
loss: 0.077189  [ 6400/69886]
loss: 0.171780  [12800/69886]
loss: 0.107222  [19200/69886]
loss: 0.179871  [25600/69886]
loss: 0.150270  [32000/69886]
loss: 0.202647  [38400/69886]
loss: 0.175242  [44800/69886]
loss: 0.222628  [51200/69886]
loss: 0.124071  [57600/69886]
loss: 0.169180  [64000/69886]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.161888 

Epoch 39
-------------------------------
loss: 0.133007  [    0/69886]
loss: 0.206874  [ 6400/69886]
loss: 0.110783  [12800/69886]
loss: 0.129582  [19200/69886]
loss: 0.100187  [25600/69886]
loss: 0.170515  [32000/69886]
loss: 0.265789  [38400/69886]
loss: 0.163982  [44800/69886]
loss: 0.197451  [51200/69886]
loss: 0.103910  [57600/69886]
loss: 0.240046  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.167704 

Epoch 40
-------------------------------
loss: 0.071015  [    0/69886]
loss: 0.158331  [ 6400/69886]
loss: 0.087566  [12800/69886]
loss: 0.073772  [19200/69886]
loss: 0.129110  [25600/69886]
loss: 0.158131  [32000/69886]
loss: 0.162393  [38400/69886]
loss: 0.109363  [44800/69886]
loss: 0.142451  [51200/69886]
loss: 0.109835  [57600/69886]
loss: 0.093736  [64000/69886]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.156236 

Epoch 41
-------------------------------
loss: 0.162201  [    0/69886]
loss: 0.128864  [ 6400/69886]
loss: 0.134753  [12800/69886]
loss: 0.132359  [19200/69886]
loss: 0.223572  [25600/69886]
loss: 0.192489  [32000/69886]
loss: 0.046608  [38400/69886]
loss: 0.191056  [44800/69886]
loss: 0.204610  [51200/69886]
loss: 0.122333  [57600/69886]
loss: 0.111296  [64000/69886]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.158168 

Epoch 42
-------------------------------
loss: 0.160119  [    0/69886]
loss: 0.193758  [ 6400/69886]
loss: 0.076824  [12800/69886]
loss: 0.096962  [19200/69886]
loss: 0.228872  [25600/69886]
loss: 0.222211  [32000/69886]
loss: 0.127218  [38400/69886]
loss: 0.123618  [44800/69886]
loss: 0.207764  [51200/69886]
loss: 0.181750  [57600/69886]
loss: 0.285820  [64000/69886]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.172914 

Epoch 43
-------------------------------
loss: 0.105254  [    0/69886]
loss: 0.247038  [ 6400/69886]
loss: 0.216958  [12800/69886]
loss: 0.165622  [19200/69886]
loss: 0.313326  [25600/69886]
loss: 0.131749  [32000/69886]
loss: 0.160953  [38400/69886]
loss: 0.226492  [44800/69886]
loss: 0.101017  [51200/69886]
loss: 0.218425  [57600/69886]
loss: 0.239532  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.170832 

Epoch 44
-------------------------------
loss: 1.765451  [    0/69886]
loss: 0.115991  [ 6400/69886]
loss: 0.202837  [12800/69886]
loss: 0.201846  [19200/69886]
loss: 0.152483  [25600/69886]
loss: 0.303654  [32000/69886]
loss: 0.169248  [38400/69886]
loss: 0.169303  [44800/69886]
loss: 0.172200  [51200/69886]
loss: 0.161013  [57600/69886]
loss: 0.063039  [64000/69886]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.158804 

Epoch 45
-------------------------------
loss: 0.165797  [    0/69886]
loss: 0.204110  [ 6400/69886]
loss: 0.225815  [12800/69886]
loss: 0.062536  [19200/69886]
loss: 0.092730  [25600/69886]
loss: 0.144989  [32000/69886]
loss: 0.092327  [38400/69886]
loss: 0.189613  [44800/69886]
loss: 0.128660  [51200/69886]
loss: 0.222366  [57600/69886]
loss: 0.234364  [64000/69886]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.160610 

Epoch 46
-------------------------------
loss: 0.113426  [    0/69886]
loss: 0.132847  [ 6400/69886]
loss: 0.074656  [12800/69886]
loss: 0.238889  [19200/69886]
loss: 0.108701  [25600/69886]
loss: 0.180492  [32000/69886]
loss: 0.124798  [38400/69886]
Epoch 36
-------------------------------
loss: 0.085080  [    0/70299]
loss: 0.078137  [ 6400/70299]
loss: 0.032741  [12800/70299]
loss: 0.049298  [19200/70299]
loss: 0.063402  [25600/70299]
loss: 0.142237  [32000/70299]
loss: 0.040645  [38400/70299]
loss: 0.096256  [44800/70299]
loss: 0.041617  [51200/70299]
loss: 0.135403  [57600/70299]
loss: 0.083422  [64000/70299]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.099801 

Epoch 37
-------------------------------
loss: 0.105617  [    0/70299]
loss: 0.029450  [ 6400/70299]
loss: 0.012314  [12800/70299]
loss: 0.165729  [19200/70299]
loss: 0.169118  [25600/70299]
loss: 0.098101  [32000/70299]
loss: 0.070140  [38400/70299]
loss: 0.031344  [44800/70299]
loss: 0.177079  [51200/70299]
loss: 0.198276  [57600/70299]
loss: 0.132215  [64000/70299]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.098707 

Epoch 38
-------------------------------
loss: 0.197135  [    0/70299]
loss: 0.041013  [ 6400/70299]
loss: 0.033011  [12800/70299]
loss: 0.042309  [19200/70299]
loss: 0.047322  [25600/70299]
loss: 0.044196  [32000/70299]
loss: 0.048830  [38400/70299]
loss: 0.098716  [44800/70299]
loss: 0.157946  [51200/70299]
loss: 0.039516  [57600/70299]
loss: 0.080869  [64000/70299]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.103112 

Epoch 39
-------------------------------
loss: 0.098358  [    0/70299]
loss: 0.026701  [ 6400/70299]
loss: 0.042895  [12800/70299]
loss: 0.222433  [19200/70299]
loss: 0.013423  [25600/70299]
loss: 0.027602  [32000/70299]
loss: 0.075330  [38400/70299]
loss: 0.057022  [44800/70299]
loss: 0.056718  [51200/70299]
loss: 0.096204  [57600/70299]
loss: 0.137135  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.104430 

Epoch 40
-------------------------------
loss: 0.083726  [    0/70299]
loss: 0.099399  [ 6400/70299]
loss: 0.023336  [12800/70299]
loss: 0.171923  [19200/70299]
loss: 0.073315  [25600/70299]
loss: 0.006214  [32000/70299]
loss: 0.196230  [38400/70299]
loss: 0.040377  [44800/70299]
loss: 1.638448  [51200/70299]
loss: 0.035803  [57600/70299]
loss: 0.070439  [64000/70299]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.103385 

Epoch 41
-------------------------------
loss: 0.220965  [    0/70299]
loss: 0.107594  [ 6400/70299]
loss: 0.149725  [12800/70299]
loss: 0.077571  [19200/70299]
loss: 0.094260  [25600/70299]
loss: 0.106368  [32000/70299]
loss: 0.074819  [38400/70299]
loss: 0.175667  [44800/70299]
loss: 0.178262  [51200/70299]
loss: 0.016930  [57600/70299]
loss: 0.022283  [64000/70299]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.109427 

Epoch 42
-------------------------------
loss: 0.063793  [    0/70299]
loss: 0.124066  [ 6400/70299]
loss: 0.089464  [12800/70299]
loss: 0.078867  [19200/70299]
loss: 0.219835  [25600/70299]
loss: 0.060584  [32000/70299]
loss: 0.044881  [38400/70299]
loss: 0.042783  [44800/70299]
loss: 0.144020  [51200/70299]
loss: 0.124649  [57600/70299]
loss: 0.032424  [64000/70299]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.105815 

Epoch 43
-------------------------------
loss: 0.168829  [    0/70299]
loss: 0.032615  [ 6400/70299]
loss: 0.058745  [12800/70299]
loss: 0.028237  [19200/70299]
loss: 0.047143  [25600/70299]
loss: 0.066290  [32000/70299]
loss: 0.057513  [38400/70299]
loss: 0.145134  [44800/70299]
loss: 0.116978  [51200/70299]
loss: 0.050215  [57600/70299]
loss: 0.112746  [64000/70299]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.100997 

Epoch 44
-------------------------------
loss: 0.045692  [    0/70299]
loss: 0.073268  [ 6400/70299]
loss: 0.158440  [12800/70299]
loss: 0.046566  [19200/70299]
loss: 0.060319  [25600/70299]
loss: 0.089957  [32000/70299]
loss: 0.110570  [38400/70299]
loss: 0.120344  [44800/70299]
loss: 0.161164  [51200/70299]
loss: 0.051762  [57600/70299]
loss: 0.134494  [64000/70299]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.097185 

Epoch 45
-------------------------------
loss: 0.147669  [    0/70299]
loss: 0.077125  [ 6400/70299]
loss: 0.042649  [12800/70299]
loss: 0.101898  [19200/70299]
loss: 0.049718  [25600/70299]
loss: 0.075867  [32000/70299]
loss: 0.045898  [38400/70299]
loss: 0.063019  [44800/70299]
loss: 0.052890  [51200/70299]
loss: 0.075068  [57600/70299]
loss: 0.049877  [64000/70299]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.113355 

Epoch 46
-------------------------------
loss: 0.076807  [    0/70299]
loss: 0.099204  [ 6400/70299]
loss: 0.097393  [12800/70299]
loss: 0.064207  [19200/70299]
loss: 0.016871  [25600/70299]
loss: 0.022916  [32000/70299]
loss: 0.043919  [38400/70299]
loss: 0.090343  [44800/70299]
loss: 0.050720  [51200/70299]
loss: 0.053999  [57600/70299]
loss: 0.122279  [64000/70299]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.099495 

Epoch 47
-------------------------------
loss: 0.046882  [    0/70299]
loss: 0.091871  [ 6400/70299]
loss: 0.077015  [12800/70299]
loss: 0.119354  [19200/70299]
loss: 0.014867  [25600/70299]
loss: 0.071863  [32000/70299]
loss: 0.061352  [38400/70299]
loss: 0.045107  [44800/70299]
loss: 0.029108  [51200/70299]
loss: 0.160449  [57600/70299]
loss: 0.067744  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.101094 

Epoch 48
-------------------------------
loss: 0.067391  [    0/70299]
loss: 0.074117  [ 6400/70299]
loss: 0.062885  [12800/70299]
loss: 0.043180  [19200/70299]
loss: 0.059336  [25600/70299]
loss: 0.009688  [32000/70299]
loss: 0.079593  [38400/70299]
loss: 0.068909  [44800/70299]
loss: 0.120923  [51200/70299]
loss: 0.067050  [57600/70299]
loss: 0.039158  [64000/70299]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.104992 

Epoch 49
-------------------------------
loss: 0.038500  [    0/70299]
loss: 0.134204  [ 6400/70299]
loss: 0.151493  [12800/70299]
loss: 0.087160  [19200/70299]
loss: 0.014428  [25600/70299]
loss: 0.049803  [32000/70299]
loss: 0.060238  [38400/70299]
loss: 0.076206  [44800/70299]
loss: 0.149727  [51200/70299]
loss: 0.060821  [57600/70299]
loss: 0.029315  [64000/70299]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.110428 

Epoch 50
-------------------------------
loss: 0.098395  [    0/70299]
loss: 0.034323  [ 6400/70299]
loss: 0.070517  [12800/70299]
loss: 0.077814  [19200/70299]
loss: 0.097073  [25600/70299]
loss: 0.092546  [32000/70299]
loss: 0.071715  [38400/70299]
loss: 0.068426  [44800/70299]
loss: 0.142787  [51200/70299]
loss: 0.068059  [57600/70299]
loss: 0.008003  [64000/70299]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.105057 

Epoch 1
-------------------------------
loss: 0.649035  [    0/69794]
loss: 0.216280  [ 6400/69794]
loss: 0.216398  [12800/69794]
loss: 0.165629  [19200/69794]
loss: 0.184194  [25600/69794]
loss: 0.112735  [32000/69794]
loss: 0.160040  [38400/69794]
loss: 0.111361  [44800/69794]
loss: 0.096488  [51200/69794]
loss: 0.104974  [57600/69794]
loss: 0.049870  [64000/69794]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.140304 

Epoch 2
-------------------------------
loss: 0.044897  [    0/69794]
loss: 0.204744  [ 6400/69794]
loss: 0.133722  [12800/69794]
loss: 0.080897  [19200/69794]
loss: 0.118661  [25600/69794]
loss: 0.060420  [32000/69794]
loss: 0.176042  [38400/69794]
loss: 0.088168  [44800/69794]
loss: 0.174613  [51200/69794]
loss: 0.081293  [57600/69794]
loss: 0.154466  [64000/69794]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.123927 

Epoch 3
-------------------------------
loss: 0.098270  [    0/69794]
loss: 0.108554  [ 6400/69794]
loss: 0.191729  [12800/69794]
loss: 0.066274  [19200/69794]
loss: 0.132671  [25600/69794]
loss: 0.163265  [32000/69794]
loss: 0.090301  [38400/69794]
loss: 0.054690  [44800/69794]
loss: 0.125746  [51200/69794]
loss: 0.169495  [57600/69794]
loss: 0.150571  [64000/69794]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.117409 

Epoch 4
-------------------------------
loss: 0.066968  [    0/69794]
loss: 0.069516  [ 6400/69794]
loss: 0.109996  [12800/69794]
loss: 0.111191  [19200/69794]
loss: 0.199158  [25600/69794]
loss: 0.050835  [32000/69794]
loss: 0.074839  [38400/69794]
loss: 0.076604  [44800/69794]
loss: 0.121579  [51200/69794]
loss: 0.379804  [57600/69794]
loss: 0.188536  [64000/69794]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.112727 

Epoch 5
-------------------------------
loss: 0.134870  [    0/69794]
loss: 0.099059  [ 6400/69794]
loss: 0.161789  [12800/69794]
loss: 0.175067  [19200/69794]loss: 0.114181  [44800/70818]
loss: 0.167428  [51200/70818]
loss: 0.052623  [57600/70818]
loss: 0.056282  [64000/70818]
loss: 0.046327  [70400/70818]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.110524 

Epoch 44
-------------------------------
loss: 0.083311  [    0/70818]
loss: 0.045355  [ 6400/70818]
loss: 0.059414  [12800/70818]
loss: 0.105772  [19200/70818]
loss: 0.025771  [25600/70818]
loss: 0.055840  [32000/70818]
loss: 0.087162  [38400/70818]
loss: 0.128653  [44800/70818]
loss: 0.086741  [51200/70818]
loss: 0.091982  [57600/70818]
loss: 0.105127  [64000/70818]
loss: 0.049392  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.111775 

Epoch 45
-------------------------------
loss: 0.090066  [    0/70818]
loss: 0.042323  [ 6400/70818]
loss: 0.175663  [12800/70818]
loss: 0.059981  [19200/70818]
loss: 0.107280  [25600/70818]
loss: 0.048463  [32000/70818]
loss: 0.155137  [38400/70818]
loss: 0.136858  [44800/70818]
loss: 0.090274  [51200/70818]
loss: 0.283737  [57600/70818]
loss: 0.054384  [64000/70818]
loss: 0.145152  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.109389 

Epoch 46
-------------------------------
loss: 0.012847  [    0/70818]
loss: 0.078958  [ 6400/70818]
loss: 0.023868  [12800/70818]
loss: 0.139285  [19200/70818]
loss: 0.039857  [25600/70818]
loss: 0.033951  [32000/70818]
loss: 0.126764  [38400/70818]
loss: 0.063072  [44800/70818]
loss: 0.196153  [51200/70818]
loss: 0.189897  [57600/70818]
loss: 0.064052  [64000/70818]
loss: 0.137366  [70400/70818]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.101919 

Epoch 47
-------------------------------
loss: 0.059892  [    0/70818]
loss: 0.048907  [ 6400/70818]
loss: 0.040969  [12800/70818]
loss: 0.071070  [19200/70818]
loss: 0.051900  [25600/70818]
loss: 0.077551  [32000/70818]
loss: 0.070233  [38400/70818]
loss: 0.154759  [44800/70818]
loss: 0.069849  [51200/70818]
loss: 0.083886  [57600/70818]
loss: 0.071878  [64000/70818]
loss: 0.096156  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.115835 

Epoch 48
-------------------------------
loss: 0.100303  [    0/70818]
loss: 0.094477  [ 6400/70818]
loss: 0.103734  [12800/70818]
loss: 0.143545  [19200/70818]
loss: 0.153329  [25600/70818]
loss: 0.103885  [32000/70818]
loss: 0.116059  [38400/70818]
loss: 0.045192  [44800/70818]
loss: 0.018897  [51200/70818]
loss: 0.134266  [57600/70818]
loss: 0.056791  [64000/70818]
loss: 0.151767  [70400/70818]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.111959 

Epoch 49
-------------------------------
loss: 0.061555  [    0/70818]
loss: 0.164386  [ 6400/70818]
loss: 0.201503  [12800/70818]
loss: 0.100238  [19200/70818]
loss: 0.094967  [25600/70818]
loss: 0.088463  [32000/70818]
loss: 0.080741  [38400/70818]
loss: 0.094810  [44800/70818]
loss: 0.098022  [51200/70818]
loss: 0.013112  [57600/70818]
loss: 0.152596  [64000/70818]
loss: 0.082031  [70400/70818]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.113414 

Epoch 50
-------------------------------
loss: 0.033863  [    0/70818]
loss: 0.022982  [ 6400/70818]
loss: 0.049093  [12800/70818]
loss: 0.090259  [19200/70818]
loss: 0.114587  [25600/70818]
loss: 0.100136  [32000/70818]
loss: 0.135300  [38400/70818]
loss: 0.198147  [44800/70818]
loss: 0.026703  [51200/70818]
loss: 0.102779  [57600/70818]
loss: 0.032914  [64000/70818]
loss: 0.152865  [70400/70818]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.115190 

Epoch 1
-------------------------------
loss: 0.642730  [    0/70127]
loss: 0.276774  [ 6400/70127]
loss: 0.132418  [12800/70127]
loss: 0.168738  [19200/70127]
loss: 0.153247  [25600/70127]
loss: 0.138024  [32000/70127]
loss: 0.076733  [38400/70127]
loss: 0.151496  [44800/70127]
loss: 0.088997  [51200/70127]
loss: 0.123736  [57600/70127]
loss: 0.298689  [64000/70127]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.130175 

Epoch 2
-------------------------------
loss: 0.102957  [    0/70127]
loss: 0.252372  [ 6400/70127]
loss: 0.060896  [12800/70127]
loss: 0.104093  [19200/70127]
loss: 0.104260  [25600/70127]
loss: 0.071119  [32000/70127]
loss: 0.123734  [38400/70127]
loss: 0.211079  [44800/70127]
loss: 0.116296  [51200/70127]
loss: 0.144770  [57600/70127]
loss: 0.126981  [64000/70127]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.129188 

Epoch 3
-------------------------------
loss: 0.102912  [    0/70127]
loss: 0.059441  [ 6400/70127]
loss: 0.132096  [12800/70127]
loss: 0.112729  [19200/70127]
loss: 0.108795  [25600/70127]
loss: 0.117643  [32000/70127]
loss: 0.052857  [38400/70127]
loss: 0.192144  [44800/70127]
loss: 0.267059  [51200/70127]
loss: 0.198803  [57600/70127]
loss: 0.145332  [64000/70127]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.115278 

Epoch 4
-------------------------------
loss: 0.136929  [    0/70127]
loss: 0.056656  [ 6400/70127]
loss: 0.099376  [12800/70127]
loss: 0.046553  [19200/70127]
loss: 0.128450  [25600/70127]
loss: 0.122154  [32000/70127]
loss: 0.110987  [38400/70127]
loss: 0.075774  [44800/70127]
loss: 0.091023  [51200/70127]
loss: 0.143594  [57600/70127]
loss: 0.088573  [64000/70127]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.103753 

Epoch 5
-------------------------------
loss: 0.144447  [    0/70127]
loss: 0.094450  [ 6400/70127]
loss: 0.136598  [12800/70127]
loss: 0.118565  [19200/70127]
loss: 0.180862  [25600/70127]
loss: 0.067784  [32000/70127]
loss: 0.111873  [38400/70127]
loss: 0.195116  [44800/70127]
loss: 0.115474  [51200/70127]
loss: 0.081080  [57600/70127]
loss: 0.250479  [64000/70127]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.108451 

Epoch 6
-------------------------------
loss: 0.084855  [    0/70127]
loss: 0.134258  [ 6400/70127]
loss: 0.246325  [12800/70127]
loss: 0.107729  [19200/70127]
loss: 0.108600  [25600/70127]
loss: 0.102460  [32000/70127]
loss: 0.066898  [38400/70127]
loss: 0.138265  [44800/70127]
loss: 0.080980  [51200/70127]
loss: 0.251914  [57600/70127]
loss: 0.033001  [64000/70127]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.100434 

Epoch 7
-------------------------------
loss: 0.260932  [    0/70127]
loss: 0.151864  [ 6400/70127]
loss: 0.136408  [12800/70127]
loss: 0.067198  [19200/70127]
loss: 0.124346  [25600/70127]
loss: 0.115427  [32000/70127]
loss: 0.121403  [38400/70127]
loss: 0.069077  [44800/70127]
loss: 0.084002  [51200/70127]
loss: 0.158815  [57600/70127]
loss: 0.147486  [64000/70127]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.104221 

Epoch 8
-------------------------------
loss: 0.057616  [    0/70127]
loss: 0.229297  [ 6400/70127]
loss: 0.116656  [12800/70127]
loss: 0.083505  [19200/70127]
loss: 0.065136  [25600/70127]
loss: 0.210330  [32000/70127]
loss: 0.078142  [38400/70127]
loss: 0.059079  [44800/70127]
loss: 0.107710  [51200/70127]
loss: 0.145546  [57600/70127]
loss: 0.059731  [64000/70127]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.114156 

Epoch 9
-------------------------------
loss: 0.095768  [    0/70127]
loss: 0.085661  [ 6400/70127]
loss: 0.084946  [12800/70127]
loss: 0.151637  [19200/70127]
loss: 0.055059  [25600/70127]
loss: 0.120677  [32000/70127]
loss: 0.131414  [38400/70127]
loss: 0.064526  [44800/70127]
loss: 0.177772  [51200/70127]
loss: 0.097247  [57600/70127]
loss: 0.044979  [64000/70127]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.101093 

Epoch 10
-------------------------------
loss: 0.104938  [    0/70127]
loss: 0.110658  [ 6400/70127]
loss: 0.138921  [12800/70127]
loss: 0.114761  [19200/70127]
loss: 0.122250  [25600/70127]
loss: 0.089634  [32000/70127]
loss: 0.050563  [38400/70127]
loss: 0.141863  [44800/70127]
loss: 0.087514  [51200/70127]
loss: 0.110495  [57600/70127]
loss: 0.083814  [64000/70127]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.097158 

Epoch 11
-------------------------------
loss: 0.127953  [    0/70127]
loss: 0.115062  [ 6400/70127]
loss: 0.231504  [12800/70127]
loss: 0.114881  [19200/70127]
loss: 0.170938  [25600/70127]
loss: 0.031766  [32000/70127]
loss: 0.165967  [38400/70127]
loss: 0.085445  [44800/70127]
loss: 0.101216  [51200/70127]
loss: 0.058348  [57600/70127]
loss: 0.106040  [64000/70127]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.096699 

Epoch 12
-------------------------------
loss: 0.046939  [    0/70127]
loss: 0.083472  [ 6400/70127]
loss: 0.129184  [12800/70127]
loss: 0.061473  [19200/70127]
loss: 0.051863  [64000/71701]
loss: 0.293771  [70400/71701]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.096355 

Epoch 2
-------------------------------
loss: 0.059532  [    0/71701]
loss: 0.037701  [ 6400/71701]
loss: 0.053908  [12800/71701]
loss: 0.134623  [19200/71701]
loss: 0.078638  [25600/71701]
loss: 0.125248  [32000/71701]
loss: 0.050051  [38400/71701]
loss: 0.059409  [44800/71701]
loss: 0.094142  [51200/71701]
loss: 0.069494  [57600/71701]
loss: 0.094092  [64000/71701]
loss: 0.024247  [70400/71701]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.074373 

Epoch 3
-------------------------------
loss: 0.050334  [    0/71701]
loss: 0.017648  [ 6400/71701]
loss: 0.086406  [12800/71701]
loss: 0.126722  [19200/71701]
loss: 0.061803  [25600/71701]
loss: 0.018102  [32000/71701]
loss: 0.059087  [38400/71701]
loss: 0.052011  [44800/71701]
loss: 0.105746  [51200/71701]
loss: 0.031175  [57600/71701]
loss: 0.123033  [64000/71701]
loss: 0.112386  [70400/71701]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.101218 

Epoch 4
-------------------------------
loss: 0.080524  [    0/71701]
loss: 0.107753  [ 6400/71701]
loss: 0.116407  [12800/71701]
loss: 0.093968  [19200/71701]
loss: 0.082557  [25600/71701]
loss: 0.049453  [32000/71701]
loss: 0.086952  [38400/71701]
loss: 0.070863  [44800/71701]
loss: 0.123918  [51200/71701]
loss: 0.058369  [57600/71701]
loss: 0.059923  [64000/71701]
loss: 0.027254  [70400/71701]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.068059 

Epoch 5
-------------------------------
loss: 0.044556  [    0/71701]
loss: 0.105575  [ 6400/71701]
loss: 0.042634  [12800/71701]
loss: 0.019726  [19200/71701]
loss: 0.093429  [25600/71701]
loss: 0.055284  [32000/71701]
loss: 0.129680  [38400/71701]
loss: 0.101819  [44800/71701]
loss: 0.164262  [51200/71701]
loss: 0.036785  [57600/71701]
loss: 0.032512  [64000/71701]
loss: 0.013066  [70400/71701]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.068641 

Epoch 6
-------------------------------
loss: 0.067374  [    0/71701]
loss: 0.015766  [ 6400/71701]
loss: 0.129178  [12800/71701]
loss: 0.330358  [19200/71701]
loss: 0.052174  [25600/71701]
loss: 0.136469  [32000/71701]
loss: 0.022518  [38400/71701]
loss: 0.054492  [44800/71701]
loss: 0.012348  [51200/71701]
loss: 0.017729  [57600/71701]
loss: 0.104503  [64000/71701]
loss: 0.093211  [70400/71701]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.062797 

Epoch 7
-------------------------------
loss: 0.015204  [    0/71701]
loss: 0.040273  [ 6400/71701]
loss: 0.014873  [12800/71701]
loss: 0.050379  [19200/71701]
loss: 0.025679  [25600/71701]
loss: 0.051601  [32000/71701]
loss: 0.036554  [38400/71701]
loss: 0.030156  [44800/71701]
loss: 0.038121  [51200/71701]
loss: 0.125426  [57600/71701]
loss: 0.049241  [64000/71701]
loss: 0.017403  [70400/71701]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.070569 

Epoch 8
-------------------------------
loss: 0.086652  [    0/71701]
loss: 0.039111  [ 6400/71701]
loss: 0.016691  [12800/71701]
loss: 0.087287  [19200/71701]
loss: 0.035386  [25600/71701]
loss: 0.074838  [32000/71701]
loss: 0.027227  [38400/71701]
loss: 0.015380  [44800/71701]
loss: 0.036186  [51200/71701]
loss: 0.047420  [57600/71701]
loss: 0.070945  [64000/71701]
loss: 0.066022  [70400/71701]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.062909 

Epoch 9
-------------------------------
loss: 0.018219  [    0/71701]
loss: 0.023408  [ 6400/71701]
loss: 0.012898  [12800/71701]
loss: 0.033283  [19200/71701]
loss: 0.038689  [25600/71701]
loss: 0.034919  [32000/71701]
loss: 0.100361  [38400/71701]
loss: 0.018984  [44800/71701]
loss: 0.027746  [51200/71701]
loss: 0.029251  [57600/71701]
loss: 0.025926  [64000/71701]
loss: 0.012235  [70400/71701]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.063145 

Epoch 10
-------------------------------
loss: 0.032320  [    0/71701]
loss: 0.180873  [ 6400/71701]
loss: 0.066748  [12800/71701]
loss: 0.075875  [19200/71701]
loss: 0.035937  [25600/71701]
loss: 0.067214  [32000/71701]
loss: 0.031988  [38400/71701]
loss: 0.053491  [44800/71701]
loss: 0.093877  [51200/71701]
loss: 0.090696  [57600/71701]
loss: 0.074719  [64000/71701]
loss: 0.060183  [70400/71701]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.061717 

Epoch 11
-------------------------------
loss: 0.037857  [    0/71701]
loss: 0.035208  [ 6400/71701]
loss: 0.278061  [12800/71701]
loss: 0.050949  [19200/71701]
loss: 0.035931  [25600/71701]
loss: 0.185183  [32000/71701]
loss: 0.048454  [38400/71701]
loss: 0.022439  [44800/71701]
loss: 0.154729  [51200/71701]
loss: 0.010619  [57600/71701]
loss: 0.061449  [64000/71701]
loss: 0.124757  [70400/71701]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076949 

Epoch 12
-------------------------------
loss: 0.062912  [    0/71701]
loss: 0.016587  [ 6400/71701]
loss: 0.051657  [12800/71701]
loss: 0.082337  [19200/71701]
loss: 0.023487  [25600/71701]
loss: 0.067759  [32000/71701]
loss: 0.037819  [38400/71701]
loss: 0.038972  [44800/71701]
loss: 0.233685  [51200/71701]
loss: 0.038202  [57600/71701]
loss: 0.078827  [64000/71701]
loss: 0.029354  [70400/71701]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.063556 

Epoch 13
-------------------------------
loss: 0.097760  [    0/71701]
loss: 0.013888  [ 6400/71701]
loss: 0.086156  [12800/71701]
loss: 0.078609  [19200/71701]
loss: 0.020158  [25600/71701]
loss: 0.124437  [32000/71701]
loss: 0.022661  [38400/71701]
loss: 0.046895  [44800/71701]
loss: 0.034275  [51200/71701]
loss: 0.029659  [57600/71701]
loss: 0.031769  [64000/71701]
loss: 0.126405  [70400/71701]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.071142 

Epoch 14
-------------------------------
loss: 0.054476  [    0/71701]
loss: 0.076579  [ 6400/71701]
loss: 0.012679  [12800/71701]
loss: 0.063964  [19200/71701]
loss: 0.047306  [25600/71701]
loss: 0.022168  [32000/71701]
loss: 0.143773  [38400/71701]
loss: 0.030141  [44800/71701]
loss: 0.051918  [51200/71701]
loss: 0.048489  [57600/71701]
loss: 0.120118  [64000/71701]
loss: 0.024379  [70400/71701]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.074189 

Epoch 15
-------------------------------
loss: 0.102481  [    0/71701]
loss: 0.068130  [ 6400/71701]
loss: 0.023016  [12800/71701]
loss: 0.014457  [19200/71701]
loss: 0.143251  [25600/71701]
loss: 0.038811  [32000/71701]
loss: 0.005347  [38400/71701]
loss: 0.013983  [44800/71701]
loss: 0.101129  [51200/71701]
loss: 0.058155  [57600/71701]
loss: 0.103564  [64000/71701]
loss: 0.004695  [70400/71701]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.080093 

Epoch 16
-------------------------------
loss: 0.019587  [    0/71701]
loss: 0.086342  [ 6400/71701]
loss: 0.020547  [12800/71701]
loss: 0.045854  [19200/71701]
loss: 0.015951  [25600/71701]
loss: 0.015863  [32000/71701]
loss: 0.044067  [38400/71701]
loss: 0.097021  [44800/71701]
loss: 0.091735  [51200/71701]
loss: 0.031409  [57600/71701]
loss: 0.044086  [64000/71701]
loss: 0.041171  [70400/71701]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.069675 

Epoch 17
-------------------------------
loss: 0.044230  [    0/71701]
loss: 0.056099  [ 6400/71701]
loss: 0.050211  [12800/71701]
loss: 0.067709  [19200/71701]
loss: 0.075312  [25600/71701]
loss: 0.089265  [32000/71701]
loss: 0.045102  [38400/71701]
loss: 0.056405  [44800/71701]
loss: 0.055020  [51200/71701]
loss: 0.135478  [57600/71701]
loss: 0.086570  [64000/71701]
loss: 0.013256  [70400/71701]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.066477 

Epoch 18
-------------------------------
loss: 0.056758  [    0/71701]
loss: 0.079721  [ 6400/71701]
loss: 0.061830  [12800/71701]
loss: 0.039217  [19200/71701]
loss: 0.051270  [25600/71701]
loss: 0.157695  [32000/71701]
loss: 0.048746  [38400/71701]
loss: 0.023162  [44800/71701]
loss: 0.033156  [51200/71701]
loss: 0.035183  [57600/71701]
loss: 0.046158  [64000/71701]
loss: 0.106690  [70400/71701]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.067944 

Epoch 19
-------------------------------
loss: 0.005311  [    0/71701]
loss: 0.655549  [ 6400/71701]
loss: 0.012934  [12800/71701]
loss: 0.092626  [19200/71701]
loss: 0.041438  [25600/71701]
loss: 0.039727  [32000/71701]
loss: 0.014854  [38400/71701]
loss: 0.019524  [44800/71701]
loss: 0.050607  [51200/71701]
loss: 0.216262  [57600/71701]
loss: 0.066592  [64000/71701]
loss: 0.176719  [12800/69546]
loss: 0.123391  [19200/69546]
loss: 0.104617  [25600/69546]
loss: 0.102220  [32000/69546]
loss: 0.125456  [38400/69546]
loss: 0.088809  [44800/69546]
loss: 0.082910  [51200/69546]
loss: 0.157419  [57600/69546]
loss: 0.249808  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.123831 

Epoch 44
-------------------------------
loss: 0.136195  [    0/69546]
loss: 0.053907  [ 6400/69546]
loss: 0.103411  [12800/69546]
loss: 0.241934  [19200/69546]
loss: 0.187344  [25600/69546]
loss: 0.138084  [32000/69546]
loss: 0.220851  [38400/69546]
loss: 0.142380  [44800/69546]
loss: 0.163791  [51200/69546]
loss: 0.070054  [57600/69546]
loss: 0.068607  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.123773 

Epoch 45
-------------------------------
loss: 0.116991  [    0/69546]
loss: 0.103605  [ 6400/69546]
loss: 0.163497  [12800/69546]
loss: 0.045973  [19200/69546]
loss: 0.109532  [25600/69546]
loss: 0.038865  [32000/69546]
loss: 0.135743  [38400/69546]
loss: 0.075079  [44800/69546]
loss: 0.148842  [51200/69546]
loss: 0.179647  [57600/69546]
loss: 0.065856  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.122442 

Epoch 46
-------------------------------
loss: 0.071645  [    0/69546]
loss: 0.134593  [ 6400/69546]
loss: 0.044536  [12800/69546]
loss: 0.153057  [19200/69546]
loss: 0.061935  [25600/69546]
loss: 0.104222  [32000/69546]
loss: 0.156026  [38400/69546]
loss: 0.124566  [44800/69546]
loss: 0.130078  [51200/69546]
loss: 0.137963  [57600/69546]
loss: 0.068666  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.125914 

Epoch 47
-------------------------------
loss: 0.060913  [    0/69546]
loss: 0.051152  [ 6400/69546]
loss: 0.090373  [12800/69546]
loss: 0.151170  [19200/69546]
loss: 0.111189  [25600/69546]
loss: 0.045520  [32000/69546]
loss: 0.046679  [38400/69546]
loss: 0.093989  [44800/69546]
loss: 0.086736  [51200/69546]
loss: 0.128922  [57600/69546]
loss: 0.031515  [64000/69546]
Test Error: 
 Accuracy: 94.9%, Avg loss: 0.134524 

Epoch 48
-------------------------------
loss: 0.046251  [    0/69546]
loss: 0.112554  [ 6400/69546]
loss: 0.051579  [12800/69546]
loss: 0.145086  [19200/69546]
loss: 0.080976  [25600/69546]
loss: 0.109637  [32000/69546]
loss: 0.085131  [38400/69546]
loss: 0.121557  [44800/69546]
loss: 0.053614  [51200/69546]
loss: 0.068301  [57600/69546]
loss: 0.174662  [64000/69546]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.137668 

Epoch 49
-------------------------------
loss: 0.168241  [    0/69546]
loss: 0.143686  [ 6400/69546]
loss: 0.120814  [12800/69546]
loss: 0.090962  [19200/69546]
loss: 0.227301  [25600/69546]
loss: 0.141931  [32000/69546]
loss: 0.262118  [38400/69546]
loss: 0.076097  [44800/69546]
loss: 0.045974  [51200/69546]
loss: 0.193609  [57600/69546]
loss: 0.156304  [64000/69546]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.125300 

Epoch 50
-------------------------------
loss: 0.098730  [    0/69546]
loss: 0.130717  [ 6400/69546]
loss: 0.122861  [12800/69546]
loss: 0.040978  [19200/69546]
loss: 0.085669  [25600/69546]
loss: 0.134808  [32000/69546]
loss: 0.065200  [38400/69546]
loss: 0.120331  [44800/69546]
loss: 0.027403  [51200/69546]
loss: 0.105936  [57600/69546]
loss: 0.230072  [64000/69546]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.126381 

Epoch 1
-------------------------------
loss: 0.651564  [    0/70678]
loss: 0.253324  [ 6400/70678]
loss: 0.247151  [12800/70678]
loss: 0.115023  [19200/70678]
loss: 0.119895  [25600/70678]
loss: 0.141266  [32000/70678]
loss: 0.101232  [38400/70678]
loss: 0.175929  [44800/70678]
loss: 0.214899  [51200/70678]
loss: 0.215945  [57600/70678]
loss: 0.175045  [64000/70678]
loss: 0.121194  [70400/70678]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.130288 

Epoch 2
-------------------------------
loss: 0.204308  [    0/70678]
loss: 0.192844  [ 6400/70678]
loss: 0.187630  [12800/70678]
loss: 0.193425  [19200/70678]
loss: 0.147720  [25600/70678]
loss: 0.104958  [32000/70678]
loss: 0.122104  [38400/70678]
loss: 0.114247  [44800/70678]
loss: 0.105501  [51200/70678]
loss: 0.163123  [57600/70678]
loss: 0.153175  [64000/70678]
loss: 0.148060  [70400/70678]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.109277 

Epoch 3
-------------------------------
loss: 0.141349  [    0/70678]
loss: 0.073350  [ 6400/70678]
loss: 0.087944  [12800/70678]
loss: 0.116201  [19200/70678]
loss: 0.209461  [25600/70678]
loss: 0.163045  [32000/70678]
loss: 0.125902  [38400/70678]
loss: 0.051397  [44800/70678]
loss: 0.168668  [51200/70678]
loss: 0.118330  [57600/70678]
loss: 0.077372  [64000/70678]
loss: 0.155518  [70400/70678]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.107410 

Epoch 4
-------------------------------
loss: 0.049008  [    0/70678]
loss: 0.110075  [ 6400/70678]
loss: 0.065599  [12800/70678]
loss: 0.137047  [19200/70678]
loss: 0.096734  [25600/70678]
loss: 0.164228  [32000/70678]
loss: 0.060636  [38400/70678]
loss: 0.068596  [44800/70678]
loss: 0.056250  [51200/70678]
loss: 0.040648  [57600/70678]
loss: 0.081063  [64000/70678]
loss: 0.115587  [70400/70678]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.113757 

Epoch 5
-------------------------------
loss: 0.121044  [    0/70678]
loss: 0.100186  [ 6400/70678]
loss: 0.107507  [12800/70678]
loss: 0.162474  [19200/70678]
loss: 0.104651  [25600/70678]
loss: 0.083029  [32000/70678]
loss: 0.156842  [38400/70678]
loss: 0.225627  [44800/70678]
loss: 0.107591  [51200/70678]
loss: 0.138616  [57600/70678]
loss: 0.071702  [64000/70678]
loss: 0.103124  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.098199 

Epoch 6
-------------------------------
loss: 0.058903  [    0/70678]
loss: 0.073897  [ 6400/70678]
loss: 0.069014  [12800/70678]
loss: 0.250083  [19200/70678]
loss: 0.190775  [25600/70678]
loss: 0.094853  [32000/70678]
loss: 0.039883  [38400/70678]
loss: 0.094487  [44800/70678]
loss: 0.052040  [51200/70678]
loss: 0.112473  [57600/70678]
loss: 0.148007  [64000/70678]
loss: 0.091652  [70400/70678]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.103947 

Epoch 7
-------------------------------
loss: 0.042035  [    0/70678]
loss: 0.115931  [ 6400/70678]
loss: 0.096793  [12800/70678]
loss: 0.104148  [19200/70678]
loss: 0.096462  [25600/70678]
loss: 0.070613  [32000/70678]
loss: 0.084932  [38400/70678]
loss: 0.076705  [44800/70678]
loss: 0.049683  [51200/70678]
loss: 0.052900  [57600/70678]
loss: 0.235348  [64000/70678]
loss: 0.182996  [70400/70678]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.097008 

Epoch 8
-------------------------------
loss: 0.046754  [    0/70678]
loss: 0.133307  [ 6400/70678]
loss: 0.079810  [12800/70678]
loss: 0.089257  [19200/70678]
loss: 0.087554  [25600/70678]
loss: 0.090241  [32000/70678]
loss: 0.149898  [38400/70678]
loss: 0.069155  [44800/70678]
loss: 0.105425  [51200/70678]
loss: 0.187941  [57600/70678]
loss: 0.116734  [64000/70678]
loss: 0.034587  [70400/70678]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.086948 

Epoch 9
-------------------------------
loss: 0.037857  [    0/70678]
loss: 0.122901  [ 6400/70678]
loss: 0.008495  [12800/70678]
loss: 0.022818  [19200/70678]
loss: 0.124624  [25600/70678]
loss: 0.055815  [32000/70678]
loss: 0.107046  [38400/70678]
loss: 0.082868  [44800/70678]
loss: 0.159780  [51200/70678]
loss: 0.092493  [57600/70678]
loss: 0.046530  [64000/70678]
loss: 0.162470  [70400/70678]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.097309 

Epoch 10
-------------------------------
loss: 0.091973  [    0/70678]
loss: 0.086378  [ 6400/70678]
loss: 0.062010  [12800/70678]
loss: 0.055328  [19200/70678]
loss: 0.174476  [25600/70678]
loss: 0.131798  [32000/70678]
loss: 0.158182  [38400/70678]
loss: 0.148154  [44800/70678]
loss: 0.121604  [51200/70678]
loss: 0.082115  [57600/70678]
loss: 0.067432  [64000/70678]
loss: 0.059321  [70400/70678]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.090438 

Epoch 11
-------------------------------
loss: 0.066016  [    0/70678]
loss: 0.052962  [ 6400/70678]
loss: 0.131389  [12800/70678]
loss: 0.053765  [19200/70678]
loss: 0.107112  [25600/70678]
loss: 0.073473  [32000/70678]
loss: 0.201664  [38400/70678]
loss: 0.054306  [44800/70678]
loss: 0.047076  [51200/70678]
loss: 0.093620  [57600/70678]
loss: 0.020764  [64000/70678]
loss: 0.091028  [ 6400/70535]
loss: 0.286563  [12800/70535]
loss: 0.100561  [19200/70535]
loss: 0.274327  [25600/70535]
loss: 0.157602  [32000/70535]
loss: 0.115365  [38400/70535]
loss: 0.179311  [44800/70535]
loss: 0.212069  [51200/70535]
loss: 0.174025  [57600/70535]
loss: 0.167874  [64000/70535]
loss: 0.061445  [70400/70535]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.182550 

Epoch 38
-------------------------------
loss: 0.194260  [    0/70535]
loss: 0.108566  [ 6400/70535]
loss: 0.155013  [12800/70535]
loss: 0.117670  [19200/70535]
loss: 0.185198  [25600/70535]
loss: 0.268882  [32000/70535]
loss: 0.196550  [38400/70535]
loss: 0.168992  [44800/70535]
loss: 0.130434  [51200/70535]
loss: 0.150028  [57600/70535]
loss: 0.240954  [64000/70535]
loss: 0.142275  [70400/70535]
Test Error: 
 Accuracy: 90.1%, Avg loss: 0.270344 

Epoch 39
-------------------------------
loss: 0.506632  [    0/70535]
loss: 0.125962  [ 6400/70535]
loss: 0.063863  [12800/70535]
loss: 0.223783  [19200/70535]
loss: 0.160918  [25600/70535]
loss: 0.142236  [32000/70535]
loss: 0.102320  [38400/70535]
loss: 0.159957  [44800/70535]
loss: 0.087097  [51200/70535]
loss: 0.162325  [57600/70535]
loss: 0.074293  [64000/70535]
loss: 0.169722  [70400/70535]
Test Error: 
 Accuracy: 91.1%, Avg loss: 0.207192 

Epoch 40
-------------------------------
loss: 0.164681  [    0/70535]
loss: 0.186112  [ 6400/70535]
loss: 0.334297  [12800/70535]
loss: 0.161923  [19200/70535]
loss: 0.324463  [25600/70535]
loss: 0.243980  [32000/70535]
loss: 0.250957  [38400/70535]
loss: 0.173454  [44800/70535]
loss: 0.258627  [51200/70535]
loss: 0.146199  [57600/70535]
loss: 0.101975  [64000/70535]
loss: 0.123228  [70400/70535]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.178902 

Epoch 41
-------------------------------
loss: 0.285052  [    0/70535]
loss: 0.152797  [ 6400/70535]
loss: 0.151518  [12800/70535]
loss: 0.220017  [19200/70535]
loss: 0.271981  [25600/70535]
loss: 0.156271  [32000/70535]
loss: 0.178830  [38400/70535]
loss: 0.248841  [44800/70535]
loss: 0.139199  [51200/70535]
loss: 0.136827  [57600/70535]
loss: 0.169041  [64000/70535]
loss: 0.195795  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.184402 

Epoch 42
-------------------------------
loss: 0.100812  [    0/70535]
loss: 0.138399  [ 6400/70535]
loss: 0.115343  [12800/70535]
loss: 0.105594  [19200/70535]
loss: 0.207159  [25600/70535]
loss: 0.206120  [32000/70535]
loss: 0.140850  [38400/70535]
loss: 0.044389  [44800/70535]
loss: 0.202943  [51200/70535]
loss: 0.135368  [57600/70535]
loss: 0.085428  [64000/70535]
loss: 0.211749  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.182331 

Epoch 43
-------------------------------
loss: 0.177004  [    0/70535]
loss: 0.116995  [ 6400/70535]
loss: 0.178160  [12800/70535]
loss: 0.142153  [19200/70535]
loss: 0.175733  [25600/70535]
loss: 0.133694  [32000/70535]
loss: 0.082319  [38400/70535]
loss: 0.126059  [44800/70535]
loss: 0.152906  [51200/70535]
loss: 0.106838  [57600/70535]
loss: 0.154965  [64000/70535]
loss: 0.185054  [70400/70535]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.170734 

Epoch 44
-------------------------------
loss: 0.113206  [    0/70535]
loss: 0.304803  [ 6400/70535]
loss: 0.174326  [12800/70535]
loss: 0.180273  [19200/70535]
loss: 0.200600  [25600/70535]
loss: 0.258082  [32000/70535]
loss: 0.220422  [38400/70535]
loss: 0.138752  [44800/70535]
loss: 0.125329  [51200/70535]
loss: 0.179185  [57600/70535]
loss: 0.244136  [64000/70535]
loss: 0.148766  [70400/70535]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.179200 

Epoch 45
-------------------------------
loss: 0.188282  [    0/70535]
loss: 0.075147  [ 6400/70535]
loss: 0.209632  [12800/70535]
loss: 0.120238  [19200/70535]
loss: 0.150204  [25600/70535]
loss: 0.107328  [32000/70535]
loss: 0.092538  [38400/70535]
loss: 0.126034  [44800/70535]
loss: 0.112027  [51200/70535]
loss: 0.208203  [57600/70535]
loss: 0.128052  [64000/70535]
loss: 0.176517  [70400/70535]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.182900 

Epoch 46
-------------------------------
loss: 0.162414  [    0/70535]
loss: 0.163706  [ 6400/70535]
loss: 0.094034  [12800/70535]
loss: 0.102507  [19200/70535]
loss: 0.118882  [25600/70535]
loss: 0.204180  [32000/70535]
loss: 1.203461  [38400/70535]
loss: 0.136365  [44800/70535]
loss: 0.138259  [51200/70535]
loss: 0.199756  [57600/70535]
loss: 0.119785  [64000/70535]
loss: 0.148274  [70400/70535]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.187126 

Epoch 47
-------------------------------
loss: 0.183836  [    0/70535]
loss: 0.128186  [ 6400/70535]
loss: 0.107375  [12800/70535]
loss: 0.074646  [19200/70535]
loss: 0.173327  [25600/70535]
loss: 0.094597  [32000/70535]
loss: 0.075572  [38400/70535]
loss: 0.133863  [44800/70535]
loss: 0.105699  [51200/70535]
loss: 0.211710  [57600/70535]
loss: 0.216079  [64000/70535]
loss: 0.120839  [70400/70535]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.199028 

Epoch 48
-------------------------------
loss: 0.164279  [    0/70535]
loss: 0.156459  [ 6400/70535]
loss: 0.102046  [12800/70535]
loss: 0.154125  [19200/70535]
loss: 0.092019  [25600/70535]
loss: 0.130641  [32000/70535]
loss: 0.109590  [38400/70535]
loss: 0.287412  [44800/70535]
loss: 0.220234  [51200/70535]
loss: 0.257185  [57600/70535]
loss: 0.266169  [64000/70535]
loss: 0.093598  [70400/70535]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.222661 

Epoch 49
-------------------------------
loss: 0.170588  [    0/70535]
loss: 0.213557  [ 6400/70535]
loss: 0.287133  [12800/70535]
loss: 0.172616  [19200/70535]
loss: 0.139333  [25600/70535]
loss: 0.105791  [32000/70535]
loss: 0.131791  [38400/70535]
loss: 0.144188  [44800/70535]
loss: 0.087222  [51200/70535]
loss: 0.123366  [57600/70535]
loss: 0.130377  [64000/70535]
loss: 0.189035  [70400/70535]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.218795 

Epoch 50
-------------------------------
loss: 0.178556  [    0/70535]
loss: 0.115757  [ 6400/70535]
loss: 0.101998  [12800/70535]
loss: 0.083444  [19200/70535]
loss: 0.288400  [25600/70535]
loss: 0.165210  [32000/70535]
loss: 0.208082  [38400/70535]
loss: 0.185638  [44800/70535]
loss: 0.132487  [51200/70535]
loss: 0.198488  [57600/70535]
loss: 0.131505  [64000/70535]
loss: 0.217268  [70400/70535]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.185468 

Epoch 1
-------------------------------
loss: 0.747324  [    0/69845]
loss: 0.283631  [ 6400/69845]
loss: 0.190904  [12800/69845]
loss: 0.309026  [19200/69845]
loss: 0.312983  [25600/69845]
loss: 0.294085  [32000/69845]
loss: 0.174571  [38400/69845]
loss: 0.220284  [44800/69845]
loss: 0.195126  [51200/69845]
loss: 0.153749  [57600/69845]
loss: 0.195004  [64000/69845]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.202183 

Epoch 2
-------------------------------
loss: 0.303265  [    0/69845]
loss: 0.325864  [ 6400/69845]
loss: 0.307659  [12800/69845]
loss: 0.310950  [19200/69845]
loss: 0.170782  [25600/69845]
loss: 0.222594  [32000/69845]
loss: 0.208736  [38400/69845]
loss: 0.393804  [44800/69845]
loss: 0.231226  [51200/69845]
loss: 0.169186  [57600/69845]
loss: 0.254532  [64000/69845]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.184775 

Epoch 3
-------------------------------
loss: 0.263057  [    0/69845]
loss: 0.289129  [ 6400/69845]
loss: 0.185491  [12800/69845]
loss: 0.443721  [19200/69845]
loss: 0.213840  [25600/69845]
loss: 0.236495  [32000/69845]
loss: 0.158154  [38400/69845]
loss: 0.235868  [44800/69845]
loss: 0.206328  [51200/69845]
loss: 0.231826  [57600/69845]
loss: 0.172545  [64000/69845]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.193651 

Epoch 4
-------------------------------
loss: 0.239732  [    0/69845]
loss: 0.236502  [ 6400/69845]
loss: 0.283436  [12800/69845]
loss: 0.229028  [19200/69845]
loss: 0.185124  [25600/69845]
loss: 0.134144  [32000/69845]
loss: 0.198914  [38400/69845]
loss: 0.224704  [44800/69845]
loss: 0.203763  [51200/69845]
loss: 0.190266  [57600/69845]
loss: 0.210659  [64000/69845]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.181203 

Epoch 5
-------------------------------
loss: 0.148365  [    0/69845]
loss: 0.300774  [ 6400/69845]
loss: 0.140660  [12800/69845]
loss: 0.174537  [19200/69845]
loss: 0.268958  [25600/69845]
loss: 0.157815  [32000/69845]
2022/09/20 20:57:50 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.051900 

Epoch 5
-------------------------------
loss: 0.004604  [    0/72605]
loss: 0.056846  [ 6400/72605]
loss: 0.001296  [12800/72605]
loss: 0.022840  [19200/72605]
loss: 0.076663  [25600/72605]
loss: 0.024869  [32000/72605]
loss: 0.000709  [38400/72605]
loss: 0.001309  [44800/72605]
loss: 0.002047  [51200/72605]
loss: 0.118416  [57600/72605]
loss: 0.085045  [64000/72605]
loss: 0.007144  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.043279 

Epoch 6
-------------------------------
loss: 0.028123  [    0/72605]
loss: 0.004046  [ 6400/72605]
loss: 0.030535  [12800/72605]
loss: 0.002058  [19200/72605]
loss: 0.005546  [25600/72605]
loss: 0.005194  [32000/72605]
loss: 0.073046  [38400/72605]
loss: 0.005557  [44800/72605]
loss: 0.002176  [51200/72605]
loss: 0.050587  [57600/72605]
loss: 0.012664  [64000/72605]
loss: 0.023400  [70400/72605]
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.040486 

Epoch 7
-------------------------------
loss: 0.054058  [    0/72605]
loss: 0.001863  [ 6400/72605]
loss: 0.133946  [12800/72605]
loss: 0.047686  [19200/72605]
loss: 0.021840  [25600/72605]
loss: 0.000595  [32000/72605]
loss: 0.030329  [38400/72605]
loss: 0.002499  [44800/72605]
loss: 0.009905  [51200/72605]
loss: 0.076848  [57600/72605]
loss: 0.006019  [64000/72605]
loss: 0.032362  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.045622 

Epoch 8
-------------------------------
loss: 0.022576  [    0/72605]
loss: 0.099766  [ 6400/72605]
loss: 0.102018  [12800/72605]
loss: 0.135840  [19200/72605]
loss: 0.004925  [25600/72605]
loss: 0.024057  [32000/72605]
loss: 0.004443  [38400/72605]
loss: 0.000991  [44800/72605]
loss: 0.008114  [51200/72605]
loss: 0.072474  [57600/72605]
loss: 0.027596  [64000/72605]
loss: 0.053161  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.041050 

Epoch 9
-------------------------------
loss: 0.021157  [    0/72605]
loss: 0.010441  [ 6400/72605]
loss: 0.006864  [12800/72605]
loss: 0.008484  [19200/72605]
loss: 0.000311  [25600/72605]
loss: 0.055915  [32000/72605]
loss: 0.091093  [38400/72605]
loss: 0.017732  [44800/72605]
loss: 0.020747  [51200/72605]
loss: 0.033901  [57600/72605]
loss: 0.028757  [64000/72605]
loss: 0.031107  [70400/72605]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.057873 

Epoch 10
-------------------------------
loss: 0.005832  [    0/72605]
loss: 0.005211  [ 6400/72605]
loss: 0.016799  [12800/72605]
loss: 0.007826  [19200/72605]
loss: 0.007015  [25600/72605]
loss: 0.015909  [32000/72605]
loss: 0.053787  [38400/72605]
loss: 0.032385  [44800/72605]
loss: 0.127850  [51200/72605]
loss: 0.011197  [57600/72605]
loss: 0.029693  [64000/72605]
loss: 0.002497  [70400/72605]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.046298 

Epoch 11
-------------------------------
loss: 0.003428  [    0/72605]
loss: 0.003528  [ 6400/72605]
loss: 0.000396  [12800/72605]
loss: 0.008317  [19200/72605]
loss: 0.050135  [25600/72605]
loss: 0.182725  [32000/72605]
loss: 0.012198  [38400/72605]
loss: 0.006947  [44800/72605]
loss: 0.022700  [51200/72605]
loss: 0.003894  [57600/72605]
loss: 0.097886  [64000/72605]
loss: 0.057041  [70400/72605]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.049845 

Epoch 12
-------------------------------
loss: 0.001751  [    0/72605]
loss: 0.014210  [ 6400/72605]
loss: 0.006200  [12800/72605]
loss: 0.026307  [19200/72605]
loss: 0.074511  [25600/72605]
loss: 0.001469  [32000/72605]
loss: 0.003344  [38400/72605]
loss: 0.003829  [44800/72605]
loss: 0.094049  [51200/72605]
loss: 0.000292  [57600/72605]
loss: 0.000451  [64000/72605]
loss: 0.024782  [70400/72605]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.043762 

Epoch 13
-------------------------------
loss: 0.006421  [    0/72605]
loss: 0.010348  [ 6400/72605]
loss: 0.004164  [12800/72605]
loss: 0.002388  [19200/72605]
loss: 0.003481  [25600/72605]
loss: 0.004748  [32000/72605]
loss: 0.035713  [38400/72605]
loss: 0.007493  [44800/72605]
loss: 0.034488  [51200/72605]
loss: 0.001976  [57600/72605]
loss: 0.012319  [64000/72605]
loss: 0.000868  [70400/72605]
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.054177 

Epoch 14
-------------------------------
loss: 0.075511  [    0/72605]
loss: 0.001387  [ 6400/72605]
loss: 0.001121  [12800/72605]
loss: 0.001504  [19200/72605]
loss: 0.002065  [25600/72605]
loss: 0.001933  [32000/72605]
loss: 0.244291  [38400/72605]
loss: 0.009194  [44800/72605]
loss: 0.007002  [51200/72605]
loss: 0.002689  [57600/72605]
loss: 0.001374  [64000/72605]
loss: 0.003220  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.047641 

Epoch 15
-------------------------------
loss: 0.013959  [    0/72605]
loss: 0.007513  [ 6400/72605]
loss: 0.001878  [12800/72605]
loss: 0.074856  [19200/72605]
loss: 0.001312  [25600/72605]
loss: 0.008501  [32000/72605]
loss: 0.057911  [38400/72605]
loss: 0.052632  [44800/72605]
loss: 0.000917  [51200/72605]
loss: 0.078994  [57600/72605]
loss: 0.012596  [64000/72605]
loss: 0.027840  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.053319 

Epoch 16
-------------------------------
loss: 0.007590  [    0/72605]
loss: 0.003484  [ 6400/72605]
loss: 0.050334  [12800/72605]
loss: 0.010925  [19200/72605]
loss: 0.013886  [25600/72605]
loss: 0.006757  [32000/72605]
loss: 0.021351  [38400/72605]
loss: 0.005105  [44800/72605]
loss: 0.000537  [51200/72605]
loss: 0.003468  [57600/72605]
loss: 0.003903  [64000/72605]
loss: 0.006648  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.045040 

Epoch 17
-------------------------------
loss: 0.085491  [    0/72605]
loss: 0.074870  [ 6400/72605]
loss: 0.001349  [12800/72605]
loss: 0.003646  [19200/72605]
loss: 0.022771  [25600/72605]
loss: 0.009288  [32000/72605]
loss: 0.000355  [38400/72605]
loss: 0.003802  [44800/72605]
loss: 0.001538  [51200/72605]
loss: 0.000283  [57600/72605]
loss: 0.014307  [64000/72605]
loss: 0.010452  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.045208 

Epoch 18
-------------------------------
loss: 0.001387  [    0/72605]
loss: 0.016418  [ 6400/72605]
loss: 0.036470  [12800/72605]
loss: 0.068752  [19200/72605]
loss: 0.022862  [25600/72605]
loss: 0.007702  [32000/72605]
loss: 0.005836  [38400/72605]
loss: 0.024770  [44800/72605]
loss: 0.001298  [51200/72605]
loss: 0.044390  [57600/72605]
loss: 0.062292  [64000/72605]
loss: 0.006275  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.051040 

Epoch 19
-------------------------------
loss: 0.003475  [    0/72605]
loss: 0.023984  [ 6400/72605]
loss: 0.004260  [12800/72605]
loss: 0.001418  [19200/72605]
loss: 0.000300  [25600/72605]
loss: 0.000088  [32000/72605]
loss: 0.003403  [38400/72605]
loss: 0.006941  [44800/72605]
loss: 0.000173  [51200/72605]
loss: 0.012060  [57600/72605]
loss: 0.000373  [64000/72605]
loss: 0.000652  [70400/72605]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.047563 

Epoch 20
-------------------------------
loss: 0.017414  [    0/72605]
loss: 0.002127  [ 6400/72605]
loss: 0.004332  [12800/72605]
loss: 0.005525  [19200/72605]
loss: 0.010565  [25600/72605]
loss: 0.000731  [32000/72605]
loss: 0.018191  [38400/72605]
loss: 0.012811  [44800/72605]
loss: 0.000166  [51200/72605]
loss: 0.006044  [57600/72605]
loss: 0.004233  [64000/72605]
loss: 0.005425  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.050894 

Epoch 21
-------------------------------
loss: 0.074173  [    0/72605]
loss: 0.000076  [ 6400/72605]
loss: 0.001314  [12800/72605]
loss: 0.005438  [19200/72605]
loss: 0.000103  [25600/72605]
loss: 0.011898  [32000/72605]
loss: 0.000246  [38400/72605]
loss: 0.009839  [44800/72605]
loss: 0.000294  [51200/72605]
loss: 0.000418  [57600/72605]
loss: 0.004616  [64000/72605]
loss: 0.004842  [70400/72605]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.061443 

Epoch 22
-------------------------------
loss: 0.004978  [    0/72605]
loss: 0.033301  [ 6400/72605]
loss: 0.006943  [12800/72605]
loss: 0.000323  [19200/72605]
loss: 0.000234  [25600/72605]
loss: 0.000906  [32000/72605]
loss: 0.005245  [38400/72605]
loss: 0.000941  [44800/72605]
loss: 0.068798  [51200/72605]
loss: 0.051328  [57600/72605]
loss: 0.035325  [64000/72605]
loss: 0.009040  [70400/72605]
2022/09/20 20:59:28 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.195859  [12800/69987]
loss: 0.212055  [19200/69987]
loss: 0.314651  [25600/69987]
loss: 0.195314  [32000/69987]
loss: 0.175414  [38400/69987]
loss: 0.101346  [44800/69987]
loss: 0.149686  [51200/69987]
loss: 0.295823  [57600/69987]
loss: 0.127715  [64000/69987]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.204604 

Epoch 6
-------------------------------
loss: 0.180369  [    0/69987]
loss: 0.147619  [ 6400/69987]
loss: 0.154914  [12800/69987]
loss: 0.187582  [19200/69987]
loss: 0.318457  [25600/69987]
loss: 0.152481  [32000/69987]
loss: 0.157690  [38400/69987]
loss: 0.145217  [44800/69987]
loss: 0.183292  [51200/69987]
loss: 0.165355  [57600/69987]
loss: 0.138999  [64000/69987]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.205864 

Epoch 7
-------------------------------
loss: 0.118282  [    0/69987]
loss: 0.125134  [ 6400/69987]
loss: 0.079820  [12800/69987]
loss: 0.167735  [19200/69987]
loss: 0.165237  [25600/69987]
loss: 0.282626  [32000/69987]
loss: 0.171042  [38400/69987]
loss: 0.311085  [44800/69987]
loss: 0.145499  [51200/69987]
loss: 0.115978  [57600/69987]
loss: 0.076363  [64000/69987]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.201318 

Epoch 8
-------------------------------
loss: 0.221629  [    0/69987]
loss: 0.124359  [ 6400/69987]
loss: 0.316280  [12800/69987]
loss: 0.119531  [19200/69987]
loss: 0.111261  [25600/69987]
loss: 0.190129  [32000/69987]
loss: 0.200952  [38400/69987]
loss: 0.303684  [44800/69987]
loss: 0.195523  [51200/69987]
loss: 0.084363  [57600/69987]
loss: 0.178288  [64000/69987]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.204405 

Epoch 9
-------------------------------
loss: 0.186152  [    0/69987]
loss: 0.101918  [ 6400/69987]
loss: 0.213056  [12800/69987]
loss: 0.086896  [19200/69987]
loss: 0.238354  [25600/69987]
loss: 0.094561  [32000/69987]
loss: 0.165599  [38400/69987]
loss: 0.143145  [44800/69987]
loss: 0.168384  [51200/69987]
loss: 0.139910  [57600/69987]
loss: 0.162828  [64000/69987]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.188542 

Epoch 10
-------------------------------
loss: 0.308879  [    0/69987]
loss: 0.153184  [ 6400/69987]
loss: 0.159626  [12800/69987]
loss: 0.078323  [19200/69987]
loss: 0.224326  [25600/69987]
loss: 0.117202  [32000/69987]
loss: 0.239120  [38400/69987]
loss: 0.225056  [44800/69987]
loss: 0.094697  [51200/69987]
loss: 0.241914  [57600/69987]
loss: 0.101723  [64000/69987]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.201530 

Epoch 11
-------------------------------
loss: 0.099503  [    0/69987]
loss: 0.132281  [ 6400/69987]
loss: 0.175482  [12800/69987]
loss: 0.105423  [19200/69987]
loss: 0.177949  [25600/69987]
loss: 0.163076  [32000/69987]
loss: 0.188626  [38400/69987]
loss: 0.243657  [44800/69987]
loss: 0.121728  [51200/69987]
loss: 0.183044  [57600/69987]
loss: 0.275991  [64000/69987]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.194662 

Epoch 12
-------------------------------
loss: 0.301026  [    0/69987]
loss: 0.267809  [ 6400/69987]
loss: 0.345108  [12800/69987]
loss: 0.126057  [19200/69987]
loss: 0.182427  [25600/69987]
loss: 0.156987  [32000/69987]
loss: 0.188067  [38400/69987]
loss: 0.128659  [44800/69987]
loss: 0.127189  [51200/69987]
loss: 0.132242  [57600/69987]
loss: 0.164682  [64000/69987]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.186739 

Epoch 13
-------------------------------
loss: 0.169252  [    0/69987]
loss: 0.162442  [ 6400/69987]
loss: 0.138919  [12800/69987]
loss: 0.120261  [19200/69987]
loss: 0.204965  [25600/69987]
loss: 0.126225  [32000/69987]
loss: 0.140439  [38400/69987]
loss: 0.185936  [44800/69987]
loss: 0.168965  [51200/69987]
loss: 0.181873  [57600/69987]
loss: 0.241011  [64000/69987]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.192787 

Epoch 14
-------------------------------
loss: 0.120692  [    0/69987]
loss: 0.117742  [ 6400/69987]
loss: 0.102780  [12800/69987]
loss: 0.079188  [19200/69987]
loss: 0.177116  [25600/69987]
loss: 0.317354  [32000/69987]
loss: 0.120000  [38400/69987]
loss: 0.069174  [44800/69987]
loss: 0.178387  [51200/69987]
loss: 0.067744  [57600/69987]
loss: 0.160501  [64000/69987]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.194550 

Epoch 15
-------------------------------
loss: 0.179591  [    0/69987]
loss: 0.125459  [ 6400/69987]
loss: 0.255353  [12800/69987]
loss: 0.100201  [19200/69987]
loss: 0.145404  [25600/69987]
loss: 0.094289  [32000/69987]
loss: 0.299477  [38400/69987]
loss: 0.165900  [44800/69987]
loss: 0.132942  [51200/69987]
loss: 0.261395  [57600/69987]
loss: 0.066593  [64000/69987]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.195362 

Epoch 16
-------------------------------
loss: 0.245621  [    0/69987]
loss: 0.137000  [ 6400/69987]
loss: 0.195140  [12800/69987]
loss: 0.153643  [19200/69987]
loss: 0.199817  [25600/69987]
loss: 0.135264  [32000/69987]
loss: 0.178438  [38400/69987]
loss: 0.093708  [44800/69987]
loss: 0.183069  [51200/69987]
loss: 0.130344  [57600/69987]
loss: 0.117881  [64000/69987]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.184127 

Epoch 17
-------------------------------
loss: 0.161931  [    0/69987]
loss: 0.159442  [ 6400/69987]
loss: 0.218170  [12800/69987]
loss: 0.118096  [19200/69987]
loss: 0.117925  [25600/69987]
loss: 0.127799  [32000/69987]
loss: 0.152071  [38400/69987]
loss: 0.157390  [44800/69987]
loss: 0.128676  [51200/69987]
loss: 0.197178  [57600/69987]
loss: 0.132535  [64000/69987]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.196529 

Epoch 18
-------------------------------
loss: 0.193974  [    0/69987]
loss: 0.156321  [ 6400/69987]
loss: 0.141593  [12800/69987]
loss: 0.134651  [19200/69987]
loss: 0.232628  [25600/69987]
loss: 0.118836  [32000/69987]
loss: 0.168213  [38400/69987]
loss: 0.168204  [44800/69987]
loss: 0.106127  [51200/69987]
loss: 0.157807  [57600/69987]
loss: 0.282411  [64000/69987]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.198561 

Epoch 19
-------------------------------
loss: 0.094130  [    0/69987]
loss: 0.184101  [ 6400/69987]
loss: 0.171672  [12800/69987]
loss: 0.167157  [19200/69987]
loss: 0.153022  [25600/69987]
loss: 0.125603  [32000/69987]
loss: 0.107043  [38400/69987]
loss: 0.206756  [44800/69987]
loss: 0.238835  [51200/69987]
loss: 0.219068  [57600/69987]
loss: 0.072767  [64000/69987]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.194103 

Epoch 20
-------------------------------
loss: 0.203327  [    0/69987]
loss: 0.176067  [ 6400/69987]
loss: 0.165728  [12800/69987]
loss: 0.337773  [19200/69987]
loss: 0.084562  [25600/69987]
loss: 0.221439  [32000/69987]
loss: 0.195552  [38400/69987]
loss: 0.218334  [44800/69987]
loss: 0.174155  [51200/69987]
loss: 0.093939  [57600/69987]
loss: 0.199256  [64000/69987]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.190396 

Epoch 21
-------------------------------
loss: 0.145662  [    0/69987]
loss: 0.102915  [ 6400/69987]
loss: 0.100775  [12800/69987]
loss: 0.232724  [19200/69987]
loss: 0.121383  [25600/69987]
loss: 0.256553  [32000/69987]
loss: 0.143799  [38400/69987]
loss: 0.132247  [44800/69987]
loss: 0.176902  [51200/69987]
loss: 0.126553  [57600/69987]
loss: 0.124113  [64000/69987]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.190524 

Epoch 22
-------------------------------
loss: 0.188450  [    0/69987]
loss: 0.077770  [ 6400/69987]
loss: 0.099024  [12800/69987]
loss: 0.134311  [19200/69987]
loss: 0.223713  [25600/69987]
loss: 0.209931  [32000/69987]
loss: 0.192919  [38400/69987]
loss: 0.176885  [44800/69987]
loss: 0.165194  [51200/69987]
loss: 0.162873  [57600/69987]
loss: 0.132512  [64000/69987]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.187808 

Epoch 23
-------------------------------
loss: 0.259913  [    0/69987]
loss: 0.174347  [ 6400/69987]
loss: 0.237500  [12800/69987]
loss: 0.240051  [19200/69987]
loss: 0.241788  [25600/69987]
loss: 0.139032  [32000/69987]
loss: 0.165434  [38400/69987]
loss: 0.153630  [44800/69987]
loss: 0.047087  [51200/69987]
loss: 0.131583  [57600/69987]
loss: 0.137607  [64000/69987]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.187803 

Epoch 24
-------------------------------
loss: 0.158240  [    0/69987]
loss: 0.131182  [ 6400/69987]
loss: 0.101218  [12800/69987]
loss: 0.198822  [19200/69987]
loss: 0.310684  [25600/69987]
loss: 0.183151  [32000/69987]
loss: 0.202179  [38400/69987]
loss: 0.036571  [70400/71157]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.094186 

Epoch 12
-------------------------------
loss: 0.290281  [    0/71157]
loss: 0.088077  [ 6400/71157]
loss: 0.064050  [12800/71157]
loss: 0.189293  [19200/71157]
loss: 0.092844  [25600/71157]
loss: 0.037085  [32000/71157]
loss: 0.125223  [38400/71157]
loss: 0.081740  [44800/71157]
loss: 0.083381  [51200/71157]
loss: 0.217648  [57600/71157]
loss: 0.060678  [64000/71157]
loss: 0.124764  [70400/71157]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095149 

Epoch 13
-------------------------------
loss: 0.027081  [    0/71157]
loss: 0.089008  [ 6400/71157]
loss: 0.068799  [12800/71157]
loss: 0.056787  [19200/71157]
loss: 0.032772  [25600/71157]
loss: 0.130039  [32000/71157]
loss: 0.140519  [38400/71157]
loss: 0.032107  [44800/71157]
loss: 0.077514  [51200/71157]
loss: 0.115566  [57600/71157]
loss: 0.101318  [64000/71157]
loss: 0.081783  [70400/71157]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.091095 

Epoch 14
-------------------------------
loss: 0.014284  [    0/71157]
loss: 0.046760  [ 6400/71157]
loss: 0.089865  [12800/71157]
loss: 0.067104  [19200/71157]
loss: 0.094600  [25600/71157]
loss: 0.208255  [32000/71157]
loss: 0.040571  [38400/71157]
loss: 0.065389  [44800/71157]
loss: 0.106114  [51200/71157]
loss: 0.043818  [57600/71157]
loss: 0.168336  [64000/71157]
loss: 0.081877  [70400/71157]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.094500 

Epoch 15
-------------------------------
loss: 0.030101  [    0/71157]
loss: 0.032037  [ 6400/71157]
loss: 0.137432  [12800/71157]
loss: 0.067236  [19200/71157]
loss: 0.184723  [25600/71157]
loss: 0.011292  [32000/71157]
loss: 0.055594  [38400/71157]
loss: 0.106887  [44800/71157]
loss: 0.054857  [51200/71157]
loss: 0.055243  [57600/71157]
loss: 0.088124  [64000/71157]
loss: 0.049137  [70400/71157]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.097833 

Epoch 16
-------------------------------
loss: 0.130794  [    0/71157]
loss: 0.073881  [ 6400/71157]
loss: 0.075118  [12800/71157]
loss: 0.146608  [19200/71157]
loss: 0.077763  [25600/71157]
loss: 0.082076  [32000/71157]
loss: 0.086196  [38400/71157]
loss: 0.037318  [44800/71157]
loss: 0.015540  [51200/71157]
loss: 0.039645  [57600/71157]
loss: 0.033546  [64000/71157]
loss: 0.074309  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.101123 

Epoch 17
-------------------------------
loss: 0.026485  [    0/71157]
loss: 0.088543  [ 6400/71157]
loss: 0.115320  [12800/71157]
loss: 0.128055  [19200/71157]
loss: 0.059545  [25600/71157]
loss: 0.073905  [32000/71157]
loss: 0.181566  [38400/71157]
loss: 0.138958  [44800/71157]
loss: 0.054403  [51200/71157]
loss: 0.076159  [57600/71157]
loss: 0.146305  [64000/71157]
loss: 0.066332  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.095329 

Epoch 18
-------------------------------
loss: 0.039856  [    0/71157]
loss: 0.044487  [ 6400/71157]
loss: 0.322205  [12800/71157]
loss: 0.147721  [19200/71157]
loss: 0.055214  [25600/71157]
loss: 0.127451  [32000/71157]
loss: 0.130697  [38400/71157]
loss: 0.059229  [44800/71157]
loss: 0.050683  [51200/71157]
loss: 0.052834  [57600/71157]
loss: 0.029756  [64000/71157]
loss: 0.021687  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097089 

Epoch 19
-------------------------------
loss: 0.068224  [    0/71157]
loss: 0.087417  [ 6400/71157]
loss: 0.031672  [12800/71157]
loss: 0.020498  [19200/71157]
loss: 0.087059  [25600/71157]
loss: 0.034932  [32000/71157]
loss: 0.113451  [38400/71157]
loss: 0.087846  [44800/71157]
loss: 0.106671  [51200/71157]
loss: 0.035899  [57600/71157]
loss: 0.037463  [64000/71157]
loss: 0.081859  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.095188 

Epoch 20
-------------------------------
loss: 0.035488  [    0/71157]
loss: 0.059879  [ 6400/71157]
loss: 0.017977  [12800/71157]
loss: 0.060502  [19200/71157]
loss: 0.091410  [25600/71157]
loss: 0.074795  [32000/71157]
loss: 0.104708  [38400/71157]
loss: 0.094644  [44800/71157]
loss: 0.062433  [51200/71157]
loss: 0.054482  [57600/71157]
loss: 0.150875  [64000/71157]
loss: 0.120329  [70400/71157]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.097248 

Epoch 21
-------------------------------
loss: 0.083862  [    0/71157]
loss: 0.122291  [ 6400/71157]
loss: 0.016773  [12800/71157]
loss: 0.079876  [19200/71157]
loss: 0.025604  [25600/71157]
loss: 0.179593  [32000/71157]
loss: 0.056426  [38400/71157]
loss: 0.034462  [44800/71157]
loss: 0.131356  [51200/71157]
loss: 0.027410  [57600/71157]
loss: 0.068307  [64000/71157]
loss: 0.050692  [70400/71157]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101095 

Epoch 22
-------------------------------
loss: 0.029232  [    0/71157]
loss: 0.045231  [ 6400/71157]
loss: 0.046241  [12800/71157]
loss: 0.145644  [19200/71157]
loss: 0.054678  [25600/71157]
loss: 0.050885  [32000/71157]
loss: 0.080882  [38400/71157]
loss: 0.121430  [44800/71157]
loss: 0.111662  [51200/71157]
loss: 0.173121  [57600/71157]
loss: 0.053386  [64000/71157]
loss: 0.085040  [70400/71157]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.092340 

Epoch 23
-------------------------------
loss: 0.026960  [    0/71157]
loss: 0.041299  [ 6400/71157]
loss: 0.078003  [12800/71157]
loss: 0.033443  [19200/71157]
loss: 0.041769  [25600/71157]
loss: 0.054758  [32000/71157]
loss: 0.076792  [38400/71157]
loss: 0.086990  [44800/71157]
loss: 0.077873  [51200/71157]
loss: 0.078982  [57600/71157]
loss: 0.086993  [64000/71157]
loss: 0.043555  [70400/71157]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.096398 

Epoch 24
-------------------------------
loss: 0.037091  [    0/71157]
loss: 0.130432  [ 6400/71157]
loss: 0.029464  [12800/71157]
loss: 0.044673  [19200/71157]
loss: 0.063727  [25600/71157]
loss: 0.098546  [32000/71157]
loss: 0.036100  [38400/71157]
loss: 0.091119  [44800/71157]
loss: 0.075172  [51200/71157]
loss: 0.047520  [57600/71157]
loss: 0.118950  [64000/71157]
loss: 0.095928  [70400/71157]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099615 

Epoch 25
-------------------------------
loss: 0.036800  [    0/71157]
loss: 0.011466  [ 6400/71157]
loss: 0.023456  [12800/71157]
loss: 0.034186  [19200/71157]
loss: 0.042075  [25600/71157]
loss: 0.125781  [32000/71157]
loss: 0.116105  [38400/71157]
loss: 0.096362  [44800/71157]
loss: 0.017354  [51200/71157]
loss: 0.068726  [57600/71157]
loss: 0.039254  [64000/71157]
loss: 0.091262  [70400/71157]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.097932 

Epoch 26
-------------------------------
loss: 0.064964  [    0/71157]
loss: 0.027683  [ 6400/71157]
loss: 0.067883  [12800/71157]
loss: 0.147441  [19200/71157]
loss: 0.070773  [25600/71157]
loss: 0.147692  [32000/71157]
loss: 0.131246  [38400/71157]
loss: 0.044228  [44800/71157]
loss: 0.088458  [51200/71157]
loss: 0.056654  [57600/71157]
loss: 0.224095  [64000/71157]
loss: 0.072048  [70400/71157]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.100472 

Epoch 27
-------------------------------
loss: 0.056401  [    0/71157]
loss: 0.069079  [ 6400/71157]
loss: 0.077672  [12800/71157]
loss: 0.046124  [19200/71157]
loss: 0.127242  [25600/71157]
loss: 0.031843  [32000/71157]
loss: 0.044403  [38400/71157]
loss: 0.097021  [44800/71157]
loss: 0.074091  [51200/71157]
loss: 0.135330  [57600/71157]
loss: 0.027245  [64000/71157]
loss: 0.085504  [70400/71157]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.101934 

Epoch 28
-------------------------------
loss: 0.036744  [    0/71157]
loss: 0.035119  [ 6400/71157]
loss: 0.037786  [12800/71157]
loss: 0.156448  [19200/71157]
loss: 0.127949  [25600/71157]
loss: 0.157026  [32000/71157]
loss: 0.030595  [38400/71157]
loss: 0.066478  [44800/71157]
loss: 0.038721  [51200/71157]
loss: 0.133132  [57600/71157]
loss: 0.053123  [64000/71157]
loss: 0.024136  [70400/71157]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102922 

Epoch 29
-------------------------------
loss: 0.068638  [    0/71157]
loss: 0.076521  [ 6400/71157]
loss: 0.121440  [12800/71157]
loss: 0.130752  [19200/71157]
loss: 0.064531  [25600/71157]
loss: 0.084248  [32000/71157]
loss: 0.085374  [38400/71157]
loss: 0.026040  [44800/71157]
loss: 0.073591  [51200/71157]
loss: 0.084575  [57600/71157]
loss: 0.020920  [64000/71157]
loss: 0.047656  [70400/71157]
Epoch 39
-------------------------------
loss: 0.136238  [    0/69886]
loss: 0.209116  [ 6400/69886]
loss: 0.125456  [12800/69886]
loss: 0.123792  [19200/69886]
loss: 0.184481  [25600/69886]
loss: 0.096204  [32000/69886]
loss: 0.291258  [38400/69886]
loss: 0.122216  [44800/69886]
loss: 0.185550  [51200/69886]
loss: 0.179458  [57600/69886]
loss: 0.120043  [64000/69886]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.171974 

Epoch 40
-------------------------------
loss: 0.080091  [    0/69886]
loss: 0.107681  [ 6400/69886]
loss: 0.254118  [12800/69886]
loss: 0.146685  [19200/69886]
loss: 0.065296  [25600/69886]
loss: 0.113000  [32000/69886]
loss: 0.203547  [38400/69886]
loss: 0.194525  [44800/69886]
loss: 0.169456  [51200/69886]
loss: 0.201993  [57600/69886]
loss: 0.144126  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.164809 

Epoch 41
-------------------------------
loss: 0.160982  [    0/69886]
loss: 0.244075  [ 6400/69886]
loss: 0.126649  [12800/69886]
loss: 0.110772  [19200/69886]
loss: 0.092232  [25600/69886]
loss: 0.064866  [32000/69886]
loss: 0.129190  [38400/69886]
loss: 0.118153  [44800/69886]
loss: 0.177863  [51200/69886]
loss: 0.151331  [57600/69886]
loss: 0.175635  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.165291 

Epoch 42
-------------------------------
loss: 0.125456  [    0/69886]
loss: 0.139427  [ 6400/69886]
loss: 0.131185  [12800/69886]
loss: 0.207961  [19200/69886]
loss: 0.153874  [25600/69886]
loss: 0.243713  [32000/69886]
loss: 0.153899  [38400/69886]
loss: 0.114891  [44800/69886]
loss: 0.127644  [51200/69886]
loss: 0.091939  [57600/69886]
loss: 0.184220  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.165360 

Epoch 43
-------------------------------
loss: 0.147320  [    0/69886]
loss: 0.190375  [ 6400/69886]
loss: 0.141304  [12800/69886]
loss: 0.189014  [19200/69886]
loss: 0.248306  [25600/69886]
loss: 0.068623  [32000/69886]
loss: 0.306132  [38400/69886]
loss: 0.162009  [44800/69886]
loss: 0.125422  [51200/69886]
loss: 0.142302  [57600/69886]
loss: 0.165196  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.175948 

Epoch 44
-------------------------------
loss: 0.175280  [    0/69886]
loss: 0.128573  [ 6400/69886]
loss: 0.076595  [12800/69886]
loss: 0.333344  [19200/69886]
loss: 0.093755  [25600/69886]
loss: 0.208209  [32000/69886]
loss: 0.136527  [38400/69886]
loss: 0.189797  [44800/69886]
loss: 0.095926  [51200/69886]
loss: 0.212905  [57600/69886]
loss: 0.094774  [64000/69886]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.168921 

Epoch 45
-------------------------------
loss: 0.077333  [    0/69886]
loss: 0.096016  [ 6400/69886]
loss: 0.179711  [12800/69886]
loss: 0.170982  [19200/69886]
loss: 0.090393  [25600/69886]
loss: 0.100676  [32000/69886]
loss: 0.236035  [38400/69886]
loss: 0.141612  [44800/69886]
loss: 0.256996  [51200/69886]
loss: 0.160269  [57600/69886]
loss: 0.187293  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.167276 

Epoch 46
-------------------------------
loss: 0.165706  [    0/69886]
loss: 0.133774  [ 6400/69886]
loss: 0.165735  [12800/69886]
loss: 0.125520  [19200/69886]
loss: 0.135714  [25600/69886]
loss: 0.138445  [32000/69886]
loss: 0.108967  [38400/69886]
loss: 0.091561  [44800/69886]
loss: 0.149813  [51200/69886]
loss: 0.153119  [57600/69886]
loss: 0.173007  [64000/69886]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.183591 

Epoch 47
-------------------------------
loss: 0.105331  [    0/69886]
loss: 0.085772  [ 6400/69886]
loss: 0.172896  [12800/69886]
loss: 0.182537  [19200/69886]
loss: 0.188940  [25600/69886]
loss: 0.145066  [32000/69886]
loss: 0.251194  [38400/69886]
loss: 0.106758  [44800/69886]
loss: 0.259622  [51200/69886]
loss: 0.170842  [57600/69886]
loss: 0.100013  [64000/69886]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.172085 

Epoch 48
-------------------------------
loss: 0.078982  [    0/69886]
loss: 0.120998  [ 6400/69886]
loss: 0.107393  [12800/69886]
loss: 0.067607  [19200/69886]
loss: 0.119740  [25600/69886]
loss: 0.179063  [32000/69886]
loss: 0.172008  [38400/69886]
loss: 0.079907  [44800/69886]
loss: 0.125488  [51200/69886]
loss: 0.134083  [57600/69886]
loss: 0.149193  [64000/69886]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.168204 

Epoch 49
-------------------------------
loss: 0.212513  [    0/69886]
loss: 0.120457  [ 6400/69886]
loss: 0.140366  [12800/69886]
loss: 0.332170  [19200/69886]
loss: 0.121604  [25600/69886]
loss: 0.187329  [32000/69886]
loss: 0.265556  [38400/69886]
loss: 0.153448  [44800/69886]
loss: 0.251308  [51200/69886]
loss: 0.129193  [57600/69886]
loss: 0.171367  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.164208 

Epoch 50
-------------------------------
loss: 0.158141  [    0/69886]
loss: 0.294727  [ 6400/69886]
loss: 0.155622  [12800/69886]
loss: 0.149767  [19200/69886]
loss: 0.105295  [25600/69886]
loss: 0.128025  [32000/69886]
loss: 0.142289  [38400/69886]
loss: 0.135843  [44800/69886]
loss: 0.214844  [51200/69886]
loss: 0.195017  [57600/69886]
loss: 0.096441  [64000/69886]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.173478 

Epoch 1
-------------------------------
loss: 0.660867  [    0/70534]
loss: 0.178138  [ 6400/70534]
loss: 0.287025  [12800/70534]
loss: 0.159754  [19200/70534]
loss: 0.343295  [25600/70534]
loss: 0.223802  [32000/70534]
loss: 0.179538  [38400/70534]
loss: 0.216180  [44800/70534]
loss: 0.370086  [51200/70534]
loss: 0.322480  [57600/70534]
loss: 0.187336  [64000/70534]
loss: 0.171183  [70400/70534]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.191180 

Epoch 2
-------------------------------
loss: 0.178649  [    0/70534]
loss: 0.237700  [ 6400/70534]
loss: 0.246639  [12800/70534]
loss: 0.149932  [19200/70534]
loss: 0.348418  [25600/70534]
loss: 0.143204  [32000/70534]
loss: 0.271317  [38400/70534]
loss: 0.216872  [44800/70534]
loss: 0.246523  [51200/70534]
loss: 0.173190  [57600/70534]
loss: 0.214835  [64000/70534]
loss: 0.176748  [70400/70534]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.175506 

Epoch 3
-------------------------------
loss: 0.193183  [    0/70534]
loss: 0.261364  [ 6400/70534]
loss: 0.209996  [12800/70534]
loss: 0.203094  [19200/70534]
loss: 0.121083  [25600/70534]
loss: 0.292800  [32000/70534]
loss: 0.214012  [38400/70534]
loss: 0.158063  [44800/70534]
loss: 0.194238  [51200/70534]
loss: 0.202493  [57600/70534]
loss: 0.212383  [64000/70534]
loss: 0.172731  [70400/70534]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.169550 

Epoch 4
-------------------------------
loss: 0.185098  [    0/70534]
loss: 0.267426  [ 6400/70534]
loss: 0.132500  [12800/70534]
loss: 0.238290  [19200/70534]
loss: 0.155229  [25600/70534]
loss: 0.187952  [32000/70534]
loss: 0.167557  [38400/70534]
loss: 0.234312  [44800/70534]
loss: 0.178025  [51200/70534]
loss: 0.147099  [57600/70534]
loss: 0.168361  [64000/70534]
loss: 0.155933  [70400/70534]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.184852 

Epoch 5
-------------------------------
loss: 0.156315  [    0/70534]
loss: 0.082725  [ 6400/70534]
loss: 0.201082  [12800/70534]
loss: 0.168676  [19200/70534]
loss: 0.202139  [25600/70534]
loss: 0.155538  [32000/70534]
loss: 0.278327  [38400/70534]
loss: 0.184458  [44800/70534]
loss: 0.102648  [51200/70534]
loss: 0.123364  [57600/70534]
loss: 0.179344  [64000/70534]
loss: 0.149425  [70400/70534]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.159878 

Epoch 6
-------------------------------
loss: 0.164330  [    0/70534]
loss: 0.245851  [ 6400/70534]
loss: 0.287532  [12800/70534]
loss: 0.138531  [19200/70534]
loss: 0.178898  [25600/70534]
loss: 0.215074  [32000/70534]
loss: 0.241068  [38400/70534]
loss: 0.310704  [44800/70534]
loss: 0.252218  [51200/70534]
loss: 0.222970  [57600/70534]
loss: 0.139910  [64000/70534]
loss: 0.403802  [70400/70534]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.154866 

Epoch 7
-------------------------------
loss: 0.179248  [    0/70534]
loss: 0.183043  [ 6400/70534]
loss: 0.190757  [12800/70534]
loss: 0.230892  [19200/70534]
loss: 0.167093  [25600/70534]
loss: 0.118383  [32000/70534]
loss: 0.170503  [38400/70534]
loss: 0.112004  [44800/70534]
loss: 0.183488  [51200/70534]
loss: 0.341445  [57600/70534]
loss: 0.209937  [64000/70534]
loss: 0.229483  [70400/70534]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.206145 

Epoch 31
-------------------------------
loss: 0.195554  [    0/70245]
loss: 0.113679  [ 6400/70245]
loss: 0.205021  [12800/70245]
loss: 0.142489  [19200/70245]
loss: 0.175453  [25600/70245]
loss: 0.094090  [32000/70245]
loss: 0.160859  [38400/70245]
loss: 0.309117  [44800/70245]
loss: 0.191369  [51200/70245]
loss: 0.165743  [57600/70245]
loss: 0.151156  [64000/70245]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.203232 

Epoch 32
-------------------------------
loss: 0.124918  [    0/70245]
loss: 0.170212  [ 6400/70245]
loss: 0.133704  [12800/70245]
loss: 0.085403  [19200/70245]
loss: 0.189782  [25600/70245]
loss: 0.233443  [32000/70245]
loss: 0.267475  [38400/70245]
loss: 0.076122  [44800/70245]
loss: 0.176479  [51200/70245]
loss: 0.304773  [57600/70245]
loss: 0.168750  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.200058 

Epoch 33
-------------------------------
loss: 0.313883  [    0/70245]
loss: 0.246192  [ 6400/70245]
loss: 0.067824  [12800/70245]
loss: 0.143147  [19200/70245]
loss: 0.197523  [25600/70245]
loss: 0.215650  [32000/70245]
loss: 0.213303  [38400/70245]
loss: 0.291240  [44800/70245]
loss: 0.169452  [51200/70245]
loss: 0.129100  [57600/70245]
loss: 0.170975  [64000/70245]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.200335 

Epoch 34
-------------------------------
loss: 0.172567  [    0/70245]
loss: 0.138782  [ 6400/70245]
loss: 0.190036  [12800/70245]
loss: 0.092214  [19200/70245]
loss: 0.147782  [25600/70245]
loss: 0.115881  [32000/70245]
loss: 0.202008  [38400/70245]
loss: 0.166286  [44800/70245]
loss: 0.138089  [51200/70245]
loss: 0.130671  [57600/70245]
loss: 0.210739  [64000/70245]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.197351 

Epoch 35
-------------------------------
loss: 0.195944  [    0/70245]
loss: 0.237923  [ 6400/70245]
loss: 0.228982  [12800/70245]
loss: 0.107717  [19200/70245]
loss: 0.212673  [25600/70245]
loss: 0.171915  [32000/70245]
loss: 0.176412  [38400/70245]
loss: 0.158945  [44800/70245]
loss: 0.324643  [51200/70245]
loss: 0.167440  [57600/70245]
loss: 0.183544  [64000/70245]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.208999 

Epoch 36
-------------------------------
loss: 0.110419  [    0/70245]
loss: 0.144727  [ 6400/70245]
loss: 0.194208  [12800/70245]
loss: 0.131944  [19200/70245]
loss: 0.178019  [25600/70245]
loss: 0.196529  [32000/70245]
loss: 0.091092  [38400/70245]
loss: 0.163855  [44800/70245]
loss: 0.096328  [51200/70245]
loss: 0.275184  [57600/70245]
loss: 0.219093  [64000/70245]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.206987 

Epoch 37
-------------------------------
loss: 0.206688  [    0/70245]
loss: 0.161542  [ 6400/70245]
loss: 0.246537  [12800/70245]
loss: 0.191799  [19200/70245]
loss: 0.359516  [25600/70245]
loss: 0.247152  [32000/70245]
loss: 0.096259  [38400/70245]
loss: 0.151152  [44800/70245]
loss: 0.183911  [51200/70245]
loss: 0.262964  [57600/70245]
loss: 0.221147  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.195862 

Epoch 38
-------------------------------
loss: 0.154026  [    0/70245]
loss: 0.120534  [ 6400/70245]
loss: 0.159556  [12800/70245]
loss: 0.195380  [19200/70245]
loss: 0.167460  [25600/70245]
loss: 0.132757  [32000/70245]
loss: 0.363552  [38400/70245]
loss: 0.145875  [44800/70245]
loss: 0.182666  [51200/70245]
loss: 0.191298  [57600/70245]
loss: 0.143964  [64000/70245]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.197836 

Epoch 39
-------------------------------
loss: 0.251064  [    0/70245]
loss: 0.113148  [ 6400/70245]
loss: 0.199700  [12800/70245]
loss: 0.183152  [19200/70245]
loss: 0.242522  [25600/70245]
loss: 0.158959  [32000/70245]
loss: 0.233109  [38400/70245]
loss: 0.073212  [44800/70245]
loss: 0.120647  [51200/70245]
loss: 0.122740  [57600/70245]
loss: 0.290559  [64000/70245]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.196397 

Epoch 40
-------------------------------
loss: 0.228736  [    0/70245]
loss: 0.135695  [ 6400/70245]
loss: 0.116502  [12800/70245]
loss: 0.114925  [19200/70245]
loss: 0.200981  [25600/70245]
loss: 0.088322  [32000/70245]
loss: 0.185132  [38400/70245]
loss: 0.096600  [44800/70245]
loss: 0.209368  [51200/70245]
loss: 0.159138  [57600/70245]
loss: 0.138051  [64000/70245]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.197935 

Epoch 41
-------------------------------
loss: 0.155324  [    0/70245]
loss: 0.162637  [ 6400/70245]
loss: 0.134343  [12800/70245]
loss: 0.195992  [19200/70245]
loss: 0.109259  [25600/70245]
loss: 0.110437  [32000/70245]
loss: 0.221110  [38400/70245]
loss: 0.168950  [44800/70245]
loss: 0.178657  [51200/70245]
loss: 0.169376  [57600/70245]
loss: 0.133024  [64000/70245]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.198339 

Epoch 42
-------------------------------
loss: 0.140150  [    0/70245]
loss: 0.170162  [ 6400/70245]
loss: 0.107696  [12800/70245]
loss: 0.188709  [19200/70245]
loss: 0.120021  [25600/70245]
loss: 0.148618  [32000/70245]
loss: 0.095852  [38400/70245]
loss: 0.153376  [44800/70245]
loss: 0.163227  [51200/70245]
loss: 0.110360  [57600/70245]
loss: 0.205946  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.201880 

Epoch 43
-------------------------------
loss: 0.111439  [    0/70245]
loss: 0.135166  [ 6400/70245]
loss: 0.126957  [12800/70245]
loss: 0.162238  [19200/70245]
loss: 0.114986  [25600/70245]
loss: 0.300956  [32000/70245]
loss: 1.686987  [38400/70245]
loss: 0.328107  [44800/70245]
loss: 0.165648  [51200/70245]
loss: 0.144823  [57600/70245]
loss: 0.097556  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.197441 

Epoch 44
-------------------------------
loss: 0.176906  [    0/70245]
loss: 0.126491  [ 6400/70245]
loss: 0.189290  [12800/70245]
loss: 0.061970  [19200/70245]
loss: 0.142352  [25600/70245]
loss: 0.120630  [32000/70245]
loss: 0.342116  [38400/70245]
loss: 0.150103  [44800/70245]
loss: 0.149746  [51200/70245]
loss: 0.152432  [57600/70245]
loss: 0.147202  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.200797 

Epoch 45
-------------------------------
loss: 0.177456  [    0/70245]
loss: 0.153680  [ 6400/70245]
loss: 0.300169  [12800/70245]
loss: 0.194147  [19200/70245]
loss: 0.217429  [25600/70245]
loss: 0.240942  [32000/70245]
loss: 0.121318  [38400/70245]
loss: 0.128588  [44800/70245]
loss: 0.185352  [51200/70245]
loss: 0.137106  [57600/70245]
loss: 0.116253  [64000/70245]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.200028 

Epoch 46
-------------------------------
loss: 0.246948  [    0/70245]
loss: 0.147950  [ 6400/70245]
loss: 0.176859  [12800/70245]
loss: 0.206866  [19200/70245]
loss: 0.153907  [25600/70245]
loss: 0.199594  [32000/70245]
loss: 0.149006  [38400/70245]
loss: 0.085287  [44800/70245]
loss: 0.136523  [51200/70245]
loss: 0.127667  [57600/70245]
loss: 0.197518  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.198366 

Epoch 47
-------------------------------
loss: 0.055855  [    0/70245]
loss: 0.300140  [ 6400/70245]
loss: 0.143401  [12800/70245]
loss: 0.137033  [19200/70245]
loss: 0.171220  [25600/70245]
loss: 0.167611  [32000/70245]
loss: 0.124705  [38400/70245]
loss: 0.195428  [44800/70245]
loss: 0.278099  [51200/70245]
loss: 0.177473  [57600/70245]
loss: 0.276723  [64000/70245]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.196151 

Epoch 48
-------------------------------
loss: 0.153038  [    0/70245]
loss: 0.101843  [ 6400/70245]
loss: 0.232224  [12800/70245]
loss: 0.174744  [19200/70245]
loss: 0.251902  [25600/70245]
loss: 0.161632  [32000/70245]
loss: 0.142417  [38400/70245]
loss: 0.065472  [44800/70245]
loss: 0.230566  [51200/70245]
loss: 0.205153  [57600/70245]
loss: 0.177230  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.202625 

Epoch 49
-------------------------------
loss: 0.082483  [    0/70245]
loss: 0.139956  [ 6400/70245]
loss: 0.112977  [12800/70245]
loss: 0.099445  [19200/70245]
loss: 0.120453  [25600/70245]
loss: 0.116402  [32000/70245]
loss: 0.101378  [38400/70245]
loss: 0.200839  [44800/70245]
loss: 0.110889  [51200/70245]
loss: 0.188078  [57600/70245]
loss: 0.171326  [64000/70245]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.200531 

Epoch 50
-------------------------------
loss: 0.103477  [    0/70245]
loss: 0.206110  [ 6400/70245]
loss: 0.246068  [51200/70549]
loss: 0.139275  [57600/70549]
loss: 1.714022  [64000/70549]
loss: 0.509395  [70400/70549]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177037 

Epoch 2
-------------------------------
loss: 0.197250  [    0/70549]
loss: 0.201845  [ 6400/70549]
loss: 0.259155  [12800/70549]
loss: 0.162885  [19200/70549]
loss: 0.196074  [25600/70549]
loss: 0.155040  [32000/70549]
loss: 0.097824  [38400/70549]
loss: 0.128654  [44800/70549]
loss: 0.166124  [51200/70549]
loss: 0.237082  [57600/70549]
loss: 0.094712  [64000/70549]
loss: 0.221032  [70400/70549]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.166491 

Epoch 3
-------------------------------
loss: 0.135017  [    0/70549]
loss: 0.231595  [ 6400/70549]
loss: 0.224372  [12800/70549]
loss: 0.134218  [19200/70549]
loss: 0.205927  [25600/70549]
loss: 0.115324  [32000/70549]
loss: 0.190578  [38400/70549]
loss: 0.236913  [44800/70549]
loss: 0.168780  [51200/70549]
loss: 0.199308  [57600/70549]
loss: 0.244283  [64000/70549]
loss: 0.175474  [70400/70549]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.149854 

Epoch 4
-------------------------------
loss: 0.243362  [    0/70549]
loss: 0.120225  [ 6400/70549]
loss: 0.201521  [12800/70549]
loss: 0.144199  [19200/70549]
loss: 0.165223  [25600/70549]
loss: 0.185466  [32000/70549]
loss: 0.518043  [38400/70549]
loss: 0.210909  [44800/70549]
loss: 0.171970  [51200/70549]
loss: 0.086286  [57600/70549]
loss: 0.283860  [64000/70549]
loss: 0.134944  [70400/70549]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.152826 

Epoch 5
-------------------------------
loss: 0.203292  [    0/70549]
loss: 0.209891  [ 6400/70549]
loss: 0.116793  [12800/70549]
loss: 0.122093  [19200/70549]
loss: 0.158607  [25600/70549]
loss: 0.170019  [32000/70549]
loss: 0.113559  [38400/70549]
loss: 0.256751  [44800/70549]
loss: 0.196004  [51200/70549]
loss: 0.102586  [57600/70549]
loss: 0.120544  [64000/70549]
loss: 0.151071  [70400/70549]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.143909 

Epoch 6
-------------------------------
loss: 0.155802  [    0/70549]
loss: 0.158196  [ 6400/70549]
loss: 0.172705  [12800/70549]
loss: 0.180580  [19200/70549]
loss: 0.139702  [25600/70549]
loss: 0.174156  [32000/70549]
loss: 0.309494  [38400/70549]
loss: 0.251322  [44800/70549]
loss: 0.219361  [51200/70549]
loss: 0.124698  [57600/70549]
loss: 0.067481  [64000/70549]
loss: 0.142915  [70400/70549]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.143002 

Epoch 7
-------------------------------
loss: 0.081053  [    0/70549]
loss: 0.156355  [ 6400/70549]
loss: 0.157264  [12800/70549]
loss: 0.112422  [19200/70549]
loss: 0.045913  [25600/70549]
loss: 0.190161  [32000/70549]
loss: 0.135226  [38400/70549]
loss: 0.177210  [44800/70549]
loss: 0.148063  [51200/70549]
loss: 0.184865  [57600/70549]
loss: 0.296739  [64000/70549]
loss: 0.103573  [70400/70549]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.144478 

Epoch 8
-------------------------------
loss: 0.255479  [    0/70549]
loss: 0.181023  [ 6400/70549]
loss: 0.190315  [12800/70549]
loss: 0.187749  [19200/70549]
loss: 0.151667  [25600/70549]
loss: 0.098963  [32000/70549]
loss: 0.166481  [38400/70549]
loss: 0.083333  [44800/70549]
loss: 0.146344  [51200/70549]
loss: 0.240680  [57600/70549]
loss: 0.140990  [64000/70549]
loss: 0.302363  [70400/70549]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.159416 

Epoch 9
-------------------------------
loss: 0.286794  [    0/70549]
loss: 0.146330  [ 6400/70549]
loss: 0.255617  [12800/70549]
loss: 0.063870  [19200/70549]
loss: 0.151258  [25600/70549]
loss: 0.315430  [32000/70549]
loss: 0.111205  [38400/70549]
loss: 0.107001  [44800/70549]
loss: 0.176561  [51200/70549]
loss: 0.253554  [57600/70549]
loss: 0.107032  [64000/70549]
loss: 0.115758  [70400/70549]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.140671 

Epoch 10
-------------------------------
loss: 0.144632  [    0/70549]
loss: 0.176337  [ 6400/70549]
loss: 0.248304  [12800/70549]
loss: 0.152566  [19200/70549]
loss: 0.273397  [25600/70549]
loss: 0.190023  [32000/70549]
loss: 0.163231  [38400/70549]
loss: 0.133022  [44800/70549]
loss: 0.200047  [51200/70549]
loss: 0.119527  [57600/70549]
loss: 0.273251  [64000/70549]
loss: 0.268003  [70400/70549]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.142423 

Epoch 11
-------------------------------
loss: 0.146258  [    0/70549]
loss: 0.073742  [ 6400/70549]
loss: 0.092369  [12800/70549]
loss: 0.178024  [19200/70549]
loss: 0.143263  [25600/70549]
loss: 0.134759  [32000/70549]
loss: 0.105233  [38400/70549]
loss: 0.291942  [44800/70549]
loss: 0.215036  [51200/70549]
loss: 0.125259  [57600/70549]
loss: 0.215113  [64000/70549]
loss: 0.125631  [70400/70549]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.143387 

Epoch 12
-------------------------------
loss: 0.201024  [    0/70549]
loss: 0.219079  [ 6400/70549]
loss: 0.198291  [12800/70549]
loss: 0.107518  [19200/70549]
loss: 0.201067  [25600/70549]
loss: 0.168182  [32000/70549]
loss: 0.091809  [38400/70549]
loss: 0.149439  [44800/70549]
loss: 0.353481  [51200/70549]
loss: 0.255806  [57600/70549]
loss: 0.179041  [64000/70549]
loss: 0.209832  [70400/70549]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.145504 

Epoch 13
-------------------------------
loss: 0.139480  [    0/70549]
loss: 0.105326  [ 6400/70549]
loss: 0.192825  [12800/70549]
loss: 0.064736  [19200/70549]
loss: 0.144092  [25600/70549]
loss: 0.174512  [32000/70549]
loss: 0.082257  [38400/70549]
loss: 0.208245  [44800/70549]
loss: 0.087988  [51200/70549]
loss: 0.183984  [57600/70549]
loss: 0.077286  [64000/70549]
loss: 0.177693  [70400/70549]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.170921 

Epoch 14
-------------------------------
loss: 0.221135  [    0/70549]
loss: 0.120544  [ 6400/70549]
loss: 0.132539  [12800/70549]
loss: 0.052081  [19200/70549]
loss: 0.181028  [25600/70549]
loss: 0.147381  [32000/70549]
loss: 0.162210  [38400/70549]
loss: 0.095415  [44800/70549]
loss: 0.307598  [51200/70549]
loss: 0.202625  [57600/70549]
loss: 0.115520  [64000/70549]
loss: 0.128309  [70400/70549]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.146504 

Epoch 15
-------------------------------
loss: 0.102535  [    0/70549]
loss: 0.308453  [ 6400/70549]
loss: 0.162273  [12800/70549]
loss: 0.156735  [19200/70549]
loss: 0.088132  [25600/70549]
loss: 0.122051  [32000/70549]
loss: 0.257198  [38400/70549]
loss: 0.101657  [44800/70549]
loss: 0.045292  [51200/70549]
loss: 0.149878  [57600/70549]
loss: 0.223855  [64000/70549]
loss: 0.154921  [70400/70549]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.144615 

Epoch 16
-------------------------------
loss: 0.121251  [    0/70549]
loss: 0.135538  [ 6400/70549]
loss: 0.279764  [12800/70549]
loss: 0.111988  [19200/70549]
loss: 0.153308  [25600/70549]
loss: 0.081431  [32000/70549]
loss: 0.129667  [38400/70549]
loss: 0.189731  [44800/70549]
loss: 0.207731  [51200/70549]
loss: 0.152164  [57600/70549]
loss: 0.081294  [64000/70549]
loss: 0.164482  [70400/70549]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.150575 

Epoch 17
-------------------------------
loss: 0.274930  [    0/70549]
loss: 0.124636  [ 6400/70549]
loss: 0.179964  [12800/70549]
loss: 0.068711  [19200/70549]
loss: 0.191015  [25600/70549]
loss: 0.211235  [32000/70549]
loss: 0.186650  [38400/70549]
loss: 0.090935  [44800/70549]
loss: 0.165041  [51200/70549]
loss: 0.102492  [57600/70549]
loss: 0.100886  [64000/70549]
loss: 0.108130  [70400/70549]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.139701 

Epoch 18
-------------------------------
loss: 0.097279  [    0/70549]
loss: 0.124026  [ 6400/70549]
loss: 0.181439  [12800/70549]
loss: 0.162980  [19200/70549]
loss: 0.121890  [25600/70549]
loss: 0.107625  [32000/70549]
loss: 0.167265  [38400/70549]
loss: 0.198063  [44800/70549]
loss: 0.227665  [51200/70549]
loss: 0.095553  [57600/70549]
loss: 0.075566  [64000/70549]
loss: 0.191691  [70400/70549]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.138977 

Epoch 19
-------------------------------
loss: 0.128670  [    0/70549]
loss: 0.102454  [ 6400/70549]
loss: 0.214970  [12800/70549]
loss: 0.201426  [19200/70549]
loss: 0.088268  [25600/70549]
loss: 0.128015  [32000/70549]
loss: 0.229121  [38400/70549]
loss: 0.252674  [44800/70549]
loss: 0.196826  [51200/70549]
2022/09/20 21:05:10 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.088902  [44800/70031]
loss: 0.042421  [51200/70031]
loss: 0.039417  [57600/70031]
loss: 0.198998  [64000/70031]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117458 

Epoch 47
-------------------------------
loss: 0.025288  [    0/70031]
loss: 0.116123  [ 6400/70031]
loss: 0.153185  [12800/70031]
loss: 0.072444  [19200/70031]
loss: 0.026970  [25600/70031]
loss: 0.129727  [32000/70031]
loss: 0.086080  [38400/70031]
loss: 0.092643  [44800/70031]
loss: 0.117034  [51200/70031]
loss: 0.075008  [57600/70031]
loss: 0.101481  [64000/70031]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117836 

Epoch 48
-------------------------------
loss: 0.076005  [    0/70031]
loss: 0.112248  [ 6400/70031]
loss: 0.085138  [12800/70031]
loss: 0.087502  [19200/70031]
loss: 0.027722  [25600/70031]
loss: 0.016473  [32000/70031]
loss: 0.031116  [38400/70031]
loss: 0.079574  [44800/70031]
loss: 0.044913  [51200/70031]
loss: 0.029542  [57600/70031]
loss: 0.045389  [64000/70031]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.115442 

Epoch 49
-------------------------------
loss: 0.034042  [    0/70031]
loss: 0.158932  [ 6400/70031]
loss: 0.194403  [12800/70031]
loss: 0.075891  [19200/70031]
loss: 0.134141  [25600/70031]
loss: 0.217753  [32000/70031]
loss: 0.080665  [38400/70031]
loss: 0.161684  [44800/70031]
loss: 0.114624  [51200/70031]
loss: 0.040555  [57600/70031]
loss: 0.116268  [64000/70031]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.115908 

Epoch 50
-------------------------------
loss: 0.036525  [    0/70031]
loss: 0.152469  [ 6400/70031]
loss: 0.147173  [12800/70031]
loss: 0.068637  [19200/70031]
loss: 0.085266  [25600/70031]
loss: 0.116228  [32000/70031]
loss: 0.103920  [38400/70031]
loss: 0.091716  [44800/70031]
loss: 0.028185  [51200/70031]
loss: 0.012495  [57600/70031]
loss: 0.146122  [64000/70031]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.129360 

Epoch 1
-------------------------------
loss: 0.697293  [    0/71373]
loss: 0.213769  [ 6400/71373]
loss: 0.225109  [12800/71373]
loss: 0.220243  [19200/71373]
loss: 0.112312  [25600/71373]
loss: 0.124439  [32000/71373]
loss: 0.123894  [38400/71373]
loss: 0.131351  [44800/71373]
loss: 0.085111  [51200/71373]
loss: 0.141933  [57600/71373]
loss: 0.079577  [64000/71373]
loss: 0.134430  [70400/71373]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.096821 

Epoch 2
-------------------------------
loss: 0.164959  [    0/71373]
loss: 0.088017  [ 6400/71373]
loss: 0.036572  [12800/71373]
loss: 0.079092  [19200/71373]
loss: 0.067581  [25600/71373]
loss: 0.209994  [32000/71373]
loss: 0.089486  [38400/71373]
loss: 0.140915  [44800/71373]
loss: 0.099088  [51200/71373]
loss: 0.190804  [57600/71373]
loss: 0.038380  [64000/71373]
loss: 0.122059  [70400/71373]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.088600 

Epoch 3
-------------------------------
loss: 0.094818  [    0/71373]
loss: 0.015076  [ 6400/71373]
loss: 0.057894  [12800/71373]
loss: 0.075011  [19200/71373]
loss: 0.046151  [25600/71373]
loss: 0.128430  [32000/71373]
loss: 0.103938  [38400/71373]
loss: 0.189227  [44800/71373]
loss: 0.055500  [51200/71373]
loss: 0.061099  [57600/71373]
loss: 0.128249  [64000/71373]
loss: 0.069509  [70400/71373]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.100494 

Epoch 4
-------------------------------
loss: 0.082776  [    0/71373]
loss: 0.062362  [ 6400/71373]
loss: 0.044709  [12800/71373]
loss: 0.112753  [19200/71373]
loss: 0.072102  [25600/71373]
loss: 0.055202  [32000/71373]
loss: 0.021701  [38400/71373]
loss: 0.064222  [44800/71373]
loss: 0.102632  [51200/71373]
loss: 0.086165  [57600/71373]
loss: 0.093043  [64000/71373]
loss: 0.187409  [70400/71373]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.096690 

Epoch 5
-------------------------------
loss: 0.045132  [    0/71373]
loss: 0.062302  [ 6400/71373]
loss: 0.143243  [12800/71373]
loss: 0.095023  [19200/71373]
loss: 0.046474  [25600/71373]
loss: 0.025299  [32000/71373]
loss: 0.122900  [38400/71373]
loss: 0.104460  [44800/71373]
loss: 0.160018  [51200/71373]
loss: 0.039156  [57600/71373]
loss: 0.037287  [64000/71373]
loss: 0.071319  [70400/71373]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.086814 

Epoch 6
-------------------------------
loss: 0.154246  [    0/71373]
loss: 0.085786  [ 6400/71373]
loss: 0.104038  [12800/71373]
loss: 0.042848  [19200/71373]
loss: 0.064112  [25600/71373]
loss: 0.067711  [32000/71373]
loss: 0.183276  [38400/71373]
loss: 0.069190  [44800/71373]
loss: 0.087548  [51200/71373]
loss: 0.072757  [57600/71373]
loss: 0.165076  [64000/71373]
loss: 0.161986  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.083186 

Epoch 7
-------------------------------
loss: 0.032431  [    0/71373]
loss: 0.042043  [ 6400/71373]
loss: 0.158746  [12800/71373]
loss: 0.047199  [19200/71373]
loss: 0.078815  [25600/71373]
loss: 0.055095  [32000/71373]
loss: 0.057663  [38400/71373]
loss: 0.063453  [44800/71373]
loss: 0.118075  [51200/71373]
loss: 0.063850  [57600/71373]
loss: 0.056956  [64000/71373]
loss: 0.084463  [70400/71373]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.078307 

Epoch 8
-------------------------------
loss: 0.065847  [    0/71373]
loss: 0.119586  [ 6400/71373]
loss: 0.053944  [12800/71373]
loss: 0.067534  [19200/71373]
loss: 0.243603  [25600/71373]
loss: 0.062707  [32000/71373]
loss: 0.046744  [38400/71373]
loss: 0.038744  [44800/71373]
loss: 0.014621  [51200/71373]
loss: 0.126531  [57600/71373]
loss: 0.052520  [64000/71373]
loss: 0.116856  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.085307 

Epoch 9
-------------------------------
loss: 0.052275  [    0/71373]
loss: 0.055047  [ 6400/71373]
loss: 0.050138  [12800/71373]
loss: 0.074866  [19200/71373]
loss: 0.103105  [25600/71373]
loss: 0.024645  [32000/71373]
loss: 0.050458  [38400/71373]
loss: 0.063896  [44800/71373]
loss: 0.116664  [51200/71373]
loss: 0.032056  [57600/71373]
loss: 0.024479  [64000/71373]
loss: 0.135799  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.082828 

Epoch 10
-------------------------------
loss: 0.060536  [    0/71373]
loss: 0.085492  [ 6400/71373]
loss: 0.065131  [12800/71373]
loss: 0.081769  [19200/71373]
loss: 0.064208  [25600/71373]
loss: 0.102368  [32000/71373]
loss: 0.018927  [38400/71373]
loss: 0.032932  [44800/71373]
loss: 0.016297  [51200/71373]
loss: 0.125549  [57600/71373]
loss: 0.054834  [64000/71373]
loss: 0.062940  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.084469 

Epoch 11
-------------------------------
loss: 0.055367  [    0/71373]
loss: 0.067584  [ 6400/71373]
loss: 0.013716  [12800/71373]
loss: 0.015133  [19200/71373]
loss: 0.039718  [25600/71373]
loss: 0.147858  [32000/71373]
loss: 0.081346  [38400/71373]
loss: 0.160469  [44800/71373]
loss: 0.119013  [51200/71373]
loss: 0.031996  [57600/71373]
loss: 0.032943  [64000/71373]
loss: 0.048534  [70400/71373]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.091650 

Epoch 12
-------------------------------
loss: 0.101887  [    0/71373]
loss: 0.022088  [ 6400/71373]
loss: 0.040644  [12800/71373]
loss: 0.036725  [19200/71373]
loss: 0.098993  [25600/71373]
loss: 0.019858  [32000/71373]
loss: 0.031514  [38400/71373]
loss: 0.061932  [44800/71373]
loss: 0.035473  [51200/71373]
loss: 0.113024  [57600/71373]
loss: 0.080337  [64000/71373]
loss: 0.020654  [70400/71373]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099006 

Epoch 13
-------------------------------
loss: 0.044450  [    0/71373]
loss: 0.041048  [ 6400/71373]
loss: 0.067785  [12800/71373]
loss: 0.073412  [19200/71373]
loss: 0.003127  [25600/71373]
loss: 0.061217  [32000/71373]
loss: 0.031419  [38400/71373]
loss: 0.075160  [44800/71373]
loss: 0.067959  [51200/71373]
loss: 0.149738  [57600/71373]
loss: 0.032691  [64000/71373]
loss: 0.060891  [70400/71373]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.092475 

Epoch 14
-------------------------------
loss: 0.094416  [    0/71373]
loss: 0.108773  [ 6400/71373]
loss: 0.039520  [12800/71373]
loss: 0.018913  [19200/71373]
loss: 0.022448  [25600/71373]
loss: 0.061291  [32000/71373]
loss: 0.027521  [38400/71373]
loss: 0.094773  [44800/71373]
loss: 0.014551  [51200/71373]
loss: 0.092510  [57600/71373]
loss: 0.102209  [64000/71373]
loss: 0.108808  [70400/71373]
loss: 0.178971  [12800/69667]
loss: 0.111887  [19200/69667]
loss: 0.076869  [25600/69667]
loss: 0.191839  [32000/69667]
loss: 0.111294  [38400/69667]
loss: 0.040911  [44800/69667]
loss: 0.074641  [51200/69667]
loss: 0.259265  [57600/69667]
loss: 0.242026  [64000/69667]
Test Error: 
 Accuracy: 94.8%, Avg loss: 0.131428 

Epoch 6
-------------------------------
loss: 0.080209  [    0/69667]
loss: 0.066255  [ 6400/69667]
loss: 0.124233  [12800/69667]
loss: 0.228077  [19200/69667]
loss: 0.246060  [25600/69667]
loss: 0.157662  [32000/69667]
loss: 0.146056  [38400/69667]
loss: 0.103701  [44800/69667]
loss: 0.177297  [51200/69667]
loss: 0.223670  [57600/69667]
loss: 0.146191  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.117103 

Epoch 7
-------------------------------
loss: 0.083459  [    0/69667]
loss: 0.114702  [ 6400/69667]
loss: 0.113693  [12800/69667]
loss: 0.194458  [19200/69667]
loss: 0.123716  [25600/69667]
loss: 0.105730  [32000/69667]
loss: 0.084473  [38400/69667]
loss: 0.121550  [44800/69667]
loss: 0.166026  [51200/69667]
loss: 0.190083  [57600/69667]
loss: 0.101142  [64000/69667]
Test Error: 
 Accuracy: 94.6%, Avg loss: 0.137592 

Epoch 8
-------------------------------
loss: 0.257087  [    0/69667]
loss: 0.077856  [ 6400/69667]
loss: 0.050415  [12800/69667]
loss: 0.181167  [19200/69667]
loss: 0.065634  [25600/69667]
loss: 0.210175  [32000/69667]
loss: 0.205100  [38400/69667]
loss: 0.116288  [44800/69667]
loss: 0.063749  [51200/69667]
loss: 0.106274  [57600/69667]
loss: 0.098956  [64000/69667]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.117492 

Epoch 9
-------------------------------
loss: 0.110254  [    0/69667]
loss: 0.297965  [ 6400/69667]
loss: 0.097196  [12800/69667]
loss: 0.093539  [19200/69667]
loss: 0.118525  [25600/69667]
loss: 0.080212  [32000/69667]
loss: 0.117774  [38400/69667]
loss: 0.201608  [44800/69667]
loss: 0.045842  [51200/69667]
loss: 0.064012  [57600/69667]
loss: 0.125437  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.117209 

Epoch 10
-------------------------------
loss: 0.016355  [    0/69667]
loss: 0.168862  [ 6400/69667]
loss: 0.085100  [12800/69667]
loss: 0.031686  [19200/69667]
loss: 0.093252  [25600/69667]
loss: 0.047034  [32000/69667]
loss: 0.204260  [38400/69667]
loss: 0.073021  [44800/69667]
loss: 0.132239  [51200/69667]
loss: 0.178388  [57600/69667]
loss: 0.132256  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.114358 

Epoch 11
-------------------------------
loss: 0.165494  [    0/69667]
loss: 0.090070  [ 6400/69667]
loss: 0.185884  [12800/69667]
loss: 0.101267  [19200/69667]
loss: 0.159120  [25600/69667]
loss: 0.065779  [32000/69667]
loss: 0.101962  [38400/69667]
loss: 0.229322  [44800/69667]
loss: 0.061851  [51200/69667]
loss: 0.097855  [57600/69667]
loss: 0.118683  [64000/69667]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.111721 

Epoch 12
-------------------------------
loss: 0.082573  [    0/69667]
loss: 0.070558  [ 6400/69667]
loss: 0.194870  [12800/69667]
loss: 0.139876  [19200/69667]
loss: 0.097092  [25600/69667]
loss: 0.171609  [32000/69667]
loss: 0.086192  [38400/69667]
loss: 0.074270  [44800/69667]
loss: 0.048736  [51200/69667]
loss: 0.067315  [57600/69667]
loss: 0.114262  [64000/69667]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.118799 

Epoch 13
-------------------------------
loss: 0.080333  [    0/69667]
loss: 0.132263  [ 6400/69667]
loss: 0.091263  [12800/69667]
loss: 0.077063  [19200/69667]
loss: 0.061090  [25600/69667]
loss: 0.084612  [32000/69667]
loss: 0.122821  [38400/69667]
loss: 0.173501  [44800/69667]
loss: 0.165993  [51200/69667]
loss: 0.280526  [57600/69667]
loss: 0.058650  [64000/69667]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.112687 

Epoch 14
-------------------------------
loss: 0.159306  [    0/69667]
loss: 0.060701  [ 6400/69667]
loss: 0.200138  [12800/69667]
loss: 0.083505  [19200/69667]
loss: 0.130478  [25600/69667]
loss: 0.039381  [32000/69667]
loss: 0.136749  [38400/69667]
loss: 0.099183  [44800/69667]
loss: 0.056925  [51200/69667]
loss: 0.194532  [57600/69667]
loss: 0.077789  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.118529 

Epoch 15
-------------------------------
loss: 0.096161  [    0/69667]
loss: 0.036577  [ 6400/69667]
loss: 0.106058  [12800/69667]
loss: 0.099479  [19200/69667]
loss: 0.118309  [25600/69667]
loss: 0.142602  [32000/69667]
loss: 0.150687  [38400/69667]
loss: 0.152171  [44800/69667]
loss: 0.143694  [51200/69667]
loss: 0.218359  [57600/69667]
loss: 0.090571  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.113827 

Epoch 16
-------------------------------
loss: 0.074296  [    0/69667]
loss: 0.129964  [ 6400/69667]
loss: 0.099369  [12800/69667]
loss: 0.028654  [19200/69667]
loss: 0.193500  [25600/69667]
loss: 0.163923  [32000/69667]
loss: 0.170582  [38400/69667]
loss: 0.177504  [44800/69667]
loss: 0.099795  [51200/69667]
loss: 0.039714  [57600/69667]
loss: 0.036476  [64000/69667]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.120702 

Epoch 17
-------------------------------
loss: 0.223648  [    0/69667]
loss: 0.035608  [ 6400/69667]
loss: 0.083399  [12800/69667]
loss: 0.089678  [19200/69667]
loss: 0.094188  [25600/69667]
loss: 0.075089  [32000/69667]
loss: 0.063115  [38400/69667]
loss: 0.046466  [44800/69667]
loss: 0.161886  [51200/69667]
loss: 0.067110  [57600/69667]
loss: 0.146500  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.116634 

Epoch 18
-------------------------------
loss: 0.042821  [    0/69667]
loss: 0.044671  [ 6400/69667]
loss: 0.143680  [12800/69667]
loss: 0.200615  [19200/69667]
loss: 0.115385  [25600/69667]
loss: 0.147365  [32000/69667]
loss: 0.083599  [38400/69667]
loss: 0.140546  [44800/69667]
loss: 0.058774  [51200/69667]
loss: 0.180902  [57600/69667]
loss: 0.120898  [64000/69667]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.115013 

Epoch 19
-------------------------------
loss: 0.114790  [    0/69667]
loss: 0.120751  [ 6400/69667]
loss: 0.057157  [12800/69667]
loss: 0.169260  [19200/69667]
loss: 0.061239  [25600/69667]
loss: 0.092090  [32000/69667]
loss: 0.097802  [38400/69667]
loss: 0.117994  [44800/69667]
loss: 0.159641  [51200/69667]
loss: 0.070104  [57600/69667]
loss: 0.116381  [64000/69667]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.117843 

Epoch 20
-------------------------------
loss: 0.087135  [    0/69667]
loss: 0.048875  [ 6400/69667]
loss: 0.123342  [12800/69667]
loss: 0.175629  [19200/69667]
loss: 0.067173  [25600/69667]
loss: 0.087720  [32000/69667]
loss: 0.044082  [38400/69667]
loss: 0.095412  [44800/69667]
loss: 0.179774  [51200/69667]
loss: 0.151680  [57600/69667]
loss: 0.117771  [64000/69667]
Test Error: 
 Accuracy: 95.0%, Avg loss: 0.124553 

Epoch 21
-------------------------------
loss: 0.095556  [    0/69667]
loss: 0.156542  [ 6400/69667]
loss: 0.234551  [12800/69667]
loss: 0.099613  [19200/69667]
loss: 0.129836  [25600/69667]
loss: 0.122759  [32000/69667]
loss: 0.054481  [38400/69667]
loss: 0.174459  [44800/69667]
loss: 0.094704  [51200/69667]
loss: 0.136590  [57600/69667]
loss: 0.140103  [64000/69667]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.118389 

Epoch 22
-------------------------------
loss: 0.062989  [    0/69667]
loss: 0.070150  [ 6400/69667]
loss: 0.187256  [12800/69667]
loss: 0.178579  [19200/69667]
loss: 0.042041  [25600/69667]
loss: 0.114104  [32000/69667]
loss: 0.078412  [38400/69667]
loss: 0.157022  [44800/69667]
loss: 0.225756  [51200/69667]
loss: 0.096365  [57600/69667]
loss: 0.101617  [64000/69667]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.113817 

Epoch 23
-------------------------------
loss: 0.059696  [    0/69667]
loss: 0.153087  [ 6400/69667]
loss: 0.115217  [12800/69667]
loss: 0.224773  [19200/69667]
loss: 0.100467  [25600/69667]
loss: 0.176508  [32000/69667]
loss: 0.064582  [38400/69667]
loss: 0.083400  [44800/69667]
loss: 0.089078  [51200/69667]
loss: 0.073073  [57600/69667]
loss: 0.033606  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.116773 

Epoch 24
-------------------------------
loss: 0.106983  [    0/69667]
loss: 0.067294  [ 6400/69667]
loss: 0.118638  [12800/69667]
loss: 0.137308  [19200/69667]
loss: 0.066093  [25600/69667]
loss: 0.044718  [32000/69667]
loss: 0.162592  [38400/69667]
loss: 0.270534  [51200/69195]
loss: 0.079176  [57600/69195]
loss: 0.176680  [64000/69195]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.139526 

Epoch 47
-------------------------------
loss: 0.061677  [    0/69195]
loss: 0.052938  [ 6400/69195]
loss: 0.114685  [12800/69195]
loss: 0.161568  [19200/69195]
loss: 0.266743  [25600/69195]
loss: 0.065585  [32000/69195]
loss: 0.247042  [38400/69195]
loss: 0.201574  [44800/69195]
loss: 0.041698  [51200/69195]
loss: 0.139961  [57600/69195]
loss: 0.152192  [64000/69195]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.138082 

Epoch 48
-------------------------------
loss: 0.112845  [    0/69195]
loss: 0.123288  [ 6400/69195]
loss: 0.179634  [12800/69195]
loss: 0.185301  [19200/69195]
loss: 0.151540  [25600/69195]
loss: 0.126096  [32000/69195]
loss: 0.160447  [38400/69195]
loss: 0.098838  [44800/69195]
loss: 0.091149  [51200/69195]
loss: 0.108195  [57600/69195]
loss: 0.213253  [64000/69195]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.155546 

Epoch 49
-------------------------------
loss: 0.109108  [    0/69195]
loss: 0.215041  [ 6400/69195]
loss: 0.122452  [12800/69195]
loss: 0.109708  [19200/69195]
loss: 0.106034  [25600/69195]
loss: 0.228075  [32000/69195]
loss: 0.069638  [38400/69195]
loss: 0.091126  [44800/69195]
loss: 0.181818  [51200/69195]
loss: 0.146108  [57600/69195]
loss: 0.153250  [64000/69195]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.139601 

Epoch 50
-------------------------------
loss: 0.067255  [    0/69195]
loss: 0.217349  [ 6400/69195]
loss: 0.085013  [12800/69195]
loss: 0.233035  [19200/69195]
loss: 0.150167  [25600/69195]
loss: 0.026565  [32000/69195]
loss: 0.132212  [38400/69195]
loss: 0.118342  [44800/69195]
loss: 0.223662  [51200/69195]
loss: 0.080331  [57600/69195]
loss: 0.119299  [64000/69195]
Test Error: 
 Accuracy: 94.3%, Avg loss: 0.146264 

Epoch 1
-------------------------------
loss: 0.687891  [    0/69978]
loss: 0.247615  [ 6400/69978]
loss: 0.195806  [12800/69978]
loss: 0.230586  [19200/69978]
loss: 0.227519  [25600/69978]
loss: 0.165440  [32000/69978]
loss: 0.321120  [38400/69978]
loss: 0.234609  [44800/69978]
loss: 0.169642  [51200/69978]
loss: 0.304218  [57600/69978]
loss: 0.219240  [64000/69978]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.195830 

Epoch 2
-------------------------------
loss: 0.214976  [    0/69978]
loss: 0.284315  [ 6400/69978]
loss: 0.232188  [12800/69978]
loss: 0.256671  [19200/69978]
loss: 0.223059  [25600/69978]
loss: 0.160207  [32000/69978]
loss: 0.220344  [38400/69978]
loss: 0.158492  [44800/69978]
loss: 0.219747  [51200/69978]
loss: 0.293869  [57600/69978]
loss: 0.207548  [64000/69978]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.181962 

Epoch 3
-------------------------------
loss: 0.265695  [    0/69978]
loss: 0.284227  [ 6400/69978]
loss: 0.185680  [12800/69978]
loss: 0.155705  [19200/69978]
loss: 0.216083  [25600/69978]
loss: 0.239590  [32000/69978]
loss: 0.188451  [38400/69978]
loss: 0.175075  [44800/69978]
loss: 0.206307  [51200/69978]
loss: 0.219205  [57600/69978]
loss: 0.222538  [64000/69978]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.172125 

Epoch 4
-------------------------------
loss: 0.118386  [    0/69978]
loss: 0.112222  [ 6400/69978]
loss: 0.205555  [12800/69978]
loss: 0.345362  [19200/69978]
loss: 0.126259  [25600/69978]
loss: 0.188347  [32000/69978]
loss: 0.168746  [38400/69978]
loss: 0.229260  [44800/69978]
loss: 0.115806  [51200/69978]
loss: 0.122647  [57600/69978]
loss: 0.111405  [64000/69978]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.174637 

Epoch 5
-------------------------------
loss: 0.173866  [    0/69978]
loss: 0.158775  [ 6400/69978]
loss: 0.157794  [12800/69978]
loss: 0.250394  [19200/69978]
loss: 0.228414  [25600/69978]
loss: 0.147019  [32000/69978]
loss: 0.120596  [38400/69978]
loss: 0.232298  [44800/69978]
loss: 0.179155  [51200/69978]
loss: 0.172842  [57600/69978]
loss: 0.151873  [64000/69978]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.170836 

Epoch 6
-------------------------------
loss: 0.241049  [    0/69978]
loss: 0.113926  [ 6400/69978]
loss: 0.146093  [12800/69978]
loss: 0.065095  [19200/69978]
loss: 0.230938  [25600/69978]
loss: 0.398053  [32000/69978]
loss: 0.161005  [38400/69978]
loss: 0.180142  [44800/69978]
loss: 0.133486  [51200/69978]
loss: 0.177486  [57600/69978]
loss: 0.121106  [64000/69978]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.168322 

Epoch 7
-------------------------------
loss: 0.166296  [    0/69978]
loss: 0.257558  [ 6400/69978]
loss: 0.179641  [12800/69978]
loss: 0.143029  [19200/69978]
loss: 0.089028  [25600/69978]
loss: 0.127003  [32000/69978]
loss: 0.278727  [38400/69978]
loss: 0.094770  [44800/69978]
loss: 0.192129  [51200/69978]
loss: 0.170345  [57600/69978]
loss: 0.162382  [64000/69978]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.169909 

Epoch 8
-------------------------------
loss: 0.328562  [    0/69978]
loss: 0.136307  [ 6400/69978]
loss: 0.211367  [12800/69978]
loss: 0.177633  [19200/69978]
loss: 0.336092  [25600/69978]
loss: 0.184796  [32000/69978]
loss: 0.219272  [38400/69978]
loss: 0.124850  [44800/69978]
loss: 0.259506  [51200/69978]
loss: 0.160670  [57600/69978]
loss: 0.087768  [64000/69978]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.161283 

Epoch 9
-------------------------------
loss: 0.179700  [    0/69978]
loss: 0.131779  [ 6400/69978]
loss: 0.184155  [12800/69978]
loss: 0.144465  [19200/69978]
loss: 0.182038  [25600/69978]
loss: 0.141383  [32000/69978]
loss: 0.131265  [38400/69978]
loss: 0.118729  [44800/69978]
loss: 0.233311  [51200/69978]
loss: 0.231699  [57600/69978]
loss: 0.156926  [64000/69978]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.193603 

Epoch 10
-------------------------------
loss: 0.157307  [    0/69978]
loss: 0.127384  [ 6400/69978]
loss: 0.208126  [12800/69978]
loss: 0.209416  [19200/69978]
loss: 0.127409  [25600/69978]
loss: 0.183591  [32000/69978]
loss: 0.190988  [38400/69978]
loss: 0.215073  [44800/69978]
loss: 0.175670  [51200/69978]
loss: 0.140068  [57600/69978]
loss: 0.149734  [64000/69978]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.159549 

Epoch 11
-------------------------------
loss: 0.186862  [    0/69978]
loss: 0.334077  [ 6400/69978]
loss: 0.155811  [12800/69978]
loss: 0.107345  [19200/69978]
loss: 0.154178  [25600/69978]
loss: 0.113630  [32000/69978]
loss: 0.296018  [38400/69978]
loss: 0.105189  [44800/69978]
loss: 0.200751  [51200/69978]
loss: 0.180097  [57600/69978]
loss: 0.157677  [64000/69978]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.180308 

Epoch 12
-------------------------------
loss: 0.115243  [    0/69978]
loss: 0.326245  [ 6400/69978]
loss: 0.234230  [12800/69978]
loss: 0.129423  [19200/69978]
loss: 0.106697  [25600/69978]
loss: 0.129307  [32000/69978]
loss: 0.364131  [38400/69978]
loss: 0.160870  [44800/69978]
loss: 0.158460  [51200/69978]
loss: 0.114699  [57600/69978]
loss: 0.122532  [64000/69978]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.184973 

Epoch 13
-------------------------------
loss: 0.067663  [    0/69978]
loss: 0.081144  [ 6400/69978]
loss: 0.135118  [12800/69978]
loss: 0.256135  [19200/69978]
loss: 0.235920  [25600/69978]
loss: 0.110555  [32000/69978]
loss: 0.119550  [38400/69978]
loss: 0.208658  [44800/69978]
loss: 0.132235  [51200/69978]
loss: 0.155512  [57600/69978]
loss: 0.183452  [64000/69978]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.189709 

Epoch 14
-------------------------------
loss: 0.130135  [    0/69978]
loss: 0.177170  [ 6400/69978]
loss: 0.167504  [12800/69978]
loss: 0.161994  [19200/69978]
loss: 0.087917  [25600/69978]
loss: 0.164443  [32000/69978]
loss: 0.167458  [38400/69978]
loss: 0.159492  [44800/69978]
loss: 0.190288  [51200/69978]
loss: 0.132136  [57600/69978]
loss: 0.111827  [64000/69978]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.177812 

Epoch 15
-------------------------------
loss: 0.167049  [    0/69978]
loss: 0.215018  [ 6400/69978]
loss: 0.087896  [12800/69978]
loss: 0.130155  [19200/69978]
loss: 0.064879  [25600/69978]
loss: 0.082094  [32000/69978]
loss: 0.072587  [38400/69978]
loss: 0.112426  [44800/69978]
loss: 0.115895  [51200/69978]
loss: 0.203230  [57600/69978]
loss: 0.265652  [64000/69978]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.180954 

Epoch 1
-------------------------------
loss: 0.916766  [    0/69771]
loss: 0.343806  [ 6400/69771]
loss: 0.316425  [12800/69771]
loss: 0.283829  [19200/69771]
loss: 0.261648  [25600/69771]
loss: 0.272594  [32000/69771]
loss: 0.206688  [38400/69771]
loss: 0.126582  [44800/69771]
loss: 0.163891  [51200/69771]
loss: 0.318915  [57600/69771]
loss: 0.317061  [64000/69771]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.203141 

Epoch 2
-------------------------------
loss: 0.209037  [    0/69771]
loss: 0.270715  [ 6400/69771]
loss: 0.222221  [12800/69771]
loss: 0.298337  [19200/69771]
loss: 0.255796  [25600/69771]
loss: 0.130416  [32000/69771]
loss: 0.151446  [38400/69771]
loss: 0.272216  [44800/69771]
loss: 0.287067  [51200/69771]
loss: 0.218039  [57600/69771]
loss: 0.185474  [64000/69771]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.207314 

Epoch 3
-------------------------------
loss: 0.203448  [    0/69771]
loss: 0.165332  [ 6400/69771]
loss: 0.209641  [12800/69771]
loss: 0.215497  [19200/69771]
loss: 0.267763  [25600/69771]
loss: 0.217240  [32000/69771]
loss: 0.337832  [38400/69771]
loss: 0.270675  [44800/69771]
loss: 0.268440  [51200/69771]
loss: 0.209362  [57600/69771]
loss: 0.785534  [64000/69771]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.191113 

Epoch 4
-------------------------------
loss: 0.275926  [    0/69771]
loss: 0.193943  [ 6400/69771]
loss: 0.551748  [12800/69771]
loss: 0.201784  [19200/69771]
loss: 0.192428  [25600/69771]
loss: 0.204703  [32000/69771]
loss: 0.220201  [38400/69771]
loss: 0.408020  [44800/69771]
loss: 0.152287  [51200/69771]
loss: 0.250890  [57600/69771]
loss: 0.153167  [64000/69771]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.195842 

Epoch 5
-------------------------------
loss: 0.202811  [    0/69771]
loss: 0.221869  [ 6400/69771]
loss: 0.258009  [12800/69771]
loss: 0.128176  [19200/69771]
loss: 0.125803  [25600/69771]
loss: 0.182562  [32000/69771]
loss: 0.271681  [38400/69771]
loss: 0.130405  [44800/69771]
loss: 0.216292  [51200/69771]
loss: 0.229549  [57600/69771]
loss: 0.141086  [64000/69771]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.188987 

Epoch 6
-------------------------------
loss: 0.148442  [    0/69771]
loss: 0.194668  [ 6400/69771]
loss: 0.136381  [12800/69771]
loss: 0.200504  [19200/69771]
loss: 0.218296  [25600/69771]
loss: 0.140107  [32000/69771]
loss: 0.188185  [38400/69771]
loss: 0.184850  [44800/69771]
loss: 0.251263  [51200/69771]
loss: 0.177020  [57600/69771]
loss: 0.243562  [64000/69771]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.189884 

Epoch 7
-------------------------------
loss: 0.179184  [    0/69771]
loss: 0.172873  [ 6400/69771]
loss: 0.265669  [12800/69771]
loss: 0.276618  [19200/69771]
loss: 0.145844  [25600/69771]
loss: 0.221792  [32000/69771]
loss: 0.246578  [38400/69771]
loss: 0.144241  [44800/69771]
loss: 0.190838  [51200/69771]
loss: 0.220299  [57600/69771]
loss: 0.181776  [64000/69771]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.176394 

Epoch 8
-------------------------------
loss: 0.183853  [    0/69771]
loss: 0.199957  [ 6400/69771]
loss: 0.155677  [12800/69771]
loss: 0.179344  [19200/69771]
loss: 0.158189  [25600/69771]
loss: 0.207870  [32000/69771]
loss: 0.237728  [38400/69771]
loss: 0.275396  [44800/69771]
loss: 0.156334  [51200/69771]
loss: 0.197514  [57600/69771]
loss: 0.140998  [64000/69771]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.177651 

Epoch 9
-------------------------------
loss: 0.225329  [    0/69771]
loss: 0.276946  [ 6400/69771]
loss: 0.153279  [12800/69771]
loss: 0.228585  [19200/69771]
loss: 0.196993  [25600/69771]
loss: 0.089632  [32000/69771]
loss: 0.133492  [38400/69771]
loss: 0.231884  [44800/69771]
loss: 0.346285  [51200/69771]
loss: 0.330244  [57600/69771]
loss: 0.100204  [64000/69771]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.190843 

Epoch 10
-------------------------------
loss: 0.142861  [    0/69771]
loss: 0.197923  [ 6400/69771]
loss: 0.134840  [12800/69771]
loss: 0.129236  [19200/69771]
loss: 0.120332  [25600/69771]
loss: 0.163451  [32000/69771]
loss: 0.188770  [38400/69771]
loss: 0.156953  [44800/69771]
loss: 0.150070  [51200/69771]
loss: 0.182937  [57600/69771]
loss: 0.196723  [64000/69771]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.185283 

Epoch 11
-------------------------------
loss: 0.192283  [    0/69771]
loss: 0.295065  [ 6400/69771]
loss: 0.104594  [12800/69771]
loss: 0.192882  [19200/69771]
loss: 0.183114  [25600/69771]
loss: 0.211967  [32000/69771]
loss: 0.179534  [38400/69771]
loss: 0.227374  [44800/69771]
loss: 0.217591  [51200/69771]
loss: 0.258606  [57600/69771]
loss: 0.260719  [64000/69771]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.179370 

Epoch 12
-------------------------------
loss: 0.215211  [    0/69771]
loss: 0.309179  [ 6400/69771]
loss: 0.173692  [12800/69771]
loss: 0.203335  [19200/69771]
loss: 0.155023  [25600/69771]
loss: 0.145592  [32000/69771]
loss: 0.197837  [38400/69771]
loss: 0.213480  [44800/69771]
loss: 0.150971  [51200/69771]
loss: 0.139092  [57600/69771]
loss: 0.131216  [64000/69771]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.182441 

Epoch 13
-------------------------------
loss: 0.173955  [    0/69771]
loss: 0.108295  [ 6400/69771]
loss: 0.265076  [12800/69771]
loss: 0.127708  [19200/69771]
loss: 0.179890  [25600/69771]
loss: 0.130305  [32000/69771]
loss: 0.188487  [38400/69771]
loss: 0.219074  [44800/69771]
loss: 0.131040  [51200/69771]
loss: 0.176309  [57600/69771]
loss: 0.104048  [64000/69771]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.188614 

Epoch 14
-------------------------------
loss: 0.178278  [    0/69771]
loss: 0.147452  [ 6400/69771]
loss: 0.147521  [12800/69771]
loss: 0.247641  [19200/69771]
loss: 0.186222  [25600/69771]
loss: 0.104040  [32000/69771]
loss: 0.300138  [38400/69771]
loss: 0.205411  [44800/69771]
loss: 0.229408  [51200/69771]
loss: 0.319552  [57600/69771]
loss: 0.255729  [64000/69771]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.186961 

Epoch 15
-------------------------------
loss: 0.221638  [    0/69771]
loss: 0.148314  [ 6400/69771]
loss: 0.096161  [12800/69771]
loss: 0.136378  [19200/69771]
loss: 0.284023  [25600/69771]
loss: 0.229195  [32000/69771]
loss: 0.186646  [38400/69771]
loss: 0.288398  [44800/69771]
loss: 0.185114  [51200/69771]
loss: 0.211360  [57600/69771]
loss: 0.303680  [64000/69771]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.177609 

Epoch 16
-------------------------------
loss: 0.199412  [    0/69771]
loss: 0.195631  [ 6400/69771]
loss: 0.176037  [12800/69771]
loss: 0.232475  [19200/69771]
loss: 0.150297  [25600/69771]
loss: 0.098634  [32000/69771]
loss: 0.197114  [38400/69771]
loss: 0.151954  [44800/69771]
loss: 0.282795  [51200/69771]
loss: 0.109124  [57600/69771]
loss: 0.298238  [64000/69771]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.181249 

Epoch 17
-------------------------------
loss: 0.214516  [    0/69771]
loss: 0.120893  [ 6400/69771]
loss: 0.168966  [12800/69771]
loss: 0.229912  [19200/69771]
loss: 0.080252  [25600/69771]
loss: 0.117282  [32000/69771]
loss: 0.242915  [38400/69771]
loss: 0.252963  [44800/69771]
loss: 0.173191  [51200/69771]
loss: 0.173200  [57600/69771]
loss: 0.117334  [64000/69771]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.197613 

Epoch 18
-------------------------------
loss: 0.131168  [    0/69771]
loss: 0.137520  [ 6400/69771]
loss: 0.072462  [12800/69771]
loss: 0.165394  [19200/69771]
loss: 0.197200  [25600/69771]
loss: 0.143623  [32000/69771]
loss: 0.179825  [38400/69771]
loss: 0.151404  [44800/69771]
loss: 0.229542  [51200/69771]
loss: 0.089565  [57600/69771]
loss: 0.241362  [64000/69771]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.188962 

Epoch 19
-------------------------------
loss: 0.135338  [    0/69771]
loss: 0.197520  [ 6400/69771]
loss: 0.138860  [12800/69771]
loss: 0.154582  [19200/69771]
loss: 0.115932  [25600/69771]
loss: 0.228606  [32000/69771]
loss: 0.161879  [38400/69771]
loss: 0.189661  [44800/69771]
loss: 0.235732  [51200/69771]
loss: 0.182486  [57600/69771]
loss: 0.178733  [64000/69771]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.179957 

Epoch 20
-------------------------------
loss: 0.085272  [    0/69771]
loss: 0.171721  [ 6400/69771]
loss: 0.266639  [12800/69771]
loss: 0.239162  [19200/69771]
loss: 0.044422  [19200/71047]
loss: 0.027668  [25600/71047]
loss: 0.138101  [32000/71047]
loss: 0.044245  [38400/71047]
loss: 0.072511  [44800/71047]
loss: 0.321963  [51200/71047]
loss: 0.050785  [57600/71047]
loss: 0.048199  [64000/71047]
loss: 0.051699  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.081700 

Epoch 9
-------------------------------
loss: 0.061004  [    0/71047]
loss: 0.027732  [ 6400/71047]
loss: 0.021076  [12800/71047]
loss: 0.028765  [19200/71047]
loss: 0.024064  [25600/71047]
loss: 0.129983  [32000/71047]
loss: 0.054409  [38400/71047]
loss: 0.008520  [44800/71047]
loss: 0.064371  [51200/71047]
loss: 0.056662  [57600/71047]
loss: 0.025823  [64000/71047]
loss: 0.020455  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075974 

Epoch 10
-------------------------------
loss: 0.086488  [    0/71047]
loss: 0.134712  [ 6400/71047]
loss: 0.093534  [12800/71047]
loss: 0.086295  [19200/71047]
loss: 0.045577  [25600/71047]
loss: 0.019881  [32000/71047]
loss: 0.122037  [38400/71047]
loss: 0.013764  [44800/71047]
loss: 0.057957  [51200/71047]
loss: 0.060722  [57600/71047]
loss: 0.071562  [64000/71047]
loss: 0.140268  [70400/71047]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.073745 

Epoch 11
-------------------------------
loss: 0.005511  [    0/71047]
loss: 0.019112  [ 6400/71047]
loss: 0.038098  [12800/71047]
loss: 0.053382  [19200/71047]
loss: 0.035286  [25600/71047]
loss: 0.114019  [32000/71047]
loss: 0.127515  [38400/71047]
loss: 0.077177  [44800/71047]
loss: 0.070772  [51200/71047]
loss: 0.089669  [57600/71047]
loss: 0.020793  [64000/71047]
loss: 0.023536  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.070115 

Epoch 12
-------------------------------
loss: 0.104615  [    0/71047]
loss: 0.011459  [ 6400/71047]
loss: 0.070258  [12800/71047]
loss: 0.093330  [19200/71047]
loss: 0.053611  [25600/71047]
loss: 0.025108  [32000/71047]
loss: 0.073641  [38400/71047]
loss: 0.066708  [44800/71047]
loss: 0.063086  [51200/71047]
loss: 0.051969  [57600/71047]
loss: 0.058771  [64000/71047]
loss: 0.009367  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.079835 

Epoch 13
-------------------------------
loss: 0.023716  [    0/71047]
loss: 0.063430  [ 6400/71047]
loss: 0.019533  [12800/71047]
loss: 0.045342  [19200/71047]
loss: 0.102901  [25600/71047]
loss: 0.038078  [32000/71047]
loss: 0.082642  [38400/71047]
loss: 0.014306  [44800/71047]
loss: 0.021816  [51200/71047]
loss: 0.095867  [57600/71047]
loss: 0.070611  [64000/71047]
loss: 0.114542  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.074033 

Epoch 14
-------------------------------
loss: 0.101635  [    0/71047]
loss: 0.017240  [ 6400/71047]
loss: 0.071708  [12800/71047]
loss: 0.082487  [19200/71047]
loss: 0.044704  [25600/71047]
loss: 0.041574  [32000/71047]
loss: 0.043716  [38400/71047]
loss: 0.143010  [44800/71047]
loss: 0.187849  [51200/71047]
loss: 0.041623  [57600/71047]
loss: 0.056172  [64000/71047]
loss: 0.080663  [70400/71047]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.114177 

Epoch 15
-------------------------------
loss: 0.036704  [    0/71047]
loss: 0.014915  [ 6400/71047]
loss: 0.057982  [12800/71047]
loss: 0.025558  [19200/71047]
loss: 0.030513  [25600/71047]
loss: 0.055902  [32000/71047]
loss: 0.057822  [38400/71047]
loss: 0.083296  [44800/71047]
loss: 0.111871  [51200/71047]
loss: 0.078121  [57600/71047]
loss: 0.081386  [64000/71047]
loss: 0.101932  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.071106 

Epoch 16
-------------------------------
loss: 0.030629  [    0/71047]
loss: 0.169989  [ 6400/71047]
loss: 0.013021  [12800/71047]
loss: 0.009839  [19200/71047]
loss: 0.052788  [25600/71047]
loss: 0.080785  [32000/71047]
loss: 0.026379  [38400/71047]
loss: 0.034957  [44800/71047]
loss: 0.026956  [51200/71047]
loss: 0.026933  [57600/71047]
loss: 0.079673  [64000/71047]
loss: 0.069082  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067305 

Epoch 17
-------------------------------
loss: 0.029281  [    0/71047]
loss: 0.054019  [ 6400/71047]
loss: 0.060415  [12800/71047]
loss: 0.064963  [19200/71047]
loss: 0.012783  [25600/71047]
loss: 0.023984  [32000/71047]
loss: 0.064818  [38400/71047]
loss: 0.019221  [44800/71047]
loss: 0.063719  [51200/71047]
loss: 0.082725  [57600/71047]
loss: 0.054153  [64000/71047]
loss: 0.006485  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.070652 

Epoch 18
-------------------------------
loss: 0.088728  [    0/71047]
loss: 0.072100  [ 6400/71047]
loss: 0.113083  [12800/71047]
loss: 0.055269  [19200/71047]
loss: 0.082811  [25600/71047]
loss: 0.069022  [32000/71047]
loss: 0.078891  [38400/71047]
loss: 0.026256  [44800/71047]
loss: 0.078146  [51200/71047]
loss: 0.017970  [57600/71047]
loss: 0.055014  [64000/71047]
loss: 0.058709  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074055 

Epoch 19
-------------------------------
loss: 0.088533  [    0/71047]
loss: 0.065928  [ 6400/71047]
loss: 0.072167  [12800/71047]
loss: 0.074142  [19200/71047]
loss: 0.045303  [25600/71047]
loss: 0.036049  [32000/71047]
loss: 0.109460  [38400/71047]
loss: 0.016152  [44800/71047]
loss: 0.048982  [51200/71047]
loss: 0.118647  [57600/71047]
loss: 0.049261  [64000/71047]
loss: 0.037300  [70400/71047]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.075739 

Epoch 20
-------------------------------
loss: 0.044535  [    0/71047]
loss: 0.060124  [ 6400/71047]
loss: 0.085908  [12800/71047]
loss: 0.037805  [19200/71047]
loss: 0.094166  [25600/71047]
loss: 0.005745  [32000/71047]
loss: 0.054417  [38400/71047]
loss: 0.205737  [44800/71047]
loss: 0.034749  [51200/71047]
loss: 0.014930  [57600/71047]
loss: 0.034660  [64000/71047]
loss: 0.007422  [70400/71047]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.068285 

Epoch 21
-------------------------------
loss: 0.004505  [    0/71047]
loss: 1.595847  [ 6400/71047]
loss: 0.038423  [12800/71047]
loss: 0.016818  [19200/71047]
loss: 0.040670  [25600/71047]
loss: 0.007336  [32000/71047]
loss: 0.033492  [38400/71047]
loss: 0.068679  [44800/71047]
loss: 0.007224  [51200/71047]
loss: 0.020384  [57600/71047]
loss: 0.094256  [64000/71047]
loss: 0.010651  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.070819 

Epoch 22
-------------------------------
loss: 0.040106  [    0/71047]
loss: 0.060693  [ 6400/71047]
loss: 0.014243  [12800/71047]
loss: 0.051914  [19200/71047]
loss: 0.056091  [25600/71047]
loss: 0.056722  [32000/71047]
loss: 0.062860  [38400/71047]
loss: 0.108399  [44800/71047]
loss: 0.074226  [51200/71047]
loss: 0.050741  [57600/71047]
loss: 0.022523  [64000/71047]
loss: 0.003164  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.071130 

Epoch 23
-------------------------------
loss: 0.097623  [    0/71047]
loss: 0.051765  [ 6400/71047]
loss: 0.095579  [12800/71047]
loss: 0.013163  [19200/71047]
loss: 0.036616  [25600/71047]
loss: 0.030437  [32000/71047]
loss: 0.077945  [38400/71047]
loss: 0.023714  [44800/71047]
loss: 0.055071  [51200/71047]
loss: 0.033389  [57600/71047]
loss: 0.012280  [64000/71047]
loss: 0.133574  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.070300 

Epoch 24
-------------------------------
loss: 0.032734  [    0/71047]
loss: 0.105011  [ 6400/71047]
loss: 0.011491  [12800/71047]
loss: 0.053599  [19200/71047]
loss: 0.038236  [25600/71047]
loss: 0.016324  [32000/71047]
loss: 0.074190  [38400/71047]
loss: 0.099990  [44800/71047]
loss: 0.056215  [51200/71047]
loss: 0.054549  [57600/71047]
loss: 0.033313  [64000/71047]
loss: 0.042170  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.069017 

Epoch 25
-------------------------------
loss: 0.090910  [    0/71047]
loss: 0.063022  [ 6400/71047]
loss: 0.034803  [12800/71047]
loss: 0.035546  [19200/71047]
loss: 0.078958  [25600/71047]
loss: 0.157557  [32000/71047]
loss: 0.017395  [38400/71047]
loss: 0.046588  [44800/71047]
loss: 0.068868  [51200/71047]
loss: 0.044378  [57600/71047]
loss: 0.035503  [64000/71047]
loss: 0.184901  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075016 

Epoch 26
-------------------------------
loss: 0.007434  [    0/71047]
loss: 0.014685  [ 6400/71047]
loss: 0.020120  [12800/71047]
loss: 0.045443  [19200/71047]
loss: 0.090297  [64000/69840]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.165443 

Epoch 47
-------------------------------
loss: 0.145663  [    0/69840]
loss: 0.097398  [ 6400/69840]
loss: 0.157460  [12800/69840]
loss: 0.093966  [19200/69840]
loss: 0.209197  [25600/69840]
loss: 0.094506  [32000/69840]
loss: 0.140331  [38400/69840]
loss: 0.035039  [44800/69840]
loss: 0.110445  [51200/69840]
loss: 0.139861  [57600/69840]
loss: 0.097150  [64000/69840]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.158873 

Epoch 48
-------------------------------
loss: 0.207063  [    0/69840]
loss: 0.158951  [ 6400/69840]
loss: 0.109941  [12800/69840]
loss: 1.728270  [19200/69840]
loss: 0.113942  [25600/69840]
loss: 0.170437  [32000/69840]
loss: 0.084483  [38400/69840]
loss: 0.073351  [44800/69840]
loss: 0.101993  [51200/69840]
loss: 0.171047  [57600/69840]
loss: 0.119518  [64000/69840]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.161173 

Epoch 49
-------------------------------
loss: 0.140827  [    0/69840]
loss: 0.170611  [ 6400/69840]
loss: 0.147058  [12800/69840]
loss: 0.163313  [19200/69840]
loss: 0.116087  [25600/69840]
loss: 0.091047  [32000/69840]
loss: 0.058724  [38400/69840]
loss: 0.094994  [44800/69840]
loss: 0.144818  [51200/69840]
loss: 0.057966  [57600/69840]
loss: 0.153965  [64000/69840]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.183213 

Epoch 50
-------------------------------
loss: 0.180235  [    0/69840]
loss: 0.334952  [ 6400/69840]
loss: 0.129140  [12800/69840]
loss: 0.095970  [19200/69840]
loss: 0.187169  [25600/69840]
loss: 0.144585  [32000/69840]
loss: 0.276144  [38400/69840]
loss: 0.135302  [44800/69840]
loss: 0.274871  [51200/69840]
loss: 0.215310  [57600/69840]
loss: 0.194775  [64000/69840]
Test Error: 
 Accuracy: 94.5%, Avg loss: 0.154950 

Epoch 1
-------------------------------
loss: 0.663452  [    0/69744]
loss: 0.354048  [ 6400/69744]
loss: 0.207846  [12800/69744]
loss: 0.174685  [19200/69744]
loss: 0.266405  [25600/69744]
loss: 0.065573  [32000/69744]
loss: 0.307852  [38400/69744]
loss: 0.201711  [44800/69744]
loss: 0.181066  [51200/69744]
loss: 0.234420  [57600/69744]
loss: 0.286066  [64000/69744]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.185680 

Epoch 2
-------------------------------
loss: 0.195793  [    0/69744]
loss: 0.248547  [ 6400/69744]
loss: 0.133609  [12800/69744]
loss: 0.186279  [19200/69744]
loss: 0.073217  [25600/69744]
loss: 0.131245  [32000/69744]
loss: 0.193718  [38400/69744]
loss: 0.151690  [44800/69744]
loss: 0.081021  [51200/69744]
loss: 0.136129  [57600/69744]
loss: 0.158456  [64000/69744]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.179662 

Epoch 3
-------------------------------
loss: 0.262797  [    0/69744]
loss: 0.226026  [ 6400/69744]
loss: 0.133187  [12800/69744]
loss: 0.215635  [19200/69744]
loss: 0.101258  [25600/69744]
loss: 0.196676  [32000/69744]
loss: 0.160941  [38400/69744]
loss: 0.122971  [44800/69744]
loss: 0.226895  [51200/69744]
loss: 0.212518  [57600/69744]
loss: 0.131416  [64000/69744]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.169467 

Epoch 4
-------------------------------
loss: 0.190165  [    0/69744]
loss: 0.110659  [ 6400/69744]
loss: 0.117834  [12800/69744]
loss: 0.169086  [19200/69744]
loss: 0.115551  [25600/69744]
loss: 0.199395  [32000/69744]
loss: 0.181079  [38400/69744]
loss: 0.126172  [44800/69744]
loss: 0.416586  [51200/69744]
loss: 0.122443  [57600/69744]
loss: 0.178479  [64000/69744]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.165310 

Epoch 5
-------------------------------
loss: 0.073259  [    0/69744]
loss: 0.152734  [ 6400/69744]
loss: 0.218943  [12800/69744]
loss: 0.273008  [19200/69744]
loss: 0.251408  [25600/69744]
loss: 0.262749  [32000/69744]
loss: 0.223172  [38400/69744]
loss: 0.180260  [44800/69744]
loss: 0.195778  [51200/69744]
loss: 0.371338  [57600/69744]
loss: 0.218187  [64000/69744]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.166004 

Epoch 6
-------------------------------
loss: 0.208116  [    0/69744]
loss: 0.265952  [ 6400/69744]
loss: 0.110671  [12800/69744]
loss: 0.170855  [19200/69744]
loss: 0.111833  [25600/69744]
loss: 0.207251  [32000/69744]
loss: 0.124474  [38400/69744]
loss: 0.170087  [44800/69744]
loss: 0.286115  [51200/69744]
loss: 0.193515  [57600/69744]
loss: 0.128028  [64000/69744]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.173991 

Epoch 7
-------------------------------
loss: 0.142389  [    0/69744]
loss: 0.160356  [ 6400/69744]
loss: 0.186921  [12800/69744]
loss: 0.143849  [19200/69744]
loss: 0.129391  [25600/69744]
loss: 0.128568  [32000/69744]
loss: 0.156470  [38400/69744]
loss: 0.106847  [44800/69744]
loss: 0.166085  [51200/69744]
loss: 0.197191  [57600/69744]
loss: 0.065508  [64000/69744]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.168315 

Epoch 8
-------------------------------
loss: 0.218475  [    0/69744]
loss: 0.101787  [ 6400/69744]
loss: 0.074443  [12800/69744]
loss: 0.097967  [19200/69744]
loss: 0.154366  [25600/69744]
loss: 0.126635  [32000/69744]
loss: 0.115557  [38400/69744]
loss: 0.198367  [44800/69744]
loss: 0.174562  [51200/69744]
loss: 0.106941  [57600/69744]
loss: 0.234814  [64000/69744]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.176244 

Epoch 9
-------------------------------
loss: 0.148127  [    0/69744]
loss: 0.122501  [ 6400/69744]
loss: 0.160374  [12800/69744]
loss: 0.128057  [19200/69744]
loss: 0.139629  [25600/69744]
loss: 0.213218  [32000/69744]
loss: 0.208208  [38400/69744]
loss: 0.145591  [44800/69744]
loss: 0.118176  [51200/69744]
loss: 0.179568  [57600/69744]
loss: 0.209962  [64000/69744]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.169440 

Epoch 10
-------------------------------
loss: 0.151971  [    0/69744]
loss: 0.204066  [ 6400/69744]
loss: 0.229195  [12800/69744]
loss: 0.178485  [19200/69744]
loss: 0.255371  [25600/69744]
loss: 0.099959  [32000/69744]
loss: 0.121796  [38400/69744]
loss: 0.052494  [44800/69744]
loss: 0.175317  [51200/69744]
loss: 0.191594  [57600/69744]
loss: 0.142048  [64000/69744]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.166466 

Epoch 11
-------------------------------
loss: 0.129611  [    0/69744]
loss: 0.131011  [ 6400/69744]
loss: 0.080819  [12800/69744]
loss: 0.069720  [19200/69744]
loss: 0.063728  [25600/69744]
loss: 0.122415  [32000/69744]
loss: 0.082793  [38400/69744]
loss: 0.083346  [44800/69744]
loss: 0.310121  [51200/69744]
loss: 0.206128  [57600/69744]
loss: 0.097439  [64000/69744]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.155619 

Epoch 12
-------------------------------
loss: 0.214281  [    0/69744]
loss: 0.061838  [ 6400/69744]
loss: 0.079581  [12800/69744]
loss: 0.165969  [19200/69744]
loss: 0.291973  [25600/69744]
loss: 0.183991  [32000/69744]
loss: 0.138813  [38400/69744]
loss: 0.231376  [44800/69744]
loss: 0.080224  [51200/69744]
loss: 0.161723  [57600/69744]
loss: 0.157404  [64000/69744]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.162779 

Epoch 13
-------------------------------
loss: 0.083146  [    0/69744]
loss: 0.192708  [ 6400/69744]
loss: 0.085680  [12800/69744]
loss: 0.135898  [19200/69744]
loss: 0.163563  [25600/69744]
loss: 0.315273  [32000/69744]
loss: 0.180735  [38400/69744]
loss: 0.104081  [44800/69744]
loss: 0.196678  [51200/69744]
loss: 0.136831  [57600/69744]
loss: 0.162638  [64000/69744]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.159778 

Epoch 14
-------------------------------
loss: 0.136999  [    0/69744]
loss: 0.253453  [ 6400/69744]
loss: 0.225425  [12800/69744]
loss: 0.177696  [19200/69744]
loss: 0.157502  [25600/69744]
loss: 0.100626  [32000/69744]
loss: 0.092030  [38400/69744]
loss: 0.152694  [44800/69744]
loss: 0.147874  [51200/69744]
loss: 0.054994  [57600/69744]
loss: 0.050744  [64000/69744]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.170756 

Epoch 15
-------------------------------
loss: 0.109888  [    0/69744]
loss: 0.174233  [ 6400/69744]
loss: 0.135203  [12800/69744]
loss: 0.134254  [19200/69744]
loss: 0.126447  [25600/69744]
loss: 0.145952  [32000/69744]
loss: 0.108367  [38400/69744]
loss: 0.148314  [44800/69744]
loss: 0.158695  [51200/69744]
loss: 0.122087  [57600/69744]
loss: 0.201981  [64000/69744]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.169459 

Epoch 16
-------------------------------
loss: 0.165398  [    0/69744]
loss: 0.052237  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067731 

Epoch 12
-------------------------------
loss: 0.033144  [    0/70789]
loss: 0.061269  [ 6400/70789]
loss: 0.145128  [12800/70789]
loss: 0.099346  [19200/70789]
loss: 0.070014  [25600/70789]
loss: 0.140817  [32000/70789]
loss: 0.008092  [38400/70789]
loss: 0.131433  [44800/70789]
loss: 0.031258  [51200/70789]
loss: 0.037877  [57600/70789]
loss: 0.058623  [64000/70789]
loss: 0.012189  [70400/70789]
Test Error: 
 Accuracy: 97.2%, Avg loss: 0.084139 

Epoch 13
-------------------------------
loss: 0.032890  [    0/70789]
loss: 0.041418  [ 6400/70789]
loss: 0.010537  [12800/70789]
loss: 0.061857  [19200/70789]
loss: 0.012027  [25600/70789]
loss: 0.036134  [32000/70789]
loss: 0.076979  [38400/70789]
loss: 0.032005  [44800/70789]
loss: 0.110611  [51200/70789]
loss: 0.084422  [57600/70789]
loss: 0.070017  [64000/70789]
loss: 0.092874  [70400/70789]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.068984 

Epoch 14
-------------------------------
loss: 0.015865  [    0/70789]
loss: 0.039750  [ 6400/70789]
loss: 0.035128  [12800/70789]
loss: 0.026162  [19200/70789]
loss: 0.032340  [25600/70789]
loss: 0.038561  [32000/70789]
loss: 0.033471  [38400/70789]
loss: 0.050393  [44800/70789]
loss: 0.188508  [51200/70789]
loss: 0.034543  [57600/70789]
loss: 0.084445  [64000/70789]
loss: 0.076341  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.066225 

Epoch 15
-------------------------------
loss: 0.062589  [    0/70789]
loss: 0.094542  [ 6400/70789]
loss: 0.051059  [12800/70789]
loss: 0.060445  [19200/70789]
loss: 0.015431  [25600/70789]
loss: 0.020229  [32000/70789]
loss: 0.047281  [38400/70789]
loss: 0.090278  [44800/70789]
loss: 0.056481  [51200/70789]
loss: 0.113609  [57600/70789]
loss: 0.051999  [64000/70789]
loss: 0.091043  [70400/70789]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.069766 

Epoch 16
-------------------------------
loss: 0.066456  [    0/70789]
loss: 0.046584  [ 6400/70789]
loss: 0.050517  [12800/70789]
loss: 0.016012  [19200/70789]
loss: 0.052186  [25600/70789]
loss: 0.073121  [32000/70789]
loss: 0.095545  [38400/70789]
loss: 0.116623  [44800/70789]
loss: 0.037444  [51200/70789]
loss: 0.011157  [57600/70789]
loss: 0.031399  [64000/70789]
loss: 0.015675  [70400/70789]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.064722 

Epoch 17
-------------------------------
loss: 0.069893  [    0/70789]
loss: 0.011534  [ 6400/70789]
loss: 0.036377  [12800/70789]
loss: 0.004941  [19200/70789]
loss: 0.002688  [25600/70789]
loss: 0.028995  [32000/70789]
loss: 0.094665  [38400/70789]
loss: 0.028416  [44800/70789]
loss: 0.120606  [51200/70789]
loss: 0.014358  [57600/70789]
loss: 0.110020  [64000/70789]
loss: 0.036075  [70400/70789]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075930 

Epoch 18
-------------------------------
loss: 0.058514  [    0/70789]
loss: 0.027543  [ 6400/70789]
loss: 0.039031  [12800/70789]
loss: 0.158621  [19200/70789]
loss: 0.058179  [25600/70789]
loss: 0.012444  [32000/70789]
loss: 0.039968  [38400/70789]
loss: 0.007546  [44800/70789]
loss: 0.084131  [51200/70789]
loss: 0.032667  [57600/70789]
loss: 0.063413  [64000/70789]
loss: 0.039282  [70400/70789]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.066537 

Epoch 19
-------------------------------
loss: 0.059225  [    0/70789]
loss: 0.073463  [ 6400/70789]
loss: 0.072457  [12800/70789]
loss: 0.090307  [19200/70789]
loss: 0.042976  [25600/70789]
loss: 0.079306  [32000/70789]
loss: 0.049450  [38400/70789]
loss: 0.022053  [44800/70789]
loss: 0.109645  [51200/70789]
loss: 0.039943  [57600/70789]
loss: 0.039810  [64000/70789]
loss: 0.037706  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.066760 

Epoch 20
-------------------------------
loss: 0.072278  [    0/70789]
loss: 0.113817  [ 6400/70789]
loss: 0.051656  [12800/70789]
loss: 0.027013  [19200/70789]
loss: 0.032208  [25600/70789]
loss: 0.070819  [32000/70789]
loss: 0.029200  [38400/70789]
loss: 0.025747  [44800/70789]
loss: 0.036393  [51200/70789]
loss: 0.016237  [57600/70789]
loss: 0.046118  [64000/70789]
loss: 0.054113  [70400/70789]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.064852 

Epoch 21
-------------------------------
loss: 0.062492  [    0/70789]
loss: 0.124504  [ 6400/70789]
loss: 0.007896  [12800/70789]
loss: 0.008982  [19200/70789]
loss: 0.013239  [25600/70789]
loss: 0.021868  [32000/70789]
loss: 0.024961  [38400/70789]
loss: 0.095256  [44800/70789]
loss: 0.077781  [51200/70789]
loss: 0.038882  [57600/70789]
loss: 0.034039  [64000/70789]
loss: 0.039556  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.068921 

Epoch 22
-------------------------------
loss: 0.044648  [    0/70789]
loss: 0.013526  [ 6400/70789]
loss: 0.008191  [12800/70789]
loss: 0.074935  [19200/70789]
loss: 0.104893  [25600/70789]
loss: 0.187551  [32000/70789]
loss: 0.039501  [38400/70789]
loss: 0.020788  [44800/70789]
loss: 0.091949  [51200/70789]
loss: 0.110455  [57600/70789]
loss: 0.097584  [64000/70789]
loss: 0.028750  [70400/70789]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.067139 

Epoch 23
-------------------------------
loss: 0.011736  [    0/70789]
loss: 0.073217  [ 6400/70789]
loss: 0.060255  [12800/70789]
loss: 0.009369  [19200/70789]
loss: 0.013537  [25600/70789]
loss: 0.156149  [32000/70789]
loss: 0.150513  [38400/70789]
loss: 0.146763  [44800/70789]
loss: 0.037146  [51200/70789]
loss: 0.040233  [57600/70789]
loss: 0.060680  [64000/70789]
loss: 0.055200  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.069964 

Epoch 24
-------------------------------
loss: 0.023272  [    0/70789]
loss: 0.083322  [ 6400/70789]
loss: 0.037684  [12800/70789]
loss: 0.022242  [19200/70789]
loss: 0.041934  [25600/70789]
loss: 0.071486  [32000/70789]
loss: 0.021271  [38400/70789]
loss: 0.098761  [44800/70789]
loss: 0.049138  [51200/70789]
loss: 0.082653  [57600/70789]
loss: 0.020836  [64000/70789]
loss: 0.022268  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072790 

Epoch 25
-------------------------------
loss: 0.048553  [    0/70789]
loss: 0.066064  [ 6400/70789]
loss: 0.062576  [12800/70789]
loss: 0.055233  [19200/70789]
loss: 0.012982  [25600/70789]
loss: 0.032505  [32000/70789]
loss: 0.100135  [38400/70789]
loss: 0.121666  [44800/70789]
loss: 0.075138  [51200/70789]
loss: 0.044372  [57600/70789]
loss: 0.029012  [64000/70789]
loss: 0.013443  [70400/70789]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.169279 

Epoch 26
-------------------------------
loss: 0.131196  [    0/70789]
loss: 0.026071  [ 6400/70789]
loss: 0.021397  [12800/70789]
loss: 0.058363  [19200/70789]
loss: 0.228928  [25600/70789]
loss: 0.009730  [32000/70789]
loss: 0.051779  [38400/70789]
loss: 0.074551  [44800/70789]
loss: 0.009690  [51200/70789]
loss: 0.040437  [57600/70789]
loss: 0.034628  [64000/70789]
loss: 0.046102  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.073793 

Epoch 27
-------------------------------
loss: 0.050687  [    0/70789]
loss: 0.054147  [ 6400/70789]
loss: 0.009337  [12800/70789]
loss: 0.019790  [19200/70789]
loss: 0.039783  [25600/70789]
loss: 0.061031  [32000/70789]
loss: 0.054700  [38400/70789]
loss: 0.098935  [44800/70789]
loss: 0.075074  [51200/70789]
loss: 0.017821  [57600/70789]
loss: 0.034153  [64000/70789]
loss: 0.039899  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.071746 

Epoch 28
-------------------------------
loss: 0.073646  [    0/70789]
loss: 0.019556  [ 6400/70789]
loss: 0.017242  [12800/70789]
loss: 0.087400  [19200/70789]
loss: 0.141097  [25600/70789]
loss: 0.015814  [32000/70789]
loss: 0.035336  [38400/70789]
loss: 0.041513  [44800/70789]
loss: 0.017560  [51200/70789]
loss: 0.144752  [57600/70789]
loss: 0.027974  [64000/70789]
loss: 0.005983  [70400/70789]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.064615 

Epoch 29
-------------------------------
loss: 0.018192  [    0/70789]
loss: 0.114730  [ 6400/70789]
loss: 0.091638  [12800/70789]
loss: 0.026426  [19200/70789]
loss: 0.038759  [25600/70789]
loss: 0.131421  [32000/70789]
loss: 0.095638  [38400/70789]
loss: 0.030185  [44800/70789]
loss: 0.042596  [51200/70789]
loss: 0.027494  [57600/70789]
loss: 0.050803  [64000/70789]
loss: 0.006772  [70400/70789]
Epoch 43
-------------------------------
loss: 0.122011  [    0/69642]
loss: 0.208956  [ 6400/69642]
loss: 0.234992  [12800/69642]
loss: 0.169729  [19200/69642]
loss: 0.179234  [25600/69642]
loss: 0.153963  [32000/69642]
loss: 0.205613  [38400/69642]
loss: 0.160543  [44800/69642]
loss: 0.280854  [51200/69642]
loss: 0.155146  [57600/69642]
loss: 0.135877  [64000/69642]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.157551 

Epoch 44
-------------------------------
loss: 0.161888  [    0/69642]
loss: 0.185648  [ 6400/69642]
loss: 0.209444  [12800/69642]
loss: 0.135656  [19200/69642]
loss: 0.283909  [25600/69642]
loss: 0.147031  [32000/69642]
loss: 0.060157  [38400/69642]
loss: 0.181236  [44800/69642]
loss: 0.191871  [51200/69642]
loss: 0.110583  [57600/69642]
loss: 0.060394  [64000/69642]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.157680 

Epoch 45
-------------------------------
loss: 0.224314  [    0/69642]
loss: 0.181142  [ 6400/69642]
loss: 0.207847  [12800/69642]
loss: 0.201581  [19200/69642]
loss: 0.102449  [25600/69642]
loss: 0.231112  [32000/69642]
loss: 0.109177  [38400/69642]
loss: 0.269723  [44800/69642]
loss: 0.083047  [51200/69642]
loss: 0.241295  [57600/69642]
loss: 0.145295  [64000/69642]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.156298 

Epoch 46
-------------------------------
loss: 0.112665  [    0/69642]
loss: 0.258930  [ 6400/69642]
loss: 0.103391  [12800/69642]
loss: 0.242168  [19200/69642]
loss: 0.227911  [25600/69642]
loss: 0.208702  [32000/69642]
loss: 0.100782  [38400/69642]
loss: 0.079813  [44800/69642]
loss: 0.176298  [51200/69642]
loss: 0.123988  [57600/69642]
loss: 0.245490  [64000/69642]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.163606 

Epoch 47
-------------------------------
loss: 0.202411  [    0/69642]
loss: 0.209800  [ 6400/69642]
loss: 0.295427  [12800/69642]
loss: 0.159044  [19200/69642]
loss: 0.152616  [25600/69642]
loss: 0.135603  [32000/69642]
loss: 0.099251  [38400/69642]
loss: 0.155125  [44800/69642]
loss: 0.201522  [51200/69642]
loss: 0.146330  [57600/69642]
loss: 0.102461  [64000/69642]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.157004 

Epoch 48
-------------------------------
loss: 0.166240  [    0/69642]
loss: 0.135849  [ 6400/69642]
loss: 0.106882  [12800/69642]
loss: 0.078256  [19200/69642]
loss: 0.226234  [25600/69642]
loss: 0.137747  [32000/69642]
loss: 0.096345  [38400/69642]
loss: 0.182881  [44800/69642]
loss: 0.109321  [51200/69642]
loss: 0.084629  [57600/69642]
loss: 0.244868  [64000/69642]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.160613 

Epoch 49
-------------------------------
loss: 0.127969  [    0/69642]
loss: 0.211517  [ 6400/69642]
loss: 0.143242  [12800/69642]
loss: 0.257772  [19200/69642]
loss: 0.159694  [25600/69642]
loss: 0.250204  [32000/69642]
loss: 0.328247  [38400/69642]
loss: 0.171029  [44800/69642]
loss: 0.121890  [51200/69642]
loss: 0.125424  [57600/69642]
loss: 0.172350  [64000/69642]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.185238 

Epoch 50
-------------------------------
loss: 0.252222  [    0/69642]
loss: 0.160783  [ 6400/69642]
loss: 0.237478  [12800/69642]
loss: 0.170736  [19200/69642]
loss: 0.136828  [25600/69642]
loss: 0.246972  [32000/69642]
loss: 0.097147  [38400/69642]
loss: 0.063930  [44800/69642]
loss: 0.167264  [51200/69642]
loss: 0.194725  [57600/69642]
loss: 0.189641  [64000/69642]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.175953 

Epoch 1
-------------------------------
loss: 0.635722  [    0/70370]
loss: 0.228586  [ 6400/70370]
loss: 0.309915  [12800/70370]
loss: 0.268990  [19200/70370]
loss: 0.194158  [25600/70370]
loss: 0.275387  [32000/70370]
loss: 0.323812  [38400/70370]
loss: 0.326198  [44800/70370]
loss: 0.283432  [51200/70370]
loss: 0.258741  [57600/70370]
loss: 0.212477  [64000/70370]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.184788 

Epoch 2
-------------------------------
loss: 0.198903  [    0/70370]
loss: 0.167087  [ 6400/70370]
loss: 0.177835  [12800/70370]
loss: 0.117874  [19200/70370]
loss: 0.278881  [25600/70370]
loss: 0.166258  [32000/70370]
loss: 0.197702  [38400/70370]
loss: 0.187566  [44800/70370]
loss: 0.360181  [51200/70370]
loss: 0.145232  [57600/70370]
loss: 0.156963  [64000/70370]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.172168 

Epoch 3
-------------------------------
loss: 0.163815  [    0/70370]
loss: 0.183055  [ 6400/70370]
loss: 0.204290  [12800/70370]
loss: 0.163365  [19200/70370]
loss: 0.169553  [25600/70370]
loss: 0.260311  [32000/70370]
loss: 0.096826  [38400/70370]
loss: 0.140252  [44800/70370]
loss: 0.272778  [51200/70370]
loss: 0.128903  [57600/70370]
loss: 0.179948  [64000/70370]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.165127 

Epoch 4
-------------------------------
loss: 0.181199  [    0/70370]
loss: 0.136280  [ 6400/70370]
loss: 0.259394  [12800/70370]
loss: 0.217357  [19200/70370]
loss: 0.190372  [25600/70370]
loss: 0.187170  [32000/70370]
loss: 0.211089  [38400/70370]
loss: 0.153445  [44800/70370]
loss: 0.181655  [51200/70370]
loss: 0.160916  [57600/70370]
loss: 0.184172  [64000/70370]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.162617 

Epoch 5
-------------------------------
loss: 0.140011  [    0/70370]
loss: 0.139106  [ 6400/70370]
loss: 0.285092  [12800/70370]
loss: 0.148034  [19200/70370]
loss: 0.229333  [25600/70370]
loss: 0.177222  [32000/70370]
loss: 0.142425  [38400/70370]
loss: 0.147872  [44800/70370]
loss: 0.214533  [51200/70370]
loss: 0.282578  [57600/70370]
loss: 0.142644  [64000/70370]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.160842 

Epoch 6
-------------------------------
loss: 0.149164  [    0/70370]
loss: 0.162716  [ 6400/70370]
loss: 0.242052  [12800/70370]
loss: 0.114249  [19200/70370]
loss: 0.145115  [25600/70370]
loss: 0.138080  [32000/70370]
loss: 0.190202  [38400/70370]
loss: 0.176539  [44800/70370]
loss: 0.190258  [51200/70370]
loss: 0.208955  [57600/70370]
loss: 0.182483  [64000/70370]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.183745 

Epoch 7
-------------------------------
loss: 0.147761  [    0/70370]
loss: 0.064157  [ 6400/70370]
loss: 0.203900  [12800/70370]
loss: 0.170941  [19200/70370]
loss: 0.241979  [25600/70370]
loss: 0.141669  [32000/70370]
loss: 0.185907  [38400/70370]
loss: 0.218581  [44800/70370]
loss: 0.202054  [51200/70370]
loss: 0.156215  [57600/70370]
loss: 0.167344  [64000/70370]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.151882 

Epoch 8
-------------------------------
loss: 0.046173  [    0/70370]
loss: 0.175632  [ 6400/70370]
loss: 0.149141  [12800/70370]
loss: 0.154173  [19200/70370]
loss: 0.074316  [25600/70370]
loss: 0.260551  [32000/70370]
loss: 0.077816  [38400/70370]
loss: 0.066260  [44800/70370]
loss: 0.137782  [51200/70370]
loss: 0.270768  [57600/70370]
loss: 0.238089  [64000/70370]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.153105 

Epoch 9
-------------------------------
loss: 0.209439  [    0/70370]
loss: 0.289813  [ 6400/70370]
loss: 0.125219  [12800/70370]
loss: 0.092386  [19200/70370]
loss: 0.231752  [25600/70370]
loss: 0.129787  [32000/70370]
loss: 0.148255  [38400/70370]
loss: 0.195783  [44800/70370]
loss: 0.136842  [51200/70370]
loss: 0.246794  [57600/70370]
loss: 0.143746  [64000/70370]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.157321 

Epoch 10
-------------------------------
loss: 0.137918  [    0/70370]
loss: 0.110076  [ 6400/70370]
loss: 0.119715  [12800/70370]
loss: 0.114002  [19200/70370]
loss: 0.408989  [25600/70370]
loss: 0.193097  [32000/70370]
loss: 0.207122  [38400/70370]
loss: 0.222137  [44800/70370]
loss: 0.131716  [51200/70370]
loss: 0.140563  [57600/70370]
loss: 0.164658  [64000/70370]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.173886 

Epoch 11
-------------------------------
loss: 0.133483  [    0/70370]
loss: 0.156134  [ 6400/70370]
loss: 0.156647  [12800/70370]
loss: 0.134134  [19200/70370]
loss: 0.148813  [25600/70370]
loss: 0.122321  [32000/70370]
loss: 0.169355  [38400/70370]
loss: 0.183747  [44800/70370]
loss: 0.160313  [51200/70370]
loss: 0.085569  [57600/70370]
loss: 0.206110  [64000/70370]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.159178 

Epoch 12
-------------------------------
loss: 0.393853  [    0/70370]
loss: 0.189861  [ 6400/70370]
loss: 0.309250  [12800/70370]
loss: 0.141610  [19200/70370]

loss: 0.086924  [25600/69794]
loss: 0.045964  [32000/69794]
loss: 0.042595  [38400/69794]
loss: 0.066590  [44800/69794]
loss: 0.091250  [51200/69794]
loss: 0.154201  [57600/69794]
loss: 0.273340  [64000/69794]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.098372 

Epoch 6
-------------------------------
loss: 0.090444  [    0/69794]
loss: 0.059615  [ 6400/69794]
loss: 0.107028  [12800/69794]
loss: 0.084965  [19200/69794]
loss: 0.118219  [25600/69794]
loss: 0.139522  [32000/69794]
loss: 0.141474  [38400/69794]
loss: 0.048389  [44800/69794]
loss: 0.111939  [51200/69794]
loss: 0.079415  [57600/69794]
loss: 0.268039  [64000/69794]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.106904 

Epoch 7
-------------------------------
loss: 0.061813  [    0/69794]
loss: 0.179068  [ 6400/69794]
loss: 0.121777  [12800/69794]
loss: 0.073990  [19200/69794]
loss: 0.140172  [25600/69794]
loss: 0.098188  [32000/69794]
loss: 0.071841  [38400/69794]
loss: 0.070026  [44800/69794]
loss: 0.050836  [51200/69794]
loss: 0.057164  [57600/69794]
loss: 0.024761  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.099786 

Epoch 8
-------------------------------
loss: 0.210377  [    0/69794]
loss: 0.083019  [ 6400/69794]
loss: 0.096259  [12800/69794]
loss: 0.102979  [19200/69794]
loss: 0.206877  [25600/69794]
loss: 0.058984  [32000/69794]
loss: 0.051367  [38400/69794]
loss: 0.117265  [44800/69794]
loss: 0.074398  [51200/69794]
loss: 0.073831  [57600/69794]
loss: 0.207413  [64000/69794]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.100693 

Epoch 9
-------------------------------
loss: 0.209752  [    0/69794]
loss: 0.140981  [ 6400/69794]
loss: 0.070609  [12800/69794]
loss: 0.098932  [19200/69794]
loss: 0.150951  [25600/69794]
loss: 0.093670  [32000/69794]
loss: 0.175291  [38400/69794]
loss: 0.107369  [44800/69794]
loss: 0.170018  [51200/69794]
loss: 0.122765  [57600/69794]
loss: 0.059362  [64000/69794]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.109696 

Epoch 10
-------------------------------
loss: 0.129800  [    0/69794]
loss: 0.151519  [ 6400/69794]
loss: 0.103158  [12800/69794]
loss: 0.075045  [19200/69794]
loss: 0.070568  [25600/69794]
loss: 0.091993  [32000/69794]
loss: 0.112320  [38400/69794]
loss: 0.143652  [44800/69794]
loss: 0.105972  [51200/69794]
loss: 0.093339  [57600/69794]
loss: 0.089102  [64000/69794]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.104586 

Epoch 11
-------------------------------
loss: 0.068070  [    0/69794]
loss: 0.049650  [ 6400/69794]
loss: 0.134476  [12800/69794]
loss: 0.102089  [19200/69794]
loss: 0.046704  [25600/69794]
loss: 0.080417  [32000/69794]
loss: 0.243253  [38400/69794]
loss: 0.143707  [44800/69794]
loss: 0.218472  [51200/69794]
loss: 0.111175  [57600/69794]
loss: 0.056868  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.102000 

Epoch 12
-------------------------------
loss: 1.636801  [    0/69794]
loss: 0.133922  [ 6400/69794]
loss: 0.108808  [12800/69794]
loss: 0.066430  [19200/69794]
loss: 0.092317  [25600/69794]
loss: 0.093732  [32000/69794]
loss: 0.147844  [38400/69794]
loss: 0.070427  [44800/69794]
loss: 0.042879  [51200/69794]
loss: 0.126695  [57600/69794]
loss: 0.142663  [64000/69794]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.101141 

Epoch 13
-------------------------------
loss: 0.051554  [    0/69794]
loss: 0.082882  [ 6400/69794]
loss: 0.080104  [12800/69794]
loss: 0.094962  [19200/69794]
loss: 0.285189  [25600/69794]
loss: 0.097360  [32000/69794]
loss: 0.074131  [38400/69794]
loss: 0.111110  [44800/69794]
loss: 0.220437  [51200/69794]
loss: 0.164438  [57600/69794]
loss: 0.062382  [64000/69794]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.102215 

Epoch 14
-------------------------------
loss: 0.127358  [    0/69794]
loss: 0.057164  [ 6400/69794]
loss: 0.182933  [12800/69794]
loss: 0.059530  [19200/69794]
loss: 0.068043  [25600/69794]
loss: 0.143819  [32000/69794]
loss: 0.103679  [38400/69794]
loss: 0.125156  [44800/69794]
loss: 0.064959  [51200/69794]
loss: 0.157257  [57600/69794]
loss: 0.077739  [64000/69794]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.106278 

Epoch 15
-------------------------------
loss: 0.134745  [    0/69794]
loss: 0.140334  [ 6400/69794]
loss: 0.194852  [12800/69794]
loss: 0.053519  [19200/69794]
loss: 0.172935  [25600/69794]
loss: 0.131981  [32000/69794]
loss: 0.080089  [38400/69794]
loss: 0.093674  [44800/69794]
loss: 0.148586  [51200/69794]
loss: 0.097180  [57600/69794]
loss: 0.111005  [64000/69794]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.101497 

Epoch 16
-------------------------------
loss: 0.095956  [    0/69794]
loss: 0.058026  [ 6400/69794]
loss: 0.054021  [12800/69794]
loss: 0.136901  [19200/69794]
loss: 0.122033  [25600/69794]
loss: 0.073659  [32000/69794]
loss: 0.134919  [38400/69794]
loss: 0.079152  [44800/69794]
loss: 0.265019  [51200/69794]
loss: 0.177771  [57600/69794]
loss: 0.233776  [64000/69794]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099877 

Epoch 17
-------------------------------
loss: 0.143655  [    0/69794]
loss: 0.193177  [ 6400/69794]
loss: 0.080460  [12800/69794]
loss: 0.101163  [19200/69794]
loss: 0.082274  [25600/69794]
loss: 0.165797  [32000/69794]
loss: 0.219733  [38400/69794]
loss: 0.072186  [44800/69794]
loss: 0.109074  [51200/69794]
loss: 0.145678  [57600/69794]
loss: 0.208812  [64000/69794]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.114915 

Epoch 18
-------------------------------
loss: 0.142992  [    0/69794]
loss: 0.113894  [ 6400/69794]
loss: 0.098148  [12800/69794]
loss: 0.120725  [19200/69794]
loss: 0.068845  [25600/69794]
loss: 0.173240  [32000/69794]
loss: 0.101825  [38400/69794]
loss: 0.165616  [44800/69794]
loss: 0.043207  [51200/69794]
loss: 0.029370  [57600/69794]
loss: 0.185841  [64000/69794]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.102323 

Epoch 19
-------------------------------
loss: 0.048393  [    0/69794]
loss: 0.042326  [ 6400/69794]
loss: 0.119220  [12800/69794]
loss: 0.151762  [19200/69794]
loss: 0.140477  [25600/69794]
loss: 0.104893  [32000/69794]
loss: 0.099081  [38400/69794]
loss: 0.138768  [44800/69794]
loss: 0.152458  [51200/69794]
loss: 0.117909  [57600/69794]
loss: 0.150229  [64000/69794]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.098337 

Epoch 20
-------------------------------
loss: 0.106948  [    0/69794]
loss: 0.071319  [ 6400/69794]
loss: 0.095219  [12800/69794]
loss: 0.025713  [19200/69794]
loss: 0.057806  [25600/69794]
loss: 0.093393  [32000/69794]
loss: 0.158529  [38400/69794]
loss: 0.058453  [44800/69794]
loss: 0.107790  [51200/69794]
loss: 0.256365  [57600/69794]
loss: 0.092655  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.099100 

Epoch 21
-------------------------------
loss: 0.046739  [    0/69794]
loss: 0.176243  [ 6400/69794]
loss: 0.073424  [12800/69794]
loss: 0.143283  [19200/69794]
loss: 0.078318  [25600/69794]
loss: 0.026889  [32000/69794]
loss: 0.186101  [38400/69794]
loss: 0.180830  [44800/69794]
loss: 0.072683  [51200/69794]
loss: 0.086419  [57600/69794]
loss: 0.105506  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.103387 

Epoch 22
-------------------------------
loss: 0.078579  [    0/69794]
loss: 0.083622  [ 6400/69794]
loss: 0.093235  [12800/69794]
loss: 0.173138  [19200/69794]
loss: 0.094870  [25600/69794]
loss: 0.092819  [32000/69794]
loss: 0.094372  [38400/69794]
loss: 0.133323  [44800/69794]
loss: 0.108797  [51200/69794]
loss: 0.246415  [57600/69794]
loss: 0.135414  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.102824 

Epoch 23
-------------------------------
loss: 0.060510  [    0/69794]
loss: 0.120781  [ 6400/69794]
loss: 0.070218  [12800/69794]
loss: 0.044351  [19200/69794]
loss: 0.039214  [25600/69794]
loss: 0.065050  [32000/69794]
loss: 0.070204  [38400/69794]
loss: 0.107987  [44800/69794]
loss: 0.096009  [51200/69794]
loss: 0.119629  [57600/69794]
loss: 0.157141  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.105738 

Epoch 24
-------------------------------
loss: 0.094088  [    0/69794]
loss: 0.038117  [ 6400/69794]
loss: 0.061677  [12800/69794]
loss: 0.108888  [19200/69794]
loss: 0.139175  [25600/69794]
loss: 0.159512  [32000/69794]
loss: 0.036573  [38400/69794]
loss: 0.048987  [44800/69794]
loss: 0.111213  [51200/69794]
loss: 0.055922  [70400/71701]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.073052 

Epoch 20
-------------------------------
loss: 0.044885  [    0/71701]
loss: 0.007574  [ 6400/71701]
loss: 0.184146  [12800/71701]
loss: 0.134899  [19200/71701]
loss: 0.030241  [25600/71701]
loss: 0.021335  [32000/71701]
loss: 0.008578  [38400/71701]
loss: 0.021075  [44800/71701]
loss: 0.005248  [51200/71701]
loss: 0.082055  [57600/71701]
loss: 0.083187  [64000/71701]
loss: 0.018508  [70400/71701]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.067462 

Epoch 21
-------------------------------
loss: 0.022496  [    0/71701]
loss: 0.031594  [ 6400/71701]
loss: 0.154551  [12800/71701]
loss: 0.019884  [19200/71701]
loss: 0.018942  [25600/71701]
loss: 0.008278  [32000/71701]
loss: 0.012157  [38400/71701]
loss: 0.055344  [44800/71701]
loss: 0.042357  [51200/71701]
loss: 0.008088  [57600/71701]
loss: 0.006537  [64000/71701]
loss: 0.069634  [70400/71701]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.096222 

Epoch 22
-------------------------------
loss: 0.027198  [    0/71701]
loss: 0.021492  [ 6400/71701]
loss: 0.188787  [12800/71701]
loss: 0.036002  [19200/71701]
loss: 0.044180  [25600/71701]
loss: 0.024366  [32000/71701]
loss: 0.074606  [38400/71701]
loss: 0.032426  [44800/71701]
loss: 0.033809  [51200/71701]
loss: 0.043626  [57600/71701]
loss: 0.137114  [64000/71701]
loss: 0.035247  [70400/71701]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.069902 

Epoch 23
-------------------------------
loss: 0.067289  [    0/71701]
loss: 0.101366  [ 6400/71701]
loss: 0.051103  [12800/71701]
loss: 0.002477  [19200/71701]
loss: 0.074127  [25600/71701]
loss: 0.067983  [32000/71701]
loss: 0.095468  [38400/71701]
loss: 0.068378  [44800/71701]
loss: 0.080892  [51200/71701]
loss: 0.030007  [57600/71701]
loss: 0.021156  [64000/71701]
loss: 0.028397  [70400/71701]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.070443 

Epoch 24
-------------------------------
loss: 0.028178  [    0/71701]
loss: 0.112260  [ 6400/71701]
loss: 0.022416  [12800/71701]
loss: 0.045881  [19200/71701]
loss: 0.119907  [25600/71701]
loss: 0.051908  [32000/71701]
loss: 0.020463  [38400/71701]
loss: 0.026158  [44800/71701]
loss: 0.046752  [51200/71701]
loss: 0.002314  [57600/71701]
loss: 0.054943  [64000/71701]
loss: 0.051661  [70400/71701]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.070492 

Epoch 25
-------------------------------
loss: 0.047325  [    0/71701]
loss: 0.035330  [ 6400/71701]
loss: 0.009912  [12800/71701]
loss: 0.099933  [19200/71701]
loss: 0.078644  [25600/71701]
loss: 0.028348  [32000/71701]
loss: 0.012090  [38400/71701]
loss: 0.099418  [44800/71701]
loss: 0.128421  [51200/71701]
loss: 0.143749  [57600/71701]
loss: 0.025309  [64000/71701]
loss: 0.047844  [70400/71701]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.078329 

Epoch 26
-------------------------------
loss: 0.045470  [    0/71701]
loss: 0.051521  [ 6400/71701]
loss: 0.031700  [12800/71701]
loss: 0.074201  [19200/71701]
loss: 0.014175  [25600/71701]
loss: 0.084116  [32000/71701]
loss: 0.045572  [38400/71701]
loss: 0.049313  [44800/71701]
loss: 0.021055  [51200/71701]
loss: 0.131697  [57600/71701]
loss: 0.031571  [64000/71701]
loss: 1.576390  [70400/71701]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.138162 

Epoch 27
-------------------------------
loss: 0.192501  [    0/71701]
loss: 0.058582  [ 6400/71701]
loss: 0.016347  [12800/71701]
loss: 0.003753  [19200/71701]
loss: 0.041145  [25600/71701]
loss: 0.011114  [32000/71701]
loss: 0.054439  [38400/71701]
loss: 0.057239  [44800/71701]
loss: 0.038465  [51200/71701]
loss: 0.028204  [57600/71701]
loss: 0.007766  [64000/71701]
loss: 0.023437  [70400/71701]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076981 

Epoch 28
-------------------------------
loss: 0.025672  [    0/71701]
loss: 0.061115  [ 6400/71701]
loss: 0.062477  [12800/71701]
loss: 0.036995  [19200/71701]
loss: 0.055363  [25600/71701]
loss: 0.028968  [32000/71701]
loss: 0.077215  [38400/71701]
loss: 0.106079  [44800/71701]
loss: 0.009369  [51200/71701]
loss: 0.148286  [57600/71701]
loss: 0.018590  [64000/71701]
loss: 0.156069  [70400/71701]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074927 

Epoch 29
-------------------------------
loss: 0.046894  [    0/71701]
loss: 0.052689  [ 6400/71701]
loss: 0.111302  [12800/71701]
loss: 0.209607  [19200/71701]
loss: 0.019567  [25600/71701]
loss: 0.035568  [32000/71701]
loss: 0.081388  [38400/71701]
loss: 0.036446  [44800/71701]
loss: 0.027451  [51200/71701]
loss: 0.081338  [57600/71701]
loss: 0.101125  [64000/71701]
loss: 0.038584  [70400/71701]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.096419 

Epoch 30
-------------------------------
loss: 0.007518  [    0/71701]
loss: 0.034645  [ 6400/71701]
loss: 0.022161  [12800/71701]
loss: 0.012820  [19200/71701]
loss: 0.039372  [25600/71701]
loss: 0.009080  [32000/71701]
loss: 0.101753  [38400/71701]
loss: 0.014092  [44800/71701]
loss: 0.043966  [51200/71701]
loss: 0.046416  [57600/71701]
loss: 0.015901  [64000/71701]
loss: 0.065559  [70400/71701]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.073429 

Epoch 31
-------------------------------
loss: 0.048588  [    0/71701]
loss: 0.043465  [ 6400/71701]
loss: 0.060149  [12800/71701]
loss: 0.072797  [19200/71701]
loss: 0.032440  [25600/71701]
loss: 0.048896  [32000/71701]
loss: 0.032442  [38400/71701]
loss: 0.007383  [44800/71701]
loss: 0.076919  [51200/71701]
loss: 0.040170  [57600/71701]
loss: 0.024354  [64000/71701]
loss: 0.041300  [70400/71701]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075309 

Epoch 32
-------------------------------
loss: 0.022528  [    0/71701]
loss: 0.007465  [ 6400/71701]
loss: 0.127116  [12800/71701]
loss: 0.039191  [19200/71701]
loss: 0.063834  [25600/71701]
loss: 0.013222  [32000/71701]
loss: 0.109936  [38400/71701]
loss: 0.147300  [44800/71701]
loss: 0.081845  [51200/71701]
loss: 0.044358  [57600/71701]
loss: 0.032028  [64000/71701]
loss: 0.044432  [70400/71701]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.092221 

Epoch 33
-------------------------------
loss: 0.064454  [    0/71701]
loss: 0.039596  [ 6400/71701]
loss: 0.008983  [12800/71701]
loss: 0.001647  [19200/71701]
loss: 0.107543  [25600/71701]
loss: 0.044975  [32000/71701]
loss: 0.031064  [38400/71701]
loss: 0.058318  [44800/71701]
loss: 0.010761  [51200/71701]
loss: 0.063527  [57600/71701]
loss: 0.058452  [64000/71701]
loss: 0.057276  [70400/71701]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.079727 

Epoch 34
-------------------------------
loss: 0.085994  [    0/71701]
loss: 0.094178  [ 6400/71701]
loss: 0.056125  [12800/71701]
loss: 0.038521  [19200/71701]
loss: 0.039121  [25600/71701]
loss: 0.048054  [32000/71701]
loss: 0.059313  [38400/71701]
loss: 0.023793  [44800/71701]
loss: 0.021231  [51200/71701]
loss: 0.010529  [57600/71701]
loss: 0.057411  [64000/71701]
loss: 0.055014  [70400/71701]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075428 

Epoch 35
-------------------------------
loss: 0.042496  [    0/71701]
loss: 0.112375  [ 6400/71701]
loss: 0.056525  [12800/71701]
loss: 0.032707  [19200/71701]
loss: 0.106142  [25600/71701]
loss: 0.006008  [32000/71701]
loss: 0.010218  [38400/71701]
loss: 0.026731  [44800/71701]
loss: 0.053458  [51200/71701]
loss: 0.015454  [57600/71701]
loss: 1.585506  [64000/71701]
loss: 0.083637  [70400/71701]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075871 

Epoch 36
-------------------------------
loss: 0.016170  [    0/71701]
loss: 0.039731  [ 6400/71701]
loss: 0.086349  [12800/71701]
loss: 0.049683  [19200/71701]
loss: 0.094228  [25600/71701]
loss: 0.065996  [32000/71701]
loss: 0.050619  [38400/71701]
loss: 0.024936  [44800/71701]
loss: 0.025416  [51200/71701]
loss: 0.025005  [57600/71701]
loss: 0.058068  [64000/71701]
loss: 0.032323  [70400/71701]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.078542 

Epoch 37
-------------------------------
loss: 0.074161  [    0/71701]
loss: 0.110778  [ 6400/71701]
loss: 0.080610  [12800/71701]
loss: 0.020800  [19200/71701]
loss: 0.061349  [25600/71701]
loss: 0.106764  [32000/71701]
loss: 0.037886  [38400/71701]
loss: 0.082773  [44800/71701]
loss: 0.006348  [51200/71701]
loss: 0.049134  [57600/71701]
loss: 0.081929  [64000/71701]
loss: 0.011519  [70400/71701]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.048050 

Epoch 23
-------------------------------
loss: 0.001588  [    0/72605]
loss: 0.022993  [ 6400/72605]
loss: 0.006785  [12800/72605]
loss: 0.083911  [19200/72605]
loss: 0.002193  [25600/72605]
loss: 0.000833  [32000/72605]
loss: 0.001519  [38400/72605]
loss: 0.140061  [44800/72605]
loss: 0.011249  [51200/72605]
loss: 0.027308  [57600/72605]
loss: 0.003256  [64000/72605]
loss: 0.010811  [70400/72605]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.051641 

Epoch 24
-------------------------------
loss: 0.021483  [    0/72605]
loss: 0.008041  [ 6400/72605]
loss: 0.007381  [12800/72605]
loss: 0.000315  [19200/72605]
loss: 0.000214  [25600/72605]
loss: 0.028791  [32000/72605]
loss: 0.000002  [38400/72605]
loss: 0.129250  [44800/72605]
loss: 0.000509  [51200/72605]
loss: 0.004768  [57600/72605]
loss: 0.005238  [64000/72605]
loss: 0.000063  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.053023 

Epoch 25
-------------------------------
loss: 0.005495  [    0/72605]
loss: 0.004656  [ 6400/72605]
loss: 0.042678  [12800/72605]
loss: 0.137826  [19200/72605]
loss: 0.003697  [25600/72605]
loss: 0.003294  [32000/72605]
loss: 0.000723  [38400/72605]
loss: 0.017639  [44800/72605]
loss: 0.003446  [51200/72605]
loss: 0.010711  [57600/72605]
loss: 0.008714  [64000/72605]
loss: 0.051097  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.053367 

Epoch 26
-------------------------------
loss: 0.000879  [    0/72605]
loss: 0.000572  [ 6400/72605]
loss: 0.001153  [12800/72605]
loss: 0.098257  [19200/72605]
loss: 0.066230  [25600/72605]
loss: 0.003164  [32000/72605]
loss: 0.000062  [38400/72605]
loss: 0.009931  [44800/72605]
loss: 0.008245  [51200/72605]
loss: 0.021187  [57600/72605]
loss: 0.000495  [64000/72605]
loss: 0.007511  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.068523 

Epoch 27
-------------------------------
loss: 0.015180  [    0/72605]
loss: 0.014331  [ 6400/72605]
loss: 0.014217  [12800/72605]
loss: 0.008811  [19200/72605]
loss: 0.002365  [25600/72605]
loss: 0.006855  [32000/72605]
loss: 0.000045  [38400/72605]
loss: 0.048472  [44800/72605]
loss: 0.003293  [51200/72605]
loss: 0.002947  [57600/72605]
loss: 0.051535  [64000/72605]
loss: 0.001125  [70400/72605]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.068889 

Epoch 28
-------------------------------
loss: 0.000058  [    0/72605]
loss: 0.002716  [ 6400/72605]
loss: 0.004356  [12800/72605]
loss: 0.041696  [19200/72605]
loss: 0.004317  [25600/72605]
loss: 0.021259  [32000/72605]
loss: 0.002700  [38400/72605]
loss: 0.000860  [44800/72605]
loss: 0.016151  [51200/72605]
loss: 0.004955  [57600/72605]
loss: 0.000005  [64000/72605]
loss: 0.010077  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.069426 

Epoch 29
-------------------------------
loss: 0.092139  [    0/72605]
loss: 0.005715  [ 6400/72605]
loss: 0.021611  [12800/72605]
loss: 0.000076  [19200/72605]
loss: 0.001499  [25600/72605]
loss: 0.005998  [32000/72605]
loss: 0.002972  [38400/72605]
loss: 0.001629  [44800/72605]
loss: 0.004249  [51200/72605]
loss: 0.011389  [57600/72605]
loss: 0.008452  [64000/72605]
loss: 0.000220  [70400/72605]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.082602 

Epoch 30
-------------------------------
loss: 0.022050  [    0/72605]
loss: 0.013031  [ 6400/72605]
loss: 0.006825  [12800/72605]
loss: 0.013773  [19200/72605]
loss: 0.204507  [25600/72605]
loss: 0.000856  [32000/72605]
loss: 0.037340  [38400/72605]
loss: 0.003532  [44800/72605]
loss: 0.032886  [51200/72605]
loss: 0.192303  [57600/72605]
loss: 0.007058  [64000/72605]
loss: 0.001373  [70400/72605]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.061551 

Epoch 31
-------------------------------
loss: 0.002462  [    0/72605]
loss: 0.000034  [ 6400/72605]
loss: 0.017004  [12800/72605]
loss: 0.019892  [19200/72605]
loss: 0.001402  [25600/72605]
loss: 0.044455  [32000/72605]
loss: 0.000010  [38400/72605]
loss: 0.021300  [44800/72605]
loss: 0.018312  [51200/72605]
loss: 0.004846  [57600/72605]
loss: 0.006175  [64000/72605]
loss: 0.124853  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.068624 

Epoch 32
-------------------------------
loss: 0.004664  [    0/72605]
loss: 0.002864  [ 6400/72605]
loss: 0.000136  [12800/72605]
loss: 0.006338  [19200/72605]
loss: 0.004625  [25600/72605]
loss: 0.049896  [32000/72605]
loss: 0.008627  [38400/72605]
loss: 0.010207  [44800/72605]
loss: 0.019450  [51200/72605]
loss: 0.001535  [57600/72605]
loss: 0.000271  [64000/72605]
loss: 0.003818  [70400/72605]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.067490 

Epoch 33
-------------------------------
loss: 0.004768  [    0/72605]
loss: 0.006678  [ 6400/72605]
loss: 0.000975  [12800/72605]
loss: 0.000485  [19200/72605]
loss: 0.013943  [25600/72605]
loss: 0.006503  [32000/72605]
loss: 0.006151  [38400/72605]
loss: 0.001650  [44800/72605]
loss: 0.014191  [51200/72605]
loss: 0.000046  [57600/72605]
loss: 0.036370  [64000/72605]
loss: 0.022838  [70400/72605]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.062653 

Epoch 34
-------------------------------
loss: 0.000799  [    0/72605]
loss: 0.000433  [ 6400/72605]
loss: 0.000520  [12800/72605]
loss: 0.006135  [19200/72605]
loss: 0.000076  [25600/72605]
loss: 0.000262  [32000/72605]
loss: 0.048054  [38400/72605]
loss: 0.000736  [44800/72605]
loss: 0.000577  [51200/72605]
loss: 0.002686  [57600/72605]
loss: 0.000924  [64000/72605]
loss: 0.000670  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.062438 

Epoch 35
-------------------------------
loss: 0.002327  [    0/72605]
loss: 0.002246  [ 6400/72605]
loss: 0.000597  [12800/72605]
loss: 0.000495  [19200/72605]
loss: 0.004399  [25600/72605]
loss: 0.000256  [32000/72605]
loss: 0.092964  [38400/72605]
loss: 0.004552  [44800/72605]
loss: 0.000045  [51200/72605]
loss: 0.027473  [57600/72605]
loss: 0.003009  [64000/72605]
loss: 0.030295  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.058713 

Epoch 36
-------------------------------
loss: 0.003222  [    0/72605]
loss: 0.015616  [ 6400/72605]
loss: 0.001440  [12800/72605]
loss: 0.005207  [19200/72605]
loss: 0.015074  [25600/72605]
loss: 0.002006  [32000/72605]
loss: 0.001328  [38400/72605]
loss: 0.000510  [44800/72605]
loss: 0.058635  [51200/72605]
loss: 0.006696  [57600/72605]
loss: 0.000246  [64000/72605]
loss: 0.000142  [70400/72605]
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.070034 

Epoch 37
-------------------------------
loss: 0.008833  [    0/72605]
loss: 0.007235  [ 6400/72605]
loss: 0.000922  [12800/72605]
loss: 0.031071  [19200/72605]
loss: 0.007243  [25600/72605]
loss: 0.009402  [32000/72605]
loss: 0.003098  [38400/72605]
loss: 0.002707  [44800/72605]
loss: 0.014775  [51200/72605]
loss: 0.085508  [57600/72605]
loss: 0.061364  [64000/72605]
loss: 0.108316  [70400/72605]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.068692 

Epoch 38
-------------------------------
loss: 0.000044  [    0/72605]
loss: 0.004441  [ 6400/72605]
loss: 0.006700  [12800/72605]
loss: 0.000021  [19200/72605]
loss: 0.000738  [25600/72605]
loss: 0.006142  [32000/72605]
loss: 0.011584  [38400/72605]
loss: 0.000001  [44800/72605]
loss: 0.001564  [51200/72605]
loss: 0.026737  [57600/72605]
loss: 0.006463  [64000/72605]
loss: 0.000379  [70400/72605]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.061150 

Epoch 39
-------------------------------
loss: 0.000378  [    0/72605]
loss: 0.001054  [ 6400/72605]
loss: 0.001636  [12800/72605]
loss: 0.022887  [19200/72605]
loss: 0.031356  [25600/72605]
loss: 0.000071  [32000/72605]
loss: 0.005131  [38400/72605]
loss: 0.035976  [44800/72605]
loss: 0.004767  [51200/72605]
loss: 0.000077  [57600/72605]
loss: 0.000397  [64000/72605]
loss: 0.000189  [70400/72605]
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.071668 

Epoch 40
-------------------------------
loss: 0.011811  [    0/72605]
loss: 0.000005  [ 6400/72605]
loss: 0.049332  [12800/72605]
loss: 0.000028  [19200/72605]
loss: 0.025145  [25600/72605]
loss: 0.002202  [32000/72605]
loss: 0.001455  [38400/72605]
loss: 0.000156  [44800/72605]
loss: 0.003404  [51200/72605]
loss: 0.004350  [57600/72605]
loss: 0.000306  [64000/72605]
loss: 0.000819  [70400/72605]
loss: 0.168310  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.087341 

Epoch 12
-------------------------------
loss: 0.116933  [    0/70678]
loss: 0.046363  [ 6400/70678]
loss: 0.051664  [12800/70678]
loss: 0.094119  [19200/70678]
loss: 0.204343  [25600/70678]
loss: 0.051293  [32000/70678]
loss: 0.085195  [38400/70678]
loss: 0.064564  [44800/70678]
loss: 0.085956  [51200/70678]
loss: 0.102048  [57600/70678]
loss: 0.079443  [64000/70678]
loss: 0.172304  [70400/70678]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.095983 

Epoch 13
-------------------------------
loss: 0.054430  [    0/70678]
loss: 0.111194  [ 6400/70678]
loss: 0.024873  [12800/70678]
loss: 0.068135  [19200/70678]
loss: 0.085329  [25600/70678]
loss: 0.141232  [32000/70678]
loss: 0.197635  [38400/70678]
loss: 0.026776  [44800/70678]
loss: 0.132393  [51200/70678]
loss: 0.211526  [57600/70678]
loss: 0.109228  [64000/70678]
loss: 0.299049  [70400/70678]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.098267 

Epoch 14
-------------------------------
loss: 0.021104  [    0/70678]
loss: 0.065069  [ 6400/70678]
loss: 0.058340  [12800/70678]
loss: 0.075454  [19200/70678]
loss: 0.059950  [25600/70678]
loss: 0.171860  [32000/70678]
loss: 0.065605  [38400/70678]
loss: 0.198424  [44800/70678]
loss: 0.090976  [51200/70678]
loss: 0.107810  [57600/70678]
loss: 0.087308  [64000/70678]
loss: 0.099022  [70400/70678]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.084332 

Epoch 15
-------------------------------
loss: 0.058478  [    0/70678]
loss: 0.040337  [ 6400/70678]
loss: 0.111068  [12800/70678]
loss: 0.092987  [19200/70678]
loss: 0.109151  [25600/70678]
loss: 0.095948  [32000/70678]
loss: 0.132065  [38400/70678]
loss: 0.093188  [44800/70678]
loss: 0.141660  [51200/70678]
loss: 0.202513  [57600/70678]
loss: 0.055993  [64000/70678]
loss: 0.079970  [70400/70678]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.097275 

Epoch 16
-------------------------------
loss: 0.105327  [    0/70678]
loss: 0.127181  [ 6400/70678]
loss: 0.033003  [12800/70678]
loss: 0.125454  [19200/70678]
loss: 0.091762  [25600/70678]
loss: 0.078335  [32000/70678]
loss: 0.137927  [38400/70678]
loss: 0.053520  [44800/70678]
loss: 0.103927  [51200/70678]
loss: 0.079614  [57600/70678]
loss: 0.086757  [64000/70678]
loss: 0.088862  [70400/70678]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.091611 

Epoch 17
-------------------------------
loss: 0.100344  [    0/70678]
loss: 0.074029  [ 6400/70678]
loss: 0.105777  [12800/70678]
loss: 0.098230  [19200/70678]
loss: 0.047196  [25600/70678]
loss: 0.135035  [32000/70678]
loss: 0.040547  [38400/70678]
loss: 0.189179  [44800/70678]
loss: 0.054597  [51200/70678]
loss: 0.178660  [57600/70678]
loss: 0.162653  [64000/70678]
loss: 0.072870  [70400/70678]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.094670 

Epoch 18
-------------------------------
loss: 0.044983  [    0/70678]
loss: 0.105772  [ 6400/70678]
loss: 0.100612  [12800/70678]
loss: 0.065211  [19200/70678]
loss: 0.082015  [25600/70678]
loss: 0.099662  [32000/70678]
loss: 0.055301  [38400/70678]
loss: 0.145967  [44800/70678]
loss: 0.038464  [51200/70678]
loss: 0.139253  [57600/70678]
loss: 0.044750  [64000/70678]
loss: 0.132838  [70400/70678]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.086571 

Epoch 19
-------------------------------
loss: 0.098255  [    0/70678]
loss: 0.048009  [ 6400/70678]
loss: 0.051297  [12800/70678]
loss: 0.048956  [19200/70678]
loss: 0.096614  [25600/70678]
loss: 0.048571  [32000/70678]
loss: 0.091870  [38400/70678]
loss: 0.113707  [44800/70678]
loss: 0.046332  [51200/70678]
loss: 0.093857  [57600/70678]
loss: 0.093195  [64000/70678]
loss: 0.120925  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090361 

Epoch 20
-------------------------------
loss: 0.057902  [    0/70678]
loss: 0.088239  [ 6400/70678]
loss: 0.044555  [12800/70678]
loss: 0.080149  [19200/70678]
loss: 0.067344  [25600/70678]
loss: 0.094716  [32000/70678]
loss: 0.051994  [38400/70678]
loss: 0.202660  [44800/70678]
loss: 0.087164  [51200/70678]
loss: 0.084094  [57600/70678]
loss: 0.089838  [64000/70678]
loss: 0.092105  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.092538 

Epoch 21
-------------------------------
loss: 0.063478  [    0/70678]
loss: 0.148784  [ 6400/70678]
loss: 0.134739  [12800/70678]
loss: 0.098127  [19200/70678]
loss: 0.095300  [25600/70678]
loss: 0.139107  [32000/70678]
loss: 0.042572  [38400/70678]
loss: 0.035732  [44800/70678]
loss: 0.152074  [51200/70678]
loss: 0.118654  [57600/70678]
loss: 0.082779  [64000/70678]
loss: 0.102720  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.085939 

Epoch 22
-------------------------------
loss: 0.106021  [    0/70678]
loss: 0.109377  [ 6400/70678]
loss: 0.094625  [12800/70678]
loss: 0.042755  [19200/70678]
loss: 0.099233  [25600/70678]
loss: 0.074014  [32000/70678]
loss: 0.017489  [38400/70678]
loss: 0.103251  [44800/70678]
loss: 0.056389  [51200/70678]
loss: 0.115243  [57600/70678]
loss: 0.053112  [64000/70678]
loss: 0.080757  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090265 

Epoch 23
-------------------------------
loss: 0.076131  [    0/70678]
loss: 0.073270  [ 6400/70678]
loss: 0.131741  [12800/70678]
loss: 0.109756  [19200/70678]
loss: 0.131945  [25600/70678]
loss: 0.198743  [32000/70678]
loss: 0.123719  [38400/70678]
loss: 0.054356  [44800/70678]
loss: 0.066145  [51200/70678]
loss: 0.123826  [57600/70678]
loss: 0.082901  [64000/70678]
loss: 0.118716  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.090217 

Epoch 24
-------------------------------
loss: 0.114761  [    0/70678]
loss: 0.123078  [ 6400/70678]
loss: 0.153365  [12800/70678]
loss: 0.094802  [19200/70678]
loss: 0.035504  [25600/70678]
loss: 0.048868  [32000/70678]
loss: 0.066207  [38400/70678]
loss: 0.116832  [44800/70678]
loss: 0.056788  [51200/70678]
loss: 0.055351  [57600/70678]
loss: 0.041436  [64000/70678]
loss: 0.244659  [70400/70678]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.085956 

Epoch 25
-------------------------------
loss: 0.118939  [    0/70678]
loss: 0.095804  [ 6400/70678]
loss: 0.129577  [12800/70678]
loss: 0.034419  [19200/70678]
loss: 0.079364  [25600/70678]
loss: 0.077085  [32000/70678]
loss: 0.022073  [38400/70678]
loss: 0.184037  [44800/70678]
loss: 0.069485  [51200/70678]
loss: 0.057099  [57600/70678]
loss: 0.053802  [64000/70678]
loss: 0.048882  [70400/70678]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102211 

Epoch 26
-------------------------------
loss: 0.103610  [    0/70678]
loss: 0.045521  [ 6400/70678]
loss: 0.016584  [12800/70678]
loss: 0.117500  [19200/70678]
loss: 0.060098  [25600/70678]
loss: 0.121171  [32000/70678]
loss: 0.118033  [38400/70678]
loss: 0.100537  [44800/70678]
loss: 0.125062  [51200/70678]
loss: 0.021747  [57600/70678]
loss: 0.070727  [64000/70678]
loss: 0.057700  [70400/70678]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102674 

Epoch 27
-------------------------------
loss: 0.095176  [    0/70678]
loss: 0.079414  [ 6400/70678]
loss: 0.043477  [12800/70678]
loss: 0.068379  [19200/70678]
loss: 0.153455  [25600/70678]
loss: 0.057079  [32000/70678]
loss: 0.039276  [38400/70678]
loss: 0.145433  [44800/70678]
loss: 0.109312  [51200/70678]
loss: 0.043767  [57600/70678]
loss: 0.070233  [64000/70678]
loss: 0.194118  [70400/70678]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.091936 

Epoch 28
-------------------------------
loss: 0.034725  [    0/70678]
loss: 0.029288  [ 6400/70678]
loss: 0.025820  [12800/70678]
loss: 0.021287  [19200/70678]
loss: 0.070109  [25600/70678]
loss: 0.030529  [32000/70678]
loss: 0.153326  [38400/70678]
loss: 0.078006  [44800/70678]
loss: 0.038917  [51200/70678]
loss: 0.036858  [57600/70678]
loss: 0.088130  [64000/70678]
loss: 0.130343  [70400/70678]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.089126 

Epoch 29
-------------------------------
loss: 0.012810  [    0/70678]
loss: 0.021941  [ 6400/70678]
loss: 0.093875  [12800/70678]
loss: 0.026036  [19200/70678]
loss: 0.074153  [25600/70678]
loss: 0.166347  [32000/70678]
loss: 0.109880  [38400/70678]
loss: 0.092474  [44800/70678]
loss: 0.338959  [51200/70678]
loss: 0.099571  [57600/70678]
loss: 0.143388  [64000/70678]
loss: 0.041050  [70400/70678]
loss: 0.116679  [44800/69886]
loss: 0.171027  [51200/69886]
loss: 0.179493  [57600/69886]
loss: 0.127123  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.164427 

Epoch 47
-------------------------------
loss: 0.172226  [    0/69886]
loss: 0.150833  [ 6400/69886]
loss: 0.145108  [12800/69886]
loss: 0.270152  [19200/69886]
loss: 0.175433  [25600/69886]
loss: 0.145137  [32000/69886]
loss: 0.101811  [38400/69886]
loss: 0.151877  [44800/69886]
loss: 0.214174  [51200/69886]
loss: 0.105842  [57600/69886]
loss: 0.166796  [64000/69886]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.157703 

Epoch 48
-------------------------------
loss: 0.134778  [    0/69886]
loss: 0.115342  [ 6400/69886]
loss: 0.166908  [12800/69886]
loss: 0.064011  [19200/69886]
loss: 0.129869  [25600/69886]
loss: 0.163337  [32000/69886]
loss: 0.252123  [38400/69886]
loss: 0.098309  [44800/69886]
loss: 0.222768  [51200/69886]
loss: 0.187452  [57600/69886]
loss: 0.117653  [64000/69886]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.165659 

Epoch 49
-------------------------------
loss: 0.130893  [    0/69886]
loss: 0.211394  [ 6400/69886]
loss: 0.109708  [12800/69886]
loss: 0.073822  [19200/69886]
loss: 0.261621  [25600/69886]
loss: 0.269800  [32000/69886]
loss: 0.070323  [38400/69886]
loss: 0.161136  [44800/69886]
loss: 0.138284  [51200/69886]
loss: 0.257784  [57600/69886]
loss: 0.254173  [64000/69886]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.181602 

Epoch 50
-------------------------------
loss: 0.151092  [    0/69886]
loss: 0.195682  [ 6400/69886]
loss: 0.095212  [12800/69886]
loss: 0.215563  [19200/69886]
loss: 0.199464  [25600/69886]
loss: 0.188452  [32000/69886]
loss: 0.122239  [38400/69886]
loss: 0.123330  [44800/69886]
loss: 0.061635  [51200/69886]
loss: 0.261075  [57600/69886]
loss: 0.259584  [64000/69886]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.159450 

Epoch 1
-------------------------------
loss: 0.666133  [    0/70153]
loss: 0.276838  [ 6400/70153]
loss: 0.269809  [12800/70153]
loss: 0.295516  [19200/70153]
loss: 0.222616  [25600/70153]
loss: 0.243311  [32000/70153]
loss: 0.162481  [38400/70153]
loss: 0.305185  [44800/70153]
loss: 0.207115  [51200/70153]
loss: 0.190755  [57600/70153]
loss: 0.168929  [64000/70153]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.206771 

Epoch 2
-------------------------------
loss: 0.170280  [    0/70153]
loss: 0.210546  [ 6400/70153]
loss: 0.232764  [12800/70153]
loss: 0.149136  [19200/70153]
loss: 0.222927  [25600/70153]
loss: 0.225747  [32000/70153]
loss: 0.257123  [38400/70153]
loss: 0.282694  [44800/70153]
loss: 0.131404  [51200/70153]
loss: 0.212621  [57600/70153]
loss: 0.286367  [64000/70153]
Test Error: 
 Accuracy: 91.0%, Avg loss: 0.214612 

Epoch 3
-------------------------------
loss: 0.185181  [    0/70153]
loss: 0.115970  [ 6400/70153]
loss: 0.168598  [12800/70153]
loss: 0.142055  [19200/70153]
loss: 0.176656  [25600/70153]
loss: 0.116015  [32000/70153]
loss: 0.219549  [38400/70153]
loss: 0.162111  [44800/70153]
loss: 0.191777  [51200/70153]
loss: 0.216555  [57600/70153]
loss: 0.122148  [64000/70153]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.179836 

Epoch 4
-------------------------------
loss: 0.216539  [    0/70153]
loss: 0.315913  [ 6400/70153]
loss: 0.148758  [12800/70153]
loss: 0.216079  [19200/70153]
loss: 0.312818  [25600/70153]
loss: 0.139650  [32000/70153]
loss: 0.250256  [38400/70153]
loss: 0.156168  [44800/70153]
loss: 0.152051  [51200/70153]
loss: 0.083292  [57600/70153]
loss: 0.222965  [64000/70153]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.183855 

Epoch 5
-------------------------------
loss: 0.174849  [    0/70153]
loss: 0.249059  [ 6400/70153]
loss: 0.231955  [12800/70153]
loss: 0.236896  [19200/70153]
loss: 0.186328  [25600/70153]
loss: 0.123753  [32000/70153]
loss: 0.229692  [38400/70153]
loss: 0.224964  [44800/70153]
loss: 0.187237  [51200/70153]
loss: 0.100301  [57600/70153]
loss: 0.167091  [64000/70153]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.185123 

Epoch 6
-------------------------------
loss: 0.386039  [    0/70153]
loss: 0.244455  [ 6400/70153]
loss: 0.141127  [12800/70153]
loss: 0.109309  [19200/70153]
loss: 0.213144  [25600/70153]
loss: 0.212394  [32000/70153]
loss: 0.139270  [38400/70153]
loss: 0.140840  [44800/70153]
loss: 0.207628  [51200/70153]
loss: 0.180574  [57600/70153]
loss: 0.145186  [64000/70153]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.167781 

Epoch 7
-------------------------------
loss: 0.111548  [    0/70153]
loss: 0.138130  [ 6400/70153]
loss: 0.191296  [12800/70153]
loss: 0.233152  [19200/70153]
loss: 0.170320  [25600/70153]
loss: 0.376373  [32000/70153]
loss: 0.204861  [38400/70153]
loss: 0.133158  [44800/70153]
loss: 0.100623  [51200/70153]
loss: 0.342868  [57600/70153]
loss: 0.223826  [64000/70153]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.177044 

Epoch 8
-------------------------------
loss: 0.127025  [    0/70153]
loss: 0.138496  [ 6400/70153]
loss: 0.206503  [12800/70153]
loss: 0.129191  [19200/70153]
loss: 0.232601  [25600/70153]
loss: 0.116123  [32000/70153]
loss: 0.140998  [38400/70153]
loss: 0.189105  [44800/70153]
loss: 0.131422  [51200/70153]
loss: 0.164244  [57600/70153]
loss: 0.169429  [64000/70153]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.205663 

Epoch 9
-------------------------------
loss: 0.171714  [    0/70153]
loss: 0.152275  [ 6400/70153]
loss: 0.111375  [12800/70153]
loss: 0.157685  [19200/70153]
loss: 0.155032  [25600/70153]
loss: 0.304802  [32000/70153]
loss: 0.212005  [38400/70153]
loss: 0.072189  [44800/70153]
loss: 0.130373  [51200/70153]
loss: 0.292030  [57600/70153]
loss: 0.155586  [64000/70153]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.169734 

Epoch 10
-------------------------------
loss: 0.197817  [    0/70153]
loss: 0.130958  [ 6400/70153]
loss: 0.282311  [12800/70153]
loss: 0.179524  [19200/70153]
loss: 0.161113  [25600/70153]
loss: 1.669710  [32000/70153]
loss: 0.158746  [38400/70153]
loss: 0.111274  [44800/70153]
loss: 0.228753  [51200/70153]
loss: 0.260978  [57600/70153]
loss: 0.183068  [64000/70153]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.174994 

Epoch 11
-------------------------------
loss: 0.065573  [    0/70153]
loss: 0.118651  [ 6400/70153]
loss: 0.106823  [12800/70153]
loss: 0.194974  [19200/70153]
loss: 0.188676  [25600/70153]
loss: 0.129607  [32000/70153]
loss: 0.105548  [38400/70153]
loss: 0.138715  [44800/70153]
loss: 0.317776  [51200/70153]
loss: 0.255558  [57600/70153]
loss: 0.112837  [64000/70153]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.164341 

Epoch 12
-------------------------------
loss: 0.266124  [    0/70153]
loss: 0.226878  [ 6400/70153]
loss: 0.220504  [12800/70153]
loss: 0.309776  [19200/70153]
loss: 0.248744  [25600/70153]
loss: 0.225370  [32000/70153]
loss: 0.196990  [38400/70153]
loss: 0.084684  [44800/70153]
loss: 0.152165  [51200/70153]
loss: 0.097125  [57600/70153]
loss: 0.208539  [64000/70153]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.164739 

Epoch 13
-------------------------------
loss: 0.097582  [    0/70153]
loss: 0.212548  [ 6400/70153]
loss: 0.214442  [12800/70153]
loss: 0.216975  [19200/70153]
loss: 0.116771  [25600/70153]
loss: 0.118794  [32000/70153]
loss: 0.141553  [38400/70153]
loss: 0.167118  [44800/70153]
loss: 0.114984  [51200/70153]
loss: 0.152859  [57600/70153]
loss: 0.176598  [64000/70153]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.200984 

Epoch 14
-------------------------------
loss: 0.237098  [    0/70153]
loss: 0.079085  [ 6400/70153]
loss: 0.159307  [12800/70153]
loss: 0.225834  [19200/70153]
loss: 0.216103  [25600/70153]
loss: 0.164930  [32000/70153]
loss: 0.065872  [38400/70153]
loss: 0.119830  [44800/70153]
loss: 0.243642  [51200/70153]
loss: 0.088901  [57600/70153]
loss: 0.107248  [64000/70153]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.164349 

Epoch 15
-------------------------------
loss: 0.294821  [    0/70153]
loss: 0.178960  [ 6400/70153]
loss: 0.170417  [12800/70153]
loss: 0.215685  [19200/70153]
loss: 0.126562  [25600/70153]
loss: 0.192156  [32000/70153]
loss: 0.169449  [38400/70153]
loss: 0.145656  [44800/70153]
loss: 0.171039  [51200/70153]
loss: 0.258700  [57600/70153]
loss: 0.076266  [64000/70153]
loss: 0.291426  [25600/70127]
loss: 0.133394  [32000/70127]
loss: 0.062051  [38400/70127]
loss: 0.091288  [44800/70127]
loss: 0.068131  [51200/70127]
loss: 0.067540  [57600/70127]
loss: 0.029762  [64000/70127]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.101168 

Epoch 13
-------------------------------
loss: 0.107270  [    0/70127]
loss: 0.124138  [ 6400/70127]
loss: 0.105507  [12800/70127]
loss: 0.110511  [19200/70127]
loss: 0.180596  [25600/70127]
loss: 0.175476  [32000/70127]
loss: 0.053358  [38400/70127]
loss: 0.150209  [44800/70127]
loss: 0.069309  [51200/70127]
loss: 0.055571  [57600/70127]
loss: 0.132080  [64000/70127]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097708 

Epoch 14
-------------------------------
loss: 0.108859  [    0/70127]
loss: 0.157925  [ 6400/70127]
loss: 0.095654  [12800/70127]
loss: 0.107620  [19200/70127]
loss: 0.057251  [25600/70127]
loss: 0.161811  [32000/70127]
loss: 0.115225  [38400/70127]
loss: 0.153288  [44800/70127]
loss: 0.124228  [51200/70127]
loss: 0.130833  [57600/70127]
loss: 0.109552  [64000/70127]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097821 

Epoch 15
-------------------------------
loss: 0.094600  [    0/70127]
loss: 0.039262  [ 6400/70127]
loss: 0.120307  [12800/70127]
loss: 0.081395  [19200/70127]
loss: 0.079288  [25600/70127]
loss: 0.144303  [32000/70127]
loss: 0.045904  [38400/70127]
loss: 0.082337  [44800/70127]
loss: 0.060025  [51200/70127]
loss: 0.109951  [57600/70127]
loss: 0.037673  [64000/70127]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.100718 

Epoch 16
-------------------------------
loss: 0.059863  [    0/70127]
loss: 0.161044  [ 6400/70127]
loss: 0.178564  [12800/70127]
loss: 0.050486  [19200/70127]
loss: 0.185888  [25600/70127]
loss: 0.070898  [32000/70127]
loss: 0.179077  [38400/70127]
loss: 0.044163  [44800/70127]
loss: 0.090103  [51200/70127]
loss: 0.084856  [57600/70127]
loss: 0.060426  [64000/70127]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.098481 

Epoch 17
-------------------------------
loss: 0.077352  [    0/70127]
loss: 0.048090  [ 6400/70127]
loss: 0.099995  [12800/70127]
loss: 0.118158  [19200/70127]
loss: 0.094766  [25600/70127]
loss: 0.228463  [32000/70127]
loss: 0.099319  [38400/70127]
loss: 0.123107  [44800/70127]
loss: 0.170043  [51200/70127]
loss: 0.140736  [57600/70127]
loss: 0.139134  [64000/70127]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.101005 

Epoch 18
-------------------------------
loss: 0.106169  [    0/70127]
loss: 0.052495  [ 6400/70127]
loss: 0.124453  [12800/70127]
loss: 0.134495  [19200/70127]
loss: 0.217676  [25600/70127]
loss: 0.027067  [32000/70127]
loss: 0.046996  [38400/70127]
loss: 0.161640  [44800/70127]
loss: 0.083328  [51200/70127]
loss: 0.085242  [57600/70127]
loss: 0.071889  [64000/70127]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.103675 

Epoch 19
-------------------------------
loss: 0.134994  [    0/70127]
loss: 0.053166  [ 6400/70127]
loss: 0.114096  [12800/70127]
loss: 0.142192  [19200/70127]
loss: 0.053477  [25600/70127]
loss: 0.137714  [32000/70127]
loss: 0.025302  [38400/70127]
loss: 0.049802  [44800/70127]
loss: 0.060355  [51200/70127]
loss: 0.090355  [57600/70127]
loss: 0.173356  [64000/70127]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.113592 

Epoch 20
-------------------------------
loss: 0.074418  [    0/70127]
loss: 0.106164  [ 6400/70127]
loss: 0.184909  [12800/70127]
loss: 0.156863  [19200/70127]
loss: 0.201066  [25600/70127]
loss: 0.074630  [32000/70127]
loss: 0.033373  [38400/70127]
loss: 0.153584  [44800/70127]
loss: 0.080751  [51200/70127]
loss: 0.043757  [57600/70127]
loss: 0.094200  [64000/70127]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.100689 

Epoch 21
-------------------------------
loss: 0.068996  [    0/70127]
loss: 0.067246  [ 6400/70127]
loss: 0.081300  [12800/70127]
loss: 0.039851  [19200/70127]
loss: 0.276869  [25600/70127]
loss: 0.087611  [32000/70127]
loss: 0.073689  [38400/70127]
loss: 0.169746  [44800/70127]
loss: 0.060635  [51200/70127]
loss: 0.067374  [57600/70127]
loss: 0.158344  [64000/70127]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.103947 

Epoch 22
-------------------------------
loss: 0.103478  [    0/70127]
loss: 0.142173  [ 6400/70127]
loss: 0.073665  [12800/70127]
loss: 0.079635  [19200/70127]
loss: 0.027309  [25600/70127]
loss: 0.318429  [32000/70127]
loss: 0.144290  [38400/70127]
loss: 0.122309  [44800/70127]
loss: 0.100745  [51200/70127]
loss: 0.112351  [57600/70127]
loss: 0.115594  [64000/70127]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.107859 

Epoch 23
-------------------------------
loss: 0.056750  [    0/70127]
loss: 0.107279  [ 6400/70127]
loss: 0.119433  [12800/70127]
loss: 0.286416  [19200/70127]
loss: 0.066134  [25600/70127]
loss: 0.258278  [32000/70127]
loss: 0.105873  [38400/70127]
loss: 0.132219  [44800/70127]
loss: 0.088416  [51200/70127]
loss: 0.071497  [57600/70127]
loss: 0.152548  [64000/70127]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.097227 

Epoch 24
-------------------------------
loss: 0.112076  [    0/70127]
loss: 0.122726  [ 6400/70127]
loss: 0.114127  [12800/70127]
loss: 0.257619  [19200/70127]
loss: 0.305371  [25600/70127]
loss: 0.035384  [32000/70127]
loss: 0.057600  [38400/70127]
loss: 0.136841  [44800/70127]
loss: 0.148837  [51200/70127]
loss: 0.085328  [57600/70127]
loss: 0.064164  [64000/70127]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099938 

Epoch 25
-------------------------------
loss: 0.065424  [    0/70127]
loss: 0.038183  [ 6400/70127]
loss: 0.061057  [12800/70127]
loss: 0.068052  [19200/70127]
loss: 0.029485  [25600/70127]
loss: 0.178199  [32000/70127]
loss: 0.066370  [38400/70127]
loss: 0.081054  [44800/70127]
loss: 0.146532  [51200/70127]
loss: 0.044923  [57600/70127]
loss: 0.124146  [64000/70127]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.100131 

Epoch 26
-------------------------------
loss: 0.084490  [    0/70127]
loss: 0.115397  [ 6400/70127]
loss: 0.159090  [12800/70127]
loss: 0.138455  [19200/70127]
loss: 0.133780  [25600/70127]
loss: 0.109402  [32000/70127]
loss: 0.100610  [38400/70127]
loss: 0.044471  [44800/70127]
loss: 0.076420  [51200/70127]
loss: 0.062511  [57600/70127]
loss: 0.045785  [64000/70127]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.099699 

Epoch 27
-------------------------------
loss: 0.067656  [    0/70127]
loss: 0.081254  [ 6400/70127]
loss: 0.077923  [12800/70127]
loss: 0.075133  [19200/70127]
loss: 0.278760  [25600/70127]
loss: 0.080424  [32000/70127]
loss: 0.050113  [38400/70127]
loss: 0.127590  [44800/70127]
loss: 0.168986  [51200/70127]
loss: 0.101997  [57600/70127]
loss: 0.092504  [64000/70127]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.104844 

Epoch 28
-------------------------------
loss: 0.087865  [    0/70127]
loss: 0.097177  [ 6400/70127]
loss: 0.082384  [12800/70127]
loss: 0.127094  [19200/70127]
loss: 0.106398  [25600/70127]
loss: 0.154275  [32000/70127]
loss: 0.121754  [38400/70127]
loss: 0.109279  [44800/70127]
loss: 0.250248  [51200/70127]
loss: 0.133395  [57600/70127]
loss: 0.059236  [64000/70127]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.111651 

Epoch 29
-------------------------------
loss: 0.079301  [    0/70127]
loss: 0.061376  [ 6400/70127]
loss: 0.036327  [12800/70127]
loss: 0.142430  [19200/70127]
loss: 0.132715  [25600/70127]
loss: 0.072768  [32000/70127]
loss: 0.136222  [38400/70127]
loss: 0.120637  [44800/70127]
loss: 0.172307  [51200/70127]
loss: 0.158977  [57600/70127]
loss: 0.197710  [64000/70127]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.102336 

Epoch 30
-------------------------------
loss: 0.065451  [    0/70127]
loss: 0.092280  [ 6400/70127]
loss: 0.143776  [12800/70127]
loss: 0.100878  [19200/70127]
loss: 0.032839  [25600/70127]
loss: 0.145468  [32000/70127]
loss: 0.055995  [38400/70127]
loss: 0.176326  [44800/70127]
loss: 0.125497  [51200/70127]
loss: 0.107966  [57600/70127]
loss: 0.146845  [64000/70127]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.119492 

Epoch 31
-------------------------------
loss: 0.074533  [    0/70127]
loss: 0.168477  [ 6400/70127]
loss: 0.149356  [12800/70127]
loss: 0.190062  [19200/70127]
loss: 0.181626  [25600/70127]
loss: 0.025750  [32000/70127]
loss: 0.097231  [38400/70127]
loss: 0.099799  [44800/70127]
loss: 0.081926  [51200/70127]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.099790 

Epoch 30
-------------------------------
loss: 0.046674  [    0/71157]
loss: 0.012489  [ 6400/71157]
loss: 0.048178  [12800/71157]
loss: 0.037324  [19200/71157]
loss: 0.115673  [25600/71157]
loss: 0.019483  [32000/71157]
loss: 0.096105  [38400/71157]
loss: 0.121068  [44800/71157]
loss: 0.082370  [51200/71157]
loss: 0.143191  [57600/71157]
loss: 0.065340  [64000/71157]
loss: 0.105959  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.096930 

Epoch 31
-------------------------------
loss: 0.065825  [    0/71157]
loss: 0.014173  [ 6400/71157]
loss: 0.043045  [12800/71157]
loss: 0.078094  [19200/71157]
loss: 0.048490  [25600/71157]
loss: 0.052787  [32000/71157]
loss: 0.016378  [38400/71157]
loss: 0.063328  [44800/71157]
loss: 0.069322  [51200/71157]
loss: 0.087671  [57600/71157]
loss: 0.105438  [64000/71157]
loss: 0.066100  [70400/71157]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.102109 

Epoch 32
-------------------------------
loss: 0.071254  [    0/71157]
loss: 0.141354  [ 6400/71157]
loss: 0.323403  [12800/71157]
loss: 0.022892  [19200/71157]
loss: 0.042834  [25600/71157]
loss: 0.288093  [32000/71157]
loss: 0.176186  [38400/71157]
loss: 0.044758  [44800/71157]
loss: 0.017522  [51200/71157]
loss: 0.052583  [57600/71157]
loss: 0.128395  [64000/71157]
loss: 0.132990  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102623 

Epoch 33
-------------------------------
loss: 0.045488  [    0/71157]
loss: 0.033566  [ 6400/71157]
loss: 0.084005  [12800/71157]
loss: 0.026827  [19200/71157]
loss: 0.048849  [25600/71157]
loss: 0.050963  [32000/71157]
loss: 0.066768  [38400/71157]
loss: 0.048599  [44800/71157]
loss: 0.023917  [51200/71157]
loss: 0.139530  [57600/71157]
loss: 0.143994  [64000/71157]
loss: 0.051434  [70400/71157]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.101292 

Epoch 34
-------------------------------
loss: 0.111858  [    0/71157]
loss: 0.023794  [ 6400/71157]
loss: 0.086262  [12800/71157]
loss: 0.097484  [19200/71157]
loss: 0.165974  [25600/71157]
loss: 0.030321  [32000/71157]
loss: 0.052991  [38400/71157]
loss: 0.083697  [44800/71157]
loss: 0.174109  [51200/71157]
loss: 0.057713  [57600/71157]
loss: 0.120244  [64000/71157]
loss: 0.022008  [70400/71157]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.101607 

Epoch 35
-------------------------------
loss: 0.033686  [    0/71157]
loss: 0.036544  [ 6400/71157]
loss: 0.082378  [12800/71157]
loss: 0.102810  [19200/71157]
loss: 0.046384  [25600/71157]
loss: 0.048247  [32000/71157]
loss: 0.110392  [38400/71157]
loss: 0.115184  [44800/71157]
loss: 0.112666  [51200/71157]
loss: 0.103813  [57600/71157]
loss: 0.071316  [64000/71157]
loss: 0.046284  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.103040 

Epoch 36
-------------------------------
loss: 0.082071  [    0/71157]
loss: 0.059532  [ 6400/71157]
loss: 0.044079  [12800/71157]
loss: 0.081377  [19200/71157]
loss: 0.034630  [25600/71157]
loss: 0.049529  [32000/71157]
loss: 0.127011  [38400/71157]
loss: 0.137344  [44800/71157]
loss: 0.082169  [51200/71157]
loss: 0.105182  [57600/71157]
loss: 0.048688  [64000/71157]
loss: 0.071381  [70400/71157]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117515 

Epoch 37
-------------------------------
loss: 0.043002  [    0/71157]
loss: 0.040756  [ 6400/71157]
loss: 0.043003  [12800/71157]
loss: 0.048815  [19200/71157]
loss: 0.051932  [25600/71157]
loss: 0.085002  [32000/71157]
loss: 0.156196  [38400/71157]
loss: 0.016428  [44800/71157]
loss: 0.069083  [51200/71157]
loss: 0.107725  [57600/71157]
loss: 0.033128  [64000/71157]
loss: 0.089989  [70400/71157]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.098852 

Epoch 38
-------------------------------
loss: 0.061531  [    0/71157]
loss: 0.121829  [ 6400/71157]
loss: 0.195923  [12800/71157]
loss: 0.176849  [19200/71157]
loss: 0.015633  [25600/71157]
loss: 0.050415  [32000/71157]
loss: 0.103334  [38400/71157]
loss: 0.053412  [44800/71157]
loss: 0.114756  [51200/71157]
loss: 0.077779  [57600/71157]
loss: 0.043584  [64000/71157]
loss: 0.094098  [70400/71157]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.110945 

Epoch 39
-------------------------------
loss: 0.067414  [    0/71157]
loss: 0.036106  [ 6400/71157]
loss: 0.039766  [12800/71157]
loss: 0.114454  [19200/71157]
loss: 0.078311  [25600/71157]
loss: 0.048656  [32000/71157]
loss: 0.138410  [38400/71157]
loss: 0.015988  [44800/71157]
loss: 0.080698  [51200/71157]
loss: 0.092571  [57600/71157]
loss: 0.080357  [64000/71157]
loss: 0.044025  [70400/71157]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.106089 

Epoch 40
-------------------------------
loss: 0.118777  [    0/71157]
loss: 0.041356  [ 6400/71157]
loss: 0.140664  [12800/71157]
loss: 0.024942  [19200/71157]
loss: 0.113001  [25600/71157]
loss: 0.044379  [32000/71157]
loss: 0.066146  [38400/71157]
loss: 0.266351  [44800/71157]
loss: 0.043213  [51200/71157]
loss: 0.049745  [57600/71157]
loss: 0.061469  [64000/71157]
loss: 0.009410  [70400/71157]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.124175 

Epoch 41
-------------------------------
loss: 0.058648  [    0/71157]
loss: 0.068603  [ 6400/71157]
loss: 0.081764  [12800/71157]
loss: 0.082730  [19200/71157]
loss: 0.036184  [25600/71157]
loss: 0.060952  [32000/71157]
loss: 0.036191  [38400/71157]
loss: 0.125972  [44800/71157]
loss: 0.106040  [51200/71157]
loss: 0.049344  [57600/71157]
loss: 0.058794  [64000/71157]
loss: 0.061879  [70400/71157]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.112099 

Epoch 42
-------------------------------
loss: 0.035845  [    0/71157]
loss: 0.175072  [ 6400/71157]
loss: 0.037041  [12800/71157]
loss: 0.131730  [19200/71157]
loss: 0.095876  [25600/71157]
loss: 0.098054  [32000/71157]
loss: 0.076010  [38400/71157]
loss: 0.043710  [44800/71157]
loss: 0.125572  [51200/71157]
loss: 0.176165  [57600/71157]
loss: 0.023059  [64000/71157]
loss: 0.024687  [70400/71157]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.104362 

Epoch 43
-------------------------------
loss: 0.058834  [    0/71157]
loss: 0.035401  [ 6400/71157]
loss: 0.054619  [12800/71157]
loss: 0.057760  [19200/71157]
loss: 0.244712  [25600/71157]
loss: 0.117693  [32000/71157]
loss: 0.047131  [38400/71157]
loss: 0.090956  [44800/71157]
loss: 0.172313  [51200/71157]
loss: 0.047986  [57600/71157]
loss: 0.051775  [64000/71157]
loss: 0.030191  [70400/71157]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.109809 

Epoch 44
-------------------------------
loss: 0.081621  [    0/71157]
loss: 0.063666  [ 6400/71157]
loss: 0.105238  [12800/71157]
loss: 0.086123  [19200/71157]
loss: 0.040200  [25600/71157]
loss: 0.111787  [32000/71157]
loss: 0.072195  [38400/71157]
loss: 0.089672  [44800/71157]
loss: 0.058564  [51200/71157]
loss: 0.026945  [57600/71157]
loss: 0.038736  [64000/71157]
loss: 0.042168  [70400/71157]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.111935 

Epoch 45
-------------------------------
loss: 0.051555  [    0/71157]
loss: 0.144825  [ 6400/71157]
loss: 0.046680  [12800/71157]
loss: 0.071308  [19200/71157]
loss: 0.065393  [25600/71157]
loss: 0.072251  [32000/71157]
loss: 0.041876  [38400/71157]
loss: 0.055647  [44800/71157]
loss: 0.105724  [51200/71157]
loss: 0.072087  [57600/71157]
loss: 0.057929  [64000/71157]
loss: 0.051896  [70400/71157]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.106191 

Epoch 46
-------------------------------
loss: 0.162792  [    0/71157]
loss: 0.099127  [ 6400/71157]
loss: 0.045063  [12800/71157]
loss: 0.085308  [19200/71157]
loss: 0.042591  [25600/71157]
loss: 0.100195  [32000/71157]
loss: 0.174767  [38400/71157]
loss: 0.117042  [44800/71157]
loss: 0.033707  [51200/71157]
loss: 0.076195  [57600/71157]
loss: 0.075885  [64000/71157]
loss: 0.027738  [70400/71157]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.119255 

Epoch 47
-------------------------------
loss: 0.040747  [    0/71157]
loss: 0.046162  [ 6400/71157]
loss: 0.064406  [12800/71157]
loss: 0.069778  [19200/71157]
loss: 0.057213  [25600/71157]
loss: 0.017988  [32000/71157]
loss: 0.062669  [38400/71157]
loss: 0.087194  [44800/71157]
loss: 0.111191  [51200/71157]
loss: 0.032934  [57600/71157]
loss: 0.025819  [64000/71157]
loss: 0.164600  [70400/71157]
loss: 0.281596  [38400/69845]
loss: 0.222531  [44800/69845]
loss: 0.175273  [51200/69845]
loss: 0.323938  [57600/69845]
loss: 0.208247  [64000/69845]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.176797 

Epoch 6
-------------------------------
loss: 0.144280  [    0/69845]
loss: 0.283645  [ 6400/69845]
loss: 0.258975  [12800/69845]
loss: 0.192317  [19200/69845]
loss: 0.125589  [25600/69845]
loss: 0.210238  [32000/69845]
loss: 0.212981  [38400/69845]
loss: 0.148986  [44800/69845]
loss: 0.192286  [51200/69845]
loss: 0.148922  [57600/69845]
loss: 0.151235  [64000/69845]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.178431 

Epoch 7
-------------------------------
loss: 0.230905  [    0/69845]
loss: 0.255338  [ 6400/69845]
loss: 0.152155  [12800/69845]
loss: 0.125556  [19200/69845]
loss: 0.221251  [25600/69845]
loss: 0.256637  [32000/69845]
loss: 0.152318  [38400/69845]
loss: 0.245477  [44800/69845]
loss: 0.271479  [51200/69845]
loss: 0.164597  [57600/69845]
loss: 0.215390  [64000/69845]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.172695 

Epoch 8
-------------------------------
loss: 0.197186  [    0/69845]
loss: 0.119398  [ 6400/69845]
loss: 0.271568  [12800/69845]
loss: 0.123569  [19200/69845]
loss: 0.333580  [25600/69845]
loss: 0.170137  [32000/69845]
loss: 0.204494  [38400/69845]
loss: 0.178659  [44800/69845]
loss: 0.160138  [51200/69845]
loss: 0.155959  [57600/69845]
loss: 0.199471  [64000/69845]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.180783 

Epoch 9
-------------------------------
loss: 0.134588  [    0/69845]
loss: 0.212416  [ 6400/69845]
loss: 0.153656  [12800/69845]
loss: 0.114486  [19200/69845]
loss: 0.123034  [25600/69845]
loss: 0.312102  [32000/69845]
loss: 0.244441  [38400/69845]
loss: 0.197496  [44800/69845]
loss: 0.145552  [51200/69845]
loss: 0.235213  [57600/69845]
loss: 0.259781  [64000/69845]
Test Error: 
 Accuracy: 90.5%, Avg loss: 0.220172 

Epoch 10
-------------------------------
loss: 0.165878  [    0/69845]
loss: 0.156489  [ 6400/69845]
loss: 0.226777  [12800/69845]
loss: 0.137338  [19200/69845]
loss: 0.166911  [25600/69845]
loss: 0.182668  [32000/69845]
loss: 0.136745  [38400/69845]
loss: 0.149420  [44800/69845]
loss: 0.145086  [51200/69845]
loss: 0.239129  [57600/69845]
loss: 0.158206  [64000/69845]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.169216 

Epoch 11
-------------------------------
loss: 0.216501  [    0/69845]
loss: 0.161155  [ 6400/69845]
loss: 0.177392  [12800/69845]
loss: 0.197775  [19200/69845]
loss: 0.123567  [25600/69845]
loss: 0.185753  [32000/69845]
loss: 0.316820  [38400/69845]
loss: 0.148709  [44800/69845]
loss: 0.098591  [51200/69845]
loss: 0.245215  [57600/69845]
loss: 0.242444  [64000/69845]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.175117 

Epoch 12
-------------------------------
loss: 0.161722  [    0/69845]
loss: 0.229193  [ 6400/69845]
loss: 0.193460  [12800/69845]
loss: 0.204086  [19200/69845]
loss: 0.189392  [25600/69845]
loss: 0.281443  [32000/69845]
loss: 0.257559  [38400/69845]
loss: 0.168959  [44800/69845]
loss: 0.179211  [51200/69845]
loss: 0.187584  [57600/69845]
loss: 0.310643  [64000/69845]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.165865 

Epoch 13
-------------------------------
loss: 0.072022  [    0/69845]
loss: 0.246147  [ 6400/69845]
loss: 0.144635  [12800/69845]
loss: 0.256166  [19200/69845]
loss: 0.170015  [25600/69845]
loss: 0.278511  [32000/69845]
loss: 0.095560  [38400/69845]
loss: 0.255463  [44800/69845]
loss: 0.245147  [51200/69845]
loss: 0.095175  [57600/69845]
loss: 0.156395  [64000/69845]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.187471 

Epoch 14
-------------------------------
loss: 0.185189  [    0/69845]
loss: 0.266340  [ 6400/69845]
loss: 0.189040  [12800/69845]
loss: 0.108448  [19200/69845]
loss: 0.117751  [25600/69845]
loss: 0.057315  [32000/69845]
loss: 0.162053  [38400/69845]
loss: 0.170884  [44800/69845]
loss: 0.144905  [51200/69845]
loss: 0.282250  [57600/69845]
loss: 0.140466  [64000/69845]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.169814 

Epoch 15
-------------------------------
loss: 0.252946  [    0/69845]
loss: 0.117929  [ 6400/69845]
loss: 0.204289  [12800/69845]
loss: 0.122423  [19200/69845]
loss: 0.223244  [25600/69845]
loss: 0.172119  [32000/69845]
loss: 0.208510  [38400/69845]
loss: 0.166340  [44800/69845]
loss: 0.190150  [51200/69845]
loss: 0.107514  [57600/69845]
loss: 0.235077  [64000/69845]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.173186 

Epoch 16
-------------------------------
loss: 0.131631  [    0/69845]
loss: 0.156533  [ 6400/69845]
loss: 0.107276  [12800/69845]
loss: 0.217306  [19200/69845]
loss: 0.186657  [25600/69845]
loss: 0.197098  [32000/69845]
loss: 0.163175  [38400/69845]
loss: 0.194656  [44800/69845]
loss: 0.124952  [51200/69845]
loss: 0.196135  [57600/69845]
loss: 0.251886  [64000/69845]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.181843 

Epoch 17
-------------------------------
loss: 0.131864  [    0/69845]
loss: 0.242392  [ 6400/69845]
loss: 0.137312  [12800/69845]
loss: 0.100527  [19200/69845]
loss: 0.223640  [25600/69845]
loss: 0.160724  [32000/69845]
loss: 0.212714  [38400/69845]
loss: 0.195125  [44800/69845]
loss: 0.250425  [51200/69845]
loss: 0.196395  [57600/69845]
loss: 0.182674  [64000/69845]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.193554 

Epoch 18
-------------------------------
loss: 0.287481  [    0/69845]
loss: 0.141067  [ 6400/69845]
loss: 0.157407  [12800/69845]
loss: 0.323833  [19200/69845]
loss: 0.238858  [25600/69845]
loss: 0.248750  [32000/69845]
loss: 0.182845  [38400/69845]
loss: 0.194204  [44800/69845]
loss: 0.078246  [51200/69845]
loss: 0.135875  [57600/69845]
loss: 0.200931  [64000/69845]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.166699 

Epoch 19
-------------------------------
loss: 0.157518  [    0/69845]
loss: 0.190635  [ 6400/69845]
loss: 0.291874  [12800/69845]
loss: 0.119538  [19200/69845]
loss: 0.150765  [25600/69845]
loss: 0.237860  [32000/69845]
loss: 0.269827  [38400/69845]
loss: 0.153256  [44800/69845]
loss: 0.128330  [51200/69845]
loss: 0.112002  [57600/69845]
loss: 0.214806  [64000/69845]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.170805 

Epoch 20
-------------------------------
loss: 0.133842  [    0/69845]
loss: 0.201209  [ 6400/69845]
loss: 0.178051  [12800/69845]
loss: 0.166614  [19200/69845]
loss: 0.318822  [25600/69845]
loss: 0.153505  [32000/69845]
loss: 0.157936  [38400/69845]
loss: 0.089338  [44800/69845]
loss: 0.323860  [51200/69845]
loss: 0.155898  [57600/69845]
loss: 0.174276  [64000/69845]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.166222 

Epoch 21
-------------------------------
loss: 0.182716  [    0/69845]
loss: 0.175063  [ 6400/69845]
loss: 0.213164  [12800/69845]
loss: 0.173209  [19200/69845]
loss: 0.241434  [25600/69845]
loss: 0.211131  [32000/69845]
loss: 0.273471  [38400/69845]
loss: 0.327404  [44800/69845]
loss: 0.112900  [51200/69845]
loss: 0.095862  [57600/69845]
loss: 0.182774  [64000/69845]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.188989 

Epoch 22
-------------------------------
loss: 0.101789  [    0/69845]
loss: 0.272890  [ 6400/69845]
loss: 0.164799  [12800/69845]
loss: 0.135208  [19200/69845]
loss: 0.191228  [25600/69845]
loss: 0.125623  [32000/69845]
loss: 0.177834  [38400/69845]
loss: 0.200136  [44800/69845]
loss: 0.141325  [51200/69845]
loss: 0.290937  [57600/69845]
loss: 0.190462  [64000/69845]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.173909 

Epoch 23
-------------------------------
loss: 0.176481  [    0/69845]
loss: 0.161974  [ 6400/69845]
loss: 0.150427  [12800/69845]
loss: 0.086647  [19200/69845]
loss: 0.179412  [25600/69845]
loss: 0.100069  [32000/69845]
loss: 0.164722  [38400/69845]
loss: 0.208453  [44800/69845]
loss: 0.210130  [51200/69845]
loss: 0.198299  [57600/69845]
loss: 0.097394  [64000/69845]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.174509 

Epoch 24
-------------------------------
loss: 0.246997  [    0/69845]
loss: 0.147429  [ 6400/69845]
loss: 0.097412  [12800/69845]
loss: 0.141157  [19200/69845]
loss: 0.219321  [25600/69845]
loss: 0.131689  [32000/69845]
loss: 0.198970  [38400/69845]
loss: 0.184406  [44800/69845]
loss: 0.251633  [51200/69845]
loss: 0.191594  [57600/69845]
loss: 0.097072  [64000/69845]
loss: 0.116516  [57600/70549]
loss: 0.178564  [64000/70549]
loss: 0.065294  [70400/70549]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.145691 

Epoch 20
-------------------------------
loss: 0.274632  [    0/70549]
loss: 0.167840  [ 6400/70549]
loss: 0.128616  [12800/70549]
loss: 0.161243  [19200/70549]
loss: 0.125975  [25600/70549]
loss: 0.082144  [32000/70549]
loss: 0.187828  [38400/70549]
loss: 0.132312  [44800/70549]
loss: 0.182348  [51200/70549]
loss: 0.162981  [57600/70549]
loss: 0.070102  [64000/70549]
loss: 0.215367  [70400/70549]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.140297 

Epoch 21
-------------------------------
loss: 0.121105  [    0/70549]
loss: 0.175198  [ 6400/70549]
loss: 0.194148  [12800/70549]
loss: 0.271856  [19200/70549]
loss: 0.139759  [25600/70549]
loss: 0.255803  [32000/70549]
loss: 0.156869  [38400/70549]
loss: 0.214850  [44800/70549]
loss: 0.098338  [51200/70549]
loss: 0.096684  [57600/70549]
loss: 0.140144  [64000/70549]
loss: 0.092791  [70400/70549]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.151115 

Epoch 22
-------------------------------
loss: 0.180840  [    0/70549]
loss: 0.088814  [ 6400/70549]
loss: 0.208778  [12800/70549]
loss: 0.161160  [19200/70549]
loss: 0.175081  [25600/70549]
loss: 0.199293  [32000/70549]
loss: 0.176730  [38400/70549]
loss: 0.152596  [44800/70549]
loss: 0.215916  [51200/70549]
loss: 0.194319  [57600/70549]
loss: 0.069376  [64000/70549]
loss: 0.307579  [70400/70549]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.164568 

Epoch 23
-------------------------------
loss: 0.181183  [    0/70549]
loss: 0.143906  [ 6400/70549]
loss: 0.112199  [12800/70549]
loss: 0.156058  [19200/70549]
loss: 0.188428  [25600/70549]
loss: 0.134304  [32000/70549]
loss: 0.149337  [38400/70549]
loss: 0.078161  [44800/70549]
loss: 0.130079  [51200/70549]
loss: 0.228461  [57600/70549]
loss: 0.177651  [64000/70549]
loss: 0.104278  [70400/70549]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.160813 

Epoch 24
-------------------------------
loss: 0.137923  [    0/70549]
loss: 0.082610  [ 6400/70549]
loss: 0.114251  [12800/70549]
loss: 0.159683  [19200/70549]
loss: 0.095084  [25600/70549]
loss: 0.107396  [32000/70549]
loss: 0.103227  [38400/70549]
loss: 0.088535  [44800/70549]
loss: 0.182639  [51200/70549]
loss: 0.195025  [57600/70549]
loss: 0.164523  [64000/70549]
loss: 0.172483  [70400/70549]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.142419 

Epoch 25
-------------------------------
loss: 0.065343  [    0/70549]
loss: 0.219266  [ 6400/70549]
loss: 0.150351  [12800/70549]
loss: 0.087785  [19200/70549]
loss: 0.105216  [25600/70549]
loss: 0.134548  [32000/70549]
loss: 0.108344  [38400/70549]
loss: 0.145381  [44800/70549]
loss: 0.235888  [51200/70549]
loss: 0.175321  [57600/70549]
loss: 0.066729  [64000/70549]
loss: 0.142439  [70400/70549]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.150617 

Epoch 26
-------------------------------
loss: 0.137607  [    0/70549]
loss: 0.148405  [ 6400/70549]
loss: 0.123163  [12800/70549]
loss: 0.167266  [19200/70549]
loss: 0.121476  [25600/70549]
loss: 0.160273  [32000/70549]
loss: 0.173956  [38400/70549]
loss: 0.188158  [44800/70549]
loss: 0.175536  [51200/70549]
loss: 0.128012  [57600/70549]
loss: 0.247693  [64000/70549]
loss: 0.130680  [70400/70549]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.148332 

Epoch 27
-------------------------------
loss: 0.172684  [    0/70549]
loss: 0.156459  [ 6400/70549]
loss: 0.158584  [12800/70549]
loss: 0.082703  [19200/70549]
loss: 0.123092  [25600/70549]
loss: 0.155190  [32000/70549]
loss: 0.197853  [38400/70549]
loss: 0.091837  [44800/70549]
loss: 0.295981  [51200/70549]
loss: 0.306348  [57600/70549]
loss: 0.150798  [64000/70549]
loss: 0.146107  [70400/70549]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.164331 

Epoch 28
-------------------------------
loss: 0.172326  [    0/70549]
loss: 0.160573  [ 6400/70549]
loss: 0.201752  [12800/70549]
loss: 0.206117  [19200/70549]
loss: 0.166757  [25600/70549]
loss: 0.142830  [32000/70549]
loss: 0.171636  [38400/70549]
loss: 0.242684  [44800/70549]
loss: 0.137080  [51200/70549]
loss: 0.089321  [57600/70549]
loss: 0.225149  [64000/70549]
loss: 0.081516  [70400/70549]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.151864 

Epoch 29
-------------------------------
loss: 0.156657  [    0/70549]
loss: 0.150605  [ 6400/70549]
loss: 0.131635  [12800/70549]
loss: 0.098793  [19200/70549]
loss: 0.148478  [25600/70549]
loss: 0.196071  [32000/70549]
loss: 0.284906  [38400/70549]
loss: 0.259719  [44800/70549]
loss: 0.051626  [51200/70549]
loss: 0.056238  [57600/70549]
loss: 0.183154  [64000/70549]
loss: 0.075205  [70400/70549]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.145392 

Epoch 30
-------------------------------
loss: 0.095324  [    0/70549]
loss: 0.090702  [ 6400/70549]
loss: 0.143177  [12800/70549]
loss: 0.086637  [19200/70549]
loss: 0.163696  [25600/70549]
loss: 0.107311  [32000/70549]
loss: 0.123975  [38400/70549]
loss: 0.143200  [44800/70549]
loss: 0.108243  [51200/70549]
loss: 0.143967  [57600/70549]
loss: 0.078185  [64000/70549]
loss: 0.113496  [70400/70549]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.144091 

Epoch 31
-------------------------------
loss: 0.158149  [    0/70549]
loss: 0.121218  [ 6400/70549]
loss: 0.164467  [12800/70549]
loss: 0.076824  [19200/70549]
loss: 0.182187  [25600/70549]
loss: 0.184752  [32000/70549]
loss: 0.164134  [38400/70549]
loss: 0.153033  [44800/70549]
loss: 0.087007  [51200/70549]
loss: 0.200131  [57600/70549]
loss: 0.052363  [64000/70549]
loss: 0.114490  [70400/70549]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.150278 

Epoch 32
-------------------------------
loss: 0.091773  [    0/70549]
loss: 0.135034  [ 6400/70549]
loss: 0.179683  [12800/70549]
loss: 0.187752  [19200/70549]
loss: 0.131332  [25600/70549]
loss: 0.086333  [32000/70549]
loss: 0.109274  [38400/70549]
loss: 0.112996  [44800/70549]
loss: 0.142164  [51200/70549]
loss: 0.085427  [57600/70549]
loss: 0.148331  [64000/70549]
loss: 0.359664  [70400/70549]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.144680 

Epoch 33
-------------------------------
loss: 0.159959  [    0/70549]
loss: 0.150727  [ 6400/70549]
loss: 0.125882  [12800/70549]
loss: 0.364189  [19200/70549]
loss: 0.112425  [25600/70549]
loss: 0.175242  [32000/70549]
loss: 0.203033  [38400/70549]
loss: 0.301757  [44800/70549]
loss: 0.162979  [51200/70549]
loss: 0.207981  [57600/70549]
loss: 0.216909  [64000/70549]
loss: 0.136467  [70400/70549]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.151810 

Epoch 34
-------------------------------
loss: 0.152735  [    0/70549]
loss: 0.145174  [ 6400/70549]
loss: 0.211950  [12800/70549]
loss: 0.152978  [19200/70549]
loss: 0.214406  [25600/70549]
loss: 0.167415  [32000/70549]
loss: 0.108232  [38400/70549]
loss: 0.128454  [44800/70549]
loss: 0.048543  [51200/70549]
loss: 0.137731  [57600/70549]
loss: 0.181895  [64000/70549]
loss: 0.220847  [70400/70549]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.150245 

Epoch 35
-------------------------------
loss: 0.158230  [    0/70549]
loss: 0.238721  [ 6400/70549]
loss: 0.082843  [12800/70549]
loss: 0.079343  [19200/70549]
loss: 0.132684  [25600/70549]
loss: 0.146046  [32000/70549]
loss: 0.238065  [38400/70549]
loss: 0.209755  [44800/70549]
loss: 0.201701  [51200/70549]
loss: 0.143800  [57600/70549]
loss: 0.156057  [64000/70549]
loss: 0.078105  [70400/70549]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.150354 

Epoch 36
-------------------------------
loss: 0.199472  [    0/70549]
loss: 0.102675  [ 6400/70549]
loss: 0.089681  [12800/70549]
loss: 0.110496  [19200/70549]
loss: 0.210809  [25600/70549]
loss: 0.149367  [32000/70549]
loss: 0.149277  [38400/70549]
loss: 0.140879  [44800/70549]
loss: 0.185582  [51200/70549]
loss: 0.096844  [57600/70549]
loss: 0.085088  [64000/70549]
loss: 0.108245  [70400/70549]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.165268 

Epoch 37
-------------------------------
loss: 0.296031  [    0/70549]
loss: 0.095411  [ 6400/70549]
loss: 0.073646  [12800/70549]
loss: 0.077374  [19200/70549]
loss: 0.174547  [25600/70549]
loss: 0.184015  [32000/70549]
loss: 0.081509  [38400/70549]
loss: 0.230134  [44800/70549]
loss: 0.193214  [51200/70549]
loss: 0.197215  [57600/70549]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.160048 

Epoch 8
-------------------------------
loss: 0.182579  [    0/70534]
loss: 0.150073  [ 6400/70534]
loss: 0.210722  [12800/70534]
loss: 0.126203  [19200/70534]
loss: 0.203409  [25600/70534]
loss: 0.167743  [32000/70534]
loss: 0.190332  [38400/70534]
loss: 0.145371  [44800/70534]
loss: 0.201166  [51200/70534]
loss: 0.169325  [57600/70534]
loss: 0.283200  [64000/70534]
loss: 0.184652  [70400/70534]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.159076 

Epoch 9
-------------------------------
loss: 0.142717  [    0/70534]
loss: 0.228061  [ 6400/70534]
loss: 0.145384  [12800/70534]
loss: 0.064118  [19200/70534]
loss: 0.186619  [25600/70534]
loss: 0.186893  [32000/70534]
loss: 0.221077  [38400/70534]
loss: 0.061683  [44800/70534]
loss: 0.253402  [51200/70534]
loss: 0.153435  [57600/70534]
loss: 0.174204  [64000/70534]
loss: 0.079434  [70400/70534]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.159639 

Epoch 10
-------------------------------
loss: 0.120746  [    0/70534]
loss: 0.180503  [ 6400/70534]
loss: 0.091745  [12800/70534]
loss: 0.106233  [19200/70534]
loss: 0.244295  [25600/70534]
loss: 0.114478  [32000/70534]
loss: 0.083267  [38400/70534]
loss: 0.147960  [44800/70534]
loss: 0.148541  [51200/70534]
loss: 0.151027  [57600/70534]
loss: 0.156265  [64000/70534]
loss: 0.260042  [70400/70534]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.157327 

Epoch 11
-------------------------------
loss: 0.084241  [    0/70534]
loss: 0.250000  [ 6400/70534]
loss: 0.073055  [12800/70534]
loss: 0.145525  [19200/70534]
loss: 0.178517  [25600/70534]
loss: 0.196707  [32000/70534]
loss: 0.118386  [38400/70534]
loss: 0.160395  [44800/70534]
loss: 0.154119  [51200/70534]
loss: 0.227958  [57600/70534]
loss: 0.165275  [64000/70534]
loss: 0.162700  [70400/70534]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.151009 

Epoch 12
-------------------------------
loss: 0.098732  [    0/70534]
loss: 0.123056  [ 6400/70534]
loss: 0.293534  [12800/70534]
loss: 0.212328  [19200/70534]
loss: 0.148482  [25600/70534]
loss: 0.181809  [32000/70534]
loss: 0.442803  [38400/70534]
loss: 0.258003  [44800/70534]
loss: 0.206994  [51200/70534]
loss: 0.180069  [57600/70534]
loss: 0.125867  [64000/70534]
loss: 0.280252  [70400/70534]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.175237 

Epoch 13
-------------------------------
loss: 0.154070  [    0/70534]
loss: 0.327464  [ 6400/70534]
loss: 0.148084  [12800/70534]
loss: 0.088564  [19200/70534]
loss: 0.163838  [25600/70534]
loss: 0.119511  [32000/70534]
loss: 0.246556  [38400/70534]
loss: 0.143323  [44800/70534]
loss: 0.167227  [51200/70534]
loss: 0.183991  [57600/70534]
loss: 0.111153  [64000/70534]
loss: 0.209088  [70400/70534]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.199662 

Epoch 14
-------------------------------
loss: 0.185147  [    0/70534]
loss: 0.198267  [ 6400/70534]
loss: 0.120827  [12800/70534]
loss: 0.133846  [19200/70534]
loss: 0.057749  [25600/70534]
loss: 0.065757  [32000/70534]
loss: 0.218902  [38400/70534]
loss: 0.045214  [44800/70534]
loss: 0.154722  [51200/70534]
loss: 0.278050  [57600/70534]
loss: 0.210374  [64000/70534]
loss: 0.151651  [70400/70534]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.167592 

Epoch 15
-------------------------------
loss: 0.219123  [    0/70534]
loss: 0.086983  [ 6400/70534]
loss: 0.058516  [12800/70534]
loss: 0.250696  [19200/70534]
loss: 0.131924  [25600/70534]
loss: 0.156613  [32000/70534]
loss: 0.123594  [38400/70534]
loss: 0.226553  [44800/70534]
loss: 0.123475  [51200/70534]
loss: 0.123202  [57600/70534]
loss: 0.176942  [64000/70534]
loss: 0.160594  [70400/70534]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.161041 

Epoch 16
-------------------------------
loss: 0.128380  [    0/70534]
loss: 0.370521  [ 6400/70534]
loss: 0.266850  [12800/70534]
loss: 0.084309  [19200/70534]
loss: 0.112682  [25600/70534]
loss: 0.145625  [32000/70534]
loss: 0.250804  [38400/70534]
loss: 0.210049  [44800/70534]
loss: 0.060506  [51200/70534]
loss: 0.125511  [57600/70534]
loss: 0.125914  [64000/70534]
loss: 0.222433  [70400/70534]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.152842 

Epoch 17
-------------------------------
loss: 0.107063  [    0/70534]
loss: 0.188706  [ 6400/70534]
loss: 0.178146  [12800/70534]
loss: 0.151388  [19200/70534]
loss: 0.166663  [25600/70534]
loss: 0.123828  [32000/70534]
loss: 0.158864  [38400/70534]
loss: 0.190089  [44800/70534]
loss: 0.197940  [51200/70534]
loss: 0.130405  [57600/70534]
loss: 0.161671  [64000/70534]
loss: 0.119926  [70400/70534]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.156652 

Epoch 18
-------------------------------
loss: 0.113023  [    0/70534]
loss: 0.252284  [ 6400/70534]
loss: 0.192982  [12800/70534]
loss: 0.115009  [19200/70534]
loss: 0.071266  [25600/70534]
loss: 0.098465  [32000/70534]
loss: 0.178180  [38400/70534]
loss: 0.113857  [44800/70534]
loss: 0.168322  [51200/70534]
loss: 0.147173  [57600/70534]
loss: 0.163571  [64000/70534]
loss: 0.192574  [70400/70534]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.151071 

Epoch 19
-------------------------------
loss: 0.082302  [    0/70534]
loss: 0.266637  [ 6400/70534]
loss: 0.183509  [12800/70534]
loss: 0.137786  [19200/70534]
loss: 0.087142  [25600/70534]
loss: 0.168965  [32000/70534]
loss: 0.155766  [38400/70534]
loss: 0.115410  [44800/70534]
loss: 0.190125  [51200/70534]
loss: 0.202527  [57600/70534]
loss: 0.170986  [64000/70534]
loss: 0.100949  [70400/70534]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.189947 

Epoch 20
-------------------------------
loss: 0.101364  [    0/70534]
loss: 0.129446  [ 6400/70534]
loss: 0.147418  [12800/70534]
loss: 0.261777  [19200/70534]
loss: 0.257949  [25600/70534]
loss: 0.273253  [32000/70534]
loss: 0.114116  [38400/70534]
loss: 0.137120  [44800/70534]
loss: 0.194276  [51200/70534]
loss: 0.193964  [57600/70534]
loss: 0.145214  [64000/70534]
loss: 0.110878  [70400/70534]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.152292 

Epoch 21
-------------------------------
loss: 0.122436  [    0/70534]
loss: 0.158781  [ 6400/70534]
loss: 0.164172  [12800/70534]
loss: 0.125639  [19200/70534]
loss: 0.138413  [25600/70534]
loss: 0.207836  [32000/70534]
loss: 0.129125  [38400/70534]
loss: 0.124574  [44800/70534]
loss: 0.184070  [51200/70534]
loss: 0.341989  [57600/70534]
loss: 0.059776  [64000/70534]
loss: 0.165482  [70400/70534]
Test Error: 
 Accuracy: 90.8%, Avg loss: 0.235001 

Epoch 22
-------------------------------
loss: 0.332327  [    0/70534]
loss: 0.135419  [ 6400/70534]
loss: 0.126461  [12800/70534]
loss: 0.085618  [19200/70534]
loss: 0.156460  [25600/70534]
loss: 0.161358  [32000/70534]
loss: 0.236688  [38400/70534]
loss: 0.113458  [44800/70534]
loss: 0.138452  [51200/70534]
loss: 0.197553  [57600/70534]
loss: 0.125474  [64000/70534]
loss: 0.133481  [70400/70534]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.150203 

Epoch 23
-------------------------------
loss: 0.107270  [    0/70534]
loss: 0.205174  [ 6400/70534]
loss: 0.160933  [12800/70534]
loss: 0.077180  [19200/70534]
loss: 0.149739  [25600/70534]
loss: 0.233477  [32000/70534]
loss: 0.225220  [38400/70534]
loss: 0.132535  [44800/70534]
loss: 0.138817  [51200/70534]
loss: 0.200112  [57600/70534]
loss: 0.160195  [64000/70534]
loss: 0.130166  [70400/70534]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.148095 

Epoch 24
-------------------------------
loss: 0.160310  [    0/70534]
loss: 0.149634  [ 6400/70534]
loss: 0.235630  [12800/70534]
loss: 0.162415  [19200/70534]
loss: 0.291499  [25600/70534]
loss: 0.164741  [32000/70534]
loss: 0.190338  [38400/70534]
loss: 0.224219  [44800/70534]
loss: 0.066296  [51200/70534]
loss: 0.129103  [57600/70534]
loss: 0.092100  [64000/70534]
loss: 0.170160  [70400/70534]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.156062 

Epoch 25
-------------------------------
loss: 0.170140  [    0/70534]
loss: 0.104271  [ 6400/70534]
loss: 0.071796  [12800/70534]
loss: 0.128062  [19200/70534]
loss: 0.205669  [25600/70534]
loss: 0.081585  [32000/70534]
loss: 0.173446  [38400/70534]
loss: 0.143911  [44800/70534]
loss: 0.082356  [51200/70534]
loss: 0.137143  [57600/70534]
loss: 0.164010  [64000/70534]
loss: 0.108141  [70400/70534]
loss: 0.102933  [44800/69987]
loss: 0.273422  [51200/69987]
loss: 0.081686  [57600/69987]
loss: 0.219196  [64000/69987]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.189628 

Epoch 25
-------------------------------
loss: 0.141246  [    0/69987]
loss: 0.213145  [ 6400/69987]
loss: 0.226873  [12800/69987]
loss: 0.145623  [19200/69987]
loss: 0.285966  [25600/69987]
loss: 0.196058  [32000/69987]
loss: 0.255275  [38400/69987]
loss: 0.190468  [44800/69987]
loss: 0.221453  [51200/69987]
loss: 0.079243  [57600/69987]
loss: 0.173670  [64000/69987]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.191784 

Epoch 26
-------------------------------
loss: 0.107632  [    0/69987]
loss: 0.211352  [ 6400/69987]
loss: 0.136054  [12800/69987]
loss: 0.104236  [19200/69987]
loss: 0.144806  [25600/69987]
loss: 0.196540  [32000/69987]
loss: 0.188886  [38400/69987]
loss: 0.346235  [44800/69987]
loss: 0.079491  [51200/69987]
loss: 0.269508  [57600/69987]
loss: 0.217424  [64000/69987]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.195315 

Epoch 27
-------------------------------
loss: 0.181541  [    0/69987]
loss: 0.091695  [ 6400/69987]
loss: 0.163479  [12800/69987]
loss: 0.225711  [19200/69987]
loss: 0.104905  [25600/69987]
loss: 0.136240  [32000/69987]
loss: 0.174701  [38400/69987]
loss: 0.188367  [44800/69987]
loss: 0.192620  [51200/69987]
loss: 0.111180  [57600/69987]
loss: 0.454567  [64000/69987]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.190582 

Epoch 28
-------------------------------
loss: 0.180248  [    0/69987]
loss: 0.086083  [ 6400/69987]
loss: 0.088011  [12800/69987]
loss: 0.191278  [19200/69987]
loss: 0.194930  [25600/69987]
loss: 0.158909  [32000/69987]
loss: 0.066233  [38400/69987]
loss: 0.177918  [44800/69987]
loss: 0.218470  [51200/69987]
loss: 0.210652  [57600/69987]
loss: 0.172154  [64000/69987]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.188650 

Epoch 29
-------------------------------
loss: 0.241314  [    0/69987]
loss: 0.075283  [ 6400/69987]
loss: 0.210453  [12800/69987]
loss: 0.171809  [19200/69987]
loss: 0.151441  [25600/69987]
loss: 0.166291  [32000/69987]
loss: 0.210609  [38400/69987]
loss: 0.166835  [44800/69987]
loss: 0.138917  [51200/69987]
loss: 0.175394  [57600/69987]
loss: 0.179260  [64000/69987]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.195851 

Epoch 30
-------------------------------
loss: 0.102793  [    0/69987]
loss: 0.191565  [ 6400/69987]
loss: 0.301679  [12800/69987]
loss: 0.150970  [19200/69987]
loss: 0.121894  [25600/69987]
loss: 0.236802  [32000/69987]
loss: 0.114092  [38400/69987]
loss: 0.112406  [44800/69987]
loss: 0.157634  [51200/69987]
loss: 0.406687  [57600/69987]
loss: 0.144171  [64000/69987]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.189799 

Epoch 31
-------------------------------
loss: 0.118563  [    0/69987]
loss: 0.225376  [ 6400/69987]
loss: 0.177081  [12800/69987]
loss: 0.141626  [19200/69987]
loss: 0.127101  [25600/69987]
loss: 0.372629  [32000/69987]
loss: 0.175459  [38400/69987]
loss: 0.207249  [44800/69987]
loss: 0.185094  [51200/69987]
loss: 0.172874  [57600/69987]
loss: 0.153798  [64000/69987]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.205094 

Epoch 32
-------------------------------
loss: 0.142436  [    0/69987]
loss: 0.115938  [ 6400/69987]
loss: 0.140333  [12800/69987]
loss: 0.160985  [19200/69987]
loss: 0.242510  [25600/69987]
loss: 0.189392  [32000/69987]
loss: 0.243541  [38400/69987]
loss: 0.171210  [44800/69987]
loss: 0.115359  [51200/69987]
loss: 0.205481  [57600/69987]
loss: 0.163121  [64000/69987]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.186402 

Epoch 33
-------------------------------
loss: 0.228268  [    0/69987]
loss: 0.078872  [ 6400/69987]
loss: 0.107253  [12800/69987]
loss: 0.113515  [19200/69987]
loss: 0.112286  [25600/69987]
loss: 0.103753  [32000/69987]
loss: 0.128237  [38400/69987]
loss: 0.172001  [44800/69987]
loss: 0.179327  [51200/69987]
loss: 0.192567  [57600/69987]
loss: 0.212457  [64000/69987]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.185208 

Epoch 34
-------------------------------
loss: 0.270082  [    0/69987]
loss: 0.120097  [ 6400/69987]
loss: 0.128306  [12800/69987]
loss: 0.170308  [19200/69987]
loss: 0.143505  [25600/69987]
loss: 0.164289  [32000/69987]
loss: 0.120695  [38400/69987]
loss: 0.126776  [44800/69987]
loss: 0.134796  [51200/69987]
loss: 0.221294  [57600/69987]
loss: 0.149076  [64000/69987]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.182553 

Epoch 35
-------------------------------
loss: 0.120612  [    0/69987]
loss: 0.236404  [ 6400/69987]
loss: 0.126938  [12800/69987]
loss: 0.083065  [19200/69987]
loss: 0.180451  [25600/69987]
loss: 0.150489  [32000/69987]
loss: 0.293540  [38400/69987]
loss: 0.153748  [44800/69987]
loss: 0.152267  [51200/69987]
loss: 0.226487  [57600/69987]
loss: 0.231998  [64000/69987]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.222464 

Epoch 36
-------------------------------
loss: 0.248174  [    0/69987]
loss: 0.149228  [ 6400/69987]
loss: 0.182491  [12800/69987]
loss: 0.122927  [19200/69987]
loss: 0.109489  [25600/69987]
loss: 0.094255  [32000/69987]
loss: 0.220398  [38400/69987]
loss: 0.239513  [44800/69987]
loss: 0.141771  [51200/69987]
loss: 0.178997  [57600/69987]
loss: 0.275208  [64000/69987]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.191700 

Epoch 37
-------------------------------
loss: 0.180141  [    0/69987]
loss: 0.233254  [ 6400/69987]
loss: 0.143436  [12800/69987]
loss: 0.159107  [19200/69987]
loss: 0.157337  [25600/69987]
loss: 0.232742  [32000/69987]
loss: 0.160509  [38400/69987]
loss: 0.094049  [44800/69987]
loss: 0.363493  [51200/69987]
loss: 0.334272  [57600/69987]
loss: 0.278018  [64000/69987]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.194939 

Epoch 38
-------------------------------
loss: 0.117016  [    0/69987]
loss: 0.197071  [ 6400/69987]
loss: 0.081715  [12800/69987]
loss: 0.158369  [19200/69987]
loss: 0.267041  [25600/69987]
loss: 0.119996  [32000/69987]
loss: 0.221794  [38400/69987]
loss: 0.100720  [44800/69987]
loss: 0.296417  [51200/69987]
loss: 0.134106  [57600/69987]
loss: 0.066930  [64000/69987]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.211216 

Epoch 39
-------------------------------
loss: 0.212477  [    0/69987]
loss: 0.073005  [ 6400/69987]
loss: 0.178374  [12800/69987]
loss: 0.188737  [19200/69987]
loss: 0.176592  [25600/69987]
loss: 0.158111  [32000/69987]
loss: 0.091611  [38400/69987]
loss: 0.215454  [44800/69987]
loss: 0.174592  [51200/69987]
loss: 0.169128  [57600/69987]
loss: 0.165519  [64000/69987]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.191318 

Epoch 40
-------------------------------
loss: 0.164393  [    0/69987]
loss: 0.124587  [ 6400/69987]
loss: 0.192906  [12800/69987]
loss: 0.109472  [19200/69987]
loss: 0.101662  [25600/69987]
loss: 0.115762  [32000/69987]
loss: 0.195683  [38400/69987]
loss: 0.242892  [44800/69987]
loss: 0.204712  [51200/69987]
loss: 0.151042  [57600/69987]
loss: 0.142737  [64000/69987]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.181680 

Epoch 41
-------------------------------
loss: 0.140134  [    0/69987]
loss: 0.129794  [ 6400/69987]
loss: 0.104068  [12800/69987]
loss: 0.186489  [19200/69987]
loss: 0.462221  [25600/69987]
loss: 0.342764  [32000/69987]
loss: 0.157978  [38400/69987]
loss: 0.160940  [44800/69987]
loss: 0.126370  [51200/69987]
loss: 0.289238  [57600/69987]
loss: 0.061954  [64000/69987]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.206434 

Epoch 42
-------------------------------
loss: 0.328180  [    0/69987]
loss: 0.194707  [ 6400/69987]
loss: 0.122436  [12800/69987]
loss: 0.196410  [19200/69987]
loss: 0.091197  [25600/69987]
loss: 0.180237  [32000/69987]
loss: 0.154408  [38400/69987]
loss: 0.210203  [44800/69987]
loss: 0.234869  [51200/69987]
loss: 0.107321  [57600/69987]
loss: 0.188436  [64000/69987]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.187507 

Epoch 43
-------------------------------
loss: 0.111831  [    0/69987]
loss: 0.245309  [ 6400/69987]
loss: 0.169688  [12800/69987]
loss: 0.184279  [19200/69987]
loss: 0.205818  [25600/69987]
loss: 0.164692  [32000/69987]
loss: 0.184473  [38400/69987]
loss: 0.193054  [44800/69987]
loss: 0.131332  [51200/69987]
loss: 0.162997  [57600/69987]
loss: 0.259934  [64000/69987]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.085093 

Epoch 15
-------------------------------
loss: 0.033226  [    0/71373]
loss: 0.123162  [ 6400/71373]
loss: 0.077088  [12800/71373]
loss: 0.117335  [19200/71373]
loss: 0.091003  [25600/71373]
loss: 0.040672  [32000/71373]
loss: 0.011016  [38400/71373]
loss: 0.041624  [44800/71373]
loss: 0.057291  [51200/71373]
loss: 0.153037  [57600/71373]
loss: 0.067353  [64000/71373]
loss: 0.179810  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.087714 

Epoch 16
-------------------------------
loss: 0.056111  [    0/71373]
loss: 0.039447  [ 6400/71373]
loss: 0.113931  [12800/71373]
loss: 0.053096  [19200/71373]
loss: 0.061478  [25600/71373]
loss: 0.065441  [32000/71373]
loss: 0.048334  [38400/71373]
loss: 0.124184  [44800/71373]
loss: 0.004538  [51200/71373]
loss: 0.103400  [57600/71373]
loss: 0.064995  [64000/71373]
loss: 0.034399  [70400/71373]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.087123 

Epoch 17
-------------------------------
loss: 0.091426  [    0/71373]
loss: 0.099373  [ 6400/71373]
loss: 0.016646  [12800/71373]
loss: 0.053540  [19200/71373]
loss: 0.038020  [25600/71373]
loss: 0.030698  [32000/71373]
loss: 0.060515  [38400/71373]
loss: 0.012280  [44800/71373]
loss: 0.030803  [51200/71373]
loss: 0.054438  [57600/71373]
loss: 0.066188  [64000/71373]
loss: 0.027145  [70400/71373]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.092450 

Epoch 18
-------------------------------
loss: 0.040507  [    0/71373]
loss: 0.095632  [ 6400/71373]
loss: 0.016348  [12800/71373]
loss: 0.065115  [19200/71373]
loss: 0.005169  [25600/71373]
loss: 0.047795  [32000/71373]
loss: 1.609673  [38400/71373]
loss: 0.046404  [44800/71373]
loss: 0.059841  [51200/71373]
loss: 0.094842  [57600/71373]
loss: 0.264605  [64000/71373]
loss: 0.083526  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.097353 

Epoch 19
-------------------------------
loss: 0.088524  [    0/71373]
loss: 0.051149  [ 6400/71373]
loss: 0.061151  [12800/71373]
loss: 0.022611  [19200/71373]
loss: 0.038237  [25600/71373]
loss: 0.129321  [32000/71373]
loss: 0.018087  [38400/71373]
loss: 0.047579  [44800/71373]
loss: 0.095184  [51200/71373]
loss: 0.040539  [57600/71373]
loss: 0.023314  [64000/71373]
loss: 0.070778  [70400/71373]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.100724 

Epoch 20
-------------------------------
loss: 0.052689  [    0/71373]
loss: 0.017792  [ 6400/71373]
loss: 0.050819  [12800/71373]
loss: 0.036468  [19200/71373]
loss: 0.064542  [25600/71373]
loss: 0.041246  [32000/71373]
loss: 0.112263  [38400/71373]
loss: 0.077504  [44800/71373]
loss: 0.168143  [51200/71373]
loss: 0.127195  [57600/71373]
loss: 0.052182  [64000/71373]
loss: 0.117369  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.089918 

Epoch 21
-------------------------------
loss: 0.060106  [    0/71373]
loss: 0.047700  [ 6400/71373]
loss: 0.063478  [12800/71373]
loss: 0.049753  [19200/71373]
loss: 0.018297  [25600/71373]
loss: 0.110319  [32000/71373]
loss: 0.056121  [38400/71373]
loss: 0.016032  [44800/71373]
loss: 0.133521  [51200/71373]
loss: 0.037284  [57600/71373]
loss: 0.095103  [64000/71373]
loss: 0.058783  [70400/71373]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.102049 

Epoch 22
-------------------------------
loss: 0.010949  [    0/71373]
loss: 0.033295  [ 6400/71373]
loss: 0.027134  [12800/71373]
loss: 0.011993  [19200/71373]
loss: 0.019462  [25600/71373]
loss: 0.030045  [32000/71373]
loss: 0.041864  [38400/71373]
loss: 0.044496  [44800/71373]
loss: 0.058765  [51200/71373]
loss: 0.016411  [57600/71373]
loss: 0.024672  [64000/71373]
loss: 0.034570  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.091195 

Epoch 23
-------------------------------
loss: 0.046464  [    0/71373]
loss: 0.041500  [ 6400/71373]
loss: 0.004168  [12800/71373]
loss: 0.029896  [19200/71373]
loss: 0.070947  [25600/71373]
loss: 0.053798  [32000/71373]
loss: 0.123593  [38400/71373]
loss: 0.037384  [44800/71373]
loss: 0.069128  [51200/71373]
loss: 0.092268  [57600/71373]
loss: 0.003264  [64000/71373]
loss: 0.057005  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.089996 

Epoch 24
-------------------------------
loss: 0.058073  [    0/71373]
loss: 0.013729  [ 6400/71373]
loss: 0.063053  [12800/71373]
loss: 0.032137  [19200/71373]
loss: 0.048915  [25600/71373]
loss: 0.078365  [32000/71373]
loss: 0.036224  [38400/71373]
loss: 0.046280  [44800/71373]
loss: 0.049107  [51200/71373]
loss: 0.045668  [57600/71373]
loss: 0.169930  [64000/71373]
loss: 0.045102  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.092964 

Epoch 25
-------------------------------
loss: 0.126268  [    0/71373]
loss: 0.098635  [ 6400/71373]
loss: 0.021891  [12800/71373]
loss: 0.051224  [19200/71373]
loss: 0.134372  [25600/71373]
loss: 0.019521  [32000/71373]
loss: 0.039671  [38400/71373]
loss: 0.044660  [44800/71373]
loss: 0.050892  [51200/71373]
loss: 0.179684  [57600/71373]
loss: 0.140342  [64000/71373]
loss: 0.025789  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.092940 

Epoch 26
-------------------------------
loss: 0.044225  [    0/71373]
loss: 0.054116  [ 6400/71373]
loss: 0.042486  [12800/71373]
loss: 0.030032  [19200/71373]
loss: 0.169253  [25600/71373]
loss: 0.042303  [32000/71373]
loss: 0.032447  [38400/71373]
loss: 0.072758  [44800/71373]
loss: 0.067361  [51200/71373]
loss: 0.075983  [57600/71373]
loss: 0.063632  [64000/71373]
loss: 0.040750  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.093804 

Epoch 27
-------------------------------
loss: 0.016197  [    0/71373]
loss: 0.036273  [ 6400/71373]
loss: 0.057281  [12800/71373]
loss: 0.026299  [19200/71373]
loss: 0.131925  [25600/71373]
loss: 0.063085  [32000/71373]
loss: 0.070371  [38400/71373]
loss: 0.163753  [44800/71373]
loss: 0.025537  [51200/71373]
loss: 0.003366  [57600/71373]
loss: 0.038834  [64000/71373]
loss: 0.115993  [70400/71373]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090338 

Epoch 28
-------------------------------
loss: 0.005514  [    0/71373]
loss: 0.018142  [ 6400/71373]
loss: 0.014944  [12800/71373]
loss: 0.045215  [19200/71373]
loss: 0.025421  [25600/71373]
loss: 0.062919  [32000/71373]
loss: 0.117518  [38400/71373]
loss: 0.145319  [44800/71373]
loss: 0.085129  [51200/71373]
loss: 0.101343  [57600/71373]
loss: 0.020285  [64000/71373]
loss: 0.144227  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.103765 

Epoch 29
-------------------------------
loss: 0.020290  [    0/71373]
loss: 0.055488  [ 6400/71373]
loss: 0.033425  [12800/71373]
loss: 0.111795  [19200/71373]
loss: 0.202631  [25600/71373]
loss: 0.045489  [32000/71373]
loss: 0.037964  [38400/71373]
loss: 0.093486  [44800/71373]
loss: 0.021995  [51200/71373]
loss: 0.064604  [57600/71373]
loss: 0.094503  [64000/71373]
loss: 0.016859  [70400/71373]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.117254 

Epoch 30
-------------------------------
loss: 0.024735  [    0/71373]
loss: 0.028376  [ 6400/71373]
loss: 0.027484  [12800/71373]
loss: 0.060836  [19200/71373]
loss: 0.048868  [25600/71373]
loss: 0.036731  [32000/71373]
loss: 0.061048  [38400/71373]
loss: 0.004434  [44800/71373]
loss: 0.054969  [51200/71373]
loss: 0.087908  [57600/71373]
loss: 0.067010  [64000/71373]
loss: 0.015345  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.093213 

Epoch 31
-------------------------------
loss: 0.094587  [    0/71373]
loss: 0.097479  [ 6400/71373]
loss: 0.042148  [12800/71373]
loss: 0.067052  [19200/71373]
loss: 0.036427  [25600/71373]
loss: 0.031598  [32000/71373]
loss: 0.018452  [38400/71373]
loss: 0.160336  [44800/71373]
loss: 0.010151  [51200/71373]
loss: 0.028500  [57600/71373]
loss: 0.112806  [64000/71373]
loss: 0.039297  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.100522 

Epoch 32
-------------------------------
loss: 0.039225  [    0/71373]
loss: 0.037200  [ 6400/71373]
loss: 0.037004  [12800/71373]
loss: 0.027617  [19200/71373]
loss: 0.036023  [25600/71373]
loss: 0.053563  [32000/71373]
loss: 0.078899  [38400/71373]
loss: 0.023643  [44800/71373]
loss: 0.009473  [51200/71373]
loss: 0.044396  [57600/71373]
loss: 0.026567  [64000/71373]
loss: 0.041988  [70400/71373]
2022/09/20 21:28:08 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Epoch 16
-------------------------------
loss: 0.117941  [    0/69978]
loss: 0.159283  [ 6400/69978]
loss: 0.234138  [12800/69978]
loss: 0.192259  [19200/69978]
loss: 0.062495  [25600/69978]
loss: 0.153209  [32000/69978]
loss: 0.181964  [38400/69978]
loss: 0.298964  [44800/69978]
loss: 0.156654  [51200/69978]
loss: 0.158237  [57600/69978]
loss: 0.178489  [64000/69978]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.180380 

Epoch 17
-------------------------------
loss: 0.055122  [    0/69978]
loss: 0.061818  [ 6400/69978]
loss: 0.091787  [12800/69978]
loss: 0.132137  [19200/69978]
loss: 0.070022  [25600/69978]
loss: 0.109651  [32000/69978]
loss: 0.275707  [38400/69978]
loss: 0.126992  [44800/69978]
loss: 0.189923  [51200/69978]
loss: 0.250384  [57600/69978]
loss: 0.105208  [64000/69978]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.173260 

Epoch 18
-------------------------------
loss: 0.064145  [    0/69978]
loss: 0.100629  [ 6400/69978]
loss: 0.084704  [12800/69978]
loss: 0.134767  [19200/69978]
loss: 0.090266  [25600/69978]
loss: 0.103836  [32000/69978]
loss: 0.136752  [38400/69978]
loss: 0.178817  [44800/69978]
loss: 0.070951  [51200/69978]
loss: 0.178506  [57600/69978]
loss: 0.097276  [64000/69978]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.188934 

Epoch 19
-------------------------------
loss: 0.112281  [    0/69978]
loss: 0.190093  [ 6400/69978]
loss: 0.094555  [12800/69978]
loss: 0.156163  [19200/69978]
loss: 0.130257  [25600/69978]
loss: 0.090048  [32000/69978]
loss: 0.186784  [38400/69978]
loss: 0.163806  [44800/69978]
loss: 0.193471  [51200/69978]
loss: 0.232566  [57600/69978]
loss: 0.263350  [64000/69978]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.174472 

Epoch 20
-------------------------------
loss: 0.108808  [    0/69978]
loss: 0.135943  [ 6400/69978]
loss: 0.078295  [12800/69978]
loss: 0.143851  [19200/69978]
loss: 0.187923  [25600/69978]
loss: 0.084543  [32000/69978]
loss: 0.128235  [38400/69978]
loss: 0.189963  [44800/69978]
loss: 0.114502  [51200/69978]
loss: 0.167884  [57600/69978]
loss: 0.210566  [64000/69978]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.179505 

Epoch 21
-------------------------------
loss: 0.096981  [    0/69978]
loss: 0.100173  [ 6400/69978]
loss: 0.265173  [12800/69978]
loss: 0.201377  [19200/69978]
loss: 0.140297  [25600/69978]
loss: 0.135240  [32000/69978]
loss: 0.243154  [38400/69978]
loss: 0.136011  [44800/69978]
loss: 0.221741  [51200/69978]
loss: 0.145612  [57600/69978]
loss: 0.190340  [64000/69978]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.175758 

Epoch 22
-------------------------------
loss: 0.129773  [    0/69978]
loss: 0.143481  [ 6400/69978]
loss: 0.202364  [12800/69978]
loss: 0.091269  [19200/69978]
loss: 0.108259  [25600/69978]
loss: 0.154704  [32000/69978]
loss: 0.233826  [38400/69978]
loss: 0.147726  [44800/69978]
loss: 0.176356  [51200/69978]
loss: 0.156928  [57600/69978]
loss: 0.214938  [64000/69978]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.176433 

Epoch 23
-------------------------------
loss: 0.130335  [    0/69978]
loss: 0.151588  [ 6400/69978]
loss: 0.127296  [12800/69978]
loss: 0.118442  [19200/69978]
loss: 0.063620  [25600/69978]
loss: 0.151847  [32000/69978]
loss: 0.060168  [38400/69978]
loss: 0.209699  [44800/69978]
loss: 0.173372  [51200/69978]
loss: 0.165502  [57600/69978]
loss: 0.139647  [64000/69978]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.173618 

Epoch 24
-------------------------------
loss: 0.114694  [    0/69978]
loss: 0.163378  [ 6400/69978]
loss: 0.091605  [12800/69978]
loss: 0.222571  [19200/69978]
loss: 0.167631  [25600/69978]
loss: 0.112096  [32000/69978]
loss: 0.105686  [38400/69978]
loss: 0.114927  [44800/69978]
loss: 0.213651  [51200/69978]
loss: 0.355162  [57600/69978]
loss: 0.100988  [64000/69978]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.212891 

Epoch 25
-------------------------------
loss: 0.126111  [    0/69978]
loss: 0.152987  [ 6400/69978]
loss: 0.093475  [12800/69978]
loss: 0.171333  [19200/69978]
loss: 0.054273  [25600/69978]
loss: 0.243837  [32000/69978]
loss: 0.168852  [38400/69978]
loss: 0.103861  [44800/69978]
loss: 0.125032  [51200/69978]
loss: 0.193888  [57600/69978]
loss: 0.090868  [64000/69978]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.184818 

Epoch 26
-------------------------------
loss: 0.140456  [    0/69978]
loss: 0.176020  [ 6400/69978]
loss: 0.216535  [12800/69978]
loss: 0.110347  [19200/69978]
loss: 0.199186  [25600/69978]
loss: 0.134790  [32000/69978]
loss: 0.151798  [38400/69978]
loss: 0.191890  [44800/69978]
loss: 0.083376  [51200/69978]
loss: 0.162567  [57600/69978]
loss: 0.128406  [64000/69978]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.175850 

Epoch 27
-------------------------------
loss: 0.231507  [    0/69978]
loss: 0.177325  [ 6400/69978]
loss: 0.142523  [12800/69978]
loss: 0.206337  [19200/69978]
loss: 0.263974  [25600/69978]
loss: 0.113970  [32000/69978]
loss: 0.211550  [38400/69978]
loss: 0.110119  [44800/69978]
loss: 0.163923  [51200/69978]
loss: 0.142137  [57600/69978]
loss: 0.171464  [64000/69978]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.210972 

Epoch 28
-------------------------------
loss: 0.119730  [    0/69978]
loss: 0.117352  [ 6400/69978]
loss: 0.181983  [12800/69978]
loss: 0.147872  [19200/69978]
loss: 0.116416  [25600/69978]
loss: 0.140103  [32000/69978]
loss: 0.236261  [38400/69978]
loss: 0.144926  [44800/69978]
loss: 0.198026  [51200/69978]
loss: 0.214039  [57600/69978]
loss: 0.199971  [64000/69978]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.188164 

Epoch 29
-------------------------------
loss: 0.104368  [    0/69978]
loss: 0.083802  [ 6400/69978]
loss: 0.344269  [12800/69978]
loss: 0.114268  [19200/69978]
loss: 0.161024  [25600/69978]
loss: 0.137311  [32000/69978]
loss: 0.145828  [38400/69978]
loss: 0.128001  [44800/69978]
loss: 0.093808  [51200/69978]
loss: 0.170475  [57600/69978]
loss: 0.102663  [64000/69978]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.179898 

Epoch 30
-------------------------------
loss: 0.193197  [    0/69978]
loss: 0.211119  [ 6400/69978]
loss: 0.069517  [12800/69978]
loss: 0.229688  [19200/69978]
loss: 0.287903  [25600/69978]
loss: 0.075254  [32000/69978]
loss: 0.118883  [38400/69978]
loss: 0.134193  [44800/69978]
loss: 0.100674  [51200/69978]
loss: 0.082970  [57600/69978]
loss: 0.162488  [64000/69978]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.185395 

Epoch 31
-------------------------------
loss: 0.083877  [    0/69978]
loss: 0.148568  [ 6400/69978]
loss: 0.183327  [12800/69978]
loss: 0.194937  [19200/69978]
loss: 0.183682  [25600/69978]
loss: 0.118804  [32000/69978]
loss: 0.167280  [38400/69978]
loss: 0.118818  [44800/69978]
loss: 0.055616  [51200/69978]
loss: 0.181944  [57600/69978]
loss: 0.061285  [64000/69978]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.173390 

Epoch 32
-------------------------------
loss: 0.181862  [    0/69978]
loss: 0.162267  [ 6400/69978]
loss: 0.167103  [12800/69978]
loss: 0.057513  [19200/69978]
loss: 0.138452  [25600/69978]
loss: 0.117953  [32000/69978]
loss: 0.211180  [38400/69978]
loss: 0.197361  [44800/69978]
loss: 0.166388  [51200/69978]
loss: 0.240423  [57600/69978]
loss: 0.080759  [64000/69978]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.194369 

Epoch 33
-------------------------------
loss: 0.143199  [    0/69978]
loss: 0.144558  [ 6400/69978]
loss: 0.205024  [12800/69978]
loss: 0.195699  [19200/69978]
loss: 0.097436  [25600/69978]
loss: 0.216414  [32000/69978]
loss: 0.099632  [38400/69978]
loss: 0.107882  [44800/69978]
loss: 0.085172  [51200/69978]
loss: 0.224392  [57600/69978]
loss: 0.115345  [64000/69978]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.183898 

Epoch 34
-------------------------------
loss: 0.315749  [    0/69978]
loss: 0.156167  [ 6400/69978]
loss: 0.131946  [12800/69978]
loss: 0.266045  [19200/69978]
loss: 0.146044  [25600/69978]
loss: 0.160443  [32000/69978]
loss: 0.130609  [38400/69978]
loss: 0.197767  [44800/69978]
loss: 0.197511  [51200/69978]
loss: 0.208406  [57600/69978]
loss: 0.193637  [64000/69978]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.199742 

Epoch 35
-------------------------------
loss: 0.099805  [    0/69978]
loss: 0.076296  [ 6400/69978]
loss: 0.116052  [12800/69978]
loss: 0.097196  [44800/69667]
loss: 0.243602  [51200/69667]
loss: 0.098178  [57600/69667]
loss: 0.111143  [64000/69667]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.119349 

Epoch 25
-------------------------------
loss: 0.041306  [    0/69667]
loss: 0.120164  [ 6400/69667]
loss: 0.072961  [12800/69667]
loss: 0.071026  [19200/69667]
loss: 0.112877  [25600/69667]
loss: 0.073242  [32000/69667]
loss: 0.075707  [38400/69667]
loss: 0.113760  [44800/69667]
loss: 0.092397  [51200/69667]
loss: 0.095074  [57600/69667]
loss: 0.143951  [64000/69667]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.121205 

Epoch 26
-------------------------------
loss: 0.105428  [    0/69667]
loss: 0.044907  [ 6400/69667]
loss: 0.062204  [12800/69667]
loss: 0.091458  [19200/69667]
loss: 0.044964  [25600/69667]
loss: 0.101353  [32000/69667]
loss: 0.123097  [38400/69667]
loss: 0.119767  [44800/69667]
loss: 0.086984  [51200/69667]
loss: 0.114549  [57600/69667]
loss: 0.178491  [64000/69667]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.124875 

Epoch 27
-------------------------------
loss: 0.115022  [    0/69667]
loss: 0.195664  [ 6400/69667]
loss: 0.126992  [12800/69667]
loss: 0.069640  [19200/69667]
loss: 0.183133  [25600/69667]
loss: 0.056934  [32000/69667]
loss: 0.157789  [38400/69667]
loss: 0.087481  [44800/69667]
loss: 0.104906  [51200/69667]
loss: 0.252886  [57600/69667]
loss: 0.129703  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.118341 

Epoch 28
-------------------------------
loss: 0.056114  [    0/69667]
loss: 0.088456  [ 6400/69667]
loss: 0.052167  [12800/69667]
loss: 0.119844  [19200/69667]
loss: 0.070263  [25600/69667]
loss: 0.173506  [32000/69667]
loss: 0.143933  [38400/69667]
loss: 0.130499  [44800/69667]
loss: 0.065653  [51200/69667]
loss: 0.116955  [57600/69667]
loss: 0.167575  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.115922 

Epoch 29
-------------------------------
loss: 0.153012  [    0/69667]
loss: 0.204641  [ 6400/69667]
loss: 0.106133  [12800/69667]
loss: 0.104818  [19200/69667]
loss: 0.146202  [25600/69667]
loss: 0.093977  [32000/69667]
loss: 0.114184  [38400/69667]
loss: 0.093750  [44800/69667]
loss: 0.099293  [51200/69667]
loss: 0.183737  [57600/69667]
loss: 0.230429  [64000/69667]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.123797 

Epoch 30
-------------------------------
loss: 0.084196  [    0/69667]
loss: 0.066128  [ 6400/69667]
loss: 0.064023  [12800/69667]
loss: 0.130335  [19200/69667]
loss: 0.038105  [25600/69667]
loss: 0.122406  [32000/69667]
loss: 0.184096  [38400/69667]
loss: 0.139546  [44800/69667]
loss: 0.067382  [51200/69667]
loss: 0.064816  [57600/69667]
loss: 0.095811  [64000/69667]
Test Error: 
 Accuracy: 94.4%, Avg loss: 0.140424 

Epoch 31
-------------------------------
loss: 0.106924  [    0/69667]
loss: 0.127587  [ 6400/69667]
loss: 0.103627  [12800/69667]
loss: 0.124904  [19200/69667]
loss: 0.101217  [25600/69667]
loss: 0.094307  [32000/69667]
loss: 0.170178  [38400/69667]
loss: 0.113104  [44800/69667]
loss: 0.091915  [51200/69667]
loss: 0.036495  [57600/69667]
loss: 0.139013  [64000/69667]
Test Error: 
 Accuracy: 95.3%, Avg loss: 0.115466 

Epoch 32
-------------------------------
loss: 0.135875  [    0/69667]
loss: 0.036748  [ 6400/69667]
loss: 0.096325  [12800/69667]
loss: 0.098413  [19200/69667]
loss: 0.092180  [25600/69667]
loss: 0.082027  [32000/69667]
loss: 0.147757  [38400/69667]
loss: 0.131961  [44800/69667]
loss: 0.138615  [51200/69667]
loss: 0.155420  [57600/69667]
loss: 0.170128  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.115841 

Epoch 33
-------------------------------
loss: 0.142059  [    0/69667]
loss: 0.120665  [ 6400/69667]
loss: 0.085980  [12800/69667]
loss: 0.264910  [19200/69667]
loss: 0.094671  [25600/69667]
loss: 0.069576  [32000/69667]
loss: 0.076544  [38400/69667]
loss: 0.093335  [44800/69667]
loss: 0.174356  [51200/69667]
loss: 0.092253  [57600/69667]
loss: 0.160564  [64000/69667]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.119050 

Epoch 34
-------------------------------
loss: 0.087071  [    0/69667]
loss: 0.153845  [ 6400/69667]
loss: 0.071120  [12800/69667]
loss: 0.078071  [19200/69667]
loss: 0.149534  [25600/69667]
loss: 0.115067  [32000/69667]
loss: 0.103265  [38400/69667]
loss: 0.138837  [44800/69667]
loss: 0.097608  [51200/69667]
loss: 0.110366  [57600/69667]
loss: 0.103443  [64000/69667]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.117398 

Epoch 35
-------------------------------
loss: 0.122542  [    0/69667]
loss: 0.098271  [ 6400/69667]
loss: 0.134179  [12800/69667]
loss: 0.294948  [19200/69667]
loss: 0.158588  [25600/69667]
loss: 0.085783  [32000/69667]
loss: 0.078717  [38400/69667]
loss: 0.242930  [44800/69667]
loss: 0.192796  [51200/69667]
loss: 0.137746  [57600/69667]
loss: 0.141492  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.120223 

Epoch 36
-------------------------------
loss: 0.110846  [    0/69667]
loss: 0.140415  [ 6400/69667]
loss: 0.106991  [12800/69667]
loss: 0.079273  [19200/69667]
loss: 0.108004  [25600/69667]
loss: 0.193428  [32000/69667]
loss: 0.184075  [38400/69667]
loss: 0.124716  [44800/69667]
loss: 0.059444  [51200/69667]
loss: 0.085607  [57600/69667]
loss: 0.087374  [64000/69667]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.114941 

Epoch 37
-------------------------------
loss: 0.089918  [    0/69667]
loss: 0.141037  [ 6400/69667]
loss: 0.128842  [12800/69667]
loss: 0.137890  [19200/69667]
loss: 0.066950  [25600/69667]
loss: 0.126245  [32000/69667]
loss: 0.108217  [38400/69667]
loss: 0.093381  [44800/69667]
loss: 0.144647  [51200/69667]
loss: 0.053238  [57600/69667]
loss: 0.138711  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.118047 

Epoch 38
-------------------------------
loss: 0.354097  [    0/69667]
loss: 0.065493  [ 6400/69667]
loss: 0.034628  [12800/69667]
loss: 0.100792  [19200/69667]
loss: 0.110869  [25600/69667]
loss: 0.038249  [32000/69667]
loss: 0.110641  [38400/69667]
loss: 0.098432  [44800/69667]
loss: 0.140334  [51200/69667]
loss: 0.041494  [57600/69667]
loss: 0.114486  [64000/69667]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.115883 

Epoch 39
-------------------------------
loss: 0.051178  [    0/69667]
loss: 0.070964  [ 6400/69667]
loss: 0.170517  [12800/69667]
loss: 0.084498  [19200/69667]
loss: 0.128168  [25600/69667]
loss: 0.092584  [32000/69667]
loss: 0.079106  [38400/69667]
loss: 0.107054  [44800/69667]
loss: 0.230705  [51200/69667]
loss: 0.078322  [57600/69667]
loss: 0.121259  [64000/69667]
Test Error: 
 Accuracy: 95.2%, Avg loss: 0.123105 

Epoch 40
-------------------------------
loss: 0.101917  [    0/69667]
loss: 0.055869  [ 6400/69667]
loss: 0.067535  [12800/69667]
loss: 0.127385  [19200/69667]
loss: 0.214557  [25600/69667]
loss: 0.075828  [32000/69667]
loss: 0.177210  [38400/69667]
loss: 0.259979  [44800/69667]
loss: 0.080471  [51200/69667]
loss: 0.068463  [57600/69667]
loss: 0.089683  [64000/69667]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.116608 

Epoch 41
-------------------------------
loss: 0.127044  [    0/69667]
loss: 0.131298  [ 6400/69667]
loss: 0.164904  [12800/69667]
loss: 0.075413  [19200/69667]
loss: 0.140510  [25600/69667]
loss: 0.110526  [32000/69667]
loss: 0.071673  [38400/69667]
loss: 0.054673  [44800/69667]
loss: 0.098388  [51200/69667]
loss: 0.068763  [57600/69667]
loss: 0.158709  [64000/69667]
Test Error: 
 Accuracy: 95.4%, Avg loss: 0.117136 

Epoch 42
-------------------------------
loss: 0.041224  [    0/69667]
loss: 0.064660  [ 6400/69667]
loss: 0.077143  [12800/69667]
loss: 0.112189  [19200/69667]
loss: 0.088596  [25600/69667]
loss: 0.092557  [32000/69667]
loss: 0.068059  [38400/69667]
loss: 0.337096  [44800/69667]
loss: 0.061337  [51200/69667]
loss: 0.198053  [57600/69667]
loss: 0.130139  [64000/69667]
Test Error: 
 Accuracy: 95.1%, Avg loss: 0.125297 

Epoch 43
-------------------------------
loss: 0.052483  [    0/69667]
loss: 0.116026  [ 6400/69667]
loss: 0.143173  [12800/69667]
loss: 0.136873  [19200/69667]
loss: 0.054049  [25600/69667]
loss: 0.066427  [32000/69667]
loss: 0.066816  [38400/69667]
loss: 0.134659  [44800/69667]
loss: 0.033416  [51200/69667]
loss: 0.270077  [57600/69667]
loss: 0.108246  [64000/69667]
loss: 0.088444  [12800/70245]
loss: 0.114119  [19200/70245]
loss: 0.114650  [25600/70245]
loss: 0.139507  [32000/70245]
loss: 0.118871  [38400/70245]
loss: 0.214570  [44800/70245]
loss: 0.264361  [51200/70245]
loss: 0.129133  [57600/70245]
loss: 0.193077  [64000/70245]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.203082 

Epoch 1
-------------------------------
loss: 0.688777  [    0/69617]
loss: 0.307066  [ 6400/69617]
loss: 0.378472  [12800/69617]
loss: 0.358054  [19200/69617]
loss: 0.246220  [25600/69617]
loss: 0.190813  [32000/69617]
loss: 0.182162  [38400/69617]
loss: 0.175562  [44800/69617]
loss: 0.281410  [51200/69617]
loss: 0.174010  [57600/69617]
loss: 0.328613  [64000/69617]
Test Error: 
 Accuracy: 90.8%, Avg loss: 0.215194 

Epoch 2
-------------------------------
loss: 0.184612  [    0/69617]
loss: 0.268381  [ 6400/69617]
loss: 0.116859  [12800/69617]
loss: 0.191948  [19200/69617]
loss: 0.238660  [25600/69617]
loss: 0.251905  [32000/69617]
loss: 0.320472  [38400/69617]
loss: 0.169226  [44800/69617]
loss: 0.231617  [51200/69617]
loss: 0.229651  [57600/69617]
loss: 0.213523  [64000/69617]
Test Error: 
 Accuracy: 90.1%, Avg loss: 0.230779 

Epoch 3
-------------------------------
loss: 0.231513  [    0/69617]
loss: 0.169778  [ 6400/69617]
loss: 0.186497  [12800/69617]
loss: 0.248710  [19200/69617]
loss: 0.192856  [25600/69617]
loss: 0.192820  [32000/69617]
loss: 0.209447  [38400/69617]
loss: 0.289026  [44800/69617]
loss: 0.160999  [51200/69617]
loss: 0.209390  [57600/69617]
loss: 0.286030  [64000/69617]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.198789 

Epoch 4
-------------------------------
loss: 0.171819  [    0/69617]
loss: 0.323495  [ 6400/69617]
loss: 0.368118  [12800/69617]
loss: 0.256625  [19200/69617]
loss: 0.269687  [25600/69617]
loss: 0.270199  [32000/69617]
loss: 0.406907  [38400/69617]
loss: 0.301983  [44800/69617]
loss: 0.187004  [51200/69617]
loss: 0.140785  [57600/69617]
loss: 0.276685  [64000/69617]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.189835 

Epoch 5
-------------------------------
loss: 0.213320  [    0/69617]
loss: 0.205523  [ 6400/69617]
loss: 0.317091  [12800/69617]
loss: 0.243232  [19200/69617]
loss: 0.266063  [25600/69617]
loss: 0.164859  [32000/69617]
loss: 0.195079  [38400/69617]
loss: 0.159478  [44800/69617]
loss: 0.210590  [51200/69617]
loss: 0.369081  [57600/69617]
loss: 0.134979  [64000/69617]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.197795 

Epoch 6
-------------------------------
loss: 0.241400  [    0/69617]
loss: 0.183725  [ 6400/69617]
loss: 0.238937  [12800/69617]
loss: 0.204763  [19200/69617]
loss: 0.256092  [25600/69617]
loss: 0.236721  [32000/69617]
loss: 0.221876  [38400/69617]
loss: 0.198084  [44800/69617]
loss: 0.172021  [51200/69617]
loss: 0.236888  [57600/69617]
loss: 0.245459  [64000/69617]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.188840 

Epoch 7
-------------------------------
loss: 0.202092  [    0/69617]
loss: 0.114680  [ 6400/69617]
loss: 0.114131  [12800/69617]
loss: 0.178303  [19200/69617]
loss: 0.165129  [25600/69617]
loss: 0.255846  [32000/69617]
loss: 0.273120  [38400/69617]
loss: 0.180218  [44800/69617]
loss: 0.245907  [51200/69617]
loss: 0.414490  [57600/69617]
loss: 0.282493  [64000/69617]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.181571 

Epoch 8
-------------------------------
loss: 0.168795  [    0/69617]
loss: 0.192309  [ 6400/69617]
loss: 0.232521  [12800/69617]
loss: 0.256602  [19200/69617]
loss: 0.350228  [25600/69617]
loss: 0.224336  [32000/69617]
loss: 0.173171  [38400/69617]
loss: 0.266603  [44800/69617]
loss: 0.297348  [51200/69617]
loss: 0.221476  [57600/69617]
loss: 0.151607  [64000/69617]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.187989 

Epoch 9
-------------------------------
loss: 0.113955  [    0/69617]
loss: 0.134493  [ 6400/69617]
loss: 0.115391  [12800/69617]
loss: 0.207610  [19200/69617]
loss: 0.241491  [25600/69617]
loss: 0.206558  [32000/69617]
loss: 0.230156  [38400/69617]
loss: 0.135162  [44800/69617]
loss: 0.181696  [51200/69617]
loss: 0.239959  [57600/69617]
loss: 0.254165  [64000/69617]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.192247 

Epoch 10
-------------------------------
loss: 0.229619  [    0/69617]
loss: 0.105283  [ 6400/69617]
loss: 0.312952  [12800/69617]
loss: 0.196747  [19200/69617]
loss: 0.139276  [25600/69617]
loss: 0.240572  [32000/69617]
loss: 0.217958  [38400/69617]
loss: 0.227707  [44800/69617]
loss: 0.184277  [51200/69617]
loss: 0.125700  [57600/69617]
loss: 0.303771  [64000/69617]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.181548 

Epoch 11
-------------------------------
loss: 0.185665  [    0/69617]
loss: 0.157925  [ 6400/69617]
loss: 0.219203  [12800/69617]
loss: 0.244141  [19200/69617]
loss: 0.212462  [25600/69617]
loss: 0.103585  [32000/69617]
loss: 0.125088  [38400/69617]
loss: 0.112005  [44800/69617]
loss: 0.101290  [51200/69617]
loss: 0.315321  [57600/69617]
loss: 0.176521  [64000/69617]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.184981 

Epoch 12
-------------------------------
loss: 0.122996  [    0/69617]
loss: 0.255427  [ 6400/69617]
loss: 0.198290  [12800/69617]
loss: 0.154902  [19200/69617]
loss: 0.098966  [25600/69617]
loss: 0.221255  [32000/69617]
loss: 0.226902  [38400/69617]
loss: 0.172590  [44800/69617]
loss: 0.223004  [51200/69617]
loss: 0.189247  [57600/69617]
loss: 0.190461  [64000/69617]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.199480 

Epoch 13
-------------------------------
loss: 0.107431  [    0/69617]
loss: 0.248144  [ 6400/69617]
loss: 0.143408  [12800/69617]
loss: 0.072762  [19200/69617]
loss: 0.164900  [25600/69617]
loss: 0.154309  [32000/69617]
loss: 0.379480  [38400/69617]
loss: 0.243873  [44800/69617]
loss: 0.277690  [51200/69617]
loss: 0.286183  [57600/69617]
loss: 0.227763  [64000/69617]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.185559 

Epoch 14
-------------------------------
loss: 0.179065  [    0/69617]
loss: 0.165757  [ 6400/69617]
loss: 0.239730  [12800/69617]
loss: 0.120126  [19200/69617]
loss: 0.332665  [25600/69617]
loss: 0.101739  [32000/69617]
loss: 0.132758  [38400/69617]
loss: 0.344496  [44800/69617]
loss: 0.156700  [51200/69617]
loss: 0.206460  [57600/69617]
loss: 0.094704  [64000/69617]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.179739 

Epoch 15
-------------------------------
loss: 0.121362  [    0/69617]
loss: 0.158664  [ 6400/69617]
loss: 0.217211  [12800/69617]
loss: 0.215420  [19200/69617]
loss: 0.169556  [25600/69617]
loss: 0.247048  [32000/69617]
loss: 0.119547  [38400/69617]
loss: 0.155117  [44800/69617]
loss: 0.079792  [51200/69617]
loss: 0.258072  [57600/69617]
loss: 0.223198  [64000/69617]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.192773 

Epoch 16
-------------------------------
loss: 0.097459  [    0/69617]
loss: 0.161518  [ 6400/69617]
loss: 0.143503  [12800/69617]
loss: 0.090490  [19200/69617]
loss: 0.192273  [25600/69617]
loss: 0.187416  [32000/69617]
loss: 0.194754  [38400/69617]
loss: 0.152217  [44800/69617]
loss: 0.249422  [51200/69617]
loss: 0.096762  [57600/69617]
loss: 0.257661  [64000/69617]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.191284 

Epoch 17
-------------------------------
loss: 0.148178  [    0/69617]
loss: 0.224605  [ 6400/69617]
loss: 0.334555  [12800/69617]
loss: 0.189117  [19200/69617]
loss: 0.162689  [25600/69617]
loss: 0.175004  [32000/69617]
loss: 0.150614  [38400/69617]
loss: 0.221568  [44800/69617]
loss: 0.191195  [51200/69617]
loss: 0.164240  [57600/69617]
loss: 0.189510  [64000/69617]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.193654 

Epoch 18
-------------------------------
loss: 0.232893  [    0/69617]
loss: 0.196423  [ 6400/69617]
loss: 0.228876  [12800/69617]
loss: 0.110944  [19200/69617]
loss: 0.187654  [25600/69617]
loss: 0.222564  [32000/69617]
loss: 0.246482  [38400/69617]
loss: 0.301091  [44800/69617]
loss: 0.113402  [51200/69617]
loss: 0.133724  [57600/69617]
loss: 0.163084  [64000/69617]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.186851 

Epoch 19
-------------------------------
loss: 0.145624  [    0/69617]
loss: 0.257673  [ 6400/69617]
loss: 0.187587  [12800/69617]
loss: 0.158851  [19200/69617]
loss: 0.172402  [25600/69617]
loss: 0.268492  [32000/69617]
loss: 0.146318  [38400/69617]
loss: 0.111423  [25600/71047]
loss: 0.158394  [32000/71047]
loss: 0.051442  [38400/71047]
loss: 0.030334  [44800/71047]
loss: 0.095193  [51200/71047]
loss: 0.063221  [57600/71047]
loss: 0.055037  [64000/71047]
loss: 0.053056  [70400/71047]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.103570 

Epoch 27
-------------------------------
loss: 0.009743  [    0/71047]
loss: 0.061732  [ 6400/71047]
loss: 0.011708  [12800/71047]
loss: 0.071178  [19200/71047]
loss: 0.088832  [25600/71047]
loss: 0.014121  [32000/71047]
loss: 0.052683  [38400/71047]
loss: 0.107329  [44800/71047]
loss: 0.090452  [51200/71047]
loss: 0.145070  [57600/71047]
loss: 0.023612  [64000/71047]
loss: 0.091637  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.075904 

Epoch 28
-------------------------------
loss: 0.013195  [    0/71047]
loss: 0.009897  [ 6400/71047]
loss: 0.015982  [12800/71047]
loss: 0.046048  [19200/71047]
loss: 0.061659  [25600/71047]
loss: 0.163695  [32000/71047]
loss: 0.017350  [38400/71047]
loss: 0.214207  [44800/71047]
loss: 0.081048  [51200/71047]
loss: 0.054828  [57600/71047]
loss: 0.082452  [64000/71047]
loss: 0.077282  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.078682 

Epoch 29
-------------------------------
loss: 0.017522  [    0/71047]
loss: 0.036701  [ 6400/71047]
loss: 0.016108  [12800/71047]
loss: 0.038626  [19200/71047]
loss: 0.155395  [25600/71047]
loss: 0.029437  [32000/71047]
loss: 0.028099  [38400/71047]
loss: 0.092954  [44800/71047]
loss: 0.019267  [51200/71047]
loss: 0.019356  [57600/71047]
loss: 0.101577  [64000/71047]
loss: 0.035280  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.071700 

Epoch 30
-------------------------------
loss: 0.052296  [    0/71047]
loss: 0.015119  [ 6400/71047]
loss: 0.082605  [12800/71047]
loss: 0.014356  [19200/71047]
loss: 0.023775  [25600/71047]
loss: 0.060338  [32000/71047]
loss: 0.097804  [38400/71047]
loss: 0.037797  [44800/71047]
loss: 0.017588  [51200/71047]
loss: 0.027593  [57600/71047]
loss: 1.697675  [64000/71047]
loss: 0.051425  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.071233 

Epoch 31
-------------------------------
loss: 0.022139  [    0/71047]
loss: 0.037089  [ 6400/71047]
loss: 0.022457  [12800/71047]
loss: 0.105906  [19200/71047]
loss: 0.041142  [25600/71047]
loss: 0.043549  [32000/71047]
loss: 0.043195  [38400/71047]
loss: 0.122341  [44800/71047]
loss: 0.037146  [51200/71047]
loss: 0.094413  [57600/71047]
loss: 0.112973  [64000/71047]
loss: 0.047660  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.076155 

Epoch 32
-------------------------------
loss: 0.115437  [    0/71047]
loss: 0.047492  [ 6400/71047]
loss: 0.076656  [12800/71047]
loss: 0.053630  [19200/71047]
loss: 0.025827  [25600/71047]
loss: 0.043981  [32000/71047]
loss: 0.152606  [38400/71047]
loss: 0.055383  [44800/71047]
loss: 0.140276  [51200/71047]
loss: 0.025346  [57600/71047]
loss: 0.064092  [64000/71047]
loss: 0.095030  [70400/71047]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.136897 

Epoch 33
-------------------------------
loss: 0.276291  [    0/71047]
loss: 0.080264  [ 6400/71047]
loss: 0.028352  [12800/71047]
loss: 0.132345  [19200/71047]
loss: 0.056924  [25600/71047]
loss: 0.012161  [32000/71047]
loss: 0.029673  [38400/71047]
loss: 0.052339  [44800/71047]
loss: 0.118046  [51200/71047]
loss: 0.030764  [57600/71047]
loss: 0.013554  [64000/71047]
loss: 0.072147  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.073678 

Epoch 34
-------------------------------
loss: 0.093669  [    0/71047]
loss: 0.015553  [ 6400/71047]
loss: 0.065047  [12800/71047]
loss: 0.068573  [19200/71047]
loss: 0.060087  [25600/71047]
loss: 0.061141  [32000/71047]
loss: 0.028192  [38400/71047]
loss: 0.030016  [44800/71047]
loss: 0.120564  [51200/71047]
loss: 0.018595  [57600/71047]
loss: 0.028854  [64000/71047]
loss: 0.176272  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.073875 

Epoch 35
-------------------------------
loss: 0.026062  [    0/71047]
loss: 0.060629  [ 6400/71047]
loss: 0.024591  [12800/71047]
loss: 0.068366  [19200/71047]
loss: 0.017506  [25600/71047]
loss: 0.013330  [32000/71047]
loss: 0.063065  [38400/71047]
loss: 0.010319  [44800/71047]
loss: 0.058235  [51200/71047]
loss: 0.022503  [57600/71047]
loss: 0.073912  [64000/71047]
loss: 0.101837  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.072894 

Epoch 36
-------------------------------
loss: 0.026640  [    0/71047]
loss: 0.031606  [ 6400/71047]
loss: 0.021543  [12800/71047]
loss: 0.019842  [19200/71047]
loss: 0.033461  [25600/71047]
loss: 0.057481  [32000/71047]
loss: 0.021327  [38400/71047]
loss: 0.027220  [44800/71047]
loss: 0.062047  [51200/71047]
loss: 0.038962  [57600/71047]
loss: 0.022653  [64000/71047]
loss: 0.010074  [70400/71047]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.094661 

Epoch 37
-------------------------------
loss: 0.018507  [    0/71047]
loss: 0.056309  [ 6400/71047]
loss: 0.084119  [12800/71047]
loss: 0.020967  [19200/71047]
loss: 0.069480  [25600/71047]
loss: 0.074807  [32000/71047]
loss: 0.047684  [38400/71047]
loss: 0.011186  [44800/71047]
loss: 0.028714  [51200/71047]
loss: 0.116909  [57600/71047]
loss: 0.069719  [64000/71047]
loss: 0.109399  [70400/71047]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.071273 

Epoch 38
-------------------------------
loss: 0.041131  [    0/71047]
loss: 0.064178  [ 6400/71047]
loss: 0.013116  [12800/71047]
loss: 0.024119  [19200/71047]
loss: 0.028515  [25600/71047]
loss: 0.226794  [32000/71047]
loss: 0.012286  [38400/71047]
loss: 0.027508  [44800/71047]
loss: 0.068047  [51200/71047]
loss: 0.033535  [57600/71047]
loss: 0.053251  [64000/71047]
loss: 0.043599  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.073734 

Epoch 39
-------------------------------
loss: 0.004961  [    0/71047]
loss: 0.025277  [ 6400/71047]
loss: 0.070850  [12800/71047]
loss: 0.075241  [19200/71047]
loss: 0.030091  [25600/71047]
loss: 0.024731  [32000/71047]
loss: 0.078264  [38400/71047]
loss: 0.115982  [44800/71047]
loss: 0.040809  [51200/71047]
loss: 0.035253  [57600/71047]
loss: 0.060462  [64000/71047]
loss: 0.103714  [70400/71047]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.072055 

Epoch 40
-------------------------------
loss: 0.083506  [    0/71047]
loss: 1.336661  [ 6400/71047]
loss: 0.026114  [12800/71047]
loss: 0.063797  [19200/71047]
loss: 0.039886  [25600/71047]
loss: 0.021078  [32000/71047]
loss: 0.145331  [38400/71047]
loss: 0.027370  [44800/71047]
loss: 0.072573  [51200/71047]
loss: 0.065037  [57600/71047]
loss: 1.580710  [64000/71047]
loss: 0.030423  [70400/71047]
Test Error: 
 Accuracy: 95.8%, Avg loss: 0.129216 

Epoch 41
-------------------------------
loss: 0.045469  [    0/71047]
loss: 0.012536  [ 6400/71047]
loss: 0.143614  [12800/71047]
loss: 0.027670  [19200/71047]
loss: 0.035382  [25600/71047]
loss: 0.039602  [32000/71047]
loss: 0.005818  [38400/71047]
loss: 0.179530  [44800/71047]
loss: 0.063208  [51200/71047]
loss: 0.067583  [57600/71047]
loss: 0.016996  [64000/71047]
loss: 0.026921  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.072289 

Epoch 42
-------------------------------
loss: 0.057235  [    0/71047]
loss: 0.037464  [ 6400/71047]
loss: 0.031366  [12800/71047]
loss: 0.126767  [19200/71047]
loss: 0.027722  [25600/71047]
loss: 0.049615  [32000/71047]
loss: 0.064479  [38400/71047]
loss: 0.060991  [44800/71047]
loss: 0.031501  [51200/71047]
loss: 0.026017  [57600/71047]
loss: 0.024344  [64000/71047]
loss: 0.087324  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.077588 

Epoch 43
-------------------------------
loss: 0.068214  [    0/71047]
loss: 0.039734  [ 6400/71047]
loss: 0.059654  [12800/71047]
loss: 0.055020  [19200/71047]
loss: 0.030260  [25600/71047]
loss: 0.039743  [32000/71047]
loss: 0.056459  [38400/71047]
loss: 0.067034  [44800/71047]
loss: 0.067654  [51200/71047]
loss: 0.011687  [57600/71047]
loss: 0.024852  [64000/71047]
loss: 0.011358  [70400/71047]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074209 

Epoch 44
-------------------------------
loss: 0.128648  [    0/71047]
loss: 0.020144  [ 6400/71047]
loss: 0.017295  [12800/71047]
loss: 0.016311  [19200/71047]
loss: 0.039976  [25600/71047]
loss: 0.303329  [ 6400/69744]
loss: 0.090457  [12800/69744]
loss: 0.160393  [19200/69744]
loss: 0.074704  [25600/69744]
loss: 0.156884  [32000/69744]
loss: 0.149520  [38400/69744]
loss: 0.141098  [44800/69744]
loss: 0.192369  [51200/69744]
loss: 0.148531  [57600/69744]
loss: 0.174714  [64000/69744]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.172878 

Epoch 17
-------------------------------
loss: 0.211169  [    0/69744]
loss: 0.222987  [ 6400/69744]
loss: 0.376934  [12800/69744]
loss: 0.214162  [19200/69744]
loss: 0.163894  [25600/69744]
loss: 0.216892  [32000/69744]
loss: 0.186867  [38400/69744]
loss: 0.092511  [44800/69744]
loss: 0.154572  [51200/69744]
loss: 0.249002  [57600/69744]
loss: 0.126785  [64000/69744]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.164119 

Epoch 18
-------------------------------
loss: 0.162676  [    0/69744]
loss: 0.224635  [ 6400/69744]
loss: 0.103282  [12800/69744]
loss: 0.088265  [19200/69744]
loss: 0.218868  [25600/69744]
loss: 0.169043  [32000/69744]
loss: 0.131592  [38400/69744]
loss: 0.192920  [44800/69744]
loss: 0.085032  [51200/69744]
loss: 0.097305  [57600/69744]
loss: 0.205479  [64000/69744]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.157199 

Epoch 19
-------------------------------
loss: 0.184002  [    0/69744]
loss: 0.183204  [ 6400/69744]
loss: 0.089345  [12800/69744]
loss: 0.218716  [19200/69744]
loss: 0.156102  [25600/69744]
loss: 0.217211  [32000/69744]
loss: 0.177383  [38400/69744]
loss: 0.125779  [44800/69744]
loss: 0.120100  [51200/69744]
loss: 0.156747  [57600/69744]
loss: 0.154884  [64000/69744]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.183322 

Epoch 20
-------------------------------
loss: 0.141885  [    0/69744]
loss: 0.226969  [ 6400/69744]
loss: 0.101564  [12800/69744]
loss: 0.101508  [19200/69744]
loss: 0.113980  [25600/69744]
loss: 0.075075  [32000/69744]
loss: 0.096423  [38400/69744]
loss: 0.121773  [44800/69744]
loss: 0.108017  [51200/69744]
loss: 0.103943  [57600/69744]
loss: 0.154718  [64000/69744]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.169504 

Epoch 21
-------------------------------
loss: 0.114001  [    0/69744]
loss: 0.088906  [ 6400/69744]
loss: 0.236781  [12800/69744]
loss: 0.174655  [19200/69744]
loss: 0.146539  [25600/69744]
loss: 0.140620  [32000/69744]
loss: 0.137529  [38400/69744]
loss: 0.093980  [44800/69744]
loss: 0.188306  [51200/69744]
loss: 0.165542  [57600/69744]
loss: 0.228345  [64000/69744]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.174213 

Epoch 22
-------------------------------
loss: 0.122447  [    0/69744]
loss: 0.235420  [ 6400/69744]
loss: 0.108613  [12800/69744]
loss: 0.163256  [19200/69744]
loss: 0.093789  [25600/69744]
loss: 0.061224  [32000/69744]
loss: 0.141678  [38400/69744]
loss: 0.101690  [44800/69744]
loss: 0.144252  [51200/69744]
loss: 0.157282  [57600/69744]
loss: 0.141579  [64000/69744]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.170013 

Epoch 23
-------------------------------
loss: 0.108575  [    0/69744]
loss: 0.137742  [ 6400/69744]
loss: 0.027164  [12800/69744]
loss: 0.142156  [19200/69744]
loss: 0.080871  [25600/69744]
loss: 0.111507  [32000/69744]
loss: 0.149656  [38400/69744]
loss: 0.104187  [44800/69744]
loss: 0.167854  [51200/69744]
loss: 0.108868  [57600/69744]
loss: 0.189314  [64000/69744]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.183804 

Epoch 24
-------------------------------
loss: 0.114605  [    0/69744]
loss: 0.096964  [ 6400/69744]
loss: 0.130694  [12800/69744]
loss: 0.237933  [19200/69744]
loss: 0.136111  [25600/69744]
loss: 0.273482  [32000/69744]
loss: 0.161437  [38400/69744]
loss: 0.154759  [44800/69744]
loss: 0.291866  [51200/69744]
loss: 0.147489  [57600/69744]
loss: 0.055195  [64000/69744]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.162725 

Epoch 25
-------------------------------
loss: 0.102579  [    0/69744]
loss: 0.118967  [ 6400/69744]
loss: 0.057005  [12800/69744]
loss: 0.112699  [19200/69744]
loss: 0.166651  [25600/69744]
loss: 0.294798  [32000/69744]
loss: 1.811326  [38400/69744]
loss: 0.195030  [44800/69744]
loss: 0.165935  [51200/69744]
loss: 0.214323  [57600/69744]
loss: 0.110610  [64000/69744]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.162078 

Epoch 26
-------------------------------
loss: 0.147822  [    0/69744]
loss: 0.081682  [ 6400/69744]
loss: 0.150226  [12800/69744]
loss: 0.097691  [19200/69744]
loss: 0.122651  [25600/69744]
loss: 0.155970  [32000/69744]
loss: 0.154210  [38400/69744]
loss: 0.123012  [44800/69744]
loss: 0.196822  [51200/69744]
loss: 0.174411  [57600/69744]
loss: 0.135616  [64000/69744]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.162842 

Epoch 27
-------------------------------
loss: 0.099806  [    0/69744]
loss: 0.168308  [ 6400/69744]
loss: 0.094608  [12800/69744]
loss: 0.096638  [19200/69744]
loss: 0.290427  [25600/69744]
loss: 0.103424  [32000/69744]
loss: 0.175311  [38400/69744]
loss: 0.072337  [44800/69744]
loss: 0.104156  [51200/69744]
loss: 0.175916  [57600/69744]
loss: 0.083482  [64000/69744]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.168255 

Epoch 28
-------------------------------
loss: 0.080080  [    0/69744]
loss: 0.107489  [ 6400/69744]
loss: 0.074956  [12800/69744]
loss: 0.133188  [19200/69744]
loss: 0.176192  [25600/69744]
loss: 0.116502  [32000/69744]
loss: 0.147102  [38400/69744]
loss: 0.059367  [44800/69744]
loss: 0.197441  [51200/69744]
loss: 0.115618  [57600/69744]
loss: 0.114501  [64000/69744]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.162456 

Epoch 29
-------------------------------
loss: 0.084768  [    0/69744]
loss: 0.107014  [ 6400/69744]
loss: 0.204140  [12800/69744]
loss: 0.078657  [19200/69744]
loss: 0.193697  [25600/69744]
loss: 0.159217  [32000/69744]
loss: 0.230157  [38400/69744]
loss: 0.186759  [44800/69744]
loss: 0.181323  [51200/69744]
loss: 0.203144  [57600/69744]
loss: 0.104069  [64000/69744]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.166911 

Epoch 30
-------------------------------
loss: 0.158344  [    0/69744]
loss: 0.063535  [ 6400/69744]
loss: 0.064954  [12800/69744]
loss: 0.056053  [19200/69744]
loss: 0.135572  [25600/69744]
loss: 0.149827  [32000/69744]
loss: 0.084501  [38400/69744]
loss: 0.113618  [44800/69744]
loss: 0.186053  [51200/69744]
loss: 0.191833  [57600/69744]
loss: 0.213369  [64000/69744]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.156853 

Epoch 31
-------------------------------
loss: 0.142799  [    0/69744]
loss: 0.070780  [ 6400/69744]
loss: 0.159883  [12800/69744]
loss: 0.214003  [19200/69744]
loss: 0.163183  [25600/69744]
loss: 0.229871  [32000/69744]
loss: 0.130369  [38400/69744]
loss: 0.111874  [44800/69744]
loss: 0.101302  [51200/69744]
loss: 0.324043  [57600/69744]
loss: 0.172502  [64000/69744]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.178035 

Epoch 32
-------------------------------
loss: 0.155053  [    0/69744]
loss: 0.096540  [ 6400/69744]
loss: 0.079169  [12800/69744]
loss: 0.096810  [19200/69744]
loss: 0.114186  [25600/69744]
loss: 0.079889  [32000/69744]
loss: 0.156312  [38400/69744]
loss: 0.129648  [44800/69744]
loss: 0.110290  [51200/69744]
loss: 0.295907  [57600/69744]
loss: 0.091015  [64000/69744]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.164970 

Epoch 33
-------------------------------
loss: 0.097669  [    0/69744]
loss: 0.107193  [ 6400/69744]
loss: 0.193951  [12800/69744]
loss: 0.155960  [19200/69744]
loss: 0.131158  [25600/69744]
loss: 0.119596  [32000/69744]
loss: 0.139055  [38400/69744]
loss: 0.123817  [44800/69744]
loss: 0.172835  [51200/69744]
loss: 0.129674  [57600/69744]
loss: 0.097046  [64000/69744]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.172084 

Epoch 34
-------------------------------
loss: 0.126498  [    0/69744]
loss: 0.140774  [ 6400/69744]
loss: 0.133163  [12800/69744]
loss: 0.153281  [19200/69744]
loss: 0.132709  [25600/69744]
loss: 0.247471  [32000/69744]
loss: 0.153413  [38400/69744]
loss: 0.117203  [44800/69744]
loss: 0.176682  [51200/69744]
loss: 0.153680  [57600/69744]
loss: 0.280061  [64000/69744]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.163925 

Epoch 35
-------------------------------
loss: 0.173970  [    0/69744]
loss: 0.135633  [ 6400/69744]
loss: 0.129836  [12800/69744]
loss: 0.247395  [19200/69744]
loss: 0.164727  [25600/69744]
loss: 0.153885  [32000/69744]
2022/09/20 21:33:13 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.175409  [25600/69771]
loss: 0.314376  [32000/69771]
loss: 0.120111  [38400/69771]
loss: 0.219473  [44800/69771]
loss: 0.260136  [51200/69771]
loss: 0.179249  [57600/69771]
loss: 0.157220  [64000/69771]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.183679 

Epoch 21
-------------------------------
loss: 0.116617  [    0/69771]
loss: 0.217568  [ 6400/69771]
loss: 0.115183  [12800/69771]
loss: 0.157375  [19200/69771]
loss: 0.173348  [25600/69771]
loss: 0.127891  [32000/69771]
loss: 0.197210  [38400/69771]
loss: 0.126907  [44800/69771]
loss: 0.231152  [51200/69771]
loss: 0.280352  [57600/69771]
loss: 0.232351  [64000/69771]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.194618 

Epoch 22
-------------------------------
loss: 0.189976  [    0/69771]
loss: 0.231749  [ 6400/69771]
loss: 0.254745  [12800/69771]
loss: 0.143861  [19200/69771]
loss: 0.134938  [25600/69771]
loss: 0.210130  [32000/69771]
loss: 0.125835  [38400/69771]
loss: 0.162870  [44800/69771]
loss: 0.082032  [51200/69771]
loss: 0.085521  [57600/69771]
loss: 0.166512  [64000/69771]
Test Error: 
 Accuracy: 91.2%, Avg loss: 0.214706 

Epoch 23
-------------------------------
loss: 0.221263  [    0/69771]
loss: 0.222691  [ 6400/69771]
loss: 0.203280  [12800/69771]
loss: 0.191201  [19200/69771]
loss: 0.194936  [25600/69771]
loss: 0.167782  [32000/69771]
loss: 0.148504  [38400/69771]
loss: 0.156406  [44800/69771]
loss: 0.165751  [51200/69771]
loss: 0.231467  [57600/69771]
loss: 0.152739  [64000/69771]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.183304 

Epoch 24
-------------------------------
loss: 0.200972  [    0/69771]
loss: 0.103445  [ 6400/69771]
loss: 0.096207  [12800/69771]
loss: 0.090353  [19200/69771]
loss: 0.085062  [25600/69771]
loss: 0.176009  [32000/69771]
loss: 0.191070  [38400/69771]
loss: 0.152382  [44800/69771]
loss: 0.175282  [51200/69771]
loss: 0.144001  [57600/69771]
loss: 0.239692  [64000/69771]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.198414 

Epoch 25
-------------------------------
loss: 0.099208  [    0/69771]
loss: 0.129267  [ 6400/69771]
loss: 0.132379  [12800/69771]
loss: 0.150162  [19200/69771]
loss: 0.208602  [25600/69771]
loss: 0.107246  [32000/69771]
loss: 0.276163  [38400/69771]
loss: 0.130288  [44800/69771]
loss: 0.246408  [51200/69771]
loss: 0.254598  [57600/69771]
loss: 0.270833  [64000/69771]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.191206 

Epoch 26
-------------------------------
loss: 0.163186  [    0/69771]
loss: 0.163076  [ 6400/69771]
loss: 0.146694  [12800/69771]
loss: 0.176387  [19200/69771]
loss: 0.270698  [25600/69771]
loss: 0.195320  [32000/69771]
loss: 0.080943  [38400/69771]
loss: 0.245045  [44800/69771]
loss: 0.234398  [51200/69771]
loss: 0.165445  [57600/69771]
loss: 0.135908  [64000/69771]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.182096 

Epoch 27
-------------------------------
loss: 0.158814  [    0/69771]
loss: 0.137461  [ 6400/69771]
loss: 0.321674  [12800/69771]
loss: 0.120907  [19200/69771]
loss: 0.080028  [25600/69771]
loss: 0.236939  [32000/69771]
loss: 0.112349  [38400/69771]
loss: 0.197062  [44800/69771]
loss: 0.190696  [51200/69771]
loss: 0.172351  [57600/69771]
loss: 0.150844  [64000/69771]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.185330 

Epoch 28
-------------------------------
loss: 0.105296  [    0/69771]
loss: 0.146292  [ 6400/69771]
loss: 0.205875  [12800/69771]
loss: 0.196694  [19200/69771]
loss: 0.201086  [25600/69771]
loss: 0.184127  [32000/69771]
loss: 0.246807  [38400/69771]
loss: 0.116564  [44800/69771]
loss: 0.231801  [51200/69771]
loss: 0.170819  [57600/69771]
loss: 0.159197  [64000/69771]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.181795 

Epoch 29
-------------------------------
loss: 0.203208  [    0/69771]
loss: 0.133695  [ 6400/69771]
loss: 0.189880  [12800/69771]
loss: 0.153594  [19200/69771]
loss: 0.175885  [25600/69771]
loss: 0.172304  [32000/69771]
loss: 0.177396  [38400/69771]
loss: 0.162158  [44800/69771]
loss: 0.171870  [51200/69771]
loss: 0.064247  [57600/69771]
loss: 0.109987  [64000/69771]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.174913 

Epoch 30
-------------------------------
loss: 0.333336  [    0/69771]
loss: 0.169264  [ 6400/69771]
loss: 0.118346  [12800/69771]
loss: 0.226401  [19200/69771]
loss: 0.107127  [25600/69771]
loss: 0.156058  [32000/69771]
loss: 0.172590  [38400/69771]
loss: 0.155394  [44800/69771]
loss: 0.288283  [51200/69771]
loss: 0.119525  [57600/69771]
loss: 0.112840  [64000/69771]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.197145 

Epoch 31
-------------------------------
loss: 0.142434  [    0/69771]
loss: 0.165028  [ 6400/69771]
loss: 0.246876  [12800/69771]
loss: 0.171536  [19200/69771]
loss: 0.174441  [25600/69771]
loss: 0.298998  [32000/69771]
loss: 0.179112  [38400/69771]
loss: 0.156587  [44800/69771]
loss: 0.188517  [51200/69771]
loss: 0.149158  [57600/69771]
loss: 0.153581  [64000/69771]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.193518 

Epoch 32
-------------------------------
loss: 0.247804  [    0/69771]
loss: 0.184746  [ 6400/69771]
loss: 0.160648  [12800/69771]
loss: 0.121797  [19200/69771]
loss: 0.134111  [25600/69771]
loss: 0.117049  [32000/69771]
loss: 0.156120  [38400/69771]
loss: 0.294841  [44800/69771]
loss: 0.334216  [51200/69771]
loss: 0.214598  [57600/69771]
loss: 0.226284  [64000/69771]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.197530 

Epoch 33
-------------------------------
loss: 0.218134  [    0/69771]
loss: 0.158882  [ 6400/69771]
loss: 0.274543  [12800/69771]
loss: 0.258202  [19200/69771]
loss: 0.209696  [25600/69771]
loss: 0.174446  [32000/69771]
loss: 0.292514  [38400/69771]
loss: 0.200556  [44800/69771]
loss: 0.182735  [51200/69771]
loss: 0.103567  [57600/69771]
loss: 0.169421  [64000/69771]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.191015 

Epoch 34
-------------------------------
loss: 0.108327  [    0/69771]
loss: 0.138541  [ 6400/69771]
loss: 0.218876  [12800/69771]
loss: 0.100470  [19200/69771]
loss: 0.112243  [25600/69771]
loss: 0.299610  [32000/69771]
loss: 0.161860  [38400/69771]
loss: 0.152017  [44800/69771]
loss: 0.204683  [51200/69771]
loss: 0.212995  [57600/69771]
loss: 0.146718  [64000/69771]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.189232 

Epoch 35
-------------------------------
loss: 0.200166  [    0/69771]
loss: 0.123606  [ 6400/69771]
loss: 0.164662  [12800/69771]
loss: 0.132132  [19200/69771]
loss: 0.203247  [25600/69771]
loss: 0.222853  [32000/69771]
loss: 0.177813  [38400/69771]
loss: 0.091544  [44800/69771]
loss: 0.216313  [51200/69771]
loss: 0.255131  [57600/69771]
loss: 0.253525  [64000/69771]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.177008 

Epoch 36
-------------------------------
loss: 0.182499  [    0/69771]
loss: 0.150285  [ 6400/69771]
loss: 0.073003  [12800/69771]
loss: 0.163887  [19200/69771]
loss: 0.174541  [25600/69771]
loss: 0.145441  [32000/69771]
loss: 0.325724  [38400/69771]
loss: 0.148898  [44800/69771]
loss: 0.160085  [51200/69771]
loss: 0.111563  [57600/69771]
loss: 0.148982  [64000/69771]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.196845 

Epoch 37
-------------------------------
loss: 0.219821  [    0/69771]
loss: 0.254904  [ 6400/69771]
loss: 0.149123  [12800/69771]
loss: 0.192209  [19200/69771]
loss: 0.262134  [25600/69771]
loss: 0.212247  [32000/69771]
loss: 0.212515  [38400/69771]
loss: 0.062873  [44800/69771]
loss: 0.099224  [51200/69771]
loss: 0.249286  [57600/69771]
loss: 0.186603  [64000/69771]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.184222 

Epoch 38
-------------------------------
loss: 0.120147  [    0/69771]
loss: 0.262105  [ 6400/69771]
loss: 0.235357  [12800/69771]
loss: 0.168374  [19200/69771]
loss: 0.119361  [25600/69771]
loss: 0.145709  [32000/69771]
loss: 0.130418  [38400/69771]
loss: 0.163586  [44800/69771]
loss: 0.124178  [51200/69771]
loss: 0.208139  [57600/69771]
loss: 0.185130  [64000/69771]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.204260 

Epoch 39
-------------------------------
loss: 0.223914  [    0/69771]
loss: 0.118005  [ 6400/69771]
loss: 0.205550  [12800/69771]
loss: 0.200822  [19200/69771]
loss: 0.114865  [25600/69771]
loss: 0.140640  [32000/69771]
loss: 0.175083  [38400/69771]
loss: 0.133604  [44800/69771]
loss: 0.198779  [51200/69771]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.272306 

Epoch 30
-------------------------------
loss: 0.240153  [    0/70789]
loss: 0.009846  [ 6400/70789]
loss: 0.025209  [12800/70789]
loss: 0.025905  [19200/70789]
loss: 0.051998  [25600/70789]
loss: 0.025650  [32000/70789]
loss: 0.062105  [38400/70789]
loss: 0.048062  [44800/70789]
loss: 0.051235  [51200/70789]
loss: 0.060159  [57600/70789]
loss: 0.008448  [64000/70789]
loss: 0.013645  [70400/70789]
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.081567 

Epoch 31
-------------------------------
loss: 0.024264  [    0/70789]
loss: 0.029096  [ 6400/70789]
loss: 0.012099  [12800/70789]
loss: 0.109287  [19200/70789]
loss: 0.062378  [25600/70789]
loss: 0.019210  [32000/70789]
loss: 0.020784  [38400/70789]
loss: 0.203616  [44800/70789]
loss: 0.021338  [51200/70789]
loss: 0.014314  [57600/70789]
loss: 0.052959  [64000/70789]
loss: 0.085063  [70400/70789]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.069919 

Epoch 32
-------------------------------
loss: 0.018494  [    0/70789]
loss: 0.115478  [ 6400/70789]
loss: 0.149581  [12800/70789]
loss: 0.074383  [19200/70789]
loss: 0.050880  [25600/70789]
loss: 0.091896  [32000/70789]
loss: 0.033320  [38400/70789]
loss: 0.105702  [44800/70789]
loss: 0.033811  [51200/70789]
loss: 0.063232  [57600/70789]
loss: 0.076003  [64000/70789]
loss: 0.022753  [70400/70789]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.081781 

Epoch 33
-------------------------------
loss: 0.163665  [    0/70789]
loss: 0.040166  [ 6400/70789]
loss: 0.039641  [12800/70789]
loss: 0.063647  [19200/70789]
loss: 0.064811  [25600/70789]
loss: 0.041781  [32000/70789]
loss: 0.012220  [38400/70789]
loss: 0.014798  [44800/70789]
loss: 0.088706  [51200/70789]
loss: 0.152247  [57600/70789]
loss: 0.014901  [64000/70789]
loss: 0.070097  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074636 

Epoch 34
-------------------------------
loss: 0.023974  [    0/70789]
loss: 0.149446  [ 6400/70789]
loss: 0.092946  [12800/70789]
loss: 0.056532  [19200/70789]
loss: 0.016841  [25600/70789]
loss: 0.181620  [32000/70789]
loss: 0.026834  [38400/70789]
loss: 0.135941  [44800/70789]
loss: 0.018594  [51200/70789]
loss: 0.122065  [57600/70789]
loss: 0.037157  [64000/70789]
loss: 0.016436  [70400/70789]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.069365 

Epoch 35
-------------------------------
loss: 0.022850  [    0/70789]
loss: 0.072134  [ 6400/70789]
loss: 0.021965  [12800/70789]
loss: 0.070859  [19200/70789]
loss: 0.009590  [25600/70789]
loss: 0.031275  [32000/70789]
loss: 0.024206  [38400/70789]
loss: 0.004940  [44800/70789]
loss: 0.058296  [51200/70789]
loss: 0.014283  [57600/70789]
loss: 0.090808  [64000/70789]
loss: 0.040462  [70400/70789]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.307814 

Epoch 36
-------------------------------
loss: 0.401358  [    0/70789]
loss: 0.024030  [ 6400/70789]
loss: 0.051707  [12800/70789]
loss: 0.033918  [19200/70789]
loss: 0.052273  [25600/70789]
loss: 0.055495  [32000/70789]
loss: 0.051535  [38400/70789]
loss: 0.138111  [44800/70789]
loss: 0.033926  [51200/70789]
loss: 0.094626  [57600/70789]
loss: 0.118591  [64000/70789]
loss: 0.027789  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074438 

Epoch 37
-------------------------------
loss: 0.089764  [    0/70789]
loss: 0.020330  [ 6400/70789]
loss: 0.037925  [12800/70789]
loss: 0.163208  [19200/70789]
loss: 0.037412  [25600/70789]
loss: 0.019226  [32000/70789]
loss: 0.019347  [38400/70789]
loss: 0.019000  [44800/70789]
loss: 0.210430  [51200/70789]
loss: 0.038088  [57600/70789]
loss: 0.046250  [64000/70789]
loss: 0.064901  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.076188 

Epoch 38
-------------------------------
loss: 0.040129  [    0/70789]
loss: 0.062595  [ 6400/70789]
loss: 0.041414  [12800/70789]
loss: 0.077104  [19200/70789]
loss: 0.043137  [25600/70789]
loss: 0.029142  [32000/70789]
loss: 0.010313  [38400/70789]
loss: 0.085684  [44800/70789]
loss: 1.622624  [51200/70789]
loss: 0.051910  [57600/70789]
loss: 0.015422  [64000/70789]
loss: 0.019804  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.071864 

Epoch 39
-------------------------------
loss: 0.095986  [    0/70789]
loss: 0.062924  [ 6400/70789]
loss: 0.015511  [12800/70789]
loss: 0.033919  [19200/70789]
loss: 0.085485  [25600/70789]
loss: 0.011756  [32000/70789]
loss: 0.229015  [38400/70789]
loss: 0.044923  [44800/70789]
loss: 0.012748  [51200/70789]
loss: 0.038787  [57600/70789]
loss: 0.047184  [64000/70789]
loss: 0.029433  [70400/70789]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.074512 

Epoch 40
-------------------------------
loss: 0.051982  [    0/70789]
loss: 0.026191  [ 6400/70789]
loss: 0.071284  [12800/70789]
loss: 0.034877  [19200/70789]
loss: 0.037285  [25600/70789]
loss: 0.004623  [32000/70789]
loss: 0.014599  [38400/70789]
loss: 0.172072  [44800/70789]
loss: 0.042095  [51200/70789]
loss: 0.014695  [57600/70789]
loss: 0.017196  [64000/70789]
loss: 0.041393  [70400/70789]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.073866 

Epoch 41
-------------------------------
loss: 0.044538  [    0/70789]
loss: 0.048069  [ 6400/70789]
loss: 0.038108  [12800/70789]
loss: 0.031416  [19200/70789]
loss: 0.014763  [25600/70789]
loss: 0.077992  [32000/70789]
loss: 0.045408  [38400/70789]
loss: 0.029245  [44800/70789]
loss: 0.053553  [51200/70789]
loss: 0.048578  [57600/70789]
loss: 0.075297  [64000/70789]
loss: 0.241456  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.075412 

Epoch 42
-------------------------------
loss: 0.009671  [    0/70789]
loss: 0.180651  [ 6400/70789]
loss: 0.064619  [12800/70789]
loss: 0.011037  [19200/70789]
loss: 0.029198  [25600/70789]
loss: 0.123606  [32000/70789]
loss: 0.045431  [38400/70789]
loss: 0.015548  [44800/70789]
loss: 0.167749  [51200/70789]
loss: 0.022927  [57600/70789]
loss: 0.119616  [64000/70789]
loss: 0.070820  [70400/70789]
Test Error: 
 Accuracy: 97.3%, Avg loss: 0.084299 

Epoch 43
-------------------------------
loss: 0.106451  [    0/70789]
loss: 0.031939  [ 6400/70789]
loss: 0.040776  [12800/70789]
loss: 1.582418  [19200/70789]
loss: 0.036848  [25600/70789]
loss: 0.012044  [32000/70789]
loss: 0.036442  [38400/70789]
loss: 0.024119  [44800/70789]
loss: 0.085548  [51200/70789]
loss: 0.011821  [57600/70789]
loss: 0.115346  [64000/70789]
loss: 0.066609  [70400/70789]
Test Error: 
 Accuracy: 97.7%, Avg loss: 0.075440 

Epoch 44
-------------------------------
loss: 0.003516  [    0/70789]
loss: 0.070761  [ 6400/70789]
loss: 0.037539  [12800/70789]
loss: 0.009271  [19200/70789]
loss: 0.089108  [25600/70789]
loss: 0.029103  [32000/70789]
loss: 0.013612  [38400/70789]
loss: 0.009154  [44800/70789]
loss: 0.014308  [51200/70789]
loss: 0.038590  [57600/70789]
loss: 0.047680  [64000/70789]
loss: 0.205570  [70400/70789]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.132861 

Epoch 45
-------------------------------
loss: 0.068569  [    0/70789]
loss: 0.071917  [ 6400/70789]
loss: 0.006431  [12800/70789]
loss: 0.051825  [19200/70789]
loss: 0.072413  [25600/70789]
loss: 0.014319  [32000/70789]
loss: 0.058352  [38400/70789]
loss: 0.015285  [44800/70789]
loss: 0.156395  [51200/70789]
loss: 0.078357  [57600/70789]
loss: 0.013500  [64000/70789]
loss: 0.116448  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.076499 

Epoch 46
-------------------------------
loss: 0.076904  [    0/70789]
loss: 0.007431  [ 6400/70789]
loss: 0.035033  [12800/70789]
loss: 0.010182  [19200/70789]
loss: 0.012286  [25600/70789]
loss: 0.016996  [32000/70789]
loss: 0.050236  [38400/70789]
loss: 0.014308  [44800/70789]
loss: 0.100543  [51200/70789]
loss: 0.110520  [57600/70789]
loss: 0.031172  [64000/70789]
loss: 0.031125  [70400/70789]
Test Error: 
 Accuracy: 97.6%, Avg loss: 0.074796 

Epoch 47
-------------------------------
loss: 0.072997  [    0/70789]
loss: 0.025902  [ 6400/70789]
loss: 0.176132  [12800/70789]
loss: 0.026900  [19200/70789]
loss: 0.024711  [25600/70789]
loss: 0.055829  [32000/70789]
loss: 0.039499  [38400/70789]
loss: 0.012224  [44800/70789]
loss: 0.065257  [51200/70789]
loss: 0.031032  [57600/70789]
loss: 0.008354  [64000/70789]
loss: 0.002279  [70400/70789]
2022/09/20 21:35:39 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 21:36:06 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 21:37:28 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.130002  [25600/70370]
loss: 0.149203  [32000/70370]
loss: 0.153233  [38400/70370]
loss: 0.228162  [44800/70370]
loss: 0.181788  [51200/70370]
loss: 0.099640  [57600/70370]
loss: 0.183019  [64000/70370]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.151027 

Epoch 13
-------------------------------
loss: 0.130839  [    0/70370]
loss: 0.185990  [ 6400/70370]
loss: 0.116689  [12800/70370]
loss: 0.112499  [19200/70370]
loss: 0.181292  [25600/70370]
loss: 0.202251  [32000/70370]
loss: 0.103791  [38400/70370]
loss: 0.170644  [44800/70370]
loss: 0.219307  [51200/70370]
loss: 0.166414  [57600/70370]
loss: 0.112888  [64000/70370]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.166178 

Epoch 14
-------------------------------
loss: 0.143007  [    0/70370]
loss: 0.131640  [ 6400/70370]
loss: 0.269782  [12800/70370]
loss: 0.233751  [19200/70370]
loss: 0.216081  [25600/70370]
loss: 0.114909  [32000/70370]
loss: 0.143726  [38400/70370]
loss: 0.191042  [44800/70370]
loss: 0.177264  [51200/70370]
loss: 0.237898  [57600/70370]
loss: 0.183939  [64000/70370]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.151760 

Epoch 15
-------------------------------
loss: 0.193397  [    0/70370]
loss: 0.149580  [ 6400/70370]
loss: 0.175152  [12800/70370]
loss: 0.279943  [19200/70370]
loss: 0.207286  [25600/70370]
loss: 0.153556  [32000/70370]
loss: 0.054215  [38400/70370]
loss: 0.138783  [44800/70370]
loss: 0.115067  [51200/70370]
loss: 0.188786  [57600/70370]
loss: 0.178296  [64000/70370]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.156407 

Epoch 16
-------------------------------
loss: 0.128622  [    0/70370]
loss: 0.149989  [ 6400/70370]
loss: 0.110238  [12800/70370]
loss: 0.141508  [19200/70370]
loss: 0.232557  [25600/70370]
loss: 0.116644  [32000/70370]
loss: 0.188563  [38400/70370]
loss: 0.125490  [44800/70370]
loss: 0.131080  [51200/70370]
loss: 0.105249  [57600/70370]
loss: 0.167164  [64000/70370]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.163509 

Epoch 17
-------------------------------
loss: 0.195732  [    0/70370]
loss: 0.132024  [ 6400/70370]
loss: 0.159519  [12800/70370]
loss: 0.135318  [19200/70370]
loss: 0.160570  [25600/70370]
loss: 0.181773  [32000/70370]
loss: 0.152559  [38400/70370]
loss: 0.106216  [44800/70370]
loss: 0.202492  [51200/70370]
loss: 0.115084  [57600/70370]
loss: 0.191648  [64000/70370]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.154499 

Epoch 18
-------------------------------
loss: 0.113412  [    0/70370]
loss: 0.185426  [ 6400/70370]
loss: 0.208969  [12800/70370]
loss: 0.183438  [19200/70370]
loss: 0.115592  [25600/70370]
loss: 0.088516  [32000/70370]
loss: 0.187496  [38400/70370]
loss: 0.106600  [44800/70370]
loss: 0.153974  [51200/70370]
loss: 0.222667  [57600/70370]
loss: 0.181822  [64000/70370]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.150556 

Epoch 19
-------------------------------
loss: 0.065458  [    0/70370]
loss: 0.223190  [ 6400/70370]
loss: 0.148806  [12800/70370]
loss: 0.128878  [19200/70370]
loss: 0.244489  [25600/70370]
loss: 0.335931  [32000/70370]
loss: 0.187981  [38400/70370]
loss: 0.088103  [44800/70370]
loss: 0.100241  [51200/70370]
loss: 0.182618  [57600/70370]
loss: 0.152218  [64000/70370]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.152801 

Epoch 20
-------------------------------
loss: 0.164941  [    0/70370]
loss: 0.215379  [ 6400/70370]
loss: 0.150165  [12800/70370]
loss: 0.324536  [19200/70370]
loss: 0.053317  [25600/70370]
loss: 0.139204  [32000/70370]
loss: 0.179211  [38400/70370]
loss: 0.126795  [44800/70370]
loss: 0.221793  [51200/70370]
loss: 0.143491  [57600/70370]
loss: 0.146756  [64000/70370]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.156835 

Epoch 21
-------------------------------
loss: 0.254852  [    0/70370]
loss: 0.069605  [ 6400/70370]
loss: 0.109438  [12800/70370]
loss: 0.239872  [19200/70370]
loss: 0.215956  [25600/70370]
loss: 0.082123  [32000/70370]
loss: 0.080335  [38400/70370]
loss: 0.059440  [44800/70370]
loss: 0.123365  [51200/70370]
loss: 0.178974  [57600/70370]
loss: 0.194142  [64000/70370]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.155874 

Epoch 22
-------------------------------
loss: 0.218781  [    0/70370]
loss: 0.102413  [ 6400/70370]
loss: 0.211727  [12800/70370]
loss: 0.176673  [19200/70370]
loss: 0.238291  [25600/70370]
loss: 0.170154  [32000/70370]
loss: 0.108838  [38400/70370]
loss: 0.127715  [44800/70370]
loss: 0.138478  [51200/70370]
loss: 0.106694  [57600/70370]
loss: 0.134295  [64000/70370]
Test Error: 
 Accuracy: 94.2%, Avg loss: 0.154363 

Epoch 23
-------------------------------
loss: 0.191375  [    0/70370]
loss: 0.121581  [ 6400/70370]
loss: 0.086500  [12800/70370]
loss: 0.199269  [19200/70370]
loss: 0.111162  [25600/70370]
loss: 0.104092  [32000/70370]
loss: 0.149707  [38400/70370]
loss: 0.135510  [44800/70370]
loss: 0.186154  [51200/70370]
loss: 0.224375  [57600/70370]
loss: 0.251798  [64000/70370]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.156317 

Epoch 24
-------------------------------
loss: 0.112630  [    0/70370]
loss: 0.139607  [ 6400/70370]
loss: 0.211658  [12800/70370]
loss: 0.108884  [19200/70370]
loss: 0.079337  [25600/70370]
loss: 0.137619  [32000/70370]
loss: 0.156673  [38400/70370]
loss: 0.118635  [44800/70370]
loss: 0.246616  [51200/70370]
loss: 0.131833  [57600/70370]
loss: 0.132648  [64000/70370]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.159198 

Epoch 25
-------------------------------
loss: 0.105464  [    0/70370]
loss: 0.131534  [ 6400/70370]
loss: 0.244720  [12800/70370]
loss: 1.691258  [19200/70370]
loss: 0.195976  [25600/70370]
loss: 0.124132  [32000/70370]
loss: 0.310169  [38400/70370]
loss: 0.104096  [44800/70370]
loss: 0.105279  [51200/70370]
loss: 0.275291  [57600/70370]
loss: 0.166265  [64000/70370]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.173921 

Epoch 26
-------------------------------
loss: 0.133149  [    0/70370]
loss: 0.183589  [ 6400/70370]
loss: 0.203810  [12800/70370]
loss: 0.246797  [19200/70370]
loss: 0.108211  [25600/70370]
loss: 0.161058  [32000/70370]
loss: 0.149659  [38400/70370]
loss: 0.082686  [44800/70370]
loss: 0.200080  [51200/70370]
loss: 0.179246  [57600/70370]
loss: 0.165552  [64000/70370]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.166872 

Epoch 27
-------------------------------
loss: 0.179988  [    0/70370]
loss: 0.115130  [ 6400/70370]
loss: 0.207250  [12800/70370]
loss: 0.117791  [19200/70370]
loss: 0.119361  [25600/70370]
loss: 0.235767  [32000/70370]
loss: 0.170401  [38400/70370]
loss: 0.120888  [44800/70370]
loss: 0.110267  [51200/70370]
loss: 0.167816  [57600/70370]
loss: 0.062502  [64000/70370]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.151058 

Epoch 28
-------------------------------
loss: 0.079730  [    0/70370]
loss: 0.229366  [ 6400/70370]
loss: 0.134096  [12800/70370]
loss: 0.104666  [19200/70370]
loss: 0.135147  [25600/70370]
loss: 0.224640  [32000/70370]
loss: 0.112271  [38400/70370]
loss: 0.131540  [44800/70370]
loss: 0.116931  [51200/70370]
loss: 0.103171  [57600/70370]
loss: 0.114989  [64000/70370]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.151995 

Epoch 29
-------------------------------
loss: 0.144406  [    0/70370]
loss: 0.171153  [ 6400/70370]
loss: 0.222375  [12800/70370]
loss: 1.645161  [19200/70370]
loss: 0.138372  [25600/70370]
loss: 0.211906  [32000/70370]
loss: 0.144366  [38400/70370]
loss: 0.295606  [44800/70370]
loss: 0.266748  [51200/70370]
loss: 0.125028  [57600/70370]
loss: 0.078091  [64000/70370]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.169155 

Epoch 30
-------------------------------
loss: 0.126948  [    0/70370]
loss: 0.092345  [ 6400/70370]
loss: 0.090994  [12800/70370]
loss: 0.147725  [19200/70370]
loss: 0.143376  [25600/70370]
loss: 0.104152  [32000/70370]
loss: 0.120314  [38400/70370]
loss: 0.073899  [44800/70370]
loss: 0.157503  [51200/70370]
loss: 0.077019  [57600/70370]
loss: 0.197828  [64000/70370]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.160993 

Epoch 31
-------------------------------
loss: 0.130959  [    0/70370]
loss: 0.122337  [ 6400/70370]
loss: 0.205961  [12800/70370]
loss: 0.172343  [19200/70370]
loss: 0.164869  [25600/70370]
loss: 0.215422  [32000/70370]
loss: 0.149676  [38400/70370]
loss: 0.272191  [44800/70370]
loss: 0.133867  [51200/70370]
2022/09/20 21:39:02 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 21:39:35 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 21:40:11 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.089111 

Epoch 30
-------------------------------
loss: 0.096238  [    0/70678]
loss: 0.233945  [ 6400/70678]
loss: 0.061305  [12800/70678]
loss: 0.080564  [19200/70678]
loss: 0.095769  [25600/70678]
loss: 0.036179  [32000/70678]
loss: 0.170690  [38400/70678]
loss: 0.057241  [44800/70678]
loss: 0.109794  [51200/70678]
loss: 0.160380  [57600/70678]
loss: 0.059484  [64000/70678]
loss: 0.115300  [70400/70678]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.092233 

Epoch 31
-------------------------------
loss: 0.053600  [    0/70678]
loss: 0.096974  [ 6400/70678]
loss: 0.058488  [12800/70678]
loss: 0.069358  [19200/70678]
loss: 0.089697  [25600/70678]
loss: 0.061502  [32000/70678]
loss: 0.049159  [38400/70678]
loss: 0.038137  [44800/70678]
loss: 0.046719  [51200/70678]
loss: 0.075030  [57600/70678]
loss: 0.101953  [64000/70678]
loss: 0.099029  [70400/70678]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.091539 

Epoch 32
-------------------------------
loss: 0.065049  [    0/70678]
loss: 0.082746  [ 6400/70678]
loss: 0.106698  [12800/70678]
loss: 0.122682  [19200/70678]
loss: 0.049764  [25600/70678]
loss: 0.077898  [32000/70678]
loss: 0.099077  [38400/70678]
loss: 0.091887  [44800/70678]
loss: 0.137842  [51200/70678]
loss: 0.121224  [57600/70678]
loss: 0.048464  [64000/70678]
loss: 0.062937  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.088393 

Epoch 33
-------------------------------
loss: 0.121313  [    0/70678]
loss: 0.073609  [ 6400/70678]
loss: 0.079836  [12800/70678]
loss: 0.101454  [19200/70678]
loss: 0.070175  [25600/70678]
loss: 0.025990  [32000/70678]
loss: 0.137991  [38400/70678]
loss: 0.187038  [44800/70678]
loss: 0.049185  [51200/70678]
loss: 0.046993  [57600/70678]
loss: 0.093194  [64000/70678]
loss: 0.074834  [70400/70678]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.090715 

Epoch 34
-------------------------------
loss: 0.084220  [    0/70678]
loss: 0.041087  [ 6400/70678]
loss: 0.161441  [12800/70678]
loss: 0.072528  [19200/70678]
loss: 0.116798  [25600/70678]
loss: 0.050888  [32000/70678]
loss: 0.085052  [38400/70678]
loss: 0.056759  [44800/70678]
loss: 0.103928  [51200/70678]
loss: 0.046734  [57600/70678]
loss: 0.060914  [64000/70678]
loss: 0.077505  [70400/70678]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.090552 

Epoch 35
-------------------------------
loss: 0.089177  [    0/70678]
loss: 0.127032  [ 6400/70678]
loss: 0.121323  [12800/70678]
loss: 0.175751  [19200/70678]
loss: 0.085078  [25600/70678]
loss: 0.096845  [32000/70678]
loss: 0.060205  [38400/70678]
loss: 0.027614  [44800/70678]
loss: 0.139518  [51200/70678]
loss: 0.060032  [57600/70678]
loss: 0.021829  [64000/70678]
loss: 0.040657  [70400/70678]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.107891 

Epoch 36
-------------------------------
loss: 0.092407  [    0/70678]
loss: 0.129289  [ 6400/70678]
loss: 0.107015  [12800/70678]
loss: 0.033682  [19200/70678]
loss: 0.081224  [25600/70678]
loss: 0.085877  [32000/70678]
loss: 0.030894  [38400/70678]
loss: 0.232965  [44800/70678]
loss: 0.148832  [51200/70678]
loss: 0.122221  [57600/70678]
loss: 0.104376  [64000/70678]
loss: 0.077912  [70400/70678]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.094225 

Epoch 37
-------------------------------
loss: 0.090162  [    0/70678]
loss: 0.113253  [ 6400/70678]
loss: 0.056533  [12800/70678]
loss: 0.105492  [19200/70678]
loss: 0.080800  [25600/70678]
loss: 0.067465  [32000/70678]
loss: 0.073355  [38400/70678]
loss: 0.071677  [44800/70678]
loss: 0.090620  [51200/70678]
loss: 0.114918  [57600/70678]
loss: 0.122288  [64000/70678]
loss: 0.120488  [70400/70678]
Test Error: 
 Accuracy: 96.6%, Avg loss: 0.097221 

Epoch 38
-------------------------------
loss: 0.038208  [    0/70678]
loss: 0.136735  [ 6400/70678]
loss: 0.013046  [12800/70678]
loss: 0.022782  [19200/70678]
loss: 0.097697  [25600/70678]
loss: 0.038987  [32000/70678]
loss: 0.183090  [38400/70678]
loss: 0.080997  [44800/70678]
loss: 0.044776  [51200/70678]
loss: 0.134528  [57600/70678]
loss: 0.054266  [64000/70678]
loss: 0.039963  [70400/70678]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.091418 

Epoch 39
-------------------------------
loss: 0.065294  [    0/70678]
loss: 0.108379  [ 6400/70678]
loss: 0.121809  [12800/70678]
loss: 0.108000  [19200/70678]
loss: 0.168956  [25600/70678]
loss: 0.052260  [32000/70678]
loss: 0.020694  [38400/70678]
loss: 0.182040  [44800/70678]
loss: 0.025507  [51200/70678]
loss: 0.097981  [57600/70678]
loss: 0.113208  [64000/70678]
loss: 0.126972  [70400/70678]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.097978 

Epoch 40
-------------------------------
loss: 0.152775  [    0/70678]
loss: 0.064008  [ 6400/70678]
loss: 0.084424  [12800/70678]
loss: 0.056660  [19200/70678]
loss: 0.108080  [25600/70678]
loss: 0.064729  [32000/70678]
loss: 0.229657  [38400/70678]
loss: 0.160186  [44800/70678]
loss: 0.168682  [51200/70678]
loss: 0.098576  [57600/70678]
loss: 0.043424  [64000/70678]
loss: 0.057444  [70400/70678]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095770 

Epoch 41
-------------------------------
loss: 0.020788  [    0/70678]
loss: 0.065558  [ 6400/70678]
loss: 0.111096  [12800/70678]
loss: 0.096269  [19200/70678]
loss: 0.055449  [25600/70678]
loss: 0.079879  [32000/70678]
loss: 0.057562  [38400/70678]
loss: 0.071670  [44800/70678]
loss: 0.113448  [51200/70678]
loss: 0.084575  [57600/70678]
loss: 0.144747  [64000/70678]
loss: 0.084311  [70400/70678]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.090606 

Epoch 42
-------------------------------
loss: 0.141726  [    0/70678]
loss: 0.048089  [ 6400/70678]
loss: 0.087076  [12800/70678]
loss: 0.175181  [19200/70678]
loss: 0.042346  [25600/70678]
loss: 0.157529  [32000/70678]
loss: 0.072297  [38400/70678]
loss: 0.029221  [44800/70678]
loss: 0.103065  [51200/70678]
loss: 0.179395  [57600/70678]
loss: 0.096660  [64000/70678]
loss: 0.066726  [70400/70678]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.092847 

Epoch 43
-------------------------------
loss: 0.223246  [    0/70678]
loss: 0.030752  [ 6400/70678]
loss: 0.088303  [12800/70678]
loss: 0.063033  [19200/70678]
loss: 0.007800  [25600/70678]
loss: 0.185968  [32000/70678]
loss: 0.080703  [38400/70678]
loss: 0.120006  [44800/70678]
loss: 0.085534  [51200/70678]
loss: 0.034233  [57600/70678]
loss: 0.191128  [64000/70678]
loss: 0.133709  [70400/70678]
Test Error: 
 Accuracy: 95.5%, Avg loss: 0.121050 

Epoch 44
-------------------------------
loss: 0.096128  [    0/70678]
loss: 0.087242  [ 6400/70678]
loss: 0.074034  [12800/70678]
loss: 0.088376  [19200/70678]
loss: 0.063229  [25600/70678]
loss: 0.223274  [32000/70678]
loss: 0.117843  [38400/70678]
loss: 0.171273  [44800/70678]
loss: 0.051020  [51200/70678]
loss: 0.170614  [57600/70678]
loss: 0.107442  [64000/70678]
loss: 0.077882  [70400/70678]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.086952 

Epoch 45
-------------------------------
loss: 0.107229  [    0/70678]
loss: 0.073859  [ 6400/70678]
loss: 0.093119  [12800/70678]
loss: 0.038420  [19200/70678]
loss: 0.077398  [25600/70678]
loss: 0.092380  [32000/70678]
loss: 0.081219  [38400/70678]
loss: 0.275132  [44800/70678]
loss: 0.012735  [51200/70678]
loss: 0.100697  [57600/70678]
loss: 0.093652  [64000/70678]
loss: 0.186835  [70400/70678]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.088826 

Epoch 46
-------------------------------
loss: 0.040593  [    0/70678]
loss: 0.028808  [ 6400/70678]
loss: 0.203897  [12800/70678]
loss: 0.102007  [19200/70678]
loss: 0.147963  [25600/70678]
loss: 0.081399  [32000/70678]
loss: 0.077914  [38400/70678]
loss: 0.095919  [44800/70678]
loss: 0.091710  [51200/70678]
loss: 0.030664  [57600/70678]
loss: 0.071054  [64000/70678]
loss: 0.213324  [70400/70678]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.095452 

Epoch 47
-------------------------------
loss: 0.170078  [    0/70678]
loss: 0.152287  [ 6400/70678]
loss: 0.051252  [12800/70678]
loss: 0.041059  [19200/70678]
loss: 0.035379  [25600/70678]
loss: 0.095775  [32000/70678]
loss: 0.049282  [38400/70678]
loss: 0.079939  [44800/70678]
loss: 0.200331  [51200/70678]
loss: 0.211593  [57600/70678]
loss: 0.088020  [64000/70678]
loss: 0.050113  [70400/70678]
loss: 0.075563  [57600/69794]
loss: 0.114256  [64000/69794]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.097260 

Epoch 25
-------------------------------
loss: 0.061869  [    0/69794]
loss: 0.181340  [ 6400/69794]
loss: 0.207611  [12800/69794]
loss: 0.041051  [19200/69794]
loss: 0.211814  [25600/69794]
loss: 0.133958  [32000/69794]
loss: 0.135020  [38400/69794]
loss: 0.072872  [44800/69794]
loss: 0.123795  [51200/69794]
loss: 0.042006  [57600/69794]
loss: 0.180285  [64000/69794]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.106597 

Epoch 26
-------------------------------
loss: 0.130528  [    0/69794]
loss: 0.161287  [ 6400/69794]
loss: 0.073713  [12800/69794]
loss: 0.176472  [19200/69794]
loss: 0.134253  [25600/69794]
loss: 0.116937  [32000/69794]
loss: 0.074123  [38400/69794]
loss: 0.164871  [44800/69794]
loss: 0.137215  [51200/69794]
loss: 0.116490  [57600/69794]
loss: 0.098215  [64000/69794]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.114776 

Epoch 27
-------------------------------
loss: 0.074648  [    0/69794]
loss: 0.095932  [ 6400/69794]
loss: 0.158741  [12800/69794]
loss: 0.134482  [19200/69794]
loss: 0.097438  [25600/69794]
loss: 0.278297  [32000/69794]
loss: 0.092431  [38400/69794]
loss: 0.095962  [44800/69794]
loss: 0.061999  [51200/69794]
loss: 0.034039  [57600/69794]
loss: 0.066342  [64000/69794]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.107544 

Epoch 28
-------------------------------
loss: 0.313370  [    0/69794]
loss: 0.093672  [ 6400/69794]
loss: 0.206476  [12800/69794]
loss: 0.094285  [19200/69794]
loss: 0.210780  [25600/69794]
loss: 0.110386  [32000/69794]
loss: 0.099359  [38400/69794]
loss: 0.258738  [44800/69794]
loss: 0.073243  [51200/69794]
loss: 0.094484  [57600/69794]
loss: 0.114680  [64000/69794]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.108145 

Epoch 29
-------------------------------
loss: 0.093305  [    0/69794]
loss: 0.191664  [ 6400/69794]
loss: 0.060209  [12800/69794]
loss: 0.079993  [19200/69794]
loss: 0.103920  [25600/69794]
loss: 0.159668  [32000/69794]
loss: 0.148869  [38400/69794]
loss: 0.103746  [44800/69794]
loss: 0.107676  [51200/69794]
loss: 0.089027  [57600/69794]
loss: 0.079341  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.101771 

Epoch 30
-------------------------------
loss: 0.102020  [    0/69794]
loss: 0.144800  [ 6400/69794]
loss: 0.247233  [12800/69794]
loss: 0.092409  [19200/69794]
loss: 0.085126  [25600/69794]
loss: 0.109053  [32000/69794]
loss: 0.049033  [38400/69794]
loss: 0.031685  [44800/69794]
loss: 0.088125  [51200/69794]
loss: 0.074321  [57600/69794]
loss: 0.025898  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.103723 

Epoch 31
-------------------------------
loss: 0.092965  [    0/69794]
loss: 0.105282  [ 6400/69794]
loss: 0.102709  [12800/69794]
loss: 0.147808  [19200/69794]
loss: 0.149616  [25600/69794]
loss: 0.046504  [32000/69794]
loss: 0.151250  [38400/69794]
loss: 0.083118  [44800/69794]
loss: 0.045971  [51200/69794]
loss: 0.119505  [57600/69794]
loss: 0.214340  [64000/69794]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.107114 

Epoch 32
-------------------------------
loss: 0.056713  [    0/69794]
loss: 0.122626  [ 6400/69794]
loss: 0.047150  [12800/69794]
loss: 0.071745  [19200/69794]
loss: 0.062186  [25600/69794]
loss: 0.077867  [32000/69794]
loss: 0.081187  [38400/69794]
loss: 0.108835  [44800/69794]
loss: 0.118362  [51200/69794]
loss: 0.155746  [57600/69794]
loss: 0.147185  [64000/69794]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.105703 

Epoch 33
-------------------------------
loss: 0.081473  [    0/69794]
loss: 0.043799  [ 6400/69794]
loss: 0.030956  [12800/69794]
loss: 0.179478  [19200/69794]
loss: 0.087831  [25600/69794]
loss: 0.099094  [32000/69794]
loss: 0.083863  [38400/69794]
loss: 0.096419  [44800/69794]
loss: 0.062814  [51200/69794]
loss: 0.035176  [57600/69794]
loss: 0.059713  [64000/69794]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.100086 

Epoch 34
-------------------------------
loss: 0.130619  [    0/69794]
loss: 0.156926  [ 6400/69794]
loss: 0.089641  [12800/69794]
loss: 0.115859  [19200/69794]
loss: 0.136052  [25600/69794]
loss: 0.085188  [32000/69794]
loss: 0.118897  [38400/69794]
loss: 0.064675  [44800/69794]
loss: 0.079043  [51200/69794]
loss: 0.117279  [57600/69794]
loss: 0.099711  [64000/69794]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.108338 

Epoch 35
-------------------------------
loss: 0.084629  [    0/69794]
loss: 0.083653  [ 6400/69794]
loss: 0.099747  [12800/69794]
loss: 0.073109  [19200/69794]
loss: 0.106979  [25600/69794]
loss: 0.082936  [32000/69794]
loss: 0.097996  [38400/69794]
loss: 0.047255  [44800/69794]
loss: 0.046597  [51200/69794]
loss: 0.125052  [57600/69794]
loss: 0.052040  [64000/69794]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.118400 

Epoch 36
-------------------------------
loss: 0.182555  [    0/69794]
loss: 0.098487  [ 6400/69794]
loss: 0.061005  [12800/69794]
loss: 0.078516  [19200/69794]
loss: 0.010618  [25600/69794]
loss: 0.096267  [32000/69794]
loss: 0.044814  [38400/69794]
loss: 0.072594  [44800/69794]
loss: 0.115968  [51200/69794]
loss: 0.129768  [57600/69794]
loss: 0.139022  [64000/69794]
Test Error: 
 Accuracy: 96.2%, Avg loss: 0.101250 

Epoch 37
-------------------------------
loss: 0.046845  [    0/69794]
loss: 0.069319  [ 6400/69794]
loss: 0.093267  [12800/69794]
loss: 0.065466  [19200/69794]
loss: 0.102420  [25600/69794]
loss: 0.089393  [32000/69794]
loss: 0.073514  [38400/69794]
loss: 0.029479  [44800/69794]
loss: 0.084817  [51200/69794]
loss: 0.081443  [57600/69794]
loss: 0.074961  [64000/69794]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.105950 

Epoch 38
-------------------------------
loss: 0.043594  [    0/69794]
loss: 0.076748  [ 6400/69794]
loss: 0.020516  [12800/69794]
loss: 0.135693  [19200/69794]
loss: 0.099966  [25600/69794]
loss: 0.024722  [32000/69794]
loss: 0.139795  [38400/69794]
loss: 0.120980  [44800/69794]
loss: 0.109382  [51200/69794]
loss: 0.160622  [57600/69794]
loss: 0.122623  [64000/69794]
Test Error: 
 Accuracy: 96.1%, Avg loss: 0.105566 

Epoch 39
-------------------------------
loss: 0.088719  [    0/69794]
loss: 0.139814  [ 6400/69794]
loss: 0.099304  [12800/69794]
loss: 0.072770  [19200/69794]
loss: 0.071745  [25600/69794]
loss: 0.187438  [32000/69794]
loss: 0.061281  [38400/69794]
loss: 0.095001  [44800/69794]
loss: 0.049676  [51200/69794]
loss: 0.106849  [57600/69794]
loss: 0.184408  [64000/69794]
Test Error: 
 Accuracy: 95.6%, Avg loss: 0.117075 

Epoch 40
-------------------------------
loss: 0.039171  [    0/69794]
loss: 0.069559  [ 6400/69794]
loss: 0.082996  [12800/69794]
loss: 0.110814  [19200/69794]
loss: 0.067164  [25600/69794]
loss: 0.043263  [32000/69794]
loss: 0.124727  [38400/69794]
loss: 0.133469  [44800/69794]
loss: 0.197528  [51200/69794]
loss: 0.114688  [57600/69794]
loss: 0.068784  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.110863 

Epoch 41
-------------------------------
loss: 0.264759  [    0/69794]
loss: 0.099168  [ 6400/69794]
loss: 0.136348  [12800/69794]
loss: 0.031394  [19200/69794]
loss: 0.107472  [25600/69794]
loss: 0.063870  [32000/69794]
loss: 0.127399  [38400/69794]
loss: 0.137381  [44800/69794]
loss: 0.135599  [51200/69794]
loss: 0.069738  [57600/69794]
loss: 0.093027  [64000/69794]
Test Error: 
 Accuracy: 95.9%, Avg loss: 0.106868 

Epoch 42
-------------------------------
loss: 0.087845  [    0/69794]
loss: 0.127588  [ 6400/69794]
loss: 0.142541  [12800/69794]
loss: 0.147714  [19200/69794]
loss: 0.055036  [25600/69794]
loss: 0.166402  [32000/69794]
loss: 0.132021  [38400/69794]
loss: 0.048841  [44800/69794]
loss: 0.208846  [51200/69794]
loss: 0.078250  [57600/69794]
loss: 0.111216  [64000/69794]
Test Error: 
 Accuracy: 95.7%, Avg loss: 0.121553 

Epoch 43
-------------------------------
loss: 0.071438  [    0/69794]
loss: 0.049073  [ 6400/69794]
loss: 0.224893  [12800/69794]
loss: 0.213431  [19200/69794]
loss: 0.105389  [25600/69794]
loss: 0.094655  [32000/69794]
loss: 0.077955  [38400/69794]
loss: 0.134444  [44800/69794]
loss: 0.071183  [51200/69794]
loss: 0.077833  [57600/69794]
loss: 0.144709  [64000/69794]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.105396 

Epoch 44
-------------------------------
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177558 

Epoch 16
-------------------------------
loss: 0.174269  [    0/70153]
loss: 0.060170  [ 6400/70153]
loss: 0.145760  [12800/70153]
loss: 0.169809  [19200/70153]
loss: 0.173701  [25600/70153]
loss: 0.145640  [32000/70153]
loss: 0.148103  [38400/70153]
loss: 0.203218  [44800/70153]
loss: 0.128428  [51200/70153]
loss: 0.179149  [57600/70153]
loss: 0.144417  [64000/70153]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.175384 

Epoch 17
-------------------------------
loss: 0.149193  [    0/70153]
loss: 0.197688  [ 6400/70153]
loss: 0.201671  [12800/70153]
loss: 0.172116  [19200/70153]
loss: 0.168501  [25600/70153]
loss: 0.201631  [32000/70153]
loss: 0.153061  [38400/70153]
loss: 0.166681  [44800/70153]
loss: 0.120380  [51200/70153]
loss: 0.151524  [57600/70153]
loss: 0.050936  [64000/70153]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.170657 

Epoch 18
-------------------------------
loss: 0.180010  [    0/70153]
loss: 0.092638  [ 6400/70153]
loss: 0.153035  [12800/70153]
loss: 0.162330  [19200/70153]
loss: 0.095093  [25600/70153]
loss: 0.113191  [32000/70153]
loss: 0.148679  [38400/70153]
loss: 0.165113  [44800/70153]
loss: 0.114964  [51200/70153]
loss: 0.115441  [57600/70153]
loss: 0.209223  [64000/70153]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.158817 

Epoch 19
-------------------------------
loss: 0.145305  [    0/70153]
loss: 0.108130  [ 6400/70153]
loss: 0.216086  [12800/70153]
loss: 0.210054  [19200/70153]
loss: 0.343651  [25600/70153]
loss: 0.147707  [32000/70153]
loss: 0.138201  [38400/70153]
loss: 0.218607  [44800/70153]
loss: 0.091790  [51200/70153]
loss: 0.141725  [57600/70153]
loss: 0.144532  [64000/70153]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.167590 

Epoch 20
-------------------------------
loss: 0.169626  [    0/70153]
loss: 0.156364  [ 6400/70153]
loss: 0.089012  [12800/70153]
loss: 0.153432  [19200/70153]
loss: 0.136974  [25600/70153]
loss: 0.125187  [32000/70153]
loss: 0.189782  [38400/70153]
loss: 0.180997  [44800/70153]
loss: 0.175078  [51200/70153]
loss: 0.155301  [57600/70153]
loss: 0.077574  [64000/70153]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.191861 

Epoch 21
-------------------------------
loss: 0.091123  [    0/70153]
loss: 0.222221  [ 6400/70153]
loss: 0.139444  [12800/70153]
loss: 0.095863  [19200/70153]
loss: 0.340201  [25600/70153]
loss: 0.250529  [32000/70153]
loss: 0.094894  [38400/70153]
loss: 0.145568  [44800/70153]
loss: 0.120977  [51200/70153]
loss: 0.119822  [57600/70153]
loss: 0.184665  [64000/70153]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.164208 

Epoch 22
-------------------------------
loss: 0.278508  [    0/70153]
loss: 0.119139  [ 6400/70153]
loss: 0.122602  [12800/70153]
loss: 0.173538  [19200/70153]
loss: 0.165167  [25600/70153]
loss: 0.103725  [32000/70153]
loss: 0.236462  [38400/70153]
loss: 0.192111  [44800/70153]
loss: 0.175435  [51200/70153]
loss: 0.292995  [57600/70153]
loss: 0.184406  [64000/70153]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.163467 

Epoch 23
-------------------------------
loss: 0.075396  [    0/70153]
loss: 0.112602  [ 6400/70153]
loss: 0.156689  [12800/70153]
loss: 0.146478  [19200/70153]
loss: 0.267663  [25600/70153]
loss: 0.169144  [32000/70153]
loss: 0.216533  [38400/70153]
loss: 0.275102  [44800/70153]
loss: 0.123651  [51200/70153]
loss: 0.337689  [57600/70153]
loss: 0.171081  [64000/70153]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.168029 

Epoch 24
-------------------------------
loss: 0.169705  [    0/70153]
loss: 0.102095  [ 6400/70153]
loss: 0.161767  [12800/70153]
loss: 0.154613  [19200/70153]
loss: 0.151734  [25600/70153]
loss: 0.109591  [32000/70153]
loss: 0.120381  [38400/70153]
loss: 0.114282  [44800/70153]
loss: 0.103452  [51200/70153]
loss: 0.247818  [57600/70153]
loss: 0.118298  [64000/70153]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.163739 

Epoch 25
-------------------------------
loss: 0.194146  [    0/70153]
loss: 0.188092  [ 6400/70153]
loss: 0.112522  [12800/70153]
loss: 0.285878  [19200/70153]
loss: 0.184812  [25600/70153]
loss: 0.228027  [32000/70153]
loss: 0.127742  [38400/70153]
loss: 0.123615  [44800/70153]
loss: 0.199460  [51200/70153]
loss: 0.047595  [57600/70153]
loss: 0.212082  [64000/70153]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.201440 

Epoch 26
-------------------------------
loss: 0.309784  [    0/70153]
loss: 0.130888  [ 6400/70153]
loss: 0.084874  [12800/70153]
loss: 0.128770  [19200/70153]
loss: 0.187701  [25600/70153]
loss: 0.137042  [32000/70153]
loss: 0.208206  [38400/70153]
loss: 0.288799  [44800/70153]
loss: 0.121085  [51200/70153]
loss: 0.102451  [57600/70153]
loss: 0.164926  [64000/70153]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.183495 

Epoch 27
-------------------------------
loss: 0.175466  [    0/70153]
loss: 0.108332  [ 6400/70153]
loss: 0.157397  [12800/70153]
loss: 0.196257  [19200/70153]
loss: 0.120983  [25600/70153]
loss: 0.131112  [32000/70153]
loss: 0.154532  [38400/70153]
loss: 0.186137  [44800/70153]
loss: 0.089552  [51200/70153]
loss: 0.136383  [57600/70153]
loss: 0.110017  [64000/70153]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.164688 

Epoch 28
-------------------------------
loss: 0.071928  [    0/70153]
loss: 0.144731  [ 6400/70153]
loss: 0.065913  [12800/70153]
loss: 0.170936  [19200/70153]
loss: 0.183939  [25600/70153]
loss: 0.142330  [32000/70153]
loss: 0.165760  [38400/70153]
loss: 0.110955  [44800/70153]
loss: 0.071441  [51200/70153]
loss: 0.200009  [57600/70153]
loss: 0.264892  [64000/70153]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.160720 

Epoch 29
-------------------------------
loss: 0.182155  [    0/70153]
loss: 0.257138  [ 6400/70153]
loss: 0.187489  [12800/70153]
loss: 0.149866  [19200/70153]
loss: 0.209632  [25600/70153]
loss: 0.106313  [32000/70153]
loss: 0.150144  [38400/70153]
loss: 0.146116  [44800/70153]
loss: 0.165796  [51200/70153]
loss: 0.211716  [57600/70153]
loss: 0.102753  [64000/70153]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.183030 

Epoch 30
-------------------------------
loss: 0.084627  [    0/70153]
loss: 0.132109  [ 6400/70153]
loss: 0.224071  [12800/70153]
loss: 0.096421  [19200/70153]
loss: 0.208417  [25600/70153]
loss: 0.138237  [32000/70153]
loss: 0.197522  [38400/70153]
loss: 0.166982  [44800/70153]
loss: 0.078827  [51200/70153]
loss: 0.185140  [57600/70153]
loss: 0.140624  [64000/70153]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.160722 

Epoch 31
-------------------------------
loss: 0.090276  [    0/70153]
loss: 0.125847  [ 6400/70153]
loss: 0.139361  [12800/70153]
loss: 0.187038  [19200/70153]
loss: 0.174367  [25600/70153]
loss: 0.084540  [32000/70153]
loss: 0.180557  [38400/70153]
loss: 0.314237  [44800/70153]
loss: 0.121392  [51200/70153]
loss: 0.051357  [57600/70153]
loss: 0.072992  [64000/70153]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.161182 

Epoch 32
-------------------------------
loss: 0.099685  [    0/70153]
loss: 0.114975  [ 6400/70153]
loss: 0.368616  [12800/70153]
loss: 0.187843  [19200/70153]
loss: 0.131518  [25600/70153]
loss: 0.115785  [32000/70153]
loss: 0.143123  [38400/70153]
loss: 0.179203  [44800/70153]
loss: 0.156207  [51200/70153]
loss: 0.358294  [57600/70153]
loss: 0.304894  [64000/70153]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.163474 

Epoch 33
-------------------------------
loss: 0.222761  [    0/70153]
loss: 0.161853  [ 6400/70153]
loss: 0.097985  [12800/70153]
loss: 0.134264  [19200/70153]
loss: 0.146353  [25600/70153]
loss: 0.253738  [32000/70153]
loss: 0.190465  [38400/70153]
loss: 0.171829  [44800/70153]
loss: 0.173326  [51200/70153]
loss: 0.162498  [57600/70153]
loss: 0.226051  [64000/70153]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.161369 

Epoch 34
-------------------------------
loss: 0.150817  [    0/70153]
loss: 0.235675  [ 6400/70153]
loss: 0.144903  [12800/70153]
loss: 0.110137  [19200/70153]
loss: 0.148594  [25600/70153]
loss: 0.188281  [32000/70153]
loss: 0.104187  [38400/70153]
loss: 0.334142  [44800/70153]
loss: 0.152544  [51200/70153]
loss: 0.168524  [57600/70153]
loss: 0.176581  [64000/70153]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.164514 

Epoch 35
-------------------------------
loss: 0.195411  [    0/70153]
loss: 0.204779  [ 6400/70153]
2022/09/20 21:42:55 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.102395 

Epoch 33
-------------------------------
loss: 0.209009  [    0/71373]
loss: 0.021382  [ 6400/71373]
loss: 0.003598  [12800/71373]
loss: 0.041240  [19200/71373]
loss: 0.031847  [25600/71373]
loss: 0.094727  [32000/71373]
loss: 0.134514  [38400/71373]
loss: 0.066270  [44800/71373]
loss: 0.107307  [51200/71373]
loss: 0.059907  [57600/71373]
loss: 0.061621  [64000/71373]
loss: 0.027195  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.091029 

Epoch 34
-------------------------------
loss: 0.055701  [    0/71373]
loss: 0.010322  [ 6400/71373]
loss: 0.062657  [12800/71373]
loss: 0.075255  [19200/71373]
loss: 0.030779  [25600/71373]
loss: 0.140498  [32000/71373]
loss: 0.062096  [38400/71373]
loss: 0.059015  [44800/71373]
loss: 0.063442  [51200/71373]
loss: 0.032907  [57600/71373]
loss: 0.100400  [64000/71373]
loss: 0.039024  [70400/71373]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.090035 

Epoch 35
-------------------------------
loss: 0.011737  [    0/71373]
loss: 0.081871  [ 6400/71373]
loss: 0.044409  [12800/71373]
loss: 0.043567  [19200/71373]
loss: 0.064006  [25600/71373]
loss: 0.183777  [32000/71373]
loss: 0.059686  [38400/71373]
loss: 0.079911  [44800/71373]
loss: 0.048978  [51200/71373]
loss: 0.070872  [57600/71373]
loss: 0.064502  [64000/71373]
loss: 0.035333  [70400/71373]
Test Error: 
 Accuracy: 96.5%, Avg loss: 0.093919 

Epoch 36
-------------------------------
loss: 0.064556  [    0/71373]
loss: 0.043518  [ 6400/71373]
loss: 0.028510  [12800/71373]
loss: 0.021655  [19200/71373]
loss: 0.086528  [25600/71373]
loss: 0.017269  [32000/71373]
loss: 0.022507  [38400/71373]
loss: 0.034564  [44800/71373]
loss: 0.012038  [51200/71373]
loss: 0.174440  [57600/71373]
loss: 0.071741  [64000/71373]
loss: 0.015381  [70400/71373]
Test Error: 
 Accuracy: 96.3%, Avg loss: 0.106992 

Epoch 37
-------------------------------
loss: 0.020722  [    0/71373]
loss: 0.009711  [ 6400/71373]
loss: 0.124881  [12800/71373]
loss: 0.104984  [19200/71373]
loss: 0.022561  [25600/71373]
loss: 0.038624  [32000/71373]
loss: 0.022862  [38400/71373]
loss: 0.056443  [44800/71373]
loss: 0.002753  [51200/71373]
loss: 0.012000  [57600/71373]
loss: 0.052410  [64000/71373]
loss: 0.090927  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.107515 

Epoch 38
-------------------------------
loss: 0.059321  [    0/71373]
loss: 1.618823  [ 6400/71373]
loss: 0.073270  [12800/71373]
loss: 0.086046  [19200/71373]
loss: 0.008850  [25600/71373]
loss: 0.229003  [32000/71373]
loss: 0.075465  [38400/71373]
loss: 0.027036  [44800/71373]
loss: 0.098269  [51200/71373]
loss: 0.015812  [57600/71373]
loss: 0.021596  [64000/71373]
loss: 0.104180  [70400/71373]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.092442 

Epoch 39
-------------------------------
loss: 0.026361  [    0/71373]
loss: 0.052431  [ 6400/71373]
loss: 0.050079  [12800/71373]
loss: 0.084673  [19200/71373]
loss: 0.032517  [25600/71373]
loss: 0.064366  [32000/71373]
loss: 0.031164  [38400/71373]
loss: 0.014679  [44800/71373]
loss: 0.030619  [51200/71373]
loss: 0.023190  [57600/71373]
loss: 0.094103  [64000/71373]
loss: 0.028550  [70400/71373]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.100456 

Epoch 40
-------------------------------
loss: 0.062701  [    0/71373]
loss: 0.023609  [ 6400/71373]
loss: 0.068245  [12800/71373]
loss: 0.039454  [19200/71373]
loss: 0.083025  [25600/71373]
loss: 0.004822  [32000/71373]
loss: 0.054444  [38400/71373]
loss: 0.042983  [44800/71373]
loss: 0.052730  [51200/71373]
loss: 0.024766  [57600/71373]
loss: 0.032389  [64000/71373]
loss: 0.023149  [70400/71373]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.095255 

Epoch 41
-------------------------------
loss: 0.028930  [    0/71373]
loss: 0.029025  [ 6400/71373]
loss: 0.083251  [12800/71373]
loss: 0.032821  [19200/71373]
loss: 0.189742  [25600/71373]
loss: 0.046705  [32000/71373]
loss: 0.050154  [38400/71373]
loss: 0.135364  [44800/71373]
loss: 0.017862  [51200/71373]
loss: 0.020138  [57600/71373]
loss: 0.013107  [64000/71373]
loss: 0.012486  [70400/71373]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.105767 

Epoch 42
-------------------------------
loss: 0.067442  [    0/71373]
loss: 0.051450  [ 6400/71373]
loss: 0.038997  [12800/71373]
loss: 0.048834  [19200/71373]
loss: 0.040747  [25600/71373]
loss: 0.025563  [32000/71373]
loss: 0.007183  [38400/71373]
loss: 0.020218  [44800/71373]
loss: 0.004586  [51200/71373]
loss: 0.009084  [57600/71373]
loss: 0.050728  [64000/71373]
loss: 0.043590  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.094309 

Epoch 43
-------------------------------
loss: 0.021707  [    0/71373]
loss: 0.085746  [ 6400/71373]
loss: 0.011497  [12800/71373]
loss: 0.064697  [19200/71373]
loss: 0.029123  [25600/71373]
loss: 0.034254  [32000/71373]
loss: 0.023151  [38400/71373]
loss: 0.056683  [44800/71373]
loss: 0.143599  [51200/71373]
loss: 0.021572  [57600/71373]
loss: 0.066228  [64000/71373]
loss: 0.011132  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.108878 

Epoch 44
-------------------------------
loss: 0.042901  [    0/71373]
loss: 0.064302  [ 6400/71373]
loss: 0.345591  [12800/71373]
loss: 0.031544  [19200/71373]
loss: 0.106741  [25600/71373]
loss: 0.105682  [32000/71373]
loss: 0.122861  [38400/71373]
loss: 0.016702  [44800/71373]
loss: 0.034447  [51200/71373]
loss: 0.031424  [57600/71373]
loss: 0.020276  [64000/71373]
loss: 0.077724  [70400/71373]
Test Error: 
 Accuracy: 96.4%, Avg loss: 0.117864 

Epoch 45
-------------------------------
loss: 0.066038  [    0/71373]
loss: 0.057235  [ 6400/71373]
loss: 0.026720  [12800/71373]
loss: 0.053081  [19200/71373]
loss: 0.083730  [25600/71373]
loss: 0.028421  [32000/71373]
loss: 0.017632  [38400/71373]
loss: 0.047491  [44800/71373]
loss: 0.022301  [51200/71373]
loss: 0.013265  [57600/71373]
loss: 0.020528  [64000/71373]
loss: 0.024763  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.105979 

Epoch 46
-------------------------------
loss: 0.057935  [    0/71373]
loss: 0.060333  [ 6400/71373]
loss: 0.062383  [12800/71373]
loss: 0.009874  [19200/71373]
loss: 0.026796  [25600/71373]
loss: 0.067581  [32000/71373]
loss: 0.042028  [38400/71373]
loss: 0.074407  [44800/71373]
loss: 0.053067  [51200/71373]
loss: 0.045124  [57600/71373]
loss: 0.010615  [64000/71373]
loss: 0.090067  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.111260 

Epoch 47
-------------------------------
loss: 0.059091  [    0/71373]
loss: 0.112984  [ 6400/71373]
loss: 0.110995  [12800/71373]
loss: 0.020509  [19200/71373]
loss: 0.121068  [25600/71373]
loss: 0.029825  [32000/71373]
loss: 0.017199  [38400/71373]
loss: 0.037922  [44800/71373]
loss: 0.022100  [51200/71373]
loss: 0.029268  [57600/71373]
loss: 0.071998  [64000/71373]
loss: 0.116322  [70400/71373]
Test Error: 
 Accuracy: 96.8%, Avg loss: 0.096236 

Epoch 48
-------------------------------
loss: 0.032045  [    0/71373]
loss: 0.023393  [ 6400/71373]
loss: 0.088461  [12800/71373]
loss: 0.038969  [19200/71373]
loss: 0.058438  [25600/71373]
loss: 0.026657  [32000/71373]
loss: 0.030212  [38400/71373]
loss: 0.032344  [44800/71373]
loss: 0.019124  [51200/71373]
loss: 0.101975  [57600/71373]
loss: 0.017057  [64000/71373]
loss: 0.041392  [70400/71373]
Test Error: 
 Accuracy: 96.7%, Avg loss: 0.113094 

Epoch 49
-------------------------------
loss: 0.095376  [    0/71373]
loss: 0.142322  [ 6400/71373]
loss: 0.186420  [12800/71373]
loss: 0.040962  [19200/71373]
loss: 0.005816  [25600/71373]
loss: 0.080689  [32000/71373]
loss: 0.011472  [38400/71373]
loss: 0.101605  [44800/71373]
loss: 0.050694  [51200/71373]
loss: 0.025889  [57600/71373]
loss: 0.142621  [64000/71373]
loss: 0.032067  [70400/71373]
Test Error: 
 Accuracy: 96.9%, Avg loss: 0.100453 

Epoch 50
-------------------------------
loss: 0.016651  [    0/71373]
loss: 0.086730  [ 6400/71373]
loss: 0.047360  [12800/71373]
loss: 0.124279  [19200/71373]
loss: 0.049023  [25600/71373]
loss: 0.023022  [32000/71373]
loss: 0.070550  [38400/71373]
loss: 0.025426  [44800/71373]
loss: 0.066011  [51200/71373]
loss: 0.020132  [57600/71373]
loss: 0.024503  [64000/71373]
loss: 0.009246  [70400/71373]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.153325 

Epoch 26
-------------------------------
loss: 0.165389  [    0/70534]
loss: 0.111204  [ 6400/70534]
loss: 0.116069  [12800/70534]
loss: 0.106098  [19200/70534]
loss: 0.104086  [25600/70534]
loss: 0.318469  [32000/70534]
loss: 0.075301  [38400/70534]
loss: 0.171125  [44800/70534]
loss: 0.194771  [51200/70534]
loss: 0.193472  [57600/70534]
loss: 0.146737  [64000/70534]
loss: 0.262564  [70400/70534]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.157959 

Epoch 27
-------------------------------
loss: 0.147824  [    0/70534]
loss: 0.151755  [ 6400/70534]
loss: 0.074153  [12800/70534]
loss: 0.150068  [19200/70534]
loss: 0.241989  [25600/70534]
loss: 0.119964  [32000/70534]
loss: 0.163923  [38400/70534]
loss: 0.243838  [44800/70534]
loss: 0.196212  [51200/70534]
loss: 0.151641  [57600/70534]
loss: 0.096583  [64000/70534]
loss: 0.057067  [70400/70534]
Test Error: 
 Accuracy: 91.2%, Avg loss: 0.217350 

Epoch 28
-------------------------------
loss: 0.227899  [    0/70534]
loss: 0.181072  [ 6400/70534]
loss: 0.250119  [12800/70534]
loss: 0.128967  [19200/70534]
loss: 0.165964  [25600/70534]
loss: 0.060012  [32000/70534]
loss: 0.110271  [38400/70534]
loss: 0.133952  [44800/70534]
loss: 0.149683  [51200/70534]
loss: 0.248181  [57600/70534]
loss: 0.154429  [64000/70534]
loss: 0.176945  [70400/70534]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.169971 

Epoch 29
-------------------------------
loss: 0.144800  [    0/70534]
loss: 0.173653  [ 6400/70534]
loss: 0.153995  [12800/70534]
loss: 0.143184  [19200/70534]
loss: 0.157040  [25600/70534]
loss: 0.106252  [32000/70534]
loss: 0.183089  [38400/70534]
loss: 0.178053  [44800/70534]
loss: 0.105585  [51200/70534]
loss: 0.244427  [57600/70534]
loss: 0.244813  [64000/70534]
loss: 0.152571  [70400/70534]
Test Error: 
 Accuracy: 94.1%, Avg loss: 0.146600 

Epoch 30
-------------------------------
loss: 0.131178  [    0/70534]
loss: 0.270158  [ 6400/70534]
loss: 0.156511  [12800/70534]
loss: 0.130180  [19200/70534]
loss: 0.108100  [25600/70534]
loss: 0.210736  [32000/70534]
loss: 0.104377  [38400/70534]
loss: 0.184442  [44800/70534]
loss: 0.149880  [51200/70534]
loss: 0.256525  [57600/70534]
loss: 0.226115  [64000/70534]
loss: 0.286998  [70400/70534]
Test Error: 
 Accuracy: 91.4%, Avg loss: 0.219775 

Epoch 31
-------------------------------
loss: 0.109931  [    0/70534]
loss: 0.119243  [ 6400/70534]
loss: 0.066464  [12800/70534]
loss: 0.142955  [19200/70534]
loss: 0.050477  [25600/70534]
loss: 0.167053  [32000/70534]
loss: 0.103667  [38400/70534]
loss: 0.184716  [44800/70534]
loss: 0.186690  [51200/70534]
loss: 0.210675  [57600/70534]
loss: 0.224099  [64000/70534]
loss: 0.079981  [70400/70534]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.198488 

Epoch 32
-------------------------------
loss: 0.213163  [    0/70534]
loss: 0.173312  [ 6400/70534]
loss: 0.129812  [12800/70534]
loss: 0.162363  [19200/70534]
loss: 0.252605  [25600/70534]
loss: 0.202251  [32000/70534]
loss: 0.287399  [38400/70534]
loss: 0.207403  [44800/70534]
loss: 0.168120  [51200/70534]
loss: 0.219744  [57600/70534]
loss: 0.133790  [64000/70534]
loss: 0.167253  [70400/70534]
Test Error: 
 Accuracy: 94.0%, Avg loss: 0.145670 

Epoch 33
-------------------------------
loss: 0.099575  [    0/70534]
loss: 0.075398  [ 6400/70534]
loss: 0.080104  [12800/70534]
loss: 0.165691  [19200/70534]
loss: 0.194262  [25600/70534]
loss: 0.105159  [32000/70534]
loss: 0.210868  [38400/70534]
loss: 0.197125  [44800/70534]
loss: 0.266084  [51200/70534]
loss: 0.200786  [57600/70534]
loss: 0.140517  [64000/70534]
loss: 0.146594  [70400/70534]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.182145 

Epoch 34
-------------------------------
loss: 0.085275  [    0/70534]
loss: 0.046138  [ 6400/70534]
loss: 0.121518  [12800/70534]
loss: 0.217611  [19200/70534]
loss: 0.332374  [25600/70534]
loss: 0.158860  [32000/70534]
loss: 0.075904  [38400/70534]
loss: 0.127300  [44800/70534]
loss: 0.141135  [51200/70534]
loss: 0.150441  [57600/70534]
loss: 0.096027  [64000/70534]
loss: 0.132733  [70400/70534]
Test Error: 
 Accuracy: 87.5%, Avg loss: 0.333673 

Epoch 35
-------------------------------
loss: 0.275161  [    0/70534]
loss: 0.142736  [ 6400/70534]
loss: 0.205344  [12800/70534]
loss: 0.101925  [19200/70534]
loss: 0.139555  [25600/70534]
loss: 0.142952  [32000/70534]
loss: 0.279145  [38400/70534]
loss: 0.115555  [44800/70534]
loss: 0.100641  [51200/70534]
loss: 0.151625  [57600/70534]
loss: 0.132402  [64000/70534]
loss: 0.145753  [70400/70534]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.156418 

Epoch 36
-------------------------------
loss: 0.084246  [    0/70534]
loss: 0.111658  [ 6400/70534]
loss: 0.214125  [12800/70534]
loss: 0.167926  [19200/70534]
loss: 0.156939  [25600/70534]
loss: 0.134356  [32000/70534]
loss: 0.262659  [38400/70534]
loss: 0.119228  [44800/70534]
loss: 0.245821  [51200/70534]
loss: 0.189766  [57600/70534]
loss: 0.126995  [64000/70534]
loss: 0.230461  [70400/70534]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.180563 

Epoch 37
-------------------------------
loss: 0.194354  [    0/70534]
loss: 0.079921  [ 6400/70534]
loss: 0.145205  [12800/70534]
loss: 0.178961  [19200/70534]
loss: 0.256540  [25600/70534]
loss: 0.194226  [32000/70534]
loss: 0.133621  [38400/70534]
loss: 0.180407  [44800/70534]
loss: 0.164535  [51200/70534]
loss: 0.146486  [57600/70534]
loss: 0.178922  [64000/70534]
loss: 0.152584  [70400/70534]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.179222 

Epoch 38
-------------------------------
loss: 0.259470  [    0/70534]
loss: 0.118813  [ 6400/70534]
loss: 0.242811  [12800/70534]
loss: 0.264460  [19200/70534]
loss: 0.137751  [25600/70534]
loss: 0.097443  [32000/70534]
loss: 0.245362  [38400/70534]
loss: 0.144380  [44800/70534]
loss: 0.193339  [51200/70534]
loss: 0.187979  [57600/70534]
loss: 0.186186  [64000/70534]
loss: 0.170426  [70400/70534]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.175992 

Epoch 39
-------------------------------
loss: 0.198878  [    0/70534]
loss: 0.189942  [ 6400/70534]
loss: 0.071362  [12800/70534]
loss: 0.196729  [19200/70534]
loss: 0.158400  [25600/70534]
loss: 0.147018  [32000/70534]
loss: 0.147649  [38400/70534]
loss: 0.197444  [44800/70534]
loss: 0.077741  [51200/70534]
loss: 0.133275  [57600/70534]
loss: 0.268409  [64000/70534]
loss: 0.161228  [70400/70534]
Test Error: 
 Accuracy: 93.9%, Avg loss: 0.150643 

Epoch 40
-------------------------------
loss: 0.101947  [    0/70534]
loss: 0.162346  [ 6400/70534]
loss: 0.138607  [12800/70534]
loss: 0.137599  [19200/70534]
loss: 0.191633  [25600/70534]
loss: 0.171962  [32000/70534]
loss: 0.211361  [38400/70534]
loss: 0.075777  [44800/70534]
loss: 0.084857  [51200/70534]
loss: 0.091390  [57600/70534]
loss: 0.131802  [64000/70534]
loss: 0.119804  [70400/70534]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.166818 

Epoch 41
-------------------------------
loss: 0.167735  [    0/70534]
loss: 0.123704  [ 6400/70534]
loss: 0.175337  [12800/70534]
loss: 0.177419  [19200/70534]
loss: 0.244877  [25600/70534]
loss: 0.163692  [32000/70534]
loss: 0.082587  [38400/70534]
loss: 0.210876  [44800/70534]
loss: 0.272934  [51200/70534]
loss: 0.151068  [57600/70534]
loss: 0.091159  [64000/70534]
loss: 0.252775  [70400/70534]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.165019 

Epoch 42
-------------------------------
loss: 0.135137  [    0/70534]
loss: 0.094498  [ 6400/70534]
loss: 0.154243  [12800/70534]
loss: 0.135946  [19200/70534]
loss: 0.184077  [25600/70534]
loss: 0.114041  [32000/70534]
loss: 0.159996  [38400/70534]
loss: 0.098483  [44800/70534]
loss: 0.100696  [51200/70534]
loss: 0.155645  [57600/70534]
loss: 0.208412  [64000/70534]
loss: 0.371447  [70400/70534]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.164129 

Epoch 43
-------------------------------
loss: 0.233649  [    0/70534]
loss: 0.180785  [ 6400/70534]
loss: 0.250797  [12800/70534]
loss: 0.101963  [19200/70534]
loss: 0.093237  [25600/70534]
loss: 0.205275  [32000/70534]
loss: 0.166885  [38400/70534]
loss: 0.089190  [44800/70534]
loss: 0.108810  [51200/70534]
loss: 0.087969  [57600/70534]
loss: 0.084844  [64000/70534]
loss: 0.085994  [70400/70534]
2022/09/20 21:43:44 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 21:43:46 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 21:43:48 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 21:44:00 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.171757 

Epoch 25
-------------------------------
loss: 0.210358  [    0/69845]
loss: 0.188863  [ 6400/69845]
loss: 0.187440  [12800/69845]
loss: 0.206520  [19200/69845]
loss: 0.304469  [25600/69845]
loss: 0.130118  [32000/69845]
loss: 0.152505  [38400/69845]
loss: 0.174759  [44800/69845]
loss: 0.249665  [51200/69845]
loss: 0.165044  [57600/69845]
loss: 0.168640  [64000/69845]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.172245 

Epoch 26
-------------------------------
loss: 0.245926  [    0/69845]
loss: 0.069723  [ 6400/69845]
loss: 0.140949  [12800/69845]
loss: 0.136035  [19200/69845]
loss: 0.182335  [25600/69845]
loss: 0.350974  [32000/69845]
loss: 0.057838  [38400/69845]
loss: 0.194563  [44800/69845]
loss: 0.176868  [51200/69845]
loss: 0.172580  [57600/69845]
loss: 0.142922  [64000/69845]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.196961 

Epoch 27
-------------------------------
loss: 0.135124  [    0/69845]
loss: 0.231610  [ 6400/69845]
loss: 0.204289  [12800/69845]
loss: 0.135101  [19200/69845]
loss: 0.165114  [25600/69845]
loss: 0.128326  [32000/69845]
loss: 0.186219  [38400/69845]
loss: 0.113162  [44800/69845]
loss: 0.094798  [51200/69845]
loss: 0.282652  [57600/69845]
loss: 0.124175  [64000/69845]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.179377 

Epoch 28
-------------------------------
loss: 0.180118  [    0/69845]
loss: 0.076427  [ 6400/69845]
loss: 0.061575  [12800/69845]
loss: 0.228795  [19200/69845]
loss: 0.162661  [25600/69845]
loss: 0.165793  [32000/69845]
loss: 0.127635  [38400/69845]
loss: 0.217478  [44800/69845]
loss: 0.127964  [51200/69845]
loss: 0.218332  [57600/69845]
loss: 0.136568  [64000/69845]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.180455 

Epoch 29
-------------------------------
loss: 0.170301  [    0/69845]
loss: 0.093593  [ 6400/69845]
loss: 0.205668  [12800/69845]
loss: 0.138451  [19200/69845]
loss: 0.265332  [25600/69845]
loss: 0.146648  [32000/69845]
loss: 0.141910  [38400/69845]
loss: 0.173334  [44800/69845]
loss: 0.101963  [51200/69845]
loss: 0.277715  [57600/69845]
loss: 0.260361  [64000/69845]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177240 

Epoch 30
-------------------------------
loss: 0.316039  [    0/69845]
loss: 0.198397  [ 6400/69845]
loss: 0.203885  [12800/69845]
loss: 0.247310  [19200/69845]
loss: 0.172828  [25600/69845]
loss: 0.163460  [32000/69845]
loss: 0.141708  [38400/69845]
loss: 0.108320  [44800/69845]
loss: 0.145470  [51200/69845]
loss: 0.141150  [57600/69845]
loss: 0.225298  [64000/69845]
Test Error: 
 Accuracy: 90.9%, Avg loss: 0.219530 

Epoch 31
-------------------------------
loss: 0.205102  [    0/69845]
loss: 0.147936  [ 6400/69845]
loss: 0.125265  [12800/69845]
loss: 0.174840  [19200/69845]
loss: 0.136285  [25600/69845]
loss: 0.076970  [32000/69845]
loss: 0.210731  [38400/69845]
loss: 0.391344  [44800/69845]
loss: 0.180633  [51200/69845]
loss: 0.352857  [57600/69845]
loss: 0.188082  [64000/69845]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.193555 

Epoch 32
-------------------------------
loss: 0.169820  [    0/69845]
loss: 0.119108  [ 6400/69845]
loss: 0.176287  [12800/69845]
loss: 0.074282  [19200/69845]
loss: 0.233165  [25600/69845]
loss: 0.274904  [32000/69845]
loss: 0.130456  [38400/69845]
loss: 0.151770  [44800/69845]
loss: 0.175015  [51200/69845]
loss: 0.215264  [57600/69845]
loss: 0.257632  [64000/69845]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.164336 

Epoch 33
-------------------------------
loss: 0.175917  [    0/69845]
loss: 0.239442  [ 6400/69845]
loss: 0.190032  [12800/69845]
loss: 0.181478  [19200/69845]
loss: 0.146902  [25600/69845]
loss: 0.142544  [32000/69845]
loss: 0.215662  [38400/69845]
loss: 0.165369  [44800/69845]
loss: 0.224745  [51200/69845]
loss: 0.142364  [57600/69845]
loss: 0.235931  [64000/69845]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.189111 

Epoch 34
-------------------------------
loss: 0.062073  [    0/69845]
loss: 0.107507  [ 6400/69845]
loss: 0.102376  [12800/69845]
loss: 0.138743  [19200/69845]
loss: 0.088163  [25600/69845]
loss: 0.217838  [32000/69845]
loss: 0.161357  [38400/69845]
loss: 0.105735  [44800/69845]
loss: 0.217490  [51200/69845]
loss: 0.117014  [57600/69845]
loss: 0.305754  [64000/69845]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.171331 

Epoch 35
-------------------------------
loss: 0.252433  [    0/69845]
loss: 0.186897  [ 6400/69845]
loss: 0.348206  [12800/69845]
loss: 0.148560  [19200/69845]
loss: 0.202227  [25600/69845]
loss: 0.169349  [32000/69845]
loss: 0.149906  [38400/69845]
loss: 0.281006  [44800/69845]
loss: 0.167861  [51200/69845]
loss: 0.144877  [57600/69845]
loss: 0.191782  [64000/69845]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.180192 

Epoch 36
-------------------------------
loss: 0.081957  [    0/69845]
loss: 0.162574  [ 6400/69845]
loss: 0.198621  [12800/69845]
loss: 0.091412  [19200/69845]
loss: 0.224885  [25600/69845]
loss: 0.136912  [32000/69845]
loss: 0.098854  [38400/69845]
loss: 0.242198  [44800/69845]
loss: 0.163882  [51200/69845]
loss: 0.184978  [57600/69845]
loss: 0.064470  [64000/69845]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.170571 

Epoch 37
-------------------------------
loss: 0.183760  [    0/69845]
loss: 0.116268  [ 6400/69845]
loss: 0.136864  [12800/69845]
loss: 0.146298  [19200/69845]
loss: 0.178925  [25600/69845]
loss: 0.116284  [32000/69845]
loss: 0.177900  [38400/69845]
loss: 0.111549  [44800/69845]
loss: 0.177474  [51200/69845]
loss: 0.167506  [57600/69845]
loss: 0.130697  [64000/69845]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.177489 

Epoch 38
-------------------------------
loss: 0.093454  [    0/69845]
loss: 0.150728  [ 6400/69845]
loss: 0.205721  [12800/69845]
loss: 0.111286  [19200/69845]
loss: 0.108016  [25600/69845]
loss: 0.253980  [32000/69845]
loss: 0.110217  [38400/69845]
loss: 0.167730  [44800/69845]
loss: 0.146961  [51200/69845]
loss: 0.142612  [57600/69845]
loss: 0.164735  [64000/69845]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.172383 

Epoch 39
-------------------------------
loss: 0.164155  [    0/69845]
loss: 0.100436  [ 6400/69845]
loss: 0.097427  [12800/69845]
loss: 0.165666  [19200/69845]
loss: 0.136812  [25600/69845]
loss: 0.134537  [32000/69845]
loss: 0.170339  [38400/69845]
loss: 0.158071  [44800/69845]
loss: 0.144999  [51200/69845]
loss: 0.249455  [57600/69845]
loss: 0.168029  [64000/69845]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.191780 

Epoch 40
-------------------------------
loss: 0.109211  [    0/69845]
loss: 0.123415  [ 6400/69845]
loss: 0.170029  [12800/69845]
loss: 0.203992  [19200/69845]
loss: 0.208379  [25600/69845]
loss: 0.226848  [32000/69845]
loss: 0.182251  [38400/69845]
loss: 0.223762  [44800/69845]
loss: 0.268384  [51200/69845]
loss: 0.081110  [57600/69845]
loss: 0.066419  [64000/69845]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.171873 

Epoch 41
-------------------------------
loss: 0.202531  [    0/69845]
loss: 0.177818  [ 6400/69845]
loss: 0.131722  [12800/69845]
loss: 0.139209  [19200/69845]
loss: 0.130275  [25600/69845]
loss: 0.219589  [32000/69845]
loss: 0.131272  [38400/69845]
loss: 0.204961  [44800/69845]
loss: 0.194454  [51200/69845]
loss: 0.165762  [57600/69845]
loss: 0.290387  [64000/69845]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.175699 

Epoch 42
-------------------------------
loss: 0.141570  [    0/69845]
loss: 0.159975  [ 6400/69845]
loss: 0.190235  [12800/69845]
loss: 0.196470  [19200/69845]
loss: 0.181719  [25600/69845]
loss: 0.299623  [32000/69845]
loss: 0.070959  [38400/69845]
loss: 0.128958  [44800/69845]
loss: 0.132561  [51200/69845]
loss: 0.149053  [57600/69845]
loss: 0.104439  [64000/69845]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.167148 

Epoch 43
-------------------------------
loss: 0.220877  [    0/69845]
loss: 0.109273  [ 6400/69845]
loss: 0.186768  [12800/69845]
loss: 0.240409  [19200/69845]
loss: 0.233442  [25600/69845]
loss: 0.184914  [32000/69845]
loss: 0.158590  [38400/69845]
loss: 0.261589  [44800/69845]
loss: 0.211385  [51200/69845]
loss: 0.276454  [57600/69845]
loss: 0.257701  [64000/69845]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.208963 

Epoch 44
-------------------------------
loss: 0.195110  [    0/69845]
loss: 0.155585  [ 6400/69845]
2022/09/20 22:03:09 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 22:03:28 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.060406  [44800/69617]
loss: 0.199739  [51200/69617]
loss: 0.179926  [57600/69617]
loss: 0.177329  [64000/69617]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.198019 

Epoch 20
-------------------------------
loss: 0.147016  [    0/69617]
loss: 0.185248  [ 6400/69617]
loss: 0.221525  [12800/69617]
loss: 0.122963  [19200/69617]
loss: 0.289620  [25600/69617]
loss: 0.246327  [32000/69617]
loss: 0.199806  [38400/69617]
loss: 0.176476  [44800/69617]
loss: 0.097922  [51200/69617]
loss: 0.182999  [57600/69617]
loss: 0.100830  [64000/69617]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.180778 

Epoch 21
-------------------------------
loss: 0.129992  [    0/69617]
loss: 0.240738  [ 6400/69617]
loss: 0.238068  [12800/69617]
loss: 0.219851  [19200/69617]
loss: 0.161858  [25600/69617]
loss: 0.109083  [32000/69617]
loss: 0.213235  [38400/69617]
loss: 0.300717  [44800/69617]
loss: 0.254933  [51200/69617]
loss: 0.146460  [57600/69617]
loss: 0.225425  [64000/69617]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.179623 

Epoch 22
-------------------------------
loss: 0.118268  [    0/69617]
loss: 0.188611  [ 6400/69617]
loss: 0.173054  [12800/69617]
loss: 0.210773  [19200/69617]
loss: 0.356018  [25600/69617]
loss: 0.167902  [32000/69617]
loss: 0.215858  [38400/69617]
loss: 0.203778  [44800/69617]
loss: 0.125209  [51200/69617]
loss: 0.194503  [57600/69617]
loss: 0.286935  [64000/69617]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.185399 

Epoch 23
-------------------------------
loss: 0.043944  [    0/69617]
loss: 0.182294  [ 6400/69617]
loss: 0.175263  [12800/69617]
loss: 0.086487  [19200/69617]
loss: 0.078663  [25600/69617]
loss: 0.152053  [32000/69617]
loss: 0.154995  [38400/69617]
loss: 0.308894  [44800/69617]
loss: 0.181524  [51200/69617]
loss: 0.174385  [57600/69617]
loss: 0.299033  [64000/69617]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.193855 

Epoch 24
-------------------------------
loss: 0.151667  [    0/69617]
loss: 0.185400  [ 6400/69617]
loss: 0.112852  [12800/69617]
loss: 0.232772  [19200/69617]
loss: 0.216321  [25600/69617]
loss: 0.224968  [32000/69617]
loss: 0.167770  [38400/69617]
loss: 0.086427  [44800/69617]
loss: 0.092736  [51200/69617]
loss: 0.158909  [57600/69617]
loss: 0.174254  [64000/69617]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.178916 

Epoch 25
-------------------------------
loss: 0.164988  [    0/69617]
loss: 0.242418  [ 6400/69617]
loss: 0.176603  [12800/69617]
loss: 0.144509  [19200/69617]
loss: 0.204041  [25600/69617]
loss: 0.100424  [32000/69617]
loss: 0.174478  [38400/69617]
loss: 0.182913  [44800/69617]
loss: 0.121585  [51200/69617]
loss: 0.164793  [57600/69617]
loss: 0.192922  [64000/69617]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.193621 

Epoch 26
-------------------------------
loss: 0.148282  [    0/69617]
loss: 0.174674  [ 6400/69617]
loss: 0.110860  [12800/69617]
loss: 0.175570  [19200/69617]
loss: 0.275304  [25600/69617]
loss: 0.124345  [32000/69617]
loss: 0.201504  [38400/69617]
loss: 0.189328  [44800/69617]
loss: 0.163179  [51200/69617]
loss: 0.124721  [57600/69617]
loss: 0.152140  [64000/69617]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.185813 

Epoch 27
-------------------------------
loss: 0.107743  [    0/69617]
loss: 0.171522  [ 6400/69617]
loss: 0.107849  [12800/69617]
loss: 0.184727  [19200/69617]
loss: 0.107334  [25600/69617]
loss: 0.167502  [32000/69617]
loss: 0.186286  [38400/69617]
loss: 0.296981  [44800/69617]
loss: 0.087168  [51200/69617]
loss: 0.116413  [57600/69617]
loss: 0.177837  [64000/69617]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.181748 

Epoch 28
-------------------------------
loss: 0.206377  [    0/69617]
loss: 0.276831  [ 6400/69617]
loss: 0.241882  [12800/69617]
loss: 0.327872  [19200/69617]
loss: 0.150328  [25600/69617]
loss: 0.088142  [32000/69617]
loss: 0.119554  [38400/69617]
loss: 0.259789  [44800/69617]
loss: 0.198239  [51200/69617]
loss: 0.256023  [57600/69617]
loss: 0.174812  [64000/69617]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.181293 

Epoch 29
-------------------------------
loss: 0.181402  [    0/69617]
loss: 0.131590  [ 6400/69617]
loss: 0.284004  [12800/69617]
loss: 0.203534  [19200/69617]
loss: 0.214606  [25600/69617]
loss: 0.181365  [32000/69617]
loss: 0.082018  [38400/69617]
loss: 0.124310  [44800/69617]
loss: 0.185359  [51200/69617]
loss: 0.183323  [57600/69617]
loss: 0.162796  [64000/69617]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.183188 

Epoch 30
-------------------------------
loss: 0.111521  [    0/69617]
loss: 0.190881  [ 6400/69617]
loss: 0.171915  [12800/69617]
loss: 0.234925  [19200/69617]
loss: 0.254969  [25600/69617]
loss: 0.175963  [32000/69617]
loss: 0.178646  [38400/69617]
loss: 0.247880  [44800/69617]
loss: 0.241200  [51200/69617]
loss: 0.193350  [57600/69617]
loss: 0.082624  [64000/69617]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.188525 

Epoch 31
-------------------------------
loss: 0.107374  [    0/69617]
loss: 0.188173  [ 6400/69617]
loss: 0.210421  [12800/69617]
loss: 0.154448  [19200/69617]
loss: 0.247025  [25600/69617]
loss: 0.294295  [32000/69617]
loss: 0.225700  [38400/69617]
loss: 0.145647  [44800/69617]
loss: 0.187313  [51200/69617]
loss: 0.126586  [57600/69617]
loss: 0.223146  [64000/69617]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.184118 

Epoch 32
-------------------------------
loss: 0.119325  [    0/69617]
loss: 0.213251  [ 6400/69617]
loss: 0.175202  [12800/69617]
loss: 0.164299  [19200/69617]
loss: 0.175088  [25600/69617]
loss: 0.231096  [32000/69617]
loss: 0.129885  [38400/69617]
loss: 0.196958  [44800/69617]
loss: 0.380785  [51200/69617]
loss: 0.182902  [57600/69617]
loss: 0.181424  [64000/69617]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.187891 

Epoch 33
-------------------------------
loss: 0.197715  [    0/69617]
loss: 0.077718  [ 6400/69617]
loss: 0.191375  [12800/69617]
loss: 0.126832  [19200/69617]
loss: 0.165052  [25600/69617]
loss: 0.166463  [32000/69617]
loss: 0.166599  [38400/69617]
loss: 0.118927  [44800/69617]
loss: 0.353395  [51200/69617]
loss: 0.171352  [57600/69617]
loss: 0.250284  [64000/69617]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.185178 

Epoch 34
-------------------------------
loss: 0.186225  [    0/69617]
loss: 0.164799  [ 6400/69617]
loss: 0.224706  [12800/69617]
loss: 0.159514  [19200/69617]
loss: 0.133578  [25600/69617]
loss: 0.110570  [32000/69617]
loss: 0.202176  [38400/69617]
loss: 0.230925  [44800/69617]
loss: 0.200868  [51200/69617]
loss: 0.107863  [57600/69617]
loss: 0.178657  [64000/69617]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.182644 

Epoch 35
-------------------------------
loss: 0.127037  [    0/69617]
loss: 0.254330  [ 6400/69617]
loss: 0.173592  [12800/69617]
loss: 0.207167  [19200/69617]
loss: 0.140181  [25600/69617]
loss: 0.274285  [32000/69617]
loss: 0.189299  [38400/69617]
loss: 0.186023  [44800/69617]
loss: 0.181340  [51200/69617]
loss: 0.250195  [57600/69617]
loss: 0.099958  [64000/69617]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.192142 

Epoch 36
-------------------------------
loss: 0.137182  [    0/69617]
loss: 0.231905  [ 6400/69617]
loss: 0.149352  [12800/69617]
loss: 0.256474  [19200/69617]
loss: 0.207421  [25600/69617]
loss: 0.116736  [32000/69617]
loss: 0.213261  [38400/69617]
loss: 0.229270  [44800/69617]
loss: 0.256232  [51200/69617]
loss: 0.269368  [57600/69617]
loss: 0.232528  [64000/69617]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.183158 

Epoch 37
-------------------------------
loss: 0.188063  [    0/69617]
loss: 0.394149  [ 6400/69617]
loss: 0.157890  [12800/69617]
loss: 0.091024  [19200/69617]
loss: 0.149084  [25600/69617]
loss: 0.179406  [32000/69617]
loss: 0.138155  [38400/69617]
loss: 0.151948  [44800/69617]
loss: 0.173574  [51200/69617]
loss: 0.129637  [57600/69617]
loss: 0.334488  [64000/69617]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.178927 

Epoch 38
-------------------------------
loss: 0.124192  [    0/69617]
loss: 0.128219  [ 6400/69617]
loss: 0.054664  [12800/69617]
loss: 0.293780  [19200/69617]
loss: 0.095785  [25600/69617]
loss: 0.261501  [32000/69617]
loss: 0.156679  [38400/69617]
loss: 0.144597  [44800/69617]
loss: 0.226605  [51200/69617]
loss: 0.317391  [57600/69617]
loss: 0.217941  [64000/69617]
2022/09/20 22:05:14 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 22:05:44 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.205969  [57600/69771]
loss: 0.287143  [64000/69771]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.191308 

Epoch 40
-------------------------------
loss: 0.127630  [    0/69771]
loss: 0.179048  [ 6400/69771]
loss: 0.174031  [12800/69771]
loss: 0.164503  [19200/69771]
loss: 0.194177  [25600/69771]
loss: 0.170445  [32000/69771]
loss: 0.177089  [38400/69771]
loss: 0.251150  [44800/69771]
loss: 0.166999  [51200/69771]
loss: 0.096107  [57600/69771]
loss: 0.180664  [64000/69771]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.186151 

Epoch 41
-------------------------------
loss: 0.168334  [    0/69771]
loss: 0.210643  [ 6400/69771]
loss: 0.177419  [12800/69771]
loss: 0.172127  [19200/69771]
loss: 0.158369  [25600/69771]
loss: 0.177041  [32000/69771]
loss: 0.145572  [38400/69771]
loss: 0.309786  [44800/69771]
loss: 0.171714  [51200/69771]
loss: 0.152695  [57600/69771]
loss: 0.193921  [64000/69771]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.218945 

Epoch 42
-------------------------------
loss: 0.100311  [    0/69771]
loss: 0.135188  [ 6400/69771]
loss: 0.214937  [12800/69771]
loss: 0.187618  [19200/69771]
loss: 0.183593  [25600/69771]
loss: 0.214424  [32000/69771]
loss: 0.151959  [38400/69771]
loss: 0.124796  [44800/69771]
loss: 0.044608  [51200/69771]
loss: 0.177376  [57600/69771]
loss: 0.201364  [64000/69771]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.181935 

Epoch 43
-------------------------------
loss: 0.111757  [    0/69771]
loss: 0.151124  [ 6400/69771]
loss: 0.132885  [12800/69771]
loss: 0.216873  [19200/69771]
loss: 0.174571  [25600/69771]
loss: 0.079924  [32000/69771]
loss: 0.270346  [38400/69771]
loss: 0.134405  [44800/69771]
loss: 0.134674  [51200/69771]
loss: 0.234911  [57600/69771]
loss: 0.167387  [64000/69771]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.190940 

Epoch 44
-------------------------------
loss: 0.113760  [    0/69771]
loss: 0.264004  [ 6400/69771]
loss: 0.208197  [12800/69771]
loss: 0.191765  [19200/69771]
loss: 0.133082  [25600/69771]
loss: 0.251362  [32000/69771]
loss: 0.141240  [38400/69771]
loss: 0.196215  [44800/69771]
loss: 0.151940  [51200/69771]
loss: 0.203025  [57600/69771]
loss: 0.177081  [64000/69771]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.185310 

Epoch 45
-------------------------------
loss: 0.142271  [    0/69771]
loss: 0.177555  [ 6400/69771]
loss: 0.141455  [12800/69771]
loss: 0.260525  [19200/69771]
loss: 0.151378  [25600/69771]
loss: 0.157574  [32000/69771]
loss: 0.145046  [38400/69771]
loss: 0.183285  [44800/69771]
loss: 0.251925  [51200/69771]
loss: 0.122605  [57600/69771]
loss: 0.141480  [64000/69771]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.203443 

Epoch 46
-------------------------------
loss: 0.246185  [    0/69771]
loss: 0.113826  [ 6400/69771]
loss: 0.161687  [12800/69771]
loss: 0.139262  [19200/69771]
loss: 0.202735  [25600/69771]
loss: 0.139057  [32000/69771]
loss: 0.204968  [38400/69771]
loss: 0.168489  [44800/69771]
loss: 0.154803  [51200/69771]
loss: 0.202455  [57600/69771]
loss: 0.231507  [64000/69771]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.195778 

Epoch 47
-------------------------------
loss: 0.220308  [    0/69771]
loss: 0.205848  [ 6400/69771]
loss: 0.163354  [12800/69771]
loss: 0.194338  [19200/69771]
loss: 0.100222  [25600/69771]
loss: 0.137829  [32000/69771]
loss: 0.109308  [38400/69771]
loss: 0.127524  [44800/69771]
loss: 0.166490  [51200/69771]
loss: 0.102070  [57600/69771]
loss: 0.215578  [64000/69771]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.176663 

Epoch 48
-------------------------------
loss: 0.167273  [    0/69771]
loss: 0.191260  [ 6400/69771]
loss: 0.200685  [12800/69771]
loss: 0.216214  [19200/69771]
loss: 0.167443  [25600/69771]
loss: 0.103908  [32000/69771]
loss: 0.245378  [38400/69771]
loss: 0.178685  [44800/69771]
loss: 0.236705  [51200/69771]
loss: 0.183364  [57600/69771]
loss: 0.184422  [64000/69771]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.191849 

Epoch 49
-------------------------------
loss: 0.269592  [    0/69771]
loss: 0.206592  [ 6400/69771]
loss: 0.155625  [12800/69771]
loss: 0.144036  [19200/69771]
loss: 0.198578  [25600/69771]
loss: 0.086026  [32000/69771]
loss: 0.336747  [38400/69771]
loss: 0.257239  [44800/69771]
loss: 0.127071  [51200/69771]
loss: 0.122845  [57600/69771]
loss: 0.092707  [64000/69771]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.190832 

Epoch 50
-------------------------------
loss: 0.264495  [    0/69771]
loss: 0.262621  [ 6400/69771]
loss: 0.178429  [12800/69771]
loss: 0.172874  [19200/69771]
loss: 0.090528  [25600/69771]
loss: 0.199352  [32000/69771]
loss: 0.243986  [38400/69771]
loss: 0.243449  [44800/69771]
loss: 0.100383  [51200/69771]
loss: 0.189833  [57600/69771]
loss: 0.229971  [64000/69771]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.188523 

Epoch 1
-------------------------------
loss: 0.740741  [    0/69881]
loss: 0.307159  [ 6400/69881]
loss: 0.221954  [12800/69881]
loss: 0.352501  [19200/69881]
loss: 0.374641  [25600/69881]
loss: 0.225747  [32000/69881]
loss: 0.313350  [38400/69881]
loss: 0.254612  [44800/69881]
loss: 0.293595  [51200/69881]
loss: 0.217539  [57600/69881]
loss: 0.293338  [64000/69881]
Test Error: 
 Accuracy: 90.7%, Avg loss: 0.236709 

Epoch 2
-------------------------------
loss: 0.233149  [    0/69881]
loss: 0.264150  [ 6400/69881]
loss: 0.232247  [12800/69881]
loss: 0.268549  [19200/69881]
loss: 0.398891  [25600/69881]
loss: 0.133544  [32000/69881]
loss: 0.085908  [38400/69881]
loss: 0.306696  [44800/69881]
loss: 0.310820  [51200/69881]
loss: 0.240983  [57600/69881]
loss: 0.201907  [64000/69881]
Test Error: 
 Accuracy: 91.5%, Avg loss: 0.213962 

Epoch 3
-------------------------------
loss: 0.161538  [    0/69881]
loss: 0.250256  [ 6400/69881]
loss: 0.100865  [12800/69881]
loss: 0.213387  [19200/69881]
loss: 0.232297  [25600/69881]
loss: 0.218277  [32000/69881]
loss: 0.250800  [38400/69881]
loss: 0.306501  [44800/69881]
loss: 0.171924  [51200/69881]
loss: 0.207721  [57600/69881]
loss: 0.276271  [64000/69881]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.191570 

Epoch 4
-------------------------------
loss: 0.269099  [    0/69881]
loss: 0.135125  [ 6400/69881]
loss: 0.144805  [12800/69881]
loss: 0.103287  [19200/69881]
loss: 0.269129  [25600/69881]
loss: 0.131976  [32000/69881]
loss: 0.267203  [38400/69881]
loss: 0.091614  [44800/69881]
loss: 0.210430  [51200/69881]
loss: 0.206374  [57600/69881]
loss: 0.187063  [64000/69881]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.210767 

Epoch 5
-------------------------------
loss: 0.269403  [    0/69881]
loss: 0.150699  [ 6400/69881]
loss: 0.222069  [12800/69881]
loss: 0.176594  [19200/69881]
loss: 0.303576  [25600/69881]
loss: 0.169971  [32000/69881]
loss: 0.266947  [38400/69881]
loss: 0.130140  [44800/69881]
loss: 0.297771  [51200/69881]
loss: 0.189781  [57600/69881]
loss: 0.181619  [64000/69881]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.194383 

Epoch 6
-------------------------------
loss: 0.136134  [    0/69881]
loss: 0.098886  [ 6400/69881]
loss: 0.210766  [12800/69881]
loss: 0.163475  [19200/69881]
loss: 0.239054  [25600/69881]
loss: 0.156689  [32000/69881]
loss: 0.214632  [38400/69881]
loss: 0.185195  [44800/69881]
loss: 0.161043  [51200/69881]
loss: 0.131661  [57600/69881]
loss: 0.243401  [64000/69881]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.196510 

Epoch 7
-------------------------------
loss: 0.275252  [    0/69881]
loss: 0.201424  [ 6400/69881]
loss: 0.107990  [12800/69881]
loss: 0.202324  [19200/69881]
loss: 0.189303  [25600/69881]
loss: 0.254573  [32000/69881]
loss: 0.187745  [38400/69881]
loss: 0.278187  [44800/69881]
loss: 1.702946  [51200/69881]
loss: 0.171207  [57600/69881]
loss: 0.198654  [64000/69881]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.186696 

Epoch 8
-------------------------------
loss: 0.251029  [    0/69881]
loss: 0.223038  [ 6400/69881]
loss: 0.114394  [12800/69881]
loss: 0.297318  [19200/69881]
loss: 0.146190  [25600/69881]
loss: 0.185713  [32000/69881]
loss: 0.370372  [38400/69881]
loss: 0.171285  [44800/69881]
loss: 0.194401  [51200/69881]
loss: 0.189704  [57600/69881]
loss: 0.218102  [64000/69881]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.186928 

Epoch 9
-------------------------------
2022/09/20 22:07:26 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 22:07:34 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 22:09:08 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.215218  [12800/69845]
loss: 0.200877  [19200/69845]
loss: 0.187561  [25600/69845]
loss: 0.241730  [32000/69845]
loss: 0.087193  [38400/69845]
loss: 0.174028  [44800/69845]
loss: 0.194956  [51200/69845]
loss: 0.131368  [57600/69845]
loss: 0.224353  [64000/69845]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.173414 

Epoch 45
-------------------------------
loss: 0.107340  [    0/69845]
loss: 0.119657  [ 6400/69845]
loss: 0.151093  [12800/69845]
loss: 0.226363  [19200/69845]
loss: 0.252482  [25600/69845]
loss: 0.109013  [32000/69845]
loss: 0.205562  [38400/69845]
loss: 0.115687  [44800/69845]
loss: 0.279275  [51200/69845]
loss: 0.171127  [57600/69845]
loss: 0.116272  [64000/69845]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.169709 

Epoch 46
-------------------------------
loss: 0.171851  [    0/69845]
loss: 0.096343  [ 6400/69845]
loss: 0.197435  [12800/69845]
loss: 0.230386  [19200/69845]
loss: 0.185107  [25600/69845]
loss: 0.197925  [32000/69845]
loss: 0.101168  [38400/69845]
loss: 0.234211  [44800/69845]
loss: 0.187319  [51200/69845]
loss: 0.219360  [57600/69845]
loss: 0.167368  [64000/69845]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.170951 

Epoch 47
-------------------------------
loss: 0.134107  [    0/69845]
loss: 0.154292  [ 6400/69845]
loss: 0.175035  [12800/69845]
loss: 0.341510  [19200/69845]
loss: 0.117022  [25600/69845]
loss: 0.085180  [32000/69845]
loss: 0.243307  [38400/69845]
loss: 0.262671  [44800/69845]
loss: 0.140292  [51200/69845]
loss: 0.128528  [57600/69845]
loss: 0.202704  [64000/69845]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.172856 

Epoch 48
-------------------------------
loss: 0.114128  [    0/69845]
loss: 0.303076  [ 6400/69845]
loss: 0.158890  [12800/69845]
loss: 0.113064  [19200/69845]
loss: 0.139121  [25600/69845]
loss: 0.134914  [32000/69845]
loss: 0.214641  [38400/69845]
loss: 0.101885  [44800/69845]
loss: 0.170347  [51200/69845]
loss: 0.271508  [57600/69845]
loss: 0.186339  [64000/69845]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.181386 

Epoch 49
-------------------------------
loss: 0.138682  [    0/69845]
loss: 0.120047  [ 6400/69845]
loss: 0.169956  [12800/69845]
loss: 0.136839  [19200/69845]
loss: 0.198123  [25600/69845]
loss: 0.177594  [32000/69845]
loss: 0.220950  [38400/69845]
loss: 0.137867  [44800/69845]
loss: 0.249266  [51200/69845]
loss: 0.096715  [57600/69845]
loss: 0.121911  [64000/69845]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.170335 

Epoch 50
-------------------------------
loss: 0.153948  [    0/69845]
loss: 0.240980  [ 6400/69845]
loss: 0.135713  [12800/69845]
loss: 0.113263  [19200/69845]
loss: 0.149748  [25600/69845]
loss: 0.282064  [32000/69845]
loss: 0.230910  [38400/69845]
loss: 0.158115  [44800/69845]
loss: 0.200600  [51200/69845]
loss: 0.232558  [57600/69845]
loss: 0.165855  [64000/69845]
Test Error: 
 Accuracy: 93.0%, Avg loss: 0.177618 

Epoch 1
-------------------------------
loss: 0.702314  [    0/70227]
loss: 0.229615  [ 6400/70227]
loss: 0.145154  [12800/70227]
loss: 0.312487  [19200/70227]
loss: 0.182976  [25600/70227]
loss: 0.196947  [32000/70227]
loss: 0.330156  [38400/70227]
loss: 0.174806  [44800/70227]
loss: 0.311838  [51200/70227]
loss: 0.215557  [57600/70227]
loss: 0.279676  [64000/70227]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.199104 

Epoch 2
-------------------------------
loss: 0.143525  [    0/70227]
loss: 0.167278  [ 6400/70227]
loss: 0.227438  [12800/70227]
loss: 0.235940  [19200/70227]
loss: 0.193849  [25600/70227]
loss: 0.259540  [32000/70227]
loss: 0.215293  [38400/70227]
loss: 0.161425  [44800/70227]
loss: 0.222490  [51200/70227]
loss: 0.301156  [57600/70227]
loss: 0.185996  [64000/70227]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.198585 

Epoch 3
-------------------------------
loss: 0.213072  [    0/70227]
loss: 0.153787  [ 6400/70227]
loss: 0.279937  [12800/70227]
loss: 0.183375  [19200/70227]
loss: 0.206992  [25600/70227]
loss: 0.245402  [32000/70227]
loss: 0.196591  [38400/70227]
loss: 0.180661  [44800/70227]
loss: 0.105606  [51200/70227]
loss: 0.119563  [57600/70227]
loss: 0.174025  [64000/70227]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.195355 

Epoch 4
-------------------------------
loss: 0.231826  [    0/70227]
loss: 0.083069  [ 6400/70227]
loss: 0.191535  [12800/70227]
loss: 0.135247  [19200/70227]
loss: 0.251420  [25600/70227]
loss: 0.147873  [32000/70227]
loss: 0.183325  [38400/70227]
loss: 0.169607  [44800/70227]
loss: 0.181791  [51200/70227]
loss: 0.120583  [57600/70227]
loss: 0.212845  [64000/70227]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.192204 

Epoch 5
-------------------------------
loss: 0.265139  [    0/70227]
loss: 0.180720  [ 6400/70227]
loss: 0.159714  [12800/70227]
loss: 0.230090  [19200/70227]
loss: 0.188875  [25600/70227]
loss: 0.104854  [32000/70227]
loss: 0.166940  [38400/70227]
loss: 0.246870  [44800/70227]
loss: 0.172500  [51200/70227]
loss: 0.171778  [57600/70227]
loss: 0.236684  [64000/70227]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.170231 

Epoch 6
-------------------------------
loss: 0.330752  [    0/70227]
loss: 0.196565  [ 6400/70227]
loss: 0.259613  [12800/70227]
loss: 0.204522  [19200/70227]
loss: 0.183121  [25600/70227]
loss: 0.248125  [32000/70227]
loss: 0.224356  [38400/70227]
loss: 0.250417  [44800/70227]
loss: 0.112102  [51200/70227]
loss: 1.824799  [57600/70227]
loss: 0.214678  [64000/70227]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.174142 

Epoch 7
-------------------------------
loss: 0.126349  [    0/70227]
loss: 0.207590  [ 6400/70227]
loss: 0.143506  [12800/70227]
loss: 0.226076  [19200/70227]
loss: 0.238202  [25600/70227]
loss: 0.290227  [32000/70227]
loss: 0.126667  [38400/70227]
loss: 0.249299  [44800/70227]
loss: 0.098982  [51200/70227]
loss: 0.228140  [57600/70227]
loss: 0.146970  [64000/70227]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.168450 

Epoch 8
-------------------------------
loss: 0.182791  [    0/70227]
loss: 0.147966  [ 6400/70227]
loss: 0.194911  [12800/70227]
loss: 0.156775  [19200/70227]
loss: 0.214575  [25600/70227]
loss: 0.216246  [32000/70227]
loss: 0.133232  [38400/70227]
loss: 0.127181  [44800/70227]
loss: 0.219757  [51200/70227]
loss: 0.200612  [57600/70227]
loss: 0.182913  [64000/70227]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.192247 

Epoch 9
-------------------------------
loss: 0.140654  [    0/70227]
loss: 0.123603  [ 6400/70227]
loss: 0.227246  [12800/70227]
loss: 0.165477  [19200/70227]
loss: 0.119938  [25600/70227]
loss: 0.167105  [32000/70227]
loss: 0.194083  [38400/70227]
loss: 0.138501  [44800/70227]
loss: 0.129539  [51200/70227]
loss: 0.200968  [57600/70227]
loss: 0.214275  [64000/70227]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.169642 

Epoch 10
-------------------------------
loss: 0.110488  [    0/70227]
loss: 0.280136  [ 6400/70227]
loss: 0.122836  [12800/70227]
loss: 0.101584  [19200/70227]
loss: 0.149122  [25600/70227]
loss: 0.108632  [32000/70227]
loss: 0.153682  [38400/70227]
loss: 0.187750  [44800/70227]
loss: 0.214597  [51200/70227]
loss: 0.134847  [57600/70227]
loss: 0.190100  [64000/70227]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.166934 

Epoch 11
-------------------------------
loss: 0.155558  [    0/70227]
loss: 0.133567  [ 6400/70227]
loss: 0.237941  [12800/70227]
loss: 0.192984  [19200/70227]
loss: 0.135966  [25600/70227]
loss: 0.140066  [32000/70227]
loss: 0.139119  [38400/70227]
loss: 0.252104  [44800/70227]
loss: 0.119194  [51200/70227]
loss: 0.168101  [57600/70227]
loss: 0.159997  [64000/70227]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.163111 

Epoch 12
-------------------------------
loss: 0.142370  [    0/70227]
loss: 0.103496  [ 6400/70227]
loss: 0.251588  [12800/70227]
loss: 0.203442  [19200/70227]
loss: 0.128001  [25600/70227]
loss: 0.197087  [32000/70227]
loss: 0.308112  [38400/70227]
loss: 0.180472  [44800/70227]
loss: 0.201175  [51200/70227]
loss: 0.074053  [57600/70227]
loss: 0.251433  [64000/70227]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.180428 

Epoch 13
-------------------------------
loss: 0.222368  [    0/70227]
loss: 0.133305  [ 6400/70227]
loss: 0.132553  [12800/70227]
loss: 0.136066  [19200/70227]
loss: 0.193811  [25600/70227]
loss: 0.140496  [32000/70227]
loss: 0.249379  [38400/70227]
loss: 0.127631  [    0/69881]
loss: 0.193921  [ 6400/69881]
loss: 0.232569  [12800/69881]
loss: 0.218072  [19200/69881]
loss: 0.270229  [25600/69881]
loss: 0.224210  [32000/69881]
loss: 0.233055  [38400/69881]
loss: 0.234175  [44800/69881]
loss: 0.174952  [51200/69881]
loss: 0.113057  [57600/69881]
loss: 0.113385  [64000/69881]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.186685 

Epoch 10
-------------------------------
loss: 0.237956  [    0/69881]
loss: 0.129156  [ 6400/69881]
loss: 0.133391  [12800/69881]
loss: 0.162727  [19200/69881]
loss: 0.177002  [25600/69881]
loss: 0.185251  [32000/69881]
loss: 0.279702  [38400/69881]
loss: 0.173564  [44800/69881]
loss: 0.132327  [51200/69881]
loss: 0.135755  [57600/69881]
loss: 0.206101  [64000/69881]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.188219 

Epoch 11
-------------------------------
loss: 0.207963  [    0/69881]
loss: 0.242547  [ 6400/69881]
loss: 0.166361  [12800/69881]
loss: 0.306514  [19200/69881]
loss: 0.182514  [25600/69881]
loss: 0.161049  [32000/69881]
loss: 0.138856  [38400/69881]
loss: 0.260462  [44800/69881]
loss: 0.068632  [51200/69881]
loss: 0.234490  [57600/69881]
loss: 0.136113  [64000/69881]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.184997 

Epoch 12
-------------------------------
loss: 0.218809  [    0/69881]
loss: 0.228726  [ 6400/69881]
loss: 0.167154  [12800/69881]
loss: 0.175272  [19200/69881]
loss: 0.096072  [25600/69881]
loss: 0.211099  [32000/69881]
loss: 0.195528  [38400/69881]
loss: 0.103087  [44800/69881]
loss: 0.212342  [51200/69881]
loss: 0.117768  [57600/69881]
loss: 0.233431  [64000/69881]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.179118 

Epoch 13
-------------------------------
loss: 0.211754  [    0/69881]
loss: 0.170505  [ 6400/69881]
loss: 0.271994  [12800/69881]
loss: 0.170029  [19200/69881]
loss: 0.183334  [25600/69881]
loss: 0.154483  [32000/69881]
loss: 0.164788  [38400/69881]
loss: 0.217044  [44800/69881]
loss: 0.276997  [51200/69881]
loss: 0.170241  [57600/69881]
loss: 0.147095  [64000/69881]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.201633 

Epoch 14
-------------------------------
loss: 0.107602  [    0/69881]
loss: 0.171671  [ 6400/69881]
loss: 0.179641  [12800/69881]
loss: 0.242756  [19200/69881]
loss: 0.162501  [25600/69881]
loss: 0.150096  [32000/69881]
loss: 0.181160  [38400/69881]
loss: 0.221043  [44800/69881]
loss: 0.154004  [51200/69881]
loss: 0.165141  [57600/69881]
loss: 0.190145  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.180750 

Epoch 15
-------------------------------
loss: 0.233612  [    0/69881]
loss: 0.172587  [ 6400/69881]
loss: 0.131467  [12800/69881]
loss: 0.229506  [19200/69881]
loss: 0.290428  [25600/69881]
loss: 0.116188  [32000/69881]
loss: 0.092866  [38400/69881]
loss: 0.186628  [44800/69881]
loss: 0.146298  [51200/69881]
loss: 0.338541  [57600/69881]
loss: 0.190492  [64000/69881]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.202359 

Epoch 16
-------------------------------
loss: 0.153409  [    0/69881]
loss: 0.144901  [ 6400/69881]
loss: 0.162999  [12800/69881]
loss: 0.146514  [19200/69881]
loss: 0.117327  [25600/69881]
loss: 0.217389  [32000/69881]
loss: 0.192765  [38400/69881]
loss: 0.172587  [44800/69881]
loss: 0.343617  [51200/69881]
loss: 0.215129  [57600/69881]
loss: 0.107167  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.179278 

Epoch 17
-------------------------------
loss: 0.135621  [    0/69881]
loss: 0.159373  [ 6400/69881]
loss: 0.246124  [12800/69881]
loss: 0.170066  [19200/69881]
loss: 0.183030  [25600/69881]
loss: 0.143451  [32000/69881]
loss: 0.238996  [38400/69881]
loss: 0.181401  [44800/69881]
loss: 0.198179  [51200/69881]
loss: 0.136935  [57600/69881]
loss: 0.341348  [64000/69881]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.189124 

Epoch 18
-------------------------------
loss: 0.180309  [    0/69881]
loss: 0.326456  [ 6400/69881]
loss: 0.123326  [12800/69881]
loss: 0.124832  [19200/69881]
loss: 0.162220  [25600/69881]
loss: 0.129529  [32000/69881]
loss: 0.149295  [38400/69881]
loss: 0.235858  [44800/69881]
loss: 0.205647  [51200/69881]
loss: 0.181315  [57600/69881]
loss: 0.160871  [64000/69881]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.177826 

Epoch 19
-------------------------------
loss: 0.294679  [    0/69881]
loss: 0.221221  [ 6400/69881]
loss: 0.185863  [12800/69881]
loss: 0.176032  [19200/69881]
loss: 0.191688  [25600/69881]
loss: 0.108446  [32000/69881]
loss: 0.204822  [38400/69881]
loss: 0.278781  [44800/69881]
loss: 0.217100  [51200/69881]
loss: 0.146732  [57600/69881]
loss: 0.151791  [64000/69881]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.184525 

Epoch 20
-------------------------------
loss: 0.139704  [    0/69881]
loss: 0.111052  [ 6400/69881]
loss: 0.214526  [12800/69881]
loss: 0.179293  [19200/69881]
loss: 0.221386  [25600/69881]
loss: 0.117609  [32000/69881]
loss: 0.146089  [38400/69881]
loss: 0.124391  [44800/69881]
loss: 0.192489  [51200/69881]
loss: 0.207413  [57600/69881]
loss: 0.330805  [64000/69881]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.176752 

Epoch 21
-------------------------------
loss: 0.230294  [    0/69881]
loss: 0.187600  [ 6400/69881]
loss: 0.142966  [12800/69881]
loss: 0.147131  [19200/69881]
loss: 0.153828  [25600/69881]
loss: 0.122423  [32000/69881]
loss: 0.101061  [38400/69881]
loss: 0.171710  [44800/69881]
loss: 0.201624  [51200/69881]
loss: 0.229510  [57600/69881]
loss: 0.245885  [64000/69881]
Test Error: 
 Accuracy: 92.9%, Avg loss: 0.175609 

Epoch 22
-------------------------------
loss: 0.225789  [    0/69881]
loss: 0.223136  [ 6400/69881]
loss: 0.308573  [12800/69881]
loss: 0.148549  [19200/69881]
loss: 0.094765  [25600/69881]
loss: 0.228971  [32000/69881]
loss: 0.276217  [38400/69881]
loss: 0.177954  [44800/69881]
loss: 0.275682  [51200/69881]
loss: 0.303113  [57600/69881]
loss: 0.064015  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.181297 

Epoch 23
-------------------------------
loss: 0.181477  [    0/69881]
loss: 0.197944  [ 6400/69881]
loss: 0.141797  [12800/69881]
loss: 0.098764  [19200/69881]
loss: 0.320709  [25600/69881]
loss: 0.194538  [32000/69881]
loss: 0.128605  [38400/69881]
loss: 0.173567  [44800/69881]
loss: 0.169936  [51200/69881]
loss: 0.204642  [57600/69881]
loss: 0.158373  [64000/69881]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.177210 

Epoch 24
-------------------------------
loss: 0.147484  [    0/69881]
loss: 0.146141  [ 6400/69881]
loss: 0.209101  [12800/69881]
loss: 0.172869  [19200/69881]
loss: 0.152193  [25600/69881]
loss: 0.208701  [32000/69881]
loss: 0.160371  [38400/69881]
loss: 0.170723  [44800/69881]
loss: 0.182164  [51200/69881]
loss: 0.157941  [57600/69881]
loss: 0.153941  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.177818 

Epoch 25
-------------------------------
loss: 0.204117  [    0/69881]
loss: 0.158734  [ 6400/69881]
loss: 0.198427  [12800/69881]
loss: 0.268253  [19200/69881]
loss: 0.177174  [25600/69881]
loss: 0.237861  [32000/69881]
loss: 0.138098  [38400/69881]
loss: 0.379787  [44800/69881]
loss: 0.134460  [51200/69881]
loss: 0.253358  [57600/69881]
loss: 0.218000  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.175291 

Epoch 26
-------------------------------
loss: 0.168766  [    0/69881]
loss: 0.249789  [ 6400/69881]
loss: 0.088867  [12800/69881]
loss: 0.173333  [19200/69881]
loss: 0.185844  [25600/69881]
loss: 0.186815  [32000/69881]
loss: 0.151579  [38400/69881]
loss: 0.219471  [44800/69881]
loss: 0.127127  [51200/69881]
loss: 0.127455  [57600/69881]
loss: 0.259851  [64000/69881]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.178337 

Epoch 27
-------------------------------
loss: 0.312610  [    0/69881]
loss: 0.212498  [ 6400/69881]
loss: 0.143072  [12800/69881]
loss: 0.162925  [19200/69881]
loss: 0.267334  [25600/69881]
loss: 0.117658  [32000/69881]
loss: 0.134724  [38400/69881]
loss: 0.143892  [44800/69881]
loss: 0.170505  [51200/69881]
loss: 0.323018  [57600/69881]
loss: 0.142433  [64000/69881]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.199507 

Epoch 28
-------------------------------
loss: 0.158298  [    0/69881]
loss: 0.166012  [ 6400/69881]
loss: 0.211617  [12800/69881]
loss: 0.328596  [19200/69881]
loss: 0.178225  [25600/69881]
loss: 0.269414  [44800/70227]
loss: 0.160711  [51200/70227]
loss: 0.128110  [57600/70227]
loss: 0.115898  [64000/70227]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.168951 

Epoch 14
-------------------------------
loss: 0.257357  [    0/70227]
loss: 0.240702  [ 6400/70227]
loss: 0.102626  [12800/70227]
loss: 0.251430  [19200/70227]
loss: 0.181254  [25600/70227]
loss: 0.255729  [32000/70227]
loss: 0.253879  [38400/70227]
loss: 0.134058  [44800/70227]
loss: 0.142659  [51200/70227]
loss: 0.190573  [57600/70227]
loss: 0.166681  [64000/70227]
Test Error: 
 Accuracy: 93.4%, Avg loss: 0.175559 

Epoch 15
-------------------------------
loss: 0.106715  [    0/70227]
loss: 0.101001  [ 6400/70227]
loss: 0.117385  [12800/70227]
loss: 0.218822  [19200/70227]
loss: 0.131389  [25600/70227]
loss: 0.202357  [32000/70227]
loss: 0.177626  [38400/70227]
loss: 0.193449  [44800/70227]
loss: 0.203110  [51200/70227]
loss: 1.706144  [57600/70227]
loss: 0.180807  [64000/70227]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.193969 

Epoch 16
-------------------------------
loss: 0.155581  [    0/70227]
loss: 0.161691  [ 6400/70227]
loss: 0.187746  [12800/70227]
loss: 0.178620  [19200/70227]
loss: 0.120072  [25600/70227]
loss: 0.277236  [32000/70227]
loss: 0.144343  [38400/70227]
loss: 0.191826  [44800/70227]
loss: 0.226628  [51200/70227]
loss: 0.183120  [57600/70227]
loss: 0.106359  [64000/70227]
Test Error: 
 Accuracy: 93.8%, Avg loss: 0.163687 

Epoch 17
-------------------------------
loss: 0.249618  [    0/70227]
loss: 0.202009  [ 6400/70227]
loss: 0.119577  [12800/70227]
loss: 0.188260  [19200/70227]
loss: 0.112598  [25600/70227]
loss: 0.251837  [32000/70227]
loss: 0.213473  [38400/70227]
loss: 0.119109  [44800/70227]
loss: 0.179168  [51200/70227]
loss: 0.151421  [57600/70227]
loss: 0.185829  [64000/70227]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.160629 

Epoch 18
-------------------------------
loss: 0.159980  [    0/70227]
loss: 0.182190  [ 6400/70227]
loss: 0.119527  [12800/70227]
loss: 0.239498  [19200/70227]
loss: 0.103664  [25600/70227]
loss: 0.103044  [32000/70227]
loss: 0.160375  [38400/70227]
loss: 0.111361  [44800/70227]
loss: 0.188796  [51200/70227]
loss: 0.124585  [57600/70227]
loss: 0.157822  [64000/70227]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.161099 

Epoch 19
-------------------------------
loss: 0.136263  [    0/70227]
loss: 0.126976  [ 6400/70227]
loss: 0.139485  [12800/70227]
loss: 0.290229  [19200/70227]
loss: 0.086111  [25600/70227]
loss: 0.271935  [32000/70227]
loss: 0.186733  [38400/70227]
loss: 0.281427  [44800/70227]
loss: 0.152367  [51200/70227]
loss: 0.176654  [57600/70227]
loss: 0.123534  [64000/70227]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.181517 

Epoch 20
-------------------------------
loss: 0.194785  [    0/70227]
loss: 0.207287  [ 6400/70227]
loss: 0.287424  [12800/70227]
loss: 0.202687  [19200/70227]
loss: 0.253310  [25600/70227]
loss: 0.173762  [32000/70227]
loss: 0.274710  [38400/70227]
loss: 0.239889  [44800/70227]
loss: 0.174864  [51200/70227]
loss: 0.194726  [57600/70227]
loss: 0.330064  [64000/70227]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.169962 

Epoch 21
-------------------------------
loss: 0.115231  [    0/70227]
loss: 0.196997  [ 6400/70227]
loss: 0.122819  [12800/70227]
loss: 0.148050  [19200/70227]
loss: 0.058433  [25600/70227]
loss: 0.127628  [32000/70227]
loss: 0.217945  [38400/70227]
loss: 0.161063  [44800/70227]
loss: 0.112072  [51200/70227]
loss: 0.138243  [57600/70227]
loss: 0.202219  [64000/70227]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.167320 

Epoch 22
-------------------------------
loss: 0.091678  [    0/70227]
loss: 0.150453  [ 6400/70227]
loss: 0.281926  [12800/70227]
loss: 0.153568  [19200/70227]
loss: 0.136080  [25600/70227]
loss: 0.160699  [32000/70227]
loss: 0.178964  [38400/70227]
loss: 0.135917  [44800/70227]
loss: 0.106330  [51200/70227]
loss: 0.225224  [57600/70227]
loss: 0.089524  [64000/70227]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.169833 

Epoch 23
-------------------------------
loss: 0.151999  [    0/70227]
loss: 0.181603  [ 6400/70227]
loss: 0.209083  [12800/70227]
loss: 0.150102  [19200/70227]
loss: 0.154509  [25600/70227]
loss: 0.258931  [32000/70227]
loss: 0.304314  [38400/70227]
loss: 0.251669  [44800/70227]
loss: 0.136356  [51200/70227]
loss: 0.127710  [57600/70227]
loss: 0.133602  [64000/70227]
Test Error: 
 Accuracy: 93.1%, Avg loss: 0.176726 

Epoch 24
-------------------------------
loss: 0.307552  [    0/70227]
loss: 0.102945  [ 6400/70227]
loss: 0.240016  [12800/70227]
loss: 0.127691  [19200/70227]
loss: 0.104309  [25600/70227]
loss: 0.139834  [32000/70227]
loss: 0.157001  [38400/70227]
loss: 0.075174  [44800/70227]
loss: 0.103784  [51200/70227]
loss: 0.165788  [57600/70227]
loss: 0.165969  [64000/70227]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.163196 

Epoch 25
-------------------------------
loss: 0.202000  [    0/70227]
loss: 0.148579  [ 6400/70227]
loss: 0.225278  [12800/70227]
loss: 0.161768  [19200/70227]
loss: 0.232592  [25600/70227]
loss: 0.150926  [32000/70227]
loss: 0.267119  [38400/70227]
loss: 0.151775  [44800/70227]
loss: 0.159670  [51200/70227]
loss: 0.102553  [57600/70227]
loss: 0.157697  [64000/70227]
Test Error: 
 Accuracy: 93.3%, Avg loss: 0.175323 

Epoch 26
-------------------------------
loss: 0.118893  [    0/70227]
loss: 0.158651  [ 6400/70227]
loss: 0.153258  [12800/70227]
loss: 0.128997  [19200/70227]
loss: 0.221164  [25600/70227]
loss: 0.098140  [32000/70227]
loss: 0.196346  [38400/70227]
loss: 0.208506  [44800/70227]
loss: 0.091679  [51200/70227]
loss: 0.084196  [57600/70227]
loss: 0.251184  [64000/70227]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.164325 

Epoch 27
-------------------------------
loss: 0.168926  [    0/70227]
loss: 0.306272  [ 6400/70227]
loss: 0.081949  [12800/70227]
loss: 0.261917  [19200/70227]
loss: 0.134241  [25600/70227]
loss: 0.135425  [32000/70227]
loss: 1.685742  [38400/70227]
loss: 0.238545  [44800/70227]
loss: 0.144261  [51200/70227]
loss: 0.114169  [57600/70227]
loss: 0.089546  [64000/70227]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.167914 

Epoch 28
-------------------------------
loss: 0.052020  [    0/70227]
loss: 0.191646  [ 6400/70227]
loss: 0.100879  [12800/70227]
loss: 0.158975  [19200/70227]
loss: 0.186606  [25600/70227]
loss: 0.161602  [32000/70227]
loss: 0.227339  [38400/70227]
loss: 0.194850  [44800/70227]
loss: 0.210229  [51200/70227]
loss: 0.188412  [57600/70227]
loss: 0.185046  [64000/70227]
Test Error: 
 Accuracy: 93.7%, Avg loss: 0.167771 

Epoch 29
-------------------------------
loss: 0.102848  [    0/70227]
loss: 0.112576  [ 6400/70227]
loss: 0.137750  [12800/70227]
loss: 0.080959  [19200/70227]
loss: 0.056164  [25600/70227]
loss: 0.128974  [32000/70227]
loss: 0.139324  [38400/70227]
loss: 0.152060  [44800/70227]
loss: 0.251758  [51200/70227]
loss: 0.090564  [57600/70227]
loss: 0.145539  [64000/70227]
Test Error: 
 Accuracy: 93.6%, Avg loss: 0.169621 

Epoch 30
-------------------------------
loss: 0.156663  [    0/70227]
loss: 0.129109  [ 6400/70227]
loss: 0.242007  [12800/70227]
loss: 0.261757  [19200/70227]
loss: 0.073478  [25600/70227]
loss: 0.117043  [32000/70227]
loss: 0.116643  [38400/70227]
loss: 0.147194  [44800/70227]
loss: 0.107758  [51200/70227]
loss: 0.134258  [57600/70227]
loss: 0.093869  [64000/70227]
Test Error: 
 Accuracy: 93.5%, Avg loss: 0.169779 

Epoch 31
-------------------------------
loss: 0.077472  [    0/70227]
loss: 0.143423  [ 6400/70227]
loss: 0.096600  [12800/70227]
loss: 0.113145  [19200/70227]
loss: 0.119794  [25600/70227]
loss: 0.212125  [32000/70227]
loss: 0.291500  [38400/70227]
loss: 0.285980  [44800/70227]
loss: 0.168007  [51200/70227]
loss: 0.044975  [57600/70227]
loss: 0.191668  [64000/70227]
Test Error: 
 Accuracy: 93.2%, Avg loss: 0.178233 

Epoch 32
-------------------------------
loss: 0.170464  [    0/70227]
loss: 0.140102  [ 6400/70227]
loss: 0.155167  [12800/70227]
loss: 0.205597  [19200/70227]
loss: 0.131897  [25600/70227]
loss: 0.277302  [32000/70227]
loss: 0.143250  [38400/70227]
loss: 0.157786  [44800/70227]
loss: 0.139397  [51200/70227]
loss: 0.147840  [57600/70227]
loss: 0.198984  [64000/70227]
loss: 0.140704  [32000/69881]
loss: 0.252870  [38400/69881]
loss: 0.158219  [44800/69881]
loss: 0.150817  [51200/69881]
loss: 0.180386  [57600/69881]
loss: 0.163816  [64000/69881]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.186745 

Epoch 29
-------------------------------
loss: 0.148313  [    0/69881]
loss: 0.140179  [ 6400/69881]
loss: 0.257268  [12800/69881]
loss: 0.170820  [19200/69881]
loss: 0.219817  [25600/69881]
loss: 0.064831  [32000/69881]
loss: 0.153095  [38400/69881]
loss: 0.219197  [44800/69881]
loss: 0.185548  [51200/69881]
loss: 0.133203  [57600/69881]
loss: 0.359459  [64000/69881]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.188147 

Epoch 30
-------------------------------
loss: 0.135020  [    0/69881]
loss: 0.126765  [ 6400/69881]
loss: 0.209955  [12800/69881]
loss: 1.698947  [19200/69881]
loss: 0.180404  [25600/69881]
loss: 0.105894  [32000/69881]
loss: 0.244465  [38400/69881]
loss: 0.160098  [44800/69881]
loss: 0.184653  [51200/69881]
loss: 0.165849  [57600/69881]
loss: 0.244780  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.174754 

Epoch 31
-------------------------------
loss: 0.144049  [    0/69881]
loss: 0.362741  [ 6400/69881]
loss: 0.134072  [12800/69881]
loss: 0.202565  [19200/69881]
loss: 0.227741  [25600/69881]
loss: 0.055113  [32000/69881]
loss: 0.126224  [38400/69881]
loss: 0.170135  [44800/69881]
loss: 0.100365  [51200/69881]
loss: 0.135423  [57600/69881]
loss: 0.231142  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.184142 

Epoch 32
-------------------------------
loss: 0.202487  [    0/69881]
loss: 0.152272  [ 6400/69881]
loss: 0.130921  [12800/69881]
loss: 0.168426  [19200/69881]
loss: 0.266190  [25600/69881]
loss: 0.102004  [32000/69881]
loss: 0.151339  [38400/69881]
loss: 0.282264  [44800/69881]
loss: 0.164591  [51200/69881]
loss: 0.196404  [57600/69881]
loss: 0.223606  [64000/69881]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.192344 

Epoch 33
-------------------------------
loss: 0.165076  [    0/69881]
loss: 0.135598  [ 6400/69881]
loss: 0.139055  [12800/69881]
loss: 0.180345  [19200/69881]
loss: 0.194765  [25600/69881]
loss: 0.121433  [32000/69881]
loss: 0.166366  [38400/69881]
loss: 0.222405  [44800/69881]
loss: 0.120659  [51200/69881]
loss: 0.133122  [57600/69881]
loss: 0.207416  [64000/69881]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.194139 

Epoch 34
-------------------------------
loss: 0.189492  [    0/69881]
loss: 0.212131  [ 6400/69881]
loss: 0.185414  [12800/69881]
loss: 0.104273  [19200/69881]
loss: 0.137207  [25600/69881]
loss: 0.294631  [32000/69881]
loss: 0.141911  [38400/69881]
loss: 0.181328  [44800/69881]
loss: 0.084390  [51200/69881]
loss: 0.146047  [57600/69881]
loss: 0.166993  [64000/69881]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.178751 

Epoch 35
-------------------------------
loss: 0.102359  [    0/69881]
loss: 0.272415  [ 6400/69881]
loss: 0.224908  [12800/69881]
loss: 0.153879  [19200/69881]
loss: 0.179930  [25600/69881]
loss: 0.237262  [32000/69881]
loss: 0.180249  [38400/69881]
loss: 0.114340  [44800/69881]
loss: 0.179366  [51200/69881]
loss: 0.186024  [57600/69881]
loss: 0.179980  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.179743 

Epoch 36
-------------------------------
loss: 0.097297  [    0/69881]
loss: 0.159061  [ 6400/69881]
loss: 0.068066  [12800/69881]
loss: 0.243325  [19200/69881]
loss: 0.315821  [25600/69881]
loss: 0.211626  [32000/69881]
loss: 0.209534  [38400/69881]
loss: 0.188376  [44800/69881]
loss: 0.080793  [51200/69881]
loss: 0.186691  [57600/69881]
loss: 0.161794  [64000/69881]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.180769 

Epoch 37
-------------------------------
loss: 0.099050  [    0/69881]
loss: 0.169604  [ 6400/69881]
loss: 0.161638  [12800/69881]
loss: 0.191763  [19200/69881]
loss: 0.216326  [25600/69881]
loss: 0.212821  [32000/69881]
loss: 0.091322  [38400/69881]
loss: 0.145370  [44800/69881]
loss: 0.115272  [51200/69881]
loss: 0.108195  [57600/69881]
loss: 0.052601  [64000/69881]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.180192 

Epoch 38
-------------------------------
loss: 0.186507  [    0/69881]
loss: 0.190539  [ 6400/69881]
loss: 0.090013  [12800/69881]
loss: 0.152165  [19200/69881]
loss: 0.158544  [25600/69881]
loss: 0.059112  [32000/69881]
loss: 0.148878  [38400/69881]
loss: 0.145909  [44800/69881]
loss: 0.180282  [51200/69881]
loss: 0.141918  [57600/69881]
loss: 0.160522  [64000/69881]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.180299 

Epoch 39
-------------------------------
loss: 0.154246  [    0/69881]
loss: 0.165641  [ 6400/69881]
loss: 0.218992  [12800/69881]
loss: 0.150921  [19200/69881]
loss: 0.178818  [25600/69881]
loss: 0.088649  [32000/69881]
loss: 0.201007  [38400/69881]
loss: 0.216678  [44800/69881]
loss: 0.184229  [51200/69881]
loss: 0.329015  [57600/69881]
loss: 0.188160  [64000/69881]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.188979 

Epoch 40
-------------------------------
loss: 0.209069  [    0/69881]
loss: 0.191181  [ 6400/69881]
loss: 0.182795  [12800/69881]
loss: 0.235472  [19200/69881]
loss: 0.112365  [25600/69881]
loss: 0.261740  [32000/69881]
loss: 0.134106  [38400/69881]
loss: 0.198275  [44800/69881]
loss: 0.199295  [51200/69881]
loss: 0.251648  [57600/69881]
loss: 0.108395  [64000/69881]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.193512 

Epoch 41
-------------------------------
loss: 0.341132  [    0/69881]
loss: 0.209259  [ 6400/69881]
loss: 0.153947  [12800/69881]
loss: 0.142780  [19200/69881]
loss: 0.283502  [25600/69881]
loss: 0.132258  [32000/69881]
loss: 0.220868  [38400/69881]
loss: 0.213496  [44800/69881]
loss: 0.106217  [51200/69881]
loss: 0.192045  [57600/69881]
loss: 0.109982  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.184520 

Epoch 42
-------------------------------
loss: 0.119099  [    0/69881]
loss: 0.113035  [ 6400/69881]
loss: 0.101079  [12800/69881]
loss: 0.211350  [19200/69881]
loss: 0.147695  [25600/69881]
loss: 0.198112  [32000/69881]
loss: 0.211030  [38400/69881]
loss: 0.113087  [44800/69881]
loss: 0.174410  [51200/69881]
loss: 0.215315  [57600/69881]
loss: 0.120007  [64000/69881]
Test Error: 
 Accuracy: 91.6%, Avg loss: 0.193276 

Epoch 43
-------------------------------
loss: 0.162107  [    0/69881]
loss: 0.152106  [ 6400/69881]
loss: 0.307376  [12800/69881]
loss: 0.145628  [19200/69881]
loss: 0.118507  [25600/69881]
loss: 0.189564  [32000/69881]
loss: 0.111255  [38400/69881]
loss: 0.151911  [44800/69881]
loss: 0.169558  [51200/69881]
loss: 0.311222  [57600/69881]
loss: 0.203546  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.187581 

Epoch 44
-------------------------------
loss: 0.146373  [    0/69881]
loss: 0.122410  [ 6400/69881]
loss: 0.087752  [12800/69881]
loss: 0.275610  [19200/69881]
loss: 0.187114  [25600/69881]
loss: 0.142002  [32000/69881]
loss: 0.231220  [38400/69881]
loss: 0.159744  [44800/69881]
loss: 0.160151  [51200/69881]
loss: 0.152376  [57600/69881]
loss: 0.290197  [64000/69881]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.180186 

Epoch 45
-------------------------------
loss: 0.172057  [    0/69881]
loss: 0.210619  [ 6400/69881]
loss: 0.161229  [12800/69881]
loss: 0.072854  [19200/69881]
loss: 0.191075  [25600/69881]
loss: 0.072854  [32000/69881]
loss: 0.092005  [38400/69881]
loss: 0.208189  [44800/69881]
loss: 0.339013  [51200/69881]
loss: 0.141305  [57600/69881]
loss: 0.110707  [64000/69881]
Test Error: 
 Accuracy: 92.8%, Avg loss: 0.181034 

Epoch 46
-------------------------------
loss: 0.124666  [    0/69881]
loss: 0.096351  [ 6400/69881]
loss: 0.280322  [12800/69881]
loss: 0.198987  [19200/69881]
loss: 0.186026  [25600/69881]
loss: 0.099900  [32000/69881]
loss: 0.266654  [38400/69881]
loss: 0.198683  [44800/69881]
loss: 0.199439  [51200/69881]
loss: 0.203147  [57600/69881]
loss: 0.166102  [64000/69881]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.196035 

Epoch 47
-------------------------------
loss: 0.220378  [    0/69881]
loss: 0.139164  [ 6400/69881]
loss: 0.130395  [12800/69881]
loss: 0.099521  [19200/69881]
loss: 0.085541  [25600/69881]
loss: 0.168230  [32000/69881]
loss: 0.232475  [38400/69881]
loss: 0.117238  [44800/69881]
loss: 0.296027  [51200/69881]
loss: 0.162810  [57600/69881]
2022/09/20 22:19:09 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
2022/09/20 22:23:05 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
loss: 0.304414  [64000/69881]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.179430 

Epoch 48
-------------------------------
loss: 0.134091  [    0/69881]
loss: 0.150810  [ 6400/69881]
loss: 0.141714  [12800/69881]
loss: 0.127184  [19200/69881]
loss: 0.101533  [25600/69881]
loss: 0.262096  [32000/69881]
loss: 0.167617  [38400/69881]
loss: 0.125385  [44800/69881]
loss: 0.407641  [51200/69881]
loss: 0.145792  [57600/69881]
loss: 0.159810  [64000/69881]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.181533 

Epoch 49
-------------------------------
loss: 0.254577  [    0/69881]
loss: 0.150876  [ 6400/69881]
loss: 0.179954  [12800/69881]
loss: 0.200050  [19200/69881]
loss: 0.258000  [25600/69881]
loss: 0.372341  [32000/69881]
loss: 0.174356  [38400/69881]
loss: 0.146859  [44800/69881]
loss: 0.194890  [51200/69881]
loss: 0.252816  [57600/69881]
loss: 0.219809  [64000/69881]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.185047 

Epoch 50
-------------------------------
loss: 0.233609  [    0/69881]
loss: 0.233380  [ 6400/69881]
loss: 0.108648  [12800/69881]
loss: 0.200919  [19200/69881]
loss: 0.164345  [25600/69881]
loss: 0.144218  [32000/69881]
loss: 0.093660  [38400/69881]
loss: 0.226302  [44800/69881]
loss: 0.241966  [51200/69881]
loss: 0.232288  [57600/69881]
loss: 0.150765  [64000/69881]
Test Error: 
 Accuracy: 91.3%, Avg loss: 0.211615 

Epoch 1
-------------------------------
loss: 0.703079  [    0/70056]
loss: 0.167539  [ 6400/70056]
loss: 0.406584  [12800/70056]
loss: 0.245864  [19200/70056]
loss: 0.201907  [25600/70056]
loss: 0.470665  [32000/70056]
loss: 0.229426  [38400/70056]
loss: 0.070756  [44800/70056]
loss: 0.243263  [51200/70056]
loss: 0.306877  [57600/70056]
loss: 0.279175  [64000/70056]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.205453 

Epoch 2
-------------------------------
loss: 0.187413  [    0/70056]
loss: 0.253278  [ 6400/70056]
loss: 0.207720  [12800/70056]
loss: 0.154229  [19200/70056]
loss: 0.112658  [25600/70056]
loss: 0.173342  [32000/70056]
loss: 0.169968  [38400/70056]
loss: 0.146635  [44800/70056]
loss: 0.331627  [51200/70056]
loss: 0.112010  [57600/70056]
loss: 0.208145  [64000/70056]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.189337 

Epoch 3
-------------------------------
loss: 0.270508  [    0/70056]
loss: 0.231503  [ 6400/70056]
loss: 0.283090  [12800/70056]
loss: 0.163712  [19200/70056]
loss: 0.236955  [25600/70056]
loss: 0.110217  [32000/70056]
loss: 0.227488  [38400/70056]
loss: 0.295014  [44800/70056]
loss: 0.158506  [51200/70056]
loss: 0.190671  [57600/70056]
loss: 0.169184  [64000/70056]
Test Error: 
 Accuracy: 91.9%, Avg loss: 0.188857 

Epoch 4
-------------------------------
loss: 0.221585  [    0/70056]
loss: 0.092552  [ 6400/70056]
loss: 0.184426  [12800/70056]
loss: 0.184188  [19200/70056]
loss: 0.275339  [25600/70056]
loss: 0.204762  [32000/70056]
loss: 0.184403  [38400/70056]
loss: 0.205350  [44800/70056]
loss: 0.196073  [51200/70056]
loss: 0.228579  [57600/70056]
loss: 0.351912  [64000/70056]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.181408 

Epoch 5
-------------------------------
loss: 0.162929  [    0/70056]
loss: 0.138668  [ 6400/70056]
loss: 0.155330  [12800/70056]
loss: 0.144803  [19200/70056]
loss: 0.169905  [25600/70056]
loss: 0.418769  [32000/70056]
loss: 0.179537  [38400/70056]
loss: 0.161909  [44800/70056]
loss: 0.196101  [51200/70056]
loss: 0.281055  [57600/70056]
loss: 0.223581  [64000/70056]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.179979 

Epoch 6
-------------------------------
loss: 0.112656  [    0/70056]
loss: 0.165113  [ 6400/70056]
loss: 0.188470  [12800/70056]
loss: 0.290225  [19200/70056]
loss: 0.203728  [25600/70056]
loss: 0.169051  [32000/70056]
loss: 0.193449  [38400/70056]
loss: 0.226292  [44800/70056]
loss: 0.171477  [51200/70056]
loss: 0.191313  [57600/70056]
loss: 0.154274  [64000/70056]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.174239 

Epoch 7
-------------------------------
loss: 0.094322  [    0/70056]
loss: 0.165442  [ 6400/70056]
loss: 0.147794  [12800/70056]
loss: 0.195413  [19200/70056]
loss: 0.184961  [25600/70056]
loss: 0.133122  [32000/70056]
loss: 0.223934  [38400/70056]
loss: 0.145799  [44800/70056]
loss: 0.296792  [51200/70056]
loss: 0.180771  [57600/70056]
loss: 0.080574  [64000/70056]
Test Error: 
 Accuracy: 91.7%, Avg loss: 0.192913 

Epoch 8
-------------------------------
loss: 0.221125  [    0/70056]
loss: 0.220038  [ 6400/70056]
loss: 0.180200  [12800/70056]
loss: 0.139363  [19200/70056]
loss: 0.225868  [25600/70056]
loss: 0.174345  [32000/70056]
loss: 0.258402  [38400/70056]
loss: 0.224336  [44800/70056]
loss: 0.250515  [51200/70056]
loss: 0.335817  [57600/70056]
loss: 0.308005  [64000/70056]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.172537 

Epoch 9
-------------------------------
loss: 0.123282  [    0/70056]
loss: 0.105039  [ 6400/70056]
loss: 0.259814  [12800/70056]
loss: 0.120607  [19200/70056]
loss: 0.094133  [25600/70056]
loss: 0.176319  [32000/70056]
loss: 0.170200  [38400/70056]
loss: 0.235453  [44800/70056]
loss: 0.140622  [51200/70056]
loss: 0.149811  [57600/70056]
loss: 0.215903  [64000/70056]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.171834 

Epoch 10
-------------------------------
loss: 0.246695  [    0/70056]
loss: 0.217224  [ 6400/70056]
loss: 0.103877  [12800/70056]
loss: 0.280224  [19200/70056]
loss: 0.119161  [25600/70056]
loss: 0.202452  [32000/70056]
loss: 0.126953  [38400/70056]
loss: 0.237513  [44800/70056]
loss: 0.291974  [51200/70056]
loss: 0.194019  [57600/70056]
loss: 0.232089  [64000/70056]
Test Error: 
 Accuracy: 92.7%, Avg loss: 0.172589 

Epoch 11
-------------------------------
loss: 0.147508  [    0/70056]
loss: 0.117071  [ 6400/70056]
loss: 0.097277  [12800/70056]
loss: 0.184773  [19200/70056]
loss: 0.156385  [25600/70056]
loss: 0.179593  [32000/70056]
loss: 0.146757  [38400/70056]
loss: 0.163074  [44800/70056]
loss: 0.149543  [51200/70056]
loss: 0.176894  [57600/70056]
loss: 0.270508  [64000/70056]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.170090 

Epoch 12
-------------------------------
loss: 0.156001  [    0/70056]
loss: 0.164867  [ 6400/70056]
loss: 0.244628  [12800/70056]
loss: 0.143964  [19200/70056]
loss: 0.269249  [25600/70056]
loss: 0.160197  [32000/70056]
loss: 0.261664  [38400/70056]
loss: 0.137523  [44800/70056]
loss: 0.128824  [51200/70056]
loss: 0.085805  [57600/70056]
loss: 0.118189  [64000/70056]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.171238 

Epoch 13
-------------------------------
loss: 0.220924  [    0/70056]
loss: 0.152092  [ 6400/70056]
loss: 0.104740  [12800/70056]
loss: 0.285083  [19200/70056]
loss: 0.195063  [25600/70056]
loss: 0.187580  [32000/70056]
loss: 0.220917  [38400/70056]
loss: 0.161516  [44800/70056]
loss: 0.171010  [51200/70056]
loss: 0.178147  [57600/70056]
loss: 0.288922  [64000/70056]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.172576 

Epoch 14
-------------------------------
loss: 0.111514  [    0/70056]
loss: 0.129071  [ 6400/70056]
loss: 0.111203  [12800/70056]
loss: 0.159810  [19200/70056]
loss: 0.282548  [25600/70056]
loss: 0.165891  [32000/70056]
loss: 0.191546  [38400/70056]
loss: 0.132113  [44800/70056]
loss: 0.127264  [51200/70056]
loss: 0.236726  [57600/70056]
loss: 0.182757  [64000/70056]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.179649 

Epoch 15
-------------------------------
loss: 0.260234  [    0/70056]
loss: 0.326302  [ 6400/70056]
loss: 0.258412  [12800/70056]
loss: 0.046933  [19200/70056]
loss: 0.189128  [25600/70056]
loss: 0.047843  [32000/70056]
loss: 0.195493  [38400/70056]
loss: 0.222088  [44800/70056]
loss: 0.129628  [51200/70056]
loss: 0.179291  [57600/70056]
loss: 0.077304  [64000/70056]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.183869 

Epoch 16
-------------------------------
loss: 0.136826  [    0/70056]
loss: 0.103744  [ 6400/70056]
loss: 0.277800  [12800/70056]
loss: 0.087707  [19200/70056]
loss: 0.206868  [25600/70056]
loss: 0.231598  [32000/70056]
loss: 0.201661  [38400/70056]
loss: 0.249046  [44800/70056]
loss: 0.213570  [51200/70056]
loss: 0.303261  [57600/70056]
loss: 0.146963  [64000/70056]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.174442 

Epoch 17
-------------------------------
loss: 0.282412  [    0/70056]
loss: 0.213074  [ 6400/70056]
loss: 0.131320  [12800/70056]
loss: 0.130255  [19200/70056]
loss: 0.206743  [25600/70056]
loss: 0.182949  [32000/70056]
loss: 0.205015  [38400/70056]
loss: 0.153683  [44800/70056]
loss: 0.190415  [51200/70056]
loss: 0.255377  [57600/70056]
loss: 0.253258  [64000/70056]
Test Error: 
 Accuracy: 92.6%, Avg loss: 0.173304 

Epoch 18
-------------------------------
loss: 0.147382  [    0/70056]
loss: 0.157307  [ 6400/70056]
loss: 0.191943  [12800/70056]
loss: 0.165400  [19200/70056]
loss: 0.146191  [25600/70056]
loss: 0.130457  [32000/70056]
loss: 0.128849  [38400/70056]
loss: 0.277838  [44800/70056]
loss: 0.224635  [51200/70056]
loss: 0.220544  [57600/70056]
loss: 0.167801  [64000/70056]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.170006 

Epoch 19
-------------------------------
loss: 0.105847  [    0/70056]
loss: 0.172177  [ 6400/70056]
loss: 0.130540  [12800/70056]
loss: 0.161507  [19200/70056]
loss: 0.105968  [25600/70056]
loss: 0.062156  [32000/70056]
loss: 0.146030  [38400/70056]
loss: 0.108074  [44800/70056]
loss: 0.238293  [51200/70056]
loss: 0.148357  [57600/70056]
loss: 0.237166  [64000/70056]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.171473 

Epoch 20
-------------------------------
loss: 0.168988  [    0/70056]
loss: 0.201091  [ 6400/70056]
loss: 0.133545  [12800/70056]
loss: 0.111769  [19200/70056]
loss: 0.152451  [25600/70056]
loss: 0.158193  [32000/70056]
loss: 0.109378  [38400/70056]
loss: 0.252145  [44800/70056]
loss: 0.168288  [51200/70056]
loss: 0.149661  [57600/70056]
loss: 0.324209  [64000/70056]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.186004 

Epoch 21
-------------------------------
loss: 0.207618  [    0/70056]
loss: 0.158937  [ 6400/70056]
loss: 0.177745  [12800/70056]
loss: 0.181067  [19200/70056]
loss: 0.155331  [25600/70056]
loss: 0.169527  [32000/70056]
loss: 0.287016  [38400/70056]
loss: 0.193075  [44800/70056]
loss: 0.128429  [51200/70056]
loss: 0.113650  [57600/70056]
loss: 0.124334  [64000/70056]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.179193 

Epoch 22
-------------------------------
loss: 0.142519  [    0/70056]
loss: 0.214125  [ 6400/70056]
loss: 0.150959  [12800/70056]
loss: 0.126132  [19200/70056]
loss: 0.187701  [25600/70056]
loss: 0.174726  [32000/70056]
loss: 0.193897  [38400/70056]
loss: 0.316687  [44800/70056]
loss: 0.114386  [51200/70056]
loss: 0.227137  [57600/70056]
loss: 0.207575  [64000/70056]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.171814 

Epoch 23
-------------------------------
loss: 0.146532  [    0/70056]
loss: 0.310417  [ 6400/70056]
loss: 0.234462  [12800/70056]
loss: 0.214586  [19200/70056]
loss: 0.150889  [25600/70056]
loss: 0.294406  [32000/70056]
loss: 0.157794  [38400/70056]
loss: 0.138212  [44800/70056]
loss: 0.216868  [51200/70056]
loss: 0.260494  [57600/70056]
loss: 0.199062  [64000/70056]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.171231 

Epoch 24
-------------------------------
loss: 0.201165  [    0/70056]
loss: 0.117465  [ 6400/70056]
loss: 0.202007  [12800/70056]
loss: 0.139432  [19200/70056]
loss: 0.167594  [25600/70056]
loss: 0.176519  [32000/70056]
loss: 0.209101  [38400/70056]
loss: 0.273745  [44800/70056]
loss: 0.137532  [51200/70056]
loss: 0.161755  [57600/70056]
loss: 0.201124  [64000/70056]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.169233 

Epoch 25
-------------------------------
loss: 0.105340  [    0/70056]
loss: 0.129801  [ 6400/70056]
loss: 0.116511  [12800/70056]
loss: 0.139271  [19200/70056]
loss: 0.225777  [25600/70056]
loss: 0.254651  [32000/70056]
loss: 0.149150  [38400/70056]
loss: 0.196822  [44800/70056]
loss: 0.062778  [51200/70056]
loss: 0.129982  [57600/70056]
loss: 0.275867  [64000/70056]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.174058 

Epoch 26
-------------------------------
loss: 0.151964  [    0/70056]
loss: 0.192043  [ 6400/70056]
loss: 0.137128  [12800/70056]
loss: 0.261874  [19200/70056]
loss: 0.199023  [25600/70056]
loss: 0.062906  [32000/70056]
loss: 0.114870  [38400/70056]
loss: 0.130985  [44800/70056]
loss: 0.174165  [51200/70056]
loss: 0.127764  [57600/70056]
loss: 0.145817  [64000/70056]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.176751 

Epoch 27
-------------------------------
loss: 0.151289  [    0/70056]
loss: 0.097945  [ 6400/70056]
loss: 0.184442  [12800/70056]
loss: 0.224673  [19200/70056]
loss: 0.181356  [25600/70056]
loss: 0.214589  [32000/70056]
loss: 0.155458  [38400/70056]
loss: 0.153247  [44800/70056]
loss: 0.157260  [51200/70056]
loss: 0.107416  [57600/70056]
loss: 0.210848  [64000/70056]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.179088 

Epoch 28
-------------------------------
loss: 0.153659  [    0/70056]
loss: 0.081829  [ 6400/70056]
loss: 0.159466  [12800/70056]
loss: 0.098865  [19200/70056]
loss: 0.213377  [25600/70056]
loss: 0.170458  [32000/70056]
loss: 0.227410  [38400/70056]
loss: 0.111197  [44800/70056]
loss: 0.109375  [51200/70056]
loss: 0.136876  [57600/70056]
loss: 0.158073  [64000/70056]
Test Error: 
 Accuracy: 92.0%, Avg loss: 0.180659 

Epoch 29
-------------------------------
loss: 0.253565  [    0/70056]
loss: 0.118162  [ 6400/70056]
loss: 0.140143  [12800/70056]
loss: 0.146527  [19200/70056]
loss: 0.249206  [25600/70056]
loss: 0.195949  [32000/70056]
loss: 0.170657  [38400/70056]
loss: 0.174987  [44800/70056]
loss: 0.100282  [51200/70056]
loss: 0.118563  [57600/70056]
loss: 0.063873  [64000/70056]
Test Error: 
 Accuracy: 92.4%, Avg loss: 0.172884 

Epoch 30
-------------------------------
loss: 0.190704  [    0/70056]
loss: 0.162455  [ 6400/70056]
loss: 0.186370  [12800/70056]
loss: 0.173721  [19200/70056]
loss: 0.207405  [25600/70056]
loss: 0.143923  [32000/70056]
loss: 0.272641  [38400/70056]
loss: 0.184793  [44800/70056]
loss: 0.145475  [51200/70056]
loss: 0.178801  [57600/70056]
loss: 0.139143  [64000/70056]
Test Error: 
 Accuracy: 91.8%, Avg loss: 0.183715 

Epoch 31
-------------------------------
loss: 0.134098  [    0/70056]
loss: 0.082001  [ 6400/70056]
loss: 0.206679  [12800/70056]
loss: 0.144010  [19200/70056]
loss: 0.101736  [25600/70056]
loss: 0.039428  [32000/70056]
loss: 0.175900  [38400/70056]
loss: 0.186125  [44800/70056]
loss: 0.232758  [51200/70056]
loss: 0.175315  [57600/70056]
loss: 0.195428  [64000/70056]
Test Error: 
 Accuracy: 92.5%, Avg loss: 0.171189 

Epoch 32
-------------------------------
loss: 0.195770  [    0/70056]
loss: 0.106896  [ 6400/70056]
loss: 0.125049  [12800/70056]
loss: 0.214505  [19200/70056]
loss: 0.138781  [25600/70056]
loss: 0.126504  [32000/70056]
loss: 0.285034  [38400/70056]
loss: 0.171945  [44800/70056]
loss: 0.124161  [51200/70056]
loss: 0.228720  [57600/70056]
loss: 0.126136  [64000/70056]
Test Error: 
 Accuracy: 92.1%, Avg loss: 0.173583 

Epoch 33
-------------------------------
loss: 0.175003  [    0/70056]
loss: 0.169644  [ 6400/70056]
loss: 0.164861  [12800/70056]
loss: 0.256685  [19200/70056]
loss: 0.198729  [25600/70056]
loss: 0.195614  [32000/70056]
loss: 0.230399  [38400/70056]
loss: 0.195054  [44800/70056]
loss: 0.134747  [51200/70056]
loss: 0.143990  [57600/70056]
loss: 0.162518  [64000/70056]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.181668 

Epoch 34
-------------------------------
loss: 0.163788  [    0/70056]
loss: 0.207091  [ 6400/70056]
loss: 0.122624  [12800/70056]
loss: 0.102391  [19200/70056]
loss: 0.190946  [25600/70056]
loss: 0.174516  [32000/70056]
loss: 0.210065  [38400/70056]
loss: 0.171131  [44800/70056]
loss: 0.166503  [51200/70056]
loss: 0.194732  [57600/70056]
loss: 0.112291  [64000/70056]
Test Error: 
 Accuracy: 92.2%, Avg loss: 0.179969 

Epoch 35
-------------------------------
loss: 0.124200  [    0/70056]
loss: 0.197497  [ 6400/70056]
loss: 0.173047  [12800/70056]
loss: 0.161475  [19200/70056]
loss: 0.193852  [25600/70056]
loss: 0.109175  [32000/70056]
loss: 0.227158  [38400/70056]
loss: 0.216888  [44800/70056]
loss: 0.106995  [51200/70056]
loss: 0.194321  [57600/70056]
loss: 0.203607  [64000/70056]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.174537 

Epoch 36
-------------------------------
loss: 0.115724  [    0/70056]
loss: 0.191358  [ 6400/70056]
loss: 0.101160  [12800/70056]
loss: 0.265300  [19200/70056]
loss: 0.057522  [25600/70056]
loss: 0.155811  [32000/70056]
2022/09/20 22:35:50 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-07-25; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'negativeclassoptimization'}
